/nishome/yui/ModifiedNGD/utils/readData.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/nishome/yui/anaconda3/envs/ng/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971214/work/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train info: 
 train data shape: torch.Size([512, 1]), 
 train lable shape: torch.Size([512, 1]), 
 positive / negative: 0.021206805482506752 / 0.978793203830719, 
 discrepancy norm error: 5.045955617788422e-07
Test info: 
 test data shape: torch.Size([128, 1]), 
 test lable shape: torch.Size([128, 1]), , 
 positive / negative: -0.030759211629629135 / 1.0307592153549194, 
 discrepancy norm error: 2.750667249529215e-07
Valid info: 
 valid data shape: torch.Size([128, 1]), valid lable shape: torch.Size([128, 1]), 
 positive / negative: 0.015859205275774002 / 0.9841408133506775, 
 discrepancy norm error: 2.3576444618811365e-07
torch.Size([512, 1]) torch.Size([512])
seed is  2191
---------------------------------------- NGD ----------------------------------------
OUTPUT CHECK:  torch.Size([512]) tensor(0.1397, device='cuda:0', grad_fn=<MaxBackward1>) tensor(0.0746, device='cuda:0', grad_fn=<MinBackward1>) 
TARGET:  torch.Size([512]) tensor(0.5000, device='cuda:0') tensor(-0.5000, device='cuda:0')
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 0/10 [00:00<?, ?it/s]Epoch:   1
Test train Loss:  0.06383244693279266
Test train Acc:  0.0
Test Loss:  0.07182655483484268
Test Acc:  0.0
Valid Loss:  0.06421749293804169
Valid Acc:  0.0
max of grad d_p:  tensor(0.1105, device='cuda:0')
min of grad d_p:  tensor(-0.0534, device='cuda:0')
max|min: (J_L, Jta/N)  (0.11054785549640656, 0.08841674029827118, ratio: 0.7998051047325134)|(-0.05340873822569847, -0.018510928377509117)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.0717, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0349, device='cuda:0') norm:  tensor(0.6158, device='cuda:0') MSE:  tensor(9.2340e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0014, device='cuda:0') mean:  tensor(3.8285e-05, device='cuda:0') min:  tensor(9.0949e-11, device='cuda:0') norm:  tensor(0.0195, device='cuda:0') MSE:  tensor(2.9275e-07, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0027, device='cuda:0')
min of d_p_list:  tensor(-0.0022, device='cuda:0')
Epoch:  1  
Training Loss: 0.06376429120427929
Test Loss:  0.07167794555425644
Test Acc:  0.0
Valid Loss:  0.06408243626356125
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 1/10 [00:02<00:21,  2.44s/it]Epoch:   2
max of grad d_p:  tensor(0.0968, device='cuda:0')
min of grad d_p:  tensor(-0.0522, device='cuda:0')
max|min: (J_L, Jta/N)  (0.09684774279594421, 0.08806109428405762, ratio: 0.9092735648155212)|(-0.05220925062894821, -0.018520938232541084)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.0618, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0337, device='cuda:0') norm:  tensor(0.6050, device='cuda:0') MSE:  tensor(9.0720e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(8.8483e-06, device='cuda:0') min:  tensor(1.4438e-11, device='cuda:0') norm:  tensor(0.0057, device='cuda:0') MSE:  tensor(8.5333e-08, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0020, device='cuda:0')
min of d_p_list:  tensor(-0.0024, device='cuda:0')
Epoch:  2  
Training Loss: 0.06334049999713898
Test Loss:  0.07138723880052567
Test Acc:  0.0
Valid Loss:  0.06380879878997803
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 2/10 [00:04<00:19,  2.41s/it]Epoch:   3
max of grad d_p:  tensor(0.1074, device='cuda:0')
min of grad d_p:  tensor(-0.0531, device='cuda:0')
max|min: (J_L, Jta/N)  (0.10735790431499481, 0.0876389890909195, ratio: 0.8163254261016846)|(-0.053062908351421356, -0.019133176654577255)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.0680, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0339, device='cuda:0') norm:  tensor(0.5996, device='cuda:0') MSE:  tensor(8.9905e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(5.6070e-06, device='cuda:0') min:  tensor(8.1855e-12, device='cuda:0') norm:  tensor(0.0031, device='cuda:0') MSE:  tensor(4.6729e-08, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0063, device='cuda:0')
min of d_p_list:  tensor(-0.0070, device='cuda:0')
Epoch:  3  
Training Loss: 0.06283311545848846
Test Loss:  0.07087099552154541
Test Acc:  0.0
Valid Loss:  0.0633319765329361
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 3/10 [00:07<00:16,  2.36s/it]Epoch:   4
max of grad d_p:  tensor(0.1296, device='cuda:0')
min of grad d_p:  tensor(-0.0546, device='cuda:0')
max|min: (J_L, Jta/N)  (0.12955649197101593, 0.0869525820016861, ratio: 0.6711557507514954)|(-0.05458031967282295, -0.023665878921747208)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.0726, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0309, device='cuda:0') norm:  tensor(0.5342, device='cuda:0') MSE:  tensor(8.0109e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(6.3573e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0032, device='cuda:0') MSE:  tensor(4.8219e-08, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0030, device='cuda:0')
Epoch:  4  
Training Loss: 0.0624859519302845
Test Loss:  0.07054278254508972
Test Acc:  0.0
Valid Loss:  0.06301955133676529
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 4/10 [00:09<00:14,  2.37s/it]Epoch:   5
max of grad d_p:  tensor(0.1473, device='cuda:0')
min of grad d_p:  tensor(-0.0565, device='cuda:0')
max|min: (J_L, Jta/N)  (0.14726755023002625, 0.08635944128036499, ratio: 0.5864118933677673)|(-0.056533049792051315, -0.020196301862597466)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.0938, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0363, device='cuda:0') norm:  tensor(0.6115, device='cuda:0') MSE:  tensor(9.1688e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0006, device='cuda:0') mean:  tensor(1.4503e-05, device='cuda:0') min:  tensor(1.3097e-10, device='cuda:0') norm:  tensor(0.0077, device='cuda:0') MSE:  tensor(1.1589e-07, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0026, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  5  
Training Loss: 0.06214071810245514
Test Loss:  0.07021679729223251
Test Acc:  0.0
Valid Loss:  0.06270938366651535
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 5/10 [00:11<00:11,  2.35s/it]Epoch:   6
max of grad d_p:  tensor(0.1642, device='cuda:0')
min of grad d_p:  tensor(-0.0575, device='cuda:0')
max|min: (J_L, Jta/N)  (0.16415026783943176, 0.08580145984888077, ratio: 0.5227007269859314)|(-0.057535313069820404, -0.01769876480102539)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.1125, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0398, device='cuda:0') norm:  tensor(0.6629, device='cuda:0') MSE:  tensor(9.9403e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(5.1087e-06, device='cuda:0') min:  tensor(2.3647e-11, device='cuda:0') norm:  tensor(0.0027, device='cuda:0') MSE:  tensor(3.9882e-08, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0065, device='cuda:0')
min of d_p_list:  tensor(-0.0047, device='cuda:0')
Epoch:  6  
Training Loss: 0.061686545610427856
Test Loss:  0.06977664679288864
Test Acc:  0.0
Valid Loss:  0.062296126037836075
Valid Acc:  0.0
std:  0.0005671614133495273 
thres:  6.2497366219759e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 6/10 [00:14<00:09,  2.35s/it]Epoch:   7
max of grad d_p:  tensor(0.1867, device='cuda:0')
min of grad d_p:  tensor(-0.0587, device='cuda:0')
max|min: (J_L, Jta/N)  (0.1867125928401947, 0.08513226360082626, ratio: 0.4559535086154938)|(-0.058722879737615585, -0.017366046085953712)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.1299, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0414, device='cuda:0') norm:  tensor(0.6763, device='cuda:0') MSE:  tensor(1.0141e-05, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(8.7028e-06, device='cuda:0') min:  tensor(8.7311e-11, device='cuda:0') norm:  tensor(0.0046, device='cuda:0') MSE:  tensor(6.9464e-08, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0050, device='cuda:0')
Epoch:  7  
Training Loss: 0.061234086751937866
Test Loss:  0.06933913379907608
Test Acc:  0.0
Valid Loss:  0.06188131868839264
Valid Acc:  0.0
std:  0.0005667389944781984 
thres:  6.207608357071877e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 7/10 [00:16<00:07,  2.35s/it]Epoch:   8
max of grad d_p:  tensor(0.2072, device='cuda:0')
min of grad d_p:  tensor(-0.0604, device='cuda:0')
max|min: (J_L, Jta/N)  (0.2072472870349884, 0.08430150151252747, ratio: 0.40676769614219666)|(-0.060400210320949554, -0.020308611914515495)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.1362, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0401, device='cuda:0') norm:  tensor(0.6516, device='cuda:0') MSE:  tensor(9.7706e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(5.1312e-06, device='cuda:0') min:  tensor(2.9104e-11, device='cuda:0') norm:  tensor(0.0028, device='cuda:0') MSE:  tensor(4.1581e-08, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0042, device='cuda:0')
min of d_p_list:  tensor(-0.0049, device='cuda:0')
Epoch:  8  
Training Loss: 0.060833126306533813
Test Loss:  0.06894301623106003
Test Acc:  0.0
Valid Loss:  0.06150960922241211
Valid Acc:  0.0
std:  0.0005962918076266898 
thres:  6.167608574032784e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 8/10 [00:18<00:04,  2.35s/it]Epoch:   9
max of grad d_p:  tensor(0.2180, device='cuda:0')
min of grad d_p:  tensor(-0.0607, device='cuda:0')
max|min: (J_L, Jta/N)  (0.21802762150764465, 0.08358751237392426, ratio: 0.38338038325309753)|(-0.060722120106220245, -0.014227932319045067)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.1659, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0465, device='cuda:0') norm:  tensor(0.7642, device='cuda:0') MSE:  tensor(1.1459e-05, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0004, device='cuda:0') mean:  tensor(7.5484e-06, device='cuda:0') min:  tensor(3.1832e-12, device='cuda:0') norm:  tensor(0.0042, device='cuda:0') MSE:  tensor(6.2693e-08, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0066, device='cuda:0')
min of d_p_list:  tensor(-0.0061, device='cuda:0')
Epoch:  9  
Training Loss: 0.06041619926691055
Test Loss:  0.06851989030838013
Test Acc:  0.0
Valid Loss:  0.06112198531627655
Valid Acc:  0.0
std:  0.0006086830147079393 
thres:  6.126213520765304e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 9/10 [00:21<00:02,  2.35s/it]Epoch:   10
max of grad d_p:  tensor(0.2412, device='cuda:0')
min of grad d_p:  tensor(-0.0621, device='cuda:0')
max|min: (J_L, Jta/N)  (0.24118494987487793, 0.08607305586338043, ratio: 0.3568757474422455)|(-0.06213746592402458, -0.021708179265260696)

 check Jacobi res:  torch.Size([66689]) max:  tensor(0.1551, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0404, device='cuda:0') norm:  tensor(0.6609, device='cuda:0') MSE:  tensor(9.9102e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([66689, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(1.0461e-05, device='cuda:0') min:  tensor(3.3651e-11, device='cuda:0') norm:  tensor(0.0062, device='cuda:0') MSE:  tensor(9.3390e-08, device='cuda:0')
Shape check:  torch.Size([66689, 1])
max of d_p_list:  tensor(0.0058, device='cuda:0')
min of d_p_list:  tensor(-0.0051, device='cuda:0')
Epoch:  10  
Training Loss: 0.06012013182044029
Test Loss:  0.06822609901428223
Test Acc:  0.0
Valid Loss:  0.060853831470012665
Valid Acc:  0.0
std:  0.0005600330545107112 
thres:  6.085801795125008e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|██████████| 10/10 [00:23<00:00,  2.35s/it]100%|██████████| 10/10 [00:23<00:00,  2.36s/it]
