/home/yuyi/Documents/ModifiedNGD/utils/readData.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/home/yuyi/anaconda3/envs/ng/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/autograd/engine.cpp:1151.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
train data shape torch.Size([256, 2])
train label shape torch.Size([256, 1])
torch.Size([256, 3])
train_data shape torch.Size([3])
seed is  1
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:49,  6.35s/it]  1%|          | 3/500 [00:06<14:07,  1.71s/it]  1%|          | 5/500 [00:06<07:08,  1.16it/s]  1%|▏         | 7/500 [00:06<04:21,  1.88it/s]  2%|▏         | 9/500 [00:06<02:54,  2.82it/s]  2%|▏         | 11/500 [00:13<11:08,  1.37s/it]  3%|▎         | 13/500 [00:13<07:35,  1.07it/s]  3%|▎         | 15/500 [00:13<05:17,  1.53it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:20<09:38,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:33,  2.21it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:27<09:16,  1.19s/it]  7%|▋         | 33/500 [00:27<06:37,  1.17it/s]  7%|▋         | 35/500 [00:27<04:45,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<09:00,  1.18s/it]  9%|▊         | 43/500 [00:34<06:25,  1.18it/s]  9%|▉         | 45/500 [00:34<04:37,  1.64it/s]  9%|▉         | 47/500 [00:34<03:25,  2.21it/s] 10%|▉         | 49/500 [00:34<02:34,  2.92it/s] 10%|█         | 51/500 [00:40<08:58,  1.20s/it] 11%|█         | 53/500 [00:41<06:24,  1.16it/s] 11%|█         | 55/500 [00:41<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:48<08:57,  1.22s/it] 13%|█▎        | 63/500 [00:48<06:23,  1.14it/s] 13%|█▎        | 65/500 [00:48<04:36,  1.57it/s] 13%|█▎        | 67/500 [00:48<03:21,  2.15it/s] 14%|█▍        | 69/500 [00:48<02:28,  2.91it/s] 14%|█▍        | 71/500 [00:54<08:30,  1.19s/it]Epoch:  1  	Training Loss: 0.030495241284370422
Test Loss:  0.09587612748146057
Valid Loss:  0.07749278843402863
Epoch:  2  	Training Loss: 0.07536043971776962
Test Loss:  0.015902141109108925
Valid Loss:  0.026615887880325317
Epoch:  3  	Training Loss: 0.04286036267876625
Test Loss:  0.014297077432274818
Valid Loss:  0.024012519046664238
Epoch:  4  	Training Loss: 0.03791532665491104
Test Loss:  0.012927870266139507
Valid Loss:  0.02163848839700222
Epoch:  5  	Training Loss: 0.03391818702220917
Test Loss:  0.012303188443183899
Valid Loss:  0.020765267312526703
Epoch:  6  	Training Loss: 0.03307734429836273
Test Loss:  0.012018073350191116
Valid Loss:  0.020502224564552307
Epoch:  7  	Training Loss: 0.03276824951171875
Test Loss:  0.011407864280045033
Valid Loss:  0.019739829003810883
Epoch:  8  	Training Loss: 0.03247219696640968
Test Loss:  0.011484188959002495
Valid Loss:  0.01987798511981964
Epoch:  9  	Training Loss: 0.03236991912126541
Test Loss:  0.011065024882555008
Valid Loss:  0.019377481192350388
Epoch:  10  	Training Loss: 0.03219165280461311
Test Loss:  0.01102598849684
Valid Loss:  0.019385594874620438
Epoch:  11  	Training Loss: 0.03210964798927307
Test Loss:  0.01088293269276619
Valid Loss:  0.019213933497667313
Epoch:  12  	Training Loss: 0.03203820437192917
Test Loss:  0.010811088606715202
Valid Loss:  0.019140144810080528
Epoch:  13  	Training Loss: 0.03198431432247162
Test Loss:  0.010732806287705898
Valid Loss:  0.019053012132644653
Epoch:  14  	Training Loss: 0.031936485320329666
Test Loss:  0.010670661926269531
Valid Loss:  0.018986456096172333
Epoch:  15  	Training Loss: 0.03189396858215332
Test Loss:  0.010618364438414574
Valid Loss:  0.018934126943349838
Epoch:  16  	Training Loss: 0.031854625791311264
Test Loss:  0.010568622499704361
Valid Loss:  0.0188856553286314
Epoch:  17  	Training Loss: 0.03181897848844528
Test Loss:  0.010515738278627396
Valid Loss:  0.018829595297574997
Epoch:  18  	Training Loss: 0.031787268817424774
Test Loss:  0.010475235059857368
Valid Loss:  0.018791601061820984
Epoch:  19  	Training Loss: 0.031758688390254974
Test Loss:  0.010436355136334896
Valid Loss:  0.01875302568078041
Epoch:  20  	Training Loss: 0.0317329578101635
Test Loss:  0.010399965569376945
Valid Loss:  0.018717225641012192
Epoch:  21  	Training Loss: 0.03170959651470184
Test Loss:  0.010367266833782196
Valid Loss:  0.018685422837734222
Epoch:  22  	Training Loss: 0.03168841451406479
Test Loss:  0.010340256616473198
Valid Loss:  0.018659131601452827
Epoch:  23  	Training Loss: 0.031668953597545624
Test Loss:  0.010317239910364151
Valid Loss:  0.01863701269030571
Epoch:  24  	Training Loss: 0.031650446355342865
Test Loss:  0.010297039523720741
Valid Loss:  0.018617436289787292
Epoch:  25  	Training Loss: 0.03163270652294159
Test Loss:  0.010279913432896137
Valid Loss:  0.018599506467580795
Epoch:  26  	Training Loss: 0.03161568194627762
Test Loss:  0.01026428584009409
Valid Loss:  0.0185827799141407
Epoch:  27  	Training Loss: 0.03160005062818527
Test Loss:  0.010239856317639351
Valid Loss:  0.01856035552918911
Epoch:  28  	Training Loss: 0.03158543258905411
Test Loss:  0.010221505537629128
Valid Loss:  0.018542800098657608
Epoch:  29  	Training Loss: 0.031572163105010986
Test Loss:  0.010203901678323746
Valid Loss:  0.018526311963796616
Epoch:  30  	Training Loss: 0.03156011551618576
Test Loss:  0.01019059494137764
Valid Loss:  0.018512431532144547
Epoch:  31  	Training Loss: 0.03154873102903366
Test Loss:  0.010179614648222923
Valid Loss:  0.018500154837965965
Epoch:  32  	Training Loss: 0.03153780847787857
Test Loss:  0.010166788473725319
Valid Loss:  0.018487565219402313
Epoch:  33  	Training Loss: 0.031527839601039886
Test Loss:  0.010153341107070446
Valid Loss:  0.018475297838449478
Epoch:  34  	Training Loss: 0.03151861950755119
Test Loss:  0.010141161270439625
Valid Loss:  0.018464192748069763
Epoch:  35  	Training Loss: 0.03151004761457443
Test Loss:  0.01013152115046978
Valid Loss:  0.018454601988196373
Epoch:  36  	Training Loss: 0.03150201588869095
Test Loss:  0.010117113590240479
Valid Loss:  0.01844378188252449
Epoch:  37  	Training Loss: 0.03149471431970596
Test Loss:  0.01011291891336441
Valid Loss:  0.01843671128153801
Epoch:  38  	Training Loss: 0.031488023698329926
Test Loss:  0.010097719728946686
Valid Loss:  0.018426986411213875
Epoch:  39  	Training Loss: 0.031481556594371796
Test Loss:  0.010088454000651836
Valid Loss:  0.018419520929455757
Epoch:  40  	Training Loss: 0.031475748866796494
Test Loss:  0.010080895386636257
Valid Loss:  0.018412873148918152
Epoch:  41  	Training Loss: 0.03147030994296074
Test Loss:  0.010075114667415619
Valid Loss:  0.01840689778327942
Epoch:  42  	Training Loss: 0.03146512061357498
Test Loss:  0.010070424526929855
Valid Loss:  0.018401633948087692
Epoch:  43  	Training Loss: 0.031460173428058624
Test Loss:  0.010066387243568897
Valid Loss:  0.01839715987443924
Epoch:  44  	Training Loss: 0.031455349177122116
Test Loss:  0.01006275974214077
Valid Loss:  0.018392976373434067
Epoch:  45  	Training Loss: 0.031450700014829636
Test Loss:  0.010056812316179276
Valid Loss:  0.018388239666819572
Epoch:  46  	Training Loss: 0.031446296721696854
Test Loss:  0.010052220895886421
Valid Loss:  0.018384099006652832
Epoch:  47  	Training Loss: 0.03144208341836929
Test Loss:  0.01004771701991558
Valid Loss:  0.01838015764951706
Epoch:  48  	Training Loss: 0.03143802285194397
Test Loss:  0.010044018737971783
Valid Loss:  0.018376654013991356
Epoch:  49  	Training Loss: 0.0314340814948082
Test Loss:  0.01004079170525074
Valid Loss:  0.018373381346464157
Epoch:  50  	Training Loss: 0.031430281698703766
Test Loss:  0.010035550221800804
Valid Loss:  0.01836974546313286
Epoch:  51  	Training Loss: 0.03142666816711426
Test Loss:  0.010031575337052345
Valid Loss:  0.01836656779050827
Epoch:  52  	Training Loss: 0.031423211097717285
Test Loss:  0.010027900338172913
Valid Loss:  0.018363580107688904
Epoch:  53  	Training Loss: 0.03141997382044792
Test Loss:  0.010025132447481155
Valid Loss:  0.018360843881964684
Epoch:  54  	Training Loss: 0.03141685575246811
Test Loss:  0.010022887960076332
Valid Loss:  0.018358545377850533
Epoch:  55  	Training Loss: 0.03141389787197113
Test Loss:  0.010017745196819305
Valid Loss:  0.018355604261159897
Epoch:  56  	Training Loss: 0.03141103684902191
Test Loss:  0.01001422293484211
Valid Loss:  0.018353259190917015
Epoch:  57  	Training Loss: 0.03140834718942642
Test Loss:  0.010011658072471619
Valid Loss:  0.018351256847381592
Epoch:  58  	Training Loss: 0.0314057320356369
Test Loss:  0.0100096445530653
Valid Loss:  0.018349457532167435
Epoch:  59  	Training Loss: 0.03140316158533096
Test Loss:  0.010008173063397408
Valid Loss:  0.018347792327404022
Epoch:  60  	Training Loss: 0.0314006544649601
Test Loss:  0.010007031261920929
Valid Loss:  0.018346209079027176
Epoch:  61  	Training Loss: 0.03139820694923401
Test Loss:  0.010006133466959
Valid Loss:  0.018344705924391747
Epoch:  62  	Training Loss: 0.03139586001634598
Test Loss:  0.010002641007304192
Valid Loss:  0.01834273338317871
Epoch:  63  	Training Loss: 0.03139355778694153
Test Loss:  0.01000033039599657
Valid Loss:  0.018341070041060448
Epoch:  64  	Training Loss: 0.031391337513923645
Test Loss:  0.009997949004173279
Valid Loss:  0.01833944395184517
Epoch:  65  	Training Loss: 0.03138917684555054
Test Loss:  0.009996280074119568
Valid Loss:  0.018337998539209366
Epoch:  66  	Training Loss: 0.03138705715537071
Test Loss:  0.009995019063353539
Valid Loss:  0.018336649984121323
Epoch:  67  	Training Loss: 0.031384970992803574
Test Loss:  0.009994005784392357
Valid Loss:  0.0183353740721941
Epoch:  68  	Training Loss: 0.03138290345668793
Test Loss:  0.009993143379688263
Valid Loss:  0.018334142863750458
Epoch:  69  	Training Loss: 0.03138086944818497
Test Loss:  0.00999239832162857
Valid Loss:  0.0183329489082098
Epoch:  70  	Training Loss: 0.0313788503408432
Test Loss:  0.009991742670536041
Valid Loss:  0.018331903964281082
Epoch:  71  	Training Loss: 0.03137686103582382
Test Loss:  0.009991124272346497
Valid Loss:  0.018330952152609825
Epoch:  72  	Training Loss: 0.03137488290667534
Test Loss:   15%|█▍        | 73/500 [00:55<06:04,  1.17it/s] 15%|█▌        | 75/500 [00:55<04:22,  1.62it/s] 15%|█▌        | 77/500 [00:55<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:55<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:01<08:20,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:57,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:02<03:11,  2.16it/s] 18%|█▊        | 89/500 [01:02<02:23,  2.85it/s] 18%|█▊        | 91/500 [01:08<08:11,  1.20s/it] 19%|█▊        | 93/500 [01:09<05:50,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:12,  1.61it/s] 19%|█▉        | 97/500 [01:09<03:03,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:15,  2.95it/s] 20%|██        | 101/500 [01:15<07:49,  1.18s/it] 21%|██        | 103/500 [01:15<05:35,  1.18it/s] 21%|██        | 105/500 [01:15<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:16<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:16<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:22<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:26,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:22<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:23<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:29<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:29<02:52,  2.16it/s] 26%|██▌       | 129/500 [01:30<02:08,  2.89it/s] 26%|██▌       | 131/500 [01:36<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:36<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:36<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:36<02:45,  2.19it/s] 28%|██▊       | 139/500 [01:36<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:43<07:05,  1.18s/it]0.009990551508963108
Valid Loss:  0.018330078572034836
Epoch:  73  	Training Loss: 0.031372979283332825
Test Loss:  0.009989988058805466
Valid Loss:  0.018329236656427383
Epoch:  74  	Training Loss: 0.031371090561151505
Test Loss:  0.009989431127905846
Valid Loss:  0.018328417092561722
Epoch:  75  	Training Loss: 0.031369224190711975
Test Loss:  0.009988836944103241
Valid Loss:  0.018327608704566956
Epoch:  76  	Training Loss: 0.0313674658536911
Test Loss:  0.00998588278889656
Valid Loss:  0.01832621544599533
Epoch:  77  	Training Loss: 0.031365737318992615
Test Loss:  0.009986313059926033
Valid Loss:  0.018325697630643845
Epoch:  78  	Training Loss: 0.03136404603719711
Test Loss:  0.009984059259295464
Valid Loss:  0.018324507400393486
Epoch:  79  	Training Loss: 0.03136235475540161
Test Loss:  0.009982557967305183
Valid Loss:  0.01832350715994835
Epoch:  80  	Training Loss: 0.03136071562767029
Test Loss:  0.009980835020542145
Valid Loss:  0.018322475254535675
Epoch:  81  	Training Loss: 0.031359098851680756
Test Loss:  0.00997963733971119
Valid Loss:  0.018321573734283447
Epoch:  82  	Training Loss: 0.031357504427433014
Test Loss:  0.009978755377233028
Valid Loss:  0.018320757895708084
Epoch:  83  	Training Loss: 0.03135594353079796
Test Loss:  0.009978026151657104
Valid Loss:  0.0183199904859066
Epoch:  84  	Training Loss: 0.03135441988706589
Test Loss:  0.009977389127016068
Valid Loss:  0.01831926964223385
Epoch:  85  	Training Loss: 0.031352922320365906
Test Loss:  0.009976845234632492
Valid Loss:  0.01831855997443199
Epoch:  86  	Training Loss: 0.03135143220424652
Test Loss:  0.009976358152925968
Valid Loss:  0.018317868933081627
Epoch:  87  	Training Loss: 0.03134995698928833
Test Loss:  0.009975900873541832
Valid Loss:  0.018317244946956635
Epoch:  88  	Training Loss: 0.03134849667549133
Test Loss:  0.009975429624319077
Valid Loss:  0.01831670291721821
Epoch:  89  	Training Loss: 0.03134706988930702
Test Loss:  0.009975009597837925
Valid Loss:  0.018316201865673065
Epoch:  90  	Training Loss: 0.031345706433057785
Test Loss:  0.009970244020223618
Valid Loss:  0.018314478918910027
Epoch:  91  	Training Loss: 0.031344346702098846
Test Loss:  0.00997035950422287
Valid Loss:  0.01831395924091339
Epoch:  92  	Training Loss: 0.03134295716881752
Test Loss:  0.009971524588763714
Valid Loss:  0.0183139368891716
Epoch:  93  	Training Loss: 0.031341664493083954
Test Loss:  0.009967774152755737
Valid Loss:  0.01831240765750408
Epoch:  94  	Training Loss: 0.0313403457403183
Test Loss:  0.009968453086912632
Valid Loss:  0.01831219717860222
Epoch:  95  	Training Loss: 0.03133903443813324
Test Loss:  0.009965639561414719
Valid Loss:  0.018310967832803726
Epoch:  96  	Training Loss: 0.031337760388851166
Test Loss:  0.009966861456632614
Valid Loss:  0.01831093803048134
Epoch:  97  	Training Loss: 0.031336478888988495
Test Loss:  0.00996439065784216
Valid Loss:  0.018309809267520905
Epoch:  98  	Training Loss: 0.03133518993854523
Test Loss:  0.009965794160962105
Valid Loss:  0.0183098204433918
Epoch:  99  	Training Loss: 0.03133396804332733
Test Loss:  0.00996225606650114
Valid Loss:  0.018308386206626892
Epoch:  100  	Training Loss: 0.03133266046643257
Test Loss:  0.009961186908185482
Valid Loss:  0.018307644873857498
Epoch:  101  	Training Loss: 0.031331419944763184
Test Loss:  0.009963326156139374
Valid Loss:  0.01830783672630787
Epoch:  102  	Training Loss: 0.03133023530244827
Test Loss:  0.00995825044810772
Valid Loss:  0.018306000158190727
Epoch:  103  	Training Loss: 0.03132897987961769
Test Loss:  0.009962409734725952
Valid Loss:  0.018306709825992584
Epoch:  104  	Training Loss: 0.03132782131433487
Test Loss:  0.009956812486052513
Valid Loss:  0.018304739147424698
Epoch:  105  	Training Loss: 0.0313265360891819
Test Loss:  0.009960027411580086
Valid Loss:  0.018305154517292976
Epoch:  106  	Training Loss: 0.03132539615035057
Test Loss:  0.009955639950931072
Valid Loss:  0.0183035209774971
Epoch:  107  	Training Loss: 0.031324129551649094
Test Loss:  0.009956011548638344
Valid Loss:  0.01830313913524151
Epoch:  108  	Training Loss: 0.031322918832302094
Test Loss:  0.009954900480806828
Valid Loss:  0.018302366137504578
Epoch:  109  	Training Loss: 0.031321726739406586
Test Loss:  0.00995403528213501
Valid Loss:  0.018301663920283318
Epoch:  110  	Training Loss: 0.031320542097091675
Test Loss:  0.00995335727930069
Valid Loss:  0.018300998955965042
Epoch:  111  	Training Loss: 0.03131936490535736
Test Loss:  0.009952775202691555
Valid Loss:  0.018300358206033707
Epoch:  112  	Training Loss: 0.03131818398833275
Test Loss:  0.009952250868082047
Valid Loss:  0.018299724906682968
Epoch:  113  	Training Loss: 0.031317003071308136
Test Loss:  0.009951736778020859
Valid Loss:  0.018299119547009468
Epoch:  114  	Training Loss: 0.03131583333015442
Test Loss:  0.009951254352927208
Valid Loss:  0.018298517912626266
Epoch:  115  	Training Loss: 0.031314667314291
Test Loss:  0.009950228035449982
Valid Loss:  0.018297772854566574
Epoch:  116  	Training Loss: 0.03131349757313728
Test Loss:  0.009949998930096626
Valid Loss:  0.0182972252368927
Epoch:  117  	Training Loss: 0.031312331557273865
Test Loss:  0.009949689731001854
Valid Loss:  0.018296649679541588
Epoch:  118  	Training Loss: 0.031311169266700745
Test Loss:  0.009949327446520329
Valid Loss:  0.018296070396900177
Epoch:  119  	Training Loss: 0.031310006976127625
Test Loss:  0.009948947466909885
Valid Loss:  0.01829547807574272
Epoch:  120  	Training Loss: 0.031308844685554504
Test Loss:  0.009946583770215511
Valid Loss:  0.018294401466846466
Epoch:  121  	Training Loss: 0.03130768984556198
Test Loss:  0.009946947917342186
Valid Loss:  0.018293963745236397
Epoch:  122  	Training Loss: 0.03130653500556946
Test Loss:  0.009946441277861595
Valid Loss:  0.01829332672059536
Epoch:  123  	Training Loss: 0.031305380165576935
Test Loss:  0.009946480393409729
Valid Loss:  0.018292827531695366
Epoch:  124  	Training Loss: 0.031304240226745605
Test Loss:  0.009944380261003971
Valid Loss:  0.018291819840669632
Epoch:  125  	Training Loss: 0.03130310773849487
Test Loss:  0.009944338351488113
Valid Loss:  0.018291283398866653
Epoch:  126  	Training Loss: 0.031301967799663544
Test Loss:  0.00994468666613102
Valid Loss:  0.018290838226675987
Epoch:  127  	Training Loss: 0.031300827860832214
Test Loss:  0.00994277372956276
Valid Loss:  0.018289869651198387
Epoch:  128  	Training Loss: 0.03129969909787178
Test Loss:  0.009942837059497833
Valid Loss:  0.018289342522621155
Epoch:  129  	Training Loss: 0.031298551708459854
Test Loss:  0.00994324404746294
Valid Loss:  0.018288910388946533
Epoch:  130  	Training Loss: 0.03129743039608002
Test Loss:  0.009940818883478642
Valid Loss:  0.018287822604179382
Epoch:  131  	Training Loss: 0.031296297907829285
Test Loss:  0.00994167197495699
Valid Loss:  0.01828746683895588
Epoch:  132  	Training Loss: 0.03129515051841736
Test Loss:  0.009940065443515778
Valid Loss:  0.0182865671813488
Epoch:  133  	Training Loss: 0.03129405155777931
Test Loss:  0.009940307587385178
Valid Loss:  0.018286069855093956
Epoch:  134  	Training Loss: 0.031292907893657684
Test Loss:  0.009938880801200867
Valid Loss:  0.018285220488905907
Epoch:  135  	Training Loss: 0.031291812658309937
Test Loss:  0.0099392244592309
Valid Loss:  0.01828474923968315
Epoch:  136  	Training Loss: 0.03129067271947861
Test Loss:  0.00993786659091711
Valid Loss:  0.018283912912011147
Epoch:  137  	Training Loss: 0.03128957748413086
Test Loss:  0.009938244707882404
Valid Loss:  0.018283437937498093
Epoch:  138  	Training Loss: 0.03128844127058983
Test Loss:  0.009936904534697533
Valid Loss:  0.018282609060406685
Epoch:  139  	Training Loss: 0.03128734603524208
Test Loss:  0.009937296621501446
Valid Loss:  0.01828213408589363
Epoch:  140  	Training Loss: 0.03128620982170105
Test Loss:  0.009935963898897171
Valid Loss:  0.018281299620866776
Epoch:  141  	Training Loss: 0.031285110861063004
Test Loss:  0.009936358779668808
Valid Loss:  0.01828082650899887
Epoch:  142  	Training Loss: 0.03128397837281227
Test Loss:  0.009935026988387108
Valid Loss:  0.018279988318681717
Epoch:  143  	Training Loss: 0.031282879412174225
Test Loss:   29%|██▊       | 143/500 [01:43<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:43<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:43<02:42,  2.17it/s] 30%|██▉       | 149/500 [01:43<02:02,  2.87it/s] 30%|███       | 151/500 [01:50<07:00,  1.21s/it] 31%|███       | 153/500 [01:50<05:00,  1.16it/s] 31%|███       | 155/500 [01:50<03:35,  1.60it/s] 31%|███▏      | 157/500 [01:50<02:36,  2.19it/s] 32%|███▏      | 159/500 [01:50<01:55,  2.95it/s] 32%|███▏      | 161/500 [01:57<06:43,  1.19s/it] 33%|███▎      | 163/500 [01:57<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:57<03:27,  1.62it/s] 33%|███▎      | 167/500 [01:57<02:31,  2.19it/s] 34%|███▍      | 169/500 [01:57<01:54,  2.90it/s] 34%|███▍      | 171/500 [02:04<06:38,  1.21s/it] 35%|███▍      | 173/500 [02:04<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:04<03:23,  1.59it/s] 35%|███▌      | 177/500 [02:04<02:27,  2.18it/s] 36%|███▌      | 179/500 [02:04<01:49,  2.94it/s] 36%|███▌      | 181/500 [02:11<06:22,  1.20s/it] 37%|███▋      | 183/500 [02:11<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:11<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:11<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:18<06:08,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:18<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:18<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:18<01:40,  2.99it/s] 40%|████      | 201/500 [02:25<06:01,  1.21s/it] 41%|████      | 203/500 [02:25<04:17,  1.15it/s] 41%|████      | 205/500 [02:25<03:04,  1.59it/s] 41%|████▏     | 207/500 [02:25<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:25<01:38,  2.94it/s] 42%|████▏     | 211/500 [02:32<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:32<04:09,  1.15it/s]0.009935401380062103
Valid Loss:  0.018279530107975006
Epoch:  144  	Training Loss: 0.03128177300095558
Test Loss:  0.009934051893651485
Valid Loss:  0.018278688192367554
Epoch:  145  	Training Loss: 0.031280677765607834
Test Loss:  0.009934441186487675
Valid Loss:  0.018278222531080246
Epoch:  146  	Training Loss: 0.03127957135438919
Test Loss:  0.009933105669915676
Valid Loss:  0.01827738620340824
Epoch:  147  	Training Loss: 0.031278472393751144
Test Loss:  0.009933492168784142
Valid Loss:  0.018276922404766083
Epoch:  148  	Training Loss: 0.0312773697078228
Test Loss:  0.009931622073054314
Valid Loss:  0.018275965005159378
Epoch:  149  	Training Loss: 0.03127627447247505
Test Loss:  0.00993276946246624
Valid Loss:  0.018275652080774307
Epoch:  150  	Training Loss: 0.031275175511837006
Test Loss:  0.009930812753736973
Valid Loss:  0.01827467978000641
Epoch:  151  	Training Loss: 0.03127407282590866
Test Loss:  0.009931908920407295
Valid Loss:  0.01827436313033104
Epoch:  152  	Training Loss: 0.03127298131585121
Test Loss:  0.009929923340678215
Valid Loss:  0.01827339455485344
Epoch:  153  	Training Loss: 0.03127187862992287
Test Loss:  0.009931002743542194
Valid Loss:  0.01827307790517807
Epoch:  154  	Training Loss: 0.03127080202102661
Test Loss:  0.009928945451974869
Valid Loss:  0.018272100016474724
Epoch:  155  	Training Loss: 0.031269703060388565
Test Loss:  0.009929983876645565
Valid Loss:  0.01827177405357361
Epoch:  156  	Training Loss: 0.031268633902072906
Test Loss:  0.009927961975336075
Valid Loss:  0.01827080547809601
Epoch:  157  	Training Loss: 0.03126753121614456
Test Loss:  0.00992901623249054
Valid Loss:  0.018270477652549744
Epoch:  158  	Training Loss: 0.0312664657831192
Test Loss:  0.009927005507051945
Valid Loss:  0.018269505351781845
Epoch:  159  	Training Loss: 0.03126535937190056
Test Loss:  0.009926144033670425
Valid Loss:  0.0182687658816576
Epoch:  160  	Training Loss: 0.0312642902135849
Test Loss:  0.009926811791956425
Valid Loss:  0.018268335610628128
Epoch:  161  	Training Loss: 0.03126320242881775
Test Loss:  0.00992510374635458
Valid Loss:  0.018267426639795303
Epoch:  162  	Training Loss: 0.0312621109187603
Test Loss:  0.009926339611411095
Valid Loss:  0.01826711744070053
Epoch:  163  	Training Loss: 0.03126103803515434
Test Loss:  0.009924449026584625
Valid Loss:  0.01826617494225502
Epoch:  164  	Training Loss: 0.031259939074516296
Test Loss:  0.009923657402396202
Valid Loss:  0.01826545223593712
Epoch:  165  	Training Loss: 0.03125888481736183
Test Loss:  0.009924354031682014
Valid Loss:  0.018265021964907646
Epoch:  166  	Training Loss: 0.03125780075788498
Test Loss:  0.009922681376338005
Valid Loss:  0.01826412044465542
Epoch:  167  	Training Loss: 0.03125671669840813
Test Loss:  0.00992392934858799
Valid Loss:  0.018263811245560646
Epoch:  168  	Training Loss: 0.03125564754009247
Test Loss:  0.009922045283019543
Valid Loss:  0.018262866884469986
Epoch:  169  	Training Loss: 0.03125455603003502
Test Loss:  0.00992125365883112
Valid Loss:  0.018262140452861786
Epoch:  170  	Training Loss: 0.03125349432229996
Test Loss:  0.009921949356794357
Valid Loss:  0.018261706456542015
Epoch:  171  	Training Loss: 0.0312524139881134
Test Loss:  0.009920279495418072
Valid Loss:  0.01826079934835434
Epoch:  172  	Training Loss: 0.03125132620334625
Test Loss:  0.009921526536345482
Valid Loss:  0.018260488286614418
Epoch:  173  	Training Loss: 0.03125027194619179
Test Loss:  0.009919633157551289
Valid Loss:  0.01825954020023346
Epoch:  174  	Training Loss: 0.03124917671084404
Test Loss:  0.009918825700879097
Valid Loss:  0.01825881004333496
Epoch:  175  	Training Loss: 0.03124811500310898
Test Loss:  0.009919527918100357
Valid Loss:  0.01825837790966034
Epoch:  176  	Training Loss: 0.03124704398214817
Test Loss:  0.009917834773659706
Valid Loss:  0.018257470801472664
Epoch:  177  	Training Loss: 0.031245959922671318
Test Loss:  0.009917185641825199
Valid Loss:  0.01825675554573536
Epoch:  178  	Training Loss: 0.031244900077581406
Test Loss:  0.009917931631207466
Valid Loss:  0.018256332725286484
Epoch:  179  	Training Loss: 0.03124382719397545
Test Loss:  0.009916320443153381
Valid Loss:  0.018255436792969704
Epoch:  180  	Training Loss: 0.031242741271853447
Test Loss:  0.009917574003338814
Valid Loss:  0.018255114555358887
Epoch:  181  	Training Loss: 0.03124169260263443
Test Loss:  0.009915712289512157
Valid Loss:  0.018254173919558525
Epoch:  182  	Training Loss: 0.03124060109257698
Test Loss:  0.009914949536323547
Valid Loss:  0.018253440037369728
Epoch:  183  	Training Loss: 0.03123953565955162
Test Loss:  0.00991562008857727
Valid Loss:  0.01825299672782421
Epoch:  184  	Training Loss: 0.031238466501235962
Test Loss:  0.009913939982652664
Valid Loss:  0.018252089619636536
Epoch:  185  	Training Loss: 0.031237389892339706
Test Loss:  0.009913291782140732
Valid Loss:  0.01825137436389923
Epoch:  186  	Training Loss: 0.031236328184604645
Test Loss:  0.009914068505167961
Valid Loss:  0.018250949680805206
Epoch:  187  	Training Loss: 0.031235257163643837
Test Loss:  0.009912419132888317
Valid Loss:  0.01825004443526268
Epoch:  188  	Training Loss: 0.031234178692102432
Test Loss:  0.009913697838783264
Valid Loss:  0.018249724060297012
Epoch:  189  	Training Loss: 0.031233124434947968
Test Loss:  0.009911799803376198
Valid Loss:  0.018248775973916054
Epoch:  190  	Training Loss: 0.031232040375471115
Test Loss:  0.00991104356944561
Valid Loss:  0.018248042091727257
Epoch:  191  	Training Loss: 0.031230978667736053
Test Loss:  0.009911715984344482
Valid Loss:  0.01824759691953659
Epoch:  192  	Training Loss: 0.031229911372065544
Test Loss:  0.009910035878419876
Valid Loss:  0.018246687948703766
Epoch:  193  	Training Loss: 0.031228836625814438
Test Loss:  0.009909385815262794
Valid Loss:  0.018245970830321312
Epoch:  194  	Training Loss: 0.031227778643369675
Test Loss:  0.009910158812999725
Valid Loss:  0.01824554055929184
Epoch:  195  	Training Loss: 0.031226709485054016
Test Loss:  0.009908515028655529
Valid Loss:  0.018244635313749313
Epoch:  196  	Training Loss: 0.031225642189383507
Test Loss:  0.00990976206958294
Valid Loss:  0.01824430376291275
Epoch:  197  	Training Loss: 0.031224587932229042
Test Loss:  0.009907913394272327
Valid Loss:  0.01824336312711239
Epoch:  198  	Training Loss: 0.031223507598042488
Test Loss:  0.009907138533890247
Valid Loss:  0.018242623656988144
Epoch:  199  	Training Loss: 0.031222453340888023
Test Loss:  0.009907806292176247
Valid Loss:  0.01824217475950718
Epoch:  200  	Training Loss: 0.031221386045217514
Test Loss:  0.009906124323606491
Valid Loss:  0.018241263926029205
Epoch:  201  	Training Loss: 0.031220315024256706
Test Loss:  0.009907380677759647
Valid Loss:  0.01824093423783779
Epoch:  202  	Training Loss: 0.03121926635503769
Test Loss:  0.009905477054417133
Valid Loss:  0.018239982426166534
Epoch:  203  	Training Loss: 0.031218186020851135
Test Loss:  0.00990469940006733
Valid Loss:  0.018239237368106842
Epoch:  204  	Training Loss: 0.03121713362634182
Test Loss:  0.009905396029353142
Valid Loss:  0.018238795921206474
Epoch:  205  	Training Loss: 0.031216073781251907
Test Loss:  0.00990370288491249
Valid Loss:  0.01823788322508335
Epoch:  206  	Training Loss: 0.031215008348226547
Test Loss:  0.009904947131872177
Valid Loss:  0.018237551674246788
Epoch:  207  	Training Loss: 0.031213967129588127
Test Loss:  0.009903041645884514
Valid Loss:  0.01823659986257553
Epoch:  208  	Training Loss: 0.031212886795401573
Test Loss:  0.009902261197566986
Valid Loss:  0.018235856667160988
Epoch:  209  	Training Loss: 0.031211841851472855
Test Loss:  0.009902924299240112
Valid Loss:  0.018235404044389725
Epoch:  210  	Training Loss: 0.031210776418447495
Test Loss:  0.009901272132992744
Valid Loss:  0.0182344987988472
Epoch:  211  	Training Loss: 0.03120972029864788
Test Loss:  0.00990248005837202
Valid Loss:  0.01823415607213974
Epoch:  212  	Training Loss: 0.031208669766783714
Test Loss:  0.009900612756609917
Valid Loss:  0.01823321357369423
Epoch:  213  	Training Loss: 0.031207595020532608
Test Loss:  0.009901701472699642
Valid Loss:  0.01823285035789013
 43%|████▎     | 215/500 [02:32<02:59,  1.59it/s] 43%|████▎     | 217/500 [02:32<02:10,  2.17it/s] 44%|████▍     | 219/500 [02:32<01:35,  2.93it/s] 44%|████▍     | 221/500 [02:39<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:39<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:39<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:39<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:39<01:33,  2.91it/s] 46%|████▌     | 231/500 [02:45<05:21,  1.19s/it] 47%|████▋     | 233/500 [02:46<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:46<02:46,  1.59it/s] 47%|████▋     | 237/500 [02:46<02:02,  2.15it/s] 48%|████▊     | 239/500 [02:46<01:31,  2.86it/s] 48%|████▊     | 241/500 [02:52<05:09,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:53<02:38,  1.60it/s] 49%|████▉     | 247/500 [02:53<01:55,  2.20it/s] 50%|████▉     | 249/500 [02:53<01:24,  2.95it/s] 50%|█████     | 251/500 [02:59<04:56,  1.19s/it] 51%|█████     | 253/500 [03:00<03:31,  1.17it/s] 51%|█████     | 255/500 [03:00<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:00<01:49,  2.21it/s] 52%|█████▏    | 259/500 [03:00<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:06<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:06<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:07<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:07<01:44,  2.22it/s] 54%|█████▍    | 269/500 [03:07<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:13<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:13<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:14<02:20,  1.61it/s] 55%|█████▌    | 277/500 [03:14<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:14<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:20<04:24,  1.21s/it] 57%|█████▋    | 283/500 [03:20<03:08,  1.15it/s]Epoch:  214  	Training Loss: 0.031206561252474785
Test Loss:  0.00989975593984127
Valid Loss:  0.018231891095638275
Epoch:  215  	Training Loss: 0.03120548278093338
Test Loss:  0.009898921474814415
Valid Loss:  0.018231142312288284
Epoch:  216  	Training Loss: 0.03120444342494011
Test Loss:  0.0098995640873909
Valid Loss:  0.018230678513646126
Epoch:  217  	Training Loss: 0.03120337799191475
Test Loss:  0.009897848591208458
Valid Loss:  0.018229763954877853
Epoch:  218  	Training Loss: 0.031202327460050583
Test Loss:  0.009899088181555271
Valid Loss:  0.018229421228170395
Epoch:  219  	Training Loss: 0.031201273202896118
Test Loss:  0.009897180832922459
Valid Loss:  0.01822846755385399
Epoch:  220  	Training Loss: 0.031200209632515907
Test Loss:  0.009898300282657146
Valid Loss:  0.018228108063340187
Epoch:  221  	Training Loss: 0.03119916468858719
Test Loss:  0.009896344505250454
Valid Loss:  0.018227146938443184
Epoch:  222  	Training Loss: 0.03119809553027153
Test Loss:  0.009897380135953426
Valid Loss:  0.018226776272058487
Epoch:  223  	Training Loss: 0.03119705617427826
Test Loss:  0.009895406663417816
Valid Loss:  0.018225811421871185
Epoch:  224  	Training Loss: 0.0311959870159626
Test Loss:  0.009896460920572281
Valid Loss:  0.01822543889284134
Epoch:  225  	Training Loss: 0.031194955110549927
Test Loss:  0.009894436225295067
Valid Loss:  0.01822446659207344
Epoch:  226  	Training Loss: 0.03119388222694397
Test Loss:  0.009895486757159233
Valid Loss:  0.018224090337753296
Epoch:  227  	Training Loss: 0.031192846596240997
Test Loss:  0.009893465787172318
Valid Loss:  0.018223121762275696
Epoch:  228  	Training Loss: 0.031191779300570488
Test Loss:  0.009894517250359058
Valid Loss:  0.01822274550795555
Epoch:  229  	Training Loss: 0.031190738081932068
Test Loss:  0.00989249162375927
Valid Loss:  0.018221775069832802
Epoch:  230  	Training Loss: 0.031189676374197006
Test Loss:  0.00989354308694601
Valid Loss:  0.018221398815512657
Epoch:  231  	Training Loss: 0.031188633292913437
Test Loss:  0.009891546331346035
Valid Loss:  0.018220430240035057
Epoch:  232  	Training Loss: 0.031187569722533226
Test Loss:  0.009892556816339493
Valid Loss:  0.018220050260424614
Epoch:  233  	Training Loss: 0.031186534091830254
Test Loss:  0.00989056471735239
Valid Loss:  0.018219074234366417
Epoch:  234  	Training Loss: 0.031185466796159744
Test Loss:  0.009891606867313385
Valid Loss:  0.018218697980046272
Epoch:  235  	Training Loss: 0.031184427440166473
Test Loss:  0.009889573790133
Valid Loss:  0.018217720091342926
Epoch:  236  	Training Loss: 0.031183365732431412
Test Loss:  0.009890623390674591
Valid Loss:  0.01821734383702278
Epoch:  237  	Training Loss: 0.031182322651147842
Test Loss:  0.00988859310746193
Valid Loss:  0.018216365948319435
Epoch:  238  	Training Loss: 0.03118126094341278
Test Loss:  0.009889641776680946
Valid Loss:  0.01821598783135414
Epoch:  239  	Training Loss: 0.031180214136838913
Test Loss:  0.009887641295790672
Valid Loss:  0.018215013667941093
Epoch:  240  	Training Loss: 0.03117915615439415
Test Loss:  0.009888647124171257
Valid Loss:  0.018214628100395203
Epoch:  241  	Training Loss: 0.03117811307311058
Test Loss:  0.009886655956506729
Valid Loss:  0.018213653936982155
Epoch:  242  	Training Loss: 0.031177053228020668
Test Loss:  0.00988769344985485
Valid Loss:  0.018213272094726562
Epoch:  243  	Training Loss: 0.031176000833511353
Test Loss:  0.00988566130399704
Valid Loss:  0.018212292343378067
Epoch:  244  	Training Loss: 0.031174954026937485
Test Loss:  0.009886704385280609
Valid Loss:  0.018211908638477325
Epoch:  245  	Training Loss: 0.03117389604449272
Test Loss:  0.009884674102067947
Valid Loss:  0.01821093261241913
Epoch:  246  	Training Loss: 0.031172849237918854
Test Loss:  0.009885725565254688
Valid Loss:  0.018210548907518387
Epoch:  247  	Training Loss: 0.03117179498076439
Test Loss:  0.009884227067232132
Valid Loss:  0.018209679052233696
Epoch:  248  	Training Loss: 0.031170744448900223
Test Loss:  0.009884526953101158
Valid Loss:  0.018209150061011314
Epoch:  249  	Training Loss: 0.031169690191745758
Test Loss:  0.009883143939077854
Valid Loss:  0.018208295106887817
Epoch:  250  	Training Loss: 0.03116864524781704
Test Loss:  0.009883455000817776
Valid Loss:  0.018207771703600883
Epoch:  251  	Training Loss: 0.031167585402727127
Test Loss:  0.009882107377052307
Valid Loss:  0.018206924200057983
Epoch:  252  	Training Loss: 0.031166546046733856
Test Loss:  0.00988246500492096
Valid Loss:  0.0182064026594162
Epoch:  253  	Training Loss: 0.031165476888418198
Test Loss:  0.009881092235445976
Valid Loss:  0.01820555329322815
Epoch:  254  	Training Loss: 0.031164444983005524
Test Loss:  0.009881465695798397
Valid Loss:  0.018205035477876663
Epoch:  255  	Training Loss: 0.031163379549980164
Test Loss:  0.0098820049315691
Valid Loss:  0.018204569816589355
Epoch:  256  	Training Loss: 0.03116234391927719
Test Loss:  0.009879727847874165
Valid Loss:  0.018203547224402428
Epoch:  257  	Training Loss: 0.031161289662122726
Test Loss:  0.009880604222416878
Valid Loss:  0.018203129991889
Epoch:  258  	Training Loss: 0.03116023540496826
Test Loss:  0.009879028424620628
Valid Loss:  0.018202245235443115
Epoch:  259  	Training Loss: 0.03115919604897499
Test Loss:  0.009879223071038723
Valid Loss:  0.01820169761776924
Epoch:  260  	Training Loss: 0.03115812875330448
Test Loss:  0.009877808392047882
Valid Loss:  0.018200840801000595
Epoch:  261  	Training Loss: 0.031157102435827255
Test Loss:  0.009878124110400677
Valid Loss:  0.018200308084487915
Epoch:  262  	Training Loss: 0.031156038865447044
Test Loss:  0.00987863540649414
Valid Loss:  0.018199842423200607
Epoch:  263  	Training Loss: 0.03115500882267952
Test Loss:  0.009876341558992863
Valid Loss:  0.01819881796836853
Epoch:  264  	Training Loss: 0.03115396946668625
Test Loss:  0.00987720675766468
Valid Loss:  0.0181984044611454
Epoch:  265  	Training Loss: 0.031152917072176933
Test Loss:  0.009875597432255745
Valid Loss:  0.01819751411676407
Epoch:  266  	Training Loss: 0.03115188702940941
Test Loss:  0.009875831194221973
Valid Loss:  0.01819697581231594
Epoch:  267  	Training Loss: 0.031150832772254944
Test Loss:  0.009876316413283348
Valid Loss:  0.018196498975157738
Epoch:  268  	Training Loss: 0.03114980086684227
Test Loss:  0.009874490089714527
Valid Loss:  0.01819557137787342
Epoch:  269  	Training Loss: 0.031148761510849
Test Loss:  0.009874589741230011
Valid Loss:  0.018195006996393204
Epoch:  270  	Training Loss: 0.031147709116339684
Test Loss:  0.009874992072582245
Valid Loss:  0.018194518983364105
Epoch:  271  	Training Loss: 0.03114667907357216
Test Loss:  0.009872605092823505
Valid Loss:  0.018193477764725685
Epoch:  272  	Training Loss: 0.031145643442869186
Test Loss:  0.009873416274785995
Valid Loss:  0.01819305121898651
Epoch:  273  	Training Loss: 0.03114459291100502
Test Loss:  0.00987177062779665
Valid Loss:  0.018192153424024582
Epoch:  274  	Training Loss: 0.031143564730882645
Test Loss:  0.009871983900666237
Valid Loss:  0.018191605806350708
Epoch:  275  	Training Loss: 0.031142516061663628
Test Loss:  0.009872430004179478
Valid Loss:  0.018191125243902206
Epoch:  276  	Training Loss: 0.031141478568315506
Test Loss:  0.009870633482933044
Valid Loss:  0.018190201371908188
Epoch:  277  	Training Loss: 0.03114045038819313
Test Loss:  0.009870720095932484
Valid Loss:  0.018189631402492523
Epoch:  278  	Training Loss: 0.031139397993683815
Test Loss:  0.00987111683934927
Valid Loss:  0.018189139664173126
Epoch:  279  	Training Loss: 0.031138364225625992
Test Loss:  0.009869237430393696
Valid Loss:  0.018188200891017914
Epoch:  280  	Training Loss: 0.03113732859492302
Test Loss:  0.00986929889768362
Valid Loss:  0.01818763092160225
Epoch:  281  	Training Loss: 0.03113628551363945
Test Loss:  0.009869684465229511
Valid Loss:  0.018187135457992554
Epoch:  282  	Training Loss: 0.03113524615764618
Test Loss:  0.009867825545370579
Valid Loss:  0.01818619668483734
Epoch:  283  	Training Loss: 0.031134217977523804
Test Loss:  0.009867878630757332
Valid Loss:  0.018185630440711975
Epoch:  284  	Training Loss: 0.03113318234682083
Test Loss:   57%|█████▋    | 285/500 [03:21<02:15,  1.59it/s] 57%|█████▋    | 287/500 [03:21<01:38,  2.17it/s] 58%|█████▊    | 289/500 [03:21<01:12,  2.92it/s] 58%|█████▊    | 291/500 [03:27<04:13,  1.21s/it] 59%|█████▊    | 293/500 [03:27<02:59,  1.15it/s] 59%|█████▉    | 295/500 [03:28<02:08,  1.59it/s] 59%|█████▉    | 297/500 [03:28<01:33,  2.18it/s] 60%|█████▉    | 299/500 [03:28<01:08,  2.93it/s] 60%|██████    | 301/500 [03:34<03:56,  1.19s/it] 61%|██████    | 303/500 [03:34<02:48,  1.17it/s] 61%|██████    | 305/500 [03:34<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:35<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:35<01:04,  2.96it/s] 62%|██████▏   | 311/500 [03:41<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:41<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:41<01:53,  1.62it/s] 63%|██████▎   | 317/500 [03:41<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:42<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:48<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:48<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:48<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:48<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:49<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:55<03:20,  1.19s/it] 67%|██████▋   | 333/500 [03:55<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:55<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:55<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:55<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:02<03:11,  1.20s/it] 69%|██████▊   | 343/500 [04:02<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:02<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:02<01:09,  2.20it/s] 70%|██████▉   | 349/500 [04:02<00:51,  2.95it/s] 70%|███████   | 351/500 [04:09<02:59,  1.21s/it] 71%|███████   | 353/500 [04:09<02:07,  1.16it/s]0.009868224151432514
Valid Loss:  0.018185129389166832
Epoch:  285  	Training Loss: 0.031132154166698456
Test Loss:  0.009866369888186455
Valid Loss:  0.018184198066592216
Epoch:  286  	Training Loss: 0.03113112784922123
Test Loss:  0.009866427630186081
Valid Loss:  0.018183628097176552
Epoch:  287  	Training Loss: 0.031130090355873108
Test Loss:  0.009866805747151375
Valid Loss:  0.018183132633566856
Epoch:  288  	Training Loss: 0.031129058450460434
Test Loss:  0.009864911437034607
Valid Loss:  0.018182193860411644
Epoch:  289  	Training Loss: 0.031128041446208954
Test Loss:  0.009865516796708107
Valid Loss:  0.018181735649704933
Epoch:  290  	Training Loss: 0.03112700581550598
Test Loss:  0.00986514613032341
Valid Loss:  0.018181096762418747
Epoch:  291  	Training Loss: 0.03112597018480301
Test Loss:  0.009865272790193558
Valid Loss:  0.018180562183260918
Epoch:  292  	Training Loss: 0.03112495131790638
Test Loss:  0.009863252751529217
Valid Loss:  0.01817958801984787
Epoch:  293  	Training Loss: 0.031123913824558258
Test Loss:  0.00986375380307436
Valid Loss:  0.018179114907979965
Epoch:  294  	Training Loss: 0.031122885644435883
Test Loss:  0.009863294661045074
Valid Loss:  0.018178462982177734
Epoch:  295  	Training Loss: 0.03112185187637806
Test Loss:  0.009863398969173431
Valid Loss:  0.018177924677729607
Epoch:  296  	Training Loss: 0.03112083487212658
Test Loss:  0.009861363098025322
Valid Loss:  0.01817694678902626
Epoch:  297  	Training Loss: 0.031119797378778458
Test Loss:  0.009861852042376995
Valid Loss:  0.018176469951868057
Epoch:  298  	Training Loss: 0.03111877106130123
Test Loss:  0.00986141711473465
Valid Loss:  0.018175818026065826
Epoch:  299  	Training Loss: 0.031117737293243408
Test Loss:  0.00986150186508894
Valid Loss:  0.01817527785897255
Epoch:  300  	Training Loss: 0.03111671656370163
Test Loss:  0.009859459474682808
Valid Loss:  0.018174296244978905
Epoch:  301  	Training Loss: 0.031115684658288956
Test Loss:  0.009859944693744183
Valid Loss:  0.018173815682530403
Epoch:  302  	Training Loss: 0.03111465647816658
Test Loss:  0.009859468787908554
Valid Loss:  0.01817314699292183
Epoch:  303  	Training Loss: 0.03111361153423786
Test Loss:  0.009859560057520866
Valid Loss:  0.018172599375247955
Epoch:  304  	Training Loss: 0.03111257776618004
Test Loss:  0.00985943153500557
Valid Loss:  0.018172016367316246
Epoch:  305  	Training Loss: 0.03111155703663826
Test Loss:  0.009857259690761566
Valid Loss:  0.018171027302742004
Epoch:  306  	Training Loss: 0.031110530719161034
Test Loss:  0.009857666678726673
Valid Loss:  0.018170524388551712
Epoch:  307  	Training Loss: 0.031109504401683807
Test Loss:  0.009857171215116978
Valid Loss:  0.01816985011100769
Epoch:  308  	Training Loss: 0.03110845386981964
Test Loss:  0.009857222437858582
Valid Loss:  0.01816929318010807
Epoch:  309  	Training Loss: 0.031107425689697266
Test Loss:  0.009857075288891792
Valid Loss:  0.018168706446886063
Epoch:  310  	Training Loss: 0.03110639750957489
Test Loss:  0.009854886680841446
Valid Loss:  0.018167708069086075
Epoch:  311  	Training Loss: 0.03110538050532341
Test Loss:  0.009855278767645359
Valid Loss:  0.01816720701754093
Epoch:  312  	Training Loss: 0.031104346737265587
Test Loss:  0.009854759089648724
Valid Loss:  0.01816653460264206
Epoch:  313  	Training Loss: 0.031103316694498062
Test Loss:  0.009854825213551521
Valid Loss:  0.018165981397032738
Epoch:  314  	Training Loss: 0.031102286651730537
Test Loss:  0.009854667820036411
Valid Loss:  0.018165389075875282
Epoch:  315  	Training Loss: 0.03110126405954361
Test Loss:  0.00985248014330864
Valid Loss:  0.018164390698075294
Epoch:  316  	Training Loss: 0.031100239604711533
Test Loss:  0.009852878749370575
Valid Loss:  0.018163885921239853
Epoch:  317  	Training Loss: 0.031099211424589157
Test Loss:  0.00985238328576088
Valid Loss:  0.01816321723163128
Epoch:  318  	Training Loss: 0.03109818324446678
Test Loss:  0.009852438233792782
Valid Loss:  0.01816266030073166
Epoch:  319  	Training Loss: 0.031097155064344406
Test Loss:  0.009852277114987373
Valid Loss:  0.018162064254283905
Epoch:  320  	Training Loss: 0.03109612688422203
Test Loss:  0.009851999580860138
Valid Loss:  0.018161451444029808
Epoch:  321  	Training Loss: 0.031095102429389954
Test Loss:  0.009851640090346336
Valid Loss:  0.018160827457904816
Epoch:  322  	Training Loss: 0.031094077974557877
Test Loss:  0.00984933041036129
Valid Loss:  0.018159814178943634
Epoch:  323  	Training Loss: 0.031093072146177292
Test Loss:  0.00984965730458498
Valid Loss:  0.018159301951527596
Epoch:  324  	Training Loss: 0.031092053279280663
Test Loss:  0.009849123656749725
Valid Loss:  0.018158631399273872
Epoch:  325  	Training Loss: 0.03109104372560978
Test Loss:  0.009849125519394875
Valid Loss:  0.018158067017793655
Epoch:  326  	Training Loss: 0.031090022996068
Test Loss:  0.009848960675299168
Valid Loss:  0.0181574784219265
Epoch:  327  	Training Loss: 0.03108900971710682
Test Loss:  0.009848682209849358
Valid Loss:  0.0181568693369627
Epoch:  328  	Training Loss: 0.03108799085021019
Test Loss:  0.009848328307271004
Valid Loss:  0.01815624348819256
Epoch:  329  	Training Loss: 0.031086981296539307
Test Loss:  0.009847929701209068
Valid Loss:  0.018155613914132118
Epoch:  330  	Training Loss: 0.031085966154932976
Test Loss:  0.009847505018115044
Valid Loss:  0.018154975026845932
Epoch:  331  	Training Loss: 0.031084958463907242
Test Loss:  0.009847061708569527
Valid Loss:  0.018154339864850044
Epoch:  332  	Training Loss: 0.03108394518494606
Test Loss:  0.009846609085798264
Valid Loss:  0.018153702840209007
Epoch:  333  	Training Loss: 0.031082935631275177
Test Loss:  0.009846152737736702
Valid Loss:  0.018153058364987373
Epoch:  334  	Training Loss: 0.031081922352313995
Test Loss:  0.009845690801739693
Valid Loss:  0.018152417615056038
Epoch:  335  	Training Loss: 0.031080912798643112
Test Loss:  0.009845227003097534
Valid Loss:  0.018151775002479553
Epoch:  336  	Training Loss: 0.03107989951968193
Test Loss:  0.00984476413577795
Valid Loss:  0.01815112866461277
Epoch:  337  	Training Loss: 0.03107888624072075
Test Loss:  0.009844297543168068
Valid Loss:  0.018150487914681435
Epoch:  338  	Training Loss: 0.031077878549695015
Test Loss:  0.009843830950558186
Valid Loss:  0.018149837851524353
Epoch:  339  	Training Loss: 0.031076867133378983
Test Loss:  0.009843362495303154
Valid Loss:  0.01814919337630272
Epoch:  340  	Training Loss: 0.03107585571706295
Test Loss:  0.009842895902693272
Valid Loss:  0.018148547038435936
Epoch:  341  	Training Loss: 0.031074846163392067
Test Loss:  0.00984242744743824
Valid Loss:  0.018147902563214302
Epoch:  342  	Training Loss: 0.031073834747076035
Test Loss:  0.009841958060860634
Valid Loss:  0.01814725622534752
Epoch:  343  	Training Loss: 0.03107282891869545
Test Loss:  0.009841491468250751
Valid Loss:  0.018146613612771034
Epoch:  344  	Training Loss: 0.031071823090314865
Test Loss:  0.00984102487564087
Valid Loss:  0.01814596727490425
Epoch:  345  	Training Loss: 0.03107081726193428
Test Loss:  0.009840558283030987
Valid Loss:  0.01814531721174717
Epoch:  346  	Training Loss: 0.031069809570908546
Test Loss:  0.009840087965130806
Valid Loss:  0.018144674599170685
Epoch:  347  	Training Loss: 0.03106880560517311
Test Loss:  0.009839619509875774
Valid Loss:  0.018144026398658752
Epoch:  348  	Training Loss: 0.031067797914147377
Test Loss:  0.009839151985943317
Valid Loss:  0.01814338192343712
Epoch:  349  	Training Loss: 0.031066790223121643
Test Loss:  0.009838682599365711
Valid Loss:  0.018142729997634888
Epoch:  350  	Training Loss: 0.03106578066945076
Test Loss:  0.009838213212788105
Valid Loss:  0.018142083659768105
Epoch:  351  	Training Loss: 0.031064780429005623
Test Loss:  0.009837742894887924
Valid Loss:  0.018141433596611023
Epoch:  352  	Training Loss: 0.031063774600625038
Test Loss:  0.009837275370955467
Valid Loss:  0.01814079098403454
Epoch:  353  	Training Loss: 0.031062772497534752
Test Loss:  0.009836805984377861
Valid Loss:  0.018140137195587158
Epoch:  354  	Training Loss: 0.031061770394444466
Test Loss:  0.009836336597800255
Valid Loss:  0.018139494583010674
 71%|███████   | 355/500 [04:09<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:09<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:09<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:16<02:49,  1.22s/it] 73%|███████▎  | 363/500 [04:16<01:59,  1.14it/s] 73%|███████▎  | 365/500 [04:16<01:25,  1.58it/s] 73%|███████▎  | 367/500 [04:16<01:01,  2.17it/s] 74%|███████▍  | 369/500 [04:16<00:44,  2.93it/s] 74%|███████▍  | 371/500 [04:23<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:23<01:50,  1.15it/s] 75%|███████▌  | 375/500 [04:23<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:23<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:23<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:30<02:23,  1.21s/it] 77%|███████▋  | 383/500 [04:30<01:41,  1.15it/s] 77%|███████▋  | 385/500 [04:30<01:12,  1.59it/s] 77%|███████▋  | 387/500 [04:30<00:51,  2.18it/s] 78%|███████▊  | 389/500 [04:30<00:37,  2.93it/s] 78%|███████▊  | 391/500 [04:37<02:12,  1.21s/it] 79%|███████▊  | 393/500 [04:37<01:33,  1.15it/s] 79%|███████▉  | 395/500 [04:37<01:06,  1.59it/s] 79%|███████▉  | 397/500 [04:37<00:47,  2.17it/s] 80%|███████▉  | 399/500 [04:37<00:34,  2.92it/s] 80%|████████  | 401/500 [04:44<01:58,  1.20s/it] 81%|████████  | 403/500 [04:44<01:23,  1.16it/s] 81%|████████  | 405/500 [04:44<00:59,  1.61it/s] 81%|████████▏ | 407/500 [04:44<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:44<00:30,  2.96it/s] 82%|████████▏ | 411/500 [04:51<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:51<01:14,  1.16it/s] 83%|████████▎ | 415/500 [04:51<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:51<00:37,  2.20it/s] 84%|████████▍ | 419/500 [04:51<00:27,  2.96it/s] 84%|████████▍ | 421/500 [04:58<01:35,  1.21s/it] 85%|████████▍ | 423/500 [04:58<01:06,  1.15it/s]Epoch:  355  	Training Loss: 0.03106076829135418
Test Loss:  0.009835867211222649
Valid Loss:  0.018138844519853592
Epoch:  356  	Training Loss: 0.031059764325618744
Test Loss:  0.009835397824645042
Valid Loss:  0.01813819631934166
Epoch:  357  	Training Loss: 0.031058762222528458
Test Loss:  0.009834930300712585
Valid Loss:  0.01813754439353943
Epoch:  358  	Training Loss: 0.03105776011943817
Test Loss:  0.00983445718884468
Valid Loss:  0.018136896193027496
Epoch:  359  	Training Loss: 0.031056758016347885
Test Loss:  0.009833987802267075
Valid Loss:  0.018136247992515564
Epoch:  360  	Training Loss: 0.031055757775902748
Test Loss:  0.00983351655304432
Valid Loss:  0.018135597929358482
Epoch:  361  	Training Loss: 0.031054753810167313
Test Loss:  0.009833048097789288
Valid Loss:  0.018134944140911102
Epoch:  362  	Training Loss: 0.031053753569722176
Test Loss:  0.009832575917243958
Valid Loss:  0.01813429594039917
Epoch:  363  	Training Loss: 0.03105274960398674
Test Loss:  0.009832104668021202
Valid Loss:  0.01813364401459694
Epoch:  364  	Training Loss: 0.031051747500896454
Test Loss:  0.009831631556153297
Valid Loss:  0.018132992088794708
Epoch:  365  	Training Loss: 0.031050745397806168
Test Loss:  0.009831162169575691
Valid Loss:  0.018132340162992477
Epoch:  366  	Training Loss: 0.03104974702000618
Test Loss:  0.009830689057707787
Valid Loss:  0.018131686374545097
Epoch:  367  	Training Loss: 0.031048744916915894
Test Loss:  0.009830216877162457
Valid Loss:  0.018131036311388016
Epoch:  368  	Training Loss: 0.031047744676470757
Test Loss:  0.009829744696617126
Valid Loss:  0.018130382522940636
Epoch:  369  	Training Loss: 0.03104674071073532
Test Loss:  0.009829273447394371
Valid Loss:  0.018129732459783554
Epoch:  370  	Training Loss: 0.031045736744999886
Test Loss:  0.009828799404203892
Valid Loss:  0.018129073083400726
Epoch:  371  	Training Loss: 0.03104473650455475
Test Loss:  0.009828327223658562
Valid Loss:  0.018128419294953346
Epoch:  372  	Training Loss: 0.031043734401464462
Test Loss:  0.009827853180468082
Valid Loss:  0.018127769231796265
Epoch:  373  	Training Loss: 0.031042736023664474
Test Loss:  0.009827381931245327
Valid Loss:  0.018127115443348885
Epoch:  374  	Training Loss: 0.031041741371154785
Test Loss:  0.009826911613345146
Valid Loss:  0.018126465380191803
Epoch:  375  	Training Loss: 0.031040742993354797
Test Loss:  0.009826432913541794
Valid Loss:  0.018125809729099274
Epoch:  376  	Training Loss: 0.03103974089026451
Test Loss:  0.009825965389609337
Valid Loss:  0.018125157803297043
Epoch:  377  	Training Loss: 0.031038746237754822
Test Loss:  0.009825492277741432
Valid Loss:  0.018124505877494812
Epoch:  378  	Training Loss: 0.031037749722599983
Test Loss:  0.009825018234550953
Valid Loss:  0.018123850226402283
Epoch:  379  	Training Loss: 0.031036749482154846
Test Loss:  0.009824544191360474
Valid Loss:  0.018123198300600052
Epoch:  380  	Training Loss: 0.031035752967000008
Test Loss:  0.009824072942137718
Valid Loss:  0.018122542649507523
Epoch:  381  	Training Loss: 0.03103475645184517
Test Loss:  0.009823597967624664
Valid Loss:  0.018121886998414993
Epoch:  382  	Training Loss: 0.03103375807404518
Test Loss:  0.009823123924434185
Valid Loss:  0.018121233209967613
Epoch:  383  	Training Loss: 0.031032761558890343
Test Loss:  0.009822653606534004
Valid Loss:  0.01812058314681053
Epoch:  384  	Training Loss: 0.031031768769025803
Test Loss:  0.00982217863202095
Valid Loss:  0.018119927495718002
Epoch:  385  	Training Loss: 0.031030774116516113
Test Loss:  0.009821707382798195
Valid Loss:  0.01811927556991577
Epoch:  386  	Training Loss: 0.031029779464006424
Test Loss:  0.009821232408285141
Valid Loss:  0.018118619918823242
Epoch:  387  	Training Loss: 0.031028781086206436
Test Loss:  0.009820759296417236
Valid Loss:  0.018117964267730713
Epoch:  388  	Training Loss: 0.031027788296341896
Test Loss:  0.009820286184549332
Valid Loss:  0.018117312341928482
Epoch:  389  	Training Loss: 0.03102678805589676
Test Loss:  0.009819811210036278
Valid Loss:  0.018116652965545654
Epoch:  390  	Training Loss: 0.031025797128677368
Test Loss:  0.009819338098168373
Valid Loss:  0.018115997314453125
Epoch:  391  	Training Loss: 0.03102480061352253
Test Loss:  0.009818864054977894
Valid Loss:  0.018115341663360596
Epoch:  392  	Training Loss: 0.03102380409836769
Test Loss:  0.009818390011787415
Valid Loss:  0.018114687874913216
Epoch:  393  	Training Loss: 0.03102281130850315
Test Loss:  0.00981791503727436
Valid Loss:  0.018114034086465836
Epoch:  394  	Training Loss: 0.03102181665599346
Test Loss:  0.009817440062761307
Valid Loss:  0.018113374710083008
Epoch:  395  	Training Loss: 0.03102082386612892
Test Loss:  0.009816967882215977
Valid Loss:  0.018112722784280777
Epoch:  396  	Training Loss: 0.031019829213619232
Test Loss:  0.009816493839025497
Valid Loss:  0.018112067133188248
Epoch:  397  	Training Loss: 0.031018836423754692
Test Loss:  0.009816018864512444
Valid Loss:  0.01811141148209572
Epoch:  398  	Training Loss: 0.031017843633890152
Test Loss:  0.009815545752644539
Valid Loss:  0.01811075583100319
Epoch:  399  	Training Loss: 0.031016848981380463
Test Loss:  0.009815068915486336
Valid Loss:  0.018110090866684914
Epoch:  400  	Training Loss: 0.031015854328870773
Test Loss:  0.009814593940973282
Valid Loss:  0.018109437078237534
Epoch:  401  	Training Loss: 0.031014859676361084
Test Loss:  0.009814119897782803
Valid Loss:  0.018108785152435303
Epoch:  402  	Training Loss: 0.031013863161206245
Test Loss:  0.009813643991947174
Valid Loss:  0.018108123913407326
Epoch:  403  	Training Loss: 0.031012874096632004
Test Loss:  0.009813169948756695
Valid Loss:  0.018107466399669647
Epoch:  404  	Training Loss: 0.031011881306767464
Test Loss:  0.009812694974243641
Valid Loss:  0.018106814473867416
Epoch:  405  	Training Loss: 0.031010890379548073
Test Loss:  0.009812219068408012
Valid Loss:  0.01810615137219429
Epoch:  406  	Training Loss: 0.031009895727038383
Test Loss:  0.00981174223124981
Valid Loss:  0.01810549944639206
Epoch:  407  	Training Loss: 0.031008904799818993
Test Loss:  0.009811269119381905
Valid Loss:  0.01810484007000923
Epoch:  408  	Training Loss: 0.031007912009954453
Test Loss:  0.009810793213546276
Valid Loss:  0.018104182556271553
Epoch:  409  	Training Loss: 0.03100692480802536
Test Loss:  0.009814231656491756
Valid Loss:  0.01810433343052864
Epoch:  410  	Training Loss: 0.03100600652396679
Test Loss:  0.009810280986130238
Valid Loss:  0.018103014677762985
Epoch:  411  	Training Loss: 0.031004950404167175
Test Loss:  0.009810760617256165
Valid Loss:  0.018102558329701424
Epoch:  412  	Training Loss: 0.031003959476947784
Test Loss:  0.009809826500713825
Valid Loss:  0.018101820722222328
Epoch:  413  	Training Loss: 0.031002962961792946
Test Loss:  0.00980900414288044
Valid Loss:  0.01810111105442047
Epoch:  414  	Training Loss: 0.0310019850730896
Test Loss:  0.009812252596020699
Valid Loss:  0.018101230263710022
Epoch:  415  	Training Loss: 0.03100106120109558
Test Loss:  0.00980816688388586
Valid Loss:  0.018099885433912277
Epoch:  416  	Training Loss: 0.030999992042779922
Test Loss:  0.009807461872696877
Valid Loss:  0.018099186941981316
Epoch:  417  	Training Loss: 0.030998997390270233
Test Loss:  0.009806850925087929
Valid Loss:  0.01809849962592125
Epoch:  418  	Training Loss: 0.03099801018834114
Test Loss:  0.009810267947614193
Valid Loss:  0.01809864491224289
Epoch:  419  	Training Loss: 0.030997104942798615
Test Loss:  0.009806239977478981
Valid Loss:  0.01809731498360634
Epoch:  420  	Training Loss: 0.03099604696035385
Test Loss:  0.009806685149669647
Valid Loss:  0.018096841871738434
Epoch:  421  	Training Loss: 0.030995042994618416
Test Loss:  0.009805643931031227
Valid Loss:  0.018096089363098145
Epoch:  422  	Training Loss: 0.030994052067399025
Test Loss:  0.009808758273720741
Valid Loss:  0.018096178770065308
Epoch:  423  	Training Loss: 0.030993135645985603
Test Loss:  0.00980459712445736
Valid Loss:  0.01809481903910637
Epoch:  424  	Training Loss: 0.030992066487669945
Test Loss:  0.009803898632526398
Valid Loss:  0.018094118684530258
Epoch:  425  	Training Loss: 0.030991073697805405 85%|████████▌ | 425/500 [04:58<00:47,  1.59it/s] 85%|████████▌ | 427/500 [04:58<00:33,  2.16it/s] 86%|████████▌ | 429/500 [04:58<00:24,  2.86it/s] 86%|████████▌ | 431/500 [05:05<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:05<00:58,  1.16it/s] 87%|████████▋ | 435/500 [05:05<00:41,  1.58it/s] 87%|████████▋ | 437/500 [05:05<00:29,  2.14it/s] 88%|████████▊ | 439/500 [05:06<00:21,  2.84it/s] 88%|████████▊ | 441/500 [05:12<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:12<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:12<00:34,  1.59it/s] 89%|████████▉ | 447/500 [05:12<00:24,  2.17it/s] 90%|████████▉ | 449/500 [05:13<00:17,  2.93it/s] 90%|█████████ | 451/500 [05:19<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:19<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:19<00:28,  1.59it/s] 91%|█████████▏| 457/500 [05:19<00:19,  2.16it/s] 92%|█████████▏| 459/500 [05:20<00:14,  2.92it/s] 92%|█████████▏| 461/500 [05:26<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.59it/s] 93%|█████████▎| 467/500 [05:26<00:15,  2.15it/s] 94%|█████████▍| 469/500 [05:27<00:10,  2.85it/s] 94%|█████████▍| 471/500 [05:33<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:33<00:23,  1.14it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.58it/s] 95%|█████████▌| 477/500 [05:33<00:10,  2.16it/s] 96%|█████████▌| 479/500 [05:34<00:07,  2.91it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.94it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:47<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:47<00:03,  1.63it/s]
Test Loss:  0.009803235530853271
Valid Loss:  0.018093427643179893
Epoch:  426  	Training Loss: 0.03099009394645691
Test Loss:  0.009806555695831776
Valid Loss:  0.018093544989824295
Epoch:  427  	Training Loss: 0.03098917193710804
Test Loss:  0.009802538901567459
Valid Loss:  0.018092215061187744
Epoch:  428  	Training Loss: 0.03098812699317932
Test Loss:  0.00980298686772585
Valid Loss:  0.01809174194931984
Epoch:  429  	Training Loss: 0.030987128615379333
Test Loss:  0.00980200245976448
Valid Loss:  0.01809098944067955
Epoch:  430  	Training Loss: 0.03098614513874054
Test Loss:  0.009805087931454182
Valid Loss:  0.018091080710291862
Epoch:  431  	Training Loss: 0.030985219404101372
Test Loss:  0.009800915606319904
Valid Loss:  0.018089719116687775
Epoch:  432  	Training Loss: 0.030984152108430862
Test Loss:  0.009800155647099018
Valid Loss:  0.018089009448885918
Epoch:  433  	Training Loss: 0.030983177945017815
Test Loss:  0.009803423658013344
Valid Loss:  0.01808912120759487
Epoch:  434  	Training Loss: 0.03098227083683014
Test Loss:  0.009800475090742111
Valid Loss:  0.01808800734579563
Epoch:  435  	Training Loss: 0.030981216579675674
Test Loss:  0.009799417108297348
Valid Loss:  0.018087247386574745
Epoch:  436  	Training Loss: 0.03098023310303688
Test Loss:  0.009802443906664848
Valid Loss:  0.018087327480316162
Epoch:  437  	Training Loss: 0.030979327857494354
Test Loss:  0.009798232465982437
Valid Loss:  0.018085956573486328
Epoch:  438  	Training Loss: 0.030978262424468994
Test Loss:  0.009797506965696812
Valid Loss:  0.01808524876832962
Epoch:  439  	Training Loss: 0.030977293848991394
Test Loss:  0.009801870211958885
Valid Loss:  0.018085598945617676
Epoch:  440  	Training Loss: 0.03097640722990036
Test Loss:  0.009796788915991783
Valid Loss:  0.018084052950143814
Epoch:  441  	Training Loss: 0.03097531758248806
Test Loss:  0.009799964725971222
Valid Loss:  0.018084153532981873
Epoch:  442  	Training Loss: 0.03097442165017128
Test Loss:  0.009796952828764915
Valid Loss:  0.018083039671182632
Epoch:  443  	Training Loss: 0.030973389744758606
Test Loss:  0.009795848280191422
Valid Loss:  0.018082277849316597
Epoch:  444  	Training Loss: 0.0309724360704422
Test Loss:  0.009798855520784855
Valid Loss:  0.018082361668348312
Epoch:  445  	Training Loss: 0.030971543863415718
Test Loss:  0.009794648736715317
Valid Loss:  0.01808100938796997
Epoch:  446  	Training Loss: 0.030970517545938492
Test Loss:  0.009793940931558609
Valid Loss:  0.018080316483974457
Epoch:  447  	Training Loss: 0.03096957877278328
Test Loss:  0.009798292070627213
Valid Loss:  0.018080659210681915
Epoch:  448  	Training Loss: 0.030968695878982544
Test Loss:  0.009793762117624283
Valid Loss:  0.0180792436003685
Epoch:  449  	Training Loss: 0.030967656522989273
Test Loss:  0.009796712547540665
Valid Loss:  0.01807931624352932
Epoch:  450  	Training Loss: 0.03096676990389824
Test Loss:  0.009792469441890717
Valid Loss:  0.01807795837521553
Epoch:  451  	Training Loss: 0.030965737998485565
Test Loss:  0.009791744872927666
Valid Loss:  0.01807725802063942
Epoch:  452  	Training Loss: 0.0309648048132658
Test Loss:  0.00979606993496418
Valid Loss:  0.018077591434121132
Epoch:  453  	Training Loss: 0.030963905155658722
Test Loss:  0.00979152973741293
Valid Loss:  0.018076159060001373
Epoch:  454  	Training Loss: 0.030962849035859108
Test Loss:  0.009794468060135841
Valid Loss:  0.01807621866464615
Epoch:  455  	Training Loss: 0.03096194565296173
Test Loss:  0.009790269657969475
Valid Loss:  0.01807485520839691
Epoch:  456  	Training Loss: 0.030960898846387863
Test Loss:  0.009794492274522781
Valid Loss:  0.018075166270136833
Epoch:  457  	Training Loss: 0.030960028991103172
Test Loss:  0.009789863601326942
Valid Loss:  0.01807371899485588
Epoch:  458  	Training Loss: 0.030958956107497215
Test Loss:  0.009792808443307877
Valid Loss:  0.01807377301156521
Epoch:  459  	Training Loss: 0.030958063900470734
Test Loss:  0.009788498282432556
Valid Loss:  0.01807239279150963
Epoch:  460  	Training Loss: 0.03095700964331627
Test Loss:  0.009792705997824669
Valid Loss:  0.018072698265314102
Epoch:  461  	Training Loss: 0.030956141650676727
Test Loss:  0.009788071736693382
Valid Loss:  0.018071249127388
Epoch:  462  	Training Loss: 0.03095507249236107
Test Loss:  0.009791014716029167
Valid Loss:  0.01807130128145218
Epoch:  463  	Training Loss: 0.030954182147979736
Test Loss:  0.009786704555153847
Valid Loss:  0.01806991547346115
Epoch:  464  	Training Loss: 0.030953124165534973
Test Loss:  0.009790968149900436
Valid Loss:  0.01807023212313652
Epoch:  465  	Training Loss: 0.030952265486121178
Test Loss:  0.009786304086446762
Valid Loss:  0.018068775534629822
Epoch:  466  	Training Loss: 0.03095119073987007
Test Loss:  0.009789174422621727
Valid Loss:  0.018068810924887657
Epoch:  467  	Training Loss: 0.030950292944908142
Test Loss:  0.009784878231585026
Valid Loss:  0.018067432567477226
Epoch:  468  	Training Loss: 0.030949246138334274
Test Loss:  0.009789148345589638
Valid Loss:  0.01806773990392685
Epoch:  469  	Training Loss: 0.030948378145694733
Test Loss:  0.009784490801393986
Valid Loss:  0.0180662889033556
Epoch:  470  	Training Loss: 0.030947305262088776
Test Loss:  0.009787362068891525
Valid Loss:  0.018066324293613434
Epoch:  471  	Training Loss: 0.030946403741836548
Test Loss:  0.00978313758969307
Valid Loss:  0.0180649496614933
Epoch:  472  	Training Loss: 0.030945371836423874
Test Loss:  0.009787305258214474
Valid Loss:  0.01806524395942688
Epoch:  473  	Training Loss: 0.03094448521733284
Test Loss:  0.009782664477825165
Valid Loss:  0.018063798546791077
Epoch:  474  	Training Loss: 0.03094344027340412
Test Loss:  0.009785600006580353
Valid Loss:  0.018063832074403763
Epoch:  475  	Training Loss: 0.03094252571463585
Test Loss:  0.009781304746866226
Valid Loss:  0.01806245744228363
Epoch:  476  	Training Loss: 0.030941512435674667
Test Loss:  0.009785478003323078
Valid Loss:  0.018062744289636612
Epoch:  477  	Training Loss: 0.030940618366003036
Test Loss:  0.009780844673514366
Valid Loss:  0.018061306327581406
Epoch:  478  	Training Loss: 0.030939579010009766
Test Loss:  0.00978377740830183
Valid Loss:  0.018061336129903793
Epoch:  479  	Training Loss: 0.030938658863306046
Test Loss:  0.009779487736523151
Valid Loss:  0.01805996149778366
Epoch:  480  	Training Loss: 0.03093765303492546
Test Loss:  0.00978371687233448
Valid Loss:  0.01806025207042694
Epoch:  481  	Training Loss: 0.030936751514673233
Test Loss:  0.009779059328138828
Valid Loss:  0.018058806657791138
Epoch:  482  	Training Loss: 0.03093571774661541
Test Loss:  0.00978192500770092
Valid Loss:  0.018058834597468376
Epoch:  483  	Training Loss: 0.03093479946255684
Test Loss:  0.009777646511793137
Valid Loss:  0.018057459965348244
Epoch:  484  	Training Loss: 0.03093380108475685
Test Loss:  0.009781887754797935
Valid Loss:  0.018057748675346375
Epoch:  485  	Training Loss: 0.030932899564504623
Test Loss:  0.009777236729860306
Valid Loss:  0.01805630698800087
Epoch:  486  	Training Loss: 0.03093186765909195
Test Loss:  0.009780118241906166
Valid Loss:  0.01805632933974266
Epoch:  487  	Training Loss: 0.030930930748581886
Test Loss:  0.009775876998901367
Valid Loss:  0.018054958432912827
Epoch:  488  	Training Loss: 0.03092995285987854
Test Loss:  0.0097800362855196
Valid Loss:  0.01805523782968521
Epoch:  489  	Training Loss: 0.03092903271317482
Test Loss:  0.009775402024388313
Valid Loss:  0.018053799867630005
Epoch:  490  	Training Loss: 0.030928023159503937
Test Loss:  0.009778342209756374
Valid Loss:  0.018053822219371796
Epoch:  491  	Training Loss: 0.03092707321047783
Test Loss:  0.009774024598300457
Valid Loss:  0.018052449449896812
Epoch:  492  	Training Loss: 0.030926110222935677
Test Loss:  0.009778192266821861
Valid Loss:  0.01805271953344345
Epoch:  493  	Training Loss: 0.030925162136554718
Test Loss:  0.009773572906851768
Valid Loss:  0.01805129088461399
Epoch:  494  	Training Loss: 0.03092418611049652
Test Loss:  0.00977651122957468
Valid Loss:  0.018051311373710632
Epoch:  495  	Training Loss: 0.03092322126030922
Test Loss:  0.009774116799235344
Valid Loss:  0.018050316721200943
 99%|█████████▉| 497/500 [05:47<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:47<00:00,  2.99it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
Epoch:  496  	Training Loss: 0.03092225082218647
Test Loss:  0.009773612022399902
Valid Loss:  0.018049679696559906
Epoch:  497  	Training Loss: 0.030921272933483124
Test Loss:  0.009772073477506638
Valid Loss:  0.018048837780952454
Epoch:  498  	Training Loss: 0.030920356512069702
Test Loss:  0.009774826467037201
Valid Loss:  0.018048828467726707
Epoch:  499  	Training Loss: 0.0309193916618824
Test Loss:  0.009772377088665962
Valid Loss:  0.018047818914055824
Epoch:  500  	Training Loss: 0.03091842494904995
Test Loss:  0.009771894663572311
Valid Loss:  0.018047183752059937
seed is  2
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:49,  6.23s/it]  1%|          | 3/500 [00:06<13:49,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:20<09:40,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.20it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:11,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:33<12:08,  1.57s/it]  7%|▋         | 37/500 [00:33<08:37,  1.12s/it]  8%|▊         | 39/500 [00:33<06:09,  1.25it/s]  8%|▊         | 41/500 [00:40<11:38,  1.52s/it]  9%|▊         | 43/500 [00:40<08:15,  1.09s/it]  9%|▉         | 45/500 [00:40<05:54,  1.28it/s]  9%|▉         | 47/500 [00:40<04:15,  1.77it/s] 10%|▉         | 49/500 [00:40<03:08,  2.39it/s] 10%|█         | 51/500 [00:53<16:31,  2.21s/it] 11%|█         | 53/500 [00:53<11:40,  1.57s/it] 11%|█         | 55/500 [00:53<08:16,  1.12s/it] 11%|█▏        | 57/500 [00:53<05:54,  1.25it/s] 12%|█▏        | 59/500 [00:53<04:15,  1.72it/s] 12%|█▏        | 59/500 [01:05<04:15,  1.72it/s] 12%|█▏        | 61/500 [01:06<16:51,  2.30s/it] 13%|█▎        | 63/500 [01:06<11:56,  1.64s/it] 13%|█▎        | 65/500 [01:13<15:21,  2.12s/it] 13%|█▎        | 67/500 [01:13<10:51,  1.51s/it]Epoch:  1  	Training Loss: 0.04824826121330261
Test Loss:  0.2135503888130188
Valid Loss:  0.1812373846769333
Epoch:  2  	Training Loss: 0.17995737493038177
Test Loss:  0.017131373286247253
Valid Loss:  0.028321895748376846
Epoch:  3  	Training Loss: 0.044713761657476425
Test Loss:  0.0161617211997509
Valid Loss:  0.025694366544485092
Epoch:  4  	Training Loss: 0.03781062737107277
Test Loss:  0.012955530546605587
Valid Loss:  0.02140960469841957
Epoch:  5  	Training Loss: 0.033906981348991394
Test Loss:  0.01079620886594057
Valid Loss:  0.018938522785902023
Epoch:  6  	Training Loss: 0.032076310366392136
Test Loss:  0.010800471529364586
Valid Loss:  0.01865142211318016
Epoch:  7  	Training Loss: 0.031088529154658318
Test Loss:  0.00949918944388628
Valid Loss:  0.017347484827041626
Epoch:  8  	Training Loss: 0.030032524839043617
Test Loss:  0.00932914949953556
Valid Loss:  0.0172734335064888
Epoch:  9  	Training Loss: 0.02980107069015503
Test Loss:  0.009115885943174362
Valid Loss:  0.017145728692412376
Epoch:  10  	Training Loss: 0.02973177842795849
Test Loss:  0.009132702834904194
Valid Loss:  0.017147023230791092
Epoch:  11  	Training Loss: 0.029693059623241425
Test Loss:  0.009033212438225746
Valid Loss:  0.017102520912885666
Epoch:  12  	Training Loss: 0.029665300622582436
Test Loss:  0.009041908197104931
Valid Loss:  0.01710234209895134
Epoch:  13  	Training Loss: 0.029650095850229263
Test Loss:  0.009012056514620781
Valid Loss:  0.0170931164175272
Epoch:  14  	Training Loss: 0.02964000776410103
Test Loss:  0.00900985300540924
Valid Loss:  0.017090780660510063
Epoch:  15  	Training Loss: 0.02963337115943432
Test Loss:  0.009003251791000366
Valid Loss:  0.017088253051042557
Epoch:  16  	Training Loss: 0.029628422111272812
Test Loss:  0.00898777972906828
Valid Loss:  0.017086051404476166
Epoch:  17  	Training Loss: 0.02962440997362137
Test Loss:  0.00899098627269268
Valid Loss:  0.017085183411836624
Epoch:  18  	Training Loss: 0.029620923101902008
Test Loss:  0.008984202519059181
Valid Loss:  0.017084386199712753
Epoch:  19  	Training Loss: 0.02961786836385727
Test Loss:  0.008983385749161243
Valid Loss:  0.017083963379263878
Epoch:  20  	Training Loss: 0.02961535006761551
Test Loss:  0.008982060477137566
Valid Loss:  0.017083769664168358
Epoch:  21  	Training Loss: 0.029613392427563667
Test Loss:  0.008978248573839664
Valid Loss:  0.017083922401070595
Epoch:  22  	Training Loss: 0.029611967504024506
Test Loss:  0.008974596858024597
Valid Loss:  0.017084285616874695
Epoch:  23  	Training Loss: 0.029610808938741684
Test Loss:  0.008980395272374153
Valid Loss:  0.01708400249481201
Epoch:  24  	Training Loss: 0.029609844088554382
Test Loss:  0.008966361172497272
Valid Loss:  0.017085900530219078
Epoch:  25  	Training Loss: 0.029609302058815956
Test Loss:  0.008983065374195576
Valid Loss:  0.0170842744410038
Epoch:  26  	Training Loss: 0.02960875816643238
Test Loss:  0.008960342034697533
Valid Loss:  0.01708790846168995
Epoch:  27  	Training Loss: 0.029608499258756638
Test Loss:  0.00898638553917408
Valid Loss:  0.017084604129195213
Epoch:  28  	Training Loss: 0.02960832230746746
Test Loss:  0.00895221158862114
Valid Loss:  0.0170911718159914
Epoch:  29  	Training Loss: 0.02960876189172268
Test Loss:  0.008989851921796799
Valid Loss:  0.017084933817386627
Epoch:  30  	Training Loss: 0.029608532786369324
Test Loss:  0.008944371715188026
Valid Loss:  0.017095185816287994
Epoch:  31  	Training Loss: 0.029609952121973038
Test Loss:  0.008993636816740036
Valid Loss:  0.017085164785385132
Epoch:  32  	Training Loss: 0.029609093442559242
Test Loss:  0.008939150720834732
Valid Loss:  0.017098838463425636
Epoch:  33  	Training Loss: 0.029611459001898766
Test Loss:  0.009013628587126732
Valid Loss:  0.017087049782276154
Epoch:  34  	Training Loss: 0.02961307018995285
Test Loss:  0.008932426571846008
Valid Loss:  0.01710459589958191
Epoch:  35  	Training Loss: 0.02961418405175209
Test Loss:  0.00903845950961113
Valid Loss:  0.017091847956180573
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.029619676992297173
Test Loss:  0.008965451270341873
Valid Loss:  0.01708967611193657
Epoch:  37  	Training Loss: 0.02960621565580368
Test Loss:  0.008963259868323803
Valid Loss:  0.017090264707803726
Epoch:  38  	Training Loss: 0.02960609644651413
Test Loss:  0.008966850116848946
Valid Loss:  0.017089515924453735
Epoch:  39  	Training Loss: 0.02960607409477234
Test Loss:  0.008963348343968391
Valid Loss:  0.01709042489528656
Epoch:  40  	Training Loss: 0.029606042429804802
Test Loss:  0.008966522291302681
Valid Loss:  0.017089761793613434
Epoch:  41  	Training Loss: 0.029605954885482788
Test Loss:  0.00896432250738144
Valid Loss:  0.017090365290641785
Epoch:  42  	Training Loss: 0.029605962336063385
Test Loss:  0.008967084810137749
Valid Loss:  0.017089813947677612
Epoch:  43  	Training Loss: 0.029605934396386147
Test Loss:  0.008963989093899727
Valid Loss:  0.017090629786252975
Epoch:  44  	Training Loss: 0.029605921357870102
Test Loss:  0.008966823108494282
Valid Loss:  0.01709004119038582
Epoch:  45  	Training Loss: 0.029605913907289505
Test Loss:  0.008964281529188156
Valid Loss:  0.017090722918510437
Epoch:  46  	Training Loss: 0.02960587479174137
Test Loss:  0.008966556750237942
Valid Loss:  0.017090260982513428
Epoch:  47  	Training Loss: 0.029605891555547714
Test Loss:  0.008962308056652546
Valid Loss:  0.01709137111902237
Epoch:  48  	Training Loss: 0.029605913907289505
Test Loss:  0.008965091779828072
Valid Loss:  0.017090706154704094
Epoch:  49  	Training Loss: 0.02960585057735443
Test Loss:  0.008963503874838352
Valid Loss:  0.017091158777475357
Epoch:  50  	Training Loss: 0.029605839401483536
Test Loss:  0.00896628387272358
Valid Loss:  0.017090536653995514
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.029605872929096222
Test Loss:  0.008963693864643574
Valid Loss:  0.017091192305088043
Epoch:  52  	Training Loss: 0.029605820775032043
Test Loss:  0.008963558822870255
Valid Loss:  0.01709124445915222
Epoch:  53  	Training Loss: 0.029605818912386894
Test Loss:  0.008963312022387981
Valid Loss:  0.017091326415538788
Epoch:  54  	Training Loss: 0.029605817049741745
Test Loss:  0.008964205160737038
Valid Loss:  0.01709112338721752
Epoch:  55  	Training Loss: 0.029605820775032043
Test Loss:  0.00896424986422062
Valid Loss:  0.017091136425733566
Epoch:  56  	Training Loss: 0.029605818912386894
Test Loss:  0.008963808417320251
Valid Loss:  0.01709126867353916
Epoch:  57  	Training Loss: 0.029605817049741745
Test Loss:  0.00896367710083723
Valid Loss:  0.01709132269024849
Epoch:  58  	Training Loss: 0.029605813324451447
Test Loss:  0.008963402360677719
Valid Loss:  0.017091408371925354
Epoch:  59  	Training Loss: 0.029605813324451447
Test Loss:  0.008963389322161674
Valid Loss:  0.017091426998376846
Epoch:  60  	Training Loss: 0.029605809599161148
Test Loss:  0.008963221684098244
Valid Loss:  0.01709148660302162
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.029605807736516
Test Loss:  0.008963169530034065
Valid Loss:  0.017091507092118263
Epoch:  62  	Training Loss: 0.029605807736516
Test Loss:  0.008963126689195633
Valid Loss:  0.017091523855924606
Epoch:  63  	Training Loss: 0.029605807736516
Test Loss:  0.008963089436292648
Valid Loss:  0.0170915387570858
Epoch:  64  	Training Loss: 0.02960580587387085
Test Loss:  0.00896306149661541
Valid Loss:  0.017091553658246994
Epoch:  65  	Training Loss: 0.02960580587387085
Test Loss:  0.008963039144873619
Valid Loss:  0.01709156483411789
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.02960580587387085
Test Loss:  0.008963028900325298
Valid Loss:  0.017091568559408188
Epoch:  67  	Training Loss: 0.02960580587387085
Test Loss:  0.008963020518422127
Valid Loss:  0.017091574147343636
 14%|█▍        | 69/500 [01:13<07:42,  1.07s/it] 14%|█▍        | 69/500 [01:25<07:42,  1.07s/it] 14%|█▍        | 71/500 [01:26<19:01,  2.66s/it] 15%|█▍        | 73/500 [01:26<13:25,  1.89s/it] 15%|█▌        | 75/500 [01:32<16:01,  2.26s/it] 15%|█▌        | 77/500 [01:32<11:18,  1.61s/it] 16%|█▌        | 79/500 [01:32<08:01,  1.14s/it] 16%|█▌        | 81/500 [01:45<18:53,  2.71s/it] 17%|█▋        | 83/500 [01:45<13:21,  1.92s/it] 17%|█▋        | 85/500 [01:52<15:56,  2.31s/it] 17%|█▋        | 87/500 [01:52<11:15,  1.64s/it] 18%|█▊        | 89/500 [01:52<07:58,  1.16s/it] 18%|█▊        | 91/500 [01:58<12:06,  1.78s/it] 19%|█▊        | 93/500 [01:59<08:36,  1.27s/it] 19%|█▉        | 95/500 [02:05<12:33,  1.86s/it] 19%|█▉        | 97/500 [02:05<08:53,  1.32s/it] 20%|█▉        | 99/500 [02:05<06:19,  1.06it/s] 20%|█▉        | 99/500 [02:16<06:19,  1.06it/s] 20%|██        | 101/500 [02:18<16:54,  2.54s/it] 20%|██        | 102/500 [02:18<14:00,  2.11s/it] 21%|██        | 104/500 [02:18<09:27,  1.43s/it] 21%|██        | 106/500 [02:25<13:07,  2.00s/it] 22%|██▏       | 108/500 [02:25<09:03,  1.39s/it] 22%|██▏       | 110/500 [02:31<12:40,  1.95s/it] 22%|██▏       | 111/500 [02:37<17:47,  2.75s/it] 23%|██▎       | 113/500 [02:38<11:48,  1.83s/it] 23%|██▎       | 115/500 [02:44<14:36,  2.28s/it] 23%|██▎       | 117/500 [02:44<10:02,  1.57s/it] 24%|██▍       | 119/500 [02:44<06:58,  1.10s/it] 24%|██▍       | 119/500 [02:56<06:58,  1.10s/it] 24%|██▍       | 121/500 [02:57<17:12,  2.72s/it] 25%|██▍       | 123/500 [02:57<12:00,  1.91s/it] 25%|██▌       | 125/500 [03:03<14:20,  2.29s/it] 25%|██▌       | 127/500 [03:03<10:04,  1.62s/it]Epoch:  68  	Training Loss: 0.02960580587387085
Test Loss:  0.00896301306784153
Valid Loss:  0.017091577872633934
Epoch:  69  	Training Loss: 0.0296058040112257
Test Loss:  0.008963005617260933
Valid Loss:  0.01709158346056938
Epoch:  70  	Training Loss: 0.02960580587387085
Test Loss:  0.008963000029325485
Valid Loss:  0.01709158718585968
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.02960580214858055
Test Loss:  0.008962998166680336
Valid Loss:  0.01709159091114998
Epoch:  72  	Training Loss: 0.02960580587387085
Test Loss:  0.008962993510067463
Valid Loss:  0.01709159091114998
Epoch:  73  	Training Loss: 0.02960580587387085
Test Loss:  0.008962992578744888
Valid Loss:  0.017091594636440277
Epoch:  74  	Training Loss: 0.0296058040112257
Test Loss:  0.008962989784777164
Valid Loss:  0.017091594636440277
Epoch:  75  	Training Loss: 0.02960580587387085
Test Loss:  0.00896298699080944
Valid Loss:  0.017091598361730576
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.0296058040112257
Test Loss:  0.008962986059486866
Valid Loss:  0.017091598361730576
Epoch:  77  	Training Loss: 0.02960580587387085
Test Loss:  0.008962986059486866
Valid Loss:  0.017091598361730576
Epoch:  78  	Training Loss: 0.0296058040112257
Test Loss:  0.008962985128164291
Valid Loss:  0.017091600224375725
Epoch:  79  	Training Loss: 0.02960580587387085
Test Loss:  0.008962984196841717
Valid Loss:  0.017091600224375725
Epoch:  80  	Training Loss: 0.02960580587387085
Test Loss:  0.008962982334196568
Valid Loss:  0.017091602087020874
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0296058040112257
Test Loss:  0.008962982334196568
Valid Loss:  0.017091602087020874
Epoch:  82  	Training Loss: 0.0296058040112257
Test Loss:  0.008962981402873993
Valid Loss:  0.017091602087020874
Epoch:  83  	Training Loss: 0.0296058040112257
Test Loss:  0.008962981402873993
Valid Loss:  0.017091602087020874
Epoch:  84  	Training Loss: 0.02960580214858055
Test Loss:  0.008962981402873993
Valid Loss:  0.017091602087020874
Epoch:  85  	Training Loss: 0.02960580587387085
Test Loss:  0.008962980471551418
Valid Loss:  0.017091603949666023
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.0296058040112257
Test Loss:  0.008962980471551418
Valid Loss:  0.017091603949666023
Epoch:  87  	Training Loss: 0.02960580587387085
Test Loss:  0.008962979540228844
Valid Loss:  0.017091605812311172
Epoch:  88  	Training Loss: 0.0296058040112257
Test Loss:  0.008962979540228844
Valid Loss:  0.017091603949666023
Epoch:  89  	Training Loss: 0.02960580214858055
Test Loss:  0.008962979540228844
Valid Loss:  0.017091605812311172
Epoch:  90  	Training Loss: 0.02960580214858055
Test Loss:  0.008962978608906269
Valid Loss:  0.017091605812311172
Epoch:  91  	Training Loss: 0.02960580587387085
Test Loss:  0.008962978608906269
Valid Loss:  0.017091605812311172
Epoch:  92  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  93  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  94  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  95  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  97  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  98  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  99  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  100  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  102  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  103  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  104  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  105  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  107  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  108  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  109  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  110  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  112  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  113  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  114  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  115  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  117  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  118  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  119  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  120  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  122  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  123  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  124  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  125  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  127  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
 26%|██▌       | 129/500 [03:04<07:06,  1.15s/it] 26%|██▌       | 129/500 [03:16<07:06,  1.15s/it] 26%|██▌       | 131/500 [03:16<16:51,  2.74s/it] 27%|██▋       | 133/500 [03:17<11:50,  1.94s/it] 27%|██▋       | 135/500 [03:23<14:10,  2.33s/it] 27%|██▋       | 137/500 [03:23<10:00,  1.65s/it] 28%|██▊       | 139/500 [03:23<07:05,  1.18s/it] 28%|██▊       | 139/500 [03:36<07:05,  1.18s/it] 28%|██▊       | 141/500 [03:36<16:37,  2.78s/it] 29%|██▊       | 143/500 [03:37<11:41,  1.97s/it] 29%|██▉       | 145/500 [03:43<13:40,  2.31s/it] 29%|██▉       | 147/500 [03:43<09:40,  1.64s/it] 30%|██▉       | 149/500 [03:43<06:52,  1.17s/it] 30%|██▉       | 149/500 [03:56<06:52,  1.17s/it] 30%|███       | 151/500 [03:56<15:47,  2.71s/it] 31%|███       | 153/500 [03:56<11:08,  1.93s/it] 31%|███       | 155/500 [04:02<13:24,  2.33s/it] 31%|███▏      | 157/500 [04:03<09:26,  1.65s/it] 32%|███▏      | 159/500 [04:03<06:41,  1.18s/it] 32%|███▏      | 159/500 [04:16<06:41,  1.18s/it] 32%|███▏      | 161/500 [04:16<15:33,  2.75s/it] 33%|███▎      | 163/500 [04:16<10:56,  1.95s/it] 33%|███▎      | 165/500 [04:22<13:00,  2.33s/it] 33%|███▎      | 167/500 [04:22<09:10,  1.65s/it] 34%|███▍      | 169/500 [04:22<06:29,  1.18s/it] 34%|███▍      | 171/500 [04:35<14:57,  2.73s/it] 35%|███▍      | 173/500 [04:35<10:31,  1.93s/it] 35%|███▌      | 175/500 [04:42<12:25,  2.29s/it] 35%|███▌      | 177/500 [04:42<08:47,  1.63s/it] 36%|███▌      | 179/500 [04:42<06:13,  1.16s/it] 36%|███▌      | 181/500 [04:55<14:31,  2.73s/it] 37%|███▋      | 183/500 [04:55<10:12,  1.93s/it] 37%|███▋      | 185/500 [05:01<12:10,  2.32s/it]Epoch:  128  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  129  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  130  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  132  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  133  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  134  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  135  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  137  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  138  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  139  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  140  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  142  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  143  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  144  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  145  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  147  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  148  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  149  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  150  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  152  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  153  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  154  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  155  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  157  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  158  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  159  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  160  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  162  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  163  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  164  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  165  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  167  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  168  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  169  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  170  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  172  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160953760147
Epoch:  173  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  174  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  175  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  177  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  178  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  179  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  180  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  182  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  183  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  184  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  185  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632 37%|███▋      | 187/500 [05:01<08:34,  1.64s/it] 38%|███▊      | 189/500 [05:02<06:04,  1.17s/it] 38%|███▊      | 191/500 [05:14<13:54,  2.70s/it] 39%|███▊      | 193/500 [05:14<09:46,  1.91s/it] 39%|███▉      | 195/500 [05:21<11:39,  2.29s/it] 39%|███▉      | 197/500 [05:21<08:14,  1.63s/it] 40%|███▉      | 199/500 [05:21<05:49,  1.16s/it] 40%|████      | 201/500 [05:27<08:46,  1.76s/it] 41%|████      | 203/500 [05:27<06:12,  1.25s/it] 41%|████      | 205/500 [05:34<08:58,  1.83s/it] 41%|████▏     | 207/500 [05:34<06:20,  1.30s/it] 42%|████▏     | 209/500 [05:34<04:30,  1.08it/s] 42%|████▏     | 209/500 [05:46<04:30,  1.08it/s] 42%|████▏     | 211/500 [05:46<12:08,  2.52s/it] 43%|████▎     | 213/500 [05:47<08:32,  1.78s/it] 43%|████▎     | 215/500 [05:53<10:36,  2.23s/it] 43%|████▎     | 217/500 [05:53<07:29,  1.59s/it] 44%|████▍     | 219/500 [05:53<05:18,  1.13s/it] 44%|████▍     | 219/500 [06:06<05:18,  1.13s/it] 44%|████▍     | 221/500 [06:06<12:25,  2.67s/it] 45%|████▍     | 223/500 [06:06<08:43,  1.89s/it] 45%|████▌     | 225/500 [06:12<10:22,  2.26s/it] 45%|████▌     | 227/500 [06:12<07:18,  1.61s/it] 46%|████▌     | 229/500 [06:13<05:09,  1.14s/it] 46%|████▌     | 231/500 [06:25<12:11,  2.72s/it] 47%|████▋     | 233/500 [06:26<08:33,  1.92s/it] 47%|████▋     | 235/500 [06:32<10:11,  2.31s/it] 47%|████▋     | 237/500 [06:32<07:11,  1.64s/it] 48%|████▊     | 239/500 [06:32<05:05,  1.17s/it] 48%|████▊     | 241/500 [06:45<11:46,  2.73s/it] 49%|████▊     | 243/500 [06:45<08:16,  1.93s/it] 49%|████▉     | 245/500 [06:52<09:54,  2.33s/it]
Epoch:  187  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  188  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  189  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  190  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  192  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  193  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  194  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  195  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  197  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  198  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  199  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  200  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  201  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  202  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  203  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  204  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  205  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  207  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  208  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  209  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  210  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  212  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  213  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  214  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  215  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  217  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  218  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  219  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  220  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  222  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  223  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  224  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  225  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  227  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  228  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  229  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  230  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  232  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  233  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  234  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  235  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  237  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  238  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  239  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  240  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  242  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  243  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  244  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  245  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
 49%|████▉     | 247/500 [06:52<06:59,  1.66s/it] 50%|████▉     | 249/500 [06:52<04:58,  1.19s/it] 50%|█████     | 250/500 [06:58<08:46,  2.11s/it] 50%|█████     | 251/500 [07:05<12:14,  2.95s/it] 51%|█████     | 253/500 [07:05<07:50,  1.91s/it] 51%|█████     | 255/500 [07:11<09:36,  2.35s/it] 51%|█████▏    | 257/500 [07:11<06:29,  1.60s/it] 52%|█████▏    | 259/500 [07:12<04:28,  1.11s/it] 52%|█████▏    | 260/500 [07:18<08:16,  2.07s/it] 52%|█████▏    | 261/500 [07:24<11:46,  2.96s/it] 53%|█████▎    | 263/500 [07:24<07:25,  1.88s/it] 53%|█████▎    | 265/500 [07:31<09:09,  2.34s/it] 53%|█████▎    | 267/500 [07:31<06:09,  1.59s/it] 54%|█████▍    | 269/500 [07:31<04:13,  1.10s/it] 54%|█████▍    | 271/500 [07:43<10:23,  2.72s/it] 55%|█████▍    | 273/500 [07:44<07:10,  1.90s/it] 55%|█████▌    | 275/500 [07:50<08:32,  2.28s/it] 55%|█████▌    | 277/500 [07:50<05:57,  1.61s/it] 56%|█████▌    | 279/500 [07:50<04:11,  1.14s/it] 56%|█████▌    | 281/500 [08:03<09:51,  2.70s/it] 57%|█████▋    | 283/500 [08:03<06:55,  1.91s/it] 57%|█████▋    | 285/500 [08:10<08:19,  2.32s/it] 57%|█████▋    | 287/500 [08:10<05:50,  1.64s/it] 58%|█████▊    | 289/500 [08:10<04:06,  1.17s/it] 58%|█████▊    | 291/500 [08:23<09:32,  2.74s/it] 59%|█████▊    | 293/500 [08:23<06:41,  1.94s/it] 59%|█████▉    | 295/500 [08:29<07:56,  2.33s/it] 59%|█████▉    | 297/500 [08:29<05:35,  1.65s/it] 60%|█████▉    | 299/500 [08:29<03:56,  1.18s/it] 60%|██████    | 301/500 [08:36<05:58,  1.80s/it] 61%|██████    | 303/500 [08:36<04:12,  1.28s/it] 61%|██████    | 305/500 [08:43<06:02,  1.86s/it]Epoch:  247  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  248  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  249  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  250  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  252  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  253  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  254  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  255  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  257  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  258  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  259  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  260  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  262  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  263  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  264  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  265  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  267  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  268  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  269  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  270  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160953760147
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  272  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  273  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  274  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  275  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  277  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  278  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  279  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  280  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  282  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  283  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  284  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  285  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  287  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  288  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  289  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  290  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  292  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  293  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  294  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  295  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  297  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  298  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  299  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  300  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  301  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  302  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  303  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  304  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  305  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
 61%|██████▏   | 307/500 [08:43<04:15,  1.32s/it] 62%|██████▏   | 309/500 [08:43<03:00,  1.06it/s] 62%|██████▏   | 311/500 [08:55<08:00,  2.54s/it] 63%|██████▎   | 313/500 [08:55<05:37,  1.81s/it] 63%|██████▎   | 315/500 [09:02<06:52,  2.23s/it] 63%|██████▎   | 317/500 [09:02<04:49,  1.58s/it] 64%|██████▍   | 319/500 [09:02<03:23,  1.13s/it] 64%|██████▍   | 321/500 [09:15<08:00,  2.68s/it] 65%|██████▍   | 323/500 [09:15<05:36,  1.90s/it] 65%|██████▌   | 325/500 [09:21<06:38,  2.28s/it] 65%|██████▌   | 327/500 [09:21<04:39,  1.62s/it] 66%|██████▌   | 329/500 [09:22<03:17,  1.15s/it] 66%|██████▌   | 331/500 [09:34<07:36,  2.70s/it] 67%|██████▋   | 333/500 [09:34<05:19,  1.91s/it] 67%|██████▋   | 335/500 [09:41<06:17,  2.29s/it] 67%|██████▋   | 337/500 [09:41<04:24,  1.62s/it] 68%|██████▊   | 339/500 [09:41<03:06,  1.16s/it] 68%|██████▊   | 341/500 [09:54<07:10,  2.71s/it] 69%|██████▊   | 343/500 [09:54<05:00,  1.92s/it] 69%|██████▉   | 345/500 [10:00<05:57,  2.31s/it] 69%|██████▉   | 347/500 [10:00<04:11,  1.64s/it] 70%|██████▉   | 349/500 [10:01<02:57,  1.18s/it] 70%|███████   | 351/500 [10:13<06:45,  2.72s/it] 71%|███████   | 353/500 [10:13<04:43,  1.93s/it] 71%|███████   | 355/500 [10:20<05:33,  2.30s/it] 71%|███████▏  | 357/500 [10:20<03:53,  1.63s/it] 72%|███████▏  | 359/500 [10:20<02:44,  1.17s/it] 72%|███████▏  | 361/500 [10:26<04:06,  1.77s/it] 73%|███████▎  | 363/500 [10:27<02:53,  1.26s/it] 73%|███████▎  | 365/500 [10:33<04:08,  1.84s/it]Epoch:  307  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  308  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  309  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  310  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  312  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  313  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  314  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  315  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  317  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  318  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  319  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  320  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  322  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  323  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  324  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  325  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  327  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  328  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  329  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  330  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  332  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  333  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  334  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  335  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  337  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  338  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  339  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  340  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  342  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  343  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  344  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  345  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160953760147
Epoch:  347  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  348  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  349  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  350  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  352  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  353  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  354  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  355  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  357  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  358  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  359  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  360  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  361  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  362  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  363  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  364  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  365  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
 73%|███████▎  | 367/500 [10:33<02:54,  1.31s/it] 74%|███████▍  | 369/500 [10:33<02:02,  1.07it/s] 74%|███████▍  | 369/500 [10:46<02:02,  1.07it/s] 74%|███████▍  | 371/500 [10:46<05:29,  2.56s/it] 75%|███████▍  | 373/500 [10:46<03:49,  1.81s/it] 75%|███████▌  | 375/500 [10:52<04:38,  2.23s/it] 75%|███████▌  | 377/500 [10:53<03:14,  1.58s/it] 76%|███████▌  | 379/500 [10:53<02:16,  1.12s/it] 76%|███████▌  | 381/500 [11:05<05:18,  2.68s/it] 77%|███████▋  | 383/500 [11:05<03:41,  1.90s/it] 77%|███████▋  | 385/500 [11:12<04:22,  2.28s/it] 77%|███████▋  | 387/500 [11:12<03:03,  1.62s/it] 78%|███████▊  | 389/500 [11:12<02:08,  1.15s/it] 78%|███████▊  | 391/500 [11:25<04:52,  2.69s/it] 79%|███████▊  | 393/500 [11:25<03:23,  1.90s/it] 79%|███████▉  | 395/500 [11:31<04:00,  2.29s/it] 79%|███████▉  | 397/500 [11:31<02:47,  1.63s/it] 80%|███████▉  | 399/500 [11:31<01:56,  1.16s/it] 80%|████████  | 401/500 [11:38<02:54,  1.76s/it] 81%|████████  | 403/500 [11:38<02:01,  1.26s/it] 81%|████████  | 405/500 [11:44<02:53,  1.82s/it] 81%|████████▏ | 407/500 [11:44<02:00,  1.30s/it] 82%|████████▏ | 409/500 [11:44<01:24,  1.08it/s] 82%|████████▏ | 409/500 [11:56<01:24,  1.08it/s] 82%|████████▏ | 411/500 [11:57<03:45,  2.54s/it] 83%|████████▎ | 413/500 [11:57<02:36,  1.80s/it] 83%|████████▎ | 415/500 [12:04<03:08,  2.21s/it] 83%|████████▎ | 417/500 [12:04<02:10,  1.57s/it] 84%|████████▍ | 419/500 [12:04<01:30,  1.12s/it] 84%|████████▍ | 419/500 [12:16<01:30,  1.12s/it] 84%|████████▍ | 421/500 [12:16<03:30,  2.67s/it] 85%|████████▍ | 423/500 [12:17<02:25,  1.89s/it] 85%|████████▌ | 425/500 [12:23<02:53,  2.31s/it]Epoch:  367  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  368  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160953760147
Epoch:  369  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  370  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  372  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  373  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  374  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  375  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160953760147
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  377  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  378  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  379  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  380  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  382  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  383  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  384  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  385  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  387  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  388  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  389  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  390  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160953760147
Epoch:  392  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  393  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  394  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  395  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  397  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  398  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  399  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  400  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  401  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  402  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  403  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  404  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  405  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  407  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  408  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  409  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  410  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  412  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  413  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  414  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  415  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  417  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  418  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  419  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  420  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  422  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  423  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  424  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  425  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
 85%|████████▌ | 427/500 [12:23<01:59,  1.64s/it] 86%|████████▌ | 429/500 [12:23<01:22,  1.17s/it] 86%|████████▌ | 429/500 [12:36<01:22,  1.17s/it] 86%|████████▌ | 431/500 [12:36<03:06,  2.71s/it] 87%|████████▋ | 433/500 [12:36<02:08,  1.92s/it] 87%|████████▋ | 435/500 [12:36<01:28,  1.36s/it] 87%|████████▋ | 437/500 [12:36<01:01,  1.03it/s] 88%|████████▊ | 439/500 [12:37<00:42,  1.43it/s] 88%|████████▊ | 441/500 [12:49<02:20,  2.37s/it] 89%|████████▊ | 443/500 [12:49<01:35,  1.68s/it] 89%|████████▉ | 445/500 [12:56<01:57,  2.14s/it] 89%|████████▉ | 447/500 [12:56<01:20,  1.52s/it] 90%|████████▉ | 449/500 [12:56<00:55,  1.08s/it] 90%|█████████ | 451/500 [13:08<02:08,  2.63s/it] 91%|█████████ | 453/500 [13:09<01:27,  1.86s/it] 91%|█████████ | 455/500 [13:15<01:41,  2.26s/it] 91%|█████████▏| 457/500 [13:15<01:08,  1.60s/it] 92%|█████████▏| 459/500 [13:15<00:47,  1.15s/it] 92%|█████████▏| 459/500 [13:26<00:47,  1.15s/it] 92%|█████████▏| 461/500 [13:28<01:45,  2.71s/it] 93%|█████████▎| 463/500 [13:28<01:11,  1.92s/it] 93%|█████████▎| 465/500 [13:35<01:21,  2.32s/it] 93%|█████████▎| 467/500 [13:35<00:54,  1.65s/it] 94%|█████████▍| 469/500 [13:35<00:36,  1.17s/it] 94%|█████████▍| 469/500 [13:46<00:36,  1.17s/it] 94%|█████████▍| 471/500 [13:48<01:18,  2.72s/it] 95%|█████████▍| 473/500 [13:48<00:51,  1.93s/it] 95%|█████████▌| 475/500 [13:54<00:57,  2.30s/it] 95%|█████████▌| 477/500 [13:54<00:37,  1.63s/it] 96%|█████████▌| 479/500 [13:54<00:24,  1.16s/it] 96%|█████████▌| 479/500 [14:06<00:24,  1.16s/it] 96%|█████████▌| 481/500 [14:07<00:51,  2.69s/it] 97%|█████████▋| 483/500 [14:07<00:32,  1.90s/it] 97%|█████████▋| 485/500 [14:13<00:34,  2.29s/it]Epoch:  427  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  428  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  429  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  430  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  432  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  433  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  434  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  435  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  436  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  437  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  438  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  439  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  440  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  442  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  443  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  444  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  445  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  447  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  448  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  449  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  450  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  452  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  453  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  454  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  455  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  457  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  458  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  459  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  460  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  462  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  463  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  464  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  465  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  467  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  468  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  469  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
Epoch:  470  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  472  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  473  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  474  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  475  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0296058040112257
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  477  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  478  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  479  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  480  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  482  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  483  	Training Loss: 0.02960580214858055
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  484  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  485  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
 97%|█████████▋| 487/500 [14:13<00:21,  1.63s/it] 98%|█████████▊| 489/500 [14:14<00:12,  1.16s/it] 98%|█████████▊| 489/500 [14:26<00:12,  1.16s/it] 98%|█████████▊| 491/500 [14:26<00:24,  2.69s/it] 99%|█████████▊| 493/500 [14:26<00:13,  1.91s/it] 99%|█████████▉| 495/500 [14:33<00:11,  2.28s/it] 99%|█████████▉| 497/500 [14:33<00:04,  1.62s/it]100%|█████████▉| 499/500 [14:33<00:01,  1.15s/it]100%|██████████| 500/500 [14:39<00:00,  1.76s/it]
Epoch:  487  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  488  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160953760147
Epoch:  489  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  490  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  492  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.017091605812311172
Epoch:  493  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.017091605812311172
Epoch:  494  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  495  	Training Loss: 0.02960580587387085
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  497  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  498  	Training Loss: 0.02960580214858055
Test Loss:  0.00896297674626112
Valid Loss:  0.01709160767495632
Epoch:  499  	Training Loss: 0.0296058040112257
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160767495632
Epoch:  500  	Training Loss: 0.02960580587387085
Test Loss:  0.008962977677583694
Valid Loss:  0.01709160953760147
**************************************************learning rate decay**************************************************
seed is  3
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:28,  6.31s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.87it/s]  2%|▏         | 11/500 [00:13<10:58,  1.35s/it]  3%|▎         | 13/500 [00:13<07:28,  1.08it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:38,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:33<16:34,  2.12s/it]  7%|▋         | 33/500 [00:33<11:42,  1.50s/it]  7%|▋         | 35/500 [00:39<15:34,  2.01s/it]  7%|▋         | 37/500 [00:39<11:00,  1.43s/it]  8%|▊         | 39/500 [00:39<07:48,  1.02s/it]  8%|▊         | 39/500 [00:50<07:48,  1.02s/it]  8%|▊         | 41/500 [00:52<19:56,  2.61s/it]  9%|▊         | 43/500 [00:52<14:03,  1.85s/it]  9%|▉         | 45/500 [00:59<17:06,  2.26s/it]  9%|▉         | 47/500 [00:59<12:05,  1.60s/it] 10%|▉         | 49/500 [00:59<08:33,  1.14s/it] 10%|▉         | 49/500 [01:10<08:33,  1.14s/it] 10%|█         | 51/500 [01:11<19:58,  2.67s/it] 11%|█         | 53/500 [01:12<14:04,  1.89s/it] 11%|█         | 55/500 [01:18<16:55,  2.28s/it] 11%|█▏        | 57/500 [01:18<11:57,  1.62s/it] 12%|█▏        | 59/500 [01:18<08:28,  1.15s/it] 12%|█▏        | 59/500 [01:30<08:28,  1.15s/it] 12%|█▏        | 61/500 [01:31<19:46,  2.70s/it] 13%|█▎        | 63/500 [01:31<13:58,  1.92s/it]Epoch:  1  	Training Loss: 0.09565693140029907
Test Loss:  3.769409656524658
Valid Loss:  3.697885513305664
Epoch:  2  	Training Loss: 3.768542766571045
Test Loss:  0.16116109490394592
Valid Loss:  0.15488015115261078
Epoch:  3  	Training Loss: 0.1196025013923645
Test Loss:  0.15701571106910706
Valid Loss:  0.150977224111557
Epoch:  4  	Training Loss: 0.11634320020675659
Test Loss:  0.1529950648546219
Valid Loss:  0.14719252288341522
Epoch:  5  	Training Loss: 0.11319096386432648
Test Loss:  0.14909517765045166
Valid Loss:  0.14352229237556458
Epoch:  6  	Training Loss: 0.11014218628406525
Test Loss:  0.14531224966049194
Valid Loss:  0.13996285200119019
Epoch:  7  	Training Loss: 0.10719339549541473
Test Loss:  0.1416425257921219
Valid Loss:  0.1365106701850891
Epoch:  8  	Training Loss: 0.10434123873710632
Test Loss:  0.13808245956897736
Valid Loss:  0.13316234946250916
Epoch:  9  	Training Loss: 0.10158246755599976
Test Loss:  0.135136216878891
Valid Loss:  0.1305491030216217
Epoch:  10  	Training Loss: 0.09927944839000702
Test Loss:  0.1350627839565277
Valid Loss:  0.13047221302986145
Epoch:  11  	Training Loss: 0.09918572008609772
Test Loss:  0.13506269454956055
Valid Loss:  0.13047191500663757
Epoch:  12  	Training Loss: 0.09918555617332458
Test Loss:  0.13506260514259338
Valid Loss:  0.13047175109386444
Epoch:  13  	Training Loss: 0.09918543696403503
Test Loss:  0.13506251573562622
Valid Loss:  0.1304716318845749
Epoch:  14  	Training Loss: 0.09918534755706787
Test Loss:  0.13506244122982025
Valid Loss:  0.1304715871810913
Epoch:  15  	Training Loss: 0.09918525815010071
Test Loss:  0.13506236672401428
Valid Loss:  0.13047155737876892
Epoch:  16  	Training Loss: 0.09918516874313354
Test Loss:  0.1350623369216919
Valid Loss:  0.13047155737876892
Epoch:  17  	Training Loss: 0.09918508678674698
Test Loss:  0.1350623220205307
Valid Loss:  0.13047154247760773
Epoch:  18  	Training Loss: 0.0991850271821022
Test Loss:  0.1350623071193695
Valid Loss:  0.13047152757644653
Epoch:  19  	Training Loss: 0.09918498247861862
Test Loss:  0.1350622922182083
Valid Loss:  0.13047152757644653
Epoch:  20  	Training Loss: 0.09918496012687683
Test Loss:  0.1350623071193695
Valid Loss:  0.13047152757644653
Epoch:  21  	Training Loss: 0.09918496012687683
Test Loss:  0.13506227731704712
Valid Loss:  0.13047152757644653
Epoch:  22  	Training Loss: 0.09918494522571564
Test Loss:  0.13506227731704712
Valid Loss:  0.13047151267528534
Epoch:  23  	Training Loss: 0.09918493777513504
Test Loss:  0.13506227731704712
Valid Loss:  0.13047151267528534
Epoch:  24  	Training Loss: 0.09918493032455444
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  25  	Training Loss: 0.09918493032455444
Test Loss:  0.13506227731704712
Valid Loss:  0.13047151267528534
Epoch:  26  	Training Loss: 0.09918493032455444
Test Loss:  0.13506227731704712
Valid Loss:  0.13047151267528534
Epoch:  27  	Training Loss: 0.09918493032455444
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  28  	Training Loss: 0.09918492287397385
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  29  	Training Loss: 0.09918492287397385
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  30  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  32  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  33  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  34  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  35  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  37  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  38  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  39  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  40  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  42  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  43  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  44  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  45  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  47  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  48  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  49  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  50  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  52  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  53  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  54  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  55  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047148287296295
Epoch:  57  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  58  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  59  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  60  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  62  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  63  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  64  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  65  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
 13%|█▎        | 65/500 [01:37<16:36,  2.29s/it] 13%|█▎        | 66/500 [01:37<13:46,  1.90s/it] 14%|█▎        | 68/500 [01:38<09:19,  1.30s/it] 14%|█▍        | 70/500 [01:44<13:47,  1.92s/it] 14%|█▍        | 71/500 [01:50<19:37,  2.74s/it] 15%|█▍        | 73/500 [01:51<12:54,  1.81s/it] 15%|█▌        | 75/500 [01:57<15:58,  2.25s/it] 15%|█▌        | 77/500 [01:57<10:55,  1.55s/it] 16%|█▌        | 79/500 [01:57<07:35,  1.08s/it] 16%|█▌        | 81/500 [02:10<18:55,  2.71s/it] 17%|█▋        | 83/500 [02:10<13:11,  1.90s/it] 17%|█▋        | 85/500 [02:16<15:52,  2.30s/it] 17%|█▋        | 87/500 [02:16<11:11,  1.63s/it] 18%|█▊        | 89/500 [02:17<07:56,  1.16s/it] 18%|█▊        | 91/500 [02:29<18:31,  2.72s/it] 19%|█▊        | 93/500 [02:29<13:02,  1.92s/it] 19%|█▉        | 95/500 [02:36<15:31,  2.30s/it] 19%|█▉        | 97/500 [02:36<10:57,  1.63s/it] 20%|█▉        | 99/500 [02:36<07:45,  1.16s/it] 20%|██        | 101/500 [02:49<18:06,  2.72s/it] 21%|██        | 103/500 [02:49<12:47,  1.93s/it] 21%|██        | 105/500 [02:55<15:16,  2.32s/it] 21%|██▏       | 107/500 [02:56<10:48,  1.65s/it] 22%|██▏       | 109/500 [02:56<07:39,  1.18s/it] 22%|██▏       | 111/500 [03:08<17:28,  2.70s/it] 23%|██▎       | 113/500 [03:08<12:18,  1.91s/it] 23%|██▎       | 115/500 [03:15<14:47,  2.31s/it] 23%|██▎       | 117/500 [03:15<10:28,  1.64s/it] 24%|██▍       | 119/500 [03:15<07:25,  1.17s/it] 24%|██▍       | 121/500 [03:28<17:18,  2.74s/it] 25%|██▍       | 123/500 [03:28<12:11,  1.94s/it]**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  67  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  68  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  69  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  70  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  72  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  73  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  74  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  75  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  77  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  78  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  79  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  80  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  82  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  83  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  84  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  85  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  87  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  88  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  89  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  90  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  92  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  93  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  94  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  95  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.09918490797281265
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  97  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  98  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  99  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  100  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  102  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  103  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  104  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  105  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  107  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  108  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  109  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  110  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  112  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  113  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  114  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  115  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  117  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  118  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047148287296295
Epoch:  119  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  120  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  122  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  123  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
Epoch:  124  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  125  	Training Loss: 0.09918491542339325
Test Loss:   25%|██▌       | 125/500 [03:35<14:32,  2.33s/it] 25%|██▌       | 127/500 [03:35<10:15,  1.65s/it] 26%|██▌       | 129/500 [03:35<07:16,  1.18s/it] 26%|██▌       | 131/500 [03:47<16:39,  2.71s/it] 27%|██▋       | 133/500 [03:48<11:43,  1.92s/it] 27%|██▋       | 135/500 [03:54<13:59,  2.30s/it] 27%|██▋       | 137/500 [03:54<09:52,  1.63s/it] 28%|██▊       | 139/500 [03:54<07:01,  1.17s/it] 28%|██▊       | 141/500 [04:07<16:17,  2.72s/it] 29%|██▊       | 143/500 [04:07<11:28,  1.93s/it] 29%|██▉       | 145/500 [04:13<13:32,  2.29s/it] 29%|██▉       | 147/500 [04:13<09:32,  1.62s/it] 30%|██▉       | 149/500 [04:14<06:46,  1.16s/it] 30%|███       | 151/500 [04:26<15:52,  2.73s/it] 31%|███       | 153/500 [04:27<11:09,  1.93s/it] 31%|███       | 155/500 [04:33<13:22,  2.33s/it] 31%|███▏      | 157/500 [04:33<09:28,  1.66s/it] 32%|███▏      | 159/500 [04:33<06:42,  1.18s/it] 32%|███▏      | 161/500 [04:46<15:30,  2.74s/it] 33%|███▎      | 163/500 [04:46<10:55,  1.94s/it] 33%|███▎      | 165/500 [04:53<12:59,  2.33s/it] 33%|███▎      | 167/500 [04:53<09:11,  1.66s/it] 34%|███▍      | 169/500 [04:53<06:32,  1.18s/it] 34%|███▍      | 170/500 [04:59<11:30,  2.09s/it] 34%|███▍      | 171/500 [05:06<16:09,  2.95s/it] 35%|███▍      | 173/500 [05:06<10:21,  1.90s/it] 35%|███▌      | 175/500 [05:12<12:44,  2.35s/it] 35%|███▌      | 177/500 [05:13<08:37,  1.60s/it] 36%|███▌      | 179/500 [05:13<05:57,  1.11s/it] 36%|███▌      | 180/500 [05:19<11:09,  2.09s/it] 36%|███▌      | 181/500 [05:25<15:53,  2.99s/it] 37%|███▋      | 183/500 [05:26<10:00,  1.89s/it]0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  127  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  128  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  129  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  130  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  132  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  133  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  134  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  135  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  137  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  138  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  139  	Training Loss: 0.09918492287397385
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  140  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  142  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  143  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  144  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  145  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  147  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  148  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  149  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  150  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  152  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047148287296295
Epoch:  153  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  154  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  155  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  157  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  158  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  159  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  160  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  162  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  163  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  164  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  165  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  167  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  168  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  169  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  170  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  172  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  173  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  174  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  175  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  177  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  178  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  179  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  180  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  182  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
Epoch:  183  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  184  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
 37%|███▋      | 185/500 [05:32<12:27,  2.37s/it] 37%|███▋      | 187/500 [05:32<08:23,  1.61s/it] 38%|███▊      | 189/500 [05:32<05:45,  1.11s/it] 38%|███▊      | 191/500 [05:45<14:11,  2.76s/it] 39%|███▊      | 193/500 [05:45<09:49,  1.92s/it] 39%|███▉      | 195/500 [05:52<11:46,  2.32s/it] 39%|███▉      | 197/500 [05:52<08:14,  1.63s/it] 40%|███▉      | 199/500 [05:52<05:49,  1.16s/it] 40%|████      | 201/500 [06:04<13:32,  2.72s/it] 41%|████      | 203/500 [06:05<09:30,  1.92s/it] 41%|████      | 205/500 [06:11<11:23,  2.32s/it] 41%|████▏     | 207/500 [06:11<08:02,  1.65s/it] 42%|████▏     | 209/500 [06:11<05:42,  1.18s/it] 42%|████▏     | 210/500 [06:18<10:12,  2.11s/it] 42%|████▏     | 211/500 [06:24<14:21,  2.98s/it] 42%|████▏     | 212/500 [06:24<11:12,  2.34s/it] 43%|████▎     | 214/500 [06:25<06:57,  1.46s/it] 43%|████▎     | 215/500 [06:31<12:02,  2.53s/it] 43%|████▎     | 217/500 [06:31<07:30,  1.59s/it] 44%|████▍     | 219/500 [06:31<04:55,  1.05s/it] 44%|████▍     | 221/500 [06:44<13:05,  2.81s/it] 45%|████▍     | 223/500 [06:44<08:53,  1.92s/it] 45%|████▌     | 225/500 [06:50<10:37,  2.32s/it] 45%|████▌     | 227/500 [06:51<07:22,  1.62s/it] 46%|████▌     | 229/500 [06:51<05:09,  1.14s/it] 46%|████▌     | 231/500 [07:03<12:18,  2.75s/it] 47%|████▋     | 233/500 [07:04<08:37,  1.94s/it] 47%|████▋     | 235/500 [07:10<10:15,  2.32s/it] 47%|████▋     | 237/500 [07:10<07:12,  1.64s/it] 48%|████▊     | 239/500 [07:10<05:04,  1.17s/it] 48%|████▊     | 241/500 [07:23<11:43,  2.72s/it]Valid Loss:  0.13047149777412415
Epoch:  185  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  187  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  188  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  189  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  190  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  192  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  193  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  194  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  195  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  197  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  198  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  199  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  200  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  202  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  203  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  204  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  205  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  207  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  208  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  209  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  210  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  212  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  213  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  214  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  215  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  217  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  218  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  219  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  220  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.09918490797281265
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  222  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  223  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  224  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  225  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  227  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  228  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  229  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  230  	Training Loss: 0.09918490797281265
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.09918492287397385
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  232  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  233  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  234  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  235  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  237  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  238  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  239  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  240  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  242  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  243  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:   49%|████▊     | 243/500 [07:23<08:14,  1.92s/it] 49%|████▉     | 245/500 [07:30<09:55,  2.34s/it] 49%|████▉     | 247/500 [07:30<06:59,  1.66s/it] 50%|████▉     | 249/500 [07:30<04:56,  1.18s/it] 50%|████▉     | 249/500 [07:40<04:56,  1.18s/it] 50%|█████     | 251/500 [07:43<11:28,  2.76s/it] 51%|█████     | 253/500 [07:43<08:03,  1.96s/it] 51%|█████     | 255/500 [07:50<09:42,  2.38s/it] 51%|█████▏    | 257/500 [07:50<06:49,  1.68s/it] 52%|█████▏    | 259/500 [07:50<04:48,  1.20s/it] 52%|█████▏    | 259/500 [08:00<04:48,  1.20s/it] 52%|█████▏    | 261/500 [08:03<11:01,  2.77s/it] 53%|█████▎    | 263/500 [08:03<07:43,  1.96s/it] 53%|█████▎    | 265/500 [08:09<09:08,  2.33s/it] 53%|█████▎    | 267/500 [08:10<06:25,  1.66s/it] 54%|█████▍    | 269/500 [08:10<04:32,  1.18s/it] 54%|█████▍    | 269/500 [08:20<04:32,  1.18s/it] 54%|█████▍    | 271/500 [08:22<10:21,  2.71s/it] 55%|█████▍    | 273/500 [08:22<07:16,  1.92s/it] 55%|█████▌    | 275/500 [08:29<08:37,  2.30s/it] 55%|█████▌    | 277/500 [08:29<06:03,  1.63s/it] 56%|█████▌    | 279/500 [08:29<04:16,  1.16s/it] 56%|█████▌    | 279/500 [08:40<04:16,  1.16s/it] 56%|█████▌    | 281/500 [08:42<09:48,  2.69s/it] 57%|█████▋    | 283/500 [08:42<06:52,  1.90s/it] 57%|█████▋    | 285/500 [08:48<08:12,  2.29s/it] 57%|█████▋    | 287/500 [08:48<05:45,  1.62s/it] 58%|█████▊    | 289/500 [08:48<04:03,  1.16s/it] 58%|█████▊    | 289/500 [09:00<04:03,  1.16s/it] 58%|█████▊    | 291/500 [09:01<09:17,  2.67s/it] 59%|█████▊    | 293/500 [09:01<06:30,  1.89s/it] 59%|█████▉    | 295/500 [09:07<07:44,  2.26s/it] 59%|█████▉    | 297/500 [09:07<05:26,  1.61s/it] 60%|█████▉    | 299/500 [09:07<03:50,  1.14s/it] 60%|██████    | 301/500 [09:20<08:50,  2.66s/it]0.13047148287296295
Epoch:  244  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  245  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  247  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  248  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  249  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  250  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  252  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  253  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  254  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  255  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  257  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  258  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  259  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  260  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.09918490797281265
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  262  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  263  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  264  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  265  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  267  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  268  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  269  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  270  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  272  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  273  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  274  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  275  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  277  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  278  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  279  	Training Loss: 0.09918490797281265
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  280  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
Epoch:  282  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  283  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  284  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  285  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
Epoch:  287  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  288  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  289  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  290  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  292  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  293  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  294  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  295  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  297  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  298  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  299  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  300  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  302  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
 61%|██████    | 303/500 [09:20<06:11,  1.89s/it] 61%|██████    | 305/500 [09:26<07:22,  2.27s/it] 61%|██████▏   | 307/500 [09:27<05:10,  1.61s/it] 62%|██████▏   | 309/500 [09:27<03:38,  1.15s/it] 62%|██████▏   | 311/500 [09:39<08:26,  2.68s/it] 63%|██████▎   | 313/500 [09:39<05:54,  1.90s/it] 63%|██████▎   | 315/500 [09:46<06:58,  2.26s/it] 63%|██████▎   | 317/500 [09:46<04:53,  1.60s/it] 64%|██████▍   | 319/500 [09:46<03:26,  1.14s/it] 64%|██████▍   | 321/500 [09:58<07:56,  2.66s/it] 65%|██████▍   | 323/500 [09:58<05:33,  1.88s/it] 65%|██████▌   | 325/500 [10:05<06:33,  2.25s/it] 65%|██████▌   | 327/500 [10:05<04:35,  1.60s/it] 66%|██████▌   | 329/500 [10:05<03:14,  1.14s/it] 66%|██████▌   | 331/500 [10:17<07:30,  2.67s/it] 67%|██████▋   | 333/500 [10:17<05:15,  1.89s/it] 67%|██████▋   | 335/500 [10:24<06:16,  2.28s/it] 67%|██████▋   | 337/500 [10:24<04:23,  1.62s/it] 68%|██████▊   | 339/500 [10:24<03:05,  1.15s/it] 68%|██████▊   | 341/500 [10:37<07:08,  2.69s/it] 69%|██████▊   | 343/500 [10:37<04:59,  1.91s/it] 69%|██████▉   | 345/500 [10:43<05:52,  2.27s/it] 69%|██████▉   | 347/500 [10:43<04:06,  1.61s/it] 70%|██████▉   | 349/500 [10:43<02:53,  1.15s/it] 70%|███████   | 351/500 [10:56<06:38,  2.68s/it] 71%|███████   | 353/500 [10:56<04:38,  1.90s/it] 71%|███████   | 355/500 [11:02<05:29,  2.27s/it] 71%|███████▏  | 357/500 [11:02<03:50,  1.61s/it] 72%|███████▏  | 359/500 [11:03<02:41,  1.15s/it] 72%|███████▏  | 361/500 [11:15<06:10,  2.67s/it]Epoch:  303  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  304  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  305  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  307  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  308  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
Epoch:  309  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  310  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  312  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  313  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  314  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047148287296295
Epoch:  315  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.09918490797281265
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  317  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  318  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  319  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  320  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  322  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  323  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  324  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  325  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  327  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  328  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  329  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  330  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  332  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  333  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  334  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  335  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  337  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  338  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  339  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  340  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  342  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  343  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  344  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  345  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  347  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  348  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  349  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  350  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  352  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
Epoch:  353  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  354  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  355  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  357  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  358  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  359  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  360  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
 73%|███████▎  | 363/500 [11:15<04:18,  1.89s/it] 73%|███████▎  | 365/500 [11:21<05:06,  2.27s/it] 73%|███████▎  | 367/500 [11:22<03:33,  1.61s/it] 74%|███████▍  | 369/500 [11:22<02:30,  1.15s/it] 74%|███████▍  | 371/500 [11:34<05:43,  2.66s/it] 75%|███████▍  | 373/500 [11:34<03:59,  1.88s/it] 75%|███████▌  | 375/500 [11:41<04:43,  2.26s/it] 75%|███████▌  | 377/500 [11:41<03:17,  1.61s/it] 76%|███████▌  | 379/500 [11:41<02:18,  1.14s/it] 76%|███████▌  | 381/500 [11:53<05:16,  2.66s/it] 77%|███████▋  | 383/500 [11:53<03:40,  1.88s/it] 77%|███████▋  | 385/500 [12:00<04:19,  2.26s/it] 77%|███████▋  | 387/500 [12:00<03:01,  1.60s/it] 78%|███████▊  | 389/500 [12:00<02:06,  1.14s/it] 78%|███████▊  | 389/500 [12:10<02:06,  1.14s/it] 78%|███████▊  | 391/500 [12:12<04:52,  2.69s/it] 79%|███████▊  | 393/500 [12:13<03:23,  1.90s/it] 79%|███████▉  | 395/500 [12:19<04:00,  2.29s/it] 79%|███████▉  | 397/500 [12:19<02:47,  1.63s/it] 80%|███████▉  | 399/500 [12:19<01:56,  1.16s/it] 80%|███████▉  | 399/500 [12:30<01:56,  1.16s/it] 80%|████████  | 401/500 [12:32<04:29,  2.73s/it] 81%|████████  | 403/500 [12:32<03:07,  1.93s/it] 81%|████████  | 405/500 [12:39<03:39,  2.31s/it] 81%|████████▏ | 407/500 [12:39<02:32,  1.64s/it] 82%|████████▏ | 409/500 [12:39<01:45,  1.16s/it] 82%|████████▏ | 409/500 [12:50<01:45,  1.16s/it] 82%|████████▏ | 411/500 [12:51<03:59,  2.69s/it] 83%|████████▎ | 413/500 [12:51<02:45,  1.90s/it] 83%|████████▎ | 415/500 [12:58<03:13,  2.28s/it] 83%|████████▎ | 417/500 [12:58<02:14,  1.62s/it] 84%|████████▍ | 419/500 [12:58<01:33,  1.15s/it]Epoch:  362  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  363  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  364  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  365  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  367  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  368  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  369  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  370  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  372  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  373  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047148287296295
Epoch:  374  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  375  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  377  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  378  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  379  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  380  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  382  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  383  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  384  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  385  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  387  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  388  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  389  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  390  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  392  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  393  	Training Loss: 0.09918492287397385
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  394  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  395  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  397  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  398  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  399  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  400  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  402  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  403  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  404  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  405  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  407  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  408  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  409  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  410  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  412  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  413  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  414  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  415  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  417  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  418  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  419  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  420  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
 84%|████████▍ | 419/500 [13:10<01:33,  1.15s/it] 84%|████████▍ | 421/500 [13:11<03:31,  2.68s/it] 85%|████████▍ | 423/500 [13:11<02:26,  1.90s/it] 85%|████████▌ | 425/500 [13:17<02:50,  2.27s/it] 85%|████████▌ | 427/500 [13:17<01:57,  1.61s/it] 86%|████████▌ | 429/500 [13:17<01:21,  1.15s/it] 86%|████████▌ | 431/500 [13:30<03:04,  2.68s/it] 87%|████████▋ | 433/500 [13:30<02:07,  1.90s/it] 87%|████████▋ | 435/500 [13:36<02:27,  2.27s/it] 87%|████████▋ | 437/500 [13:36<01:41,  1.61s/it] 88%|████████▊ | 439/500 [13:36<01:10,  1.15s/it] 88%|████████▊ | 441/500 [13:49<02:37,  2.67s/it] 89%|████████▊ | 443/500 [13:49<01:47,  1.89s/it] 89%|████████▉ | 445/500 [13:55<02:05,  2.28s/it] 89%|████████▉ | 447/500 [13:56<01:25,  1.62s/it] 90%|████████▉ | 449/500 [13:56<00:58,  1.15s/it] 90%|█████████ | 451/500 [14:08<02:10,  2.66s/it] 91%|█████████ | 453/500 [14:08<01:28,  1.88s/it] 91%|█████████ | 455/500 [14:14<01:41,  2.25s/it] 91%|█████████▏| 457/500 [14:15<01:08,  1.60s/it] 92%|█████████▏| 459/500 [14:15<00:46,  1.14s/it] 92%|█████████▏| 461/500 [14:27<01:43,  2.66s/it] 93%|█████████▎| 463/500 [14:27<01:09,  1.88s/it] 93%|█████████▎| 465/500 [14:34<01:19,  2.27s/it] 93%|█████████▎| 467/500 [14:34<00:53,  1.61s/it] 94%|█████████▍| 469/500 [14:34<00:35,  1.14s/it] 94%|█████████▍| 471/500 [14:46<01:17,  2.68s/it] 95%|█████████▍| 473/500 [14:46<00:51,  1.89s/it] 95%|█████████▌| 475/500 [14:53<00:56,  2.27s/it] 95%|█████████▌| 477/500 [14:53<00:36,  1.61s/it] 96%|█████████▌| 479/500 [14:53<00:24,  1.14s/it]Epoch:  421  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  422  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  423  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  424  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  425  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  427  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  428  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  429  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  430  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  432  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  433  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  434  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  435  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  437  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  438  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  439  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  440  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
Epoch:  442  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  443  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  444  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  445  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  447  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  448  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  449  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  450  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  452  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  453  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  454  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  455  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  457  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  458  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  459  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  460  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  462  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  463  	Training Loss: 0.09918490797281265
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  464  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  465  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  467  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  468  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  469  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  470  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  472  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  473  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  474  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  475  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  477  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
Epoch:  478  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  479  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  480  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
 96%|█████████▌| 481/500 [15:05<00:50,  2.66s/it] 97%|█████████▋| 483/500 [15:06<00:32,  1.88s/it] 97%|█████████▋| 485/500 [15:12<00:33,  2.26s/it] 97%|█████████▋| 487/500 [15:12<00:20,  1.60s/it] 98%|█████████▊| 489/500 [15:12<00:12,  1.14s/it] 98%|█████████▊| 491/500 [15:24<00:23,  2.65s/it] 99%|█████████▊| 493/500 [15:25<00:13,  1.88s/it] 99%|█████████▉| 495/500 [15:31<00:11,  2.26s/it] 99%|█████████▉| 497/500 [15:31<00:04,  1.60s/it]100%|█████████▉| 499/500 [15:31<00:01,  1.14s/it]100%|██████████| 500/500 [15:37<00:00,  1.88s/it]
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  482  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  483  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  484  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  485  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  487  	Training Loss: 0.09918490797281265
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  488  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  489  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  490  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  492  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  493  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  494  	Training Loss: 0.09918491542339325
Test Loss:  0.1350622922182083
Valid Loss:  0.13047149777412415
Epoch:  495  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  497  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  498  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047148287296295
Epoch:  499  	Training Loss: 0.09918490797281265
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
Epoch:  500  	Training Loss: 0.09918491542339325
Test Loss:  0.13506227731704712
Valid Loss:  0.13047149777412415
**************************************************learning rate decay**************************************************
seed is  4
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:33,  6.20s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:46,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:20<10:00,  1.25s/it]  5%|▍         | 23/500 [00:20<07:07,  1.12it/s]  5%|▌         | 25/500 [00:20<05:05,  1.55it/s]  5%|▌         | 27/500 [00:20<03:41,  2.13it/s]  6%|▌         | 29/500 [00:20<02:43,  2.88it/s]  6%|▌         | 31/500 [00:27<09:16,  1.19s/it]  7%|▋         | 33/500 [00:27<06:37,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:33<09:01,  1.18s/it]  9%|▊         | 43/500 [00:34<06:27,  1.18it/s]  9%|▉         | 45/500 [00:34<04:38,  1.63it/s]  9%|▉         | 47/500 [00:34<03:23,  2.23it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:50,  1.18s/it] 11%|█         | 53/500 [00:40<06:18,  1.18it/s] 11%|█         | 55/500 [00:40<04:32,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:26,  3.00it/s] 12%|█▏        | 61/500 [00:47<08:36,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.22it/s] 14%|█▍        | 69/500 [00:48<02:24,  2.98it/s] 14%|█▍        | 71/500 [01:00<15:17,  2.14s/it]Epoch:  1  	Training Loss: 0.07232363522052765
Test Loss:  11.277386665344238
Valid Loss:  11.079984664916992
Epoch:  2  	Training Loss: 10.812837600708008
Test Loss:  0.1097789853811264
Valid Loss:  0.10580219328403473
Epoch:  3  	Training Loss: 0.07936006784439087
Test Loss:  0.10965003073215485
Valid Loss:  0.10567990690469742
Epoch:  4  	Training Loss: 0.07926644384860992
Test Loss:  0.10952128469944
Valid Loss:  0.10555779188871384
Epoch:  5  	Training Loss: 0.07917296886444092
Test Loss:  0.10939273983240128
Valid Loss:  0.10543588548898697
Epoch:  6  	Training Loss: 0.07907964289188385
Test Loss:  0.10926436632871628
Valid Loss:  0.10531415790319443
Epoch:  7  	Training Loss: 0.07898646593093872
Test Loss:  0.10913620889186859
Valid Loss:  0.10519260168075562
Epoch:  8  	Training Loss: 0.07889346033334732
Test Loss:  0.10900823771953583
Valid Loss:  0.10507124662399292
Epoch:  9  	Training Loss: 0.07880059629678726
Test Loss:  0.10888046026229858
Valid Loss:  0.10495005548000336
Epoch:  10  	Training Loss: 0.07870788872241974
Test Loss:  0.10875286906957626
Valid Loss:  0.10482907295227051
Epoch:  11  	Training Loss: 0.07861533761024475
Test Loss:  0.10862546414136887
Valid Loss:  0.10470825433731079
Epoch:  12  	Training Loss: 0.0785229280591011
Test Loss:  0.10850806534290314
Valid Loss:  0.10459600389003754
Epoch:  13  	Training Loss: 0.07843771576881409
Test Loss:  0.10839081555604935
Valid Loss:  0.10448387265205383
Epoch:  14  	Training Loss: 0.07835263013839722
Test Loss:  0.1082737147808075
Valid Loss:  0.10437190532684326
Epoch:  15  	Training Loss: 0.0782676562666893
Test Loss:  0.10815674811601639
Valid Loss:  0.10426006466150284
Epoch:  16  	Training Loss: 0.07818280160427094
Test Loss:  0.10803992301225662
Valid Loss:  0.10414835810661316
Epoch:  17  	Training Loss: 0.07809804379940033
Test Loss:  0.1079232394695282
Valid Loss:  0.10403679311275482
Epoch:  18  	Training Loss: 0.07801340520381927
Test Loss:  0.10780671238899231
Valid Loss:  0.10392539203166962
Epoch:  19  	Training Loss: 0.07792888581752777
Test Loss:  0.1076926589012146
Valid Loss:  0.10381846129894257
Epoch:  20  	Training Loss: 0.07784667611122131
Test Loss:  0.10761931538581848
Valid Loss:  0.10376638919115067
Epoch:  21  	Training Loss: 0.07779692113399506
Test Loss:  0.10758176445960999
Valid Loss:  0.1037481427192688
Epoch:  22  	Training Loss: 0.07777196168899536
Test Loss:  0.10756280273199081
Valid Loss:  0.1037384420633316
Epoch:  23  	Training Loss: 0.0777568370103836
Test Loss:  0.10755312442779541
Valid Loss:  0.1037321537733078
Epoch:  24  	Training Loss: 0.07774636149406433
Test Loss:  0.10754840821027756
Valid Loss:  0.10372893512248993
Epoch:  25  	Training Loss: 0.07774199545383453
Test Loss:  0.107545405626297
Valid Loss:  0.10372623801231384
Epoch:  26  	Training Loss: 0.0777386948466301
Test Loss:  0.10754301398992538
Valid Loss:  0.10372433811426163
Epoch:  27  	Training Loss: 0.07773639261722565
Test Loss:  0.10754126310348511
Valid Loss:  0.10372304916381836
Epoch:  28  	Training Loss: 0.07773490250110626
Test Loss:  0.1075398176908493
Valid Loss:  0.10372192412614822
Epoch:  29  	Training Loss: 0.07773365080356598
Test Loss:  0.10753865540027618
Valid Loss:  0.10372108221054077
Epoch:  30  	Training Loss: 0.07773276418447495
Test Loss:  0.10753758251667023
Valid Loss:  0.10372041165828705
Epoch:  31  	Training Loss: 0.07773204147815704
Test Loss:  0.10753674805164337
Valid Loss:  0.10372000932693481
Epoch:  32  	Training Loss: 0.07773150503635406
Test Loss:  0.10753613710403442
Valid Loss:  0.10371974110603333
Epoch:  33  	Training Loss: 0.07773108780384064
Test Loss:  0.10753560811281204
Valid Loss:  0.10371953994035721
Epoch:  34  	Training Loss: 0.07773074507713318
Test Loss:  0.10753525793552399
Valid Loss:  0.10371939837932587
Epoch:  35  	Training Loss: 0.07773053646087646
Test Loss:  0.10753492265939713
Valid Loss:  0.10371924191713333
Epoch:  36  	Training Loss: 0.07773034274578094
Test Loss:  0.10753469169139862
Valid Loss:  0.10371913015842438
Epoch:  37  	Training Loss: 0.0777302011847496
Test Loss:  0.10753446072340012
Valid Loss:  0.10371900349855423
Epoch:  38  	Training Loss: 0.07773005217313766
Test Loss:  0.1075342521071434
Valid Loss:  0.10371888428926468
Epoch:  39  	Training Loss: 0.07772991061210632
Test Loss:  0.10753406584262848
Valid Loss:  0.10371876507997513
Epoch:  40  	Training Loss: 0.07772976905107498
Test Loss:  0.10753393173217773
Valid Loss:  0.10371866077184677
Epoch:  41  	Training Loss: 0.07772966474294662
Test Loss:  0.10753383487462997
Valid Loss:  0.10371857136487961
Epoch:  42  	Training Loss: 0.07772959768772125
Test Loss:  0.10753372311592102
Valid Loss:  0.10371850430965424
Epoch:  43  	Training Loss: 0.07772952318191528
Test Loss:  0.10753363370895386
Valid Loss:  0.10371844470500946
Epoch:  44  	Training Loss: 0.07772946357727051
Test Loss:  0.1075335443019867
Valid Loss:  0.10371839255094528
Epoch:  45  	Training Loss: 0.07772940397262573
Test Loss:  0.10753345489501953
Valid Loss:  0.1037183403968811
Epoch:  46  	Training Loss: 0.07772934436798096
Test Loss:  0.10753335803747177
Valid Loss:  0.10371829569339752
Epoch:  47  	Training Loss: 0.07772929221391678
Test Loss:  0.1075332909822464
Valid Loss:  0.10371824353933334
Epoch:  48  	Training Loss: 0.0777292400598526
Test Loss:  0.10753321647644043
Valid Loss:  0.10371819138526917
Epoch:  49  	Training Loss: 0.07772919535636902
Test Loss:  0.10753318667411804
Valid Loss:  0.10371814668178558
Epoch:  50  	Training Loss: 0.07772915810346603
Test Loss:  0.10753312706947327
Valid Loss:  0.1037181168794632
Epoch:  51  	Training Loss: 0.07772913575172424
Test Loss:  0.10753309726715088
Valid Loss:  0.10371807962656021
Epoch:  52  	Training Loss: 0.07772912085056305
Test Loss:  0.1075330525636673
Valid Loss:  0.10371806472539902
Epoch:  53  	Training Loss: 0.07772909104824066
Test Loss:  0.10753302276134491
Valid Loss:  0.10371802747249603
Epoch:  54  	Training Loss: 0.07772907614707947
Test Loss:  0.10753298550844193
Valid Loss:  0.10371800512075424
Epoch:  55  	Training Loss: 0.07772904634475708
Test Loss:  0.10753294825553894
Valid Loss:  0.10371798276901245
Epoch:  56  	Training Loss: 0.07772903144359589
Test Loss:  0.10753291845321655
Valid Loss:  0.10371795296669006
Epoch:  57  	Training Loss: 0.07772901654243469
Test Loss:  0.10753288865089417
Valid Loss:  0.10371793061494827
Epoch:  58  	Training Loss: 0.0777290016412735
Test Loss:  0.10753287374973297
Valid Loss:  0.10371792316436768
Epoch:  59  	Training Loss: 0.0777289867401123
Test Loss:  0.10753285884857178
Valid Loss:  0.10371790081262589
Epoch:  60  	Training Loss: 0.0777289867401123
Test Loss:  0.10753285139799118
Valid Loss:  0.10371789336204529
Epoch:  61  	Training Loss: 0.07772897183895111
Test Loss:  0.10753284394741058
Valid Loss:  0.1037178784608841
Epoch:  62  	Training Loss: 0.07772896438837051
Test Loss:  0.10753282904624939
Valid Loss:  0.1037178784608841
Epoch:  63  	Training Loss: 0.07772895693778992
Test Loss:  0.10753282904624939
Valid Loss:  0.1037178635597229
Epoch:  64  	Training Loss: 0.07772894203662872
Test Loss:  0.1075328141450882
Valid Loss:  0.1037178635597229
Epoch:  65  	Training Loss: 0.07772894203662872
Test Loss:  0.1075328141450882
Valid Loss:  0.1037178561091423
Epoch:  66  	Training Loss: 0.07772893458604813
Test Loss:  0.1075328141450882
Valid Loss:  0.1037178486585617
Epoch:  67  	Training Loss: 0.07772892713546753
Test Loss:  0.1075328066945076
Valid Loss:  0.10371784120798111
Epoch:  68  	Training Loss: 0.07772891968488693
Test Loss:  0.107532799243927
Valid Loss:  0.10371784120798111
Epoch:  69  	Training Loss: 0.07772891223430634
Test Loss:  0.107532799243927
Valid Loss:  0.10371784120798111
Epoch:  70  	Training Loss: 0.07772891223430634
Test Loss:  0.107532799243927
Valid Loss:  0.10371783375740051
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.07772890478372574
Test Loss:  0.107532799243927
Valid Loss:  0.10371783375740051
Epoch:  72  	Training Loss: 0.07772889733314514
Test Loss:  0.107532799243927
Valid Loss:   15%|█▍        | 73/500 [01:00<10:48,  1.52s/it] 15%|█▌        | 75/500 [01:01<07:39,  1.08s/it] 15%|█▌        | 77/500 [01:01<05:28,  1.29it/s] 16%|█▌        | 79/500 [01:01<03:57,  1.78it/s] 16%|█▌        | 81/500 [01:13<15:47,  2.26s/it] 17%|█▋        | 83/500 [01:13<11:08,  1.60s/it] 17%|█▋        | 85/500 [01:20<14:20,  2.07s/it] 17%|█▋        | 87/500 [01:20<10:07,  1.47s/it] 18%|█▊        | 89/500 [01:20<07:11,  1.05s/it] 18%|█▊        | 91/500 [01:33<17:53,  2.62s/it] 19%|█▊        | 93/500 [01:33<12:36,  1.86s/it] 19%|█▉        | 95/500 [01:39<15:09,  2.25s/it] 19%|█▉        | 97/500 [01:39<10:42,  1.59s/it] 20%|█▉        | 99/500 [01:39<07:35,  1.13s/it] 20%|██        | 101/500 [01:52<17:43,  2.66s/it] 21%|██        | 103/500 [01:52<12:29,  1.89s/it] 21%|██        | 105/500 [01:58<14:57,  2.27s/it] 21%|██▏       | 107/500 [01:58<10:33,  1.61s/it] 22%|██▏       | 109/500 [01:59<07:28,  1.15s/it] 22%|██▏       | 111/500 [02:11<17:25,  2.69s/it] 23%|██▎       | 113/500 [02:11<12:16,  1.90s/it] 23%|██▎       | 115/500 [02:18<14:40,  2.29s/it] 23%|██▎       | 117/500 [02:18<10:21,  1.62s/it] 24%|██▍       | 119/500 [02:18<07:21,  1.16s/it] 24%|██▍       | 121/500 [02:30<17:02,  2.70s/it] 25%|██▍       | 123/500 [02:31<12:00,  1.91s/it] 25%|██▌       | 125/500 [02:37<14:12,  2.27s/it] 25%|██▌       | 127/500 [02:37<10:01,  1.61s/it] 26%|██▌       | 129/500 [02:37<07:05,  1.15s/it] 26%|██▌       | 131/500 [02:50<16:21,  2.66s/it]0.10371783375740051
Epoch:  73  	Training Loss: 0.07772888988256454
Test Loss:  0.1075327917933464
Valid Loss:  0.10371783375740051
Epoch:  74  	Training Loss: 0.07772888988256454
Test Loss:  0.1075327917933464
Valid Loss:  0.10371783375740051
Epoch:  75  	Training Loss: 0.07772888988256454
Test Loss:  0.10753278434276581
Valid Loss:  0.10371783375740051
Epoch:  76  	Training Loss: 0.07772888988256454
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  77  	Training Loss: 0.07772888243198395
Test Loss:  0.10753278434276581
Valid Loss:  0.10371782630681992
Epoch:  78  	Training Loss: 0.07772888243198395
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  79  	Training Loss: 0.07772887498140335
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  80  	Training Loss: 0.07772887498140335
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.07772886753082275
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  82  	Training Loss: 0.07772886753082275
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  83  	Training Loss: 0.07772886753082275
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  84  	Training Loss: 0.07772886753082275
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  85  	Training Loss: 0.07772886753082275
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.07772886753082275
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  87  	Training Loss: 0.07772886753082275
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  88  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  89  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  90  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  92  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  93  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  94  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  95  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  97  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  98  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  99  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  100  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  102  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  103  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  104  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  105  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  107  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  108  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  109  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  110  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  112  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  113  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  114  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  115  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  117  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  118  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  119  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  120  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  122  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  123  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  124  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  125  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  127  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  128  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  129  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  130  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  132  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
 27%|██▋       | 133/500 [02:50<11:31,  1.88s/it] 27%|██▋       | 135/500 [02:56<13:42,  2.25s/it] 27%|██▋       | 137/500 [02:56<09:39,  1.60s/it] 28%|██▊       | 139/500 [02:56<06:50,  1.14s/it] 28%|██▊       | 139/500 [03:07<06:50,  1.14s/it] 28%|██▊       | 141/500 [03:09<15:57,  2.67s/it] 29%|██▊       | 143/500 [03:09<11:14,  1.89s/it] 29%|██▉       | 145/500 [03:15<13:22,  2.26s/it] 29%|██▉       | 147/500 [03:15<09:26,  1.60s/it] 30%|██▉       | 149/500 [03:15<06:41,  1.14s/it] 30%|██▉       | 149/500 [03:27<06:41,  1.14s/it] 30%|███       | 151/500 [03:28<15:27,  2.66s/it] 31%|███       | 153/500 [03:28<10:52,  1.88s/it] 31%|███       | 155/500 [03:34<13:00,  2.26s/it] 31%|███▏      | 157/500 [03:34<09:10,  1.60s/it] 32%|███▏      | 159/500 [03:34<06:29,  1.14s/it] 32%|███▏      | 159/500 [03:47<06:29,  1.14s/it] 32%|███▏      | 161/500 [03:47<15:05,  2.67s/it] 33%|███▎      | 163/500 [03:47<10:37,  1.89s/it] 33%|███▎      | 165/500 [03:53<12:40,  2.27s/it] 33%|███▎      | 167/500 [03:53<08:56,  1.61s/it] 34%|███▍      | 169/500 [03:54<06:19,  1.15s/it] 34%|███▍      | 171/500 [04:06<14:33,  2.65s/it] 35%|███▍      | 173/500 [04:06<10:14,  1.88s/it] 35%|███▌      | 175/500 [04:12<12:14,  2.26s/it] 35%|███▌      | 177/500 [04:13<08:38,  1.60s/it] 36%|███▌      | 179/500 [04:13<06:06,  1.14s/it] 36%|███▌      | 181/500 [04:25<14:12,  2.67s/it] 37%|███▋      | 183/500 [04:25<10:00,  1.89s/it] 37%|███▋      | 185/500 [04:31<11:50,  2.26s/it] 37%|███▋      | 187/500 [04:32<08:20,  1.60s/it] 38%|███▊      | 189/500 [04:32<05:54,  1.14s/it] 38%|███▊      | 191/500 [04:44<13:52,  2.69s/it]Epoch:  133  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  134  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  135  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  137  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  138  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  139  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  140  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  142  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  143  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  144  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  145  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  147  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  148  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  149  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  150  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  152  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781140565872
Epoch:  153  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  154  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  155  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  157  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  158  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  159  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  160  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  162  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  163  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  164  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  165  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  167  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  168  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  169  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  170  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  172  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  173  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  174  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  175  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  177  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  178  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  179  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  180  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  182  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  183  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  184  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  185  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.07772886008024216
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  187  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  188  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  189  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  190  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
 39%|███▊      | 193/500 [04:45<09:45,  1.91s/it] 39%|███▉      | 195/500 [04:51<11:35,  2.28s/it] 39%|███▉      | 197/500 [04:51<08:10,  1.62s/it] 40%|███▉      | 199/500 [04:51<05:46,  1.15s/it] 40%|████      | 201/500 [05:04<13:20,  2.68s/it] 41%|████      | 203/500 [05:04<09:22,  1.90s/it] 41%|████      | 205/500 [05:10<11:08,  2.27s/it] 41%|████▏     | 207/500 [05:10<07:50,  1.61s/it] 42%|████▏     | 209/500 [05:10<05:32,  1.14s/it] 42%|████▏     | 211/500 [05:23<12:51,  2.67s/it] 43%|████▎     | 213/500 [05:23<09:02,  1.89s/it] 43%|████▎     | 215/500 [05:29<10:44,  2.26s/it] 43%|████▎     | 217/500 [05:29<07:33,  1.60s/it] 44%|████▍     | 219/500 [05:29<05:21,  1.14s/it] 44%|████▍     | 221/500 [05:42<12:25,  2.67s/it] 45%|████▍     | 223/500 [05:42<08:43,  1.89s/it] 45%|████▌     | 225/500 [05:48<10:27,  2.28s/it] 45%|████▌     | 227/500 [05:49<07:21,  1.62s/it] 46%|████▌     | 229/500 [05:49<05:12,  1.15s/it] 46%|████▌     | 231/500 [06:01<12:00,  2.68s/it] 47%|████▋     | 233/500 [06:01<08:26,  1.90s/it] 47%|████▋     | 235/500 [06:08<10:07,  2.29s/it] 47%|████▋     | 237/500 [06:08<07:07,  1.63s/it] 48%|████▊     | 239/500 [06:08<05:02,  1.16s/it] 48%|████▊     | 241/500 [06:21<11:42,  2.71s/it] 49%|████▊     | 243/500 [06:21<08:13,  1.92s/it] 49%|████▉     | 245/500 [06:27<09:42,  2.28s/it] 49%|████▉     | 247/500 [06:27<06:50,  1.62s/it] 50%|████▉     | 249/500 [06:27<04:49,  1.15s/it]Epoch:  192  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  193  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  194  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  195  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  197  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  198  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  199  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  200  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  202  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  203  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  204  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  205  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  207  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  208  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  209  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  210  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  212  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  213  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  214  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  215  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  217  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  218  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  219  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  220  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  222  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  223  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  224  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  225  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  227  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  228  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  229  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  230  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  232  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  233  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  234  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  235  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  237  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  238  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  239  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  240  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  242  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  243  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  244  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781140565872
Epoch:  245  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  247  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  248  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  249  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  250  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
 50%|█████     | 251/500 [06:40<11:07,  2.68s/it] 51%|█████     | 253/500 [06:40<07:49,  1.90s/it] 51%|█████     | 255/500 [06:46<09:17,  2.28s/it] 51%|█████▏    | 257/500 [06:46<06:32,  1.62s/it] 52%|█████▏    | 259/500 [06:47<04:37,  1.15s/it] 52%|█████▏    | 259/500 [06:57<04:37,  1.15s/it] 52%|█████▏    | 261/500 [06:59<10:39,  2.68s/it] 53%|█████▎    | 263/500 [06:59<07:29,  1.90s/it] 53%|█████▎    | 265/500 [07:06<08:55,  2.28s/it] 53%|█████▎    | 267/500 [07:06<06:17,  1.62s/it] 54%|█████▍    | 269/500 [07:06<04:26,  1.15s/it] 54%|█████▍    | 269/500 [07:17<04:26,  1.15s/it] 54%|█████▍    | 271/500 [07:18<10:10,  2.67s/it] 55%|█████▍    | 273/500 [07:18<07:08,  1.89s/it] 55%|█████▌    | 275/500 [07:25<08:31,  2.27s/it] 55%|█████▌    | 277/500 [07:25<05:59,  1.61s/it] 56%|█████▌    | 279/500 [07:25<04:14,  1.15s/it] 56%|█████▌    | 279/500 [07:37<04:14,  1.15s/it] 56%|█████▌    | 281/500 [07:38<09:47,  2.68s/it] 57%|█████▋    | 283/500 [07:38<06:52,  1.90s/it] 57%|█████▋    | 285/500 [07:44<08:09,  2.28s/it] 57%|█████▋    | 287/500 [07:44<05:43,  1.61s/it] 58%|█████▊    | 289/500 [07:44<04:02,  1.15s/it] 58%|█████▊    | 289/500 [07:57<04:02,  1.15s/it] 58%|█████▊    | 291/500 [07:57<09:15,  2.66s/it] 59%|█████▊    | 293/500 [07:57<06:29,  1.88s/it] 59%|█████▉    | 295/500 [08:03<07:41,  2.25s/it] 59%|█████▉    | 297/500 [08:03<05:24,  1.60s/it] 60%|█████▉    | 299/500 [08:03<03:48,  1.14s/it] 60%|██████    | 301/500 [08:16<08:48,  2.65s/it] 61%|██████    | 303/500 [08:16<06:10,  1.88s/it] 61%|██████    | 305/500 [08:22<07:20,  2.26s/it] 61%|██████▏   | 307/500 [08:22<05:09,  1.61s/it] 62%|██████▏   | 309/500 [08:22<03:38,  1.14s/it]Epoch:  251  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  252  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  253  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  254  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  255  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  257  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  258  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  259  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  260  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  262  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  263  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  264  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  265  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  267  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  268  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  269  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  270  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  272  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  273  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  274  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  275  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  277  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  278  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  279  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781140565872
Epoch:  280  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  282  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  283  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  284  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  285  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  287  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  288  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  289  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  290  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  292  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  293  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  294  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  295  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  297  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  298  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  299  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  300  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  302  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  303  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  304  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  305  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  307  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  308  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  309  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  310  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
 62%|██████▏   | 311/500 [08:35<08:22,  2.66s/it] 63%|██████▎   | 313/500 [08:35<05:52,  1.88s/it] 63%|██████▎   | 315/500 [08:41<07:02,  2.29s/it] 63%|██████▎   | 317/500 [08:42<04:56,  1.62s/it] 64%|██████▍   | 319/500 [08:42<03:28,  1.15s/it] 64%|██████▍   | 321/500 [08:54<08:03,  2.70s/it] 65%|██████▍   | 323/500 [08:54<05:38,  1.91s/it] 65%|██████▌   | 325/500 [09:01<06:42,  2.30s/it] 65%|██████▌   | 327/500 [09:01<04:42,  1.63s/it] 66%|██████▌   | 329/500 [09:01<03:18,  1.16s/it] 66%|██████▌   | 331/500 [09:14<07:38,  2.71s/it] 67%|██████▋   | 333/500 [09:14<05:20,  1.92s/it] 67%|██████▋   | 335/500 [09:20<06:19,  2.30s/it] 67%|██████▋   | 337/500 [09:20<04:25,  1.63s/it] 68%|██████▊   | 339/500 [09:21<03:06,  1.16s/it] 68%|██████▊   | 341/500 [09:33<07:06,  2.68s/it] 69%|██████▊   | 343/500 [09:33<04:57,  1.90s/it] 69%|██████▉   | 345/500 [09:39<05:51,  2.27s/it] 69%|██████▉   | 347/500 [09:40<04:05,  1.61s/it] 70%|██████▉   | 349/500 [09:40<02:53,  1.15s/it] 70%|███████   | 351/500 [09:52<06:38,  2.67s/it] 71%|███████   | 353/500 [09:52<04:38,  1.89s/it] 71%|███████   | 355/500 [09:59<05:28,  2.26s/it] 71%|███████▏  | 357/500 [09:59<03:49,  1.61s/it] 72%|███████▏  | 359/500 [09:59<02:41,  1.14s/it] 72%|███████▏  | 361/500 [10:11<06:13,  2.68s/it] 73%|███████▎  | 363/500 [10:11<04:20,  1.90s/it] 73%|███████▎  | 365/500 [10:18<05:06,  2.27s/it] 73%|███████▎  | 367/500 [10:18<03:34,  1.61s/it] 74%|███████▍  | 369/500 [10:18<02:30,  1.15s/it]**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  312  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  313  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  314  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  315  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781140565872
Epoch:  317  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  318  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  319  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  320  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  322  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  323  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  324  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  325  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.07772886008024216
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  327  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  328  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  329  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  330  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  332  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  333  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  334  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  335  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  337  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  338  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  339  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  340  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  342  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  343  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  344  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  345  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  347  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  348  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  349  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  350  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  352  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  353  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  354  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781140565872
Epoch:  355  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  357  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  358  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  359  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  360  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  362  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  363  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  364  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371782630681992
Epoch:  365  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  367  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  368  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  369  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
 74%|███████▍  | 371/500 [10:30<05:44,  2.67s/it] 75%|███████▍  | 373/500 [10:31<04:00,  1.89s/it] 75%|███████▌  | 375/500 [10:37<04:43,  2.27s/it] 75%|███████▌  | 377/500 [10:37<03:17,  1.61s/it] 76%|███████▌  | 379/500 [10:37<02:18,  1.15s/it] 76%|███████▌  | 381/500 [10:50<05:16,  2.66s/it] 77%|███████▋  | 383/500 [10:50<03:40,  1.89s/it] 77%|███████▋  | 385/500 [10:56<04:18,  2.25s/it] 77%|███████▋  | 387/500 [10:56<03:00,  1.60s/it] 78%|███████▊  | 389/500 [10:56<02:06,  1.14s/it] 78%|███████▊  | 389/500 [11:07<02:06,  1.14s/it] 78%|███████▊  | 391/500 [11:09<04:49,  2.66s/it] 79%|███████▊  | 393/500 [11:09<03:21,  1.88s/it] 79%|███████▉  | 395/500 [11:15<03:58,  2.27s/it] 79%|███████▉  | 397/500 [11:15<02:45,  1.61s/it] 80%|███████▉  | 399/500 [11:15<01:55,  1.14s/it] 80%|███████▉  | 399/500 [11:27<01:55,  1.14s/it] 80%|████████  | 401/500 [11:28<04:24,  2.67s/it] 81%|████████  | 403/500 [11:28<03:03,  1.89s/it] 81%|████████  | 405/500 [11:34<03:35,  2.26s/it] 81%|████████▏ | 407/500 [11:34<02:29,  1.61s/it] 82%|████████▏ | 409/500 [11:35<01:44,  1.15s/it] 82%|████████▏ | 409/500 [11:47<01:44,  1.15s/it] 82%|████████▏ | 411/500 [11:47<03:58,  2.68s/it] 83%|████████▎ | 413/500 [11:47<02:44,  1.89s/it] 83%|████████▎ | 415/500 [11:54<03:13,  2.28s/it] 83%|████████▎ | 417/500 [11:54<02:14,  1.62s/it] 84%|████████▍ | 419/500 [11:54<01:33,  1.15s/it] 84%|████████▍ | 421/500 [12:06<03:30,  2.66s/it] 85%|████████▍ | 423/500 [12:06<02:24,  1.88s/it] 85%|████████▌ | 425/500 [12:13<02:49,  2.26s/it] 85%|████████▌ | 427/500 [12:13<01:56,  1.60s/it]Epoch:  370  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  372  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  373  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  374  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  375  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.07772886008024216
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  377  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  378  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  379  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  380  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  382  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  383  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  384  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  385  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  387  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  388  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  389  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  390  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  392  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  393  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  394  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  395  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  397  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  398  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  399  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781140565872
Epoch:  400  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  402  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  403  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  404  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781140565872
Epoch:  405  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  407  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  408  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  409  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  410  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  412  	Training Loss: 0.07772886008024216
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  413  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  414  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  415  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  417  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  418  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  419  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  420  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  422  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  423  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  424  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  425  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781140565872
Epoch:  427  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  428  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
 86%|████████▌ | 429/500 [12:13<01:20,  1.14s/it] 86%|████████▌ | 431/500 [12:25<03:03,  2.66s/it] 87%|████████▋ | 433/500 [12:25<02:06,  1.88s/it] 87%|████████▋ | 435/500 [12:32<02:26,  2.25s/it] 87%|████████▋ | 437/500 [12:32<01:40,  1.60s/it] 88%|████████▊ | 439/500 [12:32<01:09,  1.14s/it] 88%|████████▊ | 441/500 [12:44<02:36,  2.66s/it] 89%|████████▊ | 443/500 [12:44<01:47,  1.88s/it] 89%|████████▉ | 445/500 [12:51<02:04,  2.26s/it] 89%|████████▉ | 447/500 [12:51<01:24,  1.60s/it] 90%|████████▉ | 449/500 [12:51<00:58,  1.14s/it] 90%|█████████ | 451/500 [13:03<02:10,  2.66s/it] 91%|█████████ | 453/500 [13:04<01:28,  1.88s/it] 91%|█████████ | 455/500 [13:10<01:41,  2.26s/it] 91%|█████████▏| 457/500 [13:10<01:08,  1.60s/it] 92%|█████████▏| 459/500 [13:10<00:46,  1.14s/it] 92%|█████████▏| 461/500 [13:23<01:44,  2.68s/it] 93%|█████████▎| 463/500 [13:23<01:10,  1.90s/it] 93%|█████████▎| 465/500 [13:29<01:19,  2.27s/it] 93%|█████████▎| 467/500 [13:29<00:53,  1.61s/it] 94%|█████████▍| 469/500 [13:29<00:35,  1.15s/it] 94%|█████████▍| 471/500 [13:42<01:18,  2.69s/it] 95%|█████████▍| 473/500 [13:42<00:51,  1.90s/it] 95%|█████████▌| 475/500 [13:48<00:57,  2.28s/it] 95%|█████████▌| 477/500 [13:49<00:37,  1.62s/it] 96%|█████████▌| 479/500 [13:49<00:24,  1.15s/it] 96%|█████████▌| 481/500 [14:01<00:50,  2.67s/it] 97%|█████████▋| 483/500 [14:01<00:32,  1.89s/it] 97%|█████████▋| 485/500 [14:08<00:34,  2.28s/it] 97%|█████████▋| 487/500 [14:08<00:21,  1.62s/it]Epoch:  429  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  430  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  432  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  433  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  434  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  435  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  437  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  438  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  439  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  440  	Training Loss: 0.07772886008024216
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  442  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  443  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  444  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  445  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  447  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  448  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  449  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  450  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781140565872
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  452  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  453  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  454  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  455  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  457  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  458  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  459  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  460  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  462  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  463  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  464  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  465  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  467  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  468  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  469  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  470  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  472  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  473  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  474  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  475  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  477  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  478  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  479  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  480  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  482  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  483  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  484  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  485  	Training Loss: 0.07772886008024216
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  487  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
 98%|█████████▊| 489/500 [14:08<00:12,  1.15s/it] 98%|█████████▊| 491/500 [14:20<00:24,  2.69s/it] 99%|█████████▊| 493/500 [14:21<00:13,  1.91s/it] 99%|█████████▉| 495/500 [14:27<00:11,  2.28s/it] 99%|█████████▉| 497/500 [14:27<00:04,  1.62s/it]100%|█████████▉| 499/500 [14:27<00:01,  1.15s/it]100%|██████████| 500/500 [14:33<00:00,  1.75s/it]
Epoch:  488  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  489  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  490  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  492  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  493  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  494  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  495  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.07772886008024216
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  497  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
Epoch:  498  	Training Loss: 0.07772885262966156
Test Loss:  0.10753278434276581
Valid Loss:  0.10371781885623932
Epoch:  499  	Training Loss: 0.07772885262966156
Test Loss:  0.10753277689218521
Valid Loss:  0.10371781885623932
Epoch:  500  	Training Loss: 0.07772885262966156
Test Loss:  0.10753276944160461
Valid Loss:  0.10371781885623932
**************************************************learning rate decay**************************************************
seed is  5
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:25,  6.30s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:06,  1.16it/s]  1%|▏         | 7/500 [00:06<04:18,  1.91it/s]  2%|▏         | 9/500 [00:06<02:52,  2.85it/s]  2%|▏         | 11/500 [00:13<10:58,  1.35s/it]  3%|▎         | 13/500 [00:13<07:28,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.17it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:20<09:31,  1.19s/it]  5%|▍         | 23/500 [00:20<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:26<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:38,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.62it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<09:03,  1.18s/it]  9%|▊         | 43/500 [00:33<06:28,  1.17it/s]  9%|▉         | 45/500 [00:34<04:40,  1.62it/s]  9%|▉         | 47/500 [00:34<03:24,  2.22it/s] 10%|▉         | 49/500 [00:34<02:31,  2.97it/s] 10%|█         | 51/500 [00:40<08:52,  1.19s/it] 11%|█         | 53/500 [00:40<06:21,  1.17it/s] 11%|█         | 55/500 [00:40<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.98it/s] 12%|█▏        | 61/500 [00:47<08:33,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:07,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.23it/s] 14%|█▍        | 69/500 [00:48<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:54<08:26,  1.18s/it]Epoch:  1  	Training Loss: 0.18019041419029236
Test Loss:  0.18977028131484985
Valid Loss:  0.18156415224075317
Epoch:  2  	Training Loss: 0.14177146553993225
Test Loss:  0.15591014921665192
Valid Loss:  0.14991408586502075
Epoch:  3  	Training Loss: 0.11503677070140839
Test Loss:  0.12927624583244324
Valid Loss:  0.12500165402889252
Epoch:  4  	Training Loss: 0.09447894990444183
Test Loss:  0.10810789465904236
Valid Loss:  0.10523451864719391
Epoch:  5  	Training Loss: 0.0785491019487381
Test Loss:  0.09119697660207748
Valid Loss:  0.08946910500526428
Epoch:  6  	Training Loss: 0.06615526974201202
Test Loss:  0.07761865854263306
Valid Loss:  0.07682815939188004
Epoch:  7  	Training Loss: 0.05647539347410202
Test Loss:  0.06666010618209839
Valid Loss:  0.06663753092288971
Epoch:  8  	Training Loss: 0.04888409748673439
Test Loss:  0.057769615203142166
Valid Loss:  0.05837602913379669
Epoch:  9  	Training Loss: 0.042903877794742584
Test Loss:  0.05051803961396217
Valid Loss:  0.05163905769586563
Epoch:  10  	Training Loss: 0.038168806582689285
Test Loss:  0.04457060620188713
Valid Loss:  0.04611143097281456
Epoch:  11  	Training Loss: 0.0343979075551033
Test Loss:  0.039664894342422485
Valid Loss:  0.04154679551720619
Epoch:  12  	Training Loss: 0.03137485682964325
Test Loss:  0.03555706888437271
Valid Loss:  0.037717387080192566
Epoch:  13  	Training Loss: 0.028911050409078598
Test Loss:  0.03212972730398178
Valid Loss:  0.03451280668377876
Epoch:  14  	Training Loss: 0.026905391365289688
Test Loss:  0.029253054410219193
Valid Loss:  0.031812090426683426
Epoch:  15  	Training Loss: 0.025257248431444168
Test Loss:  0.026823602616786957
Valid Loss:  0.02951935864984989
Epoch:  16  	Training Loss: 0.02388881891965866
Test Loss:  0.024758929386734962
Valid Loss:  0.027558203786611557
Epoch:  17  	Training Loss: 0.022739488631486893
Test Loss:  0.022993117570877075
Valid Loss:  0.025867389515042305
Epoch:  18  	Training Loss: 0.021761992946267128
Test Loss:  0.021473143249750137
Valid Loss:  0.024398181587457657
Epoch:  19  	Training Loss: 0.020919959992170334
Test Loss:  0.020155813544988632
Valid Loss:  0.023111773654818535
Epoch:  20  	Training Loss: 0.020185329020023346
Test Loss:  0.01900649629533291
Valid Loss:  0.02197658270597458
Epoch:  21  	Training Loss: 0.019535988569259644
Test Loss:  0.017997432500123978
Valid Loss:  0.020967159420251846
Epoch:  22  	Training Loss: 0.018954619765281677
Test Loss:  0.0171048603951931
Valid Loss:  0.02006128430366516
Epoch:  23  	Training Loss: 0.018426399677991867
Test Loss:  0.016311675310134888
Valid Loss:  0.01924414560198784
Epoch:  24  	Training Loss: 0.017942165955901146
Test Loss:  0.015602242201566696
Valid Loss:  0.01850193552672863
Epoch:  25  	Training Loss: 0.017493687570095062
Test Loss:  0.014963701367378235
Valid Loss:  0.017823312431573868
Epoch:  26  	Training Loss: 0.017074665054678917
Test Loss:  0.014385697431862354
Valid Loss:  0.01719912886619568
Epoch:  27  	Training Loss: 0.01668015867471695
Test Loss:  0.013859700411558151
Valid Loss:  0.016621705144643784
Epoch:  28  	Training Loss: 0.01630626618862152
Test Loss:  0.013378012925386429
Valid Loss:  0.016084808856248856
Epoch:  29  	Training Loss: 0.015950094908475876
Test Loss:  0.012934992089867592
Valid Loss:  0.015583189204335213
Epoch:  30  	Training Loss: 0.015609163790941238
Test Loss:  0.012525582686066628
Valid Loss:  0.015112523920834064
Epoch:  31  	Training Loss: 0.015281574800610542
Test Loss:  0.012145191431045532
Valid Loss:  0.014669228345155716
Epoch:  32  	Training Loss: 0.014965813606977463
Test Loss:  0.01178997103124857
Valid Loss:  0.014249603264033794
Epoch:  33  	Training Loss: 0.014659888111054897
Test Loss:  0.011457651853561401
Valid Loss:  0.013851843774318695
Epoch:  34  	Training Loss: 0.014363523572683334
Test Loss:  0.011145345866680145
Valid Loss:  0.013473494909703732
Epoch:  35  	Training Loss: 0.0140759889036417
Test Loss:  0.01085103489458561
Valid Loss:  0.013112767599523067
Epoch:  36  	Training Loss: 0.013796595856547356
Test Loss:  0.010572667233645916
Valid Loss:  0.012767916545271873
Epoch:  37  	Training Loss: 0.013524828478693962
Test Loss:  0.010308628901839256
Valid Loss:  0.012437565252184868
Epoch:  38  	Training Loss: 0.013260237872600555
Test Loss:  0.010057609528303146
Valid Loss:  0.012120526283979416
Epoch:  39  	Training Loss: 0.013002440333366394
Test Loss:  0.009818319231271744
Valid Loss:  0.01181570440530777
Epoch:  40  	Training Loss: 0.01275111734867096
Test Loss:  0.009589648805558681
Valid Loss:  0.01152222789824009
Epoch:  41  	Training Loss: 0.01250599604099989
Test Loss:  0.009370745159685612
Valid Loss:  0.011239280924201012
Epoch:  42  	Training Loss: 0.012266850098967552
Test Loss:  0.009158875793218613
Valid Loss:  0.010964927263557911
Epoch:  43  	Training Loss: 0.012033265084028244
Test Loss:  0.00895552895963192
Valid Loss:  0.010699955746531487
Epoch:  44  	Training Loss: 0.01180525403469801
Test Loss:  0.008760040625929832
Valid Loss:  0.010443811304867268
Epoch:  45  	Training Loss: 0.01158263348042965
Test Loss:  0.008571673184633255
Valid Loss:  0.010195954702794552
Epoch:  46  	Training Loss: 0.011365259066224098
Test Loss:  0.008390074595808983
Valid Loss:  0.009955942630767822
Epoch:  47  	Training Loss: 0.011152960360050201
Test Loss:  0.008214790374040604
Valid Loss:  0.009723395109176636
Epoch:  48  	Training Loss: 0.010945601388812065
Test Loss:  0.008045423775911331
Valid Loss:  0.00949794426560402
Epoch:  49  	Training Loss: 0.010743049904704094
Test Loss:  0.00788160040974617
Valid Loss:  0.009279222227633
Epoch:  50  	Training Loss: 0.010545186698436737
Test Loss:  0.007722922600805759
Valid Loss:  0.009066931903362274
Epoch:  51  	Training Loss: 0.010351878590881824
Test Loss:  0.0075691803358495235
Valid Loss:  0.008860821835696697
Epoch:  52  	Training Loss: 0.010163024067878723
Test Loss:  0.007422046270221472
Valid Loss:  0.008662097156047821
Epoch:  53  	Training Loss: 0.00997889880090952
Test Loss:  0.007279114797711372
Valid Loss:  0.008468877524137497
Epoch:  54  	Training Loss: 0.00979899987578392
Test Loss:  0.007140163332223892
Valid Loss:  0.00828098226338625
Epoch:  55  	Training Loss: 0.009623229503631592
Test Loss:  0.0070050740614533424
Valid Loss:  0.008098214864730835
Epoch:  56  	Training Loss: 0.009451492689549923
Test Loss:  0.006873747333884239
Valid Loss:  0.007920444943010807
Epoch:  57  	Training Loss: 0.009283690713346004
Test Loss:  0.006745941936969757
Valid Loss:  0.007747466675937176
Epoch:  58  	Training Loss: 0.009119732305407524
Test Loss:  0.006621550768613815
Valid Loss:  0.007579154334962368
Epoch:  59  	Training Loss: 0.00895952619612217
Test Loss:  0.006500455550849438
Valid Loss:  0.0074153561145067215
Epoch:  60  	Training Loss: 0.008802995085716248
Test Loss:  0.006382507737725973
Valid Loss:  0.007255930453538895
Epoch:  61  	Training Loss: 0.008650040253996849
Test Loss:  0.0062676481902599335
Valid Loss:  0.007100777700543404
Epoch:  62  	Training Loss: 0.00850058812648058
Test Loss:  0.0061546675860881805
Valid Loss:  0.006949041970074177
Epoch:  63  	Training Loss: 0.00835439097136259
Test Loss:  0.006044735666364431
Valid Loss:  0.006801430135965347
Epoch:  64  	Training Loss: 0.008211535401642323
Test Loss:  0.005937764421105385
Valid Loss:  0.0066578080877661705
Epoch:  65  	Training Loss: 0.008071955293416977
Test Loss:  0.005833642557263374
Valid Loss:  0.006518056150525808
Epoch:  66  	Training Loss: 0.007935567758977413
Test Loss:  0.005732230842113495
Valid Loss:  0.006382049061357975
Epoch:  67  	Training Loss: 0.007802291307598352
Test Loss:  0.005633439868688583
Valid Loss:  0.006249695084989071
Epoch:  68  	Training Loss: 0.0076720635406672955
Test Loss:  0.0055371904745697975
Valid Loss:  0.006120879668742418
Epoch:  69  	Training Loss: 0.007544812746345997
Test Loss:  0.00544340256601572
Valid Loss:  0.005995506886392832
Epoch:  70  	Training Loss: 0.007420465350151062
Test Loss:  0.00535202119499445
Valid Loss:  0.005873487330973148
Epoch:  71  	Training Loss: 0.007298960350453854
Test Loss:  0.005262949503958225
Valid Loss:  0.0057547311298549175
 15%|█▍        | 73/500 [00:54<06:02,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:20,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:01<08:12,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:07<07:58,  1.17s/it] 19%|█▊        | 93/500 [01:08<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:08<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:14<07:48,  1.17s/it] 21%|██        | 103/500 [01:14<05:34,  1.19it/s] 21%|██        | 105/500 [01:15<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:15<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:15<02:09,  3.01it/s] 22%|██▏       | 111/500 [01:21<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.65it/s] 23%|██▎       | 117/500 [01:21<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:28<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:28<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:13,  1.17s/it] 27%|██▋       | 133/500 [01:35<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.24it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.01it/s]Epoch:  72  	Training Loss: 0.007180224638432264
Test Loss:  0.005174769554287195
Valid Loss:  0.005638290196657181
Epoch:  73  	Training Loss: 0.007063990458846092
Test Loss:  0.0050889793783426285
Valid Loss:  0.005525058135390282
Epoch:  74  	Training Loss: 0.006950416136533022
Test Loss:  0.005005464889109135
Valid Loss:  0.005414916202425957
Epoch:  75  	Training Loss: 0.006839425303041935
Test Loss:  0.004924203269183636
Valid Loss:  0.005307799205183983
Epoch:  76  	Training Loss: 0.006730982102453709
Test Loss:  0.004845071118324995
Valid Loss:  0.005203613080084324
Epoch:  77  	Training Loss: 0.006625007372349501
Test Loss:  0.0047679925337433815
Valid Loss:  0.005102263763546944
Epoch:  78  	Training Loss: 0.006521451286971569
Test Loss:  0.004692915827035904
Valid Loss:  0.005003676284104586
Epoch:  79  	Training Loss: 0.006420254707336426
Test Loss:  0.0046197837218642235
Valid Loss:  0.004907770082354546
Epoch:  80  	Training Loss: 0.0063213687390089035
Test Loss:  0.004548528231680393
Valid Loss:  0.00481448182836175
Epoch:  81  	Training Loss: 0.006224740296602249
Test Loss:  0.0044790953397750854
Valid Loss:  0.0047237323597073555
Epoch:  82  	Training Loss: 0.0061303130351006985
Test Loss:  0.004412264563143253
Valid Loss:  0.004635978490114212
Epoch:  83  	Training Loss: 0.006038212683051825
Test Loss:  0.0043470533564686775
Valid Loss:  0.004550576210021973
Epoch:  84  	Training Loss: 0.005948212463408709
Test Loss:  0.0042834593914449215
Valid Loss:  0.004467473365366459
Epoch:  85  	Training Loss: 0.005860268138349056
Test Loss:  0.00422141095623374
Valid Loss:  0.004386603832244873
Epoch:  86  	Training Loss: 0.005774326156824827
Test Loss:  0.004160866141319275
Valid Loss:  0.004307898227125406
Epoch:  87  	Training Loss: 0.005690344143658876
Test Loss:  0.0041018081828951836
Valid Loss:  0.004231339320540428
Epoch:  88  	Training Loss: 0.005608272738754749
Test Loss:  0.0040441881865262985
Valid Loss:  0.004156861454248428
Epoch:  89  	Training Loss: 0.005528074689209461
Test Loss:  0.003987979143857956
Valid Loss:  0.004084396176040173
Epoch:  90  	Training Loss: 0.005449699237942696
Test Loss:  0.0039331549778580666
Valid Loss:  0.0040139127522706985
Epoch:  91  	Training Loss: 0.005373109132051468
Test Loss:  0.0038796882145106792
Valid Loss:  0.003945368342101574
Epoch:  92  	Training Loss: 0.00529826246201992
Test Loss:  0.003827061504125595
Valid Loss:  0.003878409508615732
Epoch:  93  	Training Loss: 0.005224987398833036
Test Loss:  0.003775766585022211
Valid Loss:  0.0038133198395371437
Epoch:  94  	Training Loss: 0.0051533738151192665
Test Loss:  0.0037257885560393333
Valid Loss:  0.003750045318156481
Epoch:  95  	Training Loss: 0.005083397496491671
Test Loss:  0.00367712858133018
Valid Loss:  0.0036885670851916075
Epoch:  96  	Training Loss: 0.005015017464756966
Test Loss:  0.0036296984180808067
Valid Loss:  0.003628799691796303
Epoch:  97  	Training Loss: 0.0049481987953186035
Test Loss:  0.0035835036542266607
Valid Loss:  0.003570714732632041
Epoch:  98  	Training Loss: 0.004882904700934887
Test Loss:  0.0035384853836148977
Valid Loss:  0.0035142749547958374
Epoch:  99  	Training Loss: 0.004819093272089958
Test Loss:  0.0034945979714393616
Valid Loss:  0.0034594235476106405
Epoch:  100  	Training Loss: 0.004756740294396877
Test Loss:  0.003451828146353364
Valid Loss:  0.003406140487641096
Epoch:  101  	Training Loss: 0.0046958052553236485
Test Loss:  0.0034101400524377823
Valid Loss:  0.0033543703611940145
Epoch:  102  	Training Loss: 0.00463625555858016
Test Loss:  0.0033696519676595926
Valid Loss:  0.00330412108451128
Epoch:  103  	Training Loss: 0.004578045103698969
Test Loss:  0.0033301773946732283
Valid Loss:  0.0032553072087466717
Epoch:  104  	Training Loss: 0.0045211585238575935
Test Loss:  0.003291688859462738
Valid Loss:  0.003207877278327942
Epoch:  105  	Training Loss: 0.00446556881070137
Test Loss:  0.0032541784457862377
Valid Loss:  0.0031618126668035984
Epoch:  106  	Training Loss: 0.0044112494215369225
Test Loss:  0.0032176587264984846
Valid Loss:  0.003117079846560955
Epoch:  107  	Training Loss: 0.004358173348009586
Test Loss:  0.003182031912729144
Valid Loss:  0.0030736278276890516
Epoch:  108  	Training Loss: 0.004306301474571228
Test Loss:  0.0031473045237362385
Valid Loss:  0.0030314275063574314
Epoch:  109  	Training Loss: 0.004255605395883322
Test Loss:  0.003113457467406988
Valid Loss:  0.0029904660768806934
Epoch:  110  	Training Loss: 0.004206064157187939
Test Loss:  0.0030804602429270744
Valid Loss:  0.0029507079161703587
Epoch:  111  	Training Loss: 0.004157647490501404
Test Loss:  0.0030483074951916933
Valid Loss:  0.0029121232219040394
Epoch:  112  	Training Loss: 0.004110331181436777
Test Loss:  0.0030166658107191324
Valid Loss:  0.0028745627496391535
Epoch:  113  	Training Loss: 0.004064062610268593
Test Loss:  0.0029858876951038837
Valid Loss:  0.002838149666786194
Epoch:  114  	Training Loss: 0.004018845036625862
Test Loss:  0.0029559037648141384
Valid Loss:  0.002802821807563305
Epoch:  115  	Training Loss: 0.003974658437073231
Test Loss:  0.0029267219360917807
Valid Loss:  0.0027685733512043953
Epoch:  116  	Training Loss: 0.003931471612304449
Test Loss:  0.002898300066590309
Valid Loss:  0.0027353502810001373
Epoch:  117  	Training Loss: 0.0038892668671905994
Test Loss:  0.00287063280120492
Valid Loss:  0.002703145146369934
Epoch:  118  	Training Loss: 0.003848022548481822
Test Loss:  0.0028437101282179356
Valid Loss:  0.0026719325687736273
Epoch:  119  	Training Loss: 0.003807720262557268
Test Loss:  0.002817514818161726
Valid Loss:  0.002641674829646945
Epoch:  120  	Training Loss: 0.003768343711271882
Test Loss:  0.002791990526020527
Valid Loss:  0.00261233770288527
Epoch:  121  	Training Loss: 0.003729855176061392
Test Loss:  0.0027671472635120153
Valid Loss:  0.0025839111767709255
Epoch:  122  	Training Loss: 0.0036922437138855457
Test Loss:  0.0027431396301835775
Valid Loss:  0.0025564217939972878
Epoch:  123  	Training Loss: 0.0036554979160428047
Test Loss:  0.0027197632007300854
Valid Loss:  0.002529782010242343
Epoch:  124  	Training Loss: 0.0036195898428559303
Test Loss:  0.0026969658210873604
Valid Loss:  0.00250396435149014
Epoch:  125  	Training Loss: 0.003584500402212143
Test Loss:  0.00267476006411016
Valid Loss:  0.00247895042411983
Epoch:  126  	Training Loss: 0.003550201654434204
Test Loss:  0.002653104020282626
Valid Loss:  0.002454721601679921
Epoch:  127  	Training Loss: 0.003516681957989931
Test Loss:  0.0026320256292819977
Valid Loss:  0.0024312566965818405
Epoch:  128  	Training Loss: 0.003483931068331003
Test Loss:  0.0026114964857697487
Valid Loss:  0.002408537082374096
Epoch:  129  	Training Loss: 0.003451921744272113
Test Loss:  0.0025914835277944803
Valid Loss:  0.0023865399416536093
Epoch:  130  	Training Loss: 0.003420636523514986
Test Loss:  0.00257203564979136
Valid Loss:  0.00236525502987206
Epoch:  131  	Training Loss: 0.003390074009075761
Test Loss:  0.0025530983693897724
Valid Loss:  0.0023446509148925543
Epoch:  132  	Training Loss: 0.0033602076582610607
Test Loss:  0.00253472407348454
Valid Loss:  0.0023247231729328632
Epoch:  133  	Training Loss: 0.003331006970256567
Test Loss:  0.0025168340653181076
Valid Loss:  0.0023054475896060467
Epoch:  134  	Training Loss: 0.0033024733420461416
Test Loss:  0.0024994034320116043
Valid Loss:  0.00228679901920259
Epoch:  135  	Training Loss: 0.003274586983025074
Test Loss:  0.0024824219290167093
Valid Loss:  0.0022687779273837805
Epoch:  136  	Training Loss: 0.0032473383471369743
Test Loss:  0.002465878613293171
Valid Loss:  0.0022513498552143574
Epoch:  137  	Training Loss: 0.0032207039184868336
Test Loss:  0.0024497704580426216
Valid Loss:  0.0022345115430653095
Epoch:  138  	Training Loss: 0.0031946746166795492
Test Loss:  0.0024340795353055
Valid Loss:  0.0022182425018399954
Epoch:  139  	Training Loss: 0.0031692301854491234
Test Loss:  0.0024188037496060133
Valid Loss:  0.00220253923907876
Epoch:  140  	Training Loss: 0.0031443668995052576
Test Loss:  0.0024039382115006447
Valid Loss:  0.0021873638033866882
Epoch:  141  	Training Loss: 0.0031200693920254707
Test Loss:   28%|██▊       | 141/500 [01:41<06:58,  1.17s/it] 29%|██▊       | 143/500 [01:42<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:42<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:42<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.03it/s] 30%|███       | 151/500 [01:48<06:52,  1.18s/it] 31%|███       | 153/500 [01:49<04:55,  1.18it/s] 31%|███       | 155/500 [01:49<03:32,  1.63it/s] 31%|███▏      | 157/500 [01:49<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:49<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:55<06:43,  1.19s/it] 33%|███▎      | 163/500 [01:55<04:47,  1.17it/s] 33%|███▎      | 165/500 [01:56<03:27,  1.62it/s] 33%|███▎      | 167/500 [01:56<02:30,  2.21it/s] 34%|███▍      | 169/500 [01:56<01:51,  2.97it/s] 34%|███▍      | 171/500 [02:02<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:02<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:02<03:21,  1.62it/s] 35%|███▌      | 177/500 [02:03<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.97it/s] 36%|███▌      | 181/500 [02:09<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.02it/s] 38%|███▊      | 191/500 [02:16<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:16<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:16<03:05,  1.65it/s] 39%|███▉      | 197/500 [02:16<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:16<01:39,  3.03it/s] 40%|████      | 201/500 [02:23<05:52,  1.18s/it] 41%|████      | 203/500 [02:23<04:11,  1.18it/s] 41%|████      | 205/500 [02:23<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:23<01:36,  3.00it/s]0.00238947756588459
Valid Loss:  0.0021727276034653187
Epoch:  142  	Training Loss: 0.003096319269388914
Test Loss:  0.002375418320298195
Valid Loss:  0.0021586082875728607
Epoch:  143  	Training Loss: 0.0030731474980711937
Test Loss:  0.0023617534898221493
Valid Loss:  0.002145000034943223
Epoch:  144  	Training Loss: 0.0030505084432661533
Test Loss:  0.0023484542034566402
Valid Loss:  0.002131874207407236
Epoch:  145  	Training Loss: 0.0030283795204013586
Test Loss:  0.0023355174344033003
Valid Loss:  0.002119220094755292
Epoch:  146  	Training Loss: 0.003006749087944627
Test Loss:  0.0023229336366057396
Valid Loss:  0.002107025356963277
Epoch:  147  	Training Loss: 0.0029856134206056595
Test Loss:  0.0023106879089027643
Valid Loss:  0.002095278352499008
Epoch:  148  	Training Loss: 0.0029649538919329643
Test Loss:  0.0022987837437540293
Valid Loss:  0.0020839711651206017
Epoch:  149  	Training Loss: 0.002944766543805599
Test Loss:  0.002287194598466158
Valid Loss:  0.0020730847027152777
Epoch:  150  	Training Loss: 0.0029250290244817734
Test Loss:  0.002275929320603609
Valid Loss:  0.0020626115147024393
Epoch:  151  	Training Loss: 0.0029057434294372797
Test Loss:  0.002264969749376178
Valid Loss:  0.002052541356533766
Epoch:  152  	Training Loss: 0.002886891830712557
Test Loss:  0.002254473976790905
Valid Loss:  0.0020428986754268408
Epoch:  153  	Training Loss: 0.0028685214929282665
Test Loss:  0.0022442794870585203
Valid Loss:  0.0020336341112852097
Epoch:  154  	Training Loss: 0.002850566990673542
Test Loss:  0.002234345767647028
Valid Loss:  0.0020247306674718857
Epoch:  155  	Training Loss: 0.0028330166824162006
Test Loss:  0.002224685624241829
Valid Loss:  0.0020161874126642942
Epoch:  156  	Training Loss: 0.0028158649802207947
Test Loss:  0.0022152981255203485
Valid Loss:  0.0020079901441931725
Epoch:  157  	Training Loss: 0.0027991090901196003
Test Loss:  0.0022061760537326336
Valid Loss:  0.002000127686187625
Epoch:  158  	Training Loss: 0.002782730385661125
Test Loss:  0.00219730194658041
Valid Loss:  0.001992592355236411
Epoch:  159  	Training Loss: 0.002766722347587347
Test Loss:  0.0021886732429265976
Valid Loss:  0.0019853729754686356
Epoch:  160  	Training Loss: 0.00275108078494668
Test Loss:  0.0021802778355777264
Valid Loss:  0.0019784667529165745
Epoch:  161  	Training Loss: 0.0027357893995940685
Test Loss:  0.0021721094381064177
Valid Loss:  0.001971856225281954
Epoch:  162  	Training Loss: 0.002720843069255352
Test Loss:  0.0021642812062054873
Valid Loss:  0.0019655623473227024
Epoch:  163  	Training Loss: 0.002706274390220642
Test Loss:  0.002156668808311224
Valid Loss:  0.001959552988409996
Epoch:  164  	Training Loss: 0.002692039357498288
Test Loss:  0.0021492524538189173
Valid Loss:  0.0019538223277777433
Epoch:  165  	Training Loss: 0.0026781251654028893
Test Loss:  0.0021420447155833244
Valid Loss:  0.0019483491778373718
Epoch:  166  	Training Loss: 0.0026645218022167683
Test Loss:  0.002135032322257757
Valid Loss:  0.0019431363325566053
Epoch:  167  	Training Loss: 0.002651226706802845
Test Loss:  0.0021282185334712267
Valid Loss:  0.0019381755264475942
Epoch:  168  	Training Loss: 0.0026382310315966606
Test Loss:  0.002121594501659274
Valid Loss:  0.0019334594253450632
Epoch:  169  	Training Loss: 0.0026255305856466293
Test Loss:  0.0021151569671928883
Valid Loss:  0.0019289770862087607
Epoch:  170  	Training Loss: 0.0026131137274205685
Test Loss:  0.002108906628564
Valid Loss:  0.0019247315358370543
Epoch:  171  	Training Loss: 0.002600978361442685
Test Loss:  0.002102828584611416
Valid Loss:  0.0019206972792744637
Epoch:  172  	Training Loss: 0.0025891149416565895
Test Loss:  0.0020968113094568253
Valid Loss:  0.0019168790895491838
Epoch:  173  	Training Loss: 0.0025774810928851366
Test Loss:  0.002090982161462307
Valid Loss:  0.0019132703309878707
Epoch:  174  	Training Loss: 0.002566112205386162
Test Loss:  0.0020853308960795403
Valid Loss:  0.0019098666962236166
Epoch:  175  	Training Loss: 0.002554997568950057
Test Loss:  0.0020798714831471443
Valid Loss:  0.001906663877889514
Epoch:  176  	Training Loss: 0.0025441371835768223
Test Loss:  0.0020745776128023863
Valid Loss:  0.001903653610497713
Epoch:  177  	Training Loss: 0.0025335229001939297
Test Loss:  0.002069454872980714
Valid Loss:  0.0019008360104635358
Epoch:  178  	Training Loss: 0.002523144707083702
Test Loss:  0.002064483007416129
Valid Loss:  0.001898200367577374
Epoch:  179  	Training Loss: 0.002513004932552576
Test Loss:  0.0020596943795681
Valid Loss:  0.0018957409774884582
Epoch:  180  	Training Loss: 0.00250309519469738
Test Loss:  0.0020550484769046307
Valid Loss:  0.0018934558611363173
Epoch:  181  	Training Loss: 0.0024934103712439537
Test Loss:  0.0020505497232079506
Valid Loss:  0.0018913398962467909
Epoch:  182  	Training Loss: 0.002483942313119769
Test Loss:  0.002046249806880951
Valid Loss:  0.0018893801607191563
Epoch:  183  	Training Loss: 0.0024747103452682495
Test Loss:  0.002042088657617569
Valid Loss:  0.001887595048174262
Epoch:  184  	Training Loss: 0.002465686295181513
Test Loss:  0.0020380434580147266
Valid Loss:  0.0018859489355236292
Epoch:  185  	Training Loss: 0.002456867368891835
Test Loss:  0.002034132368862629
Valid Loss:  0.0018844578880816698
Epoch:  186  	Training Loss: 0.0024482409935444593
Test Loss:  0.0020303416531533003
Valid Loss:  0.0018831004854291677
Epoch:  187  	Training Loss: 0.002439813455566764
Test Loss:  0.0020266722422093153
Valid Loss:  0.0018818798707798123
Epoch:  188  	Training Loss: 0.002431577770039439
Test Loss:  0.0020231129601597786
Valid Loss:  0.0018807915039360523
Epoch:  189  	Training Loss: 0.0024235215969383717
Test Loss:  0.002019667997956276
Valid Loss:  0.0018798341043293476
Epoch:  190  	Training Loss: 0.0024156486615538597
Test Loss:  0.002016336191445589
Valid Loss:  0.0018789982423186302
Epoch:  191  	Training Loss: 0.0024079529102891684
Test Loss:  0.0020131105557084084
Valid Loss:  0.001878279959782958
Epoch:  192  	Training Loss: 0.0024004275910556316
Test Loss:  0.002009904244914651
Valid Loss:  0.0018776953220367432
Epoch:  193  	Training Loss: 0.002393066417425871
Test Loss:  0.002006812719628215
Valid Loss:  0.0018772147595882416
Epoch:  194  	Training Loss: 0.0023858677595853806
Test Loss:  0.0020038317888975143
Valid Loss:  0.001876849913969636
Epoch:  195  	Training Loss: 0.0023788362741470337
Test Loss:  0.0020009696017950773
Valid Loss:  0.0018765847198665142
Epoch:  196  	Training Loss: 0.0023719575256109238
Test Loss:  0.00199821125715971
Valid Loss:  0.0018764298874884844
Epoch:  197  	Training Loss: 0.0023652417585253716
Test Loss:  0.0019955665338784456
Valid Loss:  0.001876367605291307
Epoch:  198  	Training Loss: 0.0023586766328662634
Test Loss:  0.0019930198322981596
Valid Loss:  0.0018764063715934753
Epoch:  199  	Training Loss: 0.002352257026359439
Test Loss:  0.00199055764824152
Valid Loss:  0.0018765316344797611
Epoch:  200  	Training Loss: 0.0023459801450371742
Test Loss:  0.0019881923217326403
Valid Loss:  0.0018767473520711064
Epoch:  201  	Training Loss: 0.0023398485500365496
Test Loss:  0.001985914772376418
Valid Loss:  0.0018770466558635235
Epoch:  202  	Training Loss: 0.0023338529281318188
Test Loss:  0.00198382162488997
Valid Loss:  0.001877414993941784
Epoch:  203  	Training Loss: 0.0023280165623873472
Test Loss:  0.001981799490749836
Valid Loss:  0.0018778718076646328
Epoch:  204  	Training Loss: 0.0023223119787871838
Test Loss:  0.001979839289560914
Valid Loss:  0.0018783925333991647
Epoch:  205  	Training Loss: 0.0023167328909039497
Test Loss:  0.0019779468420892954
Valid Loss:  0.0018789935857057571
Epoch:  206  	Training Loss: 0.002311278134584427
Test Loss:  0.0019761172588914633
Valid Loss:  0.001879665651358664
Epoch:  207  	Training Loss: 0.0023059435188770294
Test Loss:  0.001974355196580291
Valid Loss:  0.0018804020946845412
Epoch:  208  	Training Loss: 0.0023007295094430447
Test Loss:  0.001972658559679985
Valid Loss:  0.001881205360405147
Epoch:  209  	Training Loss: 0.002295630518347025
Test Loss:  0.001971022691577673
Valid Loss:  0.001882073120214045
Epoch:  210  	Training Loss: 0.002290647244080901
Test Loss:   42%|████▏     | 211/500 [02:29<05:36,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:30<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:30<01:32,  3.03it/s] 44%|████▍     | 221/500 [02:36<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:53,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:37<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:37<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:43<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:43<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:43<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:50<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:50<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:50<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:50<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:50<01:24,  2.98it/s] 50%|█████     | 251/500 [02:57<04:51,  1.17s/it] 51%|█████     | 253/500 [02:57<03:27,  1.19it/s] 51%|█████     | 255/500 [02:57<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:57<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:03<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:04<03:18,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:04<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:10<04:24,  1.16s/it] 55%|█████▍    | 273/500 [03:10<03:08,  1.20it/s] 55%|█████▌    | 275/500 [03:10<02:15,  1.66it/s] 55%|█████▌    | 277/500 [03:11<01:38,  2.27it/s]0.00196944666095078
Valid Loss:  0.0018830016488209367
Epoch:  211  	Training Loss: 0.0022857734002172947
Test Loss:  0.0019679274410009384
Valid Loss:  0.0018839864060282707
Epoch:  212  	Training Loss: 0.0022810078226029873
Test Loss:  0.0019664354622364044
Valid Loss:  0.0018850341439247131
Epoch:  213  	Training Loss: 0.00227633910253644
Test Loss:  0.0019650007598102093
Valid Loss:  0.0018861263524740934
Epoch:  214  	Training Loss: 0.0022717732936143875
Test Loss:  0.0019636203069239855
Valid Loss:  0.0018872830551117659
Epoch:  215  	Training Loss: 0.00226731039583683
Test Loss:  0.00196230411529541
Valid Loss:  0.0018884832970798016
Epoch:  216  	Training Loss: 0.0022629473824054003
Test Loss:  0.0019610365852713585
Valid Loss:  0.0018897289410233498
Epoch:  217  	Training Loss: 0.0022586791310459375
Test Loss:  0.0019598188810050488
Valid Loss:  0.001891020918264985
Epoch:  218  	Training Loss: 0.002254502847790718
Test Loss:  0.001958666369318962
Valid Loss:  0.001892356900498271
Epoch:  219  	Training Loss: 0.002250420395284891
Test Loss:  0.0019575515761971474
Valid Loss:  0.0018937335116788745
Epoch:  220  	Training Loss: 0.0022464292123913765
Test Loss:  0.001956487772986293
Valid Loss:  0.0018951455131173134
Epoch:  221  	Training Loss: 0.00224252394400537
Test Loss:  0.001955473329871893
Valid Loss:  0.0018966019852086902
Epoch:  222  	Training Loss: 0.0022387083154171705
Test Loss:  0.001954493345692754
Valid Loss:  0.0018980910535901785
Epoch:  223  	Training Loss: 0.0022349643986672163
Test Loss:  0.0019535559695214033
Valid Loss:  0.0018996180733665824
Epoch:  224  	Training Loss: 0.0022313061635941267
Test Loss:  0.0019526664400473237
Valid Loss:  0.0019011811818927526
Epoch:  225  	Training Loss: 0.0022277284879237413
Test Loss:  0.0019518242916092277
Valid Loss:  0.0019027674570679665
Epoch:  226  	Training Loss: 0.0022242306731641293
Test Loss:  0.001951021607965231
Valid Loss:  0.0019043829524889588
Epoch:  227  	Training Loss: 0.0022208048030734062
Test Loss:  0.001950264209881425
Valid Loss:  0.0019060287158936262
Epoch:  228  	Training Loss: 0.0022174566984176636
Test Loss:  0.0019495491869747639
Valid Loss:  0.0019077020697295666
Epoch:  229  	Training Loss: 0.0022141903173178434
Test Loss:  0.001948878401890397
Valid Loss:  0.0019094027811661363
Epoch:  230  	Training Loss: 0.0022109923884272575
Test Loss:  0.0019482373027130961
Valid Loss:  0.0019111339934170246
Epoch:  231  	Training Loss: 0.0022078659385442734
Test Loss:  0.001947631943039596
Valid Loss:  0.0019128848798573017
Epoch:  232  	Training Loss: 0.002204806776717305
Test Loss:  0.0019470194820314646
Valid Loss:  0.001914674649015069
Epoch:  233  	Training Loss: 0.002201798837631941
Test Loss:  0.0019464502111077309
Valid Loss:  0.0019164716359227896
Epoch:  234  	Training Loss: 0.0021988581866025925
Test Loss:  0.0019459116738289595
Valid Loss:  0.001918303081765771
Epoch:  235  	Training Loss: 0.0021959778387099504
Test Loss:  0.0019454086432233453
Valid Loss:  0.0019201424438506365
Epoch:  236  	Training Loss: 0.0021931608207523823
Test Loss:  0.0019449354149401188
Valid Loss:  0.001921998686157167
Epoch:  237  	Training Loss: 0.002190407831221819
Test Loss:  0.0019444947829470038
Valid Loss:  0.0019238702952861786
Epoch:  238  	Training Loss: 0.0021877121180295944
Test Loss:  0.0019440923351794481
Valid Loss:  0.001925756107084453
Epoch:  239  	Training Loss: 0.0021850736811757088
Test Loss:  0.0019437195733189583
Valid Loss:  0.0019276503007858992
Epoch:  240  	Training Loss: 0.002182496478781104
Test Loss:  0.0019433744018897414
Valid Loss:  0.001929564168676734
Epoch:  241  	Training Loss: 0.0021799723617732525
Test Loss:  0.0019430548418313265
Valid Loss:  0.0019314874662086368
Epoch:  242  	Training Loss: 0.0021775015629827976
Test Loss:  0.0019427690422162414
Valid Loss:  0.001933416584506631
Epoch:  243  	Training Loss: 0.0021750940941274166
Test Loss:  0.0019425051286816597
Valid Loss:  0.0019353560637682676
Epoch:  244  	Training Loss: 0.0021727336570620537
Test Loss:  0.0019422653131186962
Valid Loss:  0.001937300432473421
Epoch:  245  	Training Loss: 0.0021704244427382946
Test Loss:  0.0019420478492975235
Valid Loss:  0.0019392587710171938
Epoch:  246  	Training Loss: 0.002168163890019059
Test Loss:  0.0019418536685407162
Valid Loss:  0.0019412266556173563
Epoch:  247  	Training Loss: 0.0021659513004124165
Test Loss:  0.0019416740396991372
Valid Loss:  0.0019431873224675655
Epoch:  248  	Training Loss: 0.002163786208257079
Test Loss:  0.001941514783538878
Valid Loss:  0.001945169409736991
Epoch:  249  	Training Loss: 0.002161668846383691
Test Loss:  0.0019413804402574897
Valid Loss:  0.0019471412524580956
Epoch:  250  	Training Loss: 0.002159595023840666
Test Loss:  0.001941267168149352
Valid Loss:  0.0019491271814331412
Epoch:  251  	Training Loss: 0.0021575670689344406
Test Loss:  0.0019411661196500063
Valid Loss:  0.001951112993992865
Epoch:  252  	Training Loss: 0.002155577065423131
Test Loss:  0.0019411020912230015
Valid Loss:  0.0019530823919922113
Epoch:  253  	Training Loss: 0.0021536340937018394
Test Loss:  0.0019410511013120413
Valid Loss:  0.0019550593569874763
Epoch:  254  	Training Loss: 0.0021517262794077396
Test Loss:  0.001941016293130815
Valid Loss:  0.0019570314325392246
Epoch:  255  	Training Loss: 0.0021498585119843483
Test Loss:  0.001940990099683404
Valid Loss:  0.0019590130541473627
Epoch:  256  	Training Loss: 0.002148033119738102
Test Loss:  0.001940977293998003
Valid Loss:  0.00196099653840065
Epoch:  257  	Training Loss: 0.0021462508011609316
Test Loss:  0.0019409859087318182
Valid Loss:  0.001962983049452305
Epoch:  258  	Training Loss: 0.002144505502656102
Test Loss:  0.0019410032546147704
Valid Loss:  0.0019649616442620754
Epoch:  259  	Training Loss: 0.0021427914034575224
Test Loss:  0.0019410372478887439
Valid Loss:  0.001966942334547639
Epoch:  260  	Training Loss: 0.002141115255653858
Test Loss:  0.0019410881213843822
Valid Loss:  0.001968926750123501
Epoch:  261  	Training Loss: 0.0021394763607531786
Test Loss:  0.0019411520333960652
Valid Loss:  0.0019709013868123293
Epoch:  262  	Training Loss: 0.0021378672681748867
Test Loss:  0.001941211987286806
Valid Loss:  0.0019728834740817547
Epoch:  263  	Training Loss: 0.0021362854167819023
Test Loss:  0.0019412825349718332
Valid Loss:  0.0019748557824641466
Epoch:  264  	Training Loss: 0.0021347342990338802
Test Loss:  0.00194136006757617
Valid Loss:  0.0019768320489674807
Epoch:  265  	Training Loss: 0.0021332139149308205
Test Loss:  0.0019414541311562061
Valid Loss:  0.0019788022618740797
Epoch:  266  	Training Loss: 0.0021317254286259413
Test Loss:  0.0019415596034377813
Valid Loss:  0.001980777829885483
Epoch:  267  	Training Loss: 0.0021302669774740934
Test Loss:  0.0019416797440499067
Valid Loss:  0.0019827475771307945
Epoch:  268  	Training Loss: 0.002128839958459139
Test Loss:  0.0019418164156377316
Valid Loss:  0.0019847131334245205
Epoch:  269  	Training Loss: 0.002127440646290779
Test Loss:  0.0019419558811932802
Valid Loss:  0.0019866731017827988
Epoch:  270  	Training Loss: 0.002126069739460945
Test Loss:  0.0019421117613092065
Valid Loss:  0.0019886239897459745
Epoch:  271  	Training Loss: 0.002124726539477706
Test Loss:  0.0019422621699050069
Valid Loss:  0.001990571618080139
Epoch:  272  	Training Loss: 0.002123409416526556
Test Loss:  0.001942421542480588
Valid Loss:  0.0019925166852772236
Epoch:  273  	Training Loss: 0.0021221167407929897
Test Loss:  0.0019425791688263416
Valid Loss:  0.0019944512750953436
Epoch:  274  	Training Loss: 0.0021208503749221563
Test Loss:  0.0019427447114139795
Valid Loss:  0.0019963663071393967
Epoch:  275  	Training Loss: 0.0021196072921156883
Test Loss:  0.0019429264357313514
Valid Loss:  0.001998288556933403
Epoch:  276  	Training Loss: 0.0021183891221880913
Test Loss:  0.0019431106047704816
Valid Loss:  0.0020002047531306744
Epoch:  277  	Training Loss: 0.002117196097970009
Test Loss:  0.0019433005945757031
Valid Loss:  0.0020021158270537853
Epoch:  278  	Training Loss: 0.002116026356816292
Test Loss:  0.0019435016438364983
Valid Loss:  0.0020040173549205065
 56%|█████▌    | 279/500 [03:11<01:12,  3.05it/s] 56%|█████▌    | 281/500 [03:17<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:17<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:24<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:24<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.03it/s] 60%|██████    | 301/500 [03:30<03:52,  1.17s/it] 61%|██████    | 303/500 [03:31<02:45,  1.19it/s] 61%|██████    | 305/500 [03:31<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:31<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:31<01:02,  3.03it/s] 62%|██████▏   | 311/500 [03:37<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:37<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:38<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:38<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:38<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:44<03:33,  1.20s/it] 65%|██████▍   | 323/500 [03:44<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:45<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:45<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:45<00:57,  2.96it/s] 66%|██████▌   | 331/500 [03:51<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:51<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:51<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:51<01:13,  2.23it/s] 68%|██████▊   | 339/500 [03:52<00:53,  3.00it/s] 68%|██████▊   | 341/500 [03:58<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:58<01:33,  1.65it/s] 69%|██████▉   | 347/500 [03:58<01:07,  2.25it/s]Epoch:  279  	Training Loss: 0.0021148796658962965
Test Loss:  0.0019437122391536832
Valid Loss:  0.002005909103900194
Epoch:  280  	Training Loss: 0.0021137543953955173
Test Loss:  0.0019439301686361432
Valid Loss:  0.0020077992230653763
Epoch:  281  	Training Loss: 0.0021126517094671726
Test Loss:  0.0019441696349531412
Valid Loss:  0.002009679563343525
Epoch:  282  	Training Loss: 0.002111571142449975
Test Loss:  0.0019443933852016926
Valid Loss:  0.002011556178331375
Epoch:  283  	Training Loss: 0.0021105026826262474
Test Loss:  0.0019446322694420815
Valid Loss:  0.002013423014432192
Epoch:  284  	Training Loss: 0.0021094512194395065
Test Loss:  0.0019448860548436642
Valid Loss:  0.00201527401804924
Epoch:  285  	Training Loss: 0.002108423039317131
Test Loss:  0.0019451465923339128
Valid Loss:  0.0020171243231743574
Epoch:  286  	Training Loss: 0.002107415348291397
Test Loss:  0.001945418305695057
Valid Loss:  0.0020189606584608555
Epoch:  287  	Training Loss: 0.0021064262837171555
Test Loss:  0.0019457046873867512
Valid Loss:  0.0020207830239087343
Epoch:  288  	Training Loss: 0.002105452585965395
Test Loss:  0.0019459901377558708
Valid Loss:  0.0020226044580340385
Epoch:  289  	Training Loss: 0.0021045017056167126
Test Loss:  0.0019462807103991508
Valid Loss:  0.0020244165789335966
Epoch:  290  	Training Loss: 0.0021035666577517986
Test Loss:  0.0019466193625703454
Valid Loss:  0.0020262207835912704
Epoch:  291  	Training Loss: 0.0021026486065238714
Test Loss:  0.001946962089277804
Valid Loss:  0.0020280140452086926
Epoch:  292  	Training Loss: 0.0021017477847635746
Test Loss:  0.0019473052816465497
Valid Loss:  0.002029792405664921
Epoch:  293  	Training Loss: 0.0021008607000112534
Test Loss:  0.001947656273841858
Valid Loss:  0.0020315556321293116
Epoch:  294  	Training Loss: 0.0020999943371862173
Test Loss:  0.001948012039065361
Valid Loss:  0.0020333160646259785
Epoch:  295  	Training Loss: 0.002099148230627179
Test Loss:  0.0019483680371195078
Valid Loss:  0.002035061828792095
Epoch:  296  	Training Loss: 0.0020983247086405754
Test Loss:  0.00194873521104455
Valid Loss:  0.0020367975812405348
Epoch:  297  	Training Loss: 0.002097523305565119
Test Loss:  0.001949099125340581
Valid Loss:  0.002038525650277734
Epoch:  298  	Training Loss: 0.0020967295859009027
Test Loss:  0.001949463738128543
Valid Loss:  0.002040230669081211
Epoch:  299  	Training Loss: 0.0020959593821316957
Test Loss:  0.0019498347537592053
Valid Loss:  0.0020419370848685503
Epoch:  300  	Training Loss: 0.0020952040795236826
Test Loss:  0.0019502145005390048
Valid Loss:  0.002043626271188259
Epoch:  301  	Training Loss: 0.002094465307891369
Test Loss:  0.0019505864474922419
Valid Loss:  0.002045305212959647
Epoch:  302  	Training Loss: 0.0020937365479767323
Test Loss:  0.0019509689882397652
Valid Loss:  0.0020469585433602333
Epoch:  303  	Training Loss: 0.0020930226892232895
Test Loss:  0.001951359212398529
Valid Loss:  0.0020485995337367058
Epoch:  304  	Training Loss: 0.002092326059937477
Test Loss:  0.0019517417531460524
Valid Loss:  0.0020502391271293163
Epoch:  305  	Training Loss: 0.0020916408393532038
Test Loss:  0.0019521235954016447
Valid Loss:  0.0020518589299172163
Epoch:  306  	Training Loss: 0.0020909709855914116
Test Loss:  0.001952510909177363
Valid Loss:  0.002053474076092243
Epoch:  307  	Training Loss: 0.0020903185941278934
Test Loss:  0.001952890190295875
Valid Loss:  0.00205507455393672
Epoch:  308  	Training Loss: 0.0020896736532449722
Test Loss:  0.0019532714504748583
Valid Loss:  0.002056659897789359
Epoch:  309  	Training Loss: 0.0020890473388135433
Test Loss:  0.001953650265932083
Valid Loss:  0.002058242680504918
Epoch:  310  	Training Loss: 0.0020884256809949875
Test Loss:  0.001954025588929653
Valid Loss:  0.002059814054518938
Epoch:  311  	Training Loss: 0.0020878198556602
Test Loss:  0.0019544134847819805
Valid Loss:  0.0020613642409443855
Epoch:  312  	Training Loss: 0.0020872224122285843
Test Loss:  0.0019547934643924236
Valid Loss:  0.0020629067439585924
Epoch:  313  	Training Loss: 0.002086630091071129
Test Loss:  0.001955183921381831
Valid Loss:  0.0020644327159971
Epoch:  314  	Training Loss: 0.002086048712953925
Test Loss:  0.0019555555190891027
Valid Loss:  0.002065952867269516
Epoch:  315  	Training Loss: 0.0020854792091995478
Test Loss:  0.0019559329375624657
Valid Loss:  0.0020674618426710367
Epoch:  316  	Training Loss: 0.0020849211141467094
Test Loss:  0.001956308027729392
Valid Loss:  0.002068957779556513
Epoch:  317  	Training Loss: 0.002084373729303479
Test Loss:  0.0019566845148801804
Valid Loss:  0.002070437418296933
Epoch:  318  	Training Loss: 0.0020838379859924316
Test Loss:  0.001957060769200325
Valid Loss:  0.0020719170570373535
Epoch:  319  	Training Loss: 0.002083311090245843
Test Loss:  0.0019574472680687904
Valid Loss:  0.0020733759738504887
Epoch:  320  	Training Loss: 0.0020827907137572765
Test Loss:  0.0019578239880502224
Valid Loss:  0.0020748316310346127
Epoch:  321  	Training Loss: 0.0020822854712605476
Test Loss:  0.00195820489898324
Valid Loss:  0.002076267497614026
Epoch:  322  	Training Loss: 0.002081780694425106
Test Loss:  0.0019585725385695696
Valid Loss:  0.0020777033641934395
Epoch:  323  	Training Loss: 0.002081294311210513
Test Loss:  0.001958942972123623
Valid Loss:  0.002079133875668049
Epoch:  324  	Training Loss: 0.0020808130502700806
Test Loss:  0.0019593164324760437
Valid Loss:  0.002080540405586362
Epoch:  325  	Training Loss: 0.00208034529350698
Test Loss:  0.001959688263013959
Valid Loss:  0.002081954386085272
Epoch:  326  	Training Loss: 0.002079889178276062
Test Loss:  0.0019600626546889544
Valid Loss:  0.0020833429880440235
Epoch:  327  	Training Loss: 0.002079447964206338
Test Loss:  0.0019604337867349386
Valid Loss:  0.0020847301930189133
Epoch:  328  	Training Loss: 0.0020790090784430504
Test Loss:  0.0019608070142567158
Valid Loss:  0.0020860922522842884
Epoch:  329  	Training Loss: 0.0020785764791071415
Test Loss:  0.001961171394214034
Valid Loss:  0.002087450586259365
Epoch:  330  	Training Loss: 0.0020781534258276224
Test Loss:  0.001961539965122938
Valid Loss:  0.002088791225105524
Epoch:  331  	Training Loss: 0.0020777368918061256
Test Loss:  0.001961908070370555
Valid Loss:  0.0020901216194033623
Epoch:  332  	Training Loss: 0.0020773326978087425
Test Loss:  0.00196227990090847
Valid Loss:  0.0020914324559271336
Epoch:  333  	Training Loss: 0.002076932229101658
Test Loss:  0.0019626449793577194
Valid Loss:  0.002092731883749366
Epoch:  334  	Training Loss: 0.0020765361841768026
Test Loss:  0.001963011920452118
Valid Loss:  0.0020940182730555534
Epoch:  335  	Training Loss: 0.0020761501509696245
Test Loss:  0.0019633760675787926
Valid Loss:  0.002095297444611788
Epoch:  336  	Training Loss: 0.0020757769234478474
Test Loss:  0.001963741146028042
Valid Loss:  0.0020965682342648506
Epoch:  337  	Training Loss: 0.0020754109136760235
Test Loss:  0.0019640973769128323
Valid Loss:  0.002097824588418007
Epoch:  338  	Training Loss: 0.0020750504918396473
Test Loss:  0.001964451279491186
Valid Loss:  0.0020990739576518536
Epoch:  339  	Training Loss: 0.0020746970549225807
Test Loss:  0.0019648100715130568
Valid Loss:  0.0021003116853535175
Epoch:  340  	Training Loss: 0.002074355026707053
Test Loss:  0.0019651660695672035
Valid Loss:  0.00210154359228909
Epoch:  341  	Training Loss: 0.002074024174362421
Test Loss:  0.001965516246855259
Valid Loss:  0.0021027657203376293
Epoch:  342  	Training Loss: 0.0020736968144774437
Test Loss:  0.0019658650271594524
Valid Loss:  0.002103965263813734
Epoch:  343  	Training Loss: 0.0020733706187456846
Test Loss:  0.0019662121776491404
Valid Loss:  0.0021051533985882998
Epoch:  344  	Training Loss: 0.0020730532705783844
Test Loss:  0.001966561423614621
Valid Loss:  0.0021063340827822685
Epoch:  345  	Training Loss: 0.0020727403461933136
Test Loss:  0.0019668997265398502
Valid Loss:  0.0021075087133795023
Epoch:  346  	Training Loss: 0.002072439529001713
Test Loss:  0.0019672387279570103
Valid Loss:  0.002108666580170393
Epoch:  347  	Training Loss: 0.0020721377804875374
Test Loss:  0.0019675728399306536
Valid Loss:  0.0021098251454532146
 70%|██████▉   | 349/500 [03:58<00:49,  3.03it/s] 70%|███████   | 351/500 [04:05<02:54,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s] 71%|███████   | 355/500 [04:05<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:05<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:11<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:12<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:12<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:12<00:43,  3.03it/s] 74%|███████▍  | 371/500 [04:18<02:29,  1.16s/it] 75%|███████▍  | 373/500 [04:18<01:46,  1.20it/s] 75%|███████▌  | 375/500 [04:18<01:15,  1.66it/s] 75%|███████▌  | 377/500 [04:19<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:19<00:39,  3.04it/s] 76%|███████▌  | 381/500 [04:25<02:22,  1.19s/it] 77%|███████▋  | 383/500 [04:25<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:25<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:26<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:26<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:32<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:32<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:32<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:32<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:33<00:33,  2.98it/s] 80%|████████  | 401/500 [04:39<01:57,  1.19s/it] 81%|████████  | 403/500 [04:39<01:22,  1.17it/s] 81%|████████  | 405/500 [04:39<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:39<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:46<01:46,  1.19s/it] 83%|████████▎ | 413/500 [04:46<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:46<00:52,  1.62it/s]Epoch:  348  	Training Loss: 0.002071843482553959
Test Loss:  0.001967906951904297
Valid Loss:  0.002110957633703947
Epoch:  349  	Training Loss: 0.0020715550053864717
Test Loss:  0.0019682315178215504
Valid Loss:  0.0021120882593095303
Epoch:  350  	Training Loss: 0.0020712693221867085
Test Loss:  0.001968554686754942
Valid Loss:  0.0021132160909473896
Epoch:  351  	Training Loss: 0.002070986432954669
Test Loss:  0.0019688792526721954
Valid Loss:  0.002114326460286975
Epoch:  352  	Training Loss: 0.0020707095973193645
Test Loss:  0.0019691891502588987
Valid Loss:  0.0021154345013201237
Epoch:  353  	Training Loss: 0.002070434857159853
Test Loss:  0.0019694953225553036
Valid Loss:  0.00211652391590178
Epoch:  354  	Training Loss: 0.0020701661705970764
Test Loss:  0.0019698049873113632
Valid Loss:  0.0021176075097173452
Epoch:  355  	Training Loss: 0.0020698988810181618
Test Loss:  0.0019701048731803894
Valid Loss:  0.0021186864469200373
Epoch:  356  	Training Loss: 0.0020696385763585567
Test Loss:  0.0019704061560332775
Valid Loss:  0.0021197497844696045
Epoch:  357  	Training Loss: 0.002069377340376377
Test Loss:  0.0019707081373780966
Valid Loss:  0.0021208052057772875
Epoch:  358  	Training Loss: 0.002069125883281231
Test Loss:  0.001971003832295537
Valid Loss:  0.0021218410693109035
Epoch:  359  	Training Loss: 0.00206887349486351
Test Loss:  0.001971307909116149
Valid Loss:  0.0021228729747235775
Epoch:  360  	Training Loss: 0.0020686283241957426
Test Loss:  0.001971595920622349
Valid Loss:  0.0021238909102976322
Epoch:  361  	Training Loss: 0.0020683840848505497
Test Loss:  0.001971894409507513
Valid Loss:  0.0021249116398394108
Epoch:  362  	Training Loss: 0.00206814706325531
Test Loss:  0.0019721947610378265
Valid Loss:  0.0021259060595184565
Epoch:  363  	Training Loss: 0.0020679174922406673
Test Loss:  0.001972499303519726
Valid Loss:  0.0021268934942781925
Epoch:  364  	Training Loss: 0.002067694440484047
Test Loss:  0.0019727987237274647
Valid Loss:  0.002127876039594412
Epoch:  365  	Training Loss: 0.0020674741826951504
Test Loss:  0.0019730953499674797
Valid Loss:  0.0021288483403623104
Epoch:  366  	Training Loss: 0.002067259280011058
Test Loss:  0.0019733882509171963
Valid Loss:  0.0021298248320817947
Epoch:  367  	Training Loss: 0.002067050663754344
Test Loss:  0.001973674865439534
Valid Loss:  0.0021307775750756264
Epoch:  368  	Training Loss: 0.0020668439101427794
Test Loss:  0.001973966136574745
Valid Loss:  0.002131724264472723
Epoch:  369  	Training Loss: 0.002066646469756961
Test Loss:  0.001974251354113221
Valid Loss:  0.0021326635032892227
Epoch:  370  	Training Loss: 0.0020664494950324297
Test Loss:  0.00197453610599041
Valid Loss:  0.0021336073987185955
Epoch:  371  	Training Loss: 0.002066256245598197
Test Loss:  0.0019748196937143803
Valid Loss:  0.0021345370914787054
Epoch:  372  	Training Loss: 0.0020660655573010445
Test Loss:  0.0019750846549868584
Valid Loss:  0.002135457005351782
Epoch:  373  	Training Loss: 0.0020658764988183975
Test Loss:  0.0019753568340092897
Valid Loss:  0.0021363741252571344
Epoch:  374  	Training Loss: 0.002065695356577635
Test Loss:  0.0019756294786930084
Valid Loss:  0.0021372614428400993
Epoch:  375  	Training Loss: 0.002065513748675585
Test Loss:  0.001975893508642912
Valid Loss:  0.0021381634287536144
Epoch:  376  	Training Loss: 0.002065337263047695
Test Loss:  0.001976162660866976
Valid Loss:  0.002139048418030143
Epoch:  377  	Training Loss: 0.002065161243081093
Test Loss:  0.001976422034204006
Valid Loss:  0.0021399243269115686
Epoch:  378  	Training Loss: 0.0020649877842515707
Test Loss:  0.001976685132831335
Valid Loss:  0.0021407848689705133
Epoch:  379  	Training Loss: 0.002064824802801013
Test Loss:  0.0019769459031522274
Valid Loss:  0.0021416577510535717
Epoch:  380  	Training Loss: 0.0020646629855036736
Test Loss:  0.0019772001542150974
Valid Loss:  0.002142507117241621
Epoch:  381  	Training Loss: 0.002064501866698265
Test Loss:  0.0019774495158344507
Valid Loss:  0.0021433536894619465
Epoch:  382  	Training Loss: 0.0020643454045057297
Test Loss:  0.0019776977133005857
Valid Loss:  0.0021441923454403877
Epoch:  383  	Training Loss: 0.0020641866140067577
Test Loss:  0.0019779352005571127
Valid Loss:  0.0021450300700962543
Epoch:  384  	Training Loss: 0.002064032945781946
Test Loss:  0.0019781803712248802
Valid Loss:  0.002145837526768446
Epoch:  385  	Training Loss: 0.002063884399831295
Test Loss:  0.0019784169271588326
Valid Loss:  0.0021466577891260386
Epoch:  386  	Training Loss: 0.0020637307316064835
Test Loss:  0.0019786572083830833
Valid Loss:  0.002147465478628874
Epoch:  387  	Training Loss: 0.0020635847467929125
Test Loss:  0.001978894229978323
Valid Loss:  0.002148265019059181
Epoch:  388  	Training Loss: 0.0020634434185922146
Test Loss:  0.0019791279919445515
Valid Loss:  0.0021490552462637424
Epoch:  389  	Training Loss: 0.0020633023232221603
Test Loss:  0.0019793608225882053
Valid Loss:  0.00214983057230711
Epoch:  390  	Training Loss: 0.002063160762190819
Test Loss:  0.0019795845728367567
Valid Loss:  0.002150603337213397
Epoch:  391  	Training Loss: 0.00206302129663527
Test Loss:  0.00197981228120625
Valid Loss:  0.002151370979845524
Epoch:  392  	Training Loss: 0.0020628883503377438
Test Loss:  0.0019800395239144564
Valid Loss:  0.0021521281450986862
Epoch:  393  	Training Loss: 0.0020627519115805626
Test Loss:  0.0019802572205662727
Valid Loss:  0.002152885776013136
Epoch:  394  	Training Loss: 0.002062621060758829
Test Loss:  0.001980473753064871
Valid Loss:  0.002153635025024414
Epoch:  395  	Training Loss: 0.0020624897442758083
Test Loss:  0.001980684231966734
Valid Loss:  0.0021543693728744984
Epoch:  396  	Training Loss: 0.0020623591262847185
Test Loss:  0.0019808944780379534
Valid Loss:  0.0021550985984504223
Epoch:  397  	Training Loss: 0.0020622285082936287
Test Loss:  0.0019811056554317474
Valid Loss:  0.0021558301523327827
Epoch:  398  	Training Loss: 0.0020621074363589287
Test Loss:  0.001981313806027174
Valid Loss:  0.0021565400529652834
Epoch:  399  	Training Loss: 0.002061981474980712
Test Loss:  0.0019815140403807163
Valid Loss:  0.0021572508849203587
Epoch:  400  	Training Loss: 0.0020618592388927937
Test Loss:  0.0019817203283309937
Valid Loss:  0.00215795636177063
Epoch:  401  	Training Loss: 0.002061735140159726
Test Loss:  0.0019819277804344893
Valid Loss:  0.00215864647179842
Epoch:  402  	Training Loss: 0.0020616219844669104
Test Loss:  0.0019821226596832275
Valid Loss:  0.0021593314595520496
Epoch:  403  	Training Loss: 0.0020615002140402794
Test Loss:  0.0019823249895125628
Valid Loss:  0.0021600089967250824
Epoch:  404  	Training Loss: 0.0020613879896700382
Test Loss:  0.0019825317431241274
Valid Loss:  0.002160677220672369
Epoch:  405  	Training Loss: 0.0020612755324691534
Test Loss:  0.001982718938961625
Valid Loss:  0.0021613328717648983
Epoch:  406  	Training Loss: 0.0020611663348972797
Test Loss:  0.0019829224329441786
Valid Loss:  0.0021619934123009443
Epoch:  407  	Training Loss: 0.002061061328276992
Test Loss:  0.001983116613700986
Valid Loss:  0.00216264883056283
Epoch:  408  	Training Loss: 0.0020609565544873476
Test Loss:  0.001983314286917448
Valid Loss:  0.0021632909774780273
Epoch:  409  	Training Loss: 0.0020608531776815653
Test Loss:  0.00198350939899683
Valid Loss:  0.002163922879844904
Epoch:  410  	Training Loss: 0.002060751896351576
Test Loss:  0.001983702415600419
Valid Loss:  0.002164557110518217
Epoch:  411  	Training Loss: 0.002060655038803816
Test Loss:  0.0019838963635265827
Valid Loss:  0.00216517667286098
Epoch:  412  	Training Loss: 0.002060557948425412
Test Loss:  0.001984082395210862
Valid Loss:  0.002165805548429489
Epoch:  413  	Training Loss: 0.0020604643505066633
Test Loss:  0.0019842605106532574
Valid Loss:  0.0021664139349013567
Epoch:  414  	Training Loss: 0.0020603686571121216
Test Loss:  0.0019844502676278353
Valid Loss:  0.0021670169662684202
Epoch:  415  	Training Loss: 0.002060273662209511
Test Loss:  0.001984624657779932
Valid Loss:  0.002167618367820978
Epoch:  416  	Training Loss: 0.002060181926935911
Test Loss:  0.001984797418117523
Valid Loss:  0.0021682032383978367
 83%|████████▎ | 417/500 [04:46<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:46<00:27,  2.98it/s] 84%|████████▍ | 421/500 [04:53<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.01it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:00<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:00<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:00<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:07<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:13<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:14<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:20<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:20<00:30,  1.19it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.26it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.03it/s] 94%|█████████▍| 471/500 [05:27<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:27<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:27<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:34<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.60it/s]Epoch:  417  	Training Loss: 0.002060092054307461
Test Loss:  0.0019849715754389763
Valid Loss:  0.0021687946282327175
Epoch:  418  	Training Loss: 0.002060001716017723
Test Loss:  0.001985149458050728
Valid Loss:  0.0021693750750273466
Epoch:  419  	Training Loss: 0.002059913706034422
Test Loss:  0.001985319657251239
Valid Loss:  0.0021699517965316772
Epoch:  420  	Training Loss: 0.0020598270930349827
Test Loss:  0.0019854868296533823
Valid Loss:  0.002170517574995756
Epoch:  421  	Training Loss: 0.0020597404800355434
Test Loss:  0.001985653769224882
Valid Loss:  0.0021710803266614676
Epoch:  422  	Training Loss: 0.002059656661003828
Test Loss:  0.0019858218729496002
Valid Loss:  0.002171643078327179
Epoch:  423  	Training Loss: 0.0020595723763108253
Test Loss:  0.0019859839230775833
Valid Loss:  0.002172193955630064
Epoch:  424  	Training Loss: 0.0020594890229403973
Test Loss:  0.0019861420150846243
Valid Loss:  0.0021727331914007664
Epoch:  425  	Training Loss: 0.0020594061352312565
Test Loss:  0.001986298244446516
Valid Loss:  0.002173268934711814
Epoch:  426  	Training Loss: 0.0020593234803527594
Test Loss:  0.001986453775316477
Valid Loss:  0.0021738093346357346
Epoch:  427  	Training Loss: 0.0020592419896274805
Test Loss:  0.0019866074435412884
Valid Loss:  0.002174325753003359
Epoch:  428  	Training Loss: 0.0020591611973941326
Test Loss:  0.0019867639057338238
Valid Loss:  0.002174852881580591
Epoch:  429  	Training Loss: 0.0020590820349752903
Test Loss:  0.0019869159441441298
Valid Loss:  0.0021753660403192043
Epoch:  430  	Training Loss: 0.002059004735201597
Test Loss:  0.0019870661199092865
Valid Loss:  0.0021758764050900936
Epoch:  431  	Training Loss: 0.0020589279010891914
Test Loss:  0.0019872121047228575
Valid Loss:  0.002176381414756179
Epoch:  432  	Training Loss: 0.0020588485058397055
Test Loss:  0.0019873620476573706
Valid Loss:  0.002176873153075576
Epoch:  433  	Training Loss: 0.0020587726030498743
Test Loss:  0.0019875115249305964
Valid Loss:  0.0021773623302578926
Epoch:  434  	Training Loss: 0.002058696001768112
Test Loss:  0.0019876544829458
Valid Loss:  0.0021778447553515434
Epoch:  435  	Training Loss: 0.0020586205646395683
Test Loss:  0.001987800933420658
Valid Loss:  0.0021783283445984125
Epoch:  436  	Training Loss: 0.0020585451275110245
Test Loss:  0.001987944357097149
Valid Loss:  0.0021788030862808228
Epoch:  437  	Training Loss: 0.002058470854535699
Test Loss:  0.0019880838226526976
Valid Loss:  0.0021792661864310503
Epoch:  438  	Training Loss: 0.002058399375528097
Test Loss:  0.001988220028579235
Valid Loss:  0.0021797283552587032
Epoch:  439  	Training Loss: 0.0020583251025527716
Test Loss:  0.0019883569329977036
Valid Loss:  0.0021801877301186323
Epoch:  440  	Training Loss: 0.0020582517609000206
Test Loss:  0.0019884882494807243
Valid Loss:  0.0021806410513818264
Epoch:  441  	Training Loss: 0.0020581791177392006
Test Loss:  0.0019886204972863197
Valid Loss:  0.0021810904145240784
Epoch:  442  	Training Loss: 0.0020581104326993227
Test Loss:  0.001988749485462904
Valid Loss:  0.0021815341897308826
Epoch:  443  	Training Loss: 0.002058037556707859
Test Loss:  0.0019888754468411207
Valid Loss:  0.0021819749381393194
Epoch:  444  	Training Loss: 0.0020579658448696136
Test Loss:  0.001988995587453246
Valid Loss:  0.002182417083531618
Epoch:  445  	Training Loss: 0.0020578973926603794
Test Loss:  0.0019891238771378994
Valid Loss:  0.0021828378085047007
Epoch:  446  	Training Loss: 0.002057828241959214
Test Loss:  0.001989250537008047
Valid Loss:  0.0021832636557519436
Epoch:  447  	Training Loss: 0.0020577535033226013
Test Loss:  0.0019893760327249765
Valid Loss:  0.0021836822852492332
Epoch:  448  	Training Loss: 0.002057688543573022
Test Loss:  0.0019895019941031933
Valid Loss:  0.0021841004490852356
Epoch:  449  	Training Loss: 0.002057620557025075
Test Loss:  0.0019896214362233877
Valid Loss:  0.0021845074370503426
Epoch:  450  	Training Loss: 0.0020575537346303463
Test Loss:  0.0019897446036338806
Valid Loss:  0.002184913493692875
Epoch:  451  	Training Loss: 0.002057484583929181
Test Loss:  0.001989864045754075
Valid Loss:  0.002185314893722534
Epoch:  452  	Training Loss: 0.0020574203226715326
Test Loss:  0.0019899848848581314
Valid Loss:  0.0021857055835425854
Epoch:  453  	Training Loss: 0.0020573516376316547
Test Loss:  0.001990101533010602
Valid Loss:  0.002186093246564269
Epoch:  454  	Training Loss: 0.0020572859793901443
Test Loss:  0.0019902149215340614
Valid Loss:  0.0021864743903279305
Epoch:  455  	Training Loss: 0.0020572193898260593
Test Loss:  0.001990333665162325
Valid Loss:  0.002186852041631937
Epoch:  456  	Training Loss: 0.0020571546629071236
Test Loss:  0.001990442629903555
Valid Loss:  0.002187230857089162
Epoch:  457  	Training Loss: 0.0020570852793753147
Test Loss:  0.001990553457289934
Valid Loss:  0.0021875968668609858
Epoch:  458  	Training Loss: 0.002057023346424103
Test Loss:  0.00199066661298275
Valid Loss:  0.002187963342294097
Epoch:  459  	Training Loss: 0.0020569597836583853
Test Loss:  0.0019907704554498196
Valid Loss:  0.0021883216686546803
Epoch:  460  	Training Loss: 0.002056896686553955
Test Loss:  0.0019908822141587734
Valid Loss:  0.0021886846516281366
Epoch:  461  	Training Loss: 0.002056834287941456
Test Loss:  0.001990978606045246
Valid Loss:  0.0021890359930694103
Epoch:  462  	Training Loss: 0.002056768164038658
Test Loss:  0.0019910894334316254
Valid Loss:  0.0021893850062042475
Epoch:  463  	Training Loss: 0.0020567073952406645
Test Loss:  0.0019911862909793854
Valid Loss:  0.0021897293627262115
Epoch:  464  	Training Loss: 0.0020566429011523724
Test Loss:  0.0019912903662770987
Valid Loss:  0.002190070692449808
Epoch:  465  	Training Loss: 0.002056580502539873
Test Loss:  0.001991384197026491
Valid Loss:  0.0021904115565121174
Epoch:  466  	Training Loss: 0.0020565171726047993
Test Loss:  0.0019914847798645496
Valid Loss:  0.002190748229622841
Epoch:  467  	Training Loss: 0.0020564571022987366
Test Loss:  0.0019915795419365168
Valid Loss:  0.0021910734940320253
Epoch:  468  	Training Loss: 0.0020563937723636627
Test Loss:  0.001991675002500415
Valid Loss:  0.002191400621086359
Epoch:  469  	Training Loss: 0.0020563341677188873
Test Loss:  0.0019917706958949566
Valid Loss:  0.002191722160205245
Epoch:  470  	Training Loss: 0.002056275261566043
Test Loss:  0.0019918582402169704
Valid Loss:  0.0021920374128967524
Epoch:  471  	Training Loss: 0.0020562130957841873
Test Loss:  0.0019919583573937416
Valid Loss:  0.00219235522672534
Epoch:  472  	Training Loss: 0.00205615209415555
Test Loss:  0.001992043573409319
Valid Loss:  0.002192661166191101
Epoch:  473  	Training Loss: 0.002056096214801073
Test Loss:  0.0019921334460377693
Valid Loss:  0.002192965941503644
Epoch:  474  	Training Loss: 0.002056034281849861
Test Loss:  0.0019922247156500816
Valid Loss:  0.0021932637318968773
Epoch:  475  	Training Loss: 0.002055978402495384
Test Loss:  0.0019923164509236813
Valid Loss:  0.002193567343056202
Epoch:  476  	Training Loss: 0.0020559176336973906
Test Loss:  0.001992406090721488
Valid Loss:  0.002193857217207551
Epoch:  477  	Training Loss: 0.002055862918496132
Test Loss:  0.001992494333535433
Valid Loss:  0.0021941550076007843
Epoch:  478  	Training Loss: 0.0020558026153594255
Test Loss:  0.001992583042010665
Valid Loss:  0.0021944406908005476
Epoch:  479  	Training Loss: 0.002055745804682374
Test Loss:  0.0019926661625504494
Valid Loss:  0.002194727538153529
Epoch:  480  	Training Loss: 0.0020556868985295296
Test Loss:  0.001992751844227314
Valid Loss:  0.002195012755692005
Epoch:  481  	Training Loss: 0.002055632881820202
Test Loss:  0.0019928335677832365
Valid Loss:  0.002195292618125677
Epoch:  482  	Training Loss: 0.0020555744413286448
Test Loss:  0.001992913195863366
Valid Loss:  0.002195558277890086
Epoch:  483  	Training Loss: 0.002055519027635455
Test Loss:  0.001993002602830529
Valid Loss:  0.0021958365105092525
Epoch:  484  	Training Loss: 0.002055463381111622
Test Loss:  0.001993076875805855
Valid Loss:  0.002196107991039753
Epoch:  485  	Training Loss: 0.002055406803265214
Test Loss:  0.0019931569695472717
Valid Loss:  0.0021963748149573803
 97%|█████████▋| 487/500 [05:34<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:34<00:03,  2.94it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:41<00:00,  2.98it/s]100%|██████████| 500/500 [05:41<00:00,  1.46it/s]
Epoch:  486  	Training Loss: 0.0020553520880639553
Test Loss:  0.001993234734982252
Valid Loss:  0.0021966418717056513
Epoch:  487  	Training Loss: 0.0020552973728626966
Test Loss:  0.0019933038856834173
Valid Loss:  0.0021969035733491182
Epoch:  488  	Training Loss: 0.0020552403293550014
Test Loss:  0.001993387471884489
Valid Loss:  0.0021971645765006542
Epoch:  489  	Training Loss: 0.0020551877096295357
Test Loss:  0.0019934596493840218
Valid Loss:  0.002197419060394168
Epoch:  490  	Training Loss: 0.002055131131783128
Test Loss:  0.0019935357850044966
Valid Loss:  0.0021976716816425323
Epoch:  491  	Training Loss: 0.0020550754852592945
Test Loss:  0.0019936058670282364
Valid Loss:  0.002197917550802231
Epoch:  492  	Training Loss: 0.0020550182089209557
Test Loss:  0.001993676647543907
Valid Loss:  0.0021981613244861364
Epoch:  493  	Training Loss: 0.002054967451840639
Test Loss:  0.0019937530159950256
Valid Loss:  0.0021983906626701355
Epoch:  494  	Training Loss: 0.002054911106824875
Test Loss:  0.0019938277546316385
Valid Loss:  0.0021986307110637426
Epoch:  495  	Training Loss: 0.0020548589527606964
Test Loss:  0.0019938983023166656
Valid Loss:  0.0021988674998283386
Epoch:  496  	Training Loss: 0.0020548084285110235
Test Loss:  0.0019939702469855547
Valid Loss:  0.002199102658778429
Epoch:  497  	Training Loss: 0.0020547579042613506
Test Loss:  0.0019940375350415707
Valid Loss:  0.00219933595508337
Epoch:  498  	Training Loss: 0.002054707147181034
Test Loss:  0.0019941022619605064
Valid Loss:  0.0021995631977915764
Epoch:  499  	Training Loss: 0.0020546556916087866
Test Loss:  0.001994168618693948
Valid Loss:  0.002199784154072404
Epoch:  500  	Training Loss: 0.002054608426988125
Test Loss:  0.001994235208258033
Valid Loss:  0.0022000051103532314
seed is  6
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:51,  6.24s/it]  1%|          | 3/500 [00:06<13:53,  1.68s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:54,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:13,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.64it/s]  7%|▋         | 37/500 [00:27<03:27,  2.24it/s]  8%|▊         | 39/500 [00:27<02:33,  3.01it/s]  8%|▊         | 41/500 [00:33<08:58,  1.17s/it]  9%|▊         | 43/500 [00:33<06:24,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.64it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:18,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.00it/s] 12%|█▏        | 61/500 [00:47<08:35,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:08,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s]Epoch:  1  	Training Loss: 0.0236221831291914
Test Loss:  0.006448795553296804
Valid Loss:  0.011087669990956783
Epoch:  2  	Training Loss: 0.018172666430473328
Test Loss:  0.059371042996644974
Valid Loss:  0.05443006008863449
Epoch:  3  	Training Loss: 0.04290526360273361
Test Loss:  0.01919054239988327
Valid Loss:  0.021136406809091568
Epoch:  4  	Training Loss: 0.0204671211540699
Test Loss:  0.007840175181627274
Valid Loss:  0.010969799943268299
Epoch:  5  	Training Loss: 0.014424354769289494
Test Loss:  0.010237904265522957
Valid Loss:  0.00955596286803484
Epoch:  6  	Training Loss: 0.010367087088525295
Test Loss:  0.00490176398307085
Valid Loss:  0.005922566168010235
Epoch:  7  	Training Loss: 0.008332865312695503
Test Loss:  0.005813909694552422
Valid Loss:  0.0052482737228274345
Epoch:  8  	Training Loss: 0.006741855759173632
Test Loss:  0.0038301809690892696
Valid Loss:  0.003837006399407983
Epoch:  9  	Training Loss: 0.005636392626911402
Test Loss:  0.0037093102000653744
Valid Loss:  0.003285124432295561
Epoch:  10  	Training Loss: 0.004841946996748447
Test Loss:  0.002722080796957016
Valid Loss:  0.0026874139439314604
Epoch:  11  	Training Loss: 0.004251938778907061
Test Loss:  0.002811094745993614
Valid Loss:  0.002416173228994012
Epoch:  12  	Training Loss: 0.003810612950474024
Test Loss:  0.0020587577018886805
Valid Loss:  0.0021546469070017338
Epoch:  13  	Training Loss: 0.0034800332505255938
Test Loss:  0.0023906156420707703
Valid Loss:  0.00201787450350821
Epoch:  14  	Training Loss: 0.0032075559720396996
Test Loss:  0.0017472980543971062
Valid Loss:  0.0019116022158414125
Epoch:  15  	Training Loss: 0.0029843412339687347
Test Loss:  0.0020218389108777046
Valid Loss:  0.0017977028619498014
Epoch:  16  	Training Loss: 0.0027828647289425135
Test Loss:  0.0016250647604465485
Valid Loss:  0.0017737546004354954
Epoch:  17  	Training Loss: 0.0026335171423852444
Test Loss:  0.0017865977715700865
Valid Loss:  0.0016873582499101758
Epoch:  18  	Training Loss: 0.0024982888717204332
Test Loss:  0.0015225925017148256
Valid Loss:  0.0016965005779638886
Epoch:  19  	Training Loss: 0.002393275499343872
Test Loss:  0.0016335976542904973
Valid Loss:  0.0016209708992391825
Epoch:  20  	Training Loss: 0.0022932947613298893
Test Loss:  0.001431813696399331
Valid Loss:  0.0016407788498327136
Epoch:  21  	Training Loss: 0.0022123949602246284
Test Loss:  0.0015090735396370292
Valid Loss:  0.001573293935507536
Epoch:  22  	Training Loss: 0.0021317615173757076
Test Loss:  0.0013718650443479419
Valid Loss:  0.0015824956353753805
Epoch:  23  	Training Loss: 0.002063607797026634
Test Loss:  0.0014057694934308529
Valid Loss:  0.0015296926721930504
Epoch:  24  	Training Loss: 0.0020003148820251226
Test Loss:  0.001300410134717822
Valid Loss:  0.0015411801869049668
Epoch:  25  	Training Loss: 0.001942311879247427
Test Loss:  0.0013295246753841639
Valid Loss:  0.001490470371209085
Epoch:  26  	Training Loss: 0.001888733240775764
Test Loss:  0.0012273851316422224
Valid Loss:  0.0015091245295479894
Epoch:  27  	Training Loss: 0.0018397049279883504
Test Loss:  0.0012659488711506128
Valid Loss:  0.0014523800928145647
Epoch:  28  	Training Loss: 0.0017911081667989492
Test Loss:  0.0011749272234737873
Valid Loss:  0.001467112684622407
Epoch:  29  	Training Loss: 0.0017472280887886882
Test Loss:  0.001205632695928216
Valid Loss:  0.0014154734089970589
Epoch:  30  	Training Loss: 0.0017041908577084541
Test Loss:  0.0011322943028062582
Valid Loss:  0.0014213176909834146
Epoch:  31  	Training Loss: 0.0016634378116577864
Test Loss:  0.0011451501632109284
Valid Loss:  0.0013803712790831923
Epoch:  32  	Training Loss: 0.0016249779146164656
Test Loss:  0.001087895012460649
Valid Loss:  0.0013812812976539135
Epoch:  33  	Training Loss: 0.0015891657676547766
Test Loss:  0.001099948538467288
Valid Loss:  0.0013416024157777429
Epoch:  34  	Training Loss: 0.0015542099718004465
Test Loss:  0.0010408557718619704
Valid Loss:  0.0013443848583847284
Epoch:  35  	Training Loss: 0.0015216555912047625
Test Loss:  0.0010546207195147872
Valid Loss:  0.0013053769944235682
Epoch:  36  	Training Loss: 0.0014888467267155647
Test Loss:  0.0010079629719257355
Valid Loss:  0.0012995708966627717
Epoch:  37  	Training Loss: 0.001458076643757522
Test Loss:  0.001004603924229741
Valid Loss:  0.0012727726716548204
Epoch:  38  	Training Loss: 0.0014286088990047574
Test Loss:  0.0009772502817213535
Valid Loss:  0.0012590874684974551
Epoch:  39  	Training Loss: 0.0014001850504428148
Test Loss:  0.0009592864662408829
Valid Loss:  0.0012413375079631805
Epoch:  40  	Training Loss: 0.0013726353645324707
Test Loss:  0.0009407378383912146
Valid Loss:  0.00122446333989501
Epoch:  41  	Training Loss: 0.0013458927860483527
Test Loss:  0.0009266729466617107
Valid Loss:  0.0012061265297234058
Epoch:  42  	Training Loss: 0.001320190029218793
Test Loss:  0.0009058522991836071
Valid Loss:  0.001192586263641715
Epoch:  43  	Training Loss: 0.0012952744727954268
Test Loss:  0.0008956423262134194
Valid Loss:  0.0011731834383681417
Epoch:  44  	Training Loss: 0.0012709631118923426
Test Loss:  0.0008753712754696608
Valid Loss:  0.0011602288577705622
Epoch:  45  	Training Loss: 0.0012475121766328812
Test Loss:  0.0008653096738271415
Valid Loss:  0.0011425985721871257
Epoch:  46  	Training Loss: 0.0012248266721144319
Test Loss:  0.0008466363651677966
Valid Loss:  0.0011305164080113173
Epoch:  47  	Training Loss: 0.001202814863063395
Test Loss:  0.0008357253391295671
Valid Loss:  0.0011144534219056368
Epoch:  48  	Training Loss: 0.0011814108584076166
Test Loss:  0.0008217708673328161
Valid Loss:  0.0011011597234755754
Epoch:  49  	Training Loss: 0.0011607925407588482
Test Loss:  0.0008087909664027393
Valid Loss:  0.001088041695766151
Epoch:  50  	Training Loss: 0.0011407113634049892
Test Loss:  0.0007962840609252453
Valid Loss:  0.00107521319296211
Epoch:  51  	Training Loss: 0.0011211701203137636
Test Loss:  0.0007844867650419474
Valid Loss:  0.0010630707256495953
Epoch:  52  	Training Loss: 0.0011021632235497236
Test Loss:  0.0007755666738376021
Valid Loss:  0.0010494537418708205
Epoch:  53  	Training Loss: 0.0010836590081453323
Test Loss:  0.0007635544752702117
Valid Loss:  0.0010380768217146397
Epoch:  54  	Training Loss: 0.0010656460653990507
Test Loss:  0.0007532351301051676
Valid Loss:  0.0010264498414471745
Epoch:  55  	Training Loss: 0.0010481055360287428
Test Loss:  0.000743006297852844
Valid Loss:  0.001015478977933526
Epoch:  56  	Training Loss: 0.0010310264769941568
Test Loss:  0.0007334500551223755
Valid Loss:  0.001004910795018077
Epoch:  57  	Training Loss: 0.0010143863037228584
Test Loss:  0.0007245269371196628
Valid Loss:  0.0009946044301614165
Epoch:  58  	Training Loss: 0.0009981703478842974
Test Loss:  0.0007161269895732403
Valid Loss:  0.0009845650056377053
Epoch:  59  	Training Loss: 0.0009823646396398544
Test Loss:  0.0007083318778313696
Valid Loss:  0.0009749724413268268
Epoch:  60  	Training Loss: 0.0009669577120803297
Test Loss:  0.0007014845032244921
Valid Loss:  0.0009657022310420871
Epoch:  61  	Training Loss: 0.0009519378072582185
Test Loss:  0.0006950419628992677
Valid Loss:  0.0009566298685967922
Epoch:  62  	Training Loss: 0.0009372922359034419
Test Loss:  0.0006887789932079613
Valid Loss:  0.0009477073326706886
Epoch:  63  	Training Loss: 0.0009231391595676541
Test Loss:  0.0006840581772848964
Valid Loss:  0.0009391652420163155
Epoch:  64  	Training Loss: 0.0009095820714719594
Test Loss:  0.0006798862013965845
Valid Loss:  0.0009304742561653256
Epoch:  65  	Training Loss: 0.000896474055480212
Test Loss:  0.000674251583404839
Valid Loss:  0.0009229823481291533
Epoch:  66  	Training Loss: 0.0008837818168103695
Test Loss:  0.0006689516012556851
Valid Loss:  0.0009154784493148327
Epoch:  67  	Training Loss: 0.0008714713621884584
Test Loss:  0.0006658150814473629
Valid Loss:  0.0009073528344742954
Epoch:  68  	Training Loss: 0.0008596035186201334
Test Loss:  0.0006602972280234098
Valid Loss:  0.000900477112736553
Epoch:  69  	Training Loss: 0.0008480714750476182
Test Loss:  0.0006558970781043172
Valid Loss:  0.0008934842189773917
Epoch:  70  	Training Loss: 0.0008369088172912598
 14%|█▍        | 71/500 [00:53<08:20,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:58,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:17,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.25it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:01<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:01<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:01<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:01<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:07<08:06,  1.19s/it] 19%|█▊        | 93/500 [01:07<05:47,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:08<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.98it/s] 20%|██        | 101/500 [01:14<07:54,  1.19s/it] 21%|██        | 103/500 [01:14<05:39,  1.17it/s] 21%|██        | 105/500 [01:15<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:15<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:15<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:21<07:45,  1.20s/it] 23%|██▎       | 113/500 [01:21<05:32,  1.16it/s] 23%|██▎       | 115/500 [01:21<03:58,  1.61it/s] 23%|██▎       | 117/500 [01:22<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:22<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:28<07:35,  1.20s/it] 25%|██▍       | 123/500 [01:28<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:28<03:53,  1.60it/s] 25%|██▌       | 127/500 [01:29<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:29<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:35<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:35<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:35<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:35<02:44,  2.21it/s]Test Loss:  0.0006506332429125905
Valid Loss:  0.0008869542507454753
Epoch:  71  	Training Loss: 0.0008259990718215704
Test Loss:  0.0006457765703089535
Valid Loss:  0.0008803774835541844
Epoch:  72  	Training Loss: 0.0008153379312716424
Test Loss:  0.0006410486530512571
Valid Loss:  0.0008738656179048121
Epoch:  73  	Training Loss: 0.0008049694588407874
Test Loss:  0.0006384826265275478
Valid Loss:  0.0008665582863613963
Epoch:  74  	Training Loss: 0.0007948653073981404
Test Loss:  0.0006336223450489342
Valid Loss:  0.0008603985188528895
Epoch:  75  	Training Loss: 0.0007850032416172326
Test Loss:  0.0006297394866123796
Valid Loss:  0.0008541817078366876
Epoch:  76  	Training Loss: 0.0007754556136205792
Test Loss:  0.000627621659077704
Valid Loss:  0.0008474247297272086
Epoch:  77  	Training Loss: 0.0007661796407774091
Test Loss:  0.0006234555039554834
Valid Loss:  0.0008417028002440929
Epoch:  78  	Training Loss: 0.0007571241585537791
Test Loss:  0.0006197653710842133
Valid Loss:  0.0008359241764992476
Epoch:  79  	Training Loss: 0.0007482897490262985
Test Loss:  0.0006166484672576189
Valid Loss:  0.0008302626665681601
Epoch:  80  	Training Loss: 0.0007397333974950016
Test Loss:  0.0006128114182502031
Valid Loss:  0.000824951333925128
Epoch:  81  	Training Loss: 0.0007314069662243128
Test Loss:  0.0006097657606005669
Valid Loss:  0.0008197698625735939
Epoch:  82  	Training Loss: 0.0007233637734316289
Test Loss:  0.0006079682498238981
Valid Loss:  0.0008142298320308328
Epoch:  83  	Training Loss: 0.000715544621925801
Test Loss:  0.0006041590822860599
Valid Loss:  0.0008094672812148929
Epoch:  84  	Training Loss: 0.000707903120201081
Test Loss:  0.0006011724472045898
Valid Loss:  0.0008045223657973111
Epoch:  85  	Training Loss: 0.0007004620274528861
Test Loss:  0.0005979822017252445
Valid Loss:  0.0007998568471521139
Epoch:  86  	Training Loss: 0.0006932215765118599
Test Loss:  0.000594542536418885
Valid Loss:  0.0007952905725687742
Epoch:  87  	Training Loss: 0.0006861220463179052
Test Loss:  0.0005912028136663139
Valid Loss:  0.0007907169638201594
Epoch:  88  	Training Loss: 0.0006791666965000331
Test Loss:  0.0005881371325813234
Valid Loss:  0.0007862286875024438
Epoch:  89  	Training Loss: 0.0006724103586748242
Test Loss:  0.0005849999142810702
Valid Loss:  0.0007819249876774848
Epoch:  90  	Training Loss: 0.0006658128695562482
Test Loss:  0.0005815797485411167
Valid Loss:  0.0007776892161928117
Epoch:  91  	Training Loss: 0.0006593396537937224
Test Loss:  0.0005785993416793644
Valid Loss:  0.0007734407554380596
Epoch:  92  	Training Loss: 0.0006530543323606253
Test Loss:  0.0005772248841822147
Valid Loss:  0.0007689364720135927
Epoch:  93  	Training Loss: 0.0006469940417446196
Test Loss:  0.0005737972096540034
Valid Loss:  0.0007650588522665203
Epoch:  94  	Training Loss: 0.0006410584319382906
Test Loss:  0.0005707276286557317
Valid Loss:  0.0007610705215483904
Epoch:  95  	Training Loss: 0.0006352363270707428
Test Loss:  0.0005716701271012425
Valid Loss:  0.0007562192622572184
Epoch:  96  	Training Loss: 0.000629682675935328
Test Loss:  0.0005647816578857601
Valid Loss:  0.000753517379052937
Epoch:  97  	Training Loss: 0.0006242474773898721
Test Loss:  0.0005705889780074358
Valid Loss:  0.000747935613617301
Epoch:  98  	Training Loss: 0.0006190891144797206
Test Loss:  0.0005592576926574111
Valid Loss:  0.0007463860092684627
Epoch:  99  	Training Loss: 0.0006139077013358474
Test Loss:  0.0005663735792040825
Valid Loss:  0.0007406906224787235
Epoch:  100  	Training Loss: 0.0006087937508709729
Test Loss:  0.0005579093704000115
Valid Loss:  0.0007386035285890102
Epoch:  101  	Training Loss: 0.0006038151914253831
Test Loss:  0.000561251537874341
Valid Loss:  0.0007340966840274632
Epoch:  102  	Training Loss: 0.0005989832570776343
Test Loss:  0.0005535451928153634
Valid Loss:  0.000731951033230871
Epoch:  103  	Training Loss: 0.0005942874122411013
Test Loss:  0.0005567058688029647
Valid Loss:  0.00072763382922858
Epoch:  104  	Training Loss: 0.0005895987851545215
Test Loss:  0.0005532150389626622
Valid Loss:  0.0007248471956700087
Epoch:  105  	Training Loss: 0.0005850724992342293
Test Loss:  0.0005518535617738962
Valid Loss:  0.0007217032252810895
Epoch:  106  	Training Loss: 0.0005806415574625134
Test Loss:  0.0005497580277733505
Valid Loss:  0.0007187746814452112
Epoch:  107  	Training Loss: 0.0005762990331277251
Test Loss:  0.0005478475359268486
Valid Loss:  0.0007158631924539804
Epoch:  108  	Training Loss: 0.000572044518776238
Test Loss:  0.000546068768016994
Valid Loss:  0.0007131219608709216
Epoch:  109  	Training Loss: 0.0005679186433553696
Test Loss:  0.0005442702095024288
Valid Loss:  0.0007104841060936451
Epoch:  110  	Training Loss: 0.000563903886359185
Test Loss:  0.0005440376698970795
Valid Loss:  0.0007077277405187488
Epoch:  111  	Training Loss: 0.00056000443873927
Test Loss:  0.0005403895047493279
Valid Loss:  0.0007055511814542115
Epoch:  112  	Training Loss: 0.0005561957368627191
Test Loss:  0.000540641718544066
Valid Loss:  0.0007028148975223303
Epoch:  113  	Training Loss: 0.0005524811567738652
Test Loss:  0.0005384311662055552
Valid Loss:  0.0007006080122664571
Epoch:  114  	Training Loss: 0.0005488725728355348
Test Loss:  0.0005365510587580502
Valid Loss:  0.0006983260391280055
Epoch:  115  	Training Loss: 0.0005453236517496407
Test Loss:  0.0005346313118934631
Valid Loss:  0.0006960711907595396
Epoch:  116  	Training Loss: 0.0005418355576694012
Test Loss:  0.0005327275721356273
Valid Loss:  0.0006938042351976037
Epoch:  117  	Training Loss: 0.000538411142770201
Test Loss:  0.0005309372209012508
Valid Loss:  0.0006915576523169875
Epoch:  118  	Training Loss: 0.0005350565770640969
Test Loss:  0.0005289457621984184
Valid Loss:  0.0006893237587064505
Epoch:  119  	Training Loss: 0.0005317516042850912
Test Loss:  0.0005270143155939877
Valid Loss:  0.0006870575598441064
Epoch:  120  	Training Loss: 0.000528516888152808
Test Loss:  0.0005268803797662258
Valid Loss:  0.0006846109172329307
Epoch:  121  	Training Loss: 0.000525354000274092
Test Loss:  0.000524915405549109
Valid Loss:  0.0006825370946899056
Epoch:  122  	Training Loss: 0.000522271147929132
Test Loss:  0.0005233020056039095
Valid Loss:  0.0006804451113566756
Epoch:  123  	Training Loss: 0.0005192511016502976
Test Loss:  0.0005217065336182714
Valid Loss:  0.0006783458520658314
Epoch:  124  	Training Loss: 0.0005162800080142915
Test Loss:  0.0005199129227548838
Valid Loss:  0.0006762715638615191
Epoch:  125  	Training Loss: 0.000513354258146137
Test Loss:  0.0005181637825444341
Valid Loss:  0.0006741835386492312
Epoch:  126  	Training Loss: 0.0005104708252474666
Test Loss:  0.000516394735313952
Valid Loss:  0.0006720880628563464
Epoch:  127  	Training Loss: 0.000507625809404999
Test Loss:  0.0005146395997144282
Valid Loss:  0.0006699833320453763
Epoch:  128  	Training Loss: 0.0005048188613727689
Test Loss:  0.0005128904595039785
Valid Loss:  0.0006678728386759758
Epoch:  129  	Training Loss: 0.0005020538228563964
Test Loss:  0.0005112378858029842
Valid Loss:  0.0006657854537479579
Epoch:  130  	Training Loss: 0.0004993326729163527
Test Loss:  0.0005094340303912759
Valid Loss:  0.0006637076730839908
Epoch:  131  	Training Loss: 0.0004966459237039089
Test Loss:  0.0005076718516647816
Valid Loss:  0.0006616117316298187
Epoch:  132  	Training Loss: 0.0004939921200275421
Test Loss:  0.0005059100221842527
Valid Loss:  0.0006595136364921927
Epoch:  133  	Training Loss: 0.0004913717275485396
Test Loss:  0.0005041684489697218
Valid Loss:  0.0006574111175723374
Epoch:  134  	Training Loss: 0.0004887840477749705
Test Loss:  0.0005024163983762264
Valid Loss:  0.0006553044659085572
Epoch:  135  	Training Loss: 0.0004862260539084673
Test Loss:  0.0005006746505387127
Valid Loss:  0.0006531957187689841
Epoch:  136  	Training Loss: 0.00048369806609116495
Test Loss:  0.0004989395383745432
Valid Loss:  0.0006510852253995836
Epoch:  137  	Training Loss: 0.00048119964776560664
Test Loss:  0.0004972091410309076
Valid Loss:  0.0006489750230684876
Epoch:  138  	Training Loss: 0.00047872919822111726
Test Loss:  0.0004954865435138345
Valid Loss:  0.00064686662517488
 28%|██▊       | 139/500 [01:36<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:42<07:05,  1.19s/it] 29%|██▊       | 143/500 [01:42<05:03,  1.17it/s] 29%|██▉       | 145/500 [01:42<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:38,  2.22it/s] 30%|██▉       | 149/500 [01:42<01:57,  2.99it/s] 30%|███       | 151/500 [01:49<06:59,  1.20s/it] 31%|███       | 153/500 [01:49<04:59,  1.16it/s] 31%|███       | 155/500 [01:49<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:49<02:36,  2.20it/s] 32%|███▏      | 159/500 [01:49<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:56<06:41,  1.19s/it] 33%|███▎      | 163/500 [01:56<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:56<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:56<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:03<06:26,  1.17s/it] 35%|███▍      | 173/500 [02:03<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:03<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:03<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:09<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:10<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:10<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:10<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:16<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:16<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:16<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:17<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:17<01:39,  3.04it/s] 40%|████      | 201/500 [02:23<05:54,  1.19s/it] 41%|████      | 203/500 [02:23<04:12,  1.17it/s] 41%|████      | 205/500 [02:23<03:01,  1.63it/s]Epoch:  139  	Training Loss: 0.0004762873868457973
Test Loss:  0.0004937686026096344
Valid Loss:  0.0006447600899264216
Epoch:  140  	Training Loss: 0.00047387188533321023
Test Loss:  0.0004920563078485429
Valid Loss:  0.0006426536128856242
Epoch:  141  	Training Loss: 0.00047148289741016924
Test Loss:  0.0004903482040390372
Valid Loss:  0.0006405515014193952
Epoch:  142  	Training Loss: 0.0004691198992077261
Test Loss:  0.0004886369570158422
Valid Loss:  0.000638456956949085
Epoch:  143  	Training Loss: 0.0004667816392611712
Test Loss:  0.00048694194993004203
Valid Loss:  0.0006363652646541595
Epoch:  144  	Training Loss: 0.0004644686705432832
Test Loss:  0.0004852493875660002
Valid Loss:  0.0006342775886878371
Epoch:  145  	Training Loss: 0.0004621826228685677
Test Loss:  0.0004836072912439704
Valid Loss:  0.0006322099361568689
Epoch:  146  	Training Loss: 0.0004599225358106196
Test Loss:  0.0004818837624043226
Valid Loss:  0.0006301514804363251
Epoch:  147  	Training Loss: 0.0004576853825710714
Test Loss:  0.00048018648521974683
Valid Loss:  0.0006280885427258909
Epoch:  148  	Training Loss: 0.0004554716288112104
Test Loss:  0.00047853332944214344
Valid Loss:  0.0006260405061766505
Epoch:  149  	Training Loss: 0.0004532825550995767
Test Loss:  0.0004768084327224642
Valid Loss:  0.0006239974754862487
Epoch:  150  	Training Loss: 0.0004511142906267196
Test Loss:  0.0004751108062919229
Valid Loss:  0.000621949671767652
Epoch:  151  	Training Loss: 0.0004489676794037223
Test Loss:  0.00047342240577563643
Valid Loss:  0.0006199018098413944
Epoch:  152  	Training Loss: 0.00044684024760499597
Test Loss:  0.0004717341507785022
Valid Loss:  0.0006178549956530333
Epoch:  153  	Training Loss: 0.00044473493471741676
Test Loss:  0.00047008629189804196
Valid Loss:  0.0006158201140351593
Epoch:  154  	Training Loss: 0.0004426514497026801
Test Loss:  0.0004684163141064346
Valid Loss:  0.0006138018216006458
Epoch:  155  	Training Loss: 0.00044058827916160226
Test Loss:  0.0004667115572374314
Valid Loss:  0.0006117817829363048
Epoch:  156  	Training Loss: 0.00043854262912645936
Test Loss:  0.0004650198097806424
Valid Loss:  0.0006097587174735963
Epoch:  157  	Training Loss: 0.0004365162458270788
Test Loss:  0.0004633380158338696
Valid Loss:  0.0006077348371036351
Epoch:  158  	Training Loss: 0.000434506859164685
Test Loss:  0.0004616654186975211
Valid Loss:  0.0006057114223949611
Epoch:  159  	Training Loss: 0.0004325156332924962
Test Loss:  0.00046002460294403136
Valid Loss:  0.0006036967388354242
Epoch:  160  	Training Loss: 0.0004305434413254261
Test Loss:  0.0004583483678288758
Valid Loss:  0.0006016882252879441
Epoch:  161  	Training Loss: 0.0004285864415578544
Test Loss:  0.0004566944553516805
Valid Loss:  0.0005996796535328031
Epoch:  162  	Training Loss: 0.00042664678767323494
Test Loss:  0.0004550491867121309
Valid Loss:  0.0005976718966849148
Epoch:  163  	Training Loss: 0.00042472098721191287
Test Loss:  0.00045340770157054067
Valid Loss:  0.0005956689128652215
Epoch:  164  	Training Loss: 0.0004228116013109684
Test Loss:  0.00045177232823334634
Valid Loss:  0.0005936703528277576
Epoch:  165  	Training Loss: 0.00042091766954399645
Test Loss:  0.0004501464427448809
Valid Loss:  0.0005916779045946896
Epoch:  166  	Training Loss: 0.0004190398321952671
Test Loss:  0.0004485289682634175
Valid Loss:  0.0005896906368434429
Epoch:  167  	Training Loss: 0.00041717669228091836
Test Loss:  0.000446921621914953
Valid Loss:  0.000587710237596184
Epoch:  168  	Training Loss: 0.0004153296467848122
Test Loss:  0.00044532204628922045
Valid Loss:  0.0005857374053448439
Epoch:  169  	Training Loss: 0.0004134979681111872
Test Loss:  0.00044373306445777416
Valid Loss:  0.0005837718490511179
Epoch:  170  	Training Loss: 0.0004116806958336383
Test Loss:  0.0004421478952281177
Valid Loss:  0.0005818138597533107
Epoch:  171  	Training Loss: 0.00040987817919813097
Test Loss:  0.00044057320337742567
Valid Loss:  0.000579863553866744
Epoch:  172  	Training Loss: 0.0004080899234395474
Test Loss:  0.00043900180025957525
Valid Loss:  0.0005779237253591418
Epoch:  173  	Training Loss: 0.00040631694719195366
Test Loss:  0.0004374435811769217
Valid Loss:  0.000575991056393832
Epoch:  174  	Training Loss: 0.0004045587847940624
Test Loss:  0.000435893569374457
Valid Loss:  0.0005740674096159637
Epoch:  175  	Training Loss: 0.00040281470865011215
Test Loss:  0.00043435118277557194
Valid Loss:  0.0005721517372876406
Epoch:  176  	Training Loss: 0.00040108413668349385
Test Loss:  0.0004328176728449762
Valid Loss:  0.0005702433991245925
Epoch:  177  	Training Loss: 0.0003993679420091212
Test Loss:  0.00043128797551617026
Valid Loss:  0.000568344141356647
Epoch:  178  	Training Loss: 0.0003976648731622845
Test Loss:  0.0004297688719816506
Valid Loss:  0.0005664530326612294
Epoch:  179  	Training Loss: 0.00039597530849277973
Test Loss:  0.00042825820855796337
Valid Loss:  0.0005645699566230178
Epoch:  180  	Training Loss: 0.0003942988987546414
Test Loss:  0.00042675630538724363
Valid Loss:  0.0005626968923024833
Epoch:  181  	Training Loss: 0.0003926357894670218
Test Loss:  0.0004252621438354254
Valid Loss:  0.0005608306382782757
Epoch:  182  	Training Loss: 0.0003909856895916164
Test Loss:  0.0004237776738591492
Valid Loss:  0.000558975269086659
Epoch:  183  	Training Loss: 0.0003893474058713764
Test Loss:  0.00042230001417919993
Valid Loss:  0.000557130086235702
Epoch:  184  	Training Loss: 0.0003877222479786724
Test Loss:  0.00042083056177943945
Valid Loss:  0.000555291713681072
Epoch:  185  	Training Loss: 0.00038610960473306477
Test Loss:  0.00041936920024454594
Valid Loss:  0.0005534623051062226
Epoch:  186  	Training Loss: 0.0003845090977847576
Test Loss:  0.0004179161915089935
Valid Loss:  0.0005516427336260676
Epoch:  187  	Training Loss: 0.00038292125100269914
Test Loss:  0.0004164705751463771
Valid Loss:  0.0005498315440490842
Epoch:  188  	Training Loss: 0.00038134472561068833
Test Loss:  0.00041503424290567636
Valid Loss:  0.0005480293766595423
Epoch:  189  	Training Loss: 0.0003797820536419749
Test Loss:  0.0004136055940762162
Valid Loss:  0.0005462359404191375
Epoch:  190  	Training Loss: 0.0003782306448556483
Test Loss:  0.00041218483238480985
Valid Loss:  0.0005444512935355306
Epoch:  191  	Training Loss: 0.0003766912268474698
Test Loss:  0.00041077189962379634
Valid Loss:  0.0005426773568615317
Epoch:  192  	Training Loss: 0.0003751638578251004
Test Loss:  0.0004093675233889371
Valid Loss:  0.0005409098230302334
Epoch:  193  	Training Loss: 0.00037364973104558885
Test Loss:  0.00040797225665301085
Valid Loss:  0.0005391523591242731
Epoch:  194  	Training Loss: 0.00037214712938293815
Test Loss:  0.0004065847606398165
Valid Loss:  0.0005374040920287371
Epoch:  195  	Training Loss: 0.0003706562565639615
Test Loss:  0.0004052039294037968
Valid Loss:  0.0005356644978746772
Epoch:  196  	Training Loss: 0.0003691766760312021
Test Loss:  0.00040383185842074454
Valid Loss:  0.0005339342169463634
Epoch:  197  	Training Loss: 0.0003677085041999817
Test Loss:  0.0004024682566523552
Valid Loss:  0.0005322144133970141
Epoch:  198  	Training Loss: 0.00036625127540901303
Test Loss:  0.0004011090495623648
Valid Loss:  0.0005305025260895491
Epoch:  199  	Training Loss: 0.000364806066500023
Test Loss:  0.00039976194966584444
Valid Loss:  0.0005287996609695256
Epoch:  200  	Training Loss: 0.00036337156780064106
Test Loss:  0.00039842238766141236
Valid Loss:  0.0005271064001135528
Epoch:  201  	Training Loss: 0.0003619475173763931
Test Loss:  0.0003970902180299163
Valid Loss:  0.0005254216375760734
Epoch:  202  	Training Loss: 0.00036053499206900597
Test Loss:  0.00039576238486915827
Valid Loss:  0.000523746944963932
Epoch:  203  	Training Loss: 0.00035913221654482186
Test Loss:  0.00039444625144824386
Valid Loss:  0.000522080110386014
Epoch:  204  	Training Loss: 0.0003577411116566509
Test Loss:  0.0003931365208700299
Valid Loss:  0.0005204227054491639
Epoch:  205  	Training Loss: 0.00035635969834402204
Test Loss:  0.0003918345319107175
Valid Loss:  0.00051877461373806
Epoch:  206  	Training Loss: 0.00035498931538313627
Test Loss:  0.0003905402263626456
Valid Loss:   41%|████▏     | 207/500 [02:23<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:24<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:30<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:30<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:30<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.23it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:37<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:37<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:37<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.22it/s] 46%|████▌     | 229/500 [02:37<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:44<05:21,  1.19s/it] 47%|████▋     | 233/500 [02:44<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:44<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:44<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:44<01:27,  2.97it/s] 48%|████▊     | 241/500 [02:51<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:51<03:38,  1.17it/s] 49%|████▉     | 245/500 [02:51<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:51<01:55,  2.18it/s] 50%|████▉     | 249/500 [02:51<01:26,  2.89it/s] 50%|█████     | 251/500 [02:58<04:57,  1.19s/it] 51%|█████     | 253/500 [02:58<03:31,  1.17it/s] 51%|█████     | 255/500 [02:58<02:31,  1.62it/s] 51%|█████▏    | 257/500 [02:58<01:49,  2.21it/s] 52%|█████▏    | 259/500 [02:58<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:04<04:40,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:05<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:05<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:05<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:11<04:30,  1.18s/it] 55%|█████▍    | 273/500 [03:11<03:12,  1.18it/s]0.0005171356024220586
Epoch:  207  	Training Loss: 0.00035362900234758854
Test Loss:  0.00038925372064113617
Valid Loss:  0.0005155046237632632
Epoch:  208  	Training Loss: 0.0003522795159369707
Test Loss:  0.00038797472370788455
Valid Loss:  0.0005138831329531968
Epoch:  209  	Training Loss: 0.00035094027407467365
Test Loss:  0.0003867025370709598
Valid Loss:  0.0005122707225382328
Epoch:  210  	Training Loss: 0.0003496110439300537
Test Loss:  0.000385439139790833
Valid Loss:  0.0005106677999719977
Epoch:  211  	Training Loss: 0.0003482916217762977
Test Loss:  0.00038418322219513357
Valid Loss:  0.0005090712802484632
Epoch:  212  	Training Loss: 0.00034698264789767563
Test Loss:  0.0003829345805570483
Valid Loss:  0.0005074844229966402
Epoch:  213  	Training Loss: 0.0003456815902609378
Test Loss:  0.0003816917887888849
Valid Loss:  0.0005059061804786325
Epoch:  214  	Training Loss: 0.00034439083538018167
Test Loss:  0.00038045691326260567
Valid Loss:  0.0005043370183557272
Epoch:  215  	Training Loss: 0.00034310948103666306
Test Loss:  0.0003792291972786188
Valid Loss:  0.0005027746083214879
Epoch:  216  	Training Loss: 0.00034183808020316064
Test Loss:  0.00037800948484800756
Valid Loss:  0.0005012218607589602
Epoch:  217  	Training Loss: 0.0003405759925954044
Test Loss:  0.0003767962916754186
Valid Loss:  0.0004996772622689605
Epoch:  218  	Training Loss: 0.00033932330552488565
Test Loss:  0.00037559025804512203
Valid Loss:  0.0004981428501196206
Epoch:  219  	Training Loss: 0.00033808033913373947
Test Loss:  0.00037439208244904876
Valid Loss:  0.0004966152482666075
Epoch:  220  	Training Loss: 0.00033684674417600036
Test Loss:  0.0003732020559255034
Valid Loss:  0.0004950962029397488
Epoch:  221  	Training Loss: 0.0003356226079631597
Test Loss:  0.00037201825762167573
Valid Loss:  0.0004935860633850098
Epoch:  222  	Training Loss: 0.0003344076103530824
Test Loss:  0.00037083771894685924
Valid Loss:  0.0004920844221487641
Epoch:  223  	Training Loss: 0.00033320247894153
Test Loss:  0.00036966888001188636
Valid Loss:  0.00049059116281569
Epoch:  224  	Training Loss: 0.0003320057294331491
Test Loss:  0.0003685063566081226
Valid Loss:  0.0004891069838777184
Epoch:  225  	Training Loss: 0.0003308188752271235
Test Loss:  0.0003673522442113608
Valid Loss:  0.00048762952792458236
Epoch:  226  	Training Loss: 0.0003296409558970481
Test Loss:  0.00036620409809984267
Valid Loss:  0.00048616164713166654
Epoch:  227  	Training Loss: 0.0003284718841314316
Test Loss:  0.00036506354808807373
Valid Loss:  0.00048470194451510906
Epoch:  228  	Training Loss: 0.00032731128158047795
Test Loss:  0.00036392902256920934
Valid Loss:  0.0004832501581404358
Epoch:  229  	Training Loss: 0.00032615926465950906
Test Loss:  0.0003628033446148038
Valid Loss:  0.000481807510368526
Epoch:  230  	Training Loss: 0.00032501653186045587
Test Loss:  0.00036168299266137183
Valid Loss:  0.00048037205124273896
Epoch:  231  	Training Loss: 0.00032388235558755696
Test Loss:  0.0003605693345889449
Valid Loss:  0.0004789441009052098
Epoch:  232  	Training Loss: 0.0003227556007914245
Test Loss:  0.000359462748747319
Valid Loss:  0.00047752505633980036
Epoch:  233  	Training Loss: 0.0003216377808712423
Test Loss:  0.0003583629440981895
Valid Loss:  0.0004761134332511574
Epoch:  234  	Training Loss: 0.00032052831375040114
Test Loss:  0.0003572713758330792
Valid Loss:  0.00047471062862314284
Epoch:  235  	Training Loss: 0.00031942673376761377
Test Loss:  0.00035618466790765524
Valid Loss:  0.0004733157984446734
Epoch:  236  	Training Loss: 0.0003183339722454548
Test Loss:  0.0003551048575900495
Valid Loss:  0.00047192838974297047
Epoch:  237  	Training Loss: 0.0003172491560690105
Test Loss:  0.0003540334291756153
Valid Loss:  0.00047054950846359134
Epoch:  238  	Training Loss: 0.00031617245986126363
Test Loss:  0.00035296770511195064
Valid Loss:  0.0004691781650763005
Epoch:  239  	Training Loss: 0.00031510466942563653
Test Loss:  0.00035190832568332553
Valid Loss:  0.00046781462151557207
Epoch:  240  	Training Loss: 0.0003140434855595231
Test Loss:  0.00035085552372038364
Valid Loss:  0.00046645954716950655
Epoch:  241  	Training Loss: 0.00031299085821956396
Test Loss:  0.0003498094156384468
Valid Loss:  0.00046511139953508973
Epoch:  242  	Training Loss: 0.00031194620532914996
Test Loss:  0.00034877180587500334
Valid Loss:  0.0004637704405467957
Epoch:  243  	Training Loss: 0.00031090975971892476
Test Loss:  0.0003477387654129416
Valid Loss:  0.0004624378925655037
Epoch:  244  	Training Loss: 0.00030988064827397466
Test Loss:  0.0003467125934548676
Valid Loss:  0.00046111279516480863
Epoch:  245  	Training Loss: 0.00030886015156283975
Test Loss:  0.0003456933773122728
Valid Loss:  0.0004597956140059978
Epoch:  246  	Training Loss: 0.00030784669797867537
Test Loss:  0.00034467995283193886
Valid Loss:  0.0004584863199852407
Epoch:  247  	Training Loss: 0.000306840956909582
Test Loss:  0.0003436731640249491
Valid Loss:  0.00045718459296040237
Epoch:  248  	Training Loss: 0.0003058427246287465
Test Loss:  0.00034267170121893287
Valid Loss:  0.0004558900836855173
Epoch:  249  	Training Loss: 0.00030485138995572925
Test Loss:  0.0003416772233322263
Valid Loss:  0.00045460311230272055
Epoch:  250  	Training Loss: 0.00030386800062842667
Test Loss:  0.00034068903187289834
Valid Loss:  0.0004533241444732994
Epoch:  251  	Training Loss: 0.0003028918581549078
Test Loss:  0.0003397069813217968
Valid Loss:  0.00045205303467810154
Epoch:  252  	Training Loss: 0.00030192307895049453
Test Loss:  0.0003387304022908211
Valid Loss:  0.0004507894045673311
Epoch:  253  	Training Loss: 0.0003009609936270863
Test Loss:  0.0003377614193595946
Valid Loss:  0.0004495327011682093
Epoch:  254  	Training Loss: 0.0003000066499225795
Test Loss:  0.00033679790794849396
Valid Loss:  0.00044828379759564996
Epoch:  255  	Training Loss: 0.00029905932024121284
Test Loss:  0.00033584045013412833
Valid Loss:  0.00044704106403514743
Epoch:  256  	Training Loss: 0.0002981188299600035
Test Loss:  0.0003348890459164977
Valid Loss:  0.00044580717803910375
Epoch:  257  	Training Loss: 0.0002971849753521383
Test Loss:  0.0003339442191645503
Valid Loss:  0.00044458062620833516
Epoch:  258  	Training Loss: 0.0002962587168440223
Test Loss:  0.0003330045146867633
Valid Loss:  0.00044335893471725285
Epoch:  259  	Training Loss: 0.0002953391522169113
Test Loss:  0.0003320714458823204
Valid Loss:  0.0004421461489982903
Epoch:  260  	Training Loss: 0.0002944262232631445
Test Loss:  0.0003311441105324775
Valid Loss:  0.000440940581029281
Epoch:  261  	Training Loss: 0.00029352004639804363
Test Loss:  0.00033022373099811375
Valid Loss:  0.00043974147411063313
Epoch:  262  	Training Loss: 0.0002926208544522524
Test Loss:  0.0003293081826996058
Valid Loss:  0.000438548915553838
Epoch:  263  	Training Loss: 0.00029172812355682254
Test Loss:  0.00032839851337485015
Valid Loss:  0.0004373629344627261
Epoch:  264  	Training Loss: 0.0002908419701270759
Test Loss:  0.00032749524689279497
Valid Loss:  0.00043618434574455023
Epoch:  265  	Training Loss: 0.000289962044917047
Test Loss:  0.000326597219100222
Valid Loss:  0.0004350133240222931
Epoch:  266  	Training Loss: 0.000289088930003345
Test Loss:  0.0003257041098549962
Valid Loss:  0.0004338484723120928
Epoch:  267  	Training Loss: 0.00028822250897064805
Test Loss:  0.00032481778180226684
Valid Loss:  0.00043269063462503254
Epoch:  268  	Training Loss: 0.00028736211243085563
Test Loss:  0.00032393771107308567
Valid Loss:  0.00043153943261131644
Epoch:  269  	Training Loss: 0.00028650814783759415
Test Loss:  0.00032306250068359077
Valid Loss:  0.0004303960013203323
Epoch:  270  	Training Loss: 0.0002856609062291682
Test Loss:  0.0003221927327103913
Valid Loss:  0.0004292588564567268
Epoch:  271  	Training Loss: 0.0002848200674634427
Test Loss:  0.00032132910564541817
Valid Loss:  0.0004281282890588045
Epoch:  272  	Training Loss: 0.0002839852240867913
Test Loss:  0.0003204696695320308
Valid Loss:  0.00042700525955297053
Epoch:  273  	Training Loss: 0.00028315637609921396
Test Loss:  0.000319617276545614
Valid Loss:  0.0004258879052940756
Epoch:  274  	Training Loss: 0.0002823335235007107
 55%|█████▌    | 275/500 [03:11<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:12<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:12<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:18<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:18<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:18<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:18<01:36,  2.22it/s] 58%|█████▊    | 289/500 [03:19<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:25<04:14,  1.22s/it] 59%|█████▊    | 293/500 [03:25<03:00,  1.15it/s] 59%|█████▉    | 295/500 [03:25<02:09,  1.59it/s] 59%|█████▉    | 297/500 [03:26<01:33,  2.17it/s] 60%|█████▉    | 299/500 [03:26<01:08,  2.93it/s] 60%|██████    | 301/500 [03:32<03:56,  1.19s/it] 61%|██████    | 303/500 [03:32<02:48,  1.17it/s] 61%|██████    | 305/500 [03:32<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:32<01:27,  2.22it/s] 62%|██████▏   | 309/500 [03:33<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:39<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:39<02:40,  1.16it/s] 63%|██████▎   | 315/500 [03:39<01:55,  1.61it/s] 63%|██████▎   | 317/500 [03:39<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:39<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:46<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:46<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:46<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:46<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:46<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:53<03:23,  1.21s/it] 67%|██████▋   | 333/500 [03:53<02:24,  1.16it/s] 67%|██████▋   | 335/500 [03:53<01:43,  1.60it/s] 67%|██████▋   | 337/500 [03:53<01:14,  2.19it/s] 68%|██████▊   | 339/500 [03:53<00:54,  2.95it/s] 68%|██████▊   | 341/500 [04:00<03:06,  1.17s/it]Test Loss:  0.0003187695983797312
Valid Loss:  0.0004247786127962172
Epoch:  275  	Training Loss: 0.00028151716105639935
Test Loss:  0.00031792817753739655
Valid Loss:  0.0004236739769112319
Epoch:  276  	Training Loss: 0.0002807065029628575
Test Loss:  0.00031709211179986596
Valid Loss:  0.00042257719906046987
Epoch:  277  	Training Loss: 0.00027990207308903337
Test Loss:  0.00031626096460968256
Valid Loss:  0.00042148653301410377
Epoch:  278  	Training Loss: 0.00027910369681194425
Test Loss:  0.0003154355799779296
Valid Loss:  0.0004204020369797945
Epoch:  279  	Training Loss: 0.0002783112577162683
Test Loss:  0.00031461584148928523
Valid Loss:  0.00041932493331842124
Epoch:  280  	Training Loss: 0.0002775242901407182
Test Loss:  0.00031380110885947943
Valid Loss:  0.000418253184761852
Epoch:  281  	Training Loss: 0.0002767437545116991
Test Loss:  0.0003129915567114949
Valid Loss:  0.0004171883629169315
Epoch:  282  	Training Loss: 0.0002759681665338576
Test Loss:  0.00031218730146065354
Valid Loss:  0.0004161300021223724
Epoch:  283  	Training Loss: 0.0002751991560216993
Test Loss:  0.00031138877966441214
Valid Loss:  0.0004150766762904823
Epoch:  284  	Training Loss: 0.0002744355006143451
Test Loss:  0.00031059564207680523
Valid Loss:  0.00041403158684261143
Epoch:  285  	Training Loss: 0.00027367781149223447
Test Loss:  0.00030980719020590186
Valid Loss:  0.00041299150325357914
Epoch:  286  	Training Loss: 0.00027292559389024973
Test Loss:  0.000309023424051702
Valid Loss:  0.0004119580262340605
Epoch:  287  	Training Loss: 0.0002721790806390345
Test Loss:  0.00030824547866359353
Valid Loss:  0.0004109303408768028
Epoch:  288  	Training Loss: 0.00027143731131218374
Test Loss:  0.0003074724809266627
Valid Loss:  0.0004099087091162801
Epoch:  289  	Training Loss: 0.0002707016537897289
Test Loss:  0.0003067044308409095
Valid Loss:  0.0004088932473678142
Epoch:  290  	Training Loss: 0.0002699713804759085
Test Loss:  0.00030594191048294306
Valid Loss:  0.0004078847705386579
Epoch:  291  	Training Loss: 0.0002692464040592313
Test Loss:  0.0003051841049455106
Valid Loss:  0.0004068815615028143
Epoch:  292  	Training Loss: 0.0002685277140699327
Test Loss:  0.00030443078139796853
Valid Loss:  0.0004058842023368925
Epoch:  293  	Training Loss: 0.0002678128075785935
Test Loss:  0.000303682463709265
Valid Loss:  0.000404893362428993
Epoch:  294  	Training Loss: 0.0002671036636456847
Test Loss:  0.0003029386862181127
Valid Loss:  0.00040390779031440616
Epoch:  295  	Training Loss: 0.0002663994091562927
Test Loss:  0.00030219994368962944
Valid Loss:  0.0004029286210425198
Epoch:  296  	Training Loss: 0.0002657006261870265
Test Loss:  0.00030146667268127203
Valid Loss:  0.00040195437031798065
Epoch:  297  	Training Loss: 0.0002650069654919207
Test Loss:  0.0003007380000781268
Valid Loss:  0.0004009866388514638
Epoch:  298  	Training Loss: 0.0002643184852786362
Test Loss:  0.00030001357663422823
Valid Loss:  0.0004000248445663601
Epoch:  299  	Training Loss: 0.00026363509823568165
Test Loss:  0.00029929468291811645
Valid Loss:  0.0003990682598669082
Epoch:  300  	Training Loss: 0.00026295686257071793
Test Loss:  0.00029858044581487775
Valid Loss:  0.00039811726310290396
Epoch:  301  	Training Loss: 0.00026228337083011866
Test Loss:  0.0002978712727781385
Valid Loss:  0.0003971724072471261
Epoch:  302  	Training Loss: 0.00026161514688283205
Test Loss:  0.00029716762946918607
Valid Loss:  0.00039623212069272995
Epoch:  303  	Training Loss: 0.0002609517832752317
Test Loss:  0.00029646727489307523
Valid Loss:  0.0003952984407078475
Epoch:  304  	Training Loss: 0.00026029342552646995
Test Loss:  0.0002957716933451593
Valid Loss:  0.00039436930092051625
Epoch:  305  	Training Loss: 0.0002596397534944117
Test Loss:  0.0002950803027488291
Valid Loss:  0.00039344668039120734
Epoch:  306  	Training Loss: 0.00025899114552885294
Test Loss:  0.00029439455829560757
Valid Loss:  0.0003925290366169065
Epoch:  307  	Training Loss: 0.00025834736879915
Test Loss:  0.0002937119279522449
Valid Loss:  0.00039161776658147573
Epoch:  308  	Training Loss: 0.00025770795764401555
Test Loss:  0.0002930350019596517
Valid Loss:  0.0003907110367435962
Epoch:  309  	Training Loss: 0.00025707404711283743
Test Loss:  0.0002923615975305438
Valid Loss:  0.00038981076795607805
Epoch:  310  	Training Loss: 0.0002564442402217537
Test Loss:  0.00029169319896027446
Valid Loss:  0.0003889153595082462
Epoch:  311  	Training Loss: 0.0002558193518780172
Test Loss:  0.0002910289913415909
Valid Loss:  0.0003880258300341666
Epoch:  312  	Training Loss: 0.0002551988582126796
Test Loss:  0.0002903664135374129
Valid Loss:  0.0003871404333040118
Epoch:  313  	Training Loss: 0.000254583457717672
Test Loss:  0.00028971099527552724
Valid Loss:  0.0003862630110234022
Epoch:  314  	Training Loss: 0.0002539724519010633
Test Loss:  0.0002890590112656355
Valid Loss:  0.00038538951775990427
Epoch:  315  	Training Loss: 0.000253365928074345
Test Loss:  0.000288412586087361
Valid Loss:  0.000384520273655653
Epoch:  316  	Training Loss: 0.000252763566095382
Test Loss:  0.00028776994440704584
Valid Loss:  0.00038365708314813673
Epoch:  317  	Training Loss: 0.00025216597714461386
Test Loss:  0.000287131464574486
Valid Loss:  0.0003827991022262722
Epoch:  318  	Training Loss: 0.00025157281197607517
Test Loss:  0.0002864977577701211
Valid Loss:  0.0003819464473053813
Epoch:  319  	Training Loss: 0.00025098404148593545
Test Loss:  0.00028586844564415514
Valid Loss:  0.00038109824527055025
Epoch:  320  	Training Loss: 0.0002503995783627033
Test Loss:  0.0002852418110705912
Valid Loss:  0.00038025560206733644
Epoch:  321  	Training Loss: 0.0002498195390217006
Test Loss:  0.0002846214920282364
Valid Loss:  0.0003794188960455358
Epoch:  322  	Training Loss: 0.00024924386525526643
Test Loss:  0.0002840039087459445
Valid Loss:  0.00037858571158722043
Epoch:  323  	Training Loss: 0.00024867200409062207
Test Loss:  0.00028339080745354295
Valid Loss:  0.00037775744567625225
Epoch:  324  	Training Loss: 0.00024810477043502033
Test Loss:  0.0002827817224897444
Valid Loss:  0.000376934593077749
Epoch:  325  	Training Loss: 0.000247541640419513
Test Loss:  0.0002821772068273276
Valid Loss:  0.0003761167754419148
Epoch:  326  	Training Loss: 0.0002469828468747437
Test Loss:  0.00028157589258626103
Valid Loss:  0.0003753039054572582
Epoch:  327  	Training Loss: 0.00024642818607389927
Test Loss:  0.000280979584204033
Valid Loss:  0.00037449627416208386
Epoch:  328  	Training Loss: 0.00024587727966718376
Test Loss:  0.00028038627351634204
Valid Loss:  0.00037369265919551253
Epoch:  329  	Training Loss: 0.00024533073883503675
Test Loss:  0.00027979788137599826
Valid Loss:  0.00037289471947588027
Epoch:  330  	Training Loss: 0.0002447882725391537
Test Loss:  0.0002792123705148697
Valid Loss:  0.0003721016983035952
Epoch:  331  	Training Loss: 0.00024424982257187366
Test Loss:  0.0002786315744742751
Valid Loss:  0.0003713126643560827
Epoch:  332  	Training Loss: 0.00024371524341404438
Test Loss:  0.00027805339777842164
Valid Loss:  0.00037052860716357827
Epoch:  333  	Training Loss: 0.00024318479700013995
Test Loss:  0.00027747961576096714
Valid Loss:  0.0003697489155456424
Epoch:  334  	Training Loss: 0.00024265795946121216
Test Loss:  0.00027691031573340297
Valid Loss:  0.0003689748118631542
Epoch:  335  	Training Loss: 0.0002421355457045138
Test Loss:  0.00027634421712718904
Valid Loss:  0.0003682043170556426
Epoch:  336  	Training Loss: 0.00024161655164789408
Test Loss:  0.0002757823676802218
Valid Loss:  0.0003674383042380214
Epoch:  337  	Training Loss: 0.00024110142840072513
Test Loss:  0.00027522395248524845
Valid Loss:  0.0003666779084596783
Epoch:  338  	Training Loss: 0.00024059023417066783
Test Loss:  0.0002746692334767431
Valid Loss:  0.0003659214125946164
Epoch:  339  	Training Loss: 0.00024008264881558716
Test Loss:  0.00027411835617385805
Valid Loss:  0.0003651697188615799
Epoch:  340  	Training Loss: 0.00023957921075634658
Test Loss:  0.000273571495199576
Valid Loss:  0.00036442201235331595
Epoch:  341  	Training Loss: 0.00023907907598186284
Test Loss:  0.0002730275155045092
Valid Loss:  0.0003636807086877525
 69%|██████▊   | 343/500 [04:00<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:00<01:34,  1.65it/s] 69%|██████▉   | 347/500 [04:00<01:08,  2.25it/s] 70%|██████▉   | 349/500 [04:00<00:49,  3.02it/s] 70%|███████   | 351/500 [04:06<02:56,  1.19s/it] 71%|███████   | 353/500 [04:07<02:05,  1.17it/s] 71%|███████   | 355/500 [04:07<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:07<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:07<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:13<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:14<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:14<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:14<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:14<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:20<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:20<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:20<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:21<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:21<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:27<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:27<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:27<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:27<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:28<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:34<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:34<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:34<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:34<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:34<00:33,  3.01it/s] 80%|████████  | 401/500 [04:41<01:57,  1.18s/it] 81%|████████  | 403/500 [04:41<01:22,  1.17it/s] 81%|████████  | 405/500 [04:41<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:41<00:41,  2.22it/s]Epoch:  342  	Training Loss: 0.00023858307395130396
Test Loss:  0.0002724870282690972
Valid Loss:  0.0003629421116784215
Epoch:  343  	Training Loss: 0.00023809008416719735
Test Loss:  0.0002719507901929319
Valid Loss:  0.0003622082294896245
Epoch:  344  	Training Loss: 0.00023760109615977854
Test Loss:  0.0002714180154725909
Valid Loss:  0.00036147981882095337
Epoch:  345  	Training Loss: 0.0002371155278524384
Test Loss:  0.000270888558588922
Valid Loss:  0.00036075463867746294
Epoch:  346  	Training Loss: 0.0002366335247643292
Test Loss:  0.0002703624777495861
Valid Loss:  0.00036003455170430243
Epoch:  347  	Training Loss: 0.00023615510144736618
Test Loss:  0.00026984047144651413
Valid Loss:  0.00035931781167164445
Epoch:  348  	Training Loss: 0.00023568022879771888
Test Loss:  0.0002693220158107579
Valid Loss:  0.0003586063103284687
Epoch:  349  	Training Loss: 0.00023520893591921777
Test Loss:  0.00026880670338869095
Valid Loss:  0.0003578987088985741
Epoch:  350  	Training Loss: 0.00023474075715057552
Test Loss:  0.00026830320712178946
Valid Loss:  0.00035720044979825616
Epoch:  351  	Training Loss: 0.000234276129049249
Test Loss:  0.00026778082246892154
Valid Loss:  0.00035650067729875445
Epoch:  352  	Training Loss: 0.00023381468781735748
Test Loss:  0.00026726897340267897
Valid Loss:  0.00035580521216616035
Epoch:  353  	Training Loss: 0.0002333560842089355
Test Loss:  0.00026675889967009425
Valid Loss:  0.00035511201713234186
Epoch:  354  	Training Loss: 0.00023290072567760944
Test Loss:  0.0002662533661350608
Valid Loss:  0.000354423769749701
Epoch:  355  	Training Loss: 0.00023244910698849708
Test Loss:  0.0002657515578903258
Valid Loss:  0.0003537381999194622
Epoch:  356  	Training Loss: 0.0002320005587534979
Test Loss:  0.00026525353314355016
Valid Loss:  0.0003530564717948437
Epoch:  357  	Training Loss: 0.00023155553208198398
Test Loss:  0.00026475940831005573
Valid Loss:  0.00035237998235970736
Epoch:  358  	Training Loss: 0.0002311139542143792
Test Loss:  0.00026426822296343744
Valid Loss:  0.0003517058794386685
Epoch:  359  	Training Loss: 0.00023067541769705713
Test Loss:  0.0002637809666339308
Valid Loss:  0.0003510356764309108
Epoch:  360  	Training Loss: 0.00023023996618576348
Test Loss:  0.00026329740649089217
Valid Loss:  0.0003503698972053826
Epoch:  361  	Training Loss: 0.0002298078907188028
Test Loss:  0.00026281693135388196
Valid Loss:  0.0003497073194012046
Epoch:  362  	Training Loss: 0.00022937898756936193
Test Loss:  0.00026233922108076513
Valid Loss:  0.0003490495146252215
Epoch:  363  	Training Loss: 0.00022895402798894793
Test Loss:  0.00026186651666648686
Valid Loss:  0.0003483964246697724
Epoch:  364  	Training Loss: 0.00022853183327242732
Test Loss:  0.0002613959659356624
Valid Loss:  0.00034774543019011617
Epoch:  365  	Training Loss: 0.0002281131164636463
Test Loss:  0.0002609288494568318
Valid Loss:  0.000347099092323333
Epoch:  366  	Training Loss: 0.00022769731003791094
Test Loss:  0.0002604651381261647
Valid Loss:  0.0003464572655502707
Epoch:  367  	Training Loss: 0.00022728450130671263
Test Loss:  0.00026000436628237367
Valid Loss:  0.00034581852378323674
Epoch:  368  	Training Loss: 0.00022687495220452547
Test Loss:  0.0002595463884063065
Valid Loss:  0.0003451835655141622
Epoch:  369  	Training Loss: 0.0002264679642394185
Test Loss:  0.0002590921358205378
Valid Loss:  0.000344552710885182
Epoch:  370  	Training Loss: 0.00022606417769566178
Test Loss:  0.00025864082272164524
Valid Loss:  0.00034392616362310946
Epoch:  371  	Training Loss: 0.00022566347615793347
Test Loss:  0.0002581923035904765
Valid Loss:  0.000343303254339844
Epoch:  372  	Training Loss: 0.00022526585962623358
Test Loss:  0.00025774596724659204
Valid Loss:  0.00034268401213921607
Epoch:  373  	Training Loss: 0.00022487074602395296
Test Loss:  0.00025730309425853193
Valid Loss:  0.00034206948475912213
Epoch:  374  	Training Loss: 0.00022447857190854847
Test Loss:  0.0002568629279267043
Valid Loss:  0.0003414577804505825
Epoch:  375  	Training Loss: 0.00022408923541661352
Test Loss:  0.0002564263704698533
Valid Loss:  0.0003408497432246804
Epoch:  376  	Training Loss: 0.0002237029402749613
Test Loss:  0.00025599286891520023
Valid Loss:  0.0003402457805350423
Epoch:  377  	Training Loss: 0.00022331965737976134
Test Loss:  0.00025556187028996646
Valid Loss:  0.0003396450192667544
Epoch:  378  	Training Loss: 0.0002229388919658959
Test Loss:  0.00025513465516269207
Valid Loss:  0.0003390485071577132
Epoch:  379  	Training Loss: 0.00022256100783124566
Test Loss:  0.00025470979744568467
Valid Loss:  0.0003384537703823298
Epoch:  380  	Training Loss: 0.0002221858303528279
Test Loss:  0.0002542878792155534
Valid Loss:  0.0003378637775313109
Epoch:  381  	Training Loss: 0.00022181309759616852
Test Loss:  0.00025387562345713377
Valid Loss:  0.0003372826031409204
Epoch:  382  	Training Loss: 0.00022144196555018425
Test Loss:  0.0002534470986574888
Valid Loss:  0.0003366984601598233
Epoch:  383  	Training Loss: 0.00022107415134087205
Test Loss:  0.00025302491849288344
Valid Loss:  0.0003361176932230592
Epoch:  384  	Training Loss: 0.0002207087236456573
Test Loss:  0.0002526052121538669
Valid Loss:  0.00033553954563103616
Epoch:  385  	Training Loss: 0.00022034611902199686
Test Loss:  0.0002521894930396229
Valid Loss:  0.0003349638427607715
Epoch:  386  	Training Loss: 0.0002199859154643491
Test Loss:  0.0002517772081773728
Valid Loss:  0.0003343920106999576
Epoch:  387  	Training Loss: 0.00021962802566122264
Test Loss:  0.00025137484772130847
Valid Loss:  0.0003338295500725508
Epoch:  388  	Training Loss: 0.00021927124180365354
Test Loss:  0.0002509595069568604
Valid Loss:  0.000333267729729414
Epoch:  389  	Training Loss: 0.00021891403594054282
Test Loss:  0.0002505320589989424
Valid Loss:  0.0003327034937683493
Epoch:  390  	Training Loss: 0.000218559755012393
Test Loss:  0.0002501119743101299
Valid Loss:  0.0003321426338516176
Epoch:  391  	Training Loss: 0.00021820797701366246
Test Loss:  0.00024969648802652955
Valid Loss:  0.00033158331643790007
Epoch:  392  	Training Loss: 0.00021785852732136846
Test Loss:  0.0002492831845302135
Valid Loss:  0.00033102594898082316
Epoch:  393  	Training Loss: 0.0002175106928916648
Test Loss:  0.0002488825120963156
Valid Loss:  0.0003304776328150183
Epoch:  394  	Training Loss: 0.0002171627274947241
Test Loss:  0.00024846228188835084
Valid Loss:  0.00032992594060488045
Epoch:  395  	Training Loss: 0.00021681751240976155
Test Loss:  0.00024805881548672915
Valid Loss:  0.0003293826011940837
Epoch:  396  	Training Loss: 0.0002164706529583782
Test Loss:  0.00024763576220721006
Valid Loss:  0.000328834488755092
Epoch:  397  	Training Loss: 0.0002161261800210923
Test Loss:  0.0002472223713994026
Valid Loss:  0.00032828914117999375
Epoch:  398  	Training Loss: 0.00021578399173449725
Test Loss:  0.00024681229842826724
Valid Loss:  0.00032774516148492694
Epoch:  399  	Training Loss: 0.00021544386981986463
Test Loss:  0.00024640641640871763
Valid Loss:  0.00032720426679588854
Epoch:  400  	Training Loss: 0.00021510622173082083
Test Loss:  0.00024600489996373653
Valid Loss:  0.0003266652929596603
Epoch:  401  	Training Loss: 0.0002147707127733156
Test Loss:  0.00024560626479797065
Valid Loss:  0.00032612873474135995
Epoch:  402  	Training Loss: 0.00021443754667416215
Test Loss:  0.0002452100161463022
Valid Loss:  0.00032559840474277735
Epoch:  403  	Training Loss: 0.00021410647605080158
Test Loss:  0.00024481816217303276
Valid Loss:  0.0003250695299357176
Epoch:  404  	Training Loss: 0.00021377767552621663
Test Loss:  0.00024442910216748714
Valid Loss:  0.0003245440311729908
Epoch:  405  	Training Loss: 0.0002134510432370007
Test Loss:  0.00024404280702583492
Valid Loss:  0.00032402033684775233
Epoch:  406  	Training Loss: 0.00021312653552740812
Test Loss:  0.00024365994613617659
Valid Loss:  0.00032349955290555954
Epoch:  407  	Training Loss: 0.00021280425426084548
Test Loss:  0.00024328107247129083
Valid Loss:  0.00032298231963068247
Epoch:  408  	Training Loss: 0.00021248418488539755
Test Loss:  0.00024290275177918375
Valid Loss:  0.00032246753107756376
 82%|████████▏ | 409/500 [04:41<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:48<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:48<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:48<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:48<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:48<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:54<01:33,  1.19s/it] 85%|████████▍ | 423/500 [04:55<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:55<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:55<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:55<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:01<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:01<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:02<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:02<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:02<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:08<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:08<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:09<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:09<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:15<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:15<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:15<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:16<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:16<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:22<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:22<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:22<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:23<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:29<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:29<00:22,  1.17it/s] 95%|█████████▌| 475/500 [05:29<00:15,  1.62it/s]Epoch:  409  	Training Loss: 0.00021216599270701408
Test Loss:  0.00024252798175439239
Valid Loss:  0.00032195437233895063
Epoch:  410  	Training Loss: 0.00021184983779676259
Test Loss:  0.00024216147721745074
Valid Loss:  0.0003214510506950319
Epoch:  411  	Training Loss: 0.00021153147099539638
Test Loss:  0.00024177772866096348
Valid Loss:  0.00032094286871142685
Epoch:  412  	Training Loss: 0.000211215578019619
Test Loss:  0.0002413995680399239
Valid Loss:  0.000320439605275169
Epoch:  413  	Training Loss: 0.00021090228983666748
Test Loss:  0.00024102663155645132
Valid Loss:  0.00031994047458283603
Epoch:  414  	Training Loss: 0.00021059089340269566
Test Loss:  0.00024065631441771984
Valid Loss:  0.00031944303191266954
Epoch:  415  	Training Loss: 0.00021028154878877103
Test Loss:  0.00024028874759096652
Valid Loss:  0.0003189476556144655
Epoch:  416  	Training Loss: 0.00020997392130084336
Test Loss:  0.0002399237419012934
Valid Loss:  0.0003184548986610025
Epoch:  417  	Training Loss: 0.00020966838928870857
Test Loss:  0.00023956107906997204
Valid Loss:  0.0003179636551067233
Epoch:  418  	Training Loss: 0.000209364719921723
Test Loss:  0.000239206783589907
Valid Loss:  0.00031748099718242884
Epoch:  419  	Training Loss: 0.0002090579946525395
Test Loss:  0.00023884074471425265
Valid Loss:  0.00031699842656962574
Epoch:  420  	Training Loss: 0.00020874844631180167
Test Loss:  0.0002384636172791943
Valid Loss:  0.0003165136440657079
Epoch:  421  	Training Loss: 0.00020844084792770445
Test Loss:  0.00023809209233149886
Valid Loss:  0.0003160304040648043
Epoch:  422  	Training Loss: 0.00020813485025428236
Test Loss:  0.0002377241471549496
Valid Loss:  0.0003155510639771819
Epoch:  423  	Training Loss: 0.00020783106447197497
Test Loss:  0.00023736034927424043
Valid Loss:  0.0003150741395074874
Epoch:  424  	Training Loss: 0.00020752681302838027
Test Loss:  0.0002370022120885551
Valid Loss:  0.0003146028029732406
Epoch:  425  	Training Loss: 0.00020722122280858457
Test Loss:  0.0002366303524468094
Valid Loss:  0.0003141192137263715
Epoch:  426  	Training Loss: 0.00020691732061095536
Test Loss:  0.00023626515758223832
Valid Loss:  0.0003136366722173989
Epoch:  427  	Training Loss: 0.00020661532471422106
Test Loss:  0.00023590290220454335
Valid Loss:  0.0003131544799543917
Epoch:  428  	Training Loss: 0.00020631306688301265
Test Loss:  0.00023554770450573415
Valid Loss:  0.0003126785159111023
Epoch:  429  	Training Loss: 0.00020600800053216517
Test Loss:  0.00023518216039519757
Valid Loss:  0.00031220150412991643
Epoch:  430  	Training Loss: 0.00020570002379827201
Test Loss:  0.0002348070265725255
Valid Loss:  0.00031172181479632854
Epoch:  431  	Training Loss: 0.0002053930948022753
Test Loss:  0.00023444168618880212
Valid Loss:  0.00031124678207561374
Epoch:  432  	Training Loss: 0.00020508182933554053
Test Loss:  0.00023406156105920672
Valid Loss:  0.0003107618831563741
Epoch:  433  	Training Loss: 0.00020476887584663928
Test Loss:  0.00023369560949504375
Valid Loss:  0.00031027902150526643
Epoch:  434  	Training Loss: 0.00020444855908863246
Test Loss:  0.00023330101976171136
Valid Loss:  0.0003097856533713639
Epoch:  435  	Training Loss: 0.00020412961021065712
Test Loss:  0.00023291673278436065
Valid Loss:  0.00030929531203582883
Epoch:  436  	Training Loss: 0.00020381182548590004
Test Loss:  0.00023253561812452972
Valid Loss:  0.0003088055527769029
Epoch:  437  	Training Loss: 0.0002034956414718181
Test Loss:  0.0002321570209460333
Valid Loss:  0.0003083162591792643
Epoch:  438  	Training Loss: 0.0002031810290645808
Test Loss:  0.0002317814651178196
Valid Loss:  0.0003078291774727404
Epoch:  439  	Training Loss: 0.0002028676390182227
Test Loss:  0.00023140796110965312
Valid Loss:  0.00030734323081560433
Epoch:  440  	Training Loss: 0.00020255529670976102
Test Loss:  0.0002310371637577191
Valid Loss:  0.0003068582445848733
Epoch:  441  	Training Loss: 0.00020224493346177042
Test Loss:  0.00023066895664669573
Valid Loss:  0.00030637512099929154
Epoch:  442  	Training Loss: 0.0002019358944380656
Test Loss:  0.00023030335432849824
Valid Loss:  0.00030589516973122954
Epoch:  443  	Training Loss: 0.00020162848522886634
Test Loss:  0.00022993990569375455
Valid Loss:  0.0003054164117202163
Epoch:  444  	Training Loss: 0.00020132286590524018
Test Loss:  0.00022957808687351644
Valid Loss:  0.00030493992380797863
Epoch:  445  	Training Loss: 0.00020101809059269726
Test Loss:  0.00022921795607544482
Valid Loss:  0.0003044635523110628
Epoch:  446  	Training Loss: 0.00020071485778316855
Test Loss:  0.0002288607502123341
Valid Loss:  0.0003039901203010231
Epoch:  447  	Training Loss: 0.00020041153766214848
Test Loss:  0.00022850692039355636
Valid Loss:  0.0003035200643353164
Epoch:  448  	Training Loss: 0.0002001061657210812
Test Loss:  0.0002281430788571015
Valid Loss:  0.0003030472726095468
Epoch:  449  	Training Loss: 0.0001998020161408931
Test Loss:  0.00022778339916840196
Valid Loss:  0.0003025764599442482
Epoch:  450  	Training Loss: 0.0001994985796045512
Test Loss:  0.00022742757573723793
Valid Loss:  0.00030210884870029986
Epoch:  451  	Training Loss: 0.00019919167971238494
Test Loss:  0.0002270643599331379
Valid Loss:  0.0003016407135874033
Epoch:  452  	Training Loss: 0.00019888259703293443
Test Loss:  0.00022669776808470488
Valid Loss:  0.0003011719963978976
Epoch:  453  	Training Loss: 0.00019857409643009305
Test Loss:  0.0002263333590235561
Valid Loss:  0.00030070554930716753
Epoch:  454  	Training Loss: 0.00019826216157525778
Test Loss:  0.00022596365306526423
Valid Loss:  0.0003002370649483055
Epoch:  455  	Training Loss: 0.00019794846593867987
Test Loss:  0.00022558128694072366
Valid Loss:  0.0002997674746438861
Epoch:  456  	Training Loss: 0.00019763594900723547
Test Loss:  0.00022519745107274503
Valid Loss:  0.0002992999507114291
Epoch:  457  	Training Loss: 0.0001973239704966545
Test Loss:  0.0002248153614345938
Valid Loss:  0.0002988339401781559
Epoch:  458  	Training Loss: 0.00019701028941199183
Test Loss:  0.00022442667977884412
Valid Loss:  0.00029836647445335984
Epoch:  459  	Training Loss: 0.0001966969430213794
Test Loss:  0.00022404109768103808
Valid Loss:  0.0002979006676468998
Epoch:  460  	Training Loss: 0.00019638505182228982
Test Loss:  0.00022365675249602646
Valid Loss:  0.00029743509367108345
Epoch:  461  	Training Loss: 0.0001960743247764185
Test Loss:  0.00022327466285787523
Valid Loss:  0.00029697094578295946
Epoch:  462  	Training Loss: 0.00019576295744627714
Test Loss:  0.0002228960074717179
Valid Loss:  0.00029650935903191566
Epoch:  463  	Training Loss: 0.0001954479666892439
Test Loss:  0.00022250341135077178
Valid Loss:  0.0002960436977446079
Epoch:  464  	Training Loss: 0.00019513412553351372
Test Loss:  0.00022211659234017134
Valid Loss:  0.00029558068490587175
Epoch:  465  	Training Loss: 0.0001948190911207348
Test Loss:  0.00022172422904986888
Valid Loss:  0.00029511633329093456
Epoch:  466  	Training Loss: 0.00019450497347861528
Test Loss:  0.0002213320112787187
Valid Loss:  0.00029465253464877605
Epoch:  467  	Training Loss: 0.0001941918017109856
Test Loss:  0.0002209389058407396
Valid Loss:  0.0002941911807283759
Epoch:  468  	Training Loss: 0.00019387988140806556
Test Loss:  0.00022054737200960517
Valid Loss:  0.0002937300014309585
Epoch:  469  	Training Loss: 0.00019356879056431353
Test Loss:  0.0002201569441240281
Valid Loss:  0.0002932697534561157
Epoch:  470  	Training Loss: 0.00019325832545291632
Test Loss:  0.00021976676362100989
Valid Loss:  0.00029281125171110034
Epoch:  471  	Training Loss: 0.00019294815137982368
Test Loss:  0.00021937579731456935
Valid Loss:  0.00029235263355076313
Epoch:  472  	Training Loss: 0.00019263866124674678
Test Loss:  0.0002189889783039689
Valid Loss:  0.0002918956452049315
Epoch:  473  	Training Loss: 0.0001923299569170922
Test Loss:  0.00021859924891032279
Valid Loss:  0.0002914387732744217
Epoch:  474  	Training Loss: 0.00019202263501938432
Test Loss:  0.00021821088739670813
Valid Loss:  0.0002909833565354347
Epoch:  475  	Training Loss: 0.0001917159534059465
Test Loss:  0.00021782302064821124
Valid Loss:  0.00029052828904241323
 95%|█████████▌| 477/500 [05:29<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:29<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:36<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:36<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:36<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:36<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:36<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:43<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:43<00:06,  1.17it/s] 99%|█████████▉| 495/500 [05:43<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:43<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:43<00:00,  2.96it/s]100%|██████████| 500/500 [05:43<00:00,  1.45it/s]
Epoch:  476  	Training Loss: 0.00019141045049764216
Test Loss:  0.00021743583783973008
Valid Loss:  0.0002900752588175237
Epoch:  477  	Training Loss: 0.00019110587891191244
Test Loss:  0.00021704986284021288
Valid Loss:  0.000289622024865821
Epoch:  478  	Training Loss: 0.0001908018020913005
Test Loss:  0.00021666541579179466
Valid Loss:  0.000289170682663098
Epoch:  479  	Training Loss: 0.00019049890397582203
Test Loss:  0.00021628043032251298
Valid Loss:  0.00028872030088678
Epoch:  480  	Training Loss: 0.00019019711180590093
Test Loss:  0.00021589611424133182
Valid Loss:  0.00028826965717598796
Epoch:  481  	Training Loss: 0.00018989594536833465
Test Loss:  0.00021551238023675978
Valid Loss:  0.0002878208179026842
Epoch:  482  	Training Loss: 0.00018959629232995212
Test Loss:  0.00021513234241865575
Valid Loss:  0.0002873733756132424
Epoch:  483  	Training Loss: 0.00018929794896394014
Test Loss:  0.00021474994719028473
Valid Loss:  0.00028692622436210513
Epoch:  484  	Training Loss: 0.0001890003477456048
Test Loss:  0.0002143686724593863
Valid Loss:  0.00028648111037909985
Epoch:  485  	Training Loss: 0.00018870364874601364
Test Loss:  0.00021398646640591323
Valid Loss:  0.00028603471582755446
Epoch:  486  	Training Loss: 0.00018840905977413058
Test Loss:  0.00021360685059335083
Valid Loss:  0.00028559117345139384
Epoch:  487  	Training Loss: 0.00018811508198268712
Test Loss:  0.00021322682732716203
Valid Loss:  0.00028514856239780784
Epoch:  488  	Training Loss: 0.0001878218026831746
Test Loss:  0.00021284783724695444
Valid Loss:  0.0002847062423825264
Epoch:  489  	Training Loss: 0.0001875306770671159
Test Loss:  0.00021246596588753164
Valid Loss:  0.0002842639514710754
Epoch:  490  	Training Loss: 0.00018724329129327089
Test Loss:  0.00021208907128311694
Valid Loss:  0.00028382387245073915
Epoch:  491  	Training Loss: 0.00018695779726840556
Test Loss:  0.00021171309344936162
Valid Loss:  0.00028338644187897444
Epoch:  492  	Training Loss: 0.0001866731618065387
Test Loss:  0.0002113396185450256
Valid Loss:  0.0002829501172527671
Epoch:  493  	Training Loss: 0.0001863889629021287
Test Loss:  0.0002109693450620398
Valid Loss:  0.0002825140254572034
Epoch:  494  	Training Loss: 0.0001861056371126324
Test Loss:  0.0002106094907503575
Valid Loss:  0.0002820789522957057
Epoch:  495  	Training Loss: 0.00018582315533421934
Test Loss:  0.00021024902525823563
Valid Loss:  0.00028164597461000085
Epoch:  496  	Training Loss: 0.00018554105190560222
Test Loss:  0.0002098893455695361
Valid Loss:  0.00028121823561377823
Epoch:  497  	Training Loss: 0.00018525967607274652
Test Loss:  0.00020953570492565632
Valid Loss:  0.0002807907003443688
Epoch:  498  	Training Loss: 0.0001849792170105502
Test Loss:  0.00020918257359880954
Valid Loss:  0.0002803655224852264
Epoch:  499  	Training Loss: 0.00018469910719431937
Test Loss:  0.00020882958779111505
Valid Loss:  0.0002799401991069317
Epoch:  500  	Training Loss: 0.0001844201033236459
Test Loss:  0.00020848275744356215
Valid Loss:  0.00027951551601290703
seed is  7
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:07,  6.27s/it]  1%|          | 3/500 [00:06<13:52,  1.68s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:34,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:32<16:29,  2.11s/it]  7%|▋         | 33/500 [00:33<11:39,  1.50s/it]  7%|▋         | 35/500 [00:33<08:15,  1.07s/it]  7%|▋         | 37/500 [00:33<05:54,  1.31it/s]  8%|▊         | 39/500 [00:33<04:16,  1.80it/s]  8%|▊         | 41/500 [00:46<17:29,  2.29s/it]  9%|▊         | 43/500 [00:46<12:22,  1.62s/it]  9%|▉         | 45/500 [00:52<15:51,  2.09s/it]  9%|▉         | 47/500 [00:52<11:12,  1.49s/it] 10%|▉         | 49/500 [00:52<07:58,  1.06s/it] 10%|█         | 51/500 [01:05<19:41,  2.63s/it] 11%|█         | 53/500 [01:05<13:53,  1.87s/it] 11%|█         | 55/500 [01:12<17:00,  2.29s/it] 11%|█▏        | 57/500 [01:12<12:00,  1.63s/it] 12%|█▏        | 59/500 [01:12<08:30,  1.16s/it] 12%|█▏        | 61/500 [01:25<19:45,  2.70s/it] 13%|█▎        | 63/500 [01:25<13:55,  1.91s/it] 13%|█▎        | 65/500 [01:31<16:45,  2.31s/it]Epoch:  1  	Training Loss: 0.2261407971382141
Test Loss:  0.4596109986305237
Valid Loss:  0.4642670154571533
Epoch:  2  	Training Loss: 0.5604863166809082
Test Loss:  0.28701096773147583
Valid Loss:  0.2741992473602295
Epoch:  3  	Training Loss: 0.22220908105373383
Test Loss:  0.28701093792915344
Valid Loss:  0.2741992473602295
Epoch:  4  	Training Loss: 0.22220908105373383
Test Loss:  0.28701093792915344
Valid Loss:  0.2741992175579071
Epoch:  5  	Training Loss: 0.22220905125141144
Test Loss:  0.28701090812683105
Valid Loss:  0.2741991877555847
Epoch:  6  	Training Loss: 0.22220905125141144
Test Loss:  0.28701087832450867
Valid Loss:  0.2741991877555847
Epoch:  7  	Training Loss: 0.22220903635025024
Test Loss:  0.28701090812683105
Valid Loss:  0.27419915795326233
Epoch:  8  	Training Loss: 0.22220903635025024
Test Loss:  0.2870108485221863
Valid Loss:  0.2741991877555847
Epoch:  9  	Training Loss: 0.22220902144908905
Test Loss:  0.2870108485221863
Valid Loss:  0.27419912815093994
Epoch:  10  	Training Loss: 0.22220900654792786
Test Loss:  0.2870108485221863
Valid Loss:  0.27419912815093994
Epoch:  11  	Training Loss: 0.22220900654792786
Test Loss:  0.2870108187198639
Valid Loss:  0.27419912815093994
Epoch:  12  	Training Loss: 0.22220900654792786
Test Loss:  0.2870107889175415
Valid Loss:  0.27419909834861755
Epoch:  13  	Training Loss: 0.22220897674560547
Test Loss:  0.2870107889175415
Valid Loss:  0.27419906854629517
Epoch:  14  	Training Loss: 0.22220896184444427
Test Loss:  0.2870107889175415
Valid Loss:  0.2741990387439728
Epoch:  15  	Training Loss: 0.22220894694328308
Test Loss:  0.2870107889175415
Valid Loss:  0.2741990089416504
Epoch:  16  	Training Loss: 0.2222089320421219
Test Loss:  0.28701072931289673
Valid Loss:  0.2741990089416504
Epoch:  17  	Training Loss: 0.2222089171409607
Test Loss:  0.28701072931289673
Valid Loss:  0.2741990089416504
Epoch:  18  	Training Loss: 0.2222088873386383
Test Loss:  0.28701069951057434
Valid Loss:  0.2741989493370056
Epoch:  19  	Training Loss: 0.2222088873386383
Test Loss:  0.28701066970825195
Valid Loss:  0.2741989493370056
Epoch:  20  	Training Loss: 0.2222088724374771
Test Loss:  0.28701066970825195
Valid Loss:  0.2741989493370056
Epoch:  21  	Training Loss: 0.22220885753631592
Test Loss:  0.2870106101036072
Valid Loss:  0.27419888973236084
Epoch:  22  	Training Loss: 0.22220884263515472
Test Loss:  0.2870106101036072
Valid Loss:  0.27419888973236084
Epoch:  23  	Training Loss: 0.22220882773399353
Test Loss:  0.2870106101036072
Valid Loss:  0.27419888973236084
Epoch:  24  	Training Loss: 0.22220879793167114
Test Loss:  0.2870105504989624
Valid Loss:  0.27419883012771606
Epoch:  25  	Training Loss: 0.22220878303050995
Test Loss:  0.2870105504989624
Valid Loss:  0.27419883012771606
Epoch:  26  	Training Loss: 0.22220879793167114
Test Loss:  0.28701052069664
Valid Loss:  0.27419883012771606
Epoch:  27  	Training Loss: 0.22220876812934875
Test Loss:  0.2870104908943176
Valid Loss:  0.2741987705230713
Epoch:  28  	Training Loss: 0.22220875322818756
Test Loss:  0.2870104908943176
Valid Loss:  0.2741987705230713
Epoch:  29  	Training Loss: 0.22220872342586517
Test Loss:  0.28701046109199524
Valid Loss:  0.2741987407207489
Epoch:  30  	Training Loss: 0.22220870852470398
Test Loss:  0.28701043128967285
Valid Loss:  0.2741987109184265
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.22220870852470398
Test Loss:  0.28701043128967285
Valid Loss:  0.2741987109184265
Epoch:  32  	Training Loss: 0.22220869362354279
Test Loss:  0.28701043128967285
Valid Loss:  0.2741987109184265
Epoch:  33  	Training Loss: 0.22220869362354279
Test Loss:  0.28701043128967285
Valid Loss:  0.2741986811161041
Epoch:  34  	Training Loss: 0.2222086787223816
Test Loss:  0.28701040148735046
Valid Loss:  0.27419865131378174
Epoch:  35  	Training Loss: 0.2222086638212204
Test Loss:  0.2870103716850281
Valid Loss:  0.27419865131378174
Epoch:  36  	Training Loss: 0.2222086638212204
Test Loss:  0.28701040148735046
Valid Loss:  0.27419865131378174
Epoch:  37  	Training Loss: 0.2222086489200592
Test Loss:  0.2870103716850281
Valid Loss:  0.27419862151145935
Epoch:  38  	Training Loss: 0.222208634018898
Test Loss:  0.2870103716850281
Valid Loss:  0.27419862151145935
Epoch:  39  	Training Loss: 0.2222086489200592
Test Loss:  0.2870103716850281
Valid Loss:  0.27419862151145935
Epoch:  40  	Training Loss: 0.22220861911773682
Test Loss:  0.2870103418827057
Valid Loss:  0.27419859170913696
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.22220861911773682
Test Loss:  0.2870103418827057
Valid Loss:  0.27419859170913696
Epoch:  42  	Training Loss: 0.22220860421657562
Test Loss:  0.2870103120803833
Valid Loss:  0.27419859170913696
Epoch:  43  	Training Loss: 0.22220861911773682
Test Loss:  0.2870103418827057
Valid Loss:  0.27419859170913696
Epoch:  44  	Training Loss: 0.22220861911773682
Test Loss:  0.2870103120803833
Valid Loss:  0.27419859170913696
Epoch:  45  	Training Loss: 0.22220861911773682
Test Loss:  0.2870103418827057
Valid Loss:  0.27419859170913696
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.27419859170913696
Epoch:  47  	Training Loss: 0.22220860421657562
Test Loss:  0.2870103120803833
Valid Loss:  0.27419859170913696
Epoch:  48  	Training Loss: 0.22220860421657562
Test Loss:  0.2870103120803833
Valid Loss:  0.27419859170913696
Epoch:  49  	Training Loss: 0.22220860421657562
Test Loss:  0.2870103120803833
Valid Loss:  0.27419859170913696
Epoch:  50  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.27419859170913696
Epoch:  52  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  53  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  54  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  55  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  57  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  58  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  59  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  60  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  62  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  63  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  64  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  65  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
 13%|█▎        | 67/500 [01:31<11:49,  1.64s/it] 14%|█▍        | 69/500 [01:31<08:22,  1.17s/it] 14%|█▍        | 71/500 [01:44<19:17,  2.70s/it] 15%|█▍        | 73/500 [01:44<13:36,  1.91s/it] 15%|█▌        | 75/500 [01:51<16:18,  2.30s/it] 15%|█▌        | 77/500 [01:51<11:31,  1.63s/it] 16%|█▌        | 79/500 [01:51<08:09,  1.16s/it] 16%|█▌        | 81/500 [02:04<19:09,  2.74s/it] 17%|█▋        | 83/500 [02:04<13:29,  1.94s/it] 17%|█▋        | 85/500 [02:10<16:07,  2.33s/it] 17%|█▋        | 87/500 [02:11<11:22,  1.65s/it] 18%|█▊        | 89/500 [02:11<08:03,  1.18s/it] 18%|█▊        | 91/500 [02:24<18:46,  2.75s/it] 19%|█▊        | 93/500 [02:24<13:13,  1.95s/it] 19%|█▉        | 95/500 [02:30<15:53,  2.36s/it] 19%|█▉        | 97/500 [02:30<11:12,  1.67s/it] 20%|█▉        | 99/500 [02:31<07:56,  1.19s/it] 20%|██        | 101/500 [02:43<18:05,  2.72s/it] 21%|██        | 103/500 [02:43<12:44,  1.93s/it] 21%|██        | 105/500 [02:50<15:02,  2.28s/it] 21%|██▏       | 107/500 [02:50<10:36,  1.62s/it] 22%|██▏       | 109/500 [02:50<07:31,  1.15s/it] 22%|██▏       | 109/500 [03:00<07:31,  1.15s/it] 22%|██▏       | 111/500 [03:02<17:35,  2.71s/it] 23%|██▎       | 113/500 [03:03<12:22,  1.92s/it] 23%|██▎       | 115/500 [03:09<14:43,  2.30s/it] 23%|██▎       | 117/500 [03:09<10:24,  1.63s/it] 24%|██▍       | 119/500 [03:09<07:21,  1.16s/it] 24%|██▍       | 119/500 [03:20<07:21,  1.16s/it] 24%|██▍       | 121/500 [03:22<17:04,  2.70s/it] 25%|██▍       | 123/500 [03:22<12:01,  1.91s/it] 25%|██▌       | 125/500 [03:28<14:18,  2.29s/it]Epoch:  67  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  68  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  69  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  70  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  72  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  73  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  74  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  75  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  77  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  78  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  79  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  80  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  82  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  83  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  84  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  85  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  87  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  88  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  89  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  90  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  92  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102524757385
Valid Loss:  0.2741985619068146
Epoch:  93  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  94  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  95  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  97  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  98  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  99  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  100  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  102  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  103  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  104  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  105  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  107  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  108  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  109  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  110  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  112  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  113  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  114  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  115  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  117  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  118  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  119  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  120  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  122  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  123  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  124  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  125  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  127  	Training Loss: 0.22220858931541443
Test Loss:   25%|██▌       | 127/500 [03:28<10:05,  1.62s/it] 26%|██▌       | 129/500 [03:29<07:08,  1.16s/it] 26%|██▌       | 129/500 [03:40<07:08,  1.16s/it] 26%|██▌       | 131/500 [03:41<16:38,  2.71s/it] 27%|██▋       | 133/500 [03:41<11:43,  1.92s/it] 27%|██▋       | 135/500 [03:48<13:57,  2.29s/it] 27%|██▋       | 137/500 [03:48<09:50,  1.63s/it] 28%|██▊       | 139/500 [03:48<06:58,  1.16s/it] 28%|██▊       | 139/500 [04:00<06:58,  1.16s/it] 28%|██▊       | 141/500 [04:01<16:12,  2.71s/it] 29%|██▊       | 143/500 [04:01<11:24,  1.92s/it] 29%|██▉       | 145/500 [04:07<13:37,  2.30s/it] 29%|██▉       | 147/500 [04:07<09:36,  1.63s/it] 30%|██▉       | 149/500 [04:07<06:47,  1.16s/it] 30%|██▉       | 149/500 [04:20<06:47,  1.16s/it] 30%|███       | 151/500 [04:20<15:50,  2.72s/it] 31%|███       | 153/500 [04:20<11:09,  1.93s/it] 31%|███       | 155/500 [04:27<13:15,  2.30s/it] 31%|███▏      | 157/500 [04:27<09:20,  1.63s/it] 32%|███▏      | 159/500 [04:27<06:36,  1.16s/it] 32%|███▏      | 161/500 [04:40<15:29,  2.74s/it] 33%|███▎      | 163/500 [04:40<10:53,  1.94s/it] 33%|███▎      | 165/500 [04:46<13:01,  2.33s/it] 33%|███▎      | 167/500 [04:47<09:10,  1.65s/it] 34%|███▍      | 169/500 [04:47<06:29,  1.18s/it] 34%|███▍      | 171/500 [04:59<14:51,  2.71s/it] 35%|███▍      | 173/500 [04:59<10:26,  1.92s/it] 35%|███▌      | 175/500 [05:06<12:24,  2.29s/it] 35%|███▌      | 176/500 [05:06<10:17,  1.91s/it] 36%|███▌      | 178/500 [05:06<06:55,  1.29s/it] 36%|███▌      | 180/500 [05:12<10:10,  1.91s/it] 36%|███▌      | 181/500 [05:19<14:37,  2.75s/it] 37%|███▋      | 183/500 [05:19<09:35,  1.82s/it] 37%|███▋      | 185/500 [05:25<11:53,  2.27s/it]0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  128  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  129  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  130  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  132  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  133  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  134  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  135  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  137  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  138  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  139  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  140  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  142  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  143  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  144  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  145  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  147  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  148  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  149  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  150  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  152  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  153  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  154  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  155  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  157  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  158  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  159  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  160  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  162  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102524757385
Valid Loss:  0.2741985321044922
Epoch:  163  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  164  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  165  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  167  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  168  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  169  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  170  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  172  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  173  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  174  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  175  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  177  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  178  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  179  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  180  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  182  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  183  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  184  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  185  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  187  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:   37%|███▋      | 187/500 [05:25<08:07,  1.56s/it] 38%|███▊      | 189/500 [05:26<05:38,  1.09s/it] 38%|███▊      | 191/500 [05:38<13:55,  2.70s/it] 39%|███▊      | 193/500 [05:38<09:41,  1.89s/it] 39%|███▉      | 195/500 [05:45<11:36,  2.28s/it] 39%|███▉      | 197/500 [05:45<08:08,  1.61s/it] 40%|███▉      | 199/500 [05:45<05:44,  1.14s/it] 40%|████      | 201/500 [05:57<13:22,  2.68s/it] 41%|████      | 203/500 [05:58<09:23,  1.90s/it] 41%|████      | 205/500 [06:04<11:17,  2.30s/it] 41%|████▏     | 207/500 [06:04<07:57,  1.63s/it] 42%|████▏     | 209/500 [06:04<05:37,  1.16s/it] 42%|████▏     | 211/500 [06:17<12:57,  2.69s/it] 43%|████▎     | 213/500 [06:17<09:06,  1.90s/it] 43%|████▎     | 215/500 [06:23<10:52,  2.29s/it] 43%|████▎     | 217/500 [06:23<07:41,  1.63s/it] 44%|████▍     | 219/500 [06:24<05:27,  1.17s/it] 44%|████▍     | 221/500 [06:36<12:35,  2.71s/it] 45%|████▍     | 223/500 [06:36<08:52,  1.92s/it] 45%|████▌     | 225/500 [06:43<10:30,  2.29s/it] 45%|████▌     | 227/500 [06:43<07:23,  1.63s/it] 46%|████▌     | 229/500 [06:43<05:13,  1.16s/it] 46%|████▌     | 231/500 [06:56<12:07,  2.70s/it] 47%|████▋     | 233/500 [06:56<08:30,  1.91s/it] 47%|████▋     | 235/500 [07:02<10:06,  2.29s/it] 47%|████▋     | 237/500 [07:02<07:06,  1.62s/it] 48%|████▊     | 239/500 [07:02<05:01,  1.16s/it] 48%|████▊     | 241/500 [07:15<11:37,  2.69s/it] 49%|████▊     | 243/500 [07:15<08:10,  1.91s/it] 49%|████▉     | 245/500 [07:21<09:40,  2.28s/it] 49%|████▉     | 247/500 [07:22<06:48,  1.62s/it]0.2741985321044922
Epoch:  188  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  189  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  190  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  192  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  193  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  194  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  195  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  197  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  198  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  199  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  200  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  202  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  203  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  204  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  205  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  207  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  208  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  209  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  210  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  212  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  213  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  214  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  215  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  217  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  218  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  219  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  220  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  222  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  223  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  224  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  225  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  227  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  228  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  229  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  230  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  232  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  233  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  234  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  235  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  237  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  238  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  239  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  240  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  242  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  243  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  244  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  245  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  247  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
 50%|████▉     | 249/500 [07:22<04:48,  1.15s/it] 50%|█████     | 251/500 [07:34<11:10,  2.69s/it] 51%|█████     | 253/500 [07:34<07:50,  1.91s/it] 51%|█████     | 255/500 [07:41<09:26,  2.31s/it] 51%|█████▏    | 257/500 [07:41<06:38,  1.64s/it] 52%|█████▏    | 259/500 [07:41<04:41,  1.17s/it] 52%|█████▏    | 261/500 [07:54<11:06,  2.79s/it] 53%|█████▎    | 263/500 [07:54<07:47,  1.97s/it] 53%|█████▎    | 265/500 [08:01<09:08,  2.34s/it] 53%|█████▎    | 267/500 [08:01<06:26,  1.66s/it] 54%|█████▍    | 269/500 [08:01<04:33,  1.18s/it] 54%|█████▍    | 271/500 [08:14<10:32,  2.76s/it] 55%|█████▍    | 273/500 [08:14<07:23,  1.96s/it] 55%|█████▌    | 275/500 [08:21<08:46,  2.34s/it] 55%|█████▌    | 277/500 [08:21<06:11,  1.67s/it] 56%|█████▌    | 279/500 [08:21<04:23,  1.19s/it] 56%|█████▌    | 281/500 [08:34<09:59,  2.74s/it] 57%|█████▋    | 283/500 [08:34<07:00,  1.94s/it] 57%|█████▋    | 285/500 [08:40<08:16,  2.31s/it] 57%|█████▋    | 287/500 [08:40<05:48,  1.64s/it] 58%|█████▊    | 289/500 [08:40<04:05,  1.16s/it] 58%|█████▊    | 291/500 [08:53<09:26,  2.71s/it] 59%|█████▊    | 293/500 [08:53<06:37,  1.92s/it] 59%|█████▉    | 295/500 [09:00<07:50,  2.30s/it] 59%|█████▉    | 297/500 [09:00<05:30,  1.63s/it] 60%|█████▉    | 299/500 [09:00<03:52,  1.16s/it] 60%|█████▉    | 299/500 [09:10<03:52,  1.16s/it] 60%|██████    | 301/500 [09:12<08:55,  2.69s/it] 61%|██████    | 303/500 [09:13<06:16,  1.91s/it] 61%|██████    | 305/500 [09:19<07:26,  2.29s/it] 61%|██████▏   | 307/500 [09:19<05:13,  1.62s/it]Epoch:  248  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  249  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  250  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  252  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  253  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  254  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  255  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  257  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  258  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  259  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  260  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  262  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  263  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  264  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  265  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  267  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  268  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  269  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102524757385
Valid Loss:  0.2741985619068146
Epoch:  270  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  272  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  273  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  274  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  275  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  277  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  278  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  279  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  280  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  282  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  283  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  284  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  285  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  287  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  288  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  289  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  290  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  292  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  293  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  294  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  295  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  297  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  298  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  299  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  300  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  302  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  303  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  304  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  305  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  307  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
 62%|██████▏   | 309/500 [09:19<03:40,  1.15s/it] 62%|██████▏   | 309/500 [09:30<03:40,  1.15s/it] 62%|██████▏   | 311/500 [09:32<08:29,  2.70s/it] 63%|██████▎   | 313/500 [09:32<05:57,  1.91s/it] 63%|██████▎   | 315/500 [09:38<07:03,  2.29s/it] 63%|██████▎   | 317/500 [09:38<04:57,  1.62s/it] 64%|██████▍   | 319/500 [09:38<03:29,  1.16s/it] 64%|██████▍   | 319/500 [09:50<03:29,  1.16s/it] 64%|██████▍   | 321/500 [09:51<08:01,  2.69s/it] 65%|██████▍   | 323/500 [09:51<05:36,  1.90s/it] 65%|██████▌   | 325/500 [09:57<06:37,  2.27s/it] 65%|██████▌   | 327/500 [09:58<04:38,  1.61s/it] 66%|██████▌   | 329/500 [09:58<03:16,  1.15s/it] 66%|██████▌   | 329/500 [10:10<03:16,  1.15s/it] 66%|██████▌   | 331/500 [10:10<07:30,  2.67s/it] 67%|██████▋   | 333/500 [10:10<05:15,  1.89s/it] 67%|██████▋   | 335/500 [10:17<06:12,  2.26s/it] 67%|██████▋   | 337/500 [10:17<04:21,  1.60s/it] 68%|██████▊   | 339/500 [10:17<03:03,  1.14s/it] 68%|██████▊   | 341/500 [10:29<07:05,  2.68s/it] 69%|██████▊   | 343/500 [10:29<04:57,  1.90s/it] 69%|██████▉   | 345/500 [10:36<05:53,  2.28s/it] 69%|██████▉   | 347/500 [10:36<04:07,  1.62s/it] 70%|██████▉   | 349/500 [10:36<02:54,  1.15s/it] 70%|███████   | 351/500 [10:49<06:45,  2.72s/it] 71%|███████   | 353/500 [10:49<04:43,  1.93s/it] 71%|███████   | 355/500 [10:55<05:33,  2.30s/it] 71%|███████▏  | 357/500 [10:56<03:53,  1.63s/it] 72%|███████▏  | 359/500 [10:56<02:44,  1.17s/it] 72%|███████▏  | 361/500 [11:08<06:19,  2.73s/it] 73%|███████▎  | 363/500 [11:09<04:24,  1.93s/it] 73%|███████▎  | 365/500 [11:15<05:12,  2.32s/it] 73%|███████▎  | 367/500 [11:15<03:38,  1.64s/it]Epoch:  308  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  309  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  310  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  312  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  313  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  314  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  315  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  317  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  318  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102524757385
Valid Loss:  0.2741985619068146
Epoch:  319  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  320  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  322  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  323  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  324  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  325  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  327  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  328  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  329  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  330  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  332  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  333  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  334  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  335  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  337  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  338  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  339  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  340  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  342  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  343  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  344  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  345  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  347  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  348  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  349  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  350  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  352  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  353  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  354  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  355  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  357  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  358  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  359  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  360  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  362  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  363  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  364  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  365  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  367  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
 74%|███████▍  | 369/500 [11:15<02:33,  1.17s/it] 74%|███████▍  | 371/500 [11:28<05:53,  2.74s/it] 75%|███████▍  | 373/500 [11:28<04:06,  1.94s/it] 75%|███████▌  | 375/500 [11:35<04:48,  2.31s/it] 75%|███████▌  | 377/500 [11:35<03:21,  1.64s/it] 76%|███████▌  | 379/500 [11:35<02:21,  1.17s/it] 76%|███████▌  | 381/500 [11:47<05:22,  2.71s/it] 77%|███████▋  | 383/500 [11:48<03:44,  1.92s/it] 77%|███████▋  | 385/500 [11:54<04:21,  2.28s/it] 77%|███████▋  | 387/500 [11:54<03:02,  1.61s/it] 78%|███████▊  | 389/500 [11:54<02:07,  1.15s/it] 78%|███████▊  | 391/500 [12:07<04:52,  2.68s/it] 79%|███████▊  | 393/500 [12:07<03:23,  1.90s/it] 79%|███████▉  | 395/500 [12:13<04:01,  2.30s/it] 79%|███████▉  | 397/500 [12:13<02:48,  1.64s/it] 80%|███████▉  | 399/500 [12:14<01:57,  1.16s/it] 80%|████████  | 401/500 [12:26<04:27,  2.71s/it] 81%|████████  | 403/500 [12:26<03:05,  1.91s/it] 81%|████████  | 405/500 [12:33<03:38,  2.30s/it] 81%|████████▏ | 407/500 [12:33<02:31,  1.63s/it] 82%|████████▏ | 409/500 [12:33<01:45,  1.16s/it] 82%|████████▏ | 411/500 [12:45<03:59,  2.69s/it] 83%|████████▎ | 413/500 [12:46<02:45,  1.90s/it] 83%|████████▎ | 415/500 [12:52<03:15,  2.30s/it] 83%|████████▎ | 417/500 [12:52<02:15,  1.63s/it] 84%|████████▍ | 419/500 [12:52<01:34,  1.17s/it] 84%|████████▍ | 421/500 [13:05<03:35,  2.73s/it] 85%|████████▍ | 423/500 [13:05<02:28,  1.93s/it] 85%|████████▌ | 425/500 [13:12<02:52,  2.30s/it] 85%|████████▌ | 427/500 [13:12<01:59,  1.63s/it]Epoch:  368  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  369  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  370  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  372  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  373  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  374  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  375  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  377  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  378  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  379  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  380  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  382  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  383  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  384  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  385  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  387  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  388  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  389  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  390  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  392  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  393  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  394  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  395  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  397  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  398  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  399  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  400  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  402  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  403  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  404  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  405  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  407  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  408  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  409  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  410  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  412  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  413  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  414  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  415  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  417  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  418  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  419  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  420  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  422  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  423  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  424  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  425  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  427  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
 86%|████████▌ | 429/500 [13:12<01:22,  1.16s/it] 86%|████████▌ | 431/500 [13:25<03:10,  2.76s/it] 87%|████████▋ | 433/500 [13:25<02:10,  1.95s/it] 87%|████████▋ | 435/500 [13:31<02:31,  2.32s/it] 87%|████████▋ | 437/500 [13:32<01:43,  1.65s/it] 88%|████████▊ | 439/500 [13:32<01:11,  1.17s/it] 88%|████████▊ | 441/500 [13:44<02:40,  2.72s/it] 89%|████████▊ | 443/500 [13:44<01:49,  1.92s/it] 89%|████████▉ | 445/500 [13:51<02:06,  2.29s/it] 89%|████████▉ | 447/500 [13:51<01:26,  1.62s/it] 90%|████████▉ | 449/500 [13:51<00:59,  1.16s/it] 90%|█████████ | 451/500 [14:04<02:12,  2.70s/it] 91%|█████████ | 453/500 [14:04<01:29,  1.91s/it] 91%|█████████ | 455/500 [14:10<01:43,  2.29s/it] 91%|█████████▏| 457/500 [14:10<01:10,  1.63s/it] 92%|█████████▏| 459/500 [14:10<00:47,  1.17s/it] 92%|█████████▏| 461/500 [14:23<01:45,  2.72s/it] 93%|█████████▎| 463/500 [14:23<01:11,  1.92s/it] 93%|█████████▎| 465/500 [14:30<01:20,  2.30s/it] 93%|█████████▎| 467/500 [14:30<00:53,  1.63s/it] 94%|█████████▍| 469/500 [14:30<00:36,  1.17s/it] 94%|█████████▍| 469/500 [14:40<00:36,  1.17s/it] 94%|█████████▍| 471/500 [14:43<01:18,  2.71s/it] 95%|█████████▍| 473/500 [14:43<00:51,  1.92s/it] 95%|█████████▌| 475/500 [14:49<00:57,  2.30s/it] 95%|█████████▌| 477/500 [14:49<00:37,  1.63s/it] 96%|█████████▌| 479/500 [14:49<00:24,  1.16s/it] 96%|█████████▌| 479/500 [15:00<00:24,  1.16s/it] 96%|█████████▌| 481/500 [15:02<00:51,  2.70s/it] 97%|█████████▋| 483/500 [15:02<00:32,  1.91s/it] 97%|█████████▋| 485/500 [15:08<00:34,  2.29s/it] 97%|█████████▋| 487/500 [15:09<00:21,  1.62s/it]Epoch:  428  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  429  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  430  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  432  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  433  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  434  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  435  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  437  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  438  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  439  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  440  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  442  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  443  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  444  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  445  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  447  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  448  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  449  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  450  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  452  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  453  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  454  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  455  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  457  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  458  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  459  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  460  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  462  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102524757385
Valid Loss:  0.2741985321044922
Epoch:  463  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  464  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  465  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  467  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  468  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  469  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102524757385
Valid Loss:  0.2741985321044922
Epoch:  470  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  472  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  473  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  474  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  475  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  477  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  478  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  479  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  480  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  482  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  483  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  484  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  485  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  487  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
 98%|█████████▊| 489/500 [15:09<00:12,  1.16s/it] 98%|█████████▊| 489/500 [15:20<00:12,  1.16s/it] 98%|█████████▊| 491/500 [15:21<00:24,  2.69s/it] 99%|█████████▊| 493/500 [15:21<00:13,  1.91s/it] 99%|█████████▉| 495/500 [15:28<00:11,  2.28s/it] 99%|█████████▉| 497/500 [15:28<00:04,  1.62s/it]100%|█████████▉| 499/500 [15:28<00:01,  1.16s/it]100%|██████████| 500/500 [15:34<00:00,  1.87s/it]
Epoch:  488  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985619068146
Epoch:  489  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  490  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  492  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  493  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  494  	Training Loss: 0.22220857441425323
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  495  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  497  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
Epoch:  498  	Training Loss: 0.22220858931541443
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985619068146
Epoch:  499  	Training Loss: 0.22220857441425323
Test Loss:  0.2870102822780609
Valid Loss:  0.2741985321044922
Epoch:  500  	Training Loss: 0.22220858931541443
Test Loss:  0.2870103120803833
Valid Loss:  0.2741985321044922
**************************************************learning rate decay**************************************************
seed is  8
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:29,  6.19s/it]  1%|          | 3/500 [00:06<13:43,  1.66s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:47,  2.92it/s]  2%|▏         | 11/500 [00:12<10:46,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:34,  1.20s/it]  5%|▍         | 23/500 [00:19<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:16,  1.19s/it]  7%|▋         | 33/500 [00:26<06:36,  1.18it/s]  7%|▋         | 35/500 [00:26<04:45,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<09:01,  1.18s/it]  9%|▊         | 43/500 [00:33<06:27,  1.18it/s]  9%|▉         | 45/500 [00:33<04:38,  1.63it/s]  9%|▉         | 47/500 [00:33<03:23,  2.22it/s] 10%|▉         | 49/500 [00:34<02:31,  2.99it/s] 10%|█         | 51/500 [00:40<08:52,  1.19s/it] 11%|█         | 53/500 [00:40<06:22,  1.17it/s] 11%|█         | 55/500 [00:40<04:38,  1.60it/s] 11%|█▏        | 57/500 [00:40<03:25,  2.16it/s] 12%|█▏        | 59/500 [00:41<02:33,  2.86it/s] 12%|█▏        | 61/500 [00:47<08:45,  1.20s/it] 13%|█▎        | 63/500 [00:47<06:17,  1.16it/s] 13%|█▎        | 65/500 [00:47<04:34,  1.59it/s] 13%|█▎        | 67/500 [00:47<03:21,  2.14it/s] 14%|█▍        | 69/500 [00:48<02:31,  2.84it/s] 14%|█▍        | 71/500 [00:54<08:42,  1.22s/it]Epoch:  1  	Training Loss: 0.029436571523547173
Test Loss:  0.029611602425575256
Valid Loss:  0.026095358654856682
Epoch:  2  	Training Loss: 0.02184314653277397
Test Loss:  0.01869981363415718
Valid Loss:  0.027018779888749123
Epoch:  3  	Training Loss: 0.0418701134622097
Test Loss:  0.12137116491794586
Valid Loss:  0.10191743075847626
Epoch:  4  	Training Loss: 0.09156587719917297
Test Loss:  0.008093137294054031
Valid Loss:  0.013795502483844757
Epoch:  5  	Training Loss: 0.022922318428754807
Test Loss:  0.007448055315762758
Valid Loss:  0.01276414655148983
Epoch:  6  	Training Loss: 0.02159930020570755
Test Loss:  0.007110746577382088
Valid Loss:  0.012113669887185097
Epoch:  7  	Training Loss: 0.02051849663257599
Test Loss:  0.006757446099072695
Valid Loss:  0.01152763981372118
Epoch:  8  	Training Loss: 0.019907146692276
Test Loss:  0.0065912832506000996
Valid Loss:  0.011377565562725067
Epoch:  9  	Training Loss: 0.019737601280212402
Test Loss:  0.006383726838976145
Valid Loss:  0.011182759888470173
Epoch:  10  	Training Loss: 0.01959678903222084
Test Loss:  0.006291288882493973
Valid Loss:  0.011111032217741013
Epoch:  11  	Training Loss: 0.01949121803045273
Test Loss:  0.006157803814858198
Valid Loss:  0.011001711711287498
Epoch:  12  	Training Loss: 0.019404789432883263
Test Loss:  0.006088928319513798
Valid Loss:  0.010943843051791191
Epoch:  13  	Training Loss: 0.01932506263256073
Test Loss:  0.006019239779561758
Valid Loss:  0.01088637299835682
Epoch:  14  	Training Loss: 0.019253937527537346
Test Loss:  0.005966661497950554
Valid Loss:  0.010842175222933292
Epoch:  15  	Training Loss: 0.01918901689350605
Test Loss:  0.005915515124797821
Valid Loss:  0.010800817981362343
Epoch:  16  	Training Loss: 0.019132155925035477
Test Loss:  0.005868574604392052
Valid Loss:  0.01076599583029747
Epoch:  17  	Training Loss: 0.019084323197603226
Test Loss:  0.005825824104249477
Valid Loss:  0.010735444724559784
Epoch:  18  	Training Loss: 0.019040977582335472
Test Loss:  0.005795675329864025
Valid Loss:  0.010712441056966782
Epoch:  19  	Training Loss: 0.01900043711066246
Test Loss:  0.0057629914954304695
Valid Loss:  0.010689868591725826
Epoch:  20  	Training Loss: 0.018963158130645752
Test Loss:  0.005725014954805374
Valid Loss:  0.01066506840288639
Epoch:  21  	Training Loss: 0.018928617238998413
Test Loss:  0.005704852752387524
Valid Loss:  0.010650869458913803
Epoch:  22  	Training Loss: 0.01889616996049881
Test Loss:  0.005675258114933968
Valid Loss:  0.010632654651999474
Epoch:  23  	Training Loss: 0.018867507576942444
Test Loss:  0.005660855211317539
Valid Loss:  0.010622027330100536
Epoch:  24  	Training Loss: 0.01883993111550808
Test Loss:  0.005640133284032345
Valid Loss:  0.010608404874801636
Epoch:  25  	Training Loss: 0.018813323229551315
Test Loss:  0.005624611862003803
Valid Loss:  0.010597015731036663
Epoch:  26  	Training Loss: 0.018787432461977005
Test Loss:  0.005610764492303133
Valid Loss:  0.010586285032331944
Epoch:  27  	Training Loss: 0.018762072548270226
Test Loss:  0.0055977473966777325
Valid Loss:  0.010575857013463974
Epoch:  28  	Training Loss: 0.018737200647592545
Test Loss:  0.005585320293903351
Valid Loss:  0.010565631091594696
Epoch:  29  	Training Loss: 0.018712783232331276
Test Loss:  0.00557359866797924
Valid Loss:  0.010555562563240528
Epoch:  30  	Training Loss: 0.018688775599002838
Test Loss:  0.005558043718338013
Valid Loss:  0.010544215328991413
Epoch:  31  	Training Loss: 0.01866542361676693
Test Loss:  0.005546979606151581
Valid Loss:  0.010533936321735382
Epoch:  32  	Training Loss: 0.018642503768205643
Test Loss:  0.0055369120091199875
Valid Loss:  0.010524515993893147
Epoch:  33  	Training Loss: 0.01862107589840889
Test Loss:  0.005527849309146404
Valid Loss:  0.010515278205275536
Epoch:  34  	Training Loss: 0.01859990507364273
Test Loss:  0.005518912337720394
Valid Loss:  0.010506002232432365
Epoch:  35  	Training Loss: 0.018579088151454926
Test Loss:  0.005505750421434641
Valid Loss:  0.010495880618691444
Epoch:  36  	Training Loss: 0.018558554351329803
Test Loss:  0.005500376224517822
Valid Loss:  0.010486929677426815
Epoch:  37  	Training Loss: 0.01853826455771923
Test Loss:  0.005488533992320299
Valid Loss:  0.01047698874026537
Epoch:  38  	Training Loss: 0.018518146127462387
Test Loss:  0.00548083521425724
Valid Loss:  0.010467459447681904
Epoch:  39  	Training Loss: 0.018498217687010765
Test Loss:  0.005472833290696144
Valid Loss:  0.010457843542098999
Epoch:  40  	Training Loss: 0.018478460609912872
Test Loss:  0.005461761262267828
Valid Loss:  0.010447805747389793
Epoch:  41  	Training Loss: 0.018458858132362366
Test Loss:  0.00545770488679409
Valid Loss:  0.010438265278935432
Epoch:  42  	Training Loss: 0.01843934878706932
Test Loss:  0.005446251481771469
Valid Loss:  0.010428091511130333
Epoch:  43  	Training Loss: 0.018419839441776276
Test Loss:  0.005443277768790722
Valid Loss:  0.010418334975838661
Epoch:  44  	Training Loss: 0.018400462344288826
Test Loss:  0.005432714708149433
Valid Loss:  0.010408168658614159
Epoch:  45  	Training Loss: 0.018381085246801376
Test Loss:  0.005425692535936832
Valid Loss:  0.010397981852293015
Epoch:  46  	Training Loss: 0.01836181990802288
Test Loss:  0.005418728105723858
Valid Loss:  0.010387727990746498
Epoch:  47  	Training Loss: 0.018342621624469757
Test Loss:  0.005412243772298098
Valid Loss:  0.010377423837780952
Epoch:  48  	Training Loss: 0.01832347735762596
Test Loss:  0.0054059214890003204
Valid Loss:  0.010367082431912422
Epoch:  49  	Training Loss: 0.018304385244846344
Test Loss:  0.005399673245847225
Valid Loss:  0.010356705635786057
Epoch:  50  	Training Loss: 0.01828533597290516
Test Loss:  0.005393477156758308
Valid Loss:  0.010346299037337303
Epoch:  51  	Training Loss: 0.018266335129737854
Test Loss:  0.0053873248398303986
Valid Loss:  0.010335864499211311
Epoch:  52  	Training Loss: 0.01824738085269928
Test Loss:  0.005381170194596052
Valid Loss:  0.01032528467476368
Epoch:  53  	Training Loss: 0.01822827011346817
Test Loss:  0.0053756521083414555
Valid Loss:  0.01031468715518713
Epoch:  54  	Training Loss: 0.018209215253591537
Test Loss:  0.005369103513658047
Valid Loss:  0.010304093360900879
Epoch:  55  	Training Loss: 0.01819019392132759
Test Loss:  0.005362938158214092
Valid Loss:  0.010293446481227875
Epoch:  56  	Training Loss: 0.018171217292547226
Test Loss:  0.0053568952716887
Valid Loss:  0.010282768867909908
Epoch:  57  	Training Loss: 0.018152279779314995
Test Loss:  0.005350905936211348
Valid Loss:  0.010272062383592129
Epoch:  58  	Training Loss: 0.01813337951898575
Test Loss:  0.005344953387975693
Valid Loss:  0.010261336341500282
Epoch:  59  	Training Loss: 0.018114522099494934
Test Loss:  0.0053390320390462875
Valid Loss:  0.010250587947666645
Epoch:  60  	Training Loss: 0.018095701932907104
Test Loss:  0.005333139095455408
Valid Loss:  0.010239819064736366
Epoch:  61  	Training Loss: 0.018076913431286812
Test Loss:  0.005327275022864342
Valid Loss:  0.010229031555354595
Epoch:  62  	Training Loss: 0.018058165907859802
Test Loss:  0.005321380216628313
Valid Loss:  0.010218074545264244
Epoch:  63  	Training Loss: 0.018039220944046974
Test Loss:  0.0053198193199932575
Valid Loss:  0.01020753849297762
Epoch:  64  	Training Loss: 0.01802251487970352
Test Loss:  0.0053122155368328094
Valid Loss:  0.01020001620054245
Epoch:  65  	Training Loss: 0.018008923158049583
Test Loss:  0.00530709233134985
Valid Loss:  0.010192718356847763
Epoch:  66  	Training Loss: 0.01799584925174713
Test Loss:  0.005306392442435026
Valid Loss:  0.01018565334379673
Epoch:  67  	Training Loss: 0.01798311248421669
Test Loss:  0.005299442447721958
Valid Loss:  0.01017899252474308
Epoch:  68  	Training Loss: 0.017970416694879532
Test Loss:  0.005295285955071449
Valid Loss:  0.010172094218432903
Epoch:  69  	Training Loss: 0.017957884818315506
Test Loss:  0.0052943178452551365
Valid Loss:  0.010165136307477951
Epoch:  70  	Training Loss: 0.017945386469364166
Test Loss:  0.005287551321089268
Valid Loss:  0.01015846710652113
Epoch:  71  	Training Loss: 0.017932871356606483
Test Loss:  0.005286716390401125
Valid Loss:  0.010151447728276253
 15%|█▍        | 73/500 [00:54<06:15,  1.14it/s] 15%|█▌        | 75/500 [00:54<04:32,  1.56it/s] 15%|█▌        | 77/500 [00:55<03:20,  2.11it/s] 16%|█▌        | 79/500 [00:55<02:30,  2.79it/s] 16%|█▌        | 81/500 [01:01<08:27,  1.21s/it] 17%|█▋        | 83/500 [01:01<06:02,  1.15it/s] 17%|█▋        | 85/500 [01:01<04:20,  1.59it/s] 17%|█▋        | 87/500 [01:02<03:09,  2.18it/s] 18%|█▊        | 89/500 [01:02<02:19,  2.94it/s] 18%|█▊        | 91/500 [01:08<08:08,  1.20s/it] 19%|█▊        | 93/500 [01:08<05:49,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.61it/s] 19%|█▉        | 97/500 [01:09<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:09<02:14,  2.97it/s] 20%|██        | 101/500 [01:15<07:57,  1.20s/it] 21%|██        | 103/500 [01:15<05:41,  1.16it/s] 21%|██        | 105/500 [01:15<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:15<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:16<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:22<07:42,  1.19s/it] 23%|██▎       | 113/500 [01:22<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:22<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:22<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:22<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:29<07:36,  1.21s/it] 25%|██▍       | 123/500 [01:29<05:26,  1.16it/s] 25%|██▌       | 125/500 [01:29<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:29<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:29<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:36<07:17,  1.19s/it] 27%|██▋       | 133/500 [01:36<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:36<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:36<02:44,  2.20it/s] 28%|██▊       | 139/500 [01:36<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:43<07:08,  1.19s/it]Epoch:  72  	Training Loss: 0.017920443788170815
Test Loss:  0.005280288867652416
Valid Loss:  0.010144747793674469
Epoch:  73  	Training Loss: 0.01790795847773552
Test Loss:  0.005279128439724445
Valid Loss:  0.010137722827494144
Epoch:  74  	Training Loss: 0.017895571887493134
Test Loss:  0.0052726417779922485
Valid Loss:  0.010131004266440868
Epoch:  75  	Training Loss: 0.017883136868476868
Test Loss:  0.005271493457257748
Valid Loss:  0.010123923420906067
Epoch:  76  	Training Loss: 0.017870783805847168
Test Loss:  0.005265047773718834
Valid Loss:  0.010117176920175552
Epoch:  77  	Training Loss: 0.01785840466618538
Test Loss:  0.005264329724013805
Valid Loss:  0.010110050439834595
Epoch:  78  	Training Loss: 0.017846088856458664
Test Loss:  0.005257748533040285
Valid Loss:  0.010103309527039528
Epoch:  79  	Training Loss: 0.017833760008215904
Test Loss:  0.005256670527160168
Valid Loss:  0.010096169076859951
Epoch:  80  	Training Loss: 0.017821451649069786
Test Loss:  0.0052498201839625835
Valid Loss:  0.01008940115571022
Epoch:  81  	Training Loss: 0.017809191718697548
Test Loss:  0.005249703768640757
Valid Loss:  0.010082142427563667
Epoch:  82  	Training Loss: 0.017796892672777176
Test Loss:  0.005241898819804192
Valid Loss:  0.010075459256768227
Epoch:  83  	Training Loss: 0.017784707248210907
Test Loss:  0.005242147482931614
Valid Loss:  0.010068107396364212
Epoch:  84  	Training Loss: 0.017772408202290535
Test Loss:  0.005238402634859085
Valid Loss:  0.010061227716505527
Epoch:  85  	Training Loss: 0.017760172486305237
Test Loss:  0.0052352542988955975
Valid Loss:  0.010054288432002068
Epoch:  86  	Training Loss: 0.017747949808835983
Test Loss:  0.005228588357567787
Valid Loss:  0.010047475807368755
Epoch:  87  	Training Loss: 0.017735738307237625
Test Loss:  0.005227712914347649
Valid Loss:  0.01004018820822239
Epoch:  88  	Training Loss: 0.01772347278892994
Test Loss:  0.005224702879786491
Valid Loss:  0.010033197700977325
Epoch:  89  	Training Loss: 0.017711244523525238
Test Loss:  0.005220778752118349
Valid Loss:  0.010026264935731888
Epoch:  90  	Training Loss: 0.017699018120765686
Test Loss:  0.005217432510107756
Valid Loss:  0.010019270703196526
Epoch:  91  	Training Loss: 0.017686795443296432
Test Loss:  0.005213831085711718
Valid Loss:  0.01001228392124176
Epoch:  92  	Training Loss: 0.01767457276582718
Test Loss:  0.005210183095186949
Valid Loss:  0.010005252435803413
Epoch:  93  	Training Loss: 0.01766233518719673
Test Loss:  0.005206511355936527
Valid Loss:  0.009998205117881298
Epoch:  94  	Training Loss: 0.017650112509727478
Test Loss:  0.00520284054800868
Valid Loss:  0.009991143830120564
Epoch:  95  	Training Loss: 0.01763789914548397
Test Loss:  0.005199177656322718
Valid Loss:  0.009984058327972889
Epoch:  96  	Training Loss: 0.01762569695711136
Test Loss:  0.005195515230298042
Valid Loss:  0.009976966306567192
Epoch:  97  	Training Loss: 0.01761351153254509
Test Loss:  0.005191864911466837
Valid Loss:  0.009969860315322876
Epoch:  98  	Training Loss: 0.017601337283849716
Test Loss:  0.0051882220432162285
Valid Loss:  0.009962735697627068
Epoch:  99  	Training Loss: 0.01758917048573494
Test Loss:  0.005184996407479048
Valid Loss:  0.00995558500289917
Epoch:  100  	Training Loss: 0.017577018588781357
Test Loss:  0.005181058309972286
Valid Loss:  0.009948480874300003
Epoch:  101  	Training Loss: 0.01756487414240837
Test Loss:  0.005177362821996212
Valid Loss:  0.009941325522959232
Epoch:  102  	Training Loss: 0.01755276508629322
Test Loss:  0.005177829414606094
Valid Loss:  0.009934032335877419
Epoch:  103  	Training Loss: 0.017540665343403816
Test Loss:  0.005171073600649834
Valid Loss:  0.009927247650921345
Epoch:  104  	Training Loss: 0.017528483644127846
Test Loss:  0.005167709197849035
Valid Loss:  0.009920083917677402
Epoch:  105  	Training Loss: 0.017516382038593292
Test Loss:  0.00516725517809391
Valid Loss:  0.009912870824337006
Epoch:  106  	Training Loss: 0.01750430092215538
Test Loss:  0.005160278640687466
Valid Loss:  0.00990607962012291
Epoch:  107  	Training Loss: 0.017492199316620827
Test Loss:  0.005161010194569826
Valid Loss:  0.009898779913783073
Epoch:  108  	Training Loss: 0.017480140551924706
Test Loss:  0.005153290927410126
Valid Loss:  0.009892054833471775
Epoch:  109  	Training Loss: 0.01746806688606739
Test Loss:  0.005153852980583906
Valid Loss:  0.009884736500680447
Epoch:  110  	Training Loss: 0.017455996945500374
Test Loss:  0.005147114396095276
Valid Loss:  0.009877948090434074
Epoch:  111  	Training Loss: 0.017443958669900894
Test Loss:  0.005146908573806286
Valid Loss:  0.009870712645351887
Epoch:  112  	Training Loss: 0.01743190921843052
Test Loss:  0.005143116228282452
Valid Loss:  0.009863934479653835
Epoch:  113  	Training Loss: 0.01742001250386238
Test Loss:  0.0051400731317698956
Valid Loss:  0.009857086464762688
Epoch:  114  	Training Loss: 0.017408132553100586
Test Loss:  0.005133426748216152
Valid Loss:  0.00985035765916109
Epoch:  115  	Training Loss: 0.017396297305822372
Test Loss:  0.005132818594574928
Valid Loss:  0.009843175299465656
Epoch:  116  	Training Loss: 0.017384398728609085
Test Loss:  0.00512896291911602
Valid Loss:  0.009836356155574322
Epoch:  117  	Training Loss: 0.017372578382492065
Test Loss:  0.005126391537487507
Valid Loss:  0.009829443879425526
Epoch:  118  	Training Loss: 0.017360758036375046
Test Loss:  0.005123094189912081
Valid Loss:  0.009822617284953594
Epoch:  119  	Training Loss: 0.01734895631670952
Test Loss:  0.005119629204273224
Valid Loss:  0.009815800935029984
Epoch:  120  	Training Loss: 0.017337173223495483
Test Loss:  0.00511612743139267
Valid Loss:  0.009808974340558052
Epoch:  121  	Training Loss: 0.017325401306152344
Test Loss:  0.005112622864544392
Valid Loss:  0.009802131913602352
Epoch:  122  	Training Loss: 0.0173136405646801
Test Loss:  0.005109109915792942
Valid Loss:  0.009795239195227623
Epoch:  123  	Training Loss: 0.017301831394433975
Test Loss:  0.005105597898364067
Valid Loss:  0.009788334369659424
Epoch:  124  	Training Loss: 0.01729002594947815
Test Loss:  0.005102098919451237
Valid Loss:  0.009781401604413986
Epoch:  125  	Training Loss: 0.017278224229812622
Test Loss:  0.005098591558635235
Valid Loss:  0.009774458594620228
Epoch:  126  	Training Loss: 0.017266426235437393
Test Loss:  0.005095099564641714
Valid Loss:  0.009767493233084679
Epoch:  127  	Training Loss: 0.01725463755428791
Test Loss:  0.0050916001200675964
Valid Loss:  0.009760518558323383
Epoch:  128  	Training Loss: 0.01724284701049328
Test Loss:  0.005088115110993385
Valid Loss:  0.009753521531820297
Epoch:  129  	Training Loss: 0.017231063917279243
Test Loss:  0.005084621254354715
Valid Loss:  0.00974651612341404
Epoch:  130  	Training Loss: 0.017219286412000656
Test Loss:  0.005081135779619217
Valid Loss:  0.009739495813846588
Epoch:  131  	Training Loss: 0.017207512632012367
Test Loss:  0.005077662877738476
Valid Loss:  0.009732457809150219
Epoch:  132  	Training Loss: 0.017195744439959526
Test Loss:  0.005074177868664265
Valid Loss:  0.0097253592684865
Epoch:  133  	Training Loss: 0.017183911055326462
Test Loss:  0.005070691928267479
Valid Loss:  0.009718245826661587
Epoch:  134  	Training Loss: 0.01717209443449974
Test Loss:  0.005071929655969143
Valid Loss:  0.009711053222417831
Epoch:  135  	Training Loss: 0.017160363495349884
Test Loss:  0.005064852070063353
Valid Loss:  0.00970439612865448
Epoch:  136  	Training Loss: 0.017148513346910477
Test Loss:  0.005061565898358822
Valid Loss:  0.009697325527668
Epoch:  137  	Training Loss: 0.017136741429567337
Test Loss:  0.005061340983957052
Valid Loss:  0.009690226055681705
Epoch:  138  	Training Loss: 0.017124991863965988
Test Loss:  0.005055090878158808
Valid Loss:  0.009683492593467236
Epoch:  139  	Training Loss: 0.01711321622133255
Test Loss:  0.005055559333413839
Valid Loss:  0.009676385670900345
Epoch:  140  	Training Loss: 0.017101485282182693
Test Loss:  0.00504801981151104
Valid Loss:  0.009669758379459381
Epoch:  141  	Training Loss: 0.017089758068323135
Test Loss:  0.005048512481153011
Valid Loss:  0.00966256856918335
Epoch:  142  	Training Loss: 0.0170779749751091
Test Loss:   29%|██▊       | 143/500 [01:43<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:43<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:43<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:43<02:00,  2.92it/s] 30%|███       | 151/500 [01:50<07:03,  1.21s/it] 31%|███       | 153/500 [01:50<05:01,  1.15it/s] 31%|███       | 155/500 [01:50<03:37,  1.58it/s] 31%|███▏      | 157/500 [01:50<02:39,  2.16it/s] 32%|███▏      | 159/500 [01:50<01:57,  2.91it/s] 32%|███▏      | 161/500 [01:57<06:51,  1.21s/it] 33%|███▎      | 163/500 [01:57<04:53,  1.15it/s] 33%|███▎      | 165/500 [01:57<03:30,  1.59it/s] 33%|███▎      | 167/500 [01:57<02:32,  2.18it/s] 34%|███▍      | 169/500 [01:57<01:52,  2.94it/s] 34%|███▍      | 171/500 [02:04<06:35,  1.20s/it] 35%|███▍      | 173/500 [02:04<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:04<03:22,  1.60it/s] 35%|███▌      | 177/500 [02:04<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:04<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:11<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:11<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:16,  1.61it/s] 37%|███▋      | 187/500 [02:11<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:11<01:46,  2.92it/s] 38%|███▊      | 191/500 [02:18<06:08,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:18<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:18<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:18<01:41,  2.98it/s] 40%|████      | 201/500 [02:24<05:55,  1.19s/it] 41%|████      | 203/500 [02:25<04:13,  1.17it/s] 41%|████      | 205/500 [02:25<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:25<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:25<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:31<05:41,  1.18s/it]0.00504546333104372
Valid Loss:  0.009655880741775036
Epoch:  143  	Training Loss: 0.017066335305571556
Test Loss:  0.005038902163505554
Valid Loss:  0.009649231098592281
Epoch:  144  	Training Loss: 0.017054695636034012
Test Loss:  0.0050385440699756145
Valid Loss:  0.009642161428928375
Epoch:  145  	Training Loss: 0.017043042927980423
Test Loss:  0.005035473499447107
Valid Loss:  0.009635424241423607
Epoch:  146  	Training Loss: 0.017031395807862282
Test Loss:  0.005032563582062721
Valid Loss:  0.009628701955080032
Epoch:  147  	Training Loss: 0.01701977476477623
Test Loss:  0.005029303953051567
Valid Loss:  0.009622003883123398
Epoch:  148  	Training Loss: 0.017008155584335327
Test Loss:  0.005025974474847317
Valid Loss:  0.009615296497941017
Epoch:  149  	Training Loss: 0.01699654385447502
Test Loss:  0.005022640340030193
Valid Loss:  0.00960856769233942
Epoch:  150  	Training Loss: 0.016984935849905014
Test Loss:  0.0050193085335195065
Valid Loss:  0.009601820260286331
Epoch:  151  	Training Loss: 0.016973331570625305
Test Loss:  0.005015983246266842
Valid Loss:  0.009595049545168877
Epoch:  152  	Training Loss: 0.016961734741926193
Test Loss:  0.005012683570384979
Valid Loss:  0.009588324464857578
Epoch:  153  	Training Loss: 0.01695024035871029
Test Loss:  0.005009397864341736
Valid Loss:  0.009581578895449638
Epoch:  154  	Training Loss: 0.016938749700784683
Test Loss:  0.005006121005862951
Valid Loss:  0.00957481563091278
Epoch:  155  	Training Loss: 0.016927272081375122
Test Loss:  0.005002855323255062
Valid Loss:  0.009568040259182453
Epoch:  156  	Training Loss: 0.016915801912546158
Test Loss:  0.004999594762921333
Valid Loss:  0.00956125557422638
Epoch:  157  	Training Loss: 0.01690434291958809
Test Loss:  0.004996343515813351
Valid Loss:  0.009554454125463963
Epoch:  158  	Training Loss: 0.016892891377210617
Test Loss:  0.004993096925318241
Valid Loss:  0.00954764150083065
Epoch:  159  	Training Loss: 0.01688144914805889
Test Loss:  0.004989860579371452
Valid Loss:  0.009540813975036144
Epoch:  160  	Training Loss: 0.016870014369487762
Test Loss:  0.004986628890037537
Valid Loss:  0.00953398086130619
Epoch:  161  	Training Loss: 0.016858592629432678
Test Loss:  0.0049834041856229305
Valid Loss:  0.009527135640382767
Epoch:  162  	Training Loss: 0.016847174614667892
Test Loss:  0.004980160854756832
Valid Loss:  0.009520200081169605
Epoch:  163  	Training Loss: 0.016835641115903854
Test Loss:  0.004976913798600435
Valid Loss:  0.009513255208730698
Epoch:  164  	Training Loss: 0.016824115067720413
Test Loss:  0.004973670933395624
Valid Loss:  0.009506299160420895
Epoch:  165  	Training Loss: 0.01681259274482727
Test Loss:  0.004970432259142399
Valid Loss:  0.00949933286756277
Epoch:  166  	Training Loss: 0.016801074147224426
Test Loss:  0.0049671996384859085
Valid Loss:  0.009492361918091774
Epoch:  167  	Training Loss: 0.016789566725492477
Test Loss:  0.004963969811797142
Valid Loss:  0.009485381655395031
Epoch:  168  	Training Loss: 0.016778061166405678
Test Loss:  0.004960745573043823
Valid Loss:  0.009478393942117691
Epoch:  169  	Training Loss: 0.016766563057899475
Test Loss:  0.00495752552524209
Valid Loss:  0.009471394121646881
Epoch:  170  	Training Loss: 0.01675507053732872
Test Loss:  0.00495431013405323
Valid Loss:  0.009464395232498646
Epoch:  171  	Training Loss: 0.016743585467338562
Test Loss:  0.004951099399477243
Valid Loss:  0.009457382373511791
Epoch:  172  	Training Loss: 0.016732107847929
Test Loss:  0.004947900306433439
Valid Loss:  0.009450435638427734
Epoch:  173  	Training Loss: 0.01672072894871235
Test Loss:  0.004944717511534691
Valid Loss:  0.009443482384085655
Epoch:  174  	Training Loss: 0.016709359362721443
Test Loss:  0.004941544029861689
Valid Loss:  0.009436528198421001
Epoch:  175  	Training Loss: 0.01669800654053688
Test Loss:  0.004938376601785421
Valid Loss:  0.009429571218788624
Epoch:  176  	Training Loss: 0.016686661168932915
Test Loss:  0.004935212433338165
Valid Loss:  0.009422609582543373
Epoch:  177  	Training Loss: 0.016675323247909546
Test Loss:  0.004932053852826357
Valid Loss:  0.009415650740265846
Epoch:  178  	Training Loss: 0.016663996502757072
Test Loss:  0.004928900394588709
Valid Loss:  0.009408684447407722
Epoch:  179  	Training Loss: 0.016652680933475494
Test Loss:  0.0049257525242865086
Valid Loss:  0.009401722811162472
Epoch:  180  	Training Loss: 0.01664137840270996
Test Loss:  0.004922610707581043
Valid Loss:  0.009394757449626923
Epoch:  181  	Training Loss: 0.016630083322525024
Test Loss:  0.0049194712191820145
Valid Loss:  0.009387793019413948
Epoch:  182  	Training Loss: 0.016618799418210983
Test Loss:  0.004916341044008732
Valid Loss:  0.009380808100104332
Epoch:  183  	Training Loss: 0.01660750061273575
Test Loss:  0.004913208074867725
Valid Loss:  0.009373821318149567
Epoch:  184  	Training Loss: 0.01659620925784111
Test Loss:  0.004910077899694443
Valid Loss:  0.00936683639883995
Epoch:  185  	Training Loss: 0.016584929078817368
Test Loss:  0.004906951449811459
Valid Loss:  0.009359849616885185
Epoch:  186  	Training Loss: 0.016573654487729073
Test Loss:  0.004903826862573624
Valid Loss:  0.00935286097228527
Epoch:  187  	Training Loss: 0.016562383621931076
Test Loss:  0.004900705069303513
Valid Loss:  0.009345871396362782
Epoch:  188  	Training Loss: 0.016551118344068527
Test Loss:  0.004897587466984987
Valid Loss:  0.009338881820440292
Epoch:  189  	Training Loss: 0.016539860516786575
Test Loss:  0.004894472658634186
Valid Loss:  0.009331888519227505
Epoch:  190  	Training Loss: 0.01652861014008522
Test Loss:  0.004891359247267246
Valid Loss:  0.009324897080659866
Epoch:  191  	Training Loss: 0.016517363488674164
Test Loss:  0.004888251423835754
Valid Loss:  0.009317908436059952
Epoch:  192  	Training Loss: 0.016506124287843704
Test Loss:  0.004885146394371986
Valid Loss:  0.009310945868492126
Epoch:  193  	Training Loss: 0.016494933515787125
Test Loss:  0.0048820506781339645
Valid Loss:  0.009303983300924301
Epoch:  194  	Training Loss: 0.016483744606375694
Test Loss:  0.0048789577558636665
Valid Loss:  0.009297020733356476
Epoch:  195  	Training Loss: 0.01647256314754486
Test Loss:  0.0048758708871901035
Valid Loss:  0.00929005816578865
Epoch:  196  	Training Loss: 0.016461392864584923
Test Loss:  0.004872786812484264
Valid Loss:  0.009283098392188549
Epoch:  197  	Training Loss: 0.016450226306915283
Test Loss:  0.004869704134762287
Valid Loss:  0.009276139549911022
Epoch:  198  	Training Loss: 0.01643906719982624
Test Loss:  0.004866624716669321
Valid Loss:  0.00926918350160122
Epoch:  199  	Training Loss: 0.016427917405962944
Test Loss:  0.004863549955189228
Valid Loss:  0.00926222838461399
Epoch:  200  	Training Loss: 0.016416773200035095
Test Loss:  0.00486047612503171
Valid Loss:  0.00925527885556221
Epoch:  201  	Training Loss: 0.01640564203262329
Test Loss:  0.004857408348470926
Valid Loss:  0.009248325601220131
Epoch:  202  	Training Loss: 0.016394512727856636
Test Loss:  0.004854338243603706
Valid Loss:  0.009241335093975067
Epoch:  203  	Training Loss: 0.016383346170186996
Test Loss:  0.004851696081459522
Valid Loss:  0.009234340861439705
Epoch:  204  	Training Loss: 0.0163721926510334
Test Loss:  0.0048482827842235565
Valid Loss:  0.009227415546774864
Epoch:  205  	Training Loss: 0.016361061483621597
Test Loss:  0.0048487200401723385
Valid Loss:  0.009220371022820473
Epoch:  206  	Training Loss: 0.016349956393241882
Test Loss:  0.004842821042984724
Valid Loss:  0.009213849902153015
Epoch:  207  	Training Loss: 0.01633879914879799
Test Loss:  0.00484312791377306
Valid Loss:  0.009206898510456085
Epoch:  208  	Training Loss: 0.01632774993777275
Test Loss:  0.004837152548134327
Valid Loss:  0.009200436994433403
Epoch:  209  	Training Loss: 0.016316629946231842
Test Loss:  0.00483745988458395
Valid Loss:  0.009193552657961845
Epoch:  210  	Training Loss: 0.01630561426281929
Test Loss:  0.004830676130950451
Valid Loss:  0.009187141433358192
Epoch:  211  	Training Loss: 0.016294538974761963
Test Loss:  0.004831202328205109
Valid Loss:  0.009180202148854733
Epoch:  212  	Training Loss: 0.016283495351672173
Test Loss:  0.0048249103128910065
 43%|████▎     | 213/500 [02:31<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:32<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:32<02:07,  2.23it/s] 44%|████▍     | 219/500 [02:32<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:38<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:38<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:38<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:39<02:03,  2.22it/s] 46%|████▌     | 229/500 [02:39<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:45<05:21,  1.20s/it] 47%|████▋     | 233/500 [02:45<03:49,  1.17it/s] 47%|████▋     | 235/500 [02:45<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:46<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:46<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:52<05:08,  1.19s/it] 49%|████▊     | 243/500 [02:52<03:40,  1.17it/s] 49%|████▉     | 245/500 [02:52<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:52<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:53<01:26,  2.92it/s] 50%|█████     | 251/500 [02:59<04:57,  1.19s/it] 51%|█████     | 253/500 [02:59<03:31,  1.17it/s] 51%|█████     | 255/500 [02:59<02:31,  1.61it/s] 51%|█████▏    | 257/500 [02:59<01:50,  2.21it/s] 52%|█████▏    | 259/500 [03:00<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:06<04:42,  1.18s/it] 53%|█████▎    | 263/500 [03:06<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:06<02:23,  1.63it/s] 53%|█████▎    | 267/500 [03:06<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:06<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:13<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:13<03:16,  1.15it/s] 55%|█████▌    | 275/500 [03:13<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:13<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:13<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:20<04:17,  1.18s/it]Valid Loss:  0.009173799306154251
Epoch:  213  	Training Loss: 0.016272516921162605
Test Loss:  0.00482574850320816
Valid Loss:  0.009166977368295193
Epoch:  214  	Training Loss: 0.01626160927116871
Test Loss:  0.0048185111954808235
Valid Loss:  0.009160652756690979
Epoch:  215  	Training Loss: 0.016250722110271454
Test Loss:  0.004819569177925587
Valid Loss:  0.009153781458735466
Epoch:  216  	Training Loss: 0.01623981073498726
Test Loss:  0.004817023407667875
Valid Loss:  0.009147408418357372
Epoch:  217  	Training Loss: 0.01622895710170269
Test Loss:  0.004814529791474342
Valid Loss:  0.009141072630882263
Epoch:  218  	Training Loss: 0.01621812768280506
Test Loss:  0.004811587277799845
Valid Loss:  0.009134788066148758
Epoch:  219  	Training Loss: 0.016207311302423477
Test Loss:  0.004808546043932438
Valid Loss:  0.009128503501415253
Epoch:  220  	Training Loss: 0.016196507960557938
Test Loss:  0.004805488977581263
Valid Loss:  0.009122206829488277
Epoch:  221  	Training Loss: 0.01618572138249874
Test Loss:  0.004802435636520386
Valid Loss:  0.009115900844335556
Epoch:  222  	Training Loss: 0.01617494970560074
Test Loss:  0.0047994088381528854
Valid Loss:  0.009109631180763245
Epoch:  223  	Training Loss: 0.016164271160960197
Test Loss:  0.0047963946126401424
Valid Loss:  0.009103352203965187
Epoch:  224  	Training Loss: 0.01615361124277115
Test Loss:  0.004793387372046709
Valid Loss:  0.009097056463360786
Epoch:  225  	Training Loss: 0.016142962500452995
Test Loss:  0.00479038804769516
Valid Loss:  0.009090755134820938
Epoch:  226  	Training Loss: 0.016132328659296036
Test Loss:  0.004787396639585495
Valid Loss:  0.009084442630410194
Epoch:  227  	Training Loss: 0.01612170599400997
Test Loss:  0.004784411750733852
Valid Loss:  0.009078122675418854
Epoch:  228  	Training Loss: 0.0161110982298851
Test Loss:  0.004781437572091818
Valid Loss:  0.009071797132492065
Epoch:  229  	Training Loss: 0.016100505366921425
Test Loss:  0.0047789281234145164
Valid Loss:  0.009065461345016956
Epoch:  230  	Training Loss: 0.016089925542473793
Test Loss:  0.004775603301823139
Valid Loss:  0.009059170261025429
Epoch:  231  	Training Loss: 0.016079356893897057
Test Loss:  0.00477256253361702
Valid Loss:  0.009052833542227745
Epoch:  232  	Training Loss: 0.016068801283836365
Test Loss:  0.004769583232700825
Valid Loss:  0.009046397171914577
Epoch:  233  	Training Loss: 0.01605815440416336
Test Loss:  0.004770404659211636
Valid Loss:  0.009039973840117455
Epoch:  234  	Training Loss: 0.016047559678554535
Test Loss:  0.00476445397362113
Valid Loss:  0.009033954702317715
Epoch:  235  	Training Loss: 0.01603691093623638
Test Loss:  0.0047616977244615555
Valid Loss:  0.009027550928294659
Epoch:  236  	Training Loss: 0.016026290133595467
Test Loss:  0.004762330092489719
Valid Loss:  0.009021211415529251
Epoch:  237  	Training Loss: 0.016015740111470222
Test Loss:  0.004756579175591469
Valid Loss:  0.009015213698148727
Epoch:  238  	Training Loss: 0.016005126759409904
Test Loss:  0.004756554029881954
Valid Loss:  0.009008938446640968
Epoch:  239  	Training Loss: 0.015994597226381302
Test Loss:  0.004750657826662064
Valid Loss:  0.009002971462905407
Epoch:  240  	Training Loss: 0.01598403975367546
Test Loss:  0.0047510359436273575
Valid Loss:  0.008996637538075447
Epoch:  241  	Training Loss: 0.015973500907421112
Test Loss:  0.004744380712509155
Valid Loss:  0.008990924805402756
Epoch:  242  	Training Loss: 0.015963012352585793
Test Loss:  0.004745491314679384
Valid Loss:  0.008984262123703957
Epoch:  243  	Training Loss: 0.01595241390168667
Test Loss:  0.00474252225831151
Valid Loss:  0.008978317491710186
Epoch:  244  	Training Loss: 0.015941858291625977
Test Loss:  0.004736599046736956
Valid Loss:  0.008972672745585442
Epoch:  245  	Training Loss: 0.015931343659758568
Test Loss:  0.004736816976219416
Valid Loss:  0.008965996094048023
Epoch:  246  	Training Loss: 0.015920788049697876
Test Loss:  0.0047339205630123615
Valid Loss:  0.008959964849054813
Epoch:  247  	Training Loss: 0.015910247340798378
Test Loss:  0.004731134511530399
Valid Loss:  0.008953962475061417
Epoch:  248  	Training Loss: 0.015899723395705223
Test Loss:  0.004728678613901138
Valid Loss:  0.008947930298745632
Epoch:  249  	Training Loss: 0.015889205038547516
Test Loss:  0.0047258175909519196
Valid Loss:  0.00894198752939701
Epoch:  250  	Training Loss: 0.015878692269325256
Test Loss:  0.004723356105387211
Valid Loss:  0.008935989812016487
Epoch:  251  	Training Loss: 0.01586819440126419
Test Loss:  0.004720022901892662
Valid Loss:  0.008930118754506111
Epoch:  252  	Training Loss: 0.01585768535733223
Test Loss:  0.004716862924396992
Valid Loss:  0.008923780173063278
Epoch:  253  	Training Loss: 0.01584654115140438
Test Loss:  0.004713733214884996
Valid Loss:  0.008917409926652908
Epoch:  254  	Training Loss: 0.015835382044315338
Test Loss:  0.004710592795163393
Valid Loss:  0.008911016397178173
Epoch:  255  	Training Loss: 0.01582420989871025
Test Loss:  0.004707460291683674
Valid Loss:  0.00890459306538105
Epoch:  256  	Training Loss: 0.01581304334104061
Test Loss:  0.004708322696387768
Valid Loss:  0.008897526189684868
Epoch:  257  	Training Loss: 0.015801889821887016
Test Loss:  0.004702720791101456
Valid Loss:  0.00889173150062561
Epoch:  258  	Training Loss: 0.015790652483701706
Test Loss:  0.004699306096881628
Valid Loss:  0.008885391056537628
Epoch:  259  	Training Loss: 0.015779433771967888
Test Loss:  0.0046998243778944016
Valid Loss:  0.008878370746970177
Epoch:  260  	Training Loss: 0.015768248587846756
Test Loss:  0.004693751223385334
Valid Loss:  0.008872675709426403
Epoch:  261  	Training Loss: 0.015756972134113312
Test Loss:  0.004693669732660055
Valid Loss:  0.008865753188729286
Epoch:  262  	Training Loss: 0.015745755285024643
Test Loss:  0.004687756299972534
Valid Loss:  0.008860863745212555
Epoch:  263  	Training Loss: 0.01573590561747551
Test Loss:  0.0046885027550160885
Valid Loss:  0.008854610845446587
Epoch:  264  	Training Loss: 0.015726037323474884
Test Loss:  0.004681801423430443
Valid Loss:  0.00884985364973545
Epoch:  265  	Training Loss: 0.01571623422205448
Test Loss:  0.004683316685259342
Valid Loss:  0.008843395859003067
Epoch:  266  	Training Loss: 0.015706324949860573
Test Loss:  0.004679892212152481
Valid Loss:  0.008838094770908356
Epoch:  267  	Training Loss: 0.015696506947278976
Test Loss:  0.004674585536122322
Valid Loss:  0.008833025582134724
Epoch:  268  	Training Loss: 0.015686731785535812
Test Loss:  0.004675263538956642
Valid Loss:  0.00882675126194954
Epoch:  269  	Training Loss: 0.01567685976624489
Test Loss:  0.004672330804169178
Valid Loss:  0.008821342140436172
Epoch:  270  	Training Loss: 0.015667054802179337
Test Loss:  0.004670486785471439
Valid Loss:  0.008815735578536987
Epoch:  271  	Training Loss: 0.01565725915133953
Test Loss:  0.004667932633310556
Valid Loss:  0.008810298517346382
Epoch:  272  	Training Loss: 0.01564747840166092
Test Loss:  0.00466507114470005
Valid Loss:  0.00880456529557705
Epoch:  273  	Training Loss: 0.015637150034308434
Test Loss:  0.004662172868847847
Valid Loss:  0.008798820897936821
Epoch:  274  	Training Loss: 0.015626832842826843
Test Loss:  0.004659756552428007
Valid Loss:  0.008792994543910027
Epoch:  275  	Training Loss: 0.015616532415151596
Test Loss:  0.004655972123146057
Valid Loss:  0.00878739170730114
Epoch:  276  	Training Loss: 0.015606237575411797
Test Loss:  0.004654324613511562
Valid Loss:  0.00878138281404972
Epoch:  277  	Training Loss: 0.015595955774188042
Test Loss:  0.004650754854083061
Valid Loss:  0.008775752037763596
Epoch:  278  	Training Loss: 0.015585686080157757
Test Loss:  0.004647714551538229
Valid Loss:  0.008769968524575233
Epoch:  279  	Training Loss: 0.015575429424643517
Test Loss:  0.004644800443202257
Valid Loss:  0.008764135651290417
Epoch:  280  	Training Loss: 0.015565192326903343
Test Loss:  0.004646054469048977
Valid Loss:  0.008757704868912697
Epoch:  281  	Training Loss: 0.015555005520582199
Test Loss:  0.004639944992959499
Valid Loss:  0.008752649649977684
Epoch:  282  	Training Loss: 0.015544775873422623
Test Loss:  0.0046380069106817245
Valid Loss:   57%|█████▋    | 283/500 [03:20<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:20<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:20<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:20<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:27<04:11,  1.20s/it] 59%|█████▊    | 293/500 [03:27<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:27<02:07,  1.60it/s] 59%|█████▉    | 297/500 [03:27<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:27<01:08,  2.95it/s] 60%|██████    | 301/500 [03:34<03:59,  1.20s/it] 61%|██████    | 303/500 [03:34<02:49,  1.16it/s] 61%|██████    | 305/500 [03:34<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:34<01:27,  2.19it/s] 62%|██████▏   | 309/500 [03:34<01:04,  2.96it/s] 62%|██████▏   | 311/500 [03:40<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:41<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:41<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:41<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:41<01:01,  2.97it/s] 64%|██████▍   | 321/500 [03:47<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:48<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:48<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:48<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:48<00:57,  2.95it/s] 66%|██████▌   | 331/500 [03:54<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:55<02:23,  1.16it/s] 67%|██████▋   | 335/500 [03:55<01:43,  1.59it/s] 67%|██████▋   | 337/500 [03:55<01:15,  2.15it/s] 68%|██████▊   | 339/500 [03:55<00:56,  2.84it/s] 68%|██████▊   | 341/500 [04:01<03:11,  1.21s/it] 69%|██████▊   | 343/500 [04:02<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:02<01:38,  1.57it/s] 69%|██████▉   | 347/500 [04:02<01:11,  2.13it/s] 70%|██████▉   | 349/500 [04:02<00:53,  2.82it/s] 70%|███████   | 351/500 [04:09<02:59,  1.21s/it]0.0087466761469841
Epoch:  283  	Training Loss: 0.015534523874521255
Test Loss:  0.004637841135263443
Valid Loss:  0.008740548975765705
Epoch:  284  	Training Loss: 0.0155243631452322
Test Loss:  0.004632599651813507
Valid Loss:  0.008735311217606068
Epoch:  285  	Training Loss: 0.01551410835236311
Test Loss:  0.004632648080587387
Valid Loss:  0.008729144930839539
Epoch:  286  	Training Loss: 0.01550397276878357
Test Loss:  0.004626982845366001
Valid Loss:  0.008723977953195572
Epoch:  287  	Training Loss: 0.015493744984269142
Test Loss:  0.004626943729817867
Valid Loss:  0.008717789314687252
Epoch:  288  	Training Loss: 0.015483612194657326
Test Loss:  0.004621737636625767
Valid Loss:  0.008712525479495525
Epoch:  289  	Training Loss: 0.015473427250981331
Test Loss:  0.004621563944965601
Valid Loss:  0.008706357330083847
Epoch:  290  	Training Loss: 0.015463299117982388
Test Loss:  0.004615436308085918
Valid Loss:  0.008701231330633163
Epoch:  291  	Training Loss: 0.015453176572918892
Test Loss:  0.00461671594530344
Valid Loss:  0.00869477167725563
Epoch:  292  	Training Loss: 0.01544303447008133
Test Loss:  0.004613139200955629
Valid Loss:  0.008689424954354763
Epoch:  293  	Training Loss: 0.015433069318532944
Test Loss:  0.004607691429555416
Valid Loss:  0.008684265427291393
Epoch:  294  	Training Loss: 0.015423166565597057
Test Loss:  0.004608479328453541
Valid Loss:  0.008677947334945202
Epoch:  295  	Training Loss: 0.015413165092468262
Test Loss:  0.004605496302247047
Valid Loss:  0.008672472089529037
Epoch:  296  	Training Loss: 0.01540322694927454
Test Loss:  0.0046036625280976295
Valid Loss:  0.0086668087169528
Epoch:  297  	Training Loss: 0.015393303707242012
Test Loss:  0.004601091146469116
Valid Loss:  0.008661307394504547
Epoch:  298  	Training Loss: 0.015383397229015827
Test Loss:  0.004598359577357769
Valid Loss:  0.00865582562983036
Epoch:  299  	Training Loss: 0.015373501926660538
Test Loss:  0.004595596808940172
Valid Loss:  0.008650331757962704
Epoch:  300  	Training Loss: 0.015363620594143867
Test Loss:  0.0045928326435387135
Valid Loss:  0.00864482019096613
Epoch:  301  	Training Loss: 0.015353748574852943
Test Loss:  0.004590071737766266
Valid Loss:  0.008639289066195488
Epoch:  302  	Training Loss: 0.015343883074820042
Test Loss:  0.004587419331073761
Valid Loss:  0.008634140715003014
Epoch:  303  	Training Loss: 0.015334662050008774
Test Loss:  0.004584830719977617
Valid Loss:  0.008628957904875278
Epoch:  304  	Training Loss: 0.015325448475778103
Test Loss:  0.004582260735332966
Valid Loss:  0.00862376019358635
Epoch:  305  	Training Loss: 0.015316247940063477
Test Loss:  0.0045796968042850494
Valid Loss:  0.008618547581136227
Epoch:  306  	Training Loss: 0.015307056717574596
Test Loss:  0.004577137064188719
Valid Loss:  0.00861332006752491
Epoch:  307  	Training Loss: 0.015297877602279186
Test Loss:  0.004574582912027836
Valid Loss:  0.008608083240687847
Epoch:  308  	Training Loss: 0.015288710594177246
Test Loss:  0.004572033882141113
Valid Loss:  0.008602830581367016
Epoch:  309  	Training Loss: 0.015279552899301052
Test Loss:  0.004569488577544689
Valid Loss:  0.00859756674617529
Epoch:  310  	Training Loss: 0.015270404517650604
Test Loss:  0.004566949326545
Valid Loss:  0.00859229639172554
Epoch:  311  	Training Loss: 0.015261269174516201
Test Loss:  0.00456441193819046
Valid Loss:  0.008587008342146873
Epoch:  312  	Training Loss: 0.01525214035063982
Test Loss:  0.004561800975352526
Valid Loss:  0.00858139619231224
Epoch:  313  	Training Loss: 0.015242530964314938
Test Loss:  0.004559141583740711
Valid Loss:  0.008575787767767906
Epoch:  314  	Training Loss: 0.015232931822538376
Test Loss:  0.004556475672870874
Valid Loss:  0.0085701709613204
Epoch:  315  	Training Loss: 0.015223342925310135
Test Loss:  0.0045538111589848995
Valid Loss:  0.008564544841647148
Epoch:  316  	Training Loss: 0.01521376334130764
Test Loss:  0.004551151767373085
Valid Loss:  0.008558917790651321
Epoch:  317  	Training Loss: 0.01520419493317604
Test Loss:  0.0045484937727451324
Valid Loss:  0.008553281426429749
Epoch:  318  	Training Loss: 0.015194633044302464
Test Loss:  0.0045458413660526276
Valid Loss:  0.008547639474272728
Epoch:  319  	Training Loss: 0.015185085125267506
Test Loss:  0.004543190356343985
Valid Loss:  0.008541993796825409
Epoch:  320  	Training Loss: 0.01517554372549057
Test Loss:  0.00454054307192564
Valid Loss:  0.008536339737474918
Epoch:  321  	Training Loss: 0.015166012570261955
Test Loss:  0.004537899512797594
Valid Loss:  0.008530684746801853
Epoch:  322  	Training Loss: 0.015156490728259087
Test Loss:  0.004535217769443989
Valid Loss:  0.008524870499968529
Epoch:  323  	Training Loss: 0.015146736055612564
Test Loss:  0.004532520193606615
Valid Loss:  0.008519057184457779
Epoch:  324  	Training Loss: 0.01513698697090149
Test Loss:  0.0045298198238015175
Valid Loss:  0.008513243868947029
Epoch:  325  	Training Loss: 0.01512724906206131
Test Loss:  0.004527120850980282
Valid Loss:  0.008507423102855682
Epoch:  326  	Training Loss: 0.015117517672479153
Test Loss:  0.004524423740804195
Valid Loss:  0.008501598611474037
Epoch:  327  	Training Loss: 0.015107794664800167
Test Loss:  0.004521729424595833
Valid Loss:  0.008495775982737541
Epoch:  328  	Training Loss: 0.01509807724505663
Test Loss:  0.004519038833677769
Valid Loss:  0.008489945903420448
Epoch:  329  	Training Loss: 0.015088370069861412
Test Loss:  0.0045163510367274284
Valid Loss:  0.008484113961458206
Epoch:  330  	Training Loss: 0.015078670345246792
Test Loss:  0.004513666965067387
Valid Loss:  0.008478283882141113
Epoch:  331  	Training Loss: 0.01506897620856762
Test Loss:  0.004510983824729919
Valid Loss:  0.008472447283565998
Epoch:  332  	Training Loss: 0.015059294179081917
Test Loss:  0.0045083146542310715
Valid Loss:  0.008466620929539204
Epoch:  333  	Training Loss: 0.015049642883241177
Test Loss:  0.004505646415054798
Valid Loss:  0.008460795506834984
Epoch:  334  	Training Loss: 0.015040003694593906
Test Loss:  0.004502980038523674
Valid Loss:  0.00845496915280819
Epoch:  335  	Training Loss: 0.01503036916255951
Test Loss:  0.004500315058976412
Valid Loss:  0.008449140004813671
Epoch:  336  	Training Loss: 0.015020742081105709
Test Loss:  0.004498191177845001
Valid Loss:  0.008443238213658333
Epoch:  337  	Training Loss: 0.015011131763458252
Test Loss:  0.004495113156735897
Valid Loss:  0.008437523618340492
Epoch:  338  	Training Loss: 0.01500152237713337
Test Loss:  0.0044923643581569195
Valid Loss:  0.008431719616055489
Epoch:  339  	Training Loss: 0.01499191951006651
Test Loss:  0.004489689599722624
Valid Loss:  0.008425894193351269
Epoch:  340  	Training Loss: 0.014982324093580246
Test Loss:  0.004487033002078533
Valid Loss:  0.008420067839324474
Epoch:  341  	Training Loss: 0.014972750097513199
Test Loss:  0.0044888341799378395
Valid Loss:  0.008413647301495075
Epoch:  342  	Training Loss: 0.014963241294026375
Test Loss:  0.004483185708522797
Valid Loss:  0.008408297784626484
Epoch:  343  	Training Loss: 0.014953158795833588
Test Loss:  0.004479729570448399
Valid Loss:  0.008402392268180847
Epoch:  344  	Training Loss: 0.014943142421543598
Test Loss:  0.0044813090935349464
Valid Loss:  0.008395773358643055
Epoch:  345  	Training Loss: 0.014933167956769466
Test Loss:  0.004474994260817766
Valid Loss:  0.00839055236428976
Epoch:  346  	Training Loss: 0.014923123642802238
Test Loss:  0.004475949797779322
Valid Loss:  0.008384069427847862
Epoch:  347  	Training Loss: 0.014913160353899002
Test Loss:  0.004470242187380791
Valid Loss:  0.00837874598801136
Epoch:  348  	Training Loss: 0.014903159812092781
Test Loss:  0.004471844062209129
Valid Loss:  0.008372236043214798
Epoch:  349  	Training Loss: 0.014893189072608948
Test Loss:  0.004463789984583855
Valid Loss:  0.00836733728647232
Epoch:  350  	Training Loss: 0.014883267693221569
Test Loss:  0.004466114565730095
Valid Loss:  0.00836060382425785
Epoch:  351  	Training Loss: 0.014873250387609005
Test Loss:  0.004463225603103638
Valid Loss:  0.00835501216351986
Epoch:  352  	Training Loss: 0.014863315038383007
Test Loss:  0.004461758770048618
Valid Loss:  0.008349496871232986
 71%|███████   | 353/500 [04:09<02:07,  1.16it/s] 71%|███████   | 355/500 [04:09<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:09<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:09<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:16<02:47,  1.21s/it] 73%|███████▎  | 363/500 [04:16<01:59,  1.15it/s] 73%|███████▎  | 365/500 [04:16<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:16<01:01,  2.18it/s] 74%|███████▍  | 369/500 [04:16<00:44,  2.93it/s] 74%|███████▍  | 371/500 [04:23<02:36,  1.21s/it] 75%|███████▍  | 373/500 [04:23<01:50,  1.15it/s] 75%|███████▌  | 375/500 [04:23<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:23<00:56,  2.17it/s] 76%|███████▌  | 379/500 [04:23<00:42,  2.87it/s] 76%|███████▌  | 381/500 [04:30<02:23,  1.21s/it] 77%|███████▋  | 383/500 [04:30<01:41,  1.15it/s] 77%|███████▋  | 385/500 [04:30<01:12,  1.59it/s] 77%|███████▋  | 387/500 [04:30<00:52,  2.15it/s] 78%|███████▊  | 389/500 [04:30<00:39,  2.84it/s] 78%|███████▊  | 391/500 [04:37<02:11,  1.21s/it] 79%|███████▊  | 393/500 [04:37<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:37<01:05,  1.59it/s] 79%|███████▉  | 397/500 [04:37<00:47,  2.17it/s] 80%|███████▉  | 399/500 [04:37<00:34,  2.93it/s] 80%|████████  | 401/500 [04:44<01:59,  1.20s/it] 81%|████████  | 403/500 [04:44<01:23,  1.16it/s] 81%|████████  | 405/500 [04:44<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:44<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:44<00:30,  2.95it/s] 82%|████████▏ | 411/500 [04:51<01:49,  1.23s/it] 83%|████████▎ | 413/500 [04:51<01:16,  1.13it/s] 83%|████████▎ | 415/500 [04:51<00:54,  1.57it/s] 83%|████████▎ | 417/500 [04:51<00:38,  2.15it/s] 84%|████████▍ | 419/500 [04:51<00:27,  2.89it/s] 84%|████████▍ | 421/500 [04:58<01:37,  1.23s/it]Epoch:  353  	Training Loss: 0.014853809028863907
Test Loss:  0.004458825569599867
Valid Loss:  0.008344237692654133
Epoch:  354  	Training Loss: 0.014844320714473724
Test Loss:  0.004456679802387953
Valid Loss:  0.008338846266269684
Epoch:  355  	Training Loss: 0.014834845438599586
Test Loss:  0.004454157315194607
Valid Loss:  0.008333527483046055
Epoch:  356  	Training Loss: 0.014825383201241493
Test Loss:  0.0044515603221952915
Valid Loss:  0.008328206837177277
Epoch:  357  	Training Loss: 0.014815934002399445
Test Loss:  0.004448944702744484
Valid Loss:  0.008322876878082752
Epoch:  358  	Training Loss: 0.014806491322815418
Test Loss:  0.004446329548954964
Valid Loss:  0.00831753108650446
Epoch:  359  	Training Loss: 0.014797065407037735
Test Loss:  0.004443716257810593
Valid Loss:  0.008312169462442398
Epoch:  360  	Training Loss: 0.014787647873163223
Test Loss:  0.004441107623279095
Valid Loss:  0.008306793868541718
Epoch:  361  	Training Loss: 0.014778239652514458
Test Loss:  0.004438502714037895
Valid Loss:  0.008301405236124992
Epoch:  362  	Training Loss: 0.014768846333026886
Test Loss:  0.004435906186699867
Valid Loss:  0.008296050131320953
Epoch:  363  	Training Loss: 0.014759520068764687
Test Loss:  0.004433325491845608
Valid Loss:  0.00829068012535572
Epoch:  364  	Training Loss: 0.014750201255083084
Test Loss:  0.004430748522281647
Valid Loss:  0.008285298012197018
Epoch:  365  	Training Loss: 0.014740901067852974
Test Loss:  0.0044281757436692715
Valid Loss:  0.00827990286052227
Epoch:  366  	Training Loss: 0.014731600880622864
Test Loss:  0.004425605293363333
Valid Loss:  0.008274494670331478
Epoch:  367  	Training Loss: 0.0147223100066185
Test Loss:  0.00442303903400898
Valid Loss:  0.00826907716691494
Epoch:  368  	Training Loss: 0.014713026583194733
Test Loss:  0.0044204723089933395
Valid Loss:  0.00826365314424038
Epoch:  369  	Training Loss: 0.014703751541674137
Test Loss:  0.004417910240590572
Valid Loss:  0.008258216083049774
Epoch:  370  	Training Loss: 0.014694483950734138
Test Loss:  0.004415350034832954
Valid Loss:  0.008252773433923721
Epoch:  371  	Training Loss: 0.014685224741697311
Test Loss:  0.004412791691720486
Valid Loss:  0.008247319608926773
Epoch:  372  	Training Loss: 0.014675970189273357
Test Loss:  0.004410808905959129
Valid Loss:  0.008241798728704453
Epoch:  373  	Training Loss: 0.014666750095784664
Test Loss:  0.004407819826155901
Valid Loss:  0.00823644082993269
Epoch:  374  	Training Loss: 0.014657528139650822
Test Loss:  0.0044051771983504295
Valid Loss:  0.008230993524193764
Epoch:  375  	Training Loss: 0.014648313634097576
Test Loss:  0.004402611870318651
Valid Loss:  0.008225519210100174
Epoch:  376  	Training Loss: 0.014639106579124928
Test Loss:  0.004400062374770641
Valid Loss:  0.008220041170716286
Epoch:  377  	Training Loss: 0.0146299097687006
Test Loss:  0.0043980423361063
Valid Loss:  0.008214488625526428
Epoch:  378  	Training Loss: 0.014620722271502018
Test Loss:  0.004395108669996262
Valid Loss:  0.008209096267819405
Epoch:  379  	Training Loss: 0.014611570164561272
Test Loss:  0.004397745709866285
Valid Loss:  0.008203034289181232
Epoch:  380  	Training Loss: 0.014602456241846085
Test Loss:  0.004391082096844912
Valid Loss:  0.008198481053113937
Epoch:  381  	Training Loss: 0.014593260362744331
Test Loss:  0.004389525391161442
Valid Loss:  0.008192939683794975
Epoch:  382  	Training Loss: 0.01458415761590004
Test Loss:  0.004390063229948282
Valid Loss:  0.008187309838831425
Epoch:  383  	Training Loss: 0.014575088396668434
Test Loss:  0.004384280182421207
Valid Loss:  0.008182594552636147
Epoch:  384  	Training Loss: 0.014565978199243546
Test Loss:  0.004386100452393293
Valid Loss:  0.008176751434803009
Epoch:  385  	Training Loss: 0.014556884765625
Test Loss:  0.0043800221756100655
Valid Loss:  0.008172127418220043
Epoch:  386  	Training Loss: 0.014547797851264477
Test Loss:  0.004381508566439152
Valid Loss:  0.008166352286934853
Epoch:  387  	Training Loss: 0.01453869417309761
Test Loss:  0.004374888259917498
Valid Loss:  0.008161773905158043
Epoch:  388  	Training Loss: 0.014529619365930557
Test Loss:  0.004376423545181751
Valid Loss:  0.008155982941389084
Epoch:  389  	Training Loss: 0.014520576223731041
Test Loss:  0.004374080803245306
Valid Loss:  0.008150950074195862
Epoch:  390  	Training Loss: 0.01451152190566063
Test Loss:  0.004372952971607447
Valid Loss:  0.008145790547132492
Epoch:  391  	Training Loss: 0.014502506703138351
Test Loss:  0.004370769020169973
Valid Loss:  0.008140837773680687
Epoch:  392  	Training Loss: 0.014493502676486969
Test Loss:  0.00436835503205657
Valid Loss:  0.008135881274938583
Epoch:  393  	Training Loss: 0.014484476298093796
Test Loss:  0.004365889355540276
Valid Loss:  0.008130913600325584
Epoch:  394  	Training Loss: 0.014475459232926369
Test Loss:  0.004363413900136948
Valid Loss:  0.008125923573970795
Epoch:  395  	Training Loss: 0.014466453343629837
Test Loss:  0.004360937513411045
Valid Loss:  0.008120916783809662
Epoch:  396  	Training Loss: 0.014457454904913902
Test Loss:  0.004358463920652866
Valid Loss:  0.008115886710584164
Epoch:  397  	Training Loss: 0.014448468573391438
Test Loss:  0.004355991259217262
Valid Loss:  0.008110841736197472
Epoch:  398  	Training Loss: 0.014439492486417294
Test Loss:  0.004353523254394531
Valid Loss:  0.008105776272714138
Epoch:  399  	Training Loss: 0.014430524781346321
Test Loss:  0.004351058509200811
Valid Loss:  0.00810069590806961
Epoch:  400  	Training Loss: 0.014421564526855946
Test Loss:  0.0043485937640070915
Valid Loss:  0.008095597848296165
Epoch:  401  	Training Loss: 0.014412613585591316
Test Loss:  0.004346132278442383
Valid Loss:  0.008090481162071228
Epoch:  402  	Training Loss: 0.014403671026229858
Test Loss:  0.004343669395893812
Valid Loss:  0.008085350506007671
Epoch:  403  	Training Loss: 0.014394721947610378
Test Loss:  0.004341207444667816
Valid Loss:  0.008080202154815197
Epoch:  404  	Training Loss: 0.014385780319571495
Test Loss:  0.004338749684393406
Valid Loss:  0.008075037971138954
Epoch:  405  	Training Loss: 0.014376846142113209
Test Loss:  0.004336291924118996
Valid Loss:  0.00806986540555954
Epoch:  406  	Training Loss: 0.01436791941523552
Test Loss:  0.004333837889134884
Valid Loss:  0.008064676076173782
Epoch:  407  	Training Loss: 0.014358993619680405
Test Loss:  0.004331384785473347
Valid Loss:  0.008059476502239704
Epoch:  408  	Training Loss: 0.014350080862641335
Test Loss:  0.004328933544456959
Valid Loss:  0.00805426761507988
Epoch:  409  	Training Loss: 0.014341173693537712
Test Loss:  0.0043264832347631454
Valid Loss:  0.008049044758081436
Epoch:  410  	Training Loss: 0.014332273975014687
Test Loss:  0.004324035719037056
Valid Loss:  0.008043818175792694
Epoch:  411  	Training Loss: 0.01432337798178196
Test Loss:  0.004321587271988392
Valid Loss:  0.008038576692342758
Epoch:  412  	Training Loss: 0.01431448943912983
Test Loss:  0.004319140687584877
Valid Loss:  0.008033321239054203
Epoch:  413  	Training Loss: 0.014305595308542252
Test Loss:  0.004316694103181362
Valid Loss:  0.008028053678572178
Epoch:  414  	Training Loss: 0.01429671235382557
Test Loss:  0.004314246587455273
Valid Loss:  0.00802278146147728
Epoch:  415  	Training Loss: 0.014287835918366909
Test Loss:  0.004311803728342056
Valid Loss:  0.008017504587769508
Epoch:  416  	Training Loss: 0.014278963208198547
Test Loss:  0.004309359937906265
Valid Loss:  0.008012223988771439
Epoch:  417  	Training Loss: 0.014270102605223656
Test Loss:  0.004306918941438198
Valid Loss:  0.008006932213902473
Epoch:  418  	Training Loss: 0.014261245727539062
Test Loss:  0.004304480738937855
Valid Loss:  0.008001638576388359
Epoch:  419  	Training Loss: 0.014252393506467342
Test Loss:  0.0043020411394536495
Valid Loss:  0.007996339350938797
Epoch:  420  	Training Loss: 0.014243547804653645
Test Loss:  0.004299604333937168
Valid Loss:  0.007991034537553787
Epoch:  421  	Training Loss: 0.014234712347388268
Test Loss:  0.004297170322388411
Valid Loss:  0.007985725998878479
Epoch:  422  	Training Loss: 0.014225879684090614
Test Loss:  0.004294738173484802
Valid Loss:  0.007980425842106342
 85%|████████▍ | 423/500 [04:58<01:08,  1.13it/s] 85%|████████▌ | 425/500 [04:58<00:47,  1.56it/s] 85%|████████▌ | 427/500 [04:58<00:34,  2.14it/s] 86%|████████▌ | 429/500 [04:58<00:24,  2.89it/s] 86%|████████▌ | 431/500 [05:05<01:25,  1.23s/it] 87%|████████▋ | 433/500 [05:05<00:59,  1.13it/s] 87%|████████▋ | 435/500 [05:05<00:41,  1.57it/s] 87%|████████▋ | 437/500 [05:05<00:29,  2.14it/s] 88%|████████▊ | 439/500 [05:06<00:21,  2.89it/s] 88%|████████▊ | 441/500 [05:12<01:12,  1.23s/it] 89%|████████▊ | 443/500 [05:12<00:50,  1.13it/s] 89%|████████▉ | 445/500 [05:12<00:35,  1.57it/s] 89%|████████▉ | 447/500 [05:13<00:24,  2.15it/s] 90%|████████▉ | 449/500 [05:13<00:17,  2.90it/s] 90%|█████████ | 451/500 [05:19<00:59,  1.22s/it] 91%|█████████ | 453/500 [05:19<00:41,  1.14it/s] 91%|█████████ | 455/500 [05:19<00:28,  1.58it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.16it/s] 92%|█████████▏| 459/500 [05:20<00:14,  2.92it/s] 92%|█████████▏| 461/500 [05:26<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:27<00:15,  2.18it/s] 94%|█████████▍| 469/500 [05:27<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:33<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:33<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.60it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.18it/s] 96%|█████████▌| 479/500 [05:34<00:07,  2.94it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.17it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.92it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.18s/it]Epoch:  423  	Training Loss: 0.014217067509889603
Test Loss:  0.004292309284210205
Valid Loss:  0.007975120097398758
Epoch:  424  	Training Loss: 0.014208259992301464
Test Loss:  0.004289884120225906
Valid Loss:  0.0079698096960783
Epoch:  425  	Training Loss: 0.014199460856616497
Test Loss:  0.0042874617502093315
Valid Loss:  0.007964495569467545
Epoch:  426  	Training Loss: 0.014190668240189552
Test Loss:  0.004285040311515331
Valid Loss:  0.007959185168147087
Epoch:  427  	Training Loss: 0.01418188214302063
Test Loss:  0.004282619804143906
Valid Loss:  0.007953867316246033
Epoch:  428  	Training Loss: 0.014173097908496857
Test Loss:  0.004280802793800831
Valid Loss:  0.007948484271764755
Epoch:  429  	Training Loss: 0.014164327643811703
Test Loss:  0.004277918487787247
Valid Loss:  0.007943268865346909
Epoch:  430  	Training Loss: 0.014155590906739235
Test Loss:  0.00428039813414216
Valid Loss:  0.007937497459352016
Epoch:  431  	Training Loss: 0.014146903529763222
Test Loss:  0.004274625331163406
Valid Loss:  0.007932957261800766
Epoch:  432  	Training Loss: 0.014138095080852509
Test Loss:  0.004271510988473892
Valid Loss:  0.007927625440061092
Epoch:  433  	Training Loss: 0.01412908174097538
Test Loss:  0.004274670500308275
Valid Loss:  0.007921612821519375
Epoch:  434  	Training Loss: 0.01412007212638855
Test Loss:  0.004267027135938406
Valid Loss:  0.007917162030935287
Epoch:  435  	Training Loss: 0.01411102619022131
Test Loss:  0.004270459990948439
Valid Loss:  0.007911144755780697
Epoch:  436  	Training Loss: 0.01410201471298933
Test Loss:  0.004262253176420927
Valid Loss:  0.007906779646873474
Epoch:  437  	Training Loss: 0.014093015342950821
Test Loss:  0.004265554714947939
Valid Loss:  0.007900754921138287
Epoch:  438  	Training Loss: 0.01408396102488041
Test Loss:  0.004257926717400551
Valid Loss:  0.007896308787167072
Epoch:  439  	Training Loss: 0.014075014740228653
Test Loss:  0.0042607542127370834
Valid Loss:  0.00789035763591528
Epoch:  440  	Training Loss: 0.014065971598029137
Test Loss:  0.004258821718394756
Valid Loss:  0.007885363884270191
Epoch:  441  	Training Loss: 0.014056993648409843
Test Loss:  0.004255709238350391
Valid Loss:  0.007880499586462975
Epoch:  442  	Training Loss: 0.014048026874661446
Test Loss:  0.004254617728292942
Valid Loss:  0.007875767536461353
Epoch:  443  	Training Loss: 0.01403970830142498
Test Loss:  0.004252604674547911
Valid Loss:  0.007871213369071484
Epoch:  444  	Training Loss: 0.014031415805220604
Test Loss:  0.004250410944223404
Valid Loss:  0.007866675034165382
Epoch:  445  	Training Loss: 0.014023139141499996
Test Loss:  0.004248177632689476
Valid Loss:  0.007862130180001259
Epoch:  446  	Training Loss: 0.014014877378940582
Test Loss:  0.0042459312826395035
Valid Loss:  0.007857564836740494
Epoch:  447  	Training Loss: 0.01400662586092949
Test Loss:  0.0042436858639121056
Valid Loss:  0.007852979004383087
Epoch:  448  	Training Loss: 0.013998379930853844
Test Loss:  0.004241441376507282
Valid Loss:  0.00784837082028389
Epoch:  449  	Training Loss: 0.013990148901939392
Test Loss:  0.004239201080054045
Valid Loss:  0.007843749597668648
Epoch:  450  	Training Loss: 0.013981922529637814
Test Loss:  0.004236957989633083
Valid Loss:  0.007839111611247063
Epoch:  451  	Training Loss: 0.013973711058497429
Test Loss:  0.004234719090163708
Valid Loss:  0.007834458723664284
Epoch:  452  	Training Loss: 0.013965505175292492
Test Loss:  0.0042324187234044075
Valid Loss:  0.007829604670405388
Epoch:  453  	Training Loss: 0.013956984505057335
Test Loss:  0.004230101592838764
Valid Loss:  0.007824737578630447
Epoch:  454  	Training Loss: 0.013948464766144753
Test Loss:  0.004227778874337673
Valid Loss:  0.007819854654371738
Epoch:  455  	Training Loss: 0.013939952477812767
Test Loss:  0.004225456155836582
Valid Loss:  0.00781495776027441
Epoch:  456  	Training Loss: 0.013931452296674252
Test Loss:  0.004223134368658066
Valid Loss:  0.00781004736199975
Epoch:  457  	Training Loss: 0.013922951184213161
Test Loss:  0.004220814444124699
Valid Loss:  0.00780512485653162
Epoch:  458  	Training Loss: 0.013914458453655243
Test Loss:  0.004218494985252619
Valid Loss:  0.007800186052918434
Epoch:  459  	Training Loss: 0.01390597503632307
Test Loss:  0.004216174595057964
Valid Loss:  0.007795237936079502
Epoch:  460  	Training Loss: 0.013897492550313473
Test Loss:  0.004213855601847172
Valid Loss:  0.007790274918079376
Epoch:  461  	Training Loss: 0.013889014720916748
Test Loss:  0.004211538005620241
Valid Loss:  0.0077853030525147915
Epoch:  462  	Training Loss: 0.013880545273423195
Test Loss:  0.0042093675583601
Valid Loss:  0.00778069905936718
Epoch:  463  	Training Loss: 0.013872778043150902
Test Loss:  0.0042072320356965065
Valid Loss:  0.007776082493364811
Epoch:  464  	Training Loss: 0.013865016400814056
Test Loss:  0.004205101635307074
Valid Loss:  0.007771461270749569
Epoch:  465  	Training Loss: 0.013857265934348106
Test Loss:  0.004202973563224077
Valid Loss:  0.007766835391521454
Epoch:  466  	Training Loss: 0.013849521987140179
Test Loss:  0.004200848750770092
Valid Loss:  0.0077622029930353165
Epoch:  467  	Training Loss: 0.013841785490512848
Test Loss:  0.004198726266622543
Valid Loss:  0.007757571525871754
Epoch:  468  	Training Loss: 0.013834061101078987
Test Loss:  0.004196605645120144
Valid Loss:  0.007752940058708191
Epoch:  469  	Training Loss: 0.013826344162225723
Test Loss:  0.004194488283246756
Valid Loss:  0.007748300675302744
Epoch:  470  	Training Loss: 0.013818636536598206
Test Loss:  0.004192370921373367
Valid Loss:  0.007743661291897297
Epoch:  471  	Training Loss: 0.013810936361551285
Test Loss:  0.0041902558878064156
Valid Loss:  0.007739020511507988
Epoch:  472  	Training Loss: 0.013803246431052685
Test Loss:  0.0041879927739501
Valid Loss:  0.007733957841992378
Epoch:  473  	Training Loss: 0.01379481516778469
Test Loss:  0.004185691010206938
Valid Loss:  0.007728902623057365
Epoch:  474  	Training Loss: 0.01378639042377472
Test Loss:  0.004183380864560604
Valid Loss:  0.007723845075815916
Epoch:  475  	Training Loss: 0.01377797406166792
Test Loss:  0.004181072115898132
Valid Loss:  0.007718782871961594
Epoch:  476  	Training Loss: 0.01376956794410944
Test Loss:  0.004179397597908974
Valid Loss:  0.007713657803833485
Epoch:  477  	Training Loss: 0.013761166483163834
Test Loss:  0.004177183378487825
Valid Loss:  0.007708650082349777
Epoch:  478  	Training Loss: 0.013752792030572891
Test Loss:  0.004179602488875389
Valid Loss:  0.007703300565481186
Epoch:  479  	Training Loss: 0.013744535855948925
Test Loss:  0.004173065535724163
Valid Loss:  0.007699073292315006
Epoch:  480  	Training Loss: 0.013736099004745483
Test Loss:  0.004171955399215221
Valid Loss:  0.007693940307945013
Epoch:  481  	Training Loss: 0.01372772641479969
Test Loss:  0.004173131659626961
Valid Loss:  0.007688817568123341
Epoch:  482  	Training Loss: 0.013719458132982254
Test Loss:  0.00416629808023572
Valid Loss:  0.007684525102376938
Epoch:  483  	Training Loss: 0.013710971921682358
Test Loss:  0.00417041452601552
Valid Loss:  0.0076787760481238365
Epoch:  484  	Training Loss: 0.013702359050512314
Test Loss:  0.0041620624251663685
Valid Loss:  0.007674757856875658
Epoch:  485  	Training Loss: 0.013693908229470253
Test Loss:  0.004165854305028915
Valid Loss:  0.007669039070606232
Epoch:  486  	Training Loss: 0.013685271143913269
Test Loss:  0.004158065654337406
Valid Loss:  0.007664949167519808
Epoch:  487  	Training Loss: 0.01367686502635479
Test Loss:  0.004161354154348373
Valid Loss:  0.007659308146685362
Epoch:  488  	Training Loss: 0.013668224215507507
Test Loss:  0.004154294729232788
Valid Loss:  0.007655120454728603
Epoch:  489  	Training Loss: 0.013659847900271416
Test Loss:  0.004156898241490126
Valid Loss:  0.007649594452232122
Epoch:  490  	Training Loss: 0.013651258312165737
Test Loss:  0.004153524991124868
Valid Loss:  0.007645072415471077
Epoch:  491  	Training Loss: 0.013642784208059311
Test Loss:  0.0041531347669661045
Valid Loss:  0.007640167139470577
Epoch:  492  	Training Loss: 0.013634285889565945
Test Loss:  0.004151268862187862
Valid Loss:  0.007635645568370819
 99%|█████████▊| 493/500 [05:47<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:47<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:47<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:47<00:00,  2.98it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
Epoch:  493  	Training Loss: 0.013625982217490673
Test Loss:  0.004149114713072777
Valid Loss:  0.007631149608641863
Epoch:  494  	Training Loss: 0.013617685064673424
Test Loss:  0.004146898631006479
Valid Loss:  0.007626641541719437
Epoch:  495  	Training Loss: 0.013609396293759346
Test Loss:  0.004144671373069286
Valid Loss:  0.007622112054377794
Epoch:  496  	Training Loss: 0.013601118698716164
Test Loss:  0.004142440855503082
Valid Loss:  0.007617558352649212
Epoch:  497  	Training Loss: 0.01359284482896328
Test Loss:  0.004140211269259453
Valid Loss:  0.007612979039549828
Epoch:  498  	Training Loss: 0.013584583066403866
Test Loss:  0.004137980751693249
Valid Loss:  0.007608379237353802
Epoch:  499  	Training Loss: 0.013576330617070198
Test Loss:  0.004135751165449619
Valid Loss:  0.00760375801473856
Epoch:  500  	Training Loss: 0.013568084686994553
Test Loss:  0.00413352157920599
Valid Loss:  0.007599121890962124
seed is  9
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:06,  6.27s/it]  1%|          | 3/500 [00:06<13:52,  1.68s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:13<10:56,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:19<13:17,  1.64s/it]  3%|▎         | 17/500 [00:19<09:14,  1.15s/it]  4%|▍         | 19/500 [00:19<06:30,  1.23it/s]  4%|▍         | 21/500 [00:32<19:46,  2.48s/it]  5%|▍         | 23/500 [00:32<13:51,  1.74s/it]  5%|▌         | 25/500 [00:38<17:15,  2.18s/it]  5%|▌         | 27/500 [00:39<12:09,  1.54s/it]  6%|▌         | 29/500 [00:39<08:36,  1.10s/it]  6%|▌         | 31/500 [00:51<20:50,  2.67s/it]  7%|▋         | 33/500 [00:51<14:40,  1.89s/it]  7%|▋         | 35/500 [00:58<17:38,  2.28s/it]  7%|▋         | 37/500 [00:58<12:27,  1.61s/it]  8%|▊         | 39/500 [00:58<08:49,  1.15s/it]  8%|▊         | 41/500 [01:11<20:32,  2.69s/it]  9%|▊         | 43/500 [01:11<14:28,  1.90s/it]  9%|▉         | 45/500 [01:17<17:18,  2.28s/it]  9%|▉         | 47/500 [01:17<12:14,  1.62s/it] 10%|▉         | 49/500 [01:17<08:40,  1.15s/it] 10%|█         | 51/500 [01:30<20:03,  2.68s/it] 11%|█         | 53/500 [01:30<14:08,  1.90s/it] 11%|█         | 55/500 [01:36<16:55,  2.28s/it] 11%|█▏        | 57/500 [01:37<11:57,  1.62s/it] 12%|█▏        | 59/500 [01:37<08:28,  1.15s/it] 12%|█▏        | 61/500 [01:49<19:39,  2.69s/it]Epoch:  1  	Training Loss: 0.07082174718379974
Test Loss:  1.5070092678070068
Valid Loss:  1.4939013719558716
Epoch:  2  	Training Loss: 1.5545172691345215
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  3  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  4  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  5  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  6  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  7  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  8  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  9  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  10  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  11  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  12  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  13  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  14  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  15  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  17  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  18  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  19  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
Epoch:  20  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  22  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  23  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  24  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  25  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  27  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  28  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  29  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  30  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  32  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  33  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
Epoch:  34  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  35  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  37  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  38  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  39  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  40  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  42  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  43  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  44  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  45  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  47  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  48  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  49  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  50  	Training Loss: 0.08508483320474625
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  52  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  53  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  54  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
Epoch:  55  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  57  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  58  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  59  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  60  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  62  	Training Loss: 0.08508484065532684
Test Loss:  0.11678128689527512
Valid Loss:   13%|█▎        | 63/500 [01:49<13:51,  1.90s/it] 13%|█▎        | 65/500 [01:56<16:25,  2.27s/it] 13%|█▎        | 67/500 [01:56<11:36,  1.61s/it] 14%|█▍        | 69/500 [01:56<08:13,  1.15s/it] 14%|█▍        | 71/500 [02:08<19:05,  2.67s/it] 15%|█▍        | 73/500 [02:08<13:26,  1.89s/it] 15%|█▌        | 75/500 [02:15<16:06,  2.27s/it] 15%|█▌        | 77/500 [02:15<11:22,  1.61s/it] 16%|█▌        | 79/500 [02:15<08:03,  1.15s/it] 16%|█▌        | 79/500 [02:26<08:03,  1.15s/it] 16%|█▌        | 81/500 [02:28<18:41,  2.68s/it] 17%|█▋        | 83/500 [02:28<13:10,  1.90s/it] 17%|█▋        | 85/500 [02:34<15:42,  2.27s/it] 17%|█▋        | 87/500 [02:34<11:05,  1.61s/it] 18%|█▊        | 89/500 [02:34<07:52,  1.15s/it] 18%|█▊        | 89/500 [02:46<07:52,  1.15s/it] 18%|█▊        | 91/500 [02:47<18:09,  2.66s/it] 19%|█▊        | 93/500 [02:47<12:48,  1.89s/it] 19%|█▉        | 95/500 [02:53<15:15,  2.26s/it] 19%|█▉        | 97/500 [02:53<10:46,  1.60s/it] 20%|█▉        | 99/500 [02:53<07:38,  1.14s/it] 20%|█▉        | 99/500 [03:06<07:38,  1.14s/it] 20%|██        | 101/500 [03:06<17:46,  2.67s/it] 21%|██        | 103/500 [03:06<12:31,  1.89s/it] 21%|██        | 105/500 [03:12<14:56,  2.27s/it] 21%|██▏       | 107/500 [03:12<10:32,  1.61s/it] 22%|██▏       | 109/500 [03:13<07:28,  1.15s/it] 22%|██▏       | 111/500 [03:25<17:19,  2.67s/it] 23%|██▎       | 113/500 [03:25<12:12,  1.89s/it] 23%|██▎       | 115/500 [03:31<14:31,  2.26s/it] 23%|██▎       | 117/500 [03:32<10:14,  1.61s/it] 24%|██▍       | 119/500 [03:32<07:15,  1.14s/it] 24%|██▍       | 121/500 [03:44<16:48,  2.66s/it]0.11504343152046204
Epoch:  63  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  64  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504341661930084
Epoch:  65  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  67  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  68  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  69  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  70  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  72  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  73  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  74  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  75  	Training Loss: 0.08508484810590744
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  77  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  78  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  79  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  80  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  82  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  83  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  84  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  85  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  87  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  88  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  89  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  90  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  92  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  93  	Training Loss: 0.08508484065532684
Test Loss:  0.1167813092470169
Valid Loss:  0.11504343152046204
Epoch:  94  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  95  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  97  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  98  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  99  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  100  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  102  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  103  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  104  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  105  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  107  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  108  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  109  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  110  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  112  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  113  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  114  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  115  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  117  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  118  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  119  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  120  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
 25%|██▍       | 123/500 [03:44<11:49,  1.88s/it] 25%|██▌       | 125/500 [03:50<14:08,  2.26s/it] 25%|██▌       | 127/500 [03:51<09:58,  1.60s/it] 26%|██▌       | 129/500 [03:51<07:03,  1.14s/it] 26%|██▌       | 131/500 [04:03<16:24,  2.67s/it] 27%|██▋       | 133/500 [04:03<11:33,  1.89s/it] 27%|██▋       | 135/500 [04:10<13:50,  2.27s/it] 27%|██▋       | 137/500 [04:10<09:45,  1.61s/it] 28%|██▊       | 139/500 [04:10<06:54,  1.15s/it] 28%|██▊       | 141/500 [04:22<15:54,  2.66s/it] 29%|██▊       | 143/500 [04:23<11:13,  1.89s/it] 29%|██▉       | 145/500 [04:29<13:24,  2.27s/it] 29%|██▉       | 147/500 [04:29<09:27,  1.61s/it] 30%|██▉       | 149/500 [04:29<06:41,  1.15s/it] 30%|███       | 151/500 [04:42<15:29,  2.66s/it] 31%|███       | 153/500 [04:42<10:54,  1.89s/it] 31%|███       | 155/500 [04:48<13:02,  2.27s/it] 31%|███▏      | 157/500 [04:48<09:12,  1.61s/it] 32%|███▏      | 159/500 [04:48<06:31,  1.15s/it] 32%|███▏      | 161/500 [05:01<15:05,  2.67s/it] 33%|███▎      | 163/500 [05:01<10:37,  1.89s/it] 33%|███▎      | 165/500 [05:07<12:41,  2.27s/it] 33%|███▎      | 167/500 [05:07<08:56,  1.61s/it] 34%|███▍      | 169/500 [05:07<06:19,  1.15s/it] 34%|███▍      | 171/500 [05:20<14:50,  2.71s/it] 35%|███▍      | 173/500 [05:20<10:26,  1.92s/it] 35%|███▌      | 175/500 [05:27<12:23,  2.29s/it] 35%|███▌      | 177/500 [05:27<08:44,  1.62s/it] 36%|███▌      | 179/500 [05:27<06:10,  1.15s/it]Epoch:  122  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  123  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  124  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  125  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  127  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  128  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  129  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  130  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  132  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  133  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  134  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  135  	Training Loss: 0.08508484065532684
Test Loss:  0.11678128689527512
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  137  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  138  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  139  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  140  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  142  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  143  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  144  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  145  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  147  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  148  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  149  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  150  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  152  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  153  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
Epoch:  154  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  155  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  157  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  158  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  159  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  160  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  162  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  163  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  164  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  165  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  167  	Training Loss: 0.08508484065532684
Test Loss:  0.11678128689527512
Valid Loss:  0.11504341661930084
Epoch:  168  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  169  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  170  	Training Loss: 0.08508484810590744
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  172  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  173  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  174  	Training Loss: 0.08508484065532684
Test Loss:  0.1167813092470169
Valid Loss:  0.11504342406988144
Epoch:  175  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  177  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  178  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  179  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  180  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
 36%|███▌      | 181/500 [05:39<14:16,  2.68s/it] 37%|███▋      | 183/500 [05:40<10:02,  1.90s/it] 37%|███▋      | 185/500 [05:46<11:54,  2.27s/it] 37%|███▋      | 187/500 [05:46<08:24,  1.61s/it] 38%|███▊      | 189/500 [05:46<05:57,  1.15s/it] 38%|███▊      | 191/500 [05:59<13:45,  2.67s/it] 39%|███▊      | 193/500 [05:59<09:40,  1.89s/it] 39%|███▉      | 195/500 [06:05<11:35,  2.28s/it] 39%|███▉      | 197/500 [06:05<08:09,  1.62s/it] 40%|███▉      | 199/500 [06:05<05:46,  1.15s/it] 40%|███▉      | 199/500 [06:16<05:46,  1.15s/it] 40%|████      | 201/500 [06:18<13:15,  2.66s/it] 41%|████      | 203/500 [06:18<09:19,  1.89s/it] 41%|████      | 205/500 [06:24<11:08,  2.26s/it] 41%|████▏     | 207/500 [06:24<07:50,  1.61s/it] 42%|████▏     | 209/500 [06:24<05:32,  1.14s/it] 42%|████▏     | 209/500 [06:36<05:32,  1.14s/it] 42%|████▏     | 211/500 [06:37<12:49,  2.66s/it] 43%|████▎     | 213/500 [06:37<09:00,  1.88s/it] 43%|████▎     | 215/500 [06:43<10:42,  2.25s/it] 43%|████▎     | 217/500 [06:43<07:32,  1.60s/it] 44%|████▍     | 219/500 [06:43<05:20,  1.14s/it] 44%|████▍     | 219/500 [06:56<05:20,  1.14s/it] 44%|████▍     | 221/500 [06:56<12:21,  2.66s/it] 45%|████▍     | 223/500 [06:56<08:41,  1.88s/it] 45%|████▌     | 225/500 [07:02<10:20,  2.26s/it] 45%|████▌     | 227/500 [07:02<07:16,  1.60s/it] 46%|████▌     | 229/500 [07:02<05:08,  1.14s/it] 46%|████▌     | 231/500 [07:15<11:54,  2.66s/it] 47%|████▋     | 233/500 [07:15<08:22,  1.88s/it] 47%|████▋     | 235/500 [07:21<10:00,  2.26s/it] 47%|████▋     | 237/500 [07:21<07:02,  1.61s/it] 48%|████▊     | 239/500 [07:22<04:58,  1.14s/it]Epoch:  181  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  182  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  183  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  184  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  185  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  187  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  188  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  189  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  190  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  192  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  193  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  194  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  195  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  197  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  198  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  199  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  200  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  202  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  203  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  204  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  205  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504341661930084
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  207  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  208  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  209  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  210  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  212  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  213  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  214  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  215  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  217  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  218  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  219  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
Epoch:  220  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  222  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  223  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  224  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  225  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  227  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  228  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  229  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  230  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  232  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  233  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  234  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  235  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  237  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  238  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  239  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  240  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
 48%|████▊     | 241/500 [07:34<11:30,  2.67s/it] 49%|████▊     | 243/500 [07:34<08:05,  1.89s/it] 49%|████▉     | 245/500 [07:40<09:35,  2.26s/it] 49%|████▉     | 247/500 [07:41<06:45,  1.60s/it] 50%|████▉     | 249/500 [07:41<04:46,  1.14s/it] 50%|█████     | 251/500 [07:53<10:59,  2.65s/it] 51%|█████     | 253/500 [07:53<07:43,  1.88s/it] 51%|█████     | 255/500 [08:00<09:14,  2.26s/it] 51%|█████▏    | 257/500 [08:00<06:30,  1.61s/it] 52%|█████▏    | 259/500 [08:00<04:35,  1.14s/it] 52%|█████▏    | 261/500 [08:12<10:37,  2.67s/it] 53%|█████▎    | 263/500 [08:12<07:27,  1.89s/it] 53%|█████▎    | 265/500 [08:19<08:50,  2.26s/it] 53%|█████▎    | 267/500 [08:19<06:13,  1.60s/it] 54%|█████▍    | 269/500 [08:19<04:23,  1.14s/it] 54%|█████▍    | 271/500 [08:31<10:05,  2.65s/it] 55%|█████▍    | 273/500 [08:31<07:05,  1.87s/it] 55%|█████▌    | 275/500 [08:38<08:26,  2.25s/it] 55%|█████▌    | 277/500 [08:38<05:56,  1.60s/it] 56%|█████▌    | 279/500 [08:38<04:11,  1.14s/it] 56%|█████▌    | 281/500 [08:50<09:45,  2.67s/it] 57%|█████▋    | 283/500 [08:51<06:50,  1.89s/it] 57%|█████▋    | 285/500 [08:57<08:05,  2.26s/it] 57%|█████▋    | 287/500 [08:57<05:41,  1.60s/it] 58%|█████▊    | 289/500 [08:57<04:00,  1.14s/it] 58%|█████▊    | 291/500 [09:10<09:25,  2.70s/it] 59%|█████▊    | 293/500 [09:10<06:36,  1.91s/it] 59%|█████▉    | 295/500 [09:16<07:49,  2.29s/it] 59%|█████▉    | 297/500 [09:16<05:29,  1.62s/it] 60%|█████▉    | 299/500 [09:17<03:52,  1.16s/it]**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  242  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  243  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  244  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  245  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  247  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  248  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  249  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  250  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  252  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  253  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  254  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
Epoch:  255  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  257  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  258  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  259  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  260  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  262  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  263  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  264  	Training Loss: 0.08508484065532684
Test Loss:  0.11678128689527512
Valid Loss:  0.11504343152046204
Epoch:  265  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  267  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  268  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  269  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  270  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  272  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  273  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  274  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  275  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  277  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  278  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  279  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  280  	Training Loss: 0.08508484065532684
Test Loss:  0.11678128689527512
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  282  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  283  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  284  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  285  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  287  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  288  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  289  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  290  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  292  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  293  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  294  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  295  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  297  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  298  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  299  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
 60%|██████    | 301/500 [09:29<08:53,  2.68s/it] 61%|██████    | 303/500 [09:29<06:13,  1.90s/it] 61%|██████    | 305/500 [09:35<07:22,  2.27s/it] 61%|██████▏   | 307/500 [09:36<05:11,  1.61s/it] 62%|██████▏   | 309/500 [09:36<03:39,  1.15s/it] 62%|██████▏   | 309/500 [09:46<03:39,  1.15s/it] 62%|██████▏   | 311/500 [09:48<08:28,  2.69s/it] 63%|██████▎   | 313/500 [09:48<05:56,  1.91s/it] 63%|██████▎   | 315/500 [09:55<07:01,  2.28s/it] 63%|██████▎   | 317/500 [09:55<04:56,  1.62s/it] 64%|██████▍   | 319/500 [09:55<03:29,  1.16s/it] 64%|██████▍   | 319/500 [10:06<03:29,  1.16s/it] 64%|██████▍   | 321/500 [10:08<07:59,  2.68s/it] 65%|██████▍   | 323/500 [10:08<05:35,  1.90s/it] 65%|██████▌   | 325/500 [10:14<06:39,  2.28s/it] 65%|██████▌   | 327/500 [10:14<04:39,  1.62s/it] 66%|██████▌   | 329/500 [10:14<03:17,  1.15s/it] 66%|██████▌   | 329/500 [10:26<03:17,  1.15s/it] 66%|██████▌   | 331/500 [10:27<07:35,  2.69s/it] 67%|██████▋   | 333/500 [10:27<05:18,  1.91s/it] 67%|██████▋   | 335/500 [10:33<06:19,  2.30s/it] 67%|██████▋   | 337/500 [10:34<04:25,  1.63s/it] 68%|██████▊   | 339/500 [10:34<03:06,  1.16s/it] 68%|██████▊   | 339/500 [10:46<03:06,  1.16s/it] 68%|██████▊   | 341/500 [10:46<07:11,  2.72s/it] 69%|██████▊   | 343/500 [10:47<05:01,  1.92s/it] 69%|██████▉   | 345/500 [10:53<05:55,  2.29s/it] 69%|██████▉   | 347/500 [10:53<04:08,  1.63s/it] 70%|██████▉   | 349/500 [10:53<02:54,  1.16s/it] 70%|███████   | 351/500 [11:06<06:39,  2.68s/it] 71%|███████   | 353/500 [11:06<04:39,  1.90s/it] 71%|███████   | 355/500 [11:12<05:29,  2.27s/it] 71%|███████▏  | 357/500 [11:12<03:50,  1.61s/it]Epoch:  300  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  302  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  303  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  304  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  305  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
Epoch:  307  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  308  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  309  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  310  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  312  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  313  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  314  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  315  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504341661930084
Epoch:  317  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  318  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  319  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  320  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  322  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  323  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  324  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  325  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  327  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  328  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  329  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  330  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  332  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  333  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  334  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  335  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  337  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  338  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  339  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  340  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  342  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  343  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  344  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  345  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  347  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  348  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  349  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  350  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.08508484065532684
Test Loss:  0.11678128689527512
Valid Loss:  0.11504342406988144
Epoch:  352  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  353  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  354  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  355  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  357  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  358  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
 72%|███████▏  | 359/500 [11:12<02:42,  1.15s/it] 72%|███████▏  | 361/500 [11:25<06:11,  2.67s/it] 73%|███████▎  | 363/500 [11:25<04:19,  1.89s/it] 73%|███████▎  | 365/500 [11:31<05:06,  2.27s/it] 73%|███████▎  | 367/500 [11:31<03:34,  1.61s/it] 74%|███████▍  | 369/500 [11:31<02:30,  1.15s/it] 74%|███████▍  | 371/500 [11:44<05:45,  2.68s/it] 75%|███████▍  | 373/500 [11:44<04:00,  1.90s/it] 75%|███████▌  | 375/500 [11:50<04:44,  2.27s/it] 75%|███████▌  | 377/500 [11:51<03:18,  1.61s/it] 76%|███████▌  | 379/500 [11:51<02:19,  1.15s/it] 76%|███████▌  | 381/500 [12:03<05:21,  2.70s/it] 77%|███████▋  | 383/500 [12:03<03:43,  1.91s/it] 77%|███████▋  | 385/500 [12:10<04:22,  2.28s/it] 77%|███████▋  | 387/500 [12:10<03:03,  1.62s/it] 78%|███████▊  | 389/500 [12:10<02:08,  1.16s/it] 78%|███████▊  | 391/500 [12:23<04:51,  2.67s/it] 79%|███████▊  | 393/500 [12:23<03:22,  1.89s/it] 79%|███████▉  | 395/500 [12:29<03:57,  2.26s/it] 79%|███████▉  | 397/500 [12:29<02:45,  1.60s/it] 80%|███████▉  | 399/500 [12:29<01:55,  1.14s/it] 80%|████████  | 401/500 [12:42<04:24,  2.67s/it] 81%|████████  | 403/500 [12:42<03:03,  1.90s/it] 81%|████████  | 405/500 [12:48<03:37,  2.29s/it] 81%|████████▏ | 407/500 [12:48<02:31,  1.62s/it] 82%|████████▏ | 409/500 [12:49<01:45,  1.16s/it] 82%|████████▏ | 411/500 [13:01<04:00,  2.70s/it] 83%|████████▎ | 413/500 [13:01<02:46,  1.91s/it] 83%|████████▎ | 415/500 [13:08<03:14,  2.29s/it] 83%|████████▎ | 417/500 [13:08<02:14,  1.62s/it]Epoch:  359  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  360  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  362  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  363  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  364  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  365  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  367  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  368  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  369  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  370  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  372  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  373  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  374  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  375  	Training Loss: 0.08508484065532684
Test Loss:  0.11678128689527512
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  377  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  378  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  379  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  380  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  382  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  383  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  384  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  385  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  387  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  388  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  389  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  390  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  392  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  393  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  394  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  395  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  397  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  398  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  399  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  400  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  402  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  403  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  404  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  405  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  407  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  408  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  409  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  410  	Training Loss: 0.08508484810590744
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  412  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  413  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  414  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  415  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  417  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
 84%|████████▍ | 419/500 [13:08<01:33,  1.16s/it] 84%|████████▍ | 421/500 [13:20<03:32,  2.69s/it] 85%|████████▍ | 423/500 [13:21<02:26,  1.90s/it] 85%|████████▌ | 425/500 [13:27<02:51,  2.28s/it] 85%|████████▌ | 427/500 [13:27<01:58,  1.62s/it] 86%|████████▌ | 429/500 [13:27<01:21,  1.15s/it] 86%|████████▌ | 431/500 [13:40<03:04,  2.67s/it] 87%|████████▋ | 433/500 [13:40<02:06,  1.89s/it] 87%|████████▋ | 435/500 [13:46<02:27,  2.27s/it] 87%|████████▋ | 437/500 [13:46<01:41,  1.61s/it] 88%|████████▊ | 439/500 [13:46<01:10,  1.15s/it] 88%|████████▊ | 441/500 [13:59<02:37,  2.67s/it] 89%|████████▊ | 443/500 [13:59<01:47,  1.89s/it] 89%|████████▉ | 445/500 [14:05<02:04,  2.27s/it] 89%|████████▉ | 447/500 [14:05<01:25,  1.61s/it] 90%|████████▉ | 449/500 [14:05<00:58,  1.15s/it] 90%|████████▉ | 449/500 [14:16<00:58,  1.15s/it] 90%|█████████ | 451/500 [14:18<02:10,  2.66s/it] 91%|█████████ | 453/500 [14:18<01:28,  1.88s/it] 91%|█████████ | 455/500 [14:24<01:41,  2.26s/it] 91%|█████████▏| 457/500 [14:24<01:08,  1.60s/it] 92%|█████████▏| 459/500 [14:25<00:46,  1.14s/it] 92%|█████████▏| 459/500 [14:36<00:46,  1.14s/it] 92%|█████████▏| 461/500 [14:37<01:44,  2.68s/it] 93%|█████████▎| 463/500 [14:37<01:10,  1.89s/it] 93%|█████████▎| 465/500 [14:44<01:19,  2.27s/it] 93%|█████████▎| 467/500 [14:44<00:53,  1.61s/it] 94%|█████████▍| 469/500 [14:44<00:35,  1.15s/it] 94%|█████████▍| 469/500 [14:56<00:35,  1.15s/it] 94%|█████████▍| 471/500 [14:56<01:18,  2.70s/it] 95%|█████████▍| 473/500 [14:57<00:51,  1.91s/it] 95%|█████████▌| 475/500 [15:03<00:57,  2.28s/it]Epoch:  418  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  419  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  420  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  422  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  423  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  424  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  425  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  427  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  428  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  429  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  430  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  432  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  433  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  434  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  435  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  437  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  438  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  439  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504341661930084
Epoch:  440  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  442  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  443  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  444  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  445  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  447  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  448  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  449  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  450  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  452  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  453  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  454  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  455  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.08508484065532684
Test Loss:  0.11678128689527512
Valid Loss:  0.11504343152046204
Epoch:  457  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  458  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  459  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  460  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  462  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  463  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  464  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  465  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  467  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  468  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  469  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  470  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  472  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  473  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504343152046204
Epoch:  474  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  475  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
 95%|█████████▌| 477/500 [15:03<00:37,  1.62s/it] 96%|█████████▌| 479/500 [15:03<00:24,  1.15s/it] 96%|█████████▌| 481/500 [15:16<00:51,  2.70s/it] 97%|█████████▋| 483/500 [15:16<00:32,  1.91s/it] 97%|█████████▋| 485/500 [15:22<00:34,  2.31s/it] 97%|█████████▋| 487/500 [15:23<00:21,  1.63s/it] 98%|█████████▊| 489/500 [15:23<00:12,  1.16s/it] 98%|█████████▊| 491/500 [15:35<00:24,  2.72s/it] 99%|█████████▊| 493/500 [15:35<00:13,  1.92s/it] 99%|█████████▉| 495/500 [15:42<00:11,  2.29s/it] 99%|█████████▉| 497/500 [15:42<00:04,  1.62s/it]100%|█████████▉| 499/500 [15:42<00:01,  1.16s/it]100%|██████████| 500/500 [15:48<00:00,  1.90s/it]
Epoch:  477  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  478  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  479  	Training Loss: 0.08508484065532684
Test Loss:  0.1167813092470169
Valid Loss:  0.11504343152046204
Epoch:  480  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  482  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  483  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  484  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  485  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  487  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  488  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  489  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  490  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  492  	Training Loss: 0.08508484065532684
Test Loss:  0.11678130179643631
Valid Loss:  0.11504342406988144
Epoch:  493  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
Epoch:  494  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  495  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  497  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  498  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  499  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504343152046204
Epoch:  500  	Training Loss: 0.08508484065532684
Test Loss:  0.11678129434585571
Valid Loss:  0.11504342406988144
**************************************************learning rate decay**************************************************
seed is  10
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:35,  6.32s/it]  1%|          | 3/500 [00:06<14:00,  1.69s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:20<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:26<09:11,  1.18s/it]  7%|▋         | 33/500 [00:26<06:34,  1.19it/s]  7%|▋         | 35/500 [00:27<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<09:00,  1.18s/it]  9%|▊         | 43/500 [00:33<06:26,  1.18it/s]  9%|▉         | 45/500 [00:33<04:40,  1.62it/s]  9%|▉         | 47/500 [00:34<03:26,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:40<08:54,  1.19s/it] 11%|█         | 53/500 [00:40<06:21,  1.17it/s] 11%|█         | 55/500 [00:40<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:36,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:54<08:26,  1.18s/it]Epoch:  1  	Training Loss: 0.054723095148801804
Test Loss:  0.062029220163822174
Valid Loss:  0.07448887825012207
Epoch:  2  	Training Loss: 0.10306517034769058
Test Loss:  0.07147865742444992
Valid Loss:  0.07113701105117798
Epoch:  3  	Training Loss: 0.053537264466285706
Test Loss:  0.07113330066204071
Valid Loss:  0.07080049812793732
Epoch:  4  	Training Loss: 0.05330095440149307
Test Loss:  0.07082267850637436
Valid Loss:  0.07049137353897095
Epoch:  5  	Training Loss: 0.053086068481206894
Test Loss:  0.07066989690065384
Valid Loss:  0.07034706324338913
Epoch:  6  	Training Loss: 0.052983999252319336
Test Loss:  0.07051952183246613
Valid Loss:  0.0702051967382431
Epoch:  7  	Training Loss: 0.05288320034742355
Test Loss:  0.07036946713924408
Valid Loss:  0.07006366550922394
Epoch:  8  	Training Loss: 0.05278266966342926
Test Loss:  0.07021965086460114
Valid Loss:  0.06992245465517044
Epoch:  9  	Training Loss: 0.05268240347504616
Test Loss:  0.0700700581073761
Valid Loss:  0.06978151202201843
Epoch:  10  	Training Loss: 0.05258238688111305
Test Loss:  0.06992076337337494
Valid Loss:  0.0696408599615097
Epoch:  11  	Training Loss: 0.05248260498046875
Test Loss:  0.06977176666259766
Valid Loss:  0.06950049847364426
Epoch:  12  	Training Loss: 0.05238306522369385
Test Loss:  0.06971612572669983
Valid Loss:  0.06945755332708359
Epoch:  13  	Training Loss: 0.052347466349601746
Test Loss:  0.06971665471792221
Valid Loss:  0.06945745646953583
Epoch:  14  	Training Loss: 0.05234675109386444
Test Loss:  0.06971699744462967
Valid Loss:  0.06945731490850449
Epoch:  15  	Training Loss: 0.05234614387154579
Test Loss:  0.06971729546785355
Valid Loss:  0.06945715844631195
Epoch:  16  	Training Loss: 0.052345551550388336
Test Loss:  0.06971757113933563
Valid Loss:  0.0694570243358612
Epoch:  17  	Training Loss: 0.05234498158097267
Test Loss:  0.06971770524978638
Valid Loss:  0.06945683062076569
Epoch:  18  	Training Loss: 0.05234441161155701
Test Loss:  0.06971783190965652
Valid Loss:  0.06945665180683136
Epoch:  19  	Training Loss: 0.05234385281801224
Test Loss:  0.06971795856952667
Valid Loss:  0.06945646554231644
Epoch:  20  	Training Loss: 0.05234329402446747
Test Loss:  0.06971804797649384
Valid Loss:  0.06945627927780151
Epoch:  21  	Training Loss: 0.052342738956213
Test Loss:  0.0697181224822998
Valid Loss:  0.0694560781121254
Epoch:  22  	Training Loss: 0.05234218388795853
Test Loss:  0.069718137383461
Valid Loss:  0.06945586204528809
Epoch:  23  	Training Loss: 0.05234164744615555
Test Loss:  0.06971821188926697
Valid Loss:  0.06945566833019257
Epoch:  24  	Training Loss: 0.05234111100435257
Test Loss:  0.06971821188926697
Valid Loss:  0.06945545226335526
Epoch:  25  	Training Loss: 0.05234057083725929
Test Loss:  0.06971821933984756
Valid Loss:  0.06945523619651794
Epoch:  26  	Training Loss: 0.052340030670166016
Test Loss:  0.06971827149391174
Valid Loss:  0.06945502758026123
Epoch:  27  	Training Loss: 0.05233949422836304
Test Loss:  0.06971828639507294
Valid Loss:  0.06945483386516571
Epoch:  28  	Training Loss: 0.05233895778656006
Test Loss:  0.06971833854913712
Valid Loss:  0.0694546326994896
Epoch:  29  	Training Loss: 0.05233842134475708
Test Loss:  0.06971834599971771
Valid Loss:  0.06945441663265228
Epoch:  30  	Training Loss: 0.0523378849029541
Test Loss:  0.06971835345029831
Valid Loss:  0.06945420056581497
Epoch:  31  	Training Loss: 0.052337344735860825
Test Loss:  0.06971842050552368
Valid Loss:  0.06945399940013885
Epoch:  32  	Training Loss: 0.052336812019348145
Test Loss:  0.06971841305494308
Valid Loss:  0.06945379078388214
Epoch:  33  	Training Loss: 0.05233626812696457
Test Loss:  0.06971845775842667
Valid Loss:  0.06945358216762543
Epoch:  34  	Training Loss: 0.05233573168516159
Test Loss:  0.06971849501132965
Valid Loss:  0.06945337355136871
Epoch:  35  	Training Loss: 0.052335187792778015
Test Loss:  0.06971849501132965
Valid Loss:  0.0694531574845314
Epoch:  36  	Training Loss: 0.052334655076265335
Test Loss:  0.06971853971481323
Valid Loss:  0.06945294886827469
Epoch:  37  	Training Loss: 0.05233411490917206
Test Loss:  0.06971853226423264
Valid Loss:  0.06945273280143738
Epoch:  38  	Training Loss: 0.05233357846736908
Test Loss:  0.0697186216711998
Valid Loss:  0.06945253908634186
Epoch:  39  	Training Loss: 0.052333034574985504
Test Loss:  0.0697186142206192
Valid Loss:  0.06945231556892395
Epoch:  40  	Training Loss: 0.052332498133182526
Test Loss:  0.06971865892410278
Valid Loss:  0.06945210695266724
Epoch:  41  	Training Loss: 0.05233196169137955
Test Loss:  0.06971865892410278
Valid Loss:  0.06945189088582993
Epoch:  42  	Training Loss: 0.05233141779899597
Test Loss:  0.06971874833106995
Valid Loss:  0.0694517195224762
Epoch:  43  	Training Loss: 0.052330899983644485
Test Loss:  0.06971876323223114
Valid Loss:  0.06945152580738068
Epoch:  44  	Training Loss: 0.052330382168293
Test Loss:  0.06971882283687592
Valid Loss:  0.06945133954286575
Epoch:  45  	Training Loss: 0.05232986435294151
Test Loss:  0.06971888244152069
Valid Loss:  0.06945115327835083
Epoch:  46  	Training Loss: 0.052329350262880325
Test Loss:  0.06971888244152069
Valid Loss:  0.06945095956325531
Epoch:  47  	Training Loss: 0.05232882872223854
Test Loss:  0.06971898674964905
Valid Loss:  0.06945078074932098
Epoch:  48  	Training Loss: 0.052328310906887054
Test Loss:  0.06971899420022964
Valid Loss:  0.06945058703422546
Epoch:  49  	Training Loss: 0.05232778936624527
Test Loss:  0.0697190910577774
Valid Loss:  0.06945042312145233
Epoch:  50  	Training Loss: 0.05232727527618408
Test Loss:  0.0697190910577774
Valid Loss:  0.06945022195577621
Epoch:  51  	Training Loss: 0.0523267537355423
Test Loss:  0.06971919536590576
Valid Loss:  0.06945005059242249
Epoch:  52  	Training Loss: 0.05232623964548111
Test Loss:  0.06971918046474457
Valid Loss:  0.06944984197616577
Epoch:  53  	Training Loss: 0.05232570692896843
Test Loss:  0.06971925497055054
Valid Loss:  0.06944964826107025
Epoch:  54  	Training Loss: 0.052325181663036346
Test Loss:  0.06971924751996994
Valid Loss:  0.06944943219423294
Epoch:  55  	Training Loss: 0.052324652671813965
Test Loss:  0.0697193294763565
Valid Loss:  0.06944924592971802
Epoch:  56  	Training Loss: 0.05232412368059158
Test Loss:  0.06971931457519531
Valid Loss:  0.0694490298628807
Epoch:  57  	Training Loss: 0.0523235946893692
Test Loss:  0.06971939653158188
Valid Loss:  0.06944884359836578
Epoch:  58  	Training Loss: 0.05232307314872742
Test Loss:  0.06971941888332367
Valid Loss:  0.06944864243268967
Epoch:  59  	Training Loss: 0.052322544157505035
Test Loss:  0.06971945613622665
Valid Loss:  0.06944844126701355
Epoch:  60  	Training Loss: 0.052322015166282654
Test Loss:  0.06971948593854904
Valid Loss:  0.06944824755191803
Epoch:  61  	Training Loss: 0.05232148990035057
Test Loss:  0.06971952319145203
Valid Loss:  0.06944803893566132
Epoch:  62  	Training Loss: 0.05232096463441849
Test Loss:  0.06971955299377441
Valid Loss:  0.0694478452205658
Epoch:  63  	Training Loss: 0.0523204430937767
Test Loss:  0.06971962004899979
Valid Loss:  0.06944765895605087
Epoch:  64  	Training Loss: 0.05231992155313492
Test Loss:  0.06971961259841919
Valid Loss:  0.06944745779037476
Epoch:  65  	Training Loss: 0.05231940373778343
Test Loss:  0.06971968710422516
Valid Loss:  0.06944727152585983
Epoch:  66  	Training Loss: 0.052318885922431946
Test Loss:  0.06971971690654755
Valid Loss:  0.06944707036018372
Epoch:  67  	Training Loss: 0.05231836810708046
Test Loss:  0.06971979141235352
Valid Loss:  0.06944689154624939
Epoch:  68  	Training Loss: 0.05231785029172897
Test Loss:  0.06971976906061172
Valid Loss:  0.06944667547941208
Epoch:  69  	Training Loss: 0.05231732875108719
Test Loss:  0.0697198361158371
Valid Loss:  0.06944648921489716
Epoch:  70  	Training Loss: 0.052316807210445404
Test Loss:  0.06971986591815948
Valid Loss:  0.06944629549980164
Epoch:  71  	Training Loss: 0.05231628939509392
Test Loss:  0.06971994042396545
Valid Loss:  0.06944611668586731
Epoch:  72  	Training Loss: 0.05231577157974243
Test Loss:  0.06971994787454605
Valid Loss:  0.0694459080696106
Epoch:  73  	Training Loss: 0.05231525003910065
Test Loss:   15%|█▍        | 73/500 [00:54<06:01,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:20,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:01<08:11,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:08<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:45,  1.17s/it] 21%|██        | 103/500 [01:14<05:32,  1.19it/s] 21%|██        | 105/500 [01:14<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:15<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:15<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:21<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:21<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:28<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:28<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:28<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:28<02:04,  2.97it/s] 26%|██▌       | 131/500 [01:35<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:35<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:41,  2.24it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.01it/s] 28%|██▊       | 141/500 [01:42<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:42<05:05,  1.17it/s]0.06971996277570724
Valid Loss:  0.06944570690393448
Epoch:  74  	Training Loss: 0.05231472849845886
Test Loss:  0.06972001492977142
Valid Loss:  0.06944550573825836
Epoch:  75  	Training Loss: 0.05231420695781708
Test Loss:  0.06972001492977142
Valid Loss:  0.06944531202316284
Epoch:  76  	Training Loss: 0.05231368914246559
Test Loss:  0.0697200670838356
Valid Loss:  0.06944510340690613
Epoch:  77  	Training Loss: 0.05231316387653351
Test Loss:  0.0697200819849968
Valid Loss:  0.06944490224123001
Epoch:  78  	Training Loss: 0.05231264606118202
Test Loss:  0.06972013413906097
Valid Loss:  0.06944470852613449
Epoch:  79  	Training Loss: 0.05231212452054024
Test Loss:  0.06972013413906097
Valid Loss:  0.06944450736045837
Epoch:  80  	Training Loss: 0.05231160670518875
Test Loss:  0.06972019374370575
Valid Loss:  0.06944431364536285
Epoch:  81  	Training Loss: 0.05231108516454697
Test Loss:  0.06972020119428635
Valid Loss:  0.06944410502910614
Epoch:  82  	Training Loss: 0.05231056734919548
Test Loss:  0.06972022354602814
Valid Loss:  0.06944391131401062
Epoch:  83  	Training Loss: 0.05231006443500519
Test Loss:  0.06972029060125351
Valid Loss:  0.06944374740123749
Epoch:  84  	Training Loss: 0.052309565246105194
Test Loss:  0.0697203129529953
Valid Loss:  0.06944355368614197
Epoch:  85  	Training Loss: 0.0523090623319149
Test Loss:  0.06972038745880127
Valid Loss:  0.06944338232278824
Epoch:  86  	Training Loss: 0.05230855941772461
Test Loss:  0.06972040235996246
Valid Loss:  0.06944318860769272
Epoch:  87  	Training Loss: 0.05230805277824402
Test Loss:  0.06972046196460724
Valid Loss:  0.06944301724433899
Epoch:  88  	Training Loss: 0.052307553589344025
Test Loss:  0.06972048431634903
Valid Loss:  0.06944282352924347
Epoch:  89  	Training Loss: 0.05230705440044403
Test Loss:  0.0697205513715744
Valid Loss:  0.06944265216588974
Epoch:  90  	Training Loss: 0.05230655148625374
Test Loss:  0.06972062587738037
Valid Loss:  0.06944248080253601
Epoch:  91  	Training Loss: 0.052306048572063446
Test Loss:  0.06972063332796097
Valid Loss:  0.06944228708744049
Epoch:  92  	Training Loss: 0.05230554938316345
Test Loss:  0.06972067058086395
Valid Loss:  0.06944207847118378
Epoch:  93  	Training Loss: 0.05230502784252167
Test Loss:  0.06972065567970276
Valid Loss:  0.06944187730550766
Epoch:  94  	Training Loss: 0.05230451375246048
Test Loss:  0.06972068548202515
Valid Loss:  0.06944166868925095
Epoch:  95  	Training Loss: 0.052303995937108994
Test Loss:  0.06972073018550873
Valid Loss:  0.06944146752357483
Epoch:  96  	Training Loss: 0.05230347812175751
Test Loss:  0.06972071528434753
Valid Loss:  0.06944125890731812
Epoch:  97  	Training Loss: 0.05230296403169632
Test Loss:  0.06972075253725052
Valid Loss:  0.069441057741642
Epoch:  98  	Training Loss: 0.05230244994163513
Test Loss:  0.06972073763608932
Valid Loss:  0.06944084912538528
Epoch:  99  	Training Loss: 0.05230192840099335
Test Loss:  0.06972075998783112
Valid Loss:  0.06944063305854797
Epoch:  100  	Training Loss: 0.05230141058564186
Test Loss:  0.0697207972407341
Valid Loss:  0.06944043934345245
Epoch:  101  	Training Loss: 0.052300892770290375
Test Loss:  0.0697207897901535
Valid Loss:  0.06944022327661514
Epoch:  102  	Training Loss: 0.05230037868022919
Test Loss:  0.06972081959247589
Valid Loss:  0.06944002211093903
Epoch:  103  	Training Loss: 0.0522998683154583
Test Loss:  0.0697208046913147
Valid Loss:  0.06943981349468231
Epoch:  104  	Training Loss: 0.05229935795068741
Test Loss:  0.06972083449363708
Valid Loss:  0.06943961977958679
Epoch:  105  	Training Loss: 0.05229884386062622
Test Loss:  0.06972087174654007
Valid Loss:  0.06943942606449127
Epoch:  106  	Training Loss: 0.05229833722114563
Test Loss:  0.06972084939479828
Valid Loss:  0.06943920999765396
Epoch:  107  	Training Loss: 0.05229782685637474
Test Loss:  0.06972087919712067
Valid Loss:  0.06943900883197784
Epoch:  108  	Training Loss: 0.05229731649160385
Test Loss:  0.06972090899944305
Valid Loss:  0.06943883001804352
Epoch:  109  	Training Loss: 0.05229681357741356
Test Loss:  0.06972095370292664
Valid Loss:  0.0694386288523674
Epoch:  110  	Training Loss: 0.05229630321264267
Test Loss:  0.06972098350524902
Valid Loss:  0.06943842768669128
Epoch:  111  	Training Loss: 0.05229579657316208
Test Loss:  0.06972100585699081
Valid Loss:  0.06943823397159576
Epoch:  112  	Training Loss: 0.05229528993368149
Test Loss:  0.06972105801105499
Valid Loss:  0.06943805515766144
Epoch:  113  	Training Loss: 0.05229480192065239
Test Loss:  0.06972105801105499
Valid Loss:  0.06943787634372711
Epoch:  114  	Training Loss: 0.05229431390762329
Test Loss:  0.06972114741802216
Valid Loss:  0.06943771243095398
Epoch:  115  	Training Loss: 0.052293822169303894
Test Loss:  0.06972119212150574
Valid Loss:  0.06943754851818085
Epoch:  116  	Training Loss: 0.052293337881565094
Test Loss:  0.06972123682498932
Valid Loss:  0.06943736970424652
Epoch:  117  	Training Loss: 0.0522928461432457
Test Loss:  0.0697212815284729
Valid Loss:  0.0694371908903122
Epoch:  118  	Training Loss: 0.0522923581302166
Test Loss:  0.06972131878137589
Valid Loss:  0.06943702697753906
Epoch:  119  	Training Loss: 0.0522918701171875
Test Loss:  0.06972135603427887
Valid Loss:  0.06943684816360474
Epoch:  120  	Training Loss: 0.0522913821041584
Test Loss:  0.06972144544124603
Valid Loss:  0.0694366917014122
Epoch:  121  	Training Loss: 0.0522908978164196
Test Loss:  0.06972145289182663
Valid Loss:  0.06943650543689728
Epoch:  122  	Training Loss: 0.0522904098033905
Test Loss:  0.069721519947052
Valid Loss:  0.06943631917238235
Epoch:  123  	Training Loss: 0.05228991061449051
Test Loss:  0.0697215348482132
Valid Loss:  0.06943611800670624
Epoch:  124  	Training Loss: 0.052289411425590515
Test Loss:  0.06972154974937439
Valid Loss:  0.06943591684103012
Epoch:  125  	Training Loss: 0.05228890851140022
Test Loss:  0.06972156465053558
Valid Loss:  0.069435715675354
Epoch:  126  	Training Loss: 0.05228840559720993
Test Loss:  0.06972158700227737
Valid Loss:  0.06943552941083908
Epoch:  127  	Training Loss: 0.052287906408309937
Test Loss:  0.06972160190343857
Valid Loss:  0.06943532824516296
Epoch:  128  	Training Loss: 0.05228740721940994
Test Loss:  0.06972165405750275
Valid Loss:  0.06943514198064804
Epoch:  129  	Training Loss: 0.05228690803050995
Test Loss:  0.06972162425518036
Valid Loss:  0.06943492591381073
Epoch:  130  	Training Loss: 0.052286408841609955
Test Loss:  0.06972169876098633
Valid Loss:  0.0694347470998764
Epoch:  131  	Training Loss: 0.05228590965270996
Test Loss:  0.0697217583656311
Valid Loss:  0.06943456828594208
Epoch:  132  	Training Loss: 0.05228541046380997
Test Loss:  0.06972172856330872
Valid Loss:  0.06943435966968536
Epoch:  133  	Training Loss: 0.05228491872549057
Test Loss:  0.06972180306911469
Valid Loss:  0.06943418830633163
Epoch:  134  	Training Loss: 0.05228443443775177
Test Loss:  0.06972181051969528
Valid Loss:  0.06943400204181671
Epoch:  135  	Training Loss: 0.05228394269943237
Test Loss:  0.06972183287143707
Valid Loss:  0.06943381577730179
Epoch:  136  	Training Loss: 0.052283454686403275
Test Loss:  0.06972190737724304
Valid Loss:  0.06943364441394806
Epoch:  137  	Training Loss: 0.052282966673374176
Test Loss:  0.06972192227840424
Valid Loss:  0.06943345069885254
Epoch:  138  	Training Loss: 0.05228247866034508
Test Loss:  0.06972194463014603
Valid Loss:  0.06943326443433762
Epoch:  139  	Training Loss: 0.05228199064731598
Test Loss:  0.0697220116853714
Valid Loss:  0.06943309307098389
Epoch:  140  	Training Loss: 0.05228150263428688
Test Loss:  0.06972202658653259
Valid Loss:  0.06943290680646896
Epoch:  141  	Training Loss: 0.052281010895967484
Test Loss:  0.06972208619117737
Valid Loss:  0.06943272799253464
Epoch:  142  	Training Loss: 0.052280522882938385
Test Loss:  0.06972210109233856
Valid Loss:  0.06943254172801971
Epoch:  143  	Training Loss: 0.05228004232048988
Test Loss:  0.06972212344408035
Valid Loss:  0.06943236291408539
Epoch:  144  	Training Loss: 0.05227956175804138
Test Loss:  0.06972219049930573
Valid Loss:  0.06943219900131226
Epoch:  145  	Training Loss: 0.05227908492088318
Test Loss:  0.06972221285104752
 29%|██▉       | 145/500 [01:42<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:42<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:42<01:59,  2.93it/s] 30%|███       | 151/500 [01:48<06:54,  1.19s/it] 31%|███       | 153/500 [01:49<04:56,  1.17it/s] 31%|███       | 155/500 [01:49<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:49<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:49<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:55<06:34,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:22,  1.65it/s] 33%|███▎      | 167/500 [01:56<02:27,  2.25it/s] 34%|███▍      | 169/500 [01:56<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:02<06:26,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:09<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.02it/s] 38%|███▊      | 191/500 [02:16<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:16<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:16<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:16<01:39,  3.01it/s] 40%|████      | 201/500 [02:22<05:51,  1.18s/it] 41%|████      | 203/500 [02:23<04:10,  1.19it/s] 41%|████      | 205/500 [02:23<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:23<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:29<05:42,  1.19s/it] 43%|████▎     | 213/500 [02:29<04:04,  1.17it/s] 43%|████▎     | 215/500 [02:30<02:55,  1.62it/s]Valid Loss:  0.06943200528621674
Epoch:  146  	Training Loss: 0.05227860063314438
Test Loss:  0.06972222775220871
Valid Loss:  0.06943182647228241
Epoch:  147  	Training Loss: 0.052278123795986176
Test Loss:  0.06972229480743408
Valid Loss:  0.06943166255950928
Epoch:  148  	Training Loss: 0.05227764695882797
Test Loss:  0.06972230970859528
Valid Loss:  0.06943148374557495
Epoch:  149  	Training Loss: 0.05227717012166977
Test Loss:  0.06972238421440125
Valid Loss:  0.06943131238222122
Epoch:  150  	Training Loss: 0.052276693284511566
Test Loss:  0.06972244381904602
Valid Loss:  0.06943114846944809
Epoch:  151  	Training Loss: 0.05227621644735336
Test Loss:  0.06972245872020721
Valid Loss:  0.06943097710609436
Epoch:  152  	Training Loss: 0.05227573588490486
Test Loss:  0.0697224885225296
Valid Loss:  0.06943079829216003
Epoch:  153  	Training Loss: 0.052275270223617554
Test Loss:  0.06972256302833557
Valid Loss:  0.0694306343793869
Epoch:  154  	Training Loss: 0.052274804562330246
Test Loss:  0.06972259283065796
Valid Loss:  0.06943047046661377
Epoch:  155  	Training Loss: 0.05227434262633324
Test Loss:  0.06972265243530273
Valid Loss:  0.06943030655384064
Epoch:  156  	Training Loss: 0.05227386951446533
Test Loss:  0.0697227194905281
Valid Loss:  0.0694301426410675
Epoch:  157  	Training Loss: 0.052273403853178024
Test Loss:  0.0697227418422699
Valid Loss:  0.06942997872829437
Epoch:  158  	Training Loss: 0.052272941917181015
Test Loss:  0.06972280889749527
Valid Loss:  0.06942982226610184
Epoch:  159  	Training Loss: 0.05227247625589371
Test Loss:  0.06972287595272064
Valid Loss:  0.0694296658039093
Epoch:  160  	Training Loss: 0.0522720068693161
Test Loss:  0.06972290575504303
Valid Loss:  0.06942948698997498
Epoch:  161  	Training Loss: 0.05227154493331909
Test Loss:  0.0697229653596878
Valid Loss:  0.06942933797836304
Epoch:  162  	Training Loss: 0.052271075546741486
Test Loss:  0.06972301006317139
Valid Loss:  0.06942915916442871
Epoch:  163  	Training Loss: 0.05227060243487358
Test Loss:  0.06972301006317139
Valid Loss:  0.06942897289991379
Epoch:  164  	Training Loss: 0.05227012559771538
Test Loss:  0.06972305476665497
Valid Loss:  0.06942880153656006
Epoch:  165  	Training Loss: 0.05226965248584747
Test Loss:  0.06972309947013855
Valid Loss:  0.06942860782146454
Epoch:  166  	Training Loss: 0.05226917564868927
Test Loss:  0.06972309947013855
Valid Loss:  0.06942842155694962
Epoch:  167  	Training Loss: 0.05226869881153107
Test Loss:  0.06972313672304153
Valid Loss:  0.06942825019359589
Epoch:  168  	Training Loss: 0.052268221974372864
Test Loss:  0.06972317397594452
Valid Loss:  0.06942807137966156
Epoch:  169  	Training Loss: 0.05226774513721466
Test Loss:  0.06972317397594452
Valid Loss:  0.06942787766456604
Epoch:  170  	Training Loss: 0.05226726830005646
Test Loss:  0.0697232186794281
Valid Loss:  0.06942769885063171
Epoch:  171  	Training Loss: 0.052266791462898254
Test Loss:  0.06972326338291168
Valid Loss:  0.06942752748727798
Epoch:  172  	Training Loss: 0.05226631835103035
Test Loss:  0.06972324848175049
Valid Loss:  0.06942733377218246
Epoch:  173  	Training Loss: 0.052265845239162445
Test Loss:  0.06972328573465347
Valid Loss:  0.06942716240882874
Epoch:  174  	Training Loss: 0.05226537212729454
Test Loss:  0.06972333043813705
Valid Loss:  0.06942698359489441
Epoch:  175  	Training Loss: 0.052264899015426636
Test Loss:  0.06972332298755646
Valid Loss:  0.06942678987979889
Epoch:  176  	Training Loss: 0.05226442962884903
Test Loss:  0.06972335278987885
Valid Loss:  0.06942661106586456
Epoch:  177  	Training Loss: 0.052263956516981125
Test Loss:  0.06972339749336243
Valid Loss:  0.06942643225193024
Epoch:  178  	Training Loss: 0.05226348340511322
Test Loss:  0.06972338259220123
Valid Loss:  0.06942623853683472
Epoch:  179  	Training Loss: 0.052263010293245316
Test Loss:  0.06972342729568481
Valid Loss:  0.06942605972290039
Epoch:  180  	Training Loss: 0.05226253718137741
Test Loss:  0.0697234570980072
Valid Loss:  0.06942588090896606
Epoch:  181  	Training Loss: 0.052262067794799805
Test Loss:  0.0697234496474266
Valid Loss:  0.06942568719387054
Epoch:  182  	Training Loss: 0.0522615946829319
Test Loss:  0.0697234719991684
Valid Loss:  0.06942550837993622
Epoch:  183  	Training Loss: 0.052261125296354294
Test Loss:  0.06972351670265198
Valid Loss:  0.06942532956600189
Epoch:  184  	Training Loss: 0.05226065590977669
Test Loss:  0.06972350180149078
Valid Loss:  0.06942513585090637
Epoch:  185  	Training Loss: 0.05226019024848938
Test Loss:  0.06972353160381317
Valid Loss:  0.06942495703697205
Epoch:  186  	Training Loss: 0.052259720861911774
Test Loss:  0.06972356140613556
Valid Loss:  0.06942477822303772
Epoch:  187  	Training Loss: 0.05225925147533417
Test Loss:  0.06972355395555496
Valid Loss:  0.0694245919585228
Epoch:  188  	Training Loss: 0.05225878208875656
Test Loss:  0.06972358375787735
Valid Loss:  0.06942441314458847
Epoch:  189  	Training Loss: 0.052258312702178955
Test Loss:  0.06972362101078033
Valid Loss:  0.06942423433065414
Epoch:  190  	Training Loss: 0.05225784704089165
Test Loss:  0.06972365081310272
Valid Loss:  0.06942405551671982
Epoch:  191  	Training Loss: 0.05225737392902374
Test Loss:  0.06972363591194153
Valid Loss:  0.0694238618016243
Epoch:  192  	Training Loss: 0.05225691199302673
Test Loss:  0.0697237104177475
Valid Loss:  0.06942372769117355
Epoch:  193  	Training Loss: 0.05225646495819092
Test Loss:  0.06972376257181168
Valid Loss:  0.06942357867956161
Epoch:  194  	Training Loss: 0.0522560253739357
Test Loss:  0.06972378492355347
Valid Loss:  0.06942342966794968
Epoch:  195  	Training Loss: 0.05225558206439018
Test Loss:  0.06972387433052063
Valid Loss:  0.06942328065633774
Epoch:  196  	Training Loss: 0.052255138754844666
Test Loss:  0.0697239339351654
Valid Loss:  0.0694231390953064
Epoch:  197  	Training Loss: 0.05225469917058945
Test Loss:  0.0697239488363266
Valid Loss:  0.06942298263311386
Epoch:  198  	Training Loss: 0.05225425958633423
Test Loss:  0.06972404569387436
Valid Loss:  0.06942284107208252
Epoch:  199  	Training Loss: 0.05225382000207901
Test Loss:  0.06972409784793854
Valid Loss:  0.06942269951105118
Epoch:  200  	Training Loss: 0.05225338041782379
Test Loss:  0.06972412765026093
Valid Loss:  0.06942254304885864
Epoch:  201  	Training Loss: 0.05225294083356857
Test Loss:  0.06972421705722809
Valid Loss:  0.0694224089384079
Epoch:  202  	Training Loss: 0.052252501249313354
Test Loss:  0.06972429156303406
Valid Loss:  0.06942227482795715
Epoch:  203  	Training Loss: 0.05225206911563873
Test Loss:  0.06972434371709824
Valid Loss:  0.06942212581634521
Epoch:  204  	Training Loss: 0.052251629531383514
Test Loss:  0.06972440332174301
Valid Loss:  0.06942197680473328
Epoch:  205  	Training Loss: 0.05225120112299919
Test Loss:  0.06972447037696838
Valid Loss:  0.06942185759544373
Epoch:  206  	Training Loss: 0.05225076898932457
Test Loss:  0.06972452998161316
Valid Loss:  0.06942171603441238
Epoch:  207  	Training Loss: 0.05225034058094025
Test Loss:  0.06972458958625793
Valid Loss:  0.06942157447338104
Epoch:  208  	Training Loss: 0.052249908447265625
Test Loss:  0.0697246566414833
Valid Loss:  0.0694214403629303
Epoch:  209  	Training Loss: 0.052249476313591
Test Loss:  0.06972474604845047
Valid Loss:  0.06942130625247955
Epoch:  210  	Training Loss: 0.05224904045462608
Test Loss:  0.06972480565309525
Valid Loss:  0.06942116469144821
Epoch:  211  	Training Loss: 0.05224861204624176
Test Loss:  0.06972483545541763
Valid Loss:  0.06942102313041687
Epoch:  212  	Training Loss: 0.05224818363785744
Test Loss:  0.06972488015890121
Valid Loss:  0.06942084431648254
Epoch:  213  	Training Loss: 0.05224771797657013
Test Loss:  0.06972488760948181
Valid Loss:  0.06942065060138702
Epoch:  214  	Training Loss: 0.05224725976586342
Test Loss:  0.06972489506006241
Valid Loss:  0.0694204717874527
Epoch:  215  	Training Loss: 0.05224679782986641
Test Loss:  0.069724902510643
Valid Loss:  0.06942027807235718
Epoch:  216  	Training Loss: 0.0522463358938694
Test Loss:  0.06972494721412659
Valid Loss:  0.06942009925842285
Epoch:  217  	Training Loss: 0.05224587023258209
Test Loss:   43%|████▎     | 217/500 [02:30<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:30<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:36<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:37<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:37<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:43<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:50<05:02,  1.17s/it] 49%|████▊     | 243/500 [02:50<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:50<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:50<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.00it/s] 50%|█████     | 251/500 [02:57<04:54,  1.18s/it] 51%|█████     | 253/500 [02:57<03:29,  1.18it/s] 51%|█████     | 255/500 [02:57<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:57<01:49,  2.22it/s] 52%|█████▏    | 259/500 [02:57<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:04<04:43,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:21,  1.17it/s] 53%|█████▎    | 265/500 [03:04<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:04<01:47,  2.17it/s] 54%|█████▍    | 269/500 [03:04<01:20,  2.87it/s] 54%|█████▍    | 271/500 [03:11<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:11<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:11<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:11<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:11<01:15,  2.94it/s] 56%|█████▌    | 281/500 [03:18<04:24,  1.21s/it] 57%|█████▋    | 283/500 [03:18<03:07,  1.16it/s] 57%|█████▋    | 285/500 [03:18<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:18<01:37,  2.18it/s]0.06972495466470718
Valid Loss:  0.06941991299390793
Epoch:  218  	Training Loss: 0.05224540829658508
Test Loss:  0.06972496211528778
Valid Loss:  0.06941971927881241
Epoch:  219  	Training Loss: 0.052244946360588074
Test Loss:  0.06972496956586838
Valid Loss:  0.06941953301429749
Epoch:  220  	Training Loss: 0.052244484424591064
Test Loss:  0.06972502171993256
Valid Loss:  0.06941936910152435
Epoch:  221  	Training Loss: 0.052244022488594055
Test Loss:  0.06972497701644897
Valid Loss:  0.06941916048526764
Epoch:  222  	Training Loss: 0.052243560552597046
Test Loss:  0.06972503662109375
Valid Loss:  0.0694190114736557
Epoch:  223  	Training Loss: 0.05224312096834183
Test Loss:  0.06972506642341614
Valid Loss:  0.06941884756088257
Epoch:  224  	Training Loss: 0.05224268138408661
Test Loss:  0.06972513347864151
Valid Loss:  0.06941868364810944
Epoch:  225  	Training Loss: 0.05224224179983139
Test Loss:  0.06972511112689972
Valid Loss:  0.0694185122847557
Epoch:  226  	Training Loss: 0.05224179849028587
Test Loss:  0.0697251707315445
Valid Loss:  0.06941835582256317
Epoch:  227  	Training Loss: 0.05224135145545006
Test Loss:  0.06972523033618927
Valid Loss:  0.06941820681095123
Epoch:  228  	Training Loss: 0.05224091187119484
Test Loss:  0.06972526013851166
Valid Loss:  0.0694180428981781
Epoch:  229  	Training Loss: 0.05224047601222992
Test Loss:  0.06972527503967285
Valid Loss:  0.06941787898540497
Epoch:  230  	Training Loss: 0.0522400327026844
Test Loss:  0.06972530484199524
Valid Loss:  0.06941771507263184
Epoch:  231  	Training Loss: 0.052239589393138885
Test Loss:  0.06972536444664001
Valid Loss:  0.0694175586104393
Epoch:  232  	Training Loss: 0.05223914980888367
Test Loss:  0.06972537934780121
Valid Loss:  0.06941738724708557
Epoch:  233  	Training Loss: 0.05223870649933815
Test Loss:  0.0697253867983818
Valid Loss:  0.06941720843315125
Epoch:  234  	Training Loss: 0.052238259464502335
Test Loss:  0.06972543150186539
Valid Loss:  0.06941704452037811
Epoch:  235  	Training Loss: 0.05223781242966652
Test Loss:  0.06972543895244598
Valid Loss:  0.06941686570644379
Epoch:  236  	Training Loss: 0.052237369120121
Test Loss:  0.06972549110651016
Valid Loss:  0.06941670179367065
Epoch:  237  	Training Loss: 0.05223692208528519
Test Loss:  0.06972552835941315
Valid Loss:  0.06941653043031693
Epoch:  238  	Training Loss: 0.05223647505044937
Test Loss:  0.06972550600767136
Valid Loss:  0.069416344165802
Epoch:  239  	Training Loss: 0.052236031740903854
Test Loss:  0.06972555071115494
Valid Loss:  0.06941618025302887
Epoch:  240  	Training Loss: 0.05223558843135834
Test Loss:  0.06972557306289673
Valid Loss:  0.06941600888967514
Epoch:  241  	Training Loss: 0.05223514139652252
Test Loss:  0.06972560286521912
Valid Loss:  0.06941583752632141
Epoch:  242  	Training Loss: 0.05223469436168671
Test Loss:  0.0697256475687027
Valid Loss:  0.06941567361354828
Epoch:  243  	Training Loss: 0.05223425477743149
Test Loss:  0.06972561776638031
Valid Loss:  0.06941547989845276
Epoch:  244  	Training Loss: 0.05223381519317627
Test Loss:  0.06972566246986389
Valid Loss:  0.06941533088684082
Epoch:  245  	Training Loss: 0.05223337188363075
Test Loss:  0.06972570717334747
Valid Loss:  0.06941515952348709
Epoch:  246  	Training Loss: 0.05223293602466583
Test Loss:  0.06972574442625046
Valid Loss:  0.06941500306129456
Epoch:  247  	Training Loss: 0.052232492715120316
Test Loss:  0.06972574442625046
Valid Loss:  0.06941481679677963
Epoch:  248  	Training Loss: 0.0522320494055748
Test Loss:  0.06972575187683105
Valid Loss:  0.0694146528840065
Epoch:  249  	Training Loss: 0.05223160982131958
Test Loss:  0.06972578912973404
Valid Loss:  0.06941448152065277
Epoch:  250  	Training Loss: 0.05223117023706436
Test Loss:  0.06972580403089523
Valid Loss:  0.06941431015729904
Epoch:  251  	Training Loss: 0.05223073065280914
Test Loss:  0.06972582638263702
Valid Loss:  0.06941413879394531
Epoch:  252  	Training Loss: 0.05223027989268303
Test Loss:  0.0697258785367012
Valid Loss:  0.06941398233175278
Epoch:  253  	Training Loss: 0.05222984403371811
Test Loss:  0.06972593069076538
Valid Loss:  0.06941382586956024
Epoch:  254  	Training Loss: 0.052229419350624084
Test Loss:  0.069725900888443
Valid Loss:  0.06941364705562592
Epoch:  255  	Training Loss: 0.05222898721694946
Test Loss:  0.06972594559192657
Valid Loss:  0.06941348314285278
Epoch:  256  	Training Loss: 0.05222855508327484
Test Loss:  0.06972599029541016
Valid Loss:  0.06941333413124084
Epoch:  257  	Training Loss: 0.05222812294960022
Test Loss:  0.06972603499889374
Valid Loss:  0.06941316276788712
Epoch:  258  	Training Loss: 0.0522276908159256
Test Loss:  0.06972607970237732
Valid Loss:  0.06941300630569458
Epoch:  259  	Training Loss: 0.05222725123167038
Test Loss:  0.06972608715295792
Valid Loss:  0.06941282749176025
Epoch:  260  	Training Loss: 0.05222681909799576
Test Loss:  0.06972609460353851
Valid Loss:  0.06941266357898712
Epoch:  261  	Training Loss: 0.052226390689611435
Test Loss:  0.0697261318564415
Valid Loss:  0.06941251456737518
Epoch:  262  	Training Loss: 0.052225954830646515
Test Loss:  0.06972618401050568
Valid Loss:  0.06941236555576324
Epoch:  263  	Training Loss: 0.05222553014755249
Test Loss:  0.06972622871398926
Valid Loss:  0.06941220164299011
Epoch:  264  	Training Loss: 0.052225105464458466
Test Loss:  0.06972625851631165
Valid Loss:  0.06941204518079758
Epoch:  265  	Training Loss: 0.05222468450665474
Test Loss:  0.06972630321979523
Valid Loss:  0.06941189616918564
Epoch:  266  	Training Loss: 0.052224259823560715
Test Loss:  0.06972634792327881
Valid Loss:  0.0694117397069931
Epoch:  267  	Training Loss: 0.05222383886575699
Test Loss:  0.06972640007734299
Valid Loss:  0.06941159814596176
Epoch:  268  	Training Loss: 0.052223414182662964
Test Loss:  0.06972640007734299
Valid Loss:  0.06941143423318863
Epoch:  269  	Training Loss: 0.05222299322485924
Test Loss:  0.06972645968198776
Valid Loss:  0.06941129267215729
Epoch:  270  	Training Loss: 0.05222257226705551
Test Loss:  0.06972650438547134
Valid Loss:  0.06941113620996475
Epoch:  271  	Training Loss: 0.05222214758396149
Test Loss:  0.06972651928663254
Valid Loss:  0.06941097974777222
Epoch:  272  	Training Loss: 0.05222172290086746
Test Loss:  0.06972655653953552
Valid Loss:  0.06941083073616028
Epoch:  273  	Training Loss: 0.052221305668354034
Test Loss:  0.0697266012430191
Valid Loss:  0.06941067427396774
Epoch:  274  	Training Loss: 0.05222088471055031
Test Loss:  0.06972665339708328
Valid Loss:  0.06941051781177521
Epoch:  275  	Training Loss: 0.052220460027456284
Test Loss:  0.06972669064998627
Valid Loss:  0.06941036880016327
Epoch:  276  	Training Loss: 0.05222003906965256
Test Loss:  0.06972673535346985
Valid Loss:  0.06941021233797073
Epoch:  277  	Training Loss: 0.05221961811184883
Test Loss:  0.06972677260637283
Valid Loss:  0.0694100558757782
Epoch:  278  	Training Loss: 0.052219197154045105
Test Loss:  0.06972680985927582
Valid Loss:  0.06940989941358566
Epoch:  279  	Training Loss: 0.05221877992153168
Test Loss:  0.06972680985927582
Valid Loss:  0.06940974295139313
Epoch:  280  	Training Loss: 0.05221835523843765
Test Loss:  0.0697268545627594
Valid Loss:  0.06940958648920059
Epoch:  281  	Training Loss: 0.052217938005924225
Test Loss:  0.06972689926624298
Valid Loss:  0.06940943747758865
Epoch:  282  	Training Loss: 0.0522175170481205
Test Loss:  0.06972692906856537
Valid Loss:  0.06940928846597672
Epoch:  283  	Training Loss: 0.05221709609031677
Test Loss:  0.06972697377204895
Valid Loss:  0.06940913200378418
Epoch:  284  	Training Loss: 0.052216678857803345
Test Loss:  0.06972697377204895
Valid Loss:  0.06940898299217224
Epoch:  285  	Training Loss: 0.05221626162528992
Test Loss:  0.06972701847553253
Valid Loss:  0.0694088265299797
Epoch:  286  	Training Loss: 0.05221584439277649
Test Loss:  0.06972704827785492
Valid Loss:  0.06940868496894836
Epoch:  287  	Training Loss: 0.05221542716026306
Test Loss:  0.0697270929813385
Valid Loss:  0.06940852105617523
Epoch:  288  	Training Loss: 0.052215009927749634
Test Loss:  0.06972712278366089
Valid Loss:  0.0694083720445633
Epoch:  289  	Training Loss: 0.052214596420526505
 58%|█████▊    | 289/500 [03:18<01:12,  2.93it/s] 58%|█████▊    | 291/500 [03:24<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:25<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:25<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:25<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:25<01:07,  2.99it/s] 60%|██████    | 301/500 [03:31<03:52,  1.17s/it] 61%|██████    | 303/500 [03:31<02:45,  1.19it/s] 61%|██████    | 305/500 [03:31<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:32<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:32<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:38<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:38<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:38<01:51,  1.65it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.26it/s] 64%|██████▍   | 319/500 [03:38<00:59,  3.04it/s] 64%|██████▍   | 321/500 [03:45<03:28,  1.16s/it] 65%|██████▍   | 323/500 [03:45<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:45<01:45,  1.66it/s] 65%|██████▌   | 327/500 [03:45<01:16,  2.26it/s] 66%|██████▌   | 329/500 [03:45<00:56,  3.03it/s] 66%|██████▌   | 331/500 [03:51<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:52<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:52<01:40,  1.65it/s] 67%|██████▋   | 337/500 [03:52<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:52<00:53,  3.03it/s] 68%|██████▊   | 341/500 [03:58<03:06,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:12,  1.19it/s] 69%|██████▉   | 345/500 [03:59<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:59<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:59<00:50,  3.01it/s] 70%|███████   | 351/500 [04:05<02:57,  1.19s/it] 71%|███████   | 353/500 [04:05<02:05,  1.17it/s] 71%|███████   | 355/500 [04:05<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:06<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:06<00:47,  2.98it/s]Test Loss:  0.06972716748714447
Valid Loss:  0.06940822303295135
Epoch:  290  	Training Loss: 0.05221417918801308
Test Loss:  0.06972719728946686
Valid Loss:  0.06940807402133942
Epoch:  291  	Training Loss: 0.05221376195549965
Test Loss:  0.06972724199295044
Valid Loss:  0.06940791755914688
Epoch:  292  	Training Loss: 0.05221334844827652
Test Loss:  0.06972727924585342
Valid Loss:  0.06940777599811554
Epoch:  293  	Training Loss: 0.05221293494105339
Test Loss:  0.069727323949337
Valid Loss:  0.0694076269865036
Epoch:  294  	Training Loss: 0.05221252515912056
Test Loss:  0.06972736120223999
Valid Loss:  0.06940748542547226
Epoch:  295  	Training Loss: 0.05221211537718773
Test Loss:  0.06972740590572357
Valid Loss:  0.06940733641386032
Epoch:  296  	Training Loss: 0.0522117093205452
Test Loss:  0.06972744315862656
Valid Loss:  0.06940719485282898
Epoch:  297  	Training Loss: 0.052211299538612366
Test Loss:  0.06972749531269073
Valid Loss:  0.06940706074237823
Epoch:  298  	Training Loss: 0.052210886031389236
Test Loss:  0.06972752511501312
Valid Loss:  0.0694069042801857
Epoch:  299  	Training Loss: 0.05221047252416611
Test Loss:  0.0697275698184967
Valid Loss:  0.06940676271915436
Epoch:  300  	Training Loss: 0.052210066467523575
Test Loss:  0.06972759962081909
Valid Loss:  0.06940661370754242
Epoch:  301  	Training Loss: 0.052209652960300446
Test Loss:  0.06972764432430267
Valid Loss:  0.06940646469593048
Epoch:  302  	Training Loss: 0.052209243178367615
Test Loss:  0.06972768157720566
Valid Loss:  0.06940633058547974
Epoch:  303  	Training Loss: 0.05220884084701538
Test Loss:  0.06972772628068924
Valid Loss:  0.0694061815738678
Epoch:  304  	Training Loss: 0.05220843479037285
Test Loss:  0.06972776353359222
Valid Loss:  0.06940603256225586
Epoch:  305  	Training Loss: 0.052208028733730316
Test Loss:  0.0697278082370758
Valid Loss:  0.06940589845180511
Epoch:  306  	Training Loss: 0.05220762640237808
Test Loss:  0.06972784548997879
Valid Loss:  0.06940576434135437
Epoch:  307  	Training Loss: 0.05220722407102585
Test Loss:  0.06972789019346237
Valid Loss:  0.06940562278032303
Epoch:  308  	Training Loss: 0.052206821739673615
Test Loss:  0.06972792744636536
Valid Loss:  0.06940548121929169
Epoch:  309  	Training Loss: 0.05220641940832138
Test Loss:  0.06972796469926834
Valid Loss:  0.06940533220767975
Epoch:  310  	Training Loss: 0.05220600962638855
Test Loss:  0.06972800195217133
Valid Loss:  0.06940519064664841
Epoch:  311  	Training Loss: 0.052205607295036316
Test Loss:  0.06972803920507431
Valid Loss:  0.06940504908561707
Epoch:  312  	Training Loss: 0.05220520496368408
Test Loss:  0.0697280764579773
Valid Loss:  0.06940490007400513
Epoch:  313  	Training Loss: 0.05220480263233185
Test Loss:  0.06972810626029968
Valid Loss:  0.06940475106239319
Epoch:  314  	Training Loss: 0.05220439285039902
Test Loss:  0.06972813606262207
Valid Loss:  0.06940461695194244
Epoch:  315  	Training Loss: 0.05220399051904678
Test Loss:  0.06972816586494446
Valid Loss:  0.0694044679403305
Epoch:  316  	Training Loss: 0.05220358818769455
Test Loss:  0.06972819566726685
Valid Loss:  0.06940431892871857
Epoch:  317  	Training Loss: 0.05220318213105202
Test Loss:  0.06972824037075043
Valid Loss:  0.06940417736768723
Epoch:  318  	Training Loss: 0.05220278352499008
Test Loss:  0.06972827017307281
Valid Loss:  0.06940403580665588
Epoch:  319  	Training Loss: 0.05220238119363785
Test Loss:  0.0697282999753952
Valid Loss:  0.06940388679504395
Epoch:  320  	Training Loss: 0.052201978862285614
Test Loss:  0.06972832977771759
Valid Loss:  0.069403737783432
Epoch:  321  	Training Loss: 0.05220157280564308
Test Loss:  0.06972835958003998
Valid Loss:  0.06940358877182007
Epoch:  322  	Training Loss: 0.05220116674900055
Test Loss:  0.06972838938236237
Valid Loss:  0.06940345466136932
Epoch:  323  	Training Loss: 0.052200764417648315
Test Loss:  0.06972841918468475
Valid Loss:  0.06940330564975739
Epoch:  324  	Training Loss: 0.05220035836100578
Test Loss:  0.06972843408584595
Valid Loss:  0.06940314918756485
Epoch:  325  	Training Loss: 0.05219995230436325
Test Loss:  0.06972846388816833
Valid Loss:  0.06940300017595291
Epoch:  326  	Training Loss: 0.05219954997301102
Test Loss:  0.06972849369049072
Valid Loss:  0.06940285116434097
Epoch:  327  	Training Loss: 0.05219914764165878
Test Loss:  0.06972852349281311
Valid Loss:  0.06940270215272903
Epoch:  328  	Training Loss: 0.05219874531030655
Test Loss:  0.0697285532951355
Valid Loss:  0.06940256059169769
Epoch:  329  	Training Loss: 0.05219833925366402
Test Loss:  0.06972858309745789
Valid Loss:  0.06940241158008575
Epoch:  330  	Training Loss: 0.05219794064760208
Test Loss:  0.06972861289978027
Valid Loss:  0.06940226256847382
Epoch:  331  	Training Loss: 0.05219753459095955
Test Loss:  0.06972863525152206
Valid Loss:  0.06940211355686188
Epoch:  332  	Training Loss: 0.052197135984897614
Test Loss:  0.06972867250442505
Valid Loss:  0.06940197944641113
Epoch:  333  	Training Loss: 0.05219674110412598
Test Loss:  0.06972870975732803
Valid Loss:  0.06940185278654099
Epoch:  334  	Training Loss: 0.052196357399225235
Test Loss:  0.06972873210906982
Valid Loss:  0.06940171122550964
Epoch:  335  	Training Loss: 0.052195966243743896
Test Loss:  0.0697287768125534
Valid Loss:  0.0694015845656395
Epoch:  336  	Training Loss: 0.052195578813552856
Test Loss:  0.06972882151603699
Valid Loss:  0.06940145045518875
Epoch:  337  	Training Loss: 0.052195191383361816
Test Loss:  0.06972885131835938
Valid Loss:  0.0694013237953186
Epoch:  338  	Training Loss: 0.052194803953170776
Test Loss:  0.06972889602184296
Valid Loss:  0.06940118968486786
Epoch:  339  	Training Loss: 0.052194416522979736
Test Loss:  0.06972892582416534
Valid Loss:  0.06940105557441711
Epoch:  340  	Training Loss: 0.0521940253674984
Test Loss:  0.06972897052764893
Valid Loss:  0.06940093636512756
Epoch:  341  	Training Loss: 0.05219363793730736
Test Loss:  0.06972901523113251
Valid Loss:  0.06940080225467682
Epoch:  342  	Training Loss: 0.05219325050711632
Test Loss:  0.06972901523113251
Valid Loss:  0.06940063834190369
Epoch:  343  	Training Loss: 0.052192844450473785
Test Loss:  0.06972901523113251
Valid Loss:  0.06940048187971115
Epoch:  344  	Training Loss: 0.052192434668540955
Test Loss:  0.0697290226817131
Valid Loss:  0.06940031051635742
Epoch:  345  	Training Loss: 0.05219202861189842
Test Loss:  0.0697290301322937
Valid Loss:  0.06940015405416489
Epoch:  346  	Training Loss: 0.05219162255525589
Test Loss:  0.0697290301322937
Valid Loss:  0.06939999014139175
Epoch:  347  	Training Loss: 0.05219121649861336
Test Loss:  0.0697290301322937
Valid Loss:  0.06939983367919922
Epoch:  348  	Training Loss: 0.052190810441970825
Test Loss:  0.0697290450334549
Valid Loss:  0.06939966231584549
Epoch:  349  	Training Loss: 0.052190400660037994
Test Loss:  0.0697290450334549
Valid Loss:  0.06939950585365295
Epoch:  350  	Training Loss: 0.05218999832868576
Test Loss:  0.06972905248403549
Valid Loss:  0.06939934194087982
Epoch:  351  	Training Loss: 0.05218958854675293
Test Loss:  0.06972905248403549
Valid Loss:  0.06939917802810669
Epoch:  352  	Training Loss: 0.052189186215400696
Test Loss:  0.06972907483577728
Valid Loss:  0.06939903646707535
Epoch:  353  	Training Loss: 0.05218879133462906
Test Loss:  0.06972908973693848
Valid Loss:  0.06939888745546341
Epoch:  354  	Training Loss: 0.05218839645385742
Test Loss:  0.06972910463809967
Valid Loss:  0.06939874589443207
Epoch:  355  	Training Loss: 0.052188001573085785
Test Loss:  0.06972911953926086
Valid Loss:  0.06939859688282013
Epoch:  356  	Training Loss: 0.05218760296702385
Test Loss:  0.06972913444042206
Valid Loss:  0.06939844787120819
Epoch:  357  	Training Loss: 0.05218721181154251
Test Loss:  0.06972914934158325
Valid Loss:  0.06939829885959625
Epoch:  358  	Training Loss: 0.052186816930770874
Test Loss:  0.06972915679216385
Valid Loss:  0.06939814984798431
Epoch:  359  	Training Loss: 0.052186425775289536
Test Loss:  0.06972917169332504
Valid Loss:  0.06939800083637238
Epoch:  360  	Training Loss: 0.0521860271692276
Test Loss:  0.06972918659448624
Valid Loss:  0.06939785182476044
 72%|███████▏  | 361/500 [04:12<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:12<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:12<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:13<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:19<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:19<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:19<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:19<00:40,  2.95it/s] 76%|███████▌  | 381/500 [04:26<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:26<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:26<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:26<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:26<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:33<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:33<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:33<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:33<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.02it/s] 80%|████████  | 401/500 [04:39<01:56,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.19it/s] 81%|████████  | 405/500 [04:40<00:58,  1.64it/s] 81%|████████▏ | 407/500 [04:40<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:40<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:46<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:46<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:47<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:47<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:53<01:34,  1.19s/it] 85%|████████▍ | 423/500 [04:53<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:53<00:46,  1.61it/s] 85%|████████▌ | 427/500 [04:53<00:33,  2.21it/s] 86%|████████▌ | 429/500 [04:54<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:00<01:21,  1.18s/it]Epoch:  361  	Training Loss: 0.05218563228845596
Test Loss:  0.06972920149564743
Valid Loss:  0.0693976953625679
Epoch:  362  	Training Loss: 0.052185237407684326
Test Loss:  0.06972922384738922
Valid Loss:  0.06939756125211716
Epoch:  363  	Training Loss: 0.05218485742807388
Test Loss:  0.06972925364971161
Valid Loss:  0.06939742714166641
Epoch:  364  	Training Loss: 0.05218448117375374
Test Loss:  0.069729283452034
Valid Loss:  0.06939730048179626
Epoch:  365  	Training Loss: 0.052184097468853
Test Loss:  0.06972929835319519
Valid Loss:  0.06939716637134552
Epoch:  366  	Training Loss: 0.05218372121453285
Test Loss:  0.06972932815551758
Valid Loss:  0.06939702481031418
Epoch:  367  	Training Loss: 0.05218333750963211
Test Loss:  0.06972935795783997
Valid Loss:  0.06939689815044403
Epoch:  368  	Training Loss: 0.052182964980602264
Test Loss:  0.06972938776016235
Valid Loss:  0.06939676403999329
Epoch:  369  	Training Loss: 0.05218258500099182
Test Loss:  0.06972940266132355
Valid Loss:  0.06939662992954254
Epoch:  370  	Training Loss: 0.05218220502138138
Test Loss:  0.06972943246364594
Valid Loss:  0.0693964958190918
Epoch:  371  	Training Loss: 0.052181825041770935
Test Loss:  0.06972949206829071
Valid Loss:  0.06939637660980225
Epoch:  372  	Training Loss: 0.05218144878745079
Test Loss:  0.06972948461771011
Valid Loss:  0.06939622759819031
Epoch:  373  	Training Loss: 0.05218105390667915
Test Loss:  0.0697295218706131
Valid Loss:  0.06939607858657837
Epoch:  374  	Training Loss: 0.052180659025907516
Test Loss:  0.0697295218706131
Valid Loss:  0.06939591467380524
Epoch:  375  	Training Loss: 0.05218026414513588
Test Loss:  0.06972954422235489
Valid Loss:  0.0693957656621933
Epoch:  376  	Training Loss: 0.05217986926436424
Test Loss:  0.06972955167293549
Valid Loss:  0.06939561665058136
Epoch:  377  	Training Loss: 0.05217947065830231
Test Loss:  0.06972955167293549
Valid Loss:  0.06939545273780823
Epoch:  378  	Training Loss: 0.05217908322811127
Test Loss:  0.06972957402467728
Valid Loss:  0.06939530372619629
Epoch:  379  	Training Loss: 0.05217868462204933
Test Loss:  0.06972958147525787
Valid Loss:  0.06939515471458435
Epoch:  380  	Training Loss: 0.05217829346656799
Test Loss:  0.06972961127758026
Valid Loss:  0.06939499825239182
Epoch:  381  	Training Loss: 0.052177898585796356
Test Loss:  0.06972961127758026
Valid Loss:  0.06939484924077988
Epoch:  382  	Training Loss: 0.05217750370502472
Test Loss:  0.06972964853048325
Valid Loss:  0.06939470767974854
Epoch:  383  	Training Loss: 0.05217711627483368
Test Loss:  0.06972965598106384
Valid Loss:  0.0693945586681366
Epoch:  384  	Training Loss: 0.05217673256993294
Test Loss:  0.06972969323396683
Valid Loss:  0.06939442455768585
Epoch:  385  	Training Loss: 0.0521763414144516
Test Loss:  0.06972969323396683
Valid Loss:  0.06939426064491272
Epoch:  386  	Training Loss: 0.05217595398426056
Test Loss:  0.06972973048686981
Valid Loss:  0.06939412653446198
Epoch:  387  	Training Loss: 0.05217556655406952
Test Loss:  0.06972973048686981
Valid Loss:  0.06939397007226944
Epoch:  388  	Training Loss: 0.05217518284916878
Test Loss:  0.0697297602891922
Valid Loss:  0.0693938285112381
Epoch:  389  	Training Loss: 0.05217479169368744
Test Loss:  0.0697297677397728
Valid Loss:  0.06939367949962616
Epoch:  390  	Training Loss: 0.052174411714076996
Test Loss:  0.0697297751903534
Valid Loss:  0.06939353793859482
Epoch:  391  	Training Loss: 0.052174024283885956
Test Loss:  0.06972980499267578
Valid Loss:  0.06939338892698288
Epoch:  392  	Training Loss: 0.05217363312840462
Test Loss:  0.06972979009151459
Valid Loss:  0.06939323246479034
Epoch:  393  	Training Loss: 0.05217324197292328
Test Loss:  0.06972983479499817
Valid Loss:  0.069393090903759
Epoch:  394  	Training Loss: 0.052172861993312836
Test Loss:  0.06972984969615936
Valid Loss:  0.06939294934272766
Epoch:  395  	Training Loss: 0.052172474563121796
Test Loss:  0.06972984224557877
Valid Loss:  0.06939279288053513
Epoch:  396  	Training Loss: 0.05217207968235016
Test Loss:  0.06972987204790115
Valid Loss:  0.06939265131950378
Epoch:  397  	Training Loss: 0.05217169225215912
Test Loss:  0.06972987204790115
Valid Loss:  0.06939249485731125
Epoch:  398  	Training Loss: 0.05217130482196808
Test Loss:  0.06972990185022354
Valid Loss:  0.06939234584569931
Epoch:  399  	Training Loss: 0.05217092111706734
Test Loss:  0.06972987949848175
Valid Loss:  0.06939218938350677
Epoch:  400  	Training Loss: 0.052170529961586
Test Loss:  0.06972990930080414
Valid Loss:  0.06939204782247543
Epoch:  401  	Training Loss: 0.05217014625668526
Test Loss:  0.06972990930080414
Valid Loss:  0.0693918913602829
Epoch:  402  	Training Loss: 0.05216975510120392
Test Loss:  0.06972993910312653
Valid Loss:  0.06939175724983215
Epoch:  403  	Training Loss: 0.052169375121593475
Test Loss:  0.06972993165254593
Valid Loss:  0.06939160823822021
Epoch:  404  	Training Loss: 0.052168991416692734
Test Loss:  0.06972996890544891
Valid Loss:  0.06939146667718887
Epoch:  405  	Training Loss: 0.05216861143708229
Test Loss:  0.06972995400428772
Valid Loss:  0.06939132511615753
Epoch:  406  	Training Loss: 0.05216823145747185
Test Loss:  0.06973002851009369
Valid Loss:  0.06939119100570679
Epoch:  407  	Training Loss: 0.052167847752571106
Test Loss:  0.06973005086183548
Valid Loss:  0.06939105689525604
Epoch:  408  	Training Loss: 0.05216746777296066
Test Loss:  0.06973008811473846
Valid Loss:  0.0693909078836441
Epoch:  409  	Training Loss: 0.05216709524393082
Test Loss:  0.06973011791706085
Valid Loss:  0.06939077377319336
Epoch:  410  	Training Loss: 0.05216670781373978
Test Loss:  0.06973010301589966
Valid Loss:  0.06939062476158142
Epoch:  411  	Training Loss: 0.052166327834129333
Test Loss:  0.06973016262054443
Valid Loss:  0.06939049065113068
Epoch:  412  	Training Loss: 0.05216595157980919
Test Loss:  0.06973019242286682
Valid Loss:  0.06939035654067993
Epoch:  413  	Training Loss: 0.05216556787490845
Test Loss:  0.06973020732402802
Valid Loss:  0.069390207529068
Epoch:  414  	Training Loss: 0.05216518044471741
Test Loss:  0.0697302371263504
Valid Loss:  0.06939005851745605
Epoch:  415  	Training Loss: 0.052164800465106964
Test Loss:  0.0697302520275116
Valid Loss:  0.06938991695642471
Epoch:  416  	Training Loss: 0.05216442048549652
Test Loss:  0.06973028182983398
Valid Loss:  0.06938976049423218
Epoch:  417  	Training Loss: 0.05216403305530548
Test Loss:  0.06973033398389816
Valid Loss:  0.06938963383436203
Epoch:  418  	Training Loss: 0.052163656800985336
Test Loss:  0.06973031163215637
Valid Loss:  0.0693894773721695
Epoch:  419  	Training Loss: 0.052163273096084595
Test Loss:  0.06973037123680115
Valid Loss:  0.06938934326171875
Epoch:  420  	Training Loss: 0.05216289311647415
Test Loss:  0.06973039358854294
Valid Loss:  0.069389209151268
Epoch:  421  	Training Loss: 0.05216251313686371
Test Loss:  0.06973041594028473
Valid Loss:  0.06938906013965607
Epoch:  422  	Training Loss: 0.05216212943196297
Test Loss:  0.06973046064376831
Valid Loss:  0.06938893347978592
Epoch:  423  	Training Loss: 0.05216175317764282
Test Loss:  0.06973046064376831
Valid Loss:  0.06938877701759338
Epoch:  424  	Training Loss: 0.05216136947274208
Test Loss:  0.06973051279783249
Valid Loss:  0.06938864290714264
Epoch:  425  	Training Loss: 0.052160993218421936
Test Loss:  0.06973053514957428
Valid Loss:  0.0693885013461113
Epoch:  426  	Training Loss: 0.05216061323881149
Test Loss:  0.06973055005073547
Valid Loss:  0.06938835978507996
Epoch:  427  	Training Loss: 0.05216023325920105
Test Loss:  0.06973057240247726
Valid Loss:  0.06938821077346802
Epoch:  428  	Training Loss: 0.052159860730171204
Test Loss:  0.06973063945770264
Valid Loss:  0.06938809156417847
Epoch:  429  	Training Loss: 0.05215947702527046
Test Loss:  0.06973061710596085
Valid Loss:  0.06938792765140533
Epoch:  430  	Training Loss: 0.05215910077095032
Test Loss:  0.06973066926002502
Valid Loss:  0.06938779354095459
Epoch:  431  	Training Loss: 0.052158720791339874
Test Loss:  0.0697307288646698
Valid Loss:  0.06938767433166504
Epoch:  432  	Training Loss: 0.05215834826231003
Test Loss:  0.0697307139635086
Valid Loss:   87%|████████▋ | 433/500 [05:00<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:00<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:00<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:07<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:07<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:07<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:07<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:14<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:14<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:14<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:20<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:21<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:21<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:21<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:27<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:27<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:28<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:28<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:34<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:34<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.22s/it] 99%|█████████▊| 493/500 [05:41<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.18it/s]100%|█████████▉| 499/500 [05:42<00:00,  2.92it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
0.0693875253200531
Epoch:  433  	Training Loss: 0.05215797200798988
Test Loss:  0.06973075866699219
Valid Loss:  0.06938739120960236
Epoch:  434  	Training Loss: 0.05215759575366974
Test Loss:  0.06973081827163696
Valid Loss:  0.06938725709915161
Epoch:  435  	Training Loss: 0.05215722322463989
Test Loss:  0.06973083317279816
Valid Loss:  0.06938712298870087
Epoch:  436  	Training Loss: 0.052156850695610046
Test Loss:  0.06973085552453995
Valid Loss:  0.06938697397708893
Epoch:  437  	Training Loss: 0.0521564707159996
Test Loss:  0.06973087787628174
Valid Loss:  0.06938683241605759
Epoch:  438  	Training Loss: 0.05215609818696976
Test Loss:  0.06973093748092651
Valid Loss:  0.06938670575618744
Epoch:  439  	Training Loss: 0.05215572565793991
Test Loss:  0.06973095238208771
Valid Loss:  0.0693865716457367
Epoch:  440  	Training Loss: 0.05215534567832947
Test Loss:  0.0697309672832489
Valid Loss:  0.06938642263412476
Epoch:  441  	Training Loss: 0.05215497314929962
Test Loss:  0.06973102688789368
Valid Loss:  0.0693863034248352
Epoch:  442  	Training Loss: 0.052154600620269775
Test Loss:  0.06973107159137726
Valid Loss:  0.06938616931438446
Epoch:  443  	Training Loss: 0.05215422809123993
Test Loss:  0.06973105669021606
Valid Loss:  0.06938602030277252
Epoch:  444  	Training Loss: 0.05215385928750038
Test Loss:  0.06973111629486084
Valid Loss:  0.06938589364290237
Epoch:  445  	Training Loss: 0.052153486758470535
Test Loss:  0.06973116099834442
Valid Loss:  0.06938576698303223
Epoch:  446  	Training Loss: 0.05215311795473099
Test Loss:  0.0697312131524086
Valid Loss:  0.06938564032316208
Epoch:  447  	Training Loss: 0.05215274915099144
Test Loss:  0.0697311982512474
Valid Loss:  0.06938549876213074
Epoch:  448  	Training Loss: 0.052152376621961594
Test Loss:  0.06973125040531158
Valid Loss:  0.06938537210226059
Epoch:  449  	Training Loss: 0.052152007818222046
Test Loss:  0.06973130255937576
Valid Loss:  0.06938523799180984
Epoch:  450  	Training Loss: 0.0521516352891922
Test Loss:  0.06973132491111755
Valid Loss:  0.0693851038813591
Epoch:  451  	Training Loss: 0.05215126648545265
Test Loss:  0.06973133981227875
Valid Loss:  0.06938496232032776
Epoch:  452  	Training Loss: 0.052150897681713104
Test Loss:  0.06973136961460114
Valid Loss:  0.06938482075929642
Epoch:  453  	Training Loss: 0.05215051770210266
Test Loss:  0.06973141431808472
Valid Loss:  0.06938468664884567
Epoch:  454  	Training Loss: 0.052150141447782516
Test Loss:  0.06973141431808472
Valid Loss:  0.06938453018665314
Epoch:  455  	Training Loss: 0.05214976519346237
Test Loss:  0.06973140686750412
Valid Loss:  0.0693843811750412
Epoch:  456  	Training Loss: 0.05214938521385193
Test Loss:  0.0697314441204071
Valid Loss:  0.06938423961400986
Epoch:  457  	Training Loss: 0.052149008959531784
Test Loss:  0.06973147392272949
Valid Loss:  0.06938411295413971
Epoch:  458  	Training Loss: 0.05214863270521164
Test Loss:  0.06973147392272949
Valid Loss:  0.06938395649194717
Epoch:  459  	Training Loss: 0.052148256450891495
Test Loss:  0.06973150372505188
Valid Loss:  0.06938381493091583
Epoch:  460  	Training Loss: 0.05214788019657135
Test Loss:  0.06973151117563248
Valid Loss:  0.0693836584687233
Epoch:  461  	Training Loss: 0.05214750021696091
Test Loss:  0.06973153352737427
Valid Loss:  0.06938351690769196
Epoch:  462  	Training Loss: 0.05214712396264076
Test Loss:  0.06973157823085785
Valid Loss:  0.06938338279724121
Epoch:  463  	Training Loss: 0.05214674770832062
Test Loss:  0.06973157078027725
Valid Loss:  0.06938323378562927
Epoch:  464  	Training Loss: 0.05214637517929077
Test Loss:  0.06973160803318024
Valid Loss:  0.06938309967517853
Epoch:  465  	Training Loss: 0.052146002650260925
Test Loss:  0.06973160803318024
Valid Loss:  0.06938295066356659
Epoch:  466  	Training Loss: 0.05214563012123108
Test Loss:  0.06973164528608322
Valid Loss:  0.06938280910253525
Epoch:  467  	Training Loss: 0.05214525759220123
Test Loss:  0.0697316825389862
Valid Loss:  0.0693826749920845
Epoch:  468  	Training Loss: 0.05214488506317139
Test Loss:  0.0697317123413086
Valid Loss:  0.06938253343105316
Epoch:  469  	Training Loss: 0.05214451253414154
Test Loss:  0.0697317123413086
Valid Loss:  0.06938239187002182
Epoch:  470  	Training Loss: 0.052144140005111694
Test Loss:  0.06973174214363098
Valid Loss:  0.06938225030899048
Epoch:  471  	Training Loss: 0.05214376002550125
Test Loss:  0.06973177194595337
Valid Loss:  0.06938210874795914
Epoch:  472  	Training Loss: 0.052143391221761703
Test Loss:  0.06973177194595337
Valid Loss:  0.0693819671869278
Epoch:  473  	Training Loss: 0.05214301869273186
Test Loss:  0.06973180919885635
Valid Loss:  0.06938183307647705
Epoch:  474  	Training Loss: 0.05214264616370201
Test Loss:  0.06973184645175934
Valid Loss:  0.0693816989660263
Epoch:  475  	Training Loss: 0.05214227735996246
Test Loss:  0.06973187625408173
Valid Loss:  0.06938155740499496
Epoch:  476  	Training Loss: 0.05214190483093262
Test Loss:  0.06973190605640411
Valid Loss:  0.06938141584396362
Epoch:  477  	Training Loss: 0.05214153230190277
Test Loss:  0.0697319358587265
Valid Loss:  0.06938128173351288
Epoch:  478  	Training Loss: 0.052141159772872925
Test Loss:  0.0697319433093071
Valid Loss:  0.06938113272190094
Epoch:  479  	Training Loss: 0.05214079096913338
Test Loss:  0.0697319433093071
Valid Loss:  0.0693809986114502
Epoch:  480  	Training Loss: 0.05214042216539383
Test Loss:  0.06973197311162949
Valid Loss:  0.06938084959983826
Epoch:  481  	Training Loss: 0.05214004963636398
Test Loss:  0.06973200291395187
Valid Loss:  0.06938071548938751
Epoch:  482  	Training Loss: 0.05213967710733414
Test Loss:  0.06973203271627426
Valid Loss:  0.06938058137893677
Epoch:  483  	Training Loss: 0.052139319479465485
Test Loss:  0.06973206996917725
Valid Loss:  0.06938046216964722
Epoch:  484  	Training Loss: 0.05213895067572594
Test Loss:  0.06973211467266083
Valid Loss:  0.06938032805919647
Epoch:  485  	Training Loss: 0.052138589322566986
Test Loss:  0.06973214447498322
Valid Loss:  0.06938019394874573
Epoch:  486  	Training Loss: 0.05213822424411774
Test Loss:  0.0697321817278862
Valid Loss:  0.06938006728887558
Epoch:  487  	Training Loss: 0.05213785916566849
Test Loss:  0.06973222643136978
Valid Loss:  0.06937994807958603
Epoch:  488  	Training Loss: 0.052137501537799835
Test Loss:  0.06973225623369217
Valid Loss:  0.06937981396913528
Epoch:  489  	Training Loss: 0.052137136459350586
Test Loss:  0.06973229348659515
Valid Loss:  0.06937967985868454
Epoch:  490  	Training Loss: 0.05213677138090134
Test Loss:  0.06973230093717575
Valid Loss:  0.0693795457482338
Epoch:  491  	Training Loss: 0.05213640630245209
Test Loss:  0.06973233819007874
Valid Loss:  0.06937941908836365
Epoch:  492  	Training Loss: 0.05213604494929314
Test Loss:  0.06973236054182053
Valid Loss:  0.0693792775273323
Epoch:  493  	Training Loss: 0.05213567987084389
Test Loss:  0.06973238289356232
Valid Loss:  0.06937913596630096
Epoch:  494  	Training Loss: 0.05213531106710434
Test Loss:  0.06973240524530411
Valid Loss:  0.06937900930643082
Epoch:  495  	Training Loss: 0.05213494598865509
Test Loss:  0.0697324275970459
Valid Loss:  0.06937886774539948
Epoch:  496  	Training Loss: 0.05213457718491554
Test Loss:  0.06973245739936829
Valid Loss:  0.06937872618436813
Epoch:  497  	Training Loss: 0.052134208381175995
Test Loss:  0.06973247975111008
Valid Loss:  0.06937859952449799
Epoch:  498  	Training Loss: 0.052133843302726746
Test Loss:  0.06973250955343246
Valid Loss:  0.06937845796346664
Epoch:  499  	Training Loss: 0.052133478224277496
Test Loss:  0.06973253190517426
Valid Loss:  0.0693783164024353
Epoch:  500  	Training Loss: 0.05213310569524765
Test Loss:  0.06973255425691605
Valid Loss:  0.06937818229198456
seed is  11
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:49,  6.23s/it]  1%|          | 3/500 [00:06<13:48,  1.67s/it]  1%|          | 5/500 [00:06<06:57,  1.18it/s]  1%|▏         | 7/500 [00:06<04:13,  1.95it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:19<13:07,  1.62s/it]  3%|▎         | 17/500 [00:19<09:07,  1.13s/it]  4%|▍         | 19/500 [00:19<06:25,  1.25it/s]  4%|▍         | 21/500 [00:26<12:10,  1.52s/it]  5%|▍         | 23/500 [00:26<08:35,  1.08s/it]  5%|▌         | 25/500 [00:26<06:06,  1.29it/s]  5%|▌         | 27/500 [00:26<04:24,  1.79it/s]  6%|▌         | 29/500 [00:26<03:12,  2.44it/s]  6%|▌         | 31/500 [00:32<09:39,  1.24s/it]  7%|▋         | 33/500 [00:33<06:53,  1.13it/s]  7%|▋         | 35/500 [00:33<04:57,  1.56it/s]  7%|▋         | 37/500 [00:33<03:36,  2.14it/s]  8%|▊         | 39/500 [00:33<02:39,  2.89it/s]  8%|▊         | 41/500 [00:39<09:11,  1.20s/it]  9%|▊         | 43/500 [00:39<06:33,  1.16it/s]  9%|▉         | 45/500 [00:40<04:43,  1.61it/s]  9%|▉         | 47/500 [00:40<03:26,  2.20it/s] 10%|▉         | 49/500 [00:40<02:34,  2.93it/s] 10%|█         | 51/500 [00:46<08:58,  1.20s/it] 11%|█         | 53/500 [00:46<06:24,  1.16it/s] 11%|█         | 55/500 [00:47<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:47<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:47<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:53<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:53<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:53<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:54<03:17,  2.19it/s]Epoch:  1  	Training Loss: 0.029232734814286232
Test Loss:  0.009351657703518867
Valid Loss:  0.015713084489107132
Epoch:  2  	Training Loss: 0.026222679764032364
Test Loss:  0.04767197370529175
Valid Loss:  0.04550958424806595
Epoch:  3  	Training Loss: 0.03590579330921173
Test Loss:  0.02578306943178177
Valid Loss:  0.02713969349861145
Epoch:  4  	Training Loss: 0.023940501734614372
Test Loss:  0.01515407208353281
Valid Loss:  0.01567012444138527
Epoch:  5  	Training Loss: 0.015919983386993408
Test Loss:  0.0052467091009020805
Valid Loss:  0.006533917970955372
Epoch:  6  	Training Loss: 0.00970657542347908
Test Loss:  0.0038132695481181145
Valid Loss:  0.004027478396892548
Epoch:  7  	Training Loss: 0.006372260861098766
Test Loss:  0.0033578146249055862
Valid Loss:  0.0033291555009782314
Epoch:  8  	Training Loss: 0.00525183929130435
Test Loss:  0.0035346373915672302
Valid Loss:  0.0029870900325477123
Epoch:  9  	Training Loss: 0.004723300691694021
Test Loss:  0.0021925517357885838
Valid Loss:  0.0030209985561668873
Epoch:  10  	Training Loss: 0.004592080134898424
Test Loss:  0.004561625421047211
Valid Loss:  0.003126027062535286
Epoch:  11  	Training Loss: 0.004805870819836855
Test Loss:  0.0021169944666326046
Valid Loss:  0.0038262074813246727
Epoch:  12  	Training Loss: 0.004969303496181965
Test Loss:  0.005741321947425604
Valid Loss:  0.003678437788039446
Epoch:  13  	Training Loss: 0.005401632748544216
Test Loss:  0.0021940739825367928
Valid Loss:  0.004149354062974453
Epoch:  14  	Training Loss: 0.005000097677111626
Test Loss:  0.005696076899766922
Valid Loss:  0.003592513967305422
Epoch:  15  	Training Loss: 0.00528569333255291
Test Loss:  0.0019211157923564315
Valid Loss:  0.0036922763101756573
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.0043914164416491985
Test Loss:  0.0018062506569549441
Valid Loss:  0.0019157553324475884
Epoch:  17  	Training Loss: 0.0027724336832761765
Test Loss:  0.001596291083842516
Valid Loss:  0.00192477076780051
Epoch:  18  	Training Loss: 0.002657222328707576
Test Loss:  0.001585175283253193
Valid Loss:  0.001889252569526434
Epoch:  19  	Training Loss: 0.0025946912355720997
Test Loss:  0.0015744370175525546
Valid Loss:  0.0018717700149863958
Epoch:  20  	Training Loss: 0.00254419376142323
Test Loss:  0.001566780381835997
Valid Loss:  0.0018605549121275544
Epoch:  21  	Training Loss: 0.0025010397657752037
Test Loss:  0.001565595273859799
Valid Loss:  0.001846118364483118
Epoch:  22  	Training Loss: 0.002461240626871586
Test Loss:  0.0015553474659100175
Valid Loss:  0.0018347585573792458
Epoch:  23  	Training Loss: 0.002424009144306183
Test Loss:  0.001543938647955656
Valid Loss:  0.001822957186959684
Epoch:  24  	Training Loss: 0.002388416789472103
Test Loss:  0.0015299454098567367
Valid Loss:  0.001812535454519093
Epoch:  25  	Training Loss: 0.002354154596105218
Test Loss:  0.0015153978019952774
Valid Loss:  0.0018022742588073015
Epoch:  26  	Training Loss: 0.0023211047518998384
Test Loss:  0.001508813351392746
Valid Loss:  0.0017843464156612754
Epoch:  27  	Training Loss: 0.00228937272913754
Test Loss:  0.0014849761500954628
Valid Loss:  0.0017790101701393723
Epoch:  28  	Training Loss: 0.002258719876408577
Test Loss:  0.0014815095346421003
Valid Loss:  0.0017561876447871327
Epoch:  29  	Training Loss: 0.0022286311723291874
Test Loss:  0.001464424654841423
Valid Loss:  0.0017430116422474384
Epoch:  30  	Training Loss: 0.0021997932344675064
Test Loss:  0.0014499416574835777
Valid Loss:  0.0017279572784900665
Epoch:  31  	Training Loss: 0.0021717040799558163
Test Loss:  0.0014329386176541448
Valid Loss:  0.0017146093305200338
Epoch:  32  	Training Loss: 0.0021442165598273277
Test Loss:  0.0014155925018712878
Valid Loss:  0.0017014816403388977
Epoch:  33  	Training Loss: 0.002117146272212267
Test Loss:  0.001398417865857482
Valid Loss:  0.0016882098279893398
Epoch:  34  	Training Loss: 0.00209064781665802
Test Loss:  0.001385132665745914
Valid Loss:  0.001672133570536971
Epoch:  35  	Training Loss: 0.002064978703856468
Test Loss:  0.0013722501462325454
Valid Loss:  0.0016557045746594667
Epoch:  36  	Training Loss: 0.002039935439825058
Test Loss:  0.0013504652306437492
Valid Loss:  0.0016467876266688108
Epoch:  37  	Training Loss: 0.002015527570620179
Test Loss:  0.0013461796334013343
Valid Loss:  0.001623922260478139
Epoch:  38  	Training Loss: 0.001991822849959135
Test Loss:  0.001318192109465599
Valid Loss:  0.0016195254866033792
Epoch:  39  	Training Loss: 0.001968408701941371
Test Loss:  0.0013173713814467192
Valid Loss:  0.0015955434646457434
Epoch:  40  	Training Loss: 0.0019460549810901284
Test Loss:  0.0012876746477559209
Valid Loss:  0.00159429048653692
Epoch:  41  	Training Loss: 0.001923989038914442
Test Loss:  0.0012912082020193338
Valid Loss:  0.0015680276555940509
Epoch:  42  	Training Loss: 0.0019026240333914757
Test Loss:  0.0012597211170941591
Valid Loss:  0.001568482955917716
Epoch:  43  	Training Loss: 0.0018814799841493368
Test Loss:  0.0012625306844711304
Valid Loss:  0.0015439146663993597
Epoch:  44  	Training Loss: 0.001860793330706656
Test Loss:  0.0012323413975536823
Valid Loss:  0.0015444804448634386
Epoch:  45  	Training Loss: 0.0018409054027870297
Test Loss:  0.0012353428173810244
Valid Loss:  0.0015204749070107937
Epoch:  46  	Training Loss: 0.0018206143286079168
Test Loss:  0.0012161260237917304
Valid Loss:  0.0015128999948501587
Epoch:  47  	Training Loss: 0.0018013768130913377
Test Loss:  0.0012068618088960648
Valid Loss:  0.0014988782349973917
Epoch:  48  	Training Loss: 0.0017825582763180137
Test Loss:  0.001194487325847149
Valid Loss:  0.0014873394975438714
Epoch:  49  	Training Loss: 0.0017641338054090738
Test Loss:  0.0011815075995400548
Valid Loss:  0.0014762600185349584
Epoch:  50  	Training Loss: 0.0017459895461797714
Test Loss:  0.0011722734197974205
Valid Loss:  0.0014628719072788954
Epoch:  51  	Training Loss: 0.0017282748594880104
Test Loss:  0.0011574665550142527
Valid Loss:  0.0014538411051034927
Epoch:  52  	Training Loss: 0.0017108866013586521
Test Loss:  0.001148315379396081
Valid Loss:  0.001441155094653368
Epoch:  53  	Training Loss: 0.0016938511980697513
Test Loss:  0.0011361809447407722
Valid Loss:  0.0014307299861684442
Epoch:  54  	Training Loss: 0.001677116728387773
Test Loss:  0.0011243459302932024
Valid Loss:  0.0014201677404344082
Epoch:  55  	Training Loss: 0.0016606864519417286
Test Loss:  0.001113387057557702
Valid Loss:  0.001410031458362937
Epoch:  56  	Training Loss: 0.0016446220688521862
Test Loss:  0.0011023349361494184
Valid Loss:  0.0014002473326399922
Epoch:  57  	Training Loss: 0.0016288402257487178
Test Loss:  0.0010916816536337137
Valid Loss:  0.001390625722706318
Epoch:  58  	Training Loss: 0.0016133091412484646
Test Loss:  0.0010810857638716698
Valid Loss:  0.0013811023673042655
Epoch:  59  	Training Loss: 0.0015979902818799019
Test Loss:  0.0010706300381571054
Valid Loss:  0.001371618127450347
Epoch:  60  	Training Loss: 0.0015828665345907211
Test Loss:  0.0010602818801999092
Valid Loss:  0.0013621584512293339
Epoch:  61  	Training Loss: 0.001567938830703497
Test Loss:  0.0010517495684325695
Valid Loss:  0.0013515091268345714
Epoch:  62  	Training Loss: 0.0015532408142462373
Test Loss:  0.0010418096790090203
Valid Loss:  0.0013419878669083118
Epoch:  63  	Training Loss: 0.001538688549771905
Test Loss:  0.0010331859812140465
Valid Loss:  0.0013316452968865633
Epoch:  64  	Training Loss: 0.0015243603847920895
Test Loss:  0.0010244122240692377
Valid Loss:  0.0013220272958278656
Epoch:  65  	Training Loss: 0.0015103358309715986
Test Loss:  0.0010153602343052626
Valid Loss:  0.0013128635473549366
Epoch:  66  	Training Loss: 0.0014965066220611334
Test Loss:  0.0010073375888168812
Valid Loss:  0.0013031032867729664
Epoch:  67  	Training Loss: 0.0014828824205324054
Test Loss:  0.0009979658061638474
Valid Loss:  0.0012946345377713442
Epoch:  68  	Training Loss: 0.0014694633428007364
Test Loss:  0.0009897277923300862
Valid Loss:  0.001285665319301188
Epoch:  69  	Training Loss: 0.001456226920709014
Test Loss:  0.0009821049170568585
 14%|█▍        | 69/500 [00:54<02:27,  2.92it/s] 14%|█▍        | 71/500 [01:00<08:23,  1.17s/it] 15%|█▍        | 73/500 [01:00<06:00,  1.19it/s] 15%|█▌        | 75/500 [01:00<04:19,  1.64it/s] 15%|█▌        | 77/500 [01:00<03:08,  2.24it/s] 16%|█▌        | 79/500 [01:00<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:07<08:07,  1.16s/it] 17%|█▋        | 83/500 [01:07<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:07<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:07<03:03,  2.26it/s] 18%|█▊        | 89/500 [01:07<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:13<08:00,  1.17s/it] 19%|█▊        | 93/500 [01:14<05:43,  1.19it/s] 19%|█▉        | 95/500 [01:14<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:14<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:14<02:12,  3.02it/s] 20%|██        | 101/500 [01:20<07:47,  1.17s/it] 21%|██        | 103/500 [01:20<05:33,  1.19it/s] 21%|██        | 105/500 [01:21<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:21<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:27<07:46,  1.20s/it] 23%|██▎       | 113/500 [01:27<05:34,  1.16it/s] 23%|██▎       | 115/500 [01:28<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:28<02:55,  2.18it/s] 24%|██▍       | 119/500 [01:28<02:09,  2.93it/s] 24%|██▍       | 121/500 [01:34<07:23,  1.17s/it] 25%|██▍       | 123/500 [01:34<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:34<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:34<02:46,  2.23it/s] 26%|██▌       | 129/500 [01:35<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:41<07:13,  1.17s/it] 27%|██▋       | 133/500 [01:41<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:41<03:43,  1.64it/s] 27%|██▋       | 137/500 [01:41<02:42,  2.23it/s]Valid Loss:  0.0012764534913003445
Epoch:  70  	Training Loss: 0.0014431867748498917
Test Loss:  0.0009723849361762404
Valid Loss:  0.00126916344743222
Epoch:  71  	Training Loss: 0.0014303924981504679
Test Loss:  0.0009654175373725593
Valid Loss:  0.0012601783964782953
Epoch:  72  	Training Loss: 0.0014177535194903612
Test Loss:  0.0009572913404554129
Valid Loss:  0.0012520403834059834
Epoch:  73  	Training Loss: 0.0014052889309823513
Test Loss:  0.0009492744575254619
Valid Loss:  0.001244119368493557
Epoch:  74  	Training Loss: 0.0013930086279287934
Test Loss:  0.000941240752581507
Valid Loss:  0.0012363363057374954
Epoch:  75  	Training Loss: 0.0013808810617774725
Test Loss:  0.0009333035559393466
Valid Loss:  0.0012286624405533075
Epoch:  76  	Training Loss: 0.001368903904221952
Test Loss:  0.0009254758479073644
Valid Loss:  0.001221049576997757
Epoch:  77  	Training Loss: 0.0013571088202297688
Test Loss:  0.0009181465720757842
Valid Loss:  0.0012135689612478018
Epoch:  78  	Training Loss: 0.0013455075677484274
Test Loss:  0.0009107899386435747
Valid Loss:  0.0012062578462064266
Epoch:  79  	Training Loss: 0.0013340592849999666
Test Loss:  0.000905060616787523
Valid Loss:  0.0011980572016909719
Epoch:  80  	Training Loss: 0.001322764903306961
Test Loss:  0.0008969184709712863
Valid Loss:  0.0011917168740183115
Epoch:  81  	Training Loss: 0.0013116593472659588
Test Loss:  0.0008923307177610695
Valid Loss:  0.0011831657029688358
Epoch:  82  	Training Loss: 0.0013006747467443347
Test Loss:  0.0008858722867444158
Valid Loss:  0.0011760509805753827
Epoch:  83  	Training Loss: 0.0012898517306894064
Test Loss:  0.0008798284688964486
Valid Loss:  0.0011690789833664894
Epoch:  84  	Training Loss: 0.001279168762266636
Test Loss:  0.0008735505398362875
Valid Loss:  0.0011623825412243605
Epoch:  85  	Training Loss: 0.0012686187401413918
Test Loss:  0.0008673107950016856
Valid Loss:  0.0011557774851098657
Epoch:  86  	Training Loss: 0.0012582007329910994
Test Loss:  0.0008612709352746606
Valid Loss:  0.0011493016500025988
Epoch:  87  	Training Loss: 0.0012479473371058702
Test Loss:  0.0008553139050491154
Valid Loss:  0.0011429504957050085
Epoch:  88  	Training Loss: 0.0012378275860100985
Test Loss:  0.0008493970963172615
Valid Loss:  0.001136672217398882
Epoch:  89  	Training Loss: 0.0012278289068490267
Test Loss:  0.0008435886120423675
Valid Loss:  0.001130521995946765
Epoch:  90  	Training Loss: 0.0012179617770016193
Test Loss:  0.000837827508803457
Valid Loss:  0.0011245176428928971
Epoch:  91  	Training Loss: 0.0012082126922905445
Test Loss:  0.0008321372442878783
Valid Loss:  0.001118561252951622
Epoch:  92  	Training Loss: 0.0011985793244093657
Test Loss:  0.0008266284130513668
Valid Loss:  0.0011126414174214005
Epoch:  93  	Training Loss: 0.0011890337336808443
Test Loss:  0.0008213797700591385
Valid Loss:  0.0011067930608987808
Epoch:  94  	Training Loss: 0.0011796077014878392
Test Loss:  0.0008161708246916533
Valid Loss:  0.0011010554153472185
Epoch:  95  	Training Loss: 0.001170295407064259
Test Loss:  0.0008111489005386829
Valid Loss:  0.0010953745804727077
Epoch:  96  	Training Loss: 0.0011610995279625058
Test Loss:  0.0008062198758125305
Valid Loss:  0.0010897545143961906
Epoch:  97  	Training Loss: 0.001152010983787477
Test Loss:  0.0008014777558855712
Valid Loss:  0.001084180548787117
Epoch:  98  	Training Loss: 0.0011430267477408051
Test Loss:  0.000796895707026124
Valid Loss:  0.00107871787622571
Epoch:  99  	Training Loss: 0.0011341468198224902
Test Loss:  0.0007923811790533364
Valid Loss:  0.001073359395377338
Epoch:  100  	Training Loss: 0.0011253694538027048
Test Loss:  0.0007882725913077593
Valid Loss:  0.0010680444538593292
Epoch:  101  	Training Loss: 0.001116711413487792
Test Loss:  0.0007855481235310435
Valid Loss:  0.0010620476678013802
Epoch:  102  	Training Loss: 0.0011081565171480179
Test Loss:  0.0007828007219359279
Valid Loss:  0.0010562462266534567
Epoch:  103  	Training Loss: 0.001099729212000966
Test Loss:  0.0007792135002091527
Valid Loss:  0.001051104860380292
Epoch:  104  	Training Loss: 0.0010914178565144539
Test Loss:  0.0007759773870930076
Valid Loss:  0.0010460240300744772
Epoch:  105  	Training Loss: 0.0010833051055669785
Test Loss:  0.0007729167118668556
Valid Loss:  0.0010412693955004215
Epoch:  106  	Training Loss: 0.0010753616224974394
Test Loss:  0.0007695624371990561
Valid Loss:  0.0010367444483563304
Epoch:  107  	Training Loss: 0.001067510573193431
Test Loss:  0.0007662461721338332
Valid Loss:  0.0010322179878130555
Epoch:  108  	Training Loss: 0.0010597719810903072
Test Loss:  0.0007651167106814682
Valid Loss:  0.001026627724058926
Epoch:  109  	Training Loss: 0.0010521512012928724
Test Loss:  0.0007605376886203885
Valid Loss:  0.0010231155902147293
Epoch:  110  	Training Loss: 0.0010447106324136257
Test Loss:  0.0007595150382257998
Valid Loss:  0.0010178808588534594
Epoch:  111  	Training Loss: 0.0010373906698077917
Test Loss:  0.0007566838758066297
Valid Loss:  0.0010137059725821018
Epoch:  112  	Training Loss: 0.0010301817674189806
Test Loss:  0.0007536956109106541
Valid Loss:  0.001009686733596027
Epoch:  113  	Training Loss: 0.0010231547057628632
Test Loss:  0.0007508165435865521
Valid Loss:  0.0010057348990812898
Epoch:  114  	Training Loss: 0.0010162460384890437
Test Loss:  0.0007479313062503934
Valid Loss:  0.0010018732864409685
Epoch:  115  	Training Loss: 0.0010094346944242716
Test Loss:  0.0007449185941368341
Valid Loss:  0.0009980627801269293
Epoch:  116  	Training Loss: 0.0010027126409113407
Test Loss:  0.0007420658366754651
Valid Loss:  0.0009942746255546808
Epoch:  117  	Training Loss: 0.0009960858151316643
Test Loss:  0.0007390801911242306
Valid Loss:  0.0009905357146635652
Epoch:  118  	Training Loss: 0.0009895372204482555
Test Loss:  0.0007361707976087928
Valid Loss:  0.0009868030901998281
Epoch:  119  	Training Loss: 0.000983072561211884
Test Loss:  0.0007344440091401339
Valid Loss:  0.0009825400775298476
Epoch:  120  	Training Loss: 0.0009767002193257213
Test Loss:  0.0007314069662243128
Valid Loss:  0.0009789394680410624
Epoch:  121  	Training Loss: 0.0009704179828986526
Test Loss:  0.0007298917043954134
Valid Loss:  0.0009747618460096419
Epoch:  122  	Training Loss: 0.0009642289951443672
Test Loss:  0.000727348611690104
Valid Loss:  0.0009711042512208223
Epoch:  123  	Training Loss: 0.0009580953628756106
Test Loss:  0.0007249240879900753
Valid Loss:  0.0009674255270510912
Epoch:  124  	Training Loss: 0.0009520376333966851
Test Loss:  0.0007223344291560352
Valid Loss:  0.0009638363844715059
Epoch:  125  	Training Loss: 0.0009460447472520173
Test Loss:  0.0007196811493486166
Valid Loss:  0.000960283912718296
Epoch:  126  	Training Loss: 0.0009401142015121877
Test Loss:  0.0007170673925429583
Valid Loss:  0.0009567394154146314
Epoch:  127  	Training Loss: 0.0009342701523564756
Test Loss:  0.0007158430526033044
Valid Loss:  0.0009527481161057949
Epoch:  128  	Training Loss: 0.000928509165532887
Test Loss:  0.0007135134655982256
Valid Loss:  0.0009492981480434537
Epoch:  129  	Training Loss: 0.000922839215490967
Test Loss:  0.000710994063410908
Valid Loss:  0.000945950741879642
Epoch:  130  	Training Loss: 0.0009172392310574651
Test Loss:  0.0007098325877450407
Valid Loss:  0.0009421347640454769
Epoch:  131  	Training Loss: 0.0009117075242102146
Test Loss:  0.0007077136542648077
Valid Loss:  0.0009387863101437688
Epoch:  132  	Training Loss: 0.0009062447934411466
Test Loss:  0.000705504440702498
Valid Loss:  0.0009355272632092237
Epoch:  133  	Training Loss: 0.0009008451597765088
Test Loss:  0.0007032194407656789
Valid Loss:  0.0009323061094619334
Epoch:  134  	Training Loss: 0.0008955127559602261
Test Loss:  0.000701064127497375
Valid Loss:  0.0009291224996559322
Epoch:  135  	Training Loss: 0.0008902605040930212
Test Loss:  0.0006988426903262734
Valid Loss:  0.000925992731936276
Epoch:  136  	Training Loss: 0.0008850640151649714
Test Loss:  0.0006966182263568044
Valid Loss:  0.0009228769922628999
Epoch:  137  	Training Loss: 0.000879945233464241
Test Loss:  0.0006946304347366095
Valid Loss:  0.0009198295883834362
Epoch:  138  	Training Loss: 0.0008749256958253682
Test Loss:   28%|██▊       | 139/500 [01:41<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:48<07:01,  1.17s/it] 29%|██▊       | 143/500 [01:48<05:01,  1.19it/s] 29%|██▉       | 145/500 [01:48<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:48<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:48<01:56,  3.01it/s] 30%|███       | 151/500 [01:55<06:50,  1.18s/it] 31%|███       | 153/500 [01:55<04:53,  1.18it/s] 31%|███       | 155/500 [01:55<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:55<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:55<01:54,  2.98it/s] 32%|███▏      | 161/500 [02:01<06:38,  1.18s/it] 33%|███▎      | 163/500 [02:02<04:44,  1.18it/s] 33%|███▎      | 165/500 [02:02<03:24,  1.64it/s] 33%|███▎      | 167/500 [02:02<02:28,  2.24it/s] 34%|███▍      | 169/500 [02:02<01:50,  3.01it/s] 34%|███▍      | 171/500 [02:08<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:08<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:08<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:09<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:09<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:15<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:15<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:15<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:15<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:16<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:22<06:04,  1.18s/it] 39%|███▊      | 193/500 [02:22<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:22<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:22<02:16,  2.23it/s] 40%|███▉      | 199/500 [02:22<01:40,  3.00it/s] 40%|████      | 201/500 [02:29<05:49,  1.17s/it] 41%|████      | 203/500 [02:29<04:09,  1.19it/s] 41%|████      | 205/500 [02:29<02:58,  1.65it/s]0.0006936124991625547
Valid Loss:  0.0009164579678326845
Epoch:  139  	Training Loss: 0.0008699727477505803
Test Loss:  0.0006925723282620311
Valid Loss:  0.0009132223203778267
Epoch:  140  	Training Loss: 0.0008651041425764561
Test Loss:  0.0006906163762323558
Valid Loss:  0.0009103587944991887
Epoch:  141  	Training Loss: 0.0008602928137406707
Test Loss:  0.000688779866322875
Valid Loss:  0.0009074524277821183
Epoch:  142  	Training Loss: 0.0008555487729609013
Test Loss:  0.0006869311328046024
Valid Loss:  0.0009046279592439532
Epoch:  143  	Training Loss: 0.0008508709724992514
Test Loss:  0.0006848796037957072
Valid Loss:  0.0009018676355481148
Epoch:  144  	Training Loss: 0.0008462429977953434
Test Loss:  0.0006829515332356095
Valid Loss:  0.0008991387439891696
Epoch:  145  	Training Loss: 0.0008416878990828991
Test Loss:  0.0006808822508901358
Valid Loss:  0.0008964427979663014
Epoch:  146  	Training Loss: 0.0008371767471544445
Test Loss:  0.0006787950987927616
Valid Loss:  0.0008937326492741704
Epoch:  147  	Training Loss: 0.0008327062241733074
Test Loss:  0.0006767153972759843
Valid Loss:  0.0008910070173442364
Epoch:  148  	Training Loss: 0.0008282770868390799
Test Loss:  0.0006746381404809654
Valid Loss:  0.0008882697438821197
Epoch:  149  	Training Loss: 0.0008238927694037557
Test Loss:  0.000672628462780267
Valid Loss:  0.000885537825524807
Epoch:  150  	Training Loss: 0.0008195668924599886
Test Loss:  0.0006706791464239359
Valid Loss:  0.0008828500285744667
Epoch:  151  	Training Loss: 0.0008153060334734619
Test Loss:  0.0006687280838377774
Valid Loss:  0.0008802206721156836
Epoch:  152  	Training Loss: 0.0008110948838293552
Test Loss:  0.0006666518747806549
Valid Loss:  0.0008776088361628354
Epoch:  153  	Training Loss: 0.000806903000921011
Test Loss:  0.0006645577377639711
Valid Loss:  0.0008749827975407243
Epoch:  154  	Training Loss: 0.0008027468575164676
Test Loss:  0.0006624682573601604
Valid Loss:  0.000872342730872333
Epoch:  155  	Training Loss: 0.0007986323907971382
Test Loss:  0.0006605526432394981
Valid Loss:  0.0008697318844497204
Epoch:  156  	Training Loss: 0.000794582418166101
Test Loss:  0.0006585359806194901
Valid Loss:  0.0008671751711517572
Epoch:  157  	Training Loss: 0.000790584716014564
Test Loss:  0.0006577334715984762
Valid Loss:  0.0008643202017992735
Epoch:  158  	Training Loss: 0.0007866567466408014
Test Loss:  0.0006567661184817553
Valid Loss:  0.0008616028353571892
Epoch:  159  	Training Loss: 0.0007828015368431807
Test Loss:  0.0006549567333422601
Valid Loss:  0.000859173946082592
Epoch:  160  	Training Loss: 0.0007789853261783719
Test Loss:  0.0006530893733724952
Valid Loss:  0.0008567828917875886
Epoch:  161  	Training Loss: 0.0007752149249427021
Test Loss:  0.0006513847038149834
Valid Loss:  0.0008543338626623154
Epoch:  162  	Training Loss: 0.0007714898092672229
Test Loss:  0.0006495500565506518
Valid Loss:  0.0008519552648067474
Epoch:  163  	Training Loss: 0.000767809571698308
Test Loss:  0.0006476377602666616
Valid Loss:  0.000849586445838213
Epoch:  164  	Training Loss: 0.0007641616393812001
Test Loss:  0.000645879190415144
Valid Loss:  0.0008472183253616095
Epoch:  165  	Training Loss: 0.0007606061408296227
Test Loss:  0.0006480853771790862
Valid Loss:  0.0008438995573669672
Epoch:  166  	Training Loss: 0.0007571229944005609
Test Loss:  0.0006429270142689347
Valid Loss:  0.0008426521671935916
Epoch:  167  	Training Loss: 0.0007536421762779355
Test Loss:  0.0006450905930250883
Valid Loss:  0.0008393829921260476
Epoch:  168  	Training Loss: 0.0007501887157559395
Test Loss:  0.0006418899865821004
Valid Loss:  0.0008376989280804992
Epoch:  169  	Training Loss: 0.0007468195981346071
Test Loss:  0.0006422629812732339
Valid Loss:  0.0008350752177648246
Epoch:  170  	Training Loss: 0.0007434850558638573
Test Loss:  0.0006397971883416176
Valid Loss:  0.0008332523284479976
Epoch:  171  	Training Loss: 0.0007401927141472697
Test Loss:  0.0006392381619662046
Valid Loss:  0.0008309424156323075
Epoch:  172  	Training Loss: 0.0007369340746663511
Test Loss:  0.0006378332618623972
Valid Loss:  0.0008288975222967565
Epoch:  173  	Training Loss: 0.0007337099523283541
Test Loss:  0.000637179531622678
Valid Loss:  0.0008267099037766457
Epoch:  174  	Training Loss: 0.0007305274484679103
Test Loss:  0.0006372610805556178
Valid Loss:  0.0008244484779424965
Epoch:  175  	Training Loss: 0.0007273929077200592
Test Loss:  0.0006348565220832825
Valid Loss:  0.0008227911312133074
Epoch:  176  	Training Loss: 0.0007242560386657715
Test Loss:  0.0006333917262963951
Valid Loss:  0.0008208685321733356
Epoch:  177  	Training Loss: 0.0007211827905848622
Test Loss:  0.0006330331088975072
Valid Loss:  0.0008187321363948286
Epoch:  178  	Training Loss: 0.0007181415567174554
Test Loss:  0.0006317164516076446
Valid Loss:  0.000816869200207293
Epoch:  179  	Training Loss: 0.0007151082390919328
Test Loss:  0.0006305292481556535
Valid Loss:  0.0008149818750098348
Epoch:  180  	Training Loss: 0.0007121332455426455
Test Loss:  0.0006290918681770563
Valid Loss:  0.0008131524082273245
Epoch:  181  	Training Loss: 0.0007091606967151165
Test Loss:  0.0006298804073594511
Valid Loss:  0.0008109228801913559
Epoch:  182  	Training Loss: 0.0007062478107400239
Test Loss:  0.0006257909117266536
Valid Loss:  0.0008097285754047334
Epoch:  183  	Training Loss: 0.0007033418514765799
Test Loss:  0.0006272564060054719
Valid Loss:  0.0008073186036199331
Epoch:  184  	Training Loss: 0.0007004396175034344
Test Loss:  0.0006240513757802546
Valid Loss:  0.0008059554966166615
Epoch:  185  	Training Loss: 0.0006975997821427882
Test Loss:  0.000623749103397131
Valid Loss:  0.0008039597887545824
Epoch:  186  	Training Loss: 0.0006947775837033987
Test Loss:  0.0006238379282876849
Valid Loss:  0.00080209004227072
Epoch:  187  	Training Loss: 0.000692022789735347
Test Loss:  0.000621727725956589
Valid Loss:  0.0008006833377294242
Epoch:  188  	Training Loss: 0.0006893015233799815
Test Loss:  0.0006214490858837962
Valid Loss:  0.0007989302393980324
Epoch:  189  	Training Loss: 0.0006866203621029854
Test Loss:  0.000620344071649015
Valid Loss:  0.0007974169566296041
Epoch:  190  	Training Loss: 0.0006839818088337779
Test Loss:  0.0006191733991727233
Valid Loss:  0.0007959262584336102
Epoch:  191  	Training Loss: 0.0006813729414716363
Test Loss:  0.0006179198389872909
Valid Loss:  0.0007944343378767371
Epoch:  192  	Training Loss: 0.0006787989987060428
Test Loss:  0.0006167702958919108
Valid Loss:  0.0007929591229185462
Epoch:  193  	Training Loss: 0.000676251424010843
Test Loss:  0.0006155023584142327
Valid Loss:  0.0007914936868473887
Epoch:  194  	Training Loss: 0.0006737338262610137
Test Loss:  0.0006142942584119737
Valid Loss:  0.0007900363998487592
Epoch:  195  	Training Loss: 0.0006712491740472615
Test Loss:  0.0006130244582891464
Valid Loss:  0.0007885890081524849
Epoch:  196  	Training Loss: 0.0006687909481115639
Test Loss:  0.0006116973236203194
Valid Loss:  0.0007871395209804177
Epoch:  197  	Training Loss: 0.0006663550157099962
Test Loss:  0.0006114892312325537
Valid Loss:  0.0007855291478335857
Epoch:  198  	Training Loss: 0.0006639624480158091
Test Loss:  0.0006100937607698143
Valid Loss:  0.000784163479693234
Epoch:  199  	Training Loss: 0.0006615801248699427
Test Loss:  0.000610091257840395
Valid Loss:  0.0007825712091289461
Epoch:  200  	Training Loss: 0.000659233657643199
Test Loss:  0.0006081234896555543
Valid Loss:  0.0007813843549229205
Epoch:  201  	Training Loss: 0.0006569225224666297
Test Loss:  0.0006078188307583332
Valid Loss:  0.0007798781734891236
Epoch:  202  	Training Loss: 0.0006546289660036564
Test Loss:  0.0006067361100576818
Valid Loss:  0.0007785370107740164
Epoch:  203  	Training Loss: 0.0006523521733470261
Test Loss:  0.0006055894773453474
Valid Loss:  0.0007772106910124421
Epoch:  204  	Training Loss: 0.0006500994204543531
Test Loss:  0.0006043882458470762
Valid Loss:  0.0007758743595331907
Epoch:  205  	Training Loss: 0.0006478651775978506
Test Loss:  0.0006031936500221491
Valid Loss:  0.0007745266775600612
Epoch:  206  	Training Loss: 0.0006456519477069378
Test Loss:  0.0006020562723278999
Valid Loss:   41%|████▏     | 207/500 [02:29<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:29<01:36,  3.03it/s] 42%|████▏     | 211/500 [02:36<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:36<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:36<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:36<02:06,  2.23it/s] 44%|████▍     | 219/500 [02:36<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:42<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:42<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:43<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:43<02:01,  2.24it/s] 46%|████▌     | 229/500 [02:43<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:49<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:49<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:49<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:50<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:50<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:56<05:02,  1.17s/it] 49%|████▊     | 243/500 [02:56<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:56<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:56<01:52,  2.25it/s] 50%|████▉     | 249/500 [02:56<01:23,  3.02it/s] 50%|█████     | 251/500 [03:03<04:53,  1.18s/it] 51%|█████     | 253/500 [03:03<03:29,  1.18it/s] 51%|█████     | 255/500 [03:03<02:29,  1.63it/s] 51%|█████▏    | 257/500 [03:03<01:48,  2.23it/s] 52%|█████▏    | 259/500 [03:03<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:10<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:10<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:10<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:10<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:10<01:16,  3.00it/s] 54%|█████▍    | 271/500 [03:16<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:16<03:10,  1.19it/s]0.0007731826044619083
Epoch:  207  	Training Loss: 0.000643467647023499
Test Loss:  0.0006009119097143412
Valid Loss:  0.000771857681684196
Epoch:  208  	Training Loss: 0.000641310412902385
Test Loss:  0.0005996798863634467
Valid Loss:  0.0007705239113420248
Epoch:  209  	Training Loss: 0.0006391678471118212
Test Loss:  0.0005984369199723005
Valid Loss:  0.0007691725622862577
Epoch:  210  	Training Loss: 0.000637044373434037
Test Loss:  0.0005972267827019095
Valid Loss:  0.0007678100955672562
Epoch:  211  	Training Loss: 0.0006349405739456415
Test Loss:  0.0005960147827863693
Valid Loss:  0.0007664483273401856
Epoch:  212  	Training Loss: 0.0006328551098704338
Test Loss:  0.0005947601748630404
Valid Loss:  0.0007650734041817486
Epoch:  213  	Training Loss: 0.0006307829753495753
Test Loss:  0.0005935030640102923
Valid Loss:  0.0007636840455234051
Epoch:  214  	Training Loss: 0.0006287246942520142
Test Loss:  0.0005922459531575441
Valid Loss:  0.0007622778066433966
Epoch:  215  	Training Loss: 0.0006266800919547677
Test Loss:  0.0005909904139116406
Valid Loss:  0.0007608591113239527
Epoch:  216  	Training Loss: 0.0006246641278266907
Test Loss:  0.0005915469955652952
Valid Loss:  0.0007592247566208243
Epoch:  217  	Training Loss: 0.0006226634723134339
Test Loss:  0.0005896248621866107
Valid Loss:  0.0007580224773846567
Epoch:  218  	Training Loss: 0.0006206886027939618
Test Loss:  0.0005893640336580575
Valid Loss:  0.0007565557025372982
Epoch:  219  	Training Loss: 0.0006187304388731718
Test Loss:  0.0005886347498744726
Valid Loss:  0.0007552421884611249
Epoch:  220  	Training Loss: 0.0006168020772747695
Test Loss:  0.0005875740898773074
Valid Loss:  0.0007539852522313595
Epoch:  221  	Training Loss: 0.0006148883840069175
Test Loss:  0.0005865197745151818
Valid Loss:  0.0007527213310822845
Epoch:  222  	Training Loss: 0.0006129899993538857
Test Loss:  0.0005854659248143435
Valid Loss:  0.0007514661410823464
Epoch:  223  	Training Loss: 0.0006111115217208862
Test Loss:  0.0005843563703820109
Valid Loss:  0.0007502083317376673
Epoch:  224  	Training Loss: 0.0006092463154345751
Test Loss:  0.0005832421011291444
Valid Loss:  0.0007489407435059547
Epoch:  225  	Training Loss: 0.0006073943804949522
Test Loss:  0.0005821367958560586
Valid Loss:  0.0007476668106392026
Epoch:  226  	Training Loss: 0.0006055558915250003
Test Loss:  0.0005810210714116693
Valid Loss:  0.0007463844958692789
Epoch:  227  	Training Loss: 0.0006037293933331966
Test Loss:  0.0005799036007374525
Valid Loss:  0.0007450951961800456
Epoch:  228  	Training Loss: 0.0006019145948812366
Test Loss:  0.0005787861300632358
Valid Loss:  0.0007437983294948936
Epoch:  229  	Training Loss: 0.0006001121364533901
Test Loss:  0.0005776816979050636
Valid Loss:  0.0007424984942190349
Epoch:  230  	Training Loss: 0.0005983226001262665
Test Loss:  0.0005765763344243169
Valid Loss:  0.0007411963888444006
Epoch:  231  	Training Loss: 0.0005965451709926128
Test Loss:  0.0005754599114879966
Valid Loss:  0.0007398909656330943
Epoch:  232  	Training Loss: 0.0005947786848992109
Test Loss:  0.0005743433721363544
Valid Loss:  0.000738578150048852
Epoch:  233  	Training Loss: 0.0005930211627855897
Test Loss:  0.0005732247955165803
Valid Loss:  0.0007372606778517365
Epoch:  234  	Training Loss: 0.0005912752239964902
Test Loss:  0.0005721200723201036
Valid Loss:  0.0007359427399933338
Epoch:  235  	Training Loss: 0.000589540577493608
Test Loss:  0.000571004580706358
Valid Loss:  0.0007346206111833453
Epoch:  236  	Training Loss: 0.0005878164665773511
Test Loss:  0.0005698886816389859
Valid Loss:  0.000733297027181834
Epoch:  237  	Training Loss: 0.0005861028330400586
Test Loss:  0.0005687735974788666
Valid Loss:  0.0007319697760976851
Epoch:  238  	Training Loss: 0.0005843995604664087
Test Loss:  0.0005676596192643046
Valid Loss:  0.0007306398474611342
Epoch:  239  	Training Loss: 0.0005827075801789761
Test Loss:  0.0005665947683155537
Valid Loss:  0.0007293228409253061
Epoch:  240  	Training Loss: 0.0005810304428450763
Test Loss:  0.0005654757842421532
Valid Loss:  0.0007280096760950983
Epoch:  241  	Training Loss: 0.0005793627351522446
Test Loss:  0.0005643515614792705
Valid Loss:  0.0007266924367286265
Epoch:  242  	Training Loss: 0.0005777043988928199
Test Loss:  0.0005632285610772669
Valid Loss:  0.0007253738585859537
Epoch:  243  	Training Loss: 0.0005760567728430033
Test Loss:  0.0005621510790660977
Valid Loss:  0.0007240648264996707
Epoch:  244  	Training Loss: 0.0005744232330471277
Test Loss:  0.0005610468797385693
Valid Loss:  0.0007227659225463867
Epoch:  245  	Training Loss: 0.0005728005198761821
Test Loss:  0.0005599107244051993
Valid Loss:  0.0007214641664177179
Epoch:  246  	Training Loss: 0.0005711859557777643
Test Loss:  0.0005587724735960364
Valid Loss:  0.0007201538537628949
Epoch:  247  	Training Loss: 0.0005695803556591272
Test Loss:  0.0005576671101152897
Valid Loss:  0.0007188480813056231
Epoch:  248  	Training Loss: 0.0005679863970726728
Test Loss:  0.0005565270548686385
Valid Loss:  0.0007175394566729665
Epoch:  249  	Training Loss: 0.0005664026830345392
Test Loss:  0.0005554249510169029
Valid Loss:  0.000716237467713654
Epoch:  250  	Training Loss: 0.0005648299120366573
Test Loss:  0.0005543195875361562
Valid Loss:  0.0007149481098167598
Epoch:  251  	Training Loss: 0.000563267502002418
Test Loss:  0.0005531618371605873
Valid Loss:  0.0007136547937989235
Epoch:  252  	Training Loss: 0.0005617130664177239
Test Loss:  0.0005519952392205596
Valid Loss:  0.0007123483810573816
Epoch:  253  	Training Loss: 0.0005601615994237363
Test Loss:  0.0005508306203410029
Valid Loss:  0.0007110306760296226
Epoch:  254  	Training Loss: 0.0005586185725405812
Test Loss:  0.0005496907397173345
Valid Loss:  0.0007097120396792889
Epoch:  255  	Training Loss: 0.0005570841021835804
Test Loss:  0.0005485491710714996
Valid Loss:  0.0007083962555043399
Epoch:  256  	Training Loss: 0.0005555596435442567
Test Loss:  0.0005474230274558067
Valid Loss:  0.000707085826434195
Epoch:  257  	Training Loss: 0.0005540447309613228
Test Loss:  0.0005462511908262968
Valid Loss:  0.0007057756884023547
Epoch:  258  	Training Loss: 0.000552535813767463
Test Loss:  0.0005450756289064884
Valid Loss:  0.0007044541416689754
Epoch:  259  	Training Loss: 0.0005510345799848437
Test Loss:  0.0005439025117084384
Valid Loss:  0.0007031245622783899
Epoch:  260  	Training Loss: 0.0005495396908372641
Test Loss:  0.0005427306750789285
Valid Loss:  0.0007017889292910695
Epoch:  261  	Training Loss: 0.0005480519030243158
Test Loss:  0.0005415825289674103
Valid Loss:  0.000700452656019479
Epoch:  262  	Training Loss: 0.0005465720314532518
Test Loss:  0.0005404122639447451
Valid Loss:  0.0006991123082116246
Epoch:  263  	Training Loss: 0.0005450957687571645
Test Loss:  0.0005392422899603844
Valid Loss:  0.0006977684097364545
Epoch:  264  	Training Loss: 0.0005436257924884558
Test Loss:  0.0005380752845667303
Valid Loss:  0.0006964190397411585
Epoch:  265  	Training Loss: 0.0005421620444394648
Test Loss:  0.0005369107238948345
Valid Loss:  0.0006950662937015295
Epoch:  266  	Training Loss: 0.0005407054559327662
Test Loss:  0.0005357488407753408
Valid Loss:  0.0006937115103937685
Epoch:  267  	Training Loss: 0.0005392547463998199
Test Loss:  0.0005345901008695364
Valid Loss:  0.0006923532346263528
Epoch:  268  	Training Loss: 0.0005378103232942522
Test Loss:  0.0005334354937076569
Valid Loss:  0.0006909945514053106
Epoch:  269  	Training Loss: 0.0005363717791624367
Test Loss:  0.0005322828656062484
Valid Loss:  0.0006896350532770157
Epoch:  270  	Training Loss: 0.00053494016174227
Test Loss:  0.0005311341374181211
Valid Loss:  0.0006882749730721116
Epoch:  271  	Training Loss: 0.0005335144815035164
Test Loss:  0.000529987271875143
Valid Loss:  0.0006869139615446329
Epoch:  272  	Training Loss: 0.0005320952041074634
Test Loss:  0.0005288439569994807
Valid Loss:  0.000685556442476809
Epoch:  273  	Training Loss: 0.0005306826788000762
Test Loss:  0.0005277034360915422
Valid Loss:  0.0006841972935944796
Epoch:  274  	Training Loss: 0.0005292765563353896
Test Loss:  0.0005265656509436667
Valid Loss:  0.0006828407640568912
 55%|█████▌    | 275/500 [03:17<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:17<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:17<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:23<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:23<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:23<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:24<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:24<01:11,  2.95it/s] 58%|█████▊    | 291/500 [03:30<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:30<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:30<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:30<01:31,  2.23it/s] 60%|█████▉    | 299/500 [03:31<01:06,  3.00it/s] 60%|██████    | 301/500 [03:37<03:53,  1.17s/it] 61%|██████    | 303/500 [03:37<02:45,  1.19it/s] 61%|██████    | 305/500 [03:37<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:37<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:37<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:44<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:44<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:44<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:44<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:44<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:51<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:51<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:51<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:51<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:51<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:57<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:58<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:58<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:58<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:58<00:54,  2.98it/s] 68%|██████▊   | 341/500 [04:04<03:07,  1.18s/it]Epoch:  275  	Training Loss: 0.0005278758471831679
Test Loss:  0.0005254311836324632
Valid Loss:  0.0006814845837652683
Epoch:  276  	Training Loss: 0.0005264821229502559
Test Loss:  0.0005243284394964576
Valid Loss:  0.0006801397539675236
Epoch:  277  	Training Loss: 0.000525095674674958
Test Loss:  0.0005231959512457252
Valid Loss:  0.0006788003956899047
Epoch:  278  	Training Loss: 0.0005237145815044641
Test Loss:  0.000522061251103878
Valid Loss:  0.0006774601642973721
Epoch:  279  	Training Loss: 0.0005223393673077226
Test Loss:  0.0005209286464378238
Valid Loss:  0.0006761187687516212
Epoch:  280  	Training Loss: 0.0005209703813306987
Test Loss:  0.0005198008147999644
Valid Loss:  0.0006747791776433587
Epoch:  281  	Training Loss: 0.0005196066340431571
Test Loss:  0.0005186737980693579
Valid Loss:  0.0006734378985129297
Epoch:  282  	Training Loss: 0.000518248591106385
Test Loss:  0.0005175504484213889
Valid Loss:  0.000672099064104259
Epoch:  283  	Training Loss: 0.0005168986972421408
Test Loss:  0.0005164447356946766
Valid Loss:  0.0006707655848003924
Epoch:  284  	Training Loss: 0.0005155549733899534
Test Loss:  0.0005153272650204599
Valid Loss:  0.0006694341427646577
Epoch:  285  	Training Loss: 0.00051421660464257
Test Loss:  0.0005142106674611568
Valid Loss:  0.0006681035738438368
Epoch:  286  	Training Loss: 0.000512884056661278
Test Loss:  0.0005130970384925604
Valid Loss:  0.0006667741108685732
Epoch:  287  	Training Loss: 0.0005115567473694682
Test Loss:  0.0005119857960380614
Valid Loss:  0.0006654455792158842
Epoch:  288  	Training Loss: 0.0005102349678054452
Test Loss:  0.00051087886095047
Valid Loss:  0.0006641192594543099
Epoch:  289  	Training Loss: 0.0005089184269309044
Test Loss:  0.000509774312376976
Valid Loss:  0.0006627951515838504
Epoch:  290  	Training Loss: 0.0005076072411611676
Test Loss:  0.0005086727906018496
Valid Loss:  0.0006614720914512873
Epoch:  291  	Training Loss: 0.0005063018179498613
Test Loss:  0.0005075749941170216
Valid Loss:  0.0006601522909477353
Epoch:  292  	Training Loss: 0.0005050015752203763
Test Loss:  0.0005064808065071702
Valid Loss:  0.0006588352844119072
Epoch:  293  	Training Loss: 0.0005037056980654597
Test Loss:  0.0005053879576735198
Valid Loss:  0.0006575214792974293
Epoch:  294  	Training Loss: 0.0005024150013923645
Test Loss:  0.0005042999982833862
Valid Loss:  0.0006562105845659971
Epoch:  295  	Training Loss: 0.0005011296598240733
Test Loss:  0.000503214483615011
Valid Loss:  0.0006549017853103578
Epoch:  296  	Training Loss: 0.0004998500808142126
Test Loss:  0.0005021318793296814
Valid Loss:  0.0006535955471917987
Epoch:  297  	Training Loss: 0.0004985756240785122
Test Loss:  0.0005010528257116675
Valid Loss:  0.0006522915209643543
Epoch:  298  	Training Loss: 0.0004973065224476159
Test Loss:  0.0004999760421924293
Valid Loss:  0.0006509899394586682
Epoch:  299  	Training Loss: 0.0004960417281836271
Test Loss:  0.0004989036242477596
Valid Loss:  0.0006496913847513497
Epoch:  300  	Training Loss: 0.0004947824636474252
Test Loss:  0.0004978325450792909
Valid Loss:  0.0006483948091045022
Epoch:  301  	Training Loss: 0.00049352808855474
Test Loss:  0.000496765598654747
Valid Loss:  0.000647101376671344
Epoch:  302  	Training Loss: 0.0004922788357362151
Test Loss:  0.000495700107421726
Valid Loss:  0.0006458092830143869
Epoch:  303  	Training Loss: 0.000491034472361207
Test Loss:  0.0004946386907249689
Valid Loss:  0.000644519052002579
Epoch:  304  	Training Loss: 0.0004897954640910029
Test Loss:  0.0004935808246955276
Valid Loss:  0.0006432337686419487
Epoch:  305  	Training Loss: 0.0004885612288489938
Test Loss:  0.000492525810841471
Valid Loss:  0.000641950755380094
Epoch:  306  	Training Loss: 0.0004873317084275186
Test Loss:  0.0004914741730317473
Valid Loss:  0.0006406707689166069
Epoch:  307  	Training Loss: 0.0004861078050453216
Test Loss:  0.0004904253873974085
Valid Loss:  0.0006393941002897918
Epoch:  308  	Training Loss: 0.00048488829634152353
Test Loss:  0.000489380385261029
Valid Loss:  0.0006381214479915798
Epoch:  309  	Training Loss: 0.0004836744046770036
Test Loss:  0.0004883378278464079
Valid Loss:  0.0006368515314534307
Epoch:  310  	Training Loss: 0.00048246484948322177
Test Loss:  0.0004872980061918497
Valid Loss:  0.0006355845252983272
Epoch:  311  	Training Loss: 0.00048125992179848254
Test Loss:  0.0004862612986471504
Valid Loss:  0.0006343210116028786
Epoch:  312  	Training Loss: 0.0004800596216227859
Test Loss:  0.0004852293059229851
Valid Loss:  0.0006330598844215274
Epoch:  313  	Training Loss: 0.0004788650549016893
Test Loss:  0.00048419972881674767
Valid Loss:  0.0006318017840385437
Epoch:  314  	Training Loss: 0.0004776752321049571
Test Loss:  0.0004831716069020331
Valid Loss:  0.0006305485730990767
Epoch:  315  	Training Loss: 0.0004764898621942848
Test Loss:  0.00048214796697720885
Valid Loss:  0.0006292975740507245
Epoch:  316  	Training Loss: 0.00047530949814245105
Test Loss:  0.00048112592776305974
Valid Loss:  0.0006280505331233144
Epoch:  317  	Training Loss: 0.000474133703391999
Test Loss:  0.0004801090690307319
Valid Loss:  0.0006268067518249154
Epoch:  318  	Training Loss: 0.00047296262346208096
Test Loss:  0.00047909372369758785
Valid Loss:  0.0006255646585486829
Epoch:  319  	Training Loss: 0.00047179654939100146
Test Loss:  0.00047808297676965594
Valid Loss:  0.0006243272218853235
Epoch:  320  	Training Loss: 0.00047063481179066
Test Loss:  0.00047707429621368647
Valid Loss:  0.0006230941507965326
Epoch:  321  	Training Loss: 0.0004694777016993612
Test Loss:  0.00047606806037947536
Valid Loss:  0.0006218630587682128
Epoch:  322  	Training Loss: 0.00046832545194774866
Test Loss:  0.00047506645205430686
Valid Loss:  0.0006206361576914787
Epoch:  323  	Training Loss: 0.00046717762597836554
Test Loss:  0.00047406795783899724
Valid Loss:  0.0006194125162437558
Epoch:  324  	Training Loss: 0.0004660345148295164
Test Loss:  0.00047307118074968457
Valid Loss:  0.0006181923672556877
Epoch:  325  	Training Loss: 0.0004648963804356754
Test Loss:  0.00047207935131154954
Valid Loss:  0.0006169761181809008
Epoch:  326  	Training Loss: 0.00046376281534321606
Test Loss:  0.00047108903527259827
Valid Loss:  0.0006157621392048895
Epoch:  327  	Training Loss: 0.00046263309195637703
Test Loss:  0.0004701020079664886
Valid Loss:  0.0006145524675957859
Epoch:  328  	Training Loss: 0.00046150776324793696
Test Loss:  0.00046911853132769465
Valid Loss:  0.0006133454153314233
Epoch:  329  	Training Loss: 0.000460387411294505
Test Loss:  0.00046813770313747227
Valid Loss:  0.0006121418555267155
Epoch:  330  	Training Loss: 0.0004592708428390324
Test Loss:  0.00046715815551579
Valid Loss:  0.0006109402747824788
Epoch:  331  	Training Loss: 0.00045815855264663696
Test Loss:  0.0004661823040805757
Valid Loss:  0.0006097436998970807
Epoch:  332  	Training Loss: 0.0004570515011437237
Test Loss:  0.0004652093630284071
Valid Loss:  0.00060854951152578
Epoch:  333  	Training Loss: 0.000455949135357514
Test Loss:  0.0004642412532120943
Valid Loss:  0.000607359572313726
Epoch:  334  	Training Loss: 0.00045485133887268603
Test Loss:  0.0004632755590137094
Valid Loss:  0.0006061724852770567
Epoch:  335  	Training Loss: 0.00045375790796242654
Test Loss:  0.00046231213491410017
Valid Loss:  0.0006049885414540768
Epoch:  336  	Training Loss: 0.0004526688135229051
Test Loss:  0.0004613522905856371
Valid Loss:  0.0006038092542439699
Epoch:  337  	Training Loss: 0.0004515838227234781
Test Loss:  0.00046039477456361055
Valid Loss:  0.0006026327610015869
Epoch:  338  	Training Loss: 0.00045050334301777184
Test Loss:  0.0004594401107169688
Valid Loss:  0.0006014584796503186
Epoch:  339  	Training Loss: 0.00044942687964066863
Test Loss:  0.0004584887938108295
Valid Loss:  0.0006002880400046706
Epoch:  340  	Training Loss: 0.00044835484004579484
Test Loss:  0.0004575407656375319
Valid Loss:  0.0005991219077259302
Epoch:  341  	Training Loss: 0.000447286874987185
Test Loss:  0.00045659582247026265
Valid Loss:  0.0005979572888463736
Epoch:  342  	Training Loss: 0.00044622295536100864
Test Loss:  0.0004556543135549873
Valid Loss:  0.0005967951728962362
 69%|██████▊   | 343/500 [04:04<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:05<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:05<01:08,  2.22it/s] 70%|██████▉   | 349/500 [04:05<00:50,  2.99it/s] 70%|███████   | 351/500 [04:11<02:58,  1.20s/it] 71%|███████   | 353/500 [04:11<02:06,  1.16it/s] 71%|███████   | 355/500 [04:12<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:12<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:12<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:18<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:18<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:18<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:19<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:19<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:25<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:25<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:25<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:25<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:25<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:32<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:32<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:32<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:32<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:39<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:39<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:39<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:39<00:47,  2.19it/s] 80%|███████▉  | 399/500 [04:39<00:34,  2.93it/s] 80%|████████  | 401/500 [04:46<01:57,  1.19s/it] 81%|████████  | 403/500 [04:46<01:22,  1.17it/s] 81%|████████  | 405/500 [04:46<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:46<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.96it/s]Epoch:  343  	Training Loss: 0.0004451617132872343
Test Loss:  0.00045471329940482974
Valid Loss:  0.0005956352688372135
Epoch:  344  	Training Loss: 0.00044410437112674117
Test Loss:  0.0004537753411568701
Valid Loss:  0.0005944794975221157
Epoch:  345  	Training Loss: 0.00044305186020210385
Test Loss:  0.00045283971121534705
Valid Loss:  0.0005933266365900636
Epoch:  346  	Training Loss: 0.0004420031327754259
Test Loss:  0.00045190751552581787
Valid Loss:  0.00059217878151685
Epoch:  347  	Training Loss: 0.00044095845078118145
Test Loss:  0.0004509779391810298
Valid Loss:  0.0005910323234274983
Epoch:  348  	Training Loss: 0.00043991778511554003
Test Loss:  0.00045005237916484475
Valid Loss:  0.0005898892995901406
Epoch:  349  	Training Loss: 0.00043888131040148437
Test Loss:  0.00044912812882103026
Valid Loss:  0.0005887504667043686
Epoch:  350  	Training Loss: 0.0004378492012619972
Test Loss:  0.000448207079898566
Valid Loss:  0.0005876142531633377
Epoch:  351  	Training Loss: 0.00043682093382813036
Test Loss:  0.000447289232397452
Valid Loss:  0.0005864816484972835
Epoch:  352  	Training Loss: 0.00043579639168456197
Test Loss:  0.0004463721998035908
Valid Loss:  0.0005853554466739297
Epoch:  353  	Training Loss: 0.00043477819417603314
Test Loss:  0.000445461249910295
Valid Loss:  0.0005842319806106389
Epoch:  354  	Training Loss: 0.00043376401299610734
Test Loss:  0.0004445535596460104
Valid Loss:  0.0005831113085150719
Epoch:  355  	Training Loss: 0.0004327537026256323
Test Loss:  0.0004436486051417887
Valid Loss:  0.0005819930229336023
Epoch:  356  	Training Loss: 0.00043174708844162524
Test Loss:  0.0004427463572937995
Valid Loss:  0.0005808798596262932
Epoch:  357  	Training Loss: 0.0004307449562475085
Test Loss:  0.00044184725265949965
Valid Loss:  0.000579769373871386
Epoch:  358  	Training Loss: 0.0004297464620321989
Test Loss:  0.0004409504763316363
Valid Loss:  0.0005786607507616282
Epoch:  359  	Training Loss: 0.0004287513729650527
Test Loss:  0.00044005707604810596
Valid Loss:  0.0005775557947345078
Epoch:  360  	Training Loss: 0.0004277608240954578
Test Loss:  0.000439166440628469
Valid Loss:  0.0005764543311670423
Epoch:  361  	Training Loss: 0.0004267737385816872
Test Loss:  0.0004382781917229295
Valid Loss:  0.0005753571167588234
Epoch:  362  	Training Loss: 0.00042579061118885875
Test Loss:  0.00043739331886172295
Valid Loss:  0.0005742625799030066
Epoch:  363  	Training Loss: 0.0004248119657859206
Test Loss:  0.0004365117638371885
Valid Loss:  0.0005731709534302354
Epoch:  364  	Training Loss: 0.00042383698746562004
Test Loss:  0.0004356321005616337
Valid Loss:  0.0005720827612094581
Epoch:  365  	Training Loss: 0.0004228659381624311
Test Loss:  0.00043475659913383424
Valid Loss:  0.0005709973629564047
Epoch:  366  	Training Loss: 0.000421898381318897
Test Loss:  0.00043388272752054036
Valid Loss:  0.0005699157482013106
Epoch:  367  	Training Loss: 0.00042093489901162684
Test Loss:  0.00043301197001710534
Valid Loss:  0.0005688375094905496
Epoch:  368  	Training Loss: 0.0004199750255793333
Test Loss:  0.00043214362813159823
Valid Loss:  0.0005677617155015469
Epoch:  369  	Training Loss: 0.00041901846998371184
Test Loss:  0.0004312790697440505
Valid Loss:  0.0005666891229338944
Epoch:  370  	Training Loss: 0.00041806622175499797
Test Loss:  0.00043041614117100835
Valid Loss:  0.0005656199064105749
Epoch:  371  	Training Loss: 0.00041711708763614297
Test Loss:  0.0004295572580303997
Valid Loss:  0.0005645533674396574
Epoch:  372  	Training Loss: 0.0004161720862612128
Test Loss:  0.000428700412157923
Valid Loss:  0.0005634886911138892
Epoch:  373  	Training Loss: 0.0004152309847995639
Test Loss:  0.0004278469132259488
Valid Loss:  0.0005624291952699423
Epoch:  374  	Training Loss: 0.0004142940160818398
Test Loss:  0.0004269967903383076
Valid Loss:  0.0005613717949017882
Epoch:  375  	Training Loss: 0.00041336112190037966
Test Loss:  0.0004261483554728329
Valid Loss:  0.0005603164900094271
Epoch:  376  	Training Loss: 0.00041243061423301697
Test Loss:  0.00042530152131803334
Valid Loss:  0.0005592657253146172
Epoch:  377  	Training Loss: 0.00041150423930957913
Test Loss:  0.0004244582960382104
Valid Loss:  0.0005582177545875311
Epoch:  378  	Training Loss: 0.00041058167698793113
Test Loss:  0.0004236189997754991
Valid Loss:  0.0005571740912273526
Epoch:  379  	Training Loss: 0.00040966260712593794
Test Loss:  0.0004227811878081411
Valid Loss:  0.0005561317666433752
Epoch:  380  	Training Loss: 0.000408746738685295
Test Loss:  0.000421946810092777
Valid Loss:  0.0005550935165956616
Epoch:  381  	Training Loss: 0.0004078345373272896
Test Loss:  0.00042111414950340986
Valid Loss:  0.0005540578858926892
Epoch:  382  	Training Loss: 0.00040692585753276944
Test Loss:  0.00042028730968013406
Valid Loss:  0.0005530214984901249
Epoch:  383  	Training Loss: 0.0004060197970829904
Test Loss:  0.00041945953853428364
Valid Loss:  0.0005519880214706063
Epoch:  384  	Training Loss: 0.0004051167634315789
Test Loss:  0.000418634619563818
Valid Loss:  0.0005509589682333171
Epoch:  385  	Training Loss: 0.00040421722223982215
Test Loss:  0.0004178114468231797
Valid Loss:  0.0005499327671714127
Epoch:  386  	Training Loss: 0.00040332155185751617
Test Loss:  0.00041699109715409577
Valid Loss:  0.0005489097093231976
Epoch:  387  	Training Loss: 0.00040242919931188226
Test Loss:  0.00041617429815232754
Valid Loss:  0.0005478906095959246
Epoch:  388  	Training Loss: 0.00040154028101824224
Test Loss:  0.0004153592453803867
Valid Loss:  0.0005468742456287146
Epoch:  389  	Training Loss: 0.0004006547969765961
Test Loss:  0.0004145482089370489
Valid Loss:  0.0005458617815747857
Epoch:  390  	Training Loss: 0.0003997729509137571
Test Loss:  0.0004137386567890644
Valid Loss:  0.0005448523443192244
Epoch:  391  	Training Loss: 0.0003988943644799292
Test Loss:  0.00041293236427009106
Valid Loss:  0.0005438453517854214
Epoch:  392  	Training Loss: 0.00039801927050575614
Test Loss:  0.0004121251404285431
Valid Loss:  0.0005428466247394681
Epoch:  393  	Training Loss: 0.0003971489204559475
Test Loss:  0.0004113254835829139
Valid Loss:  0.0005418502259999514
Epoch:  394  	Training Loss: 0.0003962822665926069
Test Loss:  0.0004105290863662958
Valid Loss:  0.0005408575525507331
Epoch:  395  	Training Loss: 0.00039541811565868556
Test Loss:  0.00040973396971821785
Valid Loss:  0.0005398668581619859
Epoch:  396  	Training Loss: 0.00039455812657251954
Test Loss:  0.0004089427529834211
Valid Loss:  0.000538880005478859
Epoch:  397  	Training Loss: 0.0003937010478693992
Test Loss:  0.00040815345710143447
Valid Loss:  0.000537893851287663
Epoch:  398  	Training Loss: 0.00039284711237996817
Test Loss:  0.00040736625669524074
Valid Loss:  0.0005369118880480528
Epoch:  399  	Training Loss: 0.00039199687307700515
Test Loss:  0.00040658243233338
Valid Loss:  0.0005359335918910801
Epoch:  400  	Training Loss: 0.0003911494859494269
Test Loss:  0.0004058011109009385
Valid Loss:  0.0005349572165869176
Epoch:  401  	Training Loss: 0.0003903056785929948
Test Loss:  0.0004050225834362209
Valid Loss:  0.0005339844501577318
Epoch:  402  	Training Loss: 0.00038946515996940434
Test Loss:  0.0004042464424856007
Valid Loss:  0.0005330141866579652
Epoch:  403  	Training Loss: 0.0003886279300786555
Test Loss:  0.000403473706683144
Valid Loss:  0.0005320475902408361
Epoch:  404  	Training Loss: 0.00038779358146712184
Test Loss:  0.0004027024260722101
Valid Loss:  0.0005310829728841782
Epoch:  405  	Training Loss: 0.000386962405173108
Test Loss:  0.00040193478344008327
Valid Loss:  0.0005301217897795141
Epoch:  406  	Training Loss: 0.00038613477954640985
Test Loss:  0.0004011687415186316
Valid Loss:  0.0005291635170578957
Epoch:  407  	Training Loss: 0.0003853103262372315
Test Loss:  0.00040040590101853013
Valid Loss:  0.0005282078636810184
Epoch:  408  	Training Loss: 0.0003844887251034379
Test Loss:  0.00039964530151337385
Valid Loss:  0.0005272558191791177
Epoch:  409  	Training Loss: 0.0003836706164292991
Test Loss:  0.000398887088522315
Valid Loss:  0.0005263063358142972
Epoch:  410  	Training Loss: 0.000382855418138206
Test Loss:  0.00039813207695260644
Valid Loss:   82%|████████▏ | 411/500 [04:52<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:53<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:53<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:53<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:53<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:59<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:00<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:00<00:32,  2.21it/s] 86%|████████▌ | 429/500 [05:00<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:06<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:06<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:06<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:07<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:07<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:13<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:13<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:13<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:13<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:20<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:20<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:20<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:27<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:27<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:27<00:14,  2.20it/s] 94%|█████████▍| 469/500 [05:27<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:34<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:34<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:34<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.22it/s]0.000525359355378896
Epoch:  411  	Training Loss: 0.0003820433630608022
Test Loss:  0.0003973799175582826
Valid Loss:  0.0005244152271188796
Epoch:  412  	Training Loss: 0.00038123459671624005
Test Loss:  0.00039663113420829177
Valid Loss:  0.0005234743002802134
Epoch:  413  	Training Loss: 0.00038042961386963725
Test Loss:  0.0003958838642574847
Valid Loss:  0.0005225350614637136
Epoch:  414  	Training Loss: 0.00037962791975587606
Test Loss:  0.00039513997035101056
Valid Loss:  0.000521600479260087
Epoch:  415  	Training Loss: 0.0003788288158830255
Test Loss:  0.000394397706259042
Valid Loss:  0.0005206681089475751
Epoch:  416  	Training Loss: 0.00037803297163918614
Test Loss:  0.0003936580615118146
Valid Loss:  0.0005197388236410916
Epoch:  417  	Training Loss: 0.00037724035792052746
Test Loss:  0.0003929216181859374
Valid Loss:  0.0005188120994716883
Epoch:  418  	Training Loss: 0.000376450625481084
Test Loss:  0.0003921866009477526
Valid Loss:  0.0005178891005925834
Epoch:  419  	Training Loss: 0.0003756638616323471
Test Loss:  0.00039145490154623985
Valid Loss:  0.0005169685464352369
Epoch:  420  	Training Loss: 0.0003748805611394346
Test Loss:  0.00039072506478987634
Valid Loss:  0.0005160504952073097
Epoch:  421  	Training Loss: 0.0003740997635759413
Test Loss:  0.0003899988951161504
Valid Loss:  0.0005151366349309683
Epoch:  422  	Training Loss: 0.0003733224584721029
Test Loss:  0.00038927223067730665
Valid Loss:  0.0005142243462614715
Epoch:  423  	Training Loss: 0.0003725475398823619
Test Loss:  0.0003885496989823878
Valid Loss:  0.000513316597789526
Epoch:  424  	Training Loss: 0.0003717755025718361
Test Loss:  0.00038782978663221
Valid Loss:  0.0005124102463014424
Epoch:  425  	Training Loss: 0.000371006375644356
Test Loss:  0.0003871131339110434
Valid Loss:  0.0005115078529343009
Epoch:  426  	Training Loss: 0.00037024045013822615
Test Loss:  0.0003863981692120433
Valid Loss:  0.0005106071475893259
Epoch:  427  	Training Loss: 0.0003694774932228029
Test Loss:  0.0003856851835735142
Valid Loss:  0.0005097094690427184
Epoch:  428  	Training Loss: 0.0003687172429636121
Test Loss:  0.00038497551577165723
Valid Loss:  0.0005088153411634266
Epoch:  429  	Training Loss: 0.00036796036874875426
Test Loss:  0.00038426893297582865
Valid Loss:  0.0005079238908365369
Epoch:  430  	Training Loss: 0.0003672066086437553
Test Loss:  0.0003835642128251493
Valid Loss:  0.0005070345941931009
Epoch:  431  	Training Loss: 0.00036645529326051474
Test Loss:  0.0003828617627732456
Valid Loss:  0.0005061487900093198
Epoch:  432  	Training Loss: 0.0003657068300526589
Test Loss:  0.000382158876163885
Valid Loss:  0.0005052654887549579
Epoch:  433  	Training Loss: 0.0003649612481240183
Test Loss:  0.00038146122824400663
Valid Loss:  0.0005043839337304235
Epoch:  434  	Training Loss: 0.0003642187803052366
Test Loss:  0.00038076553028076887
Valid Loss:  0.0005035071517340839
Epoch:  435  	Training Loss: 0.00036347919376567006
Test Loss:  0.00038007317925803363
Valid Loss:  0.0005026322323828936
Epoch:  436  	Training Loss: 0.0003627424594014883
Test Loss:  0.000379383098334074
Valid Loss:  0.0005017599323764443
Epoch:  437  	Training Loss: 0.00036200869362801313
Test Loss:  0.00037869514198973775
Valid Loss:  0.0005008902517147362
Epoch:  438  	Training Loss: 0.0003612777218222618
Test Loss:  0.0003780094557441771
Valid Loss:  0.0005000232486054301
Epoch:  439  	Training Loss: 0.0003605494857765734
Test Loss:  0.0003773267089854926
Valid Loss:  0.0004991599125787616
Epoch:  440  	Training Loss: 0.00035982427652925253
Test Loss:  0.0003766465815715492
Valid Loss:  0.0004982991376891732
Epoch:  441  	Training Loss: 0.0003591015993151814
Test Loss:  0.0003759676474146545
Valid Loss:  0.0004974405746906996
Epoch:  442  	Training Loss: 0.0003583820362109691
Test Loss:  0.0003752920310944319
Valid Loss:  0.0004965842235833406
Epoch:  443  	Training Loss: 0.000357665354385972
Test Loss:  0.00037461891770362854
Valid Loss:  0.0004957312485203147
Epoch:  444  	Training Loss: 0.00035695204860530794
Test Loss:  0.0003739494422916323
Valid Loss:  0.0004948800196871161
Epoch:  445  	Training Loss: 0.0003562406054697931
Test Loss:  0.0003732802579179406
Valid Loss:  0.0004940330982208252
Epoch:  446  	Training Loss: 0.0003555327421054244
Test Loss:  0.00037261415855027735
Valid Loss:  0.0004931886214762926
Epoch:  447  	Training Loss: 0.00035482735256664455
Test Loss:  0.00037195044569671154
Valid Loss:  0.0004923462402075529
Epoch:  448  	Training Loss: 0.0003541245823726058
Test Loss:  0.00037128833355382085
Valid Loss:  0.0004915063036605716
Epoch:  449  	Training Loss: 0.0003534243442118168
Test Loss:  0.0003706288116518408
Valid Loss:  0.0004906688118353486
Epoch:  450  	Training Loss: 0.000352726987330243
Test Loss:  0.00036997205461375415
Valid Loss:  0.0004898349288851023
Epoch:  451  	Training Loss: 0.0003520320460665971
Test Loss:  0.0003693177131935954
Valid Loss:  0.0004890033742412925
Epoch:  452  	Training Loss: 0.00035134004428982735
Test Loss:  0.0003686654381453991
Valid Loss:  0.0004881738277617842
Epoch:  453  	Training Loss: 0.00035065048723481596
Test Loss:  0.0003680158988572657
Valid Loss:  0.00048734815209172666
Epoch:  454  	Training Loss: 0.000349963316693902
Test Loss:  0.0003673675237223506
Valid Loss:  0.00048652407713234425
Epoch:  455  	Training Loss: 0.0003492786199785769
Test Loss:  0.0003667219716589898
Valid Loss:  0.0004857039311900735
Epoch:  456  	Training Loss: 0.00034859718289226294
Test Loss:  0.0003660783404484391
Valid Loss:  0.0004848848911933601
Epoch:  457  	Training Loss: 0.0003479177539702505
Test Loss:  0.0003654375614132732
Valid Loss:  0.00048406864516437054
Epoch:  458  	Training Loss: 0.00034724094439297915
Test Loss:  0.000364798674127087
Valid Loss:  0.00048325597890652716
Epoch:  459  	Training Loss: 0.0003465668123681098
Test Loss:  0.0003641615330707282
Valid Loss:  0.00048244488425552845
Epoch:  460  	Training Loss: 0.00034589527058415115
Test Loss:  0.0003635268658399582
Valid Loss:  0.00048163693281821907
Epoch:  461  	Training Loss: 0.0003452262608334422
Test Loss:  0.00036289473064243793
Valid Loss:  0.0004808313387911767
Epoch:  462  	Training Loss: 0.0003445601323619485
Test Loss:  0.0003622629737947136
Valid Loss:  0.00048002813127823174
Epoch:  463  	Training Loss: 0.000343897205311805
Test Loss:  0.0003616355243138969
Valid Loss:  0.000479227805044502
Epoch:  464  	Training Loss: 0.00034323689760640264
Test Loss:  0.0003610101994127035
Valid Loss:  0.00047843094216659665
Epoch:  465  	Training Loss: 0.0003425791801419109
Test Loss:  0.0003603873774409294
Valid Loss:  0.00047763605834916234
Epoch:  466  	Training Loss: 0.0003419238782953471
Test Loss:  0.000359766127076
Valid Loss:  0.0004768439684994519
Epoch:  467  	Training Loss: 0.00034127122489735484
Test Loss:  0.0003591483982745558
Valid Loss:  0.00047605467261746526
Epoch:  468  	Training Loss: 0.00034062121994793415
Test Loss:  0.00035853200824931264
Valid Loss:  0.00047526723938062787
Epoch:  469  	Training Loss: 0.0003399730194360018
Test Loss:  0.00035791785921901464
Valid Loss:  0.00047448318218812346
Epoch:  470  	Training Loss: 0.00033932822407223284
Test Loss:  0.0003573055437300354
Valid Loss:  0.00047370020183734596
Epoch:  471  	Training Loss: 0.0003386852622497827
Test Loss:  0.0003566966624930501
Valid Loss:  0.0004729210340883583
Epoch:  472  	Training Loss: 0.0003380450652912259
Test Loss:  0.0003560885088518262
Valid Loss:  0.0004721428267657757
Epoch:  473  	Training Loss: 0.00033740606158971786
Test Loss:  0.0003554834984242916
Valid Loss:  0.0004713696544058621
Epoch:  474  	Training Loss: 0.00033676926977932453
Test Loss:  0.0003548787208274007
Valid Loss:  0.00047059773351065814
Epoch:  475  	Training Loss: 0.0003361353010404855
Test Loss:  0.0003542773483786732
Valid Loss:  0.00046982840285636485
Epoch:  476  	Training Loss: 0.00033550342777743936
Test Loss:  0.0003536769945640117
Valid Loss:  0.0004690611094702035
Epoch:  477  	Training Loss: 0.00033487388282082975
Test Loss:  0.0003530801914166659
Valid Loss:  0.00046829553321003914
Epoch:  478  	Training Loss: 0.00033424689900130033
Test Loss:  0.0003524842322804034
 96%|█████████▌| 479/500 [05:34<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:41<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:41<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.95it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:47<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:48<00:00,  2.97it/s]100%|██████████| 500/500 [05:48<00:00,  1.44it/s]
Valid Loss:  0.0004675333620980382
Epoch:  479  	Training Loss: 0.0003336222725920379
Test Loss:  0.00035189042682759464
Valid Loss:  0.00046677293721586466
Epoch:  480  	Training Loss: 0.00033300064387731254
Test Loss:  0.000351299240719527
Valid Loss:  0.00046601585927419364
Epoch:  481  	Training Loss: 0.00033238058676943183
Test Loss:  0.0003507097717374563
Valid Loss:  0.0004652602947317064
Epoch:  482  	Training Loss: 0.0003317631781101227
Test Loss:  0.00035012204898521304
Valid Loss:  0.000464508164441213
Epoch:  483  	Training Loss: 0.00033114966936409473
Test Loss:  0.00034953816793859005
Valid Loss:  0.0004637580714188516
Epoch:  484  	Training Loss: 0.00033053854713216424
Test Loss:  0.0003489560913294554
Valid Loss:  0.00046301016118377447
Epoch:  485  	Training Loss: 0.0003299294912721962
Test Loss:  0.00034837567363865674
Valid Loss:  0.0004622650449164212
Epoch:  486  	Training Loss: 0.00032932290923781693
Test Loss:  0.0003477978170849383
Valid Loss:  0.0004615217912942171
Epoch:  487  	Training Loss: 0.0003287181898485869
Test Loss:  0.00034722231794148684
Valid Loss:  0.0004607821465469897
Epoch:  488  	Training Loss: 0.00032811600249260664
Test Loss:  0.00034664757549762726
Valid Loss:  0.00046004378236830235
Epoch:  489  	Training Loss: 0.00032751596882008016
Test Loss:  0.00034607609268277884
Valid Loss:  0.000459307775599882
Epoch:  490  	Training Loss: 0.00032691832166165113
Test Loss:  0.0003455062978900969
Valid Loss:  0.00045857479562982917
Epoch:  491  	Training Loss: 0.00032632314832881093
Test Loss:  0.0003449383075349033
Valid Loss:  0.000457843707408756
Epoch:  492  	Training Loss: 0.00032572992495261133
Test Loss:  0.000344373780535534
Valid Loss:  0.00045711506390944123
Epoch:  493  	Training Loss: 0.00032513932092115283
Test Loss:  0.0003438103012740612
Valid Loss:  0.000456387730082497
Epoch:  494  	Training Loss: 0.00032455078326165676
Test Loss:  0.00034324784064665437
Valid Loss:  0.0004556643543764949
Epoch:  495  	Training Loss: 0.0003239646030124277
Test Loss:  0.0003426881739869714
Valid Loss:  0.00045494158985093236
Epoch:  496  	Training Loss: 0.000323380867484957
Test Loss:  0.0003421312721911818
Valid Loss:  0.0004542232782114297
Epoch:  497  	Training Loss: 0.0003227990819141269
Test Loss:  0.0003415756509639323
Valid Loss:  0.00045350618893280625
Epoch:  498  	Training Loss: 0.0003222192754037678
Test Loss:  0.0003410213394090533
Valid Loss:  0.0004527915152721107
Epoch:  499  	Training Loss: 0.0003216420009266585
Test Loss:  0.00034046973451040685
Valid Loss:  0.00045207946095615625
Epoch:  500  	Training Loss: 0.00032106696744449437
Test Loss:  0.0003399199340492487
Valid Loss:  0.0004513695603236556
seed is  12
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:12,  6.28s/it]  1%|          | 3/500 [00:06<13:54,  1.68s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:44,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:20<09:44,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.95it/s]  6%|▌         | 31/500 [00:26<09:20,  1.19s/it]  7%|▋         | 33/500 [00:27<06:39,  1.17it/s]  7%|▋         | 35/500 [00:27<04:47,  1.62it/s]  7%|▋         | 37/500 [00:27<03:31,  2.19it/s]  8%|▊         | 39/500 [00:27<02:39,  2.89it/s]  8%|▊         | 41/500 [00:33<09:08,  1.20s/it]  9%|▊         | 43/500 [00:34<06:32,  1.17it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:25,  2.20it/s] 10%|▉         | 49/500 [00:34<02:31,  2.97it/s] 10%|█         | 51/500 [00:40<08:49,  1.18s/it] 11%|█         | 53/500 [00:40<06:18,  1.18it/s] 11%|█         | 55/500 [00:40<04:32,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:47<08:36,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:48<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:54<08:27,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:02,  1.18it/s]Epoch:  1  	Training Loss: 0.1598755419254303
Test Loss:  0.5864968299865723
Valid Loss:  0.5899982452392578
Epoch:  2  	Training Loss: 0.6915661096572876
Test Loss:  0.2126482129096985
Valid Loss:  0.20586904883384705
Epoch:  3  	Training Loss: 0.15855243802070618
Test Loss:  0.2126275599002838
Valid Loss:  0.20584771037101746
Epoch:  4  	Training Loss: 0.15853413939476013
Test Loss:  0.21260404586791992
Valid Loss:  0.20582515001296997
Epoch:  5  	Training Loss: 0.15851342678070068
Test Loss:  0.21257418394088745
Valid Loss:  0.20579883456230164
Epoch:  6  	Training Loss: 0.15848562121391296
Test Loss:  0.21252737939357758
Valid Loss:  0.20576532185077667
Epoch:  7  	Training Loss: 0.15844936668872833
Test Loss:  0.2124551385641098
Valid Loss:  0.20570656657218933
Epoch:  8  	Training Loss: 0.15839487314224243
Test Loss:  0.2123250663280487
Valid Loss:  0.20557866990566254
Epoch:  9  	Training Loss: 0.15829452872276306
Test Loss:  0.2121809422969818
Valid Loss:  0.20543594658374786
Epoch:  10  	Training Loss: 0.15818336606025696
Test Loss:  0.21203690767288208
Valid Loss:  0.20529331266880035
Epoch:  11  	Training Loss: 0.15807226300239563
Test Loss:  0.2118929624557495
Valid Loss:  0.2051507830619812
Epoch:  12  	Training Loss: 0.15796123445034027
Test Loss:  0.21177101135253906
Valid Loss:  0.20503146946430206
Epoch:  13  	Training Loss: 0.157866433262825
Test Loss:  0.2116490751504898
Valid Loss:  0.2049121856689453
Epoch:  14  	Training Loss: 0.15777167677879333
Test Loss:  0.21152718365192413
Valid Loss:  0.20479294657707214
Epoch:  15  	Training Loss: 0.15767690539360046
Test Loss:  0.21140530705451965
Valid Loss:  0.20467373728752136
Epoch:  16  	Training Loss: 0.15758219361305237
Test Loss:  0.21128347516059875
Valid Loss:  0.20455455780029297
Epoch:  17  	Training Loss: 0.15748751163482666
Test Loss:  0.21116167306900024
Valid Loss:  0.20443540811538696
Epoch:  18  	Training Loss: 0.15739284455776215
Test Loss:  0.21103990077972412
Valid Loss:  0.20431630313396454
Epoch:  19  	Training Loss: 0.1572982221841812
Test Loss:  0.21091815829277039
Valid Loss:  0.2041972279548645
Epoch:  20  	Training Loss: 0.15720361471176147
Test Loss:  0.21079646050930023
Valid Loss:  0.20407816767692566
Epoch:  21  	Training Loss: 0.15710905194282532
Test Loss:  0.21067477762699127
Valid Loss:  0.2039591670036316
Epoch:  22  	Training Loss: 0.15701448917388916
Test Loss:  0.21055525541305542
Valid Loss:  0.20384185016155243
Epoch:  23  	Training Loss: 0.15692177414894104
Test Loss:  0.21043576300144196
Valid Loss:  0.20372462272644043
Epoch:  24  	Training Loss: 0.1568291187286377
Test Loss:  0.21031634509563446
Valid Loss:  0.203607439994812
Epoch:  25  	Training Loss: 0.15673647820949554
Test Loss:  0.21019700169563293
Valid Loss:  0.20349033176898956
Epoch:  26  	Training Loss: 0.15664392709732056
Test Loss:  0.210077702999115
Valid Loss:  0.2033732682466507
Epoch:  27  	Training Loss: 0.15655140578746796
Test Loss:  0.20995846390724182
Valid Loss:  0.2032562792301178
Epoch:  28  	Training Loss: 0.15645894408226013
Test Loss:  0.20983929932117462
Valid Loss:  0.20313934981822968
Epoch:  29  	Training Loss: 0.1563665270805359
Test Loss:  0.2097202092409134
Valid Loss:  0.20302248001098633
Epoch:  30  	Training Loss: 0.15627416968345642
Test Loss:  0.20960113406181335
Valid Loss:  0.20290568470954895
Epoch:  31  	Training Loss: 0.15618184208869934
Test Loss:  0.20948216319084167
Valid Loss:  0.20278891921043396
Epoch:  32  	Training Loss: 0.15608958899974823
Test Loss:  0.20936492085456848
Valid Loss:  0.20267362892627716
Epoch:  33  	Training Loss: 0.15599879622459412
Test Loss:  0.20924773812294006
Valid Loss:  0.20255839824676514
Epoch:  34  	Training Loss: 0.15590804815292358
Test Loss:  0.20913061499595642
Valid Loss:  0.20244324207305908
Epoch:  35  	Training Loss: 0.15581735968589783
Test Loss:  0.20901358127593994
Valid Loss:  0.2023281455039978
Epoch:  36  	Training Loss: 0.15572674572467804
Test Loss:  0.20889660716056824
Valid Loss:  0.2022131383419037
Epoch:  37  	Training Loss: 0.15563619136810303
Test Loss:  0.2087797224521637
Valid Loss:  0.20209819078445435
Epoch:  38  	Training Loss: 0.1555456966161728
Test Loss:  0.20866292715072632
Valid Loss:  0.20198333263397217
Epoch:  39  	Training Loss: 0.15545524656772614
Test Loss:  0.20854617655277252
Valid Loss:  0.20186853408813477
Epoch:  40  	Training Loss: 0.15536487102508545
Test Loss:  0.2084295004606247
Valid Loss:  0.20175379514694214
Epoch:  41  	Training Loss: 0.15527454018592834
Test Loss:  0.20831289887428284
Valid Loss:  0.20163914561271667
Epoch:  42  	Training Loss: 0.15518426895141602
Test Loss:  0.20819750428199768
Valid Loss:  0.2015255093574524
Epoch:  43  	Training Loss: 0.15509499609470367
Test Loss:  0.2080821841955185
Valid Loss:  0.20141194760799408
Epoch:  44  	Training Loss: 0.1550057977437973
Test Loss:  0.20796695351600647
Valid Loss:  0.20129847526550293
Epoch:  45  	Training Loss: 0.1549166738986969
Test Loss:  0.207851842045784
Valid Loss:  0.20118512213230133
Epoch:  46  	Training Loss: 0.15482762455940247
Test Loss:  0.2077368050813675
Valid Loss:  0.2010718286037445
Epoch:  47  	Training Loss: 0.1547386348247528
Test Loss:  0.20762187242507935
Valid Loss:  0.20095865428447723
Epoch:  48  	Training Loss: 0.1546497344970703
Test Loss:  0.20750701427459717
Valid Loss:  0.20084556937217712
Epoch:  49  	Training Loss: 0.15456092357635498
Test Loss:  0.20739229023456573
Valid Loss:  0.20073258876800537
Epoch:  50  	Training Loss: 0.15447217226028442
Test Loss:  0.20727764070034027
Valid Loss:  0.2006196677684784
Epoch:  51  	Training Loss: 0.15438349545001984
Test Loss:  0.20716306567192078
Valid Loss:  0.20050686597824097
Epoch:  52  	Training Loss: 0.15429489314556122
Test Loss:  0.20704928040504456
Valid Loss:  0.20039474964141846
Epoch:  53  	Training Loss: 0.15420694649219513
Test Loss:  0.20693552494049072
Valid Loss:  0.20028267800807953
Epoch:  54  	Training Loss: 0.15411904454231262
Test Loss:  0.20682185888290405
Valid Loss:  0.20017068088054657
Epoch:  55  	Training Loss: 0.15403121709823608
Test Loss:  0.20670825242996216
Valid Loss:  0.2000587284564972
Epoch:  56  	Training Loss: 0.15394338965415955
Test Loss:  0.20659467577934265
Valid Loss:  0.19994685053825378
Epoch:  57  	Training Loss: 0.15385563671588898
Test Loss:  0.20648115873336792
Valid Loss:  0.19983500242233276
Epoch:  58  	Training Loss: 0.1537679135799408
Test Loss:  0.20636770129203796
Valid Loss:  0.19972321391105652
Epoch:  59  	Training Loss: 0.15368026494979858
Test Loss:  0.20625430345535278
Valid Loss:  0.19961148500442505
Epoch:  60  	Training Loss: 0.15359261631965637
Test Loss:  0.20614095032215118
Valid Loss:  0.19949980080127716
Epoch:  61  	Training Loss: 0.15350504219532013
Test Loss:  0.20602765679359436
Valid Loss:  0.19938820600509644
Epoch:  62  	Training Loss: 0.15341749787330627
Test Loss:  0.20591424405574799
Valid Loss:  0.1992764174938202
Epoch:  63  	Training Loss: 0.15332984924316406
Test Loss:  0.2058008909225464
Valid Loss:  0.1991647183895111
Epoch:  64  	Training Loss: 0.15324226021766663
Test Loss:  0.20568761229515076
Valid Loss:  0.199053093791008
Epoch:  65  	Training Loss: 0.15315471589565277
Test Loss:  0.2055744081735611
Valid Loss:  0.19894155859947205
Epoch:  66  	Training Loss: 0.15306724607944489
Test Loss:  0.2054612934589386
Valid Loss:  0.19883006811141968
Epoch:  67  	Training Loss: 0.15297982096672058
Test Loss:  0.20534822344779968
Valid Loss:  0.19871869683265686
Epoch:  68  	Training Loss: 0.15289247035980225
Test Loss:  0.20523525774478912
Valid Loss:  0.19860735535621643
Epoch:  69  	Training Loss: 0.1528051793575287
Test Loss:  0.20512235164642334
Valid Loss:  0.19849610328674316
Epoch:  70  	Training Loss: 0.1527179479598999
Test Loss:  0.20500952005386353
Valid Loss:  0.19838494062423706
Epoch:  71  	Training Loss: 0.1526307761669159
Test Loss:  0.20489677786827087
Valid Loss:  0.19827383756637573
Epoch:  72  	Training Loss: 0.15254366397857666
Test Loss:  0.20478427410125732
Valid Loss:  0.19816303253173828
Epoch:  73  	Training Loss: 0.15245673060417175
Test Loss:  0.20467185974121094
Valid Loss:  0.1980522871017456
 15%|█▌        | 75/500 [00:54<04:20,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:01<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:01<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:01<02:15,  3.02it/s] 18%|█▊        | 91/500 [01:08<08:09,  1.20s/it] 19%|█▊        | 93/500 [01:08<05:49,  1.16it/s] 19%|█▉        | 95/500 [01:08<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:08<03:02,  2.20it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.97it/s] 20%|██        | 101/500 [01:15<08:00,  1.20s/it] 21%|██        | 103/500 [01:15<05:43,  1.16it/s] 21%|██        | 105/500 [01:15<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:15<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:15<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:22<07:48,  1.20s/it] 23%|██▎       | 113/500 [01:22<05:34,  1.16it/s] 23%|██▎       | 115/500 [01:22<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:22<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:22<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:28<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:12,  1.17it/s] 27%|██▋       | 135/500 [01:36<03:44,  1.62it/s] 27%|██▋       | 137/500 [01:36<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:36<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:42<07:07,  1.19s/it] 29%|██▊       | 143/500 [01:42<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:43<03:40,  1.61it/s]Epoch:  74  	Training Loss: 0.15236984193325043
Test Loss:  0.2045595347881317
Valid Loss:  0.1979416459798813
Epoch:  75  	Training Loss: 0.15228304266929626
Test Loss:  0.20444729924201965
Valid Loss:  0.19783107936382294
Epoch:  76  	Training Loss: 0.15219631791114807
Test Loss:  0.20433513820171356
Valid Loss:  0.19772061705589294
Epoch:  77  	Training Loss: 0.15210965275764465
Test Loss:  0.20422306656837463
Valid Loss:  0.19761024415493011
Epoch:  78  	Training Loss: 0.152023047208786
Test Loss:  0.20411109924316406
Valid Loss:  0.19749993085861206
Epoch:  79  	Training Loss: 0.15193653106689453
Test Loss:  0.20399922132492065
Valid Loss:  0.19738972187042236
Epoch:  80  	Training Loss: 0.15185007452964783
Test Loss:  0.20388741791248322
Valid Loss:  0.19727961719036102
Epoch:  81  	Training Loss: 0.1517636924982071
Test Loss:  0.20377570390701294
Valid Loss:  0.19716957211494446
Epoch:  82  	Training Loss: 0.15167737007141113
Test Loss:  0.2036639302968979
Valid Loss:  0.1970595270395279
Epoch:  83  	Training Loss: 0.15159103274345398
Test Loss:  0.2035522162914276
Valid Loss:  0.1969495415687561
Epoch:  84  	Training Loss: 0.15150469541549683
Test Loss:  0.2034405767917633
Valid Loss:  0.1968396008014679
Epoch:  85  	Training Loss: 0.15141844749450684
Test Loss:  0.20332899689674377
Valid Loss:  0.19672974944114685
Epoch:  86  	Training Loss: 0.15133219957351685
Test Loss:  0.20321744680404663
Valid Loss:  0.196619912981987
Epoch:  87  	Training Loss: 0.1512460559606552
Test Loss:  0.20310600101947784
Valid Loss:  0.1965101659297943
Epoch:  88  	Training Loss: 0.15115994215011597
Test Loss:  0.20299458503723145
Valid Loss:  0.1964004784822464
Epoch:  89  	Training Loss: 0.1510738730430603
Test Loss:  0.20288324356079102
Valid Loss:  0.19629086554050446
Epoch:  90  	Training Loss: 0.15098784863948822
Test Loss:  0.20277196168899536
Valid Loss:  0.1961812824010849
Epoch:  91  	Training Loss: 0.1509018838405609
Test Loss:  0.20266073942184448
Valid Loss:  0.1960718035697937
Epoch:  92  	Training Loss: 0.1508159637451172
Test Loss:  0.20254932343959808
Valid Loss:  0.19596213102340698
Epoch:  93  	Training Loss: 0.15072986483573914
Test Loss:  0.20243799686431885
Valid Loss:  0.19585257768630981
Epoch:  94  	Training Loss: 0.15064384043216705
Test Loss:  0.20232674479484558
Valid Loss:  0.19574308395385742
Epoch:  95  	Training Loss: 0.15055787563323975
Test Loss:  0.2022155523300171
Valid Loss:  0.1956336498260498
Epoch:  96  	Training Loss: 0.15047197043895721
Test Loss:  0.20210443437099457
Valid Loss:  0.19552429020404816
Epoch:  97  	Training Loss: 0.15038610994815826
Test Loss:  0.2019934058189392
Valid Loss:  0.19541501998901367
Epoch:  98  	Training Loss: 0.15030032396316528
Test Loss:  0.20188242197036743
Valid Loss:  0.19530582427978516
Epoch:  99  	Training Loss: 0.15021458268165588
Test Loss:  0.20177152752876282
Valid Loss:  0.19519667327404022
Epoch:  100  	Training Loss: 0.15012890100479126
Test Loss:  0.20166067779064178
Valid Loss:  0.19508758187294006
Epoch:  101  	Training Loss: 0.1500432789325714
Test Loss:  0.2015499323606491
Valid Loss:  0.19497857987880707
Epoch:  102  	Training Loss: 0.14995771646499634
Test Loss:  0.20143893361091614
Valid Loss:  0.19486939907073975
Epoch:  103  	Training Loss: 0.14987193048000336
Test Loss:  0.20132799446582794
Valid Loss:  0.194760262966156
Epoch:  104  	Training Loss: 0.14978623390197754
Test Loss:  0.2012171447277069
Valid Loss:  0.19465118646621704
Epoch:  105  	Training Loss: 0.14970055222511292
Test Loss:  0.20110633969306946
Valid Loss:  0.19454216957092285
Epoch:  106  	Training Loss: 0.14961495995521545
Test Loss:  0.20099562406539917
Valid Loss:  0.19443325698375702
Epoch:  107  	Training Loss: 0.14952941238880157
Test Loss:  0.20088498294353485
Valid Loss:  0.19432437419891357
Epoch:  108  	Training Loss: 0.14944392442703247
Test Loss:  0.2007744014263153
Valid Loss:  0.1942155957221985
Epoch:  109  	Training Loss: 0.14935848116874695
Test Loss:  0.20066386461257935
Valid Loss:  0.19410686194896698
Epoch:  110  	Training Loss: 0.1492730975151062
Test Loss:  0.20055344700813293
Valid Loss:  0.19399818778038025
Epoch:  111  	Training Loss: 0.14918777346611023
Test Loss:  0.20044302940368652
Valid Loss:  0.19388961791992188
Epoch:  112  	Training Loss: 0.14910249412059784
Test Loss:  0.2003324329853058
Valid Loss:  0.19378086924552917
Epoch:  113  	Training Loss: 0.14901702105998993
Test Loss:  0.20022185146808624
Valid Loss:  0.19367218017578125
Epoch:  114  	Training Loss: 0.1489315927028656
Test Loss:  0.2001112997531891
Valid Loss:  0.19356349110603333
Epoch:  115  	Training Loss: 0.14884617924690247
Test Loss:  0.2000008225440979
Valid Loss:  0.19345486164093018
Epoch:  116  	Training Loss: 0.1487608253955841
Test Loss:  0.1998903602361679
Valid Loss:  0.1933462917804718
Epoch:  117  	Training Loss: 0.14867547154426575
Test Loss:  0.1997799575328827
Valid Loss:  0.19323775172233582
Epoch:  118  	Training Loss: 0.14859017729759216
Test Loss:  0.19966959953308105
Valid Loss:  0.19312924146652222
Epoch:  119  	Training Loss: 0.14850491285324097
Test Loss:  0.19955924153327942
Valid Loss:  0.1930208057165146
Epoch:  120  	Training Loss: 0.14841967821121216
Test Loss:  0.19944895803928375
Valid Loss:  0.19291236996650696
Epoch:  121  	Training Loss: 0.14833447337150574
Test Loss:  0.19933870434761047
Valid Loss:  0.1928040087223053
Epoch:  122  	Training Loss: 0.1482492983341217
Test Loss:  0.1992289423942566
Valid Loss:  0.19269604980945587
Epoch:  123  	Training Loss: 0.1481645107269287
Test Loss:  0.19911924004554749
Valid Loss:  0.1925881803035736
Epoch:  124  	Training Loss: 0.1480797827243805
Test Loss:  0.19900959730148315
Valid Loss:  0.19248037040233612
Epoch:  125  	Training Loss: 0.14799511432647705
Test Loss:  0.198900043964386
Valid Loss:  0.1923726201057434
Epoch:  126  	Training Loss: 0.147910475730896
Test Loss:  0.1987905502319336
Valid Loss:  0.19226494431495667
Epoch:  127  	Training Loss: 0.1478259265422821
Test Loss:  0.19868114590644836
Valid Loss:  0.19215735793113708
Epoch:  128  	Training Loss: 0.147741436958313
Test Loss:  0.19857178628444672
Valid Loss:  0.19204983115196228
Epoch:  129  	Training Loss: 0.14765697717666626
Test Loss:  0.19846251606941223
Valid Loss:  0.19194236397743225
Epoch:  130  	Training Loss: 0.1475725769996643
Test Loss:  0.19835329055786133
Valid Loss:  0.1918349713087082
Epoch:  131  	Training Loss: 0.14748826622962952
Test Loss:  0.1982441544532776
Valid Loss:  0.1917276233434677
Epoch:  132  	Training Loss: 0.14740398526191711
Test Loss:  0.19813445210456848
Valid Loss:  0.19161982834339142
Epoch:  133  	Training Loss: 0.14731921255588531
Test Loss:  0.19802479445934296
Valid Loss:  0.1915120780467987
Epoch:  134  	Training Loss: 0.1472344994544983
Test Loss:  0.1979152113199234
Valid Loss:  0.19140440225601196
Epoch:  135  	Training Loss: 0.14714983105659485
Test Loss:  0.19780570268630981
Valid Loss:  0.1912968009710312
Epoch:  136  	Training Loss: 0.14706522226333618
Test Loss:  0.197696253657341
Valid Loss:  0.1911892592906952
Epoch:  137  	Training Loss: 0.1469806730747223
Test Loss:  0.19758687913417816
Valid Loss:  0.19108180701732635
Epoch:  138  	Training Loss: 0.14689618349075317
Test Loss:  0.1974775791168213
Valid Loss:  0.1909743994474411
Epoch:  139  	Training Loss: 0.14681173861026764
Test Loss:  0.19736835360527039
Valid Loss:  0.19086706638336182
Epoch:  140  	Training Loss: 0.14672735333442688
Test Loss:  0.19725918769836426
Valid Loss:  0.1907597780227661
Epoch:  141  	Training Loss: 0.1466430276632309
Test Loss:  0.1971500813961029
Valid Loss:  0.19065259397029877
Epoch:  142  	Training Loss: 0.1465587615966797
Test Loss:  0.1970408707857132
Valid Loss:  0.19054532051086426
Epoch:  143  	Training Loss: 0.14647439122200012
Test Loss:  0.19693171977996826
Valid Loss:  0.19043807685375214
Epoch:  144  	Training Loss: 0.14639008045196533
Test Loss:  0.1968226134777069
Valid Loss:  0.19033092260360718
Epoch:  145  	Training Loss: 0.14630581438541412
Test Loss:  0.19671358168125153
Valid Loss:  0.1902238130569458
Epoch:  146  	Training Loss: 0.1462215781211853
Test Loss:  0.19660457968711853
 29%|██▉       | 147/500 [01:43<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:43<01:58,  2.96it/s] 30%|███       | 151/500 [01:49<06:50,  1.18s/it] 31%|███       | 153/500 [01:49<04:53,  1.18it/s] 31%|███       | 155/500 [01:49<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:50<01:54,  2.99it/s] 32%|███▏      | 161/500 [01:56<06:45,  1.20s/it] 33%|███▎      | 163/500 [01:56<04:49,  1.16it/s] 33%|███▎      | 165/500 [01:56<03:28,  1.61it/s] 33%|███▎      | 167/500 [01:56<02:31,  2.19it/s] 34%|███▍      | 169/500 [01:57<01:52,  2.95it/s] 34%|███▍      | 171/500 [02:03<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:03<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:03<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:03<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.00it/s] 36%|███▌      | 181/500 [02:10<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:10<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:10<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:10<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:17<06:04,  1.18s/it] 39%|███▊      | 193/500 [02:17<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:17<03:06,  1.63it/s] 39%|███▉      | 197/500 [02:17<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:17<01:40,  3.00it/s] 40%|████      | 201/500 [02:23<05:50,  1.17s/it] 41%|████      | 203/500 [02:23<04:09,  1.19it/s] 41%|████      | 205/500 [02:24<02:59,  1.65it/s] 41%|████▏     | 207/500 [02:24<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:24<01:36,  3.03it/s] 42%|████▏     | 211/500 [02:30<05:39,  1.17s/it] 43%|████▎     | 213/500 [02:30<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:31<02:06,  2.24it/s]Valid Loss:  0.190116748213768
Epoch:  147  	Training Loss: 0.14613738656044006
Test Loss:  0.1964956372976303
Valid Loss:  0.19000974297523499
Epoch:  148  	Training Loss: 0.1460532546043396
Test Loss:  0.19638675451278687
Valid Loss:  0.18990278244018555
Epoch:  149  	Training Loss: 0.14596915245056152
Test Loss:  0.1962779462337494
Valid Loss:  0.18979589641094208
Epoch:  150  	Training Loss: 0.14588510990142822
Test Loss:  0.19616913795471191
Valid Loss:  0.189689040184021
Epoch:  151  	Training Loss: 0.1458010971546173
Test Loss:  0.1960604339838028
Valid Loss:  0.18958225846290588
Epoch:  152  	Training Loss: 0.14571712911128998
Test Loss:  0.19595277309417725
Valid Loss:  0.18947646021842957
Epoch:  153  	Training Loss: 0.14563396573066711
Test Loss:  0.19584518671035767
Valid Loss:  0.1893707662820816
Epoch:  154  	Training Loss: 0.1455509066581726
Test Loss:  0.19573770463466644
Valid Loss:  0.1892651915550232
Epoch:  155  	Training Loss: 0.14546790719032288
Test Loss:  0.19563031196594238
Valid Loss:  0.18915967643260956
Epoch:  156  	Training Loss: 0.1453849822282791
Test Loss:  0.19552305340766907
Valid Loss:  0.18905425071716309
Epoch:  157  	Training Loss: 0.14530213177204132
Test Loss:  0.19541585445404053
Valid Loss:  0.18894895911216736
Epoch:  158  	Training Loss: 0.1452193558216095
Test Loss:  0.19530875980854034
Valid Loss:  0.1888437122106552
Epoch:  159  	Training Loss: 0.14513665437698364
Test Loss:  0.19520175457000732
Valid Loss:  0.18873858451843262
Epoch:  160  	Training Loss: 0.14505402743816376
Test Loss:  0.19509485363960266
Valid Loss:  0.18863354623317719
Epoch:  161  	Training Loss: 0.14497148990631104
Test Loss:  0.19498801231384277
Valid Loss:  0.18852859735488892
Epoch:  162  	Training Loss: 0.1448889970779419
Test Loss:  0.19487997889518738
Valid Loss:  0.18842251598834991
Epoch:  163  	Training Loss: 0.14480558037757874
Test Loss:  0.19477203488349915
Valid Loss:  0.1883164942264557
Epoch:  164  	Training Loss: 0.14472219347953796
Test Loss:  0.1946641057729721
Valid Loss:  0.18821054697036743
Epoch:  165  	Training Loss: 0.14463889598846436
Test Loss:  0.19455626606941223
Valid Loss:  0.18810462951660156
Epoch:  166  	Training Loss: 0.14455559849739075
Test Loss:  0.19444845616817474
Valid Loss:  0.18799877166748047
Epoch:  167  	Training Loss: 0.14447236061096191
Test Loss:  0.19434070587158203
Valid Loss:  0.18789297342300415
Epoch:  168  	Training Loss: 0.14438916742801666
Test Loss:  0.1942330300807953
Valid Loss:  0.1877872347831726
Epoch:  169  	Training Loss: 0.144306018948555
Test Loss:  0.19412538409233093
Valid Loss:  0.18768152594566345
Epoch:  170  	Training Loss: 0.1442229151725769
Test Loss:  0.19401779770851135
Valid Loss:  0.18757590651512146
Epoch:  171  	Training Loss: 0.1441398710012436
Test Loss:  0.19391028583049774
Valid Loss:  0.18747034668922424
Epoch:  172  	Training Loss: 0.14405685663223267
Test Loss:  0.1938028335571289
Valid Loss:  0.1873648464679718
Epoch:  173  	Training Loss: 0.14397385716438293
Test Loss:  0.19369544088840485
Valid Loss:  0.18725943565368652
Epoch:  174  	Training Loss: 0.14389093220233917
Test Loss:  0.19358813762664795
Valid Loss:  0.1871541142463684
Epoch:  175  	Training Loss: 0.14380806684494019
Test Loss:  0.19348092377185822
Valid Loss:  0.18704885244369507
Epoch:  176  	Training Loss: 0.14372526109218597
Test Loss:  0.19337376952171326
Valid Loss:  0.1869436651468277
Epoch:  177  	Training Loss: 0.14364250004291534
Test Loss:  0.19326668977737427
Valid Loss:  0.18683859705924988
Epoch:  178  	Training Loss: 0.14355981349945068
Test Loss:  0.19315971434116364
Valid Loss:  0.18673355877399445
Epoch:  179  	Training Loss: 0.143477201461792
Test Loss:  0.19305279850959778
Valid Loss:  0.18662860989570618
Epoch:  180  	Training Loss: 0.14339464902877808
Test Loss:  0.1929459571838379
Valid Loss:  0.18652373552322388
Epoch:  181  	Training Loss: 0.14331214129924774
Test Loss:  0.19283920526504517
Valid Loss:  0.18641895055770874
Epoch:  182  	Training Loss: 0.14322970807552338
Test Loss:  0.19273221492767334
Valid Loss:  0.1863139569759369
Epoch:  183  	Training Loss: 0.14314711093902588
Test Loss:  0.19262531399726868
Valid Loss:  0.18620902299880981
Epoch:  184  	Training Loss: 0.14306457340717316
Test Loss:  0.1925184428691864
Valid Loss:  0.1861041635274887
Epoch:  185  	Training Loss: 0.1429820954799652
Test Loss:  0.1924116462469101
Valid Loss:  0.18599933385849
Epoch:  186  	Training Loss: 0.14289964735507965
Test Loss:  0.19230493903160095
Valid Loss:  0.18589462339878082
Epoch:  187  	Training Loss: 0.14281725883483887
Test Loss:  0.1921982765197754
Valid Loss:  0.18578994274139404
Epoch:  188  	Training Loss: 0.14273492991924286
Test Loss:  0.192091703414917
Valid Loss:  0.18568533658981323
Epoch:  189  	Training Loss: 0.14265264570713043
Test Loss:  0.19198516011238098
Valid Loss:  0.1855807900428772
Epoch:  190  	Training Loss: 0.1425704061985016
Test Loss:  0.19187872111797333
Valid Loss:  0.18547631800174713
Epoch:  191  	Training Loss: 0.14248822629451752
Test Loss:  0.19177231192588806
Valid Loss:  0.18537190556526184
Epoch:  192  	Training Loss: 0.14240610599517822
Test Loss:  0.19166618585586548
Valid Loss:  0.18526774644851685
Epoch:  193  	Training Loss: 0.14232423901557922
Test Loss:  0.19156014919281006
Valid Loss:  0.18516364693641663
Epoch:  194  	Training Loss: 0.1422424018383026
Test Loss:  0.19145415723323822
Valid Loss:  0.18505963683128357
Epoch:  195  	Training Loss: 0.14216062426567078
Test Loss:  0.19134822487831116
Valid Loss:  0.1849556267261505
Epoch:  196  	Training Loss: 0.14207887649536133
Test Loss:  0.19124236702919006
Valid Loss:  0.18485170602798462
Epoch:  197  	Training Loss: 0.14199718832969666
Test Loss:  0.19113653898239136
Valid Loss:  0.1847478449344635
Epoch:  198  	Training Loss: 0.14191552996635437
Test Loss:  0.19103074073791504
Valid Loss:  0.18464401364326477
Epoch:  199  	Training Loss: 0.14183393120765686
Test Loss:  0.19092503190040588
Valid Loss:  0.18454024195671082
Epoch:  200  	Training Loss: 0.14175236225128174
Test Loss:  0.1908193677663803
Valid Loss:  0.18443655967712402
Epoch:  201  	Training Loss: 0.1416708528995514
Test Loss:  0.1907137632369995
Valid Loss:  0.18433289229869843
Epoch:  202  	Training Loss: 0.14158937335014343
Test Loss:  0.19060681760311127
Valid Loss:  0.18422801792621613
Epoch:  203  	Training Loss: 0.14150680601596832
Test Loss:  0.1904999315738678
Valid Loss:  0.1841232180595398
Epoch:  204  	Training Loss: 0.1414242684841156
Test Loss:  0.1903931200504303
Valid Loss:  0.18401847779750824
Epoch:  205  	Training Loss: 0.14134180545806885
Test Loss:  0.19028636813163757
Valid Loss:  0.18391376733779907
Epoch:  206  	Training Loss: 0.14125938713550568
Test Loss:  0.19017967581748962
Valid Loss:  0.18380916118621826
Epoch:  207  	Training Loss: 0.14117702841758728
Test Loss:  0.19007304310798645
Valid Loss:  0.18370458483695984
Epoch:  208  	Training Loss: 0.14109469950199127
Test Loss:  0.18996645510196686
Valid Loss:  0.1836000680923462
Epoch:  209  	Training Loss: 0.14101243019104004
Test Loss:  0.18985995650291443
Valid Loss:  0.1834956407546997
Epoch:  210  	Training Loss: 0.1409302055835724
Test Loss:  0.18975350260734558
Valid Loss:  0.1833912432193756
Epoch:  211  	Training Loss: 0.14084802567958832
Test Loss:  0.1896471083164215
Valid Loss:  0.18328693509101868
Epoch:  212  	Training Loss: 0.14076590538024902
Test Loss:  0.18954189121723175
Valid Loss:  0.1831837147474289
Epoch:  213  	Training Loss: 0.14068473875522614
Test Loss:  0.18943676352500916
Valid Loss:  0.1830805540084839
Epoch:  214  	Training Loss: 0.14060360193252563
Test Loss:  0.18933165073394775
Valid Loss:  0.18297746777534485
Epoch:  215  	Training Loss: 0.1405225396156311
Test Loss:  0.18922659754753113
Valid Loss:  0.1828744262456894
Epoch:  216  	Training Loss: 0.14044149219989777
Test Loss:  0.18912160396575928
Valid Loss:  0.18277142941951752
Epoch:  217  	Training Loss: 0.1403605043888092
Test Loss:  0.189016655087471
Valid Loss:  0.18266847729682922
Epoch:  218  	Training Loss: 0.14027956128120422
Test Loss:  0.1889117956161499
Valid Loss:  0.1825655698776245
 44%|████▍     | 219/500 [02:31<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:37<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:37<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:37<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:37<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:37<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:44<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:44<03:47,  1.18it/s] 47%|████▋     | 235/500 [02:44<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:44<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:44<01:27,  2.97it/s] 48%|████▊     | 241/500 [02:51<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:51<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:51<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:51<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.02it/s] 50%|█████     | 251/500 [02:57<04:51,  1.17s/it] 51%|█████     | 253/500 [02:58<03:27,  1.19it/s] 51%|█████     | 255/500 [02:58<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:58<01:48,  2.25it/s] 52%|█████▏    | 259/500 [02:58<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:04<04:40,  1.18s/it] 53%|█████▎    | 263/500 [03:04<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:05<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:05<01:16,  3.00it/s] 54%|█████▍    | 271/500 [03:11<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:11<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:11<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:11<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:12<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:18<04:19,  1.18s/it] 57%|█████▋    | 283/500 [03:18<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:18<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:18<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:18<01:10,  2.99it/s]Epoch:  219  	Training Loss: 0.14019864797592163
Test Loss:  0.18880696594715118
Valid Loss:  0.18246278166770935
Epoch:  220  	Training Loss: 0.14011777937412262
Test Loss:  0.18870216608047485
Valid Loss:  0.1823599934577942
Epoch:  221  	Training Loss: 0.14003697037696838
Test Loss:  0.1885974407196045
Valid Loss:  0.1822572648525238
Epoch:  222  	Training Loss: 0.13995619118213654
Test Loss:  0.18849271535873413
Valid Loss:  0.18215453624725342
Epoch:  223  	Training Loss: 0.1398753821849823
Test Loss:  0.18838806450366974
Valid Loss:  0.1820518970489502
Epoch:  224  	Training Loss: 0.13979464769363403
Test Loss:  0.18828348815441132
Valid Loss:  0.18194931745529175
Epoch:  225  	Training Loss: 0.13971395790576935
Test Loss:  0.18817898631095886
Valid Loss:  0.18184682726860046
Epoch:  226  	Training Loss: 0.13963332772254944
Test Loss:  0.18807455897331238
Valid Loss:  0.18174438178539276
Epoch:  227  	Training Loss: 0.1395527571439743
Test Loss:  0.18797019124031067
Valid Loss:  0.18164204061031342
Epoch:  228  	Training Loss: 0.13947224617004395
Test Loss:  0.18786591291427612
Valid Loss:  0.18153974413871765
Epoch:  229  	Training Loss: 0.13939180970191956
Test Loss:  0.18776170909404755
Valid Loss:  0.18143755197525024
Epoch:  230  	Training Loss: 0.13931141793727875
Test Loss:  0.18765756487846375
Valid Loss:  0.1813354194164276
Epoch:  231  	Training Loss: 0.13923108577728271
Test Loss:  0.1875535249710083
Valid Loss:  0.18123334646224976
Epoch:  232  	Training Loss: 0.13915079832077026
Test Loss:  0.18744945526123047
Valid Loss:  0.18113131821155548
Epoch:  233  	Training Loss: 0.13907058537006378
Test Loss:  0.1873454451560974
Valid Loss:  0.1810293346643448
Epoch:  234  	Training Loss: 0.1389903724193573
Test Loss:  0.18724146485328674
Valid Loss:  0.18092739582061768
Epoch:  235  	Training Loss: 0.1389102041721344
Test Loss:  0.18713751435279846
Valid Loss:  0.18082547187805176
Epoch:  236  	Training Loss: 0.1388300657272339
Test Loss:  0.18703363835811615
Valid Loss:  0.18072360754013062
Epoch:  237  	Training Loss: 0.13874995708465576
Test Loss:  0.18692976236343384
Valid Loss:  0.18062178790569305
Epoch:  238  	Training Loss: 0.13866987824440002
Test Loss:  0.1868259459733963
Valid Loss:  0.18052001297473907
Epoch:  239  	Training Loss: 0.13858985900878906
Test Loss:  0.18672218918800354
Valid Loss:  0.1804182529449463
Epoch:  240  	Training Loss: 0.1385098397731781
Test Loss:  0.18661843240261078
Valid Loss:  0.18031653761863708
Epoch:  241  	Training Loss: 0.13842988014221191
Test Loss:  0.1865147352218628
Valid Loss:  0.18021488189697266
Epoch:  242  	Training Loss: 0.13834993541240692
Test Loss:  0.1864115595817566
Valid Loss:  0.18011370301246643
Epoch:  243  	Training Loss: 0.13827040791511536
Test Loss:  0.18630847334861755
Valid Loss:  0.18001259863376617
Epoch:  244  	Training Loss: 0.13819089531898499
Test Loss:  0.1862054020166397
Valid Loss:  0.1799115240573883
Epoch:  245  	Training Loss: 0.13811147212982178
Test Loss:  0.18610240519046783
Valid Loss:  0.1798105388879776
Epoch:  246  	Training Loss: 0.13803206384181976
Test Loss:  0.18599948287010193
Valid Loss:  0.17970959842205048
Epoch:  247  	Training Loss: 0.13795271515846252
Test Loss:  0.1858966052532196
Valid Loss:  0.17960873246192932
Epoch:  248  	Training Loss: 0.13787341117858887
Test Loss:  0.18579378724098206
Valid Loss:  0.17950791120529175
Epoch:  249  	Training Loss: 0.13779416680335999
Test Loss:  0.18569104373455048
Valid Loss:  0.17940717935562134
Epoch:  250  	Training Loss: 0.13771496713161469
Test Loss:  0.18558835983276367
Valid Loss:  0.17930644750595093
Epoch:  251  	Training Loss: 0.13763581216335297
Test Loss:  0.18548570573329926
Valid Loss:  0.17920581996440887
Epoch:  252  	Training Loss: 0.13755670189857483
Test Loss:  0.18538257479667664
Valid Loss:  0.17910471558570862
Epoch:  253  	Training Loss: 0.13747720420360565
Test Loss:  0.18527951836585999
Valid Loss:  0.17900368571281433
Epoch:  254  	Training Loss: 0.13739773631095886
Test Loss:  0.18517650663852692
Valid Loss:  0.17890271544456482
Epoch:  255  	Training Loss: 0.13731831312179565
Test Loss:  0.18507355451583862
Valid Loss:  0.17880180478096008
Epoch:  256  	Training Loss: 0.13723894953727722
Test Loss:  0.1849706619977951
Valid Loss:  0.17870093882083893
Epoch:  257  	Training Loss: 0.13715964555740356
Test Loss:  0.18486781418323517
Valid Loss:  0.17860014736652374
Epoch:  258  	Training Loss: 0.1370803713798523
Test Loss:  0.1847650557756424
Valid Loss:  0.17849938571453094
Epoch:  259  	Training Loss: 0.1370011568069458
Test Loss:  0.184662327170372
Valid Loss:  0.17839869856834412
Epoch:  260  	Training Loss: 0.1369219720363617
Test Loss:  0.1845596730709076
Valid Loss:  0.17829810082912445
Epoch:  261  	Training Loss: 0.13684284687042236
Test Loss:  0.18445707857608795
Valid Loss:  0.17819753289222717
Epoch:  262  	Training Loss: 0.1367637813091278
Test Loss:  0.18435421586036682
Valid Loss:  0.1780967116355896
Epoch:  263  	Training Loss: 0.13668444752693176
Test Loss:  0.18425138294696808
Valid Loss:  0.177995964884758
Epoch:  264  	Training Loss: 0.1366051882505417
Test Loss:  0.1841486394405365
Valid Loss:  0.17789527773857117
Epoch:  265  	Training Loss: 0.1365259885787964
Test Loss:  0.1840459704399109
Valid Loss:  0.1777946650981903
Epoch:  266  	Training Loss: 0.13644683361053467
Test Loss:  0.18394336104393005
Valid Loss:  0.17769411206245422
Epoch:  267  	Training Loss: 0.13636770844459534
Test Loss:  0.1838407963514328
Valid Loss:  0.17759361863136292
Epoch:  268  	Training Loss: 0.13628867268562317
Test Loss:  0.1837383210659027
Valid Loss:  0.17749319970607758
Epoch:  269  	Training Loss: 0.1362096667289734
Test Loss:  0.1836359202861786
Valid Loss:  0.1773928552865982
Epoch:  270  	Training Loss: 0.13613072037696838
Test Loss:  0.18353356420993805
Valid Loss:  0.17729255557060242
Epoch:  271  	Training Loss: 0.13605184853076935
Test Loss:  0.18343129754066467
Valid Loss:  0.1771923452615738
Epoch:  272  	Training Loss: 0.1359730064868927
Test Loss:  0.18332859873771667
Valid Loss:  0.17709174752235413
Epoch:  273  	Training Loss: 0.13589388132095337
Test Loss:  0.18322595953941345
Valid Loss:  0.17699119448661804
Epoch:  274  	Training Loss: 0.13581477105617523
Test Loss:  0.183123379945755
Valid Loss:  0.17689070105552673
Epoch:  275  	Training Loss: 0.13573572039604187
Test Loss:  0.18302085995674133
Valid Loss:  0.1767902672290802
Epoch:  276  	Training Loss: 0.1356566846370697
Test Loss:  0.18291836977005005
Valid Loss:  0.17668986320495605
Epoch:  277  	Training Loss: 0.1355777233839035
Test Loss:  0.18281596899032593
Valid Loss:  0.17658951878547668
Epoch:  278  	Training Loss: 0.1354987919330597
Test Loss:  0.1827135980129242
Valid Loss:  0.1764892339706421
Epoch:  279  	Training Loss: 0.13541992008686066
Test Loss:  0.18261125683784485
Valid Loss:  0.17638900876045227
Epoch:  280  	Training Loss: 0.135341078042984
Test Loss:  0.18250900506973267
Valid Loss:  0.17628881335258484
Epoch:  281  	Training Loss: 0.13526228070259094
Test Loss:  0.18240678310394287
Valid Loss:  0.17618870735168457
Epoch:  282  	Training Loss: 0.13518351316452026
Test Loss:  0.18230487406253815
Valid Loss:  0.1760888397693634
Epoch:  283  	Training Loss: 0.13510499894618988
Test Loss:  0.182203009724617
Valid Loss:  0.175989031791687
Epoch:  284  	Training Loss: 0.13502651453018188
Test Loss:  0.18210121989250183
Valid Loss:  0.1758892834186554
Epoch:  285  	Training Loss: 0.13494808971881866
Test Loss:  0.18199948966503143
Valid Loss:  0.17578959465026855
Epoch:  286  	Training Loss: 0.13486969470977783
Test Loss:  0.18189778923988342
Valid Loss:  0.1756899654865265
Epoch:  287  	Training Loss: 0.13479137420654297
Test Loss:  0.18179619312286377
Valid Loss:  0.1755903959274292
Epoch:  288  	Training Loss: 0.1347130835056305
Test Loss:  0.1816946417093277
Valid Loss:  0.17549091577529907
Epoch:  289  	Training Loss: 0.1346348524093628
Test Loss:  0.1815931499004364
Valid Loss:  0.17539148032665253
Epoch:  290  	Training Loss: 0.13455668091773987
Test Loss:  0.18149173259735107
Valid Loss:  0.17529210448265076
Epoch:  291  	Training Loss: 0.13447853922843933
 58%|█████▊    | 291/500 [03:25<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:25<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:25<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:25<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:25<01:08,  2.92it/s] 60%|██████    | 301/500 [03:32<03:59,  1.20s/it] 61%|██████    | 303/500 [03:32<02:50,  1.16it/s] 61%|██████    | 305/500 [03:32<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:32<01:28,  2.19it/s] 62%|██████▏   | 309/500 [03:32<01:04,  2.94it/s] 62%|██████▏   | 311/500 [03:39<03:42,  1.17s/it] 63%|██████▎   | 313/500 [03:39<02:37,  1.18it/s] 63%|██████▎   | 315/500 [03:39<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:39<01:21,  2.23it/s] 64%|██████▍   | 319/500 [03:39<01:00,  3.00it/s] 64%|██████▍   | 321/500 [03:45<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:46<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:46<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:46<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:46<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:52<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:52<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:53<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:53<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:53<00:53,  3.01it/s] 68%|██████▊   | 341/500 [03:59<03:07,  1.18s/it] 69%|██████▊   | 343/500 [03:59<02:13,  1.18it/s] 69%|██████▉   | 345/500 [03:59<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:00<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:00<00:50,  3.00it/s] 70%|███████   | 351/500 [04:06<02:55,  1.18s/it] 71%|███████   | 353/500 [04:06<02:04,  1.19it/s] 71%|███████   | 355/500 [04:06<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:06<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:06<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:13<02:43,  1.18s/it]Test Loss:  0.18139034509658813
Valid Loss:  0.17519275844097137
Epoch:  292  	Training Loss: 0.13440045714378357
Test Loss:  0.18128937482833862
Valid Loss:  0.1750938594341278
Epoch:  293  	Training Loss: 0.13432267308235168
Test Loss:  0.18118849396705627
Valid Loss:  0.17499500513076782
Epoch:  294  	Training Loss: 0.13424496352672577
Test Loss:  0.1810876727104187
Valid Loss:  0.174896240234375
Epoch:  295  	Training Loss: 0.13416728377342224
Test Loss:  0.1809869110584259
Valid Loss:  0.17479750514030457
Epoch:  296  	Training Loss: 0.13408967852592468
Test Loss:  0.18088620901107788
Valid Loss:  0.17469888925552368
Epoch:  297  	Training Loss: 0.1340121030807495
Test Loss:  0.18078558146953583
Valid Loss:  0.1746002733707428
Epoch:  298  	Training Loss: 0.1339346021413803
Test Loss:  0.18068501353263855
Valid Loss:  0.17450174689292908
Epoch:  299  	Training Loss: 0.1338571459054947
Test Loss:  0.18058452010154724
Valid Loss:  0.17440330982208252
Epoch:  300  	Training Loss: 0.13377974927425385
Test Loss:  0.1804840862751007
Valid Loss:  0.17430491745471954
Epoch:  301  	Training Loss: 0.1337023824453354
Test Loss:  0.18038369715213776
Valid Loss:  0.17420656979084015
Epoch:  302  	Training Loss: 0.1336250752210617
Test Loss:  0.18028384447097778
Valid Loss:  0.17410871386528015
Epoch:  303  	Training Loss: 0.13354818522930145
Test Loss:  0.180184006690979
Valid Loss:  0.17401088774204254
Epoch:  304  	Training Loss: 0.13347133994102478
Test Loss:  0.18008428812026978
Valid Loss:  0.1739131510257721
Epoch:  305  	Training Loss: 0.1333945393562317
Test Loss:  0.17998459935188293
Valid Loss:  0.17381548881530762
Epoch:  306  	Training Loss: 0.13331779837608337
Test Loss:  0.17988499999046326
Valid Loss:  0.1737179011106491
Epoch:  307  	Training Loss: 0.13324111700057983
Test Loss:  0.17978547513484955
Valid Loss:  0.173620343208313
Epoch:  308  	Training Loss: 0.13316449522972107
Test Loss:  0.17968599498271942
Valid Loss:  0.17352290451526642
Epoch:  309  	Training Loss: 0.1330879181623459
Test Loss:  0.17958661913871765
Valid Loss:  0.17342549562454224
Epoch:  310  	Training Loss: 0.13301141560077667
Test Loss:  0.17948730289936066
Valid Loss:  0.1733281910419464
Epoch:  311  	Training Loss: 0.13293495774269104
Test Loss:  0.17938807606697083
Valid Loss:  0.17323094606399536
Epoch:  312  	Training Loss: 0.132858544588089
Test Loss:  0.17928780615329742
Valid Loss:  0.17313271760940552
Epoch:  313  	Training Loss: 0.13278135657310486
Test Loss:  0.1791875809431076
Valid Loss:  0.17303459346294403
Epoch:  314  	Training Loss: 0.1327042132616043
Test Loss:  0.17908743023872375
Valid Loss:  0.17293646931648254
Epoch:  315  	Training Loss: 0.13262709975242615
Test Loss:  0.1789872795343399
Valid Loss:  0.17283838987350464
Epoch:  316  	Training Loss: 0.13255003094673157
Test Loss:  0.17888721823692322
Valid Loss:  0.1727403998374939
Epoch:  317  	Training Loss: 0.13247300684452057
Test Loss:  0.17878718674182892
Valid Loss:  0.17264243960380554
Epoch:  318  	Training Loss: 0.13239601254463196
Test Loss:  0.1786872148513794
Valid Loss:  0.17254450917243958
Epoch:  319  	Training Loss: 0.13231906294822693
Test Loss:  0.17858728766441345
Valid Loss:  0.17244663834571838
Epoch:  320  	Training Loss: 0.13224217295646667
Test Loss:  0.17848742008209229
Valid Loss:  0.17234882712364197
Epoch:  321  	Training Loss: 0.13216529786586761
Test Loss:  0.1783876121044159
Valid Loss:  0.17225107550621033
Epoch:  322  	Training Loss: 0.13208848237991333
Test Loss:  0.17828816175460815
Valid Loss:  0.17215365171432495
Epoch:  323  	Training Loss: 0.13201192021369934
Test Loss:  0.17818883061408997
Valid Loss:  0.17205633223056793
Epoch:  324  	Training Loss: 0.13193544745445251
Test Loss:  0.17808949947357178
Valid Loss:  0.1719590723514557
Epoch:  325  	Training Loss: 0.13185900449752808
Test Loss:  0.17799028754234314
Valid Loss:  0.17186188697814941
Epoch:  326  	Training Loss: 0.1317826211452484
Test Loss:  0.1778911054134369
Valid Loss:  0.1717647761106491
Epoch:  327  	Training Loss: 0.13170629739761353
Test Loss:  0.1777920424938202
Valid Loss:  0.17166770994663239
Epoch:  328  	Training Loss: 0.13163001835346222
Test Loss:  0.17769300937652588
Valid Loss:  0.17157071828842163
Epoch:  329  	Training Loss: 0.1315537989139557
Test Loss:  0.17759403586387634
Valid Loss:  0.17147380113601685
Epoch:  330  	Training Loss: 0.13147763907909393
Test Loss:  0.17749516665935516
Valid Loss:  0.17137694358825684
Epoch:  331  	Training Loss: 0.13140153884887695
Test Loss:  0.17739634215831757
Valid Loss:  0.1712801456451416
Epoch:  332  	Training Loss: 0.13132548332214355
Test Loss:  0.17729708552360535
Valid Loss:  0.17118296027183533
Epoch:  333  	Training Loss: 0.1312490999698639
Test Loss:  0.1771978884935379
Valid Loss:  0.17108581960201263
Epoch:  334  	Training Loss: 0.13117274641990662
Test Loss:  0.17709875106811523
Valid Loss:  0.17098873853683472
Epoch:  335  	Training Loss: 0.13109645247459412
Test Loss:  0.17699964344501495
Valid Loss:  0.17089170217514038
Epoch:  336  	Training Loss: 0.131020188331604
Test Loss:  0.17690059542655945
Valid Loss:  0.17079471051692963
Epoch:  337  	Training Loss: 0.13094396889209747
Test Loss:  0.17680160701274872
Valid Loss:  0.17069777846336365
Epoch:  338  	Training Loss: 0.13086780905723572
Test Loss:  0.17670266330242157
Valid Loss:  0.17060090601444244
Epoch:  339  	Training Loss: 0.13079166412353516
Test Loss:  0.1766037940979004
Valid Loss:  0.17050409317016602
Epoch:  340  	Training Loss: 0.13071557879447937
Test Loss:  0.1765049397945404
Valid Loss:  0.17040732502937317
Epoch:  341  	Training Loss: 0.13063952326774597
Test Loss:  0.1764061450958252
Valid Loss:  0.1703105866909027
Epoch:  342  	Training Loss: 0.13056352734565735
Test Loss:  0.17630808055400848
Valid Loss:  0.17021456360816956
Epoch:  343  	Training Loss: 0.1304880678653717
Test Loss:  0.17621007561683655
Valid Loss:  0.17011860013008118
Epoch:  344  	Training Loss: 0.13041266798973083
Test Loss:  0.1761121153831482
Valid Loss:  0.17002268135547638
Epoch:  345  	Training Loss: 0.13033731281757355
Test Loss:  0.17601421475410461
Valid Loss:  0.16992682218551636
Epoch:  346  	Training Loss: 0.13026198744773865
Test Loss:  0.1759163737297058
Valid Loss:  0.1698310375213623
Epoch:  347  	Training Loss: 0.13018673658370972
Test Loss:  0.17581859230995178
Valid Loss:  0.16973529756069183
Epoch:  348  	Training Loss: 0.13011151552200317
Test Loss:  0.17572090029716492
Valid Loss:  0.16963961720466614
Epoch:  349  	Training Loss: 0.1300363391637802
Test Loss:  0.17562323808670044
Valid Loss:  0.16954398155212402
Epoch:  350  	Training Loss: 0.12996123731136322
Test Loss:  0.17552566528320312
Valid Loss:  0.16944846510887146
Epoch:  351  	Training Loss: 0.1298861801624298
Test Loss:  0.17542815208435059
Valid Loss:  0.1693529635667801
Epoch:  352  	Training Loss: 0.12981116771697998
Test Loss:  0.17532972991466522
Valid Loss:  0.16925662755966187
Epoch:  353  	Training Loss: 0.12973544001579285
Test Loss:  0.17523139715194702
Valid Loss:  0.1691603660583496
Epoch:  354  	Training Loss: 0.1296597719192505
Test Loss:  0.1751330941915512
Valid Loss:  0.16906416416168213
Epoch:  355  	Training Loss: 0.1295841634273529
Test Loss:  0.17503488063812256
Valid Loss:  0.16896802186965942
Epoch:  356  	Training Loss: 0.1295086145401001
Test Loss:  0.1749367117881775
Valid Loss:  0.1688719391822815
Epoch:  357  	Training Loss: 0.12943309545516968
Test Loss:  0.17483863234519958
Valid Loss:  0.16877591609954834
Epoch:  358  	Training Loss: 0.12935763597488403
Test Loss:  0.17474058270454407
Valid Loss:  0.16867996752262115
Epoch:  359  	Training Loss: 0.12928220629692078
Test Loss:  0.17464259266853333
Valid Loss:  0.16858404874801636
Epoch:  360  	Training Loss: 0.1292068362236023
Test Loss:  0.17454467713832855
Valid Loss:  0.16848820447921753
Epoch:  361  	Training Loss: 0.1291315257549286
Test Loss:  0.17444679141044617
Valid Loss:  0.16839243471622467
Epoch:  362  	Training Loss: 0.12905624508857727
Test Loss:  0.1743498146533966
Valid Loss:  0.1682974398136139
Epoch:  363  	Training Loss: 0.12898164987564087
Test Loss:  0.17425286769866943
Valid Loss:   73%|███████▎  | 363/500 [04:13<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:13<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:13<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:13<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:20<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:20<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:20<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:20<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:20<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:26<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:27<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:27<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:27<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:27<00:37,  3.00it/s] 78%|███████▊  | 391/500 [04:33<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:33<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:34<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:34<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:34<00:33,  3.02it/s] 80%|████████  | 401/500 [04:40<01:57,  1.18s/it] 81%|████████  | 403/500 [04:40<01:22,  1.18it/s] 81%|████████  | 405/500 [04:40<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:41<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:41<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:47<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:47<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:47<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:47<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:47<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:54<01:32,  1.18s/it] 85%|████████▍ | 423/500 [04:54<01:04,  1.18it/s] 85%|████████▌ | 425/500 [04:54<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:54<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:54<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:01<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:01<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:01<00:39,  1.63it/s]0.16820253431797028
Epoch:  364  	Training Loss: 0.12890708446502686
Test Loss:  0.17415596544742584
Valid Loss:  0.16810768842697144
Epoch:  365  	Training Loss: 0.12883260846138
Test Loss:  0.17405912280082703
Valid Loss:  0.16801288723945618
Epoch:  366  	Training Loss: 0.12875816226005554
Test Loss:  0.17396235466003418
Valid Loss:  0.1679181456565857
Epoch:  367  	Training Loss: 0.12868374586105347
Test Loss:  0.1738656759262085
Valid Loss:  0.16782346367835999
Epoch:  368  	Training Loss: 0.12860940396785736
Test Loss:  0.1737689971923828
Valid Loss:  0.16772884130477905
Epoch:  369  	Training Loss: 0.12853509187698364
Test Loss:  0.17367242276668549
Valid Loss:  0.16763430833816528
Epoch:  370  	Training Loss: 0.1284608393907547
Test Loss:  0.17357590794563293
Valid Loss:  0.1675397753715515
Epoch:  371  	Training Loss: 0.12838663160800934
Test Loss:  0.17347942292690277
Valid Loss:  0.1674453318119049
Epoch:  372  	Training Loss: 0.12831246852874756
Test Loss:  0.17338357865810394
Valid Loss:  0.16735148429870605
Epoch:  373  	Training Loss: 0.12823878228664398
Test Loss:  0.17328780889511108
Valid Loss:  0.1672576665878296
Epoch:  374  	Training Loss: 0.12816515564918518
Test Loss:  0.1731920838356018
Valid Loss:  0.1671639382839203
Epoch:  375  	Training Loss: 0.12809157371520996
Test Loss:  0.1730964481830597
Valid Loss:  0.16707026958465576
Epoch:  376  	Training Loss: 0.1280180662870407
Test Loss:  0.17300084233283997
Valid Loss:  0.166976660490036
Epoch:  377  	Training Loss: 0.12794458866119385
Test Loss:  0.1729053258895874
Valid Loss:  0.16688311100006104
Epoch:  378  	Training Loss: 0.12787117063999176
Test Loss:  0.17280985414981842
Valid Loss:  0.16678965091705322
Epoch:  379  	Training Loss: 0.12779781222343445
Test Loss:  0.1727144420146942
Valid Loss:  0.1666962206363678
Epoch:  380  	Training Loss: 0.12772448360919952
Test Loss:  0.17261910438537598
Valid Loss:  0.16660287976264954
Epoch:  381  	Training Loss: 0.12765121459960938
Test Loss:  0.1725238561630249
Valid Loss:  0.16650959849357605
Epoch:  382  	Training Loss: 0.127578005194664
Test Loss:  0.17242774367332458
Valid Loss:  0.1664155125617981
Epoch:  383  	Training Loss: 0.1275041103363037
Test Loss:  0.17233166098594666
Valid Loss:  0.16632147133350372
Epoch:  384  	Training Loss: 0.127430260181427
Test Loss:  0.1722356379032135
Valid Loss:  0.16622748970985413
Epoch:  385  	Training Loss: 0.12735646963119507
Test Loss:  0.1721397042274475
Valid Loss:  0.1661335825920105
Epoch:  386  	Training Loss: 0.12728270888328552
Test Loss:  0.1720438301563263
Valid Loss:  0.16603976488113403
Epoch:  387  	Training Loss: 0.12720903754234314
Test Loss:  0.17194804549217224
Valid Loss:  0.16594599187374115
Epoch:  388  	Training Loss: 0.12713539600372314
Test Loss:  0.17185229063034058
Valid Loss:  0.16585227847099304
Epoch:  389  	Training Loss: 0.12706181406974792
Test Loss:  0.1717565953731537
Valid Loss:  0.16575860977172852
Epoch:  390  	Training Loss: 0.1269882619380951
Test Loss:  0.17166098952293396
Valid Loss:  0.16566503047943115
Epoch:  391  	Training Loss: 0.12691478431224823
Test Loss:  0.17156542837619781
Valid Loss:  0.16557149589061737
Epoch:  392  	Training Loss: 0.12684133648872375
Test Loss:  0.17146992683410645
Valid Loss:  0.16547799110412598
Epoch:  393  	Training Loss: 0.12676799297332764
Test Loss:  0.17137452960014343
Valid Loss:  0.16538459062576294
Epoch:  394  	Training Loss: 0.1266946941614151
Test Loss:  0.1712791919708252
Valid Loss:  0.16529123485088348
Epoch:  395  	Training Loss: 0.12662144005298615
Test Loss:  0.17118389904499054
Valid Loss:  0.1651979386806488
Epoch:  396  	Training Loss: 0.12654824554920197
Test Loss:  0.17108869552612305
Valid Loss:  0.16510474681854248
Epoch:  397  	Training Loss: 0.12647511065006256
Test Loss:  0.17099355161190033
Valid Loss:  0.16501158475875854
Epoch:  398  	Training Loss: 0.12640202045440674
Test Loss:  0.17089848220348358
Valid Loss:  0.16491851210594177
Epoch:  399  	Training Loss: 0.1263289898633957
Test Loss:  0.1708034873008728
Valid Loss:  0.16482551395893097
Epoch:  400  	Training Loss: 0.1262560337781906
Test Loss:  0.1707085520029068
Valid Loss:  0.16473257541656494
Epoch:  401  	Training Loss: 0.12618312239646912
Test Loss:  0.17061369121074677
Valid Loss:  0.1646396815776825
Epoch:  402  	Training Loss: 0.1261102557182312
Test Loss:  0.17051848769187927
Valid Loss:  0.16454648971557617
Epoch:  403  	Training Loss: 0.1260371059179306
Test Loss:  0.17042334377765656
Valid Loss:  0.164453387260437
Epoch:  404  	Training Loss: 0.12596401572227478
Test Loss:  0.1703282594680786
Valid Loss:  0.16436034440994263
Epoch:  405  	Training Loss: 0.12589097023010254
Test Loss:  0.17023323476314545
Valid Loss:  0.16426736116409302
Epoch:  406  	Training Loss: 0.12581796944141388
Test Loss:  0.17013823986053467
Valid Loss:  0.1641744077205658
Epoch:  407  	Training Loss: 0.1257450133562088
Test Loss:  0.17004331946372986
Valid Loss:  0.16408151388168335
Epoch:  408  	Training Loss: 0.1256720870733261
Test Loss:  0.16994845867156982
Valid Loss:  0.16398867964744568
Epoch:  409  	Training Loss: 0.1255992352962494
Test Loss:  0.16985365748405457
Valid Loss:  0.16389591991901398
Epoch:  410  	Training Loss: 0.12552641332149506
Test Loss:  0.1697588860988617
Valid Loss:  0.16380321979522705
Epoch:  411  	Training Loss: 0.1254536360502243
Test Loss:  0.169664204120636
Valid Loss:  0.16371051967144012
Epoch:  412  	Training Loss: 0.12538090348243713
Test Loss:  0.16957072913646698
Valid Loss:  0.16361910104751587
Epoch:  413  	Training Loss: 0.12530910968780518
Test Loss:  0.16947734355926514
Valid Loss:  0.163527712225914
Epoch:  414  	Training Loss: 0.1252373456954956
Test Loss:  0.16938400268554688
Valid Loss:  0.1634363830089569
Epoch:  415  	Training Loss: 0.1251656413078308
Test Loss:  0.16929073631763458
Valid Loss:  0.16334515810012817
Epoch:  416  	Training Loss: 0.1250939965248108
Test Loss:  0.16919752955436707
Valid Loss:  0.1632539927959442
Epoch:  417  	Training Loss: 0.12502239644527435
Test Loss:  0.16910436749458313
Valid Loss:  0.16316285729408264
Epoch:  418  	Training Loss: 0.12495085597038269
Test Loss:  0.16901129484176636
Valid Loss:  0.16307178139686584
Epoch:  419  	Training Loss: 0.12487935274839401
Test Loss:  0.16891828179359436
Valid Loss:  0.1629807949066162
Epoch:  420  	Training Loss: 0.12480790168046951
Test Loss:  0.16882532835006714
Valid Loss:  0.16288985311985016
Epoch:  421  	Training Loss: 0.12473651766777039
Test Loss:  0.1687324345111847
Valid Loss:  0.16279898583889008
Epoch:  422  	Training Loss: 0.12466517090797424
Test Loss:  0.16863887012004852
Valid Loss:  0.16270747780799866
Epoch:  423  	Training Loss: 0.1245933324098587
Test Loss:  0.16854539513587952
Valid Loss:  0.16261601448059082
Epoch:  424  	Training Loss: 0.12452153116464615
Test Loss:  0.1684519350528717
Valid Loss:  0.16252458095550537
Epoch:  425  	Training Loss: 0.12444978207349777
Test Loss:  0.16835859417915344
Valid Loss:  0.16243326663970947
Epoch:  426  	Training Loss: 0.12437810003757477
Test Loss:  0.16826531291007996
Valid Loss:  0.16234198212623596
Epoch:  427  	Training Loss: 0.12430645525455475
Test Loss:  0.16817206144332886
Valid Loss:  0.16225078701972961
Epoch:  428  	Training Loss: 0.12423486262559891
Test Loss:  0.16807886958122253
Valid Loss:  0.16215960681438446
Epoch:  429  	Training Loss: 0.12416331470012665
Test Loss:  0.16798576712608337
Valid Loss:  0.16206851601600647
Epoch:  430  	Training Loss: 0.12409183382987976
Test Loss:  0.1678926944732666
Valid Loss:  0.16197748482227325
Epoch:  431  	Training Loss: 0.12402039021253586
Test Loss:  0.16779974102973938
Valid Loss:  0.161886528134346
Epoch:  432  	Training Loss: 0.12394900619983673
Test Loss:  0.16770732402801514
Valid Loss:  0.16179610788822174
Epoch:  433  	Training Loss: 0.1238781064748764
Test Loss:  0.16761498153209686
Valid Loss:  0.16170576214790344
Epoch:  434  	Training Loss: 0.12380725145339966
Test Loss:  0.16752271354198456
Valid Loss:  0.16161546111106873
Epoch:  435  	Training Loss: 0.1237364262342453
Test Loss:  0.16743047535419464
Valid Loss:  0.16152521967887878
 87%|████████▋ | 437/500 [05:01<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:01<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:08<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:08<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:08<00:23,  2.21it/s] 90%|████████▉ | 449/500 [05:08<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:14<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:15<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:15<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:15<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:15<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:21<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:21<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:22<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:22<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:28<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:28<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:28<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:29<00:06,  3.00it/s] 96%|█████████▌| 481/500 [05:35<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:35<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:35<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:35<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:35<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:42<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:42<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:42<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:42<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:42<00:00,  3.01it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
Epoch:  436  	Training Loss: 0.12366566061973572
Test Loss:  0.1673382967710495
Valid Loss:  0.16143503785133362
Epoch:  437  	Training Loss: 0.12359493970870972
Test Loss:  0.16724616289138794
Valid Loss:  0.16134491562843323
Epoch:  438  	Training Loss: 0.1235242486000061
Test Loss:  0.16715413331985474
Valid Loss:  0.16125482320785522
Epoch:  439  	Training Loss: 0.12345360964536667
Test Loss:  0.16706210374832153
Valid Loss:  0.161164790391922
Epoch:  440  	Training Loss: 0.12338301539421082
Test Loss:  0.1669701635837555
Valid Loss:  0.16107480227947235
Epoch:  441  	Training Loss: 0.12331247329711914
Test Loss:  0.16687825322151184
Valid Loss:  0.16098490357398987
Epoch:  442  	Training Loss: 0.12324195355176926
Test Loss:  0.16678601503372192
Valid Loss:  0.16089467704296112
Epoch:  443  	Training Loss: 0.12317118793725967
Test Loss:  0.16669385135173798
Valid Loss:  0.16080448031425476
Epoch:  444  	Training Loss: 0.12310045957565308
Test Loss:  0.1666017323732376
Valid Loss:  0.16071438789367676
Epoch:  445  	Training Loss: 0.12302977591753006
Test Loss:  0.16650965809822083
Valid Loss:  0.16062429547309875
Epoch:  446  	Training Loss: 0.12295913696289062
Test Loss:  0.16641764342784882
Valid Loss:  0.1605343073606491
Epoch:  447  	Training Loss: 0.12288853526115417
Test Loss:  0.1663256734609604
Valid Loss:  0.16044436395168304
Epoch:  448  	Training Loss: 0.12281797081232071
Test Loss:  0.16623380780220032
Valid Loss:  0.16035445034503937
Epoch:  449  	Training Loss: 0.12274746596813202
Test Loss:  0.16614194214344025
Valid Loss:  0.16026461124420166
Epoch:  450  	Training Loss: 0.12267699837684631
Test Loss:  0.16605016589164734
Valid Loss:  0.16017483174800873
Epoch:  451  	Training Loss: 0.12260659784078598
Test Loss:  0.165958434343338
Valid Loss:  0.16008509695529938
Epoch:  452  	Training Loss: 0.12253621965646744
Test Loss:  0.1658666878938675
Valid Loss:  0.15999534726142883
Epoch:  453  	Training Loss: 0.12246584892272949
Test Loss:  0.16577500104904175
Valid Loss:  0.15990565717220306
Epoch:  454  	Training Loss: 0.12239550054073334
Test Loss:  0.16568335890769958
Valid Loss:  0.15981602668762207
Epoch:  455  	Training Loss: 0.12232521176338196
Test Loss:  0.16559180617332458
Valid Loss:  0.15972644090652466
Epoch:  456  	Training Loss: 0.12225495278835297
Test Loss:  0.16550029814243317
Valid Loss:  0.1596369445323944
Epoch:  457  	Training Loss: 0.12218475341796875
Test Loss:  0.16540884971618652
Valid Loss:  0.15954746305942535
Epoch:  458  	Training Loss: 0.12211460620164871
Test Loss:  0.16531744599342346
Valid Loss:  0.15945805609226227
Epoch:  459  	Training Loss: 0.12204451113939285
Test Loss:  0.16522610187530518
Valid Loss:  0.15936872363090515
Epoch:  460  	Training Loss: 0.12197443842887878
Test Loss:  0.16513481736183167
Valid Loss:  0.159279465675354
Epoch:  461  	Training Loss: 0.12190443277359009
Test Loss:  0.16504360735416412
Valid Loss:  0.15919022262096405
Epoch:  462  	Training Loss: 0.12183447182178497
Test Loss:  0.16495272517204285
Valid Loss:  0.15910129249095917
Epoch:  463  	Training Loss: 0.12176474928855896
Test Loss:  0.16486185789108276
Valid Loss:  0.15901243686676025
Epoch:  464  	Training Loss: 0.12169507145881653
Test Loss:  0.16477108001708984
Valid Loss:  0.15892362594604492
Epoch:  465  	Training Loss: 0.12162543833255768
Test Loss:  0.1646803468465805
Valid Loss:  0.15883490443229675
Epoch:  466  	Training Loss: 0.12155584990978241
Test Loss:  0.16458967328071594
Valid Loss:  0.15874621272087097
Epoch:  467  	Training Loss: 0.12148632109165192
Test Loss:  0.16449905931949615
Valid Loss:  0.15865756571292877
Epoch:  468  	Training Loss: 0.12141682952642441
Test Loss:  0.16440850496292114
Valid Loss:  0.15856900811195374
Epoch:  469  	Training Loss: 0.12134740501642227
Test Loss:  0.1643180102109909
Valid Loss:  0.15848049521446228
Epoch:  470  	Training Loss: 0.12127801030874252
Test Loss:  0.16422757506370544
Valid Loss:  0.158392071723938
Epoch:  471  	Training Loss: 0.12120865285396576
Test Loss:  0.16413719952106476
Valid Loss:  0.15830367803573608
Epoch:  472  	Training Loss: 0.12113936245441437
Test Loss:  0.16404739022254944
Valid Loss:  0.15821582078933716
Epoch:  473  	Training Loss: 0.12107051908969879
Test Loss:  0.1639576554298401
Valid Loss:  0.158128023147583
Epoch:  474  	Training Loss: 0.1210017204284668
Test Loss:  0.16386795043945312
Valid Loss:  0.15804027020931244
Epoch:  475  	Training Loss: 0.12093298137187958
Test Loss:  0.16377831995487213
Valid Loss:  0.15795257687568665
Epoch:  476  	Training Loss: 0.12086426466703415
Test Loss:  0.16368871927261353
Valid Loss:  0.15786495804786682
Epoch:  477  	Training Loss: 0.1207955926656723
Test Loss:  0.1635991930961609
Valid Loss:  0.15777736902236938
Epoch:  478  	Training Loss: 0.12072698026895523
Test Loss:  0.16350974142551422
Valid Loss:  0.15768983960151672
Epoch:  479  	Training Loss: 0.12065839767456055
Test Loss:  0.16342030465602875
Valid Loss:  0.15760238468647003
Epoch:  480  	Training Loss: 0.12058987468481064
Test Loss:  0.16333094239234924
Valid Loss:  0.15751498937606812
Epoch:  481  	Training Loss: 0.12052138149738312
Test Loss:  0.16324162483215332
Valid Loss:  0.1574276089668274
Epoch:  482  	Training Loss: 0.12045294046401978
Test Loss:  0.1631508767604828
Valid Loss:  0.15733888745307922
Epoch:  483  	Training Loss: 0.1203833669424057
Test Loss:  0.16306018829345703
Valid Loss:  0.15725019574165344
Epoch:  484  	Training Loss: 0.12031383812427521
Test Loss:  0.16296952962875366
Valid Loss:  0.15716159343719482
Epoch:  485  	Training Loss: 0.1202443540096283
Test Loss:  0.16287893056869507
Valid Loss:  0.1570730209350586
Epoch:  486  	Training Loss: 0.12017491459846497
Test Loss:  0.16278839111328125
Valid Loss:  0.15698447823524475
Epoch:  487  	Training Loss: 0.12010550498962402
Test Loss:  0.16269788146018982
Valid Loss:  0.15689599514007568
Epoch:  488  	Training Loss: 0.12003614753484726
Test Loss:  0.16260744631290436
Valid Loss:  0.15680758655071259
Epoch:  489  	Training Loss: 0.11996681988239288
Test Loss:  0.16251704096794128
Valid Loss:  0.15671920776367188
Epoch:  490  	Training Loss: 0.11989752948284149
Test Loss:  0.1624266803264618
Valid Loss:  0.15663087368011475
Epoch:  491  	Training Loss: 0.11982829868793488
Test Loss:  0.16233640909194946
Valid Loss:  0.1565425992012024
Epoch:  492  	Training Loss: 0.11975909769535065
Test Loss:  0.16224579513072968
Valid Loss:  0.15645402669906616
Epoch:  493  	Training Loss: 0.11968963593244553
Test Loss:  0.16215522587299347
Valid Loss:  0.15636546909809113
Epoch:  494  	Training Loss: 0.11962022632360458
Test Loss:  0.16206470131874084
Valid Loss:  0.15627697110176086
Epoch:  495  	Training Loss: 0.11955085396766663
Test Loss:  0.161974236369133
Valid Loss:  0.15618854761123657
Epoch:  496  	Training Loss: 0.11948151886463165
Test Loss:  0.16188381612300873
Valid Loss:  0.15610016882419586
Epoch:  497  	Training Loss: 0.11941221356391907
Test Loss:  0.16179344058036804
Valid Loss:  0.15601180493831635
Epoch:  498  	Training Loss: 0.11934296041727066
Test Loss:  0.16170312464237213
Valid Loss:  0.1559234857559204
Epoch:  499  	Training Loss: 0.11927375197410583
Test Loss:  0.161612868309021
Valid Loss:  0.15583527088165283
Epoch:  500  	Training Loss: 0.119204580783844
Test Loss:  0.16152265667915344
Valid Loss:  0.15574707090854645
seed is  13
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:23,  6.30s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:17,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.63it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:27<04:42,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:58,  1.17s/it]  9%|▊         | 43/500 [00:33<06:25,  1.19it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:33<03:21,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:47,  1.17s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:47<08:35,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:08,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:54<08:33,  1.20s/it]Epoch:  1  	Training Loss: 0.04473323002457619
Test Loss:  0.04725441709160805
Valid Loss:  0.05749332159757614
Epoch:  2  	Training Loss: 0.059461675584316254
Test Loss:  4.425889015197754
Valid Loss:  4.167586326599121
Epoch:  3  	Training Loss: 4.099007606506348
Test Loss:  0.039803341031074524
Valid Loss:  0.04458730295300484
Epoch:  4  	Training Loss: 0.036389321088790894
Test Loss:  0.03764434903860092
Valid Loss:  0.042541325092315674
Epoch:  5  	Training Loss: 0.03520306944847107
Test Loss:  0.03596944734454155
Valid Loss:  0.040892958641052246
Epoch:  6  	Training Loss: 0.034238722175359726
Test Loss:  0.0344308465719223
Valid Loss:  0.039371490478515625
Epoch:  7  	Training Loss: 0.033352646976709366
Test Loss:  0.03301475942134857
Valid Loss:  0.03796399384737015
Epoch:  8  	Training Loss: 0.032535452395677567
Test Loss:  0.03170889616012573
Valid Loss:  0.036658983677625656
Epoch:  9  	Training Loss: 0.03177894651889801
Test Loss:  0.030502378940582275
Valid Loss:  0.035446278750896454
Epoch:  10  	Training Loss: 0.031075984239578247
Test Loss:  0.029385482892394066
Valid Loss:  0.03431681916117668
Epoch:  11  	Training Loss: 0.030420320108532906
Test Loss:  0.02834957465529442
Valid Loss:  0.033262547105550766
Epoch:  12  	Training Loss: 0.029806505888700485
Test Loss:  0.02731197327375412
Valid Loss:  0.03218793869018555
Epoch:  13  	Training Loss: 0.029168343171477318
Test Loss:  0.02634483203291893
Valid Loss:  0.031180676072835922
Epoch:  14  	Training Loss: 0.028567619621753693
Test Loss:  0.02544194459915161
Valid Loss:  0.03023485466837883
Epoch:  15  	Training Loss: 0.02800050377845764
Test Loss:  0.024597693234682083
Valid Loss:  0.02934514358639717
Epoch:  16  	Training Loss: 0.027463611215353012
Test Loss:  0.023807048797607422
Valid Loss:  0.02850675955414772
Epoch:  17  	Training Loss: 0.026953937485814095
Test Loss:  0.02306544780731201
Valid Loss:  0.027715366333723068
Epoch:  18  	Training Loss: 0.026468835771083832
Test Loss:  0.022368768230080605
Valid Loss:  0.026967070996761322
Epoch:  19  	Training Loss: 0.026005949825048447
Test Loss:  0.021713297814130783
Valid Loss:  0.026258349418640137
Epoch:  20  	Training Loss: 0.02556319162249565
Test Loss:  0.02109566330909729
Valid Loss:  0.025586023926734924
Epoch:  21  	Training Loss: 0.025138724595308304
Test Loss:  0.020512811839580536
Valid Loss:  0.02494720183312893
Epoch:  22  	Training Loss: 0.024730898439884186
Test Loss:  0.019961334764957428
Valid Loss:  0.02433837577700615
Epoch:  23  	Training Loss: 0.02433748170733452
Test Loss:  0.01943955011665821
Valid Loss:  0.023758232593536377
Epoch:  24  	Training Loss: 0.023957988247275352
Test Loss:  0.018945155665278435
Valid Loss:  0.023204606026411057
Epoch:  25  	Training Loss: 0.023591265082359314
Test Loss:  0.018476050347089767
Valid Loss:  0.0226755328476429
Epoch:  26  	Training Loss: 0.023236285895109177
Test Loss:  0.01803031750023365
Valid Loss:  0.022169213742017746
Epoch:  27  	Training Loss: 0.02289213426411152
Test Loss:  0.017606236040592194
Valid Loss:  0.021684039384126663
Epoch:  28  	Training Loss: 0.022558007389307022
Test Loss:  0.017202217131853104
Valid Loss:  0.021218519657850266
Epoch:  29  	Training Loss: 0.022233175113797188
Test Loss:  0.016816820949316025
Valid Loss:  0.020771317183971405
Epoch:  30  	Training Loss: 0.02191699668765068
Test Loss:  0.01644873432815075
Valid Loss:  0.020341211929917336
Epoch:  31  	Training Loss: 0.021608896553516388
Test Loss:  0.016096746549010277
Valid Loss:  0.019927065819501877
Epoch:  32  	Training Loss: 0.02130836620926857
Test Loss:  0.01576019451022148
Valid Loss:  0.019527675583958626
Epoch:  33  	Training Loss: 0.021014101803302765
Test Loss:  0.01543760672211647
Valid Loss:  0.019142262637615204
Epoch:  34  	Training Loss: 0.020726507529616356
Test Loss:  0.015128055587410927
Valid Loss:  0.018769962713122368
Epoch:  35  	Training Loss: 0.020445220172405243
Test Loss:  0.014830692671239376
Valid Loss:  0.01840999349951744
Epoch:  36  	Training Loss: 0.02016991376876831
Test Loss:  0.01454474963247776
Valid Loss:  0.01806163787841797
Epoch:  37  	Training Loss: 0.019900290295481682
Test Loss:  0.014269508421421051
Valid Loss:  0.017724238336086273
Epoch:  38  	Training Loss: 0.019636083394289017
Test Loss:  0.014004320837557316
Valid Loss:  0.017397189512848854
Epoch:  39  	Training Loss: 0.019377054646611214
Test Loss:  0.013748576864600182
Valid Loss:  0.017079921439290047
Epoch:  40  	Training Loss: 0.019122987985610962
Test Loss:  0.013501718640327454
Valid Loss:  0.01677192561328411
Epoch:  41  	Training Loss: 0.018873682245612144
Test Loss:  0.013263245113193989
Valid Loss:  0.016472725197672844
Epoch:  42  	Training Loss: 0.018628954887390137
Test Loss:  0.013033734634518623
Valid Loss:  0.01618240401148796
Epoch:  43  	Training Loss: 0.018391914665699005
Test Loss:  0.012789426371455193
Valid Loss:  0.01588979735970497
Epoch:  44  	Training Loss: 0.01817477121949196
Test Loss:  0.012538343667984009
Valid Loss:  0.015599207952618599
Epoch:  45  	Training Loss: 0.01796744018793106
Test Loss:  0.012297921814024448
Valid Loss:  0.015318810939788818
Epoch:  46  	Training Loss: 0.017765771597623825
Test Loss:  0.01206233724951744
Valid Loss:  0.015045706182718277
Epoch:  47  	Training Loss: 0.017571866512298584
Test Loss:  0.011826658621430397
Valid Loss:  0.014777678065001965
Epoch:  48  	Training Loss: 0.017385654151439667
Test Loss:  0.011596500873565674
Valid Loss:  0.014517256990075111
Epoch:  49  	Training Loss: 0.017206579446792603
Test Loss:  0.011371809989213943
Valid Loss:  0.014264322817325592
Epoch:  50  	Training Loss: 0.017033439129590988
Test Loss:  0.01115715503692627
Valid Loss:  0.014020641334354877
Epoch:  51  	Training Loss: 0.016865039244294167
Test Loss:  0.010947339236736298
Valid Loss:  0.013783790171146393
Epoch:  52  	Training Loss: 0.01670258492231369
Test Loss:  0.010757192969322205
Valid Loss:  0.013574400916695595
Epoch:  53  	Training Loss: 0.016562946140766144
Test Loss:  0.010574877262115479
Valid Loss:  0.013372126035392284
Epoch:  54  	Training Loss: 0.016427095979452133
Test Loss:  0.01039633434265852
Valid Loss:  0.013175182975828648
Epoch:  55  	Training Loss: 0.01629658229649067
Test Loss:  0.010211149230599403
Valid Loss:  0.012979688122868538
Epoch:  56  	Training Loss: 0.0161717738956213
Test Loss:  0.010034231469035149
Valid Loss:  0.01279146783053875
Epoch:  57  	Training Loss: 0.016050806269049644
Test Loss:  0.009865039959549904
Valid Loss:  0.012610038742423058
Epoch:  58  	Training Loss: 0.01593347266316414
Test Loss:  0.00969981774687767
Valid Loss:  0.012433932162821293
Epoch:  59  	Training Loss: 0.015820275992155075
Test Loss:  0.009535375982522964
Valid Loss:  0.012262701988220215
Epoch:  60  	Training Loss: 0.01571132428944111
Test Loss:  0.009378242306411266
Valid Loss:  0.01209800224751234
Epoch:  61  	Training Loss: 0.015605770982801914
Test Loss:  0.009227925911545753
Valid Loss:  0.011939387768507004
Epoch:  62  	Training Loss: 0.01550336740911007
Test Loss:  0.009085109457373619
Valid Loss:  0.011788150295615196
Epoch:  63  	Training Loss: 0.015404867939651012
Test Loss:  0.00894814170897007
Valid Loss:  0.011643271893262863
Epoch:  64  	Training Loss: 0.015309041365981102
Test Loss:  0.00881664827466011
Valid Loss:  0.011503463611006737
Epoch:  65  	Training Loss: 0.01521570049226284
Test Loss:  0.008690282702445984
Valid Loss:  0.011368407867848873
Epoch:  66  	Training Loss: 0.015125074423849583
Test Loss:  0.008566100150346756
Valid Loss:  0.011236599646508694
Epoch:  67  	Training Loss: 0.015037164092063904
Test Loss:  0.008444137871265411
Valid Loss:  0.01110803335905075
Epoch:  68  	Training Loss: 0.014952351339161396
Test Loss:  0.008324429392814636
Valid Loss:  0.010982712730765343
Epoch:  69  	Training Loss: 0.014870233833789825
Test Loss:  0.008209462277591228
Valid Loss:  0.010861705988645554
Epoch:  70  	Training Loss: 0.014790268614888191
Test Loss:  0.008098939433693886
Valid Loss:  0.010744741186499596
Epoch:  71  	Training Loss: 0.014712408185005188
Test Loss:  0.00799022801220417
Valid Loss:  0.010630594566464424
 15%|█▍        | 73/500 [00:54<06:07,  1.16it/s] 15%|█▌        | 75/500 [00:54<04:24,  1.61it/s] 15%|█▌        | 77/500 [00:54<03:12,  2.20it/s] 16%|█▌        | 79/500 [00:54<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:00<08:13,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:07<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:14<07:51,  1.18s/it] 21%|██        | 103/500 [01:14<05:37,  1.18it/s] 21%|██        | 105/500 [01:14<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:15<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:15<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:21<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:28<07:25,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:35<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:35<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:42<07:11,  1.20s/it]Epoch:  72  	Training Loss: 0.014637084677815437
Test Loss:  0.007885875180363655
Valid Loss:  0.010520472191274166
Epoch:  73  	Training Loss: 0.01456386223435402
Test Loss:  0.007785411551594734
Valid Loss:  0.010413866490125656
Epoch:  74  	Training Loss: 0.01449238508939743
Test Loss:  0.007688597775995731
Valid Loss:  0.010310569778084755
Epoch:  75  	Training Loss: 0.014422543346881866
Test Loss:  0.007595223840326071
Valid Loss:  0.010210390202701092
Epoch:  76  	Training Loss: 0.014354299753904343
Test Loss:  0.00750297587364912
Valid Loss:  0.010112373158335686
Epoch:  77  	Training Loss: 0.014288399368524551
Test Loss:  0.007411935366690159
Valid Loss:  0.01001656148582697
Epoch:  78  	Training Loss: 0.014224627055227757
Test Loss:  0.007324184291064739
Valid Loss:  0.009923679754137993
Epoch:  79  	Training Loss: 0.014162636362016201
Test Loss:  0.007237548474222422
Valid Loss:  0.009832894429564476
Epoch:  80  	Training Loss: 0.014102445915341377
Test Loss:  0.007154026068747044
Valid Loss:  0.009744863957166672
Epoch:  81  	Training Loss: 0.014043677598237991
Test Loss:  0.007071543484926224
Valid Loss:  0.009658834896981716
Epoch:  82  	Training Loss: 0.013986930251121521
Test Loss:  0.006990185007452965
Valid Loss:  0.009574821218848228
Epoch:  83  	Training Loss: 0.013931997120380402
Test Loss:  0.006911799777299166
Valid Loss:  0.009493380784988403
Epoch:  84  	Training Loss: 0.013878397643566132
Test Loss:  0.006836199201643467
Valid Loss:  0.009414365515112877
Epoch:  85  	Training Loss: 0.013826046139001846
Test Loss:  0.006763218902051449
Valid Loss:  0.009337620809674263
Epoch:  86  	Training Loss: 0.013774897903203964
Test Loss:  0.006691014394164085
Valid Loss:  0.009262608364224434
Epoch:  87  	Training Loss: 0.013725461438298225
Test Loss:  0.006621311418712139
Valid Loss:  0.009189741685986519
Epoch:  88  	Training Loss: 0.01367714162915945
Test Loss:  0.006553961429744959
Valid Loss:  0.009118901565670967
Epoch:  89  	Training Loss: 0.013629861176013947
Test Loss:  0.006488828919827938
Valid Loss:  0.00904996320605278
Epoch:  90  	Training Loss: 0.013583562336862087
Test Loss:  0.006425782106816769
Valid Loss:  0.008982825092971325
Epoch:  91  	Training Loss: 0.01353817991912365
Test Loss:  0.006364705041050911
Valid Loss:  0.00891738198697567
Epoch:  92  	Training Loss: 0.013493663631379604
Test Loss:  0.0063046617433428764
Valid Loss:  0.008852648548781872
Epoch:  93  	Training Loss: 0.013449391350150108
Test Loss:  0.006246424745768309
Valid Loss:  0.00878947600722313
Epoch:  94  	Training Loss: 0.01340591348707676
Test Loss:  0.0061914934776723385
Valid Loss:  0.008727782405912876
Epoch:  95  	Training Loss: 0.013363491743803024
Test Loss:  0.006136676296591759
Valid Loss:  0.008667311631143093
Epoch:  96  	Training Loss: 0.013322316110134125
Test Loss:  0.006083601154386997
Valid Loss:  0.008608268573880196
Epoch:  97  	Training Loss: 0.013281873427331448
Test Loss:  0.006032174918800592
Valid Loss:  0.008550580590963364
Epoch:  98  	Training Loss: 0.01324212271720171
Test Loss:  0.005982302129268646
Valid Loss:  0.008494173176586628
Epoch:  99  	Training Loss: 0.013203030452132225
Test Loss:  0.00593390641734004
Valid Loss:  0.008438988588750362
Epoch:  100  	Training Loss: 0.013164563104510307
Test Loss:  0.005886903963983059
Valid Loss:  0.008384963497519493
Epoch:  101  	Training Loss: 0.013127005659043789
Test Loss:  0.005838180426508188
Valid Loss:  0.008331915363669395
Epoch:  102  	Training Loss: 0.013091279193758965
Test Loss:  0.005790473893284798
Valid Loss:  0.008279398083686829
Epoch:  103  	Training Loss: 0.013055633753538132
Test Loss:  0.005744250491261482
Valid Loss:  0.008228055201470852
Epoch:  104  	Training Loss: 0.013020962476730347
Test Loss:  0.005697956308722496
Valid Loss:  0.008177833631634712
Epoch:  105  	Training Loss: 0.012987224385142326
Test Loss:  0.005653131753206253
Valid Loss:  0.008128751069307327
Epoch:  106  	Training Loss: 0.012954279780387878
Test Loss:  0.005608271807432175
Valid Loss:  0.008080782368779182
Epoch:  107  	Training Loss: 0.012922361493110657
Test Loss:  0.005564861465245485
Valid Loss:  0.00803392007946968
Epoch:  108  	Training Loss: 0.012891311198472977
Test Loss:  0.005521439481526613
Valid Loss:  0.007988174445927143
Epoch:  109  	Training Loss: 0.01286113541573286
Test Loss:  0.0054794498719275
Valid Loss:  0.007943492382764816
Epoch:  110  	Training Loss: 0.012831551022827625
Test Loss:  0.005438794381916523
Valid Loss:  0.007899808697402477
Epoch:  111  	Training Loss: 0.012802517972886562
Test Loss:  0.005399409681558609
Valid Loss:  0.007857069373130798
Epoch:  112  	Training Loss: 0.012774007394909859
Test Loss:  0.005360978655517101
Valid Loss:  0.007814871147274971
Epoch:  113  	Training Loss: 0.012745742686092854
Test Loss:  0.005323690362274647
Valid Loss:  0.0077735246159136295
Epoch:  114  	Training Loss: 0.012717950157821178
Test Loss:  0.005287479609251022
Valid Loss:  0.007732989266514778
Epoch:  115  	Training Loss: 0.012690600007772446
Test Loss:  0.005252293311059475
Valid Loss:  0.0076932236552238464
Epoch:  116  	Training Loss: 0.01266390085220337
Test Loss:  0.00521685928106308
Valid Loss:  0.007654410786926746
Epoch:  117  	Training Loss: 0.012638026848435402
Test Loss:  0.005182458087801933
Valid Loss:  0.007616352289915085
Epoch:  118  	Training Loss: 0.01261257752776146
Test Loss:  0.005149033851921558
Valid Loss:  0.007579009979963303
Epoch:  119  	Training Loss: 0.012587528675794601
Test Loss:  0.005116535350680351
Valid Loss:  0.007542351260781288
Epoch:  120  	Training Loss: 0.01256286446005106
Test Loss:  0.005084913223981857
Valid Loss:  0.007506340742111206
Epoch:  121  	Training Loss: 0.012538560666143894
Test Loss:  0.00505412369966507
Valid Loss:  0.007470946293324232
Epoch:  122  	Training Loss: 0.012514603324234486
Test Loss:  0.005023877136409283
Valid Loss:  0.0074356598779559135
Epoch:  123  	Training Loss: 0.012490611523389816
Test Loss:  0.004994392395019531
Valid Loss:  0.007400942966341972
Epoch:  124  	Training Loss: 0.012466943822801113
Test Loss:  0.00496562197804451
Valid Loss:  0.007366773672401905
Epoch:  125  	Training Loss: 0.012443583458662033
Test Loss:  0.004937539808452129
Valid Loss:  0.007333130110055208
Epoch:  126  	Training Loss: 0.012420520186424255
Test Loss:  0.0049101077020168304
Valid Loss:  0.0072999875992536545
Epoch:  127  	Training Loss: 0.012397745624184608
Test Loss:  0.004883102141320705
Valid Loss:  0.007267676759511232
Epoch:  128  	Training Loss: 0.012375941500067711
Test Loss:  0.004857233259826899
Valid Loss:  0.007235870696604252
Epoch:  129  	Training Loss: 0.012354426085948944
Test Loss:  0.004832047503441572
Valid Loss:  0.007204548455774784
Epoch:  130  	Training Loss: 0.012333190068602562
Test Loss:  0.00480751134455204
Valid Loss:  0.007173690479248762
Epoch:  131  	Training Loss: 0.012312221340835094
Test Loss:  0.004783592186868191
Valid Loss:  0.00714327534660697
Epoch:  132  	Training Loss: 0.012291512452065945
Test Loss:  0.004760144744068384
Valid Loss:  0.007112891413271427
Epoch:  133  	Training Loss: 0.012270761653780937
Test Loss:  0.004737259820103645
Valid Loss:  0.0070829251781105995
Epoch:  134  	Training Loss: 0.012250255793333054
Test Loss:  0.004714908078312874
Valid Loss:  0.00705336220562458
Epoch:  135  	Training Loss: 0.012229989282786846
Test Loss:  0.0046930680982768536
Valid Loss:  0.007024186197668314
Epoch:  136  	Training Loss: 0.01220994908362627
Test Loss:  0.004671717993915081
Valid Loss:  0.006995390634983778
Epoch:  137  	Training Loss: 0.012190130539238453
Test Loss:  0.0046508340165019035
Valid Loss:  0.00696695689111948
Epoch:  138  	Training Loss: 0.012170527130365372
Test Loss:  0.004630398005247116
Valid Loss:  0.006938878446817398
Epoch:  139  	Training Loss: 0.012151136994361877
Test Loss:  0.004610386677086353
Valid Loss:  0.00691196508705616
Epoch:  140  	Training Loss: 0.012131951749324799
Test Loss:  0.004590787459164858
Valid Loss:  0.00688675232231617
Epoch:  141  	Training Loss: 0.012112967669963837
Test Loss:  0.004571578465402126
Valid Loss:  0.006862599402666092
Epoch:  142  	Training Loss: 0.012094179168343544 29%|██▊       | 143/500 [01:42<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:42<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:42<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:42<01:59,  2.95it/s] 30%|███       | 151/500 [01:48<06:50,  1.18s/it] 31%|███       | 153/500 [01:49<04:52,  1.18it/s] 31%|███       | 155/500 [01:49<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:55<06:38,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:44,  1.19it/s] 33%|███▎      | 165/500 [01:56<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:56<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:56<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:02<06:30,  1.19s/it] 35%|███▍      | 173/500 [02:02<04:38,  1.17it/s] 35%|███▌      | 175/500 [02:02<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:03<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:03<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:09<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:16<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:16<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.00it/s] 40%|████      | 201/500 [02:23<05:52,  1.18s/it] 41%|████      | 203/500 [02:23<04:11,  1.18it/s] 41%|████      | 205/500 [02:23<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:23<01:37,  3.00it/s] 42%|████▏     | 211/500 [02:30<05:43,  1.19s/it]
Test Loss:  0.004552713595330715
Valid Loss:  0.006838494446128607
Epoch:  143  	Training Loss: 0.012075311504304409
Test Loss:  0.0045342035591602325
Valid Loss:  0.006814713589847088
Epoch:  144  	Training Loss: 0.01205663662403822
Test Loss:  0.0045160395093262196
Valid Loss:  0.006791247054934502
Epoch:  145  	Training Loss: 0.012038148939609528
Test Loss:  0.004498201888054609
Valid Loss:  0.006768088787794113
Epoch:  146  	Training Loss: 0.012019846588373184
Test Loss:  0.004480685573071241
Valid Loss:  0.0067452252842485905
Epoch:  147  	Training Loss: 0.01200172584503889
Test Loss:  0.004463476128876209
Valid Loss:  0.006722657009959221
Epoch:  148  	Training Loss: 0.0119837811216712
Test Loss:  0.0044465623795986176
Valid Loss:  0.0067003704607486725
Epoch:  149  	Training Loss: 0.01196601614356041
Test Loss:  0.00442993501201272
Valid Loss:  0.0066783614456653595
Epoch:  150  	Training Loss: 0.011948425322771072
Test Loss:  0.004413583781570196
Valid Loss:  0.0066566248424351215
Epoch:  151  	Training Loss: 0.011931005865335464
Test Loss:  0.004397498909384012
Valid Loss:  0.006635153666138649
Epoch:  152  	Training Loss: 0.011913754045963287
Test Loss:  0.004381648264825344
Valid Loss:  0.0066137053072452545
Epoch:  153  	Training Loss: 0.011896703392267227
Test Loss:  0.004364994820207357
Valid Loss:  0.006592638790607452
Epoch:  154  	Training Loss: 0.01188025064766407
Test Loss:  0.004348662681877613
Valid Loss:  0.006571853533387184
Epoch:  155  	Training Loss: 0.011863961815834045
Test Loss:  0.004332636948674917
Valid Loss:  0.0065521374344825745
Epoch:  156  	Training Loss: 0.011847838759422302
Test Loss:  0.004316904582083225
Valid Loss:  0.006533169187605381
Epoch:  157  	Training Loss: 0.011831877753138542
Test Loss:  0.004301456734538078
Valid Loss:  0.006514458451420069
Epoch:  158  	Training Loss: 0.011816075071692467
Test Loss:  0.004286282695829868
Valid Loss:  0.006496001034975052
Epoch:  159  	Training Loss: 0.011800428852438927
Test Loss:  0.0042713712900877
Valid Loss:  0.006477788090705872
Epoch:  160  	Training Loss: 0.011785013601183891
Test Loss:  0.0042557320557534695
Valid Loss:  0.0064598144963383675
Epoch:  161  	Training Loss: 0.01177026517689228
Test Loss:  0.004240410402417183
Valid Loss:  0.0064421044662594795
Epoch:  162  	Training Loss: 0.011755668558180332
Test Loss:  0.004225375596433878
Valid Loss:  0.006424550898373127
Epoch:  163  	Training Loss: 0.011741112917661667
Test Loss:  0.004210636951029301
Valid Loss:  0.006407245062291622
Epoch:  164  	Training Loss: 0.011726703494787216
Test Loss:  0.004196180962026119
Valid Loss:  0.006390183232724667
Epoch:  165  	Training Loss: 0.011712439358234406
Test Loss:  0.004181996453553438
Valid Loss:  0.00637446204200387
Epoch:  166  	Training Loss: 0.011698320508003235
Test Loss:  0.0041680727154016495
Valid Loss:  0.006358985789120197
Epoch:  167  	Training Loss: 0.011684341356158257
Test Loss:  0.004154425114393234
Valid Loss:  0.006344029679894447
Epoch:  168  	Training Loss: 0.011670498177409172
Test Loss:  0.004142109304666519
Valid Loss:  0.00633010920137167
Epoch:  169  	Training Loss: 0.01165679655969143
Test Loss:  0.0041300272569060326
Valid Loss:  0.006316402927041054
Epoch:  170  	Training Loss: 0.011643221601843834
Test Loss:  0.004118174780160189
Valid Loss:  0.006302901543676853
Epoch:  171  	Training Loss: 0.011629780754446983
Test Loss:  0.004106537438929081
Valid Loss:  0.006289605982601643
Epoch:  172  	Training Loss: 0.011616471223533154
Test Loss:  0.004095159471035004
Valid Loss:  0.006276450119912624
Epoch:  173  	Training Loss: 0.011603174731135368
Test Loss:  0.004083975218236446
Valid Loss:  0.006263479590415955
Epoch:  174  	Training Loss: 0.011590281501412392
Test Loss:  0.004070906899869442
Valid Loss:  0.006250253412872553
Epoch:  175  	Training Loss: 0.011578204110264778
Test Loss:  0.004058177582919598
Valid Loss:  0.006237281486392021
Epoch:  176  	Training Loss: 0.011566459201276302
Test Loss:  0.0040447525680065155
Valid Loss:  0.006224350072443485
Epoch:  177  	Training Loss: 0.011555039323866367
Test Loss:  0.004031714051961899
Valid Loss:  0.006211691536009312
Epoch:  178  	Training Loss: 0.01154375821352005
Test Loss:  0.004019042011350393
Valid Loss:  0.006199292838573456
Epoch:  179  	Training Loss: 0.011532636359333992
Test Loss:  0.004005728755146265
Valid Loss:  0.006186963990330696
Epoch:  180  	Training Loss: 0.011521963402628899
Test Loss:  0.003992823883891106
Valid Loss:  0.006174909416586161
Epoch:  181  	Training Loss: 0.011511429212987423
Test Loss:  0.0039803036488592625
Valid Loss:  0.006163116078823805
Epoch:  182  	Training Loss: 0.01150107104331255
Test Loss:  0.003967258147895336
Valid Loss:  0.006151506677269936
Epoch:  183  	Training Loss: 0.01149117574095726
Test Loss:  0.003954628482460976
Valid Loss:  0.006140164565294981
Epoch:  184  	Training Loss: 0.01148141734302044
Test Loss:  0.0039423927664756775
Valid Loss:  0.006129077170044184
Epoch:  185  	Training Loss: 0.011471793055534363
Test Loss:  0.003930528648197651
Valid Loss:  0.006118234246969223
Epoch:  186  	Training Loss: 0.01146229449659586
Test Loss:  0.003919016569852829
Valid Loss:  0.006107620894908905
Epoch:  187  	Training Loss: 0.011452920734882355
Test Loss:  0.003907837904989719
Valid Loss:  0.006097224075347185
Epoch:  188  	Training Loss: 0.011443659663200378
Test Loss:  0.003896975889801979
Valid Loss:  0.00608703400939703
Epoch:  189  	Training Loss: 0.01143451128154993
Test Loss:  0.0038864142261445522
Valid Loss:  0.00607704371213913
Epoch:  190  	Training Loss: 0.011425471864640713
Test Loss:  0.0038761398755013943
Valid Loss:  0.006067242007702589
Epoch:  191  	Training Loss: 0.011416533961892128
Test Loss:  0.0038661332800984383
Valid Loss:  0.0060576219111680984
Epoch:  192  	Training Loss: 0.011407698504626751
Test Loss:  0.0038564144633710384
Valid Loss:  0.006048159673810005
Epoch:  193  	Training Loss: 0.011398941278457642
Test Loss:  0.003846936859190464
Valid Loss:  0.006038866005837917
Epoch:  194  	Training Loss: 0.011390278115868568
Test Loss:  0.0038376948796212673
Valid Loss:  0.0060297297313809395
Epoch:  195  	Training Loss: 0.011381704360246658
Test Loss:  0.0038286703638732433
Valid Loss:  0.006020743865519762
Epoch:  196  	Training Loss: 0.011373218148946762
Test Loss:  0.003819858655333519
Valid Loss:  0.006011903751641512
Epoch:  197  	Training Loss: 0.011364844627678394
Test Loss:  0.003810422495007515
Valid Loss:  0.006003150716423988
Epoch:  198  	Training Loss: 0.011356839910149574
Test Loss:  0.0038012387230992317
Valid Loss:  0.005994555540382862
Epoch:  199  	Training Loss: 0.011348925530910492
Test Loss:  0.003792297560721636
Valid Loss:  0.005986114032566547
Epoch:  200  	Training Loss: 0.011341096833348274
Test Loss:  0.003783582942560315
Valid Loss:  0.005977816879749298
Epoch:  201  	Training Loss: 0.011333351954817772
Test Loss:  0.0037750881165266037
Valid Loss:  0.005969661753624678
Epoch:  202  	Training Loss: 0.011325692757964134
Test Loss:  0.003766827518120408
Valid Loss:  0.005961637943983078
Epoch:  203  	Training Loss: 0.01131809689104557
Test Loss:  0.003758764360100031
Valid Loss:  0.005953742656856775
Epoch:  204  	Training Loss: 0.011310596950352192
Test Loss:  0.003750104457139969
Valid Loss:  0.005945953540503979
Epoch:  205  	Training Loss: 0.011303538456559181
Test Loss:  0.00374090438708663
Valid Loss:  0.005938289687037468
Epoch:  206  	Training Loss: 0.011296686716377735
Test Loss:  0.003731988836079836
Valid Loss:  0.005930780433118343
Epoch:  207  	Training Loss: 0.011289927177131176
Test Loss:  0.0037233419716358185
Valid Loss:  0.005923415534198284
Epoch:  208  	Training Loss: 0.011283250525593758
Test Loss:  0.003714950755238533
Valid Loss:  0.005916193127632141
Epoch:  209  	Training Loss: 0.011276657693088055
Test Loss:  0.003706799354404211
Valid Loss:  0.005909103900194168
Epoch:  210  	Training Loss: 0.011270144954323769
Test Loss:  0.0036988763604313135
Valid Loss:  0.005902140401303768
Epoch:  211  	Training Loss: 0.011263705790042877
Test Loss:  0.0036911701317876577
Valid Loss:  0.005895326845347881
 43%|████▎     | 213/500 [02:30<04:05,  1.17it/s] 43%|████▎     | 215/500 [02:30<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:30<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:30<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:36<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:36<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:37<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:37<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:37<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:43<05:20,  1.19s/it] 47%|████▋     | 233/500 [02:43<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:44<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:44<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:44<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:50<05:11,  1.20s/it] 49%|████▊     | 243/500 [02:50<03:42,  1.15it/s] 49%|████▉     | 245/500 [02:51<02:39,  1.60it/s] 49%|████▉     | 247/500 [02:51<01:56,  2.16it/s] 50%|████▉     | 249/500 [02:51<01:26,  2.91it/s] 50%|█████     | 251/500 [02:57<04:56,  1.19s/it] 50%|█████     | 252/500 [02:57<04:07,  1.00it/s] 51%|█████     | 254/500 [02:57<02:49,  1.45it/s] 51%|█████     | 256/500 [02:58<01:58,  2.06it/s] 52%|█████▏    | 258/500 [02:58<01:25,  2.83it/s] 52%|█████▏    | 260/500 [02:58<01:03,  3.78it/s] 52%|█████▏    | 262/500 [03:04<04:34,  1.15s/it] 53%|█████▎    | 264/500 [03:04<03:13,  1.22it/s] 53%|█████▎    | 266/500 [03:04<02:18,  1.69it/s] 54%|█████▎    | 268/500 [03:05<01:40,  2.31it/s] 54%|█████▍    | 270/500 [03:05<01:14,  3.09it/s] 54%|█████▍    | 272/500 [03:11<04:31,  1.19s/it] 55%|█████▍    | 274/500 [03:11<03:12,  1.17it/s] 55%|█████▌    | 276/500 [03:11<02:17,  1.63it/s] 56%|█████▌    | 278/500 [03:11<01:39,  2.23it/s] 56%|█████▌    | 280/500 [03:12<01:13,  3.00it/s]Epoch:  212  	Training Loss: 0.011257339268922806
Test Loss:  0.003683661576360464
Valid Loss:  0.005889087449759245
Epoch:  213  	Training Loss: 0.011251071467995644
Test Loss:  0.0036763479001820087
Valid Loss:  0.00588296540081501
Epoch:  214  	Training Loss: 0.011244868859648705
Test Loss:  0.003669226076453924
Valid Loss:  0.005876957438886166
Epoch:  215  	Training Loss: 0.011238732375204563
Test Loss:  0.0036622798070311546
Valid Loss:  0.005871058441698551
Epoch:  216  	Training Loss: 0.011232760734856129
Test Loss:  0.003654798259958625
Valid Loss:  0.00586520042270422
Epoch:  217  	Training Loss: 0.011227069422602654
Test Loss:  0.0036468354519456625
Valid Loss:  0.0058594015426933765
Epoch:  218  	Training Loss: 0.011221526190638542
Test Loss:  0.0036391252651810646
Valid Loss:  0.005853738635778427
Epoch:  219  	Training Loss: 0.011216061189770699
Test Loss:  0.0036316581536084414
Valid Loss:  0.005848203785717487
Epoch:  220  	Training Loss: 0.011210743337869644
Test Loss:  0.003623740281909704
Valid Loss:  0.005842749960720539
Epoch:  221  	Training Loss: 0.011205567046999931
Test Loss:  0.0036160913296043873
Valid Loss:  0.005837428383529186
Epoch:  222  	Training Loss: 0.011200472712516785
Test Loss:  0.0036087031476199627
Valid Loss:  0.0058322506956756115
Epoch:  223  	Training Loss: 0.011195460334420204
Test Loss:  0.003601551055908203
Valid Loss:  0.005827188957482576
Epoch:  224  	Training Loss: 0.01119051780551672
Test Loss:  0.0035946250427514315
Valid Loss:  0.005822242237627506
Epoch:  225  	Training Loss: 0.011185644194483757
Test Loss:  0.003587913466617465
Valid Loss:  0.00581740215420723
Epoch:  226  	Training Loss: 0.011180834844708443
Test Loss:  0.00358140142634511
Valid Loss:  0.005812660325318575
Epoch:  227  	Training Loss: 0.011176087893545628
Test Loss:  0.0035750786773860455
Valid Loss:  0.005808013491332531
Epoch:  228  	Training Loss: 0.01117139682173729
Test Loss:  0.0035689384676516056
Valid Loss:  0.005803457461297512
Epoch:  229  	Training Loss: 0.011166760697960854
Test Loss:  0.0035629700869321823
Valid Loss:  0.005798984318971634
Epoch:  230  	Training Loss: 0.011162176728248596
Test Loss:  0.003557162592187524
Valid Loss:  0.005794594995677471
Epoch:  231  	Training Loss: 0.011157644912600517
Test Loss:  0.00355151086114347
Valid Loss:  0.005790282040834427
Epoch:  232  	Training Loss: 0.011153160594403744
Test Loss:  0.00354602187871933
Valid Loss:  0.005786043591797352
Epoch:  233  	Training Loss: 0.011148722842335701
Test Loss:  0.0035406718961894512
Valid Loss:  0.005781874060630798
Epoch:  234  	Training Loss: 0.011144326999783516
Test Loss:  0.0035354543942958117
Valid Loss:  0.005777773447334766
Epoch:  235  	Training Loss: 0.01113998144865036
Test Loss:  0.0035303637851029634
Valid Loss:  0.005773737095296383
Epoch:  236  	Training Loss: 0.01113567128777504
Test Loss:  0.0035253921523690224
Valid Loss:  0.005769761744886637
Epoch:  237  	Training Loss: 0.011131403036415577
Test Loss:  0.0035205367021262646
Valid Loss:  0.005765844136476517
Epoch:  238  	Training Loss: 0.011127172969281673
Test Loss:  0.003515788819640875
Valid Loss:  0.005761986598372459
Epoch:  239  	Training Loss: 0.011122982017695904
Test Loss:  0.0035111457109451294
Valid Loss:  0.005758181214332581
Epoch:  240  	Training Loss: 0.011118830181658268
Test Loss:  0.0035066038835793734
Valid Loss:  0.005754430778324604
Epoch:  241  	Training Loss: 0.011114716529846191
Test Loss:  0.003502156585454941
Valid Loss:  0.005750729702413082
Epoch:  242  	Training Loss: 0.011110633611679077
Test Loss:  0.0034978215117007494
Valid Loss:  0.005747083108872175
Epoch:  243  	Training Loss: 0.011106587946414948
Test Loss:  0.0034935728181153536
Valid Loss:  0.005743484012782574
Epoch:  244  	Training Loss: 0.011102577671408653
Test Loss:  0.003489407477900386
Valid Loss:  0.005739932414144278
Epoch:  245  	Training Loss: 0.011098599061369896
Test Loss:  0.0034853213001042604
Valid Loss:  0.005736424587666988
Epoch:  246  	Training Loss: 0.011094653978943825
Test Loss:  0.0034813135862350464
Valid Loss:  0.005732960067689419
Epoch:  247  	Training Loss: 0.011090739630162716
Test Loss:  0.0034773757215589285
Valid Loss:  0.005729536525905132
Epoch:  248  	Training Loss: 0.011086856946349144
Test Loss:  0.003473510267212987
Valid Loss:  0.005726158153265715
Epoch:  249  	Training Loss: 0.011083008721470833
Test Loss:  0.0034697141963988543
Valid Loss:  0.005722817964851856
Epoch:  250  	Training Loss: 0.011079227551817894
Test Loss:  0.003465438960120082
Valid Loss:  0.005719582084566355
Epoch:  251  	Training Loss: 0.011075625196099281
Test Loss:  0.0034612640738487244
Valid Loss:  0.0057163904421031475
Epoch:  252  	Training Loss: 0.01107205543667078
Test Loss:  0.003457192098721862
Valid Loss:  0.005713520105928183
Epoch:  253  	Training Loss: 0.011068535037338734
Test Loss:  0.003453210461884737
Valid Loss:  0.005710769444704056
Epoch:  254  	Training Loss: 0.011065044440329075
Test Loss:  0.003449316369369626
Valid Loss:  0.005708062555640936
Epoch:  255  	Training Loss: 0.011061583645641804
Test Loss:  0.0034455042332410812
Valid Loss:  0.005705400835722685
Epoch:  256  	Training Loss: 0.011058150790631771
Test Loss:  0.0034417707938700914
Valid Loss:  0.00570277776569128
Epoch:  257  	Training Loss: 0.01105475053191185
Test Loss:  0.0034381155855953693
Valid Loss:  0.005700195208191872
Epoch:  258  	Training Loss: 0.011051374487578869
Test Loss:  0.0034345313906669617
Valid Loss:  0.005697650834918022
Epoch:  259  	Training Loss: 0.011048024520277977
Test Loss:  0.0034310193732380867
Valid Loss:  0.005695142783224583
Epoch:  260  	Training Loss: 0.011044703423976898
Test Loss:  0.0034275734797120094
Valid Loss:  0.005692671984434128
Epoch:  261  	Training Loss: 0.011041408404707909
Test Loss:  0.0034241904504597187
Valid Loss:  0.005690235178917646
Epoch:  262  	Training Loss: 0.011038138531148434
Test Loss:  0.003420882858335972
Valid Loss:  0.005687833763659
Epoch:  263  	Training Loss: 0.0110348891466856
Test Loss:  0.003417633008211851
Valid Loss:  0.005685462616384029
Epoch:  264  	Training Loss: 0.011031728237867355
Test Loss:  0.003413937985897064
Valid Loss:  0.005683132912963629
Epoch:  265  	Training Loss: 0.01102868840098381
Test Loss:  0.0034103314392268658
Valid Loss:  0.005680842325091362
Epoch:  266  	Training Loss: 0.011025680229067802
Test Loss:  0.0034068096429109573
Valid Loss:  0.005678586661815643
Epoch:  267  	Training Loss: 0.01102269534021616
Test Loss:  0.003403366543352604
Valid Loss:  0.00567636638879776
Epoch:  268  	Training Loss: 0.011019734665751457
Test Loss:  0.003399998415261507
Valid Loss:  0.00567418010905385
Epoch:  269  	Training Loss: 0.01101679913699627
Test Loss:  0.00339670293033123
Valid Loss:  0.005672025494277477
Epoch:  270  	Training Loss: 0.011013886891305447
Test Loss:  0.003393480321392417
Valid Loss:  0.005669904872775078
Epoch:  271  	Training Loss: 0.01101099792867899
Test Loss:  0.0033903245348483324
Valid Loss:  0.0056678131222724915
Epoch:  272  	Training Loss: 0.011008132249116898
Test Loss:  0.0033872281201183796
Valid Loss:  0.005665746983140707
Epoch:  273  	Training Loss: 0.011005282402038574
Test Loss:  0.003384194802492857
Valid Loss:  0.005663709715008736
Epoch:  274  	Training Loss: 0.011002455838024616
Test Loss:  0.003381219459697604
Valid Loss:  0.00566170085221529
Epoch:  275  	Training Loss: 0.01099964790046215
Test Loss:  0.0033783018589019775
Valid Loss:  0.005659718997776508
Epoch:  276  	Training Loss: 0.010996900498867035
Test Loss:  0.0033749679569154978
Valid Loss:  0.005657793954014778
Epoch:  277  	Training Loss: 0.010994268581271172
Test Loss:  0.003371715545654297
Valid Loss:  0.00565589964389801
Epoch:  278  	Training Loss: 0.010991660878062248
Test Loss:  0.0033685429953038692
Valid Loss:  0.0056542702950537205
Epoch:  279  	Training Loss: 0.010989077389240265
Test Loss:  0.0033654458820819855
Valid Loss:  0.005652676802128553
Epoch:  280  	Training Loss: 0.010986518114805222
Test Loss:  0.003362420480698347
Valid Loss:  0.005651114508509636
Epoch:  281  	Training Loss: 0.01098397746682167
Test Loss:  0.0033594644628465176
Valid Loss:   56%|█████▋    | 282/500 [03:18<04:17,  1.18s/it] 57%|█████▋    | 284/500 [03:18<03:03,  1.18it/s] 57%|█████▋    | 286/500 [03:18<02:11,  1.63it/s] 58%|█████▊    | 288/500 [03:18<01:35,  2.23it/s] 58%|█████▊    | 290/500 [03:18<01:10,  2.98it/s] 58%|█████▊    | 292/500 [03:25<04:09,  1.20s/it] 59%|█████▉    | 294/500 [03:25<02:58,  1.15it/s] 59%|█████▉    | 296/500 [03:25<02:09,  1.58it/s] 60%|█████▉    | 298/500 [03:25<01:33,  2.15it/s] 60%|██████    | 300/500 [03:26<01:09,  2.88it/s] 60%|██████    | 302/500 [03:32<03:58,  1.20s/it] 61%|██████    | 304/500 [03:32<02:49,  1.16it/s] 61%|██████    | 306/500 [03:32<02:01,  1.60it/s] 62%|██████▏   | 308/500 [03:32<01:27,  2.19it/s] 62%|██████▏   | 310/500 [03:32<01:04,  2.95it/s] 62%|██████▏   | 312/500 [03:39<03:44,  1.19s/it] 63%|██████▎   | 314/500 [03:39<02:38,  1.17it/s] 63%|██████▎   | 316/500 [03:39<01:53,  1.62it/s] 64%|██████▎   | 318/500 [03:39<01:22,  2.21it/s] 64%|██████▍   | 320/500 [03:39<01:00,  2.96it/s] 64%|██████▍   | 322/500 [03:46<03:31,  1.19s/it] 65%|██████▍   | 324/500 [03:46<02:31,  1.16it/s] 65%|██████▌   | 326/500 [03:46<01:48,  1.61it/s] 66%|██████▌   | 328/500 [03:46<01:18,  2.19it/s] 66%|██████▌   | 330/500 [03:46<00:57,  2.96it/s] 66%|██████▋   | 332/500 [03:53<03:19,  1.19s/it] 67%|██████▋   | 334/500 [03:53<02:21,  1.18it/s] 67%|██████▋   | 336/500 [03:53<01:40,  1.63it/s] 68%|██████▊   | 338/500 [03:53<01:12,  2.22it/s] 68%|██████▊   | 340/500 [03:53<00:53,  2.99it/s] 68%|██████▊   | 342/500 [04:00<03:08,  1.19s/it] 69%|██████▉   | 344/500 [04:00<02:13,  1.17it/s] 69%|██████▉   | 346/500 [04:00<01:35,  1.62it/s] 70%|██████▉   | 348/500 [04:00<01:08,  2.21it/s] 70%|███████   | 350/500 [04:00<00:50,  2.96it/s]0.005649583414196968
Epoch:  282  	Training Loss: 0.010981460101902485
Test Loss:  0.0033565694466233253
Valid Loss:  0.0056480769999325275
Epoch:  283  	Training Loss: 0.010978955775499344
Test Loss:  0.0033537372946739197
Valid Loss:  0.0056465971283614635
Epoch:  284  	Training Loss: 0.010976467281579971
Test Loss:  0.0033509638160467148
Valid Loss:  0.005645143799483776
Epoch:  285  	Training Loss: 0.01097400113940239
Test Loss:  0.0033482490107417107
Valid Loss:  0.005643718875944614
Epoch:  286  	Training Loss: 0.01097155548632145
Test Loss:  0.0033455893862992525
Valid Loss:  0.0056423163041472435
Epoch:  287  	Training Loss: 0.010969128459692001
Test Loss:  0.003342984477058053
Valid Loss:  0.005640936084091663
Epoch:  288  	Training Loss: 0.010966716334223747
Test Loss:  0.0033404286950826645
Valid Loss:  0.005639578681439161
Epoch:  289  	Training Loss: 0.010964322835206985
Test Loss:  0.003337923437356949
Valid Loss:  0.005638245493173599
Epoch:  290  	Training Loss: 0.010961946099996567
Test Loss:  0.0033354631159454584
Valid Loss:  0.005636931397020817
Epoch:  291  	Training Loss: 0.01095958799123764
Test Loss:  0.0033330488950014114
Valid Loss:  0.0056356405839324
Epoch:  292  	Training Loss: 0.010957245714962482
Test Loss:  0.003330686129629612
Valid Loss:  0.0056343721225857735
Epoch:  293  	Training Loss: 0.010954958386719227
Test Loss:  0.0033279370982199907
Valid Loss:  0.005633110646158457
Epoch:  294  	Training Loss: 0.010952777229249477
Test Loss:  0.0033252525608986616
Valid Loss:  0.005631874781101942
Epoch:  295  	Training Loss: 0.01095065288245678
Test Loss:  0.003322206437587738
Valid Loss:  0.005630656145513058
Epoch:  296  	Training Loss: 0.010948589071631432
Test Loss:  0.003319249488413334
Valid Loss:  0.0056295981630682945
Epoch:  297  	Training Loss: 0.010946549475193024
Test Loss:  0.0033163786865770817
Valid Loss:  0.005628577433526516
Epoch:  298  	Training Loss: 0.010944530367851257
Test Loss:  0.0033135891426354647
Valid Loss:  0.005627588834613562
Epoch:  299  	Training Loss: 0.010942531749606133
Test Loss:  0.0033108768984675407
Valid Loss:  0.005626630038022995
Epoch:  300  	Training Loss: 0.010940552689135075
Test Loss:  0.0033082356676459312
Valid Loss:  0.005625699646770954
Epoch:  301  	Training Loss: 0.010938627645373344
Test Loss:  0.0033052542712539434
Valid Loss:  0.005624730139970779
Epoch:  302  	Training Loss: 0.01093674823641777
Test Loss:  0.0033023396972566843
Valid Loss:  0.005623787175863981
Epoch:  303  	Training Loss: 0.010934875346720219
Test Loss:  0.0032995170913636684
Valid Loss:  0.005622877739369869
Epoch:  304  	Training Loss: 0.010933025740087032
Test Loss:  0.0032967792358249426
Valid Loss:  0.005621996708214283
Epoch:  305  	Training Loss: 0.010931196622550488
Test Loss:  0.0032941224053502083
Valid Loss:  0.005621147342026234
Epoch:  306  	Training Loss: 0.010929384268820286
Test Loss:  0.0032915431074798107
Valid Loss:  0.005620322190225124
Epoch:  307  	Training Loss: 0.0109275933355093
Test Loss:  0.0032890383154153824
Valid Loss:  0.00561952218413353
Epoch:  308  	Training Loss: 0.010925819166004658
Test Loss:  0.0032866010442376137
Valid Loss:  0.005618748255074024
Epoch:  309  	Training Loss: 0.010924061760306358
Test Loss:  0.003284231759607792
Valid Loss:  0.00561799481511116
Epoch:  310  	Training Loss: 0.010922320187091827
Test Loss:  0.00328192301094532
Valid Loss:  0.0056172627955675125
Epoch:  311  	Training Loss: 0.010920591652393341
Test Loss:  0.0032796752639114857
Valid Loss:  0.005616551265120506
Epoch:  312  	Training Loss: 0.010918880812823772
Test Loss:  0.0032774838618934155
Valid Loss:  0.00561585882678628
Epoch:  313  	Training Loss: 0.010917185805737972
Test Loss:  0.0032753474079072475
Valid Loss:  0.005615187343209982
Epoch:  314  	Training Loss: 0.010915504768490791
Test Loss:  0.0032732640393078327
Valid Loss:  0.005614529363811016
Epoch:  315  	Training Loss: 0.010913836769759655
Test Loss:  0.0032712279353290796
Valid Loss:  0.005613888613879681
Epoch:  316  	Training Loss: 0.010912179946899414
Test Loss:  0.0032692381646484137
Valid Loss:  0.005613261368125677
Epoch:  317  	Training Loss: 0.010910537093877792
Test Loss:  0.0032672956585884094
Valid Loss:  0.005612650886178017
Epoch:  318  	Training Loss: 0.010908905416727066
Test Loss:  0.0032653941307216883
Valid Loss:  0.0056120529770851135
Epoch:  319  	Training Loss: 0.010907286778092384
Test Loss:  0.0032635340467095375
Valid Loss:  0.00561146903783083
Epoch:  320  	Training Loss: 0.010905677452683449
Test Loss:  0.0032617133110761642
Valid Loss:  0.005610894877463579
Epoch:  321  	Training Loss: 0.010904079303145409
Test Loss:  0.0032599298283457756
Valid Loss:  0.005610336549580097
Epoch:  322  	Training Loss: 0.01090249139815569
Test Loss:  0.003258182667195797
Valid Loss:  0.00560978427529335
Epoch:  323  	Training Loss: 0.010900910012423992
Test Loss:  0.003256468567997217
Valid Loss:  0.005609242711216211
Epoch:  324  	Training Loss: 0.010899338871240616
Test Loss:  0.0032547879964113235
Valid Loss:  0.005608712323009968
Epoch:  325  	Training Loss: 0.010897776111960411
Test Loss:  0.003253139555454254
Valid Loss:  0.0056081912480294704
Epoch:  326  	Training Loss: 0.010896224528551102
Test Loss:  0.0032515209168195724
Valid Loss:  0.005607680417597294
Epoch:  327  	Training Loss: 0.01089468039572239
Test Loss:  0.0032499306835234165
Valid Loss:  0.005607178434729576
Epoch:  328  	Training Loss: 0.010893147438764572
Test Loss:  0.0032483681570738554
Valid Loss:  0.005606687627732754
Epoch:  329  	Training Loss: 0.010891623795032501
Test Loss:  0.003246832638978958
Valid Loss:  0.005606203339993954
Epoch:  330  	Training Loss: 0.010890108533203602
Test Loss:  0.0032453229650855064
Valid Loss:  0.005605727434158325
Epoch:  331  	Training Loss: 0.010888602584600449
Test Loss:  0.003243837971240282
Valid Loss:  0.005605259910225868
Epoch:  332  	Training Loss: 0.010887103155255318
Test Loss:  0.003242378355935216
Valid Loss:  0.005604802165180445
Epoch:  333  	Training Loss: 0.01088561862707138
Test Loss:  0.003240942722186446
Valid Loss:  0.005604352802038193
Epoch:  334  	Training Loss: 0.01088414154946804
Test Loss:  0.003239527577534318
Valid Loss:  0.005603911820799112
Epoch:  335  	Training Loss: 0.01088267657905817
Test Loss:  0.003238135250285268
Valid Loss:  0.005603476893156767
Epoch:  336  	Training Loss: 0.010881230235099792
Test Loss:  0.0032364127691835165
Valid Loss:  0.005603043362498283
Epoch:  337  	Training Loss: 0.01087985746562481
Test Loss:  0.0032347305677831173
Valid Loss:  0.005602621007710695
Epoch:  338  	Training Loss: 0.010878494940698147
Test Loss:  0.003233089344576001
Valid Loss:  0.005602207500487566
Epoch:  339  	Training Loss: 0.010877140797674656
Test Loss:  0.003231485141441226
Valid Loss:  0.005601800978183746
Epoch:  340  	Training Loss: 0.010875795036554337
Test Loss:  0.0032299167942255735
Valid Loss:  0.005601403769105673
Epoch:  341  	Training Loss: 0.010874457657337189
Test Loss:  0.003228383604437113
Valid Loss:  0.0056010158732533455
Epoch:  342  	Training Loss: 0.010873129591345787
Test Loss:  0.003226878819987178
Valid Loss:  0.005600632168352604
Epoch:  343  	Training Loss: 0.010871807113289833
Test Loss:  0.003225405002012849
Valid Loss:  0.005600257311016321
Epoch:  344  	Training Loss: 0.010870493948459625
Test Loss:  0.003223962616175413
Valid Loss:  0.005599888972938061
Epoch:  345  	Training Loss: 0.010869186371564865
Test Loss:  0.0032225470058619976
Valid Loss:  0.005599528085440397
Epoch:  346  	Training Loss: 0.010867888107895851
Test Loss:  0.0032211611978709698
Valid Loss:  0.005599170923233032
Epoch:  347  	Training Loss: 0.010866595432162285
Test Loss:  0.003219800302758813
Valid Loss:  0.005598822142928839
Epoch:  348  	Training Loss: 0.010865310207009315
Test Loss:  0.00321846641600132
Valid Loss:  0.005598478019237518
Epoch:  349  	Training Loss: 0.010864034295082092
Test Loss:  0.003217156510800123
Valid Loss:  0.0055981408804655075
Epoch:  350  	Training Loss: 0.010862764902412891
Test Loss:  0.0032158708199858665
Valid Loss:  0.005597807466983795
Epoch:  351  	Training Loss: 0.010861500166356564
Test Loss:   70%|███████   | 352/500 [04:06<02:56,  1.19s/it] 71%|███████   | 354/500 [04:07<02:04,  1.17it/s] 71%|███████   | 356/500 [04:07<01:28,  1.62it/s] 72%|███████▏  | 358/500 [04:07<01:04,  2.21it/s] 72%|███████▏  | 360/500 [04:07<00:47,  2.96it/s] 72%|███████▏  | 362/500 [04:13<02:42,  1.18s/it] 73%|███████▎  | 364/500 [04:13<01:55,  1.18it/s] 73%|███████▎  | 366/500 [04:14<01:21,  1.63it/s] 74%|███████▎  | 368/500 [04:14<00:59,  2.23it/s] 74%|███████▍  | 370/500 [04:14<00:43,  3.00it/s] 74%|███████▍  | 372/500 [04:20<02:31,  1.18s/it] 75%|███████▍  | 374/500 [04:20<01:46,  1.18it/s] 75%|███████▌  | 376/500 [04:20<01:15,  1.63it/s] 76%|███████▌  | 378/500 [04:21<00:54,  2.23it/s] 76%|███████▌  | 380/500 [04:21<00:40,  2.98it/s] 76%|███████▋  | 382/500 [04:27<02:20,  1.19s/it] 77%|███████▋  | 384/500 [04:27<01:39,  1.17it/s] 77%|███████▋  | 386/500 [04:27<01:10,  1.62it/s] 78%|███████▊  | 388/500 [04:28<00:50,  2.20it/s] 78%|███████▊  | 390/500 [04:28<00:37,  2.96it/s] 78%|███████▊  | 392/500 [04:34<02:09,  1.20s/it] 79%|███████▉  | 394/500 [04:34<01:31,  1.16it/s] 79%|███████▉  | 396/500 [04:34<01:04,  1.60it/s] 80%|███████▉  | 398/500 [04:34<00:46,  2.19it/s] 80%|████████  | 400/500 [04:35<00:33,  2.96it/s] 80%|████████  | 402/500 [04:41<01:58,  1.21s/it] 81%|████████  | 404/500 [04:41<01:23,  1.15it/s] 81%|████████  | 406/500 [04:41<00:59,  1.59it/s] 82%|████████▏ | 408/500 [04:42<00:42,  2.17it/s] 82%|████████▏ | 410/500 [04:42<00:30,  2.92it/s] 82%|████████▏ | 412/500 [04:48<01:44,  1.19s/it] 83%|████████▎ | 414/500 [04:48<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:48<00:51,  1.62it/s] 84%|████████▎ | 418/500 [04:48<00:37,  2.21it/s] 84%|████████▍ | 420/500 [04:49<00:26,  2.98it/s]0.003214607248082757
Valid Loss:  0.0055974796414375305
Epoch:  352  	Training Loss: 0.010860243812203407
Test Loss:  0.0032133632339537144
Valid Loss:  0.005597154144197702
Epoch:  353  	Training Loss: 0.01085899118334055
Test Loss:  0.003212140640243888
Valid Loss:  0.005596837494522333
Epoch:  354  	Training Loss: 0.010857746936380863
Test Loss:  0.0032109380699694157
Valid Loss:  0.005596524104475975
Epoch:  355  	Training Loss: 0.0108565092086792
Test Loss:  0.003209753893315792
Valid Loss:  0.005596213974058628
Epoch:  356  	Training Loss: 0.010855276137590408
Test Loss:  0.0032085897400975227
Valid Loss:  0.005595911294221878
Epoch:  357  	Training Loss: 0.010854050517082214
Test Loss:  0.003207442117854953
Valid Loss:  0.005595610477030277
Epoch:  358  	Training Loss: 0.010852831415832043
Test Loss:  0.003206313122063875
Valid Loss:  0.005595313850790262
Epoch:  359  	Training Loss: 0.010851617902517319
Test Loss:  0.0032052004244178534
Valid Loss:  0.005595020484179258
Epoch:  360  	Training Loss: 0.01085040532052517
Test Loss:  0.0032041040249168873
Valid Loss:  0.005594730377197266
Epoch:  361  	Training Loss: 0.010849214158952236
Test Loss:  0.0032027005217969418
Valid Loss:  0.005594470538198948
Epoch:  362  	Training Loss: 0.01084808073937893
Test Loss:  0.003201331477612257
Valid Loss:  0.0055942111648619175
Epoch:  363  	Training Loss: 0.010846951976418495
Test Loss:  0.0031999966595321894
Valid Loss:  0.005593957379460335
Epoch:  364  	Training Loss: 0.010845828801393509
Test Loss:  0.0031986914109438658
Valid Loss:  0.005593706853687763
Epoch:  365  	Training Loss: 0.01084471307694912
Test Loss:  0.003197417361661792
Valid Loss:  0.005593458656221628
Epoch:  366  	Training Loss: 0.010843602940440178
Test Loss:  0.0031961710192263126
Valid Loss:  0.0055932169780135155
Epoch:  367  	Training Loss: 0.010842496529221535
Test Loss:  0.0031949514523148537
Valid Loss:  0.00559297576546669
Epoch:  368  	Training Loss: 0.010841399431228638
Test Loss:  0.003193760523572564
Valid Loss:  0.0055927406065166
Epoch:  369  	Training Loss: 0.010840306058526039
Test Loss:  0.0031925910152494907
Valid Loss:  0.0055925059132277966
Epoch:  370  	Training Loss: 0.010839218273758888
Test Loss:  0.0031914482824504375
Valid Loss:  0.005592276807874441
Epoch:  371  	Training Loss: 0.010838141664862633
Test Loss:  0.0031903258059173822
Valid Loss:  0.005592048168182373
Epoch:  372  	Training Loss: 0.010837065987288952
Test Loss:  0.0031892252154648304
Valid Loss:  0.005591826047748327
Epoch:  373  	Training Loss: 0.010836005210876465
Test Loss:  0.0031878375448286533
Valid Loss:  0.005591641645878553
Epoch:  374  	Training Loss: 0.010834986343979836
Test Loss:  0.0031864901538938284
Valid Loss:  0.00559146236628294
Epoch:  375  	Training Loss: 0.010833977721631527
Test Loss:  0.003185178153216839
Valid Loss:  0.005591283086687326
Epoch:  376  	Training Loss: 0.010832972824573517
Test Loss:  0.0031839036382734776
Valid Loss:  0.005591106601059437
Epoch:  377  	Training Loss: 0.010831975378096104
Test Loss:  0.0031826612539589405
Valid Loss:  0.005590932909399271
Epoch:  378  	Training Loss: 0.010830985382199287
Test Loss:  0.0031814503017812967
Valid Loss:  0.00559076014906168
Epoch:  379  	Training Loss: 0.010830000042915344
Test Loss:  0.003180270316079259
Valid Loss:  0.005590589251369238
Epoch:  380  	Training Loss: 0.010829020291566849
Test Loss:  0.0031791208311915398
Valid Loss:  0.00559042114764452
Epoch:  381  	Training Loss: 0.010828047059476376
Test Loss:  0.003177996724843979
Valid Loss:  0.005590252578258514
Epoch:  382  	Training Loss: 0.01082707941532135
Test Loss:  0.0031768984626978636
Valid Loss:  0.005590078420937061
Epoch:  383  	Training Loss: 0.010826107114553452
Test Loss:  0.003175825346261263
Valid Loss:  0.005589907988905907
Epoch:  384  	Training Loss: 0.010825140401721
Test Loss:  0.003174778539687395
Valid Loss:  0.005589740350842476
Epoch:  385  	Training Loss: 0.010824178345501423
Test Loss:  0.0031737538520246744
Valid Loss:  0.005589569918811321
Epoch:  386  	Training Loss: 0.010823221877217293
Test Loss:  0.003172749187797308
Valid Loss:  0.005589401815086603
Epoch:  387  	Training Loss: 0.010822268202900887
Test Loss:  0.0031717659439891577
Valid Loss:  0.00558923464268446
Epoch:  388  	Training Loss: 0.010821320116519928
Test Loss:  0.003170803189277649
Valid Loss:  0.005589068867266178
Epoch:  389  	Training Loss: 0.010820375755429268
Test Loss:  0.00316985952667892
Valid Loss:  0.005588902160525322
Epoch:  390  	Training Loss: 0.01081943605095148
Test Loss:  0.0031689335592091084
Valid Loss:  0.00558873638510704
Epoch:  391  	Training Loss: 0.010818500071763992
Test Loss:  0.0031680255196988583
Valid Loss:  0.0055885715410113335
Epoch:  392  	Training Loss: 0.010817567817866802
Test Loss:  0.0031671314500272274
Valid Loss:  0.00558840949088335
Epoch:  393  	Training Loss: 0.010816642083227634
Test Loss:  0.0031662543769925833
Valid Loss:  0.005588248372077942
Epoch:  394  	Training Loss: 0.010815722867846489
Test Loss:  0.003165392205119133
Valid Loss:  0.005588086321949959
Epoch:  395  	Training Loss: 0.010814804583787918
Test Loss:  0.0031645463313907385
Valid Loss:  0.005587927531450987
Epoch:  396  	Training Loss: 0.01081389095634222
Test Loss:  0.0031637134961783886
Valid Loss:  0.005587768740952015
Epoch:  397  	Training Loss: 0.010812981054186821
Test Loss:  0.0031628943979740143
Valid Loss:  0.005587608553469181
Epoch:  398  	Training Loss: 0.010812073945999146
Test Loss:  0.00316208996810019
Valid Loss:  0.005587450228631496
Epoch:  399  	Training Loss: 0.010811171494424343
Test Loss:  0.003161296248435974
Valid Loss:  0.005587292835116386
Epoch:  400  	Training Loss: 0.01081027090549469
Test Loss:  0.0031605158001184464
Valid Loss:  0.0055871340446174145
Epoch:  401  	Training Loss: 0.01080937311053276
Test Loss:  0.0031597469933331013
Valid Loss:  0.005586976185441017
Epoch:  402  	Training Loss: 0.010808480903506279
Test Loss:  0.003158990992233157
Valid Loss:  0.005586818791925907
Epoch:  403  	Training Loss: 0.010807591490447521
Test Loss:  0.0031582461670041084
Valid Loss:  0.005586662795394659
Epoch:  404  	Training Loss: 0.010806701146066189
Test Loss:  0.003157511353492737
Valid Loss:  0.0055865077301859856
Epoch:  405  	Training Loss: 0.010805819183588028
Test Loss:  0.003156788181513548
Valid Loss:  0.0055863503366708755
Epoch:  406  	Training Loss: 0.010804939083755016
Test Loss:  0.0031560722272843122
Valid Loss:  0.005586196202784777
Epoch:  407  	Training Loss: 0.010804062709212303
Test Loss:  0.0031553669832646847
Valid Loss:  0.005586042068898678
Epoch:  408  	Training Loss: 0.01080318819731474
Test Loss:  0.0031546708196401596
Valid Loss:  0.005585887003690004
Epoch:  409  	Training Loss: 0.010802315548062325
Test Loss:  0.0031539839692413807
Valid Loss:  0.005585734732449055
Epoch:  410  	Training Loss: 0.010801447555422783
Test Loss:  0.0031533055007457733
Valid Loss:  0.005585581995546818
Epoch:  411  	Training Loss: 0.01080058328807354
Test Loss:  0.0031526354141533375
Valid Loss:  0.005585429258644581
Epoch:  412  	Training Loss: 0.010799717158079147
Test Loss:  0.0031519688200205564
Valid Loss:  0.005585276056081057
Epoch:  413  	Training Loss: 0.010798854753375053
Test Loss:  0.0031513108406215906
Valid Loss:  0.005585124250501394
Epoch:  414  	Training Loss: 0.010797994211316109
Test Loss:  0.0031506605446338654
Valid Loss:  0.005584971513599157
Epoch:  415  	Training Loss: 0.010797135531902313
Test Loss:  0.0031500172335654497
Valid Loss:  0.00558482063934207
Epoch:  416  	Training Loss: 0.010796280577778816
Test Loss:  0.003149382071569562
Valid Loss:  0.005584670230746269
Epoch:  417  	Training Loss: 0.010795429348945618
Test Loss:  0.0031487534288316965
Valid Loss:  0.0055845193564891815
Epoch:  418  	Training Loss: 0.010794578120112419
Test Loss:  0.0031481306068599224
Valid Loss:  0.005584370344877243
Epoch:  419  	Training Loss: 0.010793732479214668
Test Loss:  0.0031475145369768143
Valid Loss:  0.0055842213332653046
Epoch:  420  	Training Loss: 0.010792887769639492
Test Loss:  0.003146905219182372
Valid Loss:  0.005584072321653366
 84%|████████▍ | 422/500 [04:55<01:33,  1.20s/it] 85%|████████▍ | 424/500 [04:55<01:05,  1.16it/s] 85%|████████▌ | 426/500 [04:55<00:45,  1.61it/s] 86%|████████▌ | 428/500 [04:55<00:32,  2.20it/s] 86%|████████▌ | 430/500 [04:55<00:23,  2.96it/s] 86%|████████▋ | 432/500 [05:02<01:19,  1.18s/it] 87%|████████▋ | 434/500 [05:02<00:55,  1.19it/s] 87%|████████▋ | 436/500 [05:02<00:39,  1.64it/s] 88%|████████▊ | 438/500 [05:02<00:27,  2.24it/s] 88%|████████▊ | 440/500 [05:02<00:19,  3.01it/s] 88%|████████▊ | 442/500 [05:09<01:08,  1.18s/it] 89%|████████▉ | 444/500 [05:09<00:47,  1.18it/s] 89%|████████▉ | 446/500 [05:09<00:32,  1.64it/s] 90%|████████▉ | 448/500 [05:09<00:23,  2.24it/s] 90%|█████████ | 450/500 [05:09<00:16,  3.00it/s] 90%|█████████ | 452/500 [05:15<00:56,  1.17s/it] 91%|█████████ | 454/500 [05:15<00:38,  1.19it/s] 91%|█████████ | 456/500 [05:16<00:26,  1.65it/s] 92%|█████████▏| 458/500 [05:16<00:18,  2.25it/s] 92%|█████████▏| 460/500 [05:16<00:13,  3.02it/s] 92%|█████████▏| 462/500 [05:22<00:44,  1.17s/it] 93%|█████████▎| 464/500 [05:22<00:30,  1.19it/s] 93%|█████████▎| 466/500 [05:22<00:20,  1.65it/s] 94%|█████████▎| 468/500 [05:23<00:14,  2.25it/s] 94%|█████████▍| 470/500 [05:23<00:09,  3.03it/s] 94%|█████████▍| 472/500 [05:29<00:32,  1.17s/it] 95%|█████████▍| 474/500 [05:29<00:21,  1.20it/s] 95%|█████████▌| 476/500 [05:29<00:14,  1.65it/s] 96%|█████████▌| 478/500 [05:29<00:09,  2.25it/s] 96%|█████████▌| 480/500 [05:29<00:06,  3.02it/s] 96%|█████████▋| 482/500 [05:36<00:21,  1.17s/it] 97%|█████████▋| 484/500 [05:36<00:13,  1.20it/s] 97%|█████████▋| 486/500 [05:36<00:08,  1.65it/s] 98%|█████████▊| 488/500 [05:36<00:05,  2.25it/s]Epoch:  421  	Training Loss: 0.010792046785354614
Test Loss:  0.003146301954984665
Valid Loss:  0.0055839247070252895
Epoch:  422  	Training Loss: 0.010791206732392311
Test Loss:  0.003145702416077256
Valid Loss:  0.005583778955042362
Epoch:  423  	Training Loss: 0.01079037319868803
Test Loss:  0.003145109862089157
Valid Loss:  0.005583633203059435
Epoch:  424  	Training Loss: 0.010789540596306324
Test Loss:  0.0031445203348994255
Valid Loss:  0.005583490245044231
Epoch:  425  	Training Loss: 0.010788710787892342
Test Loss:  0.0031439398881047964
Valid Loss:  0.005583439487963915
Epoch:  426  	Training Loss: 0.010787885636091232
Test Loss:  0.0031433638650923967
Valid Loss:  0.005583400838077068
Epoch:  427  	Training Loss: 0.010787062346935272
Test Loss:  0.003142792731523514
Valid Loss:  0.00558336079120636
Epoch:  428  	Training Loss: 0.010786239057779312
Test Loss:  0.0031422250904142857
Valid Loss:  0.005583322606980801
Epoch:  429  	Training Loss: 0.01078541949391365
Test Loss:  0.00314166396856308
Valid Loss:  0.005583285354077816
Epoch:  430  	Training Loss: 0.010784601792693138
Test Loss:  0.0031411079689860344
Valid Loss:  0.005583248566836119
Epoch:  431  	Training Loss: 0.010783787816762924
Test Loss:  0.003140556626021862
Valid Loss:  0.005583209916949272
Epoch:  432  	Training Loss: 0.01078297570347786
Test Loss:  0.003140009008347988
Valid Loss:  0.005583173595368862
Epoch:  433  	Training Loss: 0.010782165452837944
Test Loss:  0.0031394651159644127
Valid Loss:  0.0055831377394497395
Epoch:  434  	Training Loss: 0.010781358927488327
Test Loss:  0.003138927975669503
Valid Loss:  0.005583100486546755
Epoch:  435  	Training Loss: 0.01078055240213871
Test Loss:  0.003138393396511674
Valid Loss:  0.005583065561950207
Epoch:  436  	Training Loss: 0.010779749602079391
Test Loss:  0.0031378634739667177
Valid Loss:  0.005583029240369797
Epoch:  437  	Training Loss: 0.010778949595987797
Test Loss:  0.0031373377423733473
Valid Loss:  0.005582992918789387
Epoch:  438  	Training Loss: 0.010778151452541351
Test Loss:  0.0031368162017315626
Valid Loss:  0.005582958459854126
Epoch:  439  	Training Loss: 0.01077735424041748
Test Loss:  0.00313629861921072
Valid Loss:  0.00558292493224144
Epoch:  440  	Training Loss: 0.010776562616229057
Test Loss:  0.003135784761980176
Valid Loss:  0.005582890938967466
Epoch:  441  	Training Loss: 0.01077577006071806
Test Loss:  0.0031352760270237923
Valid Loss:  0.0055828578770160675
Epoch:  442  	Training Loss: 0.010774980299174786
Test Loss:  0.003134769620373845
Valid Loss:  0.005582819692790508
Epoch:  443  	Training Loss: 0.010774191468954086
Test Loss:  0.0031342669390141964
Valid Loss:  0.005582783371210098
Epoch:  444  	Training Loss: 0.010773401707410812
Test Loss:  0.0031337670516222715
Valid Loss:  0.005582747049629688
Epoch:  445  	Training Loss: 0.010772614739835262
Test Loss:  0.0031332727521657944
Valid Loss:  0.005582709331065416
Epoch:  446  	Training Loss: 0.010771828703582287
Test Loss:  0.0031327810138463974
Valid Loss:  0.005582675337791443
Epoch:  447  	Training Loss: 0.010771045461297035
Test Loss:  0.0031322925351560116
Valid Loss:  0.005582637153565884
Epoch:  448  	Training Loss: 0.010770265012979507
Test Loss:  0.0031318070832639933
Valid Loss:  0.005582604557275772
Epoch:  449  	Training Loss: 0.01076948456466198
Test Loss:  0.003131324891000986
Valid Loss:  0.005582569167017937
Epoch:  450  	Training Loss: 0.01076870784163475
Test Loss:  0.0031308471225202084
Valid Loss:  0.005582532845437527
Epoch:  451  	Training Loss: 0.010767933912575245
Test Loss:  0.00313037121668458
Valid Loss:  0.005582498852163553
Epoch:  452  	Training Loss: 0.010767160914838314
Test Loss:  0.0031298978719860315
Valid Loss:  0.00558246998116374
Epoch:  453  	Training Loss: 0.010766400955617428
Test Loss:  0.0031294282525777817
Valid Loss:  0.005582442507147789
Epoch:  454  	Training Loss: 0.01076564285904169
Test Loss:  0.003128960495814681
Valid Loss:  0.005582415498793125
Epoch:  455  	Training Loss: 0.010764887556433678
Test Loss:  0.0031284973956644535
Valid Loss:  0.005582388490438461
Epoch:  456  	Training Loss: 0.01076413318514824
Test Loss:  0.003128036856651306
Valid Loss:  0.005582361947745085
Epoch:  457  	Training Loss: 0.010763381607830524
Test Loss:  0.0031275786459445953
Valid Loss:  0.005582333542406559
Epoch:  458  	Training Loss: 0.010762631893157959
Test Loss:  0.0031271246261894703
Valid Loss:  0.005582308396697044
Epoch:  459  	Training Loss: 0.010761883109807968
Test Loss:  0.003126672701910138
Valid Loss:  0.0055822813883423805
Epoch:  460  	Training Loss: 0.010761137120425701
Test Loss:  0.003126225434243679
Valid Loss:  0.005582254845649004
Epoch:  461  	Training Loss: 0.010760392993688583
Test Loss:  0.0031257790978997946
Valid Loss:  0.00558222783729434
Epoch:  462  	Training Loss: 0.010759647935628891
Test Loss:  0.0031253336928784847
Valid Loss:  0.00558219850063324
Epoch:  463  	Training Loss: 0.010758901946246624
Test Loss:  0.0031248913146555424
Valid Loss:  0.005582168698310852
Epoch:  464  	Training Loss: 0.010758157819509506
Test Loss:  0.00312445149756968
Valid Loss:  0.005582139827311039
Epoch:  465  	Training Loss: 0.010757416486740112
Test Loss:  0.0031240140087902546
Valid Loss:  0.005582110956311226
Epoch:  466  	Training Loss: 0.010756676085293293
Test Loss:  0.0031235800124704838
Valid Loss:  0.005582083947956562
Epoch:  467  	Training Loss: 0.010755937546491623
Test Loss:  0.0031231495086103678
Valid Loss:  0.005582054611295462
Epoch:  468  	Training Loss: 0.010755199939012527
Test Loss:  0.0031227199360728264
Valid Loss:  0.005582027602940798
Epoch:  469  	Training Loss: 0.01075446605682373
Test Loss:  0.0031222947873175144
Valid Loss:  0.005581999197602272
Epoch:  470  	Training Loss: 0.010753733105957508
Test Loss:  0.003121870569884777
Valid Loss:  0.005581969860941172
Epoch:  471  	Training Loss: 0.01075300294905901
Test Loss:  0.0031214957125484943
Valid Loss:  0.005581941455602646
Epoch:  472  	Training Loss: 0.010752272792160511
Test Loss:  0.0031211618334054947
Valid Loss:  0.005581914447247982
Epoch:  473  	Training Loss: 0.010751545429229736
Test Loss:  0.003120830049738288
Valid Loss:  0.005581886973232031
Epoch:  474  	Training Loss: 0.010750818997621536
Test Loss:  0.003120499663054943
Valid Loss:  0.005581858567893505
Epoch:  475  	Training Loss: 0.010750096291303635
Test Loss:  0.0031201732344925404
Valid Loss:  0.005581831559538841
Epoch:  476  	Training Loss: 0.010749377310276031
Test Loss:  0.0031198475044220686
Valid Loss:  0.005581805016845465
Epoch:  477  	Training Loss: 0.010748656466603279
Test Loss:  0.0031195241026580334
Valid Loss:  0.005581776611506939
Epoch:  478  	Training Loss: 0.010747939348220825
Test Loss:  0.0031192032620310783
Valid Loss:  0.0055817486718297005
Epoch:  479  	Training Loss: 0.010747221298515797
Test Loss:  0.0031188835855573416
Valid Loss:  0.005581721663475037
Epoch:  480  	Training Loss: 0.010746506974101067
Test Loss:  0.0031185662373900414
Valid Loss:  0.00558169512078166
Epoch:  481  	Training Loss: 0.010745799168944359
Test Loss:  0.003117951098829508
Valid Loss:  0.005581699311733246
Epoch:  482  	Training Loss: 0.010745115578174591
Test Loss:  0.0031173531897366047
Valid Loss:  0.005581702571362257
Epoch:  483  	Training Loss: 0.010744432918727398
Test Loss:  0.0031167701818048954
Valid Loss:  0.005581705365329981
Epoch:  484  	Training Loss: 0.010743753053247929
Test Loss:  0.0031162025406956673
Valid Loss:  0.005581703968346119
Epoch:  485  	Training Loss: 0.010743075981736183
Test Loss:  0.0031156521290540695
Valid Loss:  0.005581702571362257
Epoch:  486  	Training Loss: 0.010742400772869587
Test Loss:  0.00311511498875916
Valid Loss:  0.005581699311733246
Epoch:  487  	Training Loss: 0.01074172742664814
Test Loss:  0.003114602528512478
Valid Loss:  0.0055816941894590855
Epoch:  488  	Training Loss: 0.010741055011749268
Test Loss:  0.0031141326762735844
Valid Loss:  0.005581687204539776
Epoch:  489  	Training Loss: 0.01074038352817297
Test Loss:  0.003113678190857172
Valid Loss:  0.005581678356975317
Epoch:  490  	Training Loss: 0.010739714838564396
Test Loss:  0.0031132358126342297
 98%|█████████▊| 490/500 [05:36<00:03,  3.01it/s] 98%|█████████▊| 492/500 [05:43<00:09,  1.19s/it] 99%|█████████▉| 494/500 [05:43<00:05,  1.18it/s] 99%|█████████▉| 496/500 [05:43<00:02,  1.63it/s]100%|█████████▉| 498/500 [05:43<00:00,  2.22it/s]100%|██████████| 500/500 [05:43<00:00,  2.98it/s]100%|██████████| 500/500 [05:43<00:00,  1.46it/s]
Valid Loss:  0.005581679288297892
Epoch:  491  	Training Loss: 0.010739048942923546
Test Loss:  0.0031128069385886192
Valid Loss:  0.005581713281571865
Epoch:  492  	Training Loss: 0.010738383047282696
Test Loss:  0.003112390171736479
Valid Loss:  0.00558174354955554
Epoch:  493  	Training Loss: 0.01073771808296442
Test Loss:  0.0031119827181100845
Valid Loss:  0.0055817728862166405
Epoch:  494  	Training Loss: 0.010737055912613869
Test Loss:  0.0031115859746932983
Valid Loss:  0.005581802688539028
Epoch:  495  	Training Loss: 0.010736393742263317
Test Loss:  0.0031112004071474075
Valid Loss:  0.005581830162554979
Epoch:  496  	Training Loss: 0.010735733434557915
Test Loss:  0.003110824152827263
Valid Loss:  0.005581858567893505
Epoch:  497  	Training Loss: 0.010735074058175087
Test Loss:  0.0031104583758860826
Valid Loss:  0.005581884644925594
Epoch:  498  	Training Loss: 0.010734416544437408
Test Loss:  0.0031101005151867867
Valid Loss:  0.005581910256296396
Epoch:  499  	Training Loss: 0.010733759962022305
Test Loss:  0.0031097515020519495
Valid Loss:  0.005581935402005911
Epoch:  500  	Training Loss: 0.010733104310929775
Test Loss:  0.003109411336481571
Valid Loss:  0.005581958219408989
seed is  14
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:01,  6.26s/it]  1%|          | 3/500 [00:06<13:52,  1.67s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.02it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:49,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.98it/s]  6%|▌         | 31/500 [00:26<09:14,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:26<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<09:07,  1.19s/it]  9%|▊         | 43/500 [00:33<06:31,  1.17it/s]  9%|▉         | 45/500 [00:33<04:43,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:40<08:59,  1.20s/it] 11%|█         | 53/500 [00:40<06:25,  1.16it/s] 11%|█         | 55/500 [00:40<04:37,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.96it/s] 12%|█▏        | 61/500 [00:47<08:40,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.97it/s]Epoch:  1  	Training Loss: 0.240797758102417
Test Loss:  0.1689731776714325
Valid Loss:  0.1632373034954071
Epoch:  2  	Training Loss: 0.12599268555641174
Test Loss:  0.09294299781322479
Valid Loss:  0.09182590246200562
Epoch:  3  	Training Loss: 0.06754335016012192
Test Loss:  0.05586165934801102
Valid Loss:  0.05713202804327011
Epoch:  4  	Training Loss: 0.041426219046115875
Test Loss:  0.03695744648575783
Valid Loss:  0.0394502654671669
Epoch:  5  	Training Loss: 0.02937346138060093
Test Loss:  0.026780350133776665
Valid Loss:  0.02986251749098301
Epoch:  6  	Training Loss: 0.02346872352063656
Test Loss:  0.020941561087965965
Valid Loss:  0.024257445707917213
Epoch:  7  	Training Loss: 0.020275838673114777
Test Loss:  0.01734960451722145
Valid Loss:  0.02069510519504547
Epoch:  8  	Training Loss: 0.018300916999578476
Test Loss:  0.014976088888943195
Valid Loss:  0.018233507871627808
Epoch:  9  	Training Loss: 0.016892842948436737
Test Loss:  0.01329655759036541
Valid Loss:  0.016399282962083817
Epoch:  10  	Training Loss: 0.015766486525535583
Test Loss:  0.012032728642225266
Valid Loss:  0.014945152215659618
Epoch:  11  	Training Loss: 0.014795743860304356
Test Loss:  0.011030761525034904
Valid Loss:  0.013736406341195107
Epoch:  12  	Training Loss: 0.013923699036240578
Test Loss:  0.010200228542089462
Valid Loss:  0.012694304808974266
Epoch:  13  	Training Loss: 0.013122373260557652
Test Loss:  0.009490672498941422
Valid Loss:  0.011775922030210495
Epoch:  14  	Training Loss: 0.012379753403365612
Test Loss:  0.008869326673448086
Valid Loss:  0.010952798649668694
Epoch:  15  	Training Loss: 0.011688170954585075
Test Loss:  0.008315210230648518
Valid Loss:  0.010206583887338638
Epoch:  16  	Training Loss: 0.011042658239603043
Test Loss:  0.007814547047019005
Valid Loss:  0.009524838998913765
Epoch:  17  	Training Loss: 0.010439494624733925
Test Loss:  0.00735794473439455
Valid Loss:  0.008898701518774033
Epoch:  18  	Training Loss: 0.009875636547803879
Test Loss:  0.006938781589269638
Valid Loss:  0.008321684785187244
Epoch:  19  	Training Loss: 0.00934838317334652
Test Loss:  0.006552279926836491
Valid Loss:  0.00778875220566988
Epoch:  20  	Training Loss: 0.00885532982647419
Test Loss:  0.006194753106683493
Valid Loss:  0.007295806892216206
Epoch:  21  	Training Loss: 0.008394211530685425
Test Loss:  0.005863334983587265
Valid Loss:  0.006839459761977196
Epoch:  22  	Training Loss: 0.007962970994412899
Test Loss:  0.005556815769523382
Valid Loss:  0.006417835596948862
Epoch:  23  	Training Loss: 0.007560255937278271
Test Loss:  0.0052717928774654865
Valid Loss:  0.006027083843946457
Epoch:  24  	Training Loss: 0.00718360859900713
Test Loss:  0.005006627179682255
Valid Loss:  0.005664994940161705
Epoch:  25  	Training Loss: 0.0068313367664813995
Test Loss:  0.004759908653795719
Valid Loss:  0.005329525098204613
Epoch:  26  	Training Loss: 0.006501861847937107
Test Loss:  0.004530342295765877
Valid Loss:  0.005018800497055054
Epoch:  27  	Training Loss: 0.006193708628416061
Test Loss:  0.004316720645874739
Valid Loss:  0.004731098189949989
Epoch:  28  	Training Loss: 0.0059054880402982235
Test Loss:  0.004117959178984165
Valid Loss:  0.004464816302061081
Epoch:  29  	Training Loss: 0.005635913927108049
Test Loss:  0.003933042287826538
Valid Loss:  0.0042184507474303246
Epoch:  30  	Training Loss: 0.005383784882724285
Test Loss:  0.0037610349245369434
Valid Loss:  0.0039906371384859085
Epoch:  31  	Training Loss: 0.005147960968315601
Test Loss:  0.0036010430194437504
Valid Loss:  0.003780064871534705
Epoch:  32  	Training Loss: 0.004927393049001694
Test Loss:  0.003450714750215411
Valid Loss:  0.003584530670195818
Epoch:  33  	Training Loss: 0.004720611963421106
Test Loss:  0.003311371197924018
Valid Loss:  0.0034042373299598694
Epoch:  34  	Training Loss: 0.004527213051915169
Test Loss:  0.003182121552526951
Valid Loss:  0.0032380169723182917
Epoch:  35  	Training Loss: 0.0043463255278766155
Test Loss:  0.0030621904879808426
Valid Loss:  0.003084848402068019
Epoch:  36  	Training Loss: 0.004177143797278404
Test Loss:  0.002950906753540039
Valid Loss:  0.0029437770135700703
Epoch:  37  	Training Loss: 0.004018908832222223
Test Loss:  0.0028476170264184475
Valid Loss:  0.002813933417201042
Epoch:  38  	Training Loss: 0.0038709226064383984
Test Loss:  0.0027517725247889757
Valid Loss:  0.002694514114409685
Epoch:  39  	Training Loss: 0.0037325117737054825
Test Loss:  0.0026628482155501842
Valid Loss:  0.002584754955023527
Epoch:  40  	Training Loss: 0.003603059332817793
Test Loss:  0.0025803674943745136
Valid Loss:  0.00248399144038558
Epoch:  41  	Training Loss: 0.0034819927532225847
Test Loss:  0.0025038793683052063
Valid Loss:  0.002391546033322811
Epoch:  42  	Training Loss: 0.0033687641844153404
Test Loss:  0.002433707471936941
Valid Loss:  0.0023071891628205776
Epoch:  43  	Training Loss: 0.003263054648414254
Test Loss:  0.002368471585214138
Valid Loss:  0.0022298896219581366
Epoch:  44  	Training Loss: 0.0031641824170947075
Test Loss:  0.002307892544195056
Valid Loss:  0.0021591593977063894
Epoch:  45  	Training Loss: 0.003071705810725689
Test Loss:  0.002251727506518364
Valid Loss:  0.0020945570431649685
Epoch:  46  	Training Loss: 0.0029852164443582296
Test Loss:  0.00219966983422637
Valid Loss:  0.0020356294699013233
Epoch:  47  	Training Loss: 0.0029043203685432673
Test Loss:  0.0021514790132641792
Valid Loss:  0.0019819759763777256
Epoch:  48  	Training Loss: 0.0028286604210734367
Test Loss:  0.0021068810019642115
Valid Loss:  0.0019332115771248937
Epoch:  49  	Training Loss: 0.0027578978333622217
Test Loss:  0.0020656445994973183
Valid Loss:  0.001888969331048429
Epoch:  50  	Training Loss: 0.002691711997613311
Test Loss:  0.0020275400020182133
Valid Loss:  0.0018489190842956305
Epoch:  51  	Training Loss: 0.0026298081502318382
Test Loss:  0.001992355566471815
Valid Loss:  0.0018127459334209561
Epoch:  52  	Training Loss: 0.0025719106197357178
Test Loss:  0.0019601965323090553
Valid Loss:  0.0017802679212763906
Epoch:  53  	Training Loss: 0.0025178759824484587
Test Loss:  0.0019304469460621476
Valid Loss:  0.0017510666511952877
Epoch:  54  	Training Loss: 0.0024673319421708584
Test Loss:  0.0019029888790100813
Valid Loss:  0.0017248981166630983
Epoch:  55  	Training Loss: 0.0024200535845011473
Test Loss:  0.0018776750657707453
Valid Loss:  0.0017015405464917421
Epoch:  56  	Training Loss: 0.0023758327588438988
Test Loss:  0.0018543429905548692
Valid Loss:  0.0016807601787149906
Epoch:  57  	Training Loss: 0.002334464341402054
Test Loss:  0.001832882990129292
Valid Loss:  0.0016623677220195532
Epoch:  58  	Training Loss: 0.0022957713808864355
Test Loss:  0.0018131586257368326
Valid Loss:  0.0016461812192574143
Epoch:  59  	Training Loss: 0.0022595750633627176
Test Loss:  0.0017950523179024458
Valid Loss:  0.0016320196446031332
Epoch:  60  	Training Loss: 0.0022257203236222267
Test Loss:  0.001778453472070396
Valid Loss:  0.0016197217628359795
Epoch:  61  	Training Loss: 0.0021940539591014385
Test Loss:  0.0017632392700761557
Valid Loss:  0.0016091290162876248
Epoch:  62  	Training Loss: 0.002164426725357771
Test Loss:  0.0017491189064458013
Valid Loss:  0.0016000766772776842
Epoch:  63  	Training Loss: 0.0021366362925618887
Test Loss:  0.0017362694488838315
Valid Loss:  0.0015924762701615691
Epoch:  64  	Training Loss: 0.002110642846673727
Test Loss:  0.0017245756462216377
Valid Loss:  0.0015862068394199014
Epoch:  65  	Training Loss: 0.00208633067086339
Test Loss:  0.0017139550764113665
Valid Loss:  0.0015811498742550611
Epoch:  66  	Training Loss: 0.002063591033220291
Test Loss:  0.001704309368506074
Valid Loss:  0.001577198738232255
Epoch:  67  	Training Loss: 0.0020423231180757284
Test Loss:  0.0016955723986029625
Valid Loss:  0.0015742569230496883
Epoch:  68  	Training Loss: 0.0020224330946803093
Test Loss:  0.001687660813331604
Valid Loss:  0.0015722361858934164
Epoch:  69  	Training Loss: 0.002003829926252365
Test Loss:  0.001680511748418212
Valid Loss:  0.001571053289808333
Epoch:  70  	Training Loss: 0.001986426766961813
Test Loss:  0.001674079685471952
Valid Loss:  0.0015706310514360666
 14%|█▍        | 71/500 [00:54<08:33,  1.20s/it] 15%|█▍        | 73/500 [00:54<06:06,  1.16it/s] 15%|█▌        | 75/500 [00:54<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:54<03:12,  2.20it/s] 16%|█▌        | 79/500 [00:54<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:01<08:08,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:01<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:08<08:05,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:46,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:08<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.98it/s] 20%|██        | 101/500 [01:14<07:52,  1.18s/it] 21%|██        | 103/500 [01:15<05:37,  1.18it/s] 21%|██        | 105/500 [01:15<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:15<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:15<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:21<07:39,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:22<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:22<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:28<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:28<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:14,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.23it/s]Epoch:  71  	Training Loss: 0.001970154233276844
Test Loss:  0.0016682979185134172
Valid Loss:  0.0015708946157246828
Epoch:  72  	Training Loss: 0.001954933162778616
Test Loss:  0.0016631204634904861
Valid Loss:  0.0015717786736786366
Epoch:  73  	Training Loss: 0.0019407046493142843
Test Loss:  0.0016584924887865782
Valid Loss:  0.0015732222236692905
Epoch:  74  	Training Loss: 0.0019273973302915692
Test Loss:  0.0016543827950954437
Valid Loss:  0.0015751677565276623
Epoch:  75  	Training Loss: 0.0019149521831423044
Test Loss:  0.0016507436521351337
Valid Loss:  0.0015775671927258372
Epoch:  76  	Training Loss: 0.00190330995246768
Test Loss:  0.0016475445590913296
Valid Loss:  0.0015803691931068897
Epoch:  77  	Training Loss: 0.0018924226751551032
Test Loss:  0.0016447368543595076
Valid Loss:  0.0015835334779694676
Epoch:  78  	Training Loss: 0.001882240641862154
Test Loss:  0.0016422962071374059
Valid Loss:  0.0015870033530518413
Epoch:  79  	Training Loss: 0.0018727162387222052
Test Loss:  0.001640188624151051
Valid Loss:  0.0015907608903944492
Epoch:  80  	Training Loss: 0.0018638083711266518
Test Loss:  0.0016383992042392492
Valid Loss:  0.0015947666252031922
Epoch:  81  	Training Loss: 0.0018554781563580036
Test Loss:  0.0016368867363780737
Valid Loss:  0.0015989779494702816
Epoch:  82  	Training Loss: 0.001847685081884265
Test Loss:  0.0016356280539184809
Valid Loss:  0.0016033800784498453
Epoch:  83  	Training Loss: 0.001840409473516047
Test Loss:  0.0016346212942153215
Valid Loss:  0.0016079340130090714
Epoch:  84  	Training Loss: 0.0018336039502173662
Test Loss:  0.0016338224522769451
Valid Loss:  0.001612616702914238
Epoch:  85  	Training Loss: 0.001827238593250513
Test Loss:  0.0016332308296114206
Valid Loss:  0.0016174118500202894
Epoch:  86  	Training Loss: 0.0018212880240753293
Test Loss:  0.0016328180208802223
Valid Loss:  0.0016222945414483547
Epoch:  87  	Training Loss: 0.0018157206941395998
Test Loss:  0.0016325705219060183
Valid Loss:  0.0016272509237751365
Epoch:  88  	Training Loss: 0.001810514833778143
Test Loss:  0.001632467843592167
Valid Loss:  0.001632249797694385
Epoch:  89  	Training Loss: 0.0018056394765153527
Test Loss:  0.0016325039323419333
Valid Loss:  0.0016372964018955827
Epoch:  90  	Training Loss: 0.001801084727048874
Test Loss:  0.0016326589975506067
Valid Loss:  0.001642353949137032
Epoch:  91  	Training Loss: 0.0017968241591006517
Test Loss:  0.0016329234931617975
Valid Loss:  0.0016474371077492833
Epoch:  92  	Training Loss: 0.0017928394954651594
Test Loss:  0.0016333189560100436
Valid Loss:  0.001652493141591549
Epoch:  93  	Training Loss: 0.0017891093157231808
Test Loss:  0.001633789506740868
Valid Loss:  0.001657543471083045
Epoch:  94  	Training Loss: 0.0017856191843748093
Test Loss:  0.001634333049878478
Valid Loss:  0.0016625715652480721
Epoch:  95  	Training Loss: 0.0017823564121499658
Test Loss:  0.001634934451431036
Valid Loss:  0.0016675761435180902
Epoch:  96  	Training Loss: 0.0017793031875044107
Test Loss:  0.001635600347071886
Valid Loss:  0.0016725403256714344
Epoch:  97  	Training Loss: 0.0017764498479664326
Test Loss:  0.0016363216564059258
Valid Loss:  0.0016774581745266914
Epoch:  98  	Training Loss: 0.0017737771850079298
Test Loss:  0.0016370860394090414
Valid Loss:  0.0016823275946080685
Epoch:  99  	Training Loss: 0.001771281473338604
Test Loss:  0.0016378936124965549
Valid Loss:  0.0016871426487341523
Epoch:  100  	Training Loss: 0.0017689429223537445
Test Loss:  0.0016387403011322021
Valid Loss:  0.0016918941400945187
Epoch:  101  	Training Loss: 0.001766758505254984
Test Loss:  0.001639606081880629
Valid Loss:  0.0016965707764029503
Epoch:  102  	Training Loss: 0.0017647109925746918
Test Loss:  0.0016405063215643167
Valid Loss:  0.00170119758695364
Epoch:  103  	Training Loss: 0.001762803876772523
Test Loss:  0.0016414220444858074
Valid Loss:  0.0017057375516742468
Epoch:  104  	Training Loss: 0.0017610182985663414
Test Loss:  0.001642365357838571
Valid Loss:  0.0017102083656936884
Epoch:  105  	Training Loss: 0.0017593487864360213
Test Loss:  0.0016433123964816332
Valid Loss:  0.0017145898891612887
Epoch:  106  	Training Loss: 0.0017577854450792074
Test Loss:  0.0016442800406366587
Valid Loss:  0.0017189092468470335
Epoch:  107  	Training Loss: 0.0017563232686370611
Test Loss:  0.001645255833864212
Valid Loss:  0.001723139313980937
Epoch:  108  	Training Loss: 0.0017549543408676982
Test Loss:  0.0016462299972772598
Valid Loss:  0.0017272845143452287
Epoch:  109  	Training Loss: 0.0017536787781864405
Test Loss:  0.0016472095157951117
Valid Loss:  0.0017313461285084486
Epoch:  110  	Training Loss: 0.0017524788854643703
Test Loss:  0.0016481943894177675
Valid Loss:  0.0017353270668536425
Epoch:  111  	Training Loss: 0.0017513623461127281
Test Loss:  0.00164916948415339
Valid Loss:  0.0017392185982316732
Epoch:  112  	Training Loss: 0.0017503176350146532
Test Loss:  0.0016501513309776783
Valid Loss:  0.0017430228181183338
Epoch:  113  	Training Loss: 0.001749339047819376
Test Loss:  0.0016511273570358753
Valid Loss:  0.0017467427533119917
Epoch:  114  	Training Loss: 0.0017484223935753107
Test Loss:  0.0016520894132554531
Valid Loss:  0.001750383642502129
Epoch:  115  	Training Loss: 0.001747563830576837
Test Loss:  0.0016530448338016868
Valid Loss:  0.0017539379186928272
Epoch:  116  	Training Loss: 0.0017467617290094495
Test Loss:  0.0016539921052753925
Valid Loss:  0.001757403602823615
Epoch:  117  	Training Loss: 0.0017460145754739642
Test Loss:  0.001654922147281468
Valid Loss:  0.0017607978079468012
Epoch:  118  	Training Loss: 0.001745311776176095
Test Loss:  0.001655847067013383
Valid Loss:  0.0017640970181673765
Epoch:  119  	Training Loss: 0.0017446577548980713
Test Loss:  0.0016567527782171965
Valid Loss:  0.0017673283582553267
Epoch:  120  	Training Loss: 0.0017440443625673652
Test Loss:  0.0016576454509049654
Valid Loss:  0.001770468195900321
Epoch:  121  	Training Loss: 0.0017434705514460802
Test Loss:  0.0016585288103669882
Valid Loss:  0.0017735273577272892
Epoch:  122  	Training Loss: 0.0017429329454898834
Test Loss:  0.0016593877226114273
Valid Loss:  0.0017765314551070333
Epoch:  123  	Training Loss: 0.001742430031299591
Test Loss:  0.0016602379037067294
Valid Loss:  0.0017794426530599594
Epoch:  124  	Training Loss: 0.0017419590149074793
Test Loss:  0.0016610703896731138
Valid Loss:  0.0017822813242673874
Epoch:  125  	Training Loss: 0.0017415175680071115
Test Loss:  0.0016618873924016953
Valid Loss:  0.001785042928531766
Epoch:  126  	Training Loss: 0.0017411066219210625
Test Loss:  0.0016626889118924737
Valid Loss:  0.0017877385253086686
Epoch:  127  	Training Loss: 0.0017407210543751717
Test Loss:  0.001663482398726046
Valid Loss:  0.001790352980606258
Epoch:  128  	Training Loss: 0.0017403578385710716
Test Loss:  0.0016642537666484714
Valid Loss:  0.001792903058230877
Epoch:  129  	Training Loss: 0.0017400201177224517
Test Loss:  0.0016650089528411627
Valid Loss:  0.0017953829374164343
Epoch:  130  	Training Loss: 0.0017397059127688408
Test Loss:  0.001665750751271844
Valid Loss:  0.0017977834213525057
Epoch:  131  	Training Loss: 0.001739409053698182
Test Loss:  0.0016664746217429638
Valid Loss:  0.0018001209245994687
Epoch:  132  	Training Loss: 0.0017391323344781995
Test Loss:  0.0016671849880367517
Valid Loss:  0.0018023909069597721
Epoch:  133  	Training Loss: 0.0017388766864314675
Test Loss:  0.0016678770771250129
Valid Loss:  0.001804593950510025
Epoch:  134  	Training Loss: 0.001738633494824171
Test Loss:  0.001668555778451264
Valid Loss:  0.0018067446071654558
Epoch:  135  	Training Loss: 0.001738408929668367
Test Loss:  0.0016692113131284714
Valid Loss:  0.0018088201759383082
Epoch:  136  	Training Loss: 0.0017381971701979637
Test Loss:  0.0016698583494871855
Valid Loss:  0.0018108520889654756
Epoch:  137  	Training Loss: 0.0017380035715177655
Test Loss:  0.0016704833833500743
Valid Loss:  0.001812812639400363
Epoch:  138  	Training Loss: 0.0017378154443576932
Test Loss:  0.0016710949130356312
Valid Loss:  0.0018147204536944628
Epoch:  139  	Training Loss: 0.0017376444302499294
Test Loss:  0.0016716881655156612
Valid Loss:   28%|██▊       | 139/500 [01:36<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:42<07:01,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:01,  1.19it/s] 29%|██▉       | 145/500 [01:42<03:37,  1.64it/s] 29%|██▉       | 147/500 [01:42<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.00it/s] 30%|███       | 151/500 [01:49<06:49,  1.17s/it] 31%|███       | 153/500 [01:49<04:52,  1.19it/s] 31%|███       | 155/500 [01:49<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.01it/s] 32%|███▏      | 161/500 [01:56<06:41,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:56<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.22it/s] 34%|███▍      | 169/500 [01:56<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:02<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:03<03:18,  1.63it/s] 35%|███▌      | 177/500 [02:03<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:09<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:10<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:16<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:16<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:16<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:17<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:17<01:41,  2.98it/s] 40%|████      | 201/500 [02:23<05:55,  1.19s/it] 41%|████      | 203/500 [02:23<04:13,  1.17it/s] 41%|████      | 205/500 [02:23<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:23<02:12,  2.21it/s]0.0018165749497711658
Epoch:  140  	Training Loss: 0.0017374828457832336
Test Loss:  0.0016722704749554396
Valid Loss:  0.001818376942537725
Epoch:  141  	Training Loss: 0.0017373324371874332
Test Loss:  0.0016728386981412768
Valid Loss:  0.0018201251514256
Epoch:  142  	Training Loss: 0.0017371894791722298
Test Loss:  0.001673386781476438
Valid Loss:  0.0018218237673863769
Epoch:  143  	Training Loss: 0.0017370579298585653
Test Loss:  0.0016739221755415201
Valid Loss:  0.0018234692979604006
Epoch:  144  	Training Loss: 0.0017369342967867851
Test Loss:  0.0016744404565542936
Valid Loss:  0.0018250640714541078
Epoch:  145  	Training Loss: 0.0017368175322189927
Test Loss:  0.0016749486094340682
Valid Loss:  0.0018266144907101989
Epoch:  146  	Training Loss: 0.0017367128748446703
Test Loss:  0.0016754423268139362
Valid Loss:  0.001828118460252881
Epoch:  147  	Training Loss: 0.0017366115935146809
Test Loss:  0.0016759277787059546
Valid Loss:  0.0018295752815902233
Epoch:  148  	Training Loss: 0.0017365170642733574
Test Loss:  0.0016763914609327912
Valid Loss:  0.0018309855367988348
Epoch:  149  	Training Loss: 0.001736425794661045
Test Loss:  0.0016768435016274452
Valid Loss:  0.0018323606345802546
Epoch:  150  	Training Loss: 0.0017363433726131916
Test Loss:  0.0016772899543866515
Valid Loss:  0.0018336891662329435
Epoch:  151  	Training Loss: 0.0017362660728394985
Test Loss:  0.0016777224373072386
Valid Loss:  0.0018349816091358662
Epoch:  152  	Training Loss: 0.0017361952923238277
Test Loss:  0.0016781355952844024
Valid Loss:  0.0018362270202487707
Epoch:  153  	Training Loss: 0.0017361261416226625
Test Loss:  0.0016785375773906708
Valid Loss:  0.0018374386709183455
Epoch:  154  	Training Loss: 0.0017360637430101633
Test Loss:  0.0016789310611784458
Valid Loss:  0.0018386156298220158
Epoch:  155  	Training Loss: 0.0017360050696879625
Test Loss:  0.001679317792877555
Valid Loss:  0.0018397477688267827
Epoch:  156  	Training Loss: 0.001735948957502842
Test Loss:  0.0016796872951090336
Valid Loss:  0.0018408505711704493
Epoch:  157  	Training Loss: 0.0017358933109790087
Test Loss:  0.001680044806562364
Valid Loss:  0.0018419214757159352
Epoch:  158  	Training Loss: 0.0017358484910801053
Test Loss:  0.001680396031588316
Valid Loss:  0.001842954894527793
Epoch:  159  	Training Loss: 0.0017358016921207309
Test Loss:  0.001680737710557878
Valid Loss:  0.0018439602572470903
Epoch:  160  	Training Loss: 0.0017357601318508387
Test Loss:  0.001681067980825901
Valid Loss:  0.0018449302297085524
Epoch:  161  	Training Loss: 0.0017357205506414175
Test Loss:  0.00168139161542058
Valid Loss:  0.0018458768026903272
Epoch:  162  	Training Loss: 0.0017356842290610075
Test Loss:  0.0016816994175314903
Valid Loss:  0.001846782397478819
Epoch:  163  	Training Loss: 0.0017356483731418848
Test Loss:  0.0016819993034005165
Valid Loss:  0.0018476671539247036
Epoch:  164  	Training Loss: 0.0017356157768517733
Test Loss:  0.0016822901088744402
Valid Loss:  0.0018485200125724077
Epoch:  165  	Training Loss: 0.0017355865566059947
Test Loss:  0.0016825770726427436
Valid Loss:  0.0018493522657081485
Epoch:  166  	Training Loss: 0.0017355559393763542
Test Loss:  0.0016828535590320826
Valid Loss:  0.0018501487793400884
Epoch:  167  	Training Loss: 0.001735527766868472
Test Loss:  0.0016831220127642155
Valid Loss:  0.001850930624641478
Epoch:  168  	Training Loss: 0.0017355054151266813
Test Loss:  0.001683375216089189
Valid Loss:  0.001851677312515676
Epoch:  169  	Training Loss: 0.001735482714138925
Test Loss:  0.0016836284194141626
Valid Loss:  0.0018524045590311289
Epoch:  170  	Training Loss: 0.001735461875796318
Test Loss:  0.0016838693991303444
Valid Loss:  0.0018531193491071463
Epoch:  171  	Training Loss: 0.0017354406882077456
Test Loss:  0.0016841080505400896
Valid Loss:  0.0018537994474172592
Epoch:  172  	Training Loss: 0.0017354196170344949
Test Loss:  0.0016843347111716866
Valid Loss:  0.001854458823800087
Epoch:  173  	Training Loss: 0.0017354050651192665
Test Loss:  0.0016845567151904106
Valid Loss:  0.0018550973618403077
Epoch:  174  	Training Loss: 0.0017353870207443833
Test Loss:  0.0016847720835357904
Valid Loss:  0.0018557203002274036
Epoch:  175  	Training Loss: 0.0017353715375065804
Test Loss:  0.0016849786043167114
Valid Loss:  0.001856312621384859
Epoch:  176  	Training Loss: 0.0017353586154058576
Test Loss:  0.001685179304331541
Valid Loss:  0.001856895862147212
Epoch:  177  	Training Loss: 0.0017353426665067673
Test Loss:  0.001685375813394785
Valid Loss:  0.0018574614077806473
Epoch:  178  	Training Loss: 0.0017353333532810211
Test Loss:  0.0016855642898008227
Valid Loss:  0.0018580106552690268
Epoch:  179  	Training Loss: 0.0017353203147649765
Test Loss:  0.0016857520677149296
Valid Loss:  0.001858527073636651
Epoch:  180  	Training Loss: 0.0017353079747408628
Test Loss:  0.0016859276220202446
Valid Loss:  0.0018590447725728154
Epoch:  181  	Training Loss: 0.0017352959839627147
Test Loss:  0.0016860925825312734
Valid Loss:  0.001859539421275258
Epoch:  182  	Training Loss: 0.0017352879513055086
Test Loss:  0.0016862628981471062
Valid Loss:  0.0018600216135382652
Epoch:  183  	Training Loss: 0.0017352781724184752
Test Loss:  0.0016864205244928598
Valid Loss:  0.0018604834331199527
Epoch:  184  	Training Loss: 0.001735271536745131
Test Loss:  0.0016865755897015333
Valid Loss:  0.0018609394319355488
Epoch:  185  	Training Loss: 0.0017352633876726031
Test Loss:  0.001686727162450552
Valid Loss:  0.0018613666761666536
Epoch:  186  	Training Loss: 0.0017352525610476732
Test Loss:  0.001686877803876996
Valid Loss:  0.0018617847235873342
Epoch:  187  	Training Loss: 0.0017352498834952712
Test Loss:  0.0016870192484930158
Valid Loss:  0.0018621898489072919
Epoch:  188  	Training Loss: 0.0017352418508380651
Test Loss:  0.0016871518455445766
Valid Loss:  0.001862583216279745
Epoch:  189  	Training Loss: 0.001735235913656652
Test Loss:  0.0016872837441042066
Valid Loss:  0.0018629651749506593
Epoch:  190  	Training Loss: 0.0017352300928905606
Test Loss:  0.0016874157590791583
Valid Loss:  0.00186333735473454
Epoch:  191  	Training Loss: 0.0017352248542010784
Test Loss:  0.0016875409055501223
Valid Loss:  0.0018636940512806177
Epoch:  192  	Training Loss: 0.0017352192662656307
Test Loss:  0.0016876612789928913
Valid Loss:  0.0018640384078025818
Epoch:  193  	Training Loss: 0.0017352149588987231
Test Loss:  0.0016877795569598675
Valid Loss:  0.0018643694929778576
Epoch:  194  	Training Loss: 0.0017352108843624592
Test Loss:  0.0016878924798220396
Valid Loss:  0.0018646933604031801
Epoch:  195  	Training Loss: 0.0017352071590721607
Test Loss:  0.0016880042385309935
Valid Loss:  0.001865002908743918
Epoch:  196  	Training Loss: 0.0017352021532133222
Test Loss:  0.0016881051706150174
Valid Loss:  0.0018653140868991613
Epoch:  197  	Training Loss: 0.0017351973801851273
Test Loss:  0.001688205637037754
Valid Loss:  0.0018656107131391764
Epoch:  198  	Training Loss: 0.0017351966816931963
Test Loss:  0.0016883102944120765
Valid Loss:  0.001865890109911561
Epoch:  199  	Training Loss: 0.0017351934220641851
Test Loss:  0.0016884016804397106
Valid Loss:  0.001866163220256567
Epoch:  200  	Training Loss: 0.0017351899296045303
Test Loss:  0.0016885001678019762
Valid Loss:  0.0018664298113435507
Epoch:  201  	Training Loss: 0.0017351872520521283
Test Loss:  0.0016885956283658743
Valid Loss:  0.0018666840624064207
Epoch:  202  	Training Loss: 0.0017351857386529446
Test Loss:  0.001688677817583084
Valid Loss:  0.0018669296987354755
Epoch:  203  	Training Loss: 0.001735182013362646
Test Loss:  0.0016887583769857883
Valid Loss:  0.0018671699799597263
Epoch:  204  	Training Loss: 0.001735182013362646
Test Loss:  0.0016888428945094347
Valid Loss:  0.0018674035090953112
Epoch:  205  	Training Loss: 0.001735177356749773
Test Loss:  0.0016889231046661735
Valid Loss:  0.0018676285399124026
Epoch:  206  	Training Loss: 0.0017351765418425202
Test Loss:  0.0016889991238713264
Valid Loss:  0.00186784821562469
Epoch:  207  	Training Loss: 0.001735173282213509
Test Loss:  0.00168907199986279
Valid Loss:  0.0018680556677281857
Epoch:  208  	Training Loss: 0.0017351716523990035
 42%|████▏     | 209/500 [02:24<01:37,  2.97it/s] 42%|████▏     | 211/500 [02:30<05:42,  1.19s/it] 43%|████▎     | 213/500 [02:30<04:04,  1.17it/s] 43%|████▎     | 215/500 [02:36<07:17,  1.54s/it] 43%|████▎     | 217/500 [02:36<05:10,  1.10s/it] 44%|████▍     | 219/500 [02:37<03:40,  1.27it/s] 44%|████▍     | 221/500 [02:43<06:54,  1.49s/it] 45%|████▍     | 223/500 [02:43<04:54,  1.06s/it] 45%|████▌     | 225/500 [02:49<07:44,  1.69s/it] 45%|████▌     | 227/500 [02:49<05:28,  1.20s/it] 46%|████▌     | 229/500 [02:50<03:53,  1.16it/s] 46%|████▌     | 231/500 [02:56<06:56,  1.55s/it] 47%|████▋     | 233/500 [02:56<04:55,  1.11s/it] 47%|████▋     | 235/500 [03:02<07:37,  1.73s/it] 47%|████▋     | 237/500 [03:02<05:23,  1.23s/it] 48%|████▊     | 239/500 [03:03<03:50,  1.13it/s] 48%|████▊     | 241/500 [03:09<06:43,  1.56s/it] 49%|████▊     | 243/500 [03:09<04:45,  1.11s/it] 49%|████▉     | 245/500 [03:15<07:18,  1.72s/it] 49%|████▉     | 247/500 [03:15<05:10,  1.23s/it] 50%|████▉     | 249/500 [03:16<03:40,  1.14it/s] 50%|█████     | 251/500 [03:28<10:16,  2.48s/it] 51%|█████     | 253/500 [03:28<07:13,  1.75s/it] 51%|█████     | 255/500 [03:28<05:05,  1.25s/it] 51%|█████▏    | 257/500 [03:28<03:37,  1.12it/s] 52%|█████▏    | 259/500 [03:28<02:35,  1.55it/s] 52%|█████▏    | 259/500 [03:41<02:35,  1.55it/s] 52%|█████▏    | 261/500 [03:41<09:09,  2.30s/it] 53%|█████▎    | 263/500 [03:41<06:26,  1.63s/it] 53%|█████▎    | 265/500 [03:47<08:10,  2.09s/it] 53%|█████▎    | 267/500 [03:47<05:45,  1.48s/it] 54%|█████▍    | 269/500 [03:48<04:04,  1.06s/it]Test Loss:  0.0016891439445316792
Valid Loss:  0.0018682582303881645
Epoch:  209  	Training Loss: 0.0017351731657981873
Test Loss:  0.0016892082057893276
Valid Loss:  0.0018684619572013617
Epoch:  210  	Training Loss: 0.0017351678106933832
Test Loss:  0.0016892843414098024
Valid Loss:  0.0018686518305912614
Epoch:  211  	Training Loss: 0.0017351676942780614
Test Loss:  0.0016893460415303707
Valid Loss:  0.0018688340205699205
Epoch:  212  	Training Loss: 0.001735165948048234
Test Loss:  0.0016894094878807664
Valid Loss:  0.0018690105061978102
Epoch:  213  	Training Loss: 0.0017351617570966482
Test Loss:  0.0016894722357392311
Valid Loss:  0.0018691879231482744
Epoch:  214  	Training Loss: 0.0017351660644635558
Test Loss:  0.001689528115093708
Valid Loss:  0.0018693520687520504
Epoch:  215  	Training Loss: 0.0017351609421893954
Test Loss:  0.001689585973508656
Valid Loss:  0.001869511092081666
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.00173516187351197
Test Loss:  0.001689611584879458
Valid Loss:  0.0018695901380851865
Epoch:  217  	Training Loss: 0.0017351614078506827
Test Loss:  0.0016896382439881563
Valid Loss:  0.0018696694169193506
Epoch:  218  	Training Loss: 0.0017351609421893954
Test Loss:  0.001689663389697671
Valid Loss:  0.0018697406630963087
Epoch:  219  	Training Loss: 0.001735158497467637
Test Loss:  0.0016896916786208749
Valid Loss:  0.0018698133062571287
Epoch:  220  	Training Loss: 0.0017351587302982807
Test Loss:  0.0016897215973585844
Valid Loss:  0.001869889791123569
Epoch:  221  	Training Loss: 0.0017351595452055335
Test Loss:  0.0016897418536245823
Valid Loss:  0.00186996441334486
Epoch:  222  	Training Loss: 0.0017351580318063498
Test Loss:  0.0016897704917937517
Valid Loss:  0.0018700301880016923
Epoch:  223  	Training Loss: 0.0017351589631289244
Test Loss:  0.0016897948225960135
Valid Loss:  0.0018701002700254321
Epoch:  224  	Training Loss: 0.00173516059294343
Test Loss:  0.0016898192698135972
Valid Loss:  0.0018701654626056552
Epoch:  225  	Training Loss: 0.0017351596616208553
Test Loss:  0.0016898401081562042
Valid Loss:  0.001870238222181797
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016898540779948235
Valid Loss:  0.0018702726811170578
Epoch:  227  	Training Loss: 0.001735158497467637
Test Loss:  0.0016898661851882935
Valid Loss:  0.001870300155133009
Epoch:  228  	Training Loss: 0.0017351575661450624
Test Loss:  0.0016898775938898325
Valid Loss:  0.001870334497652948
Epoch:  229  	Training Loss: 0.001735155819915235
Test Loss:  0.001689891330897808
Valid Loss:  0.001870369422249496
Epoch:  230  	Training Loss: 0.0017351559363305569
Test Loss:  0.001689903438091278
Valid Loss:  0.0018704026006162167
Epoch:  231  	Training Loss: 0.0017351575661450624
Test Loss:  0.0016899077454581857
Valid Loss:  0.0018704237882047892
Epoch:  232  	Training Loss: 0.0017351587302982807
Test Loss:  0.001689921598881483
Valid Loss:  0.0018704646499827504
Epoch:  233  	Training Loss: 0.0017351582646369934
Test Loss:  0.0016899349866434932
Valid Loss:  0.0018704934045672417
Epoch:  234  	Training Loss: 0.0017351559363305569
Test Loss:  0.0016899451147764921
Valid Loss:  0.0018705256516113877
Epoch:  235  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016899523325264454
Valid Loss:  0.0018705576658248901
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.0017351568676531315
Test Loss:  0.0016899567563086748
Valid Loss:  0.0018705694237723947
Epoch:  237  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016899638576433063
Valid Loss:  0.0018705870024859905
Epoch:  238  	Training Loss: 0.0017351553542539477
Test Loss:  0.0016899699112400413
Valid Loss:  0.001870599458925426
Epoch:  239  	Training Loss: 0.0017351566348224878
Test Loss:  0.0016899737529456615
Valid Loss:  0.001870616339147091
Epoch:  240  	Training Loss: 0.001735155819915235
Test Loss:  0.0016899826005101204
Valid Loss:  0.0018706327537074685
Epoch:  241  	Training Loss: 0.0017351553542539477
Test Loss:  0.0016899891197681427
Valid Loss:  0.0018706440459936857
Epoch:  242  	Training Loss: 0.0017351559363305569
Test Loss:  0.0016899901675060391
Valid Loss:  0.001870662672445178
Epoch:  243  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016899975016713142
Valid Loss:  0.0018706729169934988
Epoch:  244  	Training Loss: 0.0017351553542539477
Test Loss:  0.0016900016926229
Valid Loss:  0.0018706897972151637
Epoch:  245  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900089103728533
Valid Loss:  0.001870703068561852
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.0017351555870845914
Test Loss:  0.001690009143203497
Valid Loss:  0.0018707166891545057
Epoch:  247  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900141490623355
Valid Loss:  0.0018707194831222296
Epoch:  248  	Training Loss: 0.0017351561691612005
Test Loss:  0.0016900127520784736
Valid Loss:  0.0018707310082390904
Epoch:  249  	Training Loss: 0.001735156518407166
Test Loss:  0.001690017175860703
Valid Loss:  0.0018707320559769869
Epoch:  250  	Training Loss: 0.0017351560527458787
Test Loss:  0.0016900241607800126
Valid Loss:  0.0018707442795857787
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900227637961507
Valid Loss:  0.0018707450944930315
Epoch:  252  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900236951187253
Valid Loss:  0.0018707533599808812
Epoch:  253  	Training Loss: 0.0017351541901007295
Test Loss:  0.0016900284681469202
Valid Loss:  0.0018707502167671919
Epoch:  254  	Training Loss: 0.0017351550050079823
Test Loss:  0.0016900291666388512
Valid Loss:  0.001870750798843801
Epoch:  255  	Training Loss: 0.0017351547721773386
Test Loss:  0.0016900275368243456
Valid Loss:  0.0018707567360252142
Epoch:  256  	Training Loss: 0.0017351543065160513
Test Loss:  0.0016900310292840004
Valid Loss:  0.001870759529992938
Epoch:  257  	Training Loss: 0.001735154539346695
Test Loss:  0.0016900325426831841
Valid Loss:  0.0018707624403759837
Epoch:  258  	Training Loss: 0.0017351564019918442
Test Loss:  0.0016900359187275171
Valid Loss:  0.001870771637186408
Epoch:  259  	Training Loss: 0.0017351561691612005
Test Loss:  0.0016900328919291496
Valid Loss:  0.0018707679118961096
Epoch:  260  	Training Loss: 0.0017351547721773386
Test Loss:  0.0016900284681469202
Valid Loss:  0.0018707734998315573
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900378977879882
Valid Loss:  0.0018707760609686375
Epoch:  262  	Training Loss: 0.0017351571004837751
Test Loss:  0.001690038712695241
Valid Loss:  0.0018707802519202232
Epoch:  263  	Training Loss: 0.0017351550050079823
Test Loss:  0.0016900402260944247
Valid Loss:  0.0018707853741943836
Epoch:  264  	Training Loss: 0.0017351559363305569
Test Loss:  0.00169003801420331
Valid Loss:  0.0018707835115492344
Epoch:  265  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900371992960572
Valid Loss:  0.0018707822309806943
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0017351559363305569
Test Loss:  0.0016900377813726664
Valid Loss:  0.001870779786258936
Epoch:  267  	Training Loss: 0.0017351550050079823
Test Loss:  0.001690039411187172
Valid Loss:  0.0018707818817347288
Epoch:  268  	Training Loss: 0.001735153840854764
Test Loss:  0.0016900368500500917
Valid Loss:  0.0018707882845774293
Epoch:  269  	Training Loss: 0.001735155237838626
Test Loss:  0.0016900370828807354
Valid Loss:  0.0018707935232669115
 54%|█████▍    | 271/500 [04:00<09:52,  2.59s/it] 55%|█████▍    | 273/500 [04:00<06:55,  1.83s/it] 55%|█████▌    | 275/500 [04:00<04:53,  1.30s/it] 55%|█████▌    | 277/500 [04:00<03:27,  1.07it/s] 56%|█████▌    | 279/500 [04:00<02:28,  1.49it/s] 56%|█████▌    | 279/500 [04:11<02:28,  1.49it/s] 56%|█████▌    | 281/500 [04:13<08:29,  2.33s/it] 57%|█████▋    | 283/500 [04:13<05:57,  1.65s/it] 57%|█████▋    | 285/500 [04:19<07:30,  2.09s/it] 57%|█████▋    | 287/500 [04:19<05:16,  1.49s/it] 58%|█████▊    | 289/500 [04:19<03:43,  1.06s/it] 58%|█████▊    | 289/500 [04:31<03:43,  1.06s/it] 58%|█████▊    | 291/500 [04:32<09:13,  2.65s/it] 59%|█████▊    | 293/500 [04:32<06:27,  1.87s/it] 59%|█████▉    | 295/500 [04:39<07:42,  2.26s/it] 59%|█████▉    | 297/500 [04:39<05:25,  1.60s/it] 60%|█████▉    | 299/500 [04:39<03:49,  1.14s/it] 60%|█████▉    | 299/500 [04:51<03:49,  1.14s/it] 60%|██████    | 301/500 [04:51<08:55,  2.69s/it] 61%|██████    | 303/500 [04:52<06:15,  1.90s/it] 61%|██████    | 305/500 [04:58<07:21,  2.26s/it] 61%|██████▏   | 307/500 [04:58<05:09,  1.61s/it] 62%|██████▏   | 309/500 [04:58<03:38,  1.14s/it] 62%|██████▏   | 309/500 [05:11<03:38,  1.14s/it] 62%|██████▏   | 311/500 [05:11<08:28,  2.69s/it] 63%|██████▎   | 313/500 [05:11<05:55,  1.90s/it] 63%|██████▎   | 315/500 [05:17<07:05,  2.30s/it] 63%|██████▎   | 317/500 [05:17<04:58,  1.63s/it] 64%|██████▍   | 319/500 [05:17<03:29,  1.16s/it] 64%|██████▍   | 321/500 [05:30<07:58,  2.67s/it] 65%|██████▍   | 323/500 [05:30<05:34,  1.89s/it] 65%|██████▌   | 325/500 [05:36<06:35,  2.26s/it]Epoch:  270  	Training Loss: 0.001735155819915235
Test Loss:  0.0016900371992960572
Valid Loss:  0.0018707946874201298
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.001735154539346695
Test Loss:  0.0016900395276024938
Valid Loss:  0.0018707962008193135
Epoch:  272  	Training Loss: 0.0017351539572700858
Test Loss:  0.0016900376649573445
Valid Loss:  0.0018707967828959227
Epoch:  273  	Training Loss: 0.0017351536080241203
Test Loss:  0.0016900369664654136
Valid Loss:  0.001870795153081417
Epoch:  274  	Training Loss: 0.0017351534916087985
Test Loss:  0.0016900403425097466
Valid Loss:  0.001870793872512877
Epoch:  275  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900377813726664
Valid Loss:  0.0018707980634644628
Epoch:  276  	Training Loss: 0.0017351560527458787
Test Loss:  0.0016900382470339537
Valid Loss:  0.001870799926109612
Epoch:  277  	Training Loss: 0.001735153142362833
Test Loss:  0.0016900392947718501
Valid Loss:  0.001870799227617681
Epoch:  278  	Training Loss: 0.0017351534916087985
Test Loss:  0.0016900385962799191
Valid Loss:  0.0018707959679886699
Epoch:  279  	Training Loss: 0.001735154539346695
Test Loss:  0.0016900388291105628
Valid Loss:  0.0018707984127104282
Epoch:  280  	Training Loss: 0.0017351537244394422
Test Loss:  0.0016900415066629648
Valid Loss:  0.0018707970157265663
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.001735155121423304
Test Loss:  0.0016900429036468267
Valid Loss:  0.0018707984127104282
Epoch:  282  	Training Loss: 0.001735155121423304
Test Loss:  0.0016900432528927922
Valid Loss:  0.001870797947049141
Epoch:  283  	Training Loss: 0.0017351550050079823
Test Loss:  0.0016900443006306887
Valid Loss:  0.001870798645541072
Epoch:  284  	Training Loss: 0.0017351559363305569
Test Loss:  0.0016900430200621486
Valid Loss:  0.0018707995768636465
Epoch:  285  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900436021387577
Valid Loss:  0.0018708005081862211
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900437185540795
Valid Loss:  0.0018708005081862211
Epoch:  287  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  288  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
Epoch:  289  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  290  	Training Loss: 0.0017351553542539477
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900432528927922
Valid Loss:  0.001870801206678152
Epoch:  292  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  293  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  294  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  295  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  297  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  298  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900432528927922
Valid Loss:  0.001870801206678152
Epoch:  299  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  300  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  302  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  303  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  304  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  305  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  307  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  308  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  309  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  310  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  312  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  313  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
Epoch:  314  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
Epoch:  315  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  317  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  318  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  319  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900430200621486
Valid Loss:  0.0018708010902628303
Epoch:  320  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  322  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  323  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  324  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  325  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  327  	Training Loss: 0.0017351557034999132
Test Loss:   65%|██████▌   | 327/500 [05:36<04:37,  1.60s/it] 66%|██████▌   | 329/500 [05:37<03:15,  1.14s/it] 66%|██████▌   | 331/500 [05:49<07:27,  2.65s/it] 67%|██████▋   | 333/500 [05:49<05:13,  1.88s/it] 67%|██████▋   | 335/500 [05:55<06:12,  2.26s/it] 67%|██████▋   | 337/500 [05:55<04:21,  1.60s/it] 68%|██████▊   | 339/500 [05:56<03:03,  1.14s/it] 68%|██████▊   | 341/500 [06:08<07:06,  2.68s/it] 69%|██████▊   | 343/500 [06:08<04:58,  1.90s/it] 69%|██████▉   | 345/500 [06:15<05:51,  2.27s/it] 69%|██████▉   | 347/500 [06:15<04:06,  1.61s/it] 70%|██████▉   | 349/500 [06:15<02:53,  1.15s/it] 70%|███████   | 351/500 [06:27<06:39,  2.68s/it] 71%|███████   | 353/500 [06:28<04:39,  1.90s/it] 71%|███████   | 355/500 [06:34<05:27,  2.26s/it] 71%|███████▏  | 357/500 [06:34<03:49,  1.60s/it] 72%|███████▏  | 359/500 [06:34<02:41,  1.14s/it] 72%|███████▏  | 361/500 [06:47<06:14,  2.69s/it] 73%|███████▎  | 363/500 [06:47<04:21,  1.91s/it] 73%|███████▎  | 365/500 [06:53<05:06,  2.27s/it] 73%|███████▎  | 367/500 [06:53<03:34,  1.61s/it] 74%|███████▍  | 369/500 [06:53<02:30,  1.15s/it] 74%|███████▍  | 371/500 [07:06<05:46,  2.68s/it] 75%|███████▍  | 373/500 [07:06<04:01,  1.90s/it] 75%|███████▌  | 375/500 [07:12<04:43,  2.27s/it] 75%|███████▌  | 377/500 [07:12<03:18,  1.61s/it] 76%|███████▌  | 379/500 [07:12<02:18,  1.15s/it] 76%|███████▌  | 381/500 [07:19<03:26,  1.73s/it] 77%|███████▋  | 383/500 [07:19<02:24,  1.23s/it]0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  328  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  329  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  330  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  332  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  333  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  334  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  335  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900432528927922
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  337  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
Epoch:  338  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  339  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
Epoch:  340  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  342  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  343  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  344  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  345  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  347  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  348  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  349  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  350  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  352  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  353  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  354  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  355  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  357  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  358  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708014395087957
Epoch:  359  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  360  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  362  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  363  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
Epoch:  364  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  365  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  367  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  368  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  369  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900430200621486
Valid Loss:  0.0018708010902628303
Epoch:  370  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
Epoch:  372  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  373  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  374  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  375  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900432528927922
Valid Loss:  0.001870801206678152
Epoch:  377  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  378  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  379  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  380  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  381  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  382  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  383  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  384  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
Epoch:  385  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
 77%|███████▋  | 385/500 [07:25<03:28,  1.82s/it] 77%|███████▋  | 387/500 [07:25<02:26,  1.29s/it] 78%|███████▊  | 389/500 [07:25<01:42,  1.08it/s] 78%|███████▊  | 391/500 [07:38<04:33,  2.51s/it] 79%|███████▊  | 393/500 [07:38<03:10,  1.78s/it] 79%|███████▉  | 395/500 [07:44<03:49,  2.19s/it] 79%|███████▉  | 397/500 [07:44<02:39,  1.55s/it] 80%|███████▉  | 399/500 [07:45<01:51,  1.11s/it] 80%|████████  | 401/500 [07:57<04:22,  2.65s/it] 81%|████████  | 403/500 [07:57<03:02,  1.88s/it] 81%|████████  | 405/500 [08:04<03:34,  2.26s/it] 81%|████████▏ | 407/500 [08:04<02:28,  1.60s/it] 82%|████████▏ | 409/500 [08:04<01:43,  1.14s/it] 82%|████████▏ | 411/500 [08:16<03:57,  2.66s/it] 83%|████████▎ | 413/500 [08:16<02:44,  1.89s/it] 83%|████████▎ | 415/500 [08:23<03:12,  2.26s/it] 83%|████████▎ | 417/500 [08:23<02:13,  1.61s/it] 84%|████████▍ | 419/500 [08:23<01:32,  1.14s/it] 84%|████████▍ | 421/500 [08:36<03:32,  2.68s/it] 85%|████████▍ | 423/500 [08:36<02:26,  1.90s/it] 85%|████████▌ | 425/500 [08:42<02:50,  2.28s/it] 85%|████████▌ | 427/500 [08:42<01:57,  1.62s/it] 86%|████████▌ | 429/500 [08:42<01:21,  1.15s/it] 86%|████████▌ | 431/500 [08:55<03:04,  2.68s/it] 87%|████████▋ | 433/500 [08:55<02:06,  1.89s/it] 87%|████████▋ | 435/500 [09:01<02:26,  2.26s/it] 87%|████████▋ | 437/500 [09:01<01:41,  1.60s/it] 88%|████████▊ | 439/500 [09:01<01:09,  1.14s/it] 88%|████████▊ | 441/500 [09:08<01:42,  1.74s/it]**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  387  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  388  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  389  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  390  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  392  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  393  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  394  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  395  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  397  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  398  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  399  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  400  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  402  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  403  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  404  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  405  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
Epoch:  407  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
Epoch:  408  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  409  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  410  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  412  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  413  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  414  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  415  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  417  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  418  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
Epoch:  419  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  420  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  422  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  423  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  424  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  425  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  427  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  428  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  429  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  430  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  432  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
Epoch:  433  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  434  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  435  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  437  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  438  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  439  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  440  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  441  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  442  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  443  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
 89%|████████▊ | 443/500 [09:08<01:10,  1.24s/it] 89%|████████▉ | 445/500 [09:14<01:40,  1.84s/it] 89%|████████▉ | 447/500 [09:14<01:09,  1.31s/it] 90%|████████▉ | 449/500 [09:15<00:47,  1.07it/s] 90%|█████████ | 451/500 [09:27<02:02,  2.50s/it] 91%|█████████ | 453/500 [09:27<01:23,  1.77s/it] 91%|█████████ | 455/500 [09:33<01:38,  2.19s/it] 91%|█████████▏| 457/500 [09:33<01:06,  1.55s/it] 92%|█████████▏| 459/500 [09:34<00:45,  1.11s/it] 92%|█████████▏| 461/500 [09:46<01:43,  2.65s/it] 93%|█████████▎| 463/500 [09:46<01:09,  1.88s/it] 93%|█████████▎| 465/500 [09:52<01:18,  2.25s/it] 93%|█████████▎| 467/500 [09:53<00:52,  1.60s/it] 94%|█████████▍| 469/500 [09:53<00:35,  1.14s/it] 94%|█████████▍| 471/500 [10:05<01:18,  2.69s/it] 95%|█████████▍| 473/500 [10:06<00:51,  1.91s/it] 95%|█████████▌| 475/500 [10:12<00:56,  2.28s/it] 95%|█████████▌| 477/500 [10:12<00:37,  1.62s/it] 96%|█████████▌| 479/500 [10:12<00:24,  1.15s/it] 96%|█████████▌| 481/500 [10:25<00:50,  2.67s/it] 97%|█████████▋| 483/500 [10:25<00:32,  1.89s/it] 97%|█████████▋| 485/500 [10:31<00:33,  2.26s/it] 97%|█████████▋| 487/500 [10:31<00:20,  1.60s/it] 98%|█████████▊| 489/500 [10:31<00:12,  1.14s/it] 98%|█████████▊| 491/500 [10:44<00:24,  2.68s/it] 99%|█████████▊| 493/500 [10:44<00:13,  1.90s/it] 99%|█████████▉| 495/500 [10:50<00:11,  2.27s/it] 99%|█████████▉| 497/500 [10:50<00:04,  1.61s/it]100%|█████████▉| 499/500 [10:50<00:01,  1.15s/it]Valid Loss:  0.001870801206678152
Epoch:  444  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  445  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  447  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  448  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  449  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
Epoch:  450  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
Epoch:  452  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  453  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  454  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  455  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  457  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  458  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  459  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  460  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  462  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  463  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  464  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  465  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  467  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  468  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  469  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  470  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  472  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  473  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  474  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  475  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  477  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  478  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  479  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.0018708010902628303
Epoch:  480  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  482  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  483  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  484  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  485  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900430200621486
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801323093474
Epoch:  487  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  488  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  489  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  490  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  492  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  493  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  494  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  495  	Training Loss: 0.0017351554706692696
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  497  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  498  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  499  	Training Loss: 0.0017351557034999132
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
Epoch:  500  	Training Loss: 0.0017351555870845914
Test Loss:  0.0016900431364774704
Valid Loss:  0.001870801206678152
100%|██████████| 500/500 [10:57<00:00,  1.31s/it]
**************************************************learning rate decay**************************************************
seed is  15
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:38,  6.21s/it]  1%|          | 3/500 [00:06<13:46,  1.66s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:48,  1.33s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:21,  1.20s/it]  7%|▋         | 33/500 [00:27<06:43,  1.16it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:31,  2.19it/s]  8%|▊         | 39/500 [00:27<02:36,  2.95it/s]  8%|▊         | 41/500 [00:33<09:02,  1.18s/it]  9%|▊         | 43/500 [00:33<06:28,  1.18it/s]  9%|▉         | 45/500 [00:33<04:39,  1.63it/s]  9%|▉         | 47/500 [00:34<03:23,  2.23it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:45,  1.17s/it] 11%|█         | 53/500 [00:40<06:15,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.25it/s] 12%|█▏        | 59/500 [00:41<02:25,  3.02it/s] 12%|█▏        | 61/500 [00:47<08:30,  1.16s/it] 13%|█▎        | 63/500 [00:47<06:04,  1.20it/s] 13%|█▎        | 65/500 [00:47<04:22,  1.66it/s] 13%|█▎        | 67/500 [00:47<03:11,  2.26it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.03it/s] 14%|█▍        | 71/500 [00:54<08:22,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:58,  1.19it/s]Epoch:  1  	Training Loss: 0.09472019225358963
Test Loss:  12.5003662109375
Valid Loss:  12.21940803527832
Epoch:  2  	Training Loss: 12.167078971862793
Test Loss:  0.26596391201019287
Valid Loss:  0.24445688724517822
Epoch:  3  	Training Loss: 0.20755858719348907
Test Loss:  0.24901488423347473
Valid Loss:  0.22858765721321106
Epoch:  4  	Training Loss: 0.1934797167778015
Test Loss:  0.23329168558120728
Valid Loss:  0.21389786899089813
Epoch:  5  	Training Loss: 0.1804679036140442
Test Loss:  0.21868591010570526
Valid Loss:  0.20029136538505554
Epoch:  6  	Training Loss: 0.16843518614768982
Test Loss:  0.20511004328727722
Valid Loss:  0.18766595423221588
Epoch:  7  	Training Loss: 0.15729942917823792
Test Loss:  0.19248193502426147
Valid Loss:  0.17593154311180115
Epoch:  8  	Training Loss: 0.14697802066802979
Test Loss:  0.18071025609970093
Valid Loss:  0.16501271724700928
Epoch:  9  	Training Loss: 0.13740025460720062
Test Loss:  0.16973647475242615
Valid Loss:  0.15484623610973358
Epoch:  10  	Training Loss: 0.12851403653621674
Test Loss:  0.1595011055469513
Valid Loss:  0.14537103474140167
Epoch:  11  	Training Loss: 0.12026605010032654
Test Loss:  0.1499510258436203
Valid Loss:  0.13654397428035736
Epoch:  12  	Training Loss: 0.1126086488366127
Test Loss:  0.1450328230857849
Valid Loss:  0.13273313641548157
Epoch:  13  	Training Loss: 0.10832381993532181
Test Loss:  0.14485494792461395
Valid Loss:  0.13254740834236145
Epoch:  14  	Training Loss: 0.10810264945030212
Test Loss:  0.14475341141223907
Valid Loss:  0.1324462592601776
Epoch:  15  	Training Loss: 0.10799095779657364
Test Loss:  0.1446775645017624
Valid Loss:  0.1323917955160141
Epoch:  16  	Training Loss: 0.10792234539985657
Test Loss:  0.1446133852005005
Valid Loss:  0.13235095143318176
Epoch:  17  	Training Loss: 0.10786591470241547
Test Loss:  0.1445576697587967
Valid Loss:  0.13231560587882996
Epoch:  18  	Training Loss: 0.10781323909759521
Test Loss:  0.1445089876651764
Valid Loss:  0.13228437304496765
Epoch:  19  	Training Loss: 0.10776391625404358
Test Loss:  0.1444724202156067
Valid Loss:  0.1322563886642456
Epoch:  20  	Training Loss: 0.10771912336349487
Test Loss:  0.1444401741027832
Valid Loss:  0.13223008811473846
Epoch:  21  	Training Loss: 0.10767944157123566
Test Loss:  0.1444108933210373
Valid Loss:  0.13220492005348206
Epoch:  22  	Training Loss: 0.10764382779598236
Test Loss:  0.14438679814338684
Valid Loss:  0.13218417763710022
Epoch:  23  	Training Loss: 0.1076166182756424
Test Loss:  0.14436352252960205
Valid Loss:  0.1321653574705124
Epoch:  24  	Training Loss: 0.10759147256612778
Test Loss:  0.14434170722961426
Valid Loss:  0.13214905560016632
Epoch:  25  	Training Loss: 0.10756967961788177
Test Loss:  0.14432108402252197
Valid Loss:  0.13213345408439636
Epoch:  26  	Training Loss: 0.10754994302988052
Test Loss:  0.144302099943161
Valid Loss:  0.1321185827255249
Epoch:  27  	Training Loss: 0.10753235965967178
Test Loss:  0.1442844569683075
Valid Loss:  0.13210394978523254
Epoch:  28  	Training Loss: 0.10751518607139587
Test Loss:  0.14426755905151367
Valid Loss:  0.13208937644958496
Epoch:  29  	Training Loss: 0.10749821364879608
Test Loss:  0.14425131678581238
Valid Loss:  0.1320749670267105
Epoch:  30  	Training Loss: 0.10748198628425598
Test Loss:  0.14423587918281555
Valid Loss:  0.13206101953983307
Epoch:  31  	Training Loss: 0.1074666827917099
Test Loss:  0.14422115683555603
Valid Loss:  0.13204710185527802
Epoch:  32  	Training Loss: 0.10745144635438919
Test Loss:  0.14420735836029053
Valid Loss:  0.1320335865020752
Epoch:  33  	Training Loss: 0.1074371188879013
Test Loss:  0.14419370889663696
Valid Loss:  0.13202020525932312
Epoch:  34  	Training Loss: 0.10742306709289551
Test Loss:  0.1441800594329834
Valid Loss:  0.13200682401657104
Epoch:  35  	Training Loss: 0.1074090376496315
Test Loss:  0.14416685700416565
Valid Loss:  0.13199347257614136
Epoch:  36  	Training Loss: 0.10739505290985107
Test Loss:  0.14415398240089417
Valid Loss:  0.13198035955429077
Epoch:  37  	Training Loss: 0.10738154500722885
Test Loss:  0.1441413164138794
Valid Loss:  0.1319679617881775
Epoch:  38  	Training Loss: 0.10736864805221558
Test Loss:  0.1441289186477661
Valid Loss:  0.1319558173418045
Epoch:  39  	Training Loss: 0.10735618323087692
Test Loss:  0.1441165953874588
Valid Loss:  0.13194377720355988
Epoch:  40  	Training Loss: 0.10734398663043976
Test Loss:  0.14410430192947388
Valid Loss:  0.13193199038505554
Epoch:  41  	Training Loss: 0.10733196139335632
Test Loss:  0.14409220218658447
Valid Loss:  0.1319206804037094
Epoch:  42  	Training Loss: 0.10732033103704453
Test Loss:  0.14408017694950104
Valid Loss:  0.13190943002700806
Epoch:  43  	Training Loss: 0.1073089987039566
Test Loss:  0.14406827092170715
Valid Loss:  0.13189825415611267
Epoch:  44  	Training Loss: 0.1072978749871254
Test Loss:  0.14405643939971924
Valid Loss:  0.13188716769218445
Epoch:  45  	Training Loss: 0.10728701949119568
Test Loss:  0.14404472708702087
Valid Loss:  0.1318761706352234
Epoch:  46  	Training Loss: 0.10727638751268387
Test Loss:  0.144033282995224
Valid Loss:  0.1318654716014862
Epoch:  47  	Training Loss: 0.10726599395275116
Test Loss:  0.14402219653129578
Valid Loss:  0.1318551003932953
Epoch:  48  	Training Loss: 0.10725589096546173
Test Loss:  0.14401118457317352
Valid Loss:  0.13184478878974915
Epoch:  49  	Training Loss: 0.10724595934152603
Test Loss:  0.14400018751621246
Valid Loss:  0.1318344920873642
Epoch:  50  	Training Loss: 0.10723603516817093
Test Loss:  0.1439891755580902
Valid Loss:  0.13182419538497925
Epoch:  51  	Training Loss: 0.10722612589597702
Test Loss:  0.14397817850112915
Valid Loss:  0.1318139135837555
Epoch:  52  	Training Loss: 0.10721621662378311
Test Loss:  0.14396697282791138
Valid Loss:  0.13180342316627502
Epoch:  53  	Training Loss: 0.10720613598823547
Test Loss:  0.1439557671546936
Valid Loss:  0.13179291784763336
Epoch:  54  	Training Loss: 0.10719608515501022
Test Loss:  0.14394471049308777
Valid Loss:  0.13178250193595886
Epoch:  55  	Training Loss: 0.10718617588281631
Test Loss:  0.14393390715122223
Valid Loss:  0.13177207112312317
Epoch:  56  	Training Loss: 0.107176274061203
Test Loss:  0.14392316341400146
Valid Loss:  0.13176171481609344
Epoch:  57  	Training Loss: 0.10716652870178223
Test Loss:  0.1439124196767807
Valid Loss:  0.13175134360790253
Epoch:  58  	Training Loss: 0.10715683549642563
Test Loss:  0.1439017951488495
Valid Loss:  0.13174113631248474
Epoch:  59  	Training Loss: 0.1071474477648735
Test Loss:  0.14389124512672424
Valid Loss:  0.13173101842403412
Epoch:  60  	Training Loss: 0.10713817179203033
Test Loss:  0.14388076961040497
Valid Loss:  0.13172118365764618
Epoch:  61  	Training Loss: 0.10712900757789612
Test Loss:  0.1438702791929245
Valid Loss:  0.13171136379241943
Epoch:  62  	Training Loss: 0.1071198582649231
Test Loss:  0.1438596546649933
Valid Loss:  0.13170140981674194
Epoch:  63  	Training Loss: 0.10711058974266052
Test Loss:  0.14384904503822327
Valid Loss:  0.13169145584106445
Epoch:  64  	Training Loss: 0.10710136592388153
Test Loss:  0.14383849501609802
Valid Loss:  0.13168153166770935
Epoch:  65  	Training Loss: 0.1070922389626503
Test Loss:  0.14382794499397278
Valid Loss:  0.13167163729667664
Epoch:  66  	Training Loss: 0.10708311200141907
Test Loss:  0.14381739497184753
Valid Loss:  0.13166174292564392
Epoch:  67  	Training Loss: 0.10707402229309082
Test Loss:  0.14380690455436707
Valid Loss:  0.13165204226970673
Epoch:  68  	Training Loss: 0.10706514120101929
Test Loss:  0.14379653334617615
Valid Loss:  0.13164250552654266
Epoch:  69  	Training Loss: 0.10705641657114029
Test Loss:  0.14378622174263
Valid Loss:  0.13163304328918457
Epoch:  70  	Training Loss: 0.10704778134822845
Test Loss:  0.14377591013908386
Valid Loss:  0.1316237449645996
Epoch:  71  	Training Loss: 0.10703915357589722
Test Loss:  0.14376558363437653
Valid Loss:  0.13161450624465942
Epoch:  72  	Training Loss: 0.10703051090240479
Test Loss:  0.14375507831573486
Valid Loss:  0.13160507380962372
Epoch:  73  	Training Loss: 0.107021763920784
Test Loss:  0.1437448263168335
Valid Loss:  0.1315957009792328
 15%|█▌        | 75/500 [00:54<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:13,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<08:00,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:43,  1.18it/s] 19%|█▉        | 95/500 [01:07<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:14<07:47,  1.17s/it] 21%|██        | 103/500 [01:14<05:34,  1.19it/s] 21%|██        | 105/500 [01:14<04:01,  1.63it/s] 21%|██▏       | 107/500 [01:14<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:15<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:21<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:55,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.00it/s] 24%|██▍       | 121/500 [01:28<07:32,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:28<03:52,  1.62it/s] 25%|██▌       | 127/500 [01:28<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:28<02:04,  2.97it/s] 26%|██▌       | 131/500 [01:35<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:35<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:41<07:01,  1.17s/it] 29%|██▊       | 143/500 [01:42<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:42<03:36,  1.64it/s]Epoch:  74  	Training Loss: 0.10701307654380798
Test Loss:  0.14373460412025452
Valid Loss:  0.13158643245697021
Epoch:  75  	Training Loss: 0.10700442641973495
Test Loss:  0.14372456073760986
Valid Loss:  0.1315772980451584
Epoch:  76  	Training Loss: 0.10699586570262909
Test Loss:  0.14371463656425476
Valid Loss:  0.13156819343566895
Epoch:  77  	Training Loss: 0.10698740184307098
Test Loss:  0.14370472729206085
Valid Loss:  0.1315591037273407
Epoch:  78  	Training Loss: 0.10697893798351288
Test Loss:  0.14369481801986694
Valid Loss:  0.13155001401901245
Epoch:  79  	Training Loss: 0.10697050392627716
Test Loss:  0.14368495345115662
Valid Loss:  0.1315409541130066
Epoch:  80  	Training Loss: 0.10696214437484741
Test Loss:  0.1436750739812851
Valid Loss:  0.1315319538116455
Epoch:  81  	Training Loss: 0.10695379227399826
Test Loss:  0.14366522431373596
Valid Loss:  0.13152308762073517
Epoch:  82  	Training Loss: 0.10694544017314911
Test Loss:  0.14365515112876892
Valid Loss:  0.1315140575170517
Epoch:  83  	Training Loss: 0.10693693161010742
Test Loss:  0.14364545047283173
Valid Loss:  0.13150563836097717
Epoch:  84  	Training Loss: 0.10692872852087021
Test Loss:  0.1436362862586975
Valid Loss:  0.13149765133857727
Epoch:  85  	Training Loss: 0.10692109167575836
Test Loss:  0.1436275839805603
Valid Loss:  0.1314900517463684
Epoch:  86  	Training Loss: 0.10691364854574203
Test Loss:  0.1436193287372589
Valid Loss:  0.13148283958435059
Epoch:  87  	Training Loss: 0.10690672695636749
Test Loss:  0.14361147582530975
Valid Loss:  0.13147622346878052
Epoch:  88  	Training Loss: 0.10690014809370041
Test Loss:  0.1436038613319397
Valid Loss:  0.1314697563648224
Epoch:  89  	Training Loss: 0.10689367353916168
Test Loss:  0.1435963213443756
Valid Loss:  0.13146346807479858
Epoch:  90  	Training Loss: 0.10688730329275131
Test Loss:  0.14358913898468018
Valid Loss:  0.1314573585987091
Epoch:  91  	Training Loss: 0.10688110440969467
Test Loss:  0.14358215034008026
Valid Loss:  0.13145187497138977
Epoch:  92  	Training Loss: 0.10687518119812012
Test Loss:  0.14357557892799377
Valid Loss:  0.1314469426870346
Epoch:  93  	Training Loss: 0.10686972737312317
Test Loss:  0.14356933534145355
Valid Loss:  0.13144227862358093
Epoch:  94  	Training Loss: 0.10686460137367249
Test Loss:  0.14356321096420288
Valid Loss:  0.13143770396709442
Epoch:  95  	Training Loss: 0.10685959458351135
Test Loss:  0.14355739951133728
Valid Loss:  0.13143324851989746
Epoch:  96  	Training Loss: 0.10685468465089798
Test Loss:  0.1435518115758896
Valid Loss:  0.13142900168895721
Epoch:  97  	Training Loss: 0.10684997588396072
Test Loss:  0.14354641735553741
Valid Loss:  0.13142496347427368
Epoch:  98  	Training Loss: 0.10684534907341003
Test Loss:  0.14354141056537628
Valid Loss:  0.13142114877700806
Epoch:  99  	Training Loss: 0.1068408340215683
Test Loss:  0.14353647828102112
Valid Loss:  0.1314173936843872
Epoch:  100  	Training Loss: 0.10683636367321014
Test Loss:  0.14353159070014954
Valid Loss:  0.13141366839408875
Epoch:  101  	Training Loss: 0.10683191567659378
Test Loss:  0.14352679252624512
Valid Loss:  0.131410151720047
Epoch:  102  	Training Loss: 0.1068275198340416
Test Loss:  0.1435219794511795
Valid Loss:  0.1314067244529724
Epoch:  103  	Training Loss: 0.1068231388926506
Test Loss:  0.14351733028888702
Valid Loss:  0.13140347599983215
Epoch:  104  	Training Loss: 0.10681889951229095
Test Loss:  0.14351266622543335
Valid Loss:  0.13140030205249786
Epoch:  105  	Training Loss: 0.1068146824836731
Test Loss:  0.14350810647010803
Valid Loss:  0.13139718770980835
Epoch:  106  	Training Loss: 0.1068105474114418
Test Loss:  0.14350378513336182
Valid Loss:  0.1313941478729248
Epoch:  107  	Training Loss: 0.10680653154850006
Test Loss:  0.14349952340126038
Valid Loss:  0.13139110803604126
Epoch:  108  	Training Loss: 0.1068025678396225
Test Loss:  0.14349539577960968
Valid Loss:  0.1313880980014801
Epoch:  109  	Training Loss: 0.10679864883422852
Test Loss:  0.14349129796028137
Valid Loss:  0.13138511776924133
Epoch:  110  	Training Loss: 0.10679477453231812
Test Loss:  0.14348727464675903
Valid Loss:  0.13138222694396973
Epoch:  111  	Training Loss: 0.10679101198911667
Test Loss:  0.1434832513332367
Valid Loss:  0.1313793957233429
Epoch:  112  	Training Loss: 0.1067872866988182
Test Loss:  0.14347928762435913
Valid Loss:  0.131376713514328
Epoch:  113  	Training Loss: 0.10678353905677795
Test Loss:  0.1434754729270935
Valid Loss:  0.1313742995262146
Epoch:  114  	Training Loss: 0.10677984356880188
Test Loss:  0.14347177743911743
Valid Loss:  0.13137193024158478
Epoch:  115  	Training Loss: 0.10677626729011536
Test Loss:  0.14346815645694733
Valid Loss:  0.13136962056159973
Epoch:  116  	Training Loss: 0.10677281022071838
Test Loss:  0.14346478879451752
Valid Loss:  0.13136738538742065
Epoch:  117  	Training Loss: 0.10676950216293335
Test Loss:  0.14346158504486084
Valid Loss:  0.13136515021324158
Epoch:  118  	Training Loss: 0.10676628351211548
Test Loss:  0.1434585005044937
Valid Loss:  0.13136295974254608
Epoch:  119  	Training Loss: 0.10676315426826477
Test Loss:  0.14345549046993256
Valid Loss:  0.13136079907417297
Epoch:  120  	Training Loss: 0.10676013678312302
Test Loss:  0.1434524804353714
Valid Loss:  0.13135865330696106
Epoch:  121  	Training Loss: 0.10675714164972305
Test Loss:  0.14344953000545502
Valid Loss:  0.13135655224323273
Epoch:  122  	Training Loss: 0.10675419867038727
Test Loss:  0.14344671368598938
Valid Loss:  0.131354421377182
Epoch:  123  	Training Loss: 0.10675133764743805
Test Loss:  0.1434439718723297
Valid Loss:  0.13135242462158203
Epoch:  124  	Training Loss: 0.10674852132797241
Test Loss:  0.14344128966331482
Valid Loss:  0.13135044276714325
Epoch:  125  	Training Loss: 0.10674569755792618
Test Loss:  0.14343860745429993
Valid Loss:  0.13134850561618805
Epoch:  126  	Training Loss: 0.10674288868904114
Test Loss:  0.1434360146522522
Valid Loss:  0.13134661316871643
Epoch:  127  	Training Loss: 0.10674011707305908
Test Loss:  0.14343348145484924
Valid Loss:  0.1313447207212448
Epoch:  128  	Training Loss: 0.10673736035823822
Test Loss:  0.1434309333562851
Valid Loss:  0.13134285807609558
Epoch:  129  	Training Loss: 0.10673461854457855
Test Loss:  0.14342842996120453
Valid Loss:  0.13134101033210754
Epoch:  130  	Training Loss: 0.10673190653324127
Test Loss:  0.14342600107192993
Valid Loss:  0.1313391625881195
Epoch:  131  	Training Loss: 0.10672920942306519
Test Loss:  0.1434236466884613
Valid Loss:  0.13133735954761505
Epoch:  132  	Training Loss: 0.1067265048623085
Test Loss:  0.14342138171195984
Valid Loss:  0.13133567571640015
Epoch:  133  	Training Loss: 0.10672387480735779
Test Loss:  0.14341917634010315
Valid Loss:  0.13133400678634644
Epoch:  134  	Training Loss: 0.10672125220298767
Test Loss:  0.1434171348810196
Valid Loss:  0.1313323676586151
Epoch:  135  	Training Loss: 0.10671864449977875
Test Loss:  0.1434154212474823
Valid Loss:  0.13133078813552856
Epoch:  136  	Training Loss: 0.1067160815000534
Test Loss:  0.14341378211975098
Valid Loss:  0.1313292235136032
Epoch:  137  	Training Loss: 0.10671358555555344
Test Loss:  0.14341214299201965
Valid Loss:  0.13132768869400024
Epoch:  138  	Training Loss: 0.10671116411685944
Test Loss:  0.1434105485677719
Valid Loss:  0.13132616877555847
Epoch:  139  	Training Loss: 0.10670877993106842
Test Loss:  0.14340901374816895
Valid Loss:  0.1313246637582779
Epoch:  140  	Training Loss: 0.10670648515224457
Test Loss:  0.14340755343437195
Valid Loss:  0.1313231885433197
Epoch:  141  	Training Loss: 0.1067042350769043
Test Loss:  0.14340610802173615
Valid Loss:  0.1313217282295227
Epoch:  142  	Training Loss: 0.1067020446062088
Test Loss:  0.1434047669172287
Valid Loss:  0.13132032752037048
Epoch:  143  	Training Loss: 0.10670001059770584
Test Loss:  0.14340342581272125
Valid Loss:  0.13131894171237946
Epoch:  144  	Training Loss: 0.10669803619384766
Test Loss:  0.1434021294116974
Valid Loss:  0.131317600607872
Epoch:  145  	Training Loss: 0.10669617354869843
Test Loss:  0.1434008777141571
Valid Loss:  0.13131627440452576
Epoch:  146  	Training Loss: 0.10669433325529099
Test Loss:   29%|██▉       | 147/500 [01:42<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:42<01:57,  2.99it/s] 30%|███       | 151/500 [01:48<06:51,  1.18s/it] 31%|███       | 153/500 [01:48<04:54,  1.18it/s] 31%|███       | 155/500 [01:49<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:55<06:41,  1.18s/it] 33%|███▎      | 163/500 [01:55<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:55<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.22it/s] 34%|███▍      | 169/500 [01:56<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:02<06:34,  1.20s/it] 35%|███▍      | 173/500 [02:02<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:02<03:22,  1.61it/s] 35%|███▌      | 177/500 [02:02<02:27,  2.20it/s] 36%|███▌      | 179/500 [02:03<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:09<06:22,  1.20s/it] 37%|███▋      | 183/500 [02:09<04:32,  1.16it/s] 37%|███▋      | 185/500 [02:09<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:09<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:10<01:45,  2.96it/s] 38%|███▊      | 191/500 [02:16<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:16<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:07,  1.62it/s] 39%|███▉      | 197/500 [02:16<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:16<01:41,  2.97it/s] 40%|████      | 201/500 [02:23<05:51,  1.17s/it] 41%|████      | 203/500 [02:23<04:11,  1.18it/s] 41%|████      | 205/500 [02:23<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:23<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:29<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:30<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.24it/s]0.14339956641197205
Valid Loss:  0.1313149482011795
Epoch:  147  	Training Loss: 0.10669249296188354
Test Loss:  0.14339829981327057
Valid Loss:  0.13131362199783325
Epoch:  148  	Training Loss: 0.1066906675696373
Test Loss:  0.14339704811573029
Valid Loss:  0.13131237030029297
Epoch:  149  	Training Loss: 0.10668890178203583
Test Loss:  0.1433958113193512
Valid Loss:  0.13131116330623627
Epoch:  150  	Training Loss: 0.10668718814849854
Test Loss:  0.1433946192264557
Valid Loss:  0.13130998611450195
Epoch:  151  	Training Loss: 0.10668550431728363
Test Loss:  0.1433933973312378
Valid Loss:  0.13130879402160645
Epoch:  152  	Training Loss: 0.1066838800907135
Test Loss:  0.14339224994182587
Valid Loss:  0.1313076615333557
Epoch:  153  	Training Loss: 0.10668231546878815
Test Loss:  0.14339110255241394
Valid Loss:  0.13130652904510498
Epoch:  154  	Training Loss: 0.10668077319860458
Test Loss:  0.14339008927345276
Valid Loss:  0.13130545616149902
Epoch:  155  	Training Loss: 0.10667937994003296
Test Loss:  0.14338909089565277
Valid Loss:  0.13130438327789307
Epoch:  156  	Training Loss: 0.10667800903320312
Test Loss:  0.14338812232017517
Valid Loss:  0.1313033103942871
Epoch:  157  	Training Loss: 0.10667666047811508
Test Loss:  0.14338719844818115
Valid Loss:  0.13130226731300354
Epoch:  158  	Training Loss: 0.10667533427476883
Test Loss:  0.14338628947734833
Valid Loss:  0.13130122423171997
Epoch:  159  	Training Loss: 0.10667401552200317
Test Loss:  0.1433853954076767
Valid Loss:  0.1313001811504364
Epoch:  160  	Training Loss: 0.1066727414727211
Test Loss:  0.14338450133800507
Valid Loss:  0.13129915297031403
Epoch:  161  	Training Loss: 0.10667145997285843
Test Loss:  0.14338365197181702
Valid Loss:  0.13129812479019165
Epoch:  162  	Training Loss: 0.10667020082473755
Test Loss:  0.14338289201259613
Valid Loss:  0.13129714131355286
Epoch:  163  	Training Loss: 0.10666900128126144
Test Loss:  0.14338216185569763
Valid Loss:  0.13129617273807526
Epoch:  164  	Training Loss: 0.10666782408952713
Test Loss:  0.14338144659996033
Valid Loss:  0.13129518926143646
Epoch:  165  	Training Loss: 0.1066666692495346
Test Loss:  0.14338070154190063
Valid Loss:  0.13129422068595886
Epoch:  166  	Training Loss: 0.10666550695896149
Test Loss:  0.14338001608848572
Valid Loss:  0.13129325211048126
Epoch:  167  	Training Loss: 0.10666435956954956
Test Loss:  0.1433793157339096
Valid Loss:  0.13129229843616486
Epoch:  168  	Training Loss: 0.10666319727897644
Test Loss:  0.1433786153793335
Valid Loss:  0.13129132986068726
Epoch:  169  	Training Loss: 0.10666204243898392
Test Loss:  0.14337795972824097
Valid Loss:  0.13129034638404846
Epoch:  170  	Training Loss: 0.10666089504957199
Test Loss:  0.14337730407714844
Valid Loss:  0.13128939270973206
Epoch:  171  	Training Loss: 0.10665975511074066
Test Loss:  0.1433766633272171
Valid Loss:  0.13128843903541565
Epoch:  172  	Training Loss: 0.10665863007307053
Test Loss:  0.14337602257728577
Valid Loss:  0.13128745555877686
Epoch:  173  	Training Loss: 0.10665750503540039
Test Loss:  0.14337536692619324
Valid Loss:  0.13128650188446045
Epoch:  174  	Training Loss: 0.10665637254714966
Test Loss:  0.14337469637393951
Valid Loss:  0.13128554821014404
Epoch:  175  	Training Loss: 0.10665524750947952
Test Loss:  0.14337404072284698
Valid Loss:  0.13128457963466644
Epoch:  176  	Training Loss: 0.10665411502122879
Test Loss:  0.14337339997291565
Valid Loss:  0.13128361105918884
Epoch:  177  	Training Loss: 0.10665298998355865
Test Loss:  0.1433727741241455
Valid Loss:  0.13128265738487244
Epoch:  178  	Training Loss: 0.10665186494588852
Test Loss:  0.14337214827537537
Valid Loss:  0.13128170371055603
Epoch:  179  	Training Loss: 0.10665077716112137
Test Loss:  0.1433715522289276
Valid Loss:  0.131280779838562
Epoch:  180  	Training Loss: 0.1066497191786766
Test Loss:  0.14337092638015747
Valid Loss:  0.131279855966568
Epoch:  181  	Training Loss: 0.10664865374565125
Test Loss:  0.14337033033370972
Valid Loss:  0.13127897679805756
Epoch:  182  	Training Loss: 0.10664761066436768
Test Loss:  0.14336974918842316
Valid Loss:  0.1312781572341919
Epoch:  183  	Training Loss: 0.10664662718772888
Test Loss:  0.1433691680431366
Valid Loss:  0.13127735257148743
Epoch:  184  	Training Loss: 0.10664567351341248
Test Loss:  0.14336860179901123
Valid Loss:  0.13127656280994415
Epoch:  185  	Training Loss: 0.10664473474025726
Test Loss:  0.14336803555488586
Valid Loss:  0.13127578794956207
Epoch:  186  	Training Loss: 0.10664381831884384
Test Loss:  0.14336749911308289
Valid Loss:  0.13127501308918
Epoch:  187  	Training Loss: 0.10664290934801102
Test Loss:  0.14336693286895752
Valid Loss:  0.1312742382287979
Epoch:  188  	Training Loss: 0.10664200782775879
Test Loss:  0.14336638152599335
Valid Loss:  0.13127347826957703
Epoch:  189  	Training Loss: 0.10664110630750656
Test Loss:  0.14336583018302917
Valid Loss:  0.13127273321151733
Epoch:  190  	Training Loss: 0.10664022713899612
Test Loss:  0.143365278840065
Valid Loss:  0.13127198815345764
Epoch:  191  	Training Loss: 0.10663935542106628
Test Loss:  0.14336472749710083
Valid Loss:  0.13127124309539795
Epoch:  192  	Training Loss: 0.10663847625255585
Test Loss:  0.14336419105529785
Valid Loss:  0.13127052783966064
Epoch:  193  	Training Loss: 0.1066376119852066
Test Loss:  0.14336365461349487
Valid Loss:  0.13126978278160095
Epoch:  194  	Training Loss: 0.10663674026727676
Test Loss:  0.1433631181716919
Valid Loss:  0.13126905262470245
Epoch:  195  	Training Loss: 0.10663589090108871
Test Loss:  0.14336258172988892
Valid Loss:  0.13126832246780396
Epoch:  196  	Training Loss: 0.10663504898548126
Test Loss:  0.14336207509040833
Valid Loss:  0.13126760721206665
Epoch:  197  	Training Loss: 0.1066342294216156
Test Loss:  0.14336155354976654
Valid Loss:  0.13126689195632935
Epoch:  198  	Training Loss: 0.10663342475891113
Test Loss:  0.14336103200912476
Valid Loss:  0.13126620650291443
Epoch:  199  	Training Loss: 0.10663262009620667
Test Loss:  0.14336049556732178
Valid Loss:  0.13126549124717712
Epoch:  200  	Training Loss: 0.1066318228840828
Test Loss:  0.1433599889278412
Valid Loss:  0.13126477599143982
Epoch:  201  	Training Loss: 0.10663102567195892
Test Loss:  0.1433594822883606
Valid Loss:  0.1312641054391861
Epoch:  202  	Training Loss: 0.10663027316331863
Test Loss:  0.1433590054512024
Valid Loss:  0.13126343488693237
Epoch:  203  	Training Loss: 0.10662952065467834
Test Loss:  0.1433585286140442
Valid Loss:  0.13126276433467865
Epoch:  204  	Training Loss: 0.10662877559661865
Test Loss:  0.1433580368757248
Valid Loss:  0.13126209378242493
Epoch:  205  	Training Loss: 0.10662803053855896
Test Loss:  0.14335757493972778
Valid Loss:  0.1312614381313324
Epoch:  206  	Training Loss: 0.10662728548049927
Test Loss:  0.1433570832014084
Valid Loss:  0.13126076757907867
Epoch:  207  	Training Loss: 0.10662655532360077
Test Loss:  0.143356591463089
Valid Loss:  0.13126009702682495
Epoch:  208  	Training Loss: 0.10662581026554108
Test Loss:  0.1433561146259308
Valid Loss:  0.13125944137573242
Epoch:  209  	Training Loss: 0.10662507265806198
Test Loss:  0.14335563778877258
Valid Loss:  0.1312587559223175
Epoch:  210  	Training Loss: 0.10662433505058289
Test Loss:  0.14335517585277557
Valid Loss:  0.13125811517238617
Epoch:  211  	Training Loss: 0.10662363469600677
Test Loss:  0.14335469901561737
Valid Loss:  0.13125747442245483
Epoch:  212  	Training Loss: 0.10662291944026947
Test Loss:  0.14335423707962036
Valid Loss:  0.1312568038702011
Epoch:  213  	Training Loss: 0.10662220418453217
Test Loss:  0.14335376024246216
Valid Loss:  0.13125614821910858
Epoch:  214  	Training Loss: 0.10662150382995605
Test Loss:  0.14335328340530396
Valid Loss:  0.13125550746917725
Epoch:  215  	Training Loss: 0.10662077367305756
Test Loss:  0.14335280656814575
Valid Loss:  0.13125483691692352
Epoch:  216  	Training Loss: 0.10662007331848145
Test Loss:  0.14335232973098755
Valid Loss:  0.1312541961669922
Epoch:  217  	Training Loss: 0.10661935806274414
Test Loss:  0.14335186779499054
Valid Loss:  0.13125352561473846
Epoch:  218  	Training Loss: 0.10661865770816803
Test Loss:  0.14335140585899353
Valid Loss:  44%|████▍     | 219/500 [02:30<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:36<05:27,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:37<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:37<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:37<01:30,  3.01it/s] 46%|████▌     | 231/500 [02:43<05:19,  1.19s/it] 47%|████▋     | 233/500 [02:43<03:47,  1.17it/s] 47%|████▋     | 235/500 [02:43<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:44<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:44<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:50<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.00it/s] 50%|█████     | 251/500 [02:57<04:51,  1.17s/it] 51%|█████     | 253/500 [02:57<03:27,  1.19it/s] 51%|█████     | 255/500 [02:57<02:28,  1.65it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:57<01:20,  3.01it/s] 52%|█████▏    | 261/500 [03:04<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:04<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:22,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:10<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:11<03:11,  1.19it/s] 55%|█████▌    | 275/500 [03:11<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:11<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:11<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:17<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.64it/s] 57%|█████▋    | 287/500 [03:18<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:18<01:10,  3.01it/s] 0.13125288486480713
Epoch:  219  	Training Loss: 0.1066179871559143
Test Loss:  0.14335095882415771
Valid Loss:  0.131252259016037
Epoch:  220  	Training Loss: 0.10661730170249939
Test Loss:  0.1433505117893219
Valid Loss:  0.13125160336494446
Epoch:  221  	Training Loss: 0.10661663115024567
Test Loss:  0.14335006475448608
Valid Loss:  0.13125096261501312
Epoch:  222  	Training Loss: 0.10661595314741135
Test Loss:  0.14334960281848907
Valid Loss:  0.13125033676624298
Epoch:  223  	Training Loss: 0.10661528259515762
Test Loss:  0.14334917068481445
Valid Loss:  0.13124969601631165
Epoch:  224  	Training Loss: 0.1066146120429039
Test Loss:  0.14334875345230103
Valid Loss:  0.1312490552663803
Epoch:  225  	Training Loss: 0.10661394149065018
Test Loss:  0.1433483511209488
Valid Loss:  0.13124841451644897
Epoch:  226  	Training Loss: 0.10661326348781586
Test Loss:  0.14334794878959656
Valid Loss:  0.13124778866767883
Epoch:  227  	Training Loss: 0.10661262273788452
Test Loss:  0.1433475911617279
Valid Loss:  0.1312471628189087
Epoch:  228  	Training Loss: 0.10661202669143677
Test Loss:  0.14334721863269806
Valid Loss:  0.13124656677246094
Epoch:  229  	Training Loss: 0.10661142319440842
Test Loss:  0.1433468461036682
Valid Loss:  0.13124597072601318
Epoch:  230  	Training Loss: 0.10661082714796066
Test Loss:  0.14334648847579956
Valid Loss:  0.13124538958072662
Epoch:  231  	Training Loss: 0.10661023110151291
Test Loss:  0.14334611594676971
Valid Loss:  0.13124477863311768
Epoch:  232  	Training Loss: 0.10660964250564575
Test Loss:  0.14334577322006226
Valid Loss:  0.1312442272901535
Epoch:  233  	Training Loss: 0.10660906881093979
Test Loss:  0.1433454155921936
Valid Loss:  0.13124364614486694
Epoch:  234  	Training Loss: 0.10660849511623383
Test Loss:  0.14334511756896973
Valid Loss:  0.13124307990074158
Epoch:  235  	Training Loss: 0.10660791397094727
Test Loss:  0.14334481954574585
Valid Loss:  0.1312425136566162
Epoch:  236  	Training Loss: 0.1066073402762413
Test Loss:  0.14334452152252197
Valid Loss:  0.13124194741249084
Epoch:  237  	Training Loss: 0.10660676658153534
Test Loss:  0.1433442234992981
Valid Loss:  0.13124138116836548
Epoch:  238  	Training Loss: 0.10660620033740997
Test Loss:  0.14334392547607422
Valid Loss:  0.1312408447265625
Epoch:  239  	Training Loss: 0.10660567879676819
Test Loss:  0.14334362745285034
Valid Loss:  0.13124029338359833
Epoch:  240  	Training Loss: 0.1066051498055458
Test Loss:  0.14334334433078766
Valid Loss:  0.13123974204063416
Epoch:  241  	Training Loss: 0.10660462826490402
Test Loss:  0.14334306120872498
Valid Loss:  0.13123920559883118
Epoch:  242  	Training Loss: 0.10660410672426224
Test Loss:  0.1433427929878235
Valid Loss:  0.1312386840581894
Epoch:  243  	Training Loss: 0.10660359263420105
Test Loss:  0.1433424949645996
Valid Loss:  0.13123813271522522
Epoch:  244  	Training Loss: 0.10660307109355927
Test Loss:  0.14334221184253693
Valid Loss:  0.13123759627342224
Epoch:  245  	Training Loss: 0.10660254955291748
Test Loss:  0.14334192872047424
Valid Loss:  0.13123705983161926
Epoch:  246  	Training Loss: 0.10660204291343689
Test Loss:  0.14334166049957275
Valid Loss:  0.13123655319213867
Epoch:  247  	Training Loss: 0.10660156607627869
Test Loss:  0.14334137737751007
Valid Loss:  0.13123606145381927
Epoch:  248  	Training Loss: 0.10660110414028168
Test Loss:  0.14334112405776978
Valid Loss:  0.13123556971549988
Epoch:  249  	Training Loss: 0.10660064220428467
Test Loss:  0.1433408409357071
Valid Loss:  0.13123509287834167
Epoch:  250  	Training Loss: 0.10660019516944885
Test Loss:  0.1433405876159668
Valid Loss:  0.13123463094234467
Epoch:  251  	Training Loss: 0.10659973323345184
Test Loss:  0.1433403193950653
Valid Loss:  0.13123416900634766
Epoch:  252  	Training Loss: 0.10659928619861603
Test Loss:  0.14334005117416382
Valid Loss:  0.13123373687267303
Epoch:  253  	Training Loss: 0.1065988540649414
Test Loss:  0.14333978295326233
Valid Loss:  0.1312333047389984
Epoch:  254  	Training Loss: 0.10659841448068619
Test Loss:  0.14333952963352203
Valid Loss:  0.13123288750648499
Epoch:  255  	Training Loss: 0.10659800469875336
Test Loss:  0.14333927631378174
Valid Loss:  0.13123247027397156
Epoch:  256  	Training Loss: 0.10659761726856232
Test Loss:  0.14333900809288025
Valid Loss:  0.13123208284378052
Epoch:  257  	Training Loss: 0.10659724473953247
Test Loss:  0.14333876967430115
Valid Loss:  0.13123169541358948
Epoch:  258  	Training Loss: 0.10659685730934143
Test Loss:  0.14333853125572205
Valid Loss:  0.13123127818107605
Epoch:  259  	Training Loss: 0.10659648478031158
Test Loss:  0.14333829283714294
Valid Loss:  0.131230890750885
Epoch:  260  	Training Loss: 0.10659611225128174
Test Loss:  0.14333805441856384
Valid Loss:  0.13123050332069397
Epoch:  261  	Training Loss: 0.1065957248210907
Test Loss:  0.14333787560462952
Valid Loss:  0.13123014569282532
Epoch:  262  	Training Loss: 0.10659535974264145
Test Loss:  0.1433376669883728
Valid Loss:  0.13122980296611786
Epoch:  263  	Training Loss: 0.1065949946641922
Test Loss:  0.14333751797676086
Valid Loss:  0.1312294602394104
Epoch:  264  	Training Loss: 0.10659464448690414
Test Loss:  0.14333735406398773
Valid Loss:  0.13122911751270294
Epoch:  265  	Training Loss: 0.10659428685903549
Test Loss:  0.1433372050523758
Valid Loss:  0.1312287598848343
Epoch:  266  	Training Loss: 0.10659393668174744
Test Loss:  0.14333704113960266
Valid Loss:  0.13122841715812683
Epoch:  267  	Training Loss: 0.10659357905387878
Test Loss:  0.14333689212799072
Valid Loss:  0.13122805953025818
Epoch:  268  	Training Loss: 0.10659322142601013
Test Loss:  0.1433367282152176
Valid Loss:  0.13122771680355072
Epoch:  269  	Training Loss: 0.10659286379814148
Test Loss:  0.14333656430244446
Valid Loss:  0.13122737407684326
Epoch:  270  	Training Loss: 0.10659251362085342
Test Loss:  0.14333641529083252
Valid Loss:  0.131227046251297
Epoch:  271  	Training Loss: 0.10659216344356537
Test Loss:  0.1433362513780594
Valid Loss:  0.13122673332691193
Epoch:  272  	Training Loss: 0.10659180581569672
Test Loss:  0.14333610236644745
Valid Loss:  0.13122642040252686
Epoch:  273  	Training Loss: 0.10659146308898926
Test Loss:  0.14333593845367432
Valid Loss:  0.13122612237930298
Epoch:  274  	Training Loss: 0.1065911129117012
Test Loss:  0.14333578944206238
Valid Loss:  0.1312258243560791
Epoch:  275  	Training Loss: 0.10659076273441315
Test Loss:  0.14333564043045044
Valid Loss:  0.13122552633285522
Epoch:  276  	Training Loss: 0.10659042000770569
Test Loss:  0.1433354914188385
Valid Loss:  0.13122522830963135
Epoch:  277  	Training Loss: 0.10659006983041763
Test Loss:  0.14333534240722656
Valid Loss:  0.13122493028640747
Epoch:  278  	Training Loss: 0.10658971965312958
Test Loss:  0.14333519339561462
Valid Loss:  0.1312246322631836
Epoch:  279  	Training Loss: 0.10658938437700272
Test Loss:  0.14333504438400269
Valid Loss:  0.13122433423995972
Epoch:  280  	Training Loss: 0.10658904910087585
Test Loss:  0.14333492517471313
Valid Loss:  0.13122403621673584
Epoch:  281  	Training Loss: 0.10658872872591019
Test Loss:  0.1433347761631012
Valid Loss:  0.13122376799583435
Epoch:  282  	Training Loss: 0.10658841580152512
Test Loss:  0.14333465695381165
Valid Loss:  0.13122348487377167
Epoch:  283  	Training Loss: 0.10658811032772064
Test Loss:  0.1433345228433609
Valid Loss:  0.13122320175170898
Epoch:  284  	Training Loss: 0.10658780485391617
Test Loss:  0.14333438873291016
Valid Loss:  0.1312229186296463
Epoch:  285  	Training Loss: 0.1065874993801117
Test Loss:  0.14333423972129822
Valid Loss:  0.13122263550758362
Epoch:  286  	Training Loss: 0.10658720135688782
Test Loss:  0.14333412051200867
Valid Loss:  0.13122236728668213
Epoch:  287  	Training Loss: 0.10658691078424454
Test Loss:  0.14333397150039673
Valid Loss:  0.13122208416461945
Epoch:  288  	Training Loss: 0.10658660531044006
Test Loss:  0.14333383738994598
Valid Loss:  0.13122180104255676
Epoch:  289  	Training Loss: 0.10658631473779678
Test Loss:  0.14333370327949524
Valid Loss:  0.13122153282165527
Epoch:  290  	Training Loss: 0.1065860316157341
Test Loss:  0.1433335840702057
Valid Loss:  0.13122126460075378
 58%|█████▊    | 291/500 [03:24<04:06,  1.18s/it] 59%|█████▊    | 293/500 [03:24<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:24<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:24<01:31,  2.23it/s] 60%|█████▉    | 299/500 [03:25<01:07,  2.98it/s] 60%|██████    | 301/500 [03:31<03:53,  1.18s/it] 61%|██████    | 303/500 [03:31<02:46,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:31<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:38<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:38<02:39,  1.18it/s] 63%|██████▎   | 315/500 [03:38<01:53,  1.62it/s] 63%|██████▎   | 317/500 [03:38<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:38<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:45<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:45<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:45<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:45<01:17,  2.22it/s] 66%|██████▌   | 329/500 [03:45<00:57,  2.99it/s] 66%|██████▌   | 331/500 [03:51<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:52<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:52<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:52<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:52<00:53,  3.01it/s] 68%|██████▊   | 341/500 [03:58<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:58<01:34,  1.65it/s] 69%|██████▉   | 347/500 [03:59<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:59<00:50,  3.02it/s] 70%|███████   | 351/500 [04:05<02:56,  1.18s/it] 71%|███████   | 353/500 [04:05<02:05,  1.17it/s] 71%|███████   | 355/500 [04:05<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:05<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:06<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:12<02:45,  1.19s/it]Epoch:  291  	Training Loss: 0.10658574104309082
Test Loss:  0.14333346486091614
Valid Loss:  0.1312209963798523
Epoch:  292  	Training Loss: 0.10658546537160873
Test Loss:  0.1433333307504654
Valid Loss:  0.13122069835662842
Epoch:  293  	Training Loss: 0.10658517479896545
Test Loss:  0.14333321154117584
Valid Loss:  0.13122044503688812
Epoch:  294  	Training Loss: 0.10658489167690277
Test Loss:  0.1433330774307251
Valid Loss:  0.13122017681598663
Epoch:  295  	Training Loss: 0.10658460855484009
Test Loss:  0.14333295822143555
Valid Loss:  0.13121990859508514
Epoch:  296  	Training Loss: 0.1065843254327774
Test Loss:  0.1433328539133072
Valid Loss:  0.13121964037418365
Epoch:  297  	Training Loss: 0.10658404231071472
Test Loss:  0.14333273470401764
Valid Loss:  0.13121937215328217
Epoch:  298  	Training Loss: 0.10658377408981323
Test Loss:  0.1433326154947281
Valid Loss:  0.13121911883354187
Epoch:  299  	Training Loss: 0.10658350586891174
Test Loss:  0.14333251118659973
Valid Loss:  0.13121885061264038
Epoch:  300  	Training Loss: 0.10658323764801025
Test Loss:  0.143332377076149
Valid Loss:  0.13121861219406128
Epoch:  301  	Training Loss: 0.10658297687768936
Test Loss:  0.14333227276802063
Valid Loss:  0.13121837377548218
Epoch:  302  	Training Loss: 0.10658273100852966
Test Loss:  0.14333213865756989
Valid Loss:  0.13121813535690308
Epoch:  303  	Training Loss: 0.10658249258995056
Test Loss:  0.14333201944828033
Valid Loss:  0.13121791183948517
Epoch:  304  	Training Loss: 0.10658223927021027
Test Loss:  0.14333191514015198
Valid Loss:  0.13121768832206726
Epoch:  305  	Training Loss: 0.10658200085163116
Test Loss:  0.14333178102970123
Valid Loss:  0.13121744990348816
Epoch:  306  	Training Loss: 0.10658174753189087
Test Loss:  0.14333166182041168
Valid Loss:  0.13121721148490906
Epoch:  307  	Training Loss: 0.10658150911331177
Test Loss:  0.14333154261112213
Valid Loss:  0.13121697306632996
Epoch:  308  	Training Loss: 0.10658125579357147
Test Loss:  0.14333142340183258
Valid Loss:  0.13121673464775085
Epoch:  309  	Training Loss: 0.10658101737499237
Test Loss:  0.14333131909370422
Valid Loss:  0.13121654093265533
Epoch:  310  	Training Loss: 0.10658076405525208
Test Loss:  0.14333119988441467
Valid Loss:  0.13121633231639862
Epoch:  311  	Training Loss: 0.10658052563667297
Test Loss:  0.14333109557628632
Valid Loss:  0.1312161237001419
Epoch:  312  	Training Loss: 0.10658029466867447
Test Loss:  0.14333097636699677
Valid Loss:  0.131215900182724
Epoch:  313  	Training Loss: 0.10658004879951477
Test Loss:  0.14333085715770721
Valid Loss:  0.13121572136878967
Epoch:  314  	Training Loss: 0.10657981038093567
Test Loss:  0.14333073794841766
Valid Loss:  0.13121551275253296
Epoch:  315  	Training Loss: 0.10657957941293716
Test Loss:  0.1433306336402893
Valid Loss:  0.13121530413627625
Epoch:  316  	Training Loss: 0.10657933354377747
Test Loss:  0.14333051443099976
Valid Loss:  0.13121511042118073
Epoch:  317  	Training Loss: 0.10657910257577896
Test Loss:  0.1433303952217102
Valid Loss:  0.13121488690376282
Epoch:  318  	Training Loss: 0.10657885670661926
Test Loss:  0.14333027601242065
Valid Loss:  0.1312146931886673
Epoch:  319  	Training Loss: 0.10657863318920135
Test Loss:  0.1433301717042923
Valid Loss:  0.13121449947357178
Epoch:  320  	Training Loss: 0.10657840222120285
Test Loss:  0.14333005249500275
Valid Loss:  0.13121430575847626
Epoch:  321  	Training Loss: 0.10657817870378494
Test Loss:  0.1433299481868744
Valid Loss:  0.13121408224105835
Epoch:  322  	Training Loss: 0.10657794773578644
Test Loss:  0.14332984387874603
Valid Loss:  0.13121390342712402
Epoch:  323  	Training Loss: 0.10657772421836853
Test Loss:  0.14332975447177887
Valid Loss:  0.1312136948108673
Epoch:  324  	Training Loss: 0.10657749325037003
Test Loss:  0.14332963526248932
Valid Loss:  0.1312134861946106
Epoch:  325  	Training Loss: 0.10657726973295212
Test Loss:  0.14332953095436096
Valid Loss:  0.13121330738067627
Epoch:  326  	Training Loss: 0.10657703876495361
Test Loss:  0.1433294415473938
Valid Loss:  0.13121311366558075
Epoch:  327  	Training Loss: 0.1065768226981163
Test Loss:  0.14332933723926544
Valid Loss:  0.13121291995048523
Epoch:  328  	Training Loss: 0.1065765917301178
Test Loss:  0.14332923293113708
Valid Loss:  0.1312127411365509
Epoch:  329  	Training Loss: 0.10657638311386108
Test Loss:  0.14332914352416992
Valid Loss:  0.13121257722377777
Epoch:  330  	Training Loss: 0.10657615959644318
Test Loss:  0.14332903921604156
Valid Loss:  0.13121241331100464
Epoch:  331  	Training Loss: 0.10657595098018646
Test Loss:  0.1433289647102356
Valid Loss:  0.1312122344970703
Epoch:  332  	Training Loss: 0.10657574236392975
Test Loss:  0.14332886040210724
Valid Loss:  0.131212055683136
Epoch:  333  	Training Loss: 0.10657553374767303
Test Loss:  0.14332877099514008
Valid Loss:  0.13121187686920166
Epoch:  334  	Training Loss: 0.10657532513141632
Test Loss:  0.14332866668701172
Valid Loss:  0.13121169805526733
Epoch:  335  	Training Loss: 0.10657510161399841
Test Loss:  0.14332857728004456
Valid Loss:  0.1312115341424942
Epoch:  336  	Training Loss: 0.1065748929977417
Test Loss:  0.1433284878730774
Valid Loss:  0.13121135532855988
Epoch:  337  	Training Loss: 0.10657469928264618
Test Loss:  0.14332839846611023
Valid Loss:  0.13121119141578674
Epoch:  338  	Training Loss: 0.10657449066638947
Test Loss:  0.14332829415798187
Valid Loss:  0.13121101260185242
Epoch:  339  	Training Loss: 0.10657428205013275
Test Loss:  0.1433282196521759
Valid Loss:  0.1312108337879181
Epoch:  340  	Training Loss: 0.10657408088445663
Test Loss:  0.14332811534404755
Valid Loss:  0.13121066987514496
Epoch:  341  	Training Loss: 0.10657387971878052
Test Loss:  0.14332804083824158
Valid Loss:  0.13121050596237183
Epoch:  342  	Training Loss: 0.1065736785531044
Test Loss:  0.14332793653011322
Valid Loss:  0.1312103271484375
Epoch:  343  	Training Loss: 0.10657346993684769
Test Loss:  0.14332784712314606
Valid Loss:  0.13121016323566437
Epoch:  344  	Training Loss: 0.10657326877117157
Test Loss:  0.1433277428150177
Valid Loss:  0.13120999932289124
Epoch:  345  	Training Loss: 0.10657306015491486
Test Loss:  0.14332766830921173
Valid Loss:  0.1312098354101181
Epoch:  346  	Training Loss: 0.10657286643981934
Test Loss:  0.14332757890224457
Valid Loss:  0.13120967149734497
Epoch:  347  	Training Loss: 0.10657265782356262
Test Loss:  0.1433274745941162
Valid Loss:  0.13120950758457184
Epoch:  348  	Training Loss: 0.1065724566578865
Test Loss:  0.14332738518714905
Valid Loss:  0.1312093436717987
Epoch:  349  	Training Loss: 0.10657225549221039
Test Loss:  0.14332731068134308
Valid Loss:  0.13120916485786438
Epoch:  350  	Training Loss: 0.10657204687595367
Test Loss:  0.14332722127437592
Valid Loss:  0.13120901584625244
Epoch:  351  	Training Loss: 0.10657184571027756
Test Loss:  0.14332711696624756
Valid Loss:  0.1312088519334793
Epoch:  352  	Training Loss: 0.10657164454460144
Test Loss:  0.1433270126581192
Valid Loss:  0.13120868802070618
Epoch:  353  	Training Loss: 0.10657143592834473
Test Loss:  0.14332690834999084
Valid Loss:  0.13120850920677185
Epoch:  354  	Training Loss: 0.10657121986150742
Test Loss:  0.14332681894302368
Valid Loss:  0.13120833039283752
Epoch:  355  	Training Loss: 0.1065710186958313
Test Loss:  0.14332672953605652
Valid Loss:  0.13120818138122559
Epoch:  356  	Training Loss: 0.10657081753015518
Test Loss:  0.14332662522792816
Valid Loss:  0.13120800256729126
Epoch:  357  	Training Loss: 0.10657061636447906
Test Loss:  0.143326535820961
Valid Loss:  0.13120785355567932
Epoch:  358  	Training Loss: 0.10657042264938354
Test Loss:  0.14332643151283264
Valid Loss:  0.131207674741745
Epoch:  359  	Training Loss: 0.10657024383544922
Test Loss:  0.14332637190818787
Valid Loss:  0.13120752573013306
Epoch:  360  	Training Loss: 0.10657006502151489
Test Loss:  0.1433262825012207
Valid Loss:  0.13120737671852112
Epoch:  361  	Training Loss: 0.10656987875699997
Test Loss:  0.14332619309425354
Valid Loss:  0.13120724260807037
Epoch:  362  	Training Loss: 0.10656969994306564
Test Loss:  0.14332610368728638
Valid Loss:  0.13120707869529724
 73%|███████▎  | 363/500 [04:12<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:12<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:12<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:19<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:19<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:19<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:19<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:26<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:26<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:26<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:26<00:51,  2.19it/s] 78%|███████▊  | 389/500 [04:26<00:37,  2.95it/s] 78%|███████▊  | 391/500 [04:33<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:33<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:33<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:33<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.02it/s] 80%|████████  | 401/500 [04:39<01:55,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.19it/s] 81%|████████  | 405/500 [04:40<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:40<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:40<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:46<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:46<01:15,  1.16it/s] 83%|████████▎ | 415/500 [04:47<00:52,  1.60it/s] 83%|████████▎ | 417/500 [04:47<00:38,  2.18it/s] 84%|████████▍ | 419/500 [04:47<00:28,  2.87it/s] 84%|████████▍ | 421/500 [04:53<01:33,  1.19s/it] 85%|████████▍ | 423/500 [04:53<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:53<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:54<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:54<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:00<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:00<00:56,  1.18it/s]Epoch:  363  	Training Loss: 0.10656951367855072
Test Loss:  0.1433260291814804
Valid Loss:  0.1312069445848465
Epoch:  364  	Training Loss: 0.1065693348646164
Test Loss:  0.14332593977451324
Valid Loss:  0.13120681047439575
Epoch:  365  	Training Loss: 0.10656915605068207
Test Loss:  0.14332586526870728
Valid Loss:  0.1312066614627838
Epoch:  366  	Training Loss: 0.10656899213790894
Test Loss:  0.1433257907629013
Valid Loss:  0.13120652735233307
Epoch:  367  	Training Loss: 0.10656881332397461
Test Loss:  0.14332571625709534
Valid Loss:  0.13120639324188232
Epoch:  368  	Training Loss: 0.10656864196062088
Test Loss:  0.14332562685012817
Valid Loss:  0.13120624423027039
Epoch:  369  	Training Loss: 0.10656847059726715
Test Loss:  0.1433255523443222
Valid Loss:  0.13120611011981964
Epoch:  370  	Training Loss: 0.10656830668449402
Test Loss:  0.14332547783851624
Valid Loss:  0.1312059909105301
Epoch:  371  	Training Loss: 0.10656814277172089
Test Loss:  0.14332538843154907
Valid Loss:  0.13120585680007935
Epoch:  372  	Training Loss: 0.10656799376010895
Test Loss:  0.1433253139257431
Valid Loss:  0.1312057375907898
Epoch:  373  	Training Loss: 0.10656784474849701
Test Loss:  0.14332523941993713
Valid Loss:  0.13120560348033905
Epoch:  374  	Training Loss: 0.10656769573688507
Test Loss:  0.14332517981529236
Valid Loss:  0.1312054693698883
Epoch:  375  	Training Loss: 0.10656753927469254
Test Loss:  0.1433250904083252
Valid Loss:  0.13120533525943756
Epoch:  376  	Training Loss: 0.1065673828125
Test Loss:  0.14332500100135803
Valid Loss:  0.131205216050148
Epoch:  377  	Training Loss: 0.10656723380088806
Test Loss:  0.14332494139671326
Valid Loss:  0.13120508193969727
Epoch:  378  	Training Loss: 0.10656708478927612
Test Loss:  0.1433248668909073
Valid Loss:  0.13120494782924652
Epoch:  379  	Training Loss: 0.10656693577766418
Test Loss:  0.14332479238510132
Valid Loss:  0.13120481371879578
Epoch:  380  	Training Loss: 0.10656678676605225
Test Loss:  0.14332471787929535
Valid Loss:  0.13120469450950623
Epoch:  381  	Training Loss: 0.10656663775444031
Test Loss:  0.14332464337348938
Valid Loss:  0.13120457530021667
Epoch:  382  	Training Loss: 0.10656648874282837
Test Loss:  0.1433245688676834
Valid Loss:  0.13120444118976593
Epoch:  383  	Training Loss: 0.10656635463237762
Test Loss:  0.14332450926303864
Valid Loss:  0.13120433688163757
Epoch:  384  	Training Loss: 0.10656622052192688
Test Loss:  0.14332444965839386
Valid Loss:  0.13120420277118683
Epoch:  385  	Training Loss: 0.10656609386205673
Test Loss:  0.1433243751525879
Valid Loss:  0.13120409846305847
Epoch:  386  	Training Loss: 0.10656595975160599
Test Loss:  0.14332431554794312
Valid Loss:  0.13120396435260773
Epoch:  387  	Training Loss: 0.10656583309173584
Test Loss:  0.14332425594329834
Valid Loss:  0.13120384514331818
Epoch:  388  	Training Loss: 0.1065656989812851
Test Loss:  0.14332419633865356
Valid Loss:  0.13120374083518982
Epoch:  389  	Training Loss: 0.10656556487083435
Test Loss:  0.1433241367340088
Valid Loss:  0.13120362162590027
Epoch:  390  	Training Loss: 0.1065654456615448
Test Loss:  0.143324077129364
Valid Loss:  0.13120350241661072
Epoch:  391  	Training Loss: 0.10656532645225525
Test Loss:  0.14332401752471924
Valid Loss:  0.13120338320732117
Epoch:  392  	Training Loss: 0.1065651923418045
Test Loss:  0.14332395792007446
Valid Loss:  0.13120324909687042
Epoch:  393  	Training Loss: 0.10656507313251495
Test Loss:  0.1433238983154297
Valid Loss:  0.13120314478874207
Epoch:  394  	Training Loss: 0.1065649539232254
Test Loss:  0.1433238685131073
Valid Loss:  0.13120302557945251
Epoch:  395  	Training Loss: 0.10656483471393585
Test Loss:  0.14332379400730133
Valid Loss:  0.13120290637016296
Epoch:  396  	Training Loss: 0.10656470060348511
Test Loss:  0.14332374930381775
Valid Loss:  0.1312027871608734
Epoch:  397  	Training Loss: 0.10656458139419556
Test Loss:  0.14332370460033417
Valid Loss:  0.13120268285274506
Epoch:  398  	Training Loss: 0.106564462184906
Test Loss:  0.1433236300945282
Valid Loss:  0.1312025636434555
Epoch:  399  	Training Loss: 0.10656434297561646
Test Loss:  0.14332358539104462
Valid Loss:  0.13120245933532715
Epoch:  400  	Training Loss: 0.1065642237663269
Test Loss:  0.14332354068756104
Valid Loss:  0.1312023401260376
Epoch:  401  	Training Loss: 0.10656409710645676
Test Loss:  0.14332348108291626
Valid Loss:  0.13120222091674805
Epoch:  402  	Training Loss: 0.10656397044658661
Test Loss:  0.14332343637943268
Valid Loss:  0.1312021017074585
Epoch:  403  	Training Loss: 0.10656385123729706
Test Loss:  0.1433233767747879
Valid Loss:  0.13120199739933014
Epoch:  404  	Training Loss: 0.10656373202800751
Test Loss:  0.14332333207130432
Valid Loss:  0.1312018781900406
Epoch:  405  	Training Loss: 0.10656361281871796
Test Loss:  0.14332327246665955
Valid Loss:  0.13120177388191223
Epoch:  406  	Training Loss: 0.1065634936094284
Test Loss:  0.14332321286201477
Valid Loss:  0.13120165467262268
Epoch:  407  	Training Loss: 0.10656337440013885
Test Loss:  0.1433231681585312
Valid Loss:  0.13120153546333313
Epoch:  408  	Training Loss: 0.1065632551908493
Test Loss:  0.1433231085538864
Valid Loss:  0.13120143115520477
Epoch:  409  	Training Loss: 0.10656313598155975
Test Loss:  0.14332306385040283
Valid Loss:  0.13120131194591522
Epoch:  410  	Training Loss: 0.1065630167722702
Test Loss:  0.14332300424575806
Valid Loss:  0.13120120763778687
Epoch:  411  	Training Loss: 0.10656289756298065
Test Loss:  0.14332295954227448
Valid Loss:  0.13120108842849731
Epoch:  412  	Training Loss: 0.1065627932548523
Test Loss:  0.1433229148387909
Valid Loss:  0.13120098412036896
Epoch:  413  	Training Loss: 0.10656267404556274
Test Loss:  0.14332285523414612
Valid Loss:  0.1312008798122406
Epoch:  414  	Training Loss: 0.10656256973743439
Test Loss:  0.14332281053066254
Valid Loss:  0.13120076060295105
Epoch:  415  	Training Loss: 0.10656245797872543
Test Loss:  0.14332276582717896
Valid Loss:  0.1312006711959839
Epoch:  416  	Training Loss: 0.10656236112117767
Test Loss:  0.14332270622253418
Valid Loss:  0.13120055198669434
Epoch:  417  	Training Loss: 0.10656224936246872
Test Loss:  0.1433226615190506
Valid Loss:  0.13120046257972717
Epoch:  418  	Training Loss: 0.10656214505434036
Test Loss:  0.14332261681556702
Valid Loss:  0.13120037317276
Epoch:  419  	Training Loss: 0.1065620481967926
Test Loss:  0.14332255721092224
Valid Loss:  0.13120026886463165
Epoch:  420  	Training Loss: 0.10656195133924484
Test Loss:  0.14332251250743866
Valid Loss:  0.1312001645565033
Epoch:  421  	Training Loss: 0.10656184703111649
Test Loss:  0.14332246780395508
Valid Loss:  0.13120007514953613
Epoch:  422  	Training Loss: 0.10656175762414932
Test Loss:  0.1433224081993103
Valid Loss:  0.13119998574256897
Epoch:  423  	Training Loss: 0.10656166076660156
Test Loss:  0.14332237839698792
Valid Loss:  0.1311998963356018
Epoch:  424  	Training Loss: 0.1065615713596344
Test Loss:  0.14332231879234314
Valid Loss:  0.13119977712631226
Epoch:  425  	Training Loss: 0.10656146705150604
Test Loss:  0.14332228899002075
Valid Loss:  0.1311996877193451
Epoch:  426  	Training Loss: 0.10656137764453888
Test Loss:  0.14332222938537598
Valid Loss:  0.13119959831237793
Epoch:  427  	Training Loss: 0.10656128823757172
Test Loss:  0.1433221846818924
Valid Loss:  0.13119950890541077
Epoch:  428  	Training Loss: 0.10656119138002396
Test Loss:  0.1433221399784088
Valid Loss:  0.1311994194984436
Epoch:  429  	Training Loss: 0.1065611019730568
Test Loss:  0.14332209527492523
Valid Loss:  0.13119931519031525
Epoch:  430  	Training Loss: 0.10656100511550903
Test Loss:  0.14332205057144165
Valid Loss:  0.13119924068450928
Epoch:  431  	Training Loss: 0.10656093060970306
Test Loss:  0.14332200586795807
Valid Loss:  0.13119913637638092
Epoch:  432  	Training Loss: 0.1065608561038971
Test Loss:  0.1433219611644745
Valid Loss:  0.13119904696941376
Epoch:  433  	Training Loss: 0.10656076669692993
Test Loss:  0.1433219164609909
Valid Loss:  0.1311989724636078
Epoch:  434  	Training Loss: 0.10656069219112396
Test Loss:  0.14332187175750732
Valid Loss:  0.13119888305664062
Epoch:  435  	Training Loss: 0.106560617685318
 87%|████████▋ | 435/500 [05:00<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:01<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:07<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:07<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:07<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:07<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:14<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:14<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:14<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:21<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:21<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:21<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:21<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:21<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:28<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:28<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:28<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:28<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:28<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:35<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:35<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:35<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:35<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:42<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:42<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:42<00:00,  2.97it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
Test Loss:  0.14332182705402374
Valid Loss:  0.13119879364967346
Epoch:  436  	Training Loss: 0.10656052827835083
Test Loss:  0.14332179725170135
Valid Loss:  0.1311987042427063
Epoch:  437  	Training Loss: 0.10656045377254486
Test Loss:  0.14332175254821777
Valid Loss:  0.13119862973690033
Epoch:  438  	Training Loss: 0.10656037926673889
Test Loss:  0.1433217078447342
Valid Loss:  0.13119854032993317
Epoch:  439  	Training Loss: 0.10656030476093292
Test Loss:  0.1433216631412506
Valid Loss:  0.1311984658241272
Epoch:  440  	Training Loss: 0.10656022280454636
Test Loss:  0.14332161843776703
Valid Loss:  0.13119837641716003
Epoch:  441  	Training Loss: 0.10656014084815979
Test Loss:  0.14332157373428345
Valid Loss:  0.13119830191135406
Epoch:  442  	Training Loss: 0.10656006634235382
Test Loss:  0.14332154393196106
Valid Loss:  0.1311982274055481
Epoch:  443  	Training Loss: 0.10655999183654785
Test Loss:  0.14332148432731628
Valid Loss:  0.13119813799858093
Epoch:  444  	Training Loss: 0.10655991733074188
Test Loss:  0.1433214545249939
Valid Loss:  0.13119804859161377
Epoch:  445  	Training Loss: 0.10655985027551651
Test Loss:  0.1433214247226715
Valid Loss:  0.1311979591846466
Epoch:  446  	Training Loss: 0.10655978322029114
Test Loss:  0.14332138001918793
Valid Loss:  0.13119788467884064
Epoch:  447  	Training Loss: 0.10655970126390457
Test Loss:  0.14332133531570435
Valid Loss:  0.13119781017303467
Epoch:  448  	Training Loss: 0.106559619307518
Test Loss:  0.14332130551338196
Valid Loss:  0.1311977207660675
Epoch:  449  	Training Loss: 0.10655955970287323
Test Loss:  0.14332126080989838
Valid Loss:  0.13119764626026154
Epoch:  450  	Training Loss: 0.10655947774648666
Test Loss:  0.143321231007576
Valid Loss:  0.13119757175445557
Epoch:  451  	Training Loss: 0.10655941069126129
Test Loss:  0.1433211863040924
Valid Loss:  0.1311974823474884
Epoch:  452  	Training Loss: 0.10655932873487473
Test Loss:  0.14332115650177002
Valid Loss:  0.13119739294052124
Epoch:  453  	Training Loss: 0.10655926167964935
Test Loss:  0.14332111179828644
Valid Loss:  0.13119731843471527
Epoch:  454  	Training Loss: 0.10655917972326279
Test Loss:  0.14332106709480286
Valid Loss:  0.1311972290277481
Epoch:  455  	Training Loss: 0.10655910521745682
Test Loss:  0.14332103729248047
Valid Loss:  0.13119715452194214
Epoch:  456  	Training Loss: 0.10655903816223145
Test Loss:  0.14332100749015808
Valid Loss:  0.13119709491729736
Epoch:  457  	Training Loss: 0.10655896365642548
Test Loss:  0.1433209776878357
Valid Loss:  0.1311970055103302
Epoch:  458  	Training Loss: 0.1065588966012001
Test Loss:  0.1433209478855133
Valid Loss:  0.13119694590568542
Epoch:  459  	Training Loss: 0.10655882209539413
Test Loss:  0.14332090318202972
Valid Loss:  0.13119687139987946
Epoch:  460  	Training Loss: 0.10655874758958817
Test Loss:  0.14332087337970734
Valid Loss:  0.1311967968940735
Epoch:  461  	Training Loss: 0.10655868053436279
Test Loss:  0.14332082867622375
Valid Loss:  0.13119670748710632
Epoch:  462  	Training Loss: 0.10655860602855682
Test Loss:  0.14332079887390137
Valid Loss:  0.13119664788246155
Epoch:  463  	Training Loss: 0.10655853152275085
Test Loss:  0.14332076907157898
Valid Loss:  0.13119658827781677
Epoch:  464  	Training Loss: 0.10655845701694489
Test Loss:  0.1433207392692566
Valid Loss:  0.1311965137720108
Epoch:  465  	Training Loss: 0.10655838996171951
Test Loss:  0.1433207094669342
Valid Loss:  0.13119643926620483
Epoch:  466  	Training Loss: 0.10655832290649414
Test Loss:  0.143320694565773
Valid Loss:  0.13119637966156006
Epoch:  467  	Training Loss: 0.10655826330184937
Test Loss:  0.14332064986228943
Valid Loss:  0.13119632005691528
Epoch:  468  	Training Loss: 0.1065581887960434
Test Loss:  0.14332062005996704
Valid Loss:  0.1311962604522705
Epoch:  469  	Training Loss: 0.10655812919139862
Test Loss:  0.14332059025764465
Valid Loss:  0.13119620084762573
Epoch:  470  	Training Loss: 0.10655805468559265
Test Loss:  0.14332056045532227
Valid Loss:  0.13119614124298096
Epoch:  471  	Training Loss: 0.10655799508094788
Test Loss:  0.14332054555416107
Valid Loss:  0.1311960518360138
Epoch:  472  	Training Loss: 0.1065579205751419
Test Loss:  0.14332051575183868
Valid Loss:  0.13119599223136902
Epoch:  473  	Training Loss: 0.10655785351991653
Test Loss:  0.1433204859495163
Valid Loss:  0.13119594752788544
Epoch:  474  	Training Loss: 0.10655778646469116
Test Loss:  0.1433204710483551
Valid Loss:  0.13119587302207947
Epoch:  475  	Training Loss: 0.10655771195888519
Test Loss:  0.14332044124603271
Valid Loss:  0.1311958134174347
Epoch:  476  	Training Loss: 0.10655765235424042
Test Loss:  0.14332041144371033
Valid Loss:  0.13119575381278992
Epoch:  477  	Training Loss: 0.10655757784843445
Test Loss:  0.14332038164138794
Valid Loss:  0.13119570910930634
Epoch:  478  	Training Loss: 0.10655752569437027
Test Loss:  0.14332035183906555
Valid Loss:  0.13119563460350037
Epoch:  479  	Training Loss: 0.1065574586391449
Test Loss:  0.14332033693790436
Valid Loss:  0.1311955749988556
Epoch:  480  	Training Loss: 0.10655739903450012
Test Loss:  0.14332030713558197
Valid Loss:  0.13119551539421082
Epoch:  481  	Training Loss: 0.10655733942985535
Test Loss:  0.14332029223442078
Valid Loss:  0.13119547069072723
Epoch:  482  	Training Loss: 0.10655726492404938
Test Loss:  0.1433202624320984
Valid Loss:  0.13119541108608246
Epoch:  483  	Training Loss: 0.1065572053194046
Test Loss:  0.143320232629776
Valid Loss:  0.1311953365802765
Epoch:  484  	Training Loss: 0.10655713081359863
Test Loss:  0.1433202028274536
Valid Loss:  0.1311952918767929
Epoch:  485  	Training Loss: 0.10655707120895386
Test Loss:  0.14332017302513123
Valid Loss:  0.13119521737098694
Epoch:  486  	Training Loss: 0.10655701160430908
Test Loss:  0.14332015812397003
Valid Loss:  0.13119515776634216
Epoch:  487  	Training Loss: 0.1065569519996643
Test Loss:  0.14332012832164764
Valid Loss:  0.13119511306285858
Epoch:  488  	Training Loss: 0.10655688494443893
Test Loss:  0.14332011342048645
Valid Loss:  0.1311950385570526
Epoch:  489  	Training Loss: 0.10655681788921356
Test Loss:  0.14332008361816406
Valid Loss:  0.13119499385356903
Epoch:  490  	Training Loss: 0.10655675828456879
Test Loss:  0.14332008361816406
Valid Loss:  0.13119491934776306
Epoch:  491  	Training Loss: 0.10655669122934341
Test Loss:  0.14332005381584167
Valid Loss:  0.1311948597431183
Epoch:  492  	Training Loss: 0.10655663162469864
Test Loss:  0.1433200240135193
Valid Loss:  0.1311948150396347
Epoch:  493  	Training Loss: 0.10655656456947327
Test Loss:  0.1433199942111969
Valid Loss:  0.13119475543498993
Epoch:  494  	Training Loss: 0.10655651241540909
Test Loss:  0.1433199942111969
Valid Loss:  0.13119471073150635
Epoch:  495  	Training Loss: 0.10655646026134491
Test Loss:  0.1433199644088745
Valid Loss:  0.13119463622570038
Epoch:  496  	Training Loss: 0.10655640065670013
Test Loss:  0.14331994950771332
Valid Loss:  0.1311945915222168
Epoch:  497  	Training Loss: 0.10655634105205536
Test Loss:  0.14331993460655212
Valid Loss:  0.13119453191757202
Epoch:  498  	Training Loss: 0.10655628889799118
Test Loss:  0.14331990480422974
Valid Loss:  0.13119447231292725
Epoch:  499  	Training Loss: 0.106556236743927
Test Loss:  0.14331987500190735
Valid Loss:  0.13119442760944366
Epoch:  500  	Training Loss: 0.10655617713928223
Test Loss:  0.14331986010074615
Valid Loss:  0.1311943680047989
seed is  16
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:16,  6.16s/it]  1%|          | 3/500 [00:06<13:41,  1.65s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:13<10:53,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:26<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:38,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.62it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:33<08:58,  1.17s/it]  9%|▊         | 43/500 [00:33<06:27,  1.18it/s]  9%|▉         | 45/500 [00:34<04:41,  1.62it/s]  9%|▉         | 47/500 [00:34<03:24,  2.21it/s] 10%|▉         | 49/500 [00:34<02:31,  2.97it/s] 10%|█         | 51/500 [00:40<08:52,  1.19s/it] 11%|█         | 53/500 [00:40<06:20,  1.17it/s] 11%|█         | 55/500 [00:40<04:33,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:41<02:27,  2.98it/s] 12%|█▏        | 61/500 [00:47<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:48<02:23,  2.99it/s] 14%|█▍        | 71/500 [00:54<08:21,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:59,  1.19it/s]Epoch:  1  	Training Loss: 0.5022580623626709
Test Loss:  5.093164443969727
Valid Loss:  4.93317985534668
Epoch:  2  	Training Loss: 5.166353225708008
Test Loss:  0.5780513286590576
Valid Loss:  0.5548455119132996
Epoch:  3  	Training Loss: 0.4795546531677246
Test Loss:  0.5779011249542236
Valid Loss:  0.5547820329666138
Epoch:  4  	Training Loss: 0.4794490337371826
Test Loss:  0.577729344367981
Valid Loss:  0.5546911358833313
Epoch:  5  	Training Loss: 0.47932738065719604
Test Loss:  0.5775449275970459
Valid Loss:  0.5545794367790222
Epoch:  6  	Training Loss: 0.4791954457759857
Test Loss:  0.5773451328277588
Valid Loss:  0.5544620752334595
Epoch:  7  	Training Loss: 0.4790516495704651
Test Loss:  0.577122688293457
Valid Loss:  0.5543180704116821
Epoch:  8  	Training Loss: 0.4788883328437805
Test Loss:  0.5768734216690063
Valid Loss:  0.5541375279426575
Epoch:  9  	Training Loss: 0.47870659828186035
Test Loss:  0.5765746831893921
Valid Loss:  0.5539132356643677
Epoch:  10  	Training Loss: 0.4785003066062927
Test Loss:  0.5762248039245605
Valid Loss:  0.553629994392395
Epoch:  11  	Training Loss: 0.47825074195861816
Test Loss:  0.5758070945739746
Valid Loss:  0.5532424449920654
Epoch:  12  	Training Loss: 0.47793886065483093
Test Loss:  0.5753439664840698
Valid Loss:  0.552802562713623
Epoch:  13  	Training Loss: 0.47758686542510986
Test Loss:  0.5747829675674438
Valid Loss:  0.5522322654724121
Epoch:  14  	Training Loss: 0.47715461254119873
Test Loss:  0.5742132663726807
Valid Loss:  0.5516505241394043
Epoch:  15  	Training Loss: 0.47671520709991455
Test Loss:  0.5736441612243652
Valid Loss:  0.5510693788528442
Epoch:  16  	Training Loss: 0.476276159286499
Test Loss:  0.5730756521224976
Valid Loss:  0.5504888296127319
Epoch:  17  	Training Loss: 0.4758375883102417
Test Loss:  0.5725076198577881
Valid Loss:  0.5499088764190674
Epoch:  18  	Training Loss: 0.4753994941711426
Test Loss:  0.5719401836395264
Valid Loss:  0.5493295788764954
Epoch:  19  	Training Loss: 0.4749617576599121
Test Loss:  0.5713733434677124
Valid Loss:  0.5487508773803711
Epoch:  20  	Training Loss: 0.47452449798583984
Test Loss:  0.5708070993423462
Valid Loss:  0.5481727719306946
Epoch:  21  	Training Loss: 0.474087655544281
Test Loss:  0.5702413320541382
Valid Loss:  0.5475952625274658
Epoch:  22  	Training Loss: 0.47365128993988037
Test Loss:  0.5695928335189819
Valid Loss:  0.5469324588775635
Epoch:  23  	Training Loss: 0.473152220249176
Test Loss:  0.568945050239563
Valid Loss:  0.546270489692688
Epoch:  24  	Training Loss: 0.4726538062095642
Test Loss:  0.5682980418205261
Valid Loss:  0.5456094145774841
Epoch:  25  	Training Loss: 0.47215598821640015
Test Loss:  0.5676518678665161
Valid Loss:  0.5449491739273071
Epoch:  26  	Training Loss: 0.47165876626968384
Test Loss:  0.5670064091682434
Valid Loss:  0.5442897081375122
Epoch:  27  	Training Loss: 0.4711621403694153
Test Loss:  0.5663617849349976
Valid Loss:  0.5436311364173889
Epoch:  28  	Training Loss: 0.4706661105155945
Test Loss:  0.5657179355621338
Valid Loss:  0.5429733991622925
Epoch:  29  	Training Loss: 0.47017067670822144
Test Loss:  0.5650749206542969
Valid Loss:  0.5423164367675781
Epoch:  30  	Training Loss: 0.46967586874961853
Test Loss:  0.5644326210021973
Valid Loss:  0.5416603684425354
Epoch:  31  	Training Loss: 0.4691815972328186
Test Loss:  0.5637911558151245
Valid Loss:  0.5410051345825195
Epoch:  32  	Training Loss: 0.4686879813671112
Test Loss:  0.5630708932876587
Valid Loss:  0.5402688980102539
Epoch:  33  	Training Loss: 0.46813473105430603
Test Loss:  0.5623517036437988
Valid Loss:  0.5395336747169495
Epoch:  34  	Training Loss: 0.46758225560188293
Test Loss:  0.5616334676742554
Valid Loss:  0.5387996435165405
Epoch:  35  	Training Loss: 0.46703052520751953
Test Loss:  0.5609161853790283
Valid Loss:  0.5380666255950928
Epoch:  36  	Training Loss: 0.4664795994758606
Test Loss:  0.5601998567581177
Valid Loss:  0.5373345613479614
Epoch:  37  	Training Loss: 0.4659293293952942
Test Loss:  0.5594844818115234
Valid Loss:  0.536603569984436
Epoch:  38  	Training Loss: 0.46537983417510986
Test Loss:  0.5587701797485352
Valid Loss:  0.5358736515045166
Epoch:  39  	Training Loss: 0.4648311138153076
Test Loss:  0.5580568313598633
Valid Loss:  0.5351447463035583
Epoch:  40  	Training Loss: 0.4642831087112427
Test Loss:  0.557344377040863
Valid Loss:  0.534416913986206
Epoch:  41  	Training Loss: 0.46373581886291504
Test Loss:  0.5566329956054688
Valid Loss:  0.5336900949478149
Epoch:  42  	Training Loss: 0.4631893038749695
Test Loss:  0.5558422803878784
Valid Loss:  0.5328818559646606
Epoch:  43  	Training Loss: 0.462582528591156
Test Loss:  0.555052638053894
Valid Loss:  0.5320749878883362
Epoch:  44  	Training Loss: 0.46197670698165894
Test Loss:  0.5542643666267395
Valid Loss:  0.5312693119049072
Epoch:  45  	Training Loss: 0.4613717198371887
Test Loss:  0.5534772276878357
Valid Loss:  0.5304648876190186
Epoch:  46  	Training Loss: 0.4607676863670349
Test Loss:  0.5526912212371826
Valid Loss:  0.5296617746353149
Epoch:  47  	Training Loss: 0.46016454696655273
Test Loss:  0.5519064664840698
Valid Loss:  0.5288599133491516
Epoch:  48  	Training Loss: 0.4595623016357422
Test Loss:  0.5511228442192078
Valid Loss:  0.5280593037605286
Epoch:  49  	Training Loss: 0.45896095037460327
Test Loss:  0.5503404140472412
Valid Loss:  0.5272599458694458
Epoch:  50  	Training Loss: 0.458360493183136
Test Loss:  0.5495591759681702
Valid Loss:  0.5264618992805481
Epoch:  51  	Training Loss: 0.4577609598636627
Test Loss:  0.5487791299819946
Valid Loss:  0.5256651043891907
Epoch:  52  	Training Loss: 0.4571623206138611
Test Loss:  0.5479253530502319
Valid Loss:  0.5247929096221924
Epoch:  53  	Training Loss: 0.4565075933933258
Test Loss:  0.5470731258392334
Valid Loss:  0.5239222049713135
Epoch:  54  	Training Loss: 0.45585399866104126
Test Loss:  0.5462222695350647
Valid Loss:  0.5230530500411987
Epoch:  55  	Training Loss: 0.4552014470100403
Test Loss:  0.5453727841377258
Valid Loss:  0.5221853852272034
Epoch:  56  	Training Loss: 0.45455002784729004
Test Loss:  0.5445247888565063
Valid Loss:  0.5213192701339722
Epoch:  57  	Training Loss: 0.45389968156814575
Test Loss:  0.5436782836914062
Valid Loss:  0.5204547643661499
Epoch:  58  	Training Loss: 0.45325034856796265
Test Loss:  0.542833149433136
Valid Loss:  0.5195916891098022
Epoch:  59  	Training Loss: 0.45260220766067505
Test Loss:  0.5419893264770508
Valid Loss:  0.5187300443649292
Epoch:  60  	Training Loss: 0.45195508003234863
Test Loss:  0.541146993637085
Valid Loss:  0.5178700089454651
Epoch:  61  	Training Loss: 0.4513090252876282
Test Loss:  0.5403060913085938
Valid Loss:  0.5170114636421204
Epoch:  62  	Training Loss: 0.45066404342651367
Test Loss:  0.5394008159637451
Valid Loss:  0.5160870552062988
Epoch:  63  	Training Loss: 0.44996994733810425
Test Loss:  0.5384971499443054
Valid Loss:  0.515164315700531
Epoch:  64  	Training Loss: 0.4492771029472351
Test Loss:  0.5375950336456299
Valid Loss:  0.5142433047294617
Epoch:  65  	Training Loss: 0.4485854506492615
Test Loss:  0.5366945266723633
Valid Loss:  0.5133239030838013
Epoch:  66  	Training Loss: 0.4478950500488281
Test Loss:  0.5357956290245056
Valid Loss:  0.5124063491821289
Epoch:  67  	Training Loss: 0.4472058117389679
Test Loss:  0.5348982810974121
Valid Loss:  0.5114903450012207
Epoch:  68  	Training Loss: 0.44651779532432556
Test Loss:  0.5340025424957275
Valid Loss:  0.5105761289596558
Epoch:  69  	Training Loss: 0.44583094120025635
Test Loss:  0.5331083536148071
Valid Loss:  0.5096635222434998
Epoch:  70  	Training Loss: 0.44514530897140503
Test Loss:  0.5322157144546509
Valid Loss:  0.5087526440620422
Epoch:  71  	Training Loss: 0.4444608688354492
Test Loss:  0.5313247442245483
Valid Loss:  0.5078433752059937
Epoch:  72  	Training Loss: 0.4437776505947113
Test Loss:  0.5303797721862793
Valid Loss:  0.5068792104721069
Epoch:  73  	Training Loss: 0.44305312633514404
Test Loss:  0.5294366478919983
Valid Loss:  0.505916953086853
Epoch:  74  	Training Loss: 0.442330002784729
Test Loss:  0.5284952521324158
Valid Loss:  0.5049566030502319
Epoch:  75  	Training Loss: 0.441608190536499
 15%|█▌        | 75/500 [00:54<04:18,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:01<08:16,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:54,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:01<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:08<08:08,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.61it/s] 19%|█▉        | 97/500 [01:08<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:08<02:15,  2.96it/s] 20%|██        | 101/500 [01:14<07:52,  1.18s/it] 21%|██        | 103/500 [01:15<05:37,  1.18it/s] 21%|██        | 105/500 [01:15<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:15<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:15<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:21<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:55,  1.64it/s] 23%|██▎       | 117/500 [01:22<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:22<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:28<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:20,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:44,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:43,  2.23it/s] 28%|██▊       | 139/500 [01:36<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:42<07:01,  1.17s/it] 29%|██▊       | 143/500 [01:42<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:42<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:42<02:37,  2.24it/s]Test Loss:  0.5275556445121765
Valid Loss:  0.5039981007575989
Epoch:  76  	Training Loss: 0.4408877491950989
Test Loss:  0.5266178250312805
Valid Loss:  0.5030415058135986
Epoch:  77  	Training Loss: 0.4401686489582062
Test Loss:  0.5256818532943726
Valid Loss:  0.5020868182182312
Epoch:  78  	Training Loss: 0.4394509196281433
Test Loss:  0.5247475504875183
Valid Loss:  0.5011340379714966
Epoch:  79  	Training Loss: 0.4387345016002655
Test Loss:  0.5238149762153625
Valid Loss:  0.50018310546875
Epoch:  80  	Training Loss: 0.43801939487457275
Test Loss:  0.5228842496871948
Valid Loss:  0.49923408031463623
Epoch:  81  	Training Loss: 0.4373056888580322
Test Loss:  0.5219553112983704
Valid Loss:  0.4982869029045105
Epoch:  82  	Training Loss: 0.43659329414367676
Test Loss:  0.5209835767745972
Valid Loss:  0.4972962439060211
Epoch:  83  	Training Loss: 0.43584829568862915
Test Loss:  0.5200138092041016
Valid Loss:  0.4963075816631317
Epoch:  84  	Training Loss: 0.43510472774505615
Test Loss:  0.5190459489822388
Valid Loss:  0.4953210651874542
Epoch:  85  	Training Loss: 0.43436264991760254
Test Loss:  0.5180799961090088
Valid Loss:  0.4943365156650543
Epoch:  86  	Training Loss: 0.43362200260162354
Test Loss:  0.5171159505844116
Valid Loss:  0.49335405230522156
Epoch:  87  	Training Loss: 0.4328828454017639
Test Loss:  0.5161538124084473
Valid Loss:  0.4923735558986664
Epoch:  88  	Training Loss: 0.4321450889110565
Test Loss:  0.5151935815811157
Valid Loss:  0.49139511585235596
Epoch:  89  	Training Loss: 0.43140876293182373
Test Loss:  0.5142353177070618
Valid Loss:  0.4904187321662903
Epoch:  90  	Training Loss: 0.43067389726638794
Test Loss:  0.5132788419723511
Valid Loss:  0.4894443154335022
Epoch:  91  	Training Loss: 0.42994046211242676
Test Loss:  0.512324333190918
Valid Loss:  0.48847198486328125
Epoch:  92  	Training Loss: 0.42920851707458496
Test Loss:  0.5113354921340942
Valid Loss:  0.4874646067619324
Epoch:  93  	Training Loss: 0.4284503161907196
Test Loss:  0.5103486776351929
Valid Loss:  0.4864594042301178
Epoch:  94  	Training Loss: 0.42769360542297363
Test Loss:  0.5093638300895691
Valid Loss:  0.485456258058548
Epoch:  95  	Training Loss: 0.42693835496902466
Test Loss:  0.5083808898925781
Valid Loss:  0.4844552278518677
Epoch:  96  	Training Loss: 0.42618465423583984
Test Loss:  0.5073999166488647
Valid Loss:  0.48345625400543213
Epoch:  97  	Training Loss: 0.42543238401412964
Test Loss:  0.5064209699630737
Valid Loss:  0.4824594259262085
Epoch:  98  	Training Loss: 0.4246816635131836
Test Loss:  0.5054439306259155
Valid Loss:  0.48146459460258484
Epoch:  99  	Training Loss: 0.42393237352371216
Test Loss:  0.5044687986373901
Valid Loss:  0.4804719090461731
Epoch:  100  	Training Loss: 0.4231845736503601
Test Loss:  0.5034955739974976
Valid Loss:  0.4794812798500061
Epoch:  101  	Training Loss: 0.42243820428848267
Test Loss:  0.5025243163108826
Valid Loss:  0.4784926772117615
Epoch:  102  	Training Loss: 0.421693354845047
Test Loss:  0.5015275478363037
Valid Loss:  0.4774783253669739
Epoch:  103  	Training Loss: 0.4209289252758026
Test Loss:  0.500532865524292
Valid Loss:  0.47646617889404297
Epoch:  104  	Training Loss: 0.4201660752296448
Test Loss:  0.49954020977020264
Valid Loss:  0.47545623779296875
Epoch:  105  	Training Loss: 0.41940486431121826
Test Loss:  0.4985496699810028
Valid Loss:  0.474448561668396
Epoch:  106  	Training Loss: 0.4186452627182007
Test Loss:  0.4975612759590149
Valid Loss:  0.4734431803226471
Epoch:  107  	Training Loss: 0.41788721084594727
Test Loss:  0.4965749979019165
Valid Loss:  0.4724400043487549
Epoch:  108  	Training Loss: 0.4171307682991028
Test Loss:  0.4955907464027405
Valid Loss:  0.47143903374671936
Epoch:  109  	Training Loss: 0.41637593507766724
Test Loss:  0.4946085810661316
Valid Loss:  0.4704402983188629
Epoch:  110  	Training Loss: 0.41562265157699585
Test Loss:  0.49362853169441223
Valid Loss:  0.46944373846054077
Epoch:  111  	Training Loss: 0.4148709177970886
Test Loss:  0.4926505386829376
Valid Loss:  0.4684494137763977
Epoch:  112  	Training Loss: 0.41412079334259033
Test Loss:  0.4916517436504364
Valid Loss:  0.4674340784549713
Epoch:  113  	Training Loss: 0.41335463523864746
Test Loss:  0.4906550943851471
Valid Loss:  0.466420978307724
Epoch:  114  	Training Loss: 0.4125900864601135
Test Loss:  0.4896606206893921
Valid Loss:  0.46541014313697815
Epoch:  115  	Training Loss: 0.4118272066116333
Test Loss:  0.4886682629585266
Valid Loss:  0.4644016623497009
Epoch:  116  	Training Loss: 0.4110659956932068
Test Loss:  0.48767805099487305
Valid Loss:  0.4633954167366028
Epoch:  117  	Training Loss: 0.41030627489089966
Test Loss:  0.4866899847984314
Valid Loss:  0.4623914957046509
Epoch:  118  	Training Loss: 0.40954825282096863
Test Loss:  0.4857040047645569
Valid Loss:  0.46138978004455566
Epoch:  119  	Training Loss: 0.4087918698787689
Test Loss:  0.48472023010253906
Valid Loss:  0.4603903889656067
Epoch:  120  	Training Loss: 0.40803709626197815
Test Loss:  0.4837385416030884
Valid Loss:  0.4593932628631592
Epoch:  121  	Training Loss: 0.4072839021682739
Test Loss:  0.4827589690685272
Valid Loss:  0.45839834213256836
Epoch:  122  	Training Loss: 0.406532347202301
Test Loss:  0.4817633032798767
Valid Loss:  0.4573872685432434
Epoch:  123  	Training Loss: 0.405768483877182
Test Loss:  0.4807698130607605
Valid Loss:  0.4563784599304199
Epoch:  124  	Training Loss: 0.4050062298774719
Test Loss:  0.479778528213501
Valid Loss:  0.45537206530570984
Epoch:  125  	Training Loss: 0.40424567461013794
Test Loss:  0.47878938913345337
Valid Loss:  0.4543679654598236
Epoch:  126  	Training Loss: 0.40348678827285767
Test Loss:  0.4778025150299072
Valid Loss:  0.4533661901950836
Epoch:  127  	Training Loss: 0.4027295410633087
Test Loss:  0.4768177270889282
Valid Loss:  0.4523667097091675
Epoch:  128  	Training Loss: 0.4019739329814911
Test Loss:  0.4758351743221283
Valid Loss:  0.45136958360671997
Epoch:  129  	Training Loss: 0.4012199938297272
Test Loss:  0.4748547673225403
Valid Loss:  0.4503747224807739
Epoch:  130  	Training Loss: 0.40046772360801697
Test Loss:  0.4738765060901642
Valid Loss:  0.4493821859359741
Epoch:  131  	Training Loss: 0.3997170329093933
Test Loss:  0.472900390625
Valid Loss:  0.4483919143676758
Epoch:  132  	Training Loss: 0.39896804094314575
Test Loss:  0.4719122350215912
Valid Loss:  0.44738951325416565
Epoch:  133  	Training Loss: 0.39820969104766846
Test Loss:  0.4709262549877167
Valid Loss:  0.44638943672180176
Epoch:  134  	Training Loss: 0.3974530100822449
Test Loss:  0.46994245052337646
Valid Loss:  0.4453916549682617
Epoch:  135  	Training Loss: 0.396697998046875
Test Loss:  0.46896088123321533
Valid Loss:  0.4443962574005127
Epoch:  136  	Training Loss: 0.39594462513923645
Test Loss:  0.4679815173149109
Valid Loss:  0.4434032142162323
Epoch:  137  	Training Loss: 0.3951929807662964
Test Loss:  0.46700429916381836
Valid Loss:  0.44241243600845337
Epoch:  138  	Training Loss: 0.39444294571876526
Test Loss:  0.4660292863845825
Valid Loss:  0.44142407178878784
Epoch:  139  	Training Loss: 0.39369457960128784
Test Loss:  0.465056449174881
Valid Loss:  0.4404379427433014
Epoch:  140  	Training Loss: 0.39294788241386414
Test Loss:  0.46408578753471375
Valid Loss:  0.43945416808128357
Epoch:  141  	Training Loss: 0.39220285415649414
Test Loss:  0.4631173610687256
Valid Loss:  0.4384727478027344
Epoch:  142  	Training Loss: 0.39145946502685547
Test Loss:  0.46213966608047485
Valid Loss:  0.437482088804245
Epoch:  143  	Training Loss: 0.3907091021537781
Test Loss:  0.46116429567337036
Valid Loss:  0.43649378418922424
Epoch:  144  	Training Loss: 0.3899604082107544
Test Loss:  0.4601910710334778
Valid Loss:  0.4355078637599945
Epoch:  145  	Training Loss: 0.3892134428024292
Test Loss:  0.4592200815677643
Valid Loss:  0.4345242381095886
Epoch:  146  	Training Loss: 0.3884681165218353
Test Loss:  0.4582512378692627
Valid Loss:  0.43354299664497375
Epoch:  147  	Training Loss: 0.38772445917129517
Test Loss:  0.4572846293449402
Valid Loss:  0.43256402015686035
Epoch:  148  	Training Loss: 0.3869825005531311
Test Loss:  0.456320196390152
Valid Loss:   30%|██▉       | 149/500 [01:42<01:56,  3.01it/s] 30%|███       | 151/500 [01:49<06:57,  1.20s/it] 31%|███       | 153/500 [01:49<04:57,  1.17it/s] 31%|███       | 155/500 [01:49<03:33,  1.61it/s] 31%|███▏      | 157/500 [01:49<02:35,  2.20it/s] 32%|███▏      | 159/500 [01:49<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:56<06:39,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:45,  1.18it/s] 33%|███▎      | 165/500 [01:56<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:56<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:02<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:03<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:03<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:03<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:09<06:12,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:25,  1.19it/s] 37%|███▋      | 185/500 [02:10<03:11,  1.65it/s] 37%|███▋      | 187/500 [02:10<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:10<01:42,  3.03it/s] 38%|███▊      | 191/500 [02:16<05:57,  1.16s/it] 39%|███▊      | 193/500 [02:16<04:15,  1.20it/s] 39%|███▉      | 195/500 [02:16<03:03,  1.66it/s] 39%|███▉      | 197/500 [02:16<02:13,  2.26it/s] 40%|███▉      | 199/500 [02:16<01:39,  3.03it/s] 40%|████      | 201/500 [02:23<05:55,  1.19s/it] 41%|████      | 203/500 [02:23<04:13,  1.17it/s] 41%|████      | 205/500 [02:23<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:23<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:23<01:38,  2.97it/s] 42%|████▏     | 211/500 [02:30<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:30<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.00it/s]0.4315873980522156
Epoch:  149  	Training Loss: 0.386242151260376
Test Loss:  0.45535796880722046
Valid Loss:  0.43061310052871704
Epoch:  150  	Training Loss: 0.38550350069999695
Test Loss:  0.45439785718917847
Valid Loss:  0.42964112758636475
Epoch:  151  	Training Loss: 0.38476645946502686
Test Loss:  0.45343995094299316
Valid Loss:  0.4286714792251587
Epoch:  152  	Training Loss: 0.3840310871601105
Test Loss:  0.4524742364883423
Valid Loss:  0.42769408226013184
Epoch:  153  	Training Loss: 0.3832896649837494
Test Loss:  0.4515107572078705
Valid Loss:  0.426719069480896
Epoch:  154  	Training Loss: 0.38254988193511963
Test Loss:  0.45054951310157776
Valid Loss:  0.4257463812828064
Epoch:  155  	Training Loss: 0.38181185722351074
Test Loss:  0.44959044456481934
Valid Loss:  0.4247760772705078
Epoch:  156  	Training Loss: 0.3810754418373108
Test Loss:  0.44863361120224
Valid Loss:  0.42380815744400024
Epoch:  157  	Training Loss: 0.3803407549858093
Test Loss:  0.44767892360687256
Valid Loss:  0.42284247279167175
Epoch:  158  	Training Loss: 0.3796076774597168
Test Loss:  0.4467265009880066
Valid Loss:  0.4218791723251343
Epoch:  159  	Training Loss: 0.37887632846832275
Test Loss:  0.44577622413635254
Valid Loss:  0.42091822624206543
Epoch:  160  	Training Loss: 0.3781466484069824
Test Loss:  0.4448281526565552
Valid Loss:  0.41995954513549805
Epoch:  161  	Training Loss: 0.377418577671051
Test Loss:  0.4438822567462921
Valid Loss:  0.4190032482147217
Epoch:  162  	Training Loss: 0.3766922354698181
Test Loss:  0.44293057918548584
Valid Loss:  0.4180411100387573
Epoch:  163  	Training Loss: 0.37596142292022705
Test Loss:  0.44198107719421387
Valid Loss:  0.4170812964439392
Epoch:  164  	Training Loss: 0.3752322196960449
Test Loss:  0.4410337805747986
Valid Loss:  0.41612380743026733
Epoch:  165  	Training Loss: 0.3745047152042389
Test Loss:  0.4400886595249176
Valid Loss:  0.4151686429977417
Epoch:  166  	Training Loss: 0.3737788796424866
Test Loss:  0.43914568424224854
Valid Loss:  0.4142157733440399
Epoch:  167  	Training Loss: 0.3730546832084656
Test Loss:  0.43820494413375854
Valid Loss:  0.4132652282714844
Epoch:  168  	Training Loss: 0.3723321259021759
Test Loss:  0.4372662901878357
Valid Loss:  0.4123169481754303
Epoch:  169  	Training Loss: 0.37161123752593994
Test Loss:  0.43632984161376953
Valid Loss:  0.41137099266052246
Epoch:  170  	Training Loss: 0.3708919882774353
Test Loss:  0.43539556860923767
Valid Loss:  0.4104273319244385
Epoch:  171  	Training Loss: 0.3701743483543396
Test Loss:  0.43446341156959534
Valid Loss:  0.40948596596717834
Epoch:  172  	Training Loss: 0.3694583773612976
Test Loss:  0.4335268437862396
Valid Loss:  0.40854036808013916
Epoch:  173  	Training Loss: 0.3687390089035034
Test Loss:  0.4325925409793854
Valid Loss:  0.40759706497192383
Epoch:  174  	Training Loss: 0.36802130937576294
Test Loss:  0.43166035413742065
Valid Loss:  0.40665608644485474
Epoch:  175  	Training Loss: 0.36730527877807617
Test Loss:  0.430730402469635
Valid Loss:  0.4057174324989319
Epoch:  176  	Training Loss: 0.36659085750579834
Test Loss:  0.4298025965690613
Valid Loss:  0.4047810733318329
Epoch:  177  	Training Loss: 0.3658781349658966
Test Loss:  0.42887693643569946
Valid Loss:  0.4038470387458801
Epoch:  178  	Training Loss: 0.3651670813560486
Test Loss:  0.42795345187187195
Valid Loss:  0.40291523933410645
Epoch:  179  	Training Loss: 0.3644576072692871
Test Loss:  0.42703211307525635
Valid Loss:  0.401985764503479
Epoch:  180  	Training Loss: 0.36374980211257935
Test Loss:  0.42611294984817505
Valid Loss:  0.4010585844516754
Epoch:  181  	Training Loss: 0.3630436062812805
Test Loss:  0.42519593238830566
Valid Loss:  0.4001336693763733
Epoch:  182  	Training Loss: 0.3623390793800354
Test Loss:  0.42427539825439453
Valid Loss:  0.39920538663864136
Epoch:  183  	Training Loss: 0.3616317808628082
Test Loss:  0.4233570694923401
Valid Loss:  0.3982793390750885
Epoch:  184  	Training Loss: 0.3609261214733124
Test Loss:  0.42244088649749756
Valid Loss:  0.3973556160926819
Epoch:  185  	Training Loss: 0.36022213101387024
Test Loss:  0.42152684926986694
Valid Loss:  0.3964341878890991
Epoch:  186  	Training Loss: 0.35951972007751465
Test Loss:  0.42061495780944824
Valid Loss:  0.39551496505737305
Epoch:  187  	Training Loss: 0.3588189482688904
Test Loss:  0.41970521211624146
Valid Loss:  0.3945980966091156
Epoch:  188  	Training Loss: 0.35811981558799744
Test Loss:  0.4187976121902466
Valid Loss:  0.39368343353271484
Epoch:  189  	Training Loss: 0.3574223220348358
Test Loss:  0.41789209842681885
Valid Loss:  0.3927710950374603
Epoch:  190  	Training Loss: 0.35672643780708313
Test Loss:  0.416988730430603
Valid Loss:  0.3918609619140625
Epoch:  191  	Training Loss: 0.3560321629047394
Test Loss:  0.41608747839927673
Valid Loss:  0.39095306396484375
Epoch:  192  	Training Loss: 0.35533949732780457
Test Loss:  0.41518375277519226
Valid Loss:  0.39004290103912354
Epoch:  193  	Training Loss: 0.3546449542045593
Test Loss:  0.4142822027206421
Valid Loss:  0.3891350030899048
Epoch:  194  	Training Loss: 0.3539520502090454
Test Loss:  0.41338276863098145
Valid Loss:  0.3882293999195099
Epoch:  195  	Training Loss: 0.35326075553894043
Test Loss:  0.4124854803085327
Valid Loss:  0.38732606172561646
Epoch:  196  	Training Loss: 0.35257112979888916
Test Loss:  0.4115903377532959
Valid Loss:  0.3864249587059021
Epoch:  197  	Training Loss: 0.3518831133842468
Test Loss:  0.4106972813606262
Valid Loss:  0.3855261206626892
Epoch:  198  	Training Loss: 0.35119667649269104
Test Loss:  0.40980637073516846
Valid Loss:  0.3846295475959778
Epoch:  199  	Training Loss: 0.35051190853118896
Test Loss:  0.40891754627227783
Valid Loss:  0.38373517990112305
Epoch:  200  	Training Loss: 0.34982872009277344
Test Loss:  0.4080308675765991
Valid Loss:  0.3828430771827698
Epoch:  201  	Training Loss: 0.34914711117744446
Test Loss:  0.40714630484580994
Valid Loss:  0.3819531798362732
Epoch:  202  	Training Loss: 0.3484671413898468
Test Loss:  0.4062594473361969
Valid Loss:  0.3810610771179199
Epoch:  203  	Training Loss: 0.34778526425361633
Test Loss:  0.4053747057914734
Valid Loss:  0.3801712393760681
Epoch:  204  	Training Loss: 0.3471049964427948
Test Loss:  0.4044920802116394
Valid Loss:  0.3792836368083954
Epoch:  205  	Training Loss: 0.3464263081550598
Test Loss:  0.40361154079437256
Valid Loss:  0.37839823961257935
Epoch:  206  	Training Loss: 0.34574922919273376
Test Loss:  0.4027331471443176
Valid Loss:  0.37751504778862
Epoch:  207  	Training Loss: 0.34507375955581665
Test Loss:  0.40185678005218506
Valid Loss:  0.3766341209411621
Epoch:  208  	Training Loss: 0.3443998694419861
Test Loss:  0.40098249912261963
Valid Loss:  0.37575531005859375
Epoch:  209  	Training Loss: 0.3437275290489197
Test Loss:  0.4001103639602661
Valid Loss:  0.37487882375717163
Epoch:  210  	Training Loss: 0.3430567979812622
Test Loss:  0.3992402255535126
Valid Loss:  0.37400445342063904
Epoch:  211  	Training Loss: 0.3423876166343689
Test Loss:  0.39837220311164856
Valid Loss:  0.37313228845596313
Epoch:  212  	Training Loss: 0.3417200744152069
Test Loss:  0.3975033164024353
Valid Loss:  0.37225937843322754
Epoch:  213  	Training Loss: 0.34105193614959717
Test Loss:  0.3966365456581116
Valid Loss:  0.37138864398002625
Epoch:  214  	Training Loss: 0.34038540720939636
Test Loss:  0.3957718014717102
Valid Loss:  0.37052011489868164
Epoch:  215  	Training Loss: 0.3397204279899597
Test Loss:  0.394909143447876
Valid Loss:  0.36965376138687134
Epoch:  216  	Training Loss: 0.3390570282936096
Test Loss:  0.3940485119819641
Valid Loss:  0.36878955364227295
Epoch:  217  	Training Loss: 0.3383951485157013
Test Loss:  0.3931899666786194
Valid Loss:  0.36792758107185364
Epoch:  218  	Training Loss: 0.3377348482608795
Test Loss:  0.392333447933197
Valid Loss:  0.36706778407096863
Epoch:  219  	Training Loss: 0.3370761275291443
Test Loss:  0.391478955745697
Valid Loss:  0.36621010303497314
Epoch:  220  	Training Loss: 0.33641892671585083
Test Loss:  0.3906265199184418
Valid Loss:  0.36535459756851196
Epoch:  221  	Training Loss: 0.3357633352279663
Test Loss:  0.3897761106491089
Valid Loss:   44%|████▍     | 221/500 [02:37<05:34,  1.20s/it] 45%|████▍     | 223/500 [02:37<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:37<02:51,  1.61it/s] 45%|████▌     | 227/500 [02:37<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:37<01:32,  2.93it/s] 46%|████▌     | 231/500 [02:43<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:44<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:44<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:44<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:44<01:27,  2.99it/s] 48%|████▊     | 241/500 [02:50<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:50<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:51<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:51<01:52,  2.25it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.02it/s] 50%|█████     | 251/500 [02:57<04:55,  1.19s/it] 51%|█████     | 253/500 [02:57<03:30,  1.18it/s] 51%|█████     | 255/500 [02:57<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:58<01:49,  2.22it/s] 52%|█████▏    | 259/500 [02:58<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:04<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:04<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:11<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:11<03:11,  1.18it/s] 55%|█████▌    | 275/500 [03:11<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:11<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:11<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:18<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:18<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:18<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:18<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:18<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:24<04:05,  1.18s/it] 59%|█████▊    | 293/500 [03:25<02:54,  1.19it/s]0.3645011782646179
Epoch:  222  	Training Loss: 0.33510923385620117
Test Loss:  0.3889244496822357
Valid Loss:  0.36364662647247314
Epoch:  223  	Training Loss: 0.3344540596008301
Test Loss:  0.3880748152732849
Valid Loss:  0.3627941608428955
Epoch:  224  	Training Loss: 0.33380043506622314
Test Loss:  0.38722723722457886
Valid Loss:  0.36194390058517456
Epoch:  225  	Training Loss: 0.33314836025238037
Test Loss:  0.386381596326828
Valid Loss:  0.36109569668769836
Epoch:  226  	Training Loss: 0.332497775554657
Test Loss:  0.3855380415916443
Valid Loss:  0.3602496385574341
Epoch:  227  	Training Loss: 0.33184874057769775
Test Loss:  0.38469648361206055
Valid Loss:  0.3594057559967041
Epoch:  228  	Training Loss: 0.3312012553215027
Test Loss:  0.3838569223880768
Valid Loss:  0.35856395959854126
Epoch:  229  	Training Loss: 0.3305552899837494
Test Loss:  0.383019357919693
Valid Loss:  0.35772427916526794
Epoch:  230  	Training Loss: 0.32991087436676025
Test Loss:  0.38218382000923157
Valid Loss:  0.35688671469688416
Epoch:  231  	Training Loss: 0.3292679190635681
Test Loss:  0.38135021924972534
Valid Loss:  0.3560512661933899
Epoch:  232  	Training Loss: 0.3286265432834625
Test Loss:  0.38051629066467285
Valid Loss:  0.3552156090736389
Epoch:  233  	Training Loss: 0.3279849588871002
Test Loss:  0.3796842396259308
Valid Loss:  0.3543820083141327
Epoch:  234  	Training Loss: 0.3273448944091797
Test Loss:  0.37885424494743347
Valid Loss:  0.3535505533218384
Epoch:  235  	Training Loss: 0.3267063498497009
Test Loss:  0.37802621722221375
Valid Loss:  0.3527211546897888
Epoch:  236  	Training Loss: 0.32606935501098633
Test Loss:  0.3772001564502716
Valid Loss:  0.35189390182495117
Epoch:  237  	Training Loss: 0.3254338204860687
Test Loss:  0.37637609243392944
Valid Loss:  0.3510686755180359
Epoch:  238  	Training Loss: 0.3247997760772705
Test Loss:  0.37555399537086487
Valid Loss:  0.35024553537368774
Epoch:  239  	Training Loss: 0.32416725158691406
Test Loss:  0.3747338652610779
Valid Loss:  0.3494245409965515
Epoch:  240  	Training Loss: 0.323536217212677
Test Loss:  0.3739156723022461
Valid Loss:  0.34860557317733765
Epoch:  241  	Training Loss: 0.3229067027568817
Test Loss:  0.3730994462966919
Valid Loss:  0.34778866171836853
Epoch:  242  	Training Loss: 0.32227861881256104
Test Loss:  0.3722821772098541
Valid Loss:  0.3469708561897278
Epoch:  243  	Training Loss: 0.3216497004032135
Test Loss:  0.37146687507629395
Valid Loss:  0.3461551070213318
Epoch:  244  	Training Loss: 0.32102227210998535
Test Loss:  0.37065353989601135
Valid Loss:  0.3453415036201477
Epoch:  245  	Training Loss: 0.320396363735199
Test Loss:  0.36984217166900635
Valid Loss:  0.3445298671722412
Epoch:  246  	Training Loss: 0.3197718858718872
Test Loss:  0.36903268098831177
Valid Loss:  0.34372031688690186
Epoch:  247  	Training Loss: 0.3191488981246948
Test Loss:  0.3682251572608948
Valid Loss:  0.34291282296180725
Epoch:  248  	Training Loss: 0.3185274004936218
Test Loss:  0.36741960048675537
Valid Loss:  0.3421074151992798
Epoch:  249  	Training Loss: 0.3179073631763458
Test Loss:  0.3666159212589264
Valid Loss:  0.3413039445877075
Epoch:  250  	Training Loss: 0.3172887861728668
Test Loss:  0.3658141493797302
Valid Loss:  0.3405025601387024
Epoch:  251  	Training Loss: 0.3166716694831848
Test Loss:  0.36501431465148926
Valid Loss:  0.33970320224761963
Epoch:  252  	Training Loss: 0.3160559833049774
Test Loss:  0.3642149567604065
Valid Loss:  0.33890438079833984
Epoch:  253  	Training Loss: 0.31544065475463867
Test Loss:  0.36341747641563416
Valid Loss:  0.3381075859069824
Epoch:  254  	Training Loss: 0.3148268163204193
Test Loss:  0.36262190341949463
Valid Loss:  0.33731281757354736
Epoch:  255  	Training Loss: 0.31421440839767456
Test Loss:  0.3618282973766327
Valid Loss:  0.3365200459957123
Epoch:  256  	Training Loss: 0.3136034607887268
Test Loss:  0.3610365688800812
Valid Loss:  0.33572933077812195
Epoch:  257  	Training Loss: 0.31299397349357605
Test Loss:  0.3602467179298401
Valid Loss:  0.3349405825138092
Epoch:  258  	Training Loss: 0.3123859465122223
Test Loss:  0.3594588041305542
Valid Loss:  0.3341538906097412
Epoch:  259  	Training Loss: 0.31177935004234314
Test Loss:  0.35867276787757874
Valid Loss:  0.3333691656589508
Epoch:  260  	Training Loss: 0.3111741542816162
Test Loss:  0.3578885793685913
Valid Loss:  0.3325864374637604
Epoch:  261  	Training Loss: 0.31057044863700867
Test Loss:  0.3571063280105591
Valid Loss:  0.3318057060241699
Epoch:  262  	Training Loss: 0.30996817350387573
Test Loss:  0.3563244044780731
Valid Loss:  0.3310253918170929
Epoch:  263  	Training Loss: 0.3093661069869995
Test Loss:  0.3555443584918976
Valid Loss:  0.33024704456329346
Epoch:  264  	Training Loss: 0.3087655305862427
Test Loss:  0.35476619005203247
Valid Loss:  0.329470694065094
Epoch:  265  	Training Loss: 0.3081663250923157
Test Loss:  0.353989839553833
Valid Loss:  0.3286963105201721
Epoch:  266  	Training Loss: 0.3075685501098633
Test Loss:  0.35321539640426636
Valid Loss:  0.32792389392852783
Epoch:  267  	Training Loss: 0.3069722354412079
Test Loss:  0.35244280099868774
Valid Loss:  0.32715344429016113
Epoch:  268  	Training Loss: 0.3063772916793823
Test Loss:  0.35167205333709717
Valid Loss:  0.326384961605072
Epoch:  269  	Training Loss: 0.305783748626709
Test Loss:  0.350903183221817
Valid Loss:  0.3256184458732605
Epoch:  270  	Training Loss: 0.30519166588783264
Test Loss:  0.3501361310482025
Valid Loss:  0.32485389709472656
Epoch:  271  	Training Loss: 0.30460095405578613
Test Loss:  0.34937095642089844
Valid Loss:  0.32409122586250305
Epoch:  272  	Training Loss: 0.3040117025375366
Test Loss:  0.34860557317733765
Valid Loss:  0.32332855463027954
Epoch:  273  	Training Loss: 0.3034221827983856
Test Loss:  0.3478420376777649
Valid Loss:  0.3225678503513336
Epoch:  274  	Training Loss: 0.30283409357070923
Test Loss:  0.3470803499221802
Valid Loss:  0.3218090534210205
Epoch:  275  	Training Loss: 0.30224740505218506
Test Loss:  0.3463205099105835
Valid Loss:  0.3210522532463074
Epoch:  276  	Training Loss: 0.3016621172428131
Test Loss:  0.34556248784065247
Valid Loss:  0.32029733061790466
Epoch:  277  	Training Loss: 0.301078200340271
Test Loss:  0.3448063135147095
Valid Loss:  0.31954434514045715
Epoch:  278  	Training Loss: 0.3004957139492035
Test Loss:  0.34405189752578735
Valid Loss:  0.31879329681396484
Epoch:  279  	Training Loss: 0.2999145984649658
Test Loss:  0.34329935908317566
Valid Loss:  0.31804418563842773
Epoch:  280  	Training Loss: 0.299334853887558
Test Loss:  0.3425486385822296
Valid Loss:  0.31729695200920105
Epoch:  281  	Training Loss: 0.29875651001930237
Test Loss:  0.3417997360229492
Valid Loss:  0.3165516257286072
Epoch:  282  	Training Loss: 0.2981795370578766
Test Loss:  0.3410513401031494
Valid Loss:  0.31580695509910583
Epoch:  283  	Training Loss: 0.2976030111312866
Test Loss:  0.34030479192733765
Valid Loss:  0.3150641918182373
Epoch:  284  	Training Loss: 0.2970278859138489
Test Loss:  0.33956003189086914
Valid Loss:  0.3143233358860016
Epoch:  285  	Training Loss: 0.29645413160324097
Test Loss:  0.33881711959838867
Valid Loss:  0.3135843575000763
Epoch:  286  	Training Loss: 0.2958817481994629
Test Loss:  0.3380759358406067
Valid Loss:  0.3128472864627838
Epoch:  287  	Training Loss: 0.29531070590019226
Test Loss:  0.33733657002449036
Valid Loss:  0.31211206316947937
Epoch:  288  	Training Loss: 0.29474103450775146
Test Loss:  0.3365989327430725
Valid Loss:  0.31137871742248535
Epoch:  289  	Training Loss: 0.2941727042198181
Test Loss:  0.3358631134033203
Valid Loss:  0.31064730882644653
Epoch:  290  	Training Loss: 0.2936057448387146
Test Loss:  0.335129052400589
Valid Loss:  0.30991771817207336
Epoch:  291  	Training Loss: 0.2930401563644409
Test Loss:  0.3343968093395233
Valid Loss:  0.30918997526168823
Epoch:  292  	Training Loss: 0.2924758791923523
Test Loss:  0.33366528153419495
Valid Loss:  0.3084631860256195
Epoch:  293  	Training Loss: 0.2919120788574219
Test Loss:  0.33293551206588745
Valid Loss:  0.30773818492889404
Epoch:  294  	Training Loss: 0.2913496792316437
Test Loss:  0.3322076201438904
Valid Loss:   59%|█████▉    | 295/500 [03:25<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:25<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:25<01:06,  3.01it/s] 60%|██████    | 301/500 [03:31<03:53,  1.17s/it] 61%|██████    | 303/500 [03:31<02:46,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:32<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:32<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:38<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:38<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:38<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:38<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:39<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:45<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:45<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:45<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:45<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:45<00:57,  2.99it/s] 66%|██████▌   | 331/500 [03:52<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:52<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:52<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:52<01:13,  2.23it/s] 68%|██████▊   | 339/500 [03:52<00:53,  2.99it/s] 68%|██████▊   | 341/500 [03:59<03:06,  1.17s/it] 69%|██████▊   | 343/500 [03:59<02:12,  1.19it/s] 69%|██████▉   | 345/500 [03:59<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:59<01:08,  2.23it/s] 70%|██████▉   | 349/500 [03:59<00:50,  3.00it/s] 70%|███████   | 351/500 [04:06<02:57,  1.19s/it] 71%|███████   | 353/500 [04:06<02:06,  1.17it/s] 71%|███████   | 355/500 [04:06<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:06<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:06<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:12<02:47,  1.20s/it] 73%|███████▎  | 363/500 [04:13<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:13<01:24,  1.60it/s]0.3070150911808014
Epoch:  295  	Training Loss: 0.2907886505126953
Test Loss:  0.33148136734962463
Valid Loss:  0.30629387497901917
Epoch:  296  	Training Loss: 0.2902289032936096
Test Loss:  0.33075690269470215
Valid Loss:  0.3055744469165802
Epoch:  297  	Training Loss: 0.28967052698135376
Test Loss:  0.3300342559814453
Valid Loss:  0.30485689640045166
Epoch:  298  	Training Loss: 0.28911346197128296
Test Loss:  0.3293132781982422
Valid Loss:  0.30414122343063354
Epoch:  299  	Training Loss: 0.288557767868042
Test Loss:  0.3285940885543823
Valid Loss:  0.3034273386001587
Epoch:  300  	Training Loss: 0.2880033552646637
Test Loss:  0.32787662744522095
Valid Loss:  0.3027153015136719
Epoch:  301  	Training Loss: 0.28745031356811523
Test Loss:  0.32716089487075806
Valid Loss:  0.3020050525665283
Epoch:  302  	Training Loss: 0.28689855337142944
Test Loss:  0.32644525170326233
Valid Loss:  0.30129510164260864
Epoch:  303  	Training Loss: 0.2863468527793884
Test Loss:  0.3257313370704651
Valid Loss:  0.3005869686603546
Epoch:  304  	Training Loss: 0.28579646348953247
Test Loss:  0.3250191807746887
Valid Loss:  0.29988065361976624
Epoch:  305  	Training Loss: 0.28524741530418396
Test Loss:  0.32430875301361084
Valid Loss:  0.2991761565208435
Epoch:  306  	Training Loss: 0.2846996784210205
Test Loss:  0.32360005378723145
Valid Loss:  0.2984735071659088
Epoch:  307  	Training Loss: 0.2841532528400421
Test Loss:  0.32289305329322815
Valid Loss:  0.2977726459503174
Epoch:  308  	Training Loss: 0.283608078956604
Test Loss:  0.32218778133392334
Valid Loss:  0.2970735728740692
Epoch:  309  	Training Loss: 0.2830643057823181
Test Loss:  0.32148420810699463
Valid Loss:  0.2963762879371643
Epoch:  310  	Training Loss: 0.2825217843055725
Test Loss:  0.3207823634147644
Valid Loss:  0.29568082094192505
Epoch:  311  	Training Loss: 0.28198057413101196
Test Loss:  0.3200821876525879
Valid Loss:  0.29498714208602905
Epoch:  312  	Training Loss: 0.2814406752586365
Test Loss:  0.319382905960083
Valid Loss:  0.2942943572998047
Epoch:  313  	Training Loss: 0.28090134263038635
Test Loss:  0.31868529319763184
Valid Loss:  0.29360339045524597
Epoch:  314  	Training Loss: 0.2803633213043213
Test Loss:  0.31798937916755676
Valid Loss:  0.29291418194770813
Epoch:  315  	Training Loss: 0.2798265814781189
Test Loss:  0.3172951638698578
Valid Loss:  0.29222679138183594
Epoch:  316  	Training Loss: 0.27929115295410156
Test Loss:  0.3166026175022125
Valid Loss:  0.2915411591529846
Epoch:  317  	Training Loss: 0.2787569761276245
Test Loss:  0.31591174006462097
Valid Loss:  0.2908572554588318
Epoch:  318  	Training Loss: 0.27822408080101013
Test Loss:  0.3152225613594055
Valid Loss:  0.29017511010169983
Epoch:  319  	Training Loss: 0.2776924669742584
Test Loss:  0.3145350217819214
Valid Loss:  0.2894947826862335
Epoch:  320  	Training Loss: 0.2771621346473694
Test Loss:  0.31384921073913574
Valid Loss:  0.2888161540031433
Epoch:  321  	Training Loss: 0.27663305401802063
Test Loss:  0.31316500902175903
Valid Loss:  0.28813934326171875
Epoch:  322  	Training Loss: 0.27610528469085693
Test Loss:  0.3124812841415405
Valid Loss:  0.2874629497528076
Epoch:  323  	Training Loss: 0.2755779027938843
Test Loss:  0.31179916858673096
Valid Loss:  0.28678834438323975
Epoch:  324  	Training Loss: 0.2750517725944519
Test Loss:  0.3111186921596527
Valid Loss:  0.28611546754837036
Epoch:  325  	Training Loss: 0.2745268940925598
Test Loss:  0.3104398846626282
Valid Loss:  0.2854442894458771
Epoch:  326  	Training Loss: 0.274003267288208
Test Loss:  0.30976271629333496
Valid Loss:  0.2847748398780823
Epoch:  327  	Training Loss: 0.27348092198371887
Test Loss:  0.3090871572494507
Valid Loss:  0.28410714864730835
Epoch:  328  	Training Loss: 0.27295979857444763
Test Loss:  0.3084132671356201
Valid Loss:  0.2834411859512329
Epoch:  329  	Training Loss: 0.2724398970603943
Test Loss:  0.3077410161495209
Valid Loss:  0.2827768921852112
Epoch:  330  	Training Loss: 0.271921306848526
Test Loss:  0.30707037448883057
Valid Loss:  0.28211432695388794
Epoch:  331  	Training Loss: 0.2714039087295532
Test Loss:  0.3064013719558716
Valid Loss:  0.2814534604549408
Epoch:  332  	Training Loss: 0.27088773250579834
Test Loss:  0.30573344230651855
Valid Loss:  0.2807939052581787
Epoch:  333  	Training Loss: 0.270372599363327
Test Loss:  0.3050672113895416
Valid Loss:  0.2801360487937927
Epoch:  334  	Training Loss: 0.2698586881160736
Test Loss:  0.30440253019332886
Valid Loss:  0.27947986125946045
Epoch:  335  	Training Loss: 0.2693460285663605
Test Loss:  0.3037395477294922
Valid Loss:  0.2788253724575043
Epoch:  336  	Training Loss: 0.26883459091186523
Test Loss:  0.3030780851840973
Valid Loss:  0.2781725525856018
Epoch:  337  	Training Loss: 0.2683243453502655
Test Loss:  0.3024182915687561
Valid Loss:  0.2775214910507202
Epoch:  338  	Training Loss: 0.26781535148620605
Test Loss:  0.30176007747650146
Valid Loss:  0.27687203884124756
Epoch:  339  	Training Loss: 0.2673075199127197
Test Loss:  0.301103413105011
Valid Loss:  0.2762242555618286
Epoch:  340  	Training Loss: 0.2668009400367737
Test Loss:  0.3004484176635742
Valid Loss:  0.27557820081710815
Epoch:  341  	Training Loss: 0.26629558205604553
Test Loss:  0.2997949421405792
Valid Loss:  0.274933785200119
Epoch:  342  	Training Loss: 0.2657914161682129
Test Loss:  0.29914212226867676
Valid Loss:  0.27429020404815674
Epoch:  343  	Training Loss: 0.2652873992919922
Test Loss:  0.29849088191986084
Valid Loss:  0.27364832162857056
Epoch:  344  	Training Loss: 0.26478463411331177
Test Loss:  0.29784125089645386
Valid Loss:  0.2730080783367157
Epoch:  345  	Training Loss: 0.26428306102752686
Test Loss:  0.29719316959381104
Valid Loss:  0.2723695635795593
Epoch:  346  	Training Loss: 0.26378270983695984
Test Loss:  0.29654672741889954
Valid Loss:  0.2717326581478119
Epoch:  347  	Training Loss: 0.26328355073928833
Test Loss:  0.295901894569397
Valid Loss:  0.27109748125076294
Epoch:  348  	Training Loss: 0.2627856135368347
Test Loss:  0.29525864124298096
Valid Loss:  0.2704639732837677
Epoch:  349  	Training Loss: 0.2622888684272766
Test Loss:  0.2946169376373291
Valid Loss:  0.2698320746421814
Epoch:  350  	Training Loss: 0.2617933452129364
Test Loss:  0.2939768433570862
Valid Loss:  0.2692018151283264
Epoch:  351  	Training Loss: 0.2612990140914917
Test Loss:  0.2933382987976074
Valid Loss:  0.26857322454452515
Epoch:  352  	Training Loss: 0.2608059048652649
Test Loss:  0.2927008867263794
Valid Loss:  0.2679457664489746
Epoch:  353  	Training Loss: 0.2603137791156769
Test Loss:  0.2920650541782379
Valid Loss:  0.2673199772834778
Epoch:  354  	Training Loss: 0.2598228454589844
Test Loss:  0.291430801153183
Valid Loss:  0.2666957974433899
Epoch:  355  	Training Loss: 0.25933313369750977
Test Loss:  0.2907980680465698
Valid Loss:  0.2660732865333557
Epoch:  356  	Training Loss: 0.25884461402893066
Test Loss:  0.2901668846607208
Valid Loss:  0.2654523253440857
Epoch:  357  	Training Loss: 0.2583572566509247
Test Loss:  0.289537250995636
Valid Loss:  0.2648330330848694
Epoch:  358  	Training Loss: 0.2578710615634918
Test Loss:  0.2889091670513153
Valid Loss:  0.2642153203487396
Epoch:  359  	Training Loss: 0.2573860287666321
Test Loss:  0.288282573223114
Valid Loss:  0.2635992169380188
Epoch:  360  	Training Loss: 0.25690215826034546
Test Loss:  0.2876575291156769
Valid Loss:  0.2629847228527069
Epoch:  361  	Training Loss: 0.25641947984695435
Test Loss:  0.2870340049266815
Valid Loss:  0.26237183809280396
Epoch:  362  	Training Loss: 0.25593793392181396
Test Loss:  0.286410927772522
Valid Loss:  0.26175951957702637
Epoch:  363  	Training Loss: 0.25545674562454224
Test Loss:  0.285789430141449
Valid Loss:  0.2611488103866577
Epoch:  364  	Training Loss: 0.25497668981552124
Test Loss:  0.285169392824173
Valid Loss:  0.2605396807193756
Epoch:  365  	Training Loss: 0.25449782609939575
Test Loss:  0.28455090522766113
Valid Loss:  0.25993216037750244
Epoch:  366  	Training Loss: 0.2540201246738434
Test Loss:  0.2839338779449463
Valid Loss:  0.25932618975639343
Epoch:  367  	Training Loss: 0.25354352593421936
Test Loss:  0.2833184003829956
Valid Loss:   73%|███████▎  | 367/500 [04:13<01:00,  2.18it/s] 74%|███████▍  | 369/500 [04:13<00:44,  2.94it/s] 74%|███████▍  | 371/500 [04:19<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:20<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:20<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:20<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:20<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:26<02:19,  1.18s/it] 77%|███████▋  | 383/500 [04:26<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:26<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:27<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:27<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:33<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:33<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:33<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:33<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:34<00:33,  2.99it/s] 80%|████████  | 401/500 [04:40<01:57,  1.19s/it] 81%|████████  | 403/500 [04:40<01:22,  1.17it/s] 81%|████████  | 405/500 [04:40<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:40<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:40<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:47<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:47<01:14,  1.18it/s] 83%|████████▎ | 415/500 [04:47<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:47<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:47<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:54<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:54<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:54<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:54<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:54<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:01<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:01<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:01<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:01<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:01<00:20,  2.97it/s]0.25872182846069336
Epoch:  368  	Training Loss: 0.25306808948516846
Test Loss:  0.2827044129371643
Valid Loss:  0.25811898708343506
Epoch:  369  	Training Loss: 0.2525938153266907
Test Loss:  0.2820919156074524
Valid Loss:  0.2575177550315857
Epoch:  370  	Training Loss: 0.2521206736564636
Test Loss:  0.28148090839385986
Valid Loss:  0.2569181025028229
Epoch:  371  	Training Loss: 0.2516486346721649
Test Loss:  0.2808714210987091
Valid Loss:  0.2563199996948242
Epoch:  372  	Training Loss: 0.2511777877807617
Test Loss:  0.28026384115219116
Valid Loss:  0.25572383403778076
Epoch:  373  	Training Loss: 0.2507084608078003
Test Loss:  0.2796577215194702
Valid Loss:  0.25512924790382385
Epoch:  374  	Training Loss: 0.2502402663230896
Test Loss:  0.27905309200286865
Valid Loss:  0.2545362114906311
Epoch:  375  	Training Loss: 0.24977321922779083
Test Loss:  0.2784499526023865
Valid Loss:  0.2539446949958801
Epoch:  376  	Training Loss: 0.2493073046207428
Test Loss:  0.2778482437133789
Valid Loss:  0.2533547282218933
Epoch:  377  	Training Loss: 0.24884247779846191
Test Loss:  0.2772480547428131
Valid Loss:  0.25276631116867065
Epoch:  378  	Training Loss: 0.24837879836559296
Test Loss:  0.2766492962837219
Valid Loss:  0.25217944383621216
Epoch:  379  	Training Loss: 0.24791622161865234
Test Loss:  0.27605199813842773
Valid Loss:  0.25159406661987305
Epoch:  380  	Training Loss: 0.24745476245880127
Test Loss:  0.27545619010925293
Valid Loss:  0.2510102391242981
Epoch:  381  	Training Loss: 0.24699440598487854
Test Loss:  0.27486181259155273
Valid Loss:  0.2504279315471649
Epoch:  382  	Training Loss: 0.24653516709804535
Test Loss:  0.27426815032958984
Valid Loss:  0.2498464286327362
Epoch:  383  	Training Loss: 0.24607634544372559
Test Loss:  0.27367591857910156
Valid Loss:  0.24926641583442688
Epoch:  384  	Training Loss: 0.24561864137649536
Test Loss:  0.2730851173400879
Valid Loss:  0.24868792295455933
Epoch:  385  	Training Loss: 0.24516203999519348
Test Loss:  0.27249574661254883
Valid Loss:  0.24811094999313354
Epoch:  386  	Training Loss: 0.24470652639865875
Test Loss:  0.27190783619880676
Valid Loss:  0.24753551185131073
Epoch:  387  	Training Loss: 0.24425211548805237
Test Loss:  0.2713213562965393
Valid Loss:  0.2469615340232849
Epoch:  388  	Training Loss: 0.24379880726337433
Test Loss:  0.27073633670806885
Valid Loss:  0.24638909101486206
Epoch:  389  	Training Loss: 0.24334660172462463
Test Loss:  0.270152747631073
Valid Loss:  0.2458181381225586
Epoch:  390  	Training Loss: 0.2428954541683197
Test Loss:  0.26957058906555176
Valid Loss:  0.2452486753463745
Epoch:  391  	Training Loss: 0.2424454391002655
Test Loss:  0.26898980140686035
Valid Loss:  0.24468070268630981
Epoch:  392  	Training Loss: 0.24199649691581726
Test Loss:  0.268409788608551
Valid Loss:  0.24411356449127197
Epoch:  393  	Training Loss: 0.2415480613708496
Test Loss:  0.2678312063217163
Valid Loss:  0.24354788661003113
Epoch:  394  	Training Loss: 0.2411007285118103
Test Loss:  0.2672539949417114
Valid Loss:  0.24298368394374847
Epoch:  395  	Training Loss: 0.24065446853637695
Test Loss:  0.26667821407318115
Valid Loss:  0.24242094159126282
Epoch:  396  	Training Loss: 0.24020928144454956
Test Loss:  0.2661038339138031
Valid Loss:  0.24185968935489655
Epoch:  397  	Training Loss: 0.23976516723632812
Test Loss:  0.2655308246612549
Valid Loss:  0.24129991233348846
Epoch:  398  	Training Loss: 0.23932211101055145
Test Loss:  0.26495927572250366
Valid Loss:  0.2407415807247162
Epoch:  399  	Training Loss: 0.23888012766838074
Test Loss:  0.2643890976905823
Valid Loss:  0.2401847243309021
Epoch:  400  	Training Loss: 0.23843920230865479
Test Loss:  0.2638203203678131
Valid Loss:  0.239629328250885
Epoch:  401  	Training Loss: 0.23799936473369598
Test Loss:  0.26325294375419617
Valid Loss:  0.2390754073858261
Epoch:  402  	Training Loss: 0.23756058514118195
Test Loss:  0.2626860737800598
Valid Loss:  0.23852205276489258
Epoch:  403  	Training Loss: 0.23712202906608582
Test Loss:  0.2621205449104309
Valid Loss:  0.23797011375427246
Epoch:  404  	Training Loss: 0.23668448626995087
Test Loss:  0.26155638694763184
Valid Loss:  0.23741963505744934
Epoch:  405  	Training Loss: 0.23624800145626068
Test Loss:  0.2609936594963074
Valid Loss:  0.23687060177326202
Epoch:  406  	Training Loss: 0.23581257462501526
Test Loss:  0.26043227314949036
Valid Loss:  0.2363230288028717
Epoch:  407  	Training Loss: 0.235378235578537
Test Loss:  0.25987231731414795
Valid Loss:  0.2357769012451172
Epoch:  408  	Training Loss: 0.2349449247121811
Test Loss:  0.259313702583313
Valid Loss:  0.2352321892976761
Epoch:  409  	Training Loss: 0.23451267182826996
Test Loss:  0.25875645875930786
Valid Loss:  0.2346889227628708
Epoch:  410  	Training Loss: 0.2340814471244812
Test Loss:  0.25820058584213257
Valid Loss:  0.2341470718383789
Epoch:  411  	Training Loss: 0.2336512953042984
Test Loss:  0.2576460838317871
Valid Loss:  0.23360666632652283
Epoch:  412  	Training Loss: 0.23322215676307678
Test Loss:  0.25709283351898193
Valid Loss:  0.2330675572156906
Epoch:  413  	Training Loss: 0.23279410600662231
Test Loss:  0.2565409541130066
Valid Loss:  0.2325298935174942
Epoch:  414  	Training Loss: 0.2323671132326126
Test Loss:  0.2559903860092163
Valid Loss:  0.23199361562728882
Epoch:  415  	Training Loss: 0.2319411337375641
Test Loss:  0.25544121861457825
Valid Loss:  0.23145875334739685
Epoch:  416  	Training Loss: 0.23151618242263794
Test Loss:  0.25489339232444763
Valid Loss:  0.2309253215789795
Epoch:  417  	Training Loss: 0.23109227418899536
Test Loss:  0.25434690713882446
Valid Loss:  0.23039326071739197
Epoch:  418  	Training Loss: 0.23066937923431396
Test Loss:  0.25380170345306396
Valid Loss:  0.22986263036727905
Epoch:  419  	Training Loss: 0.23024749755859375
Test Loss:  0.2532579302787781
Valid Loss:  0.22933341562747955
Epoch:  420  	Training Loss: 0.2298266887664795
Test Loss:  0.25271546840667725
Valid Loss:  0.2288055717945099
Epoch:  421  	Training Loss: 0.22940687835216522
Test Loss:  0.25217434763908386
Valid Loss:  0.22827914357185364
Epoch:  422  	Training Loss: 0.22898808121681213
Test Loss:  0.2516338527202606
Valid Loss:  0.2277534157037735
Epoch:  423  	Training Loss: 0.22856956720352173
Test Loss:  0.25109466910362244
Valid Loss:  0.2272290587425232
Epoch:  424  	Training Loss: 0.2281520664691925
Test Loss:  0.2505567967891693
Valid Loss:  0.2267061024904251
Epoch:  425  	Training Loss: 0.22773560881614685
Test Loss:  0.25002026557922363
Valid Loss:  0.22618451714515686
Epoch:  426  	Training Loss: 0.22732013463974
Test Loss:  0.2494850605726242
Valid Loss:  0.22566431760787964
Epoch:  427  	Training Loss: 0.2269056737422943
Test Loss:  0.24895116686820984
Valid Loss:  0.22514548897743225
Epoch:  428  	Training Loss: 0.22649222612380981
Test Loss:  0.24841856956481934
Valid Loss:  0.2246280461549759
Epoch:  429  	Training Loss: 0.2260797619819641
Test Loss:  0.24788732826709747
Valid Loss:  0.22411195933818817
Epoch:  430  	Training Loss: 0.22566834092140198
Test Loss:  0.24735736846923828
Valid Loss:  0.22359725832939148
Epoch:  431  	Training Loss: 0.22525787353515625
Test Loss:  0.24682871997356415
Valid Loss:  0.22308388352394104
Epoch:  432  	Training Loss: 0.2248484492301941
Test Loss:  0.24630051851272583
Valid Loss:  0.22257104516029358
Epoch:  433  	Training Loss: 0.22443950176239014
Test Loss:  0.24577362835407257
Valid Loss:  0.22205956280231476
Epoch:  434  	Training Loss: 0.22403156757354736
Test Loss:  0.24524801969528198
Valid Loss:  0.22154942154884338
Epoch:  435  	Training Loss: 0.22362461686134338
Test Loss:  0.24472370743751526
Valid Loss:  0.22104063630104065
Epoch:  436  	Training Loss: 0.2232186496257782
Test Loss:  0.24420064687728882
Valid Loss:  0.22053316235542297
Epoch:  437  	Training Loss: 0.2228136658668518
Test Loss:  0.24367889761924744
Valid Loss:  0.22002704441547394
Epoch:  438  	Training Loss: 0.22240963578224182
Test Loss:  0.24315842986106873
Valid Loss:  0.21952223777770996
Epoch:  439  	Training Loss: 0.22200661897659302
Test Loss:  0.2426392138004303
Valid Loss:  0.21901878714561462
Epoch:  440  	Training Loss: 0.22160454094409943
 88%|████████▊ | 441/500 [05:08<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:08<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:08<00:24,  2.20it/s] 90%|████████▉ | 449/500 [05:08<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:14<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:14<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:15<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:15<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:15<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:21<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:21<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:21<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:22<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:22<00:10,  2.99it/s] 94%|█████████▍| 471/500 [05:28<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:28<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:28<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.18it/s] 96%|█████████▌| 479/500 [05:29<00:07,  2.88it/s] 96%|█████████▌| 481/500 [05:35<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:35<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:35<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:36<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:36<00:03,  2.94it/s] 98%|█████████▊| 491/500 [05:42<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:42<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:42<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:43<00:01,  2.18it/s]100%|█████████▉| 499/500 [05:43<00:00,  2.93it/s]100%|██████████| 500/500 [05:43<00:00,  1.46it/s]
Test Loss:  0.24212129414081573
Valid Loss:  0.21851666271686554
Epoch:  441  	Training Loss: 0.22120344638824463
Test Loss:  0.24160464107990265
Valid Loss:  0.2180158793926239
Epoch:  442  	Training Loss: 0.22080332040786743
Test Loss:  0.24108977615833282
Valid Loss:  0.2175169140100479
Epoch:  443  	Training Loss: 0.220404714345932
Test Loss:  0.24057617783546448
Valid Loss:  0.21701925992965698
Epoch:  444  	Training Loss: 0.220007061958313
Test Loss:  0.2400638461112976
Valid Loss:  0.2165229469537735
Epoch:  445  	Training Loss: 0.21961036324501038
Test Loss:  0.23955275118350983
Valid Loss:  0.21602791547775269
Epoch:  446  	Training Loss: 0.21921464800834656
Test Loss:  0.23904293775558472
Valid Loss:  0.21553419530391693
Epoch:  447  	Training Loss: 0.21881987154483795
Test Loss:  0.2385343462228775
Valid Loss:  0.21504180133342743
Epoch:  448  	Training Loss: 0.21842604875564575
Test Loss:  0.23802700638771057
Valid Loss:  0.2145506739616394
Epoch:  449  	Training Loss: 0.21803317964076996
Test Loss:  0.23752091825008392
Valid Loss:  0.21406085789203644
Epoch:  450  	Training Loss: 0.21764126420021057
Test Loss:  0.23701608180999756
Valid Loss:  0.21357232332229614
Epoch:  451  	Training Loss: 0.2172502875328064
Test Loss:  0.2365124523639679
Valid Loss:  0.2130851000547409
Epoch:  452  	Training Loss: 0.21686024963855743
Test Loss:  0.2360098659992218
Valid Loss:  0.21259894967079163
Epoch:  453  	Training Loss: 0.2164708971977234
Test Loss:  0.23550854623317719
Valid Loss:  0.2121140956878662
Epoch:  454  	Training Loss: 0.21608251333236694
Test Loss:  0.23500844836235046
Valid Loss:  0.21163052320480347
Epoch:  455  	Training Loss: 0.21569502353668213
Test Loss:  0.23450958728790283
Valid Loss:  0.211148202419281
Epoch:  456  	Training Loss: 0.21530848741531372
Test Loss:  0.2340119332075119
Valid Loss:  0.21066716313362122
Epoch:  457  	Training Loss: 0.21492290496826172
Test Loss:  0.23351550102233887
Valid Loss:  0.2101874202489853
Epoch:  458  	Training Loss: 0.21453823149204254
Test Loss:  0.23302032053470612
Valid Loss:  0.20970894396305084
Epoch:  459  	Training Loss: 0.21415449678897858
Test Loss:  0.23252634704113007
Valid Loss:  0.20923174917697906
Epoch:  460  	Training Loss: 0.21377170085906982
Test Loss:  0.23203355073928833
Valid Loss:  0.20875577628612518
Epoch:  461  	Training Loss: 0.2133898288011551
Test Loss:  0.23154202103614807
Valid Loss:  0.20828108489513397
Epoch:  462  	Training Loss: 0.21300888061523438
Test Loss:  0.23105116188526154
Valid Loss:  0.20780716836452484
Epoch:  463  	Training Loss: 0.2126285433769226
Test Loss:  0.2305615246295929
Valid Loss:  0.207334503531456
Epoch:  464  	Training Loss: 0.21224911510944366
Test Loss:  0.23007309436798096
Valid Loss:  0.20686307549476624
Epoch:  465  	Training Loss: 0.21187059581279755
Test Loss:  0.22958585619926453
Valid Loss:  0.20639288425445557
Epoch:  466  	Training Loss: 0.21149300038814545
Test Loss:  0.22909978032112122
Valid Loss:  0.20592394471168518
Epoch:  467  	Training Loss: 0.21111631393432617
Test Loss:  0.2286149114370346
Valid Loss:  0.2054562270641327
Epoch:  468  	Training Loss: 0.21074050664901733
Test Loss:  0.2281312346458435
Valid Loss:  0.2049897462129593
Epoch:  469  	Training Loss: 0.21036562323570251
Test Loss:  0.22764873504638672
Valid Loss:  0.20452453196048737
Epoch:  470  	Training Loss: 0.2099916636943817
Test Loss:  0.22716742753982544
Valid Loss:  0.20406052470207214
Epoch:  471  	Training Loss: 0.20961859822273254
Test Loss:  0.22668729722499847
Valid Loss:  0.203597754240036
Epoch:  472  	Training Loss: 0.209246426820755
Test Loss:  0.22620819509029388
Valid Loss:  0.20313604176044464
Epoch:  473  	Training Loss: 0.20887497067451477
Test Loss:  0.22573022544384003
Valid Loss:  0.20267555117607117
Epoch:  474  	Training Loss: 0.20850442349910736
Test Loss:  0.22525349259376526
Valid Loss:  0.20221629738807678
Epoch:  475  	Training Loss: 0.20813477039337158
Test Loss:  0.22477787733078003
Valid Loss:  0.2017582505941391
Epoch:  476  	Training Loss: 0.20776599645614624
Test Loss:  0.2243034541606903
Valid Loss:  0.2013014405965805
Epoch:  477  	Training Loss: 0.20739814639091492
Test Loss:  0.2238301932811737
Valid Loss:  0.20084580779075623
Epoch:  478  	Training Loss: 0.20703116059303284
Test Loss:  0.22335807979106903
Valid Loss:  0.20039138197898865
Epoch:  479  	Training Loss: 0.2066650688648224
Test Loss:  0.22288715839385986
Valid Loss:  0.19993820786476135
Epoch:  480  	Training Loss: 0.20629985630512238
Test Loss:  0.22241736948490143
Valid Loss:  0.19948619604110718
Epoch:  481  	Training Loss: 0.205935537815094
Test Loss:  0.22194871306419373
Valid Loss:  0.1990353763103485
Epoch:  482  	Training Loss: 0.20557209849357605
Test Loss:  0.2214812934398651
Valid Loss:  0.19858583807945251
Epoch:  483  	Training Loss: 0.20520947873592377
Test Loss:  0.22101500630378723
Valid Loss:  0.19813747704029083
Epoch:  484  	Training Loss: 0.20484772324562073
Test Loss:  0.22054989635944366
Valid Loss:  0.19769032299518585
Epoch:  485  	Training Loss: 0.2044868767261505
Test Loss:  0.22008588910102844
Valid Loss:  0.19724436104297638
Epoch:  486  	Training Loss: 0.20412687957286835
Test Loss:  0.21962307393550873
Valid Loss:  0.19679959118366241
Epoch:  487  	Training Loss: 0.2037677764892578
Test Loss:  0.21916137635707855
Valid Loss:  0.19635599851608276
Epoch:  488  	Training Loss: 0.20340953767299652
Test Loss:  0.21870079636573792
Valid Loss:  0.19591356813907623
Epoch:  489  	Training Loss: 0.20305216312408447
Test Loss:  0.2182413935661316
Valid Loss:  0.1954723596572876
Epoch:  490  	Training Loss: 0.20269568264484406
Test Loss:  0.217783123254776
Valid Loss:  0.1950322985649109
Epoch:  491  	Training Loss: 0.2023400366306305
Test Loss:  0.21732595562934875
Valid Loss:  0.1945934295654297
Epoch:  492  	Training Loss: 0.20198525488376617
Test Loss:  0.21687069535255432
Valid Loss:  0.1941564381122589
Epoch:  493  	Training Loss: 0.2016320824623108
Test Loss:  0.21641656756401062
Valid Loss:  0.19372063875198364
Epoch:  494  	Training Loss: 0.20127978920936584
Test Loss:  0.21596358716487885
Valid Loss:  0.1932860016822815
Epoch:  495  	Training Loss: 0.20092834532260895
Test Loss:  0.21551167964935303
Valid Loss:  0.19285252690315247
Epoch:  496  	Training Loss: 0.2005777508020401
Test Loss:  0.21506094932556152
Valid Loss:  0.19242021441459656
Epoch:  497  	Training Loss: 0.2002280205488205
Test Loss:  0.21461127698421478
Valid Loss:  0.19198904931545258
Epoch:  498  	Training Loss: 0.19987913966178894
Test Loss:  0.21416272222995758
Valid Loss:  0.19155903160572052
Epoch:  499  	Training Loss: 0.19953107833862305
Test Loss:  0.21371528506278992
Valid Loss:  0.1911301463842392
Epoch:  500  	Training Loss: 0.1991838812828064
Test Loss:  0.2132689356803894
Valid Loss:  0.1907024085521698
seed is  17
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:21,  6.30s/it]  1%|          | 3/500 [00:06<13:58,  1.69s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:36,  1.20s/it]  5%|▍         | 23/500 [00:20<06:49,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:20,  1.19s/it]  7%|▋         | 33/500 [00:27<06:40,  1.17it/s]  7%|▋         | 35/500 [00:27<04:47,  1.62it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<08:59,  1.17s/it]  9%|▊         | 43/500 [00:33<06:25,  1.19it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:34<03:21,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:47,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:41<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:47<08:41,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.22it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.99it/s]Epoch:  1  	Training Loss: 0.10601764172315598
Test Loss:  0.016017982736229897
Valid Loss:  0.022911403328180313
Epoch:  2  	Training Loss: 0.0259323138743639
Test Loss:  0.016130687668919563
Valid Loss:  0.019950520247220993
Epoch:  3  	Training Loss: 0.01991133764386177
Test Loss:  0.011258370243012905
Valid Loss:  0.014146619476377964
Epoch:  4  	Training Loss: 0.0156862773001194
Test Loss:  0.009297091513872147
Valid Loss:  0.011035719886422157
Epoch:  5  	Training Loss: 0.012512411922216415
Test Loss:  0.007313666399568319
Valid Loss:  0.008405215106904507
Epoch:  6  	Training Loss: 0.010101720690727234
Test Loss:  0.005993874743580818
Valid Loss:  0.006571576930582523
Epoch:  7  	Training Loss: 0.008267313241958618
Test Loss:  0.004958773963153362
Valid Loss:  0.005205859430134296
Epoch:  8  	Training Loss: 0.006871142890304327
Test Loss:  0.004206150770187378
Valid Loss:  0.004226158373057842
Epoch:  9  	Training Loss: 0.0058084819465875626
Test Loss:  0.00364437373355031
Valid Loss:  0.0035230256617069244
Epoch:  10  	Training Loss: 0.004999690689146519
Test Loss:  0.003232738468796015
Valid Loss:  0.0030277047771960497
Epoch:  11  	Training Loss: 0.004384133033454418
Test Loss:  0.002931324765086174
Valid Loss:  0.0026847112458199263
Epoch:  12  	Training Loss: 0.003915651235729456
Test Loss:  0.002713557332754135
Valid Loss:  0.00245375232771039
Epoch:  13  	Training Loss: 0.003559329779818654
Test Loss:  0.0025565712712705135
Valid Loss:  0.0023037861101329327
Epoch:  14  	Training Loss: 0.0032881186343729496
Test Loss:  0.002445533871650696
Valid Loss:  0.0022123302333056927
Epoch:  15  	Training Loss: 0.003081686794757843
Test Loss:  0.002368122572079301
Valid Loss:  0.0021624744404107332
Epoch:  16  	Training Loss: 0.002924557775259018
Test Loss:  0.002315488178282976
Valid Loss:  0.002141769276931882
Epoch:  17  	Training Loss: 0.0028049536049365997
Test Loss:  0.0022808786015957594
Valid Loss:  0.0021410537883639336
Epoch:  18  	Training Loss: 0.002713915426284075
Test Loss:  0.002259304281324148
Valid Loss:  0.0021536285057663918
Epoch:  19  	Training Loss: 0.002644615713506937
Test Loss:  0.002247045747935772
Valid Loss:  0.002174654509872198
Epoch:  20  	Training Loss: 0.002591867232695222
Test Loss:  0.0022413393016904593
Valid Loss:  0.002200647024437785
Epoch:  21  	Training Loss: 0.0025517132598906755
Test Loss:  0.0022401628084480762
Valid Loss:  0.0022291485220193863
Epoch:  22  	Training Loss: 0.0025213779881596565
Test Loss:  0.002236797474324703
Valid Loss:  0.0022596116177737713
Epoch:  23  	Training Loss: 0.0024989042431116104
Test Loss:  0.002227941295132041
Valid Loss:  0.002291153883561492
Epoch:  24  	Training Loss: 0.0024823094718158245
Test Loss:  0.0022467798553407192
Valid Loss:  0.0023130737245082855
Epoch:  25  	Training Loss: 0.0024696686305105686
Test Loss:  0.0022296872921288013
Valid Loss:  0.0023455233313143253
Epoch:  26  	Training Loss: 0.0024596955627202988
Test Loss:  0.00226051127538085
Valid Loss:  0.0023586004972457886
Epoch:  27  	Training Loss: 0.0024517448619008064
Test Loss:  0.002244769362732768
Valid Loss:  0.0023882160894572735
Epoch:  28  	Training Loss: 0.002445763908326626
Test Loss:  0.0022744163870811462
Valid Loss:  0.00239780405536294
Epoch:  29  	Training Loss: 0.0024409559555351734
Test Loss:  0.002259027911350131
Valid Loss:  0.0024245018139481544
Epoch:  30  	Training Loss: 0.002437231596559286
Test Loss:  0.002283139154314995
Valid Loss:  0.0024321407545357943
Epoch:  31  	Training Loss: 0.0024342802353203297
Test Loss:  0.0022772294469177723
Valid Loss:  0.002452109009027481
Epoch:  32  	Training Loss: 0.00243199709802866
Test Loss:  0.0022849650122225285
Valid Loss:  0.0024633374996483326
Epoch:  33  	Training Loss: 0.0024302364327013493
Test Loss:  0.0022875540889799595
Valid Loss:  0.0024756419006735086
Epoch:  34  	Training Loss: 0.002428849693387747
Test Loss:  0.00229138252325356
Valid Loss:  0.0024857637472450733
Epoch:  35  	Training Loss: 0.0024277702905237675
Test Loss:  0.002298325300216675
Valid Loss:  0.0024935982655733824
Epoch:  36  	Training Loss: 0.0024269295390695333
Test Loss:  0.002299594460055232
Valid Loss:  0.0025031547993421555
Epoch:  37  	Training Loss: 0.002426283899694681
Test Loss:  0.002302765380591154
Valid Loss:  0.002510457532480359
Epoch:  38  	Training Loss: 0.002425780054181814
Test Loss:  0.002304885070770979
Valid Loss:  0.002517287153750658
Epoch:  39  	Training Loss: 0.0024253816809505224
Test Loss:  0.0023070024326443672
Valid Loss:  0.0025231633335351944
Epoch:  40  	Training Loss: 0.002425064332783222
Test Loss:  0.002308792434632778
Valid Loss:  0.002528373384848237
Epoch:  41  	Training Loss: 0.0024248126428574324
Test Loss:  0.0023108082823455334
Valid Loss:  0.002532786224037409
Epoch:  42  	Training Loss: 0.0024246054235845804
Test Loss:  0.00231169699691236
Valid Loss:  0.002537087071686983
Epoch:  43  	Training Loss: 0.0024244363885372877
Test Loss:  0.002313115168362856
Valid Loss:  0.0025404836051166058
Epoch:  44  	Training Loss: 0.0024242957588285208
Test Loss:  0.002314541023224592
Valid Loss:  0.00254344055429101
Epoch:  45  	Training Loss: 0.0024241756182163954
Test Loss:  0.002315008081495762
Valid Loss:  0.0025464121717959642
Epoch:  46  	Training Loss: 0.0024240727070719004
Test Loss:  0.0023164069280028343
Valid Loss:  0.0025485067162662745
Epoch:  47  	Training Loss: 0.0024239816702902317
Test Loss:  0.002316574100404978
Valid Loss:  0.0025508892722427845
Epoch:  48  	Training Loss: 0.002423907397314906
Test Loss:  0.0023216947447508574
Valid Loss:  0.002550968434661627
Epoch:  49  	Training Loss: 0.002423882717266679
Test Loss:  0.002316792495548725
Valid Loss:  0.0025557270273566246
Epoch:  50  	Training Loss: 0.0024238466285169125
Test Loss:  0.002323398133739829
Valid Loss:  0.002554262289777398
Epoch:  51  	Training Loss: 0.0024237995967268944
Test Loss:  0.002318163402378559
Valid Loss:  0.0025587850250303745
Epoch:  52  	Training Loss: 0.0024238002952188253
Test Loss:  0.0023243194445967674
Valid Loss:  0.002557092811912298
Epoch:  53  	Training Loss: 0.0024237679317593575
Test Loss:  0.0023225261829793453
Valid Loss:  0.002559905406087637
Epoch:  54  	Training Loss: 0.0024237497709691525
Test Loss:  0.0023241660092025995
Valid Loss:  0.0025605009868741035
Epoch:  55  	Training Loss: 0.0024237362667918205
Test Loss:  0.0023241739254444838
Valid Loss:  0.0025618947111070156
Epoch:  56  	Training Loss: 0.002423727884888649
Test Loss:  0.002324675675481558
Valid Loss:  0.002562812063843012
Epoch:  57  	Training Loss: 0.0024237206671386957
Test Loss:  0.002324942499399185
Valid Loss:  0.0025637138169258833
Epoch:  58  	Training Loss: 0.002423715777695179
Test Loss:  0.0023252349346876144
Valid Loss:  0.0025644670240581036
Epoch:  59  	Training Loss: 0.002423711586743593
Test Loss:  0.002325469395145774
Valid Loss:  0.0025651375763118267
Epoch:  60  	Training Loss: 0.0024237087927758694
Test Loss:  0.0023256822023540735
Valid Loss:  0.0025657189544290304
Epoch:  61  	Training Loss: 0.0024237078614532948
Test Loss:  0.0023220283910632133
Valid Loss:  0.002567681483924389
Epoch:  62  	Training Loss: 0.0024237199686467648
Test Loss:  0.0023270249366760254
Valid Loss:  0.002565239556133747
Epoch:  63  	Training Loss: 0.002423709724098444
Test Loss:  0.0023251287639141083
Valid Loss:  0.002566894283518195
Epoch:  64  	Training Loss: 0.0024237046018242836
Test Loss:  0.002326357178390026
Valid Loss:  0.0025666500441730022
Epoch:  65  	Training Loss: 0.0024237018078565598
Test Loss:  0.0023261141031980515
Valid Loss:  0.0025672491174191236
Epoch:  66  	Training Loss: 0.0024236999452114105
Test Loss:  0.0023263623006641865
Valid Loss:  0.002567489165812731
Epoch:  67  	Training Loss: 0.0024236999452114105
Test Loss:  0.002326419111341238
Valid Loss:  0.0025677955709397793
Epoch:  68  	Training Loss: 0.002423699479550123
Test Loss:  0.002326524117961526
Valid Loss:  0.0025680335238575935
Epoch:  69  	Training Loss: 0.002423699013888836
Test Loss:  0.0023265930358320475
Valid Loss:  0.0025682495906949043
Epoch:  70  	Training Loss: 0.002423699712380767
Test Loss:  0.0023266649805009365
Valid Loss:   14%|█▍        | 71/500 [01:00<15:06,  2.11s/it] 15%|█▍        | 73/500 [01:00<10:40,  1.50s/it] 15%|█▌        | 75/500 [01:00<07:34,  1.07s/it] 15%|█▌        | 77/500 [01:00<05:26,  1.30it/s] 16%|█▌        | 79/500 [01:01<03:58,  1.77it/s] 16%|█▌        | 81/500 [01:13<15:57,  2.28s/it] 17%|█▋        | 83/500 [01:13<11:15,  1.62s/it] 17%|█▋        | 85/500 [01:20<14:31,  2.10s/it] 17%|█▋        | 87/500 [01:20<10:16,  1.49s/it] 18%|█▊        | 89/500 [01:20<07:17,  1.06s/it] 18%|█▊        | 91/500 [01:26<11:28,  1.68s/it] 19%|█▊        | 93/500 [01:26<08:08,  1.20s/it] 19%|█▉        | 95/500 [01:33<12:11,  1.81s/it] 19%|█▉        | 97/500 [01:33<08:38,  1.29s/it] 20%|█▉        | 99/500 [01:33<06:08,  1.09it/s] 20%|██        | 101/500 [01:39<10:31,  1.58s/it] 21%|██        | 103/500 [01:40<07:27,  1.13s/it] 21%|██        | 105/500 [01:46<11:23,  1.73s/it] 21%|██▏       | 107/500 [01:46<08:04,  1.23s/it] 22%|██▏       | 109/500 [01:46<05:44,  1.13it/s] 22%|██▏       | 111/500 [01:59<16:06,  2.49s/it] 23%|██▎       | 113/500 [01:59<11:21,  1.76s/it] 23%|██▎       | 115/500 [02:05<13:53,  2.16s/it] 23%|██▎       | 117/500 [02:05<09:48,  1.54s/it] 24%|██▍       | 119/500 [02:05<06:57,  1.10s/it] 24%|██▍       | 121/500 [02:18<16:37,  2.63s/it] 25%|██▍       | 123/500 [02:18<11:44,  1.87s/it] 25%|██▌       | 125/500 [02:24<14:02,  2.25s/it] 25%|██▌       | 127/500 [02:24<09:55,  1.60s/it] 26%|██▌       | 129/500 [02:24<07:01,  1.14s/it]0.0025684344582259655
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.0024236987810581923
Test Loss:  0.002326695015653968
Valid Loss:  0.002568512689322233
Epoch:  72  	Training Loss: 0.002423699013888836
Test Loss:  0.0023267194628715515
Valid Loss:  0.002568589523434639
Epoch:  73  	Training Loss: 0.0024236980825662613
Test Loss:  0.0023267455399036407
Valid Loss:  0.0025686637964099646
Epoch:  74  	Training Loss: 0.002423699013888836
Test Loss:  0.0023267725482583046
Valid Loss:  0.002568730153143406
Epoch:  75  	Training Loss: 0.0024236978497356176
Test Loss:  0.0023267946671694517
Valid Loss:  0.002568792784586549
Epoch:  76  	Training Loss: 0.002423697616904974
Test Loss:  0.0023268149234354496
Valid Loss:  0.002568848431110382
Epoch:  77  	Training Loss: 0.0024236980825662613
Test Loss:  0.002326833549886942
Valid Loss:  0.002568902913480997
Epoch:  78  	Training Loss: 0.0024236973840743303
Test Loss:  0.0023268512450158596
Valid Loss:  0.0025689578615128994
Epoch:  79  	Training Loss: 0.002423696918413043
Test Loss:  0.00232686847448349
Valid Loss:  0.0025690034963190556
Epoch:  80  	Training Loss: 0.002423697616904974
Test Loss:  0.0023268871009349823
Valid Loss:  0.002569049596786499
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.0024236973840743303
Test Loss:  0.0023268945515155792
Valid Loss:  0.002569071715697646
Epoch:  82  	Training Loss: 0.002423697616904974
Test Loss:  0.0023269029334187508
Valid Loss:  0.002569093368947506
Epoch:  83  	Training Loss: 0.002423697616904974
Test Loss:  0.002326907590031624
Valid Loss:  0.0025691082701087
Epoch:  84  	Training Loss: 0.0024236964527517557
Test Loss:  0.002326915506273508
Valid Loss:  0.0025691301561892033
Epoch:  85  	Training Loss: 0.0024236966855823994
Test Loss:  0.0023269220255315304
Valid Loss:  0.0025691462215036154
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.002423697616904974
Test Loss:  0.002326925750821829
Valid Loss:  0.0025691536720842123
Epoch:  87  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269285447895527
Valid Loss:  0.002569162053987384
Epoch:  88  	Training Loss: 0.002423697616904974
Test Loss:  0.002326932270079851
Valid Loss:  0.0025691702030599117
Epoch:  89  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269348312169313
Valid Loss:  0.0025691823102533817
Epoch:  90  	Training Loss: 0.0024236966855823994
Test Loss:  0.002326936461031437
Valid Loss:  0.002569191623479128
Epoch:  91  	Training Loss: 0.002423697616904974
Test Loss:  0.0023269406519830227
Valid Loss:  0.002569199074059725
Epoch:  92  	Training Loss: 0.0024236973840743303
Test Loss:  0.002326945075765252
Valid Loss:  0.0025692088529467583
Epoch:  93  	Training Loss: 0.0024236966855823994
Test Loss:  0.002326948568224907
Valid Loss:  0.0025692167691886425
Epoch:  94  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326949965208769
Valid Loss:  0.00256922235712409
Epoch:  95  	Training Loss: 0.002423697616904974
Test Loss:  0.0023269534576684237
Valid Loss:  0.002569228643551469
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.0024236973840743303
Test Loss:  0.002326951129361987
Valid Loss:  0.0025692335329949856
Epoch:  97  	Training Loss: 0.0024236964527517557
Test Loss:  0.0023269550874829292
Valid Loss:  0.002569238655269146
Epoch:  98  	Training Loss: 0.0024236973840743303
Test Loss:  0.0023269548546522856
Valid Loss:  0.0025692409835755825
Epoch:  99  	Training Loss: 0.002423696918413043
Test Loss:  0.002326959278434515
Valid Loss:  0.0025692451745271683
Epoch:  100  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269597440958023
Valid Loss:  0.0025692488998174667
Epoch:  101  	Training Loss: 0.0024236980825662613
Test Loss:  0.002326961373910308
Valid Loss:  0.0025692549534142017
Epoch:  102  	Training Loss: 0.0024236966855823994
Test Loss:  0.0023269611410796642
Valid Loss:  0.0025692563503980637
Epoch:  103  	Training Loss: 0.002423696219921112
Test Loss:  0.002326963935047388
Valid Loss:  0.002569260774180293
Epoch:  104  	Training Loss: 0.0024236964527517557
Test Loss:  0.002326963935047388
Valid Loss:  0.002569262869656086
Epoch:  105  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326966030523181
Valid Loss:  0.002569265430793166
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326968125998974
Valid Loss:  0.0025692665949463844
Epoch:  107  	Training Loss: 0.0024236973840743303
Test Loss:  0.0023269669618457556
Valid Loss:  0.0025692684575915337
Epoch:  108  	Training Loss: 0.002423697616904974
Test Loss:  0.0023269676603376865
Valid Loss:  0.0025692726485431194
Epoch:  109  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269704543054104
Valid Loss:  0.0025692719500511885
Epoch:  110  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326968591660261
Valid Loss:  0.002569275675341487
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326968824490905
Valid Loss:  0.002569278236478567
Epoch:  112  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269709199666977
Valid Loss:  0.0025692773051559925
Epoch:  113  	Training Loss: 0.0024236973840743303
Test Loss:  0.0023269695229828358
Valid Loss:  0.0025692814961075783
Epoch:  114  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269683588296175
Valid Loss:  0.0025692780036479235
Epoch:  115  	Training Loss: 0.0024236966855823994
Test Loss:  0.0023269690573215485
Valid Loss:  0.0025692794006317854
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0024236966855823994
Test Loss:  0.0023269711527973413
Valid Loss:  0.0025692787021398544
Epoch:  117  	Training Loss: 0.0024236964527517557
Test Loss:  0.0023269709199666977
Valid Loss:  0.002569279633462429
Epoch:  118  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269695229828358
Valid Loss:  0.0025692821945995092
Epoch:  119  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269718512892723
Valid Loss:  0.0025692812632769346
Epoch:  120  	Training Loss: 0.0024236978497356176
Test Loss:  0.0023269711527973413
Valid Loss:  0.00256928289309144
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0024236978497356176
Test Loss:  0.002326971385627985
Valid Loss:  0.0025692833587527275
Epoch:  122  	Training Loss: 0.0024236978497356176
Test Loss:  0.0023269716184586287
Valid Loss:  0.002569283824414015
Epoch:  123  	Training Loss: 0.0024236980825662613
Test Loss:  0.0023269718512892723
Valid Loss:  0.0025692821945995092
Epoch:  124  	Training Loss: 0.002423697616904974
Test Loss:  0.002326972782611847
Valid Loss:  0.0025692814961075783
Epoch:  125  	Training Loss: 0.002423697616904974
Test Loss:  0.0023269725497812033
Valid Loss:  0.0025692800991237164
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269723169505596
Valid Loss:  0.0025692805647850037
Epoch:  127  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269723169505596
Valid Loss:  0.0025692805647850037
Epoch:  128  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269723169505596
Valid Loss:  0.0025692798662930727
Epoch:  129  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  130  	Training Loss: 0.0024236966855823994
Test Loss:  0.002326973481103778
Valid Loss:   26%|██▌       | 131/500 [02:37<16:23,  2.67s/it] 27%|██▋       | 133/500 [02:37<11:32,  1.89s/it] 27%|██▋       | 135/500 [02:43<13:45,  2.26s/it] 27%|██▋       | 137/500 [02:43<09:42,  1.60s/it] 28%|██▊       | 139/500 [02:43<06:52,  1.14s/it] 28%|██▊       | 141/500 [02:56<15:51,  2.65s/it] 29%|██▊       | 143/500 [02:56<11:09,  1.88s/it] 29%|██▉       | 145/500 [03:02<13:23,  2.26s/it] 29%|██▉       | 147/500 [03:02<09:26,  1.61s/it] 30%|██▉       | 149/500 [03:03<06:41,  1.14s/it] 30%|███       | 151/500 [03:15<15:30,  2.67s/it] 31%|███       | 153/500 [03:15<10:54,  1.89s/it] 31%|███       | 155/500 [03:21<13:03,  2.27s/it] 31%|███▏      | 157/500 [03:22<09:12,  1.61s/it] 32%|███▏      | 159/500 [03:22<06:31,  1.15s/it] 32%|███▏      | 161/500 [03:34<15:09,  2.68s/it] 33%|███▎      | 163/500 [03:34<10:40,  1.90s/it] 33%|███▎      | 165/500 [03:41<12:38,  2.26s/it] 33%|███▎      | 167/500 [03:41<08:55,  1.61s/it] 34%|███▍      | 169/500 [03:41<06:18,  1.14s/it] 34%|███▍      | 171/500 [03:53<14:37,  2.67s/it] 35%|███▍      | 173/500 [03:53<10:17,  1.89s/it] 35%|███▌      | 175/500 [04:00<12:17,  2.27s/it] 35%|███▌      | 177/500 [04:00<08:39,  1.61s/it] 36%|███▌      | 179/500 [04:00<06:08,  1.15s/it] 36%|███▌      | 179/500 [04:11<06:08,  1.15s/it] 36%|███▌      | 181/500 [04:13<14:10,  2.67s/it] 37%|███▋      | 183/500 [04:13<09:58,  1.89s/it] 37%|███▋      | 185/500 [04:13<07:02,  1.34s/it] 37%|███▋      | 187/500 [04:13<05:00,  1.04it/s]0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973481103778
Valid Loss:  0.0025692805647850037
Epoch:  132  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269732482731342
Valid Loss:  0.0025692800991237164
Epoch:  133  	Training Loss: 0.0024236966855823994
Test Loss:  0.0023269732482731342
Valid Loss:  0.00256928033195436
Epoch:  134  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269730154424906
Valid Loss:  0.0025692800991237164
Epoch:  135  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692800991237164
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692798662930727
Epoch:  137  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692798662930727
Epoch:  138  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973481103778
Valid Loss:  0.0025692798662930727
Epoch:  139  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973481103778
Valid Loss:  0.002569279633462429
Epoch:  140  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.002569279633462429
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.002569279633462429
Epoch:  142  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.002569279633462429
Epoch:  143  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.002569279633462429
Epoch:  144  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  145  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.00256928033195436
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  147  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  148  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.00256928033195436
Epoch:  149  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  150  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  152  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  153  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  154  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  155  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  157  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  158  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  159  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  160  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  162  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  163  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  164  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  165  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  167  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  168  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  169  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  170  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  172  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  173  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  174  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  175  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  177  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
Epoch:  178  	Training Loss: 0.002423696918413043
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  179  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  180  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  182  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  183  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  184  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  185  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  186  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  187  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
 38%|███▊      | 189/500 [04:13<03:34,  1.45it/s] 38%|███▊      | 191/500 [04:26<12:22,  2.40s/it] 39%|███▊      | 193/500 [04:26<08:42,  1.70s/it] 39%|███▉      | 195/500 [04:32<10:52,  2.14s/it] 39%|███▉      | 197/500 [04:32<07:40,  1.52s/it] 40%|███▉      | 199/500 [04:33<05:26,  1.08s/it] 40%|████      | 201/500 [04:45<13:01,  2.61s/it] 41%|████      | 203/500 [04:45<09:09,  1.85s/it] 41%|████      | 205/500 [04:51<10:58,  2.23s/it] 41%|████▏     | 207/500 [04:51<07:44,  1.58s/it] 42%|████▏     | 209/500 [04:52<05:28,  1.13s/it] 42%|████▏     | 211/500 [05:04<12:50,  2.67s/it] 43%|████▎     | 213/500 [05:04<09:01,  1.89s/it] 43%|████▎     | 215/500 [05:10<10:43,  2.26s/it] 43%|████▎     | 217/500 [05:11<07:32,  1.60s/it] 44%|████▍     | 219/500 [05:11<05:20,  1.14s/it] 44%|████▍     | 221/500 [05:23<12:22,  2.66s/it] 45%|████▍     | 223/500 [05:23<08:41,  1.88s/it] 45%|████▌     | 225/500 [05:30<10:20,  2.26s/it] 45%|████▌     | 227/500 [05:30<07:17,  1.60s/it] 46%|████▌     | 229/500 [05:30<05:09,  1.14s/it] 46%|████▌     | 229/500 [05:41<05:09,  1.14s/it] 46%|████▌     | 231/500 [05:42<11:58,  2.67s/it] 47%|████▋     | 233/500 [05:42<08:24,  1.89s/it] 47%|████▋     | 235/500 [05:49<09:58,  2.26s/it] 47%|████▋     | 237/500 [05:49<07:01,  1.60s/it] 48%|████▊     | 239/500 [05:49<04:57,  1.14s/it] 48%|████▊     | 241/500 [05:55<07:30,  1.74s/it] 49%|████▊     | 243/500 [05:55<05:18,  1.24s/it]Epoch:  188  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  189  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  190  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  192  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  193  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  194  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  195  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  197  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  198  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  199  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  200  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  202  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  203  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  204  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
Epoch:  205  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  207  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  208  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  209  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  210  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  212  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  213  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
Epoch:  214  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  215  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  217  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  218  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  219  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  220  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  222  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  223  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  224  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  225  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  227  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  228  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  229  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  230  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  232  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  233  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  234  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  235  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  237  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  238  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  239  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  240  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  241  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  242  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  243  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
Epoch:  244  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  245  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
 49%|████▉     | 245/500 [06:02<07:39,  1.80s/it] 49%|████▉     | 247/500 [06:02<05:24,  1.28s/it] 50%|████▉     | 249/500 [06:02<03:51,  1.08it/s] 50%|█████     | 250/500 [06:08<07:44,  1.86s/it] 50%|█████     | 251/500 [06:14<11:20,  2.73s/it] 51%|█████     | 253/500 [06:15<07:15,  1.76s/it] 51%|█████     | 255/500 [06:21<09:07,  2.23s/it] 51%|█████▏    | 257/500 [06:21<06:10,  1.52s/it] 52%|█████▏    | 259/500 [06:21<04:14,  1.06s/it] 52%|█████▏    | 261/500 [06:33<10:38,  2.67s/it] 53%|█████▎    | 263/500 [06:34<07:22,  1.87s/it] 53%|█████▎    | 265/500 [06:40<08:52,  2.27s/it] 53%|█████▎    | 267/500 [06:40<06:12,  1.60s/it] 54%|█████▍    | 269/500 [06:40<04:21,  1.13s/it] 54%|█████▍    | 269/500 [06:51<04:21,  1.13s/it] 54%|█████▍    | 271/500 [06:53<10:15,  2.69s/it] 55%|█████▍    | 273/500 [06:53<07:11,  1.90s/it] 55%|█████▌    | 275/500 [06:59<08:32,  2.28s/it] 55%|█████▌    | 277/500 [06:59<06:00,  1.62s/it] 56%|█████▌    | 279/500 [07:00<04:14,  1.15s/it] 56%|█████▌    | 279/500 [07:11<04:14,  1.15s/it] 56%|█████▌    | 281/500 [07:12<09:44,  2.67s/it] 57%|█████▋    | 283/500 [07:12<06:50,  1.89s/it] 57%|█████▋    | 285/500 [07:19<08:12,  2.29s/it] 57%|█████▋    | 287/500 [07:19<05:46,  1.63s/it] 58%|█████▊    | 289/500 [07:19<04:04,  1.16s/it] 58%|█████▊    | 289/500 [07:31<04:04,  1.16s/it] 58%|█████▊    | 291/500 [07:32<09:27,  2.72s/it] 59%|█████▊    | 293/500 [07:32<06:37,  1.92s/it] 59%|█████▉    | 295/500 [07:38<07:52,  2.31s/it] 59%|█████▉    | 297/500 [07:38<05:31,  1.64s/it] 60%|█████▉    | 299/500 [07:38<03:54,  1.16s/it] 60%|█████▉    | 299/500 [07:51<03:54,  1.16s/it] 60%|██████    | 301/500 [07:51<08:52,  2.67s/it]**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  247  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  248  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  249  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  250  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  252  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  253  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  254  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  255  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  257  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  258  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  259  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  260  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  262  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  263  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  264  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  265  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  267  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  268  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  269  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
Epoch:  270  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  272  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  273  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  274  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  275  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  277  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  278  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  279  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  280  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  282  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  283  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  284  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  285  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  287  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  288  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  289  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  290  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  292  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  293  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  294  	Training Loss: 0.002423696918413043
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  295  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  297  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  298  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  299  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  300  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
 61%|██████    | 303/500 [07:51<06:12,  1.89s/it] 61%|██████    | 305/500 [07:57<07:22,  2.27s/it] 61%|██████▏   | 307/500 [07:57<05:10,  1.61s/it] 62%|██████▏   | 309/500 [07:57<03:39,  1.15s/it] 62%|██████▏   | 311/500 [08:10<08:27,  2.69s/it] 63%|██████▎   | 313/500 [08:10<05:55,  1.90s/it] 63%|██████▎   | 315/500 [08:16<06:59,  2.27s/it] 63%|██████▎   | 317/500 [08:17<04:54,  1.61s/it] 64%|██████▍   | 319/500 [08:17<03:27,  1.15s/it] 64%|██████▍   | 321/500 [08:29<08:01,  2.69s/it] 65%|██████▍   | 323/500 [08:29<05:37,  1.91s/it] 65%|██████▌   | 325/500 [08:36<06:39,  2.28s/it] 65%|██████▌   | 327/500 [08:36<04:40,  1.62s/it] 66%|██████▌   | 329/500 [08:36<03:17,  1.15s/it] 66%|██████▌   | 331/500 [08:49<07:32,  2.68s/it] 67%|██████▋   | 333/500 [08:49<05:16,  1.90s/it] 67%|██████▋   | 335/500 [08:55<06:13,  2.27s/it] 67%|██████▋   | 337/500 [08:55<04:21,  1.61s/it] 68%|██████▊   | 339/500 [08:55<03:04,  1.14s/it] 68%|██████▊   | 341/500 [09:08<07:05,  2.68s/it] 69%|██████▊   | 343/500 [09:08<04:57,  1.90s/it] 69%|██████▉   | 345/500 [09:14<05:54,  2.29s/it] 69%|██████▉   | 347/500 [09:14<04:07,  1.62s/it] 70%|██████▉   | 349/500 [09:14<02:54,  1.15s/it] 70%|███████   | 351/500 [09:27<06:37,  2.67s/it] 71%|███████   | 353/500 [09:27<04:38,  1.89s/it] 71%|███████   | 355/500 [09:33<05:28,  2.26s/it] 71%|███████▏  | 357/500 [09:33<03:49,  1.61s/it]Epoch:  302  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  303  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  304  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  305  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  307  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  308  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  309  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  310  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  312  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  313  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  314  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  315  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  317  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  318  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
Epoch:  319  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  320  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  322  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  323  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  324  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  325  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  327  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  328  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  329  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  330  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  332  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  333  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  334  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  335  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  337  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  338  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  339  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  340  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  342  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  343  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  344  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  345  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  347  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  348  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  349  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  350  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  352  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  353  	Training Loss: 0.002423696918413043
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  354  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  355  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  357  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  358  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  359  	Training Loss: 0.0024236971512436867
 72%|███████▏  | 359/500 [09:34<02:41,  1.14s/it] 72%|███████▏  | 361/500 [09:46<06:14,  2.69s/it] 73%|███████▎  | 363/500 [09:46<04:21,  1.91s/it] 73%|███████▎  | 365/500 [09:53<05:07,  2.28s/it] 73%|███████▎  | 367/500 [09:53<03:35,  1.62s/it] 74%|███████▍  | 369/500 [09:53<02:30,  1.15s/it] 74%|███████▍  | 371/500 [10:05<05:44,  2.67s/it] 75%|███████▍  | 373/500 [10:06<04:00,  1.90s/it] 75%|███████▌  | 375/500 [10:12<04:43,  2.26s/it] 75%|███████▌  | 377/500 [10:12<03:17,  1.61s/it] 76%|███████▌  | 379/500 [10:12<02:18,  1.14s/it] 76%|███████▌  | 381/500 [10:24<05:17,  2.67s/it] 77%|███████▋  | 383/500 [10:25<03:40,  1.89s/it] 77%|███████▋  | 385/500 [10:31<04:19,  2.26s/it] 77%|███████▋  | 387/500 [10:31<03:01,  1.60s/it] 78%|███████▊  | 389/500 [10:31<02:06,  1.14s/it] 78%|███████▊  | 391/500 [10:44<04:51,  2.68s/it] 79%|███████▊  | 393/500 [10:44<03:22,  1.89s/it] 79%|███████▉  | 395/500 [10:50<03:58,  2.27s/it] 79%|███████▉  | 397/500 [10:50<02:46,  1.61s/it] 80%|███████▉  | 399/500 [10:50<01:55,  1.15s/it] 80%|███████▉  | 399/500 [11:01<01:55,  1.15s/it] 80%|████████  | 401/500 [11:03<04:30,  2.73s/it] 81%|████████  | 403/500 [11:03<03:07,  1.93s/it] 81%|████████  | 405/500 [11:10<03:40,  2.32s/it] 81%|████████▏ | 407/500 [11:10<02:32,  1.64s/it] 82%|████████▏ | 409/500 [11:10<01:46,  1.17s/it] 82%|████████▏ | 409/500 [11:21<01:46,  1.17s/it] 82%|████████▏ | 411/500 [11:22<03:58,  2.68s/it] 83%|████████▎ | 413/500 [11:23<02:45,  1.90s/it]Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  360  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  362  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  363  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  364  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  365  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  367  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  368  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  369  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  370  	Training Loss: 0.002423696918413043
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  372  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  373  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  374  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  375  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  377  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  378  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  379  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  380  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  382  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  383  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  384  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  385  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  387  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  388  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  389  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  390  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  392  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
Epoch:  393  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  394  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  395  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  397  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  398  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  399  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  400  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  402  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  403  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  404  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  405  	Training Loss: 0.002423696918413043
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  407  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  408  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  409  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  410  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  412  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  413  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  414  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  415  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
 83%|████████▎ | 415/500 [11:29<03:13,  2.27s/it] 83%|████████▎ | 417/500 [11:29<02:13,  1.61s/it] 84%|████████▍ | 419/500 [11:29<01:33,  1.15s/it] 84%|████████▍ | 419/500 [11:41<01:33,  1.15s/it] 84%|████████▍ | 421/500 [11:42<03:36,  2.74s/it] 85%|████████▍ | 423/500 [11:42<02:29,  1.94s/it] 85%|████████▌ | 425/500 [11:49<02:53,  2.31s/it] 85%|████████▌ | 427/500 [11:49<01:59,  1.64s/it] 86%|████████▌ | 429/500 [11:49<01:23,  1.17s/it] 86%|████████▌ | 429/500 [12:01<01:23,  1.17s/it] 86%|████████▌ | 431/500 [12:02<03:07,  2.71s/it] 87%|████████▋ | 433/500 [12:02<02:08,  1.92s/it] 87%|████████▋ | 435/500 [12:08<02:28,  2.29s/it] 87%|████████▋ | 437/500 [12:08<01:42,  1.62s/it] 88%|████████▊ | 439/500 [12:08<01:10,  1.16s/it] 88%|████████▊ | 441/500 [12:21<02:38,  2.68s/it] 89%|████████▊ | 443/500 [12:21<01:48,  1.90s/it] 89%|████████▉ | 445/500 [12:27<02:05,  2.28s/it] 89%|████████▉ | 447/500 [12:27<01:25,  1.62s/it] 90%|████████▉ | 449/500 [12:27<00:58,  1.15s/it] 90%|█████████ | 451/500 [12:40<02:11,  2.69s/it] 91%|█████████ | 453/500 [12:40<01:29,  1.90s/it] 91%|█████████ | 455/500 [12:46<01:42,  2.28s/it] 91%|█████████▏| 457/500 [12:47<01:09,  1.62s/it] 92%|█████████▏| 459/500 [12:47<00:47,  1.15s/it] 92%|█████████▏| 461/500 [12:59<01:45,  2.71s/it] 93%|█████████▎| 463/500 [13:00<01:10,  1.92s/it] 93%|█████████▎| 465/500 [13:06<01:20,  2.30s/it] 93%|█████████▎| 467/500 [13:06<00:53,  1.63s/it] 94%|█████████▍| 469/500 [13:06<00:35,  1.16s/it] 94%|█████████▍| 471/500 [13:19<01:18,  2.70s/it]**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  417  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  418  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  419  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  420  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  422  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  423  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  424  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  425  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  427  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  428  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  429  	Training Loss: 0.002423696918413043
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  430  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  432  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  433  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  434  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  435  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  437  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  438  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  439  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  440  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  442  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  443  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  444  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  445  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  447  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692807976156473
Epoch:  448  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  449  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  450  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  452  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  453  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  454  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  455  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  457  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  458  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  459  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  460  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  462  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  463  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  464  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  465  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.00256928033195436
Epoch:  467  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  468  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  469  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  470  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
 95%|█████████▍| 473/500 [13:19<00:51,  1.91s/it] 95%|█████████▌| 475/500 [13:25<00:57,  2.28s/it] 95%|█████████▌| 477/500 [13:25<00:37,  1.62s/it] 96%|█████████▌| 479/500 [13:25<00:24,  1.15s/it] 96%|█████████▌| 481/500 [13:38<00:50,  2.66s/it] 97%|█████████▋| 483/500 [13:38<00:32,  1.88s/it] 97%|█████████▋| 485/500 [13:44<00:33,  2.25s/it] 97%|█████████▋| 487/500 [13:44<00:20,  1.60s/it] 98%|█████████▊| 489/500 [13:45<00:12,  1.14s/it] 98%|█████████▊| 491/500 [13:57<00:24,  2.68s/it] 99%|█████████▊| 493/500 [13:57<00:13,  1.89s/it] 99%|█████████▉| 495/500 [14:03<00:11,  2.27s/it] 99%|█████████▉| 497/500 [14:04<00:04,  1.61s/it]100%|█████████▉| 499/500 [14:04<00:01,  1.15s/it]100%|██████████| 500/500 [14:10<00:00,  1.70s/it]
Epoch:  472  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  473  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  474  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  475  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  477  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  478  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  479  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  480  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  482  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  483  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  484  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  485  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  487  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  488  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  489  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  490  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  492  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  493  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  494  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  495  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  497  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  498  	Training Loss: 0.0024236971512436867
Test Loss:  0.002326973946765065
Valid Loss:  0.0025692805647850037
Epoch:  499  	Training Loss: 0.0024236971512436867
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
Epoch:  500  	Training Loss: 0.002423696918413043
Test Loss:  0.0023269737139344215
Valid Loss:  0.0025692805647850037
**************************************************learning rate decay**************************************************
seed is  18
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:24,  6.30s/it]  1%|          | 3/500 [00:06<13:57,  1.69s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:54,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.97it/s]  4%|▍         | 21/500 [00:20<09:48,  1.23s/it]  5%|▍         | 23/500 [00:20<06:57,  1.14it/s]  5%|▌         | 25/500 [00:20<04:58,  1.59it/s]  5%|▌         | 27/500 [00:20<03:36,  2.18it/s]  6%|▌         | 29/500 [00:20<02:40,  2.94it/s]  6%|▌         | 31/500 [00:27<09:17,  1.19s/it]  7%|▋         | 33/500 [00:27<06:37,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.62it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:33<08:57,  1.17s/it]  9%|▊         | 43/500 [00:33<06:24,  1.19it/s]  9%|▉         | 45/500 [00:34<04:36,  1.65it/s]  9%|▉         | 47/500 [00:34<03:21,  2.25it/s] 10%|▉         | 49/500 [00:34<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:44,  1.17s/it] 11%|█         | 53/500 [00:40<06:14,  1.19it/s] 11%|█         | 55/500 [00:40<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:16,  2.25it/s] 12%|█▏        | 59/500 [00:41<02:25,  3.03it/s] 12%|█▏        | 61/500 [00:47<08:34,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:07,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:24,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.02it/s] 14%|█▍        | 71/500 [00:54<08:22,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:59,  1.19it/s]Epoch:  1  	Training Loss: 0.47964417934417725
Test Loss:  8.841203689575195
Valid Loss:  8.545013427734375
Epoch:  2  	Training Loss: 8.942988395690918
Test Loss:  0.6500802040100098
Valid Loss:  0.6229677796363831
Epoch:  3  	Training Loss: 0.5432292222976685
Test Loss:  0.6500747203826904
Valid Loss:  0.6229621171951294
Epoch:  4  	Training Loss: 0.5432251691818237
Test Loss:  0.6500692963600159
Valid Loss:  0.6229565143585205
Epoch:  5  	Training Loss: 0.5432212352752686
Test Loss:  0.6500638723373413
Valid Loss:  0.6229509115219116
Epoch:  6  	Training Loss: 0.5432172417640686
Test Loss:  0.650058388710022
Valid Loss:  0.6229453086853027
Epoch:  7  	Training Loss: 0.5432132482528687
Test Loss:  0.6500530242919922
Valid Loss:  0.6229397058486938
Epoch:  8  	Training Loss: 0.5432093143463135
Test Loss:  0.6500475406646729
Valid Loss:  0.6229339838027954
Epoch:  9  	Training Loss: 0.5432052612304688
Test Loss:  0.6500420570373535
Valid Loss:  0.6229283809661865
Epoch:  10  	Training Loss: 0.5432013273239136
Test Loss:  0.6500366926193237
Valid Loss:  0.6229227781295776
Epoch:  11  	Training Loss: 0.5431973338127136
Test Loss:  0.6500312089920044
Valid Loss:  0.6229171752929688
Epoch:  12  	Training Loss: 0.5431933403015137
Test Loss:  0.6500294804573059
Valid Loss:  0.6229153871536255
Epoch:  13  	Training Loss: 0.5431919097900391
Test Loss:  0.6500277519226074
Valid Loss:  0.622913658618927
Epoch:  14  	Training Loss: 0.5431905388832092
Test Loss:  0.6500260829925537
Valid Loss:  0.6229119300842285
Epoch:  15  	Training Loss: 0.5431891083717346
Test Loss:  0.6500242948532104
Valid Loss:  0.62291020154953
Epoch:  16  	Training Loss: 0.5431877374649048
Test Loss:  0.6500226259231567
Valid Loss:  0.6229084730148315
Epoch:  17  	Training Loss: 0.5431863069534302
Test Loss:  0.6500208377838135
Valid Loss:  0.6229068040847778
Epoch:  18  	Training Loss: 0.5431849956512451
Test Loss:  0.6500191688537598
Valid Loss:  0.6229050159454346
Epoch:  19  	Training Loss: 0.5431835651397705
Test Loss:  0.6500173807144165
Valid Loss:  0.6229032874107361
Epoch:  20  	Training Loss: 0.5431821942329407
Test Loss:  0.650015652179718
Valid Loss:  0.6229015588760376
Epoch:  21  	Training Loss: 0.5431807637214661
Test Loss:  0.6500139236450195
Valid Loss:  0.6228998899459839
Epoch:  22  	Training Loss: 0.5431793928146362
Test Loss:  0.6500122547149658
Valid Loss:  0.6228981018066406
Epoch:  23  	Training Loss: 0.5431779623031616
Test Loss:  0.6500104665756226
Valid Loss:  0.6228964328765869
Epoch:  24  	Training Loss: 0.5431766510009766
Test Loss:  0.6500087380409241
Valid Loss:  0.6228946447372437
Epoch:  25  	Training Loss: 0.5431751608848572
Test Loss:  0.6500070095062256
Valid Loss:  0.6228928565979004
Epoch:  26  	Training Loss: 0.5431737899780273
Test Loss:  0.6500052809715271
Valid Loss:  0.6228911876678467
Epoch:  27  	Training Loss: 0.5431724190711975
Test Loss:  0.6500035524368286
Valid Loss:  0.6228893995285034
Epoch:  28  	Training Loss: 0.5431709885597229
Test Loss:  0.6500017642974854
Valid Loss:  0.6228877305984497
Epoch:  29  	Training Loss: 0.5431696176528931
Test Loss:  0.6500000357627869
Valid Loss:  0.6228859424591064
Epoch:  30  	Training Loss: 0.5431681871414185
Test Loss:  0.6499983072280884
Valid Loss:  0.622884213924408
Epoch:  31  	Training Loss: 0.5431667566299438
Test Loss:  0.6499965786933899
Valid Loss:  0.6228824853897095
Epoch:  32  	Training Loss: 0.5431654453277588
Test Loss:  0.6499948501586914
Valid Loss:  0.622880756855011
Epoch:  33  	Training Loss: 0.5431640148162842
Test Loss:  0.6499931812286377
Valid Loss:  0.6228790283203125
Epoch:  34  	Training Loss: 0.5431626439094543
Test Loss:  0.6499913930892944
Valid Loss:  0.622877299785614
Epoch:  35  	Training Loss: 0.5431612730026245
Test Loss:  0.6499897241592407
Valid Loss:  0.6228755712509155
Epoch:  36  	Training Loss: 0.5431599020957947
Test Loss:  0.6499879956245422
Valid Loss:  0.6228739023208618
Epoch:  37  	Training Loss: 0.5431585311889648
Test Loss:  0.6499862670898438
Valid Loss:  0.6228721141815186
Epoch:  38  	Training Loss: 0.5431571006774902
Test Loss:  0.6499845385551453
Valid Loss:  0.6228704452514648
Epoch:  39  	Training Loss: 0.5431557297706604
Test Loss:  0.6499828100204468
Valid Loss:  0.6228686571121216
Epoch:  40  	Training Loss: 0.5431543588638306
Test Loss:  0.6499811410903931
Valid Loss:  0.6228669881820679
Epoch:  41  	Training Loss: 0.5431529879570007
Test Loss:  0.6499793529510498
Valid Loss:  0.6228653192520142
Epoch:  42  	Training Loss: 0.5431516170501709
Test Loss:  0.6499776840209961
Valid Loss:  0.6228635907173157
Epoch:  43  	Training Loss: 0.5431502461433411
Test Loss:  0.6499759554862976
Valid Loss:  0.6228618621826172
Epoch:  44  	Training Loss: 0.5431488752365112
Test Loss:  0.6499742865562439
Valid Loss:  0.6228601932525635
Epoch:  45  	Training Loss: 0.5431474447250366
Test Loss:  0.6499725580215454
Valid Loss:  0.6228584051132202
Epoch:  46  	Training Loss: 0.5431461334228516
Test Loss:  0.6499708890914917
Valid Loss:  0.6228567361831665
Epoch:  47  	Training Loss: 0.543144702911377
Test Loss:  0.6499691009521484
Valid Loss:  0.622855007648468
Epoch:  48  	Training Loss: 0.5431433916091919
Test Loss:  0.6499674320220947
Valid Loss:  0.6228532791137695
Epoch:  49  	Training Loss: 0.5431419610977173
Test Loss:  0.6499656438827515
Valid Loss:  0.622851550579071
Epoch:  50  	Training Loss: 0.5431405305862427
Test Loss:  0.6499639749526978
Valid Loss:  0.6228498220443726
Epoch:  51  	Training Loss: 0.5431392192840576
Test Loss:  0.6499622464179993
Valid Loss:  0.6228480935096741
Epoch:  52  	Training Loss: 0.543137788772583
Test Loss:  0.6499605178833008
Valid Loss:  0.6228463649749756
Epoch:  53  	Training Loss: 0.543136477470398
Test Loss:  0.6499587893486023
Valid Loss:  0.6228446364402771
Epoch:  54  	Training Loss: 0.5431350469589233
Test Loss:  0.6499570608139038
Valid Loss:  0.6228429079055786
Epoch:  55  	Training Loss: 0.5431336164474487
Test Loss:  0.6499553918838501
Valid Loss:  0.6228411793708801
Epoch:  56  	Training Loss: 0.5431323051452637
Test Loss:  0.6499536037445068
Valid Loss:  0.6228394508361816
Epoch:  57  	Training Loss: 0.5431308746337891
Test Loss:  0.6499518752098083
Valid Loss:  0.6228376626968384
Epoch:  58  	Training Loss: 0.5431295037269592
Test Loss:  0.6499501466751099
Valid Loss:  0.6228359937667847
Epoch:  59  	Training Loss: 0.5431281328201294
Test Loss:  0.6499484181404114
Valid Loss:  0.6228342056274414
Epoch:  60  	Training Loss: 0.5431267619132996
Test Loss:  0.6499466896057129
Valid Loss:  0.6228325366973877
Epoch:  61  	Training Loss: 0.5431253910064697
Test Loss:  0.6499449014663696
Valid Loss:  0.6228307485580444
Epoch:  62  	Training Loss: 0.5431239604949951
Test Loss:  0.6499432325363159
Valid Loss:  0.6228289604187012
Epoch:  63  	Training Loss: 0.5431225299835205
Test Loss:  0.6499414443969727
Valid Loss:  0.6228272318840027
Epoch:  64  	Training Loss: 0.5431211590766907
Test Loss:  0.649939775466919
Valid Loss:  0.6228255033493042
Epoch:  65  	Training Loss: 0.5431197881698608
Test Loss:  0.6499379873275757
Valid Loss:  0.6228237748146057
Epoch:  66  	Training Loss: 0.5431183576583862
Test Loss:  0.6499362587928772
Valid Loss:  0.6228220462799072
Epoch:  67  	Training Loss: 0.5431169271469116
Test Loss:  0.6499345302581787
Valid Loss:  0.6228203177452087
Epoch:  68  	Training Loss: 0.5431156158447266
Test Loss:  0.6499327421188354
Valid Loss:  0.6228184700012207
Epoch:  69  	Training Loss: 0.543114185333252
Test Loss:  0.6499310731887817
Valid Loss:  0.622816801071167
Epoch:  70  	Training Loss: 0.5431127548217773
Test Loss:  0.6499292254447937
Valid Loss:  0.6228150129318237
Epoch:  71  	Training Loss: 0.5431113243103027
Test Loss:  0.6499274969100952
Valid Loss:  0.6228132247924805
Epoch:  72  	Training Loss: 0.5431099534034729
Test Loss:  0.6499257683753967
Valid Loss:  0.6228115558624268
Epoch:  73  	Training Loss: 0.5431085228919983
Test Loss:  0.6499240398406982
Valid Loss:  0.6228098273277283
Epoch:  74  	Training Loss: 0.5431071519851685
Test Loss:  0.6499223113059998
Valid Loss:  0.622808039188385
Epoch:  75  	Training Loss: 0.5431057810783386
Test Loss:  0.6499205827713013
 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:00<08:11,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:51,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<08:04,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:46,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:01,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:14<07:45,  1.17s/it] 21%|██        | 103/500 [01:14<05:32,  1.19it/s] 21%|██        | 105/500 [01:14<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:15<02:54,  2.26it/s] 22%|██▏       | 109/500 [01:15<02:08,  3.04it/s] 22%|██▏       | 111/500 [01:21<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:21<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:28<07:23,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:34<07:10,  1.17s/it] 27%|██▋       | 133/500 [01:35<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:35<02:40,  2.25it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.03it/s] 28%|██▊       | 141/500 [01:41<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:41<05:01,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:42<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.01it/s]Valid Loss:  0.6228063106536865
Epoch:  76  	Training Loss: 0.543104350566864
Test Loss:  0.649918794631958
Valid Loss:  0.6228045225143433
Epoch:  77  	Training Loss: 0.5431029796600342
Test Loss:  0.6499170660972595
Valid Loss:  0.6228027939796448
Epoch:  78  	Training Loss: 0.5431015491485596
Test Loss:  0.649915337562561
Valid Loss:  0.6228010654449463
Epoch:  79  	Training Loss: 0.5431001782417297
Test Loss:  0.6499135494232178
Valid Loss:  0.6227993369102478
Epoch:  80  	Training Loss: 0.5430988073348999
Test Loss:  0.6499118804931641
Valid Loss:  0.6227975487709045
Epoch:  81  	Training Loss: 0.5430974364280701
Test Loss:  0.6499100923538208
Valid Loss:  0.622795820236206
Epoch:  82  	Training Loss: 0.5430960059165955
Test Loss:  0.6499083042144775
Valid Loss:  0.6227940917015076
Epoch:  83  	Training Loss: 0.5430946350097656
Test Loss:  0.6499066352844238
Valid Loss:  0.6227923035621643
Epoch:  84  	Training Loss: 0.543093204498291
Test Loss:  0.6499048471450806
Valid Loss:  0.6227905750274658
Epoch:  85  	Training Loss: 0.5430917739868164
Test Loss:  0.6499030590057373
Valid Loss:  0.6227887868881226
Epoch:  86  	Training Loss: 0.5430904030799866
Test Loss:  0.6499013304710388
Valid Loss:  0.6227870583534241
Epoch:  87  	Training Loss: 0.5430890321731567
Test Loss:  0.6498996019363403
Valid Loss:  0.6227852702140808
Epoch:  88  	Training Loss: 0.5430875420570374
Test Loss:  0.6498978137969971
Valid Loss:  0.6227835416793823
Epoch:  89  	Training Loss: 0.5430861711502075
Test Loss:  0.6498960256576538
Valid Loss:  0.6227817535400391
Epoch:  90  	Training Loss: 0.5430847406387329
Test Loss:  0.6498943567276001
Valid Loss:  0.6227799654006958
Epoch:  91  	Training Loss: 0.5430833697319031
Test Loss:  0.6498926281929016
Valid Loss:  0.6227782964706421
Epoch:  92  	Training Loss: 0.5430819988250732
Test Loss:  0.6498907804489136
Valid Loss:  0.6227765083312988
Epoch:  93  	Training Loss: 0.5430805683135986
Test Loss:  0.6498890519142151
Valid Loss:  0.6227747201919556
Epoch:  94  	Training Loss: 0.5430790781974792
Test Loss:  0.6498872637748718
Valid Loss:  0.6227729320526123
Epoch:  95  	Training Loss: 0.5430777072906494
Test Loss:  0.6498854160308838
Valid Loss:  0.622771143913269
Epoch:  96  	Training Loss: 0.5430762767791748
Test Loss:  0.6498837471008301
Valid Loss:  0.6227693557739258
Epoch:  97  	Training Loss: 0.5430748462677002
Test Loss:  0.6498819589614868
Valid Loss:  0.6227675676345825
Epoch:  98  	Training Loss: 0.5430734157562256
Test Loss:  0.6498801708221436
Valid Loss:  0.6227657794952393
Epoch:  99  	Training Loss: 0.543071985244751
Test Loss:  0.6498783826828003
Valid Loss:  0.622763991355896
Epoch:  100  	Training Loss: 0.5430705547332764
Test Loss:  0.649876594543457
Valid Loss:  0.6227622628211975
Epoch:  101  	Training Loss: 0.5430691242218018
Test Loss:  0.6498748064041138
Valid Loss:  0.6227604746818542
Epoch:  102  	Training Loss: 0.5430676937103271
Test Loss:  0.6498730778694153
Valid Loss:  0.6227587461471558
Epoch:  103  	Training Loss: 0.5430663824081421
Test Loss:  0.6498713493347168
Valid Loss:  0.6227569580078125
Epoch:  104  	Training Loss: 0.5430649518966675
Test Loss:  0.6498696208000183
Valid Loss:  0.6227551698684692
Epoch:  105  	Training Loss: 0.5430635213851929
Test Loss:  0.649867832660675
Valid Loss:  0.6227535009384155
Epoch:  106  	Training Loss: 0.5430620908737183
Test Loss:  0.6498661041259766
Valid Loss:  0.6227516531944275
Epoch:  107  	Training Loss: 0.5430607199668884
Test Loss:  0.6498643159866333
Valid Loss:  0.622749924659729
Epoch:  108  	Training Loss: 0.5430593490600586
Test Loss:  0.6498626470565796
Valid Loss:  0.6227481961250305
Epoch:  109  	Training Loss: 0.543057918548584
Test Loss:  0.6498608589172363
Valid Loss:  0.622746467590332
Epoch:  110  	Training Loss: 0.5430565476417542
Test Loss:  0.6498590707778931
Valid Loss:  0.6227446794509888
Epoch:  111  	Training Loss: 0.5430551767349243
Test Loss:  0.6498574018478394
Valid Loss:  0.6227428913116455
Epoch:  112  	Training Loss: 0.5430537462234497
Test Loss:  0.6498556137084961
Valid Loss:  0.6227411031723022
Epoch:  113  	Training Loss: 0.5430523157119751
Test Loss:  0.6498538255691528
Valid Loss:  0.6227393746376038
Epoch:  114  	Training Loss: 0.5430509448051453
Test Loss:  0.6498520374298096
Valid Loss:  0.6227376461029053
Epoch:  115  	Training Loss: 0.5430495142936707
Test Loss:  0.6498503684997559
Valid Loss:  0.622735857963562
Epoch:  116  	Training Loss: 0.5430481433868408
Test Loss:  0.6498485803604126
Valid Loss:  0.6227340698242188
Epoch:  117  	Training Loss: 0.5430467128753662
Test Loss:  0.6498467922210693
Valid Loss:  0.6227322816848755
Epoch:  118  	Training Loss: 0.5430452823638916
Test Loss:  0.6498450040817261
Valid Loss:  0.622730553150177
Epoch:  119  	Training Loss: 0.543043851852417
Test Loss:  0.6498432755470276
Valid Loss:  0.6227287650108337
Epoch:  120  	Training Loss: 0.5430425405502319
Test Loss:  0.6498415470123291
Valid Loss:  0.6227270364761353
Epoch:  121  	Training Loss: 0.5430411100387573
Test Loss:  0.6498397588729858
Valid Loss:  0.622725248336792
Epoch:  122  	Training Loss: 0.5430396795272827
Test Loss:  0.6498379707336426
Valid Loss:  0.6227234601974487
Epoch:  123  	Training Loss: 0.5430382490158081
Test Loss:  0.6498362421989441
Valid Loss:  0.6227216720581055
Epoch:  124  	Training Loss: 0.5430368781089783
Test Loss:  0.6498344540596008
Valid Loss:  0.6227198839187622
Epoch:  125  	Training Loss: 0.5430353879928589
Test Loss:  0.6498327255249023
Valid Loss:  0.6227181553840637
Epoch:  126  	Training Loss: 0.543034017086029
Test Loss:  0.6498309373855591
Valid Loss:  0.6227164268493652
Epoch:  127  	Training Loss: 0.5430326461791992
Test Loss:  0.6498291492462158
Valid Loss:  0.622714638710022
Epoch:  128  	Training Loss: 0.5430312156677246
Test Loss:  0.6498273611068726
Valid Loss:  0.6227128505706787
Epoch:  129  	Training Loss: 0.54302978515625
Test Loss:  0.6498256325721741
Valid Loss:  0.6227110624313354
Epoch:  130  	Training Loss: 0.5430284142494202
Test Loss:  0.6498239040374756
Valid Loss:  0.6227092742919922
Epoch:  131  	Training Loss: 0.5430270433425903
Test Loss:  0.6498221158981323
Valid Loss:  0.6227075457572937
Epoch:  132  	Training Loss: 0.543025553226471
Test Loss:  0.6498203277587891
Valid Loss:  0.6227056980133057
Epoch:  133  	Training Loss: 0.5430241227149963
Test Loss:  0.6498185396194458
Valid Loss:  0.6227039098739624
Epoch:  134  	Training Loss: 0.5430227518081665
Test Loss:  0.6498167514801025
Valid Loss:  0.6227021217346191
Epoch:  135  	Training Loss: 0.5430213212966919
Test Loss:  0.6498149037361145
Valid Loss:  0.6227003335952759
Epoch:  136  	Training Loss: 0.5430198311805725
Test Loss:  0.649813175201416
Valid Loss:  0.6226984858512878
Epoch:  137  	Training Loss: 0.5430184006690979
Test Loss:  0.649811327457428
Valid Loss:  0.6226967573165894
Epoch:  138  	Training Loss: 0.5430169701576233
Test Loss:  0.6498095989227295
Valid Loss:  0.6226948499679565
Epoch:  139  	Training Loss: 0.5430155396461487
Test Loss:  0.6498077511787415
Valid Loss:  0.6226931214332581
Epoch:  140  	Training Loss: 0.5430140495300293
Test Loss:  0.6498059630393982
Valid Loss:  0.62269127368927
Epoch:  141  	Training Loss: 0.5430126190185547
Test Loss:  0.6498041152954102
Valid Loss:  0.6226894855499268
Epoch:  142  	Training Loss: 0.5430111885070801
Test Loss:  0.6498023867607117
Valid Loss:  0.6226876974105835
Epoch:  143  	Training Loss: 0.543009877204895
Test Loss:  0.6498006582260132
Valid Loss:  0.6226859092712402
Epoch:  144  	Training Loss: 0.5430084466934204
Test Loss:  0.6497988700866699
Valid Loss:  0.6226841807365417
Epoch:  145  	Training Loss: 0.5430070161819458
Test Loss:  0.6497970819473267
Valid Loss:  0.6226824522018433
Epoch:  146  	Training Loss: 0.543005645275116
Test Loss:  0.649795413017273
Valid Loss:  0.6226806640625
Epoch:  147  	Training Loss: 0.5430042743682861
Test Loss:  0.6497936248779297
Valid Loss:  0.6226789355278015
Epoch:  148  	Training Loss: 0.5430028438568115
Test Loss:  0.6497918367385864
Valid Loss:  0.6226770877838135
Epoch:  149  	Training Loss: 0.5430014133453369
Test Loss:  0.6497901678085327
Valid Loss:  0.6226754188537598
 30%|███       | 151/500 [01:48<06:47,  1.17s/it] 31%|███       | 153/500 [01:48<04:51,  1.19it/s] 31%|███       | 155/500 [01:48<03:29,  1.64it/s] 31%|███▏      | 157/500 [01:48<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:49<01:52,  3.02it/s] 32%|███▏      | 161/500 [01:55<06:38,  1.18s/it] 33%|███▎      | 163/500 [01:55<04:44,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.01it/s] 34%|███▍      | 171/500 [02:02<06:26,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:09<06:14,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:15<06:04,  1.18s/it] 39%|███▊      | 193/500 [02:16<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:06,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.00it/s] 40%|████      | 201/500 [02:22<05:54,  1.19s/it] 41%|████      | 203/500 [02:22<04:13,  1.17it/s] 41%|████      | 205/500 [02:23<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:23<02:12,  2.22it/s] 42%|████▏     | 209/500 [02:23<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:29<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:29<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:29<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:29<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:36<05:27,  1.17s/it]Epoch:  150  	Training Loss: 0.5430001020431519
Test Loss:  0.6497883796691895
Valid Loss:  0.6226736307144165
Epoch:  151  	Training Loss: 0.5429986715316772
Test Loss:  0.649786651134491
Valid Loss:  0.6226718425750732
Epoch:  152  	Training Loss: 0.5429972410202026
Test Loss:  0.6497848033905029
Valid Loss:  0.62267005443573
Epoch:  153  	Training Loss: 0.542995810508728
Test Loss:  0.6497830152511597
Valid Loss:  0.6226682662963867
Epoch:  154  	Training Loss: 0.5429943799972534
Test Loss:  0.6497812271118164
Valid Loss:  0.6226664781570435
Epoch:  155  	Training Loss: 0.5429929494857788
Test Loss:  0.6497794389724731
Valid Loss:  0.6226646900177002
Epoch:  156  	Training Loss: 0.5429915189743042
Test Loss:  0.6497776508331299
Valid Loss:  0.6226629018783569
Epoch:  157  	Training Loss: 0.5429901480674744
Test Loss:  0.6497759222984314
Valid Loss:  0.6226611137390137
Epoch:  158  	Training Loss: 0.5429887175559998
Test Loss:  0.6497740745544434
Valid Loss:  0.6226593255996704
Epoch:  159  	Training Loss: 0.5429873466491699
Test Loss:  0.6497723460197449
Valid Loss:  0.6226575374603271
Epoch:  160  	Training Loss: 0.5429859161376953
Test Loss:  0.6497705578804016
Valid Loss:  0.6226557493209839
Epoch:  161  	Training Loss: 0.5429844856262207
Test Loss:  0.6497687697410583
Valid Loss:  0.6226539611816406
Epoch:  162  	Training Loss: 0.5429830551147461
Test Loss:  0.6497670412063599
Valid Loss:  0.6226521730422974
Epoch:  163  	Training Loss: 0.5429816246032715
Test Loss:  0.6497652530670166
Valid Loss:  0.6226503849029541
Epoch:  164  	Training Loss: 0.5429802536964417
Test Loss:  0.6497634649276733
Valid Loss:  0.6226485967636108
Epoch:  165  	Training Loss: 0.5429787635803223
Test Loss:  0.6497616767883301
Valid Loss:  0.6226468086242676
Epoch:  166  	Training Loss: 0.5429773926734924
Test Loss:  0.6497599482536316
Valid Loss:  0.6226450204849243
Epoch:  167  	Training Loss: 0.5429760217666626
Test Loss:  0.6497581601142883
Valid Loss:  0.622643232345581
Epoch:  168  	Training Loss: 0.5429746508598328
Test Loss:  0.6497564315795898
Valid Loss:  0.6226414442062378
Epoch:  169  	Training Loss: 0.5429731607437134
Test Loss:  0.6497546434402466
Valid Loss:  0.6226396560668945
Epoch:  170  	Training Loss: 0.5429717898368835
Test Loss:  0.6497528553009033
Valid Loss:  0.6226378679275513
Epoch:  171  	Training Loss: 0.5429702997207642
Test Loss:  0.6497510671615601
Valid Loss:  0.622636079788208
Epoch:  172  	Training Loss: 0.5429689884185791
Test Loss:  0.6497492790222168
Valid Loss:  0.6226342916488647
Epoch:  173  	Training Loss: 0.5429675579071045
Test Loss:  0.6497474908828735
Valid Loss:  0.6226325035095215
Epoch:  174  	Training Loss: 0.5429660677909851
Test Loss:  0.6497455835342407
Valid Loss:  0.6226305961608887
Epoch:  175  	Training Loss: 0.5429645776748657
Test Loss:  0.6497437953948975
Valid Loss:  0.6226288080215454
Epoch:  176  	Training Loss: 0.5429631471633911
Test Loss:  0.6497419476509094
Valid Loss:  0.6226269602775574
Epoch:  177  	Training Loss: 0.5429617166519165
Test Loss:  0.6497400999069214
Valid Loss:  0.6226251125335693
Epoch:  178  	Training Loss: 0.5429602265357971
Test Loss:  0.6497383117675781
Valid Loss:  0.6226232647895813
Epoch:  179  	Training Loss: 0.5429587364196777
Test Loss:  0.6497364640235901
Valid Loss:  0.6226214170455933
Epoch:  180  	Training Loss: 0.5429573059082031
Test Loss:  0.649734616279602
Valid Loss:  0.6226195693016052
Epoch:  181  	Training Loss: 0.5429558157920837
Test Loss:  0.6497328281402588
Valid Loss:  0.6226177215576172
Epoch:  182  	Training Loss: 0.5429543256759644
Test Loss:  0.6497309803962708
Valid Loss:  0.6226159334182739
Epoch:  183  	Training Loss: 0.5429529547691345
Test Loss:  0.6497292518615723
Valid Loss:  0.6226142048835754
Epoch:  184  	Training Loss: 0.5429515838623047
Test Loss:  0.6497274041175842
Valid Loss:  0.6226123571395874
Epoch:  185  	Training Loss: 0.5429500937461853
Test Loss:  0.6497256755828857
Valid Loss:  0.6226105690002441
Epoch:  186  	Training Loss: 0.5429486632347107
Test Loss:  0.6497238874435425
Valid Loss:  0.6226087808609009
Epoch:  187  	Training Loss: 0.5429472923278809
Test Loss:  0.6497220993041992
Valid Loss:  0.6226069927215576
Epoch:  188  	Training Loss: 0.5429458618164062
Test Loss:  0.649720311164856
Valid Loss:  0.6226052045822144
Epoch:  189  	Training Loss: 0.5429444313049316
Test Loss:  0.6497185230255127
Valid Loss:  0.6226032972335815
Epoch:  190  	Training Loss: 0.542943000793457
Test Loss:  0.6497167348861694
Valid Loss:  0.6226016283035278
Epoch:  191  	Training Loss: 0.5429415702819824
Test Loss:  0.6497149467468262
Valid Loss:  0.622599720954895
Epoch:  192  	Training Loss: 0.5429401397705078
Test Loss:  0.6497131586074829
Valid Loss:  0.6225979924201965
Epoch:  193  	Training Loss: 0.542938768863678
Test Loss:  0.6497113704681396
Valid Loss:  0.6225961446762085
Epoch:  194  	Training Loss: 0.5429373383522034
Test Loss:  0.6497095823287964
Valid Loss:  0.62259441614151
Epoch:  195  	Training Loss: 0.542935848236084
Test Loss:  0.6497077941894531
Valid Loss:  0.622592568397522
Epoch:  196  	Training Loss: 0.5429345369338989
Test Loss:  0.6497060060501099
Valid Loss:  0.6225907802581787
Epoch:  197  	Training Loss: 0.5429330468177795
Test Loss:  0.6497041583061218
Valid Loss:  0.6225889921188354
Epoch:  198  	Training Loss: 0.5429316163063049
Test Loss:  0.6497024297714233
Valid Loss:  0.6225872039794922
Epoch:  199  	Training Loss: 0.5429301857948303
Test Loss:  0.6497005820274353
Valid Loss:  0.6225852966308594
Epoch:  200  	Training Loss: 0.5429287552833557
Test Loss:  0.649698793888092
Valid Loss:  0.6225835680961609
Epoch:  201  	Training Loss: 0.5429273843765259
Test Loss:  0.6496970057487488
Valid Loss:  0.6225817203521729
Epoch:  202  	Training Loss: 0.5429259538650513
Test Loss:  0.6496952176094055
Valid Loss:  0.6225799322128296
Epoch:  203  	Training Loss: 0.5429245233535767
Test Loss:  0.6496933698654175
Valid Loss:  0.6225780844688416
Epoch:  204  	Training Loss: 0.542923092842102
Test Loss:  0.6496915221214294
Valid Loss:  0.6225762367248535
Epoch:  205  	Training Loss: 0.5429215431213379
Test Loss:  0.6496897339820862
Valid Loss:  0.6225744485855103
Epoch:  206  	Training Loss: 0.5429201126098633
Test Loss:  0.6496878862380981
Valid Loss:  0.6225725412368774
Epoch:  207  	Training Loss: 0.5429186820983887
Test Loss:  0.6496860980987549
Valid Loss:  0.6225707530975342
Epoch:  208  	Training Loss: 0.5429171919822693
Test Loss:  0.6496842503547668
Valid Loss:  0.6225688457489014
Epoch:  209  	Training Loss: 0.5429157614707947
Test Loss:  0.6496824026107788
Valid Loss:  0.6225670576095581
Epoch:  210  	Training Loss: 0.5429143905639648
Test Loss:  0.6496806144714355
Valid Loss:  0.6225652694702148
Epoch:  211  	Training Loss: 0.5429129004478455
Test Loss:  0.6496787667274475
Valid Loss:  0.622563362121582
Epoch:  212  	Training Loss: 0.5429114103317261
Test Loss:  0.6496769785881042
Valid Loss:  0.6225615739822388
Epoch:  213  	Training Loss: 0.5429099798202515
Test Loss:  0.649675190448761
Valid Loss:  0.6225597858428955
Epoch:  214  	Training Loss: 0.5429085493087769
Test Loss:  0.649673342704773
Valid Loss:  0.6225579977035522
Epoch:  215  	Training Loss: 0.5429071187973022
Test Loss:  0.6496715545654297
Valid Loss:  0.6225561499595642
Epoch:  216  	Training Loss: 0.5429056882858276
Test Loss:  0.6496697664260864
Valid Loss:  0.6225543022155762
Epoch:  217  	Training Loss: 0.542904257774353
Test Loss:  0.6496679186820984
Valid Loss:  0.6225525140762329
Epoch:  218  	Training Loss: 0.5429028272628784
Test Loss:  0.6496661305427551
Valid Loss:  0.6225506663322449
Epoch:  219  	Training Loss: 0.5429013967514038
Test Loss:  0.6496642827987671
Valid Loss:  0.6225488185882568
Epoch:  220  	Training Loss: 0.5428999662399292
Test Loss:  0.6496624946594238
Valid Loss:  0.6225470304489136
Epoch:  221  	Training Loss: 0.5428985357284546
Test Loss:  0.6496607065200806
Valid Loss:  0.6225451827049255
Epoch:  222  	Training Loss: 0.5428970456123352
Test Loss:  0.6496588587760925
Valid Loss:  0.6225433349609375
Epoch:  223  	Training Loss: 0.5428955554962158
Test Loss:  0.6496570110321045
Valid Loss:  0.6225415468215942 45%|████▍     | 223/500 [02:36<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:36<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:36<02:02,  2.24it/s] 46%|████▌     | 229/500 [02:36<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:43<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:43<01:27,  3.00it/s] 48%|████▊     | 241/500 [02:50<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:50<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:50<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:50<01:52,  2.25it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.02it/s] 50%|█████     | 251/500 [02:56<04:54,  1.18s/it] 51%|█████     | 253/500 [02:57<03:29,  1.18it/s] 51%|█████     | 255/500 [02:57<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:57<01:49,  2.23it/s] 52%|█████▏    | 259/500 [02:57<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:03<04:40,  1.18s/it] 53%|█████▎    | 263/500 [03:03<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:03<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:10<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:10<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:10<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:10<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:11<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:17<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:17<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:17<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:17<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:17<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:24<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:24<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:24<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:24<01:32,  2.20it/s]
Epoch:  224  	Training Loss: 0.5428941249847412
Test Loss:  0.6496552228927612
Valid Loss:  0.6225396990776062
Epoch:  225  	Training Loss: 0.5428926944732666
Test Loss:  0.6496533155441284
Valid Loss:  0.6225378513336182
Epoch:  226  	Training Loss: 0.5428912043571472
Test Loss:  0.6496515274047852
Valid Loss:  0.6225360035896301
Epoch:  227  	Training Loss: 0.5428897738456726
Test Loss:  0.6496496796607971
Valid Loss:  0.6225341558456421
Epoch:  228  	Training Loss: 0.5428882837295532
Test Loss:  0.6496478915214539
Valid Loss:  0.6225322484970093
Epoch:  229  	Training Loss: 0.5428868532180786
Test Loss:  0.6496460437774658
Valid Loss:  0.622530460357666
Epoch:  230  	Training Loss: 0.542885422706604
Test Loss:  0.6496441960334778
Valid Loss:  0.622528612613678
Epoch:  231  	Training Loss: 0.5428839325904846
Test Loss:  0.6496423482894897
Valid Loss:  0.6225267648696899
Epoch:  232  	Training Loss: 0.5428825616836548
Test Loss:  0.6496405601501465
Valid Loss:  0.6225249171257019
Epoch:  233  	Training Loss: 0.5428810119628906
Test Loss:  0.6496386528015137
Valid Loss:  0.6225230693817139
Epoch:  234  	Training Loss: 0.542879581451416
Test Loss:  0.6496368646621704
Valid Loss:  0.622521162033081
Epoch:  235  	Training Loss: 0.5428781509399414
Test Loss:  0.6496350169181824
Valid Loss:  0.6225192546844482
Epoch:  236  	Training Loss: 0.5428766012191772
Test Loss:  0.6496331691741943
Valid Loss:  0.622517466545105
Epoch:  237  	Training Loss: 0.5428751111030579
Test Loss:  0.6496312618255615
Valid Loss:  0.6225155591964722
Epoch:  238  	Training Loss: 0.5428736805915833
Test Loss:  0.6496294736862183
Valid Loss:  0.6225137114524841
Epoch:  239  	Training Loss: 0.5428721904754639
Test Loss:  0.6496275663375854
Valid Loss:  0.6225118637084961
Epoch:  240  	Training Loss: 0.5428707599639893
Test Loss:  0.6496257781982422
Valid Loss:  0.6225100159645081
Epoch:  241  	Training Loss: 0.5428693294525146
Test Loss:  0.6496238708496094
Valid Loss:  0.62250816822052
Epoch:  242  	Training Loss: 0.5428677797317505
Test Loss:  0.6496220827102661
Valid Loss:  0.622506320476532
Epoch:  243  	Training Loss: 0.5428663492202759
Test Loss:  0.6496201753616333
Valid Loss:  0.622504472732544
Epoch:  244  	Training Loss: 0.5428649187088013
Test Loss:  0.64961838722229
Valid Loss:  0.6225026249885559
Epoch:  245  	Training Loss: 0.5428634881973267
Test Loss:  0.649616539478302
Valid Loss:  0.6225007772445679
Epoch:  246  	Training Loss: 0.5428619980812073
Test Loss:  0.649614691734314
Valid Loss:  0.6224988698959351
Epoch:  247  	Training Loss: 0.5428605079650879
Test Loss:  0.6496129035949707
Valid Loss:  0.622497022151947
Epoch:  248  	Training Loss: 0.5428590774536133
Test Loss:  0.6496109962463379
Valid Loss:  0.622495174407959
Epoch:  249  	Training Loss: 0.5428575873374939
Test Loss:  0.6496092081069946
Valid Loss:  0.622493326663971
Epoch:  250  	Training Loss: 0.5428560972213745
Test Loss:  0.6496074199676514
Valid Loss:  0.6224914789199829
Epoch:  251  	Training Loss: 0.5428546667098999
Test Loss:  0.6496055126190186
Valid Loss:  0.6224896311759949
Epoch:  252  	Training Loss: 0.5428532361984253
Test Loss:  0.6496037244796753
Valid Loss:  0.6224877834320068
Epoch:  253  	Training Loss: 0.5428518056869507
Test Loss:  0.6496018171310425
Valid Loss:  0.622485876083374
Epoch:  254  	Training Loss: 0.5428502559661865
Test Loss:  0.6496000289916992
Valid Loss:  0.6224840879440308
Epoch:  255  	Training Loss: 0.5428488254547119
Test Loss:  0.6495981216430664
Valid Loss:  0.6224822402000427
Epoch:  256  	Training Loss: 0.5428473949432373
Test Loss:  0.6495963335037231
Valid Loss:  0.6224803328514099
Epoch:  257  	Training Loss: 0.5428459644317627
Test Loss:  0.6495944857597351
Valid Loss:  0.6224785447120667
Epoch:  258  	Training Loss: 0.5428445339202881
Test Loss:  0.6495926380157471
Valid Loss:  0.6224766969680786
Epoch:  259  	Training Loss: 0.5428429841995239
Test Loss:  0.649590790271759
Valid Loss:  0.6224747896194458
Epoch:  260  	Training Loss: 0.5428415536880493
Test Loss:  0.649588942527771
Valid Loss:  0.6224729418754578
Epoch:  261  	Training Loss: 0.5428401231765747
Test Loss:  0.649587094783783
Valid Loss:  0.6224710941314697
Epoch:  262  	Training Loss: 0.5428386330604553
Test Loss:  0.6495852470397949
Valid Loss:  0.6224693059921265
Epoch:  263  	Training Loss: 0.5428371429443359
Test Loss:  0.6495834589004517
Valid Loss:  0.6224673986434937
Epoch:  264  	Training Loss: 0.5428357124328613
Test Loss:  0.6495815515518188
Valid Loss:  0.6224655508995056
Epoch:  265  	Training Loss: 0.5428342819213867
Test Loss:  0.6495797634124756
Valid Loss:  0.6224637031555176
Epoch:  266  	Training Loss: 0.5428328514099121
Test Loss:  0.6495779752731323
Valid Loss:  0.6224617958068848
Epoch:  267  	Training Loss: 0.5428313612937927
Test Loss:  0.6495760679244995
Valid Loss:  0.6224600076675415
Epoch:  268  	Training Loss: 0.5428299307823181
Test Loss:  0.6495742797851562
Valid Loss:  0.6224581599235535
Epoch:  269  	Training Loss: 0.5428285002708435
Test Loss:  0.6495724320411682
Valid Loss:  0.6224563121795654
Epoch:  270  	Training Loss: 0.5428270101547241
Test Loss:  0.6495705842971802
Valid Loss:  0.6224544048309326
Epoch:  271  	Training Loss: 0.5428255796432495
Test Loss:  0.6495687365531921
Valid Loss:  0.6224526166915894
Epoch:  272  	Training Loss: 0.5428240895271301
Test Loss:  0.6495668888092041
Valid Loss:  0.6224507093429565
Epoch:  273  	Training Loss: 0.5428225994110107
Test Loss:  0.6495651006698608
Valid Loss:  0.6224488615989685
Epoch:  274  	Training Loss: 0.5428211688995361
Test Loss:  0.6495632529258728
Valid Loss:  0.6224470138549805
Epoch:  275  	Training Loss: 0.5428197383880615
Test Loss:  0.6495614647865295
Valid Loss:  0.6224452257156372
Epoch:  276  	Training Loss: 0.5428183078765869
Test Loss:  0.6495596766471863
Valid Loss:  0.622443437576294
Epoch:  277  	Training Loss: 0.5428169369697571
Test Loss:  0.6495578289031982
Valid Loss:  0.6224415898323059
Epoch:  278  	Training Loss: 0.5428155064582825
Test Loss:  0.649556040763855
Valid Loss:  0.6224397420883179
Epoch:  279  	Training Loss: 0.5428140163421631
Test Loss:  0.6495541930198669
Valid Loss:  0.6224379539489746
Epoch:  280  	Training Loss: 0.5428125858306885
Test Loss:  0.6495523452758789
Valid Loss:  0.6224360466003418
Epoch:  281  	Training Loss: 0.5428111553192139
Test Loss:  0.6495505571365356
Valid Loss:  0.6224341988563538
Epoch:  282  	Training Loss: 0.5428097248077393
Test Loss:  0.6495486497879028
Valid Loss:  0.6224323511123657
Epoch:  283  	Training Loss: 0.5428082346916199
Test Loss:  0.6495468616485596
Valid Loss:  0.6224304437637329
Epoch:  284  	Training Loss: 0.5428067445755005
Test Loss:  0.6495449542999268
Valid Loss:  0.6224285960197449
Epoch:  285  	Training Loss: 0.5428053140640259
Test Loss:  0.6495431065559387
Valid Loss:  0.6224267482757568
Epoch:  286  	Training Loss: 0.5428038239479065
Test Loss:  0.6495412588119507
Valid Loss:  0.622424840927124
Epoch:  287  	Training Loss: 0.5428023338317871
Test Loss:  0.6495393514633179
Valid Loss:  0.6224229335784912
Epoch:  288  	Training Loss: 0.5428008437156677
Test Loss:  0.6495374441146851
Valid Loss:  0.6224210262298584
Epoch:  289  	Training Loss: 0.5427993535995483
Test Loss:  0.6495356559753418
Valid Loss:  0.6224192380905151
Epoch:  290  	Training Loss: 0.5427979230880737
Test Loss:  0.649533748626709
Valid Loss:  0.6224173307418823
Epoch:  291  	Training Loss: 0.5427964329719543
Test Loss:  0.6495319604873657
Valid Loss:  0.6224154233932495
Epoch:  292  	Training Loss: 0.5427950024604797
Test Loss:  0.6495300531387329
Valid Loss:  0.6224135756492615
Epoch:  293  	Training Loss: 0.5427935123443604
Test Loss:  0.6495282053947449
Valid Loss:  0.6224116683006287
Epoch:  294  	Training Loss: 0.542792022228241
Test Loss:  0.6495263576507568
Valid Loss:  0.6224098205566406
Epoch:  295  	Training Loss: 0.5427905321121216
Test Loss:  0.649524450302124
Valid Loss:  0.6224079132080078
Epoch:  296  	Training Loss: 0.542789101600647
Test Loss:  0.649522602558136
Valid Loss:  0.6224060654640198
Epoch:  297  	Training Loss: 0.5427876114845276
Test Loss:  0.649520754814148
Valid Loss:  0.6224042177200317
 60%|█████▉    | 299/500 [03:24<01:07,  2.96it/s] 60%|██████    | 301/500 [03:31<03:57,  1.19s/it] 61%|██████    | 303/500 [03:31<02:48,  1.17it/s] 61%|██████    | 305/500 [03:31<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:31<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:31<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:38<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:38<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:38<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:38<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:44<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:44<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:45<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:45<01:16,  2.25it/s] 66%|██████▌   | 329/500 [03:45<00:56,  3.02it/s] 66%|██████▌   | 331/500 [03:51<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:51<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:51<01:40,  1.65it/s] 67%|██████▋   | 337/500 [03:51<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:52<00:53,  3.02it/s] 68%|██████▊   | 341/500 [03:58<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:58<01:33,  1.65it/s] 69%|██████▉   | 347/500 [03:58<01:07,  2.25it/s] 70%|██████▉   | 349/500 [03:58<00:49,  3.03it/s] 70%|███████   | 351/500 [04:05<02:54,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s] 71%|███████   | 355/500 [04:05<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:05<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:11<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:12<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:12<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:12<00:43,  3.01it/s]Epoch:  298  	Training Loss: 0.5427861213684082
Test Loss:  0.6495189070701599
Valid Loss:  0.6224023103713989
Epoch:  299  	Training Loss: 0.5427846908569336
Test Loss:  0.6495170593261719
Valid Loss:  0.6224004030227661
Epoch:  300  	Training Loss: 0.5427832007408142
Test Loss:  0.6495151519775391
Valid Loss:  0.6223985552787781
Epoch:  301  	Training Loss: 0.5427817106246948
Test Loss:  0.649513304233551
Valid Loss:  0.6223966479301453
Epoch:  302  	Training Loss: 0.5427802205085754
Test Loss:  0.649511456489563
Valid Loss:  0.6223948001861572
Epoch:  303  	Training Loss: 0.542778730392456
Test Loss:  0.6495095491409302
Valid Loss:  0.6223928928375244
Epoch:  304  	Training Loss: 0.5427772998809814
Test Loss:  0.6495077610015869
Valid Loss:  0.6223910450935364
Epoch:  305  	Training Loss: 0.5427757501602173
Test Loss:  0.6495058536529541
Valid Loss:  0.6223891377449036
Epoch:  306  	Training Loss: 0.5427743196487427
Test Loss:  0.6495039463043213
Valid Loss:  0.6223872900009155
Epoch:  307  	Training Loss: 0.5427728295326233
Test Loss:  0.6495020985603333
Valid Loss:  0.6223853826522827
Epoch:  308  	Training Loss: 0.5427713394165039
Test Loss:  0.6495002508163452
Valid Loss:  0.6223834753036499
Epoch:  309  	Training Loss: 0.5427699089050293
Test Loss:  0.6494984030723572
Valid Loss:  0.6223816275596619
Epoch:  310  	Training Loss: 0.5427684187889099
Test Loss:  0.6494964957237244
Valid Loss:  0.6223797798156738
Epoch:  311  	Training Loss: 0.5427669286727905
Test Loss:  0.6494946479797363
Valid Loss:  0.622377872467041
Epoch:  312  	Training Loss: 0.5427654981613159
Test Loss:  0.6494928002357483
Valid Loss:  0.6223759651184082
Epoch:  313  	Training Loss: 0.5427640080451965
Test Loss:  0.6494908928871155
Valid Loss:  0.6223740577697754
Epoch:  314  	Training Loss: 0.5427625179290771
Test Loss:  0.6494890451431274
Valid Loss:  0.6223722100257874
Epoch:  315  	Training Loss: 0.5427610278129578
Test Loss:  0.6494871973991394
Valid Loss:  0.6223703622817993
Epoch:  316  	Training Loss: 0.5427595973014832
Test Loss:  0.6494854092597961
Valid Loss:  0.6223685145378113
Epoch:  317  	Training Loss: 0.5427581071853638
Test Loss:  0.6494835019111633
Valid Loss:  0.6223666667938232
Epoch:  318  	Training Loss: 0.5427566766738892
Test Loss:  0.6494816541671753
Valid Loss:  0.6223647594451904
Epoch:  319  	Training Loss: 0.5427551865577698
Test Loss:  0.6494797468185425
Valid Loss:  0.6223628520965576
Epoch:  320  	Training Loss: 0.5427537560462952
Test Loss:  0.6494779586791992
Valid Loss:  0.6223609447479248
Epoch:  321  	Training Loss: 0.5427522659301758
Test Loss:  0.6494760513305664
Valid Loss:  0.6223590970039368
Epoch:  322  	Training Loss: 0.5427508354187012
Test Loss:  0.6494741439819336
Valid Loss:  0.622357189655304
Epoch:  323  	Training Loss: 0.542749285697937
Test Loss:  0.6494722962379456
Valid Loss:  0.6223553419113159
Epoch:  324  	Training Loss: 0.5427478551864624
Test Loss:  0.6494703888893127
Valid Loss:  0.6223534345626831
Epoch:  325  	Training Loss: 0.5427463054656982
Test Loss:  0.6494685411453247
Valid Loss:  0.6223514676094055
Epoch:  326  	Training Loss: 0.5427448749542236
Test Loss:  0.6494666337966919
Valid Loss:  0.6223495602607727
Epoch:  327  	Training Loss: 0.5427433252334595
Test Loss:  0.6494647264480591
Valid Loss:  0.6223476529121399
Epoch:  328  	Training Loss: 0.5427418947219849
Test Loss:  0.649462878704071
Valid Loss:  0.6223458051681519
Epoch:  329  	Training Loss: 0.5427403450012207
Test Loss:  0.6494609713554382
Valid Loss:  0.622343897819519
Epoch:  330  	Training Loss: 0.5427388548851013
Test Loss:  0.6494590640068054
Valid Loss:  0.6223419904708862
Epoch:  331  	Training Loss: 0.5427373647689819
Test Loss:  0.6494572162628174
Valid Loss:  0.6223400831222534
Epoch:  332  	Training Loss: 0.5427358746528625
Test Loss:  0.6494553089141846
Valid Loss:  0.6223381757736206
Epoch:  333  	Training Loss: 0.5427344441413879
Test Loss:  0.6494534611701965
Valid Loss:  0.6223363280296326
Epoch:  334  	Training Loss: 0.5427329540252686
Test Loss:  0.6494516134262085
Valid Loss:  0.6223344206809998
Epoch:  335  	Training Loss: 0.5427314639091492
Test Loss:  0.6494497060775757
Valid Loss:  0.6223325729370117
Epoch:  336  	Training Loss: 0.5427299737930298
Test Loss:  0.6494479179382324
Valid Loss:  0.6223306655883789
Epoch:  337  	Training Loss: 0.5427284836769104
Test Loss:  0.6494460105895996
Valid Loss:  0.6223287582397461
Epoch:  338  	Training Loss: 0.5427270531654358
Test Loss:  0.6494441628456116
Valid Loss:  0.6223269104957581
Epoch:  339  	Training Loss: 0.5427255630493164
Test Loss:  0.6494423151016235
Valid Loss:  0.62232506275177
Epoch:  340  	Training Loss: 0.5427241325378418
Test Loss:  0.6494404673576355
Valid Loss:  0.6223231554031372
Epoch:  341  	Training Loss: 0.5427227020263672
Test Loss:  0.6494386196136475
Valid Loss:  0.6223213076591492
Epoch:  342  	Training Loss: 0.542721152305603
Test Loss:  0.6494367122650146
Valid Loss:  0.6223194003105164
Epoch:  343  	Training Loss: 0.5427197217941284
Test Loss:  0.6494348645210266
Valid Loss:  0.6223175525665283
Epoch:  344  	Training Loss: 0.5427182912826538
Test Loss:  0.6494330167770386
Valid Loss:  0.6223156452178955
Epoch:  345  	Training Loss: 0.5427168011665344
Test Loss:  0.6494311690330505
Valid Loss:  0.6223137378692627
Epoch:  346  	Training Loss: 0.5427153706550598
Test Loss:  0.6494293212890625
Valid Loss:  0.6223119497299194
Epoch:  347  	Training Loss: 0.5427138805389404
Test Loss:  0.6494274735450745
Valid Loss:  0.6223100423812866
Epoch:  348  	Training Loss: 0.5427124500274658
Test Loss:  0.6494256258010864
Valid Loss:  0.6223081350326538
Epoch:  349  	Training Loss: 0.5427109599113464
Test Loss:  0.6494237184524536
Valid Loss:  0.6223063468933105
Epoch:  350  	Training Loss: 0.5427095293998718
Test Loss:  0.6494218707084656
Valid Loss:  0.6223044395446777
Epoch:  351  	Training Loss: 0.5427080392837524
Test Loss:  0.6494200229644775
Valid Loss:  0.6223025321960449
Epoch:  352  	Training Loss: 0.5427066087722778
Test Loss:  0.6494181156158447
Valid Loss:  0.6223006844520569
Epoch:  353  	Training Loss: 0.5427050590515137
Test Loss:  0.6494163274765015
Valid Loss:  0.6222987771034241
Epoch:  354  	Training Loss: 0.5427036285400391
Test Loss:  0.6494144201278687
Valid Loss:  0.6222968697547913
Epoch:  355  	Training Loss: 0.5427021384239197
Test Loss:  0.6494125127792358
Valid Loss:  0.6222950220108032
Epoch:  356  	Training Loss: 0.5427006483078003
Test Loss:  0.649410605430603
Valid Loss:  0.6222929954528809
Epoch:  357  	Training Loss: 0.5426992177963257
Test Loss:  0.6494086980819702
Valid Loss:  0.6222911477088928
Epoch:  358  	Training Loss: 0.5426976680755615
Test Loss:  0.649406909942627
Valid Loss:  0.6222892999649048
Epoch:  359  	Training Loss: 0.5426962375640869
Test Loss:  0.6494050025939941
Valid Loss:  0.622287392616272
Epoch:  360  	Training Loss: 0.5426946878433228
Test Loss:  0.6494031548500061
Valid Loss:  0.6222854852676392
Epoch:  361  	Training Loss: 0.5426932573318481
Test Loss:  0.6494012475013733
Valid Loss:  0.6222835779190063
Epoch:  362  	Training Loss: 0.5426918268203735
Test Loss:  0.6493993401527405
Valid Loss:  0.6222816705703735
Epoch:  363  	Training Loss: 0.5426903367042542
Test Loss:  0.6493974924087524
Valid Loss:  0.6222797632217407
Epoch:  364  	Training Loss: 0.5426888465881348
Test Loss:  0.6493955850601196
Valid Loss:  0.6222778558731079
Epoch:  365  	Training Loss: 0.5426873564720154
Test Loss:  0.6493937969207764
Valid Loss:  0.6222760081291199
Epoch:  366  	Training Loss: 0.542685866355896
Test Loss:  0.6493918895721436
Valid Loss:  0.6222741007804871
Epoch:  367  	Training Loss: 0.5426844358444214
Test Loss:  0.6493899822235107
Valid Loss:  0.622272253036499
Epoch:  368  	Training Loss: 0.5426828861236572
Test Loss:  0.6493881344795227
Valid Loss:  0.6222703456878662
Epoch:  369  	Training Loss: 0.5426814556121826
Test Loss:  0.6493862271308899
Valid Loss:  0.6222684383392334
Epoch:  370  	Training Loss: 0.5426799654960632
Test Loss:  0.6493843793869019
Valid Loss:  0.6222665309906006
Epoch:  371  	Training Loss: 0.5426784753799438
Test Loss:  0.649382472038269
Valid Loss:   74%|███████▍  | 371/500 [04:18<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:19<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:19<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:19<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:25<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:25<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:26<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:26<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:26<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:32<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:32<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:32<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:33<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:33<00:33,  2.99it/s] 80%|████████  | 401/500 [04:39<01:56,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.18it/s] 81%|████████  | 405/500 [04:39<00:58,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:46<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:46<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:46<00:27,  3.00it/s] 84%|████████▍ | 421/500 [04:53<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:53<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:53<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.00it/s] 86%|████████▌ | 431/500 [05:00<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:00<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:00<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:00<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.19s/it] 89%|████████▊ | 443/500 [05:07<00:48,  1.17it/s]0.6222646236419678
Epoch:  372  	Training Loss: 0.5426769852638245
Test Loss:  0.649380624294281
Valid Loss:  0.622262716293335
Epoch:  373  	Training Loss: 0.5426754951477051
Test Loss:  0.6493787169456482
Valid Loss:  0.6222608089447021
Epoch:  374  	Training Loss: 0.5426740646362305
Test Loss:  0.6493767499923706
Valid Loss:  0.6222589015960693
Epoch:  375  	Training Loss: 0.5426725149154663
Test Loss:  0.6493749022483826
Valid Loss:  0.6222569942474365
Epoch:  376  	Training Loss: 0.5426709651947021
Test Loss:  0.6493730545043945
Valid Loss:  0.6222550868988037
Epoch:  377  	Training Loss: 0.5426694750785828
Test Loss:  0.6493710875511169
Valid Loss:  0.6222531795501709
Epoch:  378  	Training Loss: 0.5426680445671082
Test Loss:  0.6493691802024841
Valid Loss:  0.6222512722015381
Epoch:  379  	Training Loss: 0.5426665544509888
Test Loss:  0.6493673324584961
Valid Loss:  0.6222493052482605
Epoch:  380  	Training Loss: 0.5426650047302246
Test Loss:  0.6493654251098633
Valid Loss:  0.6222473978996277
Epoch:  381  	Training Loss: 0.5426635146141052
Test Loss:  0.6493635177612305
Valid Loss:  0.6222454309463501
Epoch:  382  	Training Loss: 0.5426620244979858
Test Loss:  0.6493616104125977
Valid Loss:  0.6222435235977173
Epoch:  383  	Training Loss: 0.5426605343818665
Test Loss:  0.6493597030639648
Valid Loss:  0.6222416162490845
Epoch:  384  	Training Loss: 0.5426590442657471
Test Loss:  0.6493577361106873
Valid Loss:  0.6222397089004517
Epoch:  385  	Training Loss: 0.5426574945449829
Test Loss:  0.6493558883666992
Valid Loss:  0.6222376823425293
Epoch:  386  	Training Loss: 0.5426560044288635
Test Loss:  0.6493539810180664
Valid Loss:  0.6222358345985413
Epoch:  387  	Training Loss: 0.5426545143127441
Test Loss:  0.6493520736694336
Valid Loss:  0.6222338676452637
Epoch:  388  	Training Loss: 0.5426530241966248
Test Loss:  0.6493501663208008
Valid Loss:  0.6222319602966309
Epoch:  389  	Training Loss: 0.5426514744758606
Test Loss:  0.649348258972168
Valid Loss:  0.622230052947998
Epoch:  390  	Training Loss: 0.5426499843597412
Test Loss:  0.6493463516235352
Valid Loss:  0.6222280859947205
Epoch:  391  	Training Loss: 0.542648434638977
Test Loss:  0.6493444442749023
Valid Loss:  0.6222261190414429
Epoch:  392  	Training Loss: 0.5426470041275024
Test Loss:  0.6493424773216248
Valid Loss:  0.6222242116928101
Epoch:  393  	Training Loss: 0.5426454544067383
Test Loss:  0.6493405699729919
Valid Loss:  0.6222223043441772
Epoch:  394  	Training Loss: 0.5426439642906189
Test Loss:  0.6493387222290039
Valid Loss:  0.6222203969955444
Epoch:  395  	Training Loss: 0.5426424741744995
Test Loss:  0.6493368148803711
Valid Loss:  0.6222184896469116
Epoch:  396  	Training Loss: 0.5426409840583801
Test Loss:  0.6493349075317383
Valid Loss:  0.6222165822982788
Epoch:  397  	Training Loss: 0.5426394939422607
Test Loss:  0.6493330001831055
Valid Loss:  0.6222146153450012
Epoch:  398  	Training Loss: 0.5426379442214966
Test Loss:  0.6493310928344727
Valid Loss:  0.6222126483917236
Epoch:  399  	Training Loss: 0.542636513710022
Test Loss:  0.6493291854858398
Valid Loss:  0.6222107410430908
Epoch:  400  	Training Loss: 0.542634904384613
Test Loss:  0.649327278137207
Valid Loss:  0.622208833694458
Epoch:  401  	Training Loss: 0.5426334738731384
Test Loss:  0.6493253111839294
Valid Loss:  0.6222069263458252
Epoch:  402  	Training Loss: 0.542631983757019
Test Loss:  0.6493234634399414
Valid Loss:  0.6222050189971924
Epoch:  403  	Training Loss: 0.5426304340362549
Test Loss:  0.6493215560913086
Valid Loss:  0.6222030520439148
Epoch:  404  	Training Loss: 0.5426290035247803
Test Loss:  0.6493196487426758
Valid Loss:  0.6222012042999268
Epoch:  405  	Training Loss: 0.5426274538040161
Test Loss:  0.649317741394043
Valid Loss:  0.6221991777420044
Epoch:  406  	Training Loss: 0.5426259636878967
Test Loss:  0.6493158340454102
Valid Loss:  0.6221972703933716
Epoch:  407  	Training Loss: 0.5426244735717773
Test Loss:  0.6493139266967773
Valid Loss:  0.6221953630447388
Epoch:  408  	Training Loss: 0.542622983455658
Test Loss:  0.6493120193481445
Valid Loss:  0.622193455696106
Epoch:  409  	Training Loss: 0.5426214933395386
Test Loss:  0.6493101119995117
Valid Loss:  0.6221914887428284
Epoch:  410  	Training Loss: 0.5426199436187744
Test Loss:  0.6493082046508789
Valid Loss:  0.6221895813941956
Epoch:  411  	Training Loss: 0.542618453502655
Test Loss:  0.6493062973022461
Valid Loss:  0.622187614440918
Epoch:  412  	Training Loss: 0.5426169037818909
Test Loss:  0.6493043899536133
Valid Loss:  0.6221857070922852
Epoch:  413  	Training Loss: 0.5426154136657715
Test Loss:  0.6493024826049805
Valid Loss:  0.6221837997436523
Epoch:  414  	Training Loss: 0.5426139831542969
Test Loss:  0.6493006348609924
Valid Loss:  0.6221818923950195
Epoch:  415  	Training Loss: 0.5426124930381775
Test Loss:  0.6492987871170044
Valid Loss:  0.6221800446510315
Epoch:  416  	Training Loss: 0.5426110029220581
Test Loss:  0.6492969393730164
Valid Loss:  0.6221781373023987
Epoch:  417  	Training Loss: 0.5426095724105835
Test Loss:  0.6492950320243835
Valid Loss:  0.6221762895584106
Epoch:  418  	Training Loss: 0.5426081418991089
Test Loss:  0.6492931246757507
Valid Loss:  0.6221743822097778
Epoch:  419  	Training Loss: 0.5426066517829895
Test Loss:  0.6492912769317627
Valid Loss:  0.622172474861145
Epoch:  420  	Training Loss: 0.5426051616668701
Test Loss:  0.6492893695831299
Valid Loss:  0.6221705675125122
Epoch:  421  	Training Loss: 0.5426036715507507
Test Loss:  0.6492874622344971
Valid Loss:  0.6221686005592346
Epoch:  422  	Training Loss: 0.5426021814346313
Test Loss:  0.649285614490509
Valid Loss:  0.6221667528152466
Epoch:  423  	Training Loss: 0.542600691318512
Test Loss:  0.6492837071418762
Valid Loss:  0.622164785861969
Epoch:  424  	Training Loss: 0.5425992012023926
Test Loss:  0.6492817401885986
Valid Loss:  0.6221628189086914
Epoch:  425  	Training Loss: 0.5425977110862732
Test Loss:  0.6492798328399658
Valid Loss:  0.6221609115600586
Epoch:  426  	Training Loss: 0.5425962209701538
Test Loss:  0.649277925491333
Valid Loss:  0.6221590042114258
Epoch:  427  	Training Loss: 0.5425946712493896
Test Loss:  0.6492760181427002
Valid Loss:  0.6221570372581482
Epoch:  428  	Training Loss: 0.5425931811332703
Test Loss:  0.6492741107940674
Valid Loss:  0.6221551895141602
Epoch:  429  	Training Loss: 0.5425916910171509
Test Loss:  0.6492722034454346
Valid Loss:  0.6221531629562378
Epoch:  430  	Training Loss: 0.5425901412963867
Test Loss:  0.6492702960968018
Valid Loss:  0.622151255607605
Epoch:  431  	Training Loss: 0.5425885915756226
Test Loss:  0.649268388748169
Valid Loss:  0.6221492290496826
Epoch:  432  	Training Loss: 0.542587161064148
Test Loss:  0.6492664813995361
Valid Loss:  0.6221473217010498
Epoch:  433  	Training Loss: 0.5425856113433838
Test Loss:  0.6492645144462585
Valid Loss:  0.622145414352417
Epoch:  434  	Training Loss: 0.5425841212272644
Test Loss:  0.6492626070976257
Valid Loss:  0.6221435070037842
Epoch:  435  	Training Loss: 0.542582631111145
Test Loss:  0.6492606997489929
Valid Loss:  0.6221415400505066
Epoch:  436  	Training Loss: 0.5425810813903809
Test Loss:  0.6492587327957153
Valid Loss:  0.6221396327018738
Epoch:  437  	Training Loss: 0.5425795912742615
Test Loss:  0.6492568254470825
Valid Loss:  0.6221376657485962
Epoch:  438  	Training Loss: 0.5425781011581421
Test Loss:  0.6492549777030945
Valid Loss:  0.6221357583999634
Epoch:  439  	Training Loss: 0.5425766706466675
Test Loss:  0.6492530107498169
Valid Loss:  0.6221337914466858
Epoch:  440  	Training Loss: 0.5425751209259033
Test Loss:  0.6492511034011841
Valid Loss:  0.6221318244934082
Epoch:  441  	Training Loss: 0.5425735712051392
Test Loss:  0.6492491960525513
Valid Loss:  0.6221299767494202
Epoch:  442  	Training Loss: 0.5425720810890198
Test Loss:  0.6492472887039185
Valid Loss:  0.6221280097961426
Epoch:  443  	Training Loss: 0.5425705909729004
Test Loss:  0.6492453813552856
Valid Loss:  0.622126042842865
Epoch:  444  	Training Loss: 0.5425690412521362
Test Loss:  0.6492434740066528
Valid Loss:  0.6221241354942322
Epoch:  445  	Training Loss: 0.5425676107406616
Test Loss:  0.6492414474487305
Valid Loss:   89%|████████▉ | 445/500 [05:07<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:07<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:13<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:13<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:14<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:20<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:21<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:21<00:10,  2.95it/s] 94%|█████████▍| 471/500 [05:27<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:27<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:28<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:28<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:34<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:34<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:41<00:00,  2.99it/s]100%|██████████| 500/500 [05:41<00:00,  1.46it/s]
0.6221221685409546
Epoch:  446  	Training Loss: 0.5425660610198975
Test Loss:  0.6492395401000977
Valid Loss:  0.622120201587677
Epoch:  447  	Training Loss: 0.5425645112991333
Test Loss:  0.6492376327514648
Valid Loss:  0.6221182346343994
Epoch:  448  	Training Loss: 0.5425630807876587
Test Loss:  0.649235725402832
Valid Loss:  0.6221163272857666
Epoch:  449  	Training Loss: 0.5425615310668945
Test Loss:  0.6492338180541992
Valid Loss:  0.622114360332489
Epoch:  450  	Training Loss: 0.5425599813461304
Test Loss:  0.6492319107055664
Valid Loss:  0.6221123933792114
Epoch:  451  	Training Loss: 0.542558491230011
Test Loss:  0.6492300033569336
Valid Loss:  0.6221104860305786
Epoch:  452  	Training Loss: 0.5425570011138916
Test Loss:  0.649228036403656
Valid Loss:  0.622108519077301
Epoch:  453  	Training Loss: 0.5425554513931274
Test Loss:  0.6492261290550232
Valid Loss:  0.6221065521240234
Epoch:  454  	Training Loss: 0.5425539612770081
Test Loss:  0.6492241621017456
Valid Loss:  0.6221046447753906
Epoch:  455  	Training Loss: 0.5425524115562439
Test Loss:  0.6492222547531128
Valid Loss:  0.622102677822113
Epoch:  456  	Training Loss: 0.5425509214401245
Test Loss:  0.64922034740448
Valid Loss:  0.6221007108688354
Epoch:  457  	Training Loss: 0.5425494313240051
Test Loss:  0.6492184400558472
Valid Loss:  0.6220988035202026
Epoch:  458  	Training Loss: 0.5425479412078857
Test Loss:  0.6492164731025696
Valid Loss:  0.622096836566925
Epoch:  459  	Training Loss: 0.5425463914871216
Test Loss:  0.6492145657539368
Valid Loss:  0.6220949292182922
Epoch:  460  	Training Loss: 0.5425449013710022
Test Loss:  0.649212658405304
Valid Loss:  0.6220929622650146
Epoch:  461  	Training Loss: 0.542543351650238
Test Loss:  0.6492106914520264
Valid Loss:  0.6220910549163818
Epoch:  462  	Training Loss: 0.5425418615341187
Test Loss:  0.6492087841033936
Valid Loss:  0.6220890283584595
Epoch:  463  	Training Loss: 0.5425403118133545
Test Loss:  0.649206817150116
Valid Loss:  0.6220870614051819
Epoch:  464  	Training Loss: 0.5425387620925903
Test Loss:  0.6492048501968384
Valid Loss:  0.6220850944519043
Epoch:  465  	Training Loss: 0.5425373315811157
Test Loss:  0.6492029428482056
Valid Loss:  0.6220831871032715
Epoch:  466  	Training Loss: 0.5425357818603516
Test Loss:  0.6492010354995728
Valid Loss:  0.6220811605453491
Epoch:  467  	Training Loss: 0.5425342321395874
Test Loss:  0.6491990089416504
Valid Loss:  0.6220791935920715
Epoch:  468  	Training Loss: 0.5425326824188232
Test Loss:  0.6491970419883728
Valid Loss:  0.622077226638794
Epoch:  469  	Training Loss: 0.5425311326980591
Test Loss:  0.6491950750350952
Valid Loss:  0.6220752000808716
Epoch:  470  	Training Loss: 0.5425295829772949
Test Loss:  0.6491931676864624
Valid Loss:  0.6220732927322388
Epoch:  471  	Training Loss: 0.5425280928611755
Test Loss:  0.6491912603378296
Valid Loss:  0.6220712661743164
Epoch:  472  	Training Loss: 0.5425265431404114
Test Loss:  0.6491893529891968
Valid Loss:  0.6220692992210388
Epoch:  473  	Training Loss: 0.542525053024292
Test Loss:  0.6491873860359192
Valid Loss:  0.6220673322677612
Epoch:  474  	Training Loss: 0.5425235033035278
Test Loss:  0.6491854190826416
Valid Loss:  0.6220654249191284
Epoch:  475  	Training Loss: 0.5425220131874084
Test Loss:  0.6491835117340088
Valid Loss:  0.6220635175704956
Epoch:  476  	Training Loss: 0.5425204634666443
Test Loss:  0.6491815447807312
Valid Loss:  0.6220614910125732
Epoch:  477  	Training Loss: 0.5425189733505249
Test Loss:  0.6491795778274536
Valid Loss:  0.6220595836639404
Epoch:  478  	Training Loss: 0.5425174236297607
Test Loss:  0.6491776704788208
Valid Loss:  0.6220576167106628
Epoch:  479  	Training Loss: 0.5425158739089966
Test Loss:  0.649175763130188
Valid Loss:  0.6220556497573853
Epoch:  480  	Training Loss: 0.5425143241882324
Test Loss:  0.6491738557815552
Valid Loss:  0.6220536231994629
Epoch:  481  	Training Loss: 0.542512834072113
Test Loss:  0.6491718292236328
Valid Loss:  0.6220517158508301
Epoch:  482  	Training Loss: 0.5425113439559937
Test Loss:  0.6491699814796448
Valid Loss:  0.6220498085021973
Epoch:  483  	Training Loss: 0.5425097942352295
Test Loss:  0.6491680145263672
Valid Loss:  0.6220477819442749
Epoch:  484  	Training Loss: 0.5425083637237549
Test Loss:  0.6491660475730896
Valid Loss:  0.6220458745956421
Epoch:  485  	Training Loss: 0.5425068140029907
Test Loss:  0.6491641998291016
Valid Loss:  0.6220439076423645
Epoch:  486  	Training Loss: 0.5425052642822266
Test Loss:  0.649162232875824
Valid Loss:  0.6220419406890869
Epoch:  487  	Training Loss: 0.5425037741661072
Test Loss:  0.6491603255271912
Valid Loss:  0.6220400333404541
Epoch:  488  	Training Loss: 0.5425022840499878
Test Loss:  0.6491584181785583
Valid Loss:  0.6220380663871765
Epoch:  489  	Training Loss: 0.5425007343292236
Test Loss:  0.6491564512252808
Valid Loss:  0.6220360994338989
Epoch:  490  	Training Loss: 0.5424992442131042
Test Loss:  0.649154543876648
Valid Loss:  0.6220341324806213
Epoch:  491  	Training Loss: 0.5424977540969849
Test Loss:  0.6491526365280151
Valid Loss:  0.6220321655273438
Epoch:  492  	Training Loss: 0.5424962043762207
Test Loss:  0.6491506695747375
Valid Loss:  0.6220302581787109
Epoch:  493  	Training Loss: 0.5424946546554565
Test Loss:  0.64914870262146
Valid Loss:  0.6220282912254333
Epoch:  494  	Training Loss: 0.5424932241439819
Test Loss:  0.6491467952728271
Valid Loss:  0.6220263242721558
Epoch:  495  	Training Loss: 0.5424916744232178
Test Loss:  0.6491448879241943
Valid Loss:  0.6220243573188782
Epoch:  496  	Training Loss: 0.5424901247024536
Test Loss:  0.6491429805755615
Valid Loss:  0.6220223903656006
Epoch:  497  	Training Loss: 0.542488694190979
Test Loss:  0.6491410136222839
Valid Loss:  0.6220204830169678
Epoch:  498  	Training Loss: 0.5424870848655701
Test Loss:  0.6491390466690063
Valid Loss:  0.6220184564590454
Epoch:  499  	Training Loss: 0.5424855947494507
Test Loss:  0.6491371393203735
Valid Loss:  0.6220165491104126
Epoch:  500  	Training Loss: 0.5424840450286865
Test Loss:  0.6491352319717407
Valid Loss:  0.622014582157135
seed is  19
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:21,  6.29s/it]  1%|          | 3/500 [00:06<13:57,  1.69s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:19<09:30,  1.19s/it]  5%|▍         | 23/500 [00:20<06:45,  1.18it/s]  5%|▌         | 25/500 [00:26<12:16,  1.55s/it]  5%|▌         | 27/500 [00:26<08:41,  1.10s/it]  6%|▌         | 29/500 [00:26<06:11,  1.27it/s]  6%|▌         | 31/500 [00:39<18:58,  2.43s/it]  7%|▋         | 33/500 [00:39<13:22,  1.72s/it]  7%|▋         | 35/500 [00:45<16:38,  2.15s/it]  7%|▋         | 37/500 [00:45<11:45,  1.52s/it]  8%|▊         | 39/500 [00:45<08:20,  1.09s/it]  8%|▊         | 39/500 [00:56<08:20,  1.09s/it]  8%|▊         | 41/500 [00:58<20:05,  2.63s/it]  9%|▊         | 43/500 [00:58<14:10,  1.86s/it]  9%|▉         | 45/500 [01:04<17:03,  2.25s/it]  9%|▉         | 47/500 [01:04<12:02,  1.60s/it] 10%|▉         | 49/500 [01:04<08:32,  1.14s/it] 10%|▉         | 49/500 [01:16<08:32,  1.14s/it] 10%|█         | 51/500 [01:17<20:07,  2.69s/it] 11%|█         | 53/500 [01:17<14:10,  1.90s/it] 11%|█         | 55/500 [01:23<16:47,  2.26s/it] 11%|█▏        | 57/500 [01:24<11:51,  1.61s/it] 12%|█▏        | 59/500 [01:24<08:24,  1.14s/it] 12%|█▏        | 59/500 [01:36<08:24,  1.14s/it] 12%|█▏        | 61/500 [01:36<19:29,  2.66s/it] 13%|█▎        | 63/500 [01:36<13:44,  1.89s/it]Epoch:  1  	Training Loss: 0.03900011256337166
Test Loss:  3.521993637084961
Valid Loss:  3.477771759033203
Epoch:  2  	Training Loss: 3.470102310180664
Test Loss:  7.5888566970825195
Valid Loss:  7.193782806396484
Epoch:  3  	Training Loss: 7.129059791564941
Test Loss:  0.0716743916273117
Valid Loss:  0.06772235780954361
Epoch:  4  	Training Loss: 0.05215485766530037
Test Loss:  0.07167357206344604
Valid Loss:  0.06772169470787048
Epoch:  5  	Training Loss: 0.05215389281511307
Test Loss:  0.07167288661003113
Valid Loss:  0.06772106885910034
Epoch:  6  	Training Loss: 0.052153024822473526
Test Loss:  0.07167227566242218
Valid Loss:  0.06772047281265259
Epoch:  7  	Training Loss: 0.05215220898389816
Test Loss:  0.0716717541217804
Valid Loss:  0.06772000342607498
Epoch:  8  	Training Loss: 0.052151571959257126
Test Loss:  0.07167129963636398
Valid Loss:  0.06771966814994812
Epoch:  9  	Training Loss: 0.05215108394622803
Test Loss:  0.07167088985443115
Valid Loss:  0.06771937757730484
Epoch:  10  	Training Loss: 0.05215068906545639
Test Loss:  0.07167059183120728
Valid Loss:  0.06771916896104813
Epoch:  11  	Training Loss: 0.05215039104223251
Test Loss:  0.07167032361030579
Valid Loss:  0.06771896779537201
Epoch:  12  	Training Loss: 0.05215013399720192
Test Loss:  0.07167002558708191
Valid Loss:  0.06771872192621231
Epoch:  13  	Training Loss: 0.052149832248687744
Test Loss:  0.0716698169708252
Valid Loss:  0.06771855801343918
Epoch:  14  	Training Loss: 0.052149660885334015
Test Loss:  0.07166965305805206
Valid Loss:  0.06771845370531082
Epoch:  15  	Training Loss: 0.05214954540133476
Test Loss:  0.0716695562005043
Valid Loss:  0.06771842390298843
Epoch:  16  	Training Loss: 0.05214948207139969
Test Loss:  0.07166951894760132
Valid Loss:  0.06771840900182724
Epoch:  17  	Training Loss: 0.052149463444948196
Test Loss:  0.07166951149702072
Valid Loss:  0.06771840900182724
Epoch:  18  	Training Loss: 0.0521494597196579
Test Loss:  0.07166950404644012
Valid Loss:  0.06771840155124664
Epoch:  19  	Training Loss: 0.0521494559943676
Test Loss:  0.07166950404644012
Valid Loss:  0.06771840155124664
Epoch:  20  	Training Loss: 0.0521494522690773
Test Loss:  0.07166949659585953
Valid Loss:  0.06771839410066605
Epoch:  21  	Training Loss: 0.052149444818496704
Test Loss:  0.07166949659585953
Valid Loss:  0.06771838665008545
Epoch:  22  	Training Loss: 0.052149444818496704
Test Loss:  0.07166948914527893
Valid Loss:  0.06771838665008545
Epoch:  23  	Training Loss: 0.05214943736791611
Test Loss:  0.07166948914527893
Valid Loss:  0.06771838665008545
Epoch:  24  	Training Loss: 0.05214943736791611
Test Loss:  0.07166948169469833
Valid Loss:  0.06771838665008545
Epoch:  25  	Training Loss: 0.05214943736791611
Test Loss:  0.07166948169469833
Valid Loss:  0.06771837174892426
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.05214942991733551
Test Loss:  0.07166948169469833
Valid Loss:  0.06771837174892426
Epoch:  27  	Training Loss: 0.05214942991733551
Test Loss:  0.07166947424411774
Valid Loss:  0.06771837174892426
Epoch:  28  	Training Loss: 0.05214942619204521
Test Loss:  0.07166946679353714
Valid Loss:  0.06771836429834366
Epoch:  29  	Training Loss: 0.05214942619204521
Test Loss:  0.07166947424411774
Valid Loss:  0.06771836429834366
Epoch:  30  	Training Loss: 0.05214942619204521
Test Loss:  0.07166947424411774
Valid Loss:  0.06771836429834366
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.05214942246675491
Test Loss:  0.07166946679353714
Valid Loss:  0.06771835684776306
Epoch:  32  	Training Loss: 0.05214942246675491
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  33  	Training Loss: 0.05214942246675491
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  34  	Training Loss: 0.05214942246675491
Test Loss:  0.07166946679353714
Valid Loss:  0.06771835684776306
Epoch:  35  	Training Loss: 0.052149418741464615
Test Loss:  0.07166946679353714
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.052149418741464615
Test Loss:  0.07166946679353714
Valid Loss:  0.06771835684776306
Epoch:  37  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  38  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  39  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  40  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  42  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  43  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  44  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  45  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  47  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  48  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  49  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834194660187
Epoch:  50  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  52  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  53  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  54  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  55  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834194660187
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  57  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  58  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  59  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  60  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  62  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  63  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  64  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:   13%|█▎        | 65/500 [01:43<16:29,  2.28s/it] 13%|█▎        | 67/500 [01:43<11:39,  1.61s/it] 14%|█▍        | 69/500 [01:43<08:15,  1.15s/it] 14%|█▍        | 71/500 [01:55<19:02,  2.66s/it] 15%|█▍        | 73/500 [01:55<13:24,  1.88s/it] 15%|█▌        | 75/500 [02:02<16:22,  2.31s/it] 15%|█▌        | 77/500 [02:02<11:33,  1.64s/it] 16%|█▌        | 79/500 [02:02<08:11,  1.17s/it] 16%|█▌        | 81/500 [02:15<19:08,  2.74s/it] 17%|█▋        | 83/500 [02:15<13:28,  1.94s/it] 17%|█▋        | 85/500 [02:22<15:57,  2.31s/it] 17%|█▋        | 87/500 [02:22<11:15,  1.64s/it] 18%|█▊        | 89/500 [02:22<07:58,  1.16s/it] 18%|█▊        | 91/500 [02:34<18:11,  2.67s/it] 19%|█▊        | 93/500 [02:34<12:49,  1.89s/it] 19%|█▉        | 95/500 [02:41<15:43,  2.33s/it] 19%|█▉        | 97/500 [02:41<11:06,  1.65s/it] 20%|█▉        | 99/500 [02:41<07:52,  1.18s/it] 20%|██        | 101/500 [02:54<17:53,  2.69s/it] 21%|██        | 103/500 [02:54<12:36,  1.90s/it] 21%|██        | 105/500 [03:00<15:07,  2.30s/it] 21%|██▏       | 107/500 [03:01<10:40,  1.63s/it] 22%|██▏       | 109/500 [03:01<07:33,  1.16s/it] 22%|██▏       | 111/500 [03:13<17:35,  2.71s/it] 23%|██▎       | 113/500 [03:14<12:23,  1.92s/it] 23%|██▎       | 115/500 [03:20<14:45,  2.30s/it] 23%|██▎       | 117/500 [03:20<10:24,  1.63s/it] 24%|██▍       | 119/500 [03:20<07:22,  1.16s/it] 24%|██▍       | 121/500 [03:33<16:58,  2.69s/it]0.06771834939718246
Epoch:  65  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  67  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  68  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  69  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  70  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  72  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  73  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  74  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  75  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  77  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  78  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  79  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  80  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  82  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  83  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  84  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  85  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  87  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  88  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  89  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  90  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  92  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  93  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  94  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  95  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  97  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  98  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  99  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  100  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  102  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  103  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  104  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  105  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  107  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  108  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  109  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  110  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  112  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  113  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  114  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  115  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  117  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  118  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  119  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  120  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  122  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  123  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:   25%|██▍       | 123/500 [03:33<11:57,  1.90s/it] 25%|██▌       | 125/500 [03:39<14:13,  2.28s/it] 25%|██▌       | 127/500 [03:39<10:01,  1.61s/it] 26%|██▌       | 129/500 [03:39<07:06,  1.15s/it] 26%|██▌       | 131/500 [03:52<16:40,  2.71s/it] 27%|██▋       | 133/500 [03:52<11:44,  1.92s/it] 27%|██▋       | 135/500 [03:59<14:01,  2.30s/it] 27%|██▋       | 137/500 [03:59<09:53,  1.63s/it] 28%|██▊       | 139/500 [03:59<07:00,  1.16s/it] 28%|██▊       | 141/500 [04:11<16:05,  2.69s/it] 29%|██▊       | 143/500 [04:12<11:20,  1.90s/it] 29%|██▉       | 145/500 [04:18<13:30,  2.28s/it] 29%|██▉       | 147/500 [04:18<09:31,  1.62s/it] 30%|██▉       | 149/500 [04:18<06:44,  1.15s/it] 30%|███       | 151/500 [04:31<15:35,  2.68s/it] 31%|███       | 153/500 [04:31<10:58,  1.90s/it] 31%|███       | 155/500 [04:37<13:01,  2.26s/it] 31%|███▏      | 157/500 [04:37<09:10,  1.61s/it] 32%|███▏      | 159/500 [04:37<06:29,  1.14s/it] 32%|███▏      | 161/500 [04:50<15:03,  2.66s/it] 33%|███▎      | 163/500 [04:50<10:35,  1.89s/it] 33%|███▎      | 165/500 [04:56<12:38,  2.26s/it] 33%|███▎      | 167/500 [04:56<08:54,  1.61s/it] 34%|███▍      | 169/500 [04:56<06:18,  1.14s/it] 34%|███▍      | 171/500 [05:09<14:36,  2.67s/it] 35%|███▍      | 173/500 [05:09<10:17,  1.89s/it] 35%|███▌      | 175/500 [05:15<12:18,  2.27s/it] 35%|███▌      | 177/500 [05:15<08:40,  1.61s/it] 36%|███▌      | 179/500 [05:16<06:08,  1.15s/it] 36%|███▌      | 179/500 [05:26<06:08,  1.15s/it] 36%|███▌      | 181/500 [05:28<14:14,  2.68s/it]0.06771834939718246
Epoch:  124  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  125  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  127  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  128  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  129  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  130  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  132  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  133  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  134  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  135  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  137  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  138  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  139  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  140  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  142  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  143  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  144  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  145  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  147  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  148  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  149  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  150  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  152  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  153  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  154  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  155  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  157  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  158  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  159  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  160  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  162  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  163  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  164  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  165  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  167  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  168  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  169  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  170  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  172  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  173  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  174  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  175  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  177  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  178  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  179  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  180  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  182  	Training Loss: 0.052149415016174316
Test Loss:   37%|███▋      | 183/500 [05:28<10:01,  1.90s/it] 37%|███▋      | 185/500 [05:35<11:58,  2.28s/it] 37%|███▋      | 187/500 [05:35<08:26,  1.62s/it] 38%|███▊      | 189/500 [05:35<05:58,  1.15s/it] 38%|███▊      | 189/500 [05:46<05:58,  1.15s/it] 38%|███▊      | 191/500 [05:47<13:48,  2.68s/it] 39%|███▊      | 193/500 [05:48<09:42,  1.90s/it] 39%|███▉      | 195/500 [05:54<11:31,  2.27s/it] 39%|███▉      | 197/500 [05:54<08:07,  1.61s/it] 40%|███▉      | 199/500 [05:54<05:44,  1.15s/it] 40%|███▉      | 199/500 [06:06<05:44,  1.15s/it] 40%|████      | 201/500 [06:07<13:27,  2.70s/it] 41%|████      | 203/500 [06:07<09:27,  1.91s/it] 41%|████      | 205/500 [06:13<11:19,  2.30s/it] 41%|████▏     | 207/500 [06:13<07:58,  1.63s/it] 42%|████▏     | 209/500 [06:14<05:38,  1.16s/it] 42%|████▏     | 211/500 [06:26<12:57,  2.69s/it] 43%|████▎     | 213/500 [06:26<09:06,  1.90s/it] 43%|████▎     | 215/500 [06:33<11:10,  2.35s/it] 43%|████▎     | 217/500 [06:33<07:51,  1.67s/it] 44%|████▍     | 219/500 [06:33<05:33,  1.19s/it] 44%|████▍     | 221/500 [06:46<12:39,  2.72s/it] 45%|████▍     | 223/500 [06:46<08:53,  1.93s/it] 45%|████▌     | 225/500 [06:52<10:29,  2.29s/it] 45%|████▌     | 227/500 [06:52<07:23,  1.62s/it] 46%|████▌     | 229/500 [06:53<05:13,  1.16s/it] 46%|████▌     | 231/500 [07:05<12:01,  2.68s/it] 47%|████▋     | 233/500 [07:05<08:26,  1.90s/it] 47%|████▋     | 235/500 [07:12<10:05,  2.28s/it] 47%|████▋     | 237/500 [07:12<07:06,  1.62s/it] 48%|████▊     | 239/500 [07:12<05:01,  1.15s/it]0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  183  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  184  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  185  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  187  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  188  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  189  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  190  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  192  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  193  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  194  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  195  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  197  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  198  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  199  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  200  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  202  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  203  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  204  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  205  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  207  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  208  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  209  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  210  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  212  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  213  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  214  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  215  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  217  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  218  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  219  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  220  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  222  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  223  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  224  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  225  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  227  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  228  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  229  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  230  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  232  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  233  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  234  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  235  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  237  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  238  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  239  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  240  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
 48%|████▊     | 241/500 [07:24<11:39,  2.70s/it] 49%|████▊     | 243/500 [07:25<08:11,  1.91s/it] 49%|████▉     | 245/500 [07:31<09:42,  2.28s/it] 49%|████▉     | 247/500 [07:31<06:49,  1.62s/it] 50%|████▉     | 249/500 [07:31<04:49,  1.15s/it] 50%|█████     | 251/500 [07:44<11:07,  2.68s/it] 51%|█████     | 253/500 [07:44<07:49,  1.90s/it] 51%|█████     | 255/500 [07:50<09:23,  2.30s/it] 51%|█████▏    | 257/500 [07:50<06:36,  1.63s/it] 52%|█████▏    | 259/500 [07:51<04:40,  1.16s/it] 52%|█████▏    | 261/500 [08:03<10:48,  2.71s/it] 53%|█████▎    | 263/500 [08:03<07:35,  1.92s/it] 53%|█████▎    | 265/500 [08:10<09:01,  2.30s/it] 53%|█████▎    | 267/500 [08:10<06:21,  1.64s/it] 54%|█████▍    | 269/500 [08:10<04:29,  1.17s/it] 54%|█████▍    | 271/500 [08:23<10:21,  2.71s/it] 55%|█████▍    | 273/500 [08:23<07:16,  1.92s/it] 55%|█████▌    | 275/500 [08:29<08:41,  2.32s/it] 55%|█████▌    | 277/500 [08:30<06:06,  1.64s/it] 56%|█████▌    | 279/500 [08:30<04:18,  1.17s/it] 56%|█████▌    | 281/500 [08:42<09:48,  2.69s/it] 57%|█████▋    | 283/500 [08:42<06:52,  1.90s/it] 57%|█████▋    | 285/500 [08:49<08:09,  2.28s/it] 57%|█████▋    | 287/500 [08:49<05:43,  1.61s/it] 58%|█████▊    | 289/500 [08:49<04:02,  1.15s/it] 58%|█████▊    | 291/500 [09:01<09:19,  2.68s/it] 59%|█████▊    | 293/500 [09:01<06:32,  1.90s/it] 59%|█████▉    | 295/500 [09:08<07:47,  2.28s/it] 59%|█████▉    | 297/500 [09:08<05:28,  1.62s/it] 60%|█████▉    | 299/500 [09:08<03:51,  1.15s/it]Epoch:  241  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  242  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  243  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  244  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  245  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  247  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  248  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  249  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  250  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  252  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  253  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  254  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  255  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  257  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  258  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  259  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  260  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  262  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  263  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  264  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  265  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  267  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  268  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  269  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  270  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  272  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  273  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  274  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  275  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  277  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  278  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  279  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  280  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  282  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  283  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  284  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  285  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  287  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  288  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  289  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  290  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  292  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  293  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  294  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  295  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  297  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  298  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  299  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  300  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
 60%|██████    | 301/500 [09:21<08:57,  2.70s/it] 61%|██████    | 303/500 [09:21<06:16,  1.91s/it] 61%|██████    | 305/500 [09:27<07:26,  2.29s/it] 61%|██████▏   | 307/500 [09:27<05:13,  1.62s/it] 62%|██████▏   | 309/500 [09:27<03:40,  1.16s/it] 62%|██████▏   | 311/500 [09:40<08:29,  2.69s/it] 63%|██████▎   | 313/500 [09:40<05:56,  1.91s/it] 63%|██████▎   | 315/500 [09:47<07:03,  2.29s/it] 63%|██████▎   | 317/500 [09:47<04:57,  1.62s/it] 64%|██████▍   | 319/500 [09:47<03:29,  1.16s/it] 64%|██████▍   | 321/500 [09:59<08:01,  2.69s/it] 65%|██████▍   | 323/500 [09:59<05:36,  1.90s/it] 65%|██████▌   | 325/500 [10:06<06:40,  2.29s/it] 65%|██████▌   | 327/500 [10:06<04:41,  1.62s/it] 66%|██████▌   | 329/500 [10:06<03:17,  1.16s/it] 66%|██████▌   | 329/500 [10:16<03:17,  1.16s/it] 66%|██████▌   | 331/500 [10:19<07:31,  2.67s/it] 67%|██████▋   | 333/500 [10:19<05:16,  1.89s/it] 67%|██████▋   | 335/500 [10:25<06:13,  2.26s/it] 67%|██████▋   | 337/500 [10:25<04:21,  1.61s/it] 68%|██████▊   | 339/500 [10:25<03:04,  1.14s/it] 68%|██████▊   | 339/500 [10:36<03:04,  1.14s/it] 68%|██████▊   | 341/500 [10:38<07:06,  2.68s/it] 69%|██████▊   | 343/500 [10:38<04:57,  1.90s/it] 69%|██████▉   | 345/500 [10:44<05:55,  2.29s/it] 69%|██████▉   | 347/500 [10:44<04:08,  1.63s/it] 70%|██████▉   | 349/500 [10:45<02:54,  1.16s/it] 70%|██████▉   | 349/500 [10:56<02:54,  1.16s/it] 70%|███████   | 351/500 [10:57<06:37,  2.67s/it] 71%|███████   | 353/500 [10:57<04:37,  1.89s/it] 71%|███████   | 355/500 [11:03<05:28,  2.26s/it] 71%|███████▏  | 357/500 [11:04<03:49,  1.60s/it]Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  302  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  303  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  304  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  305  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  307  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  308  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  309  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  310  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  312  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  313  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  314  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  315  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  317  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  318  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  319  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  320  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  322  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  323  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  324  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  325  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  327  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  328  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  329  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  330  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  332  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  333  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  334  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  335  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  337  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  338  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  339  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  340  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  342  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  343  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  344  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  345  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  347  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  348  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  349  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  350  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  352  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  353  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  354  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  355  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  357  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  358  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  359  	Training Loss: 0.052149415016174316 72%|███████▏  | 359/500 [11:04<02:41,  1.14s/it] 72%|███████▏  | 361/500 [11:16<06:09,  2.66s/it] 73%|███████▎  | 363/500 [11:16<04:18,  1.88s/it] 73%|███████▎  | 365/500 [11:22<05:05,  2.26s/it] 73%|███████▎  | 367/500 [11:23<03:33,  1.60s/it] 74%|███████▍  | 369/500 [11:23<02:29,  1.14s/it] 74%|███████▍  | 371/500 [11:35<05:43,  2.66s/it] 75%|███████▍  | 373/500 [11:35<03:59,  1.89s/it] 75%|███████▌  | 375/500 [11:42<04:43,  2.27s/it] 75%|███████▌  | 377/500 [11:42<03:17,  1.61s/it] 76%|███████▌  | 379/500 [11:42<02:18,  1.15s/it] 76%|███████▌  | 381/500 [11:54<05:18,  2.68s/it] 77%|███████▋  | 383/500 [11:55<03:41,  1.89s/it] 77%|███████▋  | 385/500 [12:01<04:21,  2.27s/it] 77%|███████▋  | 387/500 [12:01<03:01,  1.61s/it] 78%|███████▊  | 389/500 [12:01<02:07,  1.15s/it] 78%|███████▊  | 391/500 [12:14<04:50,  2.67s/it] 79%|███████▊  | 393/500 [12:14<03:22,  1.89s/it] 79%|███████▉  | 395/500 [12:20<04:00,  2.29s/it] 79%|███████▉  | 397/500 [12:20<02:47,  1.63s/it] 80%|███████▉  | 399/500 [12:20<01:56,  1.16s/it] 80%|████████  | 401/500 [12:33<04:30,  2.73s/it] 81%|████████  | 403/500 [12:33<03:07,  1.94s/it] 81%|████████  | 405/500 [12:40<03:38,  2.30s/it] 81%|████████▏ | 407/500 [12:40<02:31,  1.63s/it] 82%|████████▏ | 409/500 [12:40<01:45,  1.16s/it] 82%|████████▏ | 411/500 [12:52<03:59,  2.69s/it] 83%|████████▎ | 413/500 [12:53<02:45,  1.91s/it] 83%|████████▎ | 415/500 [12:59<03:14,  2.29s/it] 83%|████████▎ | 417/500 [12:59<02:15,  1.63s/it]
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  360  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  362  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  363  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  364  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  365  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  367  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  368  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  369  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  370  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  372  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  373  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  374  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  375  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  377  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  378  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  379  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  380  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  382  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  383  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  384  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  385  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  387  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  388  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  389  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  390  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  392  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  393  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  394  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  395  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  397  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  398  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  399  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  400  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  402  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  403  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  404  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  405  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  407  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  408  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  409  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  410  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  412  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  413  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  414  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  415  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  417  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
 84%|████████▍ | 419/500 [12:59<01:33,  1.16s/it] 84%|████████▍ | 421/500 [13:12<03:34,  2.72s/it] 85%|████████▍ | 423/500 [13:12<02:27,  1.92s/it] 85%|████████▌ | 425/500 [13:19<02:53,  2.32s/it] 85%|████████▌ | 427/500 [13:19<02:00,  1.64s/it] 86%|████████▌ | 429/500 [13:19<01:23,  1.17s/it] 86%|████████▌ | 431/500 [13:31<03:05,  2.69s/it] 87%|████████▋ | 433/500 [13:31<02:07,  1.90s/it] 87%|████████▋ | 435/500 [13:38<02:28,  2.28s/it] 87%|████████▋ | 437/500 [13:38<01:42,  1.62s/it] 88%|████████▊ | 439/500 [13:38<01:10,  1.15s/it] 88%|████████▊ | 441/500 [13:51<02:37,  2.67s/it] 89%|████████▊ | 443/500 [13:51<01:47,  1.89s/it] 89%|████████▉ | 445/500 [13:57<02:05,  2.28s/it] 89%|████████▉ | 447/500 [13:57<01:25,  1.62s/it] 90%|████████▉ | 449/500 [13:57<00:58,  1.15s/it] 90%|█████████ | 451/500 [14:10<02:10,  2.66s/it] 91%|█████████ | 453/500 [14:10<01:28,  1.88s/it] 91%|█████████ | 455/500 [14:16<01:41,  2.25s/it] 91%|█████████▏| 457/500 [14:16<01:08,  1.60s/it] 92%|█████████▏| 459/500 [14:16<00:46,  1.14s/it] 92%|█████████▏| 459/500 [14:26<00:46,  1.14s/it] 92%|█████████▏| 461/500 [14:29<01:46,  2.73s/it] 92%|█████████▏| 462/500 [14:29<01:26,  2.27s/it] 93%|█████████▎| 464/500 [14:29<00:55,  1.53s/it] 93%|█████████▎| 466/500 [14:36<01:09,  2.05s/it] 94%|█████████▎| 468/500 [14:36<00:45,  1.42s/it] 94%|█████████▍| 470/500 [14:42<00:58,  1.96s/it] 94%|█████████▍| 471/500 [14:48<01:19,  2.73s/it] 95%|█████████▍| 473/500 [14:48<00:49,  1.82s/it] 95%|█████████▌| 475/500 [14:55<00:56,  2.27s/it]Epoch:  418  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  419  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  420  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  422  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  423  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  424  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834194660187
Epoch:  425  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  427  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  428  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834194660187
Epoch:  429  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  430  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  432  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  433  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  434  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  435  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  437  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  438  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  439  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  440  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  442  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  443  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  444  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  445  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  447  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  448  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  449  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  450  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  452  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  453  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  454  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  455  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  457  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  458  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  459  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  460  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  462  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  463  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  464  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  465  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  467  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
Epoch:  468  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  469  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  470  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  472  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  473  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  474  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  475  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
 95%|█████████▌| 477/500 [14:55<00:36,  1.57s/it] 96%|█████████▌| 479/500 [14:55<00:23,  1.10s/it] 96%|█████████▌| 479/500 [15:06<00:23,  1.10s/it] 96%|█████████▌| 481/500 [15:07<00:50,  2.67s/it] 97%|█████████▋| 483/500 [15:08<00:31,  1.88s/it] 97%|█████████▋| 485/500 [15:14<00:33,  2.26s/it] 97%|█████████▋| 487/500 [15:14<00:20,  1.60s/it] 98%|█████████▊| 489/500 [15:14<00:12,  1.14s/it] 98%|█████████▊| 489/500 [15:26<00:12,  1.14s/it] 98%|█████████▊| 491/500 [15:27<00:24,  2.68s/it] 99%|█████████▊| 493/500 [15:27<00:13,  1.89s/it] 99%|█████████▉| 495/500 [15:33<00:11,  2.26s/it] 99%|█████████▉| 497/500 [15:33<00:04,  1.61s/it]100%|█████████▉| 499/500 [15:33<00:01,  1.14s/it]100%|██████████| 500/500 [15:40<00:00,  1.88s/it]
Valid Loss:  0.06771835684776306
Epoch:  477  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  478  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  479  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  480  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  482  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  483  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  484  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  485  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  487  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  488  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  489  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  490  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.052149418741464615
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  492  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945189237595
Valid Loss:  0.06771835684776306
Epoch:  493  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  494  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  495  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  497  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  498  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771834939718246
Epoch:  499  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
Epoch:  500  	Training Loss: 0.052149415016174316
Test Loss:  0.07166945934295654
Valid Loss:  0.06771835684776306
**************************************************learning rate decay**************************************************
seed is  20
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:31,  6.20s/it]  1%|          | 3/500 [00:06<13:44,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.95it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:12<10:44,  1.32s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:34,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:26,  1.21s/it]  7%|▋         | 33/500 [00:26<06:44,  1.15it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:31,  2.18it/s]  8%|▊         | 39/500 [00:27<02:37,  2.93it/s]  8%|▊         | 41/500 [00:33<08:59,  1.18s/it]  9%|▊         | 43/500 [00:33<06:25,  1.19it/s]  9%|▉         | 45/500 [00:40<11:35,  1.53s/it]  9%|▉         | 47/500 [00:40<08:14,  1.09s/it] 10%|▉         | 49/500 [00:40<05:53,  1.28it/s] 10%|▉         | 49/500 [00:50<05:53,  1.28it/s] 10%|█         | 51/500 [00:52<18:11,  2.43s/it] 11%|█         | 53/500 [00:52<12:50,  1.72s/it] 11%|█         | 55/500 [00:59<15:49,  2.13s/it] 11%|█▏        | 57/500 [00:59<11:11,  1.52s/it] 12%|█▏        | 59/500 [00:59<07:56,  1.08s/it] 12%|█▏        | 59/500 [01:10<07:56,  1.08s/it] 12%|█▏        | 61/500 [01:12<20:03,  2.74s/it] 13%|█▎        | 63/500 [01:12<14:08,  1.94s/it] 13%|█▎        | 65/500 [01:19<16:42,  2.30s/it] 13%|█▎        | 67/500 [01:19<11:47,  1.63s/it]Epoch:  1  	Training Loss: 0.20486688613891602
Test Loss:  9.60688591003418
Valid Loss:  9.351274490356445
Epoch:  2  	Training Loss: 9.463878631591797
Test Loss:  0.28445956110954285
Valid Loss:  0.2687353491783142
Epoch:  3  	Training Loss: 0.2228018194437027
Test Loss:  0.27255332469940186
Valid Loss:  0.25728458166122437
Epoch:  4  	Training Loss: 0.21303832530975342
Test Loss:  0.2611662745475769
Valid Loss:  0.24633869528770447
Epoch:  5  	Training Loss: 0.20371666550636292
Test Loss:  0.25027552247047424
Valid Loss:  0.23587526381015778
Epoch:  6  	Training Loss: 0.19481687247753143
Test Loss:  0.24145588278770447
Valid Loss:  0.2285289168357849
Epoch:  7  	Training Loss: 0.1876835823059082
Test Loss:  0.23752400279045105
Valid Loss:  0.22527894377708435
Epoch:  8  	Training Loss: 0.18402424454689026
Test Loss:  0.23497644066810608
Valid Loss:  0.22278711199760437
Epoch:  9  	Training Loss: 0.18162190914154053
Test Loss:  0.2327427864074707
Valid Loss:  0.2206304669380188
Epoch:  10  	Training Loss: 0.17964892089366913
Test Loss:  0.23071587085723877
Valid Loss:  0.21862995624542236
Epoch:  11  	Training Loss: 0.17788751423358917
Test Loss:  0.22887234389781952
Valid Loss:  0.21675334870815277
Epoch:  12  	Training Loss: 0.17632469534873962
Test Loss:  0.22865188121795654
Valid Loss:  0.2163710594177246
Epoch:  13  	Training Loss: 0.17606471478939056
Test Loss:  0.22860144078731537
Valid Loss:  0.21625544130802155
Epoch:  14  	Training Loss: 0.1759650558233261
Test Loss:  0.22858315706253052
Valid Loss:  0.2162134051322937
Epoch:  15  	Training Loss: 0.1759190708398819
Test Loss:  0.22857500612735748
Valid Loss:  0.21619106829166412
Epoch:  16  	Training Loss: 0.17589357495307922
Test Loss:  0.22857066988945007
Valid Loss:  0.2161814421415329
Epoch:  17  	Training Loss: 0.1758754402399063
Test Loss:  0.2285667210817337
Valid Loss:  0.21617719531059265
Epoch:  18  	Training Loss: 0.17585903406143188
Test Loss:  0.22856490314006805
Valid Loss:  0.21617402136325836
Epoch:  19  	Training Loss: 0.17584346234798431
Test Loss:  0.22856329381465912
Valid Loss:  0.21617114543914795
Epoch:  20  	Training Loss: 0.17583097517490387
Test Loss:  0.2285633534193039
Valid Loss:  0.2161688506603241
Epoch:  21  	Training Loss: 0.17582203447818756
Test Loss:  0.22856341302394867
Valid Loss:  0.21616679430007935
Epoch:  22  	Training Loss: 0.17581546306610107
Test Loss:  0.22856341302394867
Valid Loss:  0.21616527438163757
Epoch:  23  	Training Loss: 0.1758110523223877
Test Loss:  0.22856339812278748
Valid Loss:  0.21616512537002563
Epoch:  24  	Training Loss: 0.17580801248550415
Test Loss:  0.22856339812278748
Valid Loss:  0.21616514027118683
Epoch:  25  	Training Loss: 0.17580676078796387
Test Loss:  0.22856339812278748
Valid Loss:  0.21616512537002563
Epoch:  26  	Training Loss: 0.17580583691596985
Test Loss:  0.22856339812278748
Valid Loss:  0.21616512537002563
Epoch:  27  	Training Loss: 0.1758050173521042
Test Loss:  0.22856341302394867
Valid Loss:  0.21616512537002563
Epoch:  28  	Training Loss: 0.17580440640449524
Test Loss:  0.22856342792510986
Valid Loss:  0.21616515517234802
Epoch:  29  	Training Loss: 0.17580389976501465
Test Loss:  0.22856341302394867
Valid Loss:  0.21616514027118683
Epoch:  30  	Training Loss: 0.17580348253250122
Test Loss:  0.22856342792510986
Valid Loss:  0.21616514027118683
Epoch:  31  	Training Loss: 0.17580316960811615
Test Loss:  0.22856342792510986
Valid Loss:  0.21616515517234802
Epoch:  32  	Training Loss: 0.17580291628837585
Test Loss:  0.22856345772743225
Valid Loss:  0.21616517007350922
Epoch:  33  	Training Loss: 0.17580267786979675
Test Loss:  0.22856347262859344
Valid Loss:  0.2161651849746704
Epoch:  34  	Training Loss: 0.17580243945121765
Test Loss:  0.22856348752975464
Valid Loss:  0.2161651998758316
Epoch:  35  	Training Loss: 0.17580220103263855
Test Loss:  0.22856348752975464
Valid Loss:  0.2161652147769928
Epoch:  36  	Training Loss: 0.17580202221870422
Test Loss:  0.22856350243091583
Valid Loss:  0.2161652147769928
Epoch:  37  	Training Loss: 0.17580191791057587
Test Loss:  0.22856350243091583
Valid Loss:  0.2161652147769928
Epoch:  38  	Training Loss: 0.17580190300941467
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
Epoch:  39  	Training Loss: 0.17580188810825348
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
Epoch:  40  	Training Loss: 0.17580187320709229
Test Loss:  0.22856350243091583
Valid Loss:  0.2161652147769928
Epoch:  41  	Training Loss: 0.17580187320709229
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
Epoch:  42  	Training Loss: 0.1758018583059311
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  43  	Training Loss: 0.1758018583059311
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  44  	Training Loss: 0.1758018434047699
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  45  	Training Loss: 0.1758018434047699
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.1758018434047699
Test Loss:  0.22856350243091583
Valid Loss:  0.2161652147769928
Epoch:  47  	Training Loss: 0.1758018434047699
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  48  	Training Loss: 0.1758018434047699
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  49  	Training Loss: 0.1758018434047699
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  50  	Training Loss: 0.1758018434047699
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  52  	Training Loss: 0.1758018434047699
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  53  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  54  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  55  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  57  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  58  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  59  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  60  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  62  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  63  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  64  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  65  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  67  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  68  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
 14%|█▍        | 69/500 [01:19<08:21,  1.16s/it] 14%|█▍        | 69/500 [01:30<08:21,  1.16s/it] 14%|█▍        | 71/500 [01:31<19:10,  2.68s/it] 15%|█▍        | 73/500 [01:31<13:30,  1.90s/it] 15%|█▌        | 75/500 [01:38<16:14,  2.29s/it] 15%|█▌        | 77/500 [01:38<11:27,  1.63s/it] 16%|█▌        | 79/500 [01:38<08:07,  1.16s/it] 16%|█▌        | 79/500 [01:50<08:07,  1.16s/it] 16%|█▌        | 81/500 [01:51<18:40,  2.67s/it] 17%|█▋        | 83/500 [01:51<13:09,  1.89s/it] 17%|█▋        | 85/500 [01:57<15:38,  2.26s/it] 17%|█▋        | 87/500 [01:57<11:02,  1.60s/it] 18%|█▊        | 89/500 [01:57<07:49,  1.14s/it] 18%|█▊        | 91/500 [02:10<18:09,  2.66s/it] 19%|█▊        | 93/500 [02:10<12:47,  1.88s/it] 19%|█▉        | 95/500 [02:16<15:14,  2.26s/it] 19%|█▉        | 97/500 [02:16<10:45,  1.60s/it] 20%|█▉        | 99/500 [02:16<07:37,  1.14s/it] 20%|██        | 101/500 [02:29<17:40,  2.66s/it] 21%|██        | 103/500 [02:29<12:27,  1.88s/it] 21%|██        | 105/500 [02:35<14:52,  2.26s/it] 21%|██▏       | 107/500 [02:35<10:29,  1.60s/it] 22%|██▏       | 109/500 [02:35<07:26,  1.14s/it] 22%|██▏       | 111/500 [02:48<17:14,  2.66s/it] 23%|██▎       | 113/500 [02:48<12:08,  1.88s/it] 23%|██▎       | 115/500 [02:54<14:32,  2.27s/it] 23%|██▎       | 117/500 [02:54<10:15,  1.61s/it] 24%|██▍       | 119/500 [02:55<07:16,  1.14s/it] 24%|██▍       | 121/500 [03:07<17:04,  2.70s/it] 25%|██▍       | 123/500 [03:07<12:01,  1.91s/it] 25%|██▌       | 125/500 [03:14<14:18,  2.29s/it] 25%|██▌       | 127/500 [03:14<10:06,  1.62s/it]Epoch:  69  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  70  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  72  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  73  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  74  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  75  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  77  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  78  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  79  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  80  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  82  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  83  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  84  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  85  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  87  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  88  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  89  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  90  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  92  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  93  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  94  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  95  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  97  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  98  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  99  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  100  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  102  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  103  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  104  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  105  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  107  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  108  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  109  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  110  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  112  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  113  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  114  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  115  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  117  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  118  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  119  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  120  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  122  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  123  	Training Loss: 0.1758018434047699
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  124  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  125  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  127  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  128  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  129  	Training Loss: 0.1758018136024475
Test Loss:   26%|██▌       | 129/500 [03:14<07:09,  1.16s/it] 26%|██▌       | 131/500 [03:26<16:25,  2.67s/it] 27%|██▋       | 133/500 [03:27<11:33,  1.89s/it] 27%|██▋       | 135/500 [03:33<13:51,  2.28s/it] 27%|██▋       | 137/500 [03:33<09:46,  1.61s/it] 28%|██▊       | 139/500 [03:33<06:55,  1.15s/it] 28%|██▊       | 141/500 [03:46<16:05,  2.69s/it] 29%|██▊       | 143/500 [03:46<11:19,  1.90s/it] 29%|██▉       | 145/500 [03:52<13:31,  2.29s/it] 29%|██▉       | 147/500 [03:52<09:32,  1.62s/it] 30%|██▉       | 149/500 [03:53<06:45,  1.15s/it] 30%|███       | 151/500 [04:05<15:39,  2.69s/it] 31%|███       | 153/500 [04:05<11:01,  1.91s/it] 31%|███       | 155/500 [04:12<13:06,  2.28s/it] 31%|███▏      | 157/500 [04:12<09:14,  1.62s/it] 32%|███▏      | 159/500 [04:12<06:32,  1.15s/it] 32%|███▏      | 161/500 [04:24<15:14,  2.70s/it] 33%|███▎      | 163/500 [04:25<10:43,  1.91s/it] 33%|███▎      | 165/500 [04:31<12:44,  2.28s/it] 33%|███▎      | 167/500 [04:31<08:59,  1.62s/it] 34%|███▍      | 169/500 [04:31<06:21,  1.15s/it] 34%|███▍      | 171/500 [04:44<14:47,  2.70s/it] 35%|███▍      | 173/500 [04:44<10:24,  1.91s/it] 35%|███▌      | 175/500 [04:50<12:28,  2.30s/it] 35%|███▌      | 177/500 [04:50<08:47,  1.63s/it] 36%|███▌      | 179/500 [04:51<06:13,  1.16s/it] 36%|███▌      | 181/500 [05:03<14:33,  2.74s/it] 37%|███▋      | 183/500 [05:04<10:14,  1.94s/it] 37%|███▋      | 185/500 [05:10<12:08,  2.31s/it] 37%|███▋      | 187/500 [05:10<08:33,  1.64s/it]0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  130  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  132  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  133  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  134  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  135  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  137  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  138  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  139  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  140  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  142  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  143  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  144  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  145  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  147  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  148  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  149  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  150  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  152  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  153  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  154  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  155  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  157  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  158  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  159  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  160  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  162  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  163  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  164  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
Epoch:  165  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  167  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  168  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  169  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  170  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  172  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  173  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  174  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  175  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  177  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  178  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  179  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  180  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  182  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  183  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  184  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  185  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  187  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  188  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  189  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:   38%|███▊      | 189/500 [05:10<06:03,  1.17s/it] 38%|███▊      | 189/500 [05:20<06:03,  1.17s/it] 38%|███▊      | 191/500 [05:23<14:08,  2.75s/it] 39%|███▊      | 193/500 [05:23<09:56,  1.94s/it] 39%|███▉      | 195/500 [05:30<11:52,  2.34s/it] 39%|███▉      | 197/500 [05:30<08:22,  1.66s/it] 40%|███▉      | 199/500 [05:30<05:55,  1.18s/it] 40%|███▉      | 199/500 [05:40<05:55,  1.18s/it] 40%|████      | 201/500 [05:42<13:27,  2.70s/it] 41%|████      | 203/500 [05:43<09:27,  1.91s/it] 41%|████      | 205/500 [05:49<11:18,  2.30s/it] 41%|████▏     | 207/500 [05:49<07:57,  1.63s/it] 42%|████▏     | 209/500 [05:49<05:37,  1.16s/it] 42%|████▏     | 209/500 [06:00<05:37,  1.16s/it] 42%|████▏     | 211/500 [06:02<12:52,  2.67s/it] 43%|████▎     | 213/500 [06:02<09:03,  1.89s/it] 43%|████▎     | 215/500 [06:08<10:51,  2.29s/it] 43%|████▎     | 217/500 [06:08<07:38,  1.62s/it] 44%|████▍     | 219/500 [06:09<05:25,  1.16s/it] 44%|████▍     | 219/500 [06:20<05:25,  1.16s/it] 44%|████▍     | 221/500 [06:21<12:41,  2.73s/it] 45%|████▍     | 223/500 [06:21<08:55,  1.93s/it] 45%|████▌     | 225/500 [06:28<10:39,  2.33s/it] 45%|████▌     | 227/500 [06:28<07:30,  1.65s/it] 46%|████▌     | 229/500 [06:28<05:18,  1.17s/it] 46%|████▌     | 229/500 [06:40<05:18,  1.17s/it] 46%|████▌     | 231/500 [06:41<12:11,  2.72s/it] 47%|████▋     | 233/500 [06:41<08:33,  1.92s/it] 47%|████▋     | 235/500 [06:47<10:05,  2.29s/it] 47%|████▋     | 237/500 [06:47<07:06,  1.62s/it] 48%|████▊     | 239/500 [06:48<05:01,  1.15s/it] 48%|████▊     | 241/500 [07:00<11:43,  2.72s/it] 49%|████▊     | 243/500 [07:00<08:14,  1.92s/it] 49%|████▉     | 245/500 [07:07<09:45,  2.30s/it] 49%|████▉     | 247/500 [07:07<06:52,  1.63s/it] 50%|████▉     | 249/500 [07:07<04:51,  1.16s/it]0.216165229678154
Epoch:  190  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  192  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  193  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  194  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  195  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  197  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  198  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  199  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  200  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  202  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  203  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  204  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  205  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  207  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  208  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  209  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  210  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  212  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  213  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  214  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  215  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  217  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  218  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  219  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
Epoch:  220  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  222  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  223  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  224  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  225  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  227  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  228  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  229  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  230  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  232  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  233  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  234  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
Epoch:  235  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  237  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  238  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  239  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  240  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  242  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  243  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  244  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  245  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  247  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  248  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  249  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
 50%|█████     | 251/500 [07:20<11:16,  2.72s/it] 51%|█████     | 253/500 [07:20<07:54,  1.92s/it] 51%|█████     | 255/500 [07:26<09:20,  2.29s/it] 51%|█████▏    | 257/500 [07:26<06:34,  1.62s/it] 52%|█████▏    | 259/500 [07:26<04:38,  1.16s/it] 52%|█████▏    | 261/500 [07:39<10:47,  2.71s/it] 53%|█████▎    | 263/500 [07:39<07:34,  1.92s/it] 53%|█████▎    | 265/500 [07:46<09:07,  2.33s/it] 53%|█████▎    | 267/500 [07:46<06:24,  1.65s/it] 54%|█████▍    | 269/500 [07:46<04:32,  1.18s/it] 54%|█████▍    | 271/500 [07:59<10:16,  2.69s/it] 55%|█████▍    | 273/500 [07:59<07:12,  1.90s/it] 55%|█████▌    | 275/500 [08:05<08:32,  2.28s/it] 55%|█████▌    | 277/500 [08:05<06:00,  1.62s/it] 56%|█████▌    | 279/500 [08:05<04:14,  1.15s/it] 56%|█████▌    | 281/500 [08:18<09:44,  2.67s/it] 57%|█████▋    | 283/500 [08:18<06:50,  1.89s/it] 57%|█████▋    | 285/500 [08:24<08:07,  2.27s/it] 57%|█████▋    | 287/500 [08:24<05:42,  1.61s/it] 58%|█████▊    | 289/500 [08:24<04:01,  1.15s/it] 58%|█████▊    | 291/500 [08:37<09:15,  2.66s/it] 59%|█████▊    | 293/500 [08:37<06:29,  1.88s/it] 59%|█████▉    | 295/500 [08:43<07:42,  2.26s/it] 59%|█████▉    | 297/500 [08:43<05:25,  1.60s/it] 60%|█████▉    | 299/500 [08:43<03:49,  1.14s/it] 60%|██████    | 301/500 [08:56<08:53,  2.68s/it] 61%|██████    | 303/500 [08:56<06:13,  1.90s/it] 61%|██████    | 305/500 [09:02<07:22,  2.27s/it] 61%|██████▏   | 307/500 [09:03<05:10,  1.61s/it] 62%|██████▏   | 309/500 [09:03<03:38,  1.15s/it]Epoch:  250  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  252  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  253  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  254  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  255  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  257  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  258  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  259  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  260  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  262  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  263  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  264  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  265  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  267  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  268  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  269  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  270  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  272  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  273  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  274  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  275  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  277  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  278  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  279  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  280  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  282  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  283  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  284  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  285  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  287  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  288  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  289  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  290  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  292  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  293  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  294  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  295  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  297  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  298  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  299  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  300  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  302  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  303  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  304  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  305  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
Epoch:  307  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  308  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  309  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
 62%|██████▏   | 311/500 [09:15<08:30,  2.70s/it] 63%|██████▎   | 313/500 [09:15<05:57,  1.91s/it] 63%|██████▎   | 315/500 [09:22<07:06,  2.31s/it] 63%|██████▎   | 317/500 [09:22<04:59,  1.64s/it] 64%|██████▍   | 319/500 [09:22<03:31,  1.17s/it] 64%|██████▍   | 321/500 [09:35<08:00,  2.68s/it] 65%|██████▍   | 323/500 [09:35<05:36,  1.90s/it] 65%|██████▌   | 325/500 [09:41<06:41,  2.29s/it] 65%|██████▌   | 327/500 [09:41<04:41,  1.63s/it] 66%|██████▌   | 329/500 [09:42<03:18,  1.16s/it] 66%|██████▌   | 331/500 [09:54<07:34,  2.69s/it] 67%|██████▋   | 333/500 [09:54<05:18,  1.90s/it] 67%|██████▋   | 335/500 [10:01<06:16,  2.28s/it] 67%|██████▋   | 337/500 [10:01<04:24,  1.62s/it] 68%|██████▊   | 339/500 [10:01<03:06,  1.16s/it] 68%|██████▊   | 341/500 [10:13<07:10,  2.71s/it] 69%|██████▊   | 343/500 [10:14<05:00,  1.92s/it] 69%|██████▉   | 345/500 [10:20<06:00,  2.32s/it] 69%|██████▉   | 347/500 [10:20<04:12,  1.65s/it] 70%|██████▉   | 349/500 [10:20<02:57,  1.17s/it] 70%|██████▉   | 349/500 [10:31<02:57,  1.17s/it] 70%|███████   | 351/500 [10:33<06:50,  2.75s/it] 71%|███████   | 353/500 [10:33<04:46,  1.95s/it] 71%|███████   | 355/500 [10:40<05:36,  2.32s/it] 71%|███████▏  | 357/500 [10:40<03:55,  1.65s/it] 72%|███████▏  | 359/500 [10:40<02:45,  1.17s/it] 72%|███████▏  | 359/500 [10:51<02:45,  1.17s/it] 72%|███████▏  | 361/500 [10:53<06:20,  2.74s/it] 73%|███████▎  | 363/500 [10:53<04:25,  1.94s/it] 73%|███████▎  | 365/500 [10:59<05:11,  2.30s/it] 73%|███████▎  | 367/500 [11:00<03:37,  1.64s/it] 74%|███████▍  | 369/500 [11:00<02:32,  1.17s/it]Epoch:  310  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  312  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  313  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  314  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  315  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  317  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  318  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  319  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  320  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  322  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  323  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  324  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  325  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  327  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  328  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  329  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  330  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  332  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  333  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  334  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  335  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  337  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  338  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  339  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  340  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  342  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  343  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  344  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  345  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  347  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  348  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  349  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  350  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  352  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  353  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  354  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  355  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  357  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  358  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  359  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  360  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  362  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  363  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  364  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  365  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  367  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  368  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  369  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
 74%|███████▍  | 369/500 [11:11<02:32,  1.17s/it] 74%|███████▍  | 371/500 [11:12<05:50,  2.72s/it] 75%|███████▍  | 373/500 [11:13<04:04,  1.93s/it] 75%|███████▌  | 375/500 [11:19<04:50,  2.32s/it] 75%|███████▌  | 377/500 [11:19<03:22,  1.65s/it] 76%|███████▌  | 379/500 [11:19<02:22,  1.17s/it] 76%|███████▌  | 379/500 [11:31<02:22,  1.17s/it] 76%|███████▌  | 381/500 [11:32<05:21,  2.70s/it] 77%|███████▋  | 383/500 [11:32<03:44,  1.91s/it] 77%|███████▋  | 385/500 [11:38<04:23,  2.30s/it] 77%|███████▋  | 387/500 [11:38<03:04,  1.63s/it] 78%|███████▊  | 389/500 [11:39<02:08,  1.16s/it] 78%|███████▊  | 389/500 [11:51<02:08,  1.16s/it] 78%|███████▊  | 391/500 [11:51<04:55,  2.71s/it] 79%|███████▊  | 393/500 [11:51<03:25,  1.92s/it] 79%|███████▉  | 395/500 [11:58<04:00,  2.29s/it] 79%|███████▉  | 397/500 [11:58<02:47,  1.63s/it] 80%|███████▉  | 399/500 [11:58<01:57,  1.16s/it] 80%|███████▉  | 399/500 [12:11<01:57,  1.16s/it] 80%|████████  | 401/500 [12:11<04:26,  2.70s/it] 81%|████████  | 403/500 [12:11<03:05,  1.91s/it] 81%|████████  | 405/500 [12:17<03:36,  2.28s/it] 81%|████████▏ | 407/500 [12:17<02:30,  1.62s/it] 82%|████████▏ | 409/500 [12:17<01:44,  1.15s/it] 82%|████████▏ | 411/500 [12:30<03:59,  2.69s/it] 83%|████████▎ | 413/500 [12:30<02:45,  1.90s/it] 83%|████████▎ | 415/500 [12:36<03:14,  2.29s/it] 83%|████████▎ | 417/500 [12:37<02:15,  1.63s/it] 84%|████████▍ | 419/500 [12:37<01:33,  1.16s/it] 84%|████████▍ | 421/500 [12:49<03:32,  2.69s/it] 85%|████████▍ | 423/500 [12:49<02:26,  1.90s/it] 85%|████████▌ | 425/500 [12:56<02:52,  2.31s/it] 85%|████████▌ | 427/500 [12:56<01:59,  1.64s/it] 86%|████████▌ | 429/500 [12:56<01:22,  1.16s/it]Epoch:  370  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  372  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  373  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  374  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  375  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  377  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  378  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  379  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  380  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  382  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  383  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  384  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  385  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  387  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  388  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  389  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  390  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  392  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  393  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  394  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  395  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  397  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  398  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  399  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  400  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  402  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  403  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  404  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
Epoch:  405  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  407  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  408  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  409  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  410  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  412  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  413  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  414  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  415  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  417  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  418  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  419  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  420  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  422  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  423  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  424  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  425  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  427  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  428  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  429  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
 86%|████████▌ | 431/500 [13:09<03:08,  2.73s/it] 87%|████████▋ | 433/500 [13:09<02:09,  1.93s/it] 87%|████████▋ | 435/500 [13:15<02:30,  2.31s/it] 87%|████████▋ | 437/500 [13:16<01:43,  1.64s/it] 88%|████████▊ | 439/500 [13:16<01:11,  1.17s/it] 88%|████████▊ | 441/500 [13:28<02:40,  2.72s/it] 89%|████████▊ | 443/500 [13:29<01:49,  1.92s/it] 89%|████████▉ | 445/500 [13:35<02:05,  2.29s/it] 89%|████████▉ | 447/500 [13:35<01:26,  1.63s/it] 90%|████████▉ | 449/500 [13:35<00:59,  1.16s/it] 90%|█████████ | 451/500 [13:48<02:13,  2.73s/it] 91%|█████████ | 453/500 [13:48<01:30,  1.93s/it] 91%|█████████ | 455/500 [13:54<01:44,  2.31s/it] 91%|█████████▏| 457/500 [13:55<01:10,  1.64s/it] 92%|█████████▏| 459/500 [13:55<00:47,  1.17s/it] 92%|█████████▏| 461/500 [14:07<01:46,  2.73s/it] 93%|█████████▎| 463/500 [14:08<01:11,  1.93s/it] 93%|█████████▎| 465/500 [14:14<01:20,  2.30s/it] 93%|█████████▎| 467/500 [14:14<00:53,  1.63s/it] 94%|█████████▍| 469/500 [14:14<00:36,  1.16s/it] 94%|█████████▍| 471/500 [14:27<01:19,  2.74s/it] 95%|█████████▍| 473/500 [14:27<00:52,  1.94s/it] 95%|█████████▌| 475/500 [14:34<00:57,  2.32s/it] 95%|█████████▌| 477/500 [14:34<00:37,  1.64s/it] 96%|█████████▌| 479/500 [14:34<00:24,  1.17s/it] 96%|█████████▌| 481/500 [14:47<00:52,  2.76s/it] 97%|█████████▋| 483/500 [14:47<00:33,  1.95s/it] 97%|█████████▋| 485/500 [14:54<00:35,  2.36s/it] 97%|█████████▋| 487/500 [14:54<00:21,  1.68s/it] 98%|█████████▊| 489/500 [14:54<00:13,  1.20s/it]Epoch:  430  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  432  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  433  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  434  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  435  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  437  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  438  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  439  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.2161652147769928
Epoch:  440  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  442  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  443  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  444  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  445  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  447  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  448  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  449  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  450  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  452  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  453  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  454  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  455  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  457  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  458  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  459  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  460  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  462  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  463  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  464  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  465  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  467  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  468  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  469  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  470  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  472  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  473  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  474  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  475  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  477  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  478  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  479  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  480  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  482  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.21616524457931519
Epoch:  483  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  484  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  485  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  487  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  488  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  489  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
 98%|█████████▊| 491/500 [15:07<00:24,  2.76s/it] 99%|█████████▊| 493/500 [15:07<00:13,  1.96s/it] 99%|█████████▉| 495/500 [15:13<00:11,  2.35s/it] 99%|█████████▉| 497/500 [15:14<00:04,  1.66s/it]100%|█████████▉| 499/500 [15:14<00:01,  1.18s/it]100%|██████████| 500/500 [15:20<00:00,  1.84s/it]
Epoch:  490  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  492  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  493  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  494  	Training Loss: 0.1758018136024475
Test Loss:  0.22856350243091583
Valid Loss:  0.2161652147769928
Epoch:  495  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.21616524457931519
Epoch:  497  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  498  	Training Loss: 0.1758018136024475
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
Epoch:  499  	Training Loss: 0.1758018285036087
Test Loss:  0.22856350243091583
Valid Loss:  0.216165229678154
Epoch:  500  	Training Loss: 0.1758018285036087
Test Loss:  0.22856351733207703
Valid Loss:  0.216165229678154
**************************************************learning rate decay**************************************************
