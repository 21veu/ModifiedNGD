/nishome/yui/ModifiedNGD/utils/readData.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/nishome/yui/anaconda3/envs/ng/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971214/work/torch/csrc/autograd/engine.cpp:1203.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Train info: 
 train data shape: torch.Size([512, 1]), 
 train lable shape: torch.Size([512, 1]), 
 positive / negative: 0.021206805482506752 / 0.978793203830719, 
 discrepancy norm error: 5.045955617788422e-07
Test info: 
 test data shape: torch.Size([128, 1]), 
 test lable shape: torch.Size([128, 1]), , 
 positive / negative: -0.030759211629629135 / 1.0307592153549194, 
 discrepancy norm error: 2.750667249529215e-07
Valid info: 
 valid data shape: torch.Size([128, 1]), valid lable shape: torch.Size([128, 1]), 
 positive / negative: 0.015859205275774002 / 0.9841408133506775, 
 discrepancy norm error: 2.3576444618811365e-07
torch.Size([512, 1]) torch.Size([512])
seed is  2191
---------------------------------------- NGD ----------------------------------------
OUTPUT CHECK:  torch.Size([512]) tensor(0.0937, device='cuda:0', grad_fn=<MaxBackward1>) tensor(-0.1901, device='cuda:0', grad_fn=<MinBackward1>) 
TARGET:  torch.Size([512]) tensor(0.5000, device='cuda:0') tensor(-0.5000, device='cuda:0')
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
  0%|          | 0/10 [00:00<?, ?it/s]Epoch:   1
Test train Loss:  0.05449257045984268
Test train Acc:  0.0
Test Loss:  0.06031211465597153
Test Acc:  0.0
Valid Loss:  0.05577273666858673
Valid Acc:  0.0
max of grad d_p:  tensor(0.0083, device='cuda:0')
min of grad d_p:  tensor(-0.0802, device='cuda:0')
max|min: (J_L, Jta/N)  (0.008287940174341202, 0.052107591181993484, ratio: 6.287158012390137)|(-0.08016137778759003, -0.08016137778759003)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.0489, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0453, device='cuda:0') norm:  tensor(1.3526, device='cuda:0') MSE:  tensor(5.0778e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0003, device='cuda:0') mean:  tensor(5.8413e-06, device='cuda:0') min:  tensor(1.3188e-11, device='cuda:0') norm:  tensor(0.0070, device='cuda:0') MSE:  tensor(2.6311e-08, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0009, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  1  
Training Loss: 0.054324741664459
Test Loss:  0.06003829091787338
Test Acc:  0.0
Valid Loss:  0.05550341308116913
Valid Acc:  0.0
local minima detector shape:  (0,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 10%|█         | 1/10 [00:02<00:21,  2.43s/it]Epoch:   2
max of grad d_p:  tensor(0.0082, device='cuda:0')
min of grad d_p:  tensor(-0.0797, device='cuda:0')
max|min: (J_L, Jta/N)  (0.008217890746891499, 0.0448896549642086, ratio: 5.462430477142334)|(-0.0797366052865982, -0.0797366127371788)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.0398, device='cuda:0') mean:  tensor(-9.4799e-05, device='cuda:0') min:  tensor(-0.0382, device='cuda:0') norm:  tensor(1.1477, device='cuda:0') MSE:  tensor(4.3088e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0015, device='cuda:0') mean:  tensor(2.4431e-05, device='cuda:0') min:  tensor(1.0004e-11, device='cuda:0') norm:  tensor(0.0259, device='cuda:0') MSE:  tensor(9.7251e-08, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0129, device='cuda:0')
min of d_p_list:  tensor(-0.0099, device='cuda:0')
Epoch:  2  
Training Loss: 0.05796631798148155
Test Loss:  0.06050661578774452
Test Acc:  0.0
Valid Loss:  0.057128455489873886
Valid Acc:  0.0
local minima detector shape:  (1,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 20%|██        | 2/10 [00:04<00:19,  2.41s/it]Epoch:   3
max of grad d_p:  tensor(0.0338, device='cuda:0')
min of grad d_p:  tensor(-0.0312, device='cuda:0')
max|min: (J_L, Jta/N)  (0.03382394462823868, 0.00963436160236597, ratio: 0.2848384976387024)|(-0.031238796189427376, -0.012728311121463776)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.0466, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0409, device='cuda:0') norm:  tensor(1.0751, device='cuda:0') MSE:  tensor(4.0363e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0007, device='cuda:0') mean:  tensor(8.0604e-06, device='cuda:0') min:  tensor(5.4570e-12, device='cuda:0') norm:  tensor(0.0101, device='cuda:0') MSE:  tensor(3.8015e-08, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0013, device='cuda:0')
min of d_p_list:  tensor(-0.0007, device='cuda:0')
Epoch:  3  
Training Loss: 0.05768905580043793
Test Loss:  0.060285359621047974
Test Acc:  0.0
Valid Loss:  0.05688776820898056
Valid Acc:  0.0
local minima detector shape:  (2,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 30%|███       | 3/10 [00:07<00:16,  2.40s/it]Epoch:   4
max of grad d_p:  tensor(0.0328, device='cuda:0')
min of grad d_p:  tensor(-0.0311, device='cuda:0')
max|min: (J_L, Jta/N)  (0.03283213824033737, 0.0068435026332736015, ratio: 0.20843914151191711)|(-0.031144287437200546, -0.01165967620909214)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.0419, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0380, device='cuda:0') norm:  tensor(0.9953, device='cuda:0') MSE:  tensor(3.7366e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0010, device='cuda:0') mean:  tensor(1.1088e-05, device='cuda:0') min:  tensor(3.6380e-12, device='cuda:0') norm:  tensor(0.0160, device='cuda:0') MSE:  tensor(6.0128e-08, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0030, device='cuda:0')
min of d_p_list:  tensor(-0.0023, device='cuda:0')
Epoch:  4  
Training Loss: 0.057343143969774246
Test Loss:  0.05998382344841957
Test Acc:  0.0
Valid Loss:  0.05658866837620735
Valid Acc:  0.0
local minima detector shape:  (3,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 40%|████      | 4/10 [00:09<00:14,  2.40s/it]Epoch:   5
max of grad d_p:  tensor(0.0457, device='cuda:0')
min of grad d_p:  tensor(-0.0323, device='cuda:0')
max|min: (J_L, Jta/N)  (0.04572322964668274, 0.010922030545771122, ratio: 0.2388726770877838)|(-0.03228891268372536, -0.01829945482313633)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.0640, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0432, device='cuda:0') norm:  tensor(1.1521, device='cuda:0') MSE:  tensor(4.3253e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0045, device='cuda:0') mean:  tensor(3.9171e-05, device='cuda:0') min:  tensor(1.4779e-12, device='cuda:0') norm:  tensor(0.0704, device='cuda:0') MSE:  tensor(2.6446e-07, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0086, device='cuda:0')
min of d_p_list:  tensor(-0.0071, device='cuda:0')
Epoch:  5  
Training Loss: 0.05672318488359451
Test Loss:  0.059458956122398376
Test Acc:  0.0
Valid Loss:  0.05609983578324318
Valid Acc:  0.0
local minima detector shape:  (4,)
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 50%|█████     | 5/10 [00:12<00:12,  2.40s/it]Epoch:   6
max of grad d_p:  tensor(0.0736, device='cuda:0')
min of grad d_p:  tensor(-0.0345, device='cuda:0')
max|min: (J_L, Jta/N)  (0.07362799346446991, 0.005264424718916416, ratio: 0.07150031626224518)|(-0.034461915493011475, -0.013166001997888088)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.0868, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0397, device='cuda:0') norm:  tensor(1.0694, device='cuda:0') MSE:  tensor(4.0147e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0012, device='cuda:0') mean:  tensor(8.5544e-06, device='cuda:0') min:  tensor(4.2064e-12, device='cuda:0') norm:  tensor(0.0125, device='cuda:0') MSE:  tensor(4.6789e-08, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0008, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  6  
Training Loss: 0.056396372616291046
Test Loss:  0.05918499454855919
Test Acc:  0.0
Valid Loss:  0.05580426752567291
Valid Acc:  0.0
std:  0.0005860529489456129 
thres:  5.722361505031586e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 60%|██████    | 6/10 [00:14<00:09,  2.41s/it]Epoch:   7
max of grad d_p:  tensor(0.0753, device='cuda:0')
min of grad d_p:  tensor(-0.0341, device='cuda:0')
max|min: (J_L, Jta/N)  (0.07530484348535538, 0.007307812571525574, ratio: 0.09704305976629257)|(-0.03407140076160431, -0.018407804891467094)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.0937, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0414, device='cuda:0') norm:  tensor(1.1336, device='cuda:0') MSE:  tensor(4.2558e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0013, device='cuda:0') mean:  tensor(9.2300e-06, device='cuda:0') min:  tensor(6.1391e-12, device='cuda:0') norm:  tensor(0.0130, device='cuda:0') MSE:  tensor(4.8924e-08, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0025, device='cuda:0')
min of d_p_list:  tensor(-0.0015, device='cuda:0')
Epoch:  7  
Training Loss: 0.056104451417922974
Test Loss:  0.058943573385477066
Test Acc:  0.0
Valid Loss:  0.05554927513003349
Valid Acc:  0.0
std:  0.0005873500603300349 
thres:  5.6851241737604145e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 70%|███████   | 7/10 [00:16<00:07,  2.41s/it]Epoch:   8
max of grad d_p:  tensor(0.0775, device='cuda:0')
min of grad d_p:  tensor(-0.0339, device='cuda:0')
max|min: (J_L, Jta/N)  (0.07754732668399811, 0.019270475953817368, ratio: 0.2484995573759079)|(-0.03390612080693245, -0.04625611752271652)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.1238, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0532, device='cuda:0') norm:  tensor(1.4648, device='cuda:0') MSE:  tensor(5.4991e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0026, device='cuda:0') mean:  tensor(1.4228e-05, device='cuda:0') min:  tensor(4.5475e-12, device='cuda:0') norm:  tensor(0.0216, device='cuda:0') MSE:  tensor(8.1085e-08, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0011, device='cuda:0')
Epoch:  8  
Training Loss: 0.055809296667575836
Test Loss:  0.058698657900094986
Test Acc:  0.0
Valid Loss:  0.055288173258304596
Valid Acc:  0.0
std:  0.0005295127406223622 
thres:  5.647528991103172e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 80%|████████  | 8/10 [00:19<00:04,  2.40s/it]Epoch:   9
max of grad d_p:  tensor(0.0801, device='cuda:0')
min of grad d_p:  tensor(-0.0337, device='cuda:0')
max|min: (J_L, Jta/N)  (0.08008374273777008, 0.01913660205900669, ratio: 0.23895739018917084)|(-0.033689163625240326, -0.048502206802368164)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.1286, device='cuda:0') mean:  tensor(-0.0002, device='cuda:0') min:  tensor(-0.0528, device='cuda:0') norm:  tensor(1.4655, device='cuda:0') MSE:  tensor(5.5018e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0005, device='cuda:0') mean:  tensor(5.9459e-06, device='cuda:0') min:  tensor(0., device='cuda:0') norm:  tensor(0.0071, device='cuda:0') MSE:  tensor(2.6470e-08, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0037, device='cuda:0')
min of d_p_list:  tensor(-0.0063, device='cuda:0')
Epoch:  9  
Training Loss: 0.05568099021911621
Test Loss:  0.05855880305171013
Test Acc:  0.0
Valid Loss:  0.05513109266757965
Valid Acc:  0.0
std:  0.00038134211085137605 
thres:  5.614285916090012e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
 90%|█████████ | 9/10 [00:21<00:02,  2.39s/it]Epoch:   10
max of grad d_p:  tensor(0.0787, device='cuda:0')
min of grad d_p:  tensor(-0.0334, device='cuda:0')
max|min: (J_L, Jta/N)  (0.07868297398090363, 0.0039737289771437645, ratio: 0.05050303414463997)|(-0.0333932489156723, -0.012501017190515995)

 check Jacobi res:  torch.Size([266369]) max:  tensor(0.0912, device='cuda:0') mean:  tensor(-0.0001, device='cuda:0') min:  tensor(-0.0371, device='cuda:0') norm:  tensor(1.0774, device='cuda:0') MSE:  tensor(4.0447e-06, device='cuda:0')
BAD Jacobian OCCURS!

 check NTK dimension reduction res:  torch.Size([266369, 1]) max:  tensor(0.0029, device='cuda:0') mean:  tensor(1.7804e-05, device='cuda:0') min:  tensor(1.1369e-12, device='cuda:0') norm:  tensor(0.0293, device='cuda:0') MSE:  tensor(1.0995e-07, device='cuda:0')
Shape check:  torch.Size([266369, 1])
max of d_p_list:  tensor(0.0015, device='cuda:0')
min of d_p_list:  tensor(-0.0012, device='cuda:0')
Epoch:  10  
Training Loss: 0.05536782741546631
Test Loss:  0.0582890585064888
Test Acc:  0.0
Valid Loss:  0.05485114827752113
Valid Acc:  0.0
std:  0.0003531590339408399 
thres:  5.587178766727448e-05
Preserved_eigens number check:  512
max of Lambda2 tensor(1000., device='cuda:0')
min of Lambda2 tensor(0.0100, device='cuda:0')
eigenvalues preserved:  512
100%|██████████| 10/10 [00:23<00:00,  2.37s/it]100%|██████████| 10/10 [00:23<00:00,  2.39s/it]
