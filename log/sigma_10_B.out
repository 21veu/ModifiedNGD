train data shape torch.Size([256, 2])
train label shape torch.Size([256, 1])
torch.Size([256, 3])
train_data shape torch.Size([3])
seed is  1
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]/home/yuyi/Documents/ModifiedNGD/utils/readData.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
  0%|          | 1/500 [00:00<03:25,  2.43it/s]  1%|          | 3/500 [00:00<01:17,  6.44it/s]  1%|          | 5/500 [00:00<00:53,  9.30it/s]  1%|▏         | 7/500 [00:00<00:45, 10.95it/s]  2%|▏         | 9/500 [00:00<00:43, 11.40it/s]  2%|▏         | 11/500 [00:01<00:41, 11.87it/s]  3%|▎         | 13/500 [00:01<00:40, 11.93it/s]  3%|▎         | 15/500 [00:01<00:40, 11.99it/s]  3%|▎         | 17/500 [00:01<00:40, 11.99it/s]  4%|▍         | 19/500 [00:01<00:40, 12.01it/s]  4%|▍         | 21/500 [00:01<00:39, 12.04it/s]  5%|▍         | 23/500 [00:02<00:39, 12.20it/s]  5%|▌         | 25/500 [00:02<00:38, 12.27it/s]  5%|▌         | 27/500 [00:02<00:38, 12.31it/s]  6%|▌         | 29/500 [00:02<00:38, 12.33it/s]  6%|▌         | 31/500 [00:02<00:37, 12.34it/s]  7%|▋         | 33/500 [00:02<00:37, 12.30it/s]  7%|▋         | 35/500 [00:03<00:37, 12.30it/s]  7%|▋         | 37/500 [00:03<00:37, 12.29it/s]  8%|▊         | 39/500 [00:03<00:37, 12.30it/s]  8%|▊         | 41/500 [00:03<00:37, 12.29it/s]  9%|▊         | 43/500 [00:03<00:37, 12.32it/s]  9%|▉         | 45/500 [00:03<00:36, 12.32it/s]  9%|▉         | 47/500 [00:04<00:36, 12.27it/s] 10%|▉         | 49/500 [00:04<00:36, 12.26it/s] 10%|█         | 51/500 [00:04<00:36, 12.22it/s] 11%|█         | 53/500 [00:04<00:36, 12.25it/s] 11%|█         | 55/500 [00:04<00:36, 12.28it/s] 11%|█▏        | 57/500 [00:04<00:35, 12.36it/s] 12%|█▏        | 59/500 [00:05<00:35, 12.39it/s] 12%|█▏        | 61/500 [00:05<00:35, 12.44it/s] 13%|█▎        | 63/500 [00:05<00:34, 12.50it/s] 13%|█▎        | 65/500 [00:05<00:34, 12.69it/s] 13%|█▎        | 67/500 [00:05<00:34, 12.58it/s] 14%|█▍        | 69/500 [00:05<00:34, 12.50it/s] 14%|█▍        | 71/500 [00:05<00:34, 12.45it/s] 15%|█▍        | 73/500 [00:06<00:34, 12.43it/s] 15%|█▌        | 75/500 [00:06<00:34, 12.38it/s] 15%|█▌        | 77/500 [00:06<00:34, 12.37it/s] 16%|█▌        | 79/500 [00:06<00:34, 12.36it/s] 16%|█▌        | 81/500 [00:06<00:33, 12.33it/s] 17%|█▋        | 83/500 [00:06<00:33, 12.32it/s] 17%|█▋        | 85/500 [00:07<00:33, 12.30it/s] 17%|█▋        | 87/500 [00:07<00:33, 12.30it/s] 18%|█▊        | 89/500 [00:07<00:33, 12.31it/s] 18%|█▊        | 91/500 [00:07<00:33, 12.30it/s] 19%|█▊        | 93/500 [00:07<00:32, 12.57it/s] 19%|█▉        | 95/500 [00:07<00:30, 13.46it/s] 19%|█▉        | 97/500 [00:08<00:28, 14.19it/s] 20%|█▉        | 99/500 [00:08<00:27, 14.74it/s] 20%|██        | 101/500 [00:08<00:26, 14.94it/s] 21%|██        | 103/500 [00:08<00:25, 15.31it/s] 21%|██        | 105/500 [00:08<00:25, 15.46it/s] 21%|██▏       | 107/500 [00:08<00:27, 14.14it/s] 22%|██▏       | 109/500 [00:08<00:29, 13.35it/s] 22%|██▏       | 111/500 [00:09<00:30, 12.86it/s] 23%|██▎       | 113/500 [00:09<00:30, 12.60it/s] 23%|██▎       | 115/500 [00:09<00:30, 12.45it/s] 23%|██▎       | 117/500 [00:09<00:30, 12.40it/s] 24%|██▍       | 119/500 [00:09<00:30, 12.34it/s] 24%|██▍       | 121/500 [00:09<00:30, 12.30it/s] 25%|██▍       | 123/500 [00:10<00:30, 12.32it/s]Epoch:  1  	Training Loss: 0.027675705030560493
Test Loss:  1.53990638256073
Valid Loss:  1.5244417190551758
Epoch:  2  	Training Loss: 1.4870660305023193
Test Loss:  108599.796875
Valid Loss:  107676.0625
Epoch:  3  	Training Loss: 106423.890625
Test Loss:  4.41926710865732e+25
Valid Loss:  4.387154094236603e+25
Epoch:  4  	Training Loss: 4.357226557820018e+25
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
 25%|██▌       | 125/500 [00:10<00:30, 12.23it/s] 25%|██▌       | 127/500 [00:10<00:29, 12.74it/s] 26%|██▌       | 129/500 [00:10<00:27, 13.65it/s] 26%|██▌       | 131/500 [00:10<00:25, 14.32it/s] 27%|██▋       | 133/500 [00:10<00:24, 14.90it/s] 27%|██▋       | 135/500 [00:10<00:23, 15.23it/s] 27%|██▋       | 137/500 [00:10<00:23, 15.57it/s] 28%|██▊       | 139/500 [00:11<00:22, 15.77it/s] 28%|██▊       | 141/500 [00:11<00:22, 15.92it/s] 29%|██▊       | 143/500 [00:11<00:22, 15.99it/s] 29%|██▉       | 145/500 [00:11<00:22, 16.07it/s] 29%|██▉       | 147/500 [00:11<00:21, 16.12it/s] 30%|██▉       | 149/500 [00:11<00:21, 16.12it/s] 30%|███       | 151/500 [00:11<00:21, 16.15it/s] 31%|███       | 153/500 [00:11<00:21, 16.15it/s] 31%|███       | 155/500 [00:12<00:21, 16.18it/s] 31%|███▏      | 157/500 [00:12<00:21, 16.12it/s] 32%|███▏      | 159/500 [00:12<00:21, 16.12it/s] 32%|███▏      | 161/500 [00:12<00:20, 16.15it/s] 33%|███▎      | 163/500 [00:12<00:20, 16.06it/s] 33%|███▎      | 165/500 [00:12<00:20, 16.08it/s] 33%|███▎      | 167/500 [00:12<00:20, 16.10it/s] 34%|███▍      | 169/500 [00:12<00:20, 16.14it/s] 34%|███▍      | 171/500 [00:13<00:20, 16.17it/s] 35%|███▍      | 173/500 [00:13<00:20, 16.13it/s] 35%|███▌      | 175/500 [00:13<00:20, 16.12it/s] 35%|███▌      | 177/500 [00:13<00:20, 16.15it/s] 36%|███▌      | 179/500 [00:13<00:19, 16.08it/s] 36%|███▌      | 181/500 [00:13<00:19, 15.99it/s] 37%|███▋      | 183/500 [00:13<00:19, 15.95it/s] 37%|███▋      | 185/500 [00:13<00:19, 15.91it/s] 37%|███▋      | 187/500 [00:14<00:19, 15.99it/s] 38%|███▊      | 189/500 [00:14<00:19, 16.03it/s] 38%|███▊      | 191/500 [00:14<00:19, 16.11it/s] 39%|███▊      | 193/500 [00:14<00:19, 16.14it/s] 39%|███▉      | 195/500 [00:14<00:18, 16.19it/s] 39%|███▉      | 197/500 [00:14<00:18, 16.08it/s] 40%|███▉      | 199/500 [00:14<00:18, 16.06it/s] 40%|████      | 201/500 [00:15<00:31,  9.62it/s] 41%|████      | 203/500 [00:15<00:38,  7.74it/s] 41%|████      | 205/500 [00:15<00:34,  8.55it/s] 41%|████▏     | 207/500 [00:15<00:29,  9.86it/s] 42%|████▏     | 209/500 [00:15<00:26, 11.14it/s] 42%|████▏     | 211/500 [00:16<00:23, 12.23it/s] 43%|████▎     | 213/500 [00:16<00:21, 13.08it/s] 43%|████▎     | 215/500 [00:16<00:20, 13.73it/s] 43%|████▎     | 217/500 [00:16<00:21, 13.19it/s] 44%|████▍     | 219/500 [00:16<00:22, 12.50it/s] 44%|████▍     | 221/500 [00:16<00:22, 12.26it/s] 45%|████▍     | 223/500 [00:17<00:22, 12.20it/s] 45%|████▌     | 225/500 [00:17<00:22, 12.13it/s] 45%|████▌     | 227/500 [00:17<00:22, 12.09it/s] 46%|████▌     | 229/500 [00:17<00:22, 12.07it/s] 46%|████▌     | 231/500 [00:17<00:22, 12.15it/s] 47%|████▋     | 233/500 [00:17<00:21, 12.21it/s] 47%|████▋     | 235/500 [00:18<00:21, 12.27it/s] 47%|████▋     | 237/500 [00:18<00:21, 12.30it/s] 48%|████▊     | 239/500 [00:18<00:21, 12.31it/s] 48%|████▊     | 241/500 [00:18<00:21, 12.31it/s] 49%|████▊     | 243/500 [00:18<00:20, 12.32it/s] 49%|████▉     | 245/500 [00:18<00:20, 12.33it/s] 49%|████▉     | 247/500 [00:19<00:20, 12.32it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
 50%|████▉     | 249/500 [00:19<00:20, 12.32it/s] 50%|█████     | 251/500 [00:19<00:20, 12.31it/s] 51%|█████     | 253/500 [00:19<00:20, 12.30it/s] 51%|█████     | 255/500 [00:19<00:19, 12.29it/s] 51%|█████▏    | 257/500 [00:19<00:19, 12.29it/s] 52%|█████▏    | 259/500 [00:19<00:18, 13.10it/s] 52%|█████▏    | 261/500 [00:20<00:17, 13.34it/s] 53%|█████▎    | 263/500 [00:20<00:16, 14.00it/s] 53%|█████▎    | 265/500 [00:20<00:16, 14.58it/s] 53%|█████▎    | 267/500 [00:20<00:15, 14.76it/s] 54%|█████▍    | 269/500 [00:20<00:16, 13.61it/s] 54%|█████▍    | 271/500 [00:20<00:17, 13.22it/s] 55%|█████▍    | 273/500 [00:20<00:16, 13.76it/s] 55%|█████▌    | 275/500 [00:21<00:17, 13.23it/s] 55%|█████▌    | 277/500 [00:21<00:17, 12.93it/s] 56%|█████▌    | 279/500 [00:21<00:17, 12.72it/s] 56%|█████▌    | 281/500 [00:21<00:17, 12.60it/s] 57%|█████▋    | 283/500 [00:21<00:17, 12.51it/s] 57%|█████▋    | 285/500 [00:21<00:16, 12.81it/s] 57%|█████▋    | 287/500 [00:22<00:16, 12.66it/s] 58%|█████▊    | 289/500 [00:22<00:16, 12.66it/s] 58%|█████▊    | 291/500 [00:22<00:20, 10.24it/s] 59%|█████▊    | 293/500 [00:22<00:19, 10.73it/s] 59%|█████▉    | 295/500 [00:22<00:18, 11.16it/s] 59%|█████▉    | 297/500 [00:23<00:17, 11.45it/s] 60%|█████▉    | 299/500 [00:23<00:16, 12.07it/s] 60%|██████    | 301/500 [00:23<00:15, 12.74it/s] 61%|██████    | 303/500 [00:23<00:14, 13.37it/s] 61%|██████    | 305/500 [00:23<00:13, 14.09it/s] 61%|██████▏   | 307/500 [00:23<00:13, 14.40it/s] 62%|██████▏   | 309/500 [00:23<00:12, 14.78it/s] 62%|██████▏   | 311/500 [00:23<00:12, 15.21it/s] 63%|██████▎   | 313/500 [00:24<00:12, 15.29it/s] 63%|██████▎   | 315/500 [00:24<00:12, 15.37it/s] 63%|██████▎   | 317/500 [00:24<00:11, 15.49it/s] 64%|██████▍   | 319/500 [00:24<00:11, 15.75it/s] 64%|██████▍   | 321/500 [00:24<00:11, 14.98it/s] 65%|██████▍   | 323/500 [00:24<00:11, 15.03it/s] 65%|██████▌   | 325/500 [00:24<00:11, 15.20it/s] 65%|██████▌   | 327/500 [00:24<00:11, 14.97it/s] 66%|██████▌   | 329/500 [00:25<00:12, 14.03it/s] 66%|██████▌   | 331/500 [00:25<00:12, 13.46it/s] 67%|██████▋   | 333/500 [00:25<00:12, 13.09it/s] 67%|██████▋   | 335/500 [00:25<00:11, 13.85it/s] 67%|██████▋   | 337/500 [00:25<00:11, 14.13it/s] 68%|██████▊   | 339/500 [00:25<00:10, 14.68it/s] 68%|██████▊   | 341/500 [00:25<00:10, 14.98it/s] 69%|██████▊   | 343/500 [00:26<00:10, 15.14it/s] 69%|██████▉   | 345/500 [00:26<00:10, 15.32it/s] 69%|██████▉   | 347/500 [00:26<00:09, 15.36it/s] 70%|██████▉   | 349/500 [00:26<00:10, 13.91it/s] 70%|███████   | 351/500 [00:26<00:10, 14.34it/s] 71%|███████   | 353/500 [00:26<00:09, 14.88it/s] 71%|███████   | 355/500 [00:26<00:09, 14.86it/s] 71%|███████▏  | 357/500 [00:27<00:09, 15.29it/s] 72%|███████▏  | 359/500 [00:27<00:09, 15.53it/s] 72%|███████▏  | 361/500 [00:27<00:08, 15.76it/s] 73%|███████▎  | 363/500 [00:27<00:08, 15.79it/s] 73%|███████▎  | 365/500 [00:27<00:08, 15.68it/s] 73%|███████▎  | 367/500 [00:27<00:08, 15.89it/s] 74%|███████▍  | 369/500 [00:27<00:08, 15.90it/s] 74%|███████▍  | 371/500 [00:27<00:08, 15.97it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
 75%|███████▍  | 373/500 [00:28<00:07, 16.07it/s] 75%|███████▌  | 375/500 [00:28<00:07, 16.14it/s] 75%|███████▌  | 377/500 [00:28<00:07, 16.04it/s] 76%|███████▌  | 379/500 [00:28<00:07, 16.05it/s] 76%|███████▌  | 381/500 [00:28<00:07, 16.08it/s] 77%|███████▋  | 383/500 [00:28<00:07, 15.84it/s] 77%|███████▋  | 385/500 [00:28<00:07, 15.95it/s] 77%|███████▋  | 387/500 [00:28<00:07, 15.79it/s] 78%|███████▊  | 389/500 [00:29<00:06, 15.94it/s] 78%|███████▊  | 391/500 [00:29<00:06, 15.90it/s] 79%|███████▊  | 393/500 [00:29<00:07, 15.23it/s] 79%|███████▉  | 395/500 [00:29<00:07, 14.08it/s] 79%|███████▉  | 397/500 [00:29<00:07, 13.49it/s] 80%|███████▉  | 399/500 [00:29<00:07, 13.11it/s] 80%|████████  | 401/500 [00:29<00:07, 12.82it/s] 81%|████████  | 403/500 [00:30<00:07, 12.66it/s] 81%|████████  | 405/500 [00:30<00:07, 12.77it/s] 81%|████████▏ | 407/500 [00:30<00:07, 12.60it/s] 82%|████████▏ | 409/500 [00:30<00:07, 12.42it/s] 82%|████████▏ | 411/500 [00:30<00:07, 12.37it/s] 83%|████████▎ | 413/500 [00:30<00:07, 12.29it/s] 83%|████████▎ | 415/500 [00:31<00:06, 12.33it/s] 83%|████████▎ | 417/500 [00:31<00:06, 12.31it/s] 84%|████████▍ | 419/500 [00:31<00:06, 12.30it/s] 84%|████████▍ | 421/500 [00:31<00:06, 12.30it/s] 85%|████████▍ | 423/500 [00:31<00:06, 12.33it/s] 85%|████████▌ | 425/500 [00:31<00:06, 12.26it/s] 85%|████████▌ | 427/500 [00:32<00:05, 12.30it/s] 86%|████████▌ | 429/500 [00:32<00:05, 12.32it/s] 86%|████████▌ | 431/500 [00:32<00:05, 12.27it/s] 87%|████████▋ | 433/500 [00:32<00:05, 12.30it/s] 87%|████████▋ | 435/500 [00:32<00:05, 12.31it/s] 87%|████████▋ | 437/500 [00:32<00:05, 12.35it/s] 88%|████████▊ | 439/500 [00:33<00:04, 12.32it/s] 88%|████████▊ | 441/500 [00:33<00:04, 12.32it/s] 89%|████████▊ | 443/500 [00:33<00:04, 12.32it/s] 89%|████████▉ | 445/500 [00:33<00:04, 12.30it/s] 89%|████████▉ | 447/500 [00:33<00:04, 12.33it/s] 90%|████████▉ | 449/500 [00:33<00:04, 12.27it/s] 90%|█████████ | 451/500 [00:34<00:03, 12.29it/s] 91%|█████████ | 453/500 [00:34<00:03, 12.22it/s] 91%|█████████ | 455/500 [00:34<00:03, 12.26it/s] 91%|█████████▏| 457/500 [00:34<00:03, 12.27it/s] 92%|█████████▏| 459/500 [00:34<00:03, 12.30it/s] 92%|█████████▏| 461/500 [00:34<00:03, 12.28it/s] 93%|█████████▎| 463/500 [00:35<00:03, 12.31it/s] 93%|█████████▎| 465/500 [00:35<00:02, 12.32it/s] 93%|█████████▎| 467/500 [00:35<00:02, 12.27it/s] 94%|█████████▍| 469/500 [00:35<00:02, 12.31it/s] 94%|█████████▍| 471/500 [00:35<00:02, 12.34it/s] 95%|█████████▍| 473/500 [00:35<00:02, 12.37it/s] 95%|█████████▌| 475/500 [00:35<00:02, 12.31it/s] 95%|█████████▌| 477/500 [00:36<00:01, 12.26it/s] 96%|█████████▌| 479/500 [00:36<00:01, 12.92it/s] 96%|█████████▌| 481/500 [00:36<00:01, 13.62it/s] 97%|█████████▋| 483/500 [00:36<00:01, 14.15it/s] 97%|█████████▋| 485/500 [00:36<00:01, 14.74it/s] 97%|█████████▋| 487/500 [00:36<00:00, 15.09it/s] 98%|█████████▊| 489/500 [00:36<00:00, 15.46it/s] 98%|█████████▊| 491/500 [00:37<00:00, 14.57it/s] 99%|█████████▊| 493/500 [00:37<00:00, 13.71it/s] 99%|█████████▉| 495/500 [00:37<00:00, 13.23it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
 99%|█████████▉| 497/500 [00:37<00:00, 12.83it/s]100%|█████████▉| 499/500 [00:37<00:00, 12.67it/s]100%|██████████| 500/500 [00:37<00:00, 13.22it/s]
/home/yuyi/anaconda3/envs/ng/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/autograd/engine.cpp:1151.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  1
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:39,  6.45s/it]  1%|          | 3/500 [00:06<14:16,  1.72s/it]  1%|          | 5/500 [00:06<07:10,  1.15it/s]  1%|▏         | 7/500 [00:06<04:20,  1.89it/s]  2%|▏         | 9/500 [00:06<02:53,  2.82it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:20<09:38,  1.21s/it]  5%|▍         | 23/500 [00:20<06:49,  1.16it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:27<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:39,  1.17it/s]  7%|▋         | 35/500 [00:27<04:47,  1.62it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:35,  2.97it/s]  8%|▊         | 41/500 [00:33<09:02,  1.18s/it]  9%|▊         | 43/500 [00:33<06:27,  1.18it/s]  9%|▉         | 45/500 [00:34<04:38,  1.63it/s]  9%|▉         | 47/500 [00:34<03:22,  2.23it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:57,  1.20s/it] 11%|█         | 53/500 [00:40<06:23,  1.16it/s] 11%|█         | 55/500 [00:41<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.96it/s] 12%|█▏        | 61/500 [00:47<08:53,  1.22s/it] 13%|█▎        | 63/500 [00:48<06:22,  1.14it/s] 13%|█▎        | 65/500 [00:48<04:34,  1.58it/s] 13%|█▎        | 67/500 [00:48<03:20,  2.16it/s] 14%|█▍        | 69/500 [00:48<02:27,  2.91it/s] 14%|█▍        | 71/500 [00:54<08:40,  1.21s/it]Epoch:  1  	Training Loss: 0.027675703167915344
Test Loss:  0.057827431708574295
Valid Loss:  0.05540641397237778
Epoch:  2  	Training Loss: 0.06189022585749626
Test Loss:  0.18789978325366974
Valid Loss:  0.19891977310180664
Epoch:  3  	Training Loss: 0.21603477001190186
Test Loss:  0.021557768806815147
Valid Loss:  0.029907293617725372
Epoch:  4  	Training Loss: 0.03527499735355377
Test Loss:  0.02142168954014778
Valid Loss:  0.029755041003227234
Epoch:  5  	Training Loss: 0.03508310765028
Test Loss:  0.021324941888451576
Valid Loss:  0.02964068576693535
Epoch:  6  	Training Loss: 0.034940093755722046
Test Loss:  0.02122991532087326
Valid Loss:  0.029532015323638916
Epoch:  7  	Training Loss: 0.034801606088876724
Test Loss:  0.02113453671336174
Valid Loss:  0.029419921338558197
Epoch:  8  	Training Loss: 0.03466067835688591
Test Loss:  0.021044310182332993
Valid Loss:  0.029314391314983368
Epoch:  9  	Training Loss: 0.03452695533633232
Test Loss:  0.02095673605799675
Valid Loss:  0.029212038964033127
Epoch:  10  	Training Loss: 0.03439691662788391
Test Loss:  0.020870311185717583
Valid Loss:  0.029110826551914215
Epoch:  11  	Training Loss: 0.03426814451813698
Test Loss:  0.020784715190529823
Valid Loss:  0.02901066467165947
Epoch:  12  	Training Loss: 0.034140557050704956
Test Loss:  0.020651906728744507
Valid Loss:  0.028855295851826668
Epoch:  13  	Training Loss: 0.033951032906770706
Test Loss:  0.020541107282042503
Valid Loss:  0.028719879686832428
Epoch:  14  	Training Loss: 0.03378656506538391
Test Loss:  0.02043437957763672
Valid Loss:  0.028590746223926544
Epoch:  15  	Training Loss: 0.03362908586859703
Test Loss:  0.020331254228949547
Valid Loss:  0.02846759930253029
Epoch:  16  	Training Loss: 0.033479735255241394
Test Loss:  0.020231541246175766
Valid Loss:  0.02834663912653923
Epoch:  17  	Training Loss: 0.033332113176584244
Test Loss:  0.020132821053266525
Valid Loss:  0.028226692229509354
Epoch:  18  	Training Loss: 0.033185552805662155
Test Loss:  0.020035065710544586
Valid Loss:  0.02810787223279476
Epoch:  19  	Training Loss: 0.033040016889572144
Test Loss:  0.01993674412369728
Valid Loss:  0.027990713715553284
Epoch:  20  	Training Loss: 0.03289538994431496
Test Loss:  0.01983904466032982
Valid Loss:  0.027874039486050606
Epoch:  21  	Training Loss: 0.032751455903053284
Test Loss:  0.01974138244986534
Valid Loss:  0.027758436277508736
Epoch:  22  	Training Loss: 0.03260825201869011
Test Loss:  0.019642114639282227
Valid Loss:  0.027636950835585594
Epoch:  23  	Training Loss: 0.032461103051900864
Test Loss:  0.019543159753084183
Valid Loss:  0.027516692876815796
Epoch:  24  	Training Loss: 0.03231490030884743
Test Loss:  0.019444800913333893
Valid Loss:  0.02739705517888069
Epoch:  25  	Training Loss: 0.032169491052627563
Test Loss:  0.019347049295902252
Valid Loss:  0.027278052642941475
Epoch:  26  	Training Loss: 0.03202492743730545
Test Loss:  0.01924959197640419
Valid Loss:  0.027160247787833214
Epoch:  27  	Training Loss: 0.03188135102391243
Test Loss:  0.01915234513580799
Valid Loss:  0.027043689042329788
Epoch:  28  	Training Loss: 0.03173861280083656
Test Loss:  0.01905583031475544
Valid Loss:  0.02692767232656479
Epoch:  29  	Training Loss: 0.031596679240465164
Test Loss:  0.01895986869931221
Valid Loss:  0.02681238204240799
Epoch:  30  	Training Loss: 0.031455520540475845
Test Loss:  0.018864694982767105
Valid Loss:  0.02669757418334484
Epoch:  31  	Training Loss: 0.0313151553273201
Test Loss:  0.0187701266258955
Valid Loss:  0.026583358645439148
Epoch:  32  	Training Loss: 0.031175583600997925
Test Loss:  0.01867862232029438
Valid Loss:  0.02647307515144348
Epoch:  33  	Training Loss: 0.031040025874972343
Test Loss:  0.018587812781333923
Valid Loss:  0.026363130658864975
Epoch:  34  	Training Loss: 0.030905138701200485
Test Loss:  0.018497105687856674
Valid Loss:  0.02625424973666668
Epoch:  35  	Training Loss: 0.03077094629406929
Test Loss:  0.01840694062411785
Valid Loss:  0.02614584192633629
Epoch:  36  	Training Loss: 0.03063741698861122
Test Loss:  0.018317241221666336
Valid Loss:  0.026037979871034622
Epoch:  37  	Training Loss: 0.03050454705953598
Test Loss:  0.01822822168469429
Valid Loss:  0.025930454954504967
Epoch:  38  	Training Loss: 0.030372321605682373
Test Loss:  0.018139583989977837
Valid Loss:  0.02582353726029396
Epoch:  39  	Training Loss: 0.030240748077630997
Test Loss:  0.018051467835903168
Valid Loss:  0.02571709081530571
Epoch:  40  	Training Loss: 0.030109811574220657
Test Loss:  0.01796400360763073
Valid Loss:  0.025610974058508873
Epoch:  41  	Training Loss: 0.029979517683386803
Test Loss:  0.01787690818309784
Valid Loss:  0.02550545334815979
Epoch:  42  	Training Loss: 0.029849855229258537
Test Loss:  0.01779213920235634
Valid Loss:  0.025402670726180077
Epoch:  43  	Training Loss: 0.02972313016653061
Test Loss:  0.01770789362490177
Valid Loss:  0.02530035376548767
Epoch:  44  	Training Loss: 0.029597051441669464
Test Loss:  0.017624152824282646
Valid Loss:  0.02519848197698593
Epoch:  45  	Training Loss: 0.029471594840288162
Test Loss:  0.017540914937853813
Valid Loss:  0.0250970721244812
Epoch:  46  	Training Loss: 0.029346777126193047
Test Loss:  0.017458179965615273
Valid Loss:  0.024996116757392883
Epoch:  47  	Training Loss: 0.029222581535577774
Test Loss:  0.017375938594341278
Valid Loss:  0.024895595386624336
Epoch:  48  	Training Loss: 0.029099054634571075
Test Loss:  0.0172936599701643
Valid Loss:  0.024796491488814354
Epoch:  49  	Training Loss: 0.028976157307624817
Test Loss:  0.01721188798546791
Valid Loss:  0.02469782344996929
Epoch:  50  	Training Loss: 0.0288538821041584
Test Loss:  0.01713087223470211
Valid Loss:  0.02459910698235035
Epoch:  51  	Training Loss: 0.028732242062687874
Test Loss:  0.017050087451934814
Valid Loss:  0.02450130507349968
Epoch:  52  	Training Loss: 0.028611216694116592
Test Loss:  0.0169716477394104
Valid Loss:  0.024406420066952705
Epoch:  53  	Training Loss: 0.028493382036685944
Test Loss:  0.016893744468688965
Valid Loss:  0.024312015622854233
Epoch:  54  	Training Loss: 0.028376247733831406
Test Loss:  0.01681637205183506
Valid Loss:  0.024218104779720306
Epoch:  55  	Training Loss: 0.02825981006026268
Test Loss:  0.016739532351493835
Valid Loss:  0.024124670773744583
Epoch:  56  	Training Loss: 0.028144054114818573
Test Loss:  0.016663214191794395
Valid Loss:  0.024031713604927063
Epoch:  57  	Training Loss: 0.028028979897499084
Test Loss:  0.016587408259510994
Valid Loss:  0.023939229547977448
Epoch:  58  	Training Loss: 0.02791457809507847
Test Loss:  0.016512108966708183
Valid Loss:  0.023847216740250587
Epoch:  59  	Training Loss: 0.027800843119621277
Test Loss:  0.01643725484609604
Valid Loss:  0.023755740374326706
Epoch:  60  	Training Loss: 0.027687758207321167
Test Loss:  0.016362890601158142
Valid Loss:  0.023664724081754684
Epoch:  61  	Training Loss: 0.02757532335817814
Test Loss:  0.016289018094539642
Valid Loss:  0.023574158549308777
Epoch:  62  	Training Loss: 0.027463529258966446
Test Loss:  0.016216114163398743
Valid Loss:  0.02348465286195278
Epoch:  63  	Training Loss: 0.02735280618071556
Test Loss:  0.016143670305609703
Valid Loss:  0.023395560681819916
Epoch:  64  	Training Loss: 0.02724268287420273
Test Loss:  0.01607150211930275
Valid Loss:  0.02330733835697174
Epoch:  65  	Training Loss: 0.02713317796587944
Test Loss:  0.01599978655576706
Valid Loss:  0.023219507187604904
Epoch:  66  	Training Loss: 0.027024254202842712
Test Loss:  0.015928514301776886
Valid Loss:  0.023132093250751495
Epoch:  67  	Training Loss: 0.02691592462360859
Test Loss:  0.01585768163204193
Valid Loss:  0.023045072332024574
Epoch:  68  	Training Loss: 0.02680817060172558
Test Loss:  0.015787284821271896
Valid Loss:  0.02295844629406929
Epoch:  69  	Training Loss: 0.02670099027454853
Test Loss:  0.015717312693595886
Valid Loss:  0.022872215136885643
Epoch:  70  	Training Loss: 0.026594378054142
Test Loss:  0.015647761523723602
Valid Loss:  0.022786365821957588
Epoch:  71  	Training Loss: 0.026488319039344788
Test Loss:  0.015578627586364746
Valid Loss:  0.022700905799865723
Epoch:  72  	Training Loss: 0.026382818818092346
Test Loss:   15%|█▍        | 73/500 [00:55<06:11,  1.15it/s] 15%|█▌        | 75/500 [00:55<04:27,  1.59it/s] 15%|█▌        | 77/500 [00:55<03:14,  2.17it/s] 16%|█▌        | 79/500 [00:55<02:23,  2.93it/s] 16%|█▌        | 81/500 [01:01<08:16,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:54,  1.18it/s] 17%|█▋        | 85/500 [01:02<04:15,  1.63it/s] 17%|█▋        | 87/500 [01:02<03:05,  2.22it/s] 18%|█▊        | 89/500 [01:02<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:08<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:08<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:08<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:09<02:12,  3.02it/s] 20%|██        | 101/500 [01:15<07:59,  1.20s/it] 21%|██        | 103/500 [01:15<05:45,  1.15it/s] 21%|██        | 105/500 [01:15<04:10,  1.58it/s] 21%|██▏       | 107/500 [01:16<03:04,  2.13it/s] 22%|██▏       | 109/500 [01:16<02:18,  2.82it/s] 22%|██▏       | 111/500 [01:22<07:58,  1.23s/it] 23%|██▎       | 113/500 [01:22<05:41,  1.13it/s] 23%|██▎       | 115/500 [01:23<04:05,  1.57it/s] 23%|██▎       | 117/500 [01:23<02:58,  2.15it/s] 24%|██▍       | 119/500 [01:23<02:11,  2.90it/s] 24%|██▍       | 121/500 [01:29<07:41,  1.22s/it] 25%|██▍       | 123/500 [01:29<05:31,  1.14it/s] 25%|██▌       | 125/500 [01:30<04:00,  1.56it/s] 25%|██▌       | 127/500 [01:30<02:56,  2.11it/s] 26%|██▌       | 129/500 [01:30<02:12,  2.80it/s] 26%|██▌       | 131/500 [01:36<07:28,  1.22s/it] 27%|██▋       | 133/500 [01:37<05:20,  1.15it/s] 27%|██▋       | 135/500 [01:37<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:37<02:47,  2.17it/s] 28%|██▊       | 139/500 [01:37<02:03,  2.93it/s] 28%|██▊       | 141/500 [01:43<07:09,  1.20s/it]0.015510914847254753
Valid Loss:  0.02261725813150406
Epoch:  73  	Training Loss: 0.026279237121343613
Test Loss:  0.015443617478013039
Valid Loss:  0.022533999755978584
Epoch:  74  	Training Loss: 0.026176216080784798
Test Loss:  0.015376737341284752
Valid Loss:  0.022451113909482956
Epoch:  75  	Training Loss: 0.026073748245835304
Test Loss:  0.01531025767326355
Valid Loss:  0.02236861363053322
Epoch:  76  	Training Loss: 0.025971824303269386
Test Loss:  0.01524418592453003
Valid Loss:  0.022286493331193924
Epoch:  77  	Training Loss: 0.02587045356631279
Test Loss:  0.015178510919213295
Valid Loss:  0.022204745560884476
Epoch:  78  	Training Loss: 0.025769613683223724
Test Loss:  0.015113220550119877
Valid Loss:  0.022123366594314575
Epoch:  79  	Training Loss: 0.02566930651664734
Test Loss:  0.015048292465507984
Valid Loss:  0.022042442113161087
Epoch:  80  	Training Loss: 0.02556954324245453
Test Loss:  0.01498374529182911
Valid Loss:  0.021961890161037445
Epoch:  81  	Training Loss: 0.025470301508903503
Test Loss:  0.014919552020728588
Valid Loss:  0.021881788969039917
Epoch:  82  	Training Loss: 0.02537158504128456
Test Loss:  0.01485648937523365
Valid Loss:  0.021803466603159904
Epoch:  83  	Training Loss: 0.025274410843849182
Test Loss:  0.014793816953897476
Valid Loss:  0.021725496277213097
Epoch:  84  	Training Loss: 0.025177761912345886
Test Loss:  0.014731524512171745
Valid Loss:  0.021647879853844643
Epoch:  85  	Training Loss: 0.025081627070903778
Test Loss:  0.01466960646212101
Valid Loss:  0.021570606157183647
Epoch:  86  	Training Loss: 0.02498600073158741
Test Loss:  0.014608055353164673
Valid Loss:  0.021493680775165558
Epoch:  87  	Training Loss: 0.024890882894396782
Test Loss:  0.014546865597367287
Valid Loss:  0.021417085081338882
Epoch:  88  	Training Loss: 0.02479626052081585
Test Loss:  0.014486035332083702
Valid Loss:  0.021340839564800262
Epoch:  89  	Training Loss: 0.02470214292407036
Test Loss:  0.014425563625991344
Valid Loss:  0.021264925599098206
Epoch:  90  	Training Loss: 0.02460850588977337
Test Loss:  0.014365436509251595
Valid Loss:  0.021189341321587563
Epoch:  91  	Training Loss: 0.024515356868505478
Test Loss:  0.014305660501122475
Valid Loss:  0.02111409418284893
Epoch:  92  	Training Loss: 0.024422690272331238
Test Loss:  0.014246640726923943
Valid Loss:  0.021039698272943497
Epoch:  93  	Training Loss: 0.024330902844667435
Test Loss:  0.014187945984303951
Valid Loss:  0.02096560224890709
Epoch:  94  	Training Loss: 0.02423955872654915
Test Loss:  0.014129574410617352
Valid Loss:  0.020891817286610603
Epoch:  95  	Training Loss: 0.024148669093847275
Test Loss:  0.014071527868509293
Valid Loss:  0.020818334072828293
Epoch:  96  	Training Loss: 0.02405821904540062
Test Loss:  0.014013802632689476
Valid Loss:  0.020745160058140755
Epoch:  97  	Training Loss: 0.02396821230649948
Test Loss:  0.013956387527287006
Valid Loss:  0.020672280341386795
Epoch:  98  	Training Loss: 0.02387864515185356
Test Loss:  0.013899245299398899
Valid Loss:  0.020599786192178726
Epoch:  99  	Training Loss: 0.023789506405591965
Test Loss:  0.013842403888702393
Valid Loss:  0.020527593791484833
Epoch:  100  	Training Loss: 0.023700837045907974
Test Loss:  0.013785803690552711
Valid Loss:  0.020456168800592422
Epoch:  101  	Training Loss: 0.023612629622220993
Test Loss:  0.01372950803488493
Valid Loss:  0.020385023206472397
Epoch:  102  	Training Loss: 0.023524852469563484
Test Loss:  0.013674039393663406
Valid Loss:  0.020314980298280716
Epoch:  103  	Training Loss: 0.023438043892383575
Test Loss:  0.013618877157568932
Valid Loss:  0.02024521864950657
Epoch:  104  	Training Loss: 0.023351673036813736
Test Loss:  0.013564018532633781
Valid Loss:  0.020175736397504807
Epoch:  105  	Training Loss: 0.02326572686433792
Test Loss:  0.013509467244148254
Valid Loss:  0.020106539130210876
Epoch:  106  	Training Loss: 0.02318020537495613
Test Loss:  0.013455206528306007
Valid Loss:  0.02003762312233448
Epoch:  107  	Training Loss: 0.023095104843378067
Test Loss:  0.013401251286268234
Valid Loss:  0.019968979060649872
Epoch:  108  	Training Loss: 0.02301042526960373
Test Loss:  0.013347581960260868
Valid Loss:  0.0199006125330925
Epoch:  109  	Training Loss: 0.022926151752471924
Test Loss:  0.013294150121510029
Valid Loss:  0.01983269676566124
Epoch:  110  	Training Loss: 0.02284231223165989
Test Loss:  0.013241028413176537
Valid Loss:  0.019764985889196396
Epoch:  111  	Training Loss: 0.02275887131690979
Test Loss:  0.013188187032938004
Valid Loss:  0.01969754695892334
Epoch:  112  	Training Loss: 0.022675838321447372
Test Loss:  0.013136406429111958
Valid Loss:  0.019631601870059967
Epoch:  113  	Training Loss: 0.022594347596168518
Test Loss:  0.013084901496767998
Valid Loss:  0.019565921276807785
Epoch:  114  	Training Loss: 0.0225132554769516
Test Loss:  0.013033700175583363
Valid Loss:  0.019500406458973885
Epoch:  115  	Training Loss: 0.022432558238506317
Test Loss:  0.012982740066945553
Valid Loss:  0.019435293972492218
Epoch:  116  	Training Loss: 0.022352244704961777
Test Loss:  0.012932049110531807
Valid Loss:  0.019370533525943756
Epoch:  117  	Training Loss: 0.022272318601608276
Test Loss:  0.012881625443696976
Valid Loss:  0.019306043162941933
Epoch:  118  	Training Loss: 0.022192776203155518
Test Loss:  0.012831468135118484
Valid Loss:  0.0192418172955513
Epoch:  119  	Training Loss: 0.022113613784313202
Test Loss:  0.012781571596860886
Valid Loss:  0.019177846610546112
Epoch:  120  	Training Loss: 0.02203482761979103
Test Loss:  0.012731929309666157
Valid Loss:  0.019114140421152115
Epoch:  121  	Training Loss: 0.021956421434879303
Test Loss:  0.012682553380727768
Valid Loss:  0.019050687551498413
Epoch:  122  	Training Loss: 0.021878372877836227
Test Loss:  0.01263340376317501
Valid Loss:  0.018987327814102173
Epoch:  123  	Training Loss: 0.021800432354211807
Test Loss:  0.012584500014781952
Valid Loss:  0.018924221396446228
Epoch:  124  	Training Loss: 0.021722842007875443
Test Loss:  0.012535841204226017
Valid Loss:  0.01886136457324028
Epoch:  125  	Training Loss: 0.02164561115205288
Test Loss:  0.012487406842410564
Valid Loss:  0.018798843026161194
Epoch:  126  	Training Loss: 0.021568726748228073
Test Loss:  0.01243923045694828
Valid Loss:  0.01873648166656494
Epoch:  127  	Training Loss: 0.02149219438433647
Test Loss:  0.012391271069645882
Valid Loss:  0.018674449995160103
Epoch:  128  	Training Loss: 0.021416008472442627
Test Loss:  0.01234355103224516
Valid Loss:  0.018612664192914963
Epoch:  129  	Training Loss: 0.02134017087519169
Test Loss:  0.012296057306230068
Valid Loss:  0.01855151355266571
Epoch:  130  	Training Loss: 0.02126476913690567
Test Loss:  0.012248787097632885
Valid Loss:  0.018490588292479515
Epoch:  131  	Training Loss: 0.021189698949456215
Test Loss:  0.012201758101582527
Valid Loss:  0.01842990703880787
Epoch:  132  	Training Loss: 0.021114978939294815
Test Loss:  0.01215534470975399
Valid Loss:  0.01836981624364853
Epoch:  133  	Training Loss: 0.02104112319648266
Test Loss:  0.012109149247407913
Valid Loss:  0.018309960141777992
Epoch:  134  	Training Loss: 0.020967595279216766
Test Loss:  0.012063192203640938
Valid Loss:  0.018250349909067154
Epoch:  135  	Training Loss: 0.020894404500722885
Test Loss:  0.012017453089356422
Valid Loss:  0.018190961331129074
Epoch:  136  	Training Loss: 0.02082154154777527
Test Loss:  0.01197193656116724
Valid Loss:  0.0181318037211895
Epoch:  137  	Training Loss: 0.020749004557728767
Test Loss:  0.011926642619073391
Valid Loss:  0.018072880804538727
Epoch:  138  	Training Loss: 0.02067679353058338
Test Loss:  0.011881564743816853
Valid Loss:  0.018014181405305862
Epoch:  139  	Training Loss: 0.020604902878403664
Test Loss:  0.011836705729365349
Valid Loss:  0.0179557166993618
Epoch:  140  	Training Loss: 0.02053334005177021
Test Loss:  0.011792060919106007
Valid Loss:  0.017897624522447586
Epoch:  141  	Training Loss: 0.020462092012166977
Test Loss:  0.011747630313038826
Valid Loss:  0.017839819192886353
Epoch:  142  	Training Loss: 0.020391162484884262
Test Loss:  0.011703676544129848
Valid Loss:  0.01778252050280571
 29%|██▊       | 143/500 [01:44<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:44<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:44<02:43,  2.16it/s] 30%|██▉       | 149/500 [01:44<02:00,  2.92it/s] 30%|███       | 151/500 [01:50<07:00,  1.20s/it] 31%|███       | 153/500 [01:51<04:59,  1.16it/s] 31%|███       | 155/500 [01:51<03:36,  1.59it/s] 31%|███▏      | 157/500 [01:51<02:39,  2.15it/s] 32%|███▏      | 159/500 [01:51<01:59,  2.85it/s] 32%|███▏      | 161/500 [01:57<06:43,  1.19s/it] 33%|███▎      | 163/500 [01:57<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:58<03:27,  1.62it/s] 33%|███▎      | 167/500 [01:58<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:58<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:04<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:04<04:40,  1.16it/s] 35%|███▌      | 175/500 [02:05<03:22,  1.61it/s] 35%|███▌      | 177/500 [02:05<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:05<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:11<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:11<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:12<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:12<01:45,  2.96it/s] 38%|███▊      | 191/500 [02:18<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:18<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:18<03:10,  1.60it/s] 39%|███▉      | 197/500 [02:19<02:20,  2.16it/s] 40%|███▉      | 199/500 [02:19<01:45,  2.86it/s] 40%|████      | 201/500 [02:25<05:53,  1.18s/it] 41%|████      | 203/500 [02:25<04:12,  1.18it/s] 41%|████      | 205/500 [02:25<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:25<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:26<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:32<05:52,  1.22s/it]Epoch:  143  	Training Loss: 0.02032081037759781
Test Loss:  0.011659936048090458
Valid Loss:  0.017725447192788124
Epoch:  144  	Training Loss: 0.020250767469406128
Test Loss:  0.011616400443017483
Valid Loss:  0.017668606713414192
Epoch:  145  	Training Loss: 0.020181041210889816
Test Loss:  0.011573073454201221
Valid Loss:  0.017611989751458168
Epoch:  146  	Training Loss: 0.020111627876758575
Test Loss:  0.01152995228767395
Valid Loss:  0.0175555981695652
Epoch:  147  	Training Loss: 0.02004252001643181
Test Loss:  0.011487037874758244
Valid Loss:  0.01749943196773529
Epoch:  148  	Training Loss: 0.019973721355199814
Test Loss:  0.011444324627518654
Valid Loss:  0.01744348742067814
Epoch:  149  	Training Loss: 0.019905220717191696
Test Loss:  0.011401811614632607
Valid Loss:  0.017387758940458298
Epoch:  150  	Training Loss: 0.0198370311409235
Test Loss:  0.011359527707099915
Valid Loss:  0.017332540825009346
Epoch:  151  	Training Loss: 0.019769228994846344
Test Loss:  0.01131744310259819
Valid Loss:  0.017277546226978302
Epoch:  152  	Training Loss: 0.01970173791050911
Test Loss:  0.011275587603449821
Valid Loss:  0.017222760245203972
Epoch:  153  	Training Loss: 0.019634243100881577
Test Loss:  0.011233906261622906
Valid Loss:  0.01716827228665352
Epoch:  154  	Training Loss: 0.019567042589187622
Test Loss:  0.011192451231181622
Valid Loss:  0.01711428537964821
Epoch:  155  	Training Loss: 0.019500192254781723
Test Loss:  0.011151195503771305
Valid Loss:  0.01706048846244812
Epoch:  156  	Training Loss: 0.0194336399435997
Test Loss:  0.011110128834843636
Valid Loss:  0.017006896436214447
Epoch:  157  	Training Loss: 0.019367368891835213
Test Loss:  0.01106924656778574
Valid Loss:  0.016953498125076294
Epoch:  158  	Training Loss: 0.019301382824778557
Test Loss:  0.011028564535081387
Valid Loss:  0.016900310292840004
Epoch:  159  	Training Loss: 0.01923569291830063
Test Loss:  0.010988063178956509
Valid Loss:  0.016847308725118637
Epoch:  160  	Training Loss: 0.019170280545949936
Test Loss:  0.01094774715602398
Valid Loss:  0.016794506460428238
Epoch:  161  	Training Loss: 0.019105151295661926
Test Loss:  0.010907619260251522
Valid Loss:  0.016741909086704254
Epoch:  162  	Training Loss: 0.019040295854210854
Test Loss:  0.010868262499570847
Valid Loss:  0.01669030822813511
Epoch:  163  	Training Loss: 0.018976662307977676
Test Loss:  0.010829094797372818
Valid Loss:  0.016638990491628647
Epoch:  164  	Training Loss: 0.018913306295871735
Test Loss:  0.010790104977786541
Valid Loss:  0.016587942838668823
Epoch:  165  	Training Loss: 0.018850235268473625
Test Loss:  0.010751294903457165
Valid Loss:  0.016537100076675415
Epoch:  166  	Training Loss: 0.018787439912557602
Test Loss:  0.010712670162320137
Valid Loss:  0.016486451029777527
Epoch:  167  	Training Loss: 0.018724923953413963
Test Loss:  0.010674217715859413
Valid Loss:  0.01643601804971695
Epoch:  168  	Training Loss: 0.018662679940462112
Test Loss:  0.010635944083333015
Valid Loss:  0.016385914757847786
Epoch:  169  	Training Loss: 0.018600713461637497
Test Loss:  0.010597852058708668
Valid Loss:  0.01633600890636444
Epoch:  170  	Training Loss: 0.018539011478424072
Test Loss:  0.010559928603470325
Valid Loss:  0.016286298632621765
Epoch:  171  	Training Loss: 0.018477585166692734
Test Loss:  0.010522183030843735
Valid Loss:  0.016236787661910057
Epoch:  172  	Training Loss: 0.018416430801153183
Test Loss:  0.010485145263373852
Valid Loss:  0.01618826575577259
Epoch:  173  	Training Loss: 0.018356282263994217
Test Loss:  0.010448276065289974
Valid Loss:  0.01613995060324669
Epoch:  174  	Training Loss: 0.01829640194773674
Test Loss:  0.0104115791618824
Valid Loss:  0.01609181798994541
Epoch:  175  	Training Loss: 0.018236778676509857
Test Loss:  0.010375045239925385
Valid Loss:  0.016043882817029953
Epoch:  176  	Training Loss: 0.018177418038249016
Test Loss:  0.0103386789560318
Valid Loss:  0.015996122732758522
Epoch:  177  	Training Loss: 0.018118320032954216
Test Loss:  0.010302488692104816
Valid Loss:  0.015948563814163208
Epoch:  178  	Training Loss: 0.01805948093533516
Test Loss:  0.010266449302434921
Valid Loss:  0.015901191160082817
Epoch:  179  	Training Loss: 0.018000900745391846
Test Loss:  0.01023058034479618
Valid Loss:  0.0158540029078722
Epoch:  180  	Training Loss: 0.017942573875188828
Test Loss:  0.010194869711995125
Valid Loss:  0.015807002782821655
Epoch:  181  	Training Loss: 0.017884496599435806
Test Loss:  0.010159321129322052
Valid Loss:  0.01576020009815693
Epoch:  182  	Training Loss: 0.017826668918132782
Test Loss:  0.010124224238097668
Valid Loss:  0.01571391150355339
Epoch:  183  	Training Loss: 0.01776929572224617
Test Loss:  0.010089290328323841
Valid Loss:  0.01566779799759388
Epoch:  184  	Training Loss: 0.017712170258164406
Test Loss:  0.010054510086774826
Valid Loss:  0.015621881000697613
Epoch:  185  	Training Loss: 0.017655299976468086
Test Loss:  0.010019892826676369
Valid Loss:  0.015576135367155075
Epoch:  186  	Training Loss: 0.017598677426576614
Test Loss:  0.009985425509512424
Valid Loss:  0.015530573204159737
Epoch:  187  	Training Loss: 0.017542321234941483
Test Loss:  0.009951184503734112
Valid Loss:  0.015485391020774841
Epoch:  188  	Training Loss: 0.01748625934123993
Test Loss:  0.009917096234858036
Valid Loss:  0.015440378338098526
Epoch:  189  	Training Loss: 0.017430443316698074
Test Loss:  0.009883244521915913
Valid Loss:  0.015395603142678738
Epoch:  190  	Training Loss: 0.01737486943602562
Test Loss:  0.009849578142166138
Valid Loss:  0.015351017005741596
Epoch:  191  	Training Loss: 0.01731955260038376
Test Loss:  0.009816063567996025
Valid Loss:  0.015306598506867886
Epoch:  192  	Training Loss: 0.017264466732740402
Test Loss:  0.009782979264855385
Valid Loss:  0.015262773260474205
Epoch:  193  	Training Loss: 0.01720990240573883
Test Loss:  0.009750040248036385
Valid Loss:  0.01521912869066
Epoch:  194  	Training Loss: 0.01715557649731636
Test Loss:  0.009717261418700218
Valid Loss:  0.015175648033618927
Epoch:  195  	Training Loss: 0.01710149645805359
Test Loss:  0.009684628807008266
Valid Loss:  0.015132330358028412
Epoch:  196  	Training Loss: 0.01704764924943447
Test Loss:  0.009652145206928253
Valid Loss:  0.015089176595211029
Epoch:  197  	Training Loss: 0.01699402928352356
Test Loss:  0.00961980875581503
Valid Loss:  0.015046190470457077
Epoch:  198  	Training Loss: 0.0169406458735466
Test Loss:  0.009587613865733147
Valid Loss:  0.015003370121121407
Epoch:  199  	Training Loss: 0.016887491568922997
Test Loss:  0.009555634111166
Valid Loss:  0.01496070809662342
Epoch:  200  	Training Loss: 0.016834571957588196
Test Loss:  0.009523862972855568
Valid Loss:  0.014918209053575993
Epoch:  201  	Training Loss: 0.01678188517689705
Test Loss:  0.00949223805218935
Valid Loss:  0.014875877648591995
Epoch:  202  	Training Loss: 0.016729414463043213
Test Loss:  0.00946086272597313
Valid Loss:  0.014833807945251465
Epoch:  203  	Training Loss: 0.016677260398864746
Test Loss:  0.00942964293062687
Valid Loss:  0.01479189470410347
Epoch:  204  	Training Loss: 0.01662534475326538
Test Loss:  0.009398525580763817
Valid Loss:  0.014750353991985321
Epoch:  205  	Training Loss: 0.016573693603277206
Test Loss:  0.009367544203996658
Valid Loss:  0.014708963222801685
Epoch:  206  	Training Loss: 0.01652226224541664
Test Loss:  0.009336711838841438
Valid Loss:  0.014667737297713757
Epoch:  207  	Training Loss: 0.016471058130264282
Test Loss:  0.009306089952588081
Valid Loss:  0.014626680873334408
Epoch:  208  	Training Loss: 0.016420090571045876
Test Loss:  0.009275546297430992
Valid Loss:  0.014585984870791435
Epoch:  209  	Training Loss: 0.01636936143040657
Test Loss:  0.009245149791240692
Valid Loss:  0.01454545184969902
Epoch:  210  	Training Loss: 0.01631886139512062
Test Loss:  0.009214898571372032
Valid Loss:  0.014505087397992611
Epoch:  211  	Training Loss: 0.016268573701381683
Test Loss:  0.009184785187244415
Valid Loss:  0.014464875683188438
Epoch:  212  	Training Loss: 0.016218503937125206
Test Loss:  0.00915483944118023
Valid Loss:  0.014424849301576614
Epoch:  213  	Training Loss: 0.01616853103041649
Test Loss:   43%|████▎     | 213/500 [02:32<04:12,  1.14it/s] 43%|████▎     | 215/500 [02:32<03:01,  1.57it/s] 43%|████▎     | 217/500 [02:33<02:11,  2.15it/s] 44%|████▍     | 219/500 [02:33<01:38,  2.85it/s] 44%|████▍     | 221/500 [02:39<05:42,  1.23s/it] 45%|████▍     | 223/500 [02:39<04:05,  1.13it/s] 45%|████▌     | 225/500 [02:40<02:57,  1.55it/s] 45%|████▌     | 227/500 [02:40<02:08,  2.12it/s] 46%|████▌     | 229/500 [02:40<01:34,  2.86it/s] 46%|████▌     | 231/500 [02:46<05:21,  1.19s/it] 47%|████▋     | 233/500 [02:46<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:47<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:47<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:53<05:11,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:53<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:54<01:55,  2.20it/s] 50%|████▉     | 249/500 [02:54<01:24,  2.96it/s] 50%|█████     | 251/500 [03:00<04:51,  1.17s/it] 51%|█████     | 253/500 [03:00<03:28,  1.18it/s] 51%|█████     | 255/500 [03:00<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:00<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:01<01:23,  2.89it/s] 52%|█████▏    | 261/500 [03:07<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:07<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:07<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:07<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:07<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:14<04:40,  1.23s/it] 55%|█████▍    | 273/500 [03:14<03:21,  1.13it/s] 55%|█████▌    | 275/500 [03:14<02:24,  1.55it/s] 55%|█████▌    | 277/500 [03:15<01:45,  2.12it/s] 56%|█████▌    | 279/500 [03:15<01:18,  2.82it/s] 56%|█████▌    | 281/500 [03:21<04:28,  1.23s/it]0.009125028736889362
Valid Loss:  0.01438496820628643
Epoch:  214  	Training Loss: 0.016118770465254784
Test Loss:  0.009095373563468456
Valid Loss:  0.014345240779221058
Epoch:  215  	Training Loss: 0.016069233417510986
Test Loss:  0.0090658413246274
Valid Loss:  0.0143056595697999
Epoch:  216  	Training Loss: 0.016019903123378754
Test Loss:  0.009036458097398281
Valid Loss:  0.01426621899008751
Epoch:  217  	Training Loss: 0.015970783308148384
Test Loss:  0.009007204324007034
Valid Loss:  0.014226934872567654
Epoch:  218  	Training Loss: 0.015921875834465027
Test Loss:  0.008978092111647129
Valid Loss:  0.014187786728143692
Epoch:  219  	Training Loss: 0.015873173251748085
Test Loss:  0.008949115872383118
Valid Loss:  0.014148790389299393
Epoch:  220  	Training Loss: 0.015824683010578156
Test Loss:  0.008920269086956978
Valid Loss:  0.014109937474131584
Epoch:  221  	Training Loss: 0.015776412561535835
Test Loss:  0.008891499601304531
Valid Loss:  0.014071498066186905
Epoch:  222  	Training Loss: 0.015728361904621124
Test Loss:  0.008863182738423347
Valid Loss:  0.014033718034625053
Epoch:  223  	Training Loss: 0.01568097434937954
Test Loss:  0.008835002779960632
Valid Loss:  0.013996071182191372
Epoch:  224  	Training Loss: 0.015633797273039818
Test Loss:  0.008806951344013214
Valid Loss:  0.013958561234176159
Epoch:  225  	Training Loss: 0.01558683067560196
Test Loss:  0.008779030293226242
Valid Loss:  0.013921189121901989
Epoch:  226  	Training Loss: 0.015540062449872494
Test Loss:  0.008751249872148037
Valid Loss:  0.013883956708014011
Epoch:  227  	Training Loss: 0.015493497252464294
Test Loss:  0.008723597973585129
Valid Loss:  0.013846850953996181
Epoch:  228  	Training Loss: 0.015447134152054787
Test Loss:  0.008696088567376137
Valid Loss:  0.013809881173074245
Epoch:  229  	Training Loss: 0.015400972217321396
Test Loss:  0.008668714202940464
Valid Loss:  0.013773053884506226
Epoch:  230  	Training Loss: 0.015355009585618973
Test Loss:  0.008641470223665237
Valid Loss:  0.013736349530518055
Epoch:  231  	Training Loss: 0.015309246256947517
Test Loss:  0.00861433707177639
Valid Loss:  0.013699820265173912
Epoch:  232  	Training Loss: 0.015263681299984455
Test Loss:  0.008587607182562351
Valid Loss:  0.013663836754858494
Epoch:  233  	Training Loss: 0.015218639746308327
Test Loss:  0.008560992777347565
Valid Loss:  0.013628020882606506
Epoch:  234  	Training Loss: 0.015173783525824547
Test Loss:  0.008534512482583523
Valid Loss:  0.013592300936579704
Epoch:  235  	Training Loss: 0.015129132196307182
Test Loss:  0.008508143946528435
Valid Loss:  0.013556738384068012
Epoch:  236  	Training Loss: 0.015084667131304741
Test Loss:  0.008481904864311218
Valid Loss:  0.013521308079361916
Epoch:  237  	Training Loss: 0.01504039578139782
Test Loss:  0.008455779403448105
Valid Loss:  0.013486008159816265
Epoch:  238  	Training Loss: 0.014996319077908993
Test Loss:  0.00842980481684208
Valid Loss:  0.01345078181475401
Epoch:  239  	Training Loss: 0.014952428638935089
Test Loss:  0.008403923362493515
Valid Loss:  0.013415726833045483
Epoch:  240  	Training Loss: 0.014908721670508385
Test Loss:  0.008378173224627972
Valid Loss:  0.013380797579884529
Epoch:  241  	Training Loss: 0.014865204691886902
Test Loss:  0.00835252832621336
Valid Loss:  0.013345999643206596
Epoch:  242  	Training Loss: 0.014821869321167469
Test Loss:  0.008327114395797253
Valid Loss:  0.0133114755153656
Epoch:  243  	Training Loss: 0.014778925105929375
Test Loss:  0.008301765657961369
Valid Loss:  0.013277320191264153
Epoch:  244  	Training Loss: 0.014736168086528778
Test Loss:  0.008276529610157013
Valid Loss:  0.013243293389678001
Epoch:  245  	Training Loss: 0.014693583361804485
Test Loss:  0.008251413702964783
Valid Loss:  0.013209383003413677
Epoch:  246  	Training Loss: 0.014651181176304817
Test Loss:  0.00822641421109438
Valid Loss:  0.013175586238503456
Epoch:  247  	Training Loss: 0.014608957804739475
Test Loss:  0.00820152647793293
Valid Loss:  0.013141913339495659
Epoch:  248  	Training Loss: 0.014566912315785885
Test Loss:  0.008176756091415882
Valid Loss:  0.013108346611261368
Epoch:  249  	Training Loss: 0.014525044709444046
Test Loss:  0.008152085356414318
Valid Loss:  0.013074956834316254
Epoch:  250  	Training Loss: 0.014483356848359108
Test Loss:  0.008127537555992603
Valid Loss:  0.013041621074080467
Epoch:  251  	Training Loss: 0.014441829174757004
Test Loss:  0.008103089407086372
Valid Loss:  0.013008467853069305
Epoch:  252  	Training Loss: 0.014400489628314972
Test Loss:  0.008078834041953087
Valid Loss:  0.012975567020475864
Epoch:  253  	Training Loss: 0.01435950305312872
Test Loss:  0.008054696954786777
Valid Loss:  0.012942773289978504
Epoch:  254  	Training Loss: 0.014318693429231644
Test Loss:  0.0080306651070714
Valid Loss:  0.012910083867609501
Epoch:  255  	Training Loss: 0.0142780477181077
Test Loss:  0.008006742224097252
Valid Loss:  0.012877525761723518
Epoch:  256  	Training Loss: 0.014237577095627785
Test Loss:  0.007982926443219185
Valid Loss:  0.01284506544470787
Epoch:  257  	Training Loss: 0.014197270385921001
Test Loss:  0.007959219627082348
Valid Loss:  0.012812732718884945
Epoch:  258  	Training Loss: 0.014157135039567947
Test Loss:  0.007935618981719017
Valid Loss:  0.012780511751770973
Epoch:  259  	Training Loss: 0.014117171056568623
Test Loss:  0.007912123575806618
Valid Loss:  0.012748400680720806
Epoch:  260  	Training Loss: 0.014077369123697281
Test Loss:  0.007888730615377426
Valid Loss:  0.012716398574411869
Epoch:  261  	Training Loss: 0.014037730172276497
Test Loss:  0.007865442894399166
Valid Loss:  0.012684514746069908
Epoch:  262  	Training Loss: 0.013998258858919144
Test Loss:  0.007842288352549076
Valid Loss:  0.012652717530727386
Epoch:  263  	Training Loss: 0.013958833180367947
Test Loss:  0.007819238118827343
Valid Loss:  0.012621020898222923
Epoch:  264  	Training Loss: 0.01391956489533186
Test Loss:  0.007796283345669508
Valid Loss:  0.012589451856911182
Epoch:  265  	Training Loss: 0.013880458660423756
Test Loss:  0.0077734277583658695
Valid Loss:  0.012558030895888805
Epoch:  266  	Training Loss: 0.013841517269611359
Test Loss:  0.007750675082206726
Valid Loss:  0.01252666674554348
Epoch:  267  	Training Loss: 0.013802733272314072
Test Loss:  0.007728021591901779
Valid Loss:  0.012495467439293861
Epoch:  268  	Training Loss: 0.013764104805886745
Test Loss:  0.0077054728753864765
Valid Loss:  0.012464381754398346
Epoch:  269  	Training Loss: 0.01372564397752285
Test Loss:  0.007683018688112497
Valid Loss:  0.012433353811502457
Epoch:  270  	Training Loss: 0.01368732936680317
Test Loss:  0.007660664618015289
Valid Loss:  0.012402478605508804
Epoch:  271  	Training Loss: 0.01364917028695345
Test Loss:  0.007638396695256233
Valid Loss:  0.01237171608954668
Epoch:  272  	Training Loss: 0.013611169531941414
Test Loss:  0.007616137154400349
Valid Loss:  0.012340855784714222
Epoch:  273  	Training Loss: 0.013573028147220612
Test Loss:  0.007593967020511627
Valid Loss:  0.012310112826526165
Epoch:  274  	Training Loss: 0.013535048812627792
Test Loss:  0.007571887224912643
Valid Loss:  0.01227947510778904
Epoch:  275  	Training Loss: 0.01349722407758236
Test Loss:  0.00754991639405489
Valid Loss:  0.012248946353793144
Epoch:  276  	Training Loss: 0.013459553942084312
Test Loss:  0.007528034038841724
Valid Loss:  0.012218520976603031
Epoch:  277  	Training Loss: 0.013422033749520779
Test Loss:  0.007506252266466618
Valid Loss:  0.012188196182250977
Epoch:  278  	Training Loss: 0.013384660705924034
Test Loss:  0.007484561298042536
Valid Loss:  0.012157993391156197
Epoch:  279  	Training Loss: 0.013347446918487549
Test Loss:  0.007462969049811363
Valid Loss:  0.012127882800996304
Epoch:  280  	Training Loss: 0.013310398906469345
Test Loss:  0.0074414703994989395
Valid Loss:  0.012098151259124279
Epoch:  281  	Training Loss: 0.013273528777062893
Test Loss:  0.007420062553137541
Valid Loss:  0.012068511918187141
Epoch:  282  	Training Loss: 0.013236808590590954
Test Loss:  0.0073989457450807095
Valid Loss:  0.012039195746183395
Epoch:  283  	Training Loss: 0.01320047490298748
Test Loss:  0.007377916015684605
 57%|█████▋    | 283/500 [03:21<03:11,  1.13it/s] 57%|█████▋    | 285/500 [03:22<02:17,  1.57it/s] 57%|█████▋    | 287/500 [03:22<01:39,  2.15it/s] 58%|█████▊    | 289/500 [03:22<01:12,  2.90it/s] 58%|█████▊    | 291/500 [03:28<04:13,  1.21s/it] 59%|█████▊    | 293/500 [03:28<03:00,  1.15it/s] 59%|█████▉    | 295/500 [03:29<02:09,  1.59it/s] 59%|█████▉    | 297/500 [03:29<01:33,  2.17it/s] 60%|█████▉    | 299/500 [03:29<01:08,  2.93it/s] 60%|██████    | 301/500 [03:35<03:56,  1.19s/it] 61%|██████    | 303/500 [03:35<02:47,  1.17it/s] 61%|██████    | 305/500 [03:35<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:36<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:36<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:42<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:42<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:42<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:42<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:42<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:49<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:49<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:49<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:49<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:49<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:56<03:28,  1.24s/it] 67%|██████▋   | 333/500 [03:56<02:28,  1.12it/s] 67%|██████▋   | 335/500 [03:56<01:47,  1.54it/s] 67%|██████▋   | 337/500 [03:57<01:18,  2.08it/s] 68%|██████▊   | 339/500 [03:57<00:57,  2.80it/s] 68%|██████▊   | 341/500 [04:03<03:18,  1.25s/it] 69%|██████▊   | 343/500 [04:03<02:20,  1.12it/s] 69%|██████▉   | 345/500 [04:04<01:40,  1.55it/s] 69%|██████▉   | 347/500 [04:04<01:12,  2.12it/s] 70%|██████▉   | 349/500 [04:04<00:52,  2.86it/s] 70%|███████   | 351/500 [04:11<03:07,  1.26s/it]Valid Loss:  0.012009966187179089
Epoch:  284  	Training Loss: 0.013164297677576542
Test Loss:  0.007356995716691017
Valid Loss:  0.011981101706624031
Epoch:  285  	Training Loss: 0.01312828529626131
Test Loss:  0.007336163893342018
Valid Loss:  0.011952338740229607
Epoch:  286  	Training Loss: 0.013092425651848316
Test Loss:  0.007315419614315033
Valid Loss:  0.011923667043447495
Epoch:  287  	Training Loss: 0.013056717813014984
Test Loss:  0.007294764276593924
Valid Loss:  0.01189509592950344
Epoch:  288  	Training Loss: 0.013021145947277546
Test Loss:  0.007274198811501265
Valid Loss:  0.011866630986332893
Epoch:  289  	Training Loss: 0.01298573613166809
Test Loss:  0.007253732532262802
Valid Loss:  0.011838252656161785
Epoch:  290  	Training Loss: 0.012950466945767403
Test Loss:  0.007233348675072193
Valid Loss:  0.011809967458248138
Epoch:  291  	Training Loss: 0.012915344908833504
Test Loss:  0.007213050499558449
Valid Loss:  0.011781787499785423
Epoch:  292  	Training Loss: 0.012880371883511543
Test Loss:  0.007192842662334442
Valid Loss:  0.011753765866160393
Epoch:  293  	Training Loss: 0.012845657765865326
Test Loss:  0.007172727026045322
Valid Loss:  0.011725847609341145
Epoch:  294  	Training Loss: 0.012811092659831047
Test Loss:  0.007152685895562172
Valid Loss:  0.01169801689684391
Epoch:  295  	Training Loss: 0.012776666320860386
Test Loss:  0.00713273836299777
Valid Loss:  0.011670293286442757
Epoch:  296  	Training Loss: 0.012742379680275917
Test Loss:  0.007112874649465084
Valid Loss:  0.011642653495073318
Epoch:  297  	Training Loss: 0.012708239257335663
Test Loss:  0.007093100808560848
Valid Loss:  0.011615118011832237
Epoch:  298  	Training Loss: 0.012674234807491302
Test Loss:  0.007073410786688328
Valid Loss:  0.011587729677557945
Epoch:  299  	Training Loss: 0.01264036726206541
Test Loss:  0.007053801324218512
Valid Loss:  0.011560432612895966
Epoch:  300  	Training Loss: 0.01260664127767086
Test Loss:  0.007034276612102985
Valid Loss:  0.011533228680491447
Epoch:  301  	Training Loss: 0.012573055922985077
Test Loss:  0.007014840841293335
Valid Loss:  0.011506129987537861
Epoch:  302  	Training Loss: 0.012539606541395187
Test Loss:  0.006995509844273329
Valid Loss:  0.011479136534035206
Epoch:  303  	Training Loss: 0.012506093829870224
Test Loss:  0.0069762542843818665
Valid Loss:  0.011452170088887215
Epoch:  304  	Training Loss: 0.012472720816731453
Test Loss:  0.006957083009183407
Valid Loss:  0.011425353586673737
Epoch:  305  	Training Loss: 0.012439473532140255
Test Loss:  0.006937988102436066
Valid Loss:  0.011398572474718094
Epoch:  306  	Training Loss: 0.012406375259160995
Test Loss:  0.006918988190591335
Valid Loss:  0.011371931992471218
Epoch:  307  	Training Loss: 0.012373401783406734
Test Loss:  0.006900054402649403
Valid Loss:  0.011345336213707924
Epoch:  308  	Training Loss: 0.012340567074716091
Test Loss:  0.00688120536506176
Valid Loss:  0.011318877339363098
Epoch:  309  	Training Loss: 0.012307866476476192
Test Loss:  0.0068624429404735565
Valid Loss:  0.01129250880330801
Epoch:  310  	Training Loss: 0.01227529626339674
Test Loss:  0.006843751296401024
Valid Loss:  0.011266232468187809
Epoch:  311  	Training Loss: 0.012242857366800308
Test Loss:  0.006825143471360207
Valid Loss:  0.011240048334002495
Epoch:  312  	Training Loss: 0.012210546992719173
Test Loss:  0.0068066418170928955
Valid Loss:  0.01121392659842968
Epoch:  313  	Training Loss: 0.012178314849734306
Test Loss:  0.006788206286728382
Valid Loss:  0.011187901720404625
Epoch:  314  	Training Loss: 0.012146213091909885
Test Loss:  0.006769857369363308
Valid Loss:  0.011161953210830688
Epoch:  315  	Training Loss: 0.012114237993955612
Test Loss:  0.006751584354788065
Valid Loss:  0.011136109940707684
Epoch:  316  	Training Loss: 0.012082393281161785
Test Loss:  0.006733385846018791
Valid Loss:  0.011110334657132626
Epoch:  317  	Training Loss: 0.012050682678818703
Test Loss:  0.006715311668813229
Valid Loss:  0.011084930039942265
Epoch:  318  	Training Loss: 0.01201912946999073
Test Loss:  0.006697311066091061
Valid Loss:  0.011059602722525597
Epoch:  319  	Training Loss: 0.01198769360780716
Test Loss:  0.006679383106529713
Valid Loss:  0.011034354567527771
Epoch:  320  	Training Loss: 0.011956386268138885
Test Loss:  0.006661532912403345
Valid Loss:  0.011009185574948788
Epoch:  321  	Training Loss: 0.011925208382308483
Test Loss:  0.006643763743340969
Valid Loss:  0.010984107851982117
Epoch:  322  	Training Loss: 0.011894157156348228
Test Loss:  0.006626085378229618
Valid Loss:  0.01095915399491787
Epoch:  323  	Training Loss: 0.011863308027386665
Test Loss:  0.006608485244214535
Valid Loss:  0.010934282094240189
Epoch:  324  	Training Loss: 0.011832578107714653
Test Loss:  0.006590963341295719
Valid Loss:  0.010909488424658775
Epoch:  325  	Training Loss: 0.011801982298493385
Test Loss:  0.006573510821908712
Valid Loss:  0.010884780436754227
Epoch:  326  	Training Loss: 0.011771505698561668
Test Loss:  0.006556134670972824
Valid Loss:  0.010860158130526543
Epoch:  327  	Training Loss: 0.011741158552467823
Test Loss:  0.006538833025842905
Valid Loss:  0.010835628025233746
Epoch:  328  	Training Loss: 0.011710930615663528
Test Loss:  0.00652159983292222
Valid Loss:  0.010811173357069492
Epoch:  329  	Training Loss: 0.011680823750793934
Test Loss:  0.006504443008452654
Valid Loss:  0.010786810889840126
Epoch:  330  	Training Loss: 0.011650838889181614
Test Loss:  0.006487354636192322
Valid Loss:  0.010762524791061878
Epoch:  331  	Training Loss: 0.01162097230553627
Test Loss:  0.006470347288995981
Valid Loss:  0.010738315060734749
Epoch:  332  	Training Loss: 0.01159122958779335
Test Loss:  0.0064534591510891914
Valid Loss:  0.01071428507566452
Epoch:  333  	Training Loss: 0.011561717838048935
Test Loss:  0.006436644587665796
Valid Loss:  0.010690335184335709
Epoch:  334  	Training Loss: 0.011532328091561794
Test Loss:  0.006419898942112923
Valid Loss:  0.01066647656261921
Epoch:  335  	Training Loss: 0.011503051035106182
Test Loss:  0.006403227336704731
Valid Loss:  0.010642684064805508
Epoch:  336  	Training Loss: 0.011473894119262695
Test Loss:  0.006386615801602602
Valid Loss:  0.010618990287184715
Epoch:  337  	Training Loss: 0.011444857344031334
Test Loss:  0.006370091810822487
Valid Loss:  0.010595373809337616
Epoch:  338  	Training Loss: 0.0114159369841218
Test Loss:  0.006353641394525766
Valid Loss:  0.01057189516723156
Epoch:  339  	Training Loss: 0.011387128382921219
Test Loss:  0.006337258964776993
Valid Loss:  0.010548497550189495
Epoch:  340  	Training Loss: 0.011358441784977913
Test Loss:  0.006320946849882603
Valid Loss:  0.010525187477469444
Epoch:  341  	Training Loss: 0.01132986694574356
Test Loss:  0.006304701790213585
Valid Loss:  0.010501951910555363
Epoch:  342  	Training Loss: 0.011301407590508461
Test Loss:  0.006288362666964531
Valid Loss:  0.010478354059159756
Epoch:  343  	Training Loss: 0.011272232979536057
Test Loss:  0.006272096186876297
Valid Loss:  0.010454840958118439
Epoch:  344  	Training Loss: 0.011243171989917755
Test Loss:  0.006255891174077988
Valid Loss:  0.010431397706270218
Epoch:  345  	Training Loss: 0.011214226484298706
Test Loss:  0.006239759270101786
Valid Loss:  0.010408034548163414
Epoch:  346  	Training Loss: 0.01118539460003376
Test Loss:  0.006223689764738083
Valid Loss:  0.01038474589586258
Epoch:  347  	Training Loss: 0.011156683787703514
Test Loss:  0.006207682657986879
Valid Loss:  0.010361538268625736
Epoch:  348  	Training Loss: 0.011128079146146774
Test Loss:  0.006191746331751347
Valid Loss:  0.010338406078517437
Epoch:  349  	Training Loss: 0.01109959464520216
Test Loss:  0.006175875663757324
Valid Loss:  0.010315347462892532
Epoch:  350  	Training Loss: 0.01107122004032135
Test Loss:  0.0061600711196660995
Valid Loss:  0.01029236800968647
Epoch:  351  	Training Loss: 0.011042959056794643
Test Loss:  0.00614433316513896
Valid Loss:  0.010269464924931526
Epoch:  352  	Training Loss: 0.011014807969331741
Test Loss:  0.0061288983561098576
Valid Loss:  0.01024720724672079
Epoch:  353  	Training Loss: 0.010987789370119572
Test Loss:  0.006113535258919001
Valid Loss:   71%|███████   | 353/500 [04:11<02:12,  1.11it/s] 71%|███████   | 355/500 [04:11<01:34,  1.54it/s] 71%|███████▏  | 357/500 [04:11<01:08,  2.09it/s] 72%|███████▏  | 359/500 [04:11<00:49,  2.82it/s] 72%|███████▏  | 361/500 [04:18<02:53,  1.24s/it] 73%|███████▎  | 363/500 [04:18<02:03,  1.11it/s] 73%|███████▎  | 365/500 [04:18<01:27,  1.53it/s] 73%|███████▎  | 367/500 [04:18<01:04,  2.08it/s] 74%|███████▍  | 369/500 [04:18<00:47,  2.76it/s] 74%|███████▍  | 371/500 [04:25<02:38,  1.23s/it] 75%|███████▍  | 373/500 [04:25<01:52,  1.13it/s] 75%|███████▌  | 375/500 [04:25<01:19,  1.57it/s] 75%|███████▌  | 377/500 [04:25<00:57,  2.15it/s] 76%|███████▌  | 379/500 [04:26<00:41,  2.89it/s] 76%|███████▌  | 381/500 [04:32<02:23,  1.21s/it] 77%|███████▋  | 383/500 [04:32<01:41,  1.16it/s] 77%|███████▋  | 385/500 [04:32<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:32<00:51,  2.19it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.95it/s] 78%|███████▊  | 391/500 [04:39<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:39<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:39<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:39<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:39<00:34,  2.92it/s] 80%|████████  | 401/500 [04:46<01:58,  1.19s/it] 81%|████████  | 403/500 [04:46<01:23,  1.16it/s] 81%|████████  | 405/500 [04:46<00:59,  1.61it/s] 81%|████████▏ | 407/500 [04:46<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.96it/s] 82%|████████▏ | 411/500 [04:53<01:47,  1.20s/it] 83%|████████▎ | 413/500 [04:53<01:15,  1.16it/s] 83%|████████▎ | 415/500 [04:53<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:53<00:38,  2.18it/s] 84%|████████▍ | 419/500 [04:53<00:27,  2.94it/s] 84%|████████▍ | 421/500 [05:00<01:34,  1.20s/it] 85%|████████▍ | 423/500 [05:00<01:06,  1.15it/s]0.01022503525018692
Epoch:  354  	Training Loss: 0.010960876010358334
Test Loss:  0.006098234094679356
Valid Loss:  0.010202944278717041
Epoch:  355  	Training Loss: 0.010934071615338326
Test Loss:  0.006083001382648945
Valid Loss:  0.010180937126278877
Epoch:  356  	Training Loss: 0.010907374322414398
Test Loss:  0.006067833863198757
Valid Loss:  0.010159005410969257
Epoch:  357  	Training Loss: 0.010880784131586552
Test Loss:  0.006052727345377207
Valid Loss:  0.010137144476175308
Epoch:  358  	Training Loss: 0.010854298248887062
Test Loss:  0.0060376962646842
Valid Loss:  0.010115373879671097
Epoch:  359  	Training Loss: 0.010827911086380482
Test Loss:  0.006022726651281118
Valid Loss:  0.010093685239553452
Epoch:  360  	Training Loss: 0.01080163661390543
Test Loss:  0.0060078175738453865
Valid Loss:  0.010072072967886925
Epoch:  361  	Training Loss: 0.01077546551823616
Test Loss:  0.0059929778799414635
Valid Loss:  0.010050535202026367
Epoch:  362  	Training Loss: 0.01074939500540495
Test Loss:  0.005978178698569536
Valid Loss:  0.010028957389295101
Epoch:  363  	Training Loss: 0.010723171755671501
Test Loss:  0.005963440053164959
Valid Loss:  0.010007461532950401
Epoch:  364  	Training Loss: 0.010697049088776112
Test Loss:  0.005948767066001892
Valid Loss:  0.009986027143895626
Epoch:  365  	Training Loss: 0.010671027936041355
Test Loss:  0.00593415554612875
Valid Loss:  0.009964687749743462
Epoch:  366  	Training Loss: 0.01064511202275753
Test Loss:  0.005919608287513256
Valid Loss:  0.00994341541081667
Epoch:  367  	Training Loss: 0.010619301348924637
Test Loss:  0.0059051220305264
Valid Loss:  0.009922223165631294
Epoch:  368  	Training Loss: 0.010593589395284653
Test Loss:  0.005890700966119766
Valid Loss:  0.009901098906993866
Epoch:  369  	Training Loss: 0.010567978955805302
Test Loss:  0.005876340437680483
Valid Loss:  0.009880062192678452
Epoch:  370  	Training Loss: 0.010542499832808971
Test Loss:  0.005862119607627392
Valid Loss:  0.009859342128038406
Epoch:  371  	Training Loss: 0.010517137125134468
Test Loss:  0.005847956985235214
Valid Loss:  0.009838693775236607
Epoch:  372  	Training Loss: 0.010491877794265747
Test Loss:  0.005833701230585575
Valid Loss:  0.009817869402468204
Epoch:  373  	Training Loss: 0.010466374456882477
Test Loss:  0.005819495767354965
Valid Loss:  0.009797122329473495
Epoch:  374  	Training Loss: 0.010440964251756668
Test Loss:  0.005805361084640026
Valid Loss:  0.009776445105671883
Epoch:  375  	Training Loss: 0.010415658354759216
Test Loss:  0.005791276693344116
Valid Loss:  0.009755833074450493
Epoch:  376  	Training Loss: 0.010390453040599823
Test Loss:  0.005777257494628429
Valid Loss:  0.009735297411680222
Epoch:  377  	Training Loss: 0.010365341790020466
Test Loss:  0.005763289052993059
Valid Loss:  0.009714825078845024
Epoch:  378  	Training Loss: 0.010340330190956593
Test Loss:  0.005749383009970188
Valid Loss:  0.009694420732557774
Epoch:  379  	Training Loss: 0.010315414518117905
Test Loss:  0.005735536105930805
Valid Loss:  0.00967409834265709
Epoch:  380  	Training Loss: 0.010290602222084999
Test Loss:  0.005721742287278175
Valid Loss:  0.009653834626078606
Epoch:  381  	Training Loss: 0.010265880264341831
Test Loss:  0.005708026234060526
Valid Loss:  0.009633688256144524
Epoch:  382  	Training Loss: 0.010241271927952766
Test Loss:  0.005694515071809292
Valid Loss:  0.00961381383240223
Epoch:  383  	Training Loss: 0.010216939263045788
Test Loss:  0.005681061185896397
Valid Loss:  0.00959399901330471
Epoch:  384  	Training Loss: 0.010192696005105972
Test Loss:  0.00566765945404768
Valid Loss:  0.009574241936206818
Epoch:  385  	Training Loss: 0.01016855426132679
Test Loss:  0.005654315464198589
Valid Loss:  0.009554567746818066
Epoch:  386  	Training Loss: 0.010144502855837345
Test Loss:  0.005641031078994274
Valid Loss:  0.009534954093396664
Epoch:  387  	Training Loss: 0.01012054830789566
Test Loss:  0.005627792328596115
Valid Loss:  0.009515395388007164
Epoch:  388  	Training Loss: 0.010096689686179161
Test Loss:  0.005614615045487881
Valid Loss:  0.009495912119746208
Epoch:  389  	Training Loss: 0.010072914883494377
Test Loss:  0.005601493641734123
Valid Loss:  0.009476501494646072
Epoch:  390  	Training Loss: 0.010049242526292801
Test Loss:  0.005588422529399395
Valid Loss:  0.009457145817577839
Epoch:  391  	Training Loss: 0.010025663301348686
Test Loss:  0.0055754054337739944
Valid Loss:  0.009437866508960724
Epoch:  392  	Training Loss: 0.010002168826758862
Test Loss:  0.005562480539083481
Valid Loss:  0.009418860077857971
Epoch:  393  	Training Loss: 0.00997924618422985
Test Loss:  0.005549699999392033
Valid Loss:  0.009400174021720886
Epoch:  394  	Training Loss: 0.009956439957022667
Test Loss:  0.005536971613764763
Valid Loss:  0.009381556883454323
Epoch:  395  	Training Loss: 0.009933722205460072
Test Loss:  0.005524293519556522
Valid Loss:  0.00936301238834858
Epoch:  396  	Training Loss: 0.009911095723509789
Test Loss:  0.005511674098670483
Valid Loss:  0.009344521909952164
Epoch:  397  	Training Loss: 0.009888559579849243
Test Loss:  0.005499101243913174
Valid Loss:  0.009326104074716568
Epoch:  398  	Training Loss: 0.00986611656844616
Test Loss:  0.005486592184752226
Valid Loss:  0.00930773839354515
Epoch:  399  	Training Loss: 0.009843760170042515
Test Loss:  0.005474129691720009
Valid Loss:  0.009289450943470001
Epoch:  400  	Training Loss: 0.009821492247283459
Test Loss:  0.005461718887090683
Valid Loss:  0.00927121751010418
Epoch:  401  	Training Loss: 0.009799307212233543
Test Loss:  0.005449364427477121
Valid Loss:  0.009253045544028282
Epoch:  402  	Training Loss: 0.009777219034731388
Test Loss:  0.005437103100121021
Valid Loss:  0.009235086850821972
Epoch:  403  	Training Loss: 0.00975539069622755
Test Loss:  0.005424882750958204
Valid Loss:  0.00921719428151846
Epoch:  404  	Training Loss: 0.009733656421303749
Test Loss:  0.005412823520600796
Valid Loss:  0.00919963326305151
Epoch:  405  	Training Loss: 0.009712031111121178
Test Loss:  0.005400817841291428
Valid Loss:  0.009182129986584187
Epoch:  406  	Training Loss: 0.009690491482615471
Test Loss:  0.005388855468481779
Valid Loss:  0.009164687246084213
Epoch:  407  	Training Loss: 0.00966903567314148
Test Loss:  0.005376943852752447
Valid Loss:  0.009147297590970993
Epoch:  408  	Training Loss: 0.009647667407989502
Test Loss:  0.005365084856748581
Valid Loss:  0.009129978716373444
Epoch:  409  	Training Loss: 0.009626391343772411
Test Loss:  0.005353269632905722
Valid Loss:  0.009112699888646603
Epoch:  410  	Training Loss: 0.009605188854038715
Test Loss:  0.005341509822756052
Valid Loss:  0.009095494635403156
Epoch:  411  	Training Loss: 0.00958408322185278
Test Loss:  0.005329791456460953
Valid Loss:  0.009078342467546463
Epoch:  412  	Training Loss: 0.00956304743885994
Test Loss:  0.005318133160471916
Valid Loss:  0.009061165153980255
Epoch:  413  	Training Loss: 0.009541880339384079
Test Loss:  0.005306513514369726
Valid Loss:  0.009044032543897629
Epoch:  414  	Training Loss: 0.009520799852907658
Test Loss:  0.00529497629031539
Valid Loss:  0.00902701448649168
Epoch:  415  	Training Loss: 0.009499802254140377
Test Loss:  0.005283478181809187
Valid Loss:  0.009010061621665955
Epoch:  416  	Training Loss: 0.009478885680437088
Test Loss:  0.0052720229141414165
Valid Loss:  0.008993152529001236
Epoch:  417  	Training Loss: 0.009458057582378387
Test Loss:  0.005260597914457321
Valid Loss:  0.008976269513368607
Epoch:  418  	Training Loss: 0.009437311440706253
Test Loss:  0.005249238573014736
Valid Loss:  0.008959529921412468
Epoch:  419  	Training Loss: 0.00941664632409811
Test Loss:  0.005237924866378307
Valid Loss:  0.008942851796746254
Epoch:  420  	Training Loss: 0.009396066889166832
Test Loss:  0.005226660519838333
Valid Loss:  0.0089262118563056
Epoch:  421  	Training Loss: 0.009375562891364098
Test Loss:  0.005215438082814217
Valid Loss:  0.008909638971090317
Epoch:  422  	Training Loss: 0.00935514084994793
Test Loss:  0.005204278975725174
Valid Loss:  0.008893189020454884
Epoch:  423  	Training Loss: 0.009334932081401348
Test Loss:  0.005193176679313183
Valid Loss:  0.008876791223883629
 85%|████████▌ | 425/500 [05:00<00:47,  1.58it/s] 85%|████████▌ | 427/500 [05:00<00:34,  2.14it/s] 86%|████████▌ | 429/500 [05:00<00:25,  2.83it/s] 86%|████████▌ | 431/500 [05:07<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:07<00:58,  1.14it/s] 87%|████████▋ | 435/500 [05:07<00:41,  1.57it/s] 87%|████████▋ | 437/500 [05:07<00:29,  2.12it/s] 88%|████████▊ | 439/500 [05:07<00:21,  2.84it/s] 88%|████████▊ | 441/500 [05:14<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:14<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:14<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:14<00:24,  2.18it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.93it/s] 90%|█████████ | 451/500 [05:21<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:21<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:21<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:21<00:19,  2.16it/s] 92%|█████████▏| 459/500 [05:21<00:14,  2.85it/s] 92%|█████████▏| 461/500 [05:28<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:28<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:28<00:22,  1.57it/s] 93%|█████████▎| 467/500 [05:28<00:15,  2.13it/s] 94%|█████████▍| 469/500 [05:29<00:10,  2.85it/s] 94%|█████████▍| 471/500 [05:35<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:35<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:35<00:15,  1.58it/s] 95%|█████████▌| 477/500 [05:35<00:10,  2.14it/s] 96%|█████████▌| 479/500 [05:36<00:07,  2.84it/s] 96%|█████████▌| 481/500 [05:42<00:23,  1.22s/it] 97%|█████████▋| 483/500 [05:42<00:14,  1.14it/s] 97%|█████████▋| 485/500 [05:42<00:09,  1.58it/s] 97%|█████████▋| 487/500 [05:43<00:06,  2.14it/s] 98%|█████████▊| 489/500 [05:43<00:03,  2.83it/s] 98%|█████████▊| 491/500 [05:49<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:49<00:06,  1.15it/s]Epoch:  424  	Training Loss: 0.00931479874998331
Test Loss:  0.005182115361094475
Valid Loss:  0.008860448375344276
Epoch:  425  	Training Loss: 0.009294744580984116
Test Loss:  0.005171095486730337
Valid Loss:  0.008844161406159401
Epoch:  426  	Training Loss: 0.009274772368371487
Test Loss:  0.0051601240411400795
Valid Loss:  0.008827939629554749
Epoch:  427  	Training Loss: 0.009254874661564827
Test Loss:  0.005149194970726967
Valid Loss:  0.008811763487756252
Epoch:  428  	Training Loss: 0.009235063567757607
Test Loss:  0.005138315726071596
Valid Loss:  0.00879565067589283
Epoch:  429  	Training Loss: 0.009215323254466057
Test Loss:  0.005127480253577232
Valid Loss:  0.008779582567512989
Epoch:  430  	Training Loss: 0.009195659309625626
Test Loss:  0.005116687156260014
Valid Loss:  0.008763572201132774
Epoch:  431  	Training Loss: 0.009176073595881462
Test Loss:  0.005105947144329548
Valid Loss:  0.008747623302042484
Epoch:  432  	Training Loss: 0.00915657076984644
Test Loss:  0.00509529747068882
Valid Loss:  0.008731715381145477
Epoch:  433  	Training Loss: 0.009137031622231007
Test Loss:  0.0050846878439188
Valid Loss:  0.008715859614312649
Epoch:  434  	Training Loss: 0.009117571637034416
Test Loss:  0.0050741201266646385
Valid Loss:  0.008700061589479446
Epoch:  435  	Training Loss: 0.00909818522632122
Test Loss:  0.005063602700829506
Valid Loss:  0.008684307336807251
Epoch:  436  	Training Loss: 0.009078887291252613
Test Loss:  0.005053236149251461
Valid Loss:  0.00866883434355259
Epoch:  437  	Training Loss: 0.009059682488441467
Test Loss:  0.00504290871322155
Valid Loss:  0.008653417229652405
Epoch:  438  	Training Loss: 0.009040557779371738
Test Loss:  0.00503262085840106
Valid Loss:  0.00863803829997778
Epoch:  439  	Training Loss: 0.009021507576107979
Test Loss:  0.005022376775741577
Valid Loss:  0.008622714318335056
Epoch:  440  	Training Loss: 0.009002536535263062
Test Loss:  0.005012172739952803
Valid Loss:  0.008607441559433937
Epoch:  441  	Training Loss: 0.008983638137578964
Test Loss:  0.0050020101480185986
Valid Loss:  0.008592218160629272
Epoch:  442  	Training Loss: 0.00896481703966856
Test Loss:  0.004991897381842136
Valid Loss:  0.008577043190598488
Epoch:  443  	Training Loss: 0.00894603319466114
Test Loss:  0.004981826059520245
Valid Loss:  0.008561923168599606
Epoch:  444  	Training Loss: 0.008927326649427414
Test Loss:  0.004971794318407774
Valid Loss:  0.008546841330826283
Epoch:  445  	Training Loss: 0.008908692747354507
Test Loss:  0.004961805418133736
Valid Loss:  0.008531821891665459
Epoch:  446  	Training Loss: 0.008890137076377869
Test Loss:  0.004951851442456245
Valid Loss:  0.008516840636730194
Epoch:  447  	Training Loss: 0.008871650323271751
Test Loss:  0.004941939376294613
Valid Loss:  0.008501905016601086
Epoch:  448  	Training Loss: 0.008853239007294178
Test Loss:  0.004932058975100517
Valid Loss:  0.008487027138471603
Epoch:  449  	Training Loss: 0.008834896609187126
Test Loss:  0.004922221414744854
Valid Loss:  0.008472202345728874
Epoch:  450  	Training Loss: 0.008816629648208618
Test Loss:  0.004912428557872772
Valid Loss:  0.008457424119114876
Epoch:  451  	Training Loss: 0.008798438124358654
Test Loss:  0.004902698565274477
Valid Loss:  0.008442739024758339
Epoch:  452  	Training Loss: 0.008780326694250107
Test Loss:  0.004892781376838684
Valid Loss:  0.008427998051047325
Epoch:  453  	Training Loss: 0.008762341924011707
Test Loss:  0.004882911220192909
Valid Loss:  0.008413300849497318
Epoch:  454  	Training Loss: 0.0087444381788373
Test Loss:  0.004873085301369429
Valid Loss:  0.00839866790920496
Epoch:  455  	Training Loss: 0.008726602420210838
Test Loss:  0.004863295704126358
Valid Loss:  0.00838407501578331
Epoch:  456  	Training Loss: 0.008708829060196877
Test Loss:  0.004853549413383007
Valid Loss:  0.008369546383619308
Epoch:  457  	Training Loss: 0.008691132068634033
Test Loss:  0.00484385434538126
Valid Loss:  0.008355059660971165
Epoch:  458  	Training Loss: 0.008673500269651413
Test Loss:  0.0048341937363147736
Valid Loss:  0.008340629749000072
Epoch:  459  	Training Loss: 0.008655939251184464
Test Loss:  0.00482457410544157
Valid Loss:  0.008326249197125435
Epoch:  460  	Training Loss: 0.008638444356620312
Test Loss:  0.004814997315406799
Valid Loss:  0.008311929181218147
Epoch:  461  	Training Loss: 0.008621026761829853
Test Loss:  0.004805461503565311
Valid Loss:  0.008297644555568695
Epoch:  462  	Training Loss: 0.008603661321103573
Test Loss:  0.004796179011464119
Valid Loss:  0.008283589966595173
Epoch:  463  	Training Loss: 0.008586456999182701
Test Loss:  0.00478692352771759
Valid Loss:  0.008269576355814934
Epoch:  464  	Training Loss: 0.008569320663809776
Test Loss:  0.0047777071595191956
Valid Loss:  0.008255615830421448
Epoch:  465  	Training Loss: 0.008552249521017075
Test Loss:  0.004768533632159233
Valid Loss:  0.008241696283221245
Epoch:  466  	Training Loss: 0.008535245433449745
Test Loss:  0.004759394098073244
Valid Loss:  0.008227834478020668
Epoch:  467  	Training Loss: 0.008518308401107788
Test Loss:  0.0047502969391644
Valid Loss:  0.008214013651013374
Epoch:  468  	Training Loss: 0.008501436561346054
Test Loss:  0.004741231445223093
Valid Loss:  0.008200242184102535
Epoch:  469  	Training Loss: 0.008484631776809692
Test Loss:  0.004732207395136356
Valid Loss:  0.00818651169538498
Epoch:  470  	Training Loss: 0.008467894047498703
Test Loss:  0.004723215941339731
Valid Loss:  0.008172839879989624
Epoch:  471  	Training Loss: 0.008451223373413086
Test Loss:  0.004714268259704113
Valid Loss:  0.00815921276807785
Epoch:  472  	Training Loss: 0.008434616960585117
Test Loss:  0.0047052642330527306
Valid Loss:  0.008145438507199287
Epoch:  473  	Training Loss: 0.008417768403887749
Test Loss:  0.004696300253272057
Valid Loss:  0.008131714537739754
Epoch:  474  	Training Loss: 0.008400984108448029
Test Loss:  0.004687376786023378
Valid Loss:  0.008118031546473503
Epoch:  475  	Training Loss: 0.00838426873087883
Test Loss:  0.00467847753316164
Valid Loss:  0.008104396052658558
Epoch:  476  	Training Loss: 0.008367618545889854
Test Loss:  0.004669621586799622
Valid Loss:  0.008090805262327194
Epoch:  477  	Training Loss: 0.008351032622158527
Test Loss:  0.004660806152969599
Valid Loss:  0.008077269420027733
Epoch:  478  	Training Loss: 0.008334505371749401
Test Loss:  0.004652022384107113
Valid Loss:  0.008063776418566704
Epoch:  479  	Training Loss: 0.008318048901855946
Test Loss:  0.004643275402486324
Valid Loss:  0.008050326257944107
Epoch:  480  	Training Loss: 0.00830165483057499
Test Loss:  0.00463456567376852
Valid Loss:  0.008036921732127666
Epoch:  481  	Training Loss: 0.008285322226583958
Test Loss:  0.004625888541340828
Valid Loss:  0.008023565635085106
Epoch:  482  	Training Loss: 0.008269052021205425
Test Loss:  0.00461729196831584
Valid Loss:  0.008010469377040863
Epoch:  483  	Training Loss: 0.008253280073404312
Test Loss:  0.004608734976500273
Valid Loss:  0.007997425273060799
Epoch:  484  	Training Loss: 0.008237563073635101
Test Loss:  0.004600212909281254
Valid Loss:  0.007984422147274017
Epoch:  485  	Training Loss: 0.008221912197768688
Test Loss:  0.004591728560626507
Valid Loss:  0.007971474900841713
Epoch:  486  	Training Loss: 0.00820632092654705
Test Loss:  0.004583335947245359
Valid Loss:  0.007958576083183289
Epoch:  487  	Training Loss: 0.008190788328647614
Test Loss:  0.00457500945776701
Valid Loss:  0.007945713587105274
Epoch:  488  	Training Loss: 0.008175315335392952
Test Loss:  0.004566717892885208
Valid Loss:  0.007932906970381737
Epoch:  489  	Training Loss: 0.00815990287810564
Test Loss:  0.004558471031486988
Valid Loss:  0.007920142263174057
Epoch:  490  	Training Loss: 0.008144550025463104
Test Loss:  0.004550257697701454
Valid Loss:  0.007907424122095108
Epoch:  491  	Training Loss: 0.008129257708787918
Test Loss:  0.004542079754173756
Valid Loss:  0.007894765585660934
Epoch:  492  	Training Loss: 0.008114021271467209
Test Loss:  0.004533878527581692
Valid Loss:  0.007882041856646538
Epoch:  493  	Training Loss: 0.008098531514406204
Test Loss:  0.004525709897279739
Valid Loss:  0.007869366556406021
 99%|█████████▉| 495/500 [05:49<00:03,  1.60it/s] 99%|█████████▉| 497/500 [05:49<00:01,  2.18it/s]100%|█████████▉| 499/500 [05:50<00:00,  2.94it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
Epoch:  494  	Training Loss: 0.008083087392151356
Test Loss:  0.004517579451203346
Valid Loss:  0.00785672664642334
Epoch:  495  	Training Loss: 0.00806771032512188
Test Loss:  0.004509493242949247
Valid Loss:  0.007844138890504837
Epoch:  496  	Training Loss: 0.008052387274801731
Test Loss:  0.00450143963098526
Valid Loss:  0.00783159863203764
Epoch:  497  	Training Loss: 0.008037126623094082
Test Loss:  0.004493429325520992
Valid Loss:  0.007819097489118576
Epoch:  498  	Training Loss: 0.008021912537515163
Test Loss:  0.004485452547669411
Valid Loss:  0.007806653156876564
Epoch:  499  	Training Loss: 0.008006777614355087
Test Loss:  0.004477509297430515
Valid Loss:  0.007794256322085857
Epoch:  500  	Training Loss: 0.007991692051291466
Test Loss:  0.004469598643481731
Valid Loss:  0.007781913038343191
seed is  1
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:21,  6.30s/it]  1%|          | 3/500 [00:06<14:03,  1.70s/it]  1%|          | 5/500 [00:06<07:10,  1.15it/s]  1%|▏         | 7/500 [00:06<04:25,  1.86it/s]  2%|▏         | 9/500 [00:06<02:58,  2.76it/s]  2%|▏         | 11/500 [00:13<10:55,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.97it/s]  4%|▍         | 21/500 [00:20<09:41,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.20it/s]  6%|▌         | 29/500 [00:20<02:39,  2.95it/s]  6%|▌         | 31/500 [00:27<09:27,  1.21s/it]  7%|▋         | 33/500 [00:27<06:47,  1.15it/s]  7%|▋         | 35/500 [00:27<04:56,  1.57it/s]  7%|▋         | 37/500 [00:27<03:38,  2.12it/s]  8%|▊         | 39/500 [00:27<02:43,  2.82it/s]  8%|▊         | 39/500 [00:39<02:43,  2.82it/s]  8%|▊         | 41/500 [00:40<16:32,  2.16s/it]  9%|▊         | 43/500 [00:40<11:41,  1.54s/it]  9%|▉         | 45/500 [00:40<08:18,  1.09s/it]  9%|▉         | 47/500 [00:41<05:55,  1.27it/s] 10%|▉         | 49/500 [00:41<04:16,  1.76it/s] 10%|█         | 51/500 [00:47<10:06,  1.35s/it] 11%|█         | 53/500 [00:47<07:12,  1.03it/s] 11%|█         | 55/500 [00:47<05:10,  1.43it/s] 11%|█▏        | 57/500 [00:47<03:44,  1.97it/s] 12%|█▏        | 59/500 [00:48<02:45,  2.67it/s] 12%|█▏        | 59/500 [00:59<02:45,  2.67it/s] 12%|█▏        | 61/500 [01:00<15:47,  2.16s/it] 13%|█▎        | 63/500 [01:00<11:10,  1.53s/it] 13%|█▎        | 65/500 [01:01<07:55,  1.09s/it] 13%|█▎        | 67/500 [01:01<05:39,  1.27it/s] 14%|█▍        | 69/500 [01:01<04:05,  1.76it/s]Epoch:  1  	Training Loss: 0.027675703167915344
Test Loss:  0.003851853311061859
Valid Loss:  0.006093442440032959
Epoch:  2  	Training Loss: 0.005927294958382845
Test Loss:  0.0038798481691628695
Valid Loss:  0.004361097235232592
Epoch:  3  	Training Loss: 0.0036405392456799746
Test Loss:  0.014403476379811764
Valid Loss:  0.01661459170281887
Epoch:  4  	Training Loss: 0.01851698011159897
Test Loss:  0.1946343630552292
Valid Loss:  0.18594253063201904
Epoch:  5  	Training Loss: 0.172805517911911
Test Loss:  0.02277243323624134
Valid Loss:  0.025454357266426086
Epoch:  6  	Training Loss: 0.030000628903508186
Test Loss:  0.022007368505001068
Valid Loss:  0.024792112410068512
Epoch:  7  	Training Loss: 0.029226362705230713
Test Loss:  0.02127404883503914
Valid Loss:  0.02420842833817005
Epoch:  8  	Training Loss: 0.02851134166121483
Test Loss:  0.02058175764977932
Valid Loss:  0.02362057939171791
Epoch:  9  	Training Loss: 0.027788354083895683
Test Loss:  0.019795367494225502
Valid Loss:  0.022992730140686035
Epoch:  10  	Training Loss: 0.026987455785274506
Test Loss:  0.018133535981178284
Valid Loss:  0.02166265808045864
Epoch:  11  	Training Loss: 0.025515027344226837
Test Loss:  0.015702560544013977
Valid Loss:  0.019654683768749237
Epoch:  12  	Training Loss: 0.02326774224638939
Test Loss:  0.12766051292419434
Valid Loss:  0.12309172749519348
Epoch:  13  	Training Loss: 0.1118367537856102
Test Loss:  0.18033424019813538
Valid Loss:  0.18716825544834137
Epoch:  14  	Training Loss: 0.1943584531545639
Test Loss:  0.01818726398050785
Valid Loss:  0.02551095187664032
Epoch:  15  	Training Loss: 0.029818354174494743
Test Loss:  0.017994031310081482
Valid Loss:  0.02533010207116604
Epoch:  16  	Training Loss: 0.029597733169794083
Test Loss:  0.017832741141319275
Valid Loss:  0.025119008496403694
Epoch:  17  	Training Loss: 0.029354557394981384
Test Loss:  0.01770002208650112
Valid Loss:  0.024941392242908478
Epoch:  18  	Training Loss: 0.029156450182199478
Test Loss:  0.017575614154338837
Valid Loss:  0.02476954087615013
Epoch:  19  	Training Loss: 0.028972232714295387
Test Loss:  0.01745113730430603
Valid Loss:  0.024600133299827576
Epoch:  20  	Training Loss: 0.028794467449188232
Test Loss:  0.01733086071908474
Valid Loss:  0.02444053441286087
Epoch:  21  	Training Loss: 0.028622008860111237
Test Loss:  0.017214342951774597
Valid Loss:  0.02429381012916565
Epoch:  22  	Training Loss: 0.028453169390559196
Test Loss:  0.017702845856547356
Valid Loss:  0.024141358211636543
Epoch:  23  	Training Loss: 0.02841910719871521
Test Loss:  0.015688486397266388
Valid Loss:  0.021890902891755104
Epoch:  24  	Training Loss: 0.02528269961476326
Test Loss:  0.015216872096061707
Valid Loss:  0.021211538463830948
Epoch:  25  	Training Loss: 0.024454373866319656
Test Loss:  0.014702755957841873
Valid Loss:  0.02054930478334427
Epoch:  26  	Training Loss: 0.023596350103616714
Test Loss:  0.014224228449165821
Valid Loss:  0.019933894276618958
Epoch:  27  	Training Loss: 0.022797346115112305
Test Loss:  0.013752620667219162
Valid Loss:  0.01934291422367096
Epoch:  28  	Training Loss: 0.022024139761924744
Test Loss:  0.013478525914251804
Valid Loss:  0.018985973671078682
Epoch:  29  	Training Loss: 0.021481048315763474
Test Loss:  0.013074284419417381
Valid Loss:  0.018415525555610657
Epoch:  30  	Training Loss: 0.02082556113600731
Test Loss:  0.012709180824458599
Valid Loss:  0.017926959320902824
Epoch:  31  	Training Loss: 0.020204193890094757
Test Loss:  0.01235956884920597
Valid Loss:  0.0174555666744709
Epoch:  32  	Training Loss: 0.019610095769166946
Test Loss:  0.011676274240016937
Valid Loss:  0.016287706792354584
Epoch:  33  	Training Loss: 0.01817498169839382
Test Loss:  0.011359477415680885
Valid Loss:  0.015883898362517357
Epoch:  34  	Training Loss: 0.017531808465719223
Test Loss:  0.00911789946258068
Valid Loss:  0.013555184938013554
Epoch:  35  	Training Loss: 0.015009928494691849
Test Loss:  0.010640638880431652
Valid Loss:  0.01466052234172821
Epoch:  36  	Training Loss: 0.017233485355973244
Test Loss:  0.011835824698209763
Valid Loss:  0.016192682087421417
Epoch:  37  	Training Loss: 0.017247652634978294
Test Loss:  0.011591882444918156
Valid Loss:  0.01578095741569996
Epoch:  38  	Training Loss: 0.016980161890387535
Test Loss:  0.01153743825852871
Valid Loss:  0.015660058706998825
Epoch:  39  	Training Loss: 0.016843685880303383
Test Loss:  0.011370690539479256
Valid Loss:  0.015467515215277672
Epoch:  40  	Training Loss: 0.01649872213602066
Test Loss:  0.010325642302632332
Valid Loss:  0.014680983498692513
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.015198564156889915
Test Loss:  0.010087082162499428
Valid Loss:  0.013777676969766617
Epoch:  42  	Training Loss: 0.014187309890985489
Test Loss:  0.009262163192033768
Valid Loss:  0.012862123548984528
Epoch:  43  	Training Loss: 0.013421153649687767
Test Loss:  0.009204418398439884
Valid Loss:  0.012781630270183086
Epoch:  44  	Training Loss: 0.013386597856879234
Test Loss:  0.00917473342269659
Valid Loss:  0.01274739857763052
Epoch:  45  	Training Loss: 0.01334499754011631
Test Loss:  0.009144100360572338
Valid Loss:  0.012713545933365822
Epoch:  46  	Training Loss: 0.013316642493009567
Test Loss:  0.009114086627960205
Valid Loss:  0.012680415995419025
Epoch:  47  	Training Loss: 0.013288779184222221
Test Loss:  0.009084664285182953
Valid Loss:  0.0126479621976614
Epoch:  48  	Training Loss: 0.013261396437883377
Test Loss:  0.009055811911821365
Valid Loss:  0.012616164982318878
Epoch:  49  	Training Loss: 0.013234470970928669
Test Loss:  0.009027509018778801
Valid Loss:  0.012585017830133438
Epoch:  50  	Training Loss: 0.013208044692873955
Test Loss:  0.008998198434710503
Valid Loss:  0.012552082538604736
Epoch:  51  	Training Loss: 0.013182142749428749
Test Loss:  0.008971992880105972
Valid Loss:  0.012523782439529896
Epoch:  52  	Training Loss: 0.013156555593013763
Test Loss:  0.008728863671422005
Valid Loss:  0.01225899625569582
Epoch:  53  	Training Loss: 0.012916984967887402
Test Loss:  0.008667219430208206
Valid Loss:  0.012247171252965927
Epoch:  54  	Training Loss: 0.013277001678943634
Test Loss:  0.008767028339207172
Valid Loss:  0.012287788093090057
Epoch:  55  	Training Loss: 0.01294940896332264
Test Loss:  0.008532865904271603
Valid Loss:  0.012028351426124573
Epoch:  56  	Training Loss: 0.012831602245569229
Test Loss:  0.00878729298710823
Valid Loss:  0.01229371502995491
Epoch:  57  	Training Loss: 0.012968512251973152
Test Loss:  0.00876571610569954
Valid Loss:  0.01227356493473053
Epoch:  58  	Training Loss: 0.012944628484547138
Test Loss:  0.008737832307815552
Valid Loss:  0.012250524014234543
Epoch:  59  	Training Loss: 0.012914134189486504
Test Loss:  0.008779703639447689
Valid Loss:  0.012298623099923134
Epoch:  60  	Training Loss: 0.012946566566824913
Test Loss:  0.008788688108325005
Valid Loss:  0.012281783856451511
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.012964960187673569
Test Loss:  0.008467564359307289
Valid Loss:  0.011859264224767685
Epoch:  62  	Training Loss: 0.012492053210735321
Test Loss:  0.008055211044847965
Valid Loss:  0.011067877523601055
Epoch:  63  	Training Loss: 0.01133618876338005
Test Loss:  0.008113862946629524
Valid Loss:  0.011065714992582798
Epoch:  64  	Training Loss: 0.0111840246245265
Test Loss:  0.00817628763616085
Valid Loss:  0.011086225509643555
Epoch:  65  	Training Loss: 0.011099297553300858
Test Loss:  0.00823780708014965
Valid Loss:  0.011113817803561687
Epoch:  66  	Training Loss: 0.0110427625477314
Test Loss:  0.00829397700726986
Valid Loss:  0.011142536997795105
Epoch:  67  	Training Loss: 0.011004195548593998
Test Loss:  0.008342934772372246
Valid Loss:  0.01116927433758974
Epoch:  68  	Training Loss: 0.010977093130350113
Test Loss:  0.008384274318814278
Valid Loss:  0.011192591860890388
Epoch:  69  	Training Loss: 0.01095731183886528
Test Loss:  0.008418332785367966
Valid Loss:  0.011212002485990524
 14%|█▍        | 71/500 [01:07<09:35,  1.34s/it] 15%|█▍        | 73/500 [01:07<06:50,  1.04it/s] 15%|█▌        | 75/500 [01:07<04:54,  1.44it/s] 15%|█▌        | 77/500 [01:07<03:34,  1.97it/s] 16%|█▌        | 79/500 [01:08<02:37,  2.67it/s] 16%|█▌        | 81/500 [01:14<08:32,  1.22s/it] 17%|█▋        | 83/500 [01:14<06:07,  1.14it/s] 17%|█▋        | 85/500 [01:14<04:23,  1.57it/s] 17%|█▋        | 87/500 [01:14<03:12,  2.15it/s] 18%|█▊        | 89/500 [01:15<02:22,  2.89it/s] 18%|█▊        | 91/500 [01:21<08:22,  1.23s/it] 19%|█▊        | 93/500 [01:21<05:58,  1.13it/s] 19%|█▉        | 95/500 [01:21<04:18,  1.57it/s] 19%|█▉        | 97/500 [01:22<03:08,  2.14it/s] 20%|█▉        | 99/500 [01:22<02:18,  2.89it/s] 20%|██        | 101/500 [01:28<08:08,  1.22s/it] 21%|██        | 103/500 [01:28<05:48,  1.14it/s] 21%|██        | 105/500 [01:29<04:10,  1.58it/s] 21%|██▏       | 107/500 [01:29<03:02,  2.16it/s] 22%|██▏       | 109/500 [01:29<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:35<07:45,  1.20s/it] 23%|██▎       | 113/500 [01:35<05:34,  1.16it/s] 23%|██▎       | 115/500 [01:35<04:02,  1.59it/s] 23%|██▎       | 117/500 [01:36<02:58,  2.14it/s] 24%|██▍       | 119/500 [01:36<02:14,  2.84it/s] 24%|██▍       | 121/500 [01:42<07:37,  1.21s/it] 25%|██▍       | 123/500 [01:42<05:27,  1.15it/s] 25%|██▌       | 125/500 [01:43<03:55,  1.59it/s] 25%|██▌       | 127/500 [01:43<02:51,  2.18it/s] 26%|██▌       | 129/500 [01:43<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:49<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:49<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:49<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:49<02:42,  2.23it/s]Epoch:  70  	Training Loss: 0.010942191816866398
Test Loss:  0.008445914834737778
Valid Loss:  0.011227548122406006
Epoch:  71  	Training Loss: 0.010930042713880539
Test Loss:  0.00846777856349945
Valid Loss:  0.01123952679336071
Epoch:  72  	Training Loss: 0.010919790714979172
Test Loss:  0.008078506216406822
Valid Loss:  0.010430097579956055
Epoch:  73  	Training Loss: 0.01013509277254343
Test Loss:  0.007601890247315168
Valid Loss:  0.009576731361448765
Epoch:  74  	Training Loss: 0.009248909540474415
Test Loss:  0.006961034145206213
Valid Loss:  0.008755899034440517
Epoch:  75  	Training Loss: 0.008329872041940689
Test Loss:  0.006324290297925472
Valid Loss:  0.007968389429152012
Epoch:  76  	Training Loss: 0.00742206908762455
Test Loss:  0.005731990095227957
Valid Loss:  0.007239282131195068
Epoch:  77  	Training Loss: 0.006618854124099016
Test Loss:  0.0051840017549693584
Valid Loss:  0.006590935401618481
Epoch:  78  	Training Loss: 0.00591781921684742
Test Loss:  0.00469375541433692
Valid Loss:  0.006008286494761705
Epoch:  79  	Training Loss: 0.0053099580109119415
Test Loss:  0.004263400565832853
Valid Loss:  0.005497279576957226
Epoch:  80  	Training Loss: 0.004799698479473591
Test Loss:  0.003889253828674555
Valid Loss:  0.005055146757513285
Epoch:  81  	Training Loss: 0.004367179702967405
Test Loss:  0.003559616394340992
Valid Loss:  0.00467194989323616
Epoch:  82  	Training Loss: 0.003998394124209881
Test Loss:  0.0033522378653287888
Valid Loss:  0.004409376531839371
Epoch:  83  	Training Loss: 0.00378625001758337
Test Loss:  0.0033173132687807083
Valid Loss:  0.004339691251516342
Epoch:  84  	Training Loss: 0.00372783443890512
Test Loss:  0.003301562275737524
Valid Loss:  0.004313672427088022
Epoch:  85  	Training Loss: 0.003701823763549328
Test Loss:  0.0032886629924178123
Valid Loss:  0.004300941713154316
Epoch:  86  	Training Loss: 0.003688297001644969
Test Loss:  0.0032779022585600615
Valid Loss:  0.004292193800210953
Epoch:  87  	Training Loss: 0.00367891788482666
Test Loss:  0.003268298925831914
Valid Loss:  0.004283965565264225
Epoch:  88  	Training Loss: 0.0036707199178636074
Test Loss:  0.003261613193899393
Valid Loss:  0.004277230706065893
Epoch:  89  	Training Loss: 0.003664161544293165
Test Loss:  0.003255869960412383
Valid Loss:  0.004271608777344227
Epoch:  90  	Training Loss: 0.0036581545136868954
Test Loss:  0.00325014884583652
Valid Loss:  0.004265892319381237
Epoch:  91  	Training Loss: 0.0036525949835777283
Test Loss:  0.0032448931597173214
Valid Loss:  0.004260721616446972
Epoch:  92  	Training Loss: 0.0036473902873694897
Test Loss:  0.0031704693101346493
Valid Loss:  0.004100217018276453
Epoch:  93  	Training Loss: 0.003433586098253727
Test Loss:  0.003148071700707078
Valid Loss:  0.004030607640743256
Epoch:  94  	Training Loss: 0.0033393828198313713
Test Loss:  0.0031217210926115513
Valid Loss:  0.003971057943999767
Epoch:  95  	Training Loss: 0.003269599284976721
Test Loss:  0.003104826668277383
Valid Loss:  0.003925366792827845
Epoch:  96  	Training Loss: 0.0032163241412490606
Test Loss:  0.00308581767603755
Valid Loss:  0.003885027952492237
Epoch:  97  	Training Loss: 0.003171778516843915
Test Loss:  0.0030678659677505493
Valid Loss:  0.003848732216283679
Epoch:  98  	Training Loss: 0.0031334704253822565
Test Loss:  0.003050711238756776
Valid Loss:  0.0038150446489453316
Epoch:  99  	Training Loss: 0.003099845489487052
Test Loss:  0.0030344610568135977
Valid Loss:  0.0037834327667951584
Epoch:  100  	Training Loss: 0.003068535355851054
Test Loss:  0.0030139759182929993
Valid Loss:  0.0037528974935412407
Epoch:  101  	Training Loss: 0.0030394946224987507
Test Loss:  0.002993314992636442
Valid Loss:  0.00372437946498394
Epoch:  102  	Training Loss: 0.0030117034912109375
Test Loss:  0.002860991982743144
Valid Loss:  0.0036005540750920773
Epoch:  103  	Training Loss: 0.0029107953887432814
Test Loss:  0.002740293275564909
Valid Loss:  0.0034867185167968273
Epoch:  104  	Training Loss: 0.0028187239076942205
Test Loss:  0.0026297408621758223
Valid Loss:  0.0033819498494267464
Epoch:  105  	Training Loss: 0.0027344366535544395
Test Loss:  0.0025284073781222105
Valid Loss:  0.0032852948643267155
Epoch:  106  	Training Loss: 0.0026571794878691435
Test Loss:  0.0024353410117328167
Valid Loss:  0.003196222009137273
Epoch:  107  	Training Loss: 0.00258614681661129
Test Loss:  0.002349606715142727
Valid Loss:  0.0031133079901337624
Epoch:  108  	Training Loss: 0.002519694622606039
Test Loss:  0.0022704731673002243
Valid Loss:  0.0030359001830220222
Epoch:  109  	Training Loss: 0.002457150025293231
Test Loss:  0.00219737458974123
Valid Loss:  0.002963472157716751
Epoch:  110  	Training Loss: 0.002396955620497465
Test Loss:  0.0021297368220984936
Valid Loss:  0.002893552416935563
Epoch:  111  	Training Loss: 0.0023378897458314896
Test Loss:  0.0020645782351493835
Valid Loss:  0.0028262317646294832
Epoch:  112  	Training Loss: 0.0022790476214140654
Test Loss:  0.0020583742298185825
Valid Loss:  0.0027851201593875885
Epoch:  113  	Training Loss: 0.002227586694061756
Test Loss:  0.0020497033838182688
Valid Loss:  0.0027499119751155376
Epoch:  114  	Training Loss: 0.002187128644436598
Test Loss:  0.002040708903223276
Valid Loss:  0.002719757379963994
Epoch:  115  	Training Loss: 0.0021540175657719374
Test Loss:  0.0020316869486123323
Valid Loss:  0.0026925557758659124
Epoch:  116  	Training Loss: 0.002125917933881283
Test Loss:  0.002020369516685605
Valid Loss:  0.0026676307898014784
Epoch:  117  	Training Loss: 0.002101354533806443
Test Loss:  0.0020096865482628345
Valid Loss:  0.0026450767181813717
Epoch:  118  	Training Loss: 0.0020795664750039577
Test Loss:  0.001999176573008299
Valid Loss:  0.002624346874654293
Epoch:  119  	Training Loss: 0.0020597847178578377
Test Loss:  0.001986568095162511
Valid Loss:  0.0026045427657663822
Epoch:  120  	Training Loss: 0.002041766420006752
Test Loss:  0.001974504441022873
Valid Loss:  0.002585845999419689
Epoch:  121  	Training Loss: 0.002024889923632145
Test Loss:  0.0019613546319305897
Valid Loss:  0.0025677550584077835
Epoch:  122  	Training Loss: 0.0020085624419152737
Test Loss:  0.0019256521482020617
Valid Loss:  0.0025262623094022274
Epoch:  123  	Training Loss: 0.0019709616899490356
Test Loss:  0.0018907524645328522
Valid Loss:  0.002486333716660738
Epoch:  124  	Training Loss: 0.0019351522205397487
Test Loss:  0.0018568257801234722
Valid Loss:  0.0024480419233441353
Epoch:  125  	Training Loss: 0.001900954870507121
Test Loss:  0.0018236305331811309
Valid Loss:  0.0024110006634145975
Epoch:  126  	Training Loss: 0.00186819804366678
Test Loss:  0.0017894621705636382
Valid Loss:  0.00237484835088253
Epoch:  127  	Training Loss: 0.0018368582241237164
Test Loss:  0.0017565347952768207
Valid Loss:  0.0023400892969220877
Epoch:  128  	Training Loss: 0.0018067412311211228
Test Loss:  0.0017239642329514027
Valid Loss:  0.0023064864799380302
Epoch:  129  	Training Loss: 0.0017777837347239256
Test Loss:  0.0016927255783230066
Valid Loss:  0.002274102298542857
Epoch:  130  	Training Loss: 0.0017498928355053067
Test Loss:  0.0016627180157229304
Valid Loss:  0.0022428943775594234
Epoch:  131  	Training Loss: 0.0017230261582881212
Test Loss:  0.0016338760033249855
Valid Loss:  0.0022128017153590918
Epoch:  132  	Training Loss: 0.0016971396980807185
Test Loss:  0.0015730024315416813
Valid Loss:  0.0021661664359271526
Epoch:  133  	Training Loss: 0.0016451014671474695
Test Loss:  0.0015164634678512812
Valid Loss:  0.0021204897202551365
Epoch:  134  	Training Loss: 0.001599609386175871
Test Loss:  0.0014668143121525645
Valid Loss:  0.00207947357557714
Epoch:  135  	Training Loss: 0.0015598628669977188
Test Loss:  0.001419235486537218
Valid Loss:  0.0020380779169499874
Epoch:  136  	Training Loss: 0.0015244388487190008
Test Loss:  0.0013758852146565914
Valid Loss:  0.001998922787606716
Epoch:  137  	Training Loss: 0.0014934804057702422
Test Loss:  0.0013378902804106474
Valid Loss:  0.001962473150342703
Epoch:  138  	Training Loss: 0.0014662615722045302
Test Loss:  0.0013040602207183838
Valid Loss:  0.0019311029464006424
Epoch:  139  	Training Loss: 0.001443421933799982
Test Loss:   28%|██▊       | 139/500 [01:50<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:56<06:58,  1.16s/it] 29%|██▊       | 143/500 [01:56<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:56<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:56<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:56<02:00,  2.90it/s] 30%|███       | 151/500 [02:03<06:56,  1.19s/it] 31%|███       | 153/500 [02:03<04:57,  1.17it/s] 31%|███       | 155/500 [02:03<03:33,  1.62it/s] 31%|███▏      | 157/500 [02:03<02:35,  2.20it/s] 32%|███▏      | 159/500 [02:03<01:55,  2.96it/s] 32%|███▏      | 161/500 [02:10<06:46,  1.20s/it] 33%|███▎      | 163/500 [02:10<04:49,  1.16it/s] 33%|███▎      | 165/500 [02:10<03:28,  1.61it/s] 33%|███▎      | 167/500 [02:10<02:31,  2.20it/s] 34%|███▍      | 169/500 [02:10<01:52,  2.95it/s] 34%|███▍      | 171/500 [02:17<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:17<04:38,  1.17it/s] 35%|███▌      | 175/500 [02:17<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:17<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:17<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:24<06:26,  1.21s/it] 37%|███▋      | 183/500 [02:24<04:36,  1.15it/s] 37%|███▋      | 185/500 [02:24<03:19,  1.58it/s] 37%|███▋      | 187/500 [02:24<02:25,  2.16it/s] 38%|███▊      | 189/500 [02:24<01:46,  2.91it/s] 38%|███▊      | 191/500 [02:31<06:11,  1.20s/it] 39%|███▊      | 193/500 [02:31<04:25,  1.16it/s] 39%|███▉      | 195/500 [02:31<03:10,  1.60it/s] 39%|███▉      | 197/500 [02:31<02:18,  2.19it/s] 40%|███▉      | 199/500 [02:31<01:42,  2.94it/s] 40%|████      | 201/500 [02:38<05:57,  1.20s/it] 41%|████      | 203/500 [02:38<04:14,  1.16it/s] 41%|████      | 205/500 [02:38<03:03,  1.61it/s] 41%|████▏     | 207/500 [02:38<02:13,  2.19it/s]0.0012712161988019943
Valid Loss:  0.0019028515089303255
Epoch:  140  	Training Loss: 0.0014225037302821875
Test Loss:  0.001241384306922555
Valid Loss:  0.0018774982308968902
Epoch:  141  	Training Loss: 0.0014038551598787308
Test Loss:  0.0012137325247749686
Valid Loss:  0.001854117028415203
Epoch:  142  	Training Loss: 0.0013858298771083355
Test Loss:  0.0011949429754167795
Valid Loss:  0.0018275592010468245
Epoch:  143  	Training Loss: 0.0013617046643048525
Test Loss:  0.0011759052285924554
Valid Loss:  0.0018017268739640713
Epoch:  144  	Training Loss: 0.0013381628086790442
Test Loss:  0.0011574139352887869
Valid Loss:  0.0017768454272300005
Epoch:  145  	Training Loss: 0.0013157057110220194
Test Loss:  0.0011397298658266664
Valid Loss:  0.0017530230106785893
Epoch:  146  	Training Loss: 0.0012946022907271981
Test Loss:  0.0011226885253563523
Valid Loss:  0.0017303091008216143
Epoch:  147  	Training Loss: 0.001274780835956335
Test Loss:  0.0011061991099268198
Valid Loss:  0.0017090009059756994
Epoch:  148  	Training Loss: 0.0012562598567456007
Test Loss:  0.001090686535462737
Valid Loss:  0.0016889553517103195
Epoch:  149  	Training Loss: 0.001239115372300148
Test Loss:  0.0010765478946268559
Valid Loss:  0.00166958081535995
Epoch:  150  	Training Loss: 0.0012229174608364701
Test Loss:  0.0010635750368237495
Valid Loss:  0.001651356229558587
Epoch:  151  	Training Loss: 0.0012085207272320986
Test Loss:  0.0010511258151382208
Valid Loss:  0.0016345022013410926
Epoch:  152  	Training Loss: 0.0011954333167523146
Test Loss:  0.0010202002013102174
Valid Loss:  0.0016050380654633045
Epoch:  153  	Training Loss: 0.00116930587682873
Test Loss:  0.0010018597822636366
Valid Loss:  0.0015845784218981862
Epoch:  154  	Training Loss: 0.0011510568438097835
Test Loss:  0.000988041516393423
Valid Loss:  0.0015657308977097273
Epoch:  155  	Training Loss: 0.0011346774408593774
Test Loss:  0.0009758376982063055
Valid Loss:  0.0015480619622394443
Epoch:  156  	Training Loss: 0.0011191016528755426
Test Loss:  0.0009653650340624154
Valid Loss:  0.0015319482190534472
Epoch:  157  	Training Loss: 0.001104647060856223
Test Loss:  0.0009564270731061697
Valid Loss:  0.001516889315098524
Epoch:  158  	Training Loss: 0.001091033685952425
Test Loss:  0.000947496562730521
Valid Loss:  0.001502513070590794
Epoch:  159  	Training Loss: 0.0010785710765048862
Test Loss:  0.0009394905064254999
Valid Loss:  0.0014882024843245745
Epoch:  160  	Training Loss: 0.0010664950823411345
Test Loss:  0.0009317738586105406
Valid Loss:  0.001474403077736497
Epoch:  161  	Training Loss: 0.0010545955738052726
Test Loss:  0.0009243838721886277
Valid Loss:  0.0014615543186664581
Epoch:  162  	Training Loss: 0.0010426418157294393
Test Loss:  0.0009047963540069759
Valid Loss:  0.0014485549181699753
Epoch:  163  	Training Loss: 0.0010332469828426838
Test Loss:  0.0008903806447051466
Valid Loss:  0.001438172534108162
Epoch:  164  	Training Loss: 0.0010256599634885788
Test Loss:  0.0008782292134128511
Valid Loss:  0.0014290252001956105
Epoch:  165  	Training Loss: 0.0010188419837504625
Test Loss:  0.0008673561387695372
Valid Loss:  0.0014206570340320468
Epoch:  166  	Training Loss: 0.001012513879686594
Test Loss:  0.0008575251558795571
Valid Loss:  0.0014128732727840543
Epoch:  167  	Training Loss: 0.001006620703265071
Test Loss:  0.0008486853912472725
Valid Loss:  0.0014056472573429346
Epoch:  168  	Training Loss: 0.0010012185666710138
Test Loss:  0.0008403913816437125
Valid Loss:  0.0013988702557981014
Epoch:  169  	Training Loss: 0.0009961971081793308
Test Loss:  0.0008326949318870902
Valid Loss:  0.0013924262020736933
Epoch:  170  	Training Loss: 0.0009914514375850558
Test Loss:  0.0008254280546680093
Valid Loss:  0.0013862980995327234
Epoch:  171  	Training Loss: 0.0009869362693279982
Test Loss:  0.0008183912723325193
Valid Loss:  0.0013804900227114558
Epoch:  172  	Training Loss: 0.0009826915338635445
Test Loss:  0.0008150943322107196
Valid Loss:  0.0013782237656414509
Epoch:  173  	Training Loss: 0.0009809175971895456
Test Loss:  0.0008119767880998552
Valid Loss:  0.0013760793954133987
Epoch:  174  	Training Loss: 0.0009792644996196032
Test Loss:  0.000808947195764631
Valid Loss:  0.001373995910398662
Epoch:  175  	Training Loss: 0.0009776611113920808
Test Loss:  0.0008060046238824725
Valid Loss:  0.0013719734270125628
Epoch:  176  	Training Loss: 0.0009761069668456912
Test Loss:  0.0008031454053707421
Valid Loss:  0.0013700067065656185
Epoch:  177  	Training Loss: 0.0009745997958816588
Test Loss:  0.0008003665716387331
Valid Loss:  0.0013680937699973583
Epoch:  178  	Training Loss: 0.0009731388418003917
Test Loss:  0.0007976671913638711
Valid Loss:  0.001366238808259368
Epoch:  179  	Training Loss: 0.0009717218345031142
Test Loss:  0.0007950430153869092
Valid Loss:  0.0013644343707710505
Epoch:  180  	Training Loss: 0.0009703609393909574
Test Loss:  0.0007925628451630473
Valid Loss:  0.0013627259759232402
Epoch:  181  	Training Loss: 0.0009690980659797788
Test Loss:  0.0007901492062956095
Valid Loss:  0.0013610649621114135
Epoch:  182  	Training Loss: 0.0009678728529252112
Test Loss:  0.0007771162199787796
Valid Loss:  0.0013489257544279099
Epoch:  183  	Training Loss: 0.0009600326302461326
Test Loss:  0.0007650071056559682
Valid Loss:  0.0013375747948884964
Epoch:  184  	Training Loss: 0.000952768255956471
Test Loss:  0.0007537159835919738
Valid Loss:  0.0013269393239170313
Epoch:  185  	Training Loss: 0.0009460297878831625
Test Loss:  0.000743179174605757
Valid Loss:  0.0013169599696993828
Epoch:  186  	Training Loss: 0.0009397608228027821
Test Loss:  0.0007333123940043151
Valid Loss:  0.0013075758470222354
Epoch:  187  	Training Loss: 0.0009339222451671958
Test Loss:  0.0007240780396386981
Valid Loss:  0.0012987437658011913
Epoch:  188  	Training Loss: 0.0009284799452871084
Test Loss:  0.0007154237246140838
Valid Loss:  0.0012904517352581024
Epoch:  189  	Training Loss: 0.0009234020253643394
Test Loss:  0.0007072287844493985
Valid Loss:  0.0012826579622924328
Epoch:  190  	Training Loss: 0.0009186886600218713
Test Loss:  0.0006995380390435457
Valid Loss:  0.0012753254268318415
Epoch:  191  	Training Loss: 0.0009142699418589473
Test Loss:  0.0006924579502083361
Valid Loss:  0.0012684529647231102
Epoch:  192  	Training Loss: 0.0009101219475269318
Test Loss:  0.0006883442401885986
Valid Loss:  0.0012591464910656214
Epoch:  193  	Training Loss: 0.0009016126859933138
Test Loss:  0.00068292097421363
Valid Loss:  0.0012502050958573818
Epoch:  194  	Training Loss: 0.0008942220592871308
Test Loss:  0.0006770407781004906
Valid Loss:  0.0012414645170792937
Epoch:  195  	Training Loss: 0.000886900641489774
Test Loss:  0.0006710127927362919
Valid Loss:  0.0012330985628068447
Epoch:  196  	Training Loss: 0.000879857805557549
Test Loss:  0.0006642289226874709
Valid Loss:  0.001224823179654777
Epoch:  197  	Training Loss: 0.0008729079272598028
Test Loss:  0.0006577363237738609
Valid Loss:  0.0012168167158961296
Epoch:  198  	Training Loss: 0.0008661020547151566
Test Loss:  0.000651331793051213
Valid Loss:  0.0012091202661395073
Epoch:  199  	Training Loss: 0.0008595159160904586
Test Loss:  0.0006451148656196892
Valid Loss:  0.0012016469845548272
Epoch:  200  	Training Loss: 0.0008531403727829456
Test Loss:  0.0006392827490344644
Valid Loss:  0.0011944612488150597
Epoch:  201  	Training Loss: 0.0008470112225040793
Test Loss:  0.0006336172809824347
Valid Loss:  0.0011875606141984463
Epoch:  202  	Training Loss: 0.0008411649614572525
Test Loss:  0.0006300518871285021
Valid Loss:  0.0011789880227297544
Epoch:  203  	Training Loss: 0.0008333538426086307
Test Loss:  0.000625382992438972
Valid Loss:  0.0011708175297826529
Epoch:  204  	Training Loss: 0.0008266718941740692
Test Loss:  0.0006203194498084486
Valid Loss:  0.0011630011722445488
Epoch:  205  	Training Loss: 0.0008207398350350559
Test Loss:  0.0006150241242721677
Valid Loss:  0.001155475270934403
Epoch:  206  	Training Loss: 0.0008151481742970645
Test Loss:  0.0006096292054280639
Valid Loss:  0.0011482443660497665
Epoch:  207  	Training Loss: 0.0008098288672044873
Test Loss:  0.0006042313762009144
Valid Loss:  0.0011412338353693485
 42%|████▏     | 209/500 [02:38<01:40,  2.89it/s] 42%|████▏     | 211/500 [02:45<05:50,  1.21s/it] 43%|████▎     | 213/500 [02:45<04:10,  1.15it/s] 43%|████▎     | 215/500 [02:45<02:59,  1.59it/s] 43%|████▎     | 217/500 [02:45<02:10,  2.17it/s] 44%|████▍     | 219/500 [02:45<01:36,  2.92it/s] 44%|████▍     | 221/500 [02:52<05:32,  1.19s/it] 44%|████▍     | 222/500 [02:52<04:38,  1.00s/it] 45%|████▍     | 224/500 [02:52<03:09,  1.46it/s] 45%|████▌     | 226/500 [02:52<02:13,  2.05it/s] 46%|████▌     | 228/500 [02:52<01:37,  2.78it/s] 46%|████▌     | 230/500 [02:52<01:12,  3.71it/s] 46%|████▋     | 232/500 [02:59<05:12,  1.17s/it] 47%|████▋     | 234/500 [02:59<03:40,  1.20it/s] 47%|████▋     | 236/500 [02:59<02:37,  1.67it/s] 48%|████▊     | 238/500 [02:59<01:54,  2.29it/s] 48%|████▊     | 240/500 [02:59<01:24,  3.08it/s] 48%|████▊     | 242/500 [03:06<05:07,  1.19s/it] 49%|████▉     | 244/500 [03:06<03:39,  1.17it/s] 49%|████▉     | 246/500 [03:06<02:38,  1.60it/s] 50%|████▉     | 248/500 [03:06<01:56,  2.16it/s] 50%|█████     | 250/500 [03:06<01:27,  2.85it/s] 50%|█████     | 252/500 [03:12<04:51,  1.18s/it] 51%|█████     | 254/500 [03:13<03:27,  1.19it/s] 51%|█████     | 256/500 [03:13<02:28,  1.64it/s] 52%|█████▏    | 258/500 [03:13<01:47,  2.25it/s] 52%|█████▏    | 260/500 [03:13<01:19,  3.02it/s] 52%|█████▏    | 262/500 [03:19<04:36,  1.16s/it] 53%|█████▎    | 264/500 [03:19<03:16,  1.20it/s] 53%|█████▎    | 266/500 [03:19<02:20,  1.66it/s] 54%|█████▎    | 268/500 [03:20<01:42,  2.27it/s] 54%|█████▍    | 270/500 [03:20<01:15,  3.05it/s] 54%|█████▍    | 272/500 [03:26<04:32,  1.20s/it] 55%|█████▍    | 274/500 [03:26<03:14,  1.16it/s]Epoch:  208  	Training Loss: 0.0008047541487030685
Test Loss:  0.0005988295306451619
Valid Loss:  0.001134383026510477
Epoch:  209  	Training Loss: 0.0007998599321581423
Test Loss:  0.0005934681976214051
Valid Loss:  0.0011276861187070608
Epoch:  210  	Training Loss: 0.000795134692452848
Test Loss:  0.0005882073892280459
Valid Loss:  0.0011211629025638103
Epoch:  211  	Training Loss: 0.0007905643433332443
Test Loss:  0.0005831187590956688
Valid Loss:  0.0011148415505886078
Epoch:  212  	Training Loss: 0.0007861325284466147
Test Loss:  0.0005798353813588619
Valid Loss:  0.0011054088827222586
Epoch:  213  	Training Loss: 0.0007764328620396554
Test Loss:  0.0005751698045060039
Valid Loss:  0.0010962903033941984
Epoch:  214  	Training Loss: 0.0007679883274249732
Test Loss:  0.0005696569569408894
Valid Loss:  0.0010871343547478318
Epoch:  215  	Training Loss: 0.000760067836381495
Test Loss:  0.0005633531836792827
Valid Loss:  0.0010780023876577616
Epoch:  216  	Training Loss: 0.0007524987449869514
Test Loss:  0.0005569025524891913
Valid Loss:  0.0010693176882341504
Epoch:  217  	Training Loss: 0.0007454617880284786
Test Loss:  0.0005506483721546829
Valid Loss:  0.0010612698970362544
Epoch:  218  	Training Loss: 0.0007389717502519488
Test Loss:  0.0005447675939649343
Valid Loss:  0.0010539067443460226
Epoch:  219  	Training Loss: 0.0007330625085160136
Test Loss:  0.0005395151092670858
Valid Loss:  0.0010473348665982485
Epoch:  220  	Training Loss: 0.0007277532131411135
Test Loss:  0.0005345168756321073
Valid Loss:  0.001041320152580738
Epoch:  221  	Training Loss: 0.0007228590548038483
Test Loss:  0.0005299531621858478
Valid Loss:  0.001035942928865552
Epoch:  222  	Training Loss: 0.000718410243280232
Test Loss:  0.0005238414159975946
Valid Loss:  0.001030166749842465
Epoch:  223  	Training Loss: 0.0007149833836592734
Test Loss:  0.0005182049935683608
Valid Loss:  0.0010247542522847652
Epoch:  224  	Training Loss: 0.00071180728264153
Test Loss:  0.0005130009958520532
Valid Loss:  0.0010196652729064226
Epoch:  225  	Training Loss: 0.000708845560438931
Test Loss:  0.000508185476064682
Valid Loss:  0.0010149050503969193
Epoch:  226  	Training Loss: 0.0007060685311444104
Test Loss:  0.0005036949878558517
Valid Loss:  0.0010104471584782004
Epoch:  227  	Training Loss: 0.0007034511072561145
Test Loss:  0.0004994943737983704
Valid Loss:  0.0010062337387353182
Epoch:  228  	Training Loss: 0.0007009741384536028
Test Loss:  0.0004955570329912007
Valid Loss:  0.0010022264905273914
Epoch:  229  	Training Loss: 0.0006986221997067332
Test Loss:  0.0004918461199849844
Valid Loss:  0.0009984010830521584
Epoch:  230  	Training Loss: 0.0006963800988160074
Test Loss:  0.0004883421934209764
Valid Loss:  0.0009947409853339195
Epoch:  231  	Training Loss: 0.0006942440522834659
Test Loss:  0.00048501789569854736
Valid Loss:  0.0009912558598443866
Epoch:  232  	Training Loss: 0.0006922561442479491
Test Loss:  0.00048428395530208945
Valid Loss:  0.000990683794952929
Epoch:  233  	Training Loss: 0.0006918867584317923
Test Loss:  0.00048357274499721825
Valid Loss:  0.00099012756254524
Epoch:  234  	Training Loss: 0.0006915292469784617
Test Loss:  0.0004828798701055348
Valid Loss:  0.0009895903058350086
Epoch:  235  	Training Loss: 0.0006911824457347393
Test Loss:  0.00048221589531749487
Valid Loss:  0.0009890757501125336
Epoch:  236  	Training Loss: 0.0006908496143296361
Test Loss:  0.0004815676074940711
Valid Loss:  0.0009885751642286777
Epoch:  237  	Training Loss: 0.0006905283080413938
Test Loss:  0.00048093515215441585
Valid Loss:  0.0009880843572318554
Epoch:  238  	Training Loss: 0.000690215383656323
Test Loss:  0.0004803163465112448
Valid Loss:  0.0009876068215817213
Epoch:  239  	Training Loss: 0.0006899142172187567
Test Loss:  0.00047972233733162284
Valid Loss:  0.00098714092746377
Epoch:  240  	Training Loss: 0.0006896248087286949
Test Loss:  0.0004791395040228963
Valid Loss:  0.0009866866748780012
Epoch:  241  	Training Loss: 0.0006893426179885864
Test Loss:  0.0004785745404660702
Valid Loss:  0.0009862433653324842
Epoch:  242  	Training Loss: 0.000689071835950017
Test Loss:  0.0004786742210853845
Valid Loss:  0.0009844973683357239
Epoch:  243  	Training Loss: 0.000687073334120214
Test Loss:  0.00047843653010204434
Valid Loss:  0.0009829882765188813
Epoch:  244  	Training Loss: 0.0006855103420093656
Test Loss:  0.0004779106820933521
Valid Loss:  0.0009815978119149804
Epoch:  245  	Training Loss: 0.0006841736030764878
Test Loss:  0.0004771692620124668
Valid Loss:  0.0009802859276533127
Epoch:  246  	Training Loss: 0.0006829628255218267
Test Loss:  0.0004762820899486542
Valid Loss:  0.0009790158364921808
Epoch:  247  	Training Loss: 0.000681838602758944
Test Loss:  0.00047530210576951504
Valid Loss:  0.0009777735685929656
Epoch:  248  	Training Loss: 0.0006807718891650438
Test Loss:  0.00047427299432456493
Valid Loss:  0.0009765989379957318
Epoch:  249  	Training Loss: 0.000679761404171586
Test Loss:  0.00047322892351076007
Valid Loss:  0.0009754645870998502
Epoch:  250  	Training Loss: 0.0006788067985326052
Test Loss:  0.0004721955629065633
Valid Loss:  0.0009743669652380049
Epoch:  251  	Training Loss: 0.0006778956158086658
Test Loss:  0.0004711971268989146
Valid Loss:  0.0009732990292832255
Epoch:  252  	Training Loss: 0.0006770136533305049
Test Loss:  0.0004667129833251238
Valid Loss:  0.0009688458521850407
Epoch:  253  	Training Loss: 0.0006746728322468698
Test Loss:  0.0004628600727301091
Valid Loss:  0.0009648072300478816
Epoch:  254  	Training Loss: 0.0006725797429680824
Test Loss:  0.00045945076271891594
Valid Loss:  0.0009610581328161061
Epoch:  255  	Training Loss: 0.0006706553394906223
Test Loss:  0.00045644608326256275
Valid Loss:  0.000957628944888711
Epoch:  256  	Training Loss: 0.000668893801048398
Test Loss:  0.0004537744971457869
Valid Loss:  0.000954428396653384
Epoch:  257  	Training Loss: 0.0006672794697806239
Test Loss:  0.00045137983397580683
Valid Loss:  0.0009514549747109413
Epoch:  258  	Training Loss: 0.0006658079801127315
Test Loss:  0.00044915289618074894
Valid Loss:  0.0009486374910920858
Epoch:  259  	Training Loss: 0.00066442193929106
Test Loss:  0.00044710515066981316
Valid Loss:  0.0009460803703404963
Epoch:  260  	Training Loss: 0.0006631433498114347
Test Loss:  0.000445155194029212
Valid Loss:  0.0009436337277293205
Epoch:  261  	Training Loss: 0.0006619304185733199
Test Loss:  0.0004433440917637199
Valid Loss:  0.0009413295774720609
Epoch:  262  	Training Loss: 0.00066079554380849
Test Loss:  0.000440587115008384
Valid Loss:  0.0009378485265187919
Epoch:  263  	Training Loss: 0.0006592069985345006
Test Loss:  0.00043798889964818954
Valid Loss:  0.0009346994338557124
Epoch:  264  	Training Loss: 0.0006578339962288737
Test Loss:  0.00043566717067733407
Valid Loss:  0.0009318871889263391
Epoch:  265  	Training Loss: 0.0006566127995029092
Test Loss:  0.000433557404903695
Valid Loss:  0.000929363421164453
Epoch:  266  	Training Loss: 0.0006554760038852692
Test Loss:  0.0004315755795687437
Valid Loss:  0.0009270289447158575
Epoch:  267  	Training Loss: 0.0006544498028233647
Test Loss:  0.0004297821142245084
Valid Loss:  0.0009248680435121059
Epoch:  268  	Training Loss: 0.0006534862332046032
Test Loss:  0.00042810619925148785
Valid Loss:  0.0009229003917425871
Epoch:  269  	Training Loss: 0.0006526026409119368
Test Loss:  0.0004266115138307214
Valid Loss:  0.0009210750577040017
Epoch:  270  	Training Loss: 0.0006517558358609676
Test Loss:  0.00042524829041212797
Valid Loss:  0.0009193653240799904
Epoch:  271  	Training Loss: 0.0006509422091767192
Test Loss:  0.0004240153357386589
Valid Loss:  0.0009177520405501127
Epoch:  272  	Training Loss: 0.000650160713121295
Test Loss:  0.0004223439027555287
Valid Loss:  0.0009161349735222757
Epoch:  273  	Training Loss: 0.0006494799163192511
Test Loss:  0.0004207809397485107
Valid Loss:  0.0009146220399998128
Epoch:  274  	Training Loss: 0.0006488605868071318
Test Loss:  0.0004193180939182639
Valid Loss:  0.0009132075938396156
Epoch:  275  	Training Loss: 0.0006482973112724721
Test Loss:  0.00041794910794124007
Valid Loss:  0.0009118819143623114
 55%|█████▌    | 276/500 [03:26<02:20,  1.59it/s] 56%|█████▌    | 278/500 [03:27<01:43,  2.15it/s] 56%|█████▌    | 280/500 [03:27<01:16,  2.87it/s] 56%|█████▋    | 282/500 [03:33<04:21,  1.20s/it] 57%|█████▋    | 284/500 [03:33<03:05,  1.16it/s] 57%|█████▋    | 286/500 [03:33<02:12,  1.61it/s] 58%|█████▊    | 288/500 [03:34<01:36,  2.20it/s] 58%|█████▊    | 290/500 [03:34<01:11,  2.96it/s] 58%|█████▊    | 292/500 [03:40<04:06,  1.18s/it] 59%|█████▉    | 294/500 [03:40<02:54,  1.18it/s] 59%|█████▉    | 296/500 [03:40<02:05,  1.63it/s] 60%|█████▉    | 298/500 [03:40<01:31,  2.22it/s] 60%|██████    | 300/500 [03:41<01:07,  2.98it/s] 60%|██████    | 302/500 [03:47<03:57,  1.20s/it] 61%|██████    | 304/500 [03:47<02:49,  1.16it/s] 61%|██████    | 306/500 [03:47<02:02,  1.59it/s] 62%|██████▏   | 308/500 [03:47<01:29,  2.14it/s] 62%|██████▏   | 310/500 [03:48<01:07,  2.83it/s] 62%|██████▏   | 312/500 [03:54<03:45,  1.20s/it] 63%|██████▎   | 314/500 [03:54<02:40,  1.16it/s] 63%|██████▎   | 316/500 [03:54<01:54,  1.60it/s] 64%|██████▎   | 318/500 [03:54<01:23,  2.19it/s] 64%|██████▍   | 320/500 [03:55<01:01,  2.95it/s] 64%|██████▍   | 322/500 [04:01<03:28,  1.17s/it] 65%|██████▍   | 324/500 [04:01<02:27,  1.19it/s] 65%|██████▌   | 326/500 [04:01<01:45,  1.65it/s] 66%|██████▌   | 328/500 [04:01<01:16,  2.25it/s] 66%|██████▌   | 330/500 [04:01<00:56,  3.01it/s] 66%|██████▋   | 332/500 [04:08<03:19,  1.19s/it] 67%|██████▋   | 334/500 [04:08<02:21,  1.17it/s] 67%|██████▋   | 336/500 [04:08<01:41,  1.62it/s] 68%|██████▊   | 338/500 [04:08<01:13,  2.21it/s] 68%|██████▊   | 340/500 [04:08<00:53,  2.98it/s] 68%|██████▊   | 342/500 [04:15<03:08,  1.19s/it]Epoch:  276  	Training Loss: 0.0006477843271568418
Test Loss:  0.00041666754987090826
Valid Loss:  0.0009106410434469581
Epoch:  277  	Training Loss: 0.000647318025585264
Test Loss:  0.0004154657945036888
Valid Loss:  0.0009094770648516715
Epoch:  278  	Training Loss: 0.0006468923529610038
Test Loss:  0.0004143381374888122
Valid Loss:  0.0009083865443244576
Epoch:  279  	Training Loss: 0.0006465048063546419
Test Loss:  0.0004132809117436409
Valid Loss:  0.000907361856661737
Epoch:  280  	Training Loss: 0.0006461515440605581
Test Loss:  0.0004122879181522876
Valid Loss:  0.0009064016630873084
Epoch:  281  	Training Loss: 0.0006458295974880457
Test Loss:  0.0004113562172278762
Valid Loss:  0.0009054974652826786
Epoch:  282  	Training Loss: 0.0006455362308770418
Test Loss:  0.0004109735309612006
Valid Loss:  0.0009047987405210733
Epoch:  283  	Training Loss: 0.0006447946652770042
Test Loss:  0.0004106063861399889
Valid Loss:  0.00090412626741454
Epoch:  284  	Training Loss: 0.0006440822035074234
Test Loss:  0.00041027035331353545
Valid Loss:  0.000903478532563895
Epoch:  285  	Training Loss: 0.0006433987291529775
Test Loss:  0.0004100030637346208
Valid Loss:  0.0009028604254126549
Epoch:  286  	Training Loss: 0.0006427600746974349
Test Loss:  0.00040975265437737107
Valid Loss:  0.000902264378964901
Epoch:  287  	Training Loss: 0.0006421616999432445
Test Loss:  0.0004095171461813152
Valid Loss:  0.0009017066331580281
Epoch:  288  	Training Loss: 0.0006416146643459797
Test Loss:  0.0004093080060556531
Valid Loss:  0.000901183346286416
Epoch:  289  	Training Loss: 0.0006411143695004284
Test Loss:  0.0004091273294761777
Valid Loss:  0.0009006778709590435
Epoch:  290  	Training Loss: 0.0006406345055438578
Test Loss:  0.0004089548601768911
Valid Loss:  0.0009001954458653927
Epoch:  291  	Training Loss: 0.0006401943974196911
Test Loss:  0.00040878928848542273
Valid Loss:  0.0008997377008199692
Epoch:  292  	Training Loss: 0.0006397790275514126
Test Loss:  0.0004091454902663827
Valid Loss:  0.0008994254749268293
Epoch:  293  	Training Loss: 0.000639443751424551
Test Loss:  0.00040938955498859286
Valid Loss:  0.0008991676149889827
Epoch:  294  	Training Loss: 0.0006391880451701581
Test Loss:  0.0004095384501852095
Valid Loss:  0.0008989378111436963
Epoch:  295  	Training Loss: 0.0006389750051312149
Test Loss:  0.0004096058546565473
Valid Loss:  0.0008987233741208911
Epoch:  296  	Training Loss: 0.0006387899629771709
Test Loss:  0.00040960992919281125
Valid Loss:  0.0008985220338217914
Epoch:  297  	Training Loss: 0.0006386223249137402
Test Loss:  0.0004095673793926835
Valid Loss:  0.0008983261650428176
Epoch:  298  	Training Loss: 0.0006384628359228373
Test Loss:  0.00040949496906250715
Valid Loss:  0.0008981300052255392
Epoch:  299  	Training Loss: 0.0006383088184520602
Test Loss:  0.0004093966563232243
Valid Loss:  0.0008979361155070364
Epoch:  300  	Training Loss: 0.0006381594575941563
Test Loss:  0.000409283849876374
Valid Loss:  0.0008977461839094758
Epoch:  301  	Training Loss: 0.0006380123668350279
Test Loss:  0.0004091616428922862
Valid Loss:  0.0008975575910881162
Epoch:  302  	Training Loss: 0.0006378672551363707
Test Loss:  0.0004076720215380192
Valid Loss:  0.000896069104783237
Epoch:  303  	Training Loss: 0.0006371094495989382
Test Loss:  0.00040635341429151595
Valid Loss:  0.0008946870220825076
Epoch:  304  	Training Loss: 0.0006364011205732822
Test Loss:  0.0004051633586641401
Valid Loss:  0.0008933809003792703
Epoch:  305  	Training Loss: 0.0006357312086038291
Test Loss:  0.0004040725762024522
Valid Loss:  0.0008921376429498196
Epoch:  306  	Training Loss: 0.0006350939511321485
Test Loss:  0.00040307320887222886
Valid Loss:  0.0008909528260119259
Epoch:  307  	Training Loss: 0.0006344824796542525
Test Loss:  0.00040214427281171083
Valid Loss:  0.0008898160886019468
Epoch:  308  	Training Loss: 0.0006338927196338773
Test Loss:  0.0004012705758213997
Valid Loss:  0.000888719514477998
Epoch:  309  	Training Loss: 0.000633323157671839
Test Loss:  0.00040044885827228427
Valid Loss:  0.0008876592619344592
Epoch:  310  	Training Loss: 0.0006327697774395347
Test Loss:  0.0003996702143922448
Valid Loss:  0.0008866313146427274
Epoch:  311  	Training Loss: 0.000632232113275677
Test Loss:  0.00039892896893434227
Valid Loss:  0.0008856343920342624
Epoch:  312  	Training Loss: 0.0006317071383818984
Test Loss:  0.00039753346936777234
Valid Loss:  0.000883410160895437
Epoch:  313  	Training Loss: 0.0006298221996985376
Test Loss:  0.0003961932670790702
Valid Loss:  0.0008812873275019228
Epoch:  314  	Training Loss: 0.0006280512316152453
Test Loss:  0.00039491464849561453
Valid Loss:  0.0008792676962912083
Epoch:  315  	Training Loss: 0.0006263827672228217
Test Loss:  0.0003936949069611728
Valid Loss:  0.0008773450972512364
Epoch:  316  	Training Loss: 0.0006248062709346414
Test Loss:  0.0003925238852389157
Valid Loss:  0.0008755013695918024
Epoch:  317  	Training Loss: 0.0006232955493032932
Test Loss:  0.0003914023982360959
Valid Loss:  0.0008737334283068776
Epoch:  318  	Training Loss: 0.0006218564230948687
Test Loss:  0.0003903302422259003
Valid Loss:  0.0008720435434952378
Epoch:  319  	Training Loss: 0.0006204870296642184
Test Loss:  0.0003893006360158324
Valid Loss:  0.0008704140782356262
Epoch:  320  	Training Loss: 0.0006191686261445284
Test Loss:  0.0003882950695697218
Valid Loss:  0.000868852948769927
Epoch:  321  	Training Loss: 0.0006179169286042452
Test Loss:  0.0003873094101436436
Valid Loss:  0.0008673506090417504
Epoch:  322  	Training Loss: 0.0006167176179587841
Test Loss:  0.0003885691985487938
Valid Loss:  0.0008679636521264911
Epoch:  323  	Training Loss: 0.000616306031588465
Test Loss:  0.00038970590685494244
Valid Loss:  0.0008685296634212136
Epoch:  324  	Training Loss: 0.000615946832112968
Test Loss:  0.00039073353400453925
Valid Loss:  0.0008690457325428724
Epoch:  325  	Training Loss: 0.0006156307063065469
Test Loss:  0.0003916634595952928
Valid Loss:  0.0008695152937434614
Epoch:  326  	Training Loss: 0.0006153489230200648
Test Loss:  0.00039250380359590054
Valid Loss:  0.0008699382888153195
Epoch:  327  	Training Loss: 0.0006150959525257349
Test Loss:  0.0003932650142814964
Valid Loss:  0.0008703201892785728
Epoch:  328  	Training Loss: 0.0006148656830191612
Test Loss:  0.0003939497983083129
Valid Loss:  0.0008706621010787785
Epoch:  329  	Training Loss: 0.0006146241212263703
Test Loss:  0.0003949095553252846
Valid Loss:  0.0008711800328455865
Epoch:  330  	Training Loss: 0.0006143473437987268
Test Loss:  0.0003957806620746851
Valid Loss:  0.0008716490119695663
Epoch:  331  	Training Loss: 0.0006140973418951035
Test Loss:  0.000396926945541054
Valid Loss:  0.0008722982602193952
Epoch:  332  	Training Loss: 0.0006137743475846946
Test Loss:  0.00039596710121259093
Valid Loss:  0.0008711410919204354
Epoch:  333  	Training Loss: 0.0006131780100986362
Test Loss:  0.0003950820246245712
Valid Loss:  0.0008700459729880095
Epoch:  334  	Training Loss: 0.0006126122316345572
Test Loss:  0.0003942625771742314
Valid Loss:  0.0008690090617164969
Epoch:  335  	Training Loss: 0.0006120750913396478
Test Loss:  0.00039349455619230866
Valid Loss:  0.0008680255268700421
Epoch:  336  	Training Loss: 0.0006115628057159483
Test Loss:  0.0003927767393179238
Valid Loss:  0.0008671088144183159
Epoch:  337  	Training Loss: 0.0006110758986324072
Test Loss:  0.00039210758404806256
Valid Loss:  0.0008662462932989001
Epoch:  338  	Training Loss: 0.0006106171058490872
Test Loss:  0.00039148025098256767
Valid Loss:  0.0008654242847114801
Epoch:  339  	Training Loss: 0.0006101775215938687
Test Loss:  0.00039089153870008886
Valid Loss:  0.0008646438946016133
Epoch:  340  	Training Loss: 0.0006097544683143497
Test Loss:  0.00039033894427120686
Valid Loss:  0.0008639004663564265
Epoch:  341  	Training Loss: 0.0006093475385569036
Test Loss:  0.0003898217109963298
Valid Loss:  0.0008631902164779603
Epoch:  342  	Training Loss: 0.0006089552771300077
Test Loss:  0.0003904778277501464
Valid Loss:  0.0008630659431219101
Epoch:  343  	Training Loss: 0.0006082289037294686
Test Loss:  0.00039139785803854465
Valid Loss:  0.0008631142554804683
 69%|██████▉   | 344/500 [04:15<02:14,  1.16it/s] 69%|██████▉   | 346/500 [04:15<01:36,  1.59it/s] 70%|██████▉   | 348/500 [04:15<01:10,  2.15it/s] 70%|███████   | 350/500 [04:15<00:52,  2.85it/s] 70%|███████   | 352/500 [04:22<02:58,  1.20s/it] 71%|███████   | 354/500 [04:22<02:05,  1.16it/s] 71%|███████   | 356/500 [04:22<01:29,  1.60it/s] 72%|███████▏  | 358/500 [04:22<01:04,  2.19it/s] 72%|███████▏  | 360/500 [04:22<00:47,  2.95it/s] 72%|███████▏  | 362/500 [04:28<02:42,  1.17s/it] 73%|███████▎  | 364/500 [04:29<01:54,  1.19it/s] 73%|███████▎  | 366/500 [04:29<01:21,  1.64it/s] 74%|███████▎  | 368/500 [04:29<00:58,  2.25it/s] 74%|███████▍  | 370/500 [04:29<00:43,  3.02it/s] 74%|███████▍  | 372/500 [04:35<02:31,  1.18s/it] 75%|███████▍  | 374/500 [04:35<01:46,  1.18it/s] 75%|███████▌  | 376/500 [04:36<01:16,  1.63it/s] 76%|███████▌  | 378/500 [04:36<00:54,  2.23it/s] 76%|███████▌  | 380/500 [04:36<00:40,  2.99it/s] 76%|███████▋  | 382/500 [04:42<02:22,  1.21s/it] 77%|███████▋  | 384/500 [04:42<01:40,  1.15it/s] 77%|███████▋  | 386/500 [04:43<01:11,  1.60it/s] 78%|███████▊  | 388/500 [04:43<00:51,  2.19it/s] 78%|███████▊  | 390/500 [04:43<00:37,  2.94it/s] 78%|███████▊  | 392/500 [04:49<02:08,  1.19s/it] 79%|███████▉  | 394/500 [04:49<01:30,  1.17it/s] 79%|███████▉  | 396/500 [04:49<01:04,  1.62it/s] 80%|███████▉  | 398/500 [04:50<00:45,  2.22it/s] 80%|████████  | 400/500 [04:50<00:33,  2.98it/s] 80%|████████  | 402/500 [04:56<01:55,  1.18s/it] 81%|████████  | 404/500 [04:56<01:20,  1.19it/s] 81%|████████  | 406/500 [04:56<00:57,  1.64it/s] 82%|████████▏ | 408/500 [04:56<00:41,  2.24it/s] 82%|████████▏ | 410/500 [04:57<00:29,  3.02it/s]Epoch:  344  	Training Loss: 0.0006074473494663835
Test Loss:  0.0003922226023860276
Valid Loss:  0.0008631060482002795
Epoch:  345  	Training Loss: 0.0006067021749913692
Test Loss:  0.00039295171154662967
Valid Loss:  0.0008630378870293498
Epoch:  346  	Training Loss: 0.0006059877341613173
Test Loss:  0.00039359432412311435
Valid Loss:  0.0008629121584817767
Epoch:  347  	Training Loss: 0.0006052999524399638
Test Loss:  0.0003941599279642105
Valid Loss:  0.000862737069837749
Epoch:  348  	Training Loss: 0.0006046357448212802
Test Loss:  0.00039466851740144193
Valid Loss:  0.0008625243790447712
Epoch:  349  	Training Loss: 0.0006039912113919854
Test Loss:  0.00039512180956080556
Valid Loss:  0.0008622806053608656
Epoch:  350  	Training Loss: 0.0006033639656379819
Test Loss:  0.0003955165739171207
Valid Loss:  0.0008620003936812282
Epoch:  351  	Training Loss: 0.0006027011550031602
Test Loss:  0.00039624079363420606
Valid Loss:  0.0008619395084679127
Epoch:  352  	Training Loss: 0.000601987587288022
Test Loss:  0.00039698544424027205
Valid Loss:  0.0008619425352662802
Epoch:  353  	Training Loss: 0.0006011857185512781
Test Loss:  0.0003978433378506452
Valid Loss:  0.0008621494635008276
Epoch:  354  	Training Loss: 0.000600353698246181
Test Loss:  0.0003985743969678879
Valid Loss:  0.0008622794412076473
Epoch:  355  	Training Loss: 0.000599565333686769
Test Loss:  0.0003991947160102427
Valid Loss:  0.0008623206522315741
Epoch:  356  	Training Loss: 0.0005988102639093995
Test Loss:  0.0003996987361460924
Valid Loss:  0.0008622878231108189
Epoch:  357  	Training Loss: 0.0005980802816338837
Test Loss:  0.0004001196939498186
Valid Loss:  0.000862192246131599
Epoch:  358  	Training Loss: 0.0005973693332634866
Test Loss:  0.0004004660004284233
Valid Loss:  0.0008620441658422351
Epoch:  359  	Training Loss: 0.0005966717144474387
Test Loss:  0.0004007388779427856
Valid Loss:  0.0008618405554443598
Epoch:  360  	Training Loss: 0.0005959792761132121
Test Loss:  0.0004009543335996568
Valid Loss:  0.0008615924161858857
Epoch:  361  	Training Loss: 0.0005952956853434443
Test Loss:  0.0004011164419353008
Valid Loss:  0.000861302949488163
Epoch:  362  	Training Loss: 0.0005946214077994227
Test Loss:  0.0004003465292043984
Valid Loss:  0.0008602974703535438
Epoch:  363  	Training Loss: 0.0005941321142017841
Test Loss:  0.0003996145387645811
Valid Loss:  0.0008593313978053629
Epoch:  364  	Training Loss: 0.0005936555098742247
Test Loss:  0.0003989179967902601
Valid Loss:  0.0008583989692851901
Epoch:  365  	Training Loss: 0.0005931931082159281
Test Loss:  0.0003982533235102892
Valid Loss:  0.000857499660924077
Epoch:  366  	Training Loss: 0.0005927482852712274
Test Loss:  0.00039762016967870295
Valid Loss:  0.0008566356846131384
Epoch:  367  	Training Loss: 0.0005923208082094789
Test Loss:  0.0003970152756664902
Valid Loss:  0.0008557977853342891
Epoch:  368  	Training Loss: 0.0005919053801335394
Test Loss:  0.0003964377974625677
Valid Loss:  0.0008549943449907005
Epoch:  369  	Training Loss: 0.0005915107321925461
Test Loss:  0.00039588462095707655
Valid Loss:  0.0008542150026187301
Epoch:  370  	Training Loss: 0.000591123360209167
Test Loss:  0.0003953569394070655
Valid Loss:  0.0008534579537808895
Epoch:  371  	Training Loss: 0.0005907420418225229
Test Loss:  0.0003948508820030838
Valid Loss:  0.000852721743285656
Epoch:  372  	Training Loss: 0.000590370618738234
Test Loss:  0.00039463600842282176
Valid Loss:  0.00085208605742082
Epoch:  373  	Training Loss: 0.0005899246316403151
Test Loss:  0.00039441260742023587
Valid Loss:  0.0008515060180798173
Epoch:  374  	Training Loss: 0.0005895420908927917
Test Loss:  0.000394160597352311
Valid Loss:  0.0008509503677487373
Epoch:  375  	Training Loss: 0.0005891923792660236
Test Loss:  0.00039387584547512233
Valid Loss:  0.0008504109573550522
Epoch:  376  	Training Loss: 0.0005888616433367133
Test Loss:  0.0003935975255444646
Valid Loss:  0.0008498773677274585
Epoch:  377  	Training Loss: 0.0005885445862077177
Test Loss:  0.00039331670268438756
Valid Loss:  0.0008493586210533977
Epoch:  378  	Training Loss: 0.000588244991376996
Test Loss:  0.00039303230005316436
Valid Loss:  0.0008488522726111114
Epoch:  379  	Training Loss: 0.0005879602977074683
Test Loss:  0.00039274245500564575
Valid Loss:  0.0008483490673825145
Epoch:  380  	Training Loss: 0.0005876790382899344
Test Loss:  0.000392451009247452
Valid Loss:  0.0008478498784825206
Epoch:  381  	Training Loss: 0.0005874012131243944
Test Loss:  0.0003921572642866522
Valid Loss:  0.0008473554626107216
Epoch:  382  	Training Loss: 0.0005871256580576301
Test Loss:  0.0003922498435713351
Valid Loss:  0.0008473690832033753
Epoch:  383  	Training Loss: 0.0005870512104593217
Test Loss:  0.0003923402982763946
Valid Loss:  0.0008473813068121672
Epoch:  384  	Training Loss: 0.0005869771703146398
Test Loss:  0.0003924258053302765
Valid Loss:  0.0008473925408907235
Epoch:  385  	Training Loss: 0.0005869028973393142
Test Loss:  0.0003925088676624
Valid Loss:  0.0008474023779854178
Epoch:  386  	Training Loss: 0.0005868293810635805
Test Loss:  0.0003925888449884951
Valid Loss:  0.0008474115747958422
Epoch:  387  	Training Loss: 0.000586757087148726
Test Loss:  0.00039266693056561053
Valid Loss:  0.0008474186179228127
Epoch:  388  	Training Loss: 0.0005866845604032278
Test Loss:  0.0003927401849068701
Valid Loss:  0.000847425137180835
Epoch:  389  	Training Loss: 0.0005866134306415915
Test Loss:  0.0003928116930183023
Valid Loss:  0.0008474305504933
Epoch:  390  	Training Loss: 0.0005865420680493116
Test Loss:  0.0003928807273041457
Valid Loss:  0.0008474344504065812
Epoch:  391  	Training Loss: 0.0005864712875336409
Test Loss:  0.0003929465019609779
Valid Loss:  0.0008474384085275233
Epoch:  392  	Training Loss: 0.0005864003323949873
Test Loss:  0.0003930050879716873
Valid Loss:  0.0008473877096548676
Epoch:  393  	Training Loss: 0.0005863086553290486
Test Loss:  0.00039305281825363636
Valid Loss:  0.0008473377674818039
Epoch:  394  	Training Loss: 0.0005862210527993739
Test Loss:  0.000393091409932822
Valid Loss:  0.0008472884073853493
Epoch:  395  	Training Loss: 0.0005861358367837965
Test Loss:  0.0003931218234356493
Valid Loss:  0.000847241492010653
Epoch:  396  	Training Loss: 0.0005860519595444202
Test Loss:  0.00039314618334174156
Valid Loss:  0.0008471927721984684
Epoch:  397  	Training Loss: 0.0005859680823050439
Test Loss:  0.00039316643960773945
Valid Loss:  0.0008471437031403184
Epoch:  398  	Training Loss: 0.0005858853692188859
Test Loss:  0.0003931816900148988
Valid Loss:  0.0008470948087051511
Epoch:  399  	Training Loss: 0.0005858030635863543
Test Loss:  0.0003931938554160297
Valid Loss:  0.0008470441680401564
Epoch:  400  	Training Loss: 0.0005857208161614835
Test Loss:  0.00039320182986557484
Valid Loss:  0.0008469931781291962
Epoch:  401  	Training Loss: 0.0005856383359059691
Test Loss:  0.00039320660289376974
Valid Loss:  0.000846941489726305
Epoch:  402  	Training Loss: 0.0005855564959347248
Test Loss:  0.000393973954487592
Valid Loss:  0.0008472832851111889
Epoch:  403  	Training Loss: 0.0005848488071933389
Test Loss:  0.0003946549550164491
Valid Loss:  0.0008475824724882841
Epoch:  404  	Training Loss: 0.0005841988604515791
Test Loss:  0.0003952556289732456
Valid Loss:  0.0008478378877043724
Epoch:  405  	Training Loss: 0.0005835895426571369
Test Loss:  0.0003961489419452846
Valid Loss:  0.0008482255507260561
Epoch:  406  	Training Loss: 0.0005829188739880919
Test Loss:  0.00039694778388366103
Valid Loss:  0.0008484491263516247
Epoch:  407  	Training Loss: 0.0005822979146614671
Test Loss:  0.0003976759035140276
Valid Loss:  0.0008486442966386676
Epoch:  408  	Training Loss: 0.0005817192140966654
Test Loss:  0.00039832445327192545
Valid Loss:  0.0008487990126013756
Epoch:  409  	Training Loss: 0.0005811764276586473
Test Loss:  0.00039877716335467994
Valid Loss:  0.0008489293395541608
Epoch:  410  	Training Loss: 0.0005806656554341316
Test Loss:  0.0003991190460510552
Valid Loss:  0.0008490232285112143
Epoch:  411  	Training Loss: 0.0005801822990179062
Test Loss:  0.0003994086291640997
Valid Loss:  0.0008490851614624262
 82%|████████▏ | 412/500 [05:03<01:42,  1.17s/it] 83%|████████▎ | 414/500 [05:03<01:12,  1.19it/s] 83%|████████▎ | 416/500 [05:03<00:51,  1.62it/s] 84%|████████▎ | 418/500 [05:03<00:37,  2.19it/s] 84%|████████▍ | 420/500 [05:03<00:27,  2.88it/s] 84%|████████▍ | 422/500 [05:10<01:33,  1.20s/it] 85%|████████▍ | 424/500 [05:10<01:05,  1.17it/s] 85%|████████▌ | 426/500 [05:10<00:45,  1.61it/s] 86%|████████▌ | 428/500 [05:10<00:32,  2.21it/s] 86%|████████▌ | 430/500 [05:10<00:23,  2.97it/s] 86%|████████▋ | 432/500 [05:17<01:19,  1.18s/it] 87%|████████▋ | 434/500 [05:17<00:55,  1.19it/s] 87%|████████▋ | 436/500 [05:17<00:38,  1.64it/s] 88%|████████▊ | 438/500 [05:17<00:27,  2.24it/s] 88%|████████▊ | 440/500 [05:17<00:19,  3.01it/s] 88%|████████▊ | 442/500 [05:23<01:08,  1.18s/it] 89%|████████▉ | 444/500 [05:24<00:47,  1.18it/s] 89%|████████▉ | 446/500 [05:24<00:33,  1.62it/s] 90%|████████▉ | 448/500 [05:24<00:23,  2.21it/s] 90%|█████████ | 450/500 [05:24<00:16,  2.98it/s] 90%|█████████ | 452/500 [05:31<00:59,  1.23s/it] 91%|█████████ | 454/500 [05:31<00:40,  1.14it/s] 91%|█████████ | 456/500 [05:31<00:28,  1.57it/s] 92%|█████████▏| 458/500 [05:31<00:19,  2.15it/s] 92%|█████████▏| 460/500 [05:31<00:13,  2.89it/s] 92%|█████████▏| 462/500 [05:38<00:46,  1.21s/it] 93%|█████████▎| 464/500 [05:38<00:31,  1.15it/s] 93%|█████████▎| 466/500 [05:38<00:21,  1.59it/s] 94%|█████████▎| 468/500 [05:38<00:14,  2.18it/s] 94%|█████████▍| 470/500 [05:38<00:10,  2.93it/s] 94%|█████████▍| 472/500 [05:44<00:33,  1.18s/it] 95%|█████████▍| 474/500 [05:45<00:21,  1.18it/s] 95%|█████████▌| 476/500 [05:45<00:14,  1.63it/s] 96%|█████████▌| 478/500 [05:45<00:09,  2.23it/s]Epoch:  412  	Training Loss: 0.0005797218764200807
Test Loss:  0.00039929317426867783
Valid Loss:  0.0008489489555358887
Epoch:  413  	Training Loss: 0.0005795877077616751
Test Loss:  0.00039921392453834414
Valid Loss:  0.0008488257299177349
Epoch:  414  	Training Loss: 0.0005794682074338198
Test Loss:  0.0003991536796092987
Valid Loss:  0.0008487062295898795
Epoch:  415  	Training Loss: 0.0005793558666482568
Test Loss:  0.0003991059784311801
Valid Loss:  0.0008485909202136099
Epoch:  416  	Training Loss: 0.0005792499287053943
Test Loss:  0.00039906788151711226
Valid Loss:  0.0008484787540510297
Epoch:  417  	Training Loss: 0.0005791516741737723
Test Loss:  0.00039903545984998345
Valid Loss:  0.0008483733981847763
Epoch:  418  	Training Loss: 0.0005790589493699372
Test Loss:  0.00039900786941871047
Valid Loss:  0.0008482672856189311
Epoch:  419  	Training Loss: 0.0005789672140963376
Test Loss:  0.0003989817341789603
Valid Loss:  0.0008481628610752523
Epoch:  420  	Training Loss: 0.0005788778071291745
Test Loss:  0.00039895783993415534
Valid Loss:  0.0008480631513521075
Epoch:  421  	Training Loss: 0.0005787928239442408
Test Loss:  0.00039893496432341635
Valid Loss:  0.00084796326700598
Epoch:  422  	Training Loss: 0.0005787081317976117
Test Loss:  0.0003995497536379844
Valid Loss:  0.0008484669961035252
Epoch:  423  	Training Loss: 0.0005786004476249218
Test Loss:  0.00040011308738030493
Valid Loss:  0.0008489301544614136
Epoch:  424  	Training Loss: 0.000578506151214242
Test Loss:  0.00040062921470962465
Valid Loss:  0.0008493519271723926
Epoch:  425  	Training Loss: 0.0005784238455817103
Test Loss:  0.00040110209374688566
Valid Loss:  0.0008497386006638408
Epoch:  426  	Training Loss: 0.0005783505039289594
Test Loss:  0.0004015343147329986
Valid Loss:  0.0008500406984239817
Epoch:  427  	Training Loss: 0.0005782850785180926
Test Loss:  0.0004019279731437564
Valid Loss:  0.0008502656128257513
Epoch:  428  	Training Loss: 0.0005782251828350127
Test Loss:  0.00040228565922006965
Valid Loss:  0.0008504681754857302
Epoch:  429  	Training Loss: 0.0005781708750873804
Test Loss:  0.0004026113310828805
Valid Loss:  0.0008506494341418147
Epoch:  430  	Training Loss: 0.0005781210493296385
Test Loss:  0.0004029065603390336
Valid Loss:  0.0008508164901286364
Epoch:  431  	Training Loss: 0.0005780758801847696
Test Loss:  0.0004031888674944639
Valid Loss:  0.0008509745821356773
Epoch:  432  	Training Loss: 0.0005780345527455211
Test Loss:  0.00040316436206921935
Valid Loss:  0.0008506966405548155
Epoch:  433  	Training Loss: 0.0005777862388640642
Test Loss:  0.00040312690543942153
Valid Loss:  0.0008504106663167477
Epoch:  434  	Training Loss: 0.0005775393801741302
Test Loss:  0.0004030777490697801
Valid Loss:  0.0008501199772581458
Epoch:  435  	Training Loss: 0.0005772940348833799
Test Loss:  0.0004030184936709702
Valid Loss:  0.0008498238166794181
Epoch:  436  	Training Loss: 0.0005770474090240896
Test Loss:  0.0004029519041068852
Valid Loss:  0.0008495233487337828
Epoch:  437  	Training Loss: 0.0005768021801486611
Test Loss:  0.00040287719457410276
Valid Loss:  0.0008492199704051018
Epoch:  438  	Training Loss: 0.0005765580572187901
Test Loss:  0.000402796984417364
Valid Loss:  0.0008489139145240188
Epoch:  439  	Training Loss: 0.0005763048538938165
Test Loss:  0.0004030502459499985
Valid Loss:  0.0008488185121677816
Epoch:  440  	Training Loss: 0.0005760187050327659
Test Loss:  0.0004032692522741854
Valid Loss:  0.0008486943552270532
Epoch:  441  	Training Loss: 0.0005757350591011345
Test Loss:  0.0004034508019685745
Valid Loss:  0.0008485498838126659
Epoch:  442  	Training Loss: 0.0005754560115747154
Test Loss:  0.00040520488983020186
Valid Loss:  0.0008461891557089984
Epoch:  443  	Training Loss: 0.0005714664584957063
Test Loss:  0.00040679765515960753
Valid Loss:  0.000843603047542274
Epoch:  444  	Training Loss: 0.0005681646289303899
Test Loss:  0.00040822121081873775
Valid Loss:  0.0008409998845309019
Epoch:  445  	Training Loss: 0.0005653732223436236
Test Loss:  0.0004094588221050799
Valid Loss:  0.0008382722735404968
Epoch:  446  	Training Loss: 0.0005628453800454736
Test Loss:  0.0004106824053451419
Valid Loss:  0.0008356233010999858
Epoch:  447  	Training Loss: 0.000560335407499224
Test Loss:  0.0004119001096114516
Valid Loss:  0.0008330296841450036
Epoch:  448  	Training Loss: 0.000557925901375711
Test Loss:  0.0004129116714466363
Valid Loss:  0.0008305771043524146
Epoch:  449  	Training Loss: 0.0005557623226195574
Test Loss:  0.00041372666601091623
Valid Loss:  0.0008282329654321074
Epoch:  450  	Training Loss: 0.0005537879187613726
Test Loss:  0.00041435781167820096
Valid Loss:  0.0008259730529971421
Epoch:  451  	Training Loss: 0.0005519590340554714
Test Loss:  0.00041482417145743966
Valid Loss:  0.0008237669244408607
Epoch:  452  	Training Loss: 0.0005501831183210015
Test Loss:  0.0004122068639844656
Valid Loss:  0.0008207702194340527
Epoch:  453  	Training Loss: 0.000548544863704592
Test Loss:  0.0004098002100363374
Valid Loss:  0.0008179402211681008
Epoch:  454  	Training Loss: 0.0005470052710734308
Test Loss:  0.00040750985499471426
Valid Loss:  0.0008152175578288734
Epoch:  455  	Training Loss: 0.0005455280188471079
Test Loss:  0.0004053123411722481
Valid Loss:  0.0008125911699607968
Epoch:  456  	Training Loss: 0.0005441044922918081
Test Loss:  0.0004032171273138374
Valid Loss:  0.0008100589038804173
Epoch:  457  	Training Loss: 0.0005427279393188655
Test Loss:  0.0004011935379821807
Valid Loss:  0.0008076059748418629
Epoch:  458  	Training Loss: 0.00054139707935974
Test Loss:  0.00039923604344949126
Valid Loss:  0.0008052228949964046
Epoch:  459  	Training Loss: 0.0005401084199547768
Test Loss:  0.0003973349230363965
Valid Loss:  0.0008029061136767268
Epoch:  460  	Training Loss: 0.0005388582358136773
Test Loss:  0.0003954885760322213
Valid Loss:  0.0008006531279534101
Epoch:  461  	Training Loss: 0.0005376486806198955
Test Loss:  0.00039369717705994844
Valid Loss:  0.0007984653930179775
Epoch:  462  	Training Loss: 0.0005364792887121439
Test Loss:  0.00039360515074804425
Valid Loss:  0.0007983136456459761
Epoch:  463  	Training Loss: 0.000536384352017194
Test Loss:  0.0003935172862838954
Valid Loss:  0.0007981772068887949
Epoch:  464  	Training Loss: 0.0005363021627999842
Test Loss:  0.00039342872332781553
Valid Loss:  0.0007980490336194634
Epoch:  465  	Training Loss: 0.0005362260271795094
Test Loss:  0.0003933396947104484
Valid Loss:  0.000797927612438798
Epoch:  466  	Training Loss: 0.0005361546063795686
Test Loss:  0.0003932490071747452
Valid Loss:  0.0007978112553246319
Epoch:  467  	Training Loss: 0.0005360849900171161
Test Loss:  0.00039315660251304507
Valid Loss:  0.0007976948982104659
Epoch:  468  	Training Loss: 0.0005360160721465945
Test Loss:  0.00039306230610236526
Valid Loss:  0.000797581858932972
Epoch:  469  	Training Loss: 0.0005359485512599349
Test Loss:  0.00039296699105761945
Valid Loss:  0.0007974695763550699
Epoch:  470  	Training Loss: 0.0005358808557502925
Test Loss:  0.0003928710939362645
Valid Loss:  0.000797358516138047
Epoch:  471  	Training Loss: 0.0005358132184483111
Test Loss:  0.0003927750512957573
Valid Loss:  0.0007972469902597368
Epoch:  472  	Training Loss: 0.0005357464542612433
Test Loss:  0.0003924462653230876
Valid Loss:  0.0007968925056047738
Epoch:  473  	Training Loss: 0.0005355061730369925
Test Loss:  0.0003921271418221295
Valid Loss:  0.0007965526310727
Epoch:  474  	Training Loss: 0.0005352796288207173
Test Loss:  0.0003918156144209206
Valid Loss:  0.0007962242234498262
Epoch:  475  	Training Loss: 0.0005350627470761538
Test Loss:  0.00039151153760030866
Valid Loss:  0.0007959090871736407
Epoch:  476  	Training Loss: 0.0005348572740331292
Test Loss:  0.00039121595909819007
Valid Loss:  0.0007956038461998105
Epoch:  477  	Training Loss: 0.000534661638084799
Test Loss:  0.0003909279766958207
Valid Loss:  0.0007953098975121975
Epoch:  478  	Training Loss: 0.0005344736855477095
Test Loss:  0.00039064325392246246
Valid Loss:  0.0007950244471430779
Epoch:  479  	Training Loss: 0.0005342929507605731
Test Loss:  0.0003903650213032961
Valid Loss:  0.0007947506383061409
 96%|█████████▌| 480/500 [05:45<00:06,  3.01it/s] 96%|█████████▋| 482/500 [05:51<00:21,  1.18s/it] 97%|█████████▋| 484/500 [05:51<00:13,  1.18it/s] 97%|█████████▋| 486/500 [05:52<00:08,  1.63it/s] 98%|█████████▊| 488/500 [05:52<00:05,  2.22it/s] 98%|█████████▊| 490/500 [05:52<00:03,  2.98it/s] 98%|█████████▊| 492/500 [05:58<00:09,  1.18s/it] 99%|█████████▉| 494/500 [05:58<00:05,  1.17it/s] 99%|█████████▉| 496/500 [05:58<00:02,  1.61it/s]100%|█████████▉| 498/500 [05:59<00:00,  2.18it/s]100%|██████████| 500/500 [05:59<00:00,  2.93it/s]100%|██████████| 500/500 [05:59<00:00,  1.39it/s]
Epoch:  480  	Training Loss: 0.0005341200157999992
Test Loss:  0.000390094006434083
Valid Loss:  0.0007944839308038354
Epoch:  481  	Training Loss: 0.0005339541239663959
Test Loss:  0.00038983020931482315
Valid Loss:  0.0007942266529425979
Epoch:  482  	Training Loss: 0.0005337949842214584
Test Loss:  0.0003883655881509185
Valid Loss:  0.0007925649406388402
Epoch:  483  	Training Loss: 0.0005329248961061239
Test Loss:  0.0003870449145324528
Valid Loss:  0.0007910477579571307
Epoch:  484  	Training Loss: 0.000532155972905457
Test Loss:  0.00038584103458561003
Valid Loss:  0.0007896436145529151
Epoch:  485  	Training Loss: 0.0005314654554240406
Test Loss:  0.00038473340100608766
Valid Loss:  0.0007883316720835865
Epoch:  486  	Training Loss: 0.0005308371037244797
Test Loss:  0.0003837054537143558
Valid Loss:  0.0007870977278798819
Epoch:  487  	Training Loss: 0.000530258403159678
Test Loss:  0.0003827451728284359
Valid Loss:  0.000785930547863245
Epoch:  488  	Training Loss: 0.0005297212628647685
Test Loss:  0.00038184193545021117
Valid Loss:  0.0007848209934309125
Epoch:  489  	Training Loss: 0.0005292188143357635
Test Loss:  0.0003809877089224756
Valid Loss:  0.0007837619632482529
Epoch:  490  	Training Loss: 0.0005287434323690832
Test Loss:  0.00038017617771402
Valid Loss:  0.0007827453082427382
Epoch:  491  	Training Loss: 0.0005282920319586992
Test Loss:  0.0003794028889387846
Valid Loss:  0.0007817698642611504
Epoch:  492  	Training Loss: 0.0005278610624372959
Test Loss:  0.00037859223084524274
Valid Loss:  0.0007808188674971461
Epoch:  493  	Training Loss: 0.0005274339928291738
Test Loss:  0.00037780788261443377
Valid Loss:  0.0007798983133397996
Epoch:  494  	Training Loss: 0.0005270205438137054
Test Loss:  0.0003770431794691831
Valid Loss:  0.0007790016243234277
Epoch:  495  	Training Loss: 0.0005266183870844543
Test Loss:  0.0003763003333006054
Valid Loss:  0.0007781299646012485
Epoch:  496  	Training Loss: 0.0005262289196252823
Test Loss:  0.00037557928590103984
Valid Loss:  0.0007772833341732621
Epoch:  497  	Training Loss: 0.0005258506862446666
Test Loss:  0.00037487881490960717
Valid Loss:  0.0007764595793560147
Epoch:  498  	Training Loss: 0.0005254835123196244
Test Loss:  0.00037419586442410946
Valid Loss:  0.0007756585255265236
Epoch:  499  	Training Loss: 0.0005251270486041903
Test Loss:  0.0003735247883014381
Valid Loss:  0.0007748740026727319
Epoch:  500  	Training Loss: 0.0005247770459391177
Test Loss:  0.0003728687879629433
Valid Loss:  0.0007741091540083289
seed is  2
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:42, 11.64it/s]  1%|          | 4/500 [00:00<00:40, 12.33it/s]  1%|          | 6/500 [00:00<00:35, 13.97it/s]  2%|▏         | 8/500 [00:00<00:33, 14.83it/s]  2%|▏         | 10/500 [00:00<00:31, 15.39it/s]  2%|▏         | 12/500 [00:00<00:30, 15.77it/s]  3%|▎         | 14/500 [00:00<00:30, 15.94it/s]  3%|▎         | 16/500 [00:01<00:30, 15.82it/s]  4%|▎         | 18/500 [00:01<00:29, 16.08it/s]  4%|▍         | 20/500 [00:01<00:29, 16.14it/s]  4%|▍         | 22/500 [00:01<00:29, 16.30it/s]  5%|▍         | 24/500 [00:01<00:29, 16.40it/s]  5%|▌         | 26/500 [00:01<00:29, 16.08it/s]  6%|▌         | 28/500 [00:01<00:29, 16.18it/s]  6%|▌         | 30/500 [00:01<00:28, 16.25it/s]  6%|▋         | 32/500 [00:02<00:28, 16.23it/s]  7%|▋         | 34/500 [00:02<00:29, 15.67it/s]  7%|▋         | 36/500 [00:02<00:30, 15.25it/s]  8%|▊         | 38/500 [00:02<00:30, 15.32it/s]  8%|▊         | 40/500 [00:02<00:30, 15.30it/s]  8%|▊         | 42/500 [00:02<00:29, 15.56it/s]  9%|▉         | 44/500 [00:02<00:29, 15.71it/s]  9%|▉         | 46/500 [00:02<00:28, 15.82it/s] 10%|▉         | 48/500 [00:03<00:28, 15.93it/s] 10%|█         | 50/500 [00:03<00:27, 16.10it/s] 10%|█         | 52/500 [00:03<00:27, 16.20it/s] 11%|█         | 54/500 [00:03<00:27, 16.27it/s] 11%|█         | 56/500 [00:03<00:27, 16.18it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.31it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.43it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.46it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.39it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.40it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.47it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.48it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.56it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.52it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.50it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.60it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.62it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.61it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.33it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.09it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.07it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.79it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.91it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.68it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.88it/s] 20%|█▉        | 98/500 [00:06<00:25, 16.02it/s] 20%|██        | 100/500 [00:06<00:24, 16.16it/s] 20%|██        | 102/500 [00:06<00:24, 16.21it/s] 21%|██        | 104/500 [00:06<00:24, 16.28it/s] 21%|██        | 106/500 [00:06<00:25, 15.45it/s] 22%|██▏       | 108/500 [00:06<00:27, 14.46it/s] 22%|██▏       | 110/500 [00:06<00:26, 14.76it/s] 22%|██▏       | 112/500 [00:07<00:25, 15.22it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.57it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.68it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.89it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.11it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.19it/s]Epoch:  1  	Training Loss: 0.044193021953105927
Test Loss:  4.549596309661865
Valid Loss:  4.465944766998291
Epoch:  2  	Training Loss: 4.451998710632324
Test Loss:  3832964.5
Valid Loss:  3806219.75
Epoch:  3  	Training Loss: 3782413.0
Test Loss:  1.6016033014979189e+31
Valid Loss:  1.5899070650857293e+31
Epoch:  4  	Training Loss: 1.5808895665046418e+31
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:   25%|██▍       | 124/500 [00:07<00:23, 16.24it/s] 25%|██▌       | 126/500 [00:07<00:23, 16.18it/s] 26%|██▌       | 128/500 [00:08<00:23, 16.12it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.10it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.69it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.89it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.02it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.17it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.21it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.31it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.38it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.34it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.34it/s] 30%|███       | 150/500 [00:09<00:21, 16.33it/s] 30%|███       | 152/500 [00:09<00:22, 15.80it/s] 31%|███       | 154/500 [00:09<00:23, 14.51it/s] 31%|███       | 156/500 [00:09<00:25, 13.70it/s] 32%|███▏      | 158/500 [00:10<00:25, 13.38it/s] 32%|███▏      | 160/500 [00:10<00:26, 12.93it/s] 32%|███▏      | 162/500 [00:10<00:26, 12.72it/s] 33%|███▎      | 164/500 [00:10<00:26, 12.60it/s] 33%|███▎      | 166/500 [00:10<00:26, 12.50it/s] 34%|███▎      | 168/500 [00:10<00:26, 12.43it/s] 34%|███▍      | 170/500 [00:11<00:26, 12.33it/s] 34%|███▍      | 172/500 [00:11<00:26, 12.17it/s] 35%|███▍      | 174/500 [00:11<00:25, 12.86it/s] 35%|███▌      | 176/500 [00:11<00:24, 13.00it/s] 36%|███▌      | 178/500 [00:11<00:24, 12.94it/s] 36%|███▌      | 180/500 [00:11<00:23, 13.84it/s] 36%|███▋      | 182/500 [00:11<00:21, 14.49it/s] 37%|███▋      | 184/500 [00:11<00:21, 14.95it/s] 37%|███▋      | 186/500 [00:12<00:20, 15.02it/s] 38%|███▊      | 188/500 [00:12<00:20, 14.93it/s] 38%|███▊      | 190/500 [00:12<00:20, 15.20it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.55it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.69it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.95it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.10it/s] 40%|████      | 200/500 [00:12<00:18, 16.22it/s] 40%|████      | 202/500 [00:13<00:18, 16.26it/s] 41%|████      | 204/500 [00:13<00:18, 16.28it/s] 41%|████      | 206/500 [00:13<00:18, 16.30it/s] 42%|████▏     | 208/500 [00:13<00:17, 16.24it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.18it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.01it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.85it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.00it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.11it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.28it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.30it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.24it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.30it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.17it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.82it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.80it/s] 47%|████▋     | 234/500 [00:15<00:16, 15.68it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.91it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.04it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.01it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.97it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.14it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.19it/s]nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
 50%|████▉     | 248/500 [00:15<00:15, 16.06it/s] 50%|█████     | 250/500 [00:16<00:15, 16.02it/s] 50%|█████     | 252/500 [00:16<00:15, 16.08it/s] 51%|█████     | 254/500 [00:16<00:15, 15.41it/s] 51%|█████     | 256/500 [00:16<00:15, 15.75it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.87it/s] 52%|█████▏    | 260/500 [00:16<00:15, 16.00it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.12it/s] 53%|█████▎    | 264/500 [00:16<00:14, 15.74it/s] 53%|█████▎    | 266/500 [00:17<00:14, 15.72it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.93it/s] 54%|█████▍    | 270/500 [00:17<00:15, 14.89it/s] 54%|█████▍    | 272/500 [00:17<00:16, 14.04it/s] 55%|█████▍    | 274/500 [00:17<00:16, 13.44it/s] 55%|█████▌    | 276/500 [00:17<00:15, 14.18it/s] 56%|█████▌    | 278/500 [00:17<00:14, 14.80it/s] 56%|█████▌    | 280/500 [00:18<00:14, 15.26it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.58it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.55it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.66it/s] 58%|█████▊    | 288/500 [00:18<00:14, 14.70it/s] 58%|█████▊    | 290/500 [00:18<00:15, 13.80it/s] 58%|█████▊    | 292/500 [00:18<00:15, 13.41it/s] 59%|█████▉    | 294/500 [00:19<00:14, 14.20it/s] 59%|█████▉    | 296/500 [00:19<00:14, 14.40it/s] 60%|█████▉    | 298/500 [00:19<00:13, 14.78it/s] 60%|██████    | 300/500 [00:19<00:13, 15.01it/s] 60%|██████    | 302/500 [00:19<00:12, 15.31it/s] 61%|██████    | 304/500 [00:19<00:12, 15.41it/s] 61%|██████    | 306/500 [00:19<00:12, 15.29it/s] 62%|██████▏   | 308/500 [00:20<00:13, 14.22it/s] 62%|██████▏   | 310/500 [00:20<00:13, 14.42it/s] 62%|██████▏   | 312/500 [00:20<00:12, 14.73it/s] 63%|██████▎   | 314/500 [00:20<00:12, 15.05it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.45it/s] 64%|██████▎   | 318/500 [00:20<00:11, 15.73it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.96it/s] 64%|██████▍   | 322/500 [00:20<00:11, 16.11it/s] 65%|██████▍   | 324/500 [00:21<00:10, 16.21it/s] 65%|██████▌   | 326/500 [00:21<00:10, 16.29it/s] 66%|██████▌   | 328/500 [00:21<00:10, 16.38it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.22it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.23it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.28it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.36it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.38it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.44it/s] 68%|██████▊   | 342/500 [00:22<00:10, 15.11it/s] 69%|██████▉   | 344/500 [00:22<00:10, 14.37it/s] 69%|██████▉   | 346/500 [00:22<00:10, 14.30it/s] 70%|██████▉   | 348/500 [00:22<00:11, 13.61it/s] 70%|███████   | 350/500 [00:22<00:11, 13.07it/s] 70%|███████   | 352/500 [00:22<00:11, 12.86it/s] 71%|███████   | 354/500 [00:23<00:11, 12.63it/s] 71%|███████   | 356/500 [00:23<00:11, 12.56it/s] 72%|███████▏  | 358/500 [00:23<00:11, 12.49it/s] 72%|███████▏  | 360/500 [00:23<00:11, 12.44it/s] 72%|███████▏  | 362/500 [00:23<00:11, 12.36it/s] 73%|███████▎  | 364/500 [00:23<00:11, 12.36it/s] 73%|███████▎  | 366/500 [00:24<00:10, 12.31it/s] 74%|███████▎  | 368/500 [00:24<00:10, 12.29it/s] 74%|███████▍  | 370/500 [00:24<00:10, 12.30it/s]Valid Loss:  nan
Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
 74%|███████▍  | 372/500 [00:24<00:10, 12.32it/s] 75%|███████▍  | 374/500 [00:24<00:10, 12.33it/s] 75%|███████▌  | 376/500 [00:24<00:10, 12.33it/s] 76%|███████▌  | 378/500 [00:25<00:09, 12.32it/s] 76%|███████▌  | 380/500 [00:25<00:09, 12.33it/s] 76%|███████▋  | 382/500 [00:25<00:09, 12.33it/s] 77%|███████▋  | 384/500 [00:25<00:09, 12.32it/s] 77%|███████▋  | 386/500 [00:25<00:09, 12.31it/s] 78%|███████▊  | 388/500 [00:25<00:09, 12.31it/s] 78%|███████▊  | 390/500 [00:26<00:08, 12.23it/s] 78%|███████▊  | 392/500 [00:26<00:08, 12.41it/s] 79%|███████▉  | 394/500 [00:26<00:08, 12.75it/s] 79%|███████▉  | 396/500 [00:26<00:07, 13.46it/s] 80%|███████▉  | 398/500 [00:26<00:07, 14.27it/s] 80%|████████  | 400/500 [00:26<00:06, 14.88it/s] 80%|████████  | 402/500 [00:26<00:06, 15.33it/s] 81%|████████  | 404/500 [00:26<00:06, 15.43it/s] 81%|████████  | 406/500 [00:27<00:06, 15.33it/s] 82%|████████▏ | 408/500 [00:27<00:05, 15.36it/s] 82%|████████▏ | 410/500 [00:27<00:05, 15.63it/s] 82%|████████▏ | 412/500 [00:27<00:05, 15.89it/s] 83%|████████▎ | 414/500 [00:27<00:05, 15.62it/s] 83%|████████▎ | 416/500 [00:27<00:05, 15.51it/s] 84%|████████▎ | 418/500 [00:27<00:05, 15.14it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.53it/s] 84%|████████▍ | 422/500 [00:28<00:04, 15.60it/s] 85%|████████▍ | 424/500 [00:28<00:04, 15.82it/s] 85%|████████▌ | 426/500 [00:28<00:04, 16.07it/s] 86%|████████▌ | 428/500 [00:28<00:04, 16.22it/s] 86%|████████▌ | 430/500 [00:28<00:04, 15.89it/s] 86%|████████▋ | 432/500 [00:28<00:04, 15.88it/s] 87%|████████▋ | 434/500 [00:28<00:04, 15.83it/s] 87%|████████▋ | 436/500 [00:28<00:04, 15.79it/s] 88%|████████▊ | 438/500 [00:29<00:04, 14.95it/s] 88%|████████▊ | 440/500 [00:29<00:04, 14.21it/s] 88%|████████▊ | 442/500 [00:29<00:04, 14.19it/s] 89%|████████▉ | 444/500 [00:29<00:03, 14.32it/s] 89%|████████▉ | 446/500 [00:29<00:03, 14.87it/s] 90%|████████▉ | 448/500 [00:29<00:03, 15.28it/s] 90%|█████████ | 450/500 [00:29<00:03, 15.56it/s] 90%|█████████ | 452/500 [00:30<00:03, 15.76it/s] 91%|█████████ | 454/500 [00:30<00:02, 15.92it/s] 91%|█████████ | 456/500 [00:30<00:02, 16.04it/s] 92%|█████████▏| 458/500 [00:30<00:02, 16.16it/s] 92%|█████████▏| 460/500 [00:30<00:02, 16.15it/s] 92%|█████████▏| 462/500 [00:30<00:02, 16.21it/s] 93%|█████████▎| 464/500 [00:30<00:02, 16.28it/s] 93%|█████████▎| 466/500 [00:30<00:02, 16.29it/s] 94%|█████████▎| 468/500 [00:31<00:02, 15.93it/s] 94%|█████████▍| 470/500 [00:31<00:01, 16.06it/s] 94%|█████████▍| 472/500 [00:31<00:01, 15.73it/s] 95%|█████████▍| 474/500 [00:31<00:01, 15.57it/s] 95%|█████████▌| 476/500 [00:31<00:01, 15.80it/s] 96%|█████████▌| 478/500 [00:31<00:01, 15.96it/s] 96%|█████████▌| 480/500 [00:31<00:01, 16.05it/s] 96%|█████████▋| 482/500 [00:31<00:01, 16.13it/s] 97%|█████████▋| 484/500 [00:32<00:01, 15.60it/s] 97%|█████████▋| 486/500 [00:32<00:00, 15.74it/s] 98%|█████████▊| 488/500 [00:32<00:00, 15.81it/s] 98%|█████████▊| 490/500 [00:32<00:00, 15.79it/s] 98%|█████████▊| 492/500 [00:32<00:00, 15.98it/s] 99%|█████████▉| 494/500 [00:32<00:00, 16.05it/s]Valid Loss:  nan
Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
 99%|█████████▉| 496/500 [00:32<00:00, 16.18it/s]100%|█████████▉| 498/500 [00:32<00:00, 16.33it/s]100%|██████████| 500/500 [00:33<00:00, 16.12it/s]100%|██████████| 500/500 [00:33<00:00, 15.13it/s]
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  2
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:41,  6.22s/it]  1%|          | 3/500 [00:06<13:49,  1.67s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:20,  1.89it/s]  2%|▏         | 9/500 [00:06<02:57,  2.76it/s]  2%|▏         | 11/500 [00:13<11:17,  1.39s/it]  3%|▎         | 13/500 [00:13<07:41,  1.06it/s]  3%|▎         | 15/500 [00:13<05:21,  1.51it/s]  3%|▎         | 17/500 [00:13<03:51,  2.09it/s]  4%|▍         | 19/500 [00:14<02:51,  2.80it/s]  4%|▍         | 21/500 [00:20<10:01,  1.26s/it]  5%|▍         | 23/500 [00:20<07:06,  1.12it/s]  5%|▌         | 25/500 [00:20<05:05,  1.56it/s]  5%|▌         | 27/500 [00:21<03:41,  2.14it/s]  6%|▌         | 29/500 [00:21<02:42,  2.89it/s]  6%|▌         | 31/500 [00:27<09:17,  1.19s/it]  7%|▋         | 33/500 [00:27<06:39,  1.17it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:33,  2.17it/s]  8%|▊         | 39/500 [00:28<02:40,  2.87it/s]  8%|▊         | 41/500 [00:34<09:18,  1.22s/it]  9%|▊         | 43/500 [00:34<06:39,  1.15it/s]  9%|▉         | 45/500 [00:34<04:46,  1.59it/s]  9%|▉         | 47/500 [00:35<03:28,  2.17it/s] 10%|▉         | 49/500 [00:35<02:34,  2.92it/s] 10%|█         | 51/500 [00:41<08:51,  1.18s/it] 11%|█         | 53/500 [00:41<06:22,  1.17it/s] 11%|█         | 55/500 [00:41<04:37,  1.60it/s] 11%|█▏        | 57/500 [00:41<03:24,  2.16it/s] 12%|█▏        | 59/500 [00:42<02:34,  2.86it/s] 12%|█▏        | 61/500 [00:48<08:53,  1.22s/it] 13%|█▎        | 63/500 [00:48<06:21,  1.14it/s] 13%|█▎        | 65/500 [00:48<04:34,  1.59it/s] 13%|█▎        | 67/500 [00:48<03:19,  2.17it/s] 14%|█▍        | 69/500 [00:49<02:27,  2.92it/s] 14%|█▍        | 71/500 [00:55<08:35,  1.20s/it]Epoch:  1  	Training Loss: 0.044193021953105927
Test Loss:  0.27470946311950684
Valid Loss:  0.2630944848060608
Epoch:  2  	Training Loss: 0.2777237594127655
Test Loss:  2.5264148712158203
Valid Loss:  2.5220537185668945
Epoch:  3  	Training Loss: 2.5373315811157227
Test Loss:  0.025772875174880028
Valid Loss:  0.034169647842645645
Epoch:  4  	Training Loss: 0.037919435650110245
Test Loss:  0.025772787630558014
Valid Loss:  0.034169554710388184
Epoch:  5  	Training Loss: 0.03791934251785278
Test Loss:  0.0257727038115263
Valid Loss:  0.03416946157813072
Epoch:  6  	Training Loss: 0.03791925683617592
Test Loss:  0.025772614404559135
Valid Loss:  0.03416936472058296
Epoch:  7  	Training Loss: 0.037919167429208755
Test Loss:  0.02577252872288227
Valid Loss:  0.0341692678630352
Epoch:  8  	Training Loss: 0.03791907802224159
Test Loss:  0.025772441178560257
Valid Loss:  0.03416917845606804
Epoch:  9  	Training Loss: 0.03791899234056473
Test Loss:  0.025772355496883392
Valid Loss:  0.03416907787322998
Epoch:  10  	Training Loss: 0.037918902933597565
Test Loss:  0.02577226608991623
Valid Loss:  0.03416898474097252
Epoch:  11  	Training Loss: 0.037918820977211
Test Loss:  0.025772176682949066
Valid Loss:  0.03416889160871506
Epoch:  12  	Training Loss: 0.037918731570243835
Test Loss:  0.025771621614694595
Valid Loss:  0.03416825458407402
Epoch:  13  	Training Loss: 0.03791810944676399
Test Loss:  0.025771062821149826
Valid Loss:  0.03416762501001358
Epoch:  14  	Training Loss: 0.03791749104857445
Test Loss:  0.025770507752895355
Valid Loss:  0.03416699171066284
Epoch:  15  	Training Loss: 0.037916868925094604
Test Loss:  0.025769950821995735
Valid Loss:  0.034166354686021805
Epoch:  16  	Training Loss: 0.03791625052690506
Test Loss:  0.025769401341676712
Valid Loss:  0.03416572883725166
Epoch:  17  	Training Loss: 0.037915635854005814
Test Loss:  0.02576884813606739
Valid Loss:  0.03416509926319122
Epoch:  18  	Training Loss: 0.03791501745581627
Test Loss:  0.025768296793103218
Valid Loss:  0.03416447713971138
Epoch:  19  	Training Loss: 0.037914395332336426
Test Loss:  0.025767747312784195
Valid Loss:  0.03416384756565094
Epoch:  20  	Training Loss: 0.03791378065943718
Test Loss:  0.025767195969820023
Valid Loss:  0.0341632217168808
Epoch:  21  	Training Loss: 0.037913162261247635
Test Loss:  0.02576664462685585
Valid Loss:  0.03416258841753006
Epoch:  22  	Training Loss: 0.03791254758834839
Test Loss:  0.02576608955860138
Valid Loss:  0.03416195511817932
Epoch:  23  	Training Loss: 0.03791192173957825
Test Loss:  0.02576553076505661
Valid Loss:  0.03416132181882858
Epoch:  24  	Training Loss: 0.03791128844022751
Test Loss:  0.02576497569680214
Valid Loss:  0.034160688519477844
Epoch:  25  	Training Loss: 0.03791066259145737
Test Loss:  0.02576441504061222
Valid Loss:  0.03416005149483681
Epoch:  26  	Training Loss: 0.03791003301739693
Test Loss:  0.0257638618350029
Valid Loss:  0.03415942192077637
Epoch:  27  	Training Loss: 0.03790940344333649
Test Loss:  0.02576330304145813
Valid Loss:  0.03415878117084503
Epoch:  28  	Training Loss: 0.037908777594566345
Test Loss:  0.02576274797320366
Valid Loss:  0.03415815159678459
Epoch:  29  	Training Loss: 0.037908151745796204
Test Loss:  0.025762192904949188
Valid Loss:  0.034157514572143555
Epoch:  30  	Training Loss: 0.037907522171735764
Test Loss:  0.02576163411140442
Valid Loss:  0.034156881272792816
Epoch:  31  	Training Loss: 0.03790690004825592
Test Loss:  0.025761082768440247
Valid Loss:  0.034156251698732376
Epoch:  32  	Training Loss: 0.03790626674890518
Test Loss:  0.025760533288121223
Valid Loss:  0.034155622124671936
Epoch:  33  	Training Loss: 0.037905652076005936
Test Loss:  0.02575998567044735
Valid Loss:  0.03415500000119209
Epoch:  34  	Training Loss: 0.03790503367781639
Test Loss:  0.025759432464838028
Valid Loss:  0.03415437787771225
Epoch:  35  	Training Loss: 0.037904419004917145
Test Loss:  0.025758882984519005
Valid Loss:  0.03415374830365181
Epoch:  36  	Training Loss: 0.0379038043320179
Test Loss:  0.02575833722949028
Valid Loss:  0.034153129905462265
Epoch:  37  	Training Loss: 0.037903185933828354
Test Loss:  0.025757785886526108
Valid Loss:  0.034152500331401825
Epoch:  38  	Training Loss: 0.03790257126092911
Test Loss:  0.025757236406207085
Valid Loss:  0.03415187448263168
Epoch:  39  	Training Loss: 0.03790195286273956
Test Loss:  0.02575668878853321
Valid Loss:  0.03415125608444214
Epoch:  40  	Training Loss: 0.03790133446455002
Test Loss:  0.02575613372027874
Valid Loss:  0.0341506265103817
Epoch:  41  	Training Loss: 0.03790071979165077
Test Loss:  0.025755589827895164
Valid Loss:  0.03415000066161156
Epoch:  42  	Training Loss: 0.037900105118751526
Test Loss:  0.02575504034757614
Valid Loss:  0.034149378538131714
Epoch:  43  	Training Loss: 0.03789948672056198
Test Loss:  0.02575448527932167
Valid Loss:  0.034148745238780975
Epoch:  44  	Training Loss: 0.03789886087179184
Test Loss:  0.025753933936357498
Valid Loss:  0.03414812311530113
Epoch:  45  	Training Loss: 0.037898242473602295
Test Loss:  0.025753386318683624
Valid Loss:  0.03414749726653099
Epoch:  46  	Training Loss: 0.03789762780070305
Test Loss:  0.025752834975719452
Valid Loss:  0.03414687141776085
Epoch:  47  	Training Loss: 0.037897005677223206
Test Loss:  0.025752287358045578
Valid Loss:  0.03414624184370041
Epoch:  48  	Training Loss: 0.03789638727903366
Test Loss:  0.025751739740371704
Valid Loss:  0.03414561599493027
Epoch:  49  	Training Loss: 0.037895772606134415
Test Loss:  0.025751188397407532
Valid Loss:  0.034144990146160126
Epoch:  50  	Training Loss: 0.03789515048265457
Test Loss:  0.02575063705444336
Valid Loss:  0.03414436802268028
Epoch:  51  	Training Loss: 0.03789453208446503
Test Loss:  0.025750085711479187
Valid Loss:  0.03414374217391014
Epoch:  52  	Training Loss: 0.03789391368627548
Test Loss:  0.02574954181909561
Valid Loss:  0.0341431200504303
Epoch:  53  	Training Loss: 0.037893299013376236
Test Loss:  0.025748994201421738
Valid Loss:  0.034142494201660156
Epoch:  54  	Training Loss: 0.03789268434047699
Test Loss:  0.025748448446393013
Valid Loss:  0.03414187580347061
Epoch:  55  	Training Loss: 0.037892065942287445
Test Loss:  0.02574789524078369
Valid Loss:  0.03414124622941017
Epoch:  56  	Training Loss: 0.0378914475440979
Test Loss:  0.025747351348400116
Valid Loss:  0.03414062410593033
Epoch:  57  	Training Loss: 0.03789083659648895
Test Loss:  0.025746803730726242
Valid Loss:  0.034140001982450485
Epoch:  58  	Training Loss: 0.03789021819829941
Test Loss:  0.02574625238776207
Valid Loss:  0.034139372408390045
Epoch:  59  	Training Loss: 0.03788959980010986
Test Loss:  0.025745708495378494
Valid Loss:  0.0341387540102005
Epoch:  60  	Training Loss: 0.037888988852500916
Test Loss:  0.02574516274034977
Valid Loss:  0.034138135612010956
Epoch:  61  	Training Loss: 0.03788837045431137
Test Loss:  0.025744616985321045
Valid Loss:  0.03413751348853111
Epoch:  62  	Training Loss: 0.03788775950670242
Test Loss:  0.025744067505002022
Valid Loss:  0.03413689509034157
Epoch:  63  	Training Loss: 0.03788714483380318
Test Loss:  0.025743525475263596
Valid Loss:  0.034136272966861725
Epoch:  64  	Training Loss: 0.03788653016090393
Test Loss:  0.02574298158288002
Valid Loss:  0.03413565084338188
Epoch:  65  	Training Loss: 0.03788591921329498
Test Loss:  0.025742433965206146
Valid Loss:  0.03413502871990204
Epoch:  66  	Training Loss: 0.037885308265686035
Test Loss:  0.02574189379811287
Valid Loss:  0.034134410321712494
Epoch:  67  	Training Loss: 0.03788469731807709
Test Loss:  0.025741346180438995
Valid Loss:  0.03413379192352295
Epoch:  68  	Training Loss: 0.03788408637046814
Test Loss:  0.02574080228805542
Valid Loss:  0.034133173525333405
Epoch:  69  	Training Loss: 0.03788347542285919
Test Loss:  0.025740258395671844
Valid Loss:  0.03413254767656326
Epoch:  70  	Training Loss: 0.037882864475250244
Test Loss:  0.025739707052707672
Valid Loss:  0.03413193300366402
Epoch:  71  	Training Loss: 0.0378822460770607
Test Loss:  0.025739166885614395
Valid Loss:  0.034131310880184174
Epoch:  72  	Training Loss: 0.03788163885474205
Test Loss:  0.025738613680005074
Valid Loss:   15%|█▍        | 73/500 [00:55<06:10,  1.15it/s] 15%|█▌        | 75/500 [00:55<04:29,  1.58it/s] 15%|█▌        | 77/500 [00:56<03:18,  2.13it/s] 16%|█▌        | 79/500 [00:56<02:28,  2.83it/s] 16%|█▌        | 81/500 [01:02<08:22,  1.20s/it] 17%|█▋        | 83/500 [01:02<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:02<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:03<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:09<08:04,  1.18s/it] 19%|█▊        | 93/500 [01:09<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:09<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:09<03:01,  2.23it/s] 20%|█▉        | 99/500 [01:09<02:13,  2.99it/s] 20%|██        | 101/500 [01:16<07:51,  1.18s/it] 21%|██        | 103/500 [01:16<05:39,  1.17it/s] 21%|██        | 105/500 [01:16<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:16<03:01,  2.16it/s] 22%|██▏       | 109/500 [01:16<02:16,  2.87it/s] 22%|██▏       | 111/500 [01:23<07:46,  1.20s/it] 23%|██▎       | 113/500 [01:23<05:35,  1.15it/s] 23%|██▎       | 115/500 [01:23<04:03,  1.58it/s] 23%|██▎       | 117/500 [01:23<02:59,  2.14it/s] 24%|██▍       | 119/500 [01:23<02:14,  2.84it/s] 24%|██▍       | 121/500 [01:30<07:41,  1.22s/it] 25%|██▍       | 123/500 [01:30<05:31,  1.14it/s] 25%|██▌       | 125/500 [01:30<04:00,  1.56it/s] 25%|██▌       | 127/500 [01:30<02:57,  2.11it/s] 26%|██▌       | 129/500 [01:31<02:12,  2.79it/s] 26%|██▌       | 131/500 [01:37<07:25,  1.21s/it] 27%|██▋       | 133/500 [01:37<05:18,  1.15it/s] 27%|██▋       | 135/500 [01:37<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:37<02:47,  2.16it/s] 28%|██▊       | 139/500 [01:38<02:05,  2.89it/s] 28%|██▊       | 141/500 [01:44<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:44<05:00,  1.19it/s]0.034130677580833435
Epoch:  73  	Training Loss: 0.03788101673126221
Test Loss:  0.02573806419968605
Valid Loss:  0.03413005545735359
Epoch:  74  	Training Loss: 0.037880390882492065
Test Loss:  0.025737512856721878
Valid Loss:  0.03412942215800285
Epoch:  75  	Training Loss: 0.03787976875901222
Test Loss:  0.025736961513757706
Valid Loss:  0.03412879630923271
Epoch:  76  	Training Loss: 0.03787914663553238
Test Loss:  0.025736406445503235
Valid Loss:  0.03412816673517227
Epoch:  77  	Training Loss: 0.03787852078676224
Test Loss:  0.02573585696518421
Valid Loss:  0.03412753716111183
Epoch:  78  	Training Loss: 0.03787790238857269
Test Loss:  0.02573530748486519
Valid Loss:  0.03412690758705139
Epoch:  79  	Training Loss: 0.03787727653980255
Test Loss:  0.025734754279255867
Valid Loss:  0.03412628173828125
Epoch:  80  	Training Loss: 0.03787665441632271
Test Loss:  0.025734204798936844
Valid Loss:  0.03412565216422081
Epoch:  81  	Training Loss: 0.037876028567552567
Test Loss:  0.025733649730682373
Valid Loss:  0.03412502259016037
Epoch:  82  	Training Loss: 0.03787540644407272
Test Loss:  0.02573310397565365
Valid Loss:  0.03412439674139023
Epoch:  83  	Training Loss: 0.03787479177117348
Test Loss:  0.025732556357979774
Valid Loss:  0.03412377089262009
Epoch:  84  	Training Loss: 0.03787417709827423
Test Loss:  0.02573201060295105
Valid Loss:  0.03412315249443054
Epoch:  85  	Training Loss: 0.037873558700084686
Test Loss:  0.025731461122632027
Valid Loss:  0.0341225303709507
Epoch:  86  	Training Loss: 0.03787294775247574
Test Loss:  0.0257309190928936
Valid Loss:  0.034121908247470856
Epoch:  87  	Training Loss: 0.037872329354286194
Test Loss:  0.025730371475219727
Valid Loss:  0.034121282398700714
Epoch:  88  	Training Loss: 0.03787171468138695
Test Loss:  0.025729821994900703
Valid Loss:  0.03412066400051117
Epoch:  89  	Training Loss: 0.0378711000084877
Test Loss:  0.025729278102517128
Valid Loss:  0.03412003815174103
Epoch:  90  	Training Loss: 0.03787048161029816
Test Loss:  0.025728728622198105
Valid Loss:  0.034119416028261185
Epoch:  91  	Training Loss: 0.03786987066268921
Test Loss:  0.02572818472981453
Valid Loss:  0.03411879763007164
Epoch:  92  	Training Loss: 0.037869252264499664
Test Loss:  0.02572762966156006
Valid Loss:  0.0341181643307209
Epoch:  93  	Training Loss: 0.03786863386631012
Test Loss:  0.025727080181241035
Valid Loss:  0.03411753475666046
Epoch:  94  	Training Loss: 0.037868015468120575
Test Loss:  0.025726526975631714
Valid Loss:  0.03411690518260002
Epoch:  95  	Training Loss: 0.03786738961935043
Test Loss:  0.025725973770022392
Valid Loss:  0.03411627933382988
Epoch:  96  	Training Loss: 0.03786677122116089
Test Loss:  0.02572542615234852
Valid Loss:  0.03411564975976944
Epoch:  97  	Training Loss: 0.037866152822971344
Test Loss:  0.025724872946739197
Valid Loss:  0.0341150239109993
Epoch:  98  	Training Loss: 0.0378655269742012
Test Loss:  0.025724317878484726
Valid Loss:  0.03411439433693886
Epoch:  99  	Training Loss: 0.03786490857601166
Test Loss:  0.025723766535520554
Valid Loss:  0.03411376476287842
Epoch:  100  	Training Loss: 0.03786429017782211
Test Loss:  0.025723211467266083
Valid Loss:  0.034113138914108276
Epoch:  101  	Training Loss: 0.03786366805434227
Test Loss:  0.02572266198694706
Valid Loss:  0.034112509340047836
Epoch:  102  	Training Loss: 0.03786304593086243
Test Loss:  0.025722110643982887
Valid Loss:  0.034111883491277695
Epoch:  103  	Training Loss: 0.03786243125796318
Test Loss:  0.025721564888954163
Valid Loss:  0.034111253917217255
Epoch:  104  	Training Loss: 0.037861816585063934
Test Loss:  0.02572101168334484
Valid Loss:  0.03411063551902771
Epoch:  105  	Training Loss: 0.03786119818687439
Test Loss:  0.02572046034038067
Valid Loss:  0.03411000594496727
Epoch:  106  	Training Loss: 0.037860579788684845
Test Loss:  0.025719912722706795
Valid Loss:  0.03410938382148743
Epoch:  107  	Training Loss: 0.0378599651157856
Test Loss:  0.02571936324238777
Valid Loss:  0.03410875424742699
Epoch:  108  	Training Loss: 0.03785935416817665
Test Loss:  0.0257188118994236
Valid Loss:  0.034108132123947144
Epoch:  109  	Training Loss: 0.037858735769987106
Test Loss:  0.025718260556459427
Valid Loss:  0.034107506275177
Epoch:  110  	Training Loss: 0.03785812109708786
Test Loss:  0.025717711076140404
Valid Loss:  0.03410688042640686
Epoch:  111  	Training Loss: 0.037857502698898315
Test Loss:  0.02571716159582138
Valid Loss:  0.03410625457763672
Epoch:  112  	Training Loss: 0.03785688802599907
Test Loss:  0.025716615840792656
Valid Loss:  0.034105636179447174
Epoch:  113  	Training Loss: 0.03785627335309982
Test Loss:  0.025716068223118782
Valid Loss:  0.03410501778125763
Epoch:  114  	Training Loss: 0.037855662405490875
Test Loss:  0.025715522468090057
Valid Loss:  0.03410439193248749
Epoch:  115  	Training Loss: 0.03785505145788193
Test Loss:  0.02571498043835163
Valid Loss:  0.03410377353429794
Epoch:  116  	Training Loss: 0.03785443305969238
Test Loss:  0.025714430958032608
Valid Loss:  0.0341031514108181
Epoch:  117  	Training Loss: 0.037853825837373734
Test Loss:  0.025713888928294182
Valid Loss:  0.03410252928733826
Epoch:  118  	Training Loss: 0.03785321116447449
Test Loss:  0.025713345035910606
Valid Loss:  0.034101907163858414
Epoch:  119  	Training Loss: 0.03785260021686554
Test Loss:  0.025712795555591583
Valid Loss:  0.03410129249095917
Epoch:  120  	Training Loss: 0.037851981818675995
Test Loss:  0.025712251663208008
Valid Loss:  0.034100666642189026
Epoch:  121  	Training Loss: 0.03785137087106705
Test Loss:  0.025711705908179283
Valid Loss:  0.03410005196928978
Epoch:  122  	Training Loss: 0.0378507599234581
Test Loss:  0.025711167603731155
Valid Loss:  0.034099433571100235
Epoch:  123  	Training Loss: 0.03785014897584915
Test Loss:  0.025710631161928177
Valid Loss:  0.03409881889820099
Epoch:  124  	Training Loss: 0.0378495417535305
Test Loss:  0.0257100909948349
Valid Loss:  0.03409820795059204
Epoch:  125  	Training Loss: 0.03784893453121185
Test Loss:  0.02570955455303192
Valid Loss:  0.034097589552402496
Epoch:  126  	Training Loss: 0.037848323583602905
Test Loss:  0.025709014385938644
Valid Loss:  0.03409697860479355
Epoch:  127  	Training Loss: 0.037847720086574554
Test Loss:  0.025708479806780815
Valid Loss:  0.0340963676571846
Epoch:  128  	Training Loss: 0.03784710913896561
Test Loss:  0.025707939639687538
Valid Loss:  0.034095749258995056
Epoch:  129  	Training Loss: 0.03784649819135666
Test Loss:  0.02570740319788456
Valid Loss:  0.03409513458609581
Epoch:  130  	Training Loss: 0.03784589469432831
Test Loss:  0.025706864893436432
Valid Loss:  0.034094519913196564
Epoch:  131  	Training Loss: 0.03784528374671936
Test Loss:  0.025706328451633453
Valid Loss:  0.03409390524029732
Epoch:  132  	Training Loss: 0.03784468024969101
Test Loss:  0.02570577710866928
Valid Loss:  0.034093283116817474
Epoch:  133  	Training Loss: 0.037844061851501465
Test Loss:  0.02570522576570511
Valid Loss:  0.03409265726804733
Epoch:  134  	Training Loss: 0.03784343972802162
Test Loss:  0.025704678148031235
Valid Loss:  0.03409203514456749
Epoch:  135  	Training Loss: 0.03784282132983208
Test Loss:  0.02570413425564766
Valid Loss:  0.03409140929579735
Epoch:  136  	Training Loss: 0.03784220665693283
Test Loss:  0.025703584775328636
Valid Loss:  0.034090787172317505
Epoch:  137  	Training Loss: 0.037841588258743286
Test Loss:  0.025703035295009613
Valid Loss:  0.03409016132354736
Epoch:  138  	Training Loss: 0.03784096986055374
Test Loss:  0.02570248767733574
Valid Loss:  0.03408953920006752
Epoch:  139  	Training Loss: 0.0378403514623642
Test Loss:  0.025701943784952164
Valid Loss:  0.03408891335129738
Epoch:  140  	Training Loss: 0.03783973306417465
Test Loss:  0.02570139244198799
Valid Loss:  0.034088291227817535
Epoch:  141  	Training Loss: 0.03783911466598511
Test Loss:  0.025700844824314117
Valid Loss:  0.034087665379047394
Epoch:  142  	Training Loss: 0.03783849999308586
Test Loss:  0.025700300931930542
Valid Loss:  0.03408704698085785
Epoch:  143  	Training Loss: 0.03783788904547691
Test Loss:  0.025699757039546967
Valid Loss:  0.034086428582668304
 29%|██▉       | 145/500 [01:44<03:35,  1.64it/s] 29%|██▉       | 147/500 [01:44<02:37,  2.25it/s] 30%|██▉       | 149/500 [01:44<01:56,  3.02it/s] 30%|███       | 151/500 [01:51<06:58,  1.20s/it] 31%|███       | 153/500 [01:51<04:59,  1.16it/s] 31%|███       | 155/500 [01:51<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:51<02:36,  2.20it/s] 32%|███▏      | 159/500 [01:51<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:58<06:44,  1.19s/it] 32%|███▏      | 162/500 [01:58<05:37,  1.00it/s] 33%|███▎      | 164/500 [01:58<03:52,  1.44it/s] 33%|███▎      | 166/500 [01:58<02:45,  2.02it/s] 34%|███▎      | 168/500 [01:58<02:01,  2.73it/s] 34%|███▍      | 170/500 [01:58<01:31,  3.61it/s] 34%|███▍      | 172/500 [02:05<06:23,  1.17s/it] 35%|███▍      | 174/500 [02:05<04:30,  1.20it/s] 35%|███▌      | 176/500 [02:05<03:13,  1.67it/s] 36%|███▌      | 178/500 [02:05<02:20,  2.29it/s] 36%|███▌      | 180/500 [02:05<01:46,  3.01it/s] 36%|███▋      | 182/500 [02:12<06:14,  1.18s/it] 37%|███▋      | 184/500 [02:12<04:26,  1.19it/s] 37%|███▋      | 186/500 [02:12<03:11,  1.64it/s] 38%|███▊      | 188/500 [02:12<02:19,  2.24it/s] 38%|███▊      | 190/500 [02:12<01:43,  2.99it/s] 38%|███▊      | 192/500 [02:18<06:02,  1.18s/it] 39%|███▉      | 194/500 [02:19<04:18,  1.19it/s] 39%|███▉      | 196/500 [02:19<03:05,  1.64it/s] 40%|███▉      | 198/500 [02:19<02:14,  2.24it/s] 40%|████      | 200/500 [02:19<01:39,  3.01it/s] 40%|████      | 202/500 [02:25<05:53,  1.19s/it] 41%|████      | 204/500 [02:26<04:13,  1.17it/s] 41%|████      | 206/500 [02:26<03:03,  1.60it/s] 42%|████▏     | 208/500 [02:26<02:15,  2.16it/s] 42%|████▏     | 210/500 [02:26<01:41,  2.86it/s] 42%|████▏     | 212/500 [02:32<05:41,  1.19s/it] 43%|████▎     | 214/500 [02:32<04:02,  1.18it/s]Epoch:  144  	Training Loss: 0.037837278097867966
Test Loss:  0.02569921314716339
Valid Loss:  0.03408581390976906
Epoch:  145  	Training Loss: 0.03783666342496872
Test Loss:  0.025698669254779816
Valid Loss:  0.034085191786289215
Epoch:  146  	Training Loss: 0.03783605247735977
Test Loss:  0.02569812722504139
Valid Loss:  0.03408456966280937
Epoch:  147  	Training Loss: 0.03783544525504112
Test Loss:  0.025697585195302963
Valid Loss:  0.03408394753932953
Epoch:  148  	Training Loss: 0.037834830582141876
Test Loss:  0.025697041302919388
Valid Loss:  0.03408333286643028
Epoch:  149  	Training Loss: 0.03783421963453293
Test Loss:  0.025696493685245514
Valid Loss:  0.034082718193531036
Epoch:  150  	Training Loss: 0.03783361241221428
Test Loss:  0.02569594979286194
Valid Loss:  0.034082092344760895
Epoch:  151  	Training Loss: 0.03783300518989563
Test Loss:  0.025695405900478363
Valid Loss:  0.03408147394657135
Epoch:  152  	Training Loss: 0.03783239424228668
Test Loss:  0.02569485828280449
Valid Loss:  0.034080855548381805
Epoch:  153  	Training Loss: 0.03783177584409714
Test Loss:  0.025694310665130615
Valid Loss:  0.034080229699611664
Epoch:  154  	Training Loss: 0.03783116489648819
Test Loss:  0.02569376491010189
Valid Loss:  0.03407960757613182
Epoch:  155  	Training Loss: 0.037830546498298645
Test Loss:  0.025693215429782867
Valid Loss:  0.03407898172736168
Epoch:  156  	Training Loss: 0.0378299355506897
Test Loss:  0.025692671537399292
Valid Loss:  0.03407836705446243
Epoch:  157  	Training Loss: 0.03782932087779045
Test Loss:  0.025692123919725418
Valid Loss:  0.03407774120569229
Epoch:  158  	Training Loss: 0.037828706204891205
Test Loss:  0.025691572576761246
Valid Loss:  0.03407711908221245
Epoch:  159  	Training Loss: 0.03782808780670166
Test Loss:  0.025691024959087372
Valid Loss:  0.034076493233442307
Epoch:  160  	Training Loss: 0.03782748058438301
Test Loss:  0.025690477341413498
Valid Loss:  0.03407587110996246
Epoch:  161  	Training Loss: 0.037826865911483765
Test Loss:  0.02568993531167507
Valid Loss:  0.03407524526119232
Epoch:  162  	Training Loss: 0.03782624751329422
Test Loss:  0.025689389556646347
Valid Loss:  0.03407462686300278
Epoch:  163  	Training Loss: 0.03782563656568527
Test Loss:  0.025688843801617622
Valid Loss:  0.034074004739522934
Epoch:  164  	Training Loss: 0.03782501816749573
Test Loss:  0.0256882905960083
Valid Loss:  0.03407338261604309
Epoch:  165  	Training Loss: 0.03782440721988678
Test Loss:  0.025687750428915024
Valid Loss:  0.034072764217853546
Epoch:  166  	Training Loss: 0.037823788821697235
Test Loss:  0.02568720281124115
Valid Loss:  0.0340721420943737
Epoch:  167  	Training Loss: 0.03782317787408829
Test Loss:  0.025686653330922127
Valid Loss:  0.03407151624560356
Epoch:  168  	Training Loss: 0.03782256320118904
Test Loss:  0.025686107575893402
Valid Loss:  0.03407089412212372
Epoch:  169  	Training Loss: 0.037821948528289795
Test Loss:  0.025685561820864677
Valid Loss:  0.034070271998643875
Epoch:  170  	Training Loss: 0.03782133758068085
Test Loss:  0.025685016065835953
Valid Loss:  0.03406965732574463
Epoch:  171  	Training Loss: 0.0378207229077816
Test Loss:  0.025684472173452377
Valid Loss:  0.03406903147697449
Epoch:  172  	Training Loss: 0.037820108234882355
Test Loss:  0.025683917105197906
Valid Loss:  0.03406840190291405
Epoch:  173  	Training Loss: 0.03781948983669281
Test Loss:  0.025683365762233734
Valid Loss:  0.03406777232885361
Epoch:  174  	Training Loss: 0.037818871438503265
Test Loss:  0.025682806968688965
Valid Loss:  0.034067146480083466
Epoch:  175  	Training Loss: 0.03781825304031372
Test Loss:  0.02568225935101509
Valid Loss:  0.034066516906023026
Epoch:  176  	Training Loss: 0.03781763091683388
Test Loss:  0.02568170428276062
Valid Loss:  0.034065887331962585
Epoch:  177  	Training Loss: 0.037817008793354034
Test Loss:  0.025681152939796448
Valid Loss:  0.034065261483192444
Epoch:  178  	Training Loss: 0.03781639039516449
Test Loss:  0.025680597871541977
Valid Loss:  0.034064628183841705
Epoch:  179  	Training Loss: 0.037815771996974945
Test Loss:  0.025680046528577805
Valid Loss:  0.034064002335071564
Epoch:  180  	Training Loss: 0.0378151498734951
Test Loss:  0.025679495185613632
Valid Loss:  0.03406337648630142
Epoch:  181  	Training Loss: 0.03781452775001526
Test Loss:  0.02567894384264946
Valid Loss:  0.034062743186950684
Epoch:  182  	Training Loss: 0.037813909351825714
Test Loss:  0.025678403675556183
Valid Loss:  0.03406212851405144
Epoch:  183  	Training Loss: 0.03781330585479736
Test Loss:  0.025677859783172607
Valid Loss:  0.03406151384115219
Epoch:  184  	Training Loss: 0.037812694907188416
Test Loss:  0.02567731961607933
Valid Loss:  0.034060895442962646
Epoch:  185  	Training Loss: 0.03781208395957947
Test Loss:  0.025676775723695755
Valid Loss:  0.034060288220644
Epoch:  186  	Training Loss: 0.03781148046255112
Test Loss:  0.025676235556602478
Valid Loss:  0.034059666097164154
Epoch:  187  	Training Loss: 0.03781086951494217
Test Loss:  0.025675691664218903
Valid Loss:  0.034059055149555206
Epoch:  188  	Training Loss: 0.03781026601791382
Test Loss:  0.025675151497125626
Valid Loss:  0.03405843675136566
Epoch:  189  	Training Loss: 0.03780965507030487
Test Loss:  0.0256746094673872
Valid Loss:  0.03405781835317612
Epoch:  190  	Training Loss: 0.03780905157327652
Test Loss:  0.025674067437648773
Valid Loss:  0.03405719995498657
Epoch:  191  	Training Loss: 0.03780844062566757
Test Loss:  0.025673527270555496
Valid Loss:  0.034056589007377625
Epoch:  192  	Training Loss: 0.03780783712863922
Test Loss:  0.02567298896610737
Valid Loss:  0.03405596688389778
Epoch:  193  	Training Loss: 0.037807222455739975
Test Loss:  0.025672446936368942
Valid Loss:  0.034055352210998535
Epoch:  194  	Training Loss: 0.037806615233421326
Test Loss:  0.025671904906630516
Valid Loss:  0.03405473381280899
Epoch:  195  	Training Loss: 0.03780600428581238
Test Loss:  0.02567136287689209
Valid Loss:  0.034054115414619446
Epoch:  196  	Training Loss: 0.03780539333820343
Test Loss:  0.025670820847153664
Valid Loss:  0.0340535007417202
Epoch:  197  	Training Loss: 0.03780478611588478
Test Loss:  0.025670276954770088
Valid Loss:  0.03405288606882095
Epoch:  198  	Training Loss: 0.03780417516827583
Test Loss:  0.02566973678767681
Valid Loss:  0.03405226022005081
Epoch:  199  	Training Loss: 0.037803564220666885
Test Loss:  0.025669194757938385
Valid Loss:  0.034051645547151566
Epoch:  200  	Training Loss: 0.037802956998348236
Test Loss:  0.02566865272819996
Valid Loss:  0.03405103087425232
Epoch:  201  	Training Loss: 0.03780234605073929
Test Loss:  0.025668110698461533
Valid Loss:  0.034050412476062775
Epoch:  202  	Training Loss: 0.03780173882842064
Test Loss:  0.025667564943432808
Valid Loss:  0.03404979407787323
Epoch:  203  	Training Loss: 0.03780113160610199
Test Loss:  0.02566702291369438
Valid Loss:  0.034049175679683685
Epoch:  204  	Training Loss: 0.037800516933202744
Test Loss:  0.025666475296020508
Valid Loss:  0.03404855728149414
Epoch:  205  	Training Loss: 0.037799905985593796
Test Loss:  0.025665927678346634
Valid Loss:  0.034047938883304596
Epoch:  206  	Training Loss: 0.037799298763275146
Test Loss:  0.025665385648608208
Valid Loss:  0.03404731675982475
Epoch:  207  	Training Loss: 0.0377986878156662
Test Loss:  0.02566484361886978
Valid Loss:  0.03404669836163521
Epoch:  208  	Training Loss: 0.03779807686805725
Test Loss:  0.025664296001195908
Valid Loss:  0.034046076238155365
Epoch:  209  	Training Loss: 0.0377974659204483
Test Loss:  0.025663752108812332
Valid Loss:  0.03404545411467552
Epoch:  210  	Training Loss: 0.037796854972839355
Test Loss:  0.025663204491138458
Valid Loss:  0.034044839441776276
Epoch:  211  	Training Loss: 0.03779624402523041
Test Loss:  0.025662660598754883
Valid Loss:  0.03404422104358673
Epoch:  212  	Training Loss: 0.03779563680291176
Test Loss:  0.025662127882242203
Valid Loss:  0.03404361009597778
Epoch:  213  	Training Loss: 0.03779502958059311
Test Loss:  0.025661587715148926
Valid Loss:  0.034042999148368835
Epoch:  214  	Training Loss: 0.03779442608356476
Test Loss:  0.025661049410700798
Valid Loss:  0.03404238447546959
 43%|████▎     | 216/500 [02:33<02:54,  1.63it/s] 44%|████▎     | 218/500 [02:33<02:06,  2.23it/s] 44%|████▍     | 220/500 [02:33<01:33,  3.00it/s] 44%|████▍     | 222/500 [02:39<05:28,  1.18s/it] 45%|████▍     | 224/500 [02:39<03:53,  1.18it/s] 45%|████▌     | 226/500 [02:39<02:47,  1.64it/s] 46%|████▌     | 228/500 [02:40<02:01,  2.23it/s] 46%|████▌     | 230/500 [02:40<01:30,  3.00it/s] 46%|████▋     | 232/500 [02:46<05:12,  1.17s/it] 47%|████▋     | 234/500 [02:46<03:42,  1.20it/s] 47%|████▋     | 236/500 [02:46<02:39,  1.66it/s] 48%|████▊     | 238/500 [02:46<01:55,  2.26it/s] 48%|████▊     | 240/500 [02:46<01:25,  3.04it/s] 48%|████▊     | 242/500 [02:53<04:58,  1.16s/it] 49%|████▉     | 244/500 [02:53<03:32,  1.20it/s] 49%|████▉     | 246/500 [02:53<02:32,  1.67it/s] 50%|████▉     | 248/500 [02:53<01:50,  2.28it/s] 50%|█████     | 250/500 [02:53<01:21,  3.06it/s] 50%|█████     | 252/500 [02:59<04:52,  1.18s/it] 51%|█████     | 254/500 [03:00<03:29,  1.17it/s] 51%|█████     | 256/500 [03:00<02:31,  1.61it/s] 52%|█████▏    | 258/500 [03:00<01:51,  2.17it/s] 52%|█████▏    | 260/500 [03:00<01:23,  2.88it/s] 52%|█████▏    | 262/500 [03:07<04:52,  1.23s/it] 53%|█████▎    | 264/500 [03:07<03:27,  1.14it/s] 53%|█████▎    | 266/500 [03:07<02:28,  1.58it/s] 54%|█████▎    | 268/500 [03:07<01:47,  2.16it/s] 54%|█████▍    | 270/500 [03:07<01:19,  2.91it/s] 54%|█████▍    | 272/500 [03:14<04:35,  1.21s/it] 55%|█████▍    | 274/500 [03:14<03:15,  1.16it/s] 55%|█████▌    | 276/500 [03:14<02:19,  1.60it/s] 56%|█████▌    | 278/500 [03:14<01:41,  2.19it/s] 56%|█████▌    | 280/500 [03:14<01:14,  2.95it/s] 56%|█████▋    | 282/500 [03:21<04:21,  1.20s/it] 57%|█████▋    | 284/500 [03:21<03:05,  1.16it/s]Epoch:  215  	Training Loss: 0.03779382258653641
Test Loss:  0.02566051110625267
Valid Loss:  0.03404177352786064
Epoch:  216  	Training Loss: 0.037793222814798355
Test Loss:  0.025659972801804543
Valid Loss:  0.034041158854961395
Epoch:  217  	Training Loss: 0.037792615592479706
Test Loss:  0.025659438222646713
Valid Loss:  0.034040555357933044
Epoch:  218  	Training Loss: 0.037792012095451355
Test Loss:  0.025658899918198586
Valid Loss:  0.0340399406850338
Epoch:  219  	Training Loss: 0.0377914123237133
Test Loss:  0.025658361613750458
Valid Loss:  0.03403932973742485
Epoch:  220  	Training Loss: 0.03779080510139465
Test Loss:  0.02565782144665718
Valid Loss:  0.0340387187898159
Epoch:  221  	Training Loss: 0.0377902053296566
Test Loss:  0.0256572887301445
Valid Loss:  0.03403811156749725
Epoch:  222  	Training Loss: 0.03778959810733795
Test Loss:  0.025656750425696373
Valid Loss:  0.03403749689459801
Epoch:  223  	Training Loss: 0.0377889983355999
Test Loss:  0.025656215846538544
Valid Loss:  0.03403688594698906
Epoch:  224  	Training Loss: 0.03778839483857155
Test Loss:  0.025655679404735565
Valid Loss:  0.03403627499938011
Epoch:  225  	Training Loss: 0.037787795066833496
Test Loss:  0.025655144825577736
Valid Loss:  0.03403566777706146
Epoch:  226  	Training Loss: 0.037787191569805145
Test Loss:  0.025654606521129608
Valid Loss:  0.034035056829452515
Epoch:  227  	Training Loss: 0.037786588072776794
Test Loss:  0.02565407194197178
Valid Loss:  0.03403444588184357
Epoch:  228  	Training Loss: 0.037785984575748444
Test Loss:  0.025653531774878502
Valid Loss:  0.03403383493423462
Epoch:  229  	Training Loss: 0.03778538107872009
Test Loss:  0.02565300092101097
Valid Loss:  0.03403322398662567
Epoch:  230  	Training Loss: 0.03778477758169174
Test Loss:  0.025652464479207993
Valid Loss:  0.034032613039016724
Epoch:  231  	Training Loss: 0.03778417780995369
Test Loss:  0.025651931762695312
Valid Loss:  0.034032002091407776
Epoch:  232  	Training Loss: 0.03778357803821564
Test Loss:  0.025651397183537483
Valid Loss:  0.03403139114379883
Epoch:  233  	Training Loss: 0.037782974541187286
Test Loss:  0.025650864467024803
Valid Loss:  0.034030795097351074
Epoch:  234  	Training Loss: 0.037782374769449234
Test Loss:  0.025650329887866974
Valid Loss:  0.03403018042445183
Epoch:  235  	Training Loss: 0.03778177499771118
Test Loss:  0.025649797171354294
Valid Loss:  0.03402957320213318
Epoch:  236  	Training Loss: 0.03778117150068283
Test Loss:  0.025649264454841614
Valid Loss:  0.03402896970510483
Epoch:  237  	Training Loss: 0.037780579179525375
Test Loss:  0.025648733600974083
Valid Loss:  0.03402836620807648
Epoch:  238  	Training Loss: 0.03777997940778732
Test Loss:  0.025648199021816254
Valid Loss:  0.03402775898575783
Epoch:  239  	Training Loss: 0.03777937963604927
Test Loss:  0.025647670030593872
Valid Loss:  0.03402715176343918
Epoch:  240  	Training Loss: 0.03777878358960152
Test Loss:  0.025647137314081192
Valid Loss:  0.03402654454112053
Epoch:  241  	Training Loss: 0.037778183817863464
Test Loss:  0.025646602734923363
Valid Loss:  0.03402593731880188
Epoch:  242  	Training Loss: 0.037777580320835114
Test Loss:  0.025646066293120384
Valid Loss:  0.034025322645902634
Epoch:  243  	Training Loss: 0.03777697682380676
Test Loss:  0.025645527988672256
Valid Loss:  0.034024711698293686
Epoch:  244  	Training Loss: 0.037776365876197815
Test Loss:  0.02564498782157898
Valid Loss:  0.03402409702539444
Epoch:  245  	Training Loss: 0.037775762379169464
Test Loss:  0.025644451379776
Valid Loss:  0.03402348607778549
Epoch:  246  	Training Loss: 0.037775155156850815
Test Loss:  0.025643913075327873
Valid Loss:  0.03402286767959595
Epoch:  247  	Training Loss: 0.037774551659822464
Test Loss:  0.025643374770879745
Valid Loss:  0.034022256731987
Epoch:  248  	Training Loss: 0.037773944437503815
Test Loss:  0.025642838329076767
Valid Loss:  0.03402164578437805
Epoch:  249  	Training Loss: 0.03777333348989487
Test Loss:  0.02564229816198349
Valid Loss:  0.034021034836769104
Epoch:  250  	Training Loss: 0.037772729992866516
Test Loss:  0.02564176544547081
Valid Loss:  0.034020423889160156
Epoch:  251  	Training Loss: 0.037772126495838165
Test Loss:  0.025641223415732384
Valid Loss:  0.03401980549097061
Epoch:  252  	Training Loss: 0.037771519273519516
Test Loss:  0.025640681385993958
Valid Loss:  0.03401918709278107
Epoch:  253  	Training Loss: 0.03777090460062027
Test Loss:  0.025640133768320084
Valid Loss:  0.03401856869459152
Epoch:  254  	Training Loss: 0.03777029365301132
Test Loss:  0.025639591738581657
Valid Loss:  0.03401795029640198
Epoch:  255  	Training Loss: 0.037769682705402374
Test Loss:  0.025639045983552933
Valid Loss:  0.034017328172922134
Epoch:  256  	Training Loss: 0.037769071757793427
Test Loss:  0.025638505816459656
Valid Loss:  0.03401670604944229
Epoch:  257  	Training Loss: 0.03776846081018448
Test Loss:  0.02563796006143093
Valid Loss:  0.034016091376543045
Epoch:  258  	Training Loss: 0.03776784986257553
Test Loss:  0.025637414306402206
Valid Loss:  0.0340154692530632
Epoch:  259  	Training Loss: 0.037767235189676285
Test Loss:  0.02563687041401863
Valid Loss:  0.03401485085487366
Epoch:  260  	Training Loss: 0.03776662051677704
Test Loss:  0.025636330246925354
Valid Loss:  0.034014225006103516
Epoch:  261  	Training Loss: 0.03776601329445839
Test Loss:  0.02563578262925148
Valid Loss:  0.03401361405849457
Epoch:  262  	Training Loss: 0.03776539862155914
Test Loss:  0.02563524805009365
Valid Loss:  0.03401299938559532
Epoch:  263  	Training Loss: 0.03776479884982109
Test Loss:  0.025634709745645523
Valid Loss:  0.034012384712696075
Epoch:  264  	Training Loss: 0.03776419162750244
Test Loss:  0.025634175166487694
Valid Loss:  0.034011777490377426
Epoch:  265  	Training Loss: 0.03776358813047409
Test Loss:  0.025633638724684715
Valid Loss:  0.03401117026805878
Epoch:  266  	Training Loss: 0.03776298463344574
Test Loss:  0.025633102282881737
Valid Loss:  0.03401055559515953
Epoch:  267  	Training Loss: 0.03776238113641739
Test Loss:  0.02563256397843361
Valid Loss:  0.03400994837284088
Epoch:  268  	Training Loss: 0.03776178136467934
Test Loss:  0.02563202753663063
Valid Loss:  0.034009337425231934
Epoch:  269  	Training Loss: 0.037761181592941284
Test Loss:  0.025631491094827652
Valid Loss:  0.034008726477622986
Epoch:  270  	Training Loss: 0.03776057809591293
Test Loss:  0.025630954653024673
Valid Loss:  0.03400811553001404
Epoch:  271  	Training Loss: 0.03775997459888458
Test Loss:  0.025630414485931396
Valid Loss:  0.03400750458240509
Epoch:  272  	Training Loss: 0.037759363651275635
Test Loss:  0.02562987059354782
Valid Loss:  0.03400688245892525
Epoch:  273  	Training Loss: 0.03775874525308609
Test Loss:  0.025629322975873947
Valid Loss:  0.034006256610155106
Epoch:  274  	Training Loss: 0.037758126854896545
Test Loss:  0.025628775358200073
Valid Loss:  0.034005627036094666
Epoch:  275  	Training Loss: 0.037757508456707
Test Loss:  0.0256282240152359
Valid Loss:  0.034005001187324524
Epoch:  276  	Training Loss: 0.03775688260793686
Test Loss:  0.02562767267227173
Valid Loss:  0.034004367887973785
Epoch:  277  	Training Loss: 0.037756264209747314
Test Loss:  0.025627123191952705
Valid Loss:  0.034003742039203644
Epoch:  278  	Training Loss: 0.03775564581155777
Test Loss:  0.02562657557427883
Valid Loss:  0.0340031161904335
Epoch:  279  	Training Loss: 0.03775501996278763
Test Loss:  0.02562602609395981
Valid Loss:  0.03400249034166336
Epoch:  280  	Training Loss: 0.037754401564598083
Test Loss:  0.025625476613640785
Valid Loss:  0.03400186449289322
Epoch:  281  	Training Loss: 0.03775377571582794
Test Loss:  0.025624927133321762
Valid Loss:  0.03400123864412308
Epoch:  282  	Training Loss: 0.0377531573176384
Test Loss:  0.025624388828873634
Valid Loss:  0.03400062397122383
Epoch:  283  	Training Loss: 0.03775254637002945
Test Loss:  0.02562384307384491
Valid Loss:  0.03400000184774399
Epoch:  284  	Training Loss: 0.0377519354224205
Test Loss:  0.025623295456171036
Valid Loss:  0.03399938717484474
Epoch:  285  	Training Loss: 0.03775132820010185
Test Loss:  0.02562275528907776
Valid Loss:  0.0339987650513649
 57%|█████▋    | 286/500 [03:21<02:12,  1.61it/s] 58%|█████▊    | 288/500 [03:21<01:36,  2.20it/s] 58%|█████▊    | 290/500 [03:21<01:10,  2.97it/s] 58%|█████▊    | 292/500 [03:27<04:04,  1.18s/it] 59%|█████▉    | 294/500 [03:28<02:54,  1.18it/s] 59%|█████▉    | 296/500 [03:28<02:06,  1.62it/s] 60%|█████▉    | 298/500 [03:28<01:32,  2.18it/s] 60%|██████    | 300/500 [03:28<01:09,  2.88it/s] 60%|██████    | 302/500 [03:34<03:58,  1.20s/it] 61%|██████    | 304/500 [03:35<02:49,  1.15it/s] 61%|██████    | 306/500 [03:35<02:02,  1.58it/s] 62%|██████▏   | 308/500 [03:35<01:30,  2.13it/s] 62%|██████▏   | 310/500 [03:35<01:07,  2.82it/s] 62%|██████▏   | 312/500 [03:42<03:48,  1.22s/it] 63%|██████▎   | 314/500 [03:42<02:42,  1.15it/s] 63%|██████▎   | 316/500 [03:42<01:56,  1.59it/s] 64%|██████▎   | 318/500 [03:42<01:24,  2.17it/s] 64%|██████▍   | 320/500 [03:42<01:02,  2.90it/s] 64%|██████▍   | 322/500 [03:48<03:30,  1.18s/it] 65%|██████▍   | 324/500 [03:49<02:29,  1.18it/s] 65%|██████▌   | 326/500 [03:49<01:46,  1.63it/s] 66%|██████▌   | 328/500 [03:49<01:17,  2.23it/s] 66%|██████▌   | 330/500 [03:49<00:56,  3.00it/s] 66%|██████▋   | 332/500 [03:55<03:18,  1.18s/it] 67%|██████▋   | 334/500 [03:55<02:20,  1.18it/s] 67%|██████▋   | 336/500 [03:56<01:40,  1.64it/s] 68%|██████▊   | 338/500 [03:56<01:12,  2.24it/s] 68%|██████▊   | 340/500 [03:56<00:53,  3.00it/s] 68%|██████▊   | 342/500 [04:02<03:11,  1.21s/it] 69%|██████▉   | 344/500 [04:02<02:15,  1.15it/s] 69%|██████▉   | 346/500 [04:03<01:37,  1.57it/s] 70%|██████▉   | 348/500 [04:03<01:11,  2.14it/s] 70%|███████   | 350/500 [04:03<00:53,  2.83it/s] 70%|███████   | 352/500 [04:09<02:58,  1.20s/it] 71%|███████   | 354/500 [04:09<02:05,  1.16it/s] 71%|███████   | 356/500 [04:10<01:29,  1.61it/s]Epoch:  286  	Training Loss: 0.037750717252492905
Test Loss:  0.025622207671403885
Valid Loss:  0.033998146653175354
Epoch:  287  	Training Loss: 0.037750110030174255
Test Loss:  0.02562166377902031
Valid Loss:  0.03399752825498581
Epoch:  288  	Training Loss: 0.03774949908256531
Test Loss:  0.025621123611927032
Valid Loss:  0.033996906131505966
Epoch:  289  	Training Loss: 0.03774889186024666
Test Loss:  0.025620579719543457
Valid Loss:  0.03399629518389702
Epoch:  290  	Training Loss: 0.03774827718734741
Test Loss:  0.02562003582715988
Valid Loss:  0.033995676785707474
Epoch:  291  	Training Loss: 0.03774766996502876
Test Loss:  0.025619491934776306
Valid Loss:  0.03399506211280823
Epoch:  292  	Training Loss: 0.037747062742710114
Test Loss:  0.025618957355618477
Valid Loss:  0.03399444743990898
Epoch:  293  	Training Loss: 0.037746451795101166
Test Loss:  0.02561841905117035
Valid Loss:  0.033993832767009735
Epoch:  294  	Training Loss: 0.037745848298072815
Test Loss:  0.02561788074672222
Valid Loss:  0.03399321809411049
Epoch:  295  	Training Loss: 0.037745244801044464
Test Loss:  0.025617338716983795
Valid Loss:  0.03399260342121124
Epoch:  296  	Training Loss: 0.037744637578725815
Test Loss:  0.025616804137825966
Valid Loss:  0.03399199619889259
Epoch:  297  	Training Loss: 0.037744034081697464
Test Loss:  0.02561626397073269
Valid Loss:  0.03399138152599335
Epoch:  298  	Training Loss: 0.037743426859378815
Test Loss:  0.02561572939157486
Valid Loss:  0.0339907743036747
Epoch:  299  	Training Loss: 0.03774281591176987
Test Loss:  0.025615189224481583
Valid Loss:  0.03399015963077545
Epoch:  300  	Training Loss: 0.037742212414741516
Test Loss:  0.025614652782678604
Valid Loss:  0.033989544957876205
Epoch:  301  	Training Loss: 0.037741612643003464
Test Loss:  0.025614116340875626
Valid Loss:  0.033988937735557556
Epoch:  302  	Training Loss: 0.037741005420684814
Test Loss:  0.025613579899072647
Valid Loss:  0.03398832306265831
Epoch:  303  	Training Loss: 0.037740401923656464
Test Loss:  0.025613045319914818
Valid Loss:  0.033987708389759064
Epoch:  304  	Training Loss: 0.037739790976047516
Test Loss:  0.02561250701546669
Valid Loss:  0.033987097442150116
Epoch:  305  	Training Loss: 0.03773919492959976
Test Loss:  0.02561197057366371
Valid Loss:  0.03398648649454117
Epoch:  306  	Training Loss: 0.03773858770728111
Test Loss:  0.02561143785715103
Valid Loss:  0.03398587554693222
Epoch:  307  	Training Loss: 0.03773798048496246
Test Loss:  0.025610899552702904
Valid Loss:  0.03398526459932327
Epoch:  308  	Training Loss: 0.03773737698793411
Test Loss:  0.025610359385609627
Valid Loss:  0.03398465737700462
Epoch:  309  	Training Loss: 0.03773677721619606
Test Loss:  0.0256098210811615
Valid Loss:  0.03398404270410538
Epoch:  310  	Training Loss: 0.03773616999387741
Test Loss:  0.02560928650200367
Valid Loss:  0.03398343175649643
Epoch:  311  	Training Loss: 0.03773556649684906
Test Loss:  0.025608748197555542
Valid Loss:  0.03398282080888748
Epoch:  312  	Training Loss: 0.03773495927453041
Test Loss:  0.02560821920633316
Valid Loss:  0.03398222476243973
Epoch:  313  	Training Loss: 0.037734370678663254
Test Loss:  0.025607695803046227
Valid Loss:  0.03398162126541138
Epoch:  314  	Training Loss: 0.037733785808086395
Test Loss:  0.025607164949178696
Valid Loss:  0.03398102521896362
Epoch:  315  	Training Loss: 0.03773320093750954
Test Loss:  0.025606639683246613
Valid Loss:  0.03398042917251587
Epoch:  316  	Training Loss: 0.03773260861635208
Test Loss:  0.02560611255466938
Valid Loss:  0.03397982567548752
Epoch:  317  	Training Loss: 0.03773202747106552
Test Loss:  0.025605583563447
Valid Loss:  0.033979229629039764
Epoch:  318  	Training Loss: 0.037731438875198364
Test Loss:  0.025605060160160065
Valid Loss:  0.03397863358259201
Epoch:  319  	Training Loss: 0.03773085027933121
Test Loss:  0.02560453489422798
Valid Loss:  0.03397803008556366
Epoch:  320  	Training Loss: 0.03773026540875435
Test Loss:  0.0256040021777153
Valid Loss:  0.033977434039115906
Epoch:  321  	Training Loss: 0.03772968053817749
Test Loss:  0.02560347691178322
Valid Loss:  0.03397683799266815
Epoch:  322  	Training Loss: 0.03772909194231033
Test Loss:  0.02560294046998024
Valid Loss:  0.033976227045059204
Epoch:  323  	Training Loss: 0.03772849217057228
Test Loss:  0.02560240589082241
Valid Loss:  0.033975616097450256
Epoch:  324  	Training Loss: 0.03772789239883423
Test Loss:  0.025601867586374283
Valid Loss:  0.03397500514984131
Epoch:  325  	Training Loss: 0.03772728890180588
Test Loss:  0.025601331144571304
Valid Loss:  0.03397439420223236
Epoch:  326  	Training Loss: 0.037726689130067825
Test Loss:  0.025600794702768326
Valid Loss:  0.03397379070520401
Epoch:  327  	Training Loss: 0.03772608935832977
Test Loss:  0.025600258260965347
Valid Loss:  0.03397317975759506
Epoch:  328  	Training Loss: 0.03772548586130142
Test Loss:  0.02559971995651722
Valid Loss:  0.033972568809986115
Epoch:  329  	Training Loss: 0.03772488981485367
Test Loss:  0.02559918910264969
Valid Loss:  0.03397195786237717
Epoch:  330  	Training Loss: 0.03772428631782532
Test Loss:  0.02559865266084671
Valid Loss:  0.03397134318947792
Epoch:  331  	Training Loss: 0.037723690271377563
Test Loss:  0.025598112493753433
Valid Loss:  0.03397073969244957
Epoch:  332  	Training Loss: 0.037723083049058914
Test Loss:  0.02559758350253105
Valid Loss:  0.03397013992071152
Epoch:  333  	Training Loss: 0.03772249072790146
Test Loss:  0.02559705451130867
Valid Loss:  0.033969536423683167
Epoch:  334  	Training Loss: 0.037721894681453705
Test Loss:  0.02559652552008629
Valid Loss:  0.03396892920136452
Epoch:  335  	Training Loss: 0.03772129863500595
Test Loss:  0.025595996528863907
Valid Loss:  0.033968329429626465
Epoch:  336  	Training Loss: 0.0377207025885582
Test Loss:  0.025595467537641525
Valid Loss:  0.033967725932598114
Epoch:  337  	Training Loss: 0.03772010654211044
Test Loss:  0.025594938546419144
Valid Loss:  0.033967114984989166
Epoch:  338  	Training Loss: 0.03771951049566269
Test Loss:  0.025594409555196762
Valid Loss:  0.033966515213251114
Epoch:  339  	Training Loss: 0.037718914449214935
Test Loss:  0.02559388056397438
Valid Loss:  0.03396591171622276
Epoch:  340  	Training Loss: 0.03771831840276718
Test Loss:  0.0255933478474617
Valid Loss:  0.03396531194448471
Epoch:  341  	Training Loss: 0.03771772235631943
Test Loss:  0.02559281885623932
Valid Loss:  0.03396471217274666
Epoch:  342  	Training Loss: 0.037717126309871674
Test Loss:  0.02559228427708149
Valid Loss:  0.03396409749984741
Epoch:  343  	Training Loss: 0.03771652281284332
Test Loss:  0.025591742247343063
Valid Loss:  0.03396347910165787
Epoch:  344  	Training Loss: 0.03771591931581497
Test Loss:  0.025591200217604637
Valid Loss:  0.03396286815404892
Epoch:  345  	Training Loss: 0.03771531209349632
Test Loss:  0.02559066191315651
Valid Loss:  0.03396225720643997
Epoch:  346  	Training Loss: 0.03771470487117767
Test Loss:  0.025590121746063232
Valid Loss:  0.03396163880825043
Epoch:  347  	Training Loss: 0.03771410137414932
Test Loss:  0.025589577853679657
Valid Loss:  0.03396102041006088
Epoch:  348  	Training Loss: 0.037713490426540375
Test Loss:  0.02558904141187668
Valid Loss:  0.033960409462451935
Epoch:  349  	Training Loss: 0.037712886929512024
Test Loss:  0.0255885012447834
Valid Loss:  0.03395979851484299
Epoch:  350  	Training Loss: 0.03771228343248367
Test Loss:  0.025587961077690125
Valid Loss:  0.03395918011665344
Epoch:  351  	Training Loss: 0.037711676210165024
Test Loss:  0.025587424635887146
Valid Loss:  0.033958565443754196
Epoch:  352  	Training Loss: 0.03771107271313667
Test Loss:  0.02558688446879387
Valid Loss:  0.03395795822143555
Epoch:  353  	Training Loss: 0.03771046921610832
Test Loss:  0.02558634988963604
Valid Loss:  0.0339573509991169
Epoch:  354  	Training Loss: 0.03770987316966057
Test Loss:  0.02558581531047821
Valid Loss:  0.03395673632621765
Epoch:  355  	Training Loss: 0.037709273397922516
Test Loss:  0.025585278868675232
Valid Loss:  0.0339561328291893
Epoch:  356  	Training Loss: 0.037708669900894165
Test Loss:  0.025584746152162552
Valid Loss:  0.03395552188158035
 72%|███████▏  | 358/500 [04:10<01:04,  2.19it/s] 72%|███████▏  | 360/500 [04:10<00:47,  2.95it/s] 72%|███████▏  | 362/500 [04:16<02:43,  1.19s/it] 73%|███████▎  | 364/500 [04:16<01:55,  1.18it/s] 73%|███████▎  | 366/500 [04:16<01:22,  1.63it/s] 74%|███████▎  | 368/500 [04:17<00:59,  2.23it/s] 74%|███████▍  | 370/500 [04:17<00:43,  2.99it/s] 74%|███████▍  | 372/500 [04:23<02:31,  1.19s/it] 75%|███████▍  | 374/500 [04:23<01:47,  1.18it/s] 75%|███████▌  | 376/500 [04:23<01:16,  1.62it/s] 76%|███████▌  | 378/500 [04:23<00:54,  2.22it/s] 76%|███████▌  | 380/500 [04:24<00:40,  2.98it/s] 76%|███████▋  | 382/500 [04:30<02:23,  1.22s/it] 77%|███████▋  | 384/500 [04:30<01:41,  1.14it/s] 77%|███████▋  | 386/500 [04:30<01:13,  1.56it/s] 78%|███████▊  | 388/500 [04:31<00:53,  2.11it/s] 78%|███████▊  | 390/500 [04:31<00:38,  2.83it/s] 78%|███████▊  | 392/500 [04:37<02:10,  1.21s/it] 79%|███████▉  | 394/500 [04:37<01:31,  1.16it/s] 79%|███████▉  | 396/500 [04:37<01:04,  1.60it/s] 80%|███████▉  | 398/500 [04:38<00:46,  2.20it/s] 80%|████████  | 400/500 [04:38<00:33,  2.96it/s] 80%|████████  | 402/500 [04:44<01:56,  1.19s/it] 81%|████████  | 404/500 [04:44<01:21,  1.18it/s] 81%|████████  | 406/500 [04:44<00:57,  1.62it/s] 82%|████████▏ | 408/500 [04:44<00:41,  2.22it/s] 82%|████████▏ | 410/500 [04:45<00:30,  2.99it/s] 82%|████████▏ | 412/500 [04:51<01:45,  1.20s/it] 83%|████████▎ | 414/500 [04:51<01:14,  1.16it/s] 83%|████████▎ | 416/500 [04:51<00:52,  1.60it/s] 84%|████████▎ | 418/500 [04:51<00:37,  2.18it/s] 84%|████████▍ | 420/500 [04:52<00:27,  2.94it/s] 84%|████████▍ | 422/500 [04:58<01:32,  1.19s/it] 85%|████████▍ | 424/500 [04:58<01:04,  1.18it/s] 85%|████████▌ | 426/500 [04:58<00:45,  1.63it/s]Epoch:  357  	Training Loss: 0.03770807385444641
Test Loss:  0.025584207847714424
Valid Loss:  0.033954914659261703
Epoch:  358  	Training Loss: 0.03770747408270836
Test Loss:  0.025583673268556595
Valid Loss:  0.033954303711652756
Epoch:  359  	Training Loss: 0.03770687058568001
Test Loss:  0.025583136826753616
Valid Loss:  0.033953696489334106
Epoch:  360  	Training Loss: 0.037706270813941956
Test Loss:  0.025582602247595787
Valid Loss:  0.03395308181643486
Epoch:  361  	Training Loss: 0.0377056710422039
Test Loss:  0.02558206394314766
Valid Loss:  0.03395247459411621
Epoch:  362  	Training Loss: 0.03770507127046585
Test Loss:  0.02558152936398983
Valid Loss:  0.03395187109708786
Epoch:  363  	Training Loss: 0.0377044677734375
Test Loss:  0.025580994784832
Valid Loss:  0.03395126014947891
Epoch:  364  	Training Loss: 0.037703871726989746
Test Loss:  0.02558046206831932
Valid Loss:  0.033950649201869965
Epoch:  365  	Training Loss: 0.037703268229961395
Test Loss:  0.02557992935180664
Valid Loss:  0.033950045704841614
Epoch:  366  	Training Loss: 0.03770267218351364
Test Loss:  0.02557939477264881
Valid Loss:  0.033949434757232666
Epoch:  367  	Training Loss: 0.03770206868648529
Test Loss:  0.025578860193490982
Valid Loss:  0.03394882753491402
Epoch:  368  	Training Loss: 0.03770147264003754
Test Loss:  0.025578327476978302
Valid Loss:  0.033948224037885666
Epoch:  369  	Training Loss: 0.037700869143009186
Test Loss:  0.025577794760465622
Valid Loss:  0.03394761681556702
Epoch:  370  	Training Loss: 0.03770026937127113
Test Loss:  0.025577260181307793
Valid Loss:  0.03394700586795807
Epoch:  371  	Training Loss: 0.03769966959953308
Test Loss:  0.025576725602149963
Valid Loss:  0.03394639864563942
Epoch:  372  	Training Loss: 0.03769907355308533
Test Loss:  0.025576192885637283
Valid Loss:  0.03394579514861107
Epoch:  373  	Training Loss: 0.03769847750663757
Test Loss:  0.0255756676197052
Valid Loss:  0.033945195376873016
Epoch:  374  	Training Loss: 0.03769788146018982
Test Loss:  0.02557513490319252
Valid Loss:  0.033944595605134964
Epoch:  375  	Training Loss: 0.037697289139032364
Test Loss:  0.025574607774615288
Valid Loss:  0.033943988382816315
Epoch:  376  	Training Loss: 0.03769669681787491
Test Loss:  0.025574078783392906
Valid Loss:  0.033943384885787964
Epoch:  377  	Training Loss: 0.037696100771427155
Test Loss:  0.025573547929525375
Valid Loss:  0.03394278883934021
Epoch:  378  	Training Loss: 0.0376955047249794
Test Loss:  0.025573022663593292
Valid Loss:  0.03394217789173126
Epoch:  379  	Training Loss: 0.03769490867853165
Test Loss:  0.025572486221790314
Valid Loss:  0.03394157439470291
Epoch:  380  	Training Loss: 0.03769431263208389
Test Loss:  0.025571957230567932
Valid Loss:  0.03394097462296486
Epoch:  381  	Training Loss: 0.03769372031092644
Test Loss:  0.02557143196463585
Valid Loss:  0.03394037112593651
Epoch:  382  	Training Loss: 0.037693124264478683
Test Loss:  0.025570902973413467
Valid Loss:  0.033939771354198456
Epoch:  383  	Training Loss: 0.03769253194332123
Test Loss:  0.025570375844836235
Valid Loss:  0.0339391753077507
Epoch:  384  	Training Loss: 0.03769194707274437
Test Loss:  0.025569848716259003
Valid Loss:  0.03393857553601265
Epoch:  385  	Training Loss: 0.037691354751586914
Test Loss:  0.025569327175617218
Valid Loss:  0.0339379757642746
Epoch:  386  	Training Loss: 0.037690769881010056
Test Loss:  0.025568803772330284
Valid Loss:  0.03393737971782684
Epoch:  387  	Training Loss: 0.0376901775598526
Test Loss:  0.0255682785063982
Valid Loss:  0.03393678367137909
Epoch:  388  	Training Loss: 0.03768959641456604
Test Loss:  0.02556775137782097
Valid Loss:  0.033936187624931335
Epoch:  389  	Training Loss: 0.037689000368118286
Test Loss:  0.025567222386598587
Valid Loss:  0.03393558785319328
Epoch:  390  	Training Loss: 0.03768841177225113
Test Loss:  0.025566698983311653
Valid Loss:  0.03393499180674553
Epoch:  391  	Training Loss: 0.03768782690167427
Test Loss:  0.025566179305315018
Valid Loss:  0.03393439203500748
Epoch:  392  	Training Loss: 0.037687238305807114
Test Loss:  0.025565654039382935
Valid Loss:  0.03393379971385002
Epoch:  393  	Training Loss: 0.03768664598464966
Test Loss:  0.02556513622403145
Valid Loss:  0.03393320366740227
Epoch:  394  	Training Loss: 0.0376860648393631
Test Loss:  0.025564610958099365
Valid Loss:  0.03393261134624481
Epoch:  395  	Training Loss: 0.03768547624349594
Test Loss:  0.02556409314274788
Valid Loss:  0.03393201529979706
Epoch:  396  	Training Loss: 0.03768489137291908
Test Loss:  0.025563573464751244
Valid Loss:  0.0339314267039299
Epoch:  397  	Training Loss: 0.037684306502342224
Test Loss:  0.025563053786754608
Valid Loss:  0.03393083065748215
Epoch:  398  	Training Loss: 0.03768371790647507
Test Loss:  0.025562528520822525
Valid Loss:  0.03393023833632469
Epoch:  399  	Training Loss: 0.03768312931060791
Test Loss:  0.02556200698018074
Valid Loss:  0.033929646015167236
Epoch:  400  	Training Loss: 0.03768254816532135
Test Loss:  0.025561489164829254
Valid Loss:  0.03392904996871948
Epoch:  401  	Training Loss: 0.03768195956945419
Test Loss:  0.02556096762418747
Valid Loss:  0.033928461372852325
Epoch:  402  	Training Loss: 0.037681374698877335
Test Loss:  0.02556043490767479
Valid Loss:  0.03392785042524338
Epoch:  403  	Training Loss: 0.03768077492713928
Test Loss:  0.02555990405380726
Valid Loss:  0.033927250653505325
Epoch:  404  	Training Loss: 0.03768017888069153
Test Loss:  0.025559375062584877
Valid Loss:  0.033926643431186676
Epoch:  405  	Training Loss: 0.037679579108953476
Test Loss:  0.025558846071362495
Valid Loss:  0.033926043659448624
Epoch:  406  	Training Loss: 0.037678979337215424
Test Loss:  0.025558313354849815
Valid Loss:  0.033925432711839676
Epoch:  407  	Training Loss: 0.03767837584018707
Test Loss:  0.025557786226272583
Valid Loss:  0.033924829214811325
Epoch:  408  	Training Loss: 0.03767777979373932
Test Loss:  0.025557251647114754
Valid Loss:  0.033924221992492676
Epoch:  409  	Training Loss: 0.037677180022001266
Test Loss:  0.025556722655892372
Valid Loss:  0.033923618495464325
Epoch:  410  	Training Loss: 0.037676580250263214
Test Loss:  0.025556188076734543
Valid Loss:  0.033923014998435974
Epoch:  411  	Training Loss: 0.03767598420381546
Test Loss:  0.02555566094815731
Valid Loss:  0.033922407776117325
Epoch:  412  	Training Loss: 0.03767538070678711
Test Loss:  0.025555133819580078
Valid Loss:  0.03392181172966957
Epoch:  413  	Training Loss: 0.03767479211091995
Test Loss:  0.025554612278938293
Valid Loss:  0.03392121195793152
Epoch:  414  	Training Loss: 0.037674203515052795
Test Loss:  0.02555408701300621
Valid Loss:  0.033920615911483765
Epoch:  415  	Training Loss: 0.03767361491918564
Test Loss:  0.025553561747074127
Valid Loss:  0.03392001986503601
Epoch:  416  	Training Loss: 0.03767302632331848
Test Loss:  0.025553036481142044
Valid Loss:  0.03391942381858826
Epoch:  417  	Training Loss: 0.037672434002161026
Test Loss:  0.02555251494050026
Valid Loss:  0.033918820321559906
Epoch:  418  	Training Loss: 0.03767184540629387
Test Loss:  0.025551987811923027
Valid Loss:  0.03391822427511215
Epoch:  419  	Training Loss: 0.037671253085136414
Test Loss:  0.025551464408636093
Valid Loss:  0.0339176245033741
Epoch:  420  	Training Loss: 0.03767066448926926
Test Loss:  0.02555093541741371
Valid Loss:  0.033917032182216644
Epoch:  421  	Training Loss: 0.0376700684428215
Test Loss:  0.025550419464707375
Valid Loss:  0.03391643613576889
Epoch:  422  	Training Loss: 0.037669483572244644
Test Loss:  0.025549884885549545
Valid Loss:  0.03391582891345024
Epoch:  423  	Training Loss: 0.03766888752579689
Test Loss:  0.025549348443746567
Valid Loss:  0.03391522169113159
Epoch:  424  	Training Loss: 0.037668295204639435
Test Loss:  0.025548819452524185
Valid Loss:  0.03391461819410324
Epoch:  425  	Training Loss: 0.03766769543290138
Test Loss:  0.025548286736011505
Valid Loss:  0.03391401097178459
Epoch:  426  	Training Loss: 0.03766709938645363
Test Loss:  0.025547754019498825
Valid Loss:  0.03391340374946594
Epoch:  427  	Training Loss: 0.037666499614715576
Test Loss:  0.025547225028276443
Valid Loss:  0.03391280025243759
 86%|████████▌ | 428/500 [04:58<00:32,  2.23it/s] 86%|████████▌ | 430/500 [04:58<00:23,  3.00it/s] 86%|████████▋ | 432/500 [05:05<01:22,  1.21s/it] 87%|████████▋ | 434/500 [05:05<00:57,  1.15it/s] 87%|████████▋ | 436/500 [05:05<00:40,  1.60it/s] 88%|████████▊ | 438/500 [05:05<00:28,  2.19it/s] 88%|████████▊ | 440/500 [05:05<00:20,  2.94it/s] 88%|████████▊ | 442/500 [05:12<01:08,  1.17s/it] 89%|████████▉ | 444/500 [05:12<00:47,  1.19it/s] 89%|████████▉ | 446/500 [05:12<00:32,  1.64it/s] 90%|████████▉ | 448/500 [05:12<00:23,  2.25it/s] 90%|█████████ | 450/500 [05:12<00:16,  3.02it/s] 90%|█████████ | 452/500 [05:19<00:56,  1.18s/it] 91%|█████████ | 454/500 [05:19<00:39,  1.17it/s] 91%|█████████ | 456/500 [05:19<00:27,  1.61it/s] 92%|█████████▏| 458/500 [05:19<00:19,  2.17it/s] 92%|█████████▏| 460/500 [05:19<00:13,  2.87it/s] 92%|█████████▏| 462/500 [05:26<00:45,  1.20s/it] 93%|█████████▎| 464/500 [05:26<00:30,  1.17it/s] 93%|█████████▎| 466/500 [05:26<00:21,  1.62it/s] 94%|█████████▎| 468/500 [05:26<00:14,  2.21it/s] 94%|█████████▍| 470/500 [05:26<00:10,  2.97it/s] 94%|█████████▍| 472/500 [05:32<00:33,  1.20s/it] 95%|█████████▍| 474/500 [05:33<00:22,  1.16it/s] 95%|█████████▌| 476/500 [05:33<00:15,  1.59it/s] 96%|█████████▌| 478/500 [05:33<00:10,  2.14it/s] 96%|█████████▌| 480/500 [05:33<00:07,  2.83it/s] 96%|█████████▋| 482/500 [05:40<00:21,  1.22s/it] 97%|█████████▋| 484/500 [05:40<00:14,  1.14it/s] 97%|█████████▋| 486/500 [05:40<00:08,  1.57it/s] 98%|█████████▊| 488/500 [05:40<00:05,  2.12it/s] 98%|█████████▊| 490/500 [05:40<00:03,  2.81it/s] 98%|█████████▊| 492/500 [05:47<00:10,  1.25s/it] 99%|█████████▉| 494/500 [05:47<00:05,  1.11it/s] 99%|█████████▉| 496/500 [05:47<00:02,  1.54it/s]100%|█████████▉| 498/500 [05:47<00:00,  2.11it/s]Epoch:  428  	Training Loss: 0.03766590356826782
Test Loss:  0.025546692311763763
Valid Loss:  0.03391220048069954
Epoch:  429  	Training Loss: 0.03766531124711037
Test Loss:  0.025546159595251083
Valid Loss:  0.03391158580780029
Epoch:  430  	Training Loss: 0.037664711475372314
Test Loss:  0.025545630604028702
Valid Loss:  0.03391098603606224
Epoch:  431  	Training Loss: 0.03766411542892456
Test Loss:  0.02554509788751602
Valid Loss:  0.03391038253903389
Epoch:  432  	Training Loss: 0.03766351938247681
Test Loss:  0.02554457262158394
Valid Loss:  0.03390978276729584
Epoch:  433  	Training Loss: 0.03766293078660965
Test Loss:  0.025544051080942154
Valid Loss:  0.03390919044613838
Epoch:  434  	Training Loss: 0.037662338465452194
Test Loss:  0.02554352395236492
Valid Loss:  0.03390859067440033
Epoch:  435  	Training Loss: 0.03766174986958504
Test Loss:  0.025543000549077988
Valid Loss:  0.033907994627952576
Epoch:  436  	Training Loss: 0.03766115754842758
Test Loss:  0.025542477145791054
Valid Loss:  0.03390739858150482
Epoch:  437  	Training Loss: 0.037660568952560425
Test Loss:  0.02554195374250412
Valid Loss:  0.03390679508447647
Epoch:  438  	Training Loss: 0.03765997663140297
Test Loss:  0.025541430339217186
Valid Loss:  0.03390619903802872
Epoch:  439  	Training Loss: 0.037659384310245514
Test Loss:  0.025540906935930252
Valid Loss:  0.03390560299158096
Epoch:  440  	Training Loss: 0.03765879571437836
Test Loss:  0.02554038166999817
Valid Loss:  0.03390500694513321
Epoch:  441  	Training Loss: 0.0376582071185112
Test Loss:  0.025539858266711235
Valid Loss:  0.03390440717339516
Epoch:  442  	Training Loss: 0.037657611072063446
Test Loss:  0.025539331138134003
Valid Loss:  0.033903807401657104
Epoch:  443  	Training Loss: 0.03765701502561569
Test Loss:  0.025538798421621323
Valid Loss:  0.033903200179338455
Epoch:  444  	Training Loss: 0.03765641897916794
Test Loss:  0.02553826943039894
Valid Loss:  0.033902592957019806
Epoch:  445  	Training Loss: 0.037655819207429886
Test Loss:  0.02553774043917656
Valid Loss:  0.033901989459991455
Epoch:  446  	Training Loss: 0.037655219435691833
Test Loss:  0.025537215173244476
Valid Loss:  0.033901385962963104
Epoch:  447  	Training Loss: 0.03765462711453438
Test Loss:  0.025536682456731796
Valid Loss:  0.03390078619122505
Epoch:  448  	Training Loss: 0.037654027342796326
Test Loss:  0.025536149740219116
Valid Loss:  0.0339001789689064
Epoch:  449  	Training Loss: 0.03765342757105827
Test Loss:  0.025535620748996735
Valid Loss:  0.03389957919716835
Epoch:  450  	Training Loss: 0.03765283524990082
Test Loss:  0.025535088032484055
Valid Loss:  0.03389897570014
Epoch:  451  	Training Loss: 0.037652235478162766
Test Loss:  0.02553456276655197
Valid Loss:  0.03389836475253105
Epoch:  452  	Training Loss: 0.03765163570642471
Test Loss:  0.025534039363265038
Valid Loss:  0.033897772431373596
Epoch:  453  	Training Loss: 0.037651047110557556
Test Loss:  0.025533515959978104
Valid Loss:  0.03389717638492584
Epoch:  454  	Training Loss: 0.0376504585146904
Test Loss:  0.02553299069404602
Valid Loss:  0.03389658033847809
Epoch:  455  	Training Loss: 0.03764986991882324
Test Loss:  0.025532471016049385
Valid Loss:  0.03389597684144974
Epoch:  456  	Training Loss: 0.037649281322956085
Test Loss:  0.025531943887472153
Valid Loss:  0.03389538452029228
Epoch:  457  	Training Loss: 0.03764869272708893
Test Loss:  0.025531422346830368
Valid Loss:  0.03389479219913483
Epoch:  458  	Training Loss: 0.03764810413122177
Test Loss:  0.025530897080898285
Valid Loss:  0.03389419615268707
Epoch:  459  	Training Loss: 0.037647515535354614
Test Loss:  0.0255303755402565
Valid Loss:  0.03389359638094902
Epoch:  460  	Training Loss: 0.03764692693948746
Test Loss:  0.025529848411679268
Valid Loss:  0.033893004059791565
Epoch:  461  	Training Loss: 0.0376463383436203
Test Loss:  0.025529326871037483
Valid Loss:  0.03389240428805351
Epoch:  462  	Training Loss: 0.03764574974775314
Test Loss:  0.025528807193040848
Valid Loss:  0.03389181196689606
Epoch:  463  	Training Loss: 0.037645161151885986
Test Loss:  0.025528285652399063
Valid Loss:  0.0338912196457386
Epoch:  464  	Training Loss: 0.037644580006599426
Test Loss:  0.02552776224911213
Valid Loss:  0.03389062359929085
Epoch:  465  	Training Loss: 0.03764399141073227
Test Loss:  0.025527236983180046
Valid Loss:  0.033890027552843094
Epoch:  466  	Training Loss: 0.03764340281486511
Test Loss:  0.02552671730518341
Valid Loss:  0.03388943523168564
Epoch:  467  	Training Loss: 0.037642817944288254
Test Loss:  0.025526192039251328
Valid Loss:  0.033888839185237885
Epoch:  468  	Training Loss: 0.037642233073711395
Test Loss:  0.025525670498609543
Valid Loss:  0.03388824313879013
Epoch:  469  	Training Loss: 0.03764164820313454
Test Loss:  0.025525150820612907
Valid Loss:  0.033887654542922974
Epoch:  470  	Training Loss: 0.03764105960726738
Test Loss:  0.025524627417325974
Valid Loss:  0.03388705477118492
Epoch:  471  	Training Loss: 0.03764047473669052
Test Loss:  0.025524107739329338
Valid Loss:  0.033886462450027466
Epoch:  472  	Training Loss: 0.037639886140823364
Test Loss:  0.025523575022816658
Valid Loss:  0.033885855227708817
Epoch:  473  	Training Loss: 0.03763929754495621
Test Loss:  0.025523047894239426
Valid Loss:  0.033885255455970764
Epoch:  474  	Training Loss: 0.037638697773218155
Test Loss:  0.025522515177726746
Valid Loss:  0.03388465195894241
Epoch:  475  	Training Loss: 0.0376381017267704
Test Loss:  0.025521982461214066
Valid Loss:  0.03388404846191406
Epoch:  476  	Training Loss: 0.03763750195503235
Test Loss:  0.025521457195281982
Valid Loss:  0.03388344123959541
Epoch:  477  	Training Loss: 0.037636905908584595
Test Loss:  0.025520924478769302
Valid Loss:  0.03388284146785736
Epoch:  478  	Training Loss: 0.03763630986213684
Test Loss:  0.02552039548754692
Valid Loss:  0.03388223424553871
Epoch:  479  	Training Loss: 0.03763571381568909
Test Loss:  0.02551986649632454
Valid Loss:  0.03388163074851036
Epoch:  480  	Training Loss: 0.037635114043951035
Test Loss:  0.02551933191716671
Valid Loss:  0.03388102725148201
Epoch:  481  	Training Loss: 0.03763452172279358
Test Loss:  0.025518804788589478
Valid Loss:  0.03388042375445366
Epoch:  482  	Training Loss: 0.037633925676345825
Test Loss:  0.025518275797367096
Valid Loss:  0.03387982398271561
Epoch:  483  	Training Loss: 0.037633322179317474
Test Loss:  0.025517750531435013
Valid Loss:  0.033879220485687256
Epoch:  484  	Training Loss: 0.03763272613286972
Test Loss:  0.02551722340285778
Valid Loss:  0.033878616988658905
Epoch:  485  	Training Loss: 0.03763213008642197
Test Loss:  0.0255166944116354
Valid Loss:  0.033878013491630554
Epoch:  486  	Training Loss: 0.03763153403997421
Test Loss:  0.025516167283058167
Valid Loss:  0.0338774099946022
Epoch:  487  	Training Loss: 0.03763093799352646
Test Loss:  0.025515643879771233
Valid Loss:  0.03387681394815445
Epoch:  488  	Training Loss: 0.037630341947078705
Test Loss:  0.02551511488854885
Valid Loss:  0.0338762104511261
Epoch:  489  	Training Loss: 0.03762974590063095
Test Loss:  0.02551458775997162
Valid Loss:  0.033875610679388046
Epoch:  490  	Training Loss: 0.0376291461288929
Test Loss:  0.025514062494039536
Valid Loss:  0.033875007182359695
Epoch:  491  	Training Loss: 0.03762855380773544
Test Loss:  0.025513533502817154
Valid Loss:  0.033874403685331345
Epoch:  492  	Training Loss: 0.03762795031070709
Test Loss:  0.02551301009953022
Valid Loss:  0.03387380763888359
Epoch:  493  	Training Loss: 0.037627361714839935
Test Loss:  0.025512484833598137
Valid Loss:  0.03387320786714554
Epoch:  494  	Training Loss: 0.03762676939368248
Test Loss:  0.025511961430311203
Valid Loss:  0.033872611820697784
Epoch:  495  	Training Loss: 0.037626177072525024
Test Loss:  0.02551143243908882
Valid Loss:  0.033872008323669434
Epoch:  496  	Training Loss: 0.03762558475136757
Test Loss:  0.025510909035801888
Valid Loss:  0.03387141227722168
Epoch:  497  	Training Loss: 0.037624992430210114
Test Loss:  0.025510385632514954
Valid Loss:  0.03387081250548363
Epoch:  498  	Training Loss: 0.03762440010905266
Test Loss:  0.025509856641292572
Valid Loss:  0.03387021645903587
100%|██████████| 500/500 [05:48<00:00,  2.84it/s]100%|██████████| 500/500 [05:48<00:00,  1.44it/s]
Epoch:  499  	Training Loss: 0.0376238077878952
Test Loss:  0.02550933137536049
Valid Loss:  0.03386962041258812
Epoch:  500  	Training Loss: 0.037623219192028046
Test Loss:  0.025508806109428406
Valid Loss:  0.03386902064085007
seed is  2
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:06,  6.14s/it]  1%|          | 3/500 [00:06<13:40,  1.65s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:12<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:42,  1.22s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:26<09:24,  1.20s/it]  7%|▋         | 33/500 [00:27<06:42,  1.16it/s]  7%|▋         | 35/500 [00:33<12:04,  1.56s/it]  7%|▋         | 37/500 [00:33<08:34,  1.11s/it]  8%|▊         | 39/500 [00:33<06:07,  1.25it/s]  8%|▊         | 41/500 [00:39<11:26,  1.50s/it]  9%|▊         | 43/500 [00:40<08:08,  1.07s/it]  9%|▉         | 45/500 [00:40<05:49,  1.30it/s]  9%|▉         | 47/500 [00:40<04:12,  1.80it/s] 10%|▉         | 49/500 [00:40<03:05,  2.44it/s] 10%|█         | 51/500 [00:46<09:14,  1.23s/it] 11%|█         | 53/500 [00:46<06:36,  1.13it/s] 11%|█         | 55/500 [00:47<04:45,  1.56it/s] 11%|█▏        | 57/500 [00:47<03:27,  2.14it/s] 12%|█▏        | 59/500 [00:47<02:33,  2.87it/s] 12%|█▏        | 61/500 [00:53<08:41,  1.19s/it] 13%|█▎        | 63/500 [00:53<06:14,  1.17it/s] 13%|█▎        | 65/500 [00:53<04:29,  1.62it/s] 13%|█▎        | 67/500 [00:54<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:54<02:24,  2.97it/s]Epoch:  1  	Training Loss: 0.044193021953105927
Test Loss:  0.008222950622439384
Valid Loss:  0.01024619396775961
Epoch:  2  	Training Loss: 0.009058578871190548
Test Loss:  0.0831046923995018
Valid Loss:  0.08690093457698822
Epoch:  3  	Training Loss: 0.0922539234161377
Test Loss:  0.9440022706985474
Valid Loss:  0.918926477432251
Epoch:  4  	Training Loss: 0.8800079822540283
Test Loss:  0.020752346143126488
Valid Loss:  0.025763917714357376
Epoch:  5  	Training Loss: 0.025729982182383537
Test Loss:  0.02039896324276924
Valid Loss:  0.025341548025608063
Epoch:  6  	Training Loss: 0.02530944161117077
Test Loss:  0.020090937614440918
Valid Loss:  0.02495463564991951
Epoch:  7  	Training Loss: 0.02493787184357643
Test Loss:  0.019809139892458916
Valid Loss:  0.024627914652228355
Epoch:  8  	Training Loss: 0.024625487625598907
Test Loss:  0.019533812999725342
Valid Loss:  0.024318546056747437
Epoch:  9  	Training Loss: 0.024334872141480446
Test Loss:  0.019263213500380516
Valid Loss:  0.024014193564653397
Epoch:  10  	Training Loss: 0.02404738962650299
Test Loss:  0.01899220421910286
Valid Loss:  0.02371334657073021
Epoch:  11  	Training Loss: 0.02376176230609417
Test Loss:  0.018719779327511787
Valid Loss:  0.02341734617948532
Epoch:  12  	Training Loss: 0.023478861898183823
Test Loss:  0.009677952155470848
Valid Loss:  0.0140115637332201
Epoch:  13  	Training Loss: 0.01663116365671158
Test Loss:  0.12421098351478577
Valid Loss:  0.11880290508270264
Epoch:  14  	Training Loss: 0.10867320001125336
Test Loss:  0.02658919245004654
Valid Loss:  0.03115876205265522
Epoch:  15  	Training Loss: 0.03685405105352402
Test Loss:  0.014169672504067421
Valid Loss:  0.01849660836160183
Epoch:  16  	Training Loss: 0.02219180203974247
Test Loss:  0.010359336622059345
Valid Loss:  0.014523828402161598
Epoch:  17  	Training Loss: 0.017056765034794807
Test Loss:  0.009619255550205708
Valid Loss:  0.014201396144926548
Epoch:  18  	Training Loss: 0.016382604837417603
Test Loss:  0.009165996685624123
Valid Loss:  0.013694408349692822
Epoch:  19  	Training Loss: 0.015874914824962616
Test Loss:  0.008714258670806885
Valid Loss:  0.013294493779540062
Epoch:  20  	Training Loss: 0.015407834202051163
Test Loss:  0.00826875027269125
Valid Loss:  0.012897742912173271
Epoch:  21  	Training Loss: 0.014944049529731274
Test Loss:  0.007966999895870686
Valid Loss:  0.012653741054236889
Epoch:  22  	Training Loss: 0.01461012102663517
Test Loss:  0.005150068551301956
Valid Loss:  0.008520146831870079
Epoch:  23  	Training Loss: 0.008903801441192627
Test Loss:  0.003692599479109049
Valid Loss:  0.006632584612816572
Epoch:  24  	Training Loss: 0.007288412190973759
Test Loss:  0.005157469306141138
Valid Loss:  0.0074501256458461285
Epoch:  25  	Training Loss: 0.006960345897823572
Test Loss:  0.00276309996843338
Valid Loss:  0.005209289491176605
Epoch:  26  	Training Loss: 0.005813510622829199
Test Loss:  0.003974732477217913
Valid Loss:  0.00578651949763298
Epoch:  27  	Training Loss: 0.0051737623289227486
Test Loss:  0.0019901918713003397
Valid Loss:  0.0039745960384607315
Epoch:  28  	Training Loss: 0.00430683558806777
Test Loss:  0.002925554756075144
Valid Loss:  0.0044331056997179985
Epoch:  29  	Training Loss: 0.003931693732738495
Test Loss:  0.0015930230729281902
Valid Loss:  0.0032504061236977577
Epoch:  30  	Training Loss: 0.0034418103750795126
Test Loss:  0.0023333043791353703
Valid Loss:  0.003617246402427554
Epoch:  31  	Training Loss: 0.0032103718258440495
Test Loss:  0.0013564873952418566
Valid Loss:  0.0027749426662921906
Epoch:  32  	Training Loss: 0.002892593387514353
Test Loss:  0.0054764654487371445
Valid Loss:  0.0050480905920267105
Epoch:  33  	Training Loss: 0.004285469651222229
Test Loss:  0.0034995749592781067
Valid Loss:  0.005985730327665806
Epoch:  34  	Training Loss: 0.0069473376497626305
Test Loss:  0.0016049833502620459
Valid Loss:  0.003035874804481864
Epoch:  35  	Training Loss: 0.002956345211714506
Test Loss:  0.0018851127242669463
Valid Loss:  0.003106988500803709
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.002851150231435895
Test Loss:  0.0018220653291791677
Valid Loss:  0.0030473966617137194
Epoch:  37  	Training Loss: 0.002819106448441744
Test Loss:  0.0018044722964987159
Valid Loss:  0.0030143901240080595
Epoch:  38  	Training Loss: 0.002791843842715025
Test Loss:  0.0017938870005309582
Valid Loss:  0.002994779497385025
Epoch:  39  	Training Loss: 0.002772172912955284
Test Loss:  0.0017170070204883814
Valid Loss:  0.0029398733749985695
Epoch:  40  	Training Loss: 0.0027595283463597298
Test Loss:  0.00175636971835047
Valid Loss:  0.0029564250726252794
Epoch:  41  	Training Loss: 0.002753115026280284
Test Loss:  0.0016667043091729283
Valid Loss:  0.0028972052969038486
Epoch:  42  	Training Loss: 0.0027459803968667984
Test Loss:  0.0016888303216546774
Valid Loss:  0.0028042541816830635
Epoch:  43  	Training Loss: 0.0026299534365534782
Test Loss:  0.001529148081317544
Valid Loss:  0.0026428168639540672
Epoch:  44  	Training Loss: 0.0025435523129999638
Test Loss:  0.0016513075679540634
Valid Loss:  0.002647303743287921
Epoch:  45  	Training Loss: 0.002474764361977577
Test Loss:  0.0014654465485364199
Valid Loss:  0.0024968453217297792
Epoch:  46  	Training Loss: 0.0024004457518458366
Test Loss:  0.0015689502470195293
Valid Loss:  0.002501466777175665
Epoch:  47  	Training Loss: 0.002335876692086458
Test Loss:  0.00142403575591743
Valid Loss:  0.002383442362770438
Epoch:  48  	Training Loss: 0.00227620592340827
Test Loss:  0.001532306196168065
Valid Loss:  0.0024016904644668102
Epoch:  49  	Training Loss: 0.0022244297433644533
Test Loss:  0.0013656275114044547
Valid Loss:  0.0022852271795272827
Epoch:  50  	Training Loss: 0.002169246319681406
Test Loss:  0.0014812052249908447
Valid Loss:  0.002313530072569847
Epoch:  51  	Training Loss: 0.00212491350248456
Test Loss:  0.0013313965173438191
Valid Loss:  0.002206570003181696
Epoch:  52  	Training Loss: 0.002076296601444483
Test Loss:  0.0013590193120762706
Valid Loss:  0.0020609654020518064
Epoch:  53  	Training Loss: 0.0018708081915974617
Test Loss:  0.0013153664767742157
Valid Loss:  0.0019791321828961372
Epoch:  54  	Training Loss: 0.0017851158045232296
Test Loss:  0.0012856073444709182
Valid Loss:  0.0019390226807445288
Epoch:  55  	Training Loss: 0.0017632918898016214
Test Loss:  0.0012695842888206244
Valid Loss:  0.0019223171984776855
Epoch:  56  	Training Loss: 0.0017564150039106607
Test Loss:  0.0012627686373889446
Valid Loss:  0.0019115663599222898
Epoch:  57  	Training Loss: 0.0017505690921097994
Test Loss:  0.0012576521839946508
Valid Loss:  0.0019036744488403201
Epoch:  58  	Training Loss: 0.0017458759248256683
Test Loss:  0.0012548955855891109
Valid Loss:  0.0018970874371007085
Epoch:  59  	Training Loss: 0.0017415827605873346
Test Loss:  0.0012509074294939637
Valid Loss:  0.0018905282486230135
Epoch:  60  	Training Loss: 0.0017377559561282396
Test Loss:  0.0012467715423554182
Valid Loss:  0.0018844213336706161
Epoch:  61  	Training Loss: 0.0017345156520605087
Test Loss:  0.001240072539076209
Valid Loss:  0.0018775996286422014
Epoch:  62  	Training Loss: 0.0017317765159532428
Test Loss:  0.0013207719894126058
Valid Loss:  0.0018671632278710604
Epoch:  63  	Training Loss: 0.0016558831557631493
Test Loss:  0.0011766814859583974
Valid Loss:  0.0017489599995315075
Epoch:  64  	Training Loss: 0.001601728843525052
Test Loss:  0.0011958786053583026
Valid Loss:  0.001733790384605527
Epoch:  65  	Training Loss: 0.0015580798499286175
Test Loss:  0.0011068058665841818
Valid Loss:  0.0016565158730372787
Epoch:  66  	Training Loss: 0.0015135420253500342
Test Loss:  0.0010978758800774813
Valid Loss:  0.0016258676769211888
Epoch:  67  	Training Loss: 0.0014694447163492441
Test Loss:  0.0010383127955719829
Valid Loss:  0.0015679590869694948
Epoch:  68  	Training Loss: 0.0014271389227360487
Test Loss:  0.0010123539250344038
Valid Loss:  0.0015295499470084906
Epoch:  69  	Training Loss: 0.0013873862335458398
Test Loss:  0.0009678023052401841
Valid Loss:  0.0014826073311269283
 14%|█▍        | 71/500 [01:00<08:44,  1.22s/it] 15%|█▍        | 73/500 [01:00<06:17,  1.13it/s] 15%|█▌        | 75/500 [01:01<04:33,  1.55it/s] 15%|█▌        | 77/500 [01:01<03:21,  2.10it/s] 16%|█▌        | 79/500 [01:01<02:31,  2.79it/s] 16%|█▌        | 81/500 [01:07<08:28,  1.21s/it] 17%|█▋        | 83/500 [01:08<06:05,  1.14it/s] 17%|█▋        | 85/500 [01:08<04:25,  1.56it/s] 17%|█▋        | 87/500 [01:08<03:15,  2.11it/s] 18%|█▊        | 89/500 [01:08<02:26,  2.81it/s] 18%|█▊        | 91/500 [01:15<08:20,  1.22s/it] 19%|█▊        | 93/500 [01:15<05:57,  1.14it/s] 19%|█▉        | 95/500 [01:15<04:16,  1.58it/s] 19%|█▉        | 97/500 [01:15<03:06,  2.16it/s] 20%|█▉        | 99/500 [01:15<02:17,  2.91it/s] 20%|██        | 101/500 [01:21<07:58,  1.20s/it] 21%|██        | 103/500 [01:22<05:41,  1.16it/s] 21%|██        | 105/500 [01:22<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:22<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:22<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:28<07:43,  1.19s/it] 23%|██▎       | 113/500 [01:28<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:29<03:58,  1.62it/s] 23%|██▎       | 117/500 [01:29<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:29<02:08,  2.98it/s] 24%|██▍       | 121/500 [01:41<13:13,  2.09s/it] 25%|██▍       | 123/500 [01:41<09:20,  1.49s/it] 25%|██▌       | 125/500 [01:42<06:37,  1.06s/it] 25%|██▌       | 127/500 [01:42<04:44,  1.31it/s] 26%|██▌       | 129/500 [01:42<03:25,  1.81it/s] 26%|██▌       | 131/500 [01:48<08:08,  1.32s/it] 27%|██▋       | 133/500 [01:48<05:47,  1.05it/s] 27%|██▋       | 135/500 [01:48<04:09,  1.46it/s]Epoch:  70  	Training Loss: 0.0013505369424819946
Test Loss:  0.0009469444048590958
Valid Loss:  0.0014487297739833593
Epoch:  71  	Training Loss: 0.0013155252672731876
Test Loss:  0.0009064616751857102
Valid Loss:  0.0014063692651689053
Epoch:  72  	Training Loss: 0.001282624201849103
Test Loss:  0.0009331363253295422
Valid Loss:  0.0013826186768710613
Epoch:  73  	Training Loss: 0.0012410623021423817
Test Loss:  0.0009167453972622752
Valid Loss:  0.0013651074841618538
Epoch:  74  	Training Loss: 0.0012253773165866733
Test Loss:  0.0009095232235267758
Valid Loss:  0.0013515688478946686
Epoch:  75  	Training Loss: 0.001211058348417282
Test Loss:  0.0009015921968966722
Valid Loss:  0.0013387645594775677
Epoch:  76  	Training Loss: 0.001197506207972765
Test Loss:  0.0008983899024315178
Valid Loss:  0.0013279872946441174
Epoch:  77  	Training Loss: 0.0011846874840557575
Test Loss:  0.0008900335524231195
Valid Loss:  0.0013160649687051773
Epoch:  78  	Training Loss: 0.001172379357740283
Test Loss:  0.0008860697271302342
Valid Loss:  0.0013054661685600877
Epoch:  79  	Training Loss: 0.0011605338659137487
Test Loss:  0.0008805635734461248
Valid Loss:  0.0012951958924531937
Epoch:  80  	Training Loss: 0.0011495667276903987
Test Loss:  0.0008779041236266494
Valid Loss:  0.0012861432041972876
Epoch:  81  	Training Loss: 0.0011392987798899412
Test Loss:  0.0008700976613909006
Valid Loss:  0.0012755743227899075
Epoch:  82  	Training Loss: 0.0011298682074993849
Test Loss:  0.0007533726166002452
Valid Loss:  0.0011853636242449284
Epoch:  83  	Training Loss: 0.0010702427243813872
Test Loss:  0.0006884251488372684
Valid Loss:  0.00113001954741776
Epoch:  84  	Training Loss: 0.001029703300446272
Test Loss:  0.0006449896609410644
Valid Loss:  0.0010894471779465675
Epoch:  85  	Training Loss: 0.000995449721813202
Test Loss:  0.0006129696848802269
Valid Loss:  0.0010561388917267323
Epoch:  86  	Training Loss: 0.0009650974534451962
Test Loss:  0.0005862351390533149
Valid Loss:  0.0010259768459945917
Epoch:  87  	Training Loss: 0.0009365021833218634
Test Loss:  0.000563114183023572
Valid Loss:  0.0009978385642170906
Epoch:  88  	Training Loss: 0.0009094075649045408
Test Loss:  0.000542564841452986
Valid Loss:  0.0009715327178128064
Epoch:  89  	Training Loss: 0.0008839801885187626
Test Loss:  0.0005238689482212067
Valid Loss:  0.0009466043557040393
Epoch:  90  	Training Loss: 0.0008601781446486712
Test Loss:  0.0005074605578556657
Valid Loss:  0.0009232526645064354
Epoch:  91  	Training Loss: 0.0008380557992495596
Test Loss:  0.000492189428769052
Valid Loss:  0.0009008540655486286
Epoch:  92  	Training Loss: 0.000817001098766923
Test Loss:  0.000526812975294888
Valid Loss:  0.000898224301636219
Epoch:  93  	Training Loss: 0.0007982183014973998
Test Loss:  0.0005133762024343014
Valid Loss:  0.0008835623157210648
Epoch:  94  	Training Loss: 0.0007868666434660554
Test Loss:  0.0005152574740350246
Valid Loss:  0.0008763751247897744
Epoch:  95  	Training Loss: 0.0007775158737786114
Test Loss:  0.0005045513389632106
Valid Loss:  0.0008662897162139416
Epoch:  96  	Training Loss: 0.0007691999198868871
Test Loss:  0.000500672438647598
Valid Loss:  0.0008596056140959263
Epoch:  97  	Training Loss: 0.0007620162796229124
Test Loss:  0.000493515282869339
Valid Loss:  0.0008524967124685645
Epoch:  98  	Training Loss: 0.0007553041796199977
Test Loss:  0.00048723153304308653
Valid Loss:  0.0008461310062557459
Epoch:  99  	Training Loss: 0.0007493188604712486
Test Loss:  0.0004811345716007054
Valid Loss:  0.0008400928927585483
Epoch:  100  	Training Loss: 0.0007437854656018317
Test Loss:  0.00047571162576787174
Valid Loss:  0.000834413047414273
Epoch:  101  	Training Loss: 0.0007384922355413437
Test Loss:  0.00047042686492204666
Valid Loss:  0.0008289403049275279
Epoch:  102  	Training Loss: 0.0007335362024605274
Test Loss:  0.00044941954547539353
Valid Loss:  0.0008084140135906637
Epoch:  103  	Training Loss: 0.0007196239312179387
Test Loss:  0.0004360204329714179
Valid Loss:  0.0007923297816887498
Epoch:  104  	Training Loss: 0.00070692237932235
Test Loss:  0.0004256560932844877
Valid Loss:  0.0007780182640999556
Epoch:  105  	Training Loss: 0.0006947937072254717
Test Loss:  0.0004165883583482355
Valid Loss:  0.0007648369064554572
Epoch:  106  	Training Loss: 0.0006830748170614243
Test Loss:  0.0004084443498868495
Valid Loss:  0.0007523352978751063
Epoch:  107  	Training Loss: 0.0006717412616126239
Test Loss:  0.00040041838656179607
Valid Loss:  0.0007402132032439113
Epoch:  108  	Training Loss: 0.0006608631811104715
Test Loss:  0.00039296678733080626
Valid Loss:  0.0007285680621862411
Epoch:  109  	Training Loss: 0.0006502911564894021
Test Loss:  0.00038590352050960064
Valid Loss:  0.0007173412013798952
Epoch:  110  	Training Loss: 0.0006400358397513628
Test Loss:  0.0003786409506574273
Valid Loss:  0.0007063286029733717
Epoch:  111  	Training Loss: 0.0006301231915131211
Test Loss:  0.00037217175122350454
Valid Loss:  0.0006958598969504237
Epoch:  112  	Training Loss: 0.0006205452373251319
Test Loss:  0.0004078286583535373
Valid Loss:  0.0006832083454355597
Epoch:  113  	Training Loss: 0.0005922303535044193
Test Loss:  0.0003278020885773003
Valid Loss:  0.0006379073020070791
Epoch:  114  	Training Loss: 0.0005692037520930171
Test Loss:  0.0004013965663034469
Valid Loss:  0.0006444857572205365
Epoch:  115  	Training Loss: 0.0005513582145795226
Test Loss:  0.00027589648379944265
Valid Loss:  0.00059531006263569
Epoch:  116  	Training Loss: 0.0005384393152780831
Test Loss:  0.0004465121019165963
Valid Loss:  0.000645408988930285
Epoch:  117  	Training Loss: 0.0005428592558018863
Test Loss:  0.0002742882934398949
Valid Loss:  0.0006818470428697765
Epoch:  118  	Training Loss: 0.0006690403679385781
Test Loss:  0.0007511409930884838
Valid Loss:  0.0008416317868977785
Epoch:  119  	Training Loss: 0.0007018987089395523
Test Loss:  0.00025049131363630295
Valid Loss:  0.0005328591214492917
Epoch:  120  	Training Loss: 0.0004719346761703491
Test Loss:  0.0002776909968815744
Valid Loss:  0.0005249156383797526
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.00045174109982326627
Test Loss:  0.00027882360154762864
Valid Loss:  0.0005213420954532921
Epoch:  122  	Training Loss: 0.0004471935681067407
Test Loss:  0.0002745156525634229
Valid Loss:  0.0005165081238374114
Epoch:  123  	Training Loss: 0.00044293023529462516
Test Loss:  0.000270969292614609
Valid Loss:  0.000511982711032033
Epoch:  124  	Training Loss: 0.00043879851000383496
Test Loss:  0.00026790384436026216
Valid Loss:  0.0005076781962998211
Epoch:  125  	Training Loss: 0.0004347763315308839
Test Loss:  0.000265078735537827
Valid Loss:  0.0005034978967159986
Epoch:  126  	Training Loss: 0.0004308533971197903
Test Loss:  0.0002625561028253287
Valid Loss:  0.0004994855262339115
Epoch:  127  	Training Loss: 0.00042705630767159164
Test Loss:  0.0002595037512946874
Valid Loss:  0.0004956019693054259
Epoch:  128  	Training Loss: 0.0004234323278069496
Test Loss:  0.0002567612973507494
Valid Loss:  0.0004918902413919568
Epoch:  129  	Training Loss: 0.0004199066897854209
Test Loss:  0.00025308714248239994
Valid Loss:  0.00048795295879244804
Epoch:  130  	Training Loss: 0.0004165613208897412
Test Loss:  0.0002489445614628494
Valid Loss:  0.0004839522880502045
Epoch:  131  	Training Loss: 0.0004133349866606295
Test Loss:  0.00024669067352078855
Valid Loss:  0.0004806077340617776
Epoch:  132  	Training Loss: 0.00041017873445525765
Test Loss:  0.00024095324624795467
Valid Loss:  0.0004761764721479267
Epoch:  133  	Training Loss: 0.00040690338937565684
Test Loss:  0.00023640962899662554
Valid Loss:  0.00047235400415956974
Epoch:  134  	Training Loss: 0.0004039040650241077
Test Loss:  0.0002326661633560434
Valid Loss:  0.0004689302295446396
Epoch:  135  	Training Loss: 0.00040108186658471823
Test Loss:  0.00022906559752300382
Valid Loss:  0.0004656572127714753
Epoch:  136  	Training Loss: 0.0003984184004366398
Test Loss:  0.0002261264162370935
Valid Loss:  0.0004627147573046386
Epoch:  137  	Training Loss: 0.00039588820072822273
 27%|██▋       | 137/500 [01:48<03:00,  2.01it/s] 28%|██▊       | 139/500 [01:49<02:12,  2.72it/s] 28%|██▊       | 141/500 [01:55<07:11,  1.20s/it] 29%|██▊       | 143/500 [01:55<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:55<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:55<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:55<01:59,  2.95it/s] 30%|███       | 151/500 [02:02<06:48,  1.17s/it] 31%|███       | 153/500 [02:02<04:54,  1.18it/s] 31%|███       | 155/500 [02:02<03:33,  1.62it/s] 31%|███▏      | 157/500 [02:02<02:37,  2.18it/s] 32%|███▏      | 159/500 [02:02<01:58,  2.88it/s] 32%|███▏      | 161/500 [02:09<06:53,  1.22s/it] 33%|███▎      | 163/500 [02:09<04:55,  1.14it/s] 33%|███▎      | 165/500 [02:09<03:32,  1.58it/s] 33%|███▎      | 167/500 [02:09<02:35,  2.14it/s] 34%|███▍      | 169/500 [02:09<01:56,  2.83it/s] 34%|███▍      | 171/500 [02:16<06:31,  1.19s/it] 35%|███▍      | 173/500 [02:16<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:16<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:16<02:30,  2.15it/s] 36%|███▌      | 179/500 [02:16<01:52,  2.84it/s] 36%|███▌      | 181/500 [02:23<06:27,  1.21s/it] 37%|███▋      | 183/500 [02:23<04:36,  1.15it/s] 37%|███▋      | 185/500 [02:23<03:18,  1.59it/s] 37%|███▋      | 187/500 [02:23<02:24,  2.17it/s] 38%|███▊      | 189/500 [02:23<01:46,  2.92it/s] 38%|███▊      | 191/500 [02:30<06:08,  1.19s/it] 39%|███▊      | 193/500 [02:30<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:30<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:30<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:30<01:41,  2.98it/s] 40%|████      | 201/500 [02:37<05:47,  1.16s/it] 41%|████      | 203/500 [02:37<04:08,  1.20it/s]Test Loss:  0.00022359669674187899
Valid Loss:  0.0004599856911227107
Epoch:  138  	Training Loss: 0.0003934255219064653
Test Loss:  0.00022132731101009995
Valid Loss:  0.00045739751658402383
Epoch:  139  	Training Loss: 0.00039102855953387916
Test Loss:  0.0002189032093156129
Valid Loss:  0.00045484781730920076
Epoch:  140  	Training Loss: 0.00038876099279150367
Test Loss:  0.0002167678321711719
Valid Loss:  0.000452449603471905
Epoch:  141  	Training Loss: 0.00038659400888718665
Test Loss:  0.0002145046746591106
Valid Loss:  0.0004500719078350812
Epoch:  142  	Training Loss: 0.00038449116982519627
Test Loss:  0.00021787725563626736
Valid Loss:  0.00044699752470478415
Epoch:  143  	Training Loss: 0.0003801163984462619
Test Loss:  0.00021785643184557557
Valid Loss:  0.0004436607996467501
Epoch:  144  	Training Loss: 0.00037650784361176193
Test Loss:  0.00021786156867165118
Valid Loss:  0.00044066907139495015
Epoch:  145  	Training Loss: 0.0003732375043909997
Test Loss:  0.00021723289682995528
Valid Loss:  0.00043773395009338856
Epoch:  146  	Training Loss: 0.00037022228934802115
Test Loss:  0.00021596338774543256
Valid Loss:  0.00043475368875078857
Epoch:  147  	Training Loss: 0.0003673881583381444
Test Loss:  0.00021499147987924516
Valid Loss:  0.0004319627769291401
Epoch:  148  	Training Loss: 0.00036470236955210567
Test Loss:  0.00021367918816395104
Valid Loss:  0.0004291708464734256
Epoch:  149  	Training Loss: 0.0003621363721322268
Test Loss:  0.00021199940238147974
Valid Loss:  0.0004264179151505232
Epoch:  150  	Training Loss: 0.00035969034070149064
Test Loss:  0.00021041011495981365
Valid Loss:  0.00042373817996121943
Epoch:  151  	Training Loss: 0.00035730082890950143
Test Loss:  0.00020882015815004706
Valid Loss:  0.000421119766542688
Epoch:  152  	Training Loss: 0.0003549738321453333
Test Loss:  0.0002081210259348154
Valid Loss:  0.0004193056665826589
Epoch:  153  	Training Loss: 0.00035317573929205537
Test Loss:  0.0002072040515486151
Valid Loss:  0.0004174538771621883
Epoch:  154  	Training Loss: 0.00035140637191943824
Test Loss:  0.00020623579621315002
Valid Loss:  0.0004156114300712943
Epoch:  155  	Training Loss: 0.000349671405274421
Test Loss:  0.00020521151600405574
Valid Loss:  0.00041377433808520436
Epoch:  156  	Training Loss: 0.00034796498948708177
Test Loss:  0.000204594834940508
Valid Loss:  0.0004121024103369564
Epoch:  157  	Training Loss: 0.0003462945460341871
Test Loss:  0.0002037447557086125
Valid Loss:  0.00041038598283194005
Epoch:  158  	Training Loss: 0.00034464962664060295
Test Loss:  0.00020279409363865852
Valid Loss:  0.0004086692933924496
Epoch:  159  	Training Loss: 0.0003430279321037233
Test Loss:  0.00020180581486783922
Valid Loss:  0.00040697120130062103
Epoch:  160  	Training Loss: 0.0003414291422814131
Test Loss:  0.00020080982358194888
Valid Loss:  0.00040528998943045735
Epoch:  161  	Training Loss: 0.0003398529370315373
Test Loss:  0.0001998182269744575
Valid Loss:  0.00040363302105106413
Epoch:  162  	Training Loss: 0.000338301295414567
Test Loss:  0.00019763308227993548
Valid Loss:  0.0004019845509901643
Epoch:  163  	Training Loss: 0.0003370263148099184
Test Loss:  0.00019638272351585329
Valid Loss:  0.0004006297967862338
Epoch:  164  	Training Loss: 0.0003357870446052402
Test Loss:  0.0001948877179529518
Valid Loss:  0.00039924035081639886
Epoch:  165  	Training Loss: 0.0003345822624396533
Test Loss:  0.00019366107881069183
Valid Loss:  0.00039794977055862546
Epoch:  166  	Training Loss: 0.00033340509980916977
Test Loss:  0.0001926019904203713
Valid Loss:  0.00039673203718848526
Epoch:  167  	Training Loss: 0.0003322606207802892
Test Loss:  0.00019164750119671226
Valid Loss:  0.0003956087166443467
Epoch:  168  	Training Loss: 0.00033118814462795854
Test Loss:  0.00019022887863684446
Valid Loss:  0.0003943906049244106
Epoch:  169  	Training Loss: 0.00033013656502589583
Test Loss:  0.000189234473509714
Valid Loss:  0.0003932446416001767
Epoch:  170  	Training Loss: 0.0003290714230388403
Test Loss:  0.00018810629262588918
Valid Loss:  0.00039210726390592754
Epoch:  171  	Training Loss: 0.00032805572845973074
Test Loss:  0.00018717514467425644
Valid Loss:  0.0003910425875801593
Epoch:  172  	Training Loss: 0.00032706576166674495
Test Loss:  0.0001854101283242926
Valid Loss:  0.000389245105907321
Epoch:  173  	Training Loss: 0.0003257861826568842
Test Loss:  0.00018324457050766796
Valid Loss:  0.0003872772504109889
Epoch:  174  	Training Loss: 0.00032432080479338765
Test Loss:  0.00018069356156047434
Valid Loss:  0.000385168386856094
Epoch:  175  	Training Loss: 0.0003227348206564784
Test Loss:  0.00017857333295978606
Valid Loss:  0.0003831912763416767
Epoch:  176  	Training Loss: 0.0003211852163076401
Test Loss:  0.00017695961287245154
Valid Loss:  0.0003814077062997967
Epoch:  177  	Training Loss: 0.00031972507713362575
Test Loss:  0.00017575218225829303
Valid Loss:  0.00037976267049089074
Epoch:  178  	Training Loss: 0.0003183684893883765
Test Loss:  0.00017515690706204623
Valid Loss:  0.00037837750278413296
Epoch:  179  	Training Loss: 0.00031716475496068597
Test Loss:  0.00017502506671007723
Valid Loss:  0.00037719670217484236
Epoch:  180  	Training Loss: 0.00031609711004421115
Test Loss:  0.00017493068298790604
Valid Loss:  0.00037608854472637177
Epoch:  181  	Training Loss: 0.000315124518238008
Test Loss:  0.00017516911611892283
Valid Loss:  0.000375159113900736
Epoch:  182  	Training Loss: 0.00031424517510458827
Test Loss:  0.000179355512955226
Valid Loss:  0.00037319614784792066
Epoch:  183  	Training Loss: 0.00031119093182496727
Test Loss:  0.00018075492698699236
Valid Loss:  0.00037128274561837316
Epoch:  184  	Training Loss: 0.00030897808028385043
Test Loss:  0.00018069849465973675
Valid Loss:  0.0003693310427479446
Epoch:  185  	Training Loss: 0.00030706351390108466
Test Loss:  0.0001801049365894869
Valid Loss:  0.0003674159524962306
Epoch:  186  	Training Loss: 0.0003053174586966634
Test Loss:  0.00017968514293897897
Valid Loss:  0.0003657413471955806
Epoch:  187  	Training Loss: 0.00030371450702659786
Test Loss:  0.000179835973540321
Valid Loss:  0.00036432468914426863
Epoch:  188  	Training Loss: 0.0003022360324393958
Test Loss:  0.00017840653890743852
Valid Loss:  0.00036268262192606926
Epoch:  189  	Training Loss: 0.00030086643528193235
Test Loss:  0.00017857126658782363
Valid Loss:  0.0003614383458625525
Epoch:  190  	Training Loss: 0.00029952815384604037
Test Loss:  0.00017772719729691744
Valid Loss:  0.00036005221772938967
Epoch:  191  	Training Loss: 0.0002982680744025856
Test Loss:  0.0001767991780070588
Valid Loss:  0.0003587132669053972
Epoch:  192  	Training Loss: 0.0002970652130898088
Test Loss:  0.0001767614739947021
Valid Loss:  0.00035774451680481434
Epoch:  193  	Training Loss: 0.0002960804267786443
Test Loss:  0.00017643134924583137
Valid Loss:  0.00035675178514793515
Epoch:  194  	Training Loss: 0.0002951124624814838
Test Loss:  0.0001759367878548801
Valid Loss:  0.00035574729554355145
Epoch:  195  	Training Loss: 0.0002941547427326441
Test Loss:  0.00017535159713588655
Valid Loss:  0.00035473876050673425
Epoch:  196  	Training Loss: 0.00029320604517124593
Test Loss:  0.00017471754108555615
Valid Loss:  0.00035373246646486223
Epoch:  197  	Training Loss: 0.00029226549668237567
Test Loss:  0.00017405927064828575
Valid Loss:  0.0003527302178554237
Epoch:  198  	Training Loss: 0.0002913327480200678
Test Loss:  0.0001733895333018154
Valid Loss:  0.000351734779542312
Epoch:  199  	Training Loss: 0.00029040788649581373
Test Loss:  0.00017271743854507804
Valid Loss:  0.0003507467918097973
Epoch:  200  	Training Loss: 0.0002894907374866307
Test Loss:  0.0001721326552797109
Valid Loss:  0.00034977757604792714
Epoch:  201  	Training Loss: 0.0002885865396820009
Test Loss:  0.0001715128601063043
Valid Loss:  0.00034881161991506815
Epoch:  202  	Training Loss: 0.00028769561322405934
Test Loss:  0.000170564599102363
Valid Loss:  0.0003476932179182768
Epoch:  203  	Training Loss: 0.0002867064322344959
Test Loss:  0.00017031400057021528
Valid Loss:  0.0003467292699497193
Epoch:  204  	Training Loss: 0.0002857244689948857
Test Loss:  0.00016972387675195932
Valid Loss:   41%|████      | 205/500 [02:37<02:58,  1.66it/s] 41%|████▏     | 207/500 [02:37<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:37<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:43<05:36,  1.17s/it] 43%|████▎     | 213/500 [02:43<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:44<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:44<02:05,  2.26it/s] 44%|████▍     | 219/500 [02:44<01:32,  3.03it/s] 44%|████▍     | 221/500 [02:50<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:50<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:51<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:51<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:51<01:31,  2.95it/s] 46%|████▌     | 231/500 [02:57<05:23,  1.20s/it] 47%|████▋     | 233/500 [02:57<03:50,  1.16it/s] 47%|████▋     | 235/500 [02:57<02:45,  1.60it/s] 47%|████▋     | 237/500 [02:58<02:00,  2.19it/s] 48%|████▊     | 239/500 [02:58<01:28,  2.95it/s] 48%|████▊     | 241/500 [03:04<05:02,  1.17s/it] 49%|████▊     | 243/500 [03:04<03:35,  1.19it/s] 49%|████▉     | 245/500 [03:04<02:34,  1.65it/s] 49%|████▉     | 247/500 [03:04<01:52,  2.24it/s] 50%|████▉     | 249/500 [03:05<01:23,  3.00it/s] 50%|█████     | 251/500 [03:11<04:50,  1.17s/it] 51%|█████     | 253/500 [03:11<03:26,  1.19it/s] 51%|█████     | 255/500 [03:11<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:11<01:47,  2.26it/s] 52%|█████▏    | 259/500 [03:11<01:19,  3.01it/s] 52%|█████▏    | 261/500 [03:18<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:18<03:23,  1.17it/s] 53%|█████▎    | 265/500 [03:18<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:18<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:18<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:25<04:32,  1.19s/it]0.00034571997821331024
Epoch:  205  	Training Loss: 0.0002847580472007394
Test Loss:  0.00016906377277337015
Valid Loss:  0.0003447073686402291
Epoch:  206  	Training Loss: 0.0002838008804246783
Test Loss:  0.00016837881412357092
Valid Loss:  0.0003436981642153114
Epoch:  207  	Training Loss: 0.0002828524447977543
Test Loss:  0.00016771926311776042
Valid Loss:  0.0003427029005251825
Epoch:  208  	Training Loss: 0.0002819136716425419
Test Loss:  0.00016692467033863068
Valid Loss:  0.0003416883118916303
Epoch:  209  	Training Loss: 0.00028098432812839746
Test Loss:  0.00016634922940284014
Valid Loss:  0.00034071668051183224
Epoch:  210  	Training Loss: 0.0002800598740577698
Test Loss:  0.00016568409046158195
Valid Loss:  0.00033974117832258344
Epoch:  211  	Training Loss: 0.0002791467122733593
Test Loss:  0.00016499648336321115
Valid Loss:  0.00033876922680065036
Epoch:  212  	Training Loss: 0.0002782461524475366
Test Loss:  0.00016000062169041485
Valid Loss:  0.0003342817071825266
Epoch:  213  	Training Loss: 0.0002753666485659778
Test Loss:  0.00015754479682072997
Valid Loss:  0.0003317482187412679
Epoch:  214  	Training Loss: 0.00027385959401726723
Test Loss:  0.000156745474669151
Valid Loss:  0.00033056436222977936
Epoch:  215  	Training Loss: 0.0002724517253227532
Test Loss:  0.00015528408403042704
Valid Loss:  0.00032897520577535033
Epoch:  216  	Training Loss: 0.0002710885601118207
Test Loss:  0.00015421141870319843
Valid Loss:  0.00032748671947047114
Epoch:  217  	Training Loss: 0.0002697605814319104
Test Loss:  0.0001531653688289225
Valid Loss:  0.00032615172676742077
Epoch:  218  	Training Loss: 0.00026848193374462426
Test Loss:  0.00015218128100968897
Valid Loss:  0.00032471309532411397
Epoch:  219  	Training Loss: 0.00026723433984443545
Test Loss:  0.00015135521243792027
Valid Loss:  0.00032358389580622315
Epoch:  220  	Training Loss: 0.0002660214086063206
Test Loss:  0.0001504155370639637
Valid Loss:  0.0003221655497327447
Epoch:  221  	Training Loss: 0.00026481872191652656
Test Loss:  0.00014945707516744733
Valid Loss:  0.0003208927228115499
Epoch:  222  	Training Loss: 0.0002636569843161851
Test Loss:  0.00015279161743819714
Valid Loss:  0.0003212418232578784
Epoch:  223  	Training Loss: 0.0002634543925523758
Test Loss:  0.00015290601004380733
Valid Loss:  0.0003210843715351075
Epoch:  224  	Training Loss: 0.00026335494476370513
Test Loss:  0.00015405190060846508
Valid Loss:  0.00032119336538016796
Epoch:  225  	Training Loss: 0.00026330308173783123
Test Loss:  0.0001545801351312548
Valid Loss:  0.000321223255014047
Epoch:  226  	Training Loss: 0.0002632754039950669
Test Loss:  0.00015482005255762488
Valid Loss:  0.0003212113515473902
Epoch:  227  	Training Loss: 0.0002632530522532761
Test Loss:  0.00015492724196519703
Valid Loss:  0.0003211784060113132
Epoch:  228  	Training Loss: 0.00026324065402150154
Test Loss:  0.0001553581387270242
Valid Loss:  0.0003212331503164023
Epoch:  229  	Training Loss: 0.0002632305258885026
Test Loss:  0.00015555339632555842
Valid Loss:  0.00032125008874572814
Epoch:  230  	Training Loss: 0.00026322377379983664
Test Loss:  0.00015564009663648903
Valid Loss:  0.0003212488372810185
Epoch:  231  	Training Loss: 0.00026321804034523666
Test Loss:  0.0001556773786433041
Valid Loss:  0.00032123952405527234
Epoch:  232  	Training Loss: 0.0002632125688251108
Test Loss:  0.00015553575940430164
Valid Loss:  0.0003202857915312052
Epoch:  233  	Training Loss: 0.00026227126363664865
Test Loss:  0.00015523735783062875
Valid Loss:  0.00031935583683662117
Epoch:  234  	Training Loss: 0.000261368986684829
Test Loss:  0.00015484522737096995
Valid Loss:  0.0003184503293596208
Epoch:  235  	Training Loss: 0.00026050006272271276
Test Loss:  0.0001543999824207276
Valid Loss:  0.0003175675228703767
Epoch:  236  	Training Loss: 0.0002596577978692949
Test Loss:  0.00015392826753668487
Valid Loss:  0.00031670776661485434
Epoch:  237  	Training Loss: 0.0002588406787253916
Test Loss:  0.00015344926214311272
Valid Loss:  0.0003158673644065857
Epoch:  238  	Training Loss: 0.0002580465516075492
Test Loss:  0.00015297062054742128
Valid Loss:  0.0003150497213937342
Epoch:  239  	Training Loss: 0.00025727355387061834
Test Loss:  0.0001524999679531902
Valid Loss:  0.00031425320776179433
Epoch:  240  	Training Loss: 0.0002565206086728722
Test Loss:  0.0001520410878583789
Valid Loss:  0.00031347712501883507
Epoch:  241  	Training Loss: 0.0002557864645496011
Test Loss:  0.0001515967451268807
Valid Loss:  0.00031272071646526456
Epoch:  242  	Training Loss: 0.0002550707140471786
Test Loss:  0.00014997675316408277
Valid Loss:  0.00031137504265643656
Epoch:  243  	Training Loss: 0.0002538622939027846
Test Loss:  0.00014846731210127473
Valid Loss:  0.00031008891528472304
Epoch:  244  	Training Loss: 0.0002527023898437619
Test Loss:  0.00014705504872836173
Valid Loss:  0.00030885825981386006
Epoch:  245  	Training Loss: 0.00025158762582577765
Test Loss:  0.0001457274192944169
Valid Loss:  0.00030767940916121006
Epoch:  246  	Training Loss: 0.00025051666307263076
Test Loss:  0.00014447563444264233
Valid Loss:  0.0003065497148782015
Epoch:  247  	Training Loss: 0.0002494871732778847
Test Loss:  0.0001432916906196624
Valid Loss:  0.0003054661792702973
Epoch:  248  	Training Loss: 0.0002484977012500167
Test Loss:  0.0001421699271304533
Valid Loss:  0.0003044236218556762
Epoch:  249  	Training Loss: 0.0002475468209013343
Test Loss:  0.0001411053235642612
Valid Loss:  0.00030341552337631583
Epoch:  250  	Training Loss: 0.00024663202930241823
Test Loss:  0.00014009306323714554
Valid Loss:  0.0003024425823241472
Epoch:  251  	Training Loss: 0.00024575236602686346
Test Loss:  0.00013913022121414542
Valid Loss:  0.0003015075344592333
Epoch:  252  	Training Loss: 0.00024490675423294306
Test Loss:  0.00014061170804779977
Valid Loss:  0.00030117196729406714
Epoch:  253  	Training Loss: 0.00024446050520054996
Test Loss:  0.00014181980805005878
Valid Loss:  0.00030093768145889044
Epoch:  254  	Training Loss: 0.00024414557265117764
Test Loss:  0.00014281398034654558
Valid Loss:  0.00030076492112129927
Epoch:  255  	Training Loss: 0.00024391175247728825
Test Loss:  0.00014362347428686917
Valid Loss:  0.0003006302868016064
Epoch:  256  	Training Loss: 0.00024373164342250675
Test Loss:  0.00014427615678869188
Valid Loss:  0.00030051812063902617
Epoch:  257  	Training Loss: 0.00024358743394259363
Test Loss:  0.00014479737728834152
Valid Loss:  0.0003004221653100103
Epoch:  258  	Training Loss: 0.00024346755526494235
Test Loss:  0.00014520937111228704
Valid Loss:  0.0003003349993377924
Epoch:  259  	Training Loss: 0.00024336398928426206
Test Loss:  0.0001455309975426644
Valid Loss:  0.0003002529265359044
Epoch:  260  	Training Loss: 0.00024327062419615686
Test Loss:  0.00014577852562069893
Valid Loss:  0.0003001740842591971
Epoch:  261  	Training Loss: 0.00024318530631717294
Test Loss:  0.00014596589608117938
Valid Loss:  0.00030009663896635175
Epoch:  262  	Training Loss: 0.00024310467415489256
Test Loss:  0.00014464696869254112
Valid Loss:  0.0002989617350976914
Epoch:  263  	Training Loss: 0.000242085283389315
Test Loss:  0.00014346852549351752
Valid Loss:  0.0002978640259243548
Epoch:  264  	Training Loss: 0.0002410939778201282
Test Loss:  0.00014239961456041783
Valid Loss:  0.0002967964392155409
Epoch:  265  	Training Loss: 0.00024012351059354842
Test Loss:  0.00014142313739284873
Valid Loss:  0.00029575751977972686
Epoch:  266  	Training Loss: 0.0002391748275840655
Test Loss:  0.00014052275219000876
Valid Loss:  0.00029474342591129243
Epoch:  267  	Training Loss: 0.0002382461680099368
Test Loss:  0.00013968547864351422
Valid Loss:  0.0002937519457191229
Epoch:  268  	Training Loss: 0.00023733577108941972
Test Loss:  0.00013890137779526412
Valid Loss:  0.0002927824389189482
Epoch:  269  	Training Loss: 0.0002364433166803792
Test Loss:  0.00013816273713018745
Valid Loss:  0.0002918323443736881
Epoch:  270  	Training Loss: 0.0002355677861487493
Test Loss:  0.0001374626299366355
Valid Loss:  0.0002909016329795122
Epoch:  271  	Training Loss: 0.00023470590531360358
Test Loss:  0.00013679233961738646
Valid Loss:  0.00028998591005802155
 55%|█████▍    | 273/500 [03:25<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:25<02:20,  1.61it/s] 55%|█████▌    | 277/500 [03:25<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:25<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:32<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:32<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:32<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:32<01:36,  2.22it/s] 58%|█████▊    | 289/500 [03:32<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:38<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:39<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:39<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:39<01:32,  2.18it/s] 60%|█████▉    | 299/500 [03:39<01:09,  2.88it/s] 60%|██████    | 301/500 [03:45<03:59,  1.20s/it] 61%|██████    | 303/500 [03:46<02:51,  1.15it/s] 61%|██████    | 305/500 [03:46<02:03,  1.58it/s] 61%|██████▏   | 307/500 [03:46<01:30,  2.13it/s] 62%|██████▏   | 309/500 [03:46<01:07,  2.82it/s] 62%|██████▏   | 311/500 [03:53<03:51,  1.22s/it] 63%|██████▎   | 313/500 [03:53<02:44,  1.14it/s] 63%|██████▎   | 315/500 [03:53<01:57,  1.57it/s] 63%|██████▎   | 317/500 [03:53<01:24,  2.15it/s] 64%|██████▍   | 319/500 [03:53<01:02,  2.90it/s] 64%|██████▍   | 321/500 [03:59<03:30,  1.18s/it] 65%|██████▍   | 323/500 [04:00<02:29,  1.18it/s] 65%|██████▌   | 325/500 [04:00<01:46,  1.64it/s] 65%|██████▌   | 327/500 [04:00<01:17,  2.23it/s] 66%|██████▌   | 329/500 [04:00<00:57,  2.98it/s] 66%|██████▌   | 331/500 [04:06<03:19,  1.18s/it] 67%|██████▋   | 333/500 [04:06<02:21,  1.18it/s] 67%|██████▋   | 335/500 [04:07<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:07<01:13,  2.22it/s]Epoch:  272  	Training Loss: 0.00023385649546980858
Test Loss:  0.0001373152481392026
Valid Loss:  0.00028981282957829535
Epoch:  273  	Training Loss: 0.00023371088900603354
Test Loss:  0.0001376494183205068
Valid Loss:  0.00028964021475985646
Epoch:  274  	Training Loss: 0.00023357770987786353
Test Loss:  0.0001378558954456821
Valid Loss:  0.00028946783277206123
Epoch:  275  	Training Loss: 0.00023345075896941125
Test Loss:  0.00013797581777907908
Valid Loss:  0.0002893211494665593
Epoch:  276  	Training Loss: 0.0002333313605049625
Test Loss:  0.00013808987569063902
Valid Loss:  0.0002891870972234756
Epoch:  277  	Training Loss: 0.00023322892957367003
Test Loss:  0.0001382024202030152
Valid Loss:  0.00028906535590067506
Epoch:  278  	Training Loss: 0.00023313731071539223
Test Loss:  0.0001383173221256584
Valid Loss:  0.0002889550232794136
Epoch:  279  	Training Loss: 0.00023305155627895147
Test Loss:  0.00013838401355315
Valid Loss:  0.000288843410089612
Epoch:  280  	Training Loss: 0.00023296696599572897
Test Loss:  0.0001384178758598864
Valid Loss:  0.0002887309528887272
Epoch:  281  	Training Loss: 0.0002328841364942491
Test Loss:  0.0001384821953251958
Valid Loss:  0.0002886312431655824
Epoch:  282  	Training Loss: 0.00023280720051843673
Test Loss:  0.00013654363283421844
Valid Loss:  0.0002873993362300098
Epoch:  283  	Training Loss: 0.00023179403797257692
Test Loss:  0.00013507824041880667
Valid Loss:  0.00028627627762034535
Epoch:  284  	Training Loss: 0.00023084841086529195
Test Loss:  0.00013393969857133925
Valid Loss:  0.0002852210309356451
Epoch:  285  	Training Loss: 0.00022994483879301697
Test Loss:  0.00013301799481268972
Valid Loss:  0.00028421240858733654
Epoch:  286  	Training Loss: 0.00022906849335413426
Test Loss:  0.0001322417228948325
Valid Loss:  0.00028323460719548166
Epoch:  287  	Training Loss: 0.0002282113127876073
Test Loss:  0.00013156502973288298
Valid Loss:  0.0002822801179718226
Epoch:  288  	Training Loss: 0.00022736926621291786
Test Loss:  0.00013095767644699663
Valid Loss:  0.0002813445753417909
Epoch:  289  	Training Loss: 0.00022653982159681618
Test Loss:  0.00013039878103882074
Valid Loss:  0.0002804247778840363
Epoch:  290  	Training Loss: 0.00022572281886823475
Test Loss:  0.0001299668656429276
Valid Loss:  0.0002795468899421394
Epoch:  291  	Training Loss: 0.00022493409051094204
Test Loss:  0.00012953173427376896
Valid Loss:  0.0002786783443298191
Epoch:  292  	Training Loss: 0.0002241559122921899
Test Loss:  0.0001305015612160787
Valid Loss:  0.00027861312264576554
Epoch:  293  	Training Loss: 0.00022403102775570005
Test Loss:  0.00013109712745063007
Valid Loss:  0.0002785397518891841
Epoch:  294  	Training Loss: 0.00022395243286155164
Test Loss:  0.00013145917910151184
Valid Loss:  0.00027845436125062406
Epoch:  295  	Training Loss: 0.00022389389050658792
Test Loss:  0.00013167003635317087
Valid Loss:  0.0002783609088510275
Epoch:  296  	Training Loss: 0.00022384553449228406
Test Loss:  0.00013178575318306684
Valid Loss:  0.0002782632363960147
Epoch:  297  	Training Loss: 0.0002238033921457827
Test Loss:  0.00013184150157030672
Valid Loss:  0.000278164487099275
Epoch:  298  	Training Loss: 0.0002237652224721387
Test Loss:  0.00013186012802179903
Valid Loss:  0.00027808049344457686
Epoch:  299  	Training Loss: 0.00022373053070623428
Test Loss:  0.00013185660645831376
Valid Loss:  0.0002780163777060807
Epoch:  300  	Training Loss: 0.0002237012959085405
Test Loss:  0.00013208469317760319
Valid Loss:  0.00027798564406111836
Epoch:  301  	Training Loss: 0.000223680428462103
Test Loss:  0.00013222062261775136
Valid Loss:  0.00027795048663392663
Epoch:  302  	Training Loss: 0.00022366264602169394
Test Loss:  0.00013161939568817616
Valid Loss:  0.00027770205633714795
Epoch:  303  	Training Loss: 0.00022354349493980408
Test Loss:  0.00013128900900483131
Valid Loss:  0.00027749346918426454
Epoch:  304  	Training Loss: 0.00022343278396874666
Test Loss:  0.00013109321298543364
Valid Loss:  0.00027730315923690796
Epoch:  305  	Training Loss: 0.00022332515800371766
Test Loss:  0.00013096511247567832
Valid Loss:  0.0002771363942883909
Epoch:  306  	Training Loss: 0.0002232185797765851
Test Loss:  0.00013087120896670967
Valid Loss:  0.00027700766804628074
Epoch:  307  	Training Loss: 0.00022312185319606215
Test Loss:  0.00013065116945654154
Valid Loss:  0.0002768771955743432
Epoch:  308  	Training Loss: 0.00022304091544356197
Test Loss:  0.00013084539386909455
Valid Loss:  0.000276801991276443
Epoch:  309  	Training Loss: 0.00022297483519650996
Test Loss:  0.00013068245607428253
Valid Loss:  0.00027669043629430234
Epoch:  310  	Training Loss: 0.00022290638298727572
Test Loss:  0.00013057555770501494
Valid Loss:  0.00027658528415486217
Epoch:  311  	Training Loss: 0.00022284452279563993
Test Loss:  0.00013083129306323826
Valid Loss:  0.0002765297540463507
Epoch:  312  	Training Loss: 0.0002227879740530625
Test Loss:  0.0001298782299272716
Valid Loss:  0.00027545588091015816
Epoch:  313  	Training Loss: 0.00022177386563271284
Test Loss:  0.0001290659129153937
Valid Loss:  0.0002744239754974842
Epoch:  314  	Training Loss: 0.00022079559857957065
Test Loss:  0.00012835758388973773
Valid Loss:  0.00027342757675796747
Epoch:  315  	Training Loss: 0.00021984650811646134
Test Loss:  0.0001277033588849008
Valid Loss:  0.0002724566147662699
Epoch:  316  	Training Loss: 0.00021892093354836106
Test Loss:  0.00012711524323094636
Valid Loss:  0.0002715116715990007
Epoch:  317  	Training Loss: 0.00021801736147608608
Test Loss:  0.00012657864135690033
Valid Loss:  0.0002705897204577923
Epoch:  318  	Training Loss: 0.00021713455498684198
Test Loss:  0.00012608166434802115
Valid Loss:  0.0002696886658668518
Epoch:  319  	Training Loss: 0.00021626918169204146
Test Loss:  0.00012561488256324083
Valid Loss:  0.00026880583027377725
Epoch:  320  	Training Loss: 0.00021542064496316016
Test Loss:  0.00012517214054241776
Valid Loss:  0.00026794057339429855
Epoch:  321  	Training Loss: 0.00021458658738993108
Test Loss:  0.0001247474574483931
Valid Loss:  0.0002670902758836746
Epoch:  322  	Training Loss: 0.00021376629592850804
Test Loss:  0.0001245570892933756
Valid Loss:  0.0002664625062607229
Epoch:  323  	Training Loss: 0.0002131620276486501
Test Loss:  0.0001243437873199582
Valid Loss:  0.0002658423618413508
Epoch:  324  	Training Loss: 0.00021256647596601397
Test Loss:  0.000124126992886886
Valid Loss:  0.00026523214182816446
Epoch:  325  	Training Loss: 0.00021197766182012856
Test Loss:  0.00012387271272018552
Valid Loss:  0.00026462547248229384
Epoch:  326  	Training Loss: 0.00021139581804163754
Test Loss:  0.00012360834807623178
Valid Loss:  0.00026402610819786787
Epoch:  327  	Training Loss: 0.00021082008606754243
Test Loss:  0.0001233550428878516
Valid Loss:  0.00026343532954342663
Epoch:  328  	Training Loss: 0.00021025091700721532
Test Loss:  0.00012309651356190443
Valid Loss:  0.00026285176863893867
Epoch:  329  	Training Loss: 0.00020968890748918056
Test Loss:  0.00012283120304346085
Valid Loss:  0.00026227484340779483
Epoch:  330  	Training Loss: 0.00020913308253511786
Test Loss:  0.00012256433547008783
Valid Loss:  0.00026170496130362153
Epoch:  331  	Training Loss: 0.0002085827582050115
Test Loss:  0.000122294484754093
Valid Loss:  0.0002611412783153355
Epoch:  332  	Training Loss: 0.00020803816732950509
Test Loss:  0.00012240101932547987
Valid Loss:  0.0002611319359857589
Epoch:  333  	Training Loss: 0.00020803077495656908
Test Loss:  0.00012248914572410285
Valid Loss:  0.000261123786913231
Epoch:  334  	Training Loss: 0.0002080239646602422
Test Loss:  0.00012256178888492286
Valid Loss:  0.00026111758779734373
Epoch:  335  	Training Loss: 0.00020801824575755745
Test Loss:  0.00012262153904885054
Valid Loss:  0.00026111165061593056
Epoch:  336  	Training Loss: 0.0002080130943795666
Test Loss:  0.00012267485726624727
Valid Loss:  0.00026110760518349707
Epoch:  337  	Training Loss: 0.00020800912170670927
Test Loss:  0.00012271855666767806
Valid Loss:  0.0002611026866361499
Epoch:  338  	Training Loss: 0.00020800568745471537
Test Loss:  0.00012275847257114947
Valid Loss:  0.00026109901955351233
 68%|██████▊   | 339/500 [04:07<00:54,  2.98it/s] 68%|██████▊   | 341/500 [04:13<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:13<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:13<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:14<01:08,  2.25it/s] 70%|██████▉   | 349/500 [04:14<00:49,  3.02it/s] 70%|███████   | 351/500 [04:20<02:55,  1.18s/it] 71%|███████   | 353/500 [04:20<02:05,  1.18it/s] 71%|███████   | 355/500 [04:20<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:20<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:21<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:27<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:27<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:27<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:27<01:00,  2.18it/s] 74%|███████▍  | 369/500 [04:27<00:45,  2.88it/s] 74%|███████▍  | 371/500 [04:34<02:36,  1.21s/it] 75%|███████▍  | 373/500 [04:34<01:50,  1.15it/s] 75%|███████▌  | 375/500 [04:34<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:34<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:34<00:41,  2.93it/s] 76%|███████▌  | 381/500 [04:41<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:41<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:41<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:41<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:41<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:47<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:48<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:48<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:48<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:48<00:33,  3.03it/s] 80%|████████  | 401/500 [04:54<01:55,  1.17s/it] 81%|████████  | 403/500 [04:54<01:21,  1.19it/s] 81%|████████  | 405/500 [04:55<00:57,  1.64it/s]Epoch:  339  	Training Loss: 0.00020800312631763518
Test Loss:  0.00012279138900339603
Valid Loss:  0.00026109570171684027
Epoch:  340  	Training Loss: 0.00020800088532269
Test Loss:  0.00012281755334697664
Valid Loss:  0.0002610919764265418
Epoch:  341  	Training Loss: 0.0002079986297758296
Test Loss:  0.00012283891555853188
Valid Loss:  0.000261088163824752
Epoch:  342  	Training Loss: 0.00020799649064429104
Test Loss:  0.0001228163600899279
Valid Loss:  0.000261053501162678
Epoch:  343  	Training Loss: 0.00020796444732695818
Test Loss:  0.0001227944012498483
Valid Loss:  0.00026101883850060403
Epoch:  344  	Training Loss: 0.00020793246221728623
Test Loss:  0.0001227724424097687
Valid Loss:  0.0002609838848002255
Epoch:  345  	Training Loss: 0.00020790065173059702
Test Loss:  0.00012275054177735
Valid Loss:  0.00026094919303432107
Epoch:  346  	Training Loss: 0.00020786875393241644
Test Loss:  0.00012272928142920136
Valid Loss:  0.00026091383188031614
Epoch:  347  	Training Loss: 0.00020783668151125312
Test Loss:  0.00012270789011381567
Valid Loss:  0.0002608792274259031
Epoch:  348  	Training Loss: 0.0002078050165437162
Test Loss:  0.0001226869208039716
Valid Loss:  0.0002608447102829814
Epoch:  349  	Training Loss: 0.00020777314784936607
Test Loss:  0.00012266638805158436
Valid Loss:  0.0002608092618174851
Epoch:  350  	Training Loss: 0.00020774122094735503
Test Loss:  0.0001226455788128078
Valid Loss:  0.0002607750939205289
Epoch:  351  	Training Loss: 0.0002077095559798181
Test Loss:  0.00012262555537745357
Valid Loss:  0.0002607402275316417
Epoch:  352  	Training Loss: 0.0002076775417663157
Test Loss:  0.00012233364395797253
Valid Loss:  0.0002601143787615001
Epoch:  353  	Training Loss: 0.00020709510135930032
Test Loss:  0.00012205165694467723
Valid Loss:  0.0002594997058622539
Epoch:  354  	Training Loss: 0.00020652220700867474
Test Loss:  0.00012177536700619385
Valid Loss:  0.0002588942588772625
Epoch:  355  	Training Loss: 0.00020595404203049839
Test Loss:  0.00012150826660217717
Valid Loss:  0.0002582983288448304
Epoch:  356  	Training Loss: 0.00020539521938189864
Test Loss:  0.0001212497882079333
Valid Loss:  0.00025771241053007543
Epoch:  357  	Training Loss: 0.00020484544802457094
Test Loss:  0.00012099901505280286
Valid Loss:  0.00025713699869811535
Epoch:  358  	Training Loss: 0.00020430400036275387
Test Loss:  0.00012075645645381883
Valid Loss:  0.0002565706381574273
Epoch:  359  	Training Loss: 0.00020377108012326062
Test Loss:  0.00012052111560478806
Valid Loss:  0.0002560129214543849
Epoch:  360  	Training Loss: 0.0002032463380601257
Test Loss:  0.00012029229401377961
Valid Loss:  0.00025546419783495367
Epoch:  361  	Training Loss: 0.00020272936671972275
Test Loss:  0.00012007083569187671
Valid Loss:  0.00025492417626082897
Epoch:  362  	Training Loss: 0.0002022200933424756
Test Loss:  0.00011962197459070012
Valid Loss:  0.00025457737501710653
Epoch:  363  	Training Loss: 0.0002018887607846409
Test Loss:  0.00011926853767363355
Valid Loss:  0.0002542531583458185
Epoch:  364  	Training Loss: 0.00020157117978669703
Test Loss:  0.00011898746015504003
Valid Loss:  0.00025394957629032433
Epoch:  365  	Training Loss: 0.00020126797608099878
Test Loss:  0.00011876259668497369
Valid Loss:  0.0002536629908718169
Epoch:  366  	Training Loss: 0.0002009760937653482
Test Loss:  0.00011857820209115744
Valid Loss:  0.00025339130661450326
Epoch:  367  	Training Loss: 0.00020069416495971382
Test Loss:  0.00011842165258713067
Valid Loss:  0.00025313449441455305
Epoch:  368  	Training Loss: 0.00020042269898112863
Test Loss:  0.00011829058348666877
Valid Loss:  0.00025288903270848095
Epoch:  369  	Training Loss: 0.00020016060443595052
Test Loss:  0.00011817993072327226
Valid Loss:  0.0002526546595618129
Epoch:  370  	Training Loss: 0.00019990734290331602
Test Loss:  0.0001180842227768153
Valid Loss:  0.0002524296869523823
Epoch:  371  	Training Loss: 0.00019966064428444952
Test Loss:  0.00011800226639024913
Valid Loss:  0.00025221399846486747
Epoch:  372  	Training Loss: 0.00019942155631724745
Test Loss:  0.00011796462058555335
Valid Loss:  0.0002516027307137847
Epoch:  373  	Training Loss: 0.00019881677872035652
Test Loss:  0.0001178843667730689
Valid Loss:  0.000251007208134979
Epoch:  374  	Training Loss: 0.0001982272369787097
Test Loss:  0.00011776925384765491
Valid Loss:  0.0002504268195480108
Epoch:  375  	Training Loss: 0.0001976505882339552
Test Loss:  0.0001176273071905598
Valid Loss:  0.00024985827622003853
Epoch:  376  	Training Loss: 0.00019708488252945244
Test Loss:  0.00011746467498596758
Valid Loss:  0.0002493016654625535
Epoch:  377  	Training Loss: 0.00019652911578305066
Test Loss:  0.00011728632671292871
Valid Loss:  0.0002487543097231537
Epoch:  378  	Training Loss: 0.00019598209473770112
Test Loss:  0.00011709595855791122
Valid Loss:  0.0002482132404111326
Epoch:  379  	Training Loss: 0.00019544173846952617
Test Loss:  0.00011688889935612679
Valid Loss:  0.00024767982540652156
Epoch:  380  	Training Loss: 0.00019490727572701871
Test Loss:  0.00011667220678646117
Valid Loss:  0.00024715453037060797
Epoch:  381  	Training Loss: 0.00019438055460341275
Test Loss:  0.00011645035556284711
Valid Loss:  0.000246634881477803
Epoch:  382  	Training Loss: 0.00019386110943742096
Test Loss:  0.00011580514546949416
Valid Loss:  0.000246476469328627
Epoch:  383  	Training Loss: 0.00019372403039596975
Test Loss:  0.00011552781506907195
Valid Loss:  0.00024636235320940614
Epoch:  384  	Training Loss: 0.00019360528676770627
Test Loss:  0.00011533429642440751
Valid Loss:  0.00024625827791169286
Epoch:  385  	Training Loss: 0.00019349073409102857
Test Loss:  0.00011519642430357635
Valid Loss:  0.00024616101291030645
Epoch:  386  	Training Loss: 0.00019337915000505745
Test Loss:  0.00011509576870594174
Valid Loss:  0.00024606616352684796
Epoch:  387  	Training Loss: 0.00019326881738379598
Test Loss:  0.00011501884728204459
Valid Loss:  0.0002459722454659641
Epoch:  388  	Training Loss: 0.0001931582810357213
Test Loss:  0.00011495617218315601
Valid Loss:  0.00024587922962382436
Epoch:  389  	Training Loss: 0.00019304640591144562
Test Loss:  0.00011493780766613781
Valid Loss:  0.00024579092860221863
Epoch:  390  	Training Loss: 0.00019293568038847297
Test Loss:  0.00011491622717585415
Valid Loss:  0.0002457030932419002
Epoch:  391  	Training Loss: 0.00019282617722637951
Test Loss:  0.0001147085422417149
Valid Loss:  0.00024560492602176964
Epoch:  392  	Training Loss: 0.0001927204430103302
Test Loss:  0.00011519579129526392
Valid Loss:  0.0002450551255606115
Epoch:  393  	Training Loss: 0.00019223176059313118
Test Loss:  0.00011512573109939694
Valid Loss:  0.00024453969672322273
Epoch:  394  	Training Loss: 0.00019178645743522793
Test Loss:  0.00011512075434438884
Valid Loss:  0.00024406251031905413
Epoch:  395  	Training Loss: 0.00019136290939059108
Test Loss:  0.00011497853847686201
Valid Loss:  0.00024359981762245297
Epoch:  396  	Training Loss: 0.0001909506827360019
Test Loss:  0.00011477999214548618
Valid Loss:  0.0002431456814520061
Epoch:  397  	Training Loss: 0.00019054461154155433
Test Loss:  0.00011453770275693387
Valid Loss:  0.00024269956338685006
Epoch:  398  	Training Loss: 0.00019014396821148694
Test Loss:  0.00011428246216382831
Valid Loss:  0.0002422585093881935
Epoch:  399  	Training Loss: 0.0001897478650789708
Test Loss:  0.00011401843221392483
Valid Loss:  0.00024182455672416836
Epoch:  400  	Training Loss: 0.00018935689877253026
Test Loss:  0.00011375352187315002
Valid Loss:  0.0002413973561488092
Epoch:  401  	Training Loss: 0.00018897019617725164
Test Loss:  0.00011349131818860769
Valid Loss:  0.0002409759326837957
Epoch:  402  	Training Loss: 0.00018858809198718518
Test Loss:  0.0001134592603193596
Valid Loss:  0.00024082689196802676
Epoch:  403  	Training Loss: 0.00018850536434911191
Test Loss:  0.00011340540368109941
Valid Loss:  0.00024068121274467558
Epoch:  404  	Training Loss: 0.00018842554709408432
Test Loss:  0.00011333709699101746
Valid Loss:  0.00024053936067502946
Epoch:  405  	Training Loss: 0.00018834733054973185
Test Loss:  0.00011325848026899621
Valid Loss:  0.0002403999533271417
 81%|████████▏ | 407/500 [04:55<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:55<00:30,  3.02it/s] 82%|████████▏ | 411/500 [05:01<01:44,  1.18s/it] 83%|████████▎ | 413/500 [05:01<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:01<00:52,  1.63it/s] 83%|████████▎ | 417/500 [05:02<00:37,  2.23it/s] 84%|████████▍ | 419/500 [05:02<00:26,  3.01it/s] 84%|████████▍ | 421/500 [05:08<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:08<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:08<00:47,  1.59it/s] 85%|████████▌ | 427/500 [05:09<00:33,  2.15it/s] 86%|████████▌ | 429/500 [05:09<00:24,  2.84it/s] 86%|████████▌ | 431/500 [05:15<01:23,  1.20s/it] 87%|████████▋ | 433/500 [05:15<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:15<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:15<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:16<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:22<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:22<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:22<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:22<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:23<00:17,  2.95it/s] 90%|█████████ | 451/500 [05:29<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:29<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:29<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:29<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:29<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:36<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:36<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:36<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:36<00:15,  2.16it/s] 94%|█████████▍| 469/500 [05:36<00:10,  2.88it/s] 94%|█████████▍| 471/500 [05:43<00:34,  1.20s/it]Epoch:  406  	Training Loss: 0.0001882710785139352
Test Loss:  0.0001131736789830029
Valid Loss:  0.00024026280152611434
Epoch:  407  	Training Loss: 0.0001882001815829426
Test Loss:  0.0001131472090492025
Valid Loss:  0.00024014261725824326
Epoch:  408  	Training Loss: 0.00018813871429301798
Test Loss:  0.00011310425179544836
Valid Loss:  0.00024002438294701278
Epoch:  409  	Training Loss: 0.0001880782947409898
Test Loss:  0.00011305048246867955
Valid Loss:  0.00023990785120986402
Epoch:  410  	Training Loss: 0.00018801895203068852
Test Loss:  0.00011298893514322117
Valid Loss:  0.0002397932403255254
Epoch:  411  	Training Loss: 0.00018796039512380958
Test Loss:  0.00011292230919934809
Valid Loss:  0.00023967995366547257
Epoch:  412  	Training Loss: 0.0001879027404356748
Test Loss:  0.00011296624143142253
Valid Loss:  0.0002395687042735517
Epoch:  413  	Training Loss: 0.0001878512994153425
Test Loss:  0.00011298113531665877
Valid Loss:  0.0002394587208982557
Epoch:  414  	Training Loss: 0.00018780042591970414
Test Loss:  0.0001129754600697197
Valid Loss:  0.0002393494505668059
Epoch:  415  	Training Loss: 0.00018775052740238607
Test Loss:  0.00011295513832010329
Valid Loss:  0.00023924096603877842
Epoch:  416  	Training Loss: 0.00018770090537145734
Test Loss:  0.00011292505951132625
Valid Loss:  0.00023913339828141034
Epoch:  417  	Training Loss: 0.00018765171989798546
Test Loss:  0.00011288838868495077
Valid Loss:  0.00023902603425085545
Epoch:  418  	Training Loss: 0.0001876026508398354
Test Loss:  0.00011284665379207581
Valid Loss:  0.0002389188448432833
Epoch:  419  	Training Loss: 0.0001875541202025488
Test Loss:  0.0001128017611335963
Valid Loss:  0.00023881287779659033
Epoch:  420  	Training Loss: 0.00018750570598058403
Test Loss:  0.00011275475844740868
Valid Loss:  0.0002387066197115928
Epoch:  421  	Training Loss: 0.00018745767010841519
Test Loss:  0.00011270616960246116
Valid Loss:  0.00023860199144110084
Epoch:  422  	Training Loss: 0.0001874096051324159
Test Loss:  0.00011212661047466099
Valid Loss:  0.00023828045232221484
Epoch:  423  	Training Loss: 0.00018712415476329625
Test Loss:  0.00011174063547514379
Valid Loss:  0.00023798472830094397
Epoch:  424  	Training Loss: 0.00018685366376303136
Test Loss:  0.00011146911128889769
Valid Loss:  0.0002377047057962045
Epoch:  425  	Training Loss: 0.0001865897502284497
Test Loss:  0.00011126695608254522
Valid Loss:  0.00023742421763017774
Epoch:  426  	Training Loss: 0.00018632943101692945
Test Loss:  0.00011110572086181492
Valid Loss:  0.00023714476265013218
Epoch:  427  	Training Loss: 0.00018607005767989904
Test Loss:  0.00011096670641563833
Valid Loss:  0.00023686620988883078
Epoch:  428  	Training Loss: 0.0001858106697909534
Test Loss:  0.00011084383004345
Valid Loss:  0.0002365886466577649
Epoch:  429  	Training Loss: 0.00018555301357991993
Test Loss:  0.00011073077621404082
Valid Loss:  0.00023631364456377923
Epoch:  430  	Training Loss: 0.00018529889348428696
Test Loss:  0.00011068294406868517
Valid Loss:  0.00023604313901159912
Epoch:  431  	Training Loss: 0.00018505012849345803
Test Loss:  0.00011061722761951387
Valid Loss:  0.00023577251704409719
Epoch:  432  	Training Loss: 0.0001848033571150154
Test Loss:  0.00011062336852774024
Valid Loss:  0.00023537149536423385
Epoch:  433  	Training Loss: 0.00018442807777319103
Test Loss:  0.00011054897913709283
Valid Loss:  0.0002349798014620319
Epoch:  434  	Training Loss: 0.0001840573677327484
Test Loss:  0.00011043316771974787
Valid Loss:  0.00023459387011826038
Epoch:  435  	Training Loss: 0.00018369055760558695
Test Loss:  0.00011029656889149919
Valid Loss:  0.00023421151854563504
Epoch:  436  	Training Loss: 0.0001833269780036062
Test Loss:  0.00011014897609129548
Valid Loss:  0.00023383309599012136
Epoch:  437  	Training Loss: 0.00018296611960977316
Test Loss:  0.00010999613004969433
Valid Loss:  0.00023345679801423103
Epoch:  438  	Training Loss: 0.0001826080260798335
Test Loss:  0.00010984074469888583
Valid Loss:  0.00023308364325203001
Epoch:  439  	Training Loss: 0.0001822532940423116
Test Loss:  0.00010968365677399561
Valid Loss:  0.00023271251120604575
Epoch:  440  	Training Loss: 0.00018190087575931102
Test Loss:  0.00010951758304145187
Valid Loss:  0.00023234530817717314
Epoch:  441  	Training Loss: 0.0001815499272197485
Test Loss:  0.00010935436876025051
Valid Loss:  0.00023197979317046702
Epoch:  442  	Training Loss: 0.00018120172899216413
Test Loss:  0.0001095602783607319
Valid Loss:  0.00023185243480838835
Epoch:  443  	Training Loss: 0.00018113690020982176
Test Loss:  0.00010965509864035994
Valid Loss:  0.00023173367662820965
Epoch:  444  	Training Loss: 0.00018107693176716566
Test Loss:  0.00010968423157464713
Valid Loss:  0.00023162036086432636
Epoch:  445  	Training Loss: 0.00018101904424838722
Test Loss:  0.00010967384878313169
Valid Loss:  0.00023150979541242123
Epoch:  446  	Training Loss: 0.00018096218991559
Test Loss:  0.00010964005923597142
Valid Loss:  0.00023140270786825567
Epoch:  447  	Training Loss: 0.00018090594676323235
Test Loss:  0.00010959296196233481
Valid Loss:  0.00023129655164666474
Epoch:  448  	Training Loss: 0.00018084968905895948
Test Loss:  0.00010954849858535454
Valid Loss:  0.00023118816898204386
Epoch:  449  	Training Loss: 0.00018079175788443536
Test Loss:  0.00010949352872557938
Valid Loss:  0.00023108057212084532
Epoch:  450  	Training Loss: 0.0001807342196116224
Test Loss:  0.00010943225788651034
Valid Loss:  0.00023097411030903459
Epoch:  451  	Training Loss: 0.00018067705968860537
Test Loss:  0.0001093675964511931
Valid Loss:  0.0002308683324372396
Epoch:  452  	Training Loss: 0.00018062032177112997
Test Loss:  0.00010867610399145633
Valid Loss:  0.00023062746913637966
Epoch:  453  	Training Loss: 0.00018037445261143148
Test Loss:  0.0001083168390323408
Valid Loss:  0.00023040070664137602
Epoch:  454  	Training Loss: 0.00018015548994299024
Test Loss:  0.00010813107655849308
Valid Loss:  0.00023017916828393936
Epoch:  455  	Training Loss: 0.00017994677182286978
Test Loss:  0.00010803517216118053
Valid Loss:  0.00022995892504695803
Epoch:  456  	Training Loss: 0.00017974062939174473
Test Loss:  0.00010798674338730052
Valid Loss:  0.00022974025341682136
Epoch:  457  	Training Loss: 0.00017953735368791968
Test Loss:  0.00010796696005854756
Valid Loss:  0.00022952475410420448
Epoch:  458  	Training Loss: 0.00017933809431269765
Test Loss:  0.00010797166760312393
Valid Loss:  0.00022931024432182312
Epoch:  459  	Training Loss: 0.00017914228374138474
Test Loss:  0.00010798195580719039
Valid Loss:  0.00022909947438165545
Epoch:  460  	Training Loss: 0.00017894996562972665
Test Loss:  0.00010799424489960074
Valid Loss:  0.00022889164392836392
Epoch:  461  	Training Loss: 0.00017876029596664011
Test Loss:  0.00010801015741890296
Valid Loss:  0.00022868753876537085
Epoch:  462  	Training Loss: 0.0001785744389053434
Test Loss:  0.00010786757047753781
Valid Loss:  0.00022827401699032634
Epoch:  463  	Training Loss: 0.00017829047283157706
Test Loss:  0.00010765269689727575
Valid Loss:  0.0002278848405694589
Epoch:  464  	Training Loss: 0.00017801753710955381
Test Loss:  0.0001075748514267616
Valid Loss:  0.00022755487589165568
Epoch:  465  	Training Loss: 0.000177752212039195
Test Loss:  0.00010738603305071592
Valid Loss:  0.00022724248992744833
Epoch:  466  	Training Loss: 0.00017748717800714076
Test Loss:  0.00010716808901634067
Valid Loss:  0.0002269369433633983
Epoch:  467  	Training Loss: 0.00017722335178405046
Test Loss:  0.00010695299715735018
Valid Loss:  0.00022662905394099653
Epoch:  468  	Training Loss: 0.000176957284566015
Test Loss:  0.00010672599455574527
Valid Loss:  0.00022632363834418356
Epoch:  469  	Training Loss: 0.00017669297812972218
Test Loss:  0.00010649821342667565
Valid Loss:  0.00022601368254981935
Epoch:  470  	Training Loss: 0.00017643088358454406
Test Loss:  0.00010626946459524333
Valid Loss:  0.00022570282453671098
Epoch:  471  	Training Loss: 0.00017617054982110858
Test Loss:  0.00010604113049339503
Valid Loss:  0.00022539502242580056
Epoch:  472  	Training Loss: 0.00017591188952792436
Test Loss:  0.00010614985512802377
Valid Loss:  0.00022508722031489015 95%|█████████▍| 473/500 [05:43<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:43<00:15,  1.58it/s] 95%|█████████▌| 477/500 [05:43<00:10,  2.14it/s] 96%|█████████▌| 479/500 [05:43<00:07,  2.88it/s] 96%|█████████▌| 481/500 [05:50<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:50<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:50<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:50<00:05,  2.19it/s] 98%|█████████▊| 489/500 [05:50<00:03,  2.95it/s] 98%|█████████▊| 491/500 [05:57<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:57<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:57<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:57<00:01,  2.17it/s]100%|█████████▉| 499/500 [05:57<00:00,  2.90it/s]100%|██████████| 500/500 [05:57<00:00,  1.40it/s]

Epoch:  473  	Training Loss: 0.00017562312132213265
Test Loss:  0.00010620216198731214
Valid Loss:  0.00022479564358945936
Epoch:  474  	Training Loss: 0.00017534045036882162
Test Loss:  0.00010621733235893771
Valid Loss:  0.00022451605764217675
Epoch:  475  	Training Loss: 0.00017506278527434915
Test Loss:  0.00010620293323881924
Valid Loss:  0.00022424566850531846
Epoch:  476  	Training Loss: 0.0001747885689837858
Test Loss:  0.00010616723739076406
Valid Loss:  0.00022398229339160025
Epoch:  477  	Training Loss: 0.00017451801977586
Test Loss:  0.00010611399920890108
Valid Loss:  0.00022372437524609268
Epoch:  478  	Training Loss: 0.00017425016267225146
Test Loss:  0.00010605015268083662
Valid Loss:  0.00022347099729813635
Epoch:  479  	Training Loss: 0.00017398509953636676
Test Loss:  0.00010597424989100546
Valid Loss:  0.00022322338190861046
Epoch:  480  	Training Loss: 0.00017372192814946175
Test Loss:  0.00010588324221316725
Valid Loss:  0.00022298033582046628
Epoch:  481  	Training Loss: 0.00017345970263704658
Test Loss:  0.00010579232912277803
Valid Loss:  0.0002227395452791825
Epoch:  482  	Training Loss: 0.00017319998005405068
Test Loss:  0.00010534853208810091
Valid Loss:  0.00022246937442105263
Epoch:  483  	Training Loss: 0.0001729465730022639
Test Loss:  0.00010501602082513273
Valid Loss:  0.00022219176753424108
Epoch:  484  	Training Loss: 0.0001726945338305086
Test Loss:  0.00010473356087459251
Valid Loss:  0.0002219151210738346
Epoch:  485  	Training Loss: 0.00017244479386135936
Test Loss:  0.00010448052489664406
Valid Loss:  0.00022163931862451136
Epoch:  486  	Training Loss: 0.0001721974986139685
Test Loss:  0.00010424469655845314
Valid Loss:  0.0002213645784649998
Epoch:  487  	Training Loss: 0.00017195202235598117
Test Loss:  0.00010402013140264899
Valid Loss:  0.00022109138080850244
Epoch:  488  	Training Loss: 0.00017170819046441466
Test Loss:  0.0001038027839967981
Valid Loss:  0.00022082022042013705
Epoch:  489  	Training Loss: 0.00017146625032182783
Test Loss:  0.00010359074804000556
Valid Loss:  0.00022055133013054729
Epoch:  490  	Training Loss: 0.00017122586723417044
Test Loss:  0.00010338307765778154
Valid Loss:  0.00022028438979759812
Epoch:  491  	Training Loss: 0.00017098739044740796
Test Loss:  0.00010317865235265344
Valid Loss:  0.0002200195740442723
Epoch:  492  	Training Loss: 0.00017075077630579472
Test Loss:  0.00010307806223863736
Valid Loss:  0.00021998747251927853
Epoch:  493  	Training Loss: 0.00017072499031201005
Test Loss:  0.00010299291898263618
Valid Loss:  0.0002199559676228091
Epoch:  494  	Training Loss: 0.00017070026660803705
Test Loss:  0.00010292061779182404
Valid Loss:  0.00021992444817442447
Epoch:  495  	Training Loss: 0.00017067606677301228
Test Loss:  0.00010285916505381465
Valid Loss:  0.00021989343804307282
Epoch:  496  	Training Loss: 0.00017065234715119004
Test Loss:  0.00010280610149493441
Valid Loss:  0.00021986220963299274
Epoch:  497  	Training Loss: 0.00017062947154045105
Test Loss:  0.00010276057582814246
Valid Loss:  0.00021983102487865835
Epoch:  498  	Training Loss: 0.0001706064067548141
Test Loss:  0.00010272128565702587
Valid Loss:  0.0002197996072936803
Epoch:  499  	Training Loss: 0.000170584098668769
Test Loss:  0.0001026871323119849
Valid Loss:  0.00021976904827170074
Epoch:  500  	Training Loss: 0.00017056197975762188
Test Loss:  0.00010265728633385152
Valid Loss:  0.00021973816910758615
seed is  3
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.28it/s]  1%|          | 4/500 [00:00<00:31, 15.84it/s]  1%|          | 6/500 [00:00<00:30, 16.12it/s]  2%|▏         | 8/500 [00:00<00:30, 16.25it/s]  2%|▏         | 10/500 [00:00<00:30, 16.31it/s]  2%|▏         | 12/500 [00:00<00:29, 16.35it/s]  3%|▎         | 14/500 [00:00<00:29, 16.41it/s]  3%|▎         | 16/500 [00:00<00:29, 16.41it/s]  4%|▎         | 18/500 [00:01<00:29, 16.42it/s]  4%|▍         | 20/500 [00:01<00:29, 16.43it/s]  4%|▍         | 22/500 [00:01<00:29, 16.43it/s]  5%|▍         | 24/500 [00:01<00:28, 16.43it/s]  5%|▌         | 26/500 [00:01<00:29, 16.10it/s]  6%|▌         | 28/500 [00:01<00:29, 16.14it/s]  6%|▌         | 30/500 [00:01<00:29, 16.20it/s]  6%|▋         | 32/500 [00:01<00:29, 16.09it/s]  7%|▋         | 34/500 [00:02<00:28, 16.14it/s]  7%|▋         | 36/500 [00:02<00:28, 16.20it/s]  8%|▊         | 38/500 [00:02<00:28, 16.13it/s]  8%|▊         | 40/500 [00:02<00:28, 16.04it/s]  8%|▊         | 42/500 [00:02<00:28, 15.91it/s]  9%|▉         | 44/500 [00:02<00:28, 15.92it/s]  9%|▉         | 46/500 [00:02<00:28, 15.90it/s] 10%|▉         | 48/500 [00:02<00:28, 15.95it/s] 10%|█         | 50/500 [00:03<00:28, 16.06it/s] 10%|█         | 52/500 [00:03<00:28, 15.94it/s] 11%|█         | 54/500 [00:03<00:28, 15.48it/s] 11%|█         | 56/500 [00:03<00:31, 14.32it/s] 12%|█▏        | 58/500 [00:03<00:31, 13.99it/s] 12%|█▏        | 60/500 [00:03<00:30, 14.30it/s] 12%|█▏        | 62/500 [00:03<00:29, 14.75it/s] 13%|█▎        | 64/500 [00:04<00:29, 14.88it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.32it/s] 14%|█▎        | 68/500 [00:04<00:28, 15.34it/s] 14%|█▍        | 70/500 [00:04<00:28, 15.35it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.29it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.47it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.58it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.83it/s] 16%|█▌        | 80/500 [00:05<00:26, 16.00it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.61it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.83it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.67it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.85it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.01it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.12it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.26it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.32it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.35it/s] 20%|██        | 100/500 [00:06<00:25, 15.91it/s] 20%|██        | 102/500 [00:06<00:24, 16.07it/s] 21%|██        | 104/500 [00:06<00:24, 16.03it/s] 21%|██        | 106/500 [00:06<00:24, 16.16it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.03it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.03it/s] 22%|██▏       | 112/500 [00:07<00:24, 16.14it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.27it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.30it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.15it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.18it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.29it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.36it/s]Epoch:  1  	Training Loss: 0.11148996651172638
Test Loss:  2314.783203125
Valid Loss:  2313.18359375
Epoch:  2  	Training Loss: 2310.03759765625
Test Loss:  77659342110720.0
Valid Loss:  77134676623360.0
Epoch:  3  	Training Loss: 76620798885888.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.38it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.43it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.36it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.35it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.38it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.41it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.40it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.41it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.45it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.44it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.15it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.25it/s] 30%|███       | 150/500 [00:09<00:21, 16.34it/s] 30%|███       | 152/500 [00:09<00:21, 16.19it/s] 31%|███       | 154/500 [00:09<00:21, 16.19it/s] 31%|███       | 156/500 [00:09<00:21, 16.26it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.36it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.08it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.19it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.14it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.20it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.27it/s] 34%|███▍      | 170/500 [00:10<00:20, 15.84it/s] 34%|███▍      | 172/500 [00:10<00:21, 15.42it/s] 35%|███▍      | 174/500 [00:10<00:22, 14.35it/s] 35%|███▌      | 176/500 [00:11<00:22, 14.30it/s] 36%|███▌      | 178/500 [00:11<00:22, 14.24it/s] 36%|███▌      | 180/500 [00:11<00:22, 14.43it/s] 36%|███▋      | 182/500 [00:11<00:21, 14.95it/s] 37%|███▋      | 184/500 [00:11<00:22, 13.98it/s] 37%|███▋      | 186/500 [00:11<00:23, 13.31it/s] 38%|███▊      | 188/500 [00:11<00:24, 12.96it/s] 38%|███▊      | 190/500 [00:12<00:24, 12.76it/s] 38%|███▊      | 192/500 [00:12<00:24, 12.52it/s] 39%|███▉      | 194/500 [00:12<00:24, 12.46it/s] 39%|███▉      | 196/500 [00:12<00:24, 12.50it/s] 40%|███▉      | 198/500 [00:12<00:22, 13.22it/s] 40%|████      | 200/500 [00:12<00:21, 13.99it/s] 40%|████      | 202/500 [00:13<00:20, 14.61it/s] 41%|████      | 204/500 [00:13<00:19, 14.98it/s] 41%|████      | 206/500 [00:13<00:19, 15.29it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.60it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.81it/s] 42%|████▏     | 212/500 [00:13<00:19, 14.77it/s] 43%|████▎     | 214/500 [00:13<00:20, 13.94it/s] 43%|████▎     | 216/500 [00:13<00:21, 13.43it/s] 44%|████▎     | 218/500 [00:14<00:21, 13.07it/s] 44%|████▍     | 220/500 [00:14<00:20, 13.35it/s] 44%|████▍     | 222/500 [00:14<00:19, 13.94it/s] 45%|████▍     | 224/500 [00:14<00:18, 14.54it/s] 45%|████▌     | 226/500 [00:14<00:18, 15.08it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.47it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.58it/s] 46%|████▋     | 232/500 [00:15<00:17, 15.61it/s] 47%|████▋     | 234/500 [00:15<00:16, 15.79it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.95it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.06it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.05it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.20it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.26it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.31it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.34it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.28it/s] 50%|█████     | 252/500 [00:16<00:15, 16.15it/s] 51%|█████     | 254/500 [00:16<00:15, 16.20it/s] 51%|█████     | 256/500 [00:16<00:14, 16.28it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.36it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.36it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.40it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.46it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.49it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.52it/s] 54%|█████▍    | 270/500 [00:17<00:13, 16.48it/s] 54%|█████▍    | 272/500 [00:17<00:13, 16.38it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.29it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.07it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.03it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.09it/s] 56%|█████▋    | 282/500 [00:18<00:13, 16.25it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.29it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.33it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.13it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.21it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.23it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.01it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.73it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.80it/s] 60%|██████    | 300/500 [00:19<00:12, 15.96it/s] 60%|██████    | 302/500 [00:19<00:12, 16.06it/s] 61%|██████    | 304/500 [00:19<00:12, 16.14it/s] 61%|██████    | 306/500 [00:19<00:11, 16.20it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.24it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.16it/s] 62%|██████▏   | 312/500 [00:19<00:11, 15.90it/s] 63%|██████▎   | 314/500 [00:20<00:11, 16.05it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.17it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.26it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.30it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.32it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.20it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.03it/s] 66%|██████▌   | 328/500 [00:20<00:10, 15.78it/s] 66%|██████▌   | 330/500 [00:21<00:10, 15.65it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.58it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.25it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.54it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.51it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.75it/s] 68%|██████▊   | 342/500 [00:21<00:09, 15.94it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.09it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.19it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.27it/s] 70%|███████   | 350/500 [00:22<00:09, 16.32it/s] 70%|███████   | 352/500 [00:22<00:09, 16.34it/s] 71%|███████   | 354/500 [00:22<00:08, 16.36it/s] 71%|███████   | 356/500 [00:22<00:08, 16.37it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.39it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.41it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.39it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.44it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.43it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.26it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.38it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.30it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 15.97it/s] 75%|███████▌  | 376/500 [00:23<00:08, 14.67it/s] 76%|███████▌  | 378/500 [00:24<00:08, 13.89it/s] 76%|███████▌  | 380/500 [00:24<00:08, 13.38it/s] 76%|███████▋  | 382/500 [00:24<00:09, 13.05it/s] 77%|███████▋  | 384/500 [00:24<00:09, 12.76it/s] 77%|███████▋  | 386/500 [00:24<00:09, 12.43it/s] 78%|███████▊  | 388/500 [00:24<00:08, 12.70it/s] 78%|███████▊  | 390/500 [00:25<00:08, 12.54it/s] 78%|███████▊  | 392/500 [00:25<00:08, 12.41it/s] 79%|███████▉  | 394/500 [00:25<00:08, 12.27it/s] 79%|███████▉  | 396/500 [00:25<00:08, 12.29it/s] 80%|███████▉  | 398/500 [00:25<00:08, 12.65it/s] 80%|████████  | 400/500 [00:25<00:07, 12.84it/s] 80%|████████  | 402/500 [00:26<00:07, 13.31it/s] 81%|████████  | 404/500 [00:26<00:06, 14.07it/s] 81%|████████  | 406/500 [00:26<00:06, 14.58it/s] 82%|████████▏ | 408/500 [00:26<00:06, 15.10it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.52it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.75it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.83it/s] 83%|████████▎ | 416/500 [00:26<00:05, 15.91it/s] 84%|████████▎ | 418/500 [00:27<00:05, 15.71it/s] 84%|████████▍ | 420/500 [00:27<00:05, 14.83it/s] 84%|████████▍ | 422/500 [00:27<00:05, 15.24it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.40it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.47it/s] 86%|████████▌ | 428/500 [00:27<00:04, 15.16it/s] 86%|████████▌ | 430/500 [00:27<00:04, 15.50it/s] 86%|████████▋ | 432/500 [00:27<00:04, 15.72it/s] 87%|████████▋ | 434/500 [00:28<00:04, 15.79it/s] 87%|████████▋ | 436/500 [00:28<00:04, 15.75it/s] 88%|████████▊ | 438/500 [00:28<00:03, 15.94it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.02it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.11it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.16it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.02it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.08it/s] 90%|█████████ | 450/500 [00:29<00:03, 16.18it/s] 90%|█████████ | 452/500 [00:29<00:02, 16.23it/s] 91%|█████████ | 454/500 [00:29<00:02, 16.26it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.29it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.30it/s] 92%|█████████▏| 460/500 [00:29<00:02, 16.31it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.30it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.32it/s] 93%|█████████▎| 466/500 [00:30<00:02, 16.24it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.97it/s] 94%|█████████▍| 470/500 [00:30<00:01, 16.07it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.06it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.15it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.25it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.21it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.22it/s] 96%|█████████▋| 482/500 [00:31<00:01, 16.22it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.19it/s] 97%|█████████▋| 486/500 [00:31<00:00, 16.21it/s] 98%|█████████▊| 488/500 [00:31<00:00, 16.22it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.24it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.28it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.25it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.13it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 16.17it/s]100%|██████████| 500/500 [00:32<00:00, 16.21it/s]100%|██████████| 500/500 [00:32<00:00, 15.55it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  3
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:35,  6.32s/it]  1%|          | 3/500 [00:06<14:07,  1.71s/it]  1%|          | 5/500 [00:06<07:11,  1.15it/s]  1%|▏         | 7/500 [00:06<04:22,  1.88it/s]  2%|▏         | 9/500 [00:06<02:54,  2.81it/s]  2%|▏         | 11/500 [00:13<11:05,  1.36s/it]  3%|▎         | 13/500 [00:13<07:35,  1.07it/s]  3%|▎         | 15/500 [00:13<05:20,  1.51it/s]  3%|▎         | 17/500 [00:13<03:50,  2.10it/s]  4%|▍         | 19/500 [00:14<02:47,  2.87it/s]  4%|▍         | 21/500 [00:20<09:44,  1.22s/it]  5%|▍         | 23/500 [00:20<06:55,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:36,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.95it/s]  6%|▌         | 31/500 [00:27<09:16,  1.19s/it]  7%|▋         | 33/500 [00:27<06:37,  1.17it/s]  7%|▋         | 35/500 [00:27<04:45,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:34<09:12,  1.20s/it]  9%|▊         | 43/500 [00:34<06:34,  1.16it/s]  9%|▉         | 45/500 [00:34<04:44,  1.60it/s]  9%|▉         | 47/500 [00:34<03:27,  2.19it/s] 10%|▉         | 49/500 [00:34<02:33,  2.93it/s] 10%|█         | 51/500 [00:41<08:52,  1.19s/it] 11%|█         | 53/500 [00:41<06:20,  1.17it/s] 11%|█         | 55/500 [00:41<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.98it/s] 12%|█▏        | 61/500 [00:48<08:44,  1.19s/it] 13%|█▎        | 63/500 [00:48<06:14,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:29,  1.61it/s] 13%|█▎        | 67/500 [00:48<03:16,  2.20it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.97it/s] 14%|█▍        | 71/500 [00:54<08:24,  1.18s/it]Epoch:  1  	Training Loss: 0.11148996651172638
Test Loss:  198.23410034179688
Valid Loss:  196.00978088378906
Epoch:  2  	Training Loss: 192.97738647460938
Test Loss:  0.29181867837905884
Valid Loss:  0.29501745104789734
Epoch:  3  	Training Loss: 0.27976253628730774
Test Loss:  0.2671124041080475
Valid Loss:  0.27042531967163086
Epoch:  4  	Training Loss: 0.25621479749679565
Test Loss:  0.2446632832288742
Valid Loss:  0.24807941913604736
Epoch:  5  	Training Loss: 0.2348397672176361
Test Loss:  0.22425660490989685
Valid Loss:  0.22776614129543304
Epoch:  6  	Training Loss: 0.21542969346046448
Test Loss:  0.20569919049739838
Valid Loss:  0.2092931568622589
Epoch:  7  	Training Loss: 0.197797492146492
Test Loss:  0.18881672620773315
Valid Loss:  0.192486971616745
Epoch:  8  	Training Loss: 0.18177446722984314
Test Loss:  0.17345209419727325
Valid Loss:  0.1771911382675171
Epoch:  9  	Training Loss: 0.16720861196517944
Test Loss:  0.15946336090564728
Valid Loss:  0.1632644683122635
Epoch:  10  	Training Loss: 0.15396270155906677
Test Loss:  0.14672259986400604
Valid Loss:  0.1505795270204544
Epoch:  11  	Training Loss: 0.14191299676895142
Test Loss:  0.13511396944522858
Valid Loss:  0.139021098613739
Epoch:  12  	Training Loss: 0.13094764947891235
Test Loss:  0.12243267148733139
Valid Loss:  0.1263515055179596
Epoch:  13  	Training Loss: 0.11892008781433105
Test Loss:  0.11105681955814362
Valid Loss:  0.1149851530790329
Epoch:  14  	Training Loss: 0.10814658552408218
Test Loss:  0.10084924846887589
Valid Loss:  0.10478508472442627
Epoch:  15  	Training Loss: 0.09849421679973602
Test Loss:  0.09168732166290283
Valid Loss:  0.09562884271144867
Epoch:  16  	Training Loss: 0.08984418958425522
Test Loss:  0.0834614560008049
Valid Loss:  0.0874069482088089
Epoch:  17  	Training Loss: 0.08209043741226196
Test Loss:  0.07607360184192657
Valid Loss:  0.08002156019210815
Epoch:  18  	Training Loss: 0.0751381367444992
Test Loss:  0.06943615525960922
Valid Loss:  0.07338513433933258
Epoch:  19  	Training Loss: 0.06890256702899933
Test Loss:  0.06347072124481201
Valid Loss:  0.06741940975189209
Epoch:  20  	Training Loss: 0.0633079782128334
Test Loss:  0.05810719355940819
Valid Loss:  0.062054380774497986
Epoch:  21  	Training Loss: 0.058286719024181366
Test Loss:  0.05328287184238434
Valid Loss:  0.05722741782665253
Epoch:  22  	Training Loss: 0.053778275847435
Test Loss:  0.04890431463718414
Valid Loss:  0.05284441262483597
Epoch:  23  	Training Loss: 0.04969238489866257
Test Loss:  0.04496557265520096
Valid Loss:  0.04890032857656479
Epoch:  24  	Training Loss: 0.04602360725402832
Test Loss:  0.04142071679234505
Valid Loss:  0.045349299907684326
Epoch:  25  	Training Loss: 0.042727746069431305
Test Loss:  0.03822869807481766
Valid Loss:  0.04215032979846001
Epoch:  26  	Training Loss: 0.03976532071828842
Test Loss:  0.035352807492017746
Valid Loss:  0.03926675021648407
Epoch:  27  	Training Loss: 0.037101056426763535
Test Loss:  0.03276018798351288
Valid Loss:  0.03666575998067856
Epoch:  28  	Training Loss: 0.034703440964221954
Test Loss:  0.03042147494852543
Valid Loss:  0.03431803360581398
Epoch:  29  	Training Loss: 0.03254430741071701
Test Loss:  0.028310369700193405
Valid Loss:  0.03219730779528618
Epoch:  30  	Training Loss: 0.030598491430282593
Test Loss:  0.026403382420539856
Valid Loss:  0.030280131846666336
Epoch:  31  	Training Loss: 0.02884352207183838
Test Loss:  0.024679463356733322
Valid Loss:  0.02854548767209053
Epoch:  32  	Training Loss: 0.027259303256869316
Test Loss:  0.023109085857868195
Valid Loss:  0.02696513757109642
Epoch:  33  	Training Loss: 0.02582065388560295
Test Loss:  0.021688571199774742
Valid Loss:  0.025534018874168396
Epoch:  34  	Training Loss: 0.02452078089118004
Test Loss:  0.020402446389198303
Valid Loss:  0.024236692115664482
Epoch:  35  	Training Loss: 0.023344993591308594
Test Loss:  0.019236840307712555
Valid Loss:  0.02305932343006134
Epoch:  36  	Training Loss: 0.022280151024460793
Test Loss:  0.018179379403591156
Valid Loss:  0.021989580243825912
Epoch:  37  	Training Loss: 0.021314546465873718
Test Loss:  0.017218980938196182
Valid Loss:  0.02101641148328781
Epoch:  38  	Training Loss: 0.020437713712453842
Test Loss:  0.016345713287591934
Valid Loss:  0.02013194002211094
Epoch:  39  	Training Loss: 0.019640304148197174
Test Loss:  0.015559084713459015
Valid Loss:  0.019390618428587914
Epoch:  40  	Training Loss: 0.018946882337331772
Test Loss:  0.014928868040442467
Valid Loss:  0.01878875307738781
Epoch:  41  	Training Loss: 0.018407484516501427
Test Loss:  0.014430366456508636
Valid Loss:  0.018298139795660973
Epoch:  42  	Training Loss: 0.018007969483733177
Test Loss:  0.014149234630167484
Valid Loss:  0.018010564148426056
Epoch:  43  	Training Loss: 0.01779281534254551
Test Loss:  0.013915546238422394
Valid Loss:  0.01777351275086403
Epoch:  44  	Training Loss: 0.017611481249332428
Test Loss:  0.013714471831917763
Valid Loss:  0.017576105892658234
Epoch:  45  	Training Loss: 0.017456915229558945
Test Loss:  0.013545431196689606
Valid Loss:  0.017400527372956276
Epoch:  46  	Training Loss: 0.01732023060321808
Test Loss:  0.013396117836236954
Valid Loss:  0.0172311719506979
Epoch:  47  	Training Loss: 0.01719321683049202
Test Loss:  0.013276146724820137
Valid Loss:  0.017087820917367935
Epoch:  48  	Training Loss: 0.0170940812677145
Test Loss:  0.013173418119549751
Valid Loss:  0.016962707042694092
Epoch:  49  	Training Loss: 0.01701004058122635
Test Loss:  0.013084066100418568
Valid Loss:  0.016851743683218956
Epoch:  50  	Training Loss: 0.01693635620176792
Test Loss:  0.01300199143588543
Valid Loss:  0.01674848422408104
Epoch:  51  	Training Loss: 0.01686670258641243
Test Loss:  0.012925824150443077
Valid Loss:  0.016650041565299034
Epoch:  52  	Training Loss: 0.01679917797446251
Test Loss:  0.012828733772039413
Valid Loss:  0.016524838283658028
Epoch:  53  	Training Loss: 0.016711998730897903
Test Loss:  0.012736786156892776
Valid Loss:  0.01640595681965351
Epoch:  54  	Training Loss: 0.016631269827485085
Test Loss:  0.012657598592340946
Valid Loss:  0.016301196068525314
Epoch:  55  	Training Loss: 0.016560770571231842
Test Loss:  0.012591232545673847
Valid Loss:  0.016210362315177917
Epoch:  56  	Training Loss: 0.01649531163275242
Test Loss:  0.012532265856862068
Valid Loss:  0.016123641282320023
Epoch:  57  	Training Loss: 0.01643192395567894
Test Loss:  0.012474087998270988
Valid Loss:  0.016037926077842712
Epoch:  58  	Training Loss: 0.016369711607694626
Test Loss:  0.012421030551195145
Valid Loss:  0.015961401164531708
Epoch:  59  	Training Loss: 0.01631086692214012
Test Loss:  0.012370689772069454
Valid Loss:  0.015888072550296783
Epoch:  60  	Training Loss: 0.016253739595413208
Test Loss:  0.01232295110821724
Valid Loss:  0.015817727893590927
Epoch:  61  	Training Loss: 0.01619812659919262
Test Loss:  0.012278835289180279
Valid Loss:  0.015747878700494766
Epoch:  62  	Training Loss: 0.0161428265273571
Test Loss:  0.012238574214279652
Valid Loss:  0.015682868659496307
Epoch:  63  	Training Loss: 0.01608870178461075
Test Loss:  0.012201797217130661
Valid Loss:  0.015619148500263691
Epoch:  64  	Training Loss: 0.016035081818699837
Test Loss:  0.012166832573711872
Valid Loss:  0.015557831153273582
Epoch:  65  	Training Loss: 0.015982825309038162
Test Loss:  0.012133507058024406
Valid Loss:  0.015498829074203968
Epoch:  66  	Training Loss: 0.0159328430891037
Test Loss:  0.01210452988743782
Valid Loss:  0.015445864759385586
Epoch:  67  	Training Loss: 0.015885505825281143
Test Loss:  0.012078385800123215
Valid Loss:  0.015396895818412304
Epoch:  68  	Training Loss: 0.015839651226997375
Test Loss:  0.012052246369421482
Valid Loss:  0.015349369496107101
Epoch:  69  	Training Loss: 0.015794191509485245
Test Loss:  0.012027491815388203
Valid Loss:  0.015303675085306168
Epoch:  70  	Training Loss: 0.015749551355838776
Test Loss:  0.012002711184322834
Valid Loss:  0.015258979983627796
Epoch:  71  	Training Loss: 0.015705179423093796
Test Loss:  0.011977910995483398
Valid Loss:  0.015214670449495316
Epoch:  72  	Training Loss: 0.01566133461892605
Test Loss:  0.011954771354794502
Valid Loss:   15%|█▍        | 73/500 [00:54<06:00,  1.18it/s] 15%|█▌        | 75/500 [00:55<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:55<03:09,  2.24it/s] 16%|█▌        | 79/500 [00:55<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:01<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:02<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:02<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:08<08:05,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:49,  1.16it/s] 19%|█▉        | 95/500 [01:08<04:12,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:03,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.95it/s] 20%|██        | 101/500 [01:15<07:49,  1.18s/it] 21%|██        | 103/500 [01:15<05:35,  1.18it/s] 21%|██        | 105/500 [01:15<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:15<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:15<02:10,  3.01it/s] 22%|██▏       | 111/500 [01:22<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:29,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:22<02:52,  2.23it/s] 24%|██▍       | 119/500 [01:22<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:29<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.99it/s] 26%|██▌       | 131/500 [01:36<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:36<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:36<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:36<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:36<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:43<07:17,  1.22s/it]0.015172608196735382
Epoch:  73  	Training Loss: 0.015618744306266308
Test Loss:  0.011931588873267174
Valid Loss:  0.015130585059523582
Epoch:  74  	Training Loss: 0.015576422214508057
Test Loss:  0.011908372864127159
Valid Loss:  0.015089391730725765
Epoch:  75  	Training Loss: 0.01553436554968357
Test Loss:  0.01188511960208416
Valid Loss:  0.015049763955175877
Epoch:  76  	Training Loss: 0.015492560341954231
Test Loss:  0.011862563900649548
Valid Loss:  0.015010219998657703
Epoch:  77  	Training Loss: 0.015451010316610336
Test Loss:  0.011840412393212318
Valid Loss:  0.014970753341913223
Epoch:  78  	Training Loss: 0.01540989987552166
Test Loss:  0.01181945763528347
Valid Loss:  0.014932629652321339
Epoch:  79  	Training Loss: 0.015369397588074207
Test Loss:  0.011798469349741936
Valid Loss:  0.014894559979438782
Epoch:  80  	Training Loss: 0.015329142101109028
Test Loss:  0.011777443811297417
Valid Loss:  0.014856552705168724
Epoch:  81  	Training Loss: 0.015289136208593845
Test Loss:  0.011756393127143383
Valid Loss:  0.014818615280091763
Epoch:  82  	Training Loss: 0.015249377116560936
Test Loss:  0.011735428124666214
Valid Loss:  0.014780924655497074
Epoch:  83  	Training Loss: 0.015210018493235111
Test Loss:  0.011714437045156956
Valid Loss:  0.014743303880095482
Epoch:  84  	Training Loss: 0.01517089456319809
Test Loss:  0.011693423613905907
Valid Loss:  0.014705744571983814
Epoch:  85  	Training Loss: 0.015132071450352669
Test Loss:  0.011673584580421448
Valid Loss:  0.014669490978121758
Epoch:  86  	Training Loss: 0.015093911439180374
Test Loss:  0.011653699912130833
Valid Loss:  0.014633284881711006
Epoch:  87  	Training Loss: 0.015056082978844643
Test Loss:  0.011634977534413338
Valid Loss:  0.014598360285162926
Epoch:  88  	Training Loss: 0.015018845908343792
Test Loss:  0.011616194620728493
Valid Loss:  0.014564309269189835
Epoch:  89  	Training Loss: 0.014981849119067192
Test Loss:  0.011597353965044022
Valid Loss:  0.014530321583151817
Epoch:  90  	Training Loss: 0.014945092611014843
Test Loss:  0.011578457430005074
Valid Loss:  0.01449638418853283
Epoch:  91  	Training Loss: 0.014908566139638424
Test Loss:  0.011559510603547096
Valid Loss:  0.014462500810623169
Epoch:  92  	Training Loss: 0.014872267842292786
Test Loss:  0.011541368439793587
Valid Loss:  0.014429628849029541
Epoch:  93  	Training Loss: 0.014835757203400135
Test Loss:  0.01152316015213728
Valid Loss:  0.014397140592336655
Epoch:  94  	Training Loss: 0.014799494296312332
Test Loss:  0.01150522381067276
Valid Loss:  0.014364708214998245
Epoch:  95  	Training Loss: 0.014763462357223034
Test Loss:  0.011487709358334541
Valid Loss:  0.014332342892885208
Epoch:  96  	Training Loss: 0.014727668836712837
Test Loss:  0.011470145545899868
Valid Loss:  0.014300033450126648
Epoch:  97  	Training Loss: 0.01469228882342577
Test Loss:  0.011453621089458466
Valid Loss:  0.014268756844103336
Epoch:  98  	Training Loss: 0.014657342806458473
Test Loss:  0.01143704168498516
Valid Loss:  0.01423754170536995
Epoch:  99  	Training Loss: 0.014622634276747704
Test Loss:  0.011420398950576782
Valid Loss:  0.014206935651600361
Epoch:  100  	Training Loss: 0.014588149264454842
Test Loss:  0.011403699405491352
Valid Loss:  0.014176592230796814
Epoch:  101  	Training Loss: 0.014553895220160484
Test Loss:  0.011386943981051445
Valid Loss:  0.014146313071250916
Epoch:  102  	Training Loss: 0.014519852586090565
Test Loss:  0.011371303349733353
Valid Loss:  0.014116542413830757
Epoch:  103  	Training Loss: 0.014485390856862068
Test Loss:  0.011355806142091751
Valid Loss:  0.014086835086345673
Epoch:  104  	Training Loss: 0.014451177790760994
Test Loss:  0.011340685188770294
Valid Loss:  0.014057185500860214
Epoch:  105  	Training Loss: 0.01441720686852932
Test Loss:  0.011325509287416935
Valid Loss:  0.014027601107954979
Epoch:  106  	Training Loss: 0.014383470639586449
Test Loss:  0.011310271918773651
Valid Loss:  0.01399807259440422
Epoch:  107  	Training Loss: 0.014349965378642082
Test Loss:  0.01129498053342104
Valid Loss:  0.01396903395652771
Epoch:  108  	Training Loss: 0.014316681772470474
Test Loss:  0.01127963699400425
Valid Loss:  0.013940375298261642
Epoch:  109  	Training Loss: 0.01428380236029625
Test Loss:  0.011265238747000694
Valid Loss:  0.013912525959312916
Epoch:  110  	Training Loss: 0.014251302927732468
Test Loss:  0.011250772513449192
Valid Loss:  0.01388474553823471
Epoch:  111  	Training Loss: 0.014219029806554317
Test Loss:  0.01123624574393034
Valid Loss:  0.013857034966349602
Epoch:  112  	Training Loss: 0.014186976477503777
Test Loss:  0.011222334578633308
Valid Loss:  0.013829736039042473
Epoch:  113  	Training Loss: 0.014154966920614243
Test Loss:  0.011208338662981987
Valid Loss:  0.01380249485373497
Epoch:  114  	Training Loss: 0.014123182743787766
Test Loss:  0.011194268241524696
Valid Loss:  0.013775317929685116
Epoch:  115  	Training Loss: 0.014091619290411472
Test Loss:  0.011180125176906586
Valid Loss:  0.013748206198215485
Epoch:  116  	Training Loss: 0.01406027190387249
Test Loss:  0.011165918782353401
Valid Loss:  0.0137211624532938
Epoch:  117  	Training Loss: 0.014029137790203094
Test Loss:  0.0111516322940588
Valid Loss:  0.013694172725081444
Epoch:  118  	Training Loss: 0.013998202979564667
Test Loss:  0.01113728154450655
Valid Loss:  0.013667243532836437
Epoch:  119  	Training Loss: 0.013967467471957207
Test Loss:  0.011122866533696651
Valid Loss:  0.013640377670526505
Epoch:  120  	Training Loss: 0.013936927542090416
Test Loss:  0.011108387261629105
Valid Loss:  0.013613571412861347
Epoch:  121  	Training Loss: 0.013906573876738548
Test Loss:  0.011093849316239357
Valid Loss:  0.013586826622486115
Epoch:  122  	Training Loss: 0.013876412063837051
Test Loss:  0.011079799383878708
Valid Loss:  0.013560520485043526
Epoch:  123  	Training Loss: 0.013846720568835735
Test Loss:  0.011066227219998837
Valid Loss:  0.013534272089600563
Epoch:  124  	Training Loss: 0.013817360624670982
Test Loss:  0.011053511872887611
Valid Loss:  0.013508815318346024
Epoch:  125  	Training Loss: 0.013788365758955479
Test Loss:  0.011040745303034782
Valid Loss:  0.01348341628909111
Epoch:  126  	Training Loss: 0.013759618625044823
Test Loss:  0.011028831824660301
Valid Loss:  0.013458799570798874
Epoch:  127  	Training Loss: 0.013731292448937893
Test Loss:  0.011016850359737873
Valid Loss:  0.01343422569334507
Epoch:  128  	Training Loss: 0.01370316557586193
Test Loss:  0.011004799976944923
Valid Loss:  0.013409693725407124
Epoch:  129  	Training Loss: 0.013675220310688019
Test Loss:  0.0109926862642169
Valid Loss:  0.013385203666985035
Epoch:  130  	Training Loss: 0.01364746131002903
Test Loss:  0.010980505496263504
Valid Loss:  0.013360748067498207
Epoch:  131  	Training Loss: 0.01361987367272377
Test Loss:  0.010968266054987907
Valid Loss:  0.01333634089678526
Epoch:  132  	Training Loss: 0.013592465780675411
Test Loss:  0.010955753736197948
Valid Loss:  0.013311825692653656
Epoch:  133  	Training Loss: 0.013565251603722572
Test Loss:  0.010943188332021236
Valid Loss:  0.013287357985973358
Epoch:  134  	Training Loss: 0.013538195751607418
Test Loss:  0.010930572636425495
Valid Loss:  0.013262929394841194
Epoch:  135  	Training Loss: 0.013511297293007374
Test Loss:  0.01091790571808815
Valid Loss:  0.013238548301160336
Epoch:  136  	Training Loss: 0.013484552502632141
Test Loss:  0.010905194096267223
Valid Loss:  0.013214204460382462
Epoch:  137  	Training Loss: 0.013457953929901123
Test Loss:  0.01089243683964014
Valid Loss:  0.013189909979701042
Epoch:  138  	Training Loss: 0.013431626372039318
Test Loss:  0.010880561545491219
Valid Loss:  0.013166410848498344
Epoch:  139  	Training Loss: 0.013405668549239635
Test Loss:  0.010869549587368965
Valid Loss:  0.01314370147883892
Epoch:  140  	Training Loss: 0.013380142860114574
Test Loss:  0.010858463123440742
Valid Loss:  0.013121016323566437
Epoch:  141  	Training Loss: 0.013354780152440071
Test Loss:  0.010847304947674274
Valid Loss:  0.013098356314003468
Epoch:  142  	Training Loss: 0.013329576700925827
Test Loss:  0.010835673660039902
Valid Loss:  0.013075416907668114
 29%|██▊       | 143/500 [01:43<05:13,  1.14it/s] 29%|██▉       | 145/500 [01:43<03:47,  1.56it/s] 29%|██▉       | 147/500 [01:43<02:46,  2.12it/s] 30%|██▉       | 149/500 [01:43<02:02,  2.85it/s] 30%|███       | 151/500 [01:50<06:57,  1.20s/it] 31%|███       | 153/500 [01:50<04:58,  1.16it/s] 31%|███       | 155/500 [01:50<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:50<02:36,  2.19it/s] 32%|███▏      | 159/500 [01:50<01:55,  2.94it/s] 32%|███▏      | 161/500 [01:56<06:42,  1.19s/it] 33%|███▎      | 163/500 [01:57<04:47,  1.17it/s] 33%|███▎      | 165/500 [01:57<03:26,  1.62it/s] 33%|███▎      | 167/500 [01:57<02:30,  2.21it/s] 34%|███▍      | 169/500 [01:57<01:51,  2.97it/s] 34%|███▍      | 171/500 [02:04<06:37,  1.21s/it] 35%|███▍      | 173/500 [02:04<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:04<03:25,  1.58it/s] 35%|███▌      | 177/500 [02:04<02:31,  2.13it/s] 36%|███▌      | 179/500 [02:04<01:53,  2.83it/s] 36%|███▌      | 181/500 [02:11<06:28,  1.22s/it] 37%|███▋      | 183/500 [02:11<04:38,  1.14it/s] 37%|███▋      | 185/500 [02:11<03:21,  1.56it/s] 37%|███▋      | 187/500 [02:11<02:28,  2.11it/s] 38%|███▊      | 189/500 [02:11<01:51,  2.80it/s] 38%|███▊      | 191/500 [02:18<06:09,  1.20s/it] 39%|███▊      | 193/500 [02:18<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:18<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:18<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:18<01:41,  2.96it/s] 40%|████      | 201/500 [02:24<05:51,  1.18s/it] 41%|████      | 203/500 [02:25<04:10,  1.19it/s] 41%|████      | 205/500 [02:25<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:25<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:25<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:31<05:46,  1.20s/it]Epoch:  143  	Training Loss: 0.013304576277732849
Test Loss:  0.010824901983141899
Valid Loss:  0.013053273782134056
Epoch:  144  	Training Loss: 0.013279909268021584
Test Loss:  0.0108140604570508
Valid Loss:  0.013031148351728916
Epoch:  145  	Training Loss: 0.013255400583148003
Test Loss:  0.010803146287798882
Valid Loss:  0.013009046204388142
Epoch:  146  	Training Loss: 0.013231041841208935
Test Loss:  0.010792163200676441
Valid Loss:  0.01298696268349886
Epoch:  147  	Training Loss: 0.01320683304220438
Test Loss:  0.010781113058328629
Valid Loss:  0.012964902445673943
Epoch:  148  	Training Loss: 0.01318276859819889
Test Loss:  0.010769995860755444
Valid Loss:  0.012942863628268242
Epoch:  149  	Training Loss: 0.013158844783902168
Test Loss:  0.010758817195892334
Valid Loss:  0.01292085088789463
Epoch:  150  	Training Loss: 0.013135059736669064
Test Loss:  0.010747572407126427
Valid Loss:  0.012898856773972511
Epoch:  151  	Training Loss: 0.013111408799886703
Test Loss:  0.010736269876360893
Valid Loss:  0.012876888737082481
Epoch:  152  	Training Loss: 0.013087889179587364
Test Loss:  0.010724520310759544
Valid Loss:  0.01285463571548462
Epoch:  153  	Training Loss: 0.013064438477158546
Test Loss:  0.010712720453739166
Valid Loss:  0.012832407839596272
Epoch:  154  	Training Loss: 0.013041107915341854
Test Loss:  0.010700877755880356
Valid Loss:  0.012810212559998035
Epoch:  155  	Training Loss: 0.013017895631492138
Test Loss:  0.010688994079828262
Valid Loss:  0.01278805173933506
Epoch:  156  	Training Loss: 0.012994803488254547
Test Loss:  0.010677063837647438
Valid Loss:  0.012765919789671898
Epoch:  157  	Training Loss: 0.012971979565918446
Test Loss:  0.010666043497622013
Valid Loss:  0.012744894251227379
Epoch:  158  	Training Loss: 0.012949437834322453
Test Loss:  0.010654954239726067
Valid Loss:  0.012724179774522781
Epoch:  159  	Training Loss: 0.012927012518048286
Test Loss:  0.01064381655305624
Valid Loss:  0.012703502550721169
Epoch:  160  	Training Loss: 0.012904711067676544
Test Loss:  0.010632624849677086
Valid Loss:  0.012682853266596794
Epoch:  161  	Training Loss: 0.01288265734910965
Test Loss:  0.010622315108776093
Valid Loss:  0.012662914581596851
Epoch:  162  	Training Loss: 0.012860866263508797
Test Loss:  0.010611758567392826
Valid Loss:  0.012642886489629745
Epoch:  163  	Training Loss: 0.012839270755648613
Test Loss:  0.010602077469229698
Valid Loss:  0.012623565271496773
Epoch:  164  	Training Loss: 0.012817991897463799
Test Loss:  0.010592318139970303
Valid Loss:  0.012604260817170143
Epoch:  165  	Training Loss: 0.012796837836503983
Test Loss:  0.010582488030195236
Valid Loss:  0.01258497592061758
Epoch:  166  	Training Loss: 0.01277580764144659
Test Loss:  0.010572584345936775
Valid Loss:  0.01256571151316166
Epoch:  167  	Training Loss: 0.012754897587001324
Test Loss:  0.010562606155872345
Valid Loss:  0.012546456418931484
Epoch:  168  	Training Loss: 0.012734098359942436
Test Loss:  0.01055256836116314
Valid Loss:  0.012527650222182274
Epoch:  169  	Training Loss: 0.0127134183421731
Test Loss:  0.010542461648583412
Valid Loss:  0.012508967891335487
Epoch:  170  	Training Loss: 0.012692850083112717
Test Loss:  0.01053229346871376
Valid Loss:  0.012490316294133663
Epoch:  171  	Training Loss: 0.012672390788793564
Test Loss:  0.010522060096263885
Valid Loss:  0.012471692636609077
Epoch:  172  	Training Loss: 0.012652149423956871
Test Loss:  0.010512489825487137
Valid Loss:  0.01245351042598486
Epoch:  173  	Training Loss: 0.012632042169570923
Test Loss:  0.010502845048904419
Valid Loss:  0.012435738928616047
Epoch:  174  	Training Loss: 0.01261204294860363
Test Loss:  0.010493135079741478
Valid Loss:  0.012418095022439957
Epoch:  175  	Training Loss: 0.01259215921163559
Test Loss:  0.010483352467417717
Valid Loss:  0.012400489300489426
Epoch:  176  	Training Loss: 0.012572377920150757
Test Loss:  0.01047351211309433
Valid Loss:  0.012382922694087029
Epoch:  177  	Training Loss: 0.01255270466208458
Test Loss:  0.010463600046932697
Valid Loss:  0.012365384958684444
Epoch:  178  	Training Loss: 0.01253320649266243
Test Loss:  0.0104545708745718
Valid Loss:  0.012348395772278309
Epoch:  179  	Training Loss: 0.012513975612819195
Test Loss:  0.010445469990372658
Valid Loss:  0.012331444770097733
Epoch:  180  	Training Loss: 0.012494860216975212
Test Loss:  0.010436290875077248
Valid Loss:  0.012314519844949245
Epoch:  181  	Training Loss: 0.012475849129259586
Test Loss:  0.010427042841911316
Valid Loss:  0.01229762937873602
Epoch:  182  	Training Loss: 0.012456942349672318
Test Loss:  0.01041770912706852
Valid Loss:  0.012280790135264397
Epoch:  183  	Training Loss: 0.01243818923830986
Test Loss:  0.01040831208229065
Valid Loss:  0.012263985350728035
Epoch:  184  	Training Loss: 0.012419536709785461
Test Loss:  0.010398851707577705
Valid Loss:  0.012247211299836636
Epoch:  185  	Training Loss: 0.012400979176163673
Test Loss:  0.010389327071607113
Valid Loss:  0.01223046611994505
Epoch:  186  	Training Loss: 0.01238269079476595
Test Loss:  0.010381625965237617
Valid Loss:  0.012214788235723972
Epoch:  187  	Training Loss: 0.012364750728011131
Test Loss:  0.010373827069997787
Valid Loss:  0.012199124321341515
Epoch:  188  	Training Loss: 0.012346915900707245
Test Loss:  0.010365943424403667
Valid Loss:  0.01218349114060402
Epoch:  189  	Training Loss: 0.01232919842004776
Test Loss:  0.010357968509197235
Valid Loss:  0.01216787751764059
Epoch:  190  	Training Loss: 0.012311587110161781
Test Loss:  0.010349907912313938
Valid Loss:  0.012152282521128654
Epoch:  191  	Training Loss: 0.01229407824575901
Test Loss:  0.0103417644277215
Valid Loss:  0.012136711739003658
Epoch:  192  	Training Loss: 0.012276675552129745
Test Loss:  0.010334476828575134
Valid Loss:  0.012121684849262238
Epoch:  193  	Training Loss: 0.012259559705853462
Test Loss:  0.010327096097171307
Valid Loss:  0.012106671929359436
Epoch:  194  	Training Loss: 0.012242548167705536
Test Loss:  0.01031961664557457
Valid Loss:  0.012091675773262978
Epoch:  195  	Training Loss: 0.012225640937685966
Test Loss:  0.010312044061720371
Valid Loss:  0.01207669172435999
Epoch:  196  	Training Loss: 0.012208834290504456
Test Loss:  0.010304383933544159
Valid Loss:  0.012061729095876217
Epoch:  197  	Training Loss: 0.012192129157483578
Test Loss:  0.01029662974178791
Valid Loss:  0.012046769261360168
Epoch:  198  	Training Loss: 0.012175516225397587
Test Loss:  0.010288795456290245
Valid Loss:  0.012031834572553635
Epoch:  199  	Training Loss: 0.01215900108218193
Test Loss:  0.010280877351760864
Valid Loss:  0.012016914784908295
Epoch:  200  	Training Loss: 0.012142576277256012
Test Loss:  0.010272879153490067
Valid Loss:  0.012002009898424149
Epoch:  201  	Training Loss: 0.012126242741942406
Test Loss:  0.010264802724123001
Valid Loss:  0.011987118050456047
Epoch:  202  	Training Loss: 0.012109996750950813
Test Loss:  0.010256538167595863
Valid Loss:  0.01197212003171444
Epoch:  203  	Training Loss: 0.012093724682927132
Test Loss:  0.010248208418488503
Valid Loss:  0.011957146227359772
Epoch:  204  	Training Loss: 0.012077543884515762
Test Loss:  0.010239805094897747
Valid Loss:  0.01194218173623085
Epoch:  205  	Training Loss: 0.012061439454555511
Test Loss:  0.01023133285343647
Valid Loss:  0.01192723773419857
Epoch:  206  	Training Loss: 0.012045416980981827
Test Loss:  0.010222792625427246
Valid Loss:  0.011912308633327484
Epoch:  207  	Training Loss: 0.012029540725052357
Test Loss:  0.010215145535767078
Valid Loss:  0.011897938326001167
Epoch:  208  	Training Loss: 0.012013884261250496
Test Loss:  0.010207422077655792
Valid Loss:  0.011883584782481194
Epoch:  209  	Training Loss: 0.011998318135738373
Test Loss:  0.01019961480051279
Valid Loss:  0.011869240552186966
Epoch:  210  	Training Loss: 0.011982832103967667
Test Loss:  0.010191733948886395
Valid Loss:  0.011854907497763634
Epoch:  211  	Training Loss: 0.011967428028583527
Test Loss:  0.010183773003518581
Valid Loss:  0.011840587481856346
Epoch:  212  	Training Loss: 0.011952100321650505
Test Loss:  0.010175701230764389
Valid Loss:  0.01182621717453003
Epoch:  213  	Training Loss: 0.011936794966459274 43%|████▎     | 213/500 [02:32<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:32<02:57,  1.61it/s] 43%|████▎     | 217/500 [02:32<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:32<01:34,  2.96it/s] 44%|████▍     | 221/500 [02:38<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:38<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:39<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:39<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:39<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:45<05:21,  1.20s/it] 47%|████▋     | 233/500 [02:45<03:49,  1.17it/s] 47%|████▋     | 235/500 [02:46<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:46<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:46<01:27,  2.97it/s] 48%|████▊     | 241/500 [02:52<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:52<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:52<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:53<01:55,  2.20it/s] 50%|████▉     | 249/500 [02:53<01:24,  2.96it/s] 50%|█████     | 251/500 [02:59<04:49,  1.16s/it] 51%|█████     | 253/500 [02:59<03:25,  1.20it/s] 51%|█████     | 255/500 [02:59<02:28,  1.65it/s] 51%|█████▏    | 257/500 [02:59<01:48,  2.25it/s] 52%|█████▏    | 259/500 [02:59<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:06<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:06<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:06<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:06<01:47,  2.17it/s] 54%|█████▍    | 269/500 [03:06<01:20,  2.88it/s] 54%|█████▍    | 271/500 [03:13<04:40,  1.23s/it] 55%|█████▍    | 273/500 [03:13<03:19,  1.14it/s] 55%|█████▌    | 275/500 [03:13<02:23,  1.57it/s] 55%|█████▌    | 277/500 [03:13<01:43,  2.15it/s] 56%|█████▌    | 279/500 [03:14<01:16,  2.90it/s] 56%|█████▌    | 281/500 [03:20<04:20,  1.19s/it]
Test Loss:  0.010167555883526802
Valid Loss:  0.011811858974397182
Epoch:  214  	Training Loss: 0.011921561323106289
Test Loss:  0.010159348137676716
Valid Loss:  0.011797516606748104
Epoch:  215  	Training Loss: 0.01190640777349472
Test Loss:  0.01015106588602066
Valid Loss:  0.011783184483647346
Epoch:  216  	Training Loss: 0.011891321279108524
Test Loss:  0.010142727755010128
Valid Loss:  0.011768870055675507
Epoch:  217  	Training Loss: 0.011876312084496021
Test Loss:  0.010134322568774223
Valid Loss:  0.011754992417991161
Epoch:  218  	Training Loss: 0.011861369013786316
Test Loss:  0.010125864297151566
Valid Loss:  0.011741163209080696
Epoch:  219  	Training Loss: 0.011846547946333885
Test Loss:  0.01011829636991024
Valid Loss:  0.011727824807167053
Epoch:  220  	Training Loss: 0.01183195412158966
Test Loss:  0.010110663250088692
Valid Loss:  0.011714506894350052
Epoch:  221  	Training Loss: 0.011817441321909428
Test Loss:  0.010102948173880577
Valid Loss:  0.011701203882694244
Epoch:  222  	Training Loss: 0.011802995577454567
Test Loss:  0.010095017030835152
Valid Loss:  0.011687759310007095
Epoch:  223  	Training Loss: 0.011788480915129185
Test Loss:  0.010087013244628906
Valid Loss:  0.011674325913190842
Epoch:  224  	Training Loss: 0.011774031445384026
Test Loss:  0.010078946128487587
Valid Loss:  0.011660918593406677
Epoch:  225  	Training Loss: 0.011759653687477112
Test Loss:  0.010070811957120895
Valid Loss:  0.011647521518170834
Epoch:  226  	Training Loss: 0.011745341122150421
Test Loss:  0.010062620043754578
Valid Loss:  0.011634144932031631
Epoch:  227  	Training Loss: 0.011731092818081379
Test Loss:  0.010054370388388634
Valid Loss:  0.011620791628956795
Epoch:  228  	Training Loss: 0.011716917157173157
Test Loss:  0.010046062059700489
Valid Loss:  0.011607451364398003
Epoch:  229  	Training Loss: 0.011702800169587135
Test Loss:  0.010037695989012718
Valid Loss:  0.011594127863645554
Epoch:  230  	Training Loss: 0.011688741855323315
Test Loss:  0.010029282420873642
Valid Loss:  0.011580830439925194
Epoch:  231  	Training Loss: 0.011674752458930016
Test Loss:  0.01002081111073494
Valid Loss:  0.011567579582333565
Epoch:  232  	Training Loss: 0.011660818010568619
Test Loss:  0.010012246668338776
Valid Loss:  0.011554695665836334
Epoch:  233  	Training Loss: 0.011646848171949387
Test Loss:  0.010003635659813881
Valid Loss:  0.011542299762368202
Epoch:  234  	Training Loss: 0.011632939800620079
Test Loss:  0.009994975291192532
Valid Loss:  0.011529929004609585
Epoch:  235  	Training Loss: 0.011619089171290398
Test Loss:  0.009986277669668198
Valid Loss:  0.011517593637108803
Epoch:  236  	Training Loss: 0.011605297215282917
Test Loss:  0.009977530688047409
Valid Loss:  0.01150528434664011
Epoch:  237  	Training Loss: 0.011591578833758831
Test Loss:  0.009969688951969147
Valid Loss:  0.01149333082139492
Epoch:  238  	Training Loss: 0.011578118428587914
Test Loss:  0.009961792267858982
Valid Loss:  0.011481404304504395
Epoch:  239  	Training Loss: 0.01156472135335207
Test Loss:  0.009953835979104042
Valid Loss:  0.011469505727291107
Epoch:  240  	Training Loss: 0.011551382020115852
Test Loss:  0.0099458247423172
Valid Loss:  0.011457633227109909
Epoch:  241  	Training Loss: 0.01153810229152441
Test Loss:  0.009937755763530731
Valid Loss:  0.011445789597928524
Epoch:  242  	Training Loss: 0.011524880304932594
Test Loss:  0.009929758496582508
Valid Loss:  0.011434049345552921
Epoch:  243  	Training Loss: 0.011511772871017456
Test Loss:  0.00992170162498951
Valid Loss:  0.011422334238886833
Epoch:  244  	Training Loss: 0.01149878278374672
Test Loss:  0.009914545342326164
Valid Loss:  0.011410982348024845
Epoch:  245  	Training Loss: 0.011485990136861801
Test Loss:  0.009907322004437447
Valid Loss:  0.011399651877582073
Epoch:  246  	Training Loss: 0.011473258025944233
Test Loss:  0.009900030680000782
Valid Loss:  0.011388343758881092
Epoch:  247  	Training Loss: 0.011460671201348305
Test Loss:  0.009893616661429405
Valid Loss:  0.01137739047408104
Epoch:  248  	Training Loss: 0.011448230594396591
Test Loss:  0.009887121617794037
Valid Loss:  0.011366462334990501
Epoch:  249  	Training Loss: 0.011435854248702526
Test Loss:  0.009880546480417252
Valid Loss:  0.011355551891028881
Epoch:  250  	Training Loss: 0.011423539370298386
Test Loss:  0.009873894974589348
Valid Loss:  0.011344661004841328
Epoch:  251  	Training Loss: 0.011411288753151894
Test Loss:  0.009867168962955475
Valid Loss:  0.01133379153907299
Epoch:  252  	Training Loss: 0.011399096809327602
Test Loss:  0.009860367514193058
Valid Loss:  0.011322930455207825
Epoch:  253  	Training Loss: 0.011386996135115623
Test Loss:  0.00985444150865078
Valid Loss:  0.01131242886185646
Epoch:  254  	Training Loss: 0.0113750658929348
Test Loss:  0.009848427027463913
Valid Loss:  0.011301970109343529
Epoch:  255  	Training Loss: 0.011363198049366474
Test Loss:  0.009842326864600182
Valid Loss:  0.011291800066828728
Epoch:  256  	Training Loss: 0.011351394467055798
Test Loss:  0.009836146607995033
Valid Loss:  0.011281659826636314
Epoch:  257  	Training Loss: 0.011339659802615643
Test Loss:  0.009830832481384277
Valid Loss:  0.011271817609667778
Epoch:  258  	Training Loss: 0.011328119784593582
Test Loss:  0.009825415909290314
Valid Loss:  0.011261998675763607
Epoch:  259  	Training Loss: 0.01131664402782917
Test Loss:  0.00981990247964859
Valid Loss:  0.011252200230956078
Epoch:  260  	Training Loss: 0.011305230669677258
Test Loss:  0.009814299643039703
Valid Loss:  0.011242423206567764
Epoch:  261  	Training Loss: 0.011293880641460419
Test Loss:  0.009808607399463654
Valid Loss:  0.011232670396566391
Epoch:  262  	Training Loss: 0.011282592080533504
Test Loss:  0.009802774526178837
Valid Loss:  0.011222869157791138
Epoch:  263  	Training Loss: 0.011271294206380844
Test Loss:  0.009796852245926857
Valid Loss:  0.011213084682822227
Epoch:  264  	Training Loss: 0.011260049417614937
Test Loss:  0.009790845215320587
Valid Loss:  0.011203324422240257
Epoch:  265  	Training Loss: 0.011248866096138954
Test Loss:  0.009784762747585773
Valid Loss:  0.011193584650754929
Epoch:  266  	Training Loss: 0.011237742379307747
Test Loss:  0.009778597392141819
Valid Loss:  0.011183866299688816
Epoch:  267  	Training Loss: 0.011226669885218143
Test Loss:  0.00977235846221447
Valid Loss:  0.011174165643751621
Epoch:  268  	Training Loss: 0.011215648613870144
Test Loss:  0.009766042232513428
Valid Loss:  0.011164482682943344
Epoch:  269  	Training Loss: 0.011204682290554047
Test Loss:  0.009759657084941864
Valid Loss:  0.011154824867844582
Epoch:  270  	Training Loss: 0.011193769052624702
Test Loss:  0.009753194637596607
Valid Loss:  0.011145178228616714
Epoch:  271  	Training Loss: 0.011182902380824089
Test Loss:  0.009746669791638851
Valid Loss:  0.011135555803775787
Epoch:  272  	Training Loss: 0.011172084137797356
Test Loss:  0.009740150533616543
Valid Loss:  0.011125961318612099
Epoch:  273  	Training Loss: 0.011161303147673607
Test Loss:  0.009733568876981735
Valid Loss:  0.0111163929104805
Epoch:  274  	Training Loss: 0.011150575242936611
Test Loss:  0.00972691923379898
Valid Loss:  0.011106833815574646
Epoch:  275  	Training Loss: 0.011139892041683197
Test Loss:  0.00972020998597145
Valid Loss:  0.011097296141088009
Epoch:  276  	Training Loss: 0.011129251681268215
Test Loss:  0.009713435545563698
Valid Loss:  0.011087775230407715
Epoch:  277  	Training Loss: 0.011118657886981964
Test Loss:  0.009706608951091766
Valid Loss:  0.011078275740146637
Epoch:  278  	Training Loss: 0.01110810786485672
Test Loss:  0.009699723683297634
Valid Loss:  0.011068791151046753
Epoch:  279  	Training Loss: 0.011097603477537632
Test Loss:  0.009692785330116749
Valid Loss:  0.011059323325753212
Epoch:  280  	Training Loss: 0.011087140999734402
Test Loss:  0.009685792028903961
Valid Loss:  0.011049875989556313
Epoch:  281  	Training Loss: 0.011076720431447029
Test Loss:  0.009678753092885017
Valid Loss:  0.01104044821113348
Epoch:  282  	Training Loss: 0.011066341772675514
Test Loss:  0.009671762585639954
Valid Loss:  0.011031067930161953
Epoch:  283  	Training Loss: 0.01105600968003273
Test Loss:   57%|█████▋    | 283/500 [03:20<03:06,  1.16it/s] 57%|█████▋    | 285/500 [03:20<02:14,  1.59it/s] 57%|█████▋    | 287/500 [03:20<01:39,  2.15it/s] 58%|█████▊    | 289/500 [03:21<01:14,  2.84it/s] 58%|█████▊    | 291/500 [03:27<04:12,  1.21s/it] 59%|█████▊    | 293/500 [03:27<03:00,  1.15it/s] 59%|█████▉    | 295/500 [03:27<02:10,  1.57it/s] 59%|█████▉    | 297/500 [03:27<01:35,  2.13it/s] 60%|█████▉    | 299/500 [03:28<01:11,  2.82it/s] 60%|██████    | 301/500 [03:34<03:57,  1.19s/it] 61%|██████    | 303/500 [03:34<02:49,  1.16it/s] 61%|██████    | 305/500 [03:34<02:02,  1.59it/s] 61%|██████▏   | 307/500 [03:34<01:29,  2.15it/s] 62%|██████▏   | 309/500 [03:35<01:07,  2.84it/s] 62%|██████▏   | 311/500 [03:41<03:47,  1.20s/it] 63%|██████▎   | 313/500 [03:41<02:42,  1.15it/s] 63%|██████▎   | 315/500 [03:41<01:57,  1.58it/s] 63%|██████▎   | 317/500 [03:42<01:25,  2.13it/s] 64%|██████▍   | 319/500 [03:42<01:03,  2.85it/s] 64%|██████▍   | 321/500 [03:48<03:37,  1.21s/it] 65%|██████▍   | 323/500 [03:48<02:33,  1.15it/s] 65%|██████▌   | 325/500 [03:48<01:49,  1.59it/s] 65%|██████▌   | 327/500 [03:49<01:19,  2.18it/s] 66%|██████▌   | 329/500 [03:49<00:58,  2.94it/s] 66%|██████▌   | 331/500 [03:55<03:25,  1.22s/it] 67%|██████▋   | 333/500 [03:55<02:25,  1.15it/s] 67%|██████▋   | 335/500 [03:55<01:44,  1.58it/s] 67%|██████▋   | 337/500 [03:56<01:15,  2.16it/s] 68%|██████▊   | 339/500 [03:56<00:55,  2.90it/s] 68%|██████▊   | 341/500 [04:02<03:14,  1.22s/it] 69%|██████▊   | 343/500 [04:02<02:18,  1.13it/s] 69%|██████▉   | 345/500 [04:03<01:39,  1.55it/s] 69%|██████▉   | 347/500 [04:03<01:12,  2.11it/s] 70%|██████▉   | 349/500 [04:03<00:53,  2.80it/s] 70%|███████   | 351/500 [04:09<03:01,  1.22s/it]0.009664714336395264
Valid Loss:  0.011021699756383896
Epoch:  284  	Training Loss: 0.01104571484029293
Test Loss:  0.009657626040279865
Valid Loss:  0.011012354865670204
Epoch:  285  	Training Loss: 0.011035461910068989
Test Loss:  0.009650491178035736
Valid Loss:  0.01100302767008543
Epoch:  286  	Training Loss: 0.01102525182068348
Test Loss:  0.00964331068098545
Valid Loss:  0.010993717238307
Epoch:  287  	Training Loss: 0.011015080846846104
Test Loss:  0.009636085480451584
Valid Loss:  0.010984424501657486
Epoch:  288  	Training Loss: 0.011004944331943989
Test Loss:  0.00962882675230503
Valid Loss:  0.010975150391459465
Epoch:  289  	Training Loss: 0.010994849726557732
Test Loss:  0.009621527045965195
Valid Loss:  0.01096589770168066
Epoch:  290  	Training Loss: 0.010984795168042183
Test Loss:  0.009614191949367523
Valid Loss:  0.010956662707030773
Epoch:  291  	Training Loss: 0.010974777862429619
Test Loss:  0.009606815874576569
Valid Loss:  0.01094744447618723
Epoch:  292  	Training Loss: 0.010964793153107166
Test Loss:  0.009599419310688972
Valid Loss:  0.010938184335827827
Epoch:  293  	Training Loss: 0.01095476932823658
Test Loss:  0.009591984562575817
Valid Loss:  0.010928941890597343
Epoch:  294  	Training Loss: 0.010944778099656105
Test Loss:  0.009584514424204826
Valid Loss:  0.010919714346528053
Epoch:  295  	Training Loss: 0.010934824123978615
Test Loss:  0.009577011689543724
Valid Loss:  0.010910507291555405
Epoch:  296  	Training Loss: 0.010924904607236385
Test Loss:  0.009569484740495682
Valid Loss:  0.010901317931711674
Epoch:  297  	Training Loss: 0.010915023274719715
Test Loss:  0.009561952203512192
Valid Loss:  0.010892149992287159
Epoch:  298  	Training Loss: 0.01090526394546032
Test Loss:  0.009555641561746597
Valid Loss:  0.01088329404592514
Epoch:  299  	Training Loss: 0.010895642451941967
Test Loss:  0.009549289010465145
Valid Loss:  0.010874457657337189
Epoch:  300  	Training Loss: 0.010886061936616898
Test Loss:  0.009542889893054962
Valid Loss:  0.010865630581974983
Epoch:  301  	Training Loss: 0.010876513086259365
Test Loss:  0.009536449797451496
Valid Loss:  0.01085682027041912
Epoch:  302  	Training Loss: 0.010867003351449966
Test Loss:  0.009529978968203068
Valid Loss:  0.010847985744476318
Epoch:  303  	Training Loss: 0.010857467539608479
Test Loss:  0.00952346995472908
Valid Loss:  0.010839159600436687
Epoch:  304  	Training Loss: 0.010847968980669975
Test Loss:  0.009516921825706959
Valid Loss:  0.010830352082848549
Epoch:  305  	Training Loss: 0.010838503949344158
Test Loss:  0.009510337375104427
Valid Loss:  0.01082155667245388
Epoch:  306  	Training Loss: 0.010829078033566475
Test Loss:  0.00950371939688921
Valid Loss:  0.010812781751155853
Epoch:  307  	Training Loss: 0.010819684714078903
Test Loss:  0.009497066959738731
Valid Loss:  0.010804022662341595
Epoch:  308  	Training Loss: 0.010810326784849167
Test Loss:  0.00949038378894329
Valid Loss:  0.010795279406011105
Epoch:  309  	Training Loss: 0.010801003314554691
Test Loss:  0.00948366615921259
Valid Loss:  0.010786551982164383
Epoch:  310  	Training Loss: 0.010791712440550327
Test Loss:  0.009476921521127224
Valid Loss:  0.01077783852815628
Epoch:  311  	Training Loss: 0.01078245509415865
Test Loss:  0.009470148012042046
Valid Loss:  0.01076914370059967
Epoch:  312  	Training Loss: 0.010773230344057083
Test Loss:  0.009463487192988396
Valid Loss:  0.010760560631752014
Epoch:  313  	Training Loss: 0.010764112696051598
Test Loss:  0.009456798434257507
Valid Loss:  0.010751992464065552
Epoch:  314  	Training Loss: 0.010755027644336224
Test Loss:  0.00945008173584938
Valid Loss:  0.010743441060185432
Epoch:  315  	Training Loss: 0.010746011510491371
Test Loss:  0.009444188326597214
Valid Loss:  0.010735204443335533
Epoch:  316  	Training Loss: 0.010737165808677673
Test Loss:  0.009438246488571167
Valid Loss:  0.01072697527706623
Epoch:  317  	Training Loss: 0.010728355497121811
Test Loss:  0.009432261809706688
Valid Loss:  0.010718763805925846
Epoch:  318  	Training Loss: 0.01071957778185606
Test Loss:  0.009426236152648926
Valid Loss:  0.010710559785366058
Epoch:  319  	Training Loss: 0.010710835456848145
Test Loss:  0.009420168586075306
Valid Loss:  0.01070236787199974
Epoch:  320  	Training Loss: 0.010702120140194893
Test Loss:  0.00941406562924385
Valid Loss:  0.010694187134504318
Epoch:  321  	Training Loss: 0.010693440213799477
Test Loss:  0.009407928213477135
Valid Loss:  0.010686023160815239
Epoch:  322  	Training Loss: 0.010684795677661896
Test Loss:  0.00940186157822609
Valid Loss:  0.01067793183028698
Epoch:  323  	Training Loss: 0.010676217265427113
Test Loss:  0.009395754896104336
Valid Loss:  0.010669851675629616
Epoch:  324  	Training Loss: 0.010667670518159866
Test Loss:  0.00938961561769247
Valid Loss:  0.010661782696843147
Epoch:  325  	Training Loss: 0.010659155435860157
Test Loss:  0.00938344281166792
Valid Loss:  0.010653723962605
Epoch:  326  	Training Loss: 0.01065067108720541
Test Loss:  0.00937724020332098
Valid Loss:  0.01064568292349577
Epoch:  327  	Training Loss: 0.010642215609550476
Test Loss:  0.009371006861329079
Valid Loss:  0.010637655854225159
Epoch:  328  	Training Loss: 0.01063387468457222
Test Loss:  0.009365572594106197
Valid Loss:  0.010629933327436447
Epoch:  329  	Training Loss: 0.01062563993036747
Test Loss:  0.00936009082943201
Valid Loss:  0.010622222907841206
Epoch:  330  	Training Loss: 0.010617438703775406
Test Loss:  0.009354565292596817
Valid Loss:  0.010614519938826561
Epoch:  331  	Training Loss: 0.01060926727950573
Test Loss:  0.009348995983600616
Valid Loss:  0.010606829077005386
Epoch:  332  	Training Loss: 0.010601132176816463
Test Loss:  0.009343421086668968
Valid Loss:  0.010599156841635704
Epoch:  333  	Training Loss: 0.010593025013804436
Test Loss:  0.00933779962360859
Valid Loss:  0.010591494850814342
Epoch:  334  	Training Loss: 0.01058495044708252
Test Loss:  0.0093321418389678
Valid Loss:  0.010583844035863876
Epoch:  335  	Training Loss: 0.010576906614005566
Test Loss:  0.009326443076133728
Valid Loss:  0.010576203465461731
Epoch:  336  	Training Loss: 0.010568896308541298
Test Loss:  0.009321531280875206
Valid Loss:  0.01056886650621891
Epoch:  337  	Training Loss: 0.010561048984527588
Test Loss:  0.009316563606262207
Valid Loss:  0.010561533272266388
Epoch:  338  	Training Loss: 0.010553237050771713
Test Loss:  0.009311542846262455
Valid Loss:  0.010554207488894463
Epoch:  339  	Training Loss: 0.010545512661337852
Test Loss:  0.009308122098445892
Valid Loss:  0.010547484271228313
Epoch:  340  	Training Loss: 0.010537974536418915
Test Loss:  0.009304610081017017
Valid Loss:  0.010540759190917015
Epoch:  341  	Training Loss: 0.010530473664402962
Test Loss:  0.009301016107201576
Valid Loss:  0.010534033179283142
Epoch:  342  	Training Loss: 0.010523011907935143
Test Loss:  0.009297491982579231
Valid Loss:  0.010527342557907104
Epoch:  343  	Training Loss: 0.010515572503209114
Test Loss:  0.009293878450989723
Valid Loss:  0.010520647279918194
Epoch:  344  	Training Loss: 0.010508163832128048
Test Loss:  0.009290186688303947
Valid Loss:  0.010513953864574432
Epoch:  345  	Training Loss: 0.010500794276595116
Test Loss:  0.009286416694521904
Valid Loss:  0.010507263243198395
Epoch:  346  	Training Loss: 0.010493466630578041
Test Loss:  0.009282564744353294
Valid Loss:  0.01050056517124176
Epoch:  347  	Training Loss: 0.010486170649528503
Test Loss:  0.009278643876314163
Valid Loss:  0.010493874549865723
Epoch:  348  	Training Loss: 0.0104789137840271
Test Loss:  0.009274642914533615
Valid Loss:  0.010487180203199387
Epoch:  349  	Training Loss: 0.010471687652170658
Test Loss:  0.009270576760172844
Valid Loss:  0.010480490513145924
Epoch:  350  	Training Loss: 0.010464496910572052
Test Loss:  0.00926659069955349
Valid Loss:  0.010473797097802162
Epoch:  351  	Training Loss: 0.010457336902618408
Test Loss:  0.009262594394385815
Valid Loss:  0.010467101819813251
Epoch:  352  	Training Loss: 0.010450206696987152
Test Loss:  0.00925859808921814
Valid Loss:  0.010460451245307922
Epoch:  353  	Training Loss: 0.010443132370710373
Test Loss:  0.009254536591470242
Valid Loss:   71%|███████   | 353/500 [04:10<02:08,  1.14it/s] 71%|███████   | 355/500 [04:10<01:32,  1.57it/s] 71%|███████▏  | 357/500 [04:10<01:07,  2.11it/s] 72%|███████▏  | 359/500 [04:10<00:50,  2.81it/s] 72%|███████▏  | 361/500 [04:16<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:16<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:17<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:17<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:17<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:23<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:23<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:23<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:24<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:24<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:30<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:30<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:30<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:30<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:31<00:36,  3.00it/s] 78%|███████▊  | 391/500 [04:37<02:11,  1.21s/it] 79%|███████▊  | 393/500 [04:37<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:37<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:37<00:47,  2.19it/s] 80%|███████▉  | 399/500 [04:38<00:34,  2.94it/s] 80%|████████  | 401/500 [04:44<01:58,  1.19s/it] 81%|████████  | 403/500 [04:44<01:23,  1.17it/s] 81%|████████  | 405/500 [04:44<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:44<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:44<00:30,  2.97it/s] 82%|████████▏ | 411/500 [04:51<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:51<01:15,  1.15it/s] 83%|████████▎ | 415/500 [04:51<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:51<00:38,  2.18it/s] 84%|████████▍ | 419/500 [04:51<00:27,  2.94it/s] 84%|████████▍ | 421/500 [04:58<01:36,  1.22s/it] 85%|████████▍ | 423/500 [04:58<01:07,  1.14it/s]0.010453793220221996
Epoch:  354  	Training Loss: 0.010436085984110832
Test Loss:  0.009250421077013016
Valid Loss:  0.010447138920426369
Epoch:  355  	Training Loss: 0.010429068468511105
Test Loss:  0.00924624688923359
Valid Loss:  0.010440485551953316
Epoch:  356  	Training Loss: 0.010422080755233765
Test Loss:  0.009242027997970581
Valid Loss:  0.01043383777141571
Epoch:  357  	Training Loss: 0.010415125638246536
Test Loss:  0.009237747639417648
Valid Loss:  0.010427189990878105
Epoch:  358  	Training Loss: 0.010408196598291397
Test Loss:  0.009233418852090836
Valid Loss:  0.010420544072985649
Epoch:  359  	Training Loss: 0.010401294566690922
Test Loss:  0.009229041635990143
Valid Loss:  0.010413899086415768
Epoch:  360  	Training Loss: 0.010394418612122536
Test Loss:  0.009224622510373592
Valid Loss:  0.010407263413071632
Epoch:  361  	Training Loss: 0.010387624613940716
Test Loss:  0.009220914915204048
Valid Loss:  0.010400932282209396
Epoch:  362  	Training Loss: 0.010380912572145462
Test Loss:  0.009217305108904839
Valid Loss:  0.010394711047410965
Epoch:  363  	Training Loss: 0.010374312289059162
Test Loss:  0.009213637560606003
Valid Loss:  0.010388495400547981
Epoch:  364  	Training Loss: 0.0103677436709404
Test Loss:  0.009209908545017242
Valid Loss:  0.010382280685007572
Epoch:  365  	Training Loss: 0.010361205786466599
Test Loss:  0.009206118993461132
Valid Loss:  0.010376058518886566
Epoch:  366  	Training Loss: 0.010354690253734589
Test Loss:  0.009202277287840843
Valid Loss:  0.010369841009378433
Epoch:  367  	Training Loss: 0.010348206385970116
Test Loss:  0.009198375046253204
Valid Loss:  0.010363619774580002
Epoch:  368  	Training Loss: 0.010341745801270008
Test Loss:  0.009194426238536835
Valid Loss:  0.01035740040242672
Epoch:  369  	Training Loss: 0.010335315950214863
Test Loss:  0.009190421551465988
Valid Loss:  0.010351177304983139
Epoch:  370  	Training Loss: 0.010328908450901508
Test Loss:  0.00918637029826641
Valid Loss:  0.010344961658120155
Epoch:  371  	Training Loss: 0.010322527959942818
Test Loss:  0.009182270616292953
Valid Loss:  0.010338742285966873
Epoch:  372  	Training Loss: 0.010316172614693642
Test Loss:  0.00917818397283554
Valid Loss:  0.01033259741961956
Epoch:  373  	Training Loss: 0.010309908539056778
Test Loss:  0.009174199774861336
Valid Loss:  0.010326454415917397
Epoch:  374  	Training Loss: 0.010303669609129429
Test Loss:  0.009170256555080414
Valid Loss:  0.010320312343537807
Epoch:  375  	Training Loss: 0.010297453962266445
Test Loss:  0.009166271425783634
Valid Loss:  0.010314170271158218
Epoch:  376  	Training Loss: 0.010291257873177528
Test Loss:  0.009162254631519318
Valid Loss:  0.0103080365806818
Epoch:  377  	Training Loss: 0.010285091586411
Test Loss:  0.009158194996416569
Valid Loss:  0.010301899164915085
Epoch:  378  	Training Loss: 0.010278940200805664
Test Loss:  0.009154101833701134
Valid Loss:  0.010295763611793518
Epoch:  379  	Training Loss: 0.010272813029587269
Test Loss:  0.009149972349405289
Valid Loss:  0.01028963178396225
Epoch:  380  	Training Loss: 0.01026670727878809
Test Loss:  0.009145813062787056
Valid Loss:  0.01028350181877613
Epoch:  381  	Training Loss: 0.010260620154440403
Test Loss:  0.009141622111201286
Valid Loss:  0.01027737744152546
Epoch:  382  	Training Loss: 0.010254560969769955
Test Loss:  0.009137557819485664
Valid Loss:  0.010271337814629078
Epoch:  383  	Training Loss: 0.01024855487048626
Test Loss:  0.009133458137512207
Valid Loss:  0.010265303775668144
Epoch:  384  	Training Loss: 0.010242569260299206
Test Loss:  0.009129336103796959
Valid Loss:  0.010259272530674934
Epoch:  385  	Training Loss: 0.010236609727144241
Test Loss:  0.009125174023211002
Valid Loss:  0.0102532422170043
Epoch:  386  	Training Loss: 0.01023066509515047
Test Loss:  0.009120984002947807
Valid Loss:  0.010247213765978813
Epoch:  387  	Training Loss: 0.010224740952253342
Test Loss:  0.009116768836975098
Valid Loss:  0.01024119183421135
Epoch:  388  	Training Loss: 0.010218838229775429
Test Loss:  0.009112521074712276
Valid Loss:  0.010235171765089035
Epoch:  389  	Training Loss: 0.010213010013103485
Test Loss:  0.009108935482800007
Valid Loss:  0.01022945437580347
Epoch:  390  	Training Loss: 0.010207257233560085
Test Loss:  0.009105313569307327
Valid Loss:  0.010223738849163055
Epoch:  391  	Training Loss: 0.0102015295997262
Test Loss:  0.009101640433073044
Valid Loss:  0.010218024253845215
Epoch:  392  	Training Loss: 0.010195819661021233
Test Loss:  0.00909816101193428
Valid Loss:  0.010212475433945656
Epoch:  393  	Training Loss: 0.010190244764089584
Test Loss:  0.009094638749957085
Valid Loss:  0.010206928476691246
Epoch:  394  	Training Loss: 0.010184692218899727
Test Loss:  0.00909107830375433
Valid Loss:  0.010201375000178814
Epoch:  395  	Training Loss: 0.010179157368838787
Test Loss:  0.009087484329938889
Valid Loss:  0.010195830836892128
Epoch:  396  	Training Loss: 0.010173647664487362
Test Loss:  0.00908384844660759
Valid Loss:  0.01019027829170227
Epoch:  397  	Training Loss: 0.01016815472394228
Test Loss:  0.00908017810434103
Valid Loss:  0.010184729471802711
Epoch:  398  	Training Loss: 0.01016267854720354
Test Loss:  0.009076472371816635
Valid Loss:  0.010179177857935429
Epoch:  399  	Training Loss: 0.010157221928238869
Test Loss:  0.00907273218035698
Valid Loss:  0.01017362717539072
Epoch:  400  	Training Loss: 0.010151783004403114
Test Loss:  0.009068958461284637
Valid Loss:  0.010168076492846012
Epoch:  401  	Training Loss: 0.01014641858637333
Test Loss:  0.009065832942724228
Valid Loss:  0.010162828490138054
Epoch:  402  	Training Loss: 0.010141117498278618
Test Loss:  0.009062780067324638
Valid Loss:  0.010157652199268341
Epoch:  403  	Training Loss: 0.010135865770280361
Test Loss:  0.009059677831828594
Valid Loss:  0.010152468457818031
Epoch:  404  	Training Loss: 0.010130634531378746
Test Loss:  0.009056534618139267
Valid Loss:  0.010147280991077423
Epoch:  405  	Training Loss: 0.010125420987606049
Test Loss:  0.009053343906998634
Valid Loss:  0.010142089799046516
Epoch:  406  	Training Loss: 0.010120228864252567
Test Loss:  0.009050114080309868
Valid Loss:  0.010136894881725311
Epoch:  407  	Training Loss: 0.010115053504705429
Test Loss:  0.009046847000718117
Valid Loss:  0.010131698101758957
Epoch:  408  	Training Loss: 0.010109898634254932
Test Loss:  0.009043531492352486
Valid Loss:  0.010126500390470028
Epoch:  409  	Training Loss: 0.010104760527610779
Test Loss:  0.009040184319019318
Valid Loss:  0.01012130081653595
Epoch:  410  	Training Loss: 0.010099643841385841
Test Loss:  0.009036797098815441
Valid Loss:  0.01011609472334385
Epoch:  411  	Training Loss: 0.010094542056322098
Test Loss:  0.009033373557031155
Valid Loss:  0.010110893286764622
Epoch:  412  	Training Loss: 0.010089460760354996
Test Loss:  0.009030096232891083
Valid Loss:  0.010105855762958527
Epoch:  413  	Training Loss: 0.010084530338644981
Test Loss:  0.009026787243783474
Valid Loss:  0.010100826621055603
Epoch:  414  	Training Loss: 0.010079623199999332
Test Loss:  0.009023439139127731
Valid Loss:  0.010095786303281784
Epoch:  415  	Training Loss: 0.010074726305902004
Test Loss:  0.009020062163472176
Valid Loss:  0.010090749710798264
Epoch:  416  	Training Loss: 0.010069851763546467
Test Loss:  0.009016647934913635
Valid Loss:  0.010085707530379295
Epoch:  417  	Training Loss: 0.010064986534416676
Test Loss:  0.009013209491968155
Valid Loss:  0.010080669075250626
Epoch:  418  	Training Loss: 0.010060140863060951
Test Loss:  0.00900973193347454
Valid Loss:  0.010075624100863934
Epoch:  419  	Training Loss: 0.010055306367576122
Test Loss:  0.009006230160593987
Valid Loss:  0.01007058285176754
Epoch:  420  	Training Loss: 0.010050490498542786
Test Loss:  0.009002698585391045
Valid Loss:  0.010065539740025997
Epoch:  421  	Training Loss: 0.01004568487405777
Test Loss:  0.008999143727123737
Valid Loss:  0.010060498490929604
Epoch:  422  	Training Loss: 0.010040899738669395
Test Loss:  0.008995653130114079
Valid Loss:  0.010055484250187874
Epoch:  423  	Training Loss: 0.010036107152700424
Test Loss:  0.008992139250040054
Valid Loss:  0.010050474666059017
 85%|████████▌ | 425/500 [04:58<00:47,  1.58it/s] 85%|████████▌ | 427/500 [04:58<00:33,  2.16it/s] 86%|████████▌ | 429/500 [04:59<00:24,  2.91it/s] 86%|████████▌ | 431/500 [05:05<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:05<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:05<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:05<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:06<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:12<01:11,  1.20s/it] 89%|████████▊ | 443/500 [05:12<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:12<00:34,  1.59it/s] 89%|████████▉ | 447/500 [05:12<00:24,  2.18it/s] 90%|████████▉ | 449/500 [05:13<00:17,  2.92it/s] 90%|█████████ | 451/500 [05:19<00:58,  1.18s/it] 91%|█████████ | 453/500 [05:19<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:19<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:19<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:19<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:26<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:26<00:15,  2.17it/s] 94%|█████████▍| 469/500 [05:26<00:10,  2.88it/s] 94%|█████████▍| 471/500 [05:33<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:33<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.59it/s] 95%|█████████▌| 477/500 [05:33<00:10,  2.15it/s] 96%|█████████▌| 479/500 [05:33<00:07,  2.86it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.15it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.59it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:40<00:03,  2.93it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:47<00:06,  1.16it/s]Epoch:  424  	Training Loss: 0.010031336918473244
Test Loss:  0.008988600224256516
Valid Loss:  0.010045464150607586
Epoch:  425  	Training Loss: 0.010026577860116959
Test Loss:  0.008985033258795738
Valid Loss:  0.010040458291769028
Epoch:  426  	Training Loss: 0.010021832771599293
Test Loss:  0.008981438353657722
Valid Loss:  0.010035442188382149
Epoch:  427  	Training Loss: 0.010017098858952522
Test Loss:  0.008977819234132767
Valid Loss:  0.010030433535575867
Epoch:  428  	Training Loss: 0.010012384504079819
Test Loss:  0.008974181488156319
Valid Loss:  0.01002542581409216
Epoch:  429  	Training Loss: 0.01000768132507801
Test Loss:  0.00897051952779293
Valid Loss:  0.010020419955253601
Epoch:  430  	Training Loss: 0.010002990253269672
Test Loss:  0.008966835215687752
Valid Loss:  0.010015411302447319
Epoch:  431  	Training Loss: 0.009998313151299953
Test Loss:  0.008963122963905334
Valid Loss:  0.010010402649641037
Epoch:  432  	Training Loss: 0.009993644431233406
Test Loss:  0.008959593251347542
Valid Loss:  0.010005555115640163
Epoch:  433  	Training Loss: 0.009989102371037006
Test Loss:  0.00895603559911251
Valid Loss:  0.010000702925026417
Epoch:  434  	Training Loss: 0.009984568692743778
Test Loss:  0.00895245373249054
Valid Loss:  0.00999585259705782
Epoch:  435  	Training Loss: 0.00998004525899887
Test Loss:  0.00894885789602995
Valid Loss:  0.009991008788347244
Epoch:  436  	Training Loss: 0.009975539520382881
Test Loss:  0.008945237845182419
Valid Loss:  0.009986160323023796
Epoch:  437  	Training Loss: 0.009971042163670063
Test Loss:  0.008941598236560822
Valid Loss:  0.009981314651668072
Epoch:  438  	Training Loss: 0.00996655598282814
Test Loss:  0.00893794372677803
Valid Loss:  0.009976472705602646
Epoch:  439  	Training Loss: 0.009962085634469986
Test Loss:  0.008934268727898598
Valid Loss:  0.009971647523343563
Epoch:  440  	Training Loss: 0.009957622736692429
Test Loss:  0.008930577896535397
Valid Loss:  0.009967029094696045
Epoch:  441  	Training Loss: 0.009953205473721027
Test Loss:  0.008927498012781143
Valid Loss:  0.009962654672563076
Epoch:  442  	Training Loss: 0.009948903694748878
Test Loss:  0.008925065398216248
Valid Loss:  0.009958535432815552
Epoch:  443  	Training Loss: 0.009944665245711803
Test Loss:  0.008922591805458069
Valid Loss:  0.009954424574971199
Epoch:  444  	Training Loss: 0.00994044542312622
Test Loss:  0.008920077234506607
Valid Loss:  0.00995030626654625
Epoch:  445  	Training Loss: 0.009936243295669556
Test Loss:  0.008917516097426414
Valid Loss:  0.009946182370185852
Epoch:  446  	Training Loss: 0.009932052344083786
Test Loss:  0.008914921432733536
Valid Loss:  0.00994205940514803
Epoch:  447  	Training Loss: 0.00992787815630436
Test Loss:  0.008912280201911926
Valid Loss:  0.009937929920852184
Epoch:  448  	Training Loss: 0.009923717007040977
Test Loss:  0.008909685537219048
Valid Loss:  0.009933801367878914
Epoch:  449  	Training Loss: 0.009919572621583939
Test Loss:  0.00890712533146143
Valid Loss:  0.009929667226970196
Epoch:  450  	Training Loss: 0.009915439411997795
Test Loss:  0.008904535323381424
Valid Loss:  0.009925536811351776
Epoch:  451  	Training Loss: 0.00991132389754057
Test Loss:  0.008901914581656456
Valid Loss:  0.009921405464410782
Epoch:  452  	Training Loss: 0.009907221421599388
Test Loss:  0.008899389766156673
Valid Loss:  0.009917372837662697
Epoch:  453  	Training Loss: 0.009903207421302795
Test Loss:  0.008896944113075733
Valid Loss:  0.009913339279592037
Epoch:  454  	Training Loss: 0.009899206459522247
Test Loss:  0.00889451615512371
Valid Loss:  0.009909303858876228
Epoch:  455  	Training Loss: 0.009895218536257744
Test Loss:  0.008892059326171875
Valid Loss:  0.009905265644192696
Epoch:  456  	Training Loss: 0.009891241788864136
Test Loss:  0.008889574557542801
Valid Loss:  0.009901228360831738
Epoch:  457  	Training Loss: 0.009887278079986572
Test Loss:  0.008887067437171936
Valid Loss:  0.009897186420857906
Epoch:  458  	Training Loss: 0.009883327409625053
Test Loss:  0.008884533308446407
Valid Loss:  0.0098931435495615
Epoch:  459  	Training Loss: 0.009879386983811855
Test Loss:  0.00888197310268879
Valid Loss:  0.009889103472232819
Epoch:  460  	Training Loss: 0.009875459596514702
Test Loss:  0.008879391476511955
Valid Loss:  0.009885060600936413
Epoch:  461  	Training Loss: 0.009871541522443295
Test Loss:  0.008876859210431576
Valid Loss:  0.009881017729640007
Epoch:  462  	Training Loss: 0.009867636486887932
Test Loss:  0.008874502032995224
Valid Loss:  0.009877057746052742
Epoch:  463  	Training Loss: 0.009863799437880516
Test Loss:  0.008872127160429955
Valid Loss:  0.009873265400528908
Epoch:  464  	Training Loss: 0.009859973564743996
Test Loss:  0.008869729936122894
Valid Loss:  0.009869472123682499
Epoch:  465  	Training Loss: 0.009856159798800945
Test Loss:  0.008867308497428894
Valid Loss:  0.00986568070948124
Epoch:  466  	Training Loss: 0.009852349758148193
Test Loss:  0.008864871226251125
Valid Loss:  0.009861892089247704
Epoch:  467  	Training Loss: 0.00984855554997921
Test Loss:  0.008862417191267014
Valid Loss:  0.009858105331659317
Epoch:  468  	Training Loss: 0.009844772517681122
Test Loss:  0.008859943598508835
Valid Loss:  0.00985431857407093
Epoch:  469  	Training Loss: 0.00984099693596363
Test Loss:  0.008857453241944313
Valid Loss:  0.009850533679127693
Epoch:  470  	Training Loss: 0.009837232530117035
Test Loss:  0.008854947984218597
Valid Loss:  0.009846750646829605
Epoch:  471  	Training Loss: 0.00983348023146391
Test Loss:  0.00885242410004139
Valid Loss:  0.009842971339821815
Epoch:  472  	Training Loss: 0.009829734452068806
Test Loss:  0.008849937468767166
Valid Loss:  0.00983922928571701
Epoch:  473  	Training Loss: 0.009826021268963814
Test Loss:  0.008847437798976898
Valid Loss:  0.009835489094257355
Epoch:  474  	Training Loss: 0.009822316467761993
Test Loss:  0.00884491577744484
Valid Loss:  0.009831748902797699
Epoch:  475  	Training Loss: 0.009818615391850471
Test Loss:  0.00884238351136446
Valid Loss:  0.009828012436628342
Epoch:  476  	Training Loss: 0.009814929217100143
Test Loss:  0.008839837275445461
Valid Loss:  0.009824277833104134
Epoch:  477  	Training Loss: 0.009811252355575562
Test Loss:  0.008837275207042694
Valid Loss:  0.0098205441609025
Epoch:  478  	Training Loss: 0.009807582944631577
Test Loss:  0.008834700100123882
Valid Loss:  0.009816814213991165
Epoch:  479  	Training Loss: 0.009803923778235912
Test Loss:  0.008832111023366451
Valid Loss:  0.009813088923692703
Epoch:  480  	Training Loss: 0.009800273925065994
Test Loss:  0.008829512633383274
Valid Loss:  0.009809363633394241
Epoch:  481  	Training Loss: 0.009796632453799248
Test Loss:  0.008826900273561478
Valid Loss:  0.009805643931031227
Epoch:  482  	Training Loss: 0.009793000295758247
Test Loss:  0.008824405260384083
Valid Loss:  0.009802024811506271
Epoch:  483  	Training Loss: 0.009789451956748962
Test Loss:  0.008821896277368069
Valid Loss:  0.009798405691981316
Epoch:  484  	Training Loss: 0.009785911068320274
Test Loss:  0.00881937611848116
Valid Loss:  0.009794792160391808
Epoch:  485  	Training Loss: 0.009782378561794758
Test Loss:  0.008816844783723354
Valid Loss:  0.00979117676615715
Epoch:  486  	Training Loss: 0.009778855368494987
Test Loss:  0.008814300410449505
Valid Loss:  0.009787569753825665
Epoch:  487  	Training Loss: 0.009775339625775814
Test Loss:  0.00881174299865961
Valid Loss:  0.00978396087884903
Epoch:  488  	Training Loss: 0.009771831333637238
Test Loss:  0.008809172548353672
Valid Loss:  0.009780354797840118
Epoch:  489  	Training Loss: 0.009768332354724407
Test Loss:  0.00880659744143486
Valid Loss:  0.009776752442121506
Epoch:  490  	Training Loss: 0.009764840826392174
Test Loss:  0.008804013021290302
Valid Loss:  0.00977315567433834
Epoch:  491  	Training Loss: 0.00976136140525341
Test Loss:  0.0088014155626297
Valid Loss:  0.00976955983787775
Epoch:  492  	Training Loss: 0.009757885709404945
Test Loss:  0.008798906579613686
Valid Loss:  0.00976604875177145
Epoch:  493  	Training Loss: 0.009754477068781853
Test Loss:  0.008796395733952522
Valid Loss:  0.009762544184923172
 99%|█████████▉| 495/500 [05:47<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:47<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:47<00:00,  2.95it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
Epoch:  494  	Training Loss: 0.009751085191965103
Test Loss:  0.008793871849775314
Valid Loss:  0.009759039618074894
Epoch:  495  	Training Loss: 0.009747697040438652
Test Loss:  0.00879133865237236
Valid Loss:  0.009755542501807213
Epoch:  496  	Training Loss: 0.009744318202137947
Test Loss:  0.00878879614174366
Valid Loss:  0.009752044454216957
Epoch:  497  	Training Loss: 0.00974094495177269
Test Loss:  0.008786244317889214
Valid Loss:  0.009748551994562149
Epoch:  498  	Training Loss: 0.009737581014633179
Test Loss:  0.00878368504345417
Valid Loss:  0.009745056740939617
Epoch:  499  	Training Loss: 0.009734218940138817
Test Loss:  0.00878111645579338
Valid Loss:  0.009741581976413727
Epoch:  500  	Training Loss: 0.0097308699041605
Test Loss:  0.008778541348874569
Valid Loss:  0.00973827950656414
seed is  3
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:55,  6.24s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:46,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:36,  2.19it/s]  6%|▌         | 29/500 [00:20<02:42,  2.91it/s]  6%|▌         | 31/500 [00:27<09:34,  1.22s/it]  7%|▋         | 33/500 [00:27<06:49,  1.14it/s]  7%|▋         | 35/500 [00:27<04:54,  1.58it/s]  7%|▋         | 37/500 [00:27<03:34,  2.16it/s]  8%|▊         | 39/500 [00:27<02:38,  2.91it/s]  8%|▊         | 41/500 [00:33<09:05,  1.19s/it]  9%|▊         | 43/500 [00:34<06:29,  1.17it/s]  9%|▉         | 45/500 [00:34<04:40,  1.62it/s]  9%|▉         | 47/500 [00:34<03:24,  2.22it/s] 10%|▉         | 49/500 [00:34<02:31,  2.98it/s] 10%|█         | 51/500 [00:40<08:45,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:41<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:26,  3.00it/s] 12%|█▏        | 61/500 [00:53<15:36,  2.13s/it] 13%|█▎        | 63/500 [00:54<11:01,  1.51s/it] 13%|█▎        | 65/500 [00:54<07:49,  1.08s/it] 13%|█▎        | 67/500 [00:54<05:35,  1.29it/s] 14%|█▍        | 69/500 [00:54<04:02,  1.78it/s] 14%|█▍        | 71/500 [01:00<09:36,  1.34s/it]Epoch:  1  	Training Loss: 0.11148996651172638
Test Loss:  7.52491569519043
Valid Loss:  7.465451717376709
Epoch:  2  	Training Loss: 7.389500617980957
Test Loss:  369.08465576171875
Valid Loss:  362.06689453125
Epoch:  3  	Training Loss: 359.35821533203125
Test Loss:  1.303199052810669
Valid Loss:  1.3282760381698608
Epoch:  4  	Training Loss: 1.323254108428955
Test Loss:  1.3030918836593628
Valid Loss:  1.3282239437103271
Epoch:  5  	Training Loss: 1.3231432437896729
Test Loss:  1.3029847145080566
Valid Loss:  1.3281714916229248
Epoch:  6  	Training Loss: 1.3230352401733398
Test Loss:  1.3028810024261475
Valid Loss:  1.3281209468841553
Epoch:  7  	Training Loss: 1.3229355812072754
Test Loss:  1.3027875423431396
Valid Loss:  1.328074336051941
Epoch:  8  	Training Loss: 1.3228466510772705
Test Loss:  1.3027048110961914
Valid Loss:  1.3280277252197266
Epoch:  9  	Training Loss: 1.3227578401565552
Test Loss:  1.3026220798492432
Valid Loss:  1.3279809951782227
Epoch:  10  	Training Loss: 1.322672724723816
Test Loss:  1.3025453090667725
Valid Loss:  1.3279378414154053
Epoch:  11  	Training Loss: 1.3225986957550049
Test Loss:  1.302474021911621
Valid Loss:  1.3278977870941162
Epoch:  12  	Training Loss: 1.322533130645752
Test Loss:  4.859142303466797
Valid Loss:  4.856155872344971
Epoch:  13  	Training Loss: 4.720242023468018
Test Loss:  0.09171389043331146
Valid Loss:  0.09951648861169815
Epoch:  14  	Training Loss: 0.11072228103876114
Test Loss:  0.08936990797519684
Valid Loss:  0.09651500731706619
Epoch:  15  	Training Loss: 0.1076648160815239
Test Loss:  0.08752802759408951
Valid Loss:  0.09470473229885101
Epoch:  16  	Training Loss: 0.10592865943908691
Test Loss:  0.08581557869911194
Valid Loss:  0.09314315021038055
Epoch:  17  	Training Loss: 0.10445593297481537
Test Loss:  0.08422397077083588
Valid Loss:  0.09169785678386688
Epoch:  18  	Training Loss: 0.103096604347229
Test Loss:  0.08274439722299576
Valid Loss:  0.09036113321781158
Epoch:  19  	Training Loss: 0.1018422469496727
Test Loss:  0.08136850595474243
Valid Loss:  0.08912404626607895
Epoch:  20  	Training Loss: 0.10068376362323761
Test Loss:  0.08008880913257599
Valid Loss:  0.08797959983348846
Epoch:  21  	Training Loss: 0.09961477667093277
Test Loss:  0.07889825105667114
Valid Loss:  0.08692070841789246
Epoch:  22  	Training Loss: 0.09862782806158066
Test Loss:  0.23053273558616638
Valid Loss:  0.22472012042999268
Epoch:  23  	Training Loss: 0.21434386074543
Test Loss:  0.10549719631671906
Valid Loss:  0.11217549443244934
Epoch:  24  	Training Loss: 0.12318990379571915
Test Loss:  0.0734211876988411
Valid Loss:  0.08130596578121185
Epoch:  25  	Training Loss: 0.09200118482112885
Test Loss:  0.06547217816114426
Valid Loss:  0.07346420735120773
Epoch:  26  	Training Loss: 0.08396880328655243
Test Loss:  0.06162149831652641
Valid Loss:  0.07018344104290009
Epoch:  27  	Training Loss: 0.08095331490039825
Test Loss:  0.05904586240649223
Valid Loss:  0.0680825263261795
Epoch:  28  	Training Loss: 0.07906271517276764
Test Loss:  0.05730263143777847
Valid Loss:  0.06673072278499603
Epoch:  29  	Training Loss: 0.07787716388702393
Test Loss:  0.05610789731144905
Valid Loss:  0.06585600227117538
Epoch:  30  	Training Loss: 0.07713361084461212
Test Loss:  0.05527817830443382
Valid Loss:  0.06528569757938385
Epoch:  31  	Training Loss: 0.07666709274053574
Test Loss:  0.05469419062137604
Valid Loss:  0.06491079926490784
Epoch:  32  	Training Loss: 0.07637431472539902
Test Loss:  0.029912643134593964
Valid Loss:  0.036445681005716324
Epoch:  33  	Training Loss: 0.03937355428934097
Test Loss:  0.02463393285870552
Valid Loss:  0.03034653142094612
Epoch:  34  	Training Loss: 0.033481039106845856
Test Loss:  0.020993273705244064
Valid Loss:  0.02549627423286438
Epoch:  35  	Training Loss: 0.027602849528193474
Test Loss:  0.017972804605960846
Valid Loss:  0.022791394963860512
Epoch:  36  	Training Loss: 0.02493760548532009
Test Loss:  0.017370475456118584
Valid Loss:  0.022232547402381897
Epoch:  37  	Training Loss: 0.02357698231935501
Test Loss:  0.016363054513931274
Valid Loss:  0.021353233605623245
Epoch:  38  	Training Loss: 0.02292957901954651
Test Loss:  0.016356229782104492
Valid Loss:  0.021230008453130722
Epoch:  39  	Training Loss: 0.022546924650669098
Test Loss:  0.015929732471704483
Valid Loss:  0.02086404524743557
Epoch:  40  	Training Loss: 0.02230723761022091
Test Loss:  0.01603538729250431
Valid Loss:  0.020870424807071686
Epoch:  41  	Training Loss: 0.022144582122564316
Test Loss:  0.015730498358607292
Valid Loss:  0.020617613568902016
Epoch:  42  	Training Loss: 0.022053517401218414
Test Loss:  0.015684034675359726
Valid Loss:  0.020575549453496933
Epoch:  43  	Training Loss: 0.02204909548163414
Test Loss:  0.01566457934677601
Valid Loss:  0.020553279668092728
Epoch:  44  	Training Loss: 0.02204637974500656
Test Loss:  0.01565614342689514
Valid Loss:  0.02053901180624962
Epoch:  45  	Training Loss: 0.02204400673508644
Test Loss:  0.015652302652597427
Valid Loss:  0.020528092980384827
Epoch:  46  	Training Loss: 0.02204170823097229
Test Loss:  0.015650395303964615
Valid Loss:  0.020518627017736435
Epoch:  47  	Training Loss: 0.022039443254470825
Test Loss:  0.015649311244487762
Valid Loss:  0.02050980180501938
Epoch:  48  	Training Loss: 0.02203720435500145
Test Loss:  0.01564856804907322
Valid Loss:  0.020501263439655304
Epoch:  49  	Training Loss: 0.02203497663140297
Test Loss:  0.015647973865270615
Valid Loss:  0.02049289643764496
Epoch:  50  	Training Loss: 0.022032765671610832
Test Loss:  0.015647444874048233
Valid Loss:  0.020484626293182373
Epoch:  51  	Training Loss: 0.022030575200915337
Test Loss:  0.015646997839212418
Valid Loss:  0.02047641947865486
Epoch:  52  	Training Loss: 0.022028401494026184
Test Loss:  0.013711629435420036
Valid Loss:  0.0177325289696455
Epoch:  53  	Training Loss: 0.019406162202358246
Test Loss:  0.013808384537696838
Valid Loss:  0.017154134809970856
Epoch:  54  	Training Loss: 0.017663471400737762
Test Loss:  0.010388732887804508
Valid Loss:  0.013962989673018456
Epoch:  55  	Training Loss: 0.01580177992582321
Test Loss:  0.014158166944980621
Valid Loss:  0.0167881790548563
Epoch:  56  	Training Loss: 0.016108239069581032
Test Loss:  0.012069951742887497
Valid Loss:  0.01613493263721466
Epoch:  57  	Training Loss: 0.01908821240067482
Test Loss:  0.030386008322238922
Valid Loss:  0.03174435347318649
Epoch:  58  	Training Loss: 0.028403203934431076
Test Loss:  0.04570114612579346
Valid Loss:  0.0507715567946434
Epoch:  59  	Training Loss: 0.057605210691690445
Test Loss:  0.12030769884586334
Valid Loss:  0.11772418022155762
Epoch:  60  	Training Loss: 0.10890645533800125
Test Loss:  0.1152862161397934
Valid Loss:  0.12070906162261963
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.13395166397094727
Test Loss:  0.035817041993141174
Valid Loss:  0.04072834178805351
Epoch:  62  	Training Loss: 0.04808877408504486
Test Loss:  0.017604980617761612
Valid Loss:  0.022106731310486794
Epoch:  63  	Training Loss: 0.024510115385055542
Test Loss:  0.013410168699920177
Valid Loss:  0.01716880314052105
Epoch:  64  	Training Loss: 0.01961223967373371
Test Loss:  0.013041826896369457
Valid Loss:  0.016579777002334595
Epoch:  65  	Training Loss: 0.01828981190919876
Test Loss:  0.012660260312259197
Valid Loss:  0.01609940081834793
Epoch:  66  	Training Loss: 0.01776817813515663
Test Loss:  0.012394087389111519
Valid Loss:  0.015738289803266525
Epoch:  67  	Training Loss: 0.017390629276633263
Test Loss:  0.012214194051921368
Valid Loss:  0.015441016294062138
Epoch:  68  	Training Loss: 0.017119701951742172
Test Loss:  0.012068506330251694
Valid Loss:  0.015197474509477615
Epoch:  69  	Training Loss: 0.01696380227804184
Test Loss:  0.01199459657073021
Valid Loss:  0.015055500902235508
Epoch:  70  	Training Loss: 0.01683218777179718
Test Loss:  0.011887511238455772
Valid Loss:  0.014854339882731438
Epoch:  71  	Training Loss: 0.016754522919654846
Test Loss:  0.011827656999230385
Valid Loss:  0.014737408608198166
Epoch:  72  	Training Loss: 0.01663392223417759
 15%|█▍        | 73/500 [01:00<06:50,  1.04it/s] 15%|█▌        | 75/500 [01:01<04:56,  1.43it/s] 15%|█▌        | 77/500 [01:01<03:36,  1.95it/s] 16%|█▌        | 79/500 [01:01<02:40,  2.63it/s] 16%|█▌        | 81/500 [01:07<08:25,  1.21s/it] 17%|█▋        | 83/500 [01:07<06:03,  1.15it/s] 17%|█▋        | 85/500 [01:08<04:23,  1.57it/s] 17%|█▋        | 87/500 [01:08<03:14,  2.13it/s] 18%|█▊        | 89/500 [01:08<02:23,  2.87it/s] 18%|█▊        | 91/500 [01:14<08:03,  1.18s/it] 19%|█▊        | 93/500 [01:14<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:14<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:15<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:15<02:13,  3.00it/s] 20%|██        | 101/500 [01:21<07:58,  1.20s/it] 21%|██        | 103/500 [01:21<05:41,  1.16it/s] 21%|██        | 105/500 [01:21<04:05,  1.61it/s] 21%|██▏       | 107/500 [01:21<02:59,  2.19it/s] 22%|██▏       | 109/500 [01:22<02:13,  2.93it/s] 22%|██▏       | 111/500 [01:28<07:39,  1.18s/it] 23%|██▎       | 113/500 [01:28<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:28<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:28<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:28<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:35<07:32,  1.20s/it] 25%|██▍       | 123/500 [01:35<05:23,  1.16it/s] 25%|██▌       | 125/500 [01:35<03:53,  1.61it/s] 25%|██▌       | 127/500 [01:35<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:35<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:42<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:42<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:42<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:42<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:42<02:00,  3.00it/s]Test Loss:  0.012310835532844067
Valid Loss:  0.014377663843333721
Epoch:  73  	Training Loss: 0.014826331287622452
Test Loss:  0.00922548957169056
Valid Loss:  0.011761697009205818
Epoch:  74  	Training Loss: 0.013644317165017128
Test Loss:  0.00875651091337204
Valid Loss:  0.011268578469753265
Epoch:  75  	Training Loss: 0.013163212686777115
Test Loss:  0.008687790483236313
Valid Loss:  0.011164046823978424
Epoch:  76  	Training Loss: 0.013094853609800339
Test Loss:  0.008662165142595768
Valid Loss:  0.01111657079309225
Epoch:  77  	Training Loss: 0.013077830895781517
Test Loss:  0.008650209754705429
Valid Loss:  0.011089546605944633
Epoch:  78  	Training Loss: 0.013068853877484798
Test Loss:  0.008641720749437809
Valid Loss:  0.011070046573877335
Epoch:  79  	Training Loss: 0.013064887374639511
Test Loss:  0.0086380485445261
Valid Loss:  0.011060770601034164
Epoch:  80  	Training Loss: 0.013063410297036171
Test Loss:  0.008636164478957653
Valid Loss:  0.011053526774048805
Epoch:  81  	Training Loss: 0.013062426820397377
Test Loss:  0.008634424768388271
Valid Loss:  0.011046689003705978
Epoch:  82  	Training Loss: 0.013061530888080597
Test Loss:  0.008524641394615173
Valid Loss:  0.010845029726624489
Epoch:  83  	Training Loss: 0.012546791695058346
Test Loss:  0.008603991009294987
Valid Loss:  0.010879108682274818
Epoch:  84  	Training Loss: 0.012434957548975945
Test Loss:  0.008669341914355755
Valid Loss:  0.010922820307314396
Epoch:  85  	Training Loss: 0.012410655617713928
Test Loss:  0.008705975487828255
Valid Loss:  0.010949254967272282
Epoch:  86  	Training Loss: 0.01240537315607071
Test Loss:  0.008724392391741276
Valid Loss:  0.010962888598442078
Epoch:  87  	Training Loss: 0.012404222972691059
Test Loss:  0.008733270689845085
Valid Loss:  0.010969533585011959
Epoch:  88  	Training Loss: 0.012403969652950764
Test Loss:  0.008737477473914623
Valid Loss:  0.01097269169986248
Epoch:  89  	Training Loss: 0.012403913773596287
Test Loss:  0.008739449083805084
Valid Loss:  0.010974174365401268
Epoch:  90  	Training Loss: 0.012403898872435093
Test Loss:  0.008740369230508804
Valid Loss:  0.01097487099468708
Epoch:  91  	Training Loss: 0.012403896078467369
Test Loss:  0.008740800432860851
Valid Loss:  0.010975195094943047
Epoch:  92  	Training Loss: 0.012403896078467369
Test Loss:  0.0068089100532233715
Valid Loss:  0.008699272759258747
Epoch:  93  	Training Loss: 0.009836258366703987
Test Loss:  0.005566773004829884
Valid Loss:  0.007158899679780006
Epoch:  94  	Training Loss: 0.008126541040837765
Test Loss:  0.004686097148805857
Valid Loss:  0.006034852936863899
Epoch:  95  	Training Loss: 0.00686211371794343
Test Loss:  0.003998111933469772
Valid Loss:  0.0051566241309046745
Epoch:  96  	Training Loss: 0.005884403362870216
Test Loss:  0.0034517538733780384
Valid Loss:  0.004449159372597933
Epoch:  97  	Training Loss: 0.005083444528281689
Test Loss:  0.0029978612437844276
Valid Loss:  0.0038706474006175995
Epoch:  98  	Training Loss: 0.004418791271746159
Test Loss:  0.0026172632351517677
Valid Loss:  0.003386220196262002
Epoch:  99  	Training Loss: 0.0038536135107278824
Test Loss:  0.0022964784875512123
Valid Loss:  0.00297361658886075
Epoch:  100  	Training Loss: 0.0033694724552333355
Test Loss:  0.0020236149430274963
Valid Loss:  0.002621915889903903
Epoch:  101  	Training Loss: 0.002954494208097458
Test Loss:  0.0017911097966134548
Valid Loss:  0.002320241881534457
Epoch:  102  	Training Loss: 0.002598612569272518
Test Loss:  0.0014157552504912019
Valid Loss:  0.0018792214104905725
Epoch:  103  	Training Loss: 0.002120003569871187
Test Loss:  0.0011934185167774558
Valid Loss:  0.0016020414186641574
Epoch:  104  	Training Loss: 0.001773842261172831
Test Loss:  0.0010131492745131254
Valid Loss:  0.001398405060172081
Epoch:  105  	Training Loss: 0.0015620030462741852
Test Loss:  0.0008780476055108011
Valid Loss:  0.001245236024260521
Epoch:  106  	Training Loss: 0.0014072040794417262
Test Loss:  0.0007951739244163036
Valid Loss:  0.0011550309136509895
Epoch:  107  	Training Loss: 0.0012992878910154104
Test Loss:  0.0007418395252898335
Valid Loss:  0.0011017262004315853
Epoch:  108  	Training Loss: 0.001231699832715094
Test Loss:  0.000705795013345778
Valid Loss:  0.0010659655090421438
Epoch:  109  	Training Loss: 0.0011825324036180973
Test Loss:  0.0006785811856389046
Valid Loss:  0.0010372106917202473
Epoch:  110  	Training Loss: 0.001146970083937049
Test Loss:  0.0006579125765711069
Valid Loss:  0.0010149555746465921
Epoch:  111  	Training Loss: 0.0011173642706125975
Test Loss:  0.0006389297777786851
Valid Loss:  0.000991171458736062
Epoch:  112  	Training Loss: 0.0010903403162956238
Test Loss:  0.0005674227140843868
Valid Loss:  0.000862067099660635
Epoch:  113  	Training Loss: 0.000898718717508018
Test Loss:  0.0004995496710762382
Valid Loss:  0.0007434870349243283
Epoch:  114  	Training Loss: 0.0007603925187140703
Test Loss:  0.000447841826826334
Valid Loss:  0.000654654810205102
Epoch:  115  	Training Loss: 0.0006571197882294655
Test Loss:  0.0004063044907525182
Valid Loss:  0.0005848853616043925
Epoch:  116  	Training Loss: 0.000579574319999665
Test Loss:  0.0003687130520120263
Valid Loss:  0.0005262484773993492
Epoch:  117  	Training Loss: 0.0005201465683057904
Test Loss:  0.0003381409915164113
Valid Loss:  0.00047796801663935184
Epoch:  118  	Training Loss: 0.00047359560267068446
Test Loss:  0.0003154514415655285
Valid Loss:  0.00044103822438046336
Epoch:  119  	Training Loss: 0.00043705664575099945
Test Loss:  0.00029770293622277677
Valid Loss:  0.00041247904300689697
Epoch:  120  	Training Loss: 0.00040785042801871896
Test Loss:  0.00028384121833369136
Valid Loss:  0.00039101243601180613
Epoch:  121  	Training Loss: 0.00038490709266625345
Test Loss:  0.00027213647263124585
Valid Loss:  0.00037451591924764216
Epoch:  122  	Training Loss: 0.0003669177822303027
Test Loss:  0.00028302668943069875
Valid Loss:  0.0003709899028763175
Epoch:  123  	Training Loss: 0.0003531859256327152
Test Loss:  0.0002770886057987809
Valid Loss:  0.00036128523061051965
Epoch:  124  	Training Loss: 0.00034332150244154036
Test Loss:  0.0002694812137633562
Valid Loss:  0.0003511026152409613
Epoch:  125  	Training Loss: 0.0003340625262353569
Test Loss:  0.0002620965242385864
Valid Loss:  0.0003413966915104538
Epoch:  126  	Training Loss: 0.00032532576005905867
Test Loss:  0.0002550872741267085
Valid Loss:  0.00033219472970813513
Epoch:  127  	Training Loss: 0.0003170634154230356
Test Loss:  0.0002484390279278159
Valid Loss:  0.00032347001251764596
Epoch:  128  	Training Loss: 0.0003092244151048362
Test Loss:  0.0002420589153189212
Valid Loss:  0.00031516444869339466
Epoch:  129  	Training Loss: 0.00030178335146047175
Test Loss:  0.00023594082449562848
Valid Loss:  0.0003072502149734646
Epoch:  130  	Training Loss: 0.0002947206958197057
Test Loss:  0.0002301286585861817
Valid Loss:  0.0002997351111844182
Epoch:  131  	Training Loss: 0.00028801412554457784
Test Loss:  0.00022461058688350022
Valid Loss:  0.00029259815346449614
Epoch:  132  	Training Loss: 0.00028164274408482015
Test Loss:  0.00022401567548513412
Valid Loss:  0.0002914326614700258
Epoch:  133  	Training Loss: 0.0002806769625749439
Test Loss:  0.00022321147844195366
Valid Loss:  0.0002901891421061009
Epoch:  134  	Training Loss: 0.0002797186025418341
Test Loss:  0.0002222713374067098
Valid Loss:  0.00028889288660138845
Epoch:  135  	Training Loss: 0.0002787630946841091
Test Loss:  0.0002215127897216007
Valid Loss:  0.0002876846701838076
Epoch:  136  	Training Loss: 0.0002778180642053485
Test Loss:  0.00022077214089222252
Valid Loss:  0.000286496797343716
Epoch:  137  	Training Loss: 0.0002769047860056162
Test Loss:  0.00021989129891153425
Valid Loss:  0.0002853187615983188
Epoch:  138  	Training Loss: 0.000275992788374424
Test Loss:  0.00021918055426795036
Valid Loss:  0.0002842196845449507
Epoch:  139  	Training Loss: 0.0002750794810708612
Test Loss:  0.0002184706536354497
Valid Loss:  0.0002831311139743775
Epoch:  140  	Training Loss: 0.00027416093507781625
Test Loss:  0.00021761702373623848
Valid Loss:  0.00028196803759783506
Epoch:  141  	Training Loss: 0.00027320970548316836
 28%|██▊       | 141/500 [01:49<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:49<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:49<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:49<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:49<01:57,  3.00it/s] 30%|███       | 151/500 [01:56<06:58,  1.20s/it] 31%|███       | 153/500 [01:56<04:58,  1.16it/s] 31%|███       | 155/500 [01:56<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:56<02:36,  2.20it/s] 32%|███▏      | 159/500 [01:56<01:55,  2.95it/s] 32%|███▏      | 161/500 [02:03<06:53,  1.22s/it] 33%|███▎      | 163/500 [02:03<04:55,  1.14it/s] 33%|███▎      | 165/500 [02:03<03:32,  1.58it/s] 33%|███▎      | 167/500 [02:03<02:33,  2.16it/s] 34%|███▍      | 169/500 [02:03<01:53,  2.91it/s] 34%|███▍      | 171/500 [02:16<11:48,  2.15s/it] 35%|███▍      | 173/500 [02:16<08:20,  1.53s/it] 35%|███▌      | 175/500 [02:16<05:54,  1.09s/it] 35%|███▌      | 177/500 [02:16<04:12,  1.28it/s] 36%|███▌      | 179/500 [02:16<03:03,  1.75it/s] 36%|███▌      | 181/500 [02:23<07:14,  1.36s/it] 37%|███▋      | 183/500 [02:23<05:08,  1.03it/s] 37%|███▋      | 185/500 [02:23<03:41,  1.43it/s] 37%|███▋      | 187/500 [02:23<02:40,  1.95it/s] 38%|███▊      | 189/500 [02:23<01:59,  2.60it/s] 38%|███▊      | 191/500 [02:30<06:23,  1.24s/it] 39%|███▊      | 193/500 [02:30<04:33,  1.12it/s] 39%|███▉      | 195/500 [02:30<03:16,  1.56it/s] 39%|███▉      | 197/500 [02:30<02:22,  2.13it/s] 40%|███▉      | 199/500 [02:30<01:44,  2.88it/s] 40%|████      | 201/500 [02:37<05:58,  1.20s/it] 41%|████      | 203/500 [02:37<04:17,  1.15it/s] 41%|████      | 205/500 [02:37<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:37<02:14,  2.17it/s]Test Loss:  0.0002169092040276155
Valid Loss:  0.0002808712888509035
Epoch:  142  	Training Loss: 0.00027226231759414077
Test Loss:  0.0002174777036998421
Valid Loss:  0.00028097251197323203
Epoch:  143  	Training Loss: 0.0002721141208894551
Test Loss:  0.00021898200793657452
Valid Loss:  0.000281467626336962
Epoch:  144  	Training Loss: 0.0002720117336139083
Test Loss:  0.00021917404956184328
Valid Loss:  0.0002815047628246248
Epoch:  145  	Training Loss: 0.00027193824644200504
Test Loss:  0.0002197061403421685
Valid Loss:  0.00028168881544843316
Epoch:  146  	Training Loss: 0.0002718854520935565
Test Loss:  0.00022032170090824366
Valid Loss:  0.0002819037181325257
Epoch:  147  	Training Loss: 0.00027184822829440236
Test Loss:  0.00022039793839212507
Valid Loss:  0.0002819396322593093
Epoch:  148  	Training Loss: 0.00027182605117559433
Test Loss:  0.0002221709000878036
Valid Loss:  0.00028254877543076873
Epoch:  149  	Training Loss: 0.0002718236646614969
Test Loss:  0.00022009489475749433
Valid Loss:  0.0002818548819050193
Epoch:  150  	Training Loss: 0.0002718211035244167
Test Loss:  0.00022271895431913435
Valid Loss:  0.000282754423096776
Epoch:  151  	Training Loss: 0.0002718008472584188
Test Loss:  0.00022072889260016382
Valid Loss:  0.0002820804656948894
Epoch:  152  	Training Loss: 0.00027179979952052236
Test Loss:  0.00021947849018033594
Valid Loss:  0.00026517052901908755
Epoch:  153  	Training Loss: 0.0002443192061036825
Test Loss:  0.00019871605036314577
Valid Loss:  0.0002350674185436219
Epoch:  154  	Training Loss: 0.0002126785257132724
Test Loss:  0.00017997394024860114
Valid Loss:  0.00020056494395248592
Epoch:  155  	Training Loss: 0.00017656979616731405
Test Loss:  0.0001532682654215023
Valid Loss:  0.00017103567370213568
Epoch:  156  	Training Loss: 0.0001487710396759212
Test Loss:  0.00013640124234370887
Valid Loss:  0.00015316938515752554
Epoch:  157  	Training Loss: 0.00012954516569152474
Test Loss:  0.00011880378588102758
Valid Loss:  0.00013755765394307673
Epoch:  158  	Training Loss: 0.00011648447980405763
Test Loss:  0.00010841261246241629
Valid Loss:  0.00012807866733055562
Epoch:  159  	Training Loss: 0.00010757774725789204
Test Loss:  9.80106124188751e-05
Valid Loss:  0.00011974132212344557
Epoch:  160  	Training Loss: 0.00010124730761162937
Test Loss:  9.129001409746706e-05
Valid Loss:  0.00011406322300899774
Epoch:  161  	Training Loss: 9.663111995905638e-05
Test Loss:  8.544718730263412e-05
Valid Loss:  0.00010947538248728961
Epoch:  162  	Training Loss: 9.324867278337479e-05
Test Loss:  6.834050873294473e-05
Valid Loss:  9.992332343244925e-05
Epoch:  163  	Training Loss: 9.02467654668726e-05
Test Loss:  7.958638889249414e-05
Valid Loss:  0.00010456849850015715
Epoch:  164  	Training Loss: 8.864231494953856e-05
Test Loss:  6.399884296115488e-05
Valid Loss:  9.65682920650579e-05
Epoch:  165  	Training Loss: 8.777642506174743e-05
Test Loss:  7.983110117493197e-05
Valid Loss:  0.00010347779607400298
Epoch:  166  	Training Loss: 8.67644848767668e-05
Test Loss:  6.111507536843419e-05
Valid Loss:  9.464849426876754e-05
Epoch:  167  	Training Loss: 8.67591006681323e-05
Test Loss:  8.208133658627048e-05
Valid Loss:  0.00010391243267804384
Epoch:  168  	Training Loss: 8.61742882989347e-05
Test Loss:  5.9443678765092045e-05
Valid Loss:  9.384070290252566e-05
Epoch:  169  	Training Loss: 8.700864418642595e-05
Test Loss:  8.556073589716107e-05
Valid Loss:  0.00010542684321990237
Epoch:  170  	Training Loss: 8.67105700308457e-05
Test Loss:  5.9141762903891504e-05
Valid Loss:  9.436978143639863e-05
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 8.874064951669425e-05
Test Loss:  5.722637433791533e-05
Valid Loss:  8.88459908310324e-05
Epoch:  172  	Training Loss: 7.937687769299373e-05
Test Loss:  5.633591354126111e-05
Valid Loss:  8.646459900774062e-05
Epoch:  173  	Training Loss: 7.63340067351237e-05
Test Loss:  5.572689406108111e-05
Valid Loss:  8.456291106995195e-05
Epoch:  174  	Training Loss: 7.388582889689133e-05
Test Loss:  5.5295866332016885e-05
Valid Loss:  8.300961053464562e-05
Epoch:  175  	Training Loss: 7.187711889855564e-05
Test Loss:  5.4971009376458824e-05
Valid Loss:  8.170789806172252e-05
Epoch:  176  	Training Loss: 7.019958866294473e-05
Test Loss:  5.4719075706088915e-05
Valid Loss:  8.058884122874588e-05
Epoch:  177  	Training Loss: 6.877222040202469e-05
Test Loss:  5.449626041809097e-05
Valid Loss:  7.960241055116057e-05
Epoch:  178  	Training Loss: 6.753511115675792e-05
Test Loss:  5.427503492683172e-05
Valid Loss:  7.871187699493021e-05
Epoch:  179  	Training Loss: 6.644538370892406e-05
Test Loss:  5.403707837103866e-05
Valid Loss:  7.788775837980211e-05
Epoch:  180  	Training Loss: 6.547296652570367e-05
Test Loss:  5.378000787459314e-05
Valid Loss:  7.711502985330299e-05
Epoch:  181  	Training Loss: 6.45863838144578e-05
Test Loss:  5.3499785281019285e-05
Valid Loss:  7.638086390215904e-05
Epoch:  182  	Training Loss: 6.376711826305836e-05
Test Loss:  5.0321032176725566e-05
Valid Loss:  7.372572144959122e-05
Epoch:  183  	Training Loss: 6.156016024760902e-05
Test Loss:  4.763706965604797e-05
Valid Loss:  7.160248060245067e-05
Epoch:  184  	Training Loss: 5.9672718634828925e-05
Test Loss:  4.6783025027252734e-05
Valid Loss:  7.086654659360647e-05
Epoch:  185  	Training Loss: 5.944102304056287e-05
Test Loss:  4.7190529585350305e-05
Valid Loss:  7.115879270713776e-05
Epoch:  186  	Training Loss: 5.9345882618799806e-05
Test Loss:  4.710158464149572e-05
Valid Loss:  7.102551171556115e-05
Epoch:  187  	Training Loss: 5.929706458118744e-05
Test Loss:  4.722878657048568e-05
Valid Loss:  7.108550926204771e-05
Epoch:  188  	Training Loss: 5.925181176280603e-05
Test Loss:  4.7255762183340266e-05
Valid Loss:  7.105746772140265e-05
Epoch:  189  	Training Loss: 5.920876719756052e-05
Test Loss:  4.72752726636827e-05
Valid Loss:  7.102370727807283e-05
Epoch:  190  	Training Loss: 5.916694499319419e-05
Test Loss:  4.735748370876536e-05
Valid Loss:  7.104857650119811e-05
Epoch:  191  	Training Loss: 5.9128640714334324e-05
Test Loss:  4.734853428089991e-05
Valid Loss:  7.099255890352651e-05
Epoch:  192  	Training Loss: 5.909012907068245e-05
Test Loss:  4.720921424450353e-05
Valid Loss:  6.991121335886419e-05
Epoch:  193  	Training Loss: 5.680285539710894e-05
Test Loss:  4.664684092858806e-05
Valid Loss:  6.923472392372787e-05
Epoch:  194  	Training Loss: 5.581326695391908e-05
Test Loss:  4.5826745918020606e-05
Valid Loss:  6.858506822027266e-05
Epoch:  195  	Training Loss: 5.5149885156424716e-05
Test Loss:  4.497285044635646e-05
Valid Loss:  6.798192043788731e-05
Epoch:  196  	Training Loss: 5.463046545628458e-05
Test Loss:  4.41798401880078e-05
Valid Loss:  6.744515121681616e-05
Epoch:  197  	Training Loss: 5.420601519290358e-05
Test Loss:  4.3474276026245207e-05
Valid Loss:  6.697587377857417e-05
Epoch:  198  	Training Loss: 5.3850424592383206e-05
Test Loss:  4.285246177460067e-05
Valid Loss:  6.656379264313728e-05
Epoch:  199  	Training Loss: 5.354777749744244e-05
Test Loss:  4.230745253153145e-05
Valid Loss:  6.62006059428677e-05
Epoch:  200  	Training Loss: 5.328634870238602e-05
Test Loss:  4.183002238278277e-05
Valid Loss:  6.587865937035531e-05
Epoch:  201  	Training Loss: 5.30566212546546e-05
Test Loss:  4.140609235037118e-05
Valid Loss:  6.558765016961843e-05
Epoch:  202  	Training Loss: 5.2850369684165344e-05
Test Loss:  4.102449747733772e-05
Valid Loss:  6.497313734143972e-05
Epoch:  203  	Training Loss: 5.2360141125973314e-05
Test Loss:  4.0704122511669993e-05
Valid Loss:  6.440070865210146e-05
Epoch:  204  	Training Loss: 5.1892053306801245e-05
Test Loss:  4.04056154366117e-05
Valid Loss:  6.385898450389504e-05
Epoch:  205  	Training Loss: 5.1442315452732146e-05
Test Loss:  4.013915895484388e-05
Valid Loss:  6.334183854050934e-05
Epoch:  206  	Training Loss: 5.100903945276514e-05
Test Loss:  3.989174365415238e-05
Valid Loss:  6.28446287009865e-05
Epoch:  207  	Training Loss: 5.059045724919997e-05
Test Loss:  3.965697396779433e-05
Valid Loss:  6.236486660782248e-05
 42%|████▏     | 209/500 [02:37<01:39,  2.91it/s] 42%|████▏     | 211/500 [02:44<05:48,  1.21s/it] 43%|████▎     | 213/500 [02:44<04:08,  1.15it/s] 43%|████▎     | 215/500 [02:44<02:58,  1.60it/s] 43%|████▎     | 217/500 [02:44<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:44<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:51<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:51<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:51<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:51<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:51<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:58<05:26,  1.21s/it] 47%|████▋     | 233/500 [02:58<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:58<02:46,  1.59it/s] 47%|████▋     | 237/500 [02:58<02:01,  2.17it/s] 48%|████▊     | 239/500 [02:58<01:29,  2.92it/s] 48%|████▊     | 241/500 [03:05<05:15,  1.22s/it] 49%|████▊     | 243/500 [03:05<03:44,  1.14it/s] 49%|████▉     | 245/500 [03:05<02:41,  1.58it/s] 49%|████▉     | 247/500 [03:05<01:57,  2.16it/s] 50%|████▉     | 249/500 [03:05<01:26,  2.91it/s] 50%|█████     | 251/500 [03:12<04:56,  1.19s/it] 51%|█████     | 253/500 [03:12<03:31,  1.17it/s] 51%|█████     | 255/500 [03:12<02:31,  1.61it/s] 51%|█████▏    | 257/500 [03:12<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:12<01:21,  2.95it/s] 52%|█████▏    | 261/500 [03:19<04:45,  1.19s/it] 53%|█████▎    | 263/500 [03:19<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:19<02:27,  1.59it/s] 53%|█████▎    | 267/500 [03:19<01:47,  2.17it/s] 54%|█████▍    | 269/500 [03:19<01:18,  2.93it/s] 54%|█████▍    | 271/500 [03:26<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:26<03:15,  1.16it/s]Epoch:  208  	Training Loss: 5.0182934501208365e-05
Test Loss:  3.9417056541424245e-05
Valid Loss:  6.189018313307315e-05
Epoch:  209  	Training Loss: 4.9777278036344796e-05
Test Loss:  3.918866423191503e-05
Valid Loss:  6.143029895611107e-05
Epoch:  210  	Training Loss: 4.938265192322433e-05
Test Loss:  3.8968883018242195e-05
Valid Loss:  6.098375888541341e-05
Epoch:  211  	Training Loss: 4.8998004785971716e-05
Test Loss:  3.875569018418901e-05
Valid Loss:  6.054832192603499e-05
Epoch:  212  	Training Loss: 4.8622685426380485e-05
Test Loss:  3.904691766365431e-05
Valid Loss:  5.9893664001720026e-05
Epoch:  213  	Training Loss: 4.7892146540107206e-05
Test Loss:  3.9099151763366535e-05
Valid Loss:  5.9306392358848825e-05
Epoch:  214  	Training Loss: 4.732947127195075e-05
Test Loss:  3.9005884900689125e-05
Valid Loss:  5.8751342294272035e-05
Epoch:  215  	Training Loss: 4.6852004743414e-05
Test Loss:  3.883644239977002e-05
Valid Loss:  5.8225450629834086e-05
Epoch:  216  	Training Loss: 4.643088686862029e-05
Test Loss:  3.863437450490892e-05
Valid Loss:  5.773181328549981e-05
Epoch:  217  	Training Loss: 4.6054112317506224e-05
Test Loss:  3.842404839815572e-05
Valid Loss:  5.7272041885880753e-05
Epoch:  218  	Training Loss: 4.5715103624388576e-05
Test Loss:  3.821772406809032e-05
Valid Loss:  5.684563075192273e-05
Epoch:  219  	Training Loss: 4.540973895927891e-05
Test Loss:  3.802224819082767e-05
Valid Loss:  5.645201963488944e-05
Epoch:  220  	Training Loss: 4.5133900130167603e-05
Test Loss:  3.783998545259237e-05
Valid Loss:  5.6088902056217194e-05
Epoch:  221  	Training Loss: 4.4884720409754664e-05
Test Loss:  3.76723037334159e-05
Valid Loss:  5.5754520872142166e-05
Epoch:  222  	Training Loss: 4.465919846552424e-05
Test Loss:  3.75977651856374e-05
Valid Loss:  5.561819125432521e-05
Epoch:  223  	Training Loss: 4.458146941033192e-05
Test Loss:  3.7527268432313576e-05
Valid Loss:  5.5485528719145805e-05
Epoch:  224  	Training Loss: 4.4505934056360275e-05
Test Loss:  3.746068250620738e-05
Valid Loss:  5.5356671509798616e-05
Epoch:  225  	Training Loss: 4.443257785169408e-05
Test Loss:  3.739757084986195e-05
Valid Loss:  5.5231008445844054e-05
Epoch:  226  	Training Loss: 4.4361193431541324e-05
Test Loss:  3.733715129783377e-05
Valid Loss:  5.510866321856156e-05
Epoch:  227  	Training Loss: 4.4291853555478156e-05
Test Loss:  3.727970033651218e-05
Valid Loss:  5.498912651091814e-05
Epoch:  228  	Training Loss: 4.42243144789245e-05
Test Loss:  3.7224315747153014e-05
Valid Loss:  5.4872398322913796e-05
Epoch:  229  	Training Loss: 4.415861258166842e-05
Test Loss:  3.7171339499764144e-05
Valid Loss:  5.475822399603203e-05
Epoch:  230  	Training Loss: 4.4094747863709927e-05
Test Loss:  3.7120076740393415e-05
Valid Loss:  5.464688365464099e-05
Epoch:  231  	Training Loss: 4.40324074588716e-05
Test Loss:  3.7070327380206436e-05
Valid Loss:  5.453801713883877e-05
Epoch:  232  	Training Loss: 4.397180600790307e-05
Test Loss:  3.631534491432831e-05
Valid Loss:  5.3812284022569656e-05
Epoch:  233  	Training Loss: 4.351696770754643e-05
Test Loss:  3.573701542336494e-05
Valid Loss:  5.319745832821354e-05
Epoch:  234  	Training Loss: 4.313262616051361e-05
Test Loss:  3.528259549057111e-05
Valid Loss:  5.2661933295894414e-05
Epoch:  235  	Training Loss: 4.2794963519554585e-05
Test Loss:  3.4882214094977826e-05
Valid Loss:  5.216169302002527e-05
Epoch:  236  	Training Loss: 4.247043762006797e-05
Test Loss:  3.4556691389298066e-05
Valid Loss:  5.171340308152139e-05
Epoch:  237  	Training Loss: 4.217709647491574e-05
Test Loss:  3.4270724427187815e-05
Valid Loss:  5.129536293679848e-05
Epoch:  238  	Training Loss: 4.190078470855951e-05
Test Loss:  3.401592039153911e-05
Valid Loss:  5.0903927331091836e-05
Epoch:  239  	Training Loss: 4.163975972915068e-05
Test Loss:  3.3801348763518035e-05
Valid Loss:  5.054534267401323e-05
Epoch:  240  	Training Loss: 4.140135570196435e-05
Test Loss:  3.361784547450952e-05
Valid Loss:  5.021490142098628e-05
Epoch:  241  	Training Loss: 4.118263314012438e-05
Test Loss:  3.345883669680916e-05
Valid Loss:  4.9908885557670146e-05
Epoch:  242  	Training Loss: 4.098164936294779e-05
Test Loss:  3.395523890503682e-05
Valid Loss:  5.008021253161132e-05
Epoch:  243  	Training Loss: 4.08924970543012e-05
Test Loss:  3.4228345612064004e-05
Valid Loss:  5.019412492401898e-05
Epoch:  244  	Training Loss: 4.0858620195649564e-05
Test Loss:  3.4371085348539054e-05
Valid Loss:  5.026537473895587e-05
Epoch:  245  	Training Loss: 4.0840270230546594e-05
Test Loss:  3.444203321123496e-05
Valid Loss:  5.031008186051622e-05
Epoch:  246  	Training Loss: 4.08262676501181e-05
Test Loss:  3.447490234975703e-05
Valid Loss:  5.033978231949732e-05
Epoch:  247  	Training Loss: 4.0813647501636297e-05
Test Loss:  3.448692586971447e-05
Valid Loss:  5.0361399189569056e-05
Epoch:  248  	Training Loss: 4.0801765862852335e-05
Test Loss:  3.448854113230482e-05
Valid Loss:  5.037867958890274e-05
Epoch:  249  	Training Loss: 4.0790469938656315e-05
Test Loss:  3.4485143260098994e-05
Valid Loss:  5.039407187723555e-05
Epoch:  250  	Training Loss: 4.077931953361258e-05
Test Loss:  3.447836934356019e-05
Valid Loss:  5.040794349042699e-05
Epoch:  251  	Training Loss: 4.0768492908682674e-05
Test Loss:  3.4470394894015044e-05
Valid Loss:  5.042096017859876e-05
Epoch:  252  	Training Loss: 4.075815013493411e-05
Test Loss:  3.3589771192055196e-05
Valid Loss:  4.9373549700248986e-05
Epoch:  253  	Training Loss: 3.9292317524086684e-05
Test Loss:  3.3129192161140963e-05
Valid Loss:  4.878656909568235e-05
Epoch:  254  	Training Loss: 3.848344931611791e-05
Test Loss:  3.2866075343918055e-05
Valid Loss:  4.843867282033898e-05
Epoch:  255  	Training Loss: 3.803147410508245e-05
Test Loss:  3.2687097700545564e-05
Valid Loss:  4.821277252631262e-05
Epoch:  256  	Training Loss: 3.7761412386316806e-05
Test Loss:  3.253984323237091e-05
Valid Loss:  4.804924537893385e-05
Epoch:  257  	Training Loss: 3.7584723031613976e-05
Test Loss:  3.240113801439293e-05
Valid Loss:  4.7916866606101394e-05
Epoch:  258  	Training Loss: 3.745757567230612e-05
Test Loss:  3.226211993023753e-05
Valid Loss:  4.780050949193537e-05
Epoch:  259  	Training Loss: 3.735687641892582e-05
Test Loss:  3.212047158740461e-05
Valid Loss:  4.769278166349977e-05
Epoch:  260  	Training Loss: 3.72698632418178e-05
Test Loss:  3.1976436730474234e-05
Valid Loss:  4.758989598485641e-05
Epoch:  261  	Training Loss: 3.719165761140175e-05
Test Loss:  3.1830742955207825e-05
Valid Loss:  4.749123036162928e-05
Epoch:  262  	Training Loss: 3.711910540005192e-05
Test Loss:  2.893716373364441e-05
Valid Loss:  4.567168070934713e-05
Epoch:  263  	Training Loss: 3.5826284147333354e-05
Test Loss:  2.773469350358937e-05
Valid Loss:  4.483649900066666e-05
Epoch:  264  	Training Loss: 3.527721855789423e-05
Test Loss:  2.7113834221381694e-05
Valid Loss:  4.429140972206369e-05
Epoch:  265  	Training Loss: 3.4881628380389884e-05
Test Loss:  2.6735888241091743e-05
Valid Loss:  4.385434294817969e-05
Epoch:  266  	Training Loss: 3.4530676202848554e-05
Test Loss:  2.646327266120352e-05
Valid Loss:  4.34635003330186e-05
Epoch:  267  	Training Loss: 3.419335189391859e-05
Test Loss:  2.6213854653178714e-05
Valid Loss:  4.308056304580532e-05
Epoch:  268  	Training Loss: 3.384733645361848e-05
Test Loss:  2.5998178898589686e-05
Valid Loss:  4.271707439329475e-05
Epoch:  269  	Training Loss: 3.351090708747506e-05
Test Loss:  2.579973624960985e-05
Valid Loss:  4.236711538396776e-05
Epoch:  270  	Training Loss: 3.31828196067363e-05
Test Loss:  2.561078144935891e-05
Valid Loss:  4.2028135794680566e-05
Epoch:  271  	Training Loss: 3.286235732957721e-05
Test Loss:  2.542965012253262e-05
Valid Loss:  4.169833118794486e-05
Epoch:  272  	Training Loss: 3.254956391174346e-05
Test Loss:  2.5137473130598664e-05
Valid Loss:  4.105990956304595e-05
Epoch:  273  	Training Loss: 3.2101524993777275e-05
Test Loss:  2.487796518835239e-05
Valid Loss:  4.050369170727208e-05
Epoch:  274  	Training Loss: 3.172752622049302e-05
Test Loss:  2.46476884058211e-05
Valid Loss:  4.00166172767058e-05
Epoch:  275  	Training Loss: 3.1414569093612954e-05
Test Loss:  2.4443383153993636e-05
 55%|█████▌    | 275/500 [03:26<02:20,  1.61it/s] 55%|█████▌    | 277/500 [03:26<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:26<01:15,  2.94it/s] 56%|█████▌    | 281/500 [03:33<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:33<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:33<02:13,  1.62it/s] 57%|█████▋    | 287/500 [03:33<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:33<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:40<04:11,  1.20s/it] 59%|█████▊    | 293/500 [03:40<02:59,  1.16it/s] 59%|█████▉    | 295/500 [03:40<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:40<01:32,  2.18it/s] 60%|█████▉    | 299/500 [03:40<01:08,  2.94it/s] 60%|██████    | 301/500 [03:47<03:57,  1.19s/it] 61%|██████    | 303/500 [03:47<02:48,  1.17it/s] 61%|██████    | 305/500 [03:47<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:47<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:47<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:53<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:54<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:54<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:54<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:54<01:00,  2.97it/s] 64%|██████▍   | 321/500 [04:00<03:31,  1.18s/it] 65%|██████▍   | 323/500 [04:00<02:30,  1.18it/s] 65%|██████▌   | 325/500 [04:01<01:47,  1.63it/s] 65%|██████▌   | 327/500 [04:01<01:17,  2.23it/s] 66%|██████▌   | 329/500 [04:01<00:57,  2.99it/s] 66%|██████▌   | 331/500 [04:07<03:17,  1.17s/it] 67%|██████▋   | 333/500 [04:07<02:20,  1.19it/s] 67%|██████▋   | 335/500 [04:07<01:40,  1.64it/s] 67%|██████▋   | 337/500 [04:07<01:12,  2.24it/s] 68%|██████▊   | 339/500 [04:08<00:53,  3.02it/s] 68%|██████▊   | 341/500 [04:14<03:10,  1.20s/it]Valid Loss:  3.958899469580501e-05
Epoch:  276  	Training Loss: 3.115207073278725e-05
Test Loss:  2.426231003482826e-05
Valid Loss:  3.921254392480478e-05
Epoch:  277  	Training Loss: 3.093092891504057e-05
Test Loss:  2.4090091756079346e-05
Valid Loss:  3.8872800359968096e-05
Epoch:  278  	Training Loss: 3.0737879569642246e-05
Test Loss:  2.3938693630043417e-05
Valid Loss:  3.8572659832425416e-05
Epoch:  279  	Training Loss: 3.057541835005395e-05
Test Loss:  2.3805423552403226e-05
Valid Loss:  3.8307243812596425e-05
Epoch:  280  	Training Loss: 3.0438575777225196e-05
Test Loss:  2.3687854991294444e-05
Valid Loss:  3.807175380643457e-05
Epoch:  281  	Training Loss: 3.032320091733709e-05
Test Loss:  2.3584734663018025e-05
Valid Loss:  3.786296656471677e-05
Epoch:  282  	Training Loss: 3.0226088711060584e-05
Test Loss:  2.361283804930281e-05
Valid Loss:  3.7854944821447134e-05
Epoch:  283  	Training Loss: 3.020551594090648e-05
Test Loss:  2.362384657317307e-05
Valid Loss:  3.7845209590159357e-05
Epoch:  284  	Training Loss: 3.0185859941411763e-05
Test Loss:  2.3623926608706824e-05
Valid Loss:  3.783418651437387e-05
Epoch:  285  	Training Loss: 3.016647315234877e-05
Test Loss:  2.361777296755463e-05
Valid Loss:  3.782227577175945e-05
Epoch:  286  	Training Loss: 3.014748108398635e-05
Test Loss:  2.360775943088811e-05
Valid Loss:  3.78098884539213e-05
Epoch:  287  	Training Loss: 3.0128650905680843e-05
Test Loss:  2.3595272068632767e-05
Valid Loss:  3.779729740926996e-05
Epoch:  288  	Training Loss: 3.011015178344678e-05
Test Loss:  2.358159690629691e-05
Valid Loss:  3.778432073886506e-05
Epoch:  289  	Training Loss: 3.0091767257545143e-05
Test Loss:  2.3567088646814227e-05
Valid Loss:  3.7771471397718415e-05
Epoch:  290  	Training Loss: 3.007352279382758e-05
Test Loss:  2.3552318452857435e-05
Valid Loss:  3.775859295274131e-05
Epoch:  291  	Training Loss: 3.0055376555537805e-05
Test Loss:  2.353722811676562e-05
Valid Loss:  3.7746929592685774e-05
Epoch:  292  	Training Loss: 3.0037484975764528e-05
Test Loss:  2.260749533888884e-05
Valid Loss:  3.6417433875612915e-05
Epoch:  293  	Training Loss: 2.8311193091212772e-05
Test Loss:  2.1065574401291087e-05
Valid Loss:  3.544860373949632e-05
Epoch:  294  	Training Loss: 2.7307236450724304e-05
Test Loss:  1.9914581571356393e-05
Valid Loss:  3.474070399533957e-05
Epoch:  295  	Training Loss: 2.6582223654258996e-05
Test Loss:  1.9006420188816264e-05
Valid Loss:  3.4199634683318436e-05
Epoch:  296  	Training Loss: 2.6030502340290695e-05
Test Loss:  1.8300925148651004e-05
Valid Loss:  3.378214023541659e-05
Epoch:  297  	Training Loss: 2.558787127782125e-05
Test Loss:  1.7764923541108146e-05
Valid Loss:  3.3434145734645426e-05
Epoch:  298  	Training Loss: 2.5218494556611404e-05
Test Loss:  1.7292612028541043e-05
Valid Loss:  3.312460466986522e-05
Epoch:  299  	Training Loss: 2.4901835786295123e-05
Test Loss:  1.6902475181268528e-05
Valid Loss:  3.2841937354533e-05
Epoch:  300  	Training Loss: 2.4619394025648944e-05
Test Loss:  1.6552208762732334e-05
Valid Loss:  3.2558265957050025e-05
Epoch:  301  	Training Loss: 2.436294744256884e-05
Test Loss:  1.626091034268029e-05
Valid Loss:  3.228427158319391e-05
Epoch:  302  	Training Loss: 2.4122840841300786e-05
Test Loss:  1.5916224583634175e-05
Valid Loss:  3.173492586938664e-05
Epoch:  303  	Training Loss: 2.363227031310089e-05
Test Loss:  1.5631165297236294e-05
Valid Loss:  3.120471956208348e-05
Epoch:  304  	Training Loss: 2.3165823222370818e-05
Test Loss:  1.53573346324265e-05
Valid Loss:  3.069310696446337e-05
Epoch:  305  	Training Loss: 2.2700929548591375e-05
Test Loss:  1.5065825209603645e-05
Valid Loss:  3.0211616831365973e-05
Epoch:  306  	Training Loss: 2.2253581846598536e-05
Test Loss:  1.478696594858775e-05
Valid Loss:  2.97460410365602e-05
Epoch:  307  	Training Loss: 2.1827021555509418e-05
Test Loss:  1.4528748579323292e-05
Valid Loss:  2.930001210188493e-05
Epoch:  308  	Training Loss: 2.141434742952697e-05
Test Loss:  1.4272547559812665e-05
Valid Loss:  2.8872529583168216e-05
Epoch:  309  	Training Loss: 2.1012587239965796e-05
Test Loss:  1.4035670574230608e-05
Valid Loss:  2.8463808121159673e-05
Epoch:  310  	Training Loss: 2.063035572064109e-05
Test Loss:  1.3795302947983146e-05
Valid Loss:  2.8066820959793404e-05
Epoch:  311  	Training Loss: 2.0257793948985636e-05
Test Loss:  1.3578534890257288e-05
Valid Loss:  2.7684578526532277e-05
Epoch:  312  	Training Loss: 1.9901490304619074e-05
Test Loss:  1.3606532775156666e-05
Valid Loss:  2.760095776466187e-05
Epoch:  313  	Training Loss: 1.9857936422340572e-05
Test Loss:  1.3633838534587994e-05
Valid Loss:  2.7523919925442897e-05
Epoch:  314  	Training Loss: 1.9818780856439844e-05
Test Loss:  1.3660061995324213e-05
Valid Loss:  2.7452664653537795e-05
Epoch:  315  	Training Loss: 1.9783150492003188e-05
Test Loss:  1.3685291378351394e-05
Valid Loss:  2.7386900910641998e-05
Epoch:  316  	Training Loss: 1.9750907085835934e-05
Test Loss:  1.3709222912439145e-05
Valid Loss:  2.7325797418598086e-05
Epoch:  317  	Training Loss: 1.9721584976650774e-05
Test Loss:  1.3731778381043114e-05
Valid Loss:  2.7269112251815386e-05
Epoch:  318  	Training Loss: 1.969462027773261e-05
Test Loss:  1.375305055262288e-05
Valid Loss:  2.7215897716814652e-05
Epoch:  319  	Training Loss: 1.9669781977427192e-05
Test Loss:  1.3772976672044024e-05
Valid Loss:  2.7166410291101784e-05
Epoch:  320  	Training Loss: 1.9646995497168973e-05
Test Loss:  1.3791441233479418e-05
Valid Loss:  2.711959859880153e-05
Epoch:  321  	Training Loss: 1.9625829736469314e-05
Test Loss:  1.380886351398658e-05
Valid Loss:  2.70757736871019e-05
Epoch:  322  	Training Loss: 1.9606162823038176e-05
Test Loss:  1.3830970601702575e-05
Valid Loss:  2.702906567719765e-05
Epoch:  323  	Training Loss: 1.9586615962907672e-05
Test Loss:  1.385276482324116e-05
Valid Loss:  2.6985459044226445e-05
Epoch:  324  	Training Loss: 1.956879350473173e-05
Test Loss:  1.387399242958054e-05
Valid Loss:  2.6944522687699646e-05
Epoch:  325  	Training Loss: 1.9552462617866695e-05
Test Loss:  1.3894541552872397e-05
Valid Loss:  2.6905931008514017e-05
Epoch:  326  	Training Loss: 1.953737773874309e-05
Test Loss:  1.3914681403548457e-05
Valid Loss:  2.6869645807892084e-05
Epoch:  327  	Training Loss: 1.952356251422316e-05
Test Loss:  1.393416096107103e-05
Valid Loss:  2.6835639800992794e-05
Epoch:  328  	Training Loss: 1.9510793208610266e-05
Test Loss:  1.3952805602457374e-05
Valid Loss:  2.6803500077221543e-05
Epoch:  329  	Training Loss: 1.949909346876666e-05
Test Loss:  1.3970910913485568e-05
Valid Loss:  2.6773208446684293e-05
Epoch:  330  	Training Loss: 1.9488157704472542e-05
Test Loss:  1.3988450518809259e-05
Valid Loss:  2.674438655958511e-05
Epoch:  331  	Training Loss: 1.9478111425996758e-05
Test Loss:  1.4005310731590725e-05
Valid Loss:  2.6717376385931857e-05
Epoch:  332  	Training Loss: 1.9468698155833408e-05
Test Loss:  1.3957926057628356e-05
Valid Loss:  2.6632096705725417e-05
Epoch:  333  	Training Loss: 1.941821028594859e-05
Test Loss:  1.3915005183662288e-05
Valid Loss:  2.6551988412393257e-05
Epoch:  334  	Training Loss: 1.9372033420950174e-05
Test Loss:  1.38737668748945e-05
Valid Loss:  2.64753180090338e-05
Epoch:  335  	Training Loss: 1.9328479538671672e-05
Test Loss:  1.3834380297339521e-05
Valid Loss:  2.640241291373968e-05
Epoch:  336  	Training Loss: 1.928731035150122e-05
Test Loss:  1.3796956409350969e-05
Valid Loss:  2.6332298148190603e-05
Epoch:  337  	Training Loss: 1.9248762328061275e-05
Test Loss:  1.376239197270479e-05
Valid Loss:  2.626625973789487e-05
Epoch:  338  	Training Loss: 1.9213510313420556e-05
Test Loss:  1.373097074974794e-05
Valid Loss:  2.6204024834441952e-05
Epoch:  339  	Training Loss: 1.9180944946128875e-05
Test Loss:  1.3701875104743522e-05
Valid Loss:  2.614415279822424e-05
Epoch:  340  	Training Loss: 1.915024040499702e-05
Test Loss:  1.3677208698936738e-05
Valid Loss:  2.608879549370613e-05
Epoch:  341  	Training Loss: 1.9121680452371947e-05
Test Loss:  1.3653168934979476e-05
Valid Loss:  2.6036166673293337e-05
Epoch:  342  	Training Loss: 1.90944156202022e-05
Test Loss:  1.3348005268198904e-05
Valid Loss:   69%|██████▊   | 343/500 [04:14<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:14<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:14<01:11,  2.14it/s] 70%|██████▉   | 349/500 [04:15<00:53,  2.84it/s] 70%|███████   | 351/500 [04:21<02:59,  1.21s/it] 71%|███████   | 353/500 [04:21<02:07,  1.15it/s] 71%|███████   | 355/500 [04:21<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:21<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:22<00:47,  2.94it/s] 72%|███████▏  | 361/500 [04:28<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:28<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:28<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:28<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:28<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:35<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:35<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:35<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:35<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:35<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:42<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:42<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:42<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:42<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:42<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:49<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:49<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:49<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:49<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:49<00:33,  3.01it/s] 80%|████████  | 401/500 [04:55<01:57,  1.18s/it] 81%|████████  | 403/500 [04:56<01:23,  1.16it/s] 81%|████████  | 405/500 [04:56<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:56<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:56<00:30,  2.96it/s]2.5777106202440336e-05
Epoch:  343  	Training Loss: 1.8898252164945006e-05
Test Loss:  1.3104528989060782e-05
Valid Loss:  2.5551435101078823e-05
Epoch:  344  	Training Loss: 1.8734797777142376e-05
Test Loss:  1.2907603377243504e-05
Valid Loss:  2.5351017029606737e-05
Epoch:  345  	Training Loss: 1.8595545043353923e-05
Test Loss:  1.2746306310873479e-05
Valid Loss:  2.5170811568386853e-05
Epoch:  346  	Training Loss: 1.8474576791049913e-05
Test Loss:  1.2612805221579038e-05
Valid Loss:  2.5006480427691713e-05
Epoch:  347  	Training Loss: 1.8367696611676365e-05
Test Loss:  1.2500498087320011e-05
Valid Loss:  2.4855504307197407e-05
Epoch:  348  	Training Loss: 1.8271912267664447e-05
Test Loss:  1.2405535017023794e-05
Valid Loss:  2.471552579663694e-05
Epoch:  349  	Training Loss: 1.818509554141201e-05
Test Loss:  1.2323788723733742e-05
Valid Loss:  2.458553899487015e-05
Epoch:  350  	Training Loss: 1.810553476389032e-05
Test Loss:  1.2253336535650305e-05
Valid Loss:  2.4464046873617917e-05
Epoch:  351  	Training Loss: 1.8032096704700962e-05
Test Loss:  1.2191240784886759e-05
Valid Loss:  2.4350114472326823e-05
Epoch:  352  	Training Loss: 1.7963686332223006e-05
Test Loss:  1.2179465556982905e-05
Valid Loss:  2.4311662855325267e-05
Epoch:  353  	Training Loss: 1.7899654267239384e-05
Test Loss:  1.2174166840850376e-05
Valid Loss:  2.4278526325360872e-05
Epoch:  354  	Training Loss: 1.784308915375732e-05
Test Loss:  1.2171719390607905e-05
Valid Loss:  2.425015190965496e-05
Epoch:  355  	Training Loss: 1.7793008737498894e-05
Test Loss:  1.2171407433925197e-05
Valid Loss:  2.422554462100379e-05
Epoch:  356  	Training Loss: 1.7748414393281564e-05
Test Loss:  1.2172852621006314e-05
Valid Loss:  2.420450618956238e-05
Epoch:  357  	Training Loss: 1.770904054865241e-05
Test Loss:  1.2175210031273309e-05
Valid Loss:  2.41862544498872e-05
Epoch:  358  	Training Loss: 1.767467983881943e-05
Test Loss:  1.2178328688605689e-05
Valid Loss:  2.4170372853404842e-05
Epoch:  359  	Training Loss: 1.7643753380980343e-05
Test Loss:  1.218186389451148e-05
Valid Loss:  2.415613562334329e-05
Epoch:  360  	Training Loss: 1.7615735487197526e-05
Test Loss:  1.2185653758933768e-05
Valid Loss:  2.414358823443763e-05
Epoch:  361  	Training Loss: 1.7590433344594203e-05
Test Loss:  1.2190171219117474e-05
Valid Loss:  2.413242145848926e-05
Epoch:  362  	Training Loss: 1.7567555914865807e-05
Test Loss:  1.2008445992250927e-05
Valid Loss:  2.4041892174864188e-05
Epoch:  363  	Training Loss: 1.7388820197083987e-05
Test Loss:  1.1840798833873123e-05
Valid Loss:  2.3961249098647386e-05
Epoch:  364  	Training Loss: 1.7222460883203894e-05
Test Loss:  1.1685365279845428e-05
Valid Loss:  2.388958637311589e-05
Epoch:  365  	Training Loss: 1.7067501175915822e-05
Test Loss:  1.1541626008693129e-05
Valid Loss:  2.3825712560210377e-05
Epoch:  366  	Training Loss: 1.6923379007494077e-05
Test Loss:  1.1408170394133776e-05
Valid Loss:  2.3769496692693792e-05
Epoch:  367  	Training Loss: 1.678883927525021e-05
Test Loss:  1.1284696483926382e-05
Valid Loss:  2.3720000172033906e-05
Epoch:  368  	Training Loss: 1.6663590940879658e-05
Test Loss:  1.117026295105461e-05
Valid Loss:  2.367653723922558e-05
Epoch:  369  	Training Loss: 1.6545760445296764e-05
Test Loss:  1.1062282283091918e-05
Valid Loss:  2.3637880076421425e-05
Epoch:  370  	Training Loss: 1.6431764379376546e-05
Test Loss:  1.0960181498376187e-05
Valid Loss:  2.360411781410221e-05
Epoch:  371  	Training Loss: 1.632366365811322e-05
Test Loss:  1.086566953745205e-05
Valid Loss:  2.3574837541673332e-05
Epoch:  372  	Training Loss: 1.6222356862272136e-05
Test Loss:  1.0802401448017918e-05
Valid Loss:  2.3418668206431903e-05
Epoch:  373  	Training Loss: 1.6041474736994132e-05
Test Loss:  1.0759318683994934e-05
Valid Loss:  2.331408904865384e-05
Epoch:  374  	Training Loss: 1.5925987099763006e-05
Test Loss:  1.0720357749960385e-05
Valid Loss:  2.3235137632582337e-05
Epoch:  375  	Training Loss: 1.5841444110265e-05
Test Loss:  1.0680527338990942e-05
Valid Loss:  2.3169413907453418e-05
Epoch:  376  	Training Loss: 1.577204602654092e-05
Test Loss:  1.0638101230142638e-05
Valid Loss:  2.3110922484192997e-05
Epoch:  377  	Training Loss: 1.571040047565475e-05
Test Loss:  1.0593676051939838e-05
Valid Loss:  2.305686939507723e-05
Epoch:  378  	Training Loss: 1.5653138689231128e-05
Test Loss:  1.054825224855449e-05
Valid Loss:  2.3005852199275978e-05
Epoch:  379  	Training Loss: 1.5598623576806858e-05
Test Loss:  1.0502187251404393e-05
Valid Loss:  2.2957243345445022e-05
Epoch:  380  	Training Loss: 1.554619120724965e-05
Test Loss:  1.0456014933879487e-05
Valid Loss:  2.2910615371074528e-05
Epoch:  381  	Training Loss: 1.5495483239647e-05
Test Loss:  1.0410518370917998e-05
Valid Loss:  2.2863234335090965e-05
Epoch:  382  	Training Loss: 1.5446214092662558e-05
Test Loss:  1.0310359357390553e-05
Valid Loss:  2.2824129700893536e-05
Epoch:  383  	Training Loss: 1.5351008187280968e-05
Test Loss:  1.0221604497928638e-05
Valid Loss:  2.2790260118199512e-05
Epoch:  384  	Training Loss: 1.5263383829733357e-05
Test Loss:  1.0142282917513512e-05
Valid Loss:  2.27611672016792e-05
Epoch:  385  	Training Loss: 1.5182504284894094e-05
Test Loss:  1.0070691132568754e-05
Valid Loss:  2.2736150640412234e-05
Epoch:  386  	Training Loss: 1.5107722902030218e-05
Test Loss:  1.0006015145336278e-05
Valid Loss:  2.2714837541570887e-05
Epoch:  387  	Training Loss: 1.503841849626042e-05
Test Loss:  9.947299986379221e-06
Valid Loss:  2.2696860469295643e-05
Epoch:  388  	Training Loss: 1.4974302757764235e-05
Test Loss:  9.894325557979755e-06
Valid Loss:  2.268158641527407e-05
Epoch:  389  	Training Loss: 1.4915000065229833e-05
Test Loss:  9.846171451499686e-06
Valid Loss:  2.2668786186841317e-05
Epoch:  390  	Training Loss: 1.485989287175471e-05
Test Loss:  9.802379281609319e-06
Valid Loss:  2.2658383386442438e-05
Epoch:  391  	Training Loss: 1.4808771084062755e-05
Test Loss:  9.761622095538769e-06
Valid Loss:  2.265017610625364e-05
Epoch:  392  	Training Loss: 1.475899807701353e-05
Test Loss:  9.70146902545821e-06
Valid Loss:  2.193194450228475e-05
Epoch:  393  	Training Loss: 1.4429529073822778e-05
Test Loss:  9.641268661653157e-06
Valid Loss:  2.140306241926737e-05
Epoch:  394  	Training Loss: 1.4195103176461998e-05
Test Loss:  9.576137927069794e-06
Valid Loss:  2.0992276404285803e-05
Epoch:  395  	Training Loss: 1.4016938621352892e-05
Test Loss:  9.510695235803723e-06
Valid Loss:  2.0659203073591925e-05
Epoch:  396  	Training Loss: 1.3875413060304709e-05
Test Loss:  9.44896055443678e-06
Valid Loss:  2.0381845388328657e-05
Epoch:  397  	Training Loss: 1.3760601177637e-05
Test Loss:  9.393291293235961e-06
Valid Loss:  2.014592791965697e-05
Epoch:  398  	Training Loss: 1.3666165614267811e-05
Test Loss:  9.344488717033528e-06
Valid Loss:  1.9942939616157673e-05
Epoch:  399  	Training Loss: 1.3587887224275619e-05
Test Loss:  9.3024609668646e-06
Valid Loss:  1.9765840988839045e-05
Epoch:  400  	Training Loss: 1.3522474546334706e-05
Test Loss:  9.266801498597488e-06
Valid Loss:  1.961027373909019e-05
Epoch:  401  	Training Loss: 1.3467436474456917e-05
Test Loss:  9.23665447771782e-06
Valid Loss:  1.9472496205708012e-05
Epoch:  402  	Training Loss: 1.3420639334071893e-05
Test Loss:  9.232877346221358e-06
Valid Loss:  1.937839260790497e-05
Epoch:  403  	Training Loss: 1.3383700206759386e-05
Test Loss:  9.225315807270817e-06
Valid Loss:  1.9296454411232844e-05
Epoch:  404  	Training Loss: 1.3349390428629704e-05
Test Loss:  9.214227247866802e-06
Valid Loss:  1.9224296920583583e-05
Epoch:  405  	Training Loss: 1.3317056072992273e-05
Test Loss:  9.200792192132212e-06
Valid Loss:  1.9159570001647808e-05
Epoch:  406  	Training Loss: 1.3286342436913401e-05
Test Loss:  9.185567250824533e-06
Valid Loss:  1.9100971258012578e-05
Epoch:  407  	Training Loss: 1.3256898455438204e-05
Test Loss:  9.168881661025807e-06
Valid Loss:  1.9047234673053026e-05
Epoch:  408  	Training Loss: 1.3228611351223662e-05
Test Loss:  9.144579962594435e-06
Valid Loss:  1.899746712297201e-05
Epoch:  409  	Training Loss: 1.3201429283071775e-05
Test Loss:  9.119806236412842e-06
Valid Loss:  1.89508300536545e-05
 82%|████████▏ | 411/500 [05:02<01:44,  1.17s/it] 83%|████████▎ | 413/500 [05:02<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:03<00:52,  1.61it/s] 83%|████████▎ | 417/500 [05:03<00:38,  2.18it/s] 84%|████████▍ | 419/500 [05:03<00:27,  2.93it/s] 84%|████████▍ | 421/500 [05:09<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:09<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:10<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:10<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:10<00:23,  2.96it/s] 86%|████████▌ | 431/500 [05:16<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:16<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:16<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:16<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:17<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:23<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:23<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:23<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:23<00:23,  2.21it/s] 90%|████████▉ | 449/500 [05:23<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:30<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:30<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:30<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:30<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:30<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:37<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:37<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:37<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:37<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:37<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:43<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:44<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:44<00:15,  1.64it/s]Epoch:  410  	Training Loss: 1.317521309829317e-05
Test Loss:  9.095168934436515e-06
Valid Loss:  1.890733983600512e-05
Epoch:  411  	Training Loss: 1.314972269028658e-05
Test Loss:  9.070527994481381e-06
Valid Loss:  1.8865805031964555e-05
Epoch:  412  	Training Loss: 1.3125121768098325e-05
Test Loss:  9.025596227729693e-06
Valid Loss:  1.8808699678629637e-05
Epoch:  413  	Training Loss: 1.3048711480223574e-05
Test Loss:  8.953497854236048e-06
Valid Loss:  1.8771033865050413e-05
Epoch:  414  	Training Loss: 1.2983793567400426e-05
Test Loss:  8.887674084689934e-06
Valid Loss:  1.8735321646090597e-05
Epoch:  415  	Training Loss: 1.2925835108035244e-05
Test Loss:  8.826592420518864e-06
Valid Loss:  1.8696846382226795e-05
Epoch:  416  	Training Loss: 1.287469331145985e-05
Test Loss:  8.771918146521784e-06
Valid Loss:  1.865451122284867e-05
Epoch:  417  	Training Loss: 1.2827319551433902e-05
Test Loss:  8.721890480956063e-06
Valid Loss:  1.8607646779855713e-05
Epoch:  418  	Training Loss: 1.2782835256075487e-05
Test Loss:  8.675898243382107e-06
Valid Loss:  1.855822847574018e-05
Epoch:  419  	Training Loss: 1.2741204955091234e-05
Test Loss:  8.639352017780766e-06
Valid Loss:  1.8506623746361583e-05
Epoch:  420  	Training Loss: 1.2701904779532924e-05
Test Loss:  8.602650268585421e-06
Valid Loss:  1.8455331883160397e-05
Epoch:  421  	Training Loss: 1.2664970199693926e-05
Test Loss:  8.568062185076997e-06
Valid Loss:  1.8403359717922285e-05
Epoch:  422  	Training Loss: 1.2630911442101933e-05
Test Loss:  8.523873475496657e-06
Valid Loss:  1.8374794308329e-05
Epoch:  423  	Training Loss: 1.2615677405847237e-05
Test Loss:  8.488890671287663e-06
Valid Loss:  1.8347196601098403e-05
Epoch:  424  	Training Loss: 1.2603222785401158e-05
Test Loss:  8.460902790830005e-06
Valid Loss:  1.8320484741707332e-05
Epoch:  425  	Training Loss: 1.2592664461408276e-05
Test Loss:  8.43872840050608e-06
Valid Loss:  1.8294533219886944e-05
Epoch:  426  	Training Loss: 1.2583563147927634e-05
Test Loss:  8.420821359322872e-06
Valid Loss:  1.8268734493176453e-05
Epoch:  427  	Training Loss: 1.2575064829434268e-05
Test Loss:  8.400837941735517e-06
Valid Loss:  1.8242481019115075e-05
Epoch:  428  	Training Loss: 1.2566008081194013e-05
Test Loss:  8.38478263176512e-06
Valid Loss:  1.8216738681076095e-05
Epoch:  429  	Training Loss: 1.2557866284623742e-05
Test Loss:  8.371915100724436e-06
Valid Loss:  1.8191221897723153e-05
Epoch:  430  	Training Loss: 1.2550586689030752e-05
Test Loss:  8.361645996046718e-06
Valid Loss:  1.816643271013163e-05
Epoch:  431  	Training Loss: 1.2543830962385982e-05
Test Loss:  8.353340490430128e-06
Valid Loss:  1.814185088733211e-05
Epoch:  432  	Training Loss: 1.2537630027509294e-05
Test Loss:  8.350183634320274e-06
Valid Loss:  1.8110647943103686e-05
Epoch:  433  	Training Loss: 1.2509621228673495e-05
Test Loss:  8.343739864358213e-06
Valid Loss:  1.8084714611177333e-05
Epoch:  434  	Training Loss: 1.2483851605793461e-05
Test Loss:  8.335287020599935e-06
Valid Loss:  1.8062713934341446e-05
Epoch:  435  	Training Loss: 1.245958173967665e-05
Test Loss:  8.32468595035607e-06
Valid Loss:  1.8043388990918174e-05
Epoch:  436  	Training Loss: 1.2436536053428426e-05
Test Loss:  8.312419595313258e-06
Valid Loss:  1.8026392353931442e-05
Epoch:  437  	Training Loss: 1.2414547200023662e-05
Test Loss:  8.298792636196595e-06
Valid Loss:  1.8010839994531125e-05
Epoch:  438  	Training Loss: 1.239335415448295e-05
Test Loss:  8.2843289419543e-06
Valid Loss:  1.7996875612880103e-05
Epoch:  439  	Training Loss: 1.2372924174997024e-05
Test Loss:  8.269427780760452e-06
Valid Loss:  1.7984180885832757e-05
Epoch:  440  	Training Loss: 1.23531617646222e-05
Test Loss:  8.254110070993192e-06
Valid Loss:  1.7972226487472653e-05
Epoch:  441  	Training Loss: 1.2334218808973674e-05
Test Loss:  8.238663212978281e-06
Valid Loss:  1.7961163393920287e-05
Epoch:  442  	Training Loss: 1.2315822459640913e-05
Test Loss:  8.238399459514767e-06
Valid Loss:  1.7956597730517387e-05
Epoch:  443  	Training Loss: 1.2314258128753863e-05
Test Loss:  8.238090231316164e-06
Valid Loss:  1.7951968402485363e-05
Epoch:  444  	Training Loss: 1.2312704711803235e-05
Test Loss:  8.237880138040055e-06
Valid Loss:  1.794726267689839e-05
Epoch:  445  	Training Loss: 1.2311174941714853e-05
Test Loss:  8.237606380134821e-06
Valid Loss:  1.794267154764384e-05
Epoch:  446  	Training Loss: 1.2309653357078787e-05
Test Loss:  8.23739537736401e-06
Valid Loss:  1.793796218407806e-05
Epoch:  447  	Training Loss: 1.2308133591432124e-05
Test Loss:  8.23715981823625e-06
Valid Loss:  1.7933325580088422e-05
Epoch:  448  	Training Loss: 1.2306552889640443e-05
Test Loss:  8.23696427687537e-06
Valid Loss:  1.7928781744558364e-05
Epoch:  449  	Training Loss: 1.2305046766414307e-05
Test Loss:  8.23666232463438e-06
Valid Loss:  1.792410148482304e-05
Epoch:  450  	Training Loss: 1.2303533367230557e-05
Test Loss:  8.236516805482097e-06
Valid Loss:  1.7919457604875788e-05
Epoch:  451  	Training Loss: 1.230202633450972e-05
Test Loss:  8.236312169174198e-06
Valid Loss:  1.791489376046229e-05
Epoch:  452  	Training Loss: 1.2300514754315373e-05
Test Loss:  8.242020157922525e-06
Valid Loss:  1.7887014109874144e-05
Epoch:  453  	Training Loss: 1.2285697266634088e-05
Test Loss:  8.24386461317772e-06
Valid Loss:  1.7862519598565996e-05
Epoch:  454  	Training Loss: 1.2271419109310955e-05
Test Loss:  8.243625416071154e-06
Valid Loss:  1.784026244422421e-05
Epoch:  455  	Training Loss: 1.2257434718776494e-05
Test Loss:  8.24218204797944e-06
Valid Loss:  1.781903119990602e-05
Epoch:  456  	Training Loss: 1.2243718629179057e-05
Test Loss:  8.239856470027007e-06
Valid Loss:  1.7798614862840623e-05
Epoch:  457  	Training Loss: 1.223018261953257e-05
Test Loss:  8.237106158048846e-06
Valid Loss:  1.7778600522433408e-05
Epoch:  458  	Training Loss: 1.2216842151246965e-05
Test Loss:  8.234274901042227e-06
Valid Loss:  1.7759259208105505e-05
Epoch:  459  	Training Loss: 1.2203789992781822e-05
Test Loss:  8.231289029936306e-06
Valid Loss:  1.7739796021487564e-05
Epoch:  460  	Training Loss: 1.2190886991447769e-05
Test Loss:  8.228463229897898e-06
Valid Loss:  1.772087489371188e-05
Epoch:  461  	Training Loss: 1.2178230463177897e-05
Test Loss:  8.22553010948468e-06
Valid Loss:  1.7702001059660688e-05
Epoch:  462  	Training Loss: 1.216581222251989e-05
Test Loss:  8.124443411361426e-06
Valid Loss:  1.7667274732957594e-05
Epoch:  463  	Training Loss: 1.2102805158065166e-05
Test Loss:  8.04710180091206e-06
Valid Loss:  1.762816282280255e-05
Epoch:  464  	Training Loss: 1.2051970770698972e-05
Test Loss:  7.98659493739251e-06
Valid Loss:  1.758546568453312e-05
Epoch:  465  	Training Loss: 1.200959195557516e-05
Test Loss:  7.938432645460125e-06
Valid Loss:  1.7540109183755703e-05
Epoch:  466  	Training Loss: 1.1973439541179687e-05
Test Loss:  7.899593583715614e-06
Valid Loss:  1.7493401173851453e-05
Epoch:  467  	Training Loss: 1.194200558529701e-05
Test Loss:  7.867771273595281e-06
Valid Loss:  1.7445934645365924e-05
Epoch:  468  	Training Loss: 1.1914435162907466e-05
Test Loss:  7.841307706257794e-06
Valid Loss:  1.7398597265128046e-05
Epoch:  469  	Training Loss: 1.1890091627719812e-05
Test Loss:  7.819204256520607e-06
Valid Loss:  1.73519947566092e-05
Epoch:  470  	Training Loss: 1.1868358342326246e-05
Test Loss:  7.800563253113069e-06
Valid Loss:  1.7306438166997395e-05
Epoch:  471  	Training Loss: 1.1848937901959289e-05
Test Loss:  7.784616173012182e-06
Valid Loss:  1.7262622350244783e-05
Epoch:  472  	Training Loss: 1.1831612937385216e-05
Test Loss:  7.849279427318834e-06
Valid Loss:  1.7108952306443825e-05
Epoch:  473  	Training Loss: 1.1744523362722248e-05
Test Loss:  7.84804615250323e-06
Valid Loss:  1.706238981569186e-05
Epoch:  474  	Training Loss: 1.1685524441418238e-05
Test Loss:  7.815079698048066e-06
Valid Loss:  1.703617090242915e-05
Epoch:  475  	Training Loss: 1.163458000519313e-05
Test Loss:  7.785187335684896e-06
Valid Loss:  1.7007991118589416e-05
Epoch:  476  	Training Loss: 1.1585047104745172e-05
Test Loss:  7.751437806291506e-06
Valid Loss:  1.6977573977783322e-05
Epoch:  477  	Training Loss: 1.1538232683960814e-05
Test Loss:   95%|█████████▌| 477/500 [05:44<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:44<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:50<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:51<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:51<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:51<00:05,  2.19it/s] 98%|█████████▊| 489/500 [05:51<00:03,  2.93it/s] 98%|█████████▊| 491/500 [05:57<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:57<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:57<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:58<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:58<00:00,  3.00it/s]100%|██████████| 500/500 [05:58<00:00,  1.40it/s]
7.722260306763928e-06
Valid Loss:  1.6942547517828643e-05
Epoch:  478  	Training Loss: 1.1492365956655703e-05
Test Loss:  7.694925443502143e-06
Valid Loss:  1.690555836830754e-05
Epoch:  479  	Training Loss: 1.1447486940596718e-05
Test Loss:  7.668403668503743e-06
Valid Loss:  1.6867963495315053e-05
Epoch:  480  	Training Loss: 1.1403925782360602e-05
Test Loss:  7.636326699866913e-06
Valid Loss:  1.6828937077661976e-05
Epoch:  481  	Training Loss: 1.1361284123267978e-05
Test Loss:  7.6089654612587765e-06
Valid Loss:  1.6786929336376488e-05
Epoch:  482  	Training Loss: 1.1319462828396354e-05
Test Loss:  7.559876848972635e-06
Valid Loss:  1.6722953660064377e-05
Epoch:  483  	Training Loss: 1.1218793588341214e-05
Test Loss:  7.499136700062081e-06
Valid Loss:  1.666341267991811e-05
Epoch:  484  	Training Loss: 1.1124503544124309e-05
Test Loss:  7.446363269991707e-06
Valid Loss:  1.6600090020801872e-05
Epoch:  485  	Training Loss: 1.1034437193302438e-05
Test Loss:  7.391715371340979e-06
Valid Loss:  1.6536907423869707e-05
Epoch:  486  	Training Loss: 1.0949232091661543e-05
Test Loss:  7.339889634749852e-06
Valid Loss:  1.6471505659865215e-05
Epoch:  487  	Training Loss: 1.0867749551835004e-05
Test Loss:  7.2950047069753055e-06
Valid Loss:  1.640399386815261e-05
Epoch:  488  	Training Loss: 1.0789583939185832e-05
Test Loss:  7.251960596477147e-06
Valid Loss:  1.6338712157448754e-05
Epoch:  489  	Training Loss: 1.0714082236518152e-05
Test Loss:  7.210918283817591e-06
Valid Loss:  1.6275513189611956e-05
Epoch:  490  	Training Loss: 1.0641607332217973e-05
Test Loss:  7.171927791205235e-06
Valid Loss:  1.621527007955592e-05
Epoch:  491  	Training Loss: 1.0571923667157535e-05
Test Loss:  7.135035048122518e-06
Valid Loss:  1.615683504496701e-05
Epoch:  492  	Training Loss: 1.0504925739951432e-05
Test Loss:  7.087062840582803e-06
Valid Loss:  1.610080107639078e-05
Epoch:  493  	Training Loss: 1.0468124855833594e-05
Test Loss:  7.052715318422997e-06
Valid Loss:  1.6033198335208e-05
Epoch:  494  	Training Loss: 1.0434746400278527e-05
Test Loss:  7.026139883237192e-06
Valid Loss:  1.596165748196654e-05
Epoch:  495  	Training Loss: 1.0406340152258053e-05
Test Loss:  6.996388947300147e-06
Valid Loss:  1.5910411093500443e-05
Epoch:  496  	Training Loss: 1.0382043910794891e-05
Test Loss:  6.973432846280048e-06
Valid Loss:  1.5852969227125868e-05
Epoch:  497  	Training Loss: 1.0359836778661702e-05
Test Loss:  6.955162916710833e-06
Valid Loss:  1.5794870705576614e-05
Epoch:  498  	Training Loss: 1.033996250043856e-05
Test Loss:  6.939005288586486e-06
Valid Loss:  1.5741305105620995e-05
Epoch:  499  	Training Loss: 1.0321401532564778e-05
Test Loss:  6.924086846993305e-06
Valid Loss:  1.5689833162468858e-05
Epoch:  500  	Training Loss: 1.0304097486368846e-05
Test Loss:  6.911287982802605e-06
Valid Loss:  1.5640793208149262e-05
seed is  4
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:34, 14.53it/s]  1%|          | 4/500 [00:00<00:31, 15.57it/s]  1%|          | 6/500 [00:00<00:31, 15.83it/s]  2%|▏         | 8/500 [00:00<00:30, 16.05it/s]  2%|▏         | 10/500 [00:00<00:31, 15.58it/s]  2%|▏         | 12/500 [00:00<00:31, 15.55it/s]  3%|▎         | 14/500 [00:00<00:31, 15.61it/s]  3%|▎         | 16/500 [00:01<00:30, 15.84it/s]  4%|▎         | 18/500 [00:01<00:30, 15.97it/s]  4%|▍         | 20/500 [00:01<00:29, 16.11it/s]  4%|▍         | 22/500 [00:01<00:29, 16.04it/s]  5%|▍         | 24/500 [00:01<00:30, 15.86it/s]  5%|▌         | 26/500 [00:01<00:29, 16.05it/s]  6%|▌         | 28/500 [00:01<00:29, 16.16it/s]  6%|▌         | 30/500 [00:01<00:29, 16.20it/s]  6%|▋         | 32/500 [00:02<00:28, 16.31it/s]  7%|▋         | 34/500 [00:02<00:28, 16.39it/s]  7%|▋         | 36/500 [00:02<00:28, 16.37it/s]  8%|▊         | 38/500 [00:02<00:28, 16.19it/s]  8%|▊         | 40/500 [00:02<00:28, 16.25it/s]  8%|▊         | 42/500 [00:02<00:28, 16.28it/s]  9%|▉         | 44/500 [00:02<00:28, 16.22it/s]  9%|▉         | 46/500 [00:02<00:27, 16.28it/s] 10%|▉         | 48/500 [00:02<00:27, 16.32it/s] 10%|█         | 50/500 [00:03<00:28, 15.84it/s] 10%|█         | 52/500 [00:03<00:30, 14.62it/s] 11%|█         | 54/500 [00:03<00:32, 13.86it/s] 11%|█         | 56/500 [00:03<00:33, 13.32it/s] 12%|█▏        | 58/500 [00:03<00:34, 12.95it/s] 12%|█▏        | 60/500 [00:03<00:34, 12.75it/s] 12%|█▏        | 62/500 [00:04<00:34, 12.64it/s] 13%|█▎        | 64/500 [00:04<00:33, 13.12it/s] 13%|█▎        | 66/500 [00:04<00:31, 13.92it/s] 14%|█▎        | 68/500 [00:04<00:29, 14.60it/s] 14%|█▍        | 70/500 [00:04<00:28, 15.13it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.34it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.56it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.19it/s] 16%|█▌        | 78/500 [00:05<00:29, 14.49it/s] 16%|█▌        | 80/500 [00:05<00:27, 15.02it/s] 16%|█▋        | 82/500 [00:05<00:27, 15.38it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.71it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.92it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.95it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.67it/s] 18%|█▊        | 92/500 [00:06<00:26, 15.62it/s] 19%|█▉        | 94/500 [00:06<00:26, 15.59it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.78it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.92it/s] 20%|██        | 100/500 [00:06<00:24, 16.05it/s] 20%|██        | 102/500 [00:06<00:25, 15.54it/s] 21%|██        | 104/500 [00:06<00:25, 15.80it/s] 21%|██        | 106/500 [00:06<00:24, 15.98it/s] 22%|██▏       | 108/500 [00:07<00:24, 16.08it/s] 22%|██▏       | 110/500 [00:07<00:24, 16.14it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.22it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.91it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.73it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.79it/s] 24%|██▍       | 120/500 [00:07<00:25, 14.88it/s] 24%|██▍       | 122/500 [00:07<00:27, 14.00it/s] 25%|██▍       | 124/500 [00:08<00:27, 13.45it/s]Epoch:  1  	Training Loss: 0.08722381293773651
Test Loss:  2284.9248046875
Valid Loss:  2276.3017578125
Epoch:  2  	Training Loss: 2266.201171875
Test Loss:  6432065713078272.0
Valid Loss:  6386954597826560.0
Epoch:  3  	Training Loss: 6341317349081088.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:28, 13.12it/s] 26%|██▌       | 128/500 [00:08<00:28, 12.88it/s] 26%|██▌       | 130/500 [00:08<00:29, 12.71it/s] 26%|██▋       | 132/500 [00:08<00:28, 12.70it/s] 27%|██▋       | 134/500 [00:08<00:26, 13.62it/s] 27%|██▋       | 136/500 [00:09<00:25, 14.15it/s] 28%|██▊       | 138/500 [00:09<00:24, 14.77it/s] 28%|██▊       | 140/500 [00:09<00:23, 15.21it/s] 28%|██▊       | 142/500 [00:09<00:23, 15.37it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.67it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.89it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.03it/s] 30%|███       | 150/500 [00:09<00:21, 16.17it/s] 30%|███       | 152/500 [00:10<00:21, 16.25it/s] 31%|███       | 154/500 [00:10<00:21, 16.21it/s] 31%|███       | 156/500 [00:10<00:23, 14.75it/s] 32%|███▏      | 158/500 [00:10<00:24, 13.87it/s] 32%|███▏      | 160/500 [00:10<00:25, 13.37it/s] 32%|███▏      | 162/500 [00:10<00:24, 13.58it/s] 33%|███▎      | 164/500 [00:10<00:25, 13.18it/s] 33%|███▎      | 166/500 [00:11<00:25, 12.91it/s] 34%|███▎      | 168/500 [00:11<00:25, 13.23it/s] 34%|███▍      | 170/500 [00:11<00:23, 13.88it/s] 34%|███▍      | 172/500 [00:11<00:22, 14.47it/s] 35%|███▍      | 174/500 [00:11<00:22, 14.60it/s] 35%|███▌      | 176/500 [00:11<00:21, 14.84it/s] 36%|███▌      | 178/500 [00:11<00:21, 15.26it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.52it/s] 36%|███▋      | 182/500 [00:12<00:20, 15.54it/s] 37%|███▋      | 184/500 [00:12<00:20, 15.57it/s] 37%|███▋      | 186/500 [00:12<00:19, 15.74it/s] 38%|███▊      | 188/500 [00:12<00:19, 15.96it/s] 38%|███▊      | 190/500 [00:12<00:19, 15.90it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.73it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.78it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.77it/s] 40%|███▉      | 198/500 [00:13<00:19, 15.67it/s] 40%|████      | 200/500 [00:13<00:18, 15.84it/s] 40%|████      | 202/500 [00:13<00:18, 16.00it/s] 41%|████      | 204/500 [00:13<00:18, 15.82it/s] 41%|████      | 206/500 [00:13<00:18, 16.05it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.14it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.16it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.26it/s] 43%|████▎     | 214/500 [00:14<00:17, 16.28it/s] 43%|████▎     | 216/500 [00:14<00:17, 16.33it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.33it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.34it/s] 44%|████▍     | 222/500 [00:14<00:16, 16.37it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.37it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.36it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.34it/s] 46%|████▌     | 230/500 [00:15<00:16, 16.36it/s] 46%|████▋     | 232/500 [00:15<00:16, 16.29it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.36it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.32it/s] 48%|████▊     | 238/500 [00:15<00:15, 16.38it/s] 48%|████▊     | 240/500 [00:15<00:15, 16.36it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.24it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.31it/s] 49%|████▉     | 246/500 [00:16<00:15, 16.22it/s] 50%|████▉     | 248/500 [00:16<00:15, 15.87it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 15.81it/s] 50%|█████     | 252/500 [00:16<00:15, 15.98it/s] 51%|█████     | 254/500 [00:16<00:15, 16.20it/s] 51%|█████     | 256/500 [00:16<00:15, 16.24it/s] 52%|█████▏    | 258/500 [00:16<00:15, 16.10it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.04it/s] 52%|█████▏    | 262/500 [00:17<00:14, 16.07it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.19it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.26it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.30it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.40it/s] 54%|█████▍    | 272/500 [00:17<00:13, 16.34it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.41it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.38it/s] 56%|█████▌    | 278/500 [00:18<00:13, 16.22it/s] 56%|█████▌    | 280/500 [00:18<00:13, 16.15it/s] 56%|█████▋    | 282/500 [00:18<00:13, 16.20it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.20it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.68it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.39it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.68it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.49it/s] 59%|█████▉    | 294/500 [00:19<00:13, 15.42it/s] 59%|█████▉    | 296/500 [00:19<00:13, 15.58it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.76it/s] 60%|██████    | 300/500 [00:19<00:12, 15.93it/s] 60%|██████    | 302/500 [00:19<00:12, 16.07it/s] 61%|██████    | 304/500 [00:19<00:12, 16.21it/s] 61%|██████    | 306/500 [00:19<00:11, 16.32it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.39it/s] 62%|██████▏   | 310/500 [00:20<00:11, 16.46it/s] 62%|██████▏   | 312/500 [00:20<00:11, 16.43it/s] 63%|██████▎   | 314/500 [00:20<00:11, 16.38it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.37it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.13it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.26it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.32it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.07it/s] 65%|██████▌   | 326/500 [00:21<00:10, 16.20it/s] 66%|██████▌   | 328/500 [00:21<00:10, 16.31it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.32it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.36it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.87it/s] 67%|██████▋   | 336/500 [00:21<00:11, 14.64it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.12it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.49it/s] 68%|██████▊   | 342/500 [00:22<00:10, 15.77it/s] 69%|██████▉   | 344/500 [00:22<00:09, 15.94it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.04it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.11it/s] 70%|███████   | 350/500 [00:22<00:09, 16.16it/s] 70%|███████   | 352/500 [00:22<00:09, 16.26it/s] 71%|███████   | 354/500 [00:22<00:08, 16.34it/s] 71%|███████   | 356/500 [00:22<00:08, 16.35it/s] 72%|███████▏  | 358/500 [00:23<00:08, 16.35it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.32it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.37it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.36it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.41it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.29it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.28it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.32it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 16.34it/s] 75%|███████▌  | 376/500 [00:24<00:07, 16.36it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.37it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.38it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.46it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.16it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.17it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.12it/s] 78%|███████▊  | 390/500 [00:25<00:06, 16.12it/s] 78%|███████▊  | 392/500 [00:25<00:06, 15.98it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.84it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.02it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.01it/s] 80%|████████  | 400/500 [00:25<00:06, 15.30it/s] 80%|████████  | 402/500 [00:25<00:06, 14.21it/s] 81%|████████  | 404/500 [00:25<00:07, 13.56it/s] 81%|████████  | 406/500 [00:26<00:07, 13.17it/s] 82%|████████▏ | 408/500 [00:26<00:07, 12.91it/s] 82%|████████▏ | 410/500 [00:26<00:07, 12.38it/s] 82%|████████▏ | 412/500 [00:26<00:06, 12.77it/s] 83%|████████▎ | 414/500 [00:26<00:06, 13.67it/s] 83%|████████▎ | 416/500 [00:26<00:05, 14.28it/s] 84%|████████▎ | 418/500 [00:27<00:05, 14.86it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.28it/s] 84%|████████▍ | 422/500 [00:27<00:05, 15.47it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.76it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.85it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.04it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.15it/s] 86%|████████▋ | 432/500 [00:27<00:04, 15.91it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.04it/s] 87%|████████▋ | 436/500 [00:28<00:04, 15.99it/s] 88%|████████▊ | 438/500 [00:28<00:03, 15.98it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.12it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.19it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.31it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.37it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.43it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.45it/s] 90%|█████████ | 452/500 [00:29<00:02, 16.42it/s] 91%|█████████ | 454/500 [00:29<00:02, 16.46it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.51it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.49it/s] 92%|█████████▏| 460/500 [00:29<00:02, 16.44it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.42it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.44it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.36it/s] 94%|█████████▎| 468/500 [00:30<00:01, 16.26it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.82it/s] 94%|█████████▍| 472/500 [00:30<00:01, 14.57it/s] 95%|█████████▍| 474/500 [00:30<00:01, 13.82it/s] 95%|█████████▌| 476/500 [00:30<00:01, 13.33it/s] 96%|█████████▌| 478/500 [00:30<00:01, 13.03it/s] 96%|█████████▌| 480/500 [00:31<00:01, 12.81it/s] 96%|█████████▋| 482/500 [00:31<00:01, 12.67it/s] 97%|█████████▋| 484/500 [00:31<00:01, 12.44it/s] 97%|█████████▋| 486/500 [00:31<00:01, 12.40it/s] 98%|█████████▊| 488/500 [00:31<00:00, 12.35it/s] 98%|█████████▊| 490/500 [00:31<00:00, 12.88it/s] 98%|█████████▊| 492/500 [00:31<00:00, 12.67it/s] 99%|█████████▉| 494/500 [00:32<00:00, 13.02it/s] 99%|█████████▉| 496/500 [00:32<00:00, 13.69it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 14.28it/s]100%|██████████| 500/500 [00:32<00:00, 14.72it/s]100%|██████████| 500/500 [00:32<00:00, 15.38it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  4
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:11,  6.28s/it]  1%|          | 3/500 [00:06<13:54,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<11:01,  1.35s/it]  3%|▎         | 13/500 [00:13<07:30,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:20<09:34,  1.20s/it]  5%|▍         | 23/500 [00:20<06:50,  1.16it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:38,  2.16it/s]  6%|▌         | 29/500 [00:20<02:44,  2.87it/s]  6%|▌         | 31/500 [00:27<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:40,  1.17it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:34,  2.16it/s]  8%|▊         | 39/500 [00:27<02:41,  2.86it/s]  8%|▊         | 41/500 [00:34<09:11,  1.20s/it]  9%|▊         | 43/500 [00:34<06:36,  1.15it/s]  9%|▉         | 45/500 [00:34<04:47,  1.58it/s]  9%|▉         | 47/500 [00:34<03:32,  2.13it/s] 10%|▉         | 49/500 [00:34<02:39,  2.83it/s] 10%|█         | 51/500 [00:41<09:00,  1.20s/it] 11%|█         | 53/500 [00:41<06:26,  1.16it/s] 11%|█         | 55/500 [00:41<04:37,  1.60it/s] 11%|█▏        | 57/500 [00:41<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:48<08:48,  1.20s/it] 13%|█▎        | 63/500 [00:48<06:19,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:35,  1.58it/s] 13%|█▎        | 67/500 [00:48<03:23,  2.13it/s] 14%|█▍        | 69/500 [00:48<02:32,  2.83it/s] 14%|█▍        | 71/500 [00:55<08:33,  1.20s/it] 15%|█▍        | 73/500 [00:55<06:06,  1.16it/s]Epoch:  1  	Training Loss: 0.08722381293773651
Test Loss:  143.9329376220703
Valid Loss:  142.69723510742188
Epoch:  2  	Training Loss: 140.34555053710938
Test Loss:  0.08825551718473434
Valid Loss:  0.09211301803588867
Epoch:  3  	Training Loss: 0.08676294982433319
Test Loss:  0.08770392090082169
Valid Loss:  0.09156706929206848
Epoch:  4  	Training Loss: 0.08625103533267975
Test Loss:  0.0871565192937851
Valid Loss:  0.09102525562047958
Epoch:  5  	Training Loss: 0.08574308454990387
Test Loss:  0.0866132453083992
Valid Loss:  0.09048736095428467
Epoch:  6  	Training Loss: 0.08523880690336227
Test Loss:  0.08607311546802521
Valid Loss:  0.08995065093040466
Epoch:  7  	Training Loss: 0.08473625034093857
Test Loss:  0.08555975556373596
Valid Loss:  0.08943726122379303
Epoch:  8  	Training Loss: 0.08425411581993103
Test Loss:  0.08507950603961945
Valid Loss:  0.08896234631538391
Epoch:  9  	Training Loss: 0.08380383998155594
Test Loss:  0.08461529016494751
Valid Loss:  0.08850178122520447
Epoch:  10  	Training Loss: 0.0833708792924881
Test Loss:  0.0841568186879158
Valid Loss:  0.08804699778556824
Epoch:  11  	Training Loss: 0.08294466137886047
Test Loss:  0.08370184898376465
Valid Loss:  0.08759593218564987
Epoch:  12  	Training Loss: 0.08252204954624176
Test Loss:  0.08329520374536514
Valid Loss:  0.08719149231910706
Epoch:  13  	Training Loss: 0.08214230835437775
Test Loss:  0.08289093524217606
Valid Loss:  0.08678954839706421
Epoch:  14  	Training Loss: 0.08176486194133759
Test Loss:  0.0824890211224556
Valid Loss:  0.08639012277126312
Epoch:  15  	Training Loss: 0.0813896581530571
Test Loss:  0.08220437169075012
Valid Loss:  0.08611178398132324
Epoch:  16  	Training Loss: 0.0811607837677002
Test Loss:  0.08214972913265228
Valid Loss:  0.08607485145330429
Epoch:  17  	Training Loss: 0.08112965524196625
Test Loss:  0.08213064074516296
Valid Loss:  0.0860627293586731
Epoch:  18  	Training Loss: 0.0811198428273201
Test Loss:  0.08212128281593323
Valid Loss:  0.08605579286813736
Epoch:  19  	Training Loss: 0.08111458271741867
Test Loss:  0.08211633563041687
Valid Loss:  0.08605301380157471
Epoch:  20  	Training Loss: 0.08111191540956497
Test Loss:  0.08211361616849899
Valid Loss:  0.08605220913887024
Epoch:  21  	Training Loss: 0.08111021667718887
Test Loss:  0.08211158215999603
Valid Loss:  0.08605161309242249
Epoch:  22  	Training Loss: 0.08110897243022919
Test Loss:  0.08211018145084381
Valid Loss:  0.08605113625526428
Epoch:  23  	Training Loss: 0.08110801875591278
Test Loss:  0.08210912346839905
Valid Loss:  0.08605097234249115
Epoch:  24  	Training Loss: 0.0811072289943695
Test Loss:  0.08210840821266174
Valid Loss:  0.08605103939771652
Epoch:  25  	Training Loss: 0.0811067596077919
Test Loss:  0.08210798352956772
Valid Loss:  0.0860510766506195
Epoch:  26  	Training Loss: 0.08110656589269638
Test Loss:  0.08210776746273041
Valid Loss:  0.0860510915517807
Epoch:  27  	Training Loss: 0.08110649138689041
Test Loss:  0.08210764825344086
Valid Loss:  0.08605106174945831
Epoch:  28  	Training Loss: 0.08110643178224564
Test Loss:  0.0821075364947319
Valid Loss:  0.08605106920003891
Epoch:  29  	Training Loss: 0.08110637217760086
Test Loss:  0.08210740983486176
Valid Loss:  0.0860510766506195
Epoch:  30  	Training Loss: 0.08110632002353668
Test Loss:  0.0821072980761528
Valid Loss:  0.0860510915517807
Epoch:  31  	Training Loss: 0.0811062678694725
Test Loss:  0.08210718631744385
Valid Loss:  0.0860510915517807
Epoch:  32  	Training Loss: 0.08110621571540833
Test Loss:  0.0821070671081543
Valid Loss:  0.0860510990023613
Epoch:  33  	Training Loss: 0.08110616356134415
Test Loss:  0.0821070522069931
Valid Loss:  0.08605106174945831
Epoch:  34  	Training Loss: 0.08110612630844116
Test Loss:  0.08210703730583191
Valid Loss:  0.08605104684829712
Epoch:  35  	Training Loss: 0.08110608905553818
Test Loss:  0.08210702240467072
Valid Loss:  0.08605101704597473
Epoch:  36  	Training Loss: 0.08110605180263519
Test Loss:  0.08210700750350952
Valid Loss:  0.08605098724365234
Epoch:  37  	Training Loss: 0.0811060220003128
Test Loss:  0.08210699260234833
Valid Loss:  0.08605097234249115
Epoch:  38  	Training Loss: 0.08110598474740982
Test Loss:  0.08210697770118713
Valid Loss:  0.08605094254016876
Epoch:  39  	Training Loss: 0.08110594749450684
Test Loss:  0.08210696280002594
Valid Loss:  0.08605091273784637
Epoch:  40  	Training Loss: 0.08110591024160385
Test Loss:  0.08210694789886475
Valid Loss:  0.08605088293552399
Epoch:  41  	Training Loss: 0.08110587298870087
Test Loss:  0.08210693299770355
Valid Loss:  0.0860508605837822
Epoch:  42  	Training Loss: 0.08110584318637848
Test Loss:  0.08210691809654236
Valid Loss:  0.08605082333087921
Epoch:  43  	Training Loss: 0.0811057984828949
Test Loss:  0.08210690319538116
Valid Loss:  0.08605080097913742
Epoch:  44  	Training Loss: 0.08110576868057251
Test Loss:  0.08210688829421997
Valid Loss:  0.08605076372623444
Epoch:  45  	Training Loss: 0.08110572397708893
Test Loss:  0.08210687339305878
Valid Loss:  0.08605073392391205
Epoch:  46  	Training Loss: 0.08110568672418594
Test Loss:  0.08210685849189758
Valid Loss:  0.08605070412158966
Epoch:  47  	Training Loss: 0.08110564947128296
Test Loss:  0.08210684359073639
Valid Loss:  0.08605067431926727
Epoch:  48  	Training Loss: 0.08110560476779938
Test Loss:  0.0821068286895752
Valid Loss:  0.08605064451694489
Epoch:  49  	Training Loss: 0.08110556751489639
Test Loss:  0.0821068212389946
Valid Loss:  0.0860506147146225
Epoch:  50  	Training Loss: 0.08110553026199341
Test Loss:  0.0821068063378334
Valid Loss:  0.08605057746171951
Epoch:  51  	Training Loss: 0.08110548555850983
Test Loss:  0.08210678398609161
Valid Loss:  0.08605055510997772
Epoch:  52  	Training Loss: 0.08110545575618744
Test Loss:  0.08210678398609161
Valid Loss:  0.08605051785707474
Epoch:  53  	Training Loss: 0.08110541105270386
Test Loss:  0.08210676163434982
Valid Loss:  0.08605049550533295
Epoch:  54  	Training Loss: 0.08110538125038147
Test Loss:  0.08210675418376923
Valid Loss:  0.08605046570301056
Epoch:  55  	Training Loss: 0.08110533654689789
Test Loss:  0.08210677653551102
Valid Loss:  0.08605041354894638
Epoch:  56  	Training Loss: 0.0811053067445755
Test Loss:  0.08210676908493042
Valid Loss:  0.0860503762960434
Epoch:  57  	Training Loss: 0.08110526204109192
Test Loss:  0.08210679143667221
Valid Loss:  0.08605033904314041
Epoch:  58  	Training Loss: 0.08110523223876953
Test Loss:  0.08210676908493042
Valid Loss:  0.08605030924081802
Epoch:  59  	Training Loss: 0.08110519498586655
Test Loss:  0.08210679888725281
Valid Loss:  0.08605025708675385
Epoch:  60  	Training Loss: 0.08110515773296356
Test Loss:  0.08210678398609161
Valid Loss:  0.08605022728443146
Epoch:  61  	Training Loss: 0.08110511302947998
Test Loss:  0.082106813788414
Valid Loss:  0.08605018258094788
Epoch:  62  	Training Loss: 0.08110508322715759
Test Loss:  0.08210679888725281
Valid Loss:  0.08605015277862549
Epoch:  63  	Training Loss: 0.08110504597425461
Test Loss:  0.08210677653551102
Valid Loss:  0.0860501229763031
Epoch:  64  	Training Loss: 0.08110500872135162
Test Loss:  0.08210679888725281
Valid Loss:  0.08605007082223892
Epoch:  65  	Training Loss: 0.08110497146844864
Test Loss:  0.08210678398609161
Valid Loss:  0.08605004847049713
Epoch:  66  	Training Loss: 0.08110493421554565
Test Loss:  0.082106813788414
Valid Loss:  0.08604998886585236
Epoch:  67  	Training Loss: 0.08110488951206207
Test Loss:  0.08210679888725281
Valid Loss:  0.08604995906352997
Epoch:  68  	Training Loss: 0.08110485225915909
Test Loss:  0.082106813788414
Valid Loss:  0.08604991436004639
Epoch:  69  	Training Loss: 0.0811048150062561
Test Loss:  0.08210679888725281
Valid Loss:  0.086049884557724
Epoch:  70  	Training Loss: 0.08110477030277252
Test Loss:  0.0821068212389946
Valid Loss:  0.08604983240365982
Epoch:  71  	Training Loss: 0.08110474050045013
Test Loss:  0.0821068063378334
Valid Loss:  0.08604979515075684
Epoch:  72  	Training Loss: 0.08110469579696655
Test Loss:  0.0821068286895752
Valid Loss:  0.08604975044727325
Epoch:  73  	Training Loss: 0.08110465854406357
Test Loss:  0.082106813788414
Valid Loss:  0.08604972064495087
 15%|█▌        | 75/500 [00:55<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:12,  2.20it/s] 16%|█▌        | 79/500 [00:55<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:01<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:02<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:02<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:02<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:02<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:08<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:08<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:08<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:09<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:09<02:12,  3.02it/s] 20%|██        | 101/500 [01:15<07:45,  1.17s/it] 20%|██        | 102/500 [01:15<06:29,  1.02it/s] 21%|██        | 104/500 [01:15<04:29,  1.47it/s] 21%|██        | 106/500 [01:15<03:11,  2.06it/s] 22%|██▏       | 108/500 [01:16<02:18,  2.82it/s] 22%|██▏       | 110/500 [01:16<01:43,  3.78it/s] 22%|██▏       | 112/500 [01:22<07:30,  1.16s/it] 23%|██▎       | 114/500 [01:22<05:21,  1.20it/s] 23%|██▎       | 116/500 [01:22<03:52,  1.65it/s] 24%|██▎       | 118/500 [01:23<02:51,  2.23it/s] 24%|██▍       | 120/500 [01:23<02:08,  2.95it/s] 24%|██▍       | 122/500 [01:29<07:29,  1.19s/it] 25%|██▍       | 124/500 [01:29<05:22,  1.17it/s] 25%|██▌       | 126/500 [01:29<03:53,  1.60it/s] 26%|██▌       | 128/500 [01:30<02:52,  2.16it/s] 26%|██▌       | 130/500 [01:30<02:09,  2.86it/s] 26%|██▋       | 132/500 [01:36<07:22,  1.20s/it] 27%|██▋       | 134/500 [01:36<05:15,  1.16it/s] 27%|██▋       | 136/500 [01:36<03:46,  1.61it/s] 28%|██▊       | 138/500 [01:36<02:44,  2.19it/s] 28%|██▊       | 140/500 [01:37<02:01,  2.95it/s] 28%|██▊       | 142/500 [01:43<07:02,  1.18s/it] 29%|██▉       | 144/500 [01:43<05:03,  1.17it/s]Epoch:  74  	Training Loss: 0.08110462129116058
Test Loss:  0.0821068286895752
Valid Loss:  0.08604966104030609
Epoch:  75  	Training Loss: 0.081104576587677
Test Loss:  0.082106813788414
Valid Loss:  0.0860496312379837
Epoch:  76  	Training Loss: 0.08110453933477402
Test Loss:  0.08210684359073639
Valid Loss:  0.08604957908391953
Epoch:  77  	Training Loss: 0.08110449463129044
Test Loss:  0.082106813788414
Valid Loss:  0.08604954928159714
Epoch:  78  	Training Loss: 0.08110445737838745
Test Loss:  0.0821068286895752
Valid Loss:  0.08604949712753296
Epoch:  79  	Training Loss: 0.08110441267490387
Test Loss:  0.0821068212389946
Valid Loss:  0.08604946732521057
Epoch:  80  	Training Loss: 0.08110437542200089
Test Loss:  0.08210684359073639
Valid Loss:  0.08604941517114639
Epoch:  81  	Training Loss: 0.0811043381690979
Test Loss:  0.0821068212389946
Valid Loss:  0.08604937791824341
Epoch:  82  	Training Loss: 0.08110429346561432
Test Loss:  0.08210684359073639
Valid Loss:  0.08604933321475983
Epoch:  83  	Training Loss: 0.08110425621271133
Test Loss:  0.0821068286895752
Valid Loss:  0.08604929596185684
Epoch:  84  	Training Loss: 0.08110421895980835
Test Loss:  0.08210685104131699
Valid Loss:  0.08604925125837326
Epoch:  85  	Training Loss: 0.08110417425632477
Test Loss:  0.0821068286895752
Valid Loss:  0.08604922890663147
Epoch:  86  	Training Loss: 0.08110413700342178
Test Loss:  0.08210685104131699
Valid Loss:  0.0860491693019867
Epoch:  87  	Training Loss: 0.0811040997505188
Test Loss:  0.08210684359073639
Valid Loss:  0.0860491394996643
Epoch:  88  	Training Loss: 0.08110406249761581
Test Loss:  0.08210685849189758
Valid Loss:  0.08604909479618073
Epoch:  89  	Training Loss: 0.08110402524471283
Test Loss:  0.08210684359073639
Valid Loss:  0.08604906499385834
Epoch:  90  	Training Loss: 0.08110399544239044
Test Loss:  0.08210685849189758
Valid Loss:  0.08604901283979416
Epoch:  91  	Training Loss: 0.08110395073890686
Test Loss:  0.08210685104131699
Valid Loss:  0.08604898303747177
Epoch:  92  	Training Loss: 0.08110390603542328
Test Loss:  0.08210687339305878
Valid Loss:  0.08604893088340759
Epoch:  93  	Training Loss: 0.08110387623310089
Test Loss:  0.08210685849189758
Valid Loss:  0.0860489010810852
Epoch:  94  	Training Loss: 0.08110383152961731
Test Loss:  0.08210688084363937
Valid Loss:  0.08604884892702103
Epoch:  95  	Training Loss: 0.08110379427671432
Test Loss:  0.08210686594247818
Valid Loss:  0.08604881912469864
Epoch:  96  	Training Loss: 0.08110375702381134
Test Loss:  0.08210688829421997
Valid Loss:  0.08604876697063446
Epoch:  97  	Training Loss: 0.08110371977090836
Test Loss:  0.08210687339305878
Valid Loss:  0.08604874461889267
Epoch:  98  	Training Loss: 0.08110368251800537
Test Loss:  0.08210688084363937
Valid Loss:  0.08604869246482849
Epoch:  99  	Training Loss: 0.08110363781452179
Test Loss:  0.08210687339305878
Valid Loss:  0.0860486626625061
Epoch:  100  	Training Loss: 0.0811036080121994
Test Loss:  0.08210688829421997
Valid Loss:  0.08604861795902252
Epoch:  101  	Training Loss: 0.08110356330871582
Test Loss:  0.08210687339305878
Valid Loss:  0.08604858070611954
Epoch:  102  	Training Loss: 0.08110351860523224
Test Loss:  0.08210688829421997
Valid Loss:  0.08604853600263596
Epoch:  103  	Training Loss: 0.08110348880290985
Test Loss:  0.08210687339305878
Valid Loss:  0.08604849874973297
Epoch:  104  	Training Loss: 0.08110344409942627
Test Loss:  0.08210688829421997
Valid Loss:  0.08604844659566879
Epoch:  105  	Training Loss: 0.08110340684652328
Test Loss:  0.08210687339305878
Valid Loss:  0.08604840934276581
Epoch:  106  	Training Loss: 0.0811033695936203
Test Loss:  0.08210688829421997
Valid Loss:  0.08604836463928223
Epoch:  107  	Training Loss: 0.08110332489013672
Test Loss:  0.08210687339305878
Valid Loss:  0.08604833483695984
Epoch:  108  	Training Loss: 0.08110328018665314
Test Loss:  0.08210688829421997
Valid Loss:  0.08604828268289566
Epoch:  109  	Training Loss: 0.08110324293375015
Test Loss:  0.08210686594247818
Valid Loss:  0.08604825288057327
Epoch:  110  	Training Loss: 0.08110320568084717
Test Loss:  0.08210688829421997
Valid Loss:  0.0860482007265091
Epoch:  111  	Training Loss: 0.08110316097736359
Test Loss:  0.08210687339305878
Valid Loss:  0.08604816347360611
Epoch:  112  	Training Loss: 0.0811031237244606
Test Loss:  0.08210688829421997
Valid Loss:  0.08604811131954193
Epoch:  113  	Training Loss: 0.08110308647155762
Test Loss:  0.08210687339305878
Valid Loss:  0.08604808151721954
Epoch:  114  	Training Loss: 0.08110304921865463
Test Loss:  0.08210689574480057
Valid Loss:  0.08604802936315536
Epoch:  115  	Training Loss: 0.08110299706459045
Test Loss:  0.08210688084363937
Valid Loss:  0.08604800701141357
Epoch:  116  	Training Loss: 0.08110296726226807
Test Loss:  0.08210689574480057
Valid Loss:  0.0860479548573494
Epoch:  117  	Training Loss: 0.08110292255878448
Test Loss:  0.08210687339305878
Valid Loss:  0.08604792505502701
Epoch:  118  	Training Loss: 0.0811028853058815
Test Loss:  0.08210689574480057
Valid Loss:  0.08604787290096283
Epoch:  119  	Training Loss: 0.08110284805297852
Test Loss:  0.08210688084363937
Valid Loss:  0.08604784309864044
Epoch:  120  	Training Loss: 0.08110280334949493
Test Loss:  0.08210690319538116
Valid Loss:  0.08604779094457626
Epoch:  121  	Training Loss: 0.08110277354717255
Test Loss:  0.08210688084363937
Valid Loss:  0.08604776859283447
Epoch:  122  	Training Loss: 0.08110272884368896
Test Loss:  0.08210690319538116
Valid Loss:  0.0860477089881897
Epoch:  123  	Training Loss: 0.08110268414020538
Test Loss:  0.08210687339305878
Valid Loss:  0.08604767918586731
Epoch:  124  	Training Loss: 0.0811026468873024
Test Loss:  0.08210688829421997
Valid Loss:  0.08604761958122253
Epoch:  125  	Training Loss: 0.08110259473323822
Test Loss:  0.08210687339305878
Valid Loss:  0.08604758977890015
Epoch:  126  	Training Loss: 0.08110255748033524
Test Loss:  0.08210688829421997
Valid Loss:  0.08604753017425537
Epoch:  127  	Training Loss: 0.08110252022743225
Test Loss:  0.08210687339305878
Valid Loss:  0.08604750037193298
Epoch:  128  	Training Loss: 0.08110247552394867
Test Loss:  0.08210688084363937
Valid Loss:  0.0860474556684494
Epoch:  129  	Training Loss: 0.08110243082046509
Test Loss:  0.08210688829421997
Valid Loss:  0.08604739606380463
Epoch:  130  	Training Loss: 0.0811023861169815
Test Loss:  0.08210686594247818
Valid Loss:  0.08604735881090164
Epoch:  131  	Training Loss: 0.08110234886407852
Test Loss:  0.08210688829421997
Valid Loss:  0.08604730665683746
Epoch:  132  	Training Loss: 0.08110230416059494
Test Loss:  0.08210687339305878
Valid Loss:  0.08604727685451508
Epoch:  133  	Training Loss: 0.08110226690769196
Test Loss:  0.08210690319538116
Valid Loss:  0.0860472321510315
Epoch:  134  	Training Loss: 0.08110222220420837
Test Loss:  0.08210688084363937
Valid Loss:  0.0860472023487091
Epoch:  135  	Training Loss: 0.08110219240188599
Test Loss:  0.08210689574480057
Valid Loss:  0.08604715764522552
Epoch:  136  	Training Loss: 0.081102155148983
Test Loss:  0.08210688829421997
Valid Loss:  0.08604712784290314
Epoch:  137  	Training Loss: 0.08110211789608002
Test Loss:  0.08210690319538116
Valid Loss:  0.08604708313941956
Epoch:  138  	Training Loss: 0.08110207319259644
Test Loss:  0.08210688829421997
Valid Loss:  0.08604706078767776
Epoch:  139  	Training Loss: 0.08110204339027405
Test Loss:  0.08210690319538116
Valid Loss:  0.08604700118303299
Epoch:  140  	Training Loss: 0.08110200613737106
Test Loss:  0.08210688829421997
Valid Loss:  0.0860469713807106
Epoch:  141  	Training Loss: 0.08110196888446808
Test Loss:  0.08210691064596176
Valid Loss:  0.08604693412780762
Epoch:  142  	Training Loss: 0.0811019316315651
Test Loss:  0.08210688829421997
Valid Loss:  0.08604690432548523
Epoch:  143  	Training Loss: 0.08110189437866211
Test Loss:  0.08210691064596176
Valid Loss:  0.08604684472084045
Epoch:  144  	Training Loss: 0.08110184967517853
Test Loss:  0.08210693299770355
Valid Loss:  0.08604680746793747
Epoch:  145  	Training Loss: 0.08110181987285614
Test Loss:  0.08210691064596176
Valid Loss:  0.08604677021503448
 29%|██▉       | 146/500 [01:43<03:40,  1.61it/s] 30%|██▉       | 148/500 [01:43<02:42,  2.17it/s] 30%|███       | 150/500 [01:44<02:01,  2.87it/s] 30%|███       | 152/500 [01:50<06:54,  1.19s/it] 31%|███       | 154/500 [01:50<04:55,  1.17it/s] 31%|███       | 156/500 [01:50<03:32,  1.62it/s] 32%|███▏      | 158/500 [01:50<02:34,  2.22it/s] 32%|███▏      | 160/500 [01:50<01:53,  2.98it/s] 32%|███▏      | 162/500 [01:57<06:49,  1.21s/it] 33%|███▎      | 164/500 [01:57<04:51,  1.15it/s] 33%|███▎      | 166/500 [01:57<03:30,  1.59it/s] 34%|███▎      | 168/500 [01:57<02:32,  2.17it/s] 34%|███▍      | 170/500 [01:57<01:52,  2.93it/s] 34%|███▍      | 172/500 [02:04<06:28,  1.19s/it] 35%|███▍      | 174/500 [02:04<04:36,  1.18it/s] 35%|███▌      | 176/500 [02:04<03:18,  1.63it/s] 36%|███▌      | 178/500 [02:04<02:24,  2.23it/s] 36%|███▌      | 180/500 [02:04<01:46,  2.99it/s] 36%|███▋      | 182/500 [02:11<06:14,  1.18s/it] 37%|███▋      | 184/500 [02:11<04:26,  1.19it/s] 37%|███▋      | 186/500 [02:11<03:11,  1.64it/s] 38%|███▊      | 188/500 [02:11<02:19,  2.24it/s] 38%|███▊      | 190/500 [02:11<01:43,  3.01it/s] 38%|███▊      | 192/500 [02:17<06:04,  1.18s/it] 39%|███▉      | 194/500 [02:18<04:19,  1.18it/s] 39%|███▉      | 196/500 [02:18<03:06,  1.63it/s] 40%|███▉      | 198/500 [02:18<02:15,  2.23it/s] 40%|████      | 200/500 [02:18<01:40,  3.00it/s] 40%|████      | 202/500 [02:25<06:01,  1.21s/it] 41%|████      | 204/500 [02:25<04:19,  1.14it/s] 41%|████      | 206/500 [02:25<03:07,  1.56it/s] 42%|████▏     | 208/500 [02:25<02:18,  2.11it/s] 42%|████▏     | 210/500 [02:25<01:43,  2.80it/s] 42%|████▏     | 212/500 [02:32<05:45,  1.20s/it] 43%|████▎     | 214/500 [02:32<04:06,  1.16it/s] 43%|████▎     | 216/500 [02:32<02:56,  1.61it/s]Epoch:  146  	Training Loss: 0.08110178261995316
Test Loss:  0.08210693299770355
Valid Loss:  0.0860467255115509
Epoch:  147  	Training Loss: 0.08110174536705017
Test Loss:  0.08210691809654236
Valid Loss:  0.08604670315980911
Epoch:  148  	Training Loss: 0.08110170811414719
Test Loss:  0.08210694789886475
Valid Loss:  0.08604665100574493
Epoch:  149  	Training Loss: 0.0811016708612442
Test Loss:  0.08210691809654236
Valid Loss:  0.08604662120342255
Epoch:  150  	Training Loss: 0.08110163360834122
Test Loss:  0.08210694789886475
Valid Loss:  0.08604657649993896
Epoch:  151  	Training Loss: 0.08110159635543823
Test Loss:  0.08210692554712296
Valid Loss:  0.08604654669761658
Epoch:  152  	Training Loss: 0.08110155910253525
Test Loss:  0.08210694789886475
Valid Loss:  0.086046501994133
Epoch:  153  	Training Loss: 0.08110152184963226
Test Loss:  0.08210692554712296
Valid Loss:  0.08604647219181061
Epoch:  154  	Training Loss: 0.08110147714614868
Test Loss:  0.08210694044828415
Valid Loss:  0.08604641258716583
Epoch:  155  	Training Loss: 0.0811014398932457
Test Loss:  0.08210696280002594
Valid Loss:  0.08604636788368225
Epoch:  156  	Training Loss: 0.08110139518976212
Test Loss:  0.08210694044828415
Valid Loss:  0.08604633808135986
Epoch:  157  	Training Loss: 0.08110135793685913
Test Loss:  0.08210696280002594
Valid Loss:  0.08604628592729568
Epoch:  158  	Training Loss: 0.08110132068395615
Test Loss:  0.08210693299770355
Valid Loss:  0.0860462561249733
Epoch:  159  	Training Loss: 0.08110127598047256
Test Loss:  0.08210695534944534
Valid Loss:  0.08604620397090912
Epoch:  160  	Training Loss: 0.08110123872756958
Test Loss:  0.08210693299770355
Valid Loss:  0.08604617416858673
Epoch:  161  	Training Loss: 0.0811012014746666
Test Loss:  0.08210694789886475
Valid Loss:  0.08604612946510315
Epoch:  162  	Training Loss: 0.08110116422176361
Test Loss:  0.08210693299770355
Valid Loss:  0.08604609221220016
Epoch:  163  	Training Loss: 0.08110112696886063
Test Loss:  0.08210695534944534
Valid Loss:  0.08604604750871658
Epoch:  164  	Training Loss: 0.08110108226537704
Test Loss:  0.08210694044828415
Valid Loss:  0.08604602515697479
Epoch:  165  	Training Loss: 0.08110104501247406
Test Loss:  0.08210694789886475
Valid Loss:  0.08604597300291061
Epoch:  166  	Training Loss: 0.08110100030899048
Test Loss:  0.08210696280002594
Valid Loss:  0.08604592084884644
Epoch:  167  	Training Loss: 0.0811009556055069
Test Loss:  0.08210694789886475
Valid Loss:  0.08604589104652405
Epoch:  168  	Training Loss: 0.08110092580318451
Test Loss:  0.08210696280002594
Valid Loss:  0.08604583889245987
Epoch:  169  	Training Loss: 0.08110088855028152
Test Loss:  0.08210694789886475
Valid Loss:  0.08604581654071808
Epoch:  170  	Training Loss: 0.08110085129737854
Test Loss:  0.08210696280002594
Valid Loss:  0.0860457718372345
Epoch:  171  	Training Loss: 0.08110080659389496
Test Loss:  0.08210694789886475
Valid Loss:  0.08604574203491211
Epoch:  172  	Training Loss: 0.08110077679157257
Test Loss:  0.08210696280002594
Valid Loss:  0.08604568988084793
Epoch:  173  	Training Loss: 0.08110073208808899
Test Loss:  0.08210697770118713
Valid Loss:  0.08604563772678375
Epoch:  174  	Training Loss: 0.0811007022857666
Test Loss:  0.08210697025060654
Valid Loss:  0.08604561537504196
Epoch:  175  	Training Loss: 0.08110065758228302
Test Loss:  0.08210697770118713
Valid Loss:  0.08604556322097778
Epoch:  176  	Training Loss: 0.08110061287879944
Test Loss:  0.08210696280002594
Valid Loss:  0.0860455334186554
Epoch:  177  	Training Loss: 0.08110058307647705
Test Loss:  0.08210697770118713
Valid Loss:  0.08604548871517181
Epoch:  178  	Training Loss: 0.08110053837299347
Test Loss:  0.08210696280002594
Valid Loss:  0.08604545891284943
Epoch:  179  	Training Loss: 0.08110050857067108
Test Loss:  0.08210697770118713
Valid Loss:  0.08604541420936584
Epoch:  180  	Training Loss: 0.0811004638671875
Test Loss:  0.08210700005292892
Valid Loss:  0.08604535460472107
Epoch:  181  	Training Loss: 0.08110041916370392
Test Loss:  0.08210697770118713
Valid Loss:  0.08604532480239868
Epoch:  182  	Training Loss: 0.08110038936138153
Test Loss:  0.08210699260234833
Valid Loss:  0.0860452800989151
Epoch:  183  	Training Loss: 0.08110034465789795
Test Loss:  0.08210697770118713
Valid Loss:  0.0860452651977539
Epoch:  184  	Training Loss: 0.08110031485557556
Test Loss:  0.08210700005292892
Valid Loss:  0.08604522049427032
Epoch:  185  	Training Loss: 0.08110027760267258
Test Loss:  0.08210699260234833
Valid Loss:  0.08604519069194794
Epoch:  186  	Training Loss: 0.08110024034976959
Test Loss:  0.08210700750350952
Valid Loss:  0.08604514598846436
Epoch:  187  	Training Loss: 0.0811002105474472
Test Loss:  0.08210702240467072
Valid Loss:  0.08604509383440018
Epoch:  188  	Training Loss: 0.08110017329454422
Test Loss:  0.08210700750350952
Valid Loss:  0.08604507148265839
Epoch:  189  	Training Loss: 0.08110013604164124
Test Loss:  0.08210702240467072
Valid Loss:  0.0860450267791748
Epoch:  190  	Training Loss: 0.08110009133815765
Test Loss:  0.08210700750350952
Valid Loss:  0.08604499697685242
Epoch:  191  	Training Loss: 0.08110006153583527
Test Loss:  0.08210702240467072
Valid Loss:  0.08604495972394943
Epoch:  192  	Training Loss: 0.08110003173351288
Test Loss:  0.08210700750350952
Valid Loss:  0.08604493737220764
Epoch:  193  	Training Loss: 0.0810999944806099
Test Loss:  0.08210703730583191
Valid Loss:  0.08604488521814346
Epoch:  194  	Training Loss: 0.08109995722770691
Test Loss:  0.0821070522069931
Valid Loss:  0.08604484796524048
Epoch:  195  	Training Loss: 0.08109991997480392
Test Loss:  0.0821070522069931
Valid Loss:  0.08604483306407928
Epoch:  196  	Training Loss: 0.08109989017248154
Test Loss:  0.0821070745587349
Valid Loss:  0.0860447809100151
Epoch:  197  	Training Loss: 0.08109986782073975
Test Loss:  0.0821070596575737
Valid Loss:  0.08604476600885391
Epoch:  198  	Training Loss: 0.08109983801841736
Test Loss:  0.08210708200931549
Valid Loss:  0.08604472875595093
Epoch:  199  	Training Loss: 0.08109979331493378
Test Loss:  0.08210710436105728
Valid Loss:  0.08604468405246735
Epoch:  200  	Training Loss: 0.08109976351261139
Test Loss:  0.08210709691047668
Valid Loss:  0.08604466170072556
Epoch:  201  	Training Loss: 0.081099733710289
Test Loss:  0.08210711181163788
Valid Loss:  0.08604461699724197
Epoch:  202  	Training Loss: 0.08109969645738602
Test Loss:  0.08210709691047668
Valid Loss:  0.08604459464550018
Epoch:  203  	Training Loss: 0.08109967410564423
Test Loss:  0.08210711181163788
Valid Loss:  0.0860445499420166
Epoch:  204  	Training Loss: 0.08109962940216064
Test Loss:  0.08210711181163788
Valid Loss:  0.08604452759027481
Epoch:  205  	Training Loss: 0.08109959959983826
Test Loss:  0.08210712671279907
Valid Loss:  0.08604449033737183
Epoch:  206  	Training Loss: 0.08109956979751587
Test Loss:  0.08210714906454086
Valid Loss:  0.08604444563388824
Epoch:  207  	Training Loss: 0.08109952509403229
Test Loss:  0.08210713416337967
Valid Loss:  0.08604441583156586
Epoch:  208  	Training Loss: 0.0810994952917099
Test Loss:  0.08210715651512146
Valid Loss:  0.08604437112808228
Epoch:  209  	Training Loss: 0.08109946548938751
Test Loss:  0.08210714161396027
Valid Loss:  0.08604435622692108
Epoch:  210  	Training Loss: 0.08109942823648453
Test Loss:  0.08210715651512146
Valid Loss:  0.0860443040728569
Epoch:  211  	Training Loss: 0.08109939098358154
Test Loss:  0.08210717886686325
Valid Loss:  0.08604426681995392
Epoch:  212  	Training Loss: 0.08109936118125916
Test Loss:  0.08210715651512146
Valid Loss:  0.08604423701763153
Epoch:  213  	Training Loss: 0.08109931647777557
Test Loss:  0.08210718631744385
Valid Loss:  0.08604419231414795
Epoch:  214  	Training Loss: 0.08109928667545319
Test Loss:  0.08210717141628265
Valid Loss:  0.08604416996240616
Epoch:  215  	Training Loss: 0.0810992494225502
Test Loss:  0.08210718631744385
Valid Loss:  0.08604411780834198
Epoch:  216  	Training Loss: 0.08109921216964722
Test Loss:  0.08210720121860504
Valid Loss:  0.0860440731048584
Epoch:  217  	Training Loss: 0.08109917491674423
Test Loss:  0.08210718631744385
Valid Loss:  0.08604404330253601
 44%|████▎     | 218/500 [02:32<02:08,  2.20it/s] 44%|████▍     | 220/500 [02:32<01:34,  2.96it/s] 44%|████▍     | 222/500 [02:38<05:33,  1.20s/it] 45%|████▍     | 224/500 [02:39<03:57,  1.16it/s] 45%|████▌     | 226/500 [02:39<02:50,  1.61it/s] 46%|████▌     | 228/500 [02:39<02:03,  2.20it/s] 46%|████▌     | 230/500 [02:39<01:31,  2.96it/s] 46%|████▋     | 232/500 [02:45<05:15,  1.18s/it] 47%|████▋     | 234/500 [02:45<03:44,  1.18it/s] 47%|████▋     | 236/500 [02:46<02:41,  1.64it/s] 48%|████▊     | 238/500 [02:46<01:57,  2.24it/s] 48%|████▊     | 240/500 [02:46<01:26,  3.00it/s] 48%|████▊     | 242/500 [02:52<05:09,  1.20s/it] 49%|████▉     | 244/500 [02:52<03:39,  1.16it/s] 49%|████▉     | 246/500 [02:53<02:37,  1.61it/s] 50%|████▉     | 248/500 [02:53<01:54,  2.20it/s] 50%|█████     | 250/500 [02:53<01:24,  2.96it/s] 50%|█████     | 252/500 [02:59<04:58,  1.20s/it] 51%|█████     | 254/500 [02:59<03:31,  1.16it/s] 51%|█████     | 256/500 [02:59<02:31,  1.61it/s] 52%|█████▏    | 258/500 [03:00<01:50,  2.20it/s] 52%|█████▏    | 260/500 [03:00<01:21,  2.96it/s] 52%|█████▏    | 262/500 [03:06<04:40,  1.18s/it] 53%|█████▎    | 264/500 [03:06<03:21,  1.17it/s] 53%|█████▎    | 266/500 [03:06<02:25,  1.60it/s] 54%|█████▎    | 268/500 [03:07<01:45,  2.19it/s] 54%|█████▍    | 270/500 [03:07<01:18,  2.95it/s] 54%|█████▍    | 272/500 [03:13<04:33,  1.20s/it] 55%|█████▍    | 274/500 [03:13<03:14,  1.16it/s] 55%|█████▌    | 276/500 [03:13<02:19,  1.61it/s] 56%|█████▌    | 278/500 [03:13<01:40,  2.20it/s] 56%|█████▌    | 280/500 [03:14<01:14,  2.96it/s] 56%|█████▋    | 282/500 [03:20<04:20,  1.19s/it] 57%|█████▋    | 284/500 [03:20<03:06,  1.16it/s] 57%|█████▋    | 286/500 [03:20<02:14,  1.59it/s] 58%|█████▊    | 288/500 [03:20<01:38,  2.15it/s]Epoch:  218  	Training Loss: 0.08109913021326065
Test Loss:  0.08210719376802444
Valid Loss:  0.08604400604963303
Epoch:  219  	Training Loss: 0.08109910041093826
Test Loss:  0.08210717141628265
Valid Loss:  0.08604396879673004
Epoch:  220  	Training Loss: 0.08109906315803528
Test Loss:  0.08210720121860504
Valid Loss:  0.08604393899440765
Epoch:  221  	Training Loss: 0.08109903335571289
Test Loss:  0.08210721611976624
Valid Loss:  0.08604388684034348
Epoch:  222  	Training Loss: 0.08109898865222931
Test Loss:  0.08210720121860504
Valid Loss:  0.08604386448860168
Epoch:  223  	Training Loss: 0.08109895884990692
Test Loss:  0.08210721611976624
Valid Loss:  0.0860438123345375
Epoch:  224  	Training Loss: 0.08109892159700394
Test Loss:  0.08210719376802444
Valid Loss:  0.08604378998279572
Epoch:  225  	Training Loss: 0.08109888434410095
Test Loss:  0.08210720866918564
Valid Loss:  0.08604373782873154
Epoch:  226  	Training Loss: 0.08109883964061737
Test Loss:  0.08210722357034683
Valid Loss:  0.08604369312524796
Epoch:  227  	Training Loss: 0.08109880238771439
Test Loss:  0.08210720121860504
Valid Loss:  0.08604367077350616
Epoch:  228  	Training Loss: 0.0810987651348114
Test Loss:  0.08210723102092743
Valid Loss:  0.08604361861944199
Epoch:  229  	Training Loss: 0.08109873533248901
Test Loss:  0.08210720866918564
Valid Loss:  0.0860435888171196
Epoch:  230  	Training Loss: 0.08109869062900543
Test Loss:  0.08210721611976624
Valid Loss:  0.08604355156421661
Epoch:  231  	Training Loss: 0.08109866082668304
Test Loss:  0.08210723102092743
Valid Loss:  0.08604350686073303
Epoch:  232  	Training Loss: 0.08109861612319946
Test Loss:  0.08210722357034683
Valid Loss:  0.08604347705841064
Epoch:  233  	Training Loss: 0.08109858632087708
Test Loss:  0.08210723847150803
Valid Loss:  0.08604343235492706
Epoch:  234  	Training Loss: 0.0810985416173935
Test Loss:  0.08210724592208862
Valid Loss:  0.08604337275028229
Epoch:  235  	Training Loss: 0.08109850436449051
Test Loss:  0.08210723847150803
Valid Loss:  0.0860433578491211
Epoch:  236  	Training Loss: 0.08109846711158752
Test Loss:  0.08210724592208862
Valid Loss:  0.08604331314563751
Epoch:  237  	Training Loss: 0.08109842985868454
Test Loss:  0.08210723102092743
Valid Loss:  0.08604328334331512
Epoch:  238  	Training Loss: 0.08109839260578156
Test Loss:  0.08210723847150803
Valid Loss:  0.08604323863983154
Epoch:  239  	Training Loss: 0.08109836280345917
Test Loss:  0.08210725337266922
Valid Loss:  0.08604319393634796
Epoch:  240  	Training Loss: 0.08109831809997559
Test Loss:  0.08210723102092743
Valid Loss:  0.08604316413402557
Epoch:  241  	Training Loss: 0.0810982808470726
Test Loss:  0.08210725337266922
Valid Loss:  0.08604311943054199
Epoch:  242  	Training Loss: 0.08109824359416962
Test Loss:  0.08210726082324982
Valid Loss:  0.08604307472705841
Epoch:  243  	Training Loss: 0.08109819889068604
Test Loss:  0.08210724592208862
Valid Loss:  0.08604304492473602
Epoch:  244  	Training Loss: 0.08109816908836365
Test Loss:  0.08210726082324982
Valid Loss:  0.08604300022125244
Epoch:  245  	Training Loss: 0.08109812438488007
Test Loss:  0.08210723102092743
Valid Loss:  0.08604297041893005
Epoch:  246  	Training Loss: 0.08109807968139648
Test Loss:  0.08210724592208862
Valid Loss:  0.08604291826486588
Epoch:  247  	Training Loss: 0.0810980498790741
Test Loss:  0.08210726082324982
Valid Loss:  0.0860428735613823
Epoch:  248  	Training Loss: 0.08109800517559052
Test Loss:  0.08210724592208862
Valid Loss:  0.0860428437590599
Epoch:  249  	Training Loss: 0.08109797537326813
Test Loss:  0.08210724592208862
Valid Loss:  0.08604279160499573
Epoch:  250  	Training Loss: 0.08109793812036514
Test Loss:  0.08210726827383041
Valid Loss:  0.08604274690151215
Epoch:  251  	Training Loss: 0.08109790086746216
Test Loss:  0.08210725337266922
Valid Loss:  0.08604271709918976
Epoch:  252  	Training Loss: 0.08109785616397858
Test Loss:  0.08210726082324982
Valid Loss:  0.08604267239570618
Epoch:  253  	Training Loss: 0.081097811460495
Test Loss:  0.08210723847150803
Valid Loss:  0.08604264259338379
Epoch:  254  	Training Loss: 0.08109778165817261
Test Loss:  0.08210726082324982
Valid Loss:  0.08604259788990021
Epoch:  255  	Training Loss: 0.08109774440526962
Test Loss:  0.08210726827383041
Valid Loss:  0.08604255318641663
Epoch:  256  	Training Loss: 0.08109769970178604
Test Loss:  0.08210725337266922
Valid Loss:  0.08604252338409424
Epoch:  257  	Training Loss: 0.08109766244888306
Test Loss:  0.08210726082324982
Valid Loss:  0.08604247868061066
Epoch:  258  	Training Loss: 0.08109763264656067
Test Loss:  0.08210727572441101
Valid Loss:  0.08604243397712708
Epoch:  259  	Training Loss: 0.08109758794307709
Test Loss:  0.08210725337266922
Valid Loss:  0.08604240417480469
Epoch:  260  	Training Loss: 0.0810975432395935
Test Loss:  0.08210726827383041
Valid Loss:  0.0860423594713211
Epoch:  261  	Training Loss: 0.08109751343727112
Test Loss:  0.0821072906255722
Valid Loss:  0.08604230731725693
Epoch:  262  	Training Loss: 0.08109746873378754
Test Loss:  0.08210726082324982
Valid Loss:  0.08604228496551514
Epoch:  263  	Training Loss: 0.08109743893146515
Test Loss:  0.08210727572441101
Valid Loss:  0.08604224026203156
Epoch:  264  	Training Loss: 0.08109739422798157
Test Loss:  0.08210726082324982
Valid Loss:  0.08604221045970917
Epoch:  265  	Training Loss: 0.08109736442565918
Test Loss:  0.08210727572441101
Valid Loss:  0.08604216575622559
Epoch:  266  	Training Loss: 0.0810973197221756
Test Loss:  0.08210728317499161
Valid Loss:  0.086042121052742
Epoch:  267  	Training Loss: 0.08109728991985321
Test Loss:  0.08210726827383041
Valid Loss:  0.08604209125041962
Epoch:  268  	Training Loss: 0.08109725266695023
Test Loss:  0.0821072906255722
Valid Loss:  0.08604205399751663
Epoch:  269  	Training Loss: 0.08109721541404724
Test Loss:  0.0821073055267334
Valid Loss:  0.08604200184345245
Epoch:  270  	Training Loss: 0.08109717071056366
Test Loss:  0.08210728317499161
Valid Loss:  0.08604197949171066
Epoch:  271  	Training Loss: 0.08109714090824127
Test Loss:  0.0821072980761528
Valid Loss:  0.08604194223880768
Epoch:  272  	Training Loss: 0.08109710365533829
Test Loss:  0.0821073055267334
Valid Loss:  0.0860418975353241
Epoch:  273  	Training Loss: 0.0810970664024353
Test Loss:  0.0821072906255722
Valid Loss:  0.08604186773300171
Epoch:  274  	Training Loss: 0.08109702914953232
Test Loss:  0.0821073055267334
Valid Loss:  0.08604182302951813
Epoch:  275  	Training Loss: 0.08109699934720993
Test Loss:  0.08210732042789459
Valid Loss:  0.08604178577661514
Epoch:  276  	Training Loss: 0.08109696209430695
Test Loss:  0.0821073055267334
Valid Loss:  0.08604176342487335
Epoch:  277  	Training Loss: 0.08109693229198456
Test Loss:  0.08210732042789459
Valid Loss:  0.08604171872138977
Epoch:  278  	Training Loss: 0.08109688758850098
Test Loss:  0.08210733532905579
Valid Loss:  0.08604167401790619
Epoch:  279  	Training Loss: 0.08109685033559799
Test Loss:  0.08210732042789459
Valid Loss:  0.0860416442155838
Epoch:  280  	Training Loss: 0.08109681308269501
Test Loss:  0.08210733532905579
Valid Loss:  0.08604159951210022
Epoch:  281  	Training Loss: 0.08109678328037262
Test Loss:  0.08210734277963638
Valid Loss:  0.08604155480861664
Epoch:  282  	Training Loss: 0.08109673857688904
Test Loss:  0.08210733532905579
Valid Loss:  0.08604153245687485
Epoch:  283  	Training Loss: 0.08109670877456665
Test Loss:  0.08210733532905579
Valid Loss:  0.08604148775339127
Epoch:  284  	Training Loss: 0.08109666407108307
Test Loss:  0.08210735768079758
Valid Loss:  0.08604143559932709
Epoch:  285  	Training Loss: 0.08109663426876068
Test Loss:  0.08210733532905579
Valid Loss:  0.0860414206981659
Epoch:  286  	Training Loss: 0.0810965970158577
Test Loss:  0.08210735023021698
Valid Loss:  0.08604136854410172
Epoch:  287  	Training Loss: 0.08109655976295471
Test Loss:  0.08210736513137817
Valid Loss:  0.08604132384061813
Epoch:  288  	Training Loss: 0.08109651505947113
Test Loss:  0.08210734277963638
Valid Loss:  0.08604130148887634
Epoch:  289  	Training Loss: 0.08109648525714874
Test Loss:  0.08210735023021698
Valid Loss:  0.08604125678539276
 58%|█████▊    | 290/500 [03:21<01:13,  2.84it/s] 58%|█████▊    | 292/500 [03:27<04:09,  1.20s/it] 59%|█████▉    | 294/500 [03:27<02:56,  1.16it/s] 59%|█████▉    | 296/500 [03:27<02:07,  1.59it/s] 60%|█████▉    | 298/500 [03:27<01:32,  2.18it/s] 60%|██████    | 300/500 [03:28<01:08,  2.94it/s] 60%|██████    | 302/500 [03:34<03:54,  1.18s/it] 61%|██████    | 304/500 [03:34<02:46,  1.18it/s] 61%|██████    | 306/500 [03:34<01:59,  1.63it/s] 62%|██████▏   | 308/500 [03:34<01:26,  2.22it/s] 62%|██████▏   | 310/500 [03:34<01:03,  2.99it/s] 62%|██████▏   | 312/500 [03:41<03:44,  1.19s/it] 63%|██████▎   | 314/500 [03:41<02:39,  1.17it/s] 63%|██████▎   | 316/500 [03:41<01:53,  1.62it/s] 64%|██████▎   | 318/500 [03:41<01:22,  2.21it/s] 64%|██████▍   | 320/500 [03:41<01:00,  2.98it/s] 64%|██████▍   | 322/500 [03:48<03:29,  1.18s/it] 65%|██████▍   | 324/500 [03:48<02:29,  1.18it/s] 65%|██████▌   | 326/500 [03:48<01:48,  1.61it/s] 66%|██████▌   | 328/500 [03:48<01:19,  2.17it/s] 66%|██████▌   | 330/500 [03:48<00:59,  2.87it/s] 66%|██████▋   | 332/500 [03:55<03:20,  1.20s/it] 67%|██████▋   | 334/500 [03:55<02:23,  1.16it/s] 67%|██████▋   | 336/500 [03:55<01:43,  1.59it/s] 68%|██████▊   | 338/500 [03:55<01:14,  2.17it/s] 68%|██████▊   | 340/500 [03:55<00:54,  2.92it/s] 68%|██████▊   | 342/500 [04:02<03:11,  1.21s/it] 69%|██████▉   | 344/500 [04:02<02:15,  1.15it/s] 69%|██████▉   | 346/500 [04:02<01:36,  1.59it/s] 70%|██████▉   | 348/500 [04:02<01:09,  2.18it/s] 70%|███████   | 350/500 [04:02<00:51,  2.93it/s] 70%|███████   | 352/500 [04:09<02:57,  1.20s/it] 71%|███████   | 354/500 [04:09<02:06,  1.16it/s] 71%|███████   | 356/500 [04:09<01:30,  1.60it/s] 72%|███████▏  | 358/500 [04:09<01:05,  2.18it/s] 72%|███████▏  | 360/500 [04:09<00:47,  2.93it/s]Epoch:  290  	Training Loss: 0.08109644055366516
Test Loss:  0.08210736513137817
Valid Loss:  0.08604121208190918
Epoch:  291  	Training Loss: 0.08109641075134277
Test Loss:  0.08210734277963638
Valid Loss:  0.08604118227958679
Epoch:  292  	Training Loss: 0.08109637349843979
Test Loss:  0.08210735768079758
Valid Loss:  0.08604113757610321
Epoch:  293  	Training Loss: 0.08109632879495621
Test Loss:  0.08210736513137817
Valid Loss:  0.08604107797145844
Epoch:  294  	Training Loss: 0.08109629154205322
Test Loss:  0.08210735023021698
Valid Loss:  0.08604106307029724
Epoch:  295  	Training Loss: 0.08109625428915024
Test Loss:  0.08210736513137817
Valid Loss:  0.08604101836681366
Epoch:  296  	Training Loss: 0.08109621703624725
Test Loss:  0.08210737258195877
Valid Loss:  0.08604097366333008
Epoch:  297  	Training Loss: 0.08109617978334427
Test Loss:  0.08210735023021698
Valid Loss:  0.08604094386100769
Epoch:  298  	Training Loss: 0.08109614253044128
Test Loss:  0.08210736513137817
Valid Loss:  0.08604089915752411
Epoch:  299  	Training Loss: 0.0810960978269577
Test Loss:  0.08210736513137817
Valid Loss:  0.08604084700345993
Epoch:  300  	Training Loss: 0.08109606057405472
Test Loss:  0.08210735023021698
Valid Loss:  0.08604082465171814
Epoch:  301  	Training Loss: 0.08109602332115173
Test Loss:  0.08210736513137817
Valid Loss:  0.08604077994823456
Epoch:  302  	Training Loss: 0.08109598606824875
Test Loss:  0.08210738003253937
Valid Loss:  0.08604073524475098
Epoch:  303  	Training Loss: 0.08109594881534576
Test Loss:  0.08210735023021698
Valid Loss:  0.08604070544242859
Epoch:  304  	Training Loss: 0.08109591901302338
Test Loss:  0.08210736513137817
Valid Loss:  0.0860406681895256
Epoch:  305  	Training Loss: 0.0810958743095398
Test Loss:  0.08210738003253937
Valid Loss:  0.08604062348604202
Epoch:  306  	Training Loss: 0.08109583705663681
Test Loss:  0.08210735768079758
Valid Loss:  0.08604060113430023
Epoch:  307  	Training Loss: 0.08109579980373383
Test Loss:  0.08210737258195877
Valid Loss:  0.08604055643081665
Epoch:  308  	Training Loss: 0.08109576255083084
Test Loss:  0.08210738748311996
Valid Loss:  0.08604051172733307
Epoch:  309  	Training Loss: 0.08109572529792786
Test Loss:  0.08210736513137817
Valid Loss:  0.08604048192501068
Epoch:  310  	Training Loss: 0.08109569549560547
Test Loss:  0.08210738003253937
Valid Loss:  0.0860404446721077
Epoch:  311  	Training Loss: 0.08109565079212189
Test Loss:  0.08210739493370056
Valid Loss:  0.08604039996862411
Epoch:  312  	Training Loss: 0.0810956209897995
Test Loss:  0.08210737258195877
Valid Loss:  0.08604037761688232
Epoch:  313  	Training Loss: 0.08109558373689651
Test Loss:  0.08210738748311996
Valid Loss:  0.08604033291339874
Epoch:  314  	Training Loss: 0.08109554648399353
Test Loss:  0.08210740238428116
Valid Loss:  0.08604028820991516
Epoch:  315  	Training Loss: 0.08109550923109055
Test Loss:  0.08210742473602295
Valid Loss:  0.08604024350643158
Epoch:  316  	Training Loss: 0.08109547197818756
Test Loss:  0.08210739493370056
Valid Loss:  0.08604021370410919
Epoch:  317  	Training Loss: 0.08109544217586517
Test Loss:  0.08210740983486176
Valid Loss:  0.0860401839017868
Epoch:  318  	Training Loss: 0.08109539747238159
Test Loss:  0.08210742473602295
Valid Loss:  0.08604013919830322
Epoch:  319  	Training Loss: 0.0810953676700592
Test Loss:  0.08210740238428116
Valid Loss:  0.08604010939598083
Epoch:  320  	Training Loss: 0.08109533041715622
Test Loss:  0.08210740983486176
Valid Loss:  0.08604006469249725
Epoch:  321  	Training Loss: 0.08109529316425323
Test Loss:  0.08210742473602295
Valid Loss:  0.08604002743959427
Epoch:  322  	Training Loss: 0.08109526336193085
Test Loss:  0.08210740983486176
Valid Loss:  0.08603999763727188
Epoch:  323  	Training Loss: 0.08109521865844727
Test Loss:  0.08210742473602295
Valid Loss:  0.0860399603843689
Epoch:  324  	Training Loss: 0.08109518885612488
Test Loss:  0.08210743963718414
Valid Loss:  0.08603991568088531
Epoch:  325  	Training Loss: 0.08109515905380249
Test Loss:  0.08210742473602295
Valid Loss:  0.08603989332914352
Epoch:  326  	Training Loss: 0.0810951218008995
Test Loss:  0.08210743218660355
Valid Loss:  0.08603985607624054
Epoch:  327  	Training Loss: 0.08109508454799652
Test Loss:  0.08210743963718414
Valid Loss:  0.08603981137275696
Epoch:  328  	Training Loss: 0.08109504729509354
Test Loss:  0.08210746198892593
Valid Loss:  0.08603976666927338
Epoch:  329  	Training Loss: 0.08109501004219055
Test Loss:  0.08210744708776474
Valid Loss:  0.08603975176811218
Epoch:  330  	Training Loss: 0.08109498023986816
Test Loss:  0.08210745453834534
Valid Loss:  0.0860397070646286
Epoch:  331  	Training Loss: 0.08109494298696518
Test Loss:  0.08210746943950653
Valid Loss:  0.08603966236114502
Epoch:  332  	Training Loss: 0.0810949057340622
Test Loss:  0.08210744708776474
Valid Loss:  0.08603963255882263
Epoch:  333  	Training Loss: 0.08109487593173981
Test Loss:  0.08210746943950653
Valid Loss:  0.08603958785533905
Epoch:  334  	Training Loss: 0.08109483867883682
Test Loss:  0.08210746943950653
Valid Loss:  0.08603955060243607
Epoch:  335  	Training Loss: 0.08109480142593384
Test Loss:  0.08210748434066772
Valid Loss:  0.08603949844837189
Epoch:  336  	Training Loss: 0.08109476417303085
Test Loss:  0.08210746943950653
Valid Loss:  0.0860394835472107
Epoch:  337  	Training Loss: 0.08109472692012787
Test Loss:  0.08210747689008713
Valid Loss:  0.08603943884372711
Epoch:  338  	Training Loss: 0.08109468966722488
Test Loss:  0.08210748434066772
Valid Loss:  0.08603939414024353
Epoch:  339  	Training Loss: 0.0810946524143219
Test Loss:  0.08210746943950653
Valid Loss:  0.08603937923908234
Epoch:  340  	Training Loss: 0.08109461516141891
Test Loss:  0.08210747689008713
Valid Loss:  0.08603932708501816
Epoch:  341  	Training Loss: 0.08109457790851593
Test Loss:  0.08210748434066772
Valid Loss:  0.08603927493095398
Epoch:  342  	Training Loss: 0.08109454810619354
Test Loss:  0.08210749924182892
Valid Loss:  0.086039237678051
Epoch:  343  	Training Loss: 0.08109450340270996
Test Loss:  0.08210748434066772
Valid Loss:  0.0860392227768898
Epoch:  344  	Training Loss: 0.08109447360038757
Test Loss:  0.08210749924182892
Valid Loss:  0.08603917807340622
Epoch:  345  	Training Loss: 0.08109444379806519
Test Loss:  0.08210751414299011
Valid Loss:  0.08603912591934204
Epoch:  346  	Training Loss: 0.0810943990945816
Test Loss:  0.08210748434066772
Valid Loss:  0.08603911101818085
Epoch:  347  	Training Loss: 0.08109436929225922
Test Loss:  0.08210749924182892
Valid Loss:  0.08603906631469727
Epoch:  348  	Training Loss: 0.08109433203935623
Test Loss:  0.08210751414299011
Valid Loss:  0.08603902906179428
Epoch:  349  	Training Loss: 0.08109429478645325
Test Loss:  0.0821075290441513
Valid Loss:  0.0860389918088913
Epoch:  350  	Training Loss: 0.08109426498413086
Test Loss:  0.08210750669240952
Valid Loss:  0.0860389694571495
Epoch:  351  	Training Loss: 0.08109422773122787
Test Loss:  0.08210751414299011
Valid Loss:  0.08603892475366592
Epoch:  352  	Training Loss: 0.08109419047832489
Test Loss:  0.0821075290441513
Valid Loss:  0.08603888005018234
Epoch:  353  	Training Loss: 0.0810941532254219
Test Loss:  0.08210751414299011
Valid Loss:  0.08603885769844055
Epoch:  354  	Training Loss: 0.08109411597251892
Test Loss:  0.08210752159357071
Valid Loss:  0.08603881299495697
Epoch:  355  	Training Loss: 0.08109407871961594
Test Loss:  0.0821075364947319
Valid Loss:  0.08603876829147339
Epoch:  356  	Training Loss: 0.08109404146671295
Test Loss:  0.0821075364947319
Valid Loss:  0.08603872358798981
Epoch:  357  	Training Loss: 0.08109400421380997
Test Loss:  0.08210751414299011
Valid Loss:  0.08603869378566742
Epoch:  358  	Training Loss: 0.08109396696090698
Test Loss:  0.08210752159357071
Valid Loss:  0.08603864908218384
Epoch:  359  	Training Loss: 0.081093929708004
Test Loss:  0.0821075439453125
Valid Loss:  0.08603861182928085
Epoch:  360  	Training Loss: 0.08109389245510101
Test Loss:  0.0821075513958931
Valid Loss:  0.08603856712579727
Epoch:  361  	Training Loss: 0.08109386265277863
Test Loss:  0.0821075290441513
Valid Loss:  0.08603854477405548
 72%|███████▏  | 362/500 [04:16<02:44,  1.20s/it] 73%|███████▎  | 364/500 [04:16<01:57,  1.16it/s] 73%|███████▎  | 366/500 [04:16<01:24,  1.59it/s] 74%|███████▎  | 368/500 [04:16<01:01,  2.15it/s] 74%|███████▍  | 370/500 [04:16<00:45,  2.84it/s] 74%|███████▍  | 372/500 [04:23<02:33,  1.20s/it] 75%|███████▍  | 374/500 [04:23<01:48,  1.16it/s] 75%|███████▌  | 376/500 [04:23<01:18,  1.59it/s] 76%|███████▌  | 378/500 [04:23<00:56,  2.14it/s] 76%|███████▌  | 380/500 [04:23<00:42,  2.84it/s] 76%|███████▋  | 382/500 [04:30<02:23,  1.22s/it] 77%|███████▋  | 384/500 [04:30<01:41,  1.15it/s] 77%|███████▋  | 386/500 [04:30<01:11,  1.59it/s] 78%|███████▊  | 388/500 [04:30<00:51,  2.17it/s] 78%|███████▊  | 390/500 [04:30<00:37,  2.92it/s] 78%|███████▊  | 392/500 [04:37<02:06,  1.17s/it] 79%|███████▉  | 394/500 [04:37<01:28,  1.19it/s] 79%|███████▉  | 396/500 [04:37<01:03,  1.65it/s] 80%|███████▉  | 398/500 [04:37<00:45,  2.25it/s] 80%|████████  | 400/500 [04:37<00:33,  3.03it/s] 80%|████████  | 402/500 [04:43<01:54,  1.17s/it] 81%|████████  | 404/500 [04:43<01:20,  1.20it/s] 81%|████████  | 406/500 [04:44<00:56,  1.65it/s] 82%|████████▏ | 408/500 [04:44<00:40,  2.25it/s] 82%|████████▏ | 410/500 [04:44<00:29,  3.03it/s] 82%|████████▏ | 412/500 [04:50<01:43,  1.18s/it] 83%|████████▎ | 414/500 [04:50<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:51<00:52,  1.61it/s] 84%|████████▎ | 418/500 [04:51<00:37,  2.17it/s] 84%|████████▍ | 420/500 [04:51<00:27,  2.91it/s] 84%|████████▍ | 422/500 [04:57<01:33,  1.19s/it] 85%|████████▍ | 424/500 [04:57<01:04,  1.17it/s] 85%|████████▌ | 426/500 [04:57<00:45,  1.62it/s] 86%|████████▌ | 428/500 [04:58<00:32,  2.21it/s] 86%|████████▌ | 430/500 [04:58<00:23,  2.97it/s] 86%|████████▋ | 432/500 [05:04<01:19,  1.17s/it]Epoch:  362  	Training Loss: 0.08109381794929504
Test Loss:  0.0821075364947319
Valid Loss:  0.0860385000705719
Epoch:  363  	Training Loss: 0.08109378069639206
Test Loss:  0.0821075439453125
Valid Loss:  0.08603845536708832
Epoch:  364  	Training Loss: 0.08109374344348907
Test Loss:  0.0821075588464737
Valid Loss:  0.08603841066360474
Epoch:  365  	Training Loss: 0.08109370619058609
Test Loss:  0.0821075290441513
Valid Loss:  0.08603838086128235
Epoch:  366  	Training Loss: 0.0810936689376831
Test Loss:  0.0821075439453125
Valid Loss:  0.08603833615779877
Epoch:  367  	Training Loss: 0.08109363168478012
Test Loss:  0.0821075588464737
Valid Loss:  0.08603829145431519
Epoch:  368  	Training Loss: 0.08109359443187714
Test Loss:  0.0821075364947319
Valid Loss:  0.08603827655315399
Epoch:  369  	Training Loss: 0.08109355717897415
Test Loss:  0.0821075439453125
Valid Loss:  0.08603823184967041
Epoch:  370  	Training Loss: 0.08109351992607117
Test Loss:  0.0821075588464737
Valid Loss:  0.08603818714618683
Epoch:  371  	Training Loss: 0.08109347522258759
Test Loss:  0.08210756629705429
Valid Loss:  0.08603814244270325
Epoch:  372  	Training Loss: 0.0810934379696846
Test Loss:  0.0821075439453125
Valid Loss:  0.08603812009096146
Epoch:  373  	Training Loss: 0.08109340071678162
Test Loss:  0.0821075513958931
Valid Loss:  0.08603807538747787
Epoch:  374  	Training Loss: 0.08109337091445923
Test Loss:  0.0821075588464737
Valid Loss:  0.08603803813457489
Epoch:  375  	Training Loss: 0.08109333366155624
Test Loss:  0.08210757374763489
Valid Loss:  0.08603799343109131
Epoch:  376  	Training Loss: 0.08109329640865326
Test Loss:  0.0821075513958931
Valid Loss:  0.08603797107934952
Epoch:  377  	Training Loss: 0.08109326660633087
Test Loss:  0.0821075588464737
Valid Loss:  0.08603793382644653
Epoch:  378  	Training Loss: 0.08109322935342789
Test Loss:  0.08210757374763489
Valid Loss:  0.08603788912296295
Epoch:  379  	Training Loss: 0.0810931921005249
Test Loss:  0.08210758119821548
Valid Loss:  0.08603784441947937
Epoch:  380  	Training Loss: 0.08109316229820251
Test Loss:  0.08210756629705429
Valid Loss:  0.08603781461715698
Epoch:  381  	Training Loss: 0.08109311759471893
Test Loss:  0.08210757374763489
Valid Loss:  0.0860377848148346
Epoch:  382  	Training Loss: 0.08109308034181595
Test Loss:  0.08210758864879608
Valid Loss:  0.08603774011135101
Epoch:  383  	Training Loss: 0.08109304308891296
Test Loss:  0.08210759609937668
Valid Loss:  0.08603769540786743
Epoch:  384  	Training Loss: 0.08109300583600998
Test Loss:  0.08210757374763489
Valid Loss:  0.08603766560554504
Epoch:  385  	Training Loss: 0.081092968583107
Test Loss:  0.08210757374763489
Valid Loss:  0.08603762090206146
Epoch:  386  	Training Loss: 0.08109293133020401
Test Loss:  0.08210758864879608
Valid Loss:  0.08603757619857788
Epoch:  387  	Training Loss: 0.08109289407730103
Test Loss:  0.08210759609937668
Valid Loss:  0.0860375314950943
Epoch:  388  	Training Loss: 0.08109285682439804
Test Loss:  0.08210757374763489
Valid Loss:  0.0860375165939331
Epoch:  389  	Training Loss: 0.08109281957149506
Test Loss:  0.08210758119821548
Valid Loss:  0.08603745698928833
Epoch:  390  	Training Loss: 0.08109278231859207
Test Loss:  0.08210758864879608
Valid Loss:  0.08603742718696594
Epoch:  391  	Training Loss: 0.08109274506568909
Test Loss:  0.08210759609937668
Valid Loss:  0.08603738248348236
Epoch:  392  	Training Loss: 0.0810927078127861
Test Loss:  0.08210761100053787
Valid Loss:  0.08603733777999878
Epoch:  393  	Training Loss: 0.08109267055988312
Test Loss:  0.08210759609937668
Valid Loss:  0.08603732287883759
Epoch:  394  	Training Loss: 0.08109264075756073
Test Loss:  0.08210761845111847
Valid Loss:  0.0860372856259346
Epoch:  395  	Training Loss: 0.08109261095523834
Test Loss:  0.08210761845111847
Valid Loss:  0.08603724837303162
Epoch:  396  	Training Loss: 0.08109258115291595
Test Loss:  0.08210763335227966
Valid Loss:  0.08603720366954803
Epoch:  397  	Training Loss: 0.08109255135059357
Test Loss:  0.08210761845111847
Valid Loss:  0.08603718876838684
Epoch:  398  	Training Loss: 0.08109251409769058
Test Loss:  0.08210763335227966
Valid Loss:  0.08603715151548386
Epoch:  399  	Training Loss: 0.0810924768447876
Test Loss:  0.08210764825344086
Valid Loss:  0.08603711426258087
Epoch:  400  	Training Loss: 0.08109244704246521
Test Loss:  0.08210766315460205
Valid Loss:  0.08603707700967789
Epoch:  401  	Training Loss: 0.08109241724014282
Test Loss:  0.08210764080286026
Valid Loss:  0.0860370546579361
Epoch:  402  	Training Loss: 0.08109238743782043
Test Loss:  0.08210764825344086
Valid Loss:  0.08603700995445251
Epoch:  403  	Training Loss: 0.08109234273433685
Test Loss:  0.08210765570402145
Valid Loss:  0.08603696525096893
Epoch:  404  	Training Loss: 0.08109230548143387
Test Loss:  0.08210766315460205
Valid Loss:  0.08603692054748535
Epoch:  405  	Training Loss: 0.08109226822853088
Test Loss:  0.08210766315460205
Valid Loss:  0.08603689074516296
Epoch:  406  	Training Loss: 0.0810922235250473
Test Loss:  0.08210764825344086
Valid Loss:  0.08603686094284058
Epoch:  407  	Training Loss: 0.08109219372272491
Test Loss:  0.08210764825344086
Valid Loss:  0.0860368087887764
Epoch:  408  	Training Loss: 0.08109214901924133
Test Loss:  0.08210765570402145
Valid Loss:  0.08603677153587341
Epoch:  409  	Training Loss: 0.08109210431575775
Test Loss:  0.08210766315460205
Valid Loss:  0.08603672683238983
Epoch:  410  	Training Loss: 0.08109207451343536
Test Loss:  0.08210764825344086
Valid Loss:  0.08603669703006744
Epoch:  411  	Training Loss: 0.08109203726053238
Test Loss:  0.08210764825344086
Valid Loss:  0.08603665977716446
Epoch:  412  	Training Loss: 0.0810920000076294
Test Loss:  0.08210764825344086
Valid Loss:  0.08603660762310028
Epoch:  413  	Training Loss: 0.08109195530414581
Test Loss:  0.08210765570402145
Valid Loss:  0.0860365629196167
Epoch:  414  	Training Loss: 0.08109191060066223
Test Loss:  0.08210765570402145
Valid Loss:  0.08603651821613312
Epoch:  415  	Training Loss: 0.08109187334775925
Test Loss:  0.08210762590169907
Valid Loss:  0.08603648841381073
Epoch:  416  	Training Loss: 0.08109183609485626
Test Loss:  0.08210763335227966
Valid Loss:  0.08603643625974655
Epoch:  417  	Training Loss: 0.08109179139137268
Test Loss:  0.08210763335227966
Valid Loss:  0.08603639900684357
Epoch:  418  	Training Loss: 0.0810917466878891
Test Loss:  0.08210763335227966
Valid Loss:  0.08603634685277939
Epoch:  419  	Training Loss: 0.08109170943498611
Test Loss:  0.08210760354995728
Valid Loss:  0.0860363095998764
Epoch:  420  	Training Loss: 0.08109166473150253
Test Loss:  0.08210761100053787
Valid Loss:  0.08603627234697342
Epoch:  421  	Training Loss: 0.08109162747859955
Test Loss:  0.08210761845111847
Valid Loss:  0.08603622764348984
Epoch:  422  	Training Loss: 0.08109158277511597
Test Loss:  0.08210762590169907
Valid Loss:  0.08603618294000626
Epoch:  423  	Training Loss: 0.08109154552221298
Test Loss:  0.08210763335227966
Valid Loss:  0.08603613078594208
Epoch:  424  	Training Loss: 0.08109150826931
Test Loss:  0.08210760354995728
Valid Loss:  0.08603610843420029
Epoch:  425  	Training Loss: 0.08109146356582642
Test Loss:  0.08210760354995728
Valid Loss:  0.08603605628013611
Epoch:  426  	Training Loss: 0.08109143376350403
Test Loss:  0.08210761100053787
Valid Loss:  0.08603601902723312
Epoch:  427  	Training Loss: 0.08109138906002045
Test Loss:  0.08210761845111847
Valid Loss:  0.08603597432374954
Epoch:  428  	Training Loss: 0.08109135180711746
Test Loss:  0.08210762590169907
Valid Loss:  0.08603592962026596
Epoch:  429  	Training Loss: 0.08109131455421448
Test Loss:  0.08210759609937668
Valid Loss:  0.08603589981794357
Epoch:  430  	Training Loss: 0.0810912698507309
Test Loss:  0.08210760354995728
Valid Loss:  0.08603586256504059
Epoch:  431  	Training Loss: 0.08109123259782791
Test Loss:  0.08210761845111847
Valid Loss:  0.086035817861557
Epoch:  432  	Training Loss: 0.08109119534492493
Test Loss:  0.08210761845111847
Valid Loss:  0.08603577315807343
Epoch:  433  	Training Loss: 0.08109115064144135
Test Loss:  0.08210761845111847
Valid Loss:  0.08603573590517044
 87%|████████▋ | 434/500 [05:04<00:55,  1.19it/s] 87%|████████▋ | 436/500 [05:04<00:38,  1.64it/s] 88%|████████▊ | 438/500 [05:04<00:27,  2.24it/s] 88%|████████▊ | 440/500 [05:04<00:19,  3.00it/s] 88%|████████▊ | 442/500 [05:11<01:07,  1.16s/it] 89%|████████▉ | 444/500 [05:11<00:46,  1.21it/s] 89%|████████▉ | 446/500 [05:11<00:32,  1.67it/s] 90%|████████▉ | 448/500 [05:11<00:22,  2.28it/s] 90%|█████████ | 450/500 [05:11<00:16,  3.04it/s] 90%|█████████ | 452/500 [05:18<00:58,  1.22s/it] 91%|█████████ | 454/500 [05:18<00:40,  1.14it/s] 91%|█████████ | 456/500 [05:18<00:27,  1.58it/s] 92%|█████████▏| 458/500 [05:18<00:19,  2.16it/s] 92%|█████████▏| 460/500 [05:18<00:13,  2.91it/s] 92%|█████████▏| 462/500 [05:25<00:44,  1.18s/it] 93%|█████████▎| 464/500 [05:25<00:30,  1.18it/s] 93%|█████████▎| 466/500 [05:25<00:21,  1.61it/s] 94%|█████████▎| 468/500 [05:25<00:14,  2.18it/s] 94%|█████████▍| 470/500 [05:25<00:10,  2.93it/s] 94%|█████████▍| 472/500 [05:31<00:32,  1.18s/it] 95%|█████████▍| 474/500 [05:32<00:21,  1.19it/s] 95%|█████████▌| 476/500 [05:32<00:14,  1.64it/s] 96%|█████████▌| 478/500 [05:32<00:09,  2.24it/s] 96%|█████████▌| 480/500 [05:32<00:06,  3.00it/s] 96%|█████████▋| 482/500 [05:39<00:22,  1.23s/it] 97%|█████████▋| 484/500 [05:39<00:14,  1.14it/s] 97%|█████████▋| 486/500 [05:39<00:08,  1.58it/s] 98%|█████████▊| 488/500 [05:39<00:05,  2.16it/s] 98%|█████████▊| 490/500 [05:39<00:03,  2.90it/s] 98%|█████████▊| 492/500 [05:45<00:09,  1.19s/it] 99%|█████████▉| 494/500 [05:46<00:05,  1.18it/s] 99%|█████████▉| 496/500 [05:46<00:02,  1.63it/s]100%|█████████▉| 498/500 [05:46<00:00,  2.22it/s]100%|██████████| 500/500 [05:46<00:00,  2.99it/s]100%|██████████| 500/500 [05:46<00:00,  1.44it/s]
Epoch:  434  	Training Loss: 0.08109112083911896
Test Loss:  0.08210760354995728
Valid Loss:  0.08603571355342865
Epoch:  435  	Training Loss: 0.08109109103679657
Test Loss:  0.08210761100053787
Valid Loss:  0.08603566884994507
Epoch:  436  	Training Loss: 0.08109104633331299
Test Loss:  0.08210761845111847
Valid Loss:  0.08603563159704208
Epoch:  437  	Training Loss: 0.0810910165309906
Test Loss:  0.08210763335227966
Valid Loss:  0.0860355943441391
Epoch:  438  	Training Loss: 0.08109097182750702
Test Loss:  0.08210764825344086
Valid Loss:  0.08603555709123611
Epoch:  439  	Training Loss: 0.08109094202518463
Test Loss:  0.08210761845111847
Valid Loss:  0.08603552728891373
Epoch:  440  	Training Loss: 0.08109090477228165
Test Loss:  0.08210761845111847
Valid Loss:  0.08603549003601074
Epoch:  441  	Training Loss: 0.08109086751937866
Test Loss:  0.08210763335227966
Valid Loss:  0.08603544533252716
Epoch:  442  	Training Loss: 0.08109083771705627
Test Loss:  0.08210763335227966
Valid Loss:  0.08603540807962418
Epoch:  443  	Training Loss: 0.08109079301357269
Test Loss:  0.08210764825344086
Valid Loss:  0.08603535592556
Epoch:  444  	Training Loss: 0.0810907632112503
Test Loss:  0.08210761845111847
Valid Loss:  0.0860353410243988
Epoch:  445  	Training Loss: 0.08109071850776672
Test Loss:  0.08210762590169907
Valid Loss:  0.08603528887033463
Epoch:  446  	Training Loss: 0.08109068125486374
Test Loss:  0.08210763335227966
Valid Loss:  0.08603524416685104
Epoch:  447  	Training Loss: 0.08109064400196075
Test Loss:  0.08210763335227966
Valid Loss:  0.08603520691394806
Epoch:  448  	Training Loss: 0.08109061419963837
Test Loss:  0.08210764825344086
Valid Loss:  0.08603516221046448
Epoch:  449  	Training Loss: 0.08109056949615479
Test Loss:  0.08210764825344086
Valid Loss:  0.0860351175069809
Epoch:  450  	Training Loss: 0.0810905247926712
Test Loss:  0.08210763335227966
Valid Loss:  0.0860350951552391
Epoch:  451  	Training Loss: 0.08109049499034882
Test Loss:  0.08210763335227966
Valid Loss:  0.08603505790233612
Epoch:  452  	Training Loss: 0.08109045773744583
Test Loss:  0.08210764080286026
Valid Loss:  0.08603501319885254
Epoch:  453  	Training Loss: 0.08109042048454285
Test Loss:  0.08210764825344086
Valid Loss:  0.08603497594594955
Epoch:  454  	Training Loss: 0.08109039068222046
Test Loss:  0.08210765570402145
Valid Loss:  0.08603493869304657
Epoch:  455  	Training Loss: 0.08109034597873688
Test Loss:  0.08210766315460205
Valid Loss:  0.08603489398956299
Epoch:  456  	Training Loss: 0.08109031617641449
Test Loss:  0.08210764825344086
Valid Loss:  0.0860348716378212
Epoch:  457  	Training Loss: 0.0810902789235115
Test Loss:  0.08210764825344086
Valid Loss:  0.08603483438491821
Epoch:  458  	Training Loss: 0.08109024167060852
Test Loss:  0.08210765570402145
Valid Loss:  0.08603478968143463
Epoch:  459  	Training Loss: 0.08109020441770554
Test Loss:  0.08210766315460205
Valid Loss:  0.08603475242853165
Epoch:  460  	Training Loss: 0.08109016716480255
Test Loss:  0.08210767805576324
Valid Loss:  0.08603471517562866
Epoch:  461  	Training Loss: 0.08109013736248016
Test Loss:  0.08210764825344086
Valid Loss:  0.08603468537330627
Epoch:  462  	Training Loss: 0.08109010010957718
Test Loss:  0.08210765570402145
Valid Loss:  0.08603464812040329
Epoch:  463  	Training Loss: 0.0810900628566742
Test Loss:  0.08210766315460205
Valid Loss:  0.08603460341691971
Epoch:  464  	Training Loss: 0.0810900330543518
Test Loss:  0.08210767060518265
Valid Loss:  0.08603457361459732
Epoch:  465  	Training Loss: 0.08108998835086823
Test Loss:  0.08210767805576324
Valid Loss:  0.08603453636169434
Epoch:  466  	Training Loss: 0.08108995854854584
Test Loss:  0.08210768550634384
Valid Loss:  0.08603449165821075
Epoch:  467  	Training Loss: 0.08108992129564285
Test Loss:  0.08210765570402145
Valid Loss:  0.08603446185588837
Epoch:  468  	Training Loss: 0.08108988404273987
Test Loss:  0.08210766315460205
Valid Loss:  0.08603443205356598
Epoch:  469  	Training Loss: 0.08108984678983688
Test Loss:  0.08210767805576324
Valid Loss:  0.0860343873500824
Epoch:  470  	Training Loss: 0.0810898095369339
Test Loss:  0.08210767805576324
Valid Loss:  0.08603435009717941
Epoch:  471  	Training Loss: 0.08108977973461151
Test Loss:  0.08210769295692444
Valid Loss:  0.08603431284427643
Epoch:  472  	Training Loss: 0.08108974248170853
Test Loss:  0.08210770040750504
Valid Loss:  0.08603426814079285
Epoch:  473  	Training Loss: 0.08108970522880554
Test Loss:  0.08210767805576324
Valid Loss:  0.08603425323963165
Epoch:  474  	Training Loss: 0.08108967542648315
Test Loss:  0.08210767805576324
Valid Loss:  0.08603420853614807
Epoch:  475  	Training Loss: 0.08108963072299957
Test Loss:  0.08210769295692444
Valid Loss:  0.08603416383266449
Epoch:  476  	Training Loss: 0.08108960092067719
Test Loss:  0.08210770040750504
Valid Loss:  0.0860341340303421
Epoch:  477  	Training Loss: 0.0810895636677742
Test Loss:  0.08210770785808563
Valid Loss:  0.08603408932685852
Epoch:  478  	Training Loss: 0.08108953386545181
Test Loss:  0.08210772275924683
Valid Loss:  0.08603405952453613
Epoch:  479  	Training Loss: 0.08108949661254883
Test Loss:  0.08210772275924683
Valid Loss:  0.08603401482105255
Epoch:  480  	Training Loss: 0.08108946681022644
Test Loss:  0.08210769295692444
Valid Loss:  0.08603399246931076
Epoch:  481  	Training Loss: 0.08108942955732346
Test Loss:  0.08210770785808563
Valid Loss:  0.08603395521640778
Epoch:  482  	Training Loss: 0.08108939230442047
Test Loss:  0.08210771530866623
Valid Loss:  0.0860339105129242
Epoch:  483  	Training Loss: 0.08108935505151749
Test Loss:  0.08210772275924683
Valid Loss:  0.08603387326002121
Epoch:  484  	Training Loss: 0.0810893252491951
Test Loss:  0.08210773766040802
Valid Loss:  0.08603383600711823
Epoch:  485  	Training Loss: 0.08108928799629211
Test Loss:  0.08210774511098862
Valid Loss:  0.08603380620479584
Epoch:  486  	Training Loss: 0.08108925819396973
Test Loss:  0.08210775256156921
Valid Loss:  0.08603376895189285
Epoch:  487  	Training Loss: 0.08108922094106674
Test Loss:  0.08210773020982742
Valid Loss:  0.08603374660015106
Epoch:  488  	Training Loss: 0.08108918368816376
Test Loss:  0.08210773766040802
Valid Loss:  0.08603370189666748
Epoch:  489  	Training Loss: 0.08108915388584137
Test Loss:  0.08210775256156921
Valid Loss:  0.08603367209434509
Epoch:  490  	Training Loss: 0.08108911663293839
Test Loss:  0.08210776001214981
Valid Loss:  0.08603362739086151
Epoch:  491  	Training Loss: 0.081089086830616
Test Loss:  0.08210776746273041
Valid Loss:  0.08603359013795853
Epoch:  492  	Training Loss: 0.08108904957771301
Test Loss:  0.08210776746273041
Valid Loss:  0.08603355288505554
Epoch:  493  	Training Loss: 0.08108901977539062
Test Loss:  0.08210776746273041
Valid Loss:  0.08603350818157196
Epoch:  494  	Training Loss: 0.08108897507190704
Test Loss:  0.08210774511098862
Valid Loss:  0.08603349328041077
Epoch:  495  	Training Loss: 0.08108893781900406
Test Loss:  0.08210774511098862
Valid Loss:  0.08603343367576599
Epoch:  496  	Training Loss: 0.08108890056610107
Test Loss:  0.08210775256156921
Valid Loss:  0.0860334038734436
Epoch:  497  	Training Loss: 0.08108885586261749
Test Loss:  0.08210776001214981
Valid Loss:  0.08603335916996002
Epoch:  498  	Training Loss: 0.0810888260602951
Test Loss:  0.08210776001214981
Valid Loss:  0.08603331446647644
Epoch:  499  	Training Loss: 0.08108878135681152
Test Loss:  0.08210776746273041
Valid Loss:  0.08603327721357346
Epoch:  500  	Training Loss: 0.08108875155448914
Test Loss:  0.08210776746273041
Valid Loss:  0.08603323996067047
seed is  4
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:56,  6.25s/it]  1%|          | 3/500 [00:06<13:57,  1.69s/it]  1%|          | 5/500 [00:06<07:07,  1.16it/s]  1%|▏         | 7/500 [00:06<04:23,  1.87it/s]  2%|▏         | 9/500 [00:06<02:57,  2.76it/s]  2%|▏         | 11/500 [00:13<11:17,  1.38s/it]  3%|▎         | 13/500 [00:13<07:41,  1.06it/s]  3%|▎         | 15/500 [00:13<05:21,  1.51it/s]  3%|▎         | 17/500 [00:13<03:49,  2.11it/s]  4%|▍         | 19/500 [00:14<02:47,  2.87it/s]  4%|▍         | 21/500 [00:20<09:32,  1.19s/it]  5%|▍         | 23/500 [00:20<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:40,  2.94it/s]  6%|▌         | 31/500 [00:27<09:11,  1.18s/it]  7%|▋         | 33/500 [00:27<06:36,  1.18it/s]  7%|▋         | 35/500 [00:33<12:00,  1.55s/it]  7%|▋         | 37/500 [00:33<08:31,  1.11s/it]  8%|▊         | 39/500 [00:33<06:05,  1.26it/s]  8%|▊         | 41/500 [00:40<11:27,  1.50s/it]  9%|▊         | 43/500 [00:40<08:08,  1.07s/it]  9%|▉         | 45/500 [00:40<05:49,  1.30it/s]  9%|▉         | 47/500 [00:40<04:12,  1.79it/s] 10%|▉         | 49/500 [00:40<03:04,  2.44it/s] 10%|█         | 51/500 [00:47<09:19,  1.25s/it] 11%|█         | 53/500 [00:47<06:39,  1.12it/s] 11%|█         | 55/500 [00:47<04:46,  1.55it/s] 11%|█▏        | 57/500 [00:47<03:29,  2.12it/s] 12%|█▏        | 59/500 [00:47<02:34,  2.86it/s] 12%|█▏        | 61/500 [00:54<08:54,  1.22s/it] 13%|█▎        | 63/500 [00:54<06:21,  1.14it/s] 13%|█▎        | 65/500 [00:54<04:34,  1.59it/s] 13%|█▎        | 67/500 [00:54<03:19,  2.17it/s] 14%|█▍        | 69/500 [00:54<02:27,  2.93it/s]Epoch:  1  	Training Loss: 0.08722381293773651
Test Loss:  6.899648666381836
Valid Loss:  6.95975923538208
Epoch:  2  	Training Loss: 6.877707481384277
Test Loss:  258.2027587890625
Valid Loss:  254.250732421875
Epoch:  3  	Training Loss: 249.94036865234375
Test Loss:  0.2907167673110962
Valid Loss:  0.3196350634098053
Epoch:  4  	Training Loss: 0.32936757802963257
Test Loss:  0.29064637422561646
Valid Loss:  0.31954342126846313
Epoch:  5  	Training Loss: 0.3292769193649292
Test Loss:  0.2905791103839874
Valid Loss:  0.3194521367549896
Epoch:  6  	Training Loss: 0.3291865885257721
Test Loss:  0.29051196575164795
Valid Loss:  0.3193611204624176
Epoch:  7  	Training Loss: 0.32909661531448364
Test Loss:  0.29044508934020996
Valid Loss:  0.3192705512046814
Epoch:  8  	Training Loss: 0.3290071189403534
Test Loss:  0.2903783917427063
Valid Loss:  0.31918013095855713
Epoch:  9  	Training Loss: 0.328917920589447
Test Loss:  0.2903124690055847
Valid Loss:  0.31909096240997314
Epoch:  10  	Training Loss: 0.3288308084011078
Test Loss:  0.29024672508239746
Valid Loss:  0.3190020024776459
Epoch:  11  	Training Loss: 0.32874393463134766
Test Loss:  0.2901858985424042
Valid Loss:  0.3189195692539215
Epoch:  12  	Training Loss: 0.3286655843257904
Test Loss:  0.7002420425415039
Valid Loss:  0.666644811630249
Epoch:  13  	Training Loss: 0.636134147644043
Test Loss:  0.051641374826431274
Valid Loss:  0.05846097320318222
Epoch:  14  	Training Loss: 0.054698165506124496
Test Loss:  0.05113905668258667
Valid Loss:  0.05637787654995918
Epoch:  15  	Training Loss: 0.05237184092402458
Test Loss:  0.05088699981570244
Valid Loss:  0.055048927664756775
Epoch:  16  	Training Loss: 0.05083107203245163
Test Loss:  0.05074363201856613
Valid Loss:  0.05416230857372284
Epoch:  17  	Training Loss: 0.049752794206142426
Test Loss:  0.05065910518169403
Valid Loss:  0.05352500453591347
Epoch:  18  	Training Loss: 0.0489668995141983
Test Loss:  0.05059251934289932
Valid Loss:  0.05305997282266617
Epoch:  19  	Training Loss: 0.04838341102004051
Test Loss:  0.05054265633225441
Valid Loss:  0.052723534405231476
Epoch:  20  	Training Loss: 0.04794447124004364
Test Loss:  0.05051302909851074
Valid Loss:  0.05245664343237877
Epoch:  21  	Training Loss: 0.04761044681072235
Test Loss:  0.05049839988350868
Valid Loss:  0.052254483103752136
Epoch:  22  	Training Loss: 0.047359466552734375
Test Loss:  0.1844167411327362
Valid Loss:  0.1929377019405365
Epoch:  23  	Training Loss: 0.19936075806617737
Test Loss:  0.0658075362443924
Valid Loss:  0.06496335566043854
Epoch:  24  	Training Loss: 0.059797242283821106
Test Loss:  0.05870818346738815
Valid Loss:  0.05947719141840935
Epoch:  25  	Training Loss: 0.053829751908779144
Test Loss:  0.058701515197753906
Valid Loss:  0.05944865942001343
Epoch:  26  	Training Loss: 0.05379973351955414
Test Loss:  0.05869673565030098
Valid Loss:  0.05942326411604881
Epoch:  27  	Training Loss: 0.05377264320850372
Test Loss:  0.05869315564632416
Valid Loss:  0.0594005286693573
Epoch:  28  	Training Loss: 0.053748518228530884
Test Loss:  0.058690667152404785
Valid Loss:  0.05938030406832695
Epoch:  29  	Training Loss: 0.05372661352157593
Test Loss:  0.05868872255086899
Valid Loss:  0.05936175584793091
Epoch:  30  	Training Loss: 0.05370659381151199
Test Loss:  0.058686867356300354
Valid Loss:  0.05934460461139679
Epoch:  31  	Training Loss: 0.053688131272792816
Test Loss:  0.058685287833213806
Valid Loss:  0.05932897329330444
Epoch:  32  	Training Loss: 0.053671274334192276
Test Loss:  0.9116500020027161
Valid Loss:  0.9138893485069275
Epoch:  33  	Training Loss: 0.926925778388977
Test Loss:  0.13566282391548157
Valid Loss:  0.13821452856063843
Epoch:  34  	Training Loss: 0.12981000542640686
Test Loss:  0.13561972975730896
Valid Loss:  0.1381877362728119
Epoch:  35  	Training Loss: 0.12976497411727905
Test Loss:  0.1356036365032196
Valid Loss:  0.138179749250412
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.1297515332698822
Test Loss:  0.033036887645721436
Valid Loss:  0.03837011381983757
Epoch:  37  	Training Loss: 0.03779857978224754
Test Loss:  0.018836403265595436
Valid Loss:  0.024069391191005707
Epoch:  38  	Training Loss: 0.025302357971668243
Test Loss:  0.014863619580864906
Valid Loss:  0.019748752936720848
Epoch:  39  	Training Loss: 0.021283874288201332
Test Loss:  0.012849956750869751
Valid Loss:  0.01740855723619461
Epoch:  40  	Training Loss: 0.018807077780365944
Test Loss:  0.011373426765203476
Valid Loss:  0.015595309436321259
Epoch:  41  	Training Loss: 0.016830159351229668
Test Loss:  0.010163580067455769
Valid Loss:  0.014062246307730675
Epoch:  42  	Training Loss: 0.015118141658604145
Test Loss:  0.010073676705360413
Valid Loss:  0.013577815145254135
Epoch:  43  	Training Loss: 0.014421907253563404
Test Loss:  0.010021217167377472
Valid Loss:  0.01347956620156765
Epoch:  44  	Training Loss: 0.014265745878219604
Test Loss:  0.00996758509427309
Valid Loss:  0.013381529599428177
Epoch:  45  	Training Loss: 0.014118421822786331
Test Loss:  0.009917806833982468
Valid Loss:  0.0132887102663517
Epoch:  46  	Training Loss: 0.01397949643433094
Test Loss:  0.009876104071736336
Valid Loss:  0.013206868432462215
Epoch:  47  	Training Loss: 0.013848213478922844
Test Loss:  0.009831234812736511
Valid Loss:  0.013123564422130585
Epoch:  48  	Training Loss: 0.01372307725250721
Test Loss:  0.009788990020751953
Valid Loss:  0.013045133091509342
Epoch:  49  	Training Loss: 0.013603366911411285
Test Loss:  0.009743276983499527
Valid Loss:  0.012965500354766846
Epoch:  50  	Training Loss: 0.013488007709383965
Test Loss:  0.00969427265226841
Valid Loss:  0.012883815914392471
Epoch:  51  	Training Loss: 0.013376136310398579
Test Loss:  0.009646483696997166
Valid Loss:  0.012804833240807056
Epoch:  52  	Training Loss: 0.01326768472790718
Test Loss:  0.007824115455150604
Valid Loss:  0.011114963330328465
Epoch:  53  	Training Loss: 0.012794947251677513
Test Loss:  0.006921634078025818
Valid Loss:  0.009587343782186508
Epoch:  54  	Training Loss: 0.010029366239905357
Test Loss:  0.004891056567430496
Valid Loss:  0.007271621376276016
Epoch:  55  	Training Loss: 0.00794953852891922
Test Loss:  0.0042832717299461365
Valid Loss:  0.006505997851490974
Epoch:  56  	Training Loss: 0.007172712124884129
Test Loss:  0.0038891523145139217
Valid Loss:  0.00598883256316185
Epoch:  57  	Training Loss: 0.00658022565767169
Test Loss:  0.0035678367130458355
Valid Loss:  0.005560079123824835
Epoch:  58  	Training Loss: 0.0060642920434474945
Test Loss:  0.0032928823493421078
Valid Loss:  0.00518831517547369
Epoch:  59  	Training Loss: 0.005608418956398964
Test Loss:  0.003054720349609852
Valid Loss:  0.0048621417954564095
Epoch:  60  	Training Loss: 0.005205030553042889
Test Loss:  0.0028477716259658337
Valid Loss:  0.004574956372380257
Epoch:  61  	Training Loss: 0.004848041571676731
Test Loss:  0.002667903434485197
Valid Loss:  0.004321836866438389
Epoch:  62  	Training Loss: 0.004532124847173691
Test Loss:  0.0030951788648962975
Valid Loss:  0.004279053770005703
Epoch:  63  	Training Loss: 0.0037928943056613207
Test Loss:  0.0028127431869506836
Valid Loss:  0.004047004505991936
Epoch:  64  	Training Loss: 0.003703243564814329
Test Loss:  0.0028033354319632053
Valid Loss:  0.004002956673502922
Epoch:  65  	Training Loss: 0.003638884052634239
Test Loss:  0.0027520740404725075
Valid Loss:  0.0039298636838793755
Epoch:  66  	Training Loss: 0.003577366704121232
Test Loss:  0.002706313505768776
Valid Loss:  0.003860157448798418
Epoch:  67  	Training Loss: 0.003517122007906437
Test Loss:  0.002673315117135644
Valid Loss:  0.003802688792347908
Epoch:  68  	Training Loss: 0.0034673893824219704
Test Loss:  0.002649521455168724
Valid Loss:  0.0037557203322649
Epoch:  69  	Training Loss: 0.00342634622938931
Test Loss:  0.0026275792624801397
Valid Loss:  0.0037126620300114155
Epoch:  70  	Training Loss: 0.003389350138604641
Test Loss:  0.002605044050142169
Valid Loss:  0.0036730810534209013
Epoch:  71  	Training Loss: 0.0033562863245606422
Test Loss:  0.0025834906846284866
Valid Loss:   14%|█▍        | 71/500 [01:01<08:32,  1.19s/it] 15%|█▍        | 73/500 [01:01<06:06,  1.16it/s] 15%|█▌        | 75/500 [01:01<04:23,  1.61it/s] 15%|█▌        | 77/500 [01:01<03:12,  2.20it/s] 16%|█▌        | 79/500 [01:01<02:25,  2.90it/s] 16%|█▌        | 81/500 [01:07<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:08<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:08<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:08<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:08<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:14<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:14<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:15<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:15<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:15<02:13,  3.01it/s] 20%|██        | 101/500 [01:21<07:55,  1.19s/it] 21%|██        | 103/500 [01:21<05:39,  1.17it/s] 21%|██        | 105/500 [01:21<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:22<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:22<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:28<07:32,  1.16s/it] 23%|██▎       | 113/500 [01:28<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:28<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:28<02:54,  2.20it/s] 24%|██▍       | 119/500 [01:29<02:11,  2.90it/s] 24%|██▍       | 121/500 [01:35<07:28,  1.18s/it] 25%|██▍       | 123/500 [01:35<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:35<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:35<02:51,  2.18it/s] 26%|██▌       | 129/500 [01:36<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:42<07:13,  1.18s/it] 27%|██▋       | 133/500 [01:42<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:42<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:42<02:42,  2.24it/s] 28%|██▊       | 139/500 [01:42<01:59,  3.01it/s]0.003637037705630064
Epoch:  72  	Training Loss: 0.003324441611766815
Test Loss:  0.002410594606772065
Valid Loss:  0.0034602817613631487
Epoch:  73  	Training Loss: 0.003185272915288806
Test Loss:  0.002296483376994729
Valid Loss:  0.003329592291265726
Epoch:  74  	Training Loss: 0.003064005170017481
Test Loss:  0.002205916913226247
Valid Loss:  0.003219484817236662
Epoch:  75  	Training Loss: 0.00295253936201334
Test Loss:  0.0021284555550664663
Valid Loss:  0.0031217799987643957
Epoch:  76  	Training Loss: 0.002849734853953123
Test Loss:  0.0020597202237695456
Valid Loss:  0.0030338577926158905
Epoch:  77  	Training Loss: 0.0027551983948796988
Test Loss:  0.001997557235881686
Valid Loss:  0.0029534734785556793
Epoch:  78  	Training Loss: 0.0026680519804358482
Test Loss:  0.001940868329256773
Valid Loss:  0.002879336941987276
Epoch:  79  	Training Loss: 0.0025878404267132282
Test Loss:  0.0018892571097239852
Valid Loss:  0.0028107715770602226
Epoch:  80  	Training Loss: 0.0025143460370600224
Test Loss:  0.0018425816670060158
Valid Loss:  0.002747566206380725
Epoch:  81  	Training Loss: 0.002446799073368311
Test Loss:  0.0018000672571361065
Valid Loss:  0.0026886374689638615
Epoch:  82  	Training Loss: 0.0023841853253543377
Test Loss:  0.0017622385639697313
Valid Loss:  0.0026252553798258305
Epoch:  83  	Training Loss: 0.002305959351360798
Test Loss:  0.0017154861707240343
Valid Loss:  0.0025608984287828207
Epoch:  84  	Training Loss: 0.0022372319363057613
Test Loss:  0.0016761419828981161
Valid Loss:  0.002504979493096471
Epoch:  85  	Training Loss: 0.002176720416173339
Test Loss:  0.001693796832114458
Valid Loss:  0.002504116389900446
Epoch:  86  	Training Loss: 0.0021560201421380043
Test Loss:  0.0016869425307959318
Valid Loss:  0.0024903477169573307
Epoch:  87  	Training Loss: 0.0021385187283158302
Test Loss:  0.0016749697970226407
Valid Loss:  0.0024738656356930733
Epoch:  88  	Training Loss: 0.0021216850727796555
Test Loss:  0.0016636052168905735
Valid Loss:  0.0024580620229244232
Epoch:  89  	Training Loss: 0.002105407416820526
Test Loss:  0.001652468927204609
Valid Loss:  0.00244275969453156
Epoch:  90  	Training Loss: 0.002089638961479068
Test Loss:  0.0016414881683886051
Valid Loss:  0.002427930012345314
Epoch:  91  	Training Loss: 0.002074326854199171
Test Loss:  0.0016308489721268415
Valid Loss:  0.002413578098639846
Epoch:  92  	Training Loss: 0.002059631049633026
Test Loss:  0.001610541483387351
Valid Loss:  0.002357910154387355
Epoch:  93  	Training Loss: 0.0020009465515613556
Test Loss:  0.0015690259169787169
Valid Loss:  0.0022770571522414684
Epoch:  94  	Training Loss: 0.0019157879287377
Test Loss:  0.001513156690634787
Valid Loss:  0.0021924376487731934
Epoch:  95  	Training Loss: 0.001823990372940898
Test Loss:  0.0014567906036973
Valid Loss:  0.002108941785991192
Epoch:  96  	Training Loss: 0.0017387940315529704
Test Loss:  0.0014089413452893496
Valid Loss:  0.0020396404433995485
Epoch:  97  	Training Loss: 0.0016737127443775535
Test Loss:  0.0013700256822630763
Valid Loss:  0.0019829971715807915
Epoch:  98  	Training Loss: 0.0016235022339969873
Test Loss:  0.0013382381293922663
Valid Loss:  0.0019426147919148207
Epoch:  99  	Training Loss: 0.0015854252269491553
Test Loss:  0.0013160099042579532
Valid Loss:  0.0019111738074570894
Epoch:  100  	Training Loss: 0.0015575294382870197
Test Loss:  0.0012966576032340527
Valid Loss:  0.001884586876258254
Epoch:  101  	Training Loss: 0.0015364359132945538
Test Loss:  0.0012813929934054613
Valid Loss:  0.0018630546983331442
Epoch:  102  	Training Loss: 0.0015195540618151426
Test Loss:  0.0010795394191518426
Valid Loss:  0.0016831380780786276
Epoch:  103  	Training Loss: 0.0014172312803566456
Test Loss:  0.0010288988705724478
Valid Loss:  0.0016331829829141498
Epoch:  104  	Training Loss: 0.0013890606351196766
Test Loss:  0.0010161041282117367
Valid Loss:  0.0016050257254391909
Epoch:  105  	Training Loss: 0.0013641503173857927
Test Loss:  0.0010127132991328835
Valid Loss:  0.0015978957526385784
Epoch:  106  	Training Loss: 0.0013582760002464056
Test Loss:  0.0010159318335354328
Valid Loss:  0.0015957884024828672
Epoch:  107  	Training Loss: 0.0013537447666749358
Test Loss:  0.0010174356866627932
Valid Loss:  0.0015933278482407331
Epoch:  108  	Training Loss: 0.0013500816421583295
Test Loss:  0.0010188885498791933
Valid Loss:  0.0015913755632936954
Epoch:  109  	Training Loss: 0.0013470265548676252
Test Loss:  0.0010199288371950388
Valid Loss:  0.0015895916149020195
Epoch:  110  	Training Loss: 0.0013443995267152786
Test Loss:  0.0010206622537225485
Valid Loss:  0.0015879549318924546
Epoch:  111  	Training Loss: 0.0013421096373349428
Test Loss:  0.0010211319895461202
Valid Loss:  0.0015864132437855005
Epoch:  112  	Training Loss: 0.0013400515308603644
Test Loss:  0.0010147701250389218
Valid Loss:  0.0015683346427977085
Epoch:  113  	Training Loss: 0.0013148372527211905
Test Loss:  0.0010077730985358357
Valid Loss:  0.0015400921693071723
Epoch:  114  	Training Loss: 0.0012678271159529686
Test Loss:  0.0009945299243554473
Valid Loss:  0.0015014485688880086
Epoch:  115  	Training Loss: 0.001207226188853383
Test Loss:  0.000982571393251419
Valid Loss:  0.0014423299580812454
Epoch:  116  	Training Loss: 0.001142167137004435
Test Loss:  0.0009659329080022871
Valid Loss:  0.001387879136018455
Epoch:  117  	Training Loss: 0.0010930183343589306
Test Loss:  0.000939018907956779
Valid Loss:  0.0013418149901553988
Epoch:  118  	Training Loss: 0.001043838681653142
Test Loss:  0.0009095496498048306
Valid Loss:  0.0012917757267132401
Epoch:  119  	Training Loss: 0.0010028642136603594
Test Loss:  0.0008934926590882242
Valid Loss:  0.0012659033527597785
Epoch:  120  	Training Loss: 0.0009836836252361536
Test Loss:  0.0008833883330225945
Valid Loss:  0.001253342954441905
Epoch:  121  	Training Loss: 0.0009742547990754247
Test Loss:  0.0008768596453592181
Valid Loss:  0.00124749809037894
Epoch:  122  	Training Loss: 0.0009700193768367171
Test Loss:  0.0008702474879100919
Valid Loss:  0.0012408423935994506
Epoch:  123  	Training Loss: 0.0009651214350014925
Test Loss:  0.0008640248561277986
Valid Loss:  0.001234770636074245
Epoch:  124  	Training Loss: 0.0009605841478332877
Test Loss:  0.0008580650901421905
Valid Loss:  0.0012293581385165453
Epoch:  125  	Training Loss: 0.0009562913328409195
Test Loss:  0.0008523617871105671
Valid Loss:  0.0012242058292031288
Epoch:  126  	Training Loss: 0.0009522496839053929
Test Loss:  0.0008469946915283799
Valid Loss:  0.0012193541042506695
Epoch:  127  	Training Loss: 0.0009485494811087847
Test Loss:  0.0008418508805334568
Valid Loss:  0.0012146900407969952
Epoch:  128  	Training Loss: 0.0009450035868212581
Test Loss:  0.0008369191200472414
Valid Loss:  0.0012102080509066582
Epoch:  129  	Training Loss: 0.0009416253305971622
Test Loss:  0.0008320825290866196
Valid Loss:  0.00120608473662287
Epoch:  130  	Training Loss: 0.0009383397409692407
Test Loss:  0.0008274454739876091
Valid Loss:  0.0012021701550111175
Epoch:  131  	Training Loss: 0.0009351750486530364
Test Loss:  0.0008228900260291994
Valid Loss:  0.0011987786274403334
Epoch:  132  	Training Loss: 0.0009320799726992846
Test Loss:  0.0008226842037402093
Valid Loss:  0.0011975513771176338
Epoch:  133  	Training Loss: 0.0009308563312515616
Test Loss:  0.0008224939228966832
Valid Loss:  0.001196512719616294
Epoch:  134  	Training Loss: 0.0009297996875829995
Test Loss:  0.000822299683932215
Valid Loss:  0.0011955786030739546
Epoch:  135  	Training Loss: 0.0009288517758250237
Test Loss:  0.0008221323369070888
Valid Loss:  0.0011947621824219823
Epoch:  136  	Training Loss: 0.0009280267986468971
Test Loss:  0.0008219624287448823
Valid Loss:  0.0011940394761040807
Epoch:  137  	Training Loss: 0.0009273025789298117
Test Loss:  0.0008218048606067896
Valid Loss:  0.0011933866189792752
Epoch:  138  	Training Loss: 0.0009266595588997006
Test Loss:  0.0008216981077566743
Valid Loss:  0.0011928180465474725
Epoch:  139  	Training Loss: 0.0009261079831048846
Test Loss:  0.0008216022397391498
Valid Loss:  0.0011923101264983416
Epoch:  140  	Training Loss: 0.0009256215416826308
Test Loss:  0.0008215186535380781
 28%|██▊       | 141/500 [01:49<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:49<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:49<03:35,  1.64it/s] 29%|██▉       | 147/500 [01:49<02:37,  2.25it/s] 30%|██▉       | 149/500 [01:49<01:56,  3.02it/s] 30%|███       | 151/500 [01:56<07:07,  1.23s/it] 31%|███       | 153/500 [01:56<05:05,  1.14it/s] 31%|███       | 155/500 [01:56<03:39,  1.57it/s] 31%|███▏      | 157/500 [01:56<02:39,  2.16it/s] 32%|███▏      | 159/500 [01:56<01:57,  2.91it/s] 32%|███▏      | 161/500 [02:03<06:43,  1.19s/it] 33%|███▎      | 163/500 [02:03<04:47,  1.17it/s] 33%|███▎      | 165/500 [02:03<03:26,  1.62it/s] 33%|███▎      | 167/500 [02:03<02:30,  2.22it/s] 34%|███▍      | 169/500 [02:03<01:50,  2.98it/s] 34%|███▍      | 171/500 [02:09<06:26,  1.17s/it] 35%|███▍      | 173/500 [02:09<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:10<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:10<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:10<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:16<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:16<04:29,  1.17it/s] 37%|███▋      | 185/500 [02:17<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:17<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:17<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:23<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:23<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:23<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:24<02:20,  2.15it/s] 40%|███▉      | 199/500 [02:24<01:45,  2.85it/s] 40%|████      | 201/500 [02:30<06:01,  1.21s/it] 41%|████      | 203/500 [02:30<04:17,  1.15it/s] 41%|████      | 205/500 [02:31<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:31<02:14,  2.18it/s]Valid Loss:  0.0011918653035536408
Epoch:  141  	Training Loss: 0.0009252001764252782
Test Loss:  0.0008214134722948074
Valid Loss:  0.0011914550559595227
Epoch:  142  	Training Loss: 0.0009248030255548656
Test Loss:  0.0007047136314213276
Valid Loss:  0.0010833870619535446
Epoch:  143  	Training Loss: 0.0008822766249068081
Test Loss:  0.000690508633852005
Valid Loss:  0.0010701932478696108
Epoch:  144  	Training Loss: 0.0008772563887760043
Test Loss:  0.0006860285066068172
Valid Loss:  0.0010659059043973684
Epoch:  145  	Training Loss: 0.0008731802809052169
Test Loss:  0.0006830021739006042
Valid Loss:  0.0010629703756421804
Epoch:  146  	Training Loss: 0.0008693323470652103
Test Loss:  0.000680493307299912
Valid Loss:  0.0010604149429127574
Epoch:  147  	Training Loss: 0.0008658126462250948
Test Loss:  0.0006783175049349666
Valid Loss:  0.001058070920407772
Epoch:  148  	Training Loss: 0.0008625122136436403
Test Loss:  0.0006761671393178403
Valid Loss:  0.001055766362696886
Epoch:  149  	Training Loss: 0.0008593398379161954
Test Loss:  0.0006742066470906138
Valid Loss:  0.0010536018526181579
Epoch:  150  	Training Loss: 0.000856408616527915
Test Loss:  0.00067237886833027
Valid Loss:  0.0010514769237488508
Epoch:  151  	Training Loss: 0.0008536390960216522
Test Loss:  0.0006708338623866439
Valid Loss:  0.0010495863389223814
Epoch:  152  	Training Loss: 0.0008510175975970924
Test Loss:  0.0006751248729415238
Valid Loss:  0.001051649684086442
Epoch:  153  	Training Loss: 0.0008476348011754453
Test Loss:  0.0006785370642319322
Valid Loss:  0.0010531112784519792
Epoch:  154  	Training Loss: 0.0008449172601103783
Test Loss:  0.0006811842322349548
Valid Loss:  0.001054030261002481
Epoch:  155  	Training Loss: 0.0008426337735727429
Test Loss:  0.0006831912905909121
Valid Loss:  0.001054486958310008
Epoch:  156  	Training Loss: 0.0008406485430896282
Test Loss:  0.000684679311234504
Valid Loss:  0.0010545696131885052
Epoch:  157  	Training Loss: 0.000838874897453934
Test Loss:  0.0006857494590803981
Valid Loss:  0.0010543549433350563
Epoch:  158  	Training Loss: 0.0008372613228857517
Test Loss:  0.0006865006871521473
Valid Loss:  0.0010539153590798378
Epoch:  159  	Training Loss: 0.0008357748156413436
Test Loss:  0.000686998013406992
Valid Loss:  0.0010533048771321774
Epoch:  160  	Training Loss: 0.0008343931986019015
Test Loss:  0.0006873052916489542
Valid Loss:  0.0010525729740038514
Epoch:  161  	Training Loss: 0.000833100697491318
Test Loss:  0.0006874685641378164
Valid Loss:  0.001051754574291408
Epoch:  162  	Training Loss: 0.0008318861946463585
Test Loss:  0.0007018278120085597
Valid Loss:  0.0010599445085972548
Epoch:  163  	Training Loss: 0.0008273290586657822
Test Loss:  0.0006994810537435114
Valid Loss:  0.001055820262990892
Epoch:  164  	Training Loss: 0.0008245595963671803
Test Loss:  0.0006973276613280177
Valid Loss:  0.0010520878713577986
Epoch:  165  	Training Loss: 0.0008222055621445179
Test Loss:  0.0006955129210837185
Valid Loss:  0.0010488267289474607
Epoch:  166  	Training Loss: 0.00082023796858266
Test Loss:  0.0006939282175153494
Valid Loss:  0.0010459291515871882
Epoch:  167  	Training Loss: 0.0008185590850189328
Test Loss:  0.0006925523048266768
Valid Loss:  0.001043358352035284
Epoch:  168  	Training Loss: 0.0008171199006028473
Test Loss:  0.0006913534598425031
Valid Loss:  0.00104106857907027
Epoch:  169  	Training Loss: 0.0008158838027156889
Test Loss:  0.0006903301691636443
Valid Loss:  0.001039027003571391
Epoch:  170  	Training Loss: 0.0008148293127305806
Test Loss:  0.0006895045517012477
Valid Loss:  0.0010372251272201538
Epoch:  171  	Training Loss: 0.0008139347191900015
Test Loss:  0.000688767759129405
Valid Loss:  0.0010355969425290823
Epoch:  172  	Training Loss: 0.0008131585782393813
Test Loss:  0.0006549071986228228
Valid Loss:  0.0009857079712674022
Epoch:  173  	Training Loss: 0.0007632703636772931
Test Loss:  0.0006291111931204796
Valid Loss:  0.0009625302045606077
Epoch:  174  	Training Loss: 0.0007386336801573634
Test Loss:  0.0006090658134780824
Valid Loss:  0.0009509054361842573
Epoch:  175  	Training Loss: 0.0007272626971825957
Test Loss:  0.0005951294442638755
Valid Loss:  0.0009439572459086776
Epoch:  176  	Training Loss: 0.0007209701579995453
Test Loss:  0.0005858399090357125
Valid Loss:  0.0009394819498993456
Epoch:  177  	Training Loss: 0.0007171677425503731
Test Loss:  0.0005789451533928514
Valid Loss:  0.0009354412904940546
Epoch:  178  	Training Loss: 0.0007142372778616846
Test Loss:  0.0005735363811254501
Valid Loss:  0.0009323321282863617
Epoch:  179  	Training Loss: 0.0007121517555788159
Test Loss:  0.0005693875136785209
Valid Loss:  0.0009302465477958322
Epoch:  180  	Training Loss: 0.0007105303811840713
Test Loss:  0.0005663966294378042
Valid Loss:  0.0009286118438467383
Epoch:  181  	Training Loss: 0.0007093715248629451
Test Loss:  0.000564074027352035
Valid Loss:  0.0009271883172914386
Epoch:  182  	Training Loss: 0.0007084686076268554
Test Loss:  0.0005001342506147921
Valid Loss:  0.0008454570197500288
Epoch:  183  	Training Loss: 0.0006825578166171908
Test Loss:  0.000492520397529006
Valid Loss:  0.0008426597923971713
Epoch:  184  	Training Loss: 0.0006660654908046126
Test Loss:  0.0004725648614112288
Valid Loss:  0.0008191124652512372
Epoch:  185  	Training Loss: 0.0006504837656393647
Test Loss:  0.00045869179302826524
Valid Loss:  0.0008039054227992892
Epoch:  186  	Training Loss: 0.0006352001219056547
Test Loss:  0.0004443606885615736
Valid Loss:  0.0007866831147111952
Epoch:  187  	Training Loss: 0.0006211581057868898
Test Loss:  0.00043254284537397325
Valid Loss:  0.0007721615256741643
Epoch:  188  	Training Loss: 0.0006083592888899148
Test Loss:  0.000421792792622
Valid Loss:  0.0007588614826090634
Epoch:  189  	Training Loss: 0.0005957281682640314
Test Loss:  0.0004115925985388458
Valid Loss:  0.0007460347842425108
Epoch:  190  	Training Loss: 0.0005837189964950085
Test Loss:  0.00040269814780913293
Valid Loss:  0.000733798835426569
Epoch:  191  	Training Loss: 0.0005724354996345937
Test Loss:  0.00039452954661101103
Valid Loss:  0.0007225151057355106
Epoch:  192  	Training Loss: 0.0005617100978270173
Test Loss:  0.00039618322625756264
Valid Loss:  0.0007236386300064623
Epoch:  193  	Training Loss: 0.0005597241688519716
Test Loss:  0.0003977821033913642
Valid Loss:  0.0007247484754770994
Epoch:  194  	Training Loss: 0.0005580830620601773
Test Loss:  0.00039927923353388906
Valid Loss:  0.0007258158293552697
Epoch:  195  	Training Loss: 0.0005567144835367799
Test Loss:  0.00040064449422061443
Valid Loss:  0.0007267988985404372
Epoch:  196  	Training Loss: 0.0005555609823204577
Test Loss:  0.0004018797480966896
Valid Loss:  0.000727702456060797
Epoch:  197  	Training Loss: 0.0005545738385990262
Test Loss:  0.000402982986997813
Valid Loss:  0.0007285224855877459
Epoch:  198  	Training Loss: 0.0005537159740924835
Test Loss:  0.0004039570048917085
Valid Loss:  0.0007292577065527439
Epoch:  199  	Training Loss: 0.0005529624759219587
Test Loss:  0.00040480768075212836
Valid Loss:  0.0007298511918634176
Epoch:  200  	Training Loss: 0.0005522930296137929
Test Loss:  0.0004055604222230613
Valid Loss:  0.000730345374904573
Epoch:  201  	Training Loss: 0.0005517000099644065
Test Loss:  0.0004062027728650719
Valid Loss:  0.000730763771571219
Epoch:  202  	Training Loss: 0.0005511585623025894
Test Loss:  0.00040535011794418097
Valid Loss:  0.0007310709916055202
Epoch:  203  	Training Loss: 0.0005497897509485483
Test Loss:  0.0004051474097650498
Valid Loss:  0.0007310075452551246
Epoch:  204  	Training Loss: 0.0005487417220138013
Test Loss:  0.00040470235398970544
Valid Loss:  0.0007308715721592307
Epoch:  205  	Training Loss: 0.0005477322265505791
Test Loss:  0.00040439856820739806
Valid Loss:  0.0007304393802769482
Epoch:  206  	Training Loss: 0.0005467409500852227
Test Loss:  0.0004040729836560786
Valid Loss:  0.0007299667922779918
Epoch:  207  	Training Loss: 0.0005458035739138722
Test Loss:  0.000403908226871863
Valid Loss:  0.0007296043913811445
Epoch:  208  	Training Loss: 0.0005449487362056971
Test Loss:  0.00040381745202466846
Valid Loss:  0.0007292545633390546
 42%|████▏     | 209/500 [02:31<01:39,  2.94it/s] 42%|████▏     | 211/500 [02:37<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:37<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:37<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:38<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:38<01:37,  2.89it/s] 44%|████▍     | 221/500 [02:44<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:44<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:44<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:44<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:45<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:51<05:20,  1.19s/it] 47%|████▋     | 233/500 [02:51<03:47,  1.17it/s] 47%|████▋     | 235/500 [02:51<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:51<01:58,  2.21it/s] 48%|████▊     | 239/500 [02:51<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:58<05:06,  1.19s/it] 49%|████▊     | 243/500 [02:58<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:58<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:58<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:58<01:24,  2.98it/s] 50%|█████     | 251/500 [03:05<04:50,  1.17s/it] 51%|█████     | 253/500 [03:05<03:26,  1.19it/s] 51%|█████     | 255/500 [03:05<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:05<01:47,  2.26it/s] 52%|█████▏    | 259/500 [03:05<01:19,  3.04it/s] 52%|█████▏    | 261/500 [03:11<04:36,  1.16s/it] 53%|█████▎    | 263/500 [03:11<03:17,  1.20it/s] 53%|█████▎    | 265/500 [03:12<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:12<01:42,  2.27it/s] 54%|█████▍    | 269/500 [03:12<01:15,  3.05it/s] 54%|█████▍    | 271/500 [03:18<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:18<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:18<02:19,  1.61it/s]Epoch:  209  	Training Loss: 0.0005441165412776172
Test Loss:  0.0004037106118630618
Valid Loss:  0.0007288616034202278
Epoch:  210  	Training Loss: 0.0005431757308542728
Test Loss:  0.00040353662916459143
Valid Loss:  0.000728502927813679
Epoch:  211  	Training Loss: 0.0005423215916380286
Test Loss:  0.00040332615026272833
Valid Loss:  0.0007281600264832377
Epoch:  212  	Training Loss: 0.0005415453342720866
Test Loss:  0.0003823713050223887
Valid Loss:  0.0006988883251324296
Epoch:  213  	Training Loss: 0.0005315719172358513
Test Loss:  0.0003787300956901163
Valid Loss:  0.0006905304617248476
Epoch:  214  	Training Loss: 0.0005277912714518607
Test Loss:  0.0003782684216275811
Valid Loss:  0.0006864810129627585
Epoch:  215  	Training Loss: 0.0005248551606200635
Test Loss:  0.0003785839071497321
Valid Loss:  0.0006837000255472958
Epoch:  216  	Training Loss: 0.0005223854095675051
Test Loss:  0.000379137578420341
Valid Loss:  0.0006814701482653618
Epoch:  217  	Training Loss: 0.0005202953470870852
Test Loss:  0.0003797844983637333
Valid Loss:  0.0006795923109166324
Epoch:  218  	Training Loss: 0.0005185269983485341
Test Loss:  0.0003804775478783995
Valid Loss:  0.0006779833929613233
Epoch:  219  	Training Loss: 0.0005170299555175006
Test Loss:  0.0003811917267739773
Valid Loss:  0.0006765959551557899
Epoch:  220  	Training Loss: 0.0005157616105861962
Test Loss:  0.00038191431667655706
Valid Loss:  0.0006753992638550699
Epoch:  221  	Training Loss: 0.0005146876210346818
Test Loss:  0.000382631435059011
Valid Loss:  0.0006743633421137929
Epoch:  222  	Training Loss: 0.0005137781845405698
Test Loss:  0.0003792208153754473
Valid Loss:  0.0006672715535387397
Epoch:  223  	Training Loss: 0.0005131288198754191
Test Loss:  0.00038298676372505724
Valid Loss:  0.0006716757779940963
Epoch:  224  	Training Loss: 0.0005123664741404355
Test Loss:  0.0003834139497485012
Valid Loss:  0.0006700807716697454
Epoch:  225  	Training Loss: 0.0005116462707519531
Test Loss:  0.00038483928074128926
Valid Loss:  0.0006701999809592962
Epoch:  226  	Training Loss: 0.0005110719357617199
Test Loss:  0.0003854312817566097
Valid Loss:  0.0006692790193483233
Epoch:  227  	Training Loss: 0.0005106131429784
Test Loss:  0.0003865100152324885
Valid Loss:  0.0006692672614008188
Epoch:  228  	Training Loss: 0.0005102466675452888
Test Loss:  0.0003871223598252982
Valid Loss:  0.0006687265704385936
Epoch:  229  	Training Loss: 0.0005099539994262159
Test Loss:  0.00038795958971604705
Valid Loss:  0.0006686702836304903
Epoch:  230  	Training Loss: 0.0005097197135910392
Test Loss:  0.00038852664874866605
Valid Loss:  0.0006683460087515414
Epoch:  231  	Training Loss: 0.0005095320520922542
Test Loss:  0.00038918829523026943
Valid Loss:  0.0006682824459858239
Epoch:  232  	Training Loss: 0.000509381468873471
Test Loss:  0.00039041583659127355
Valid Loss:  0.0006692872848361731
Epoch:  233  	Training Loss: 0.0005092673818580806
Test Loss:  0.00039129084325395525
Valid Loss:  0.0006700088270008564
Epoch:  234  	Training Loss: 0.0005092036444693804
Test Loss:  0.0003919109876733273
Valid Loss:  0.0006705214618705213
Epoch:  235  	Training Loss: 0.0005091658676974475
Test Loss:  0.0003923475742340088
Valid Loss:  0.0006708856672048569
Epoch:  236  	Training Loss: 0.0005091414786875248
Test Loss:  0.00039265415398404
Valid Loss:  0.0006711406749673188
Epoch:  237  	Training Loss: 0.0005091243656352162
Test Loss:  0.0003928685327991843
Valid Loss:  0.0006713196635246277
Epoch:  238  	Training Loss: 0.0005091115599498153
Test Loss:  0.00039301777724176645
Valid Loss:  0.0006714448099955916
Epoch:  239  	Training Loss: 0.0005091010825708508
Test Loss:  0.0003931215906050056
Valid Loss:  0.0006715327617712319
Epoch:  240  	Training Loss: 0.0005090878112241626
Test Loss:  0.0003931947285309434
Valid Loss:  0.0006715939380228519
Epoch:  241  	Training Loss: 0.0005090769845992327
Test Loss:  0.00039324467070400715
Valid Loss:  0.0006716379430145025
Epoch:  242  	Training Loss: 0.000509067380335182
Test Loss:  0.0003910078958142549
Valid Loss:  0.0006687456625513732
Epoch:  243  	Training Loss: 0.0005069896578788757
Test Loss:  0.00038889009738340974
Valid Loss:  0.0006662728264927864
Epoch:  244  	Training Loss: 0.0005055492511019111
Test Loss:  0.00038727730861864984
Valid Loss:  0.0006641378276981413
Epoch:  245  	Training Loss: 0.0005043434211984277
Test Loss:  0.00038615279481746256
Valid Loss:  0.0006623174413107336
Epoch:  246  	Training Loss: 0.000503266928717494
Test Loss:  0.000385238352464512
Valid Loss:  0.0006607617833651602
Epoch:  247  	Training Loss: 0.0005022983532398939
Test Loss:  0.0003844871243927628
Valid Loss:  0.0006593971629627049
Epoch:  248  	Training Loss: 0.0005013477057218552
Test Loss:  0.0003838417469523847
Valid Loss:  0.0006581477355211973
Epoch:  249  	Training Loss: 0.0005004172562621534
Test Loss:  0.0003832596412394196
Valid Loss:  0.0006569479592144489
Epoch:  250  	Training Loss: 0.0004995508352294564
Test Loss:  0.00038273120298981667
Valid Loss:  0.000655790907330811
Epoch:  251  	Training Loss: 0.0004987423890270293
Test Loss:  0.0003823160077445209
Valid Loss:  0.0006546786171384156
Epoch:  252  	Training Loss: 0.0004979399382136762
Test Loss:  0.0003810172784142196
Valid Loss:  0.0006523503107018769
Epoch:  253  	Training Loss: 0.0004976870841346681
Test Loss:  0.00038036584737710655
Valid Loss:  0.0006509562954306602
Epoch:  254  	Training Loss: 0.0004975299816578627
Test Loss:  0.0003800504491664469
Valid Loss:  0.0006500590243376791
Epoch:  255  	Training Loss: 0.0004974076873622835
Test Loss:  0.00037991907447576523
Valid Loss:  0.0006494455737993121
Epoch:  256  	Training Loss: 0.0004973027971573174
Test Loss:  0.00037989995325915515
Valid Loss:  0.0006490132655017078
Epoch:  257  	Training Loss: 0.0004972098977304995
Test Loss:  0.0003799538826569915
Valid Loss:  0.0006487051141448319
Epoch:  258  	Training Loss: 0.0004971224698238075
Test Loss:  0.0003800520789809525
Valid Loss:  0.0006484760669991374
Epoch:  259  	Training Loss: 0.0004970402223989367
Test Loss:  0.00038017594488337636
Valid Loss:  0.0006482942262664437
Epoch:  260  	Training Loss: 0.000496961991302669
Test Loss:  0.00038031808799132705
Valid Loss:  0.0006481481250375509
Epoch:  261  	Training Loss: 0.0004968877183273435
Test Loss:  0.0003804691368713975
Valid Loss:  0.0006480221636593342
Epoch:  262  	Training Loss: 0.0004968158318661153
Test Loss:  0.0003807671891991049
Valid Loss:  0.000648259767331183
Epoch:  263  	Training Loss: 0.0004967746208421886
Test Loss:  0.00038105229032225907
Valid Loss:  0.0006484874757006764
Epoch:  264  	Training Loss: 0.0004967367276549339
Test Loss:  0.00038132478948682547
Valid Loss:  0.0006487044738605618
Epoch:  265  	Training Loss: 0.0004967030836269259
Test Loss:  0.0003815837553702295
Valid Loss:  0.0006489128572866321
Epoch:  266  	Training Loss: 0.0004966724663972855
Test Loss:  0.00038183125434443355
Valid Loss:  0.0006491115200333297
Epoch:  267  	Training Loss: 0.0004966456908732653
Test Loss:  0.0003820660640485585
Valid Loss:  0.0006493012770079076
Epoch:  268  	Training Loss: 0.0004966206615790725
Test Loss:  0.0003822905127890408
Valid Loss:  0.0006494823028333485
Epoch:  269  	Training Loss: 0.0004965984844602644
Test Loss:  0.00038250471698120236
Valid Loss:  0.0006496545393019915
Epoch:  270  	Training Loss: 0.0004965780535712838
Test Loss:  0.00038270733784884214
Valid Loss:  0.000649819674436003
Epoch:  271  	Training Loss: 0.0004965600091964006
Test Loss:  0.00038290105294436216
Valid Loss:  0.0006499753799289465
Epoch:  272  	Training Loss: 0.0004965441767126322
Test Loss:  0.00038195453817024827
Valid Loss:  0.0006484031910076737
Epoch:  273  	Training Loss: 0.0004964229883626103
Test Loss:  0.0003814456285908818
Valid Loss:  0.000647560169454664
Epoch:  274  	Training Loss: 0.0004963500541634858
Test Loss:  0.00038115589995868504
Valid Loss:  0.0006470883963629603
Epoch:  275  	Training Loss: 0.0004962915554642677
Test Loss:  0.0003809777554124594
Valid Loss:  0.0006468089995905757
Epoch:  276  	Training Loss: 0.0004962386447004974
Test Loss:  0.0003808598266914487
Valid Loss:  0.0006466370541602373
 55%|█████▌    | 277/500 [03:19<01:42,  2.17it/s] 56%|█████▌    | 279/500 [03:19<01:16,  2.88it/s] 56%|█████▌    | 281/500 [03:25<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:25<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:25<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:26<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:26<01:10,  2.97it/s] 58%|█████▊    | 291/500 [03:32<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:32<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:32<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:32<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:32<01:06,  3.02it/s] 60%|██████    | 301/500 [03:39<03:54,  1.18s/it] 61%|██████    | 303/500 [03:39<02:46,  1.18it/s] 61%|██████    | 305/500 [03:39<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:39<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:39<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:46<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:46<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:46<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:46<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:46<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:53<03:37,  1.21s/it] 65%|██████▍   | 323/500 [03:53<02:34,  1.15it/s] 65%|██████▌   | 325/500 [03:53<01:50,  1.59it/s] 65%|██████▌   | 327/500 [03:53<01:19,  2.17it/s] 66%|██████▌   | 329/500 [03:53<00:58,  2.93it/s] 66%|██████▌   | 331/500 [04:00<03:22,  1.20s/it] 67%|██████▋   | 333/500 [04:00<02:23,  1.16it/s] 67%|██████▋   | 335/500 [04:00<01:42,  1.61it/s] 67%|██████▋   | 337/500 [04:00<01:14,  2.20it/s] 68%|██████▊   | 339/500 [04:00<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:07<03:08,  1.19s/it] 69%|██████▊   | 343/500 [04:07<02:13,  1.17it/s]Epoch:  277  	Training Loss: 0.0004961914964951575
Test Loss:  0.0003807725152000785
Valid Loss:  0.0006465191254392266
Epoch:  278  	Training Loss: 0.0004961462691426277
Test Loss:  0.0003807029570452869
Valid Loss:  0.0006464316393248737
Epoch:  279  	Training Loss: 0.0004961017984896898
Test Loss:  0.000380643003154546
Valid Loss:  0.0006463583558797836
Epoch:  280  	Training Loss: 0.0004960569203831255
Test Loss:  0.0003805897431448102
Valid Loss:  0.0006462991586886346
Epoch:  281  	Training Loss: 0.0004960126243531704
Test Loss:  0.00038054949254728854
Valid Loss:  0.0006462434539571404
Epoch:  282  	Training Loss: 0.0004959680372849107
Test Loss:  0.000380451325327158
Valid Loss:  0.0006460678996518254
Epoch:  283  	Training Loss: 0.0004959554644301534
Test Loss:  0.0003805088344961405
Valid Loss:  0.0006461632438004017
Epoch:  284  	Training Loss: 0.0004959433572366834
Test Loss:  0.000380444573238492
Valid Loss:  0.0006460474105551839
Epoch:  285  	Training Loss: 0.0004959317739121616
Test Loss:  0.0003804757143370807
Valid Loss:  0.0006460973527282476
Epoch:  286  	Training Loss: 0.0004959209472872317
Test Loss:  0.0003804341540671885
Valid Loss:  0.0006460205186158419
Epoch:  287  	Training Loss: 0.0004959105281159282
Test Loss:  0.00038044899702072144
Valid Loss:  0.0006460449076257646
Epoch:  288  	Training Loss: 0.0004959000507369637
Test Loss:  0.00038042018422856927
Valid Loss:  0.0006459884461946785
Epoch:  289  	Training Loss: 0.000495889806188643
Test Loss:  0.00038042693631723523
Valid Loss:  0.0006459967116825283
Epoch:  290  	Training Loss: 0.0004958799108862877
Test Loss:  0.00038040627259761095
Valid Loss:  0.0006459561409428716
Epoch:  291  	Training Loss: 0.0004958704230375588
Test Loss:  0.00038040749495849013
Valid Loss:  0.0006459544529207051
Epoch:  292  	Training Loss: 0.0004958615754731
Test Loss:  0.00038094393676146865
Valid Loss:  0.0006465742480941117
Epoch:  293  	Training Loss: 0.0004949597641825676
Test Loss:  0.0003811653587035835
Valid Loss:  0.0006465759943239391
Epoch:  294  	Training Loss: 0.0004941961960867047
Test Loss:  0.00038117257645353675
Valid Loss:  0.000646212138235569
Epoch:  295  	Training Loss: 0.0004935349570587277
Test Loss:  0.0003809698682744056
Valid Loss:  0.0006455686525441706
Epoch:  296  	Training Loss: 0.0004929743008688092
Test Loss:  0.0003806946624536067
Valid Loss:  0.000644828483927995
Epoch:  297  	Training Loss: 0.0004924552049487829
Test Loss:  0.0003804057778324932
Valid Loss:  0.0006440624711103737
Epoch:  298  	Training Loss: 0.000491939892526716
Test Loss:  0.00038010976277291775
Valid Loss:  0.000643282022792846
Epoch:  299  	Training Loss: 0.0004914363380521536
Test Loss:  0.00037979273474775255
Valid Loss:  0.0006424773600883782
Epoch:  300  	Training Loss: 0.0004909629933536053
Test Loss:  0.00037949351826682687
Valid Loss:  0.000641692487988621
Epoch:  301  	Training Loss: 0.0004904937231913209
Test Loss:  0.00037920736940577626
Valid Loss:  0.0006409187335520983
Epoch:  302  	Training Loss: 0.0004900263738818467
Test Loss:  0.00036609784001484513
Valid Loss:  0.0006356899393722415
Epoch:  303  	Training Loss: 0.0004757900023832917
Test Loss:  0.00035849373671226203
Valid Loss:  0.0006296189967542887
Epoch:  304  	Training Loss: 0.0004708893538918346
Test Loss:  0.0003534582210704684
Valid Loss:  0.0006243133684620261
Epoch:  305  	Training Loss: 0.0004676762910094112
Test Loss:  0.00034998165210708976
Valid Loss:  0.0006197095499373972
Epoch:  306  	Training Loss: 0.000464961543912068
Test Loss:  0.00034727778984233737
Valid Loss:  0.0006157135358080268
Epoch:  307  	Training Loss: 0.0004624085850082338
Test Loss:  0.0003451395605225116
Valid Loss:  0.0006120817270129919
Epoch:  308  	Training Loss: 0.0004599446547217667
Test Loss:  0.00034329871414229274
Valid Loss:  0.0006086677312850952
Epoch:  309  	Training Loss: 0.00045755060273222625
Test Loss:  0.0003416263498365879
Valid Loss:  0.0006053962279111147
Epoch:  310  	Training Loss: 0.00045522372238337994
Test Loss:  0.00034006155328825116
Valid Loss:  0.0006022308371029794
Epoch:  311  	Training Loss: 0.00045295836753211915
Test Loss:  0.0003385744639672339
Valid Loss:  0.0005991514190100133
Epoch:  312  	Training Loss: 0.00045075389789417386
Test Loss:  0.00033835292560979724
Valid Loss:  0.0005984826711937785
Epoch:  313  	Training Loss: 0.0004497287154663354
Test Loss:  0.00033816875657066703
Valid Loss:  0.0005979265552014112
Epoch:  314  	Training Loss: 0.0004488981212489307
Test Loss:  0.0003380216658115387
Valid Loss:  0.0005974811501801014
Epoch:  315  	Training Loss: 0.0004482489894144237
Test Loss:  0.00033789791632443666
Valid Loss:  0.0005971069913357496
Epoch:  316  	Training Loss: 0.00044770928798243403
Test Loss:  0.00033779448131099343
Valid Loss:  0.0005967923789285123
Epoch:  317  	Training Loss: 0.00044728131615556777
Test Loss:  0.00033771185553632677
Valid Loss:  0.0005965414457023144
Epoch:  318  	Training Loss: 0.00044694269308820367
Test Loss:  0.0003376418899279088
Valid Loss:  0.0005963259609416127
Epoch:  319  	Training Loss: 0.0004466626269277185
Test Loss:  0.00033763551618903875
Valid Loss:  0.0005961558781564236
Epoch:  320  	Training Loss: 0.00044645159505307674
Test Loss:  0.00033764063846319914
Valid Loss:  0.0005960095440968871
Epoch:  321  	Training Loss: 0.0004462823853828013
Test Loss:  0.00033764465479180217
Valid Loss:  0.0005958941765129566
Epoch:  322  	Training Loss: 0.0004461517673917115
Test Loss:  0.00033630308462306857
Valid Loss:  0.0005934093496762216
Epoch:  323  	Training Loss: 0.000445330748334527
Test Loss:  0.00033532650559209287
Valid Loss:  0.0005913747590966523
Epoch:  324  	Training Loss: 0.00044463068479672074
Test Loss:  0.00033462385181337595
Valid Loss:  0.000589683884754777
Epoch:  325  	Training Loss: 0.0004440157790668309
Test Loss:  0.0003341261763125658
Valid Loss:  0.0005882575642317533
Epoch:  326  	Training Loss: 0.00044346379581838846
Test Loss:  0.0003337837406434119
Valid Loss:  0.0005870392778888345
Epoch:  327  	Training Loss: 0.0004429593973327428
Test Loss:  0.00033356097992509604
Valid Loss:  0.0005859847879037261
Epoch:  328  	Training Loss: 0.000442493095761165
Test Loss:  0.00033342844108119607
Valid Loss:  0.0005850624875165522
Epoch:  329  	Training Loss: 0.0004420580808073282
Test Loss:  0.00033336630440317094
Valid Loss:  0.0005842439131811261
Epoch:  330  	Training Loss: 0.00044165068538859487
Test Loss:  0.0003333599306643009
Valid Loss:  0.0005835140473209321
Epoch:  331  	Training Loss: 0.00044126762077212334
Test Loss:  0.0003333944478072226
Valid Loss:  0.000582853564992547
Epoch:  332  	Training Loss: 0.0004409062094055116
Test Loss:  0.00033483566949144006
Valid Loss:  0.0005833025788888335
Epoch:  333  	Training Loss: 0.0004402852791827172
Test Loss:  0.00033578710281290114
Valid Loss:  0.0005833170143887401
Epoch:  334  	Training Loss: 0.0004397781740408391
Test Loss:  0.00033642363268882036
Valid Loss:  0.0005830660811625421
Epoch:  335  	Training Loss: 0.00043933416600339115
Test Loss:  0.00033686464303173125
Valid Loss:  0.000582663924433291
Epoch:  336  	Training Loss: 0.00043893326073884964
Test Loss:  0.0003371852508280426
Valid Loss:  0.0005821796366944909
Epoch:  337  	Training Loss: 0.0004385658248793334
Test Loss:  0.0003374317893758416
Valid Loss:  0.0005816558841615915
Epoch:  338  	Training Loss: 0.00043822682346217334
Test Loss:  0.0003376343520358205
Valid Loss:  0.0005811213050037622
Epoch:  339  	Training Loss: 0.0004379121237434447
Test Loss:  0.0003378117107786238
Valid Loss:  0.0005805878317914903
Epoch:  340  	Training Loss: 0.00043761817505583167
Test Loss:  0.0003379716945346445
Valid Loss:  0.000580065418034792
Epoch:  341  	Training Loss: 0.0004373442498035729
Test Loss:  0.00033811875618994236
Valid Loss:  0.0005795573233626783
Epoch:  342  	Training Loss: 0.00043709040619432926
Test Loss:  0.0003368757897987962
Valid Loss:  0.0005772265722043812
Epoch:  343  	Training Loss: 0.00043671196908690035
Test Loss:  0.0003362302086316049
Valid Loss:  0.000575742800720036
Epoch:  344  	Training Loss: 0.0004364590276964009
Test Loss:  0.0003359263646416366
Valid Loss:   69%|██████▉   | 345/500 [04:07<01:35,  1.62it/s] 69%|██████▉   | 347/500 [04:07<01:08,  2.22it/s] 70%|██████▉   | 349/500 [04:07<00:50,  2.98it/s] 70%|███████   | 351/500 [04:13<02:58,  1.20s/it] 71%|███████   | 353/500 [04:14<02:06,  1.16it/s] 71%|███████   | 355/500 [04:14<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:14<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:14<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:20<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:21<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:21<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:21<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:21<00:44,  2.97it/s] 74%|███████▍  | 371/500 [04:27<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:27<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:28<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:28<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:28<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:34<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:34<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:35<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:35<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:35<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:41<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:41<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:42<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:42<00:47,  2.19it/s] 80%|███████▉  | 399/500 [04:42<00:34,  2.95it/s] 80%|████████  | 401/500 [04:48<01:57,  1.18s/it] 81%|████████  | 403/500 [04:48<01:22,  1.17it/s] 81%|████████  | 405/500 [04:48<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:49<00:42,  2.16it/s] 82%|████████▏ | 409/500 [04:49<00:31,  2.87it/s] 82%|████████▏ | 411/500 [04:55<01:47,  1.21s/it]0.0005747638642787933
Epoch:  345  	Training Loss: 0.00043626042315736413
Test Loss:  0.0003358223184477538
Valid Loss:  0.00057409011060372
Epoch:  346  	Training Loss: 0.00043608900159597397
Test Loss:  0.00033583614276722074
Valid Loss:  0.0005736070452257991
Epoch:  347  	Training Loss: 0.0004359327140264213
Test Loss:  0.00033591975807212293
Valid Loss:  0.0005732410354539752
Epoch:  348  	Training Loss: 0.00043578710756264627
Test Loss:  0.00033604324562475085
Valid Loss:  0.0005729523254558444
Epoch:  349  	Training Loss: 0.00043565075611695647
Test Loss:  0.00033619030728004873
Valid Loss:  0.0005727143725380301
Epoch:  350  	Training Loss: 0.0004355221171863377
Test Loss:  0.00033635017462074757
Valid Loss:  0.0005725078517571092
Epoch:  351  	Training Loss: 0.0004354010452516377
Test Loss:  0.000336515688104555
Valid Loss:  0.0005723260692320764
Epoch:  352  	Training Loss: 0.00043528462992981076
Test Loss:  0.00032716250279918313
Valid Loss:  0.0005692469421774149
Epoch:  353  	Training Loss: 0.0004271561047062278
Test Loss:  0.0003243479586672038
Valid Loss:  0.000569561030715704
Epoch:  354  	Training Loss: 0.0004260384012013674
Test Loss:  0.00032277105492539704
Valid Loss:  0.0005699294852092862
Epoch:  355  	Training Loss: 0.00042564122122712433
Test Loss:  0.00032225673203356564
Valid Loss:  0.0005700810579583049
Epoch:  356  	Training Loss: 0.0004254471277818084
Test Loss:  0.0003220413636881858
Valid Loss:  0.0005701706395484507
Epoch:  357  	Training Loss: 0.0004253166844137013
Test Loss:  0.00032193190418183804
Valid Loss:  0.0005702183116227388
Epoch:  358  	Training Loss: 0.00042521057184785604
Test Loss:  0.0003218586789444089
Valid Loss:  0.0005702593480236828
Epoch:  359  	Training Loss: 0.00042513341759331524
Test Loss:  0.00032181100687012076
Valid Loss:  0.0005702898488380015
Epoch:  360  	Training Loss: 0.00042506365571171045
Test Loss:  0.0003217722987756133
Valid Loss:  0.0005703174974769354
Epoch:  361  	Training Loss: 0.00042500070412643254
Test Loss:  0.0003217371413484216
Valid Loss:  0.0005703439237549901
Epoch:  362  	Training Loss: 0.00042494351509958506
Test Loss:  0.0003190029237885028
Valid Loss:  0.0005655966233462095
Epoch:  363  	Training Loss: 0.00042288488475605845
Test Loss:  0.0003166545648127794
Valid Loss:  0.0005617645801976323
Epoch:  364  	Training Loss: 0.0004212006460875273
Test Loss:  0.0003149948315694928
Valid Loss:  0.0005589724751189351
Epoch:  365  	Training Loss: 0.0004201732808724046
Test Loss:  0.00031387415947392583
Valid Loss:  0.0005571137298829854
Epoch:  366  	Training Loss: 0.0004196378285996616
Test Loss:  0.0003131083503831178
Valid Loss:  0.0005558389239013195
Epoch:  367  	Training Loss: 0.00041936911293305457
Test Loss:  0.0003125562216155231
Valid Loss:  0.0005549247143790126
Epoch:  368  	Training Loss: 0.00041922880336642265
Test Loss:  0.00031213604961521924
Valid Loss:  0.0005542227299883962
Epoch:  369  	Training Loss: 0.0004191428888589144
Test Loss:  0.0003118003369309008
Valid Loss:  0.0005536607932299376
Epoch:  370  	Training Loss: 0.00041908398270606995
Test Loss:  0.0003115246072411537
Valid Loss:  0.000553195714019239
Epoch:  371  	Training Loss: 0.000419040210545063
Test Loss:  0.0003112905833404511
Valid Loss:  0.0005527999019250274
Epoch:  372  	Training Loss: 0.00041900380165316164
Test Loss:  0.000310336152324453
Valid Loss:  0.0005518710240721703
Epoch:  373  	Training Loss: 0.0004182328120805323
Test Loss:  0.00030949251959100366
Valid Loss:  0.0005510438932105899
Epoch:  374  	Training Loss: 0.00041762946057133377
Test Loss:  0.0003088722296524793
Valid Loss:  0.0005503289285115898
Epoch:  375  	Training Loss: 0.0004170995089225471
Test Loss:  0.00030828022863715887
Valid Loss:  0.0005496130906976759
Epoch:  376  	Training Loss: 0.0004166557628195733
Test Loss:  0.00030780123779550195
Valid Loss:  0.0005489011527970433
Epoch:  377  	Training Loss: 0.0004162895493209362
Test Loss:  0.00030736802727915347
Valid Loss:  0.0005482044070959091
Epoch:  378  	Training Loss: 0.0004160421958658844
Test Loss:  0.0003069679078180343
Valid Loss:  0.0005475570214912295
Epoch:  379  	Training Loss: 0.00041583096026442945
Test Loss:  0.00030662966310046613
Valid Loss:  0.0005469566094689071
Epoch:  380  	Training Loss: 0.00041564757702872157
Test Loss:  0.00030632910784333944
Valid Loss:  0.0005463999696075916
Epoch:  381  	Training Loss: 0.0004154859925620258
Test Loss:  0.00030605727806687355
Valid Loss:  0.0005458880914375186
Epoch:  382  	Training Loss: 0.00041532935574650764
Test Loss:  0.00030432530911639333
Valid Loss:  0.0005435263155959547
Epoch:  383  	Training Loss: 0.00041500505176372826
Test Loss:  0.0003038310387637466
Valid Loss:  0.0005432685138657689
Epoch:  384  	Training Loss: 0.0004147247818764299
Test Loss:  0.00030319555662572384
Valid Loss:  0.0005428328877314925
Epoch:  385  	Training Loss: 0.00041440053610131145
Test Loss:  0.0003025637415703386
Valid Loss:  0.0005423951079137623
Epoch:  386  	Training Loss: 0.0004140727687627077
Test Loss:  0.0003018923744093627
Valid Loss:  0.0005419519147835672
Epoch:  387  	Training Loss: 0.0004136997740715742
Test Loss:  0.000301218475215137
Valid Loss:  0.0005414925399236381
Epoch:  388  	Training Loss: 0.0004133354814257473
Test Loss:  0.00030055869137868285
Valid Loss:  0.0005410475423559546
Epoch:  389  	Training Loss: 0.00041298067662864923
Test Loss:  0.00029991124756634235
Valid Loss:  0.000540612090844661
Epoch:  390  	Training Loss: 0.0004126344865653664
Test Loss:  0.0002992778900079429
Valid Loss:  0.0005401862435974181
Epoch:  391  	Training Loss: 0.0004122963873669505
Test Loss:  0.00029865483520552516
Valid Loss:  0.0005397715140134096
Epoch:  392  	Training Loss: 0.00041196634992957115
Test Loss:  0.00029854074819013476
Valid Loss:  0.0005395739572122693
Epoch:  393  	Training Loss: 0.00041196172242052853
Test Loss:  0.0002985144383274019
Valid Loss:  0.0005395259940996766
Epoch:  394  	Training Loss: 0.00041195814264938235
Test Loss:  0.00029850754071958363
Valid Loss:  0.0005395121988840401
Epoch:  395  	Training Loss: 0.0004119541263207793
Test Loss:  0.0002985051251016557
Valid Loss:  0.0005395055050030351
Epoch:  396  	Training Loss: 0.00041195086669176817
Test Loss:  0.00029850422288291156
Valid Loss:  0.0005394993349909782
Epoch:  397  	Training Loss: 0.0004119470249861479
Test Loss:  0.00029850273858755827
Valid Loss:  0.0005394959007389843
Epoch:  398  	Training Loss: 0.0004119436489418149
Test Loss:  0.0002985014580190182
Valid Loss:  0.0005394915933720767
Epoch:  399  	Training Loss: 0.0004119398654438555
Test Loss:  0.000298500235658139
Valid Loss:  0.0005394878680817783
Epoch:  400  	Training Loss: 0.0004119363147765398
Test Loss:  0.00029849971178919077
Valid Loss:  0.0005394831532612443
Epoch:  401  	Training Loss: 0.0004119327350053936
Test Loss:  0.00029849863494746387
Valid Loss:  0.0005394791369326413
Epoch:  402  	Training Loss: 0.0004119291843380779
Test Loss:  0.0002930086338892579
Valid Loss:  0.0005392141756601632
Epoch:  403  	Training Loss: 0.00040833494858816266
Test Loss:  0.0002896639925893396
Valid Loss:  0.0005376964109018445
Epoch:  404  	Training Loss: 0.0004070982977282256
Test Loss:  0.00028699985705316067
Valid Loss:  0.0005356212495826185
Epoch:  405  	Training Loss: 0.00040623988024890423
Test Loss:  0.00028476526495069265
Valid Loss:  0.0005337453912943602
Epoch:  406  	Training Loss: 0.0004055416793562472
Test Loss:  0.00028285651933401823
Valid Loss:  0.0005321438075043261
Epoch:  407  	Training Loss: 0.00040496804285794497
Test Loss:  0.0002812088932842016
Valid Loss:  0.0005307403043843806
Epoch:  408  	Training Loss: 0.00040448870277032256
Test Loss:  0.00027978018624708056
Valid Loss:  0.0005295196315273643
Epoch:  409  	Training Loss: 0.0004040545900352299
Test Loss:  0.00027820421382784843
Valid Loss:  0.0005286538507789373
Epoch:  410  	Training Loss: 0.0004035730380564928
Test Loss:  0.00027662323554977775
Valid Loss:  0.000527844880707562
Epoch:  411  	Training Loss: 0.0004031015851069242
Test Loss:  0.00027535445406101644
Valid Loss:  0.000526825082488358
Epoch:  412  	Training Loss: 0.000402719306293875
Test Loss:   83%|████████▎ | 413/500 [04:55<01:15,  1.16it/s] 83%|████████▎ | 415/500 [04:55<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:56<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:56<00:27,  2.95it/s] 84%|████████▍ | 421/500 [05:02<01:33,  1.19s/it] 85%|████████▍ | 423/500 [05:02<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:02<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:02<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:03<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:09<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:09<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:09<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:09<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:09<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:16<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:16<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:16<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:16<00:23,  2.21it/s] 90%|████████▉ | 449/500 [05:16<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:23<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:23<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:23<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:23<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:23<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:30<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:30<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:30<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:30<00:15,  2.17it/s] 94%|█████████▍| 469/500 [05:30<00:10,  2.87it/s] 94%|█████████▍| 471/500 [05:37<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:37<00:23,  1.14it/s] 95%|█████████▌| 475/500 [05:37<00:15,  1.58it/s] 95%|█████████▌| 477/500 [05:37<00:10,  2.16it/s] 96%|█████████▌| 479/500 [05:37<00:07,  2.91it/s]0.00027454219525679946
Valid Loss:  0.0005259930039756
Epoch:  413  	Training Loss: 0.0004024314694106579
Test Loss:  0.0002738176262937486
Valid Loss:  0.000525293464306742
Epoch:  414  	Training Loss: 0.00040216976776719093
Test Loss:  0.00027316322666592896
Valid Loss:  0.000524698116350919
Epoch:  415  	Training Loss: 0.0004019279731437564
Test Loss:  0.0002725648519117385
Valid Loss:  0.0005241877515800297
Epoch:  416  	Training Loss: 0.0004017008759547025
Test Loss:  0.0002720125485211611
Valid Loss:  0.0005237445002421737
Epoch:  417  	Training Loss: 0.00040148411062546074
Test Loss:  0.00027149671223014593
Valid Loss:  0.0005233525298535824
Epoch:  418  	Training Loss: 0.00040127706597559154
Test Loss:  0.00027101251180283725
Valid Loss:  0.0005230049137026072
Epoch:  419  	Training Loss: 0.00040107755921781063
Test Loss:  0.0002705529914237559
Valid Loss:  0.0005226936773397028
Epoch:  420  	Training Loss: 0.00040088416426442564
Test Loss:  0.00027011637575924397
Valid Loss:  0.0005224106716923416
Epoch:  421  	Training Loss: 0.0004006967064924538
Test Loss:  0.00026969879399985075
Valid Loss:  0.0005221515893936157
Epoch:  422  	Training Loss: 0.0004005148366559297
Test Loss:  0.00026857745251618326
Valid Loss:  0.0005203009350225329
Epoch:  423  	Training Loss: 0.0004004827351309359
Test Loss:  0.0002691341796889901
Valid Loss:  0.0005212215473875403
Epoch:  424  	Training Loss: 0.000400462478864938
Test Loss:  0.00026872666785493493
Valid Loss:  0.0005205433117225766
Epoch:  425  	Training Loss: 0.00040044786874204874
Test Loss:  0.0002688850509002805
Valid Loss:  0.0005208014626987278
Epoch:  426  	Training Loss: 0.0004004338406957686
Test Loss:  0.0002687177911866456
Valid Loss:  0.0005205180495977402
Epoch:  427  	Training Loss: 0.000400421442463994
Test Loss:  0.00026874113245867193
Valid Loss:  0.0005205530906096101
Epoch:  428  	Training Loss: 0.0004004093643743545
Test Loss:  0.0002686548978090286
Valid Loss:  0.0005204057088121772
Epoch:  429  	Training Loss: 0.0004003976355306804
Test Loss:  0.0002686292282305658
Valid Loss:  0.0005203598993830383
Epoch:  430  	Training Loss: 0.00040038704173639417
Test Loss:  0.00026857011835090816
Valid Loss:  0.0005202562315389514
Epoch:  431  	Training Loss: 0.0004003762733191252
Test Loss:  0.00026853661984205246
Valid Loss:  0.0005201981985010207
Epoch:  432  	Training Loss: 0.00040036533027887344
Test Loss:  0.00027411174960434437
Valid Loss:  0.0005219815648160875
Epoch:  433  	Training Loss: 0.00039369671139866114
Test Loss:  0.0002770803403109312
Valid Loss:  0.0005221818573772907
Epoch:  434  	Training Loss: 0.0003906842030119151
Test Loss:  0.0002782717056106776
Valid Loss:  0.0005210925010032952
Epoch:  435  	Training Loss: 0.00038853634032420814
Test Loss:  0.00027866734308190644
Valid Loss:  0.0005194887053221464
Epoch:  436  	Training Loss: 0.0003867500927299261
Test Loss:  0.00027876737294718623
Valid Loss:  0.0005177814746275544
Epoch:  437  	Training Loss: 0.0003852121881209314
Test Loss:  0.0002787842822726816
Valid Loss:  0.0005161425215192139
Epoch:  438  	Training Loss: 0.0003838787379208952
Test Loss:  0.0002787995326798409
Valid Loss:  0.000514631625264883
Epoch:  439  	Training Loss: 0.00038271985249593854
Test Loss:  0.00027884001610800624
Valid Loss:  0.0005132618825882673
Epoch:  440  	Training Loss: 0.0003817122778855264
Test Loss:  0.00027891260106116533
Valid Loss:  0.0005120272981002927
Epoch:  441  	Training Loss: 0.000380836077965796
Test Loss:  0.0002790137950796634
Valid Loss:  0.0005109169869683683
Epoch:  442  	Training Loss: 0.0003800729173235595
Test Loss:  0.0002740302006714046
Valid Loss:  0.0005035786307416856
Epoch:  443  	Training Loss: 0.00037851440720260143
Test Loss:  0.0002742962387856096
Valid Loss:  0.0005033333436585963
Epoch:  444  	Training Loss: 0.0003775685327127576
Test Loss:  0.00027407408924773335
Valid Loss:  0.0005024949787184596
Epoch:  445  	Training Loss: 0.0003766902373172343
Test Loss:  0.000273882964393124
Valid Loss:  0.0005017154617235065
Epoch:  446  	Training Loss: 0.0003758656675927341
Test Loss:  0.0002736692549660802
Valid Loss:  0.000500876281876117
Epoch:  447  	Training Loss: 0.0003750885371118784
Test Loss:  0.0002734401496127248
Valid Loss:  0.000500076450407505
Epoch:  448  	Training Loss: 0.00037435267586261034
Test Loss:  0.000273193814791739
Valid Loss:  0.0004993084585294127
Epoch:  449  	Training Loss: 0.0003736535436473787
Test Loss:  0.00027293339371681213
Valid Loss:  0.0004985741106793284
Epoch:  450  	Training Loss: 0.00037298741517588496
Test Loss:  0.00027265885728411376
Valid Loss:  0.0004978642100468278
Epoch:  451  	Training Loss: 0.00037235068157315254
Test Loss:  0.00027236982714384794
Valid Loss:  0.0004971792222931981
Epoch:  452  	Training Loss: 0.0003717403160408139
Test Loss:  0.0002721753262449056
Valid Loss:  0.0004968037828803062
Epoch:  453  	Training Loss: 0.0003716351930052042
Test Loss:  0.0002720220072660595
Valid Loss:  0.0004964928375557065
Epoch:  454  	Training Loss: 0.00037153728771954775
Test Loss:  0.00027189700631424785
Valid Loss:  0.0004962292732670903
Epoch:  455  	Training Loss: 0.00037144552334211767
Test Loss:  0.00027179389144293964
Valid Loss:  0.0004959997022524476
Epoch:  456  	Training Loss: 0.00037135917227715254
Test Loss:  0.000271706550847739
Valid Loss:  0.000495797605253756
Epoch:  457  	Training Loss: 0.00037127657560631633
Test Loss:  0.00027162942569702864
Valid Loss:  0.0004956151242367923
Epoch:  458  	Training Loss: 0.00037119799526408315
Test Loss:  0.00027156027499586344
Valid Loss:  0.0004954506875947118
Epoch:  459  	Training Loss: 0.0003711242461577058
Test Loss:  0.0002714984002523124
Valid Loss:  0.0004952988820150495
Epoch:  460  	Training Loss: 0.00037105404771864414
Test Loss:  0.0002714410948101431
Valid Loss:  0.0004951606970280409
Epoch:  461  	Training Loss: 0.00037098873872309923
Test Loss:  0.00027138780569657683
Valid Loss:  0.0004950317088514566
Epoch:  462  	Training Loss: 0.00037092750426381826
Test Loss:  0.00027116923592984676
Valid Loss:  0.000494591542519629
Epoch:  463  	Training Loss: 0.0003703632391989231
Test Loss:  0.00027077231789007783
Valid Loss:  0.0004938471829518676
Epoch:  464  	Training Loss: 0.0003698655345942825
Test Loss:  0.00027030165074393153
Valid Loss:  0.0004930015420541167
Epoch:  465  	Training Loss: 0.0003693923936225474
Test Loss:  0.000269804906565696
Valid Loss:  0.0004921236541122198
Epoch:  466  	Training Loss: 0.0003689438453875482
Test Loss:  0.0002693086280487478
Valid Loss:  0.0004912536242045462
Epoch:  467  	Training Loss: 0.0003685189294628799
Test Loss:  0.00026882157544605434
Valid Loss:  0.000490401522256434
Epoch:  468  	Training Loss: 0.0003681169473566115
Test Loss:  0.0002683483762666583
Valid Loss:  0.0004895751480944455
Epoch:  469  	Training Loss: 0.0003677356871776283
Test Loss:  0.0002678904857020825
Valid Loss:  0.0004887779359705746
Epoch:  470  	Training Loss: 0.0003673736937344074
Test Loss:  0.00026744656497612596
Valid Loss:  0.0004880050546489656
Epoch:  471  	Training Loss: 0.0003670355654321611
Test Loss:  0.0002670186513569206
Valid Loss:  0.00048731931019574404
Epoch:  472  	Training Loss: 0.00036674606963060796
Test Loss:  0.00026372107095085084
Valid Loss:  0.0004836298176087439
Epoch:  473  	Training Loss: 0.0003635603643488139
Test Loss:  0.00025993396411649883
Valid Loss:  0.0004787876387126744
Epoch:  474  	Training Loss: 0.00036075024399906397
Test Loss:  0.00025798488059081137
Valid Loss:  0.0004763738834299147
Epoch:  475  	Training Loss: 0.0003582172794267535
Test Loss:  0.00025430842651985586
Valid Loss:  0.0004713851376436651
Epoch:  476  	Training Loss: 0.0003560013137757778
Test Loss:  0.0002539657580200583
Valid Loss:  0.0004709404311142862
Epoch:  477  	Training Loss: 0.00035408843541517854
Test Loss:  0.000250006967689842
Valid Loss:  0.0004653781361412257
Epoch:  478  	Training Loss: 0.00035243522142991424
Test Loss:  0.0002524545998312533
Valid Loss:  0.00046814882080070674
Epoch:  479  	Training Loss: 0.0003509734815452248
Test Loss:  0.00024666142417117953
Valid Loss:  0.00045992026571184397
 96%|█████████▌| 481/500 [05:43<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:44<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:44<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:44<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:44<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:56<00:18,  2.10s/it] 99%|█████████▊| 493/500 [05:57<00:10,  1.49s/it] 99%|█████████▉| 495/500 [05:57<00:05,  1.07s/it] 99%|█████████▉| 497/500 [05:57<00:02,  1.30it/s]100%|█████████▉| 499/500 [05:57<00:00,  1.80it/s]100%|██████████| 500/500 [05:57<00:00,  1.40it/s]
Epoch:  480  	Training Loss: 0.0003497396828606725
Test Loss:  0.0002531599020585418
Valid Loss:  0.0004676529497373849
Epoch:  481  	Training Loss: 0.00034883824991993606
Test Loss:  0.00024336445494554937
Valid Loss:  0.0004540471127256751
Epoch:  482  	Training Loss: 0.00034836679697036743
Test Loss:  0.000252379453741014
Valid Loss:  0.0004679663688875735
Epoch:  483  	Training Loss: 0.0003443946479819715
Test Loss:  0.000230410136282444
Valid Loss:  0.00043998996261507273
Epoch:  484  	Training Loss: 0.00034047983353957534
Test Loss:  0.0002471837215125561
Valid Loss:  0.0004622535780072212
Epoch:  485  	Training Loss: 0.00033801241079345345
Test Loss:  0.00022423015616368502
Valid Loss:  0.0004303088935557753
Epoch:  486  	Training Loss: 0.0003367881290614605
Test Loss:  0.00025187546270899475
Valid Loss:  0.00046523986384272575
Epoch:  487  	Training Loss: 0.0003384811570867896
Test Loss:  0.00022934103617444634
Valid Loss:  0.0004297891864553094
Epoch:  488  	Training Loss: 0.00034475914435461164
Test Loss:  0.00028063738136552274
Valid Loss:  0.0004899845225736499
Epoch:  489  	Training Loss: 0.00035971117904409766
Test Loss:  0.00026745651848614216
Valid Loss:  0.00045837892685085535
Epoch:  490  	Training Loss: 0.0003914347616955638
Test Loss:  0.0003661162918433547
Valid Loss:  0.0005713387508876622
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0004383375053294003
Test Loss:  0.0003114346181973815
Valid Loss:  0.0005226397188380361
Epoch:  492  	Training Loss: 0.0003994047292508185
Test Loss:  0.0002657152945175767
Valid Loss:  0.0004783757613040507
Epoch:  493  	Training Loss: 0.00034759542904794216
Test Loss:  0.0002523024450056255
Valid Loss:  0.0004660358536057174
Epoch:  494  	Training Loss: 0.00033544859616085887
Test Loss:  0.00024767202557995915
Valid Loss:  0.00046154807205311954
Epoch:  495  	Training Loss: 0.000332405703375116
Test Loss:  0.00024572727852500975
Valid Loss:  0.00045965734170749784
Epoch:  496  	Training Loss: 0.0003313938213977963
Test Loss:  0.000244688504608348
Valid Loss:  0.00045870913891121745
Epoch:  497  	Training Loss: 0.0003310088941361755
Test Loss:  0.00024406355805695057
Valid Loss:  0.00045821789535693824
Epoch:  498  	Training Loss: 0.00033081701258197427
Test Loss:  0.0002436180948279798
Valid Loss:  0.00045786620466969907
Epoch:  499  	Training Loss: 0.0003306905855424702
Test Loss:  0.00024330410815309733
Valid Loss:  0.00045766186667606235
Epoch:  500  	Training Loss: 0.0003306003345642239
Test Loss:  0.00024306244449689984
Valid Loss:  0.000457530579296872
seed is  5
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 15.07it/s]  1%|          | 4/500 [00:00<00:32, 15.10it/s]  1%|          | 6/500 [00:00<00:31, 15.77it/s]  2%|▏         | 8/500 [00:00<00:30, 16.01it/s]  2%|▏         | 10/500 [00:00<00:30, 15.98it/s]  2%|▏         | 12/500 [00:00<00:30, 16.20it/s]  3%|▎         | 14/500 [00:00<00:29, 16.31it/s]  3%|▎         | 16/500 [00:00<00:29, 16.37it/s]  4%|▎         | 18/500 [00:01<00:29, 16.41it/s]  4%|▍         | 20/500 [00:01<00:29, 16.10it/s]  4%|▍         | 22/500 [00:01<00:29, 16.14it/s]  5%|▍         | 24/500 [00:01<00:29, 16.20it/s]  5%|▌         | 26/500 [00:01<00:29, 16.24it/s]  6%|▌         | 28/500 [00:01<00:28, 16.28it/s]  6%|▌         | 30/500 [00:01<00:28, 16.32it/s]  6%|▋         | 32/500 [00:01<00:29, 15.83it/s]  7%|▋         | 34/500 [00:02<00:29, 15.91it/s]  7%|▋         | 36/500 [00:02<00:31, 14.87it/s]  8%|▊         | 38/500 [00:02<00:30, 15.11it/s]  8%|▊         | 40/500 [00:02<00:29, 15.45it/s]  8%|▊         | 42/500 [00:02<00:29, 15.67it/s]  9%|▉         | 44/500 [00:02<00:28, 15.89it/s]  9%|▉         | 46/500 [00:02<00:28, 16.06it/s] 10%|▉         | 48/500 [00:03<00:27, 16.15it/s] 10%|█         | 50/500 [00:03<00:27, 16.14it/s] 10%|█         | 52/500 [00:03<00:29, 14.97it/s] 11%|█         | 54/500 [00:03<00:30, 14.53it/s] 11%|█         | 56/500 [00:03<00:30, 14.78it/s] 12%|█▏        | 58/500 [00:03<00:30, 14.36it/s] 12%|█▏        | 60/500 [00:03<00:29, 14.74it/s] 12%|█▏        | 62/500 [00:03<00:29, 14.83it/s] 13%|█▎        | 64/500 [00:04<00:28, 15.12it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.39it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.62it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.87it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.02it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.17it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.08it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.69it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.87it/s] 16%|█▋        | 82/500 [00:05<00:26, 16.07it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.17it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.25it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.16it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.22it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.27it/s] 19%|█▉        | 94/500 [00:05<00:25, 16.21it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.20it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.96it/s] 20%|██        | 100/500 [00:06<00:24, 16.09it/s] 20%|██        | 102/500 [00:06<00:24, 16.24it/s] 21%|██        | 104/500 [00:06<00:24, 16.20it/s] 21%|██        | 106/500 [00:06<00:24, 16.07it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.98it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.10it/s] 22%|██▏       | 112/500 [00:07<00:24, 16.01it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.16it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.23it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.30it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.29it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.14it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.21it/s]Epoch:  1  	Training Loss: 0.20616371929645538
Test Loss:  4841.13818359375
Valid Loss:  4846.3720703125
Epoch:  2  	Training Loss: 4840.705078125
Test Loss:  9.326117756338176e+16
Valid Loss:  9.260768969936077e+16
Epoch:  3  	Training Loss: 9.194452956898918e+16
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.25it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.22it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.22it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.27it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.30it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.20it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.04it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.13it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.14it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.19it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.22it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.29it/s] 30%|███       | 150/500 [00:09<00:21, 15.91it/s] 30%|███       | 152/500 [00:09<00:24, 14.49it/s] 31%|███       | 154/500 [00:09<00:25, 13.37it/s] 31%|███       | 156/500 [00:09<00:26, 13.03it/s] 32%|███▏      | 158/500 [00:10<00:26, 12.79it/s] 32%|███▏      | 160/500 [00:10<00:26, 12.84it/s] 32%|███▏      | 162/500 [00:10<00:26, 12.69it/s] 33%|███▎      | 164/500 [00:10<00:26, 12.57it/s] 33%|███▎      | 166/500 [00:10<00:26, 12.50it/s] 34%|███▎      | 168/500 [00:10<00:26, 12.45it/s] 34%|███▍      | 170/500 [00:11<00:26, 12.43it/s] 34%|███▍      | 172/500 [00:11<00:26, 12.40it/s] 35%|███▍      | 174/500 [00:11<00:26, 12.35it/s] 35%|███▌      | 176/500 [00:11<00:26, 12.16it/s] 36%|███▌      | 178/500 [00:11<00:26, 12.23it/s] 36%|███▌      | 180/500 [00:11<00:26, 12.26it/s] 36%|███▋      | 182/500 [00:12<00:25, 12.31it/s] 37%|███▋      | 184/500 [00:12<00:25, 12.33it/s] 37%|███▋      | 186/500 [00:12<00:25, 12.32it/s] 38%|███▊      | 188/500 [00:12<00:25, 12.29it/s] 38%|███▊      | 190/500 [00:12<00:25, 12.29it/s] 38%|███▊      | 192/500 [00:12<00:25, 12.11it/s] 39%|███▉      | 194/500 [00:13<00:24, 12.66it/s] 39%|███▉      | 196/500 [00:13<00:23, 12.74it/s] 40%|███▉      | 198/500 [00:13<00:24, 12.46it/s] 40%|████      | 200/500 [00:13<00:24, 12.27it/s] 40%|████      | 202/500 [00:13<00:23, 12.52it/s] 41%|████      | 204/500 [00:13<00:22, 13.44it/s] 41%|████      | 206/500 [00:13<00:20, 14.16it/s] 42%|████▏     | 208/500 [00:14<00:21, 13.79it/s] 42%|████▏     | 210/500 [00:14<00:21, 13.19it/s] 42%|████▏     | 212/500 [00:14<00:22, 12.99it/s] 43%|████▎     | 214/500 [00:14<00:22, 12.94it/s] 43%|████▎     | 216/500 [00:14<00:22, 12.41it/s] 44%|████▎     | 218/500 [00:14<00:22, 12.39it/s] 44%|████▍     | 220/500 [00:15<00:22, 12.38it/s] 44%|████▍     | 222/500 [00:15<00:22, 12.35it/s] 45%|████▍     | 224/500 [00:15<00:22, 12.31it/s] 45%|████▌     | 226/500 [00:15<00:22, 12.30it/s] 46%|████▌     | 228/500 [00:15<00:22, 12.24it/s] 46%|████▌     | 230/500 [00:15<00:22, 12.27it/s] 46%|████▋     | 232/500 [00:16<00:21, 12.32it/s] 47%|████▋     | 234/500 [00:16<00:21, 12.32it/s] 47%|████▋     | 236/500 [00:16<00:21, 12.32it/s] 48%|████▊     | 238/500 [00:16<00:20, 12.65it/s] 48%|████▊     | 240/500 [00:16<00:19, 13.62it/s] 48%|████▊     | 242/500 [00:16<00:17, 14.40it/s] 49%|████▉     | 244/500 [00:16<00:17, 14.85it/s] 49%|████▉     | 246/500 [00:16<00:16, 15.24it/s] 50%|████▉     | 248/500 [00:17<00:16, 15.51it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:17<00:15, 15.75it/s] 50%|█████     | 252/500 [00:17<00:15, 15.93it/s] 51%|█████     | 254/500 [00:17<00:15, 16.05it/s] 51%|█████     | 256/500 [00:17<00:15, 16.09it/s] 52%|█████▏    | 258/500 [00:17<00:15, 16.01it/s] 52%|█████▏    | 260/500 [00:17<00:15, 15.97it/s] 52%|█████▏    | 262/500 [00:17<00:14, 15.91it/s] 53%|█████▎    | 264/500 [00:18<00:15, 15.57it/s] 53%|█████▎    | 266/500 [00:18<00:16, 14.39it/s] 54%|█████▎    | 268/500 [00:18<00:16, 13.70it/s] 54%|█████▍    | 270/500 [00:18<00:17, 13.21it/s] 54%|█████▍    | 272/500 [00:18<00:17, 12.88it/s] 55%|█████▍    | 274/500 [00:18<00:17, 12.90it/s] 55%|█████▌    | 276/500 [00:19<00:17, 12.68it/s] 56%|█████▌    | 278/500 [00:19<00:17, 12.51it/s] 56%|█████▌    | 280/500 [00:19<00:17, 12.33it/s] 56%|█████▋    | 282/500 [00:19<00:17, 12.35it/s] 57%|█████▋    | 284/500 [00:19<00:17, 12.33it/s] 57%|█████▋    | 286/500 [00:19<00:17, 12.34it/s] 58%|█████▊    | 288/500 [00:20<00:17, 12.34it/s] 58%|█████▊    | 290/500 [00:20<00:16, 12.38it/s] 58%|█████▊    | 292/500 [00:20<00:16, 12.41it/s] 59%|█████▉    | 294/500 [00:20<00:15, 12.89it/s] 59%|█████▉    | 296/500 [00:20<00:15, 13.30it/s] 60%|█████▉    | 298/500 [00:20<00:14, 13.50it/s] 60%|██████    | 300/500 [00:20<00:15, 13.29it/s] 60%|██████    | 302/500 [00:21<00:15, 12.99it/s] 61%|██████    | 304/500 [00:21<00:15, 12.78it/s] 61%|██████    | 306/500 [00:21<00:15, 12.63it/s] 62%|██████▏   | 308/500 [00:21<00:15, 12.55it/s] 62%|██████▏   | 310/500 [00:21<00:15, 12.48it/s] 62%|██████▏   | 312/500 [00:21<00:15, 12.53it/s] 63%|██████▎   | 314/500 [00:22<00:13, 13.39it/s] 63%|██████▎   | 316/500 [00:22<00:13, 14.07it/s] 64%|██████▎   | 318/500 [00:22<00:12, 14.52it/s] 64%|██████▍   | 320/500 [00:22<00:12, 14.10it/s] 64%|██████▍   | 322/500 [00:22<00:13, 13.49it/s] 65%|██████▍   | 324/500 [00:22<00:12, 13.62it/s] 65%|██████▌   | 326/500 [00:22<00:12, 14.32it/s] 66%|██████▌   | 328/500 [00:23<00:11, 14.81it/s] 66%|██████▌   | 330/500 [00:23<00:11, 15.06it/s] 66%|██████▋   | 332/500 [00:23<00:10, 15.38it/s] 67%|██████▋   | 334/500 [00:23<00:10, 15.59it/s] 67%|██████▋   | 336/500 [00:23<00:10, 15.79it/s] 68%|██████▊   | 338/500 [00:23<00:10, 16.01it/s] 68%|██████▊   | 340/500 [00:23<00:09, 16.09it/s] 68%|██████▊   | 342/500 [00:23<00:09, 16.17it/s] 69%|██████▉   | 344/500 [00:23<00:09, 16.21it/s] 69%|██████▉   | 346/500 [00:24<00:09, 16.25it/s] 70%|██████▉   | 348/500 [00:24<00:09, 16.27it/s] 70%|███████   | 350/500 [00:24<00:09, 16.29it/s] 70%|███████   | 352/500 [00:24<00:09, 16.33it/s] 71%|███████   | 354/500 [00:24<00:09, 16.11it/s] 71%|███████   | 356/500 [00:24<00:09, 15.70it/s] 72%|███████▏  | 358/500 [00:24<00:09, 15.68it/s] 72%|███████▏  | 360/500 [00:24<00:08, 15.85it/s] 72%|███████▏  | 362/500 [00:25<00:08, 16.01it/s] 73%|███████▎  | 364/500 [00:25<00:08, 16.13it/s] 73%|███████▎  | 366/500 [00:25<00:08, 16.16it/s] 74%|███████▎  | 368/500 [00:25<00:08, 16.22it/s] 74%|███████▍  | 370/500 [00:25<00:08, 15.65it/s] 74%|███████▍  | 372/500 [00:25<00:08, 15.77it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:25<00:07, 15.86it/s] 75%|███████▌  | 376/500 [00:25<00:07, 15.97it/s] 76%|███████▌  | 378/500 [00:26<00:07, 16.11it/s] 76%|███████▌  | 380/500 [00:26<00:07, 15.64it/s] 76%|███████▋  | 382/500 [00:26<00:07, 15.83it/s] 77%|███████▋  | 384/500 [00:26<00:07, 15.99it/s] 77%|███████▋  | 386/500 [00:26<00:07, 16.15it/s] 78%|███████▊  | 388/500 [00:26<00:06, 16.15it/s] 78%|███████▊  | 390/500 [00:26<00:06, 15.83it/s] 78%|███████▊  | 392/500 [00:26<00:06, 15.96it/s] 79%|███████▉  | 394/500 [00:27<00:06, 15.91it/s] 79%|███████▉  | 396/500 [00:27<00:06, 16.09it/s] 80%|███████▉  | 398/500 [00:27<00:06, 16.14it/s] 80%|████████  | 400/500 [00:27<00:06, 16.15it/s] 80%|████████  | 402/500 [00:27<00:06, 16.24it/s] 81%|████████  | 404/500 [00:27<00:05, 16.10it/s] 81%|████████  | 406/500 [00:27<00:05, 15.98it/s] 82%|████████▏ | 408/500 [00:27<00:05, 16.13it/s] 82%|████████▏ | 410/500 [00:28<00:05, 16.20it/s] 82%|████████▏ | 412/500 [00:28<00:05, 15.89it/s] 83%|████████▎ | 414/500 [00:28<00:05, 15.87it/s] 83%|████████▎ | 416/500 [00:28<00:05, 16.05it/s] 84%|████████▎ | 418/500 [00:28<00:05, 16.05it/s] 84%|████████▍ | 420/500 [00:28<00:04, 16.19it/s] 84%|████████▍ | 422/500 [00:28<00:04, 16.23it/s] 85%|████████▍ | 424/500 [00:28<00:04, 16.29it/s] 85%|████████▌ | 426/500 [00:29<00:04, 16.32it/s] 86%|████████▌ | 428/500 [00:29<00:04, 16.24it/s] 86%|████████▌ | 430/500 [00:29<00:04, 16.38it/s] 86%|████████▋ | 432/500 [00:29<00:04, 16.40it/s] 87%|████████▋ | 434/500 [00:29<00:04, 16.40it/s] 87%|████████▋ | 436/500 [00:29<00:03, 16.40it/s] 88%|████████▊ | 438/500 [00:29<00:03, 16.43it/s] 88%|████████▊ | 440/500 [00:29<00:03, 15.97it/s] 88%|████████▊ | 442/500 [00:30<00:03, 16.03it/s] 89%|████████▉ | 444/500 [00:30<00:03, 16.05it/s] 89%|████████▉ | 446/500 [00:30<00:03, 16.03it/s] 90%|████████▉ | 448/500 [00:30<00:03, 16.02it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.93it/s] 90%|█████████ | 452/500 [00:30<00:02, 16.06it/s] 91%|█████████ | 454/500 [00:30<00:02, 16.14it/s] 91%|█████████ | 456/500 [00:30<00:02, 16.13it/s] 92%|█████████▏| 458/500 [00:31<00:02, 16.18it/s] 92%|█████████▏| 460/500 [00:31<00:02, 16.00it/s] 92%|█████████▏| 462/500 [00:31<00:02, 15.65it/s] 93%|█████████▎| 464/500 [00:31<00:02, 15.60it/s] 93%|█████████▎| 466/500 [00:31<00:02, 15.80it/s] 94%|█████████▎| 468/500 [00:31<00:02, 14.55it/s] 94%|█████████▍| 470/500 [00:31<00:02, 13.79it/s] 94%|█████████▍| 472/500 [00:32<00:02, 13.30it/s] 95%|█████████▍| 474/500 [00:32<00:02, 12.98it/s] 95%|█████████▌| 476/500 [00:32<00:01, 12.65it/s] 96%|█████████▌| 478/500 [00:32<00:01, 12.65it/s] 96%|█████████▌| 480/500 [00:32<00:01, 13.59it/s] 96%|█████████▋| 482/500 [00:32<00:01, 14.29it/s] 97%|█████████▋| 484/500 [00:32<00:01, 14.85it/s] 97%|█████████▋| 486/500 [00:33<00:00, 15.04it/s] 98%|█████████▊| 488/500 [00:33<00:00, 15.37it/s] 98%|█████████▊| 490/500 [00:33<00:00, 15.58it/s] 98%|█████████▊| 492/500 [00:33<00:00, 15.81it/s] 99%|█████████▉| 494/500 [00:33<00:00, 15.98it/s] 99%|█████████▉| 496/500 [00:33<00:00, 16.10it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:33<00:00, 16.18it/s]100%|██████████| 500/500 [00:33<00:00, 16.24it/s]100%|██████████| 500/500 [00:33<00:00, 14.74it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  5
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:40,  6.21s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:20,  1.89it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<10:44,  1.32s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:47,  2.87it/s]  4%|▍         | 21/500 [00:20<09:49,  1.23s/it]  5%|▍         | 23/500 [00:20<07:00,  1.13it/s]  5%|▌         | 25/500 [00:20<05:03,  1.56it/s]  5%|▌         | 27/500 [00:20<03:43,  2.12it/s]  6%|▌         | 29/500 [00:20<02:47,  2.82it/s]  6%|▌         | 31/500 [00:27<09:26,  1.21s/it]  7%|▋         | 33/500 [00:27<06:46,  1.15it/s]  7%|▋         | 35/500 [00:27<04:55,  1.58it/s]  7%|▋         | 37/500 [00:27<03:37,  2.13it/s]  8%|▊         | 39/500 [00:27<02:43,  2.82it/s]  8%|▊         | 41/500 [00:34<09:14,  1.21s/it]  9%|▊         | 43/500 [00:34<06:38,  1.15it/s]  9%|▉         | 45/500 [00:34<04:48,  1.58it/s]  9%|▉         | 47/500 [00:34<03:32,  2.13it/s] 10%|▉         | 49/500 [00:34<02:39,  2.83it/s] 10%|█         | 51/500 [00:41<08:49,  1.18s/it] 11%|█         | 53/500 [00:41<06:18,  1.18it/s] 11%|█         | 55/500 [00:41<04:32,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:47<08:30,  1.16s/it] 13%|█▎        | 63/500 [00:48<06:04,  1.20it/s] 13%|█▎        | 65/500 [00:48<04:22,  1.66it/s] 13%|█▎        | 67/500 [00:48<03:12,  2.24it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.97it/s]Epoch:  1  	Training Loss: 0.2061637043952942
Test Loss:  0.013113917782902718
Valid Loss:  0.01787506975233555
Epoch:  2  	Training Loss: 0.02073138952255249
Test Loss:  0.010963410139083862
Valid Loss:  0.014907153323292732
Epoch:  3  	Training Loss: 0.016478119418025017
Test Loss:  0.008952584117650986
Valid Loss:  0.012382985092699528
Epoch:  4  	Training Loss: 0.01358813513070345
Test Loss:  0.007404954172670841
Valid Loss:  0.01040143147110939
Epoch:  5  	Training Loss: 0.011286307126283646
Test Loss:  0.006211169064044952
Valid Loss:  0.008844079449772835
Epoch:  6  	Training Loss: 0.009454949758946896
Test Loss:  0.0052569773979485035
Valid Loss:  0.007595255970954895
Epoch:  7  	Training Loss: 0.007993355393409729
Test Loss:  0.004501529969274998
Valid Loss:  0.006596453487873077
Epoch:  8  	Training Loss: 0.006823254749178886
Test Loss:  0.00390041247010231
Valid Loss:  0.005794184282422066
Epoch:  9  	Training Loss: 0.005886554718017578
Test Loss:  0.0034224370028823614
Valid Loss:  0.005149679258465767
Epoch:  10  	Training Loss: 0.005136392079293728
Test Loss:  0.0030450394842773676
Valid Loss:  0.004633544012904167
Epoch:  11  	Training Loss: 0.004535401239991188
Test Loss:  0.00274572242051363
Valid Loss:  0.004220099188387394
Epoch:  12  	Training Loss: 0.004054316319525242
Test Loss:  0.0025019003078341484
Valid Loss:  0.0038881360087543726
Epoch:  13  	Training Loss: 0.003675682470202446
Test Loss:  0.0023129391483962536
Valid Loss:  0.0036227197851985693
Epoch:  14  	Training Loss: 0.00337274931371212
Test Loss:  0.0021651398856192827
Valid Loss:  0.0034090394619852304
Epoch:  15  	Training Loss: 0.00312866922467947
Test Loss:  0.0020504924468696117
Valid Loss:  0.0032374344300478697
Epoch:  16  	Training Loss: 0.0029316346626728773
Test Loss:  0.001958779990673065
Valid Loss:  0.0030973204411566257
Epoch:  17  	Training Loss: 0.0027723750099539757
Test Loss:  0.001888618222437799
Valid Loss:  0.0029849389102309942
Epoch:  18  	Training Loss: 0.002643544925376773
Test Loss:  0.001832092646509409
Valid Loss:  0.002892574295401573
Epoch:  19  	Training Loss: 0.00253922026604414
Test Loss:  0.001787887653335929
Valid Loss:  0.0028173294849693775
Epoch:  20  	Training Loss: 0.0024546508211642504
Test Loss:  0.0017533444333821535
Valid Loss:  0.0027558347210288048
Epoch:  21  	Training Loss: 0.00238609267398715
Test Loss:  0.0017299253959208727
Valid Loss:  0.002708019921556115
Epoch:  22  	Training Loss: 0.0023305914364755154
Test Loss:  0.0017084982246160507
Valid Loss:  0.0026666265912353992
Epoch:  23  	Training Loss: 0.0022855009883642197
Test Loss:  0.0016935626044869423
Valid Loss:  0.00263370294123888
Epoch:  24  	Training Loss: 0.0022488876711577177
Test Loss:  0.001681568450294435
Valid Loss:  0.0026062210090458393
Epoch:  25  	Training Loss: 0.0022191486787050962
Test Loss:  0.0016737731639295816
Valid Loss:  0.0025845402851700783
Epoch:  26  	Training Loss: 0.0021950288210064173
Test Loss:  0.0016664746217429638
Valid Loss:  0.0025656651705503464
Epoch:  27  	Training Loss: 0.0021753432229161263
Test Loss:  0.001661177258938551
Valid Loss:  0.0025500385090708733
Epoch:  28  	Training Loss: 0.0021592238917946815
Test Loss:  0.0016572833992540836
Valid Loss:  0.0025370195508003235
Epoch:  29  	Training Loss: 0.002145991660654545
Test Loss:  0.0016541287768632174
Valid Loss:  0.002525971969589591
Epoch:  30  	Training Loss: 0.002135140122845769
Test Loss:  0.001653489307500422
Valid Loss:  0.002517824526876211
Epoch:  31  	Training Loss: 0.0021262643858790398
Test Loss:  0.0016522768419235945
Valid Loss:  0.002510523423552513
Epoch:  32  	Training Loss: 0.0021189721301198006
Test Loss:  0.0016538678901270032
Valid Loss:  0.002505803480744362
Epoch:  33  	Training Loss: 0.002112956950441003
Test Loss:  0.0016538125928491354
Valid Loss:  0.0025008381344377995
Epoch:  34  	Training Loss: 0.0021079923026263714
Test Loss:  0.0016543825622648
Valid Loss:  0.0024969056248664856
Epoch:  35  	Training Loss: 0.0021038739942014217
Test Loss:  0.0016539714997634292
Valid Loss:  0.002492954023182392
Epoch:  36  	Training Loss: 0.0021004676818847656
Test Loss:  0.0016549353022128344
Valid Loss:  0.002490321872755885
Epoch:  37  	Training Loss: 0.002097634132951498
Test Loss:  0.0016554093454033136
Valid Loss:  0.0024877889081835747
Epoch:  38  	Training Loss: 0.0020952881313860416
Test Loss:  0.0016556903719902039
Valid Loss:  0.002485469449311495
Epoch:  39  	Training Loss: 0.002093324437737465
Test Loss:  0.0016563194803893566
Valid Loss:  0.002483679912984371
Epoch:  40  	Training Loss: 0.0020916713401675224
Test Loss:  0.0016563518438488245
Valid Loss:  0.0024818251840770245
Epoch:  41  	Training Loss: 0.0020902669057250023
Test Loss:  0.0016584675759077072
Valid Loss:  0.002481493167579174
Epoch:  42  	Training Loss: 0.00208909809589386
Test Loss:  0.001657526707276702
Valid Loss:  0.0024795248173177242
Epoch:  43  	Training Loss: 0.0020881351083517075
Test Loss:  0.0016587238060310483
Valid Loss:  0.0024790074676275253
Epoch:  44  	Training Loss: 0.002087303204461932
Test Loss:  0.0016589411534368992
Valid Loss:  0.002478041686117649
Epoch:  45  	Training Loss: 0.0020865807309746742
Test Loss:  0.0016592380125075579
Valid Loss:  0.0024772353935986757
Epoch:  46  	Training Loss: 0.002085957443341613
Test Loss:  0.0016594750341027975
Valid Loss:  0.0024764975532889366
Epoch:  47  	Training Loss: 0.002085404936224222
Test Loss:  0.0016601624665781856
Valid Loss:  0.0024760912638157606
Epoch:  48  	Training Loss: 0.0020849218126386404
Test Loss:  0.001659858855418861
Valid Loss:  0.0024752006866037846
Epoch:  49  	Training Loss: 0.0020844973623752594
Test Loss:  0.0016601122915744781
Valid Loss:  0.002474685199558735
Epoch:  50  	Training Loss: 0.0020841334480792284
Test Loss:  0.0016607363941147923
Valid Loss:  0.002474430250003934
Epoch:  51  	Training Loss: 0.002083809580653906
Test Loss:  0.0016603812109678984
Valid Loss:  0.002473660046234727
Epoch:  52  	Training Loss: 0.002083503408357501
Test Loss:  0.0016605122946202755
Valid Loss:  0.0024732165038585663
Epoch:  53  	Training Loss: 0.0020832200534641743
Test Loss:  0.0016610592138022184
Valid Loss:  0.0024730416480451822
Epoch:  54  	Training Loss: 0.002082958584651351
Test Loss:  0.001660629059188068
Valid Loss:  0.0024723478127270937
Epoch:  55  	Training Loss: 0.0020827141124755144
Test Loss:  0.0016611574683338404
Valid Loss:  0.0024722437374293804
Epoch:  56  	Training Loss: 0.0020824794191867113
Test Loss:  0.0016610119491815567
Valid Loss:  0.0024717883206903934
Epoch:  57  	Training Loss: 0.002082269173115492
Test Loss:  0.0016612273175269365
Valid Loss:  0.002471593674272299
Epoch:  58  	Training Loss: 0.002082065911963582
Test Loss:  0.0016615474596619606
Valid Loss:  0.002471510786563158
Epoch:  59  	Training Loss: 0.0020818752236664295
Test Loss:  0.0016612933250144124
Valid Loss:  0.0024711221922188997
Epoch:  60  	Training Loss: 0.0020816982723772526
Test Loss:  0.0016631416510790586
Valid Loss:  0.002471925225108862
Epoch:  61  	Training Loss: 0.002081529702991247
Test Loss:  0.0016625263961032033
Valid Loss:  0.0024713422171771526
Epoch:  62  	Training Loss: 0.0020813788287341595
Test Loss:  0.0016616035718470812
Valid Loss:  0.0024706260301172733
Epoch:  63  	Training Loss: 0.002081235870718956
Test Loss:  0.0016628284938633442
Valid Loss:  0.0024711349979043007
Epoch:  64  	Training Loss: 0.0020810901187360287
Test Loss:  0.0016630501486361027
Valid Loss:  0.0024710758589208126
Epoch:  65  	Training Loss: 0.002080949954688549
Test Loss:  0.0016630325699225068
Valid Loss:  0.002470890525728464
Epoch:  66  	Training Loss: 0.002080813515931368
Test Loss:  0.001662594499066472
Valid Loss:  0.002470480976626277
Epoch:  67  	Training Loss: 0.002080687088891864
Test Loss:  0.0016629834426566958
Valid Loss:  0.0024705578107386827
Epoch:  68  	Training Loss: 0.0020805615931749344
Test Loss:  0.0016629777383059263
Valid Loss:  0.0024704118259251118
Epoch:  69  	Training Loss: 0.0020804398227483034
Test Loss:  0.0016619076486676931
Valid Loss:  0.002469685859978199
Epoch:  70  	Training Loss: 0.002080325037240982
Test Loss:  0.0016624985728412867
Valid Loss:   14%|█▍        | 71/500 [00:54<08:32,  1.19s/it] 15%|█▍        | 73/500 [00:55<06:06,  1.17it/s] 15%|█▌        | 75/500 [00:55<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:11,  2.21it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:01<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:02<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:02<03:06,  2.22it/s] 18%|█▊        | 89/500 [01:02<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:08<08:03,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:09<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:09<02:14,  2.99it/s] 20%|██        | 101/500 [01:15<07:51,  1.18s/it] 21%|██        | 103/500 [01:15<05:38,  1.17it/s] 21%|██        | 105/500 [01:15<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:15<02:58,  2.21it/s] 22%|██▏       | 109/500 [01:16<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:22<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:22<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:22<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:22<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:29<07:32,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:10,  1.17s/it] 27%|██▋       | 133/500 [01:36<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:36<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:36<02:41,  2.25it/s] 28%|██▊       | 139/500 [01:36<01:59,  3.02it/s]0.0024699154309928417
Epoch:  71  	Training Loss: 0.0020802062936127186
Test Loss:  0.0016625183634459972
Valid Loss:  0.002469816477969289
Epoch:  72  	Training Loss: 0.002080088946968317
Test Loss:  0.001662757946178317
Valid Loss:  0.0024698383640497923
Epoch:  73  	Training Loss: 0.002079972065985203
Test Loss:  0.0016626748256385326
Valid Loss:  0.002469687955453992
Epoch:  74  	Training Loss: 0.0020798593759536743
Test Loss:  0.0016626145225018263
Valid Loss:  0.0024695484898984432
Epoch:  75  	Training Loss: 0.002079746685922146
Test Loss:  0.001662547467276454
Valid Loss:  0.002469410188496113
Epoch:  76  	Training Loss: 0.0020796358585357666
Test Loss:  0.0016624678391963243
Valid Loss:  0.0024692744482308626
Epoch:  77  	Training Loss: 0.0020795240998268127
Test Loss:  0.0016624004347249866
Valid Loss:  0.0024691433645784855
Epoch:  78  	Training Loss: 0.0020794179290533066
Test Loss:  0.0016623258125036955
Valid Loss:  0.00246901111677289
Epoch:  79  	Training Loss: 0.0020793091971427202
Test Loss:  0.0016622500261291862
Valid Loss:  0.0024688809644430876
Epoch:  80  	Training Loss: 0.0020792027935385704
Test Loss:  0.0016617305809631944
Valid Loss:  0.002468505408614874
Epoch:  81  	Training Loss: 0.002079096157103777
Test Loss:  0.0016621111426502466
Valid Loss:  0.002468651160597801
Epoch:  82  	Training Loss: 0.0020789913833141327
Test Loss:  0.0016619977541267872
Valid Loss:  0.002468506107106805
Epoch:  83  	Training Loss: 0.0020788905676454306
Test Loss:  0.001661920454353094
Valid Loss:  0.0024683834053575993
Epoch:  84  	Training Loss: 0.0020787909161299467
Test Loss:  0.001661775866523385
Valid Loss:  0.002468226943165064
Epoch:  85  	Training Loss: 0.0020786907989531755
Test Loss:  0.0016617539804428816
Valid Loss:  0.002468142192810774
Epoch:  86  	Training Loss: 0.0020785899832844734
Test Loss:  0.0016616634093225002
Valid Loss:  0.0024680164642632008
Epoch:  87  	Training Loss: 0.0020784924272447824
Test Loss:  0.001661572139710188
Valid Loss:  0.002467898651957512
Epoch:  88  	Training Loss: 0.0020783920772373676
Test Loss:  0.0016614834312349558
Valid Loss:  0.0024677799083292484
Epoch:  89  	Training Loss: 0.0020782924257218838
Test Loss:  0.001661389833316207
Valid Loss:  0.0024676595348864794
Epoch:  90  	Training Loss: 0.0020781937055289745
Test Loss:  0.0016612991457805037
Valid Loss:  0.002467540791258216
Epoch:  91  	Training Loss: 0.002078094519674778
Test Loss:  0.0016612118342891335
Valid Loss:  0.0024674213491380215
Epoch:  92  	Training Loss: 0.002077996963635087
Test Loss:  0.0016611268511041999
Valid Loss:  0.0024673044681549072
Epoch:  93  	Training Loss: 0.0020779005717486143
Test Loss:  0.0016610388411208987
Valid Loss:  0.002467190381139517
Epoch:  94  	Training Loss: 0.00207780534401536
Test Loss:  0.0016609575832262635
Valid Loss:  0.0024670755956321955
Epoch:  95  	Training Loss: 0.002077709184959531
Test Loss:  0.0016608713194727898
Valid Loss:  0.0024669659323990345
Epoch:  96  	Training Loss: 0.0020776139572262764
Test Loss:  0.0016607888974249363
Valid Loss:  0.002466854639351368
Epoch:  97  	Training Loss: 0.0020775198936462402
Test Loss:  0.0016607039142400026
Valid Loss:  0.0024667498655617237
Epoch:  98  	Training Loss: 0.002077423734590411
Test Loss:  0.0016606176504865289
Valid Loss:  0.002466644626110792
Epoch:  99  	Training Loss: 0.0020773287396878004
Test Loss:  0.001660532201640308
Valid Loss:  0.002466537756845355
Epoch:  100  	Training Loss: 0.0020772330462932587
Test Loss:  0.0016604478005319834
Valid Loss:  0.0024664353113621473
Epoch:  101  	Training Loss: 0.0020771378185600042
Test Loss:  0.0016603588592261076
Valid Loss:  0.0024663330987095833
Epoch:  102  	Training Loss: 0.002077043056488037
Test Loss:  0.0016602857504040003
Valid Loss:  0.0024662341456860304
Epoch:  103  	Training Loss: 0.0020769513212144375
Test Loss:  0.0016602026298642159
Valid Loss:  0.002466134261339903
Epoch:  104  	Training Loss: 0.002076859585940838
Test Loss:  0.001660116482526064
Valid Loss:  0.0024660290218889713
Epoch:  105  	Training Loss: 0.0020767697133123875
Test Loss:  0.001660031615756452
Valid Loss:  0.0024659307673573494
Epoch:  106  	Training Loss: 0.002076677745208144
Test Loss:  0.0016599477967247367
Valid Loss:  0.002465831348672509
Epoch:  107  	Training Loss: 0.00207658763974905
Test Loss:  0.0016598645597696304
Valid Loss:  0.002465731929987669
Epoch:  108  	Training Loss: 0.002076497534289956
Test Loss:  0.0016597793437540531
Valid Loss:  0.0024656238965690136
Epoch:  109  	Training Loss: 0.0020764069631695747
Test Loss:  0.001659695291891694
Valid Loss:  0.002465528901666403
Epoch:  110  	Training Loss: 0.002076315227895975
Test Loss:  0.0016596083296462893
Valid Loss:  0.0024654262233525515
Epoch:  111  	Training Loss: 0.0020762246567755938
Test Loss:  0.0016595222987234592
Valid Loss:  0.002465326339006424
Epoch:  112  	Training Loss: 0.0020761345513164997
Test Loss:  0.0016594445332884789
Valid Loss:  0.0024652271531522274
Epoch:  113  	Training Loss: 0.0020760460756719112
Test Loss:  0.0016593654872849584
Valid Loss:  0.00246512982994318
Epoch:  114  	Training Loss: 0.0020759576000273228
Test Loss:  0.0016592855099588633
Valid Loss:  0.002465025754645467
Epoch:  115  	Training Loss: 0.002075869357213378
Test Loss:  0.001659207046031952
Valid Loss:  0.0024649284314364195
Epoch:  116  	Training Loss: 0.0020757815800607204
Test Loss:  0.0016591285821050406
Valid Loss:  0.002464829944074154
Epoch:  117  	Training Loss: 0.0020756935700774193
Test Loss:  0.0016590473242104053
Valid Loss:  0.0024647268000990152
Epoch:  118  	Training Loss: 0.002075605094432831
Test Loss:  0.0016589666483923793
Valid Loss:  0.002464630175381899
Epoch:  119  	Training Loss: 0.0020755163859575987
Test Loss:  0.0016588872531428933
Valid Loss:  0.0024645281955599785
Epoch:  120  	Training Loss: 0.002075428608804941
Test Loss:  0.0016588057624176145
Valid Loss:  0.002464430406689644
Epoch:  121  	Training Loss: 0.002075341995805502
Test Loss:  0.001658726017922163
Valid Loss:  0.002464329358190298
Epoch:  122  	Training Loss: 0.002075251191854477
Test Loss:  0.001658650697208941
Valid Loss:  0.0024642329663038254
Epoch:  123  	Training Loss: 0.002075165743008256
Test Loss:  0.0016585708362981677
Valid Loss:  0.0024641379714012146
Epoch:  124  	Training Loss: 0.002075080294162035
Test Loss:  0.0016584908589720726
Valid Loss:  0.0024640406481921673
Epoch:  125  	Training Loss: 0.0020749936811625957
Test Loss:  0.0016584127442911267
Valid Loss:  0.0024639430921524763
Epoch:  126  	Training Loss: 0.0020749084651470184
Test Loss:  0.0016583334654569626
Valid Loss:  0.002463845070451498
Epoch:  127  	Training Loss: 0.0020748204551637173
Test Loss:  0.001658253138884902
Valid Loss:  0.002463751006871462
Epoch:  128  	Training Loss: 0.0020747357048094273
Test Loss:  0.0016581777017563581
Valid Loss:  0.002463652053847909
Epoch:  129  	Training Loss: 0.002074649091809988
Test Loss:  0.001658103778026998
Valid Loss:  0.0024635582230985165
Epoch:  130  	Training Loss: 0.0020745641086250544
Test Loss:  0.0016580281080678105
Valid Loss:  0.0024634585715830326
Epoch:  131  	Training Loss: 0.0020744786597788334
Test Loss:  0.0016579476650804281
Valid Loss:  0.0024633610155433416
Epoch:  132  	Training Loss: 0.002074394142255187
Test Loss:  0.0016578694339841604
Valid Loss:  0.002463266486302018
Epoch:  133  	Training Loss: 0.002074310090392828
Test Loss:  0.0016577917849645019
Valid Loss:  0.0024631693959236145
Epoch:  134  	Training Loss: 0.0020742267370224
Test Loss:  0.0016577158821746707
Valid Loss:  0.002463077660650015
Epoch:  135  	Training Loss: 0.002074142685160041
Test Loss:  0.0016576374182477593
Valid Loss:  0.0024629775434732437
Epoch:  136  	Training Loss: 0.002074059098958969
Test Loss:  0.001657560933381319
Valid Loss:  0.0024628841783851385
Epoch:  137  	Training Loss: 0.002073975745588541
Test Loss:  0.0016574847977608442
Valid Loss:  0.0024627894163131714
Epoch:  138  	Training Loss: 0.002073892392218113
Test Loss:  0.0016574093606323004
Valid Loss:  0.002462692093104124
Epoch:  139  	Training Loss: 0.002073809038847685
Test Loss:  0.001657336950302124
Valid Loss:  0.002462600124999881
 28%|██▊       | 141/500 [01:42<07:05,  1.19s/it] 29%|██▊       | 143/500 [01:43<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:43<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:43<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:43<01:56,  3.00it/s] 30%|███       | 151/500 [01:49<06:53,  1.19s/it] 31%|███       | 153/500 [01:49<04:57,  1.17it/s] 31%|███       | 155/500 [01:50<03:35,  1.60it/s] 31%|███▏      | 157/500 [01:50<02:37,  2.18it/s] 32%|███▏      | 159/500 [01:50<01:56,  2.93it/s] 32%|███▏      | 161/500 [01:56<06:41,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:57<03:29,  1.60it/s] 33%|███▎      | 167/500 [01:57<02:33,  2.16it/s] 34%|███▍      | 169/500 [01:57<01:55,  2.87it/s] 34%|███▍      | 171/500 [02:03<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:03<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:04<03:23,  1.59it/s] 35%|███▌      | 177/500 [02:04<02:30,  2.15it/s] 36%|███▌      | 179/500 [02:04<01:51,  2.88it/s] 36%|███▌      | 181/500 [02:10<06:14,  1.18s/it] 37%|███▋      | 183/500 [02:10<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:10<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:10<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:11<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:17<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:17<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:17<03:04,  1.66it/s] 39%|███▉      | 197/500 [02:17<02:13,  2.26it/s] 40%|███▉      | 199/500 [02:17<01:39,  3.04it/s] 40%|████      | 201/500 [02:24<05:48,  1.17s/it] 41%|████      | 203/500 [02:24<04:08,  1.20it/s] 41%|████      | 205/500 [02:24<02:58,  1.66it/s] 41%|████▏     | 207/500 [02:24<02:09,  2.26it/s]Epoch:  140  	Training Loss: 0.002073724754154682
Test Loss:  0.0016572652384638786
Valid Loss:  0.00246250256896019
Epoch:  141  	Training Loss: 0.0020736418664455414
Test Loss:  0.001657187007367611
Valid Loss:  0.0024624066427350044
Epoch:  142  	Training Loss: 0.002073559444397688
Test Loss:  0.0016571132000535727
Valid Loss:  0.002462313510477543
Epoch:  143  	Training Loss: 0.0020734770223498344
Test Loss:  0.0016570407897233963
Valid Loss:  0.0024622217752039433
Epoch:  144  	Training Loss: 0.0020733950659632683
Test Loss:  0.0016569626750424504
Valid Loss:  0.0024621293414384127
Epoch:  145  	Training Loss: 0.0020733140408992767
Test Loss:  0.001656890963204205
Valid Loss:  0.002462035045027733
Epoch:  146  	Training Loss: 0.002073233248665929
Test Loss:  0.0016568161081522703
Valid Loss:  0.0024619423784315586
Epoch:  147  	Training Loss: 0.0020731512922793627
Test Loss:  0.0016567420680075884
Valid Loss:  0.0024618490133434534
Epoch:  148  	Training Loss: 0.0020730700343847275
Test Loss:  0.0016566673293709755
Valid Loss:  0.0024617528542876244
Epoch:  149  	Training Loss: 0.0020729880779981613
Test Loss:  0.0016565904952585697
Valid Loss:  0.0024616606533527374
Epoch:  150  	Training Loss: 0.0020729070529341698
Test Loss:  0.0016565188998356462
Valid Loss:  0.002461566822603345
Epoch:  151  	Training Loss: 0.0020728250965476036
Test Loss:  0.0016564426477998495
Valid Loss:  0.0024614729918539524
Epoch:  152  	Training Loss: 0.0020727445371448994
Test Loss:  0.001656366279348731
Valid Loss:  0.0024613807909190655
Epoch:  153  	Training Loss: 0.0020726630464196205
Test Loss:  0.0016562939854338765
Valid Loss:  0.00246128486469388
Epoch:  154  	Training Loss: 0.0020725824870169163
Test Loss:  0.0016562213422730565
Valid Loss:  0.002461194060742855
Epoch:  155  	Training Loss: 0.0020725016947835684
Test Loss:  0.0016561453230679035
Valid Loss:  0.00246110325679183
Epoch:  156  	Training Loss: 0.002072421135380864
Test Loss:  0.0016560712829232216
Valid Loss:  0.0024610080290585756
Epoch:  157  	Training Loss: 0.0020723408088088036
Test Loss:  0.0016559958457946777
Valid Loss:  0.002460916293784976
Epoch:  158  	Training Loss: 0.002072259783744812
Test Loss:  0.001655922969803214
Valid Loss:  0.0024608257226645947
Epoch:  159  	Training Loss: 0.002072178525850177
Test Loss:  0.0016558511415496469
Valid Loss:  0.0024607316590845585
Epoch:  160  	Training Loss: 0.00207209843210876
Test Loss:  0.0016557727940380573
Valid Loss:  0.0024606394581496716
Epoch:  161  	Training Loss: 0.0020720171742141247
Test Loss:  0.0016556998016312718
Valid Loss:  0.0024605458602309227
Epoch:  162  	Training Loss: 0.002071936149150133
Test Loss:  0.0016556275077164173
Valid Loss:  0.0024604550562798977
Epoch:  163  	Training Loss: 0.002071856986731291
Test Loss:  0.0016555532347410917
Valid Loss:  0.0024603670462965965
Epoch:  164  	Training Loss: 0.002071777358651161
Test Loss:  0.001655479660257697
Valid Loss:  0.002460271120071411
Epoch:  165  	Training Loss: 0.0020716979634016752
Test Loss:  0.0016554081812500954
Valid Loss:  0.0024601793847978115
Epoch:  166  	Training Loss: 0.0020716183353215456
Test Loss:  0.0016553329769521952
Valid Loss:  0.002460088115185499
Epoch:  167  	Training Loss: 0.0020715375430881977
Test Loss:  0.0016552607994526625
Valid Loss:  0.002459997544065118
Epoch:  168  	Training Loss: 0.0020714588463306427
Test Loss:  0.0016551887383684516
Valid Loss:  0.0024599062744528055
Epoch:  169  	Training Loss: 0.002071378054097295
Test Loss:  0.0016551141161471605
Valid Loss:  0.0024598129093647003
Epoch:  170  	Training Loss: 0.0020712981931865215
Test Loss:  0.0016550420550629497
Valid Loss:  0.002459722338244319
Epoch:  171  	Training Loss: 0.0020712194964289665
Test Loss:  0.0016549683641642332
Valid Loss:  0.002459630835801363
Epoch:  172  	Training Loss: 0.002071140334010124
Test Loss:  0.0016548961866647005
Valid Loss:  0.0024595409631729126
Epoch:  173  	Training Loss: 0.002071061171591282
Test Loss:  0.0016548234270885587
Valid Loss:  0.002459452487528324
Epoch:  174  	Training Loss: 0.0020709820091724396
Test Loss:  0.0016547502018511295
Valid Loss:  0.0024593633133918047
Epoch:  175  	Training Loss: 0.0020709033124148846
Test Loss:  0.0016546801198273897
Valid Loss:  0.0024592739064246416
Epoch:  176  	Training Loss: 0.002070824382826686
Test Loss:  0.0016546060796827078
Valid Loss:  0.0024591817054897547
Epoch:  177  	Training Loss: 0.0020707459188997746
Test Loss:  0.0016545350663363934
Valid Loss:  0.0024590888060629368
Epoch:  178  	Training Loss: 0.002070668153464794
Test Loss:  0.0016544648678973317
Valid Loss:  0.0024590003304183483
Epoch:  179  	Training Loss: 0.0020705892238765955
Test Loss:  0.001654391991905868
Valid Loss:  0.0024589113891124725
Epoch:  180  	Training Loss: 0.0020705098286271095
Test Loss:  0.0016543198144063354
Valid Loss:  0.0024588231462985277
Epoch:  181  	Training Loss: 0.002070432296022773
Test Loss:  0.0016542465891689062
Valid Loss:  0.002458730014041066
Epoch:  182  	Training Loss: 0.0020703538320958614
Test Loss:  0.0016541730146855116
Valid Loss:  0.0024586410727351904
Epoch:  183  	Training Loss: 0.0020702765323221684
Test Loss:  0.0016541046788915992
Valid Loss:  0.00245855376124382
Epoch:  184  	Training Loss: 0.0020702010951936245
Test Loss:  0.0016540326178073883
Valid Loss:  0.002458463655784726
Epoch:  185  	Training Loss: 0.002070122864097357
Test Loss:  0.0016539632342755795
Valid Loss:  0.002458375645801425
Epoch:  186  	Training Loss: 0.002070046029984951
Test Loss:  0.0016538959462195635
Valid Loss:  0.0024582906626164913
Epoch:  187  	Training Loss: 0.0020699684973806143
Test Loss:  0.001653824234381318
Valid Loss:  0.0024582012556493282
Epoch:  188  	Training Loss: 0.0020698923617601395
Test Loss:  0.0016537565970793366
Valid Loss:  0.002458112547174096
Epoch:  189  	Training Loss: 0.0020698143634945154
Test Loss:  0.001653685118071735
Valid Loss:  0.002458021277561784
Epoch:  190  	Training Loss: 0.0020697377622127533
Test Loss:  0.0016536167822778225
Valid Loss:  0.002457935595884919
Epoch:  191  	Training Loss: 0.00206966046243906
Test Loss:  0.001653545186854899
Valid Loss:  0.0024578466545790434
Epoch:  192  	Training Loss: 0.0020695840939879417
Test Loss:  0.0016534774331375957
Valid Loss:  0.002457756781950593
Epoch:  193  	Training Loss: 0.002069507958367467
Test Loss:  0.0016534089809283614
Valid Loss:  0.0024576683063060045
Epoch:  194  	Training Loss: 0.0020694327540695667
Test Loss:  0.001653337967582047
Valid Loss:  0.0024575809948146343
Epoch:  195  	Training Loss: 0.002069354522973299
Test Loss:  0.0016532670706510544
Valid Loss:  0.0024574934504926205
Epoch:  196  	Training Loss: 0.0020692767575383186
Test Loss:  0.0016531989676877856
Valid Loss:  0.0024574040435254574
Epoch:  197  	Training Loss: 0.002069199923425913
Test Loss:  0.0016531278379261494
Valid Loss:  0.00245731882750988
Epoch:  198  	Training Loss: 0.0020691233221441507
Test Loss:  0.0016530624125152826
Valid Loss:  0.0024572277907282114
Epoch:  199  	Training Loss: 0.0020690481178462505
Test Loss:  0.0016529911663383245
Valid Loss:  0.0024571395479142666
Epoch:  200  	Training Loss: 0.002068971749395132
Test Loss:  0.001652921549975872
Valid Loss:  0.0024570515379309654
Epoch:  201  	Training Loss: 0.0020688942167907953
Test Loss:  0.0016528514679521322
Valid Loss:  0.0024569646921008825
Epoch:  202  	Training Loss: 0.0020688166841864586
Test Loss:  0.0016527824336662889
Valid Loss:  0.0024568764492869377
Epoch:  203  	Training Loss: 0.0020687412470579147
Test Loss:  0.0016527152620255947
Valid Loss:  0.0024567903019487858
Epoch:  204  	Training Loss: 0.00206866511143744
Test Loss:  0.0016526468098163605
Valid Loss:  0.002456704853102565
Epoch:  205  	Training Loss: 0.0020685908384621143
Test Loss:  0.001652578474022448
Valid Loss:  0.0024566170759499073
Epoch:  206  	Training Loss: 0.0020685147028416395
Test Loss:  0.0016525093233212829
Valid Loss:  0.0024565288331359625
Epoch:  207  	Training Loss: 0.0020684378687292337
Test Loss:  0.0016524391248822212
Valid Loss:  0.002456442918628454
Epoch:  208  	Training Loss: 0.00206836243160069
Test Loss:  0.001652372069656849
Valid Loss:   42%|████▏     | 209/500 [02:24<01:35,  3.04it/s] 42%|████▏     | 211/500 [02:30<05:35,  1.16s/it] 43%|████▎     | 213/500 [02:30<03:59,  1.20it/s] 43%|████▎     | 215/500 [02:31<02:51,  1.66it/s] 43%|████▎     | 217/500 [02:31<02:04,  2.27it/s] 44%|████▍     | 219/500 [02:31<01:32,  3.04it/s] 44%|████▍     | 221/500 [02:37<05:24,  1.16s/it] 45%|████▍     | 223/500 [02:37<03:50,  1.20it/s] 45%|████▌     | 225/500 [02:37<02:45,  1.66it/s] 45%|████▌     | 227/500 [02:37<02:00,  2.27it/s] 46%|████▌     | 229/500 [02:38<01:28,  3.05it/s] 46%|████▌     | 231/500 [02:44<05:39,  1.26s/it] 47%|████▋     | 233/500 [02:45<04:01,  1.11it/s] 47%|████▋     | 235/500 [02:45<02:53,  1.53it/s] 47%|████▋     | 237/500 [02:45<02:05,  2.10it/s] 48%|████▊     | 239/500 [02:45<01:32,  2.83it/s] 48%|████▊     | 241/500 [02:51<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:51<03:38,  1.17it/s] 49%|████▉     | 245/500 [02:51<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:52<01:53,  2.22it/s] 50%|████▉     | 249/500 [02:52<01:23,  2.99it/s] 50%|█████     | 251/500 [02:58<05:00,  1.21s/it] 51%|█████     | 253/500 [02:58<03:34,  1.15it/s] 51%|█████     | 255/500 [02:58<02:33,  1.59it/s] 51%|█████▏    | 257/500 [02:59<01:51,  2.18it/s] 52%|█████▏    | 259/500 [02:59<01:21,  2.94it/s] 52%|█████▏    | 261/500 [03:05<04:51,  1.22s/it] 53%|█████▎    | 263/500 [03:05<03:28,  1.14it/s] 53%|█████▎    | 265/500 [03:06<02:30,  1.56it/s] 53%|█████▎    | 267/500 [03:06<01:50,  2.11it/s] 54%|█████▍    | 269/500 [03:06<01:22,  2.80it/s] 54%|█████▍    | 271/500 [03:12<04:35,  1.20s/it] 55%|█████▍    | 273/500 [03:12<03:17,  1.15it/s] 55%|█████▌    | 275/500 [03:13<02:21,  1.59it/s]0.002456354908645153
Epoch:  209  	Training Loss: 0.0020682865288108587
Test Loss:  0.0016523010563105345
Valid Loss:  0.0024562678299844265
Epoch:  210  	Training Loss: 0.002068211091682315
Test Loss:  0.0016522306250408292
Valid Loss:  0.002456182148307562
Epoch:  211  	Training Loss: 0.002068135654553771
Test Loss:  0.001652163453400135
Valid Loss:  0.002456093905493617
Epoch:  212  	Training Loss: 0.0020680592861026525
Test Loss:  0.0016520950011909008
Valid Loss:  0.0024560086894780397
Epoch:  213  	Training Loss: 0.0020679838489741087
Test Loss:  0.001652028877288103
Valid Loss:  0.0024559195153415203
Epoch:  214  	Training Loss: 0.0020679100416600704
Test Loss:  0.0016519587952643633
Valid Loss:  0.0024558380246162415
Epoch:  215  	Training Loss: 0.002067835535854101
Test Loss:  0.0016518912743777037
Valid Loss:  0.002455751411616802
Epoch:  216  	Training Loss: 0.0020677594002336264
Test Loss:  0.0016518211923539639
Valid Loss:  0.0024556624703109264
Epoch:  217  	Training Loss: 0.0020676851272583008
Test Loss:  0.0016517512267455459
Valid Loss:  0.002455577254295349
Epoch:  218  	Training Loss: 0.0020676101557910442
Test Loss:  0.001651691272854805
Valid Loss:  0.00245549320243299
Epoch:  219  	Training Loss: 0.0020675344858318567
Test Loss:  0.0016516258474439383
Valid Loss:  0.002455407753586769
Epoch:  220  	Training Loss: 0.002067460212856531
Test Loss:  0.0016515563474968076
Valid Loss:  0.0024553206749260426
Epoch:  221  	Training Loss: 0.002067386172711849
Test Loss:  0.001651490805670619
Valid Loss:  0.002455235691741109
Epoch:  222  	Training Loss: 0.00206731166690588
Test Loss:  0.0016514182789251208
Valid Loss:  0.0024551486130803823
Epoch:  223  	Training Loss: 0.0020672366954386234
Test Loss:  0.0016513580922037363
Valid Loss:  0.002455064794048667
Epoch:  224  	Training Loss: 0.002067162189632654
Test Loss:  0.0016512905713170767
Valid Loss:  0.0024549816735088825
Epoch:  225  	Training Loss: 0.0020670888479799032
Test Loss:  0.0016512232832610607
Valid Loss:  0.002454895293340087
Epoch:  226  	Training Loss: 0.0020670131780207157
Test Loss:  0.0016511555295437574
Valid Loss:  0.0024548075161874294
Epoch:  227  	Training Loss: 0.002066941000521183
Test Loss:  0.0016510861460119486
Valid Loss:  0.0024547227658331394
Epoch:  228  	Training Loss: 0.002066865097731352
Test Loss:  0.0016510237473994493
Valid Loss:  0.0024546394124627113
Epoch:  229  	Training Loss: 0.0020667915232479572
Test Loss:  0.001650955993682146
Valid Loss:  0.0024545537307858467
Epoch:  230  	Training Loss: 0.0020667167846113443
Test Loss:  0.0016508891712874174
Valid Loss:  0.0024544717743992805
Epoch:  231  	Training Loss: 0.0020666439086198807
Test Loss:  0.0016508223488926888
Valid Loss:  0.0024543837644159794
Epoch:  232  	Training Loss: 0.0020665698684751987
Test Loss:  0.0016507570398971438
Valid Loss:  0.002454301342368126
Epoch:  233  	Training Loss: 0.002066495828330517
Test Loss:  0.0016506882384419441
Valid Loss:  0.0024542114697396755
Epoch:  234  	Training Loss: 0.0020664234180003405
Test Loss:  0.001650625141337514
Valid Loss:  0.002454128349199891
Epoch:  235  	Training Loss: 0.002066347748041153
Test Loss:  0.001650556456297636
Valid Loss:  0.002454044297337532
Epoch:  236  	Training Loss: 0.0020662755705416203
Test Loss:  0.0016504914965480566
Valid Loss:  0.0024539621081203222
Epoch:  237  	Training Loss: 0.0020662022288888693
Test Loss:  0.001650421298108995
Valid Loss:  0.002453876892104745
Epoch:  238  	Training Loss: 0.0020661272574216127
Test Loss:  0.0016503590159118176
Valid Loss:  0.002453793305903673
Epoch:  239  	Training Loss: 0.0020660539157688618
Test Loss:  0.0016502884682267904
Valid Loss:  0.0024537043645977974
Epoch:  240  	Training Loss: 0.002065980341285467
Test Loss:  0.0016502264188602567
Valid Loss:  0.002453621942549944
Epoch:  241  	Training Loss: 0.0020659063011407852
Test Loss:  0.0016501573845744133
Valid Loss:  0.0024535381235182285
Epoch:  242  	Training Loss: 0.0020658355206251144
Test Loss:  0.0016500909114256501
Valid Loss:  0.0024534487165510654
Epoch:  243  	Training Loss: 0.0020657603163272142
Test Loss:  0.0016500243218615651
Valid Loss:  0.0024533653631806374
Epoch:  244  	Training Loss: 0.0020656881388276815
Test Loss:  0.0016499581979587674
Valid Loss:  0.0024532845709472895
Epoch:  245  	Training Loss: 0.002065614564344287
Test Loss:  0.0016498934710398316
Valid Loss:  0.0024531991221010685
Epoch:  246  	Training Loss: 0.0020655421540141106
Test Loss:  0.0016498258337378502
Valid Loss:  0.0024531169328838587
Epoch:  247  	Training Loss: 0.0020654688123613596
Test Loss:  0.0016497576143592596
Valid Loss:  0.002453029388561845
Epoch:  248  	Training Loss: 0.0020653950050473213
Test Loss:  0.001649694750085473
Valid Loss:  0.002452945802360773
Epoch:  249  	Training Loss: 0.0020653209649026394
Test Loss:  0.0016496286261826754
Valid Loss:  0.002452863147482276
Epoch:  250  	Training Loss: 0.002065247856080532
Test Loss:  0.0016495655290782452
Valid Loss:  0.0024527781642973423
Epoch:  251  	Training Loss: 0.0020651756785809994
Test Loss:  0.001649498357437551
Valid Loss:  0.002452695742249489
Epoch:  252  	Training Loss: 0.0020651021040976048
Test Loss:  0.0016494359588250518
Valid Loss:  0.002452611457556486
Epoch:  253  	Training Loss: 0.0020650301594287157
Test Loss:  0.0016493704169988632
Valid Loss:  0.0024525325279682875
Epoch:  254  	Training Loss: 0.0020649582147598267
Test Loss:  0.0016493072034791112
Valid Loss:  0.0024524484761059284
Epoch:  255  	Training Loss: 0.0020648872014135122
Test Loss:  0.0016492399154230952
Valid Loss:  0.002452366054058075
Epoch:  256  	Training Loss: 0.0020648138597607613
Test Loss:  0.0016491704154759645
Valid Loss:  0.0024522789753973484
Epoch:  257  	Training Loss: 0.002064740750938654
Test Loss:  0.0016491080168634653
Valid Loss:  0.002452199812978506
Epoch:  258  	Training Loss: 0.0020646704360842705
Test Loss:  0.0016490446869283915
Valid Loss:  0.0024521159939467907
Epoch:  259  	Training Loss: 0.0020645977929234505
Test Loss:  0.0016489801928400993
Valid Loss:  0.0024520335718989372
Epoch:  260  	Training Loss: 0.0020645237527787685
Test Loss:  0.0016489150002598763
Valid Loss:  0.002451952314004302
Epoch:  261  	Training Loss: 0.0020644532050937414
Test Loss:  0.0016488509718328714
Valid Loss:  0.0024518677964806557
Epoch:  262  	Training Loss: 0.002064381493255496
Test Loss:  0.0016487834509462118
Valid Loss:  0.002451786305755377
Epoch:  263  	Training Loss: 0.0020643093157559633
Test Loss:  0.0016487186076119542
Valid Loss:  0.002451702021062374
Epoch:  264  	Training Loss: 0.0020642352756112814
Test Loss:  0.0016486565582454205
Valid Loss:  0.0024516209959983826
Epoch:  265  	Training Loss: 0.0020641651935875416
Test Loss:  0.001648592296987772
Valid Loss:  0.0024515376426279545
Epoch:  266  	Training Loss: 0.0020640939474105835
Test Loss:  0.001648525008931756
Valid Loss:  0.0024514528922736645
Epoch:  267  	Training Loss: 0.0020640213042497635
Test Loss:  0.0016484525986015797
Valid Loss:  0.002451368374750018
Epoch:  268  	Training Loss: 0.002063948893919587
Test Loss:  0.0016483954386785626
Valid Loss:  0.0024512901436537504
Epoch:  269  	Training Loss: 0.00206387834623456
Test Loss:  0.0016483290819451213
Valid Loss:  0.002451207023113966
Epoch:  270  	Training Loss: 0.00206380570307374
Test Loss:  0.0016482656355947256
Valid Loss:  0.002451125532388687
Epoch:  271  	Training Loss: 0.002063735155388713
Test Loss:  0.0016482011415064335
Valid Loss:  0.0024510431103408337
Epoch:  272  	Training Loss: 0.0020636613480746746
Test Loss:  0.0016481371130794287
Valid Loss:  0.002450960222631693
Epoch:  273  	Training Loss: 0.002063591033220291
Test Loss:  0.0016480735503137112
Valid Loss:  0.0024508775677531958
Epoch:  274  	Training Loss: 0.0020635193213820457
Test Loss:  0.0016480071935802698
Valid Loss:  0.0024507958441972733
Epoch:  275  	Training Loss: 0.0020634480752050877
Test Loss:  0.0016479430487379432
Valid Loss:  0.0024507169146090746
Epoch:  276  	Training Loss: 0.002063377294689417
Test Loss:  0.0016478804172948003
Valid Loss:  0.00245063379406929
Epoch:  277  	Training Loss: 0.0020633055828511715
Test Loss:   55%|█████▌    | 277/500 [03:13<01:44,  2.14it/s] 56%|█████▌    | 279/500 [03:13<01:17,  2.84it/s] 56%|█████▌    | 281/500 [03:19<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:19<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:20<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:20<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:20<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:26<04:03,  1.17s/it] 59%|█████▊    | 293/500 [03:26<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:26<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:26<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:27<01:07,  2.98it/s] 60%|██████    | 301/500 [03:33<03:53,  1.18s/it] 61%|██████    | 303/500 [03:33<02:47,  1.18it/s] 61%|██████    | 305/500 [03:33<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:33<01:28,  2.18it/s] 62%|██████▏   | 309/500 [03:34<01:05,  2.93it/s] 62%|██████▏   | 311/500 [03:40<03:39,  1.16s/it] 63%|██████▎   | 313/500 [03:40<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:40<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:40<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:40<01:02,  2.92it/s] 64%|██████▍   | 321/500 [03:47<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:47<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:47<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:47<01:19,  2.17it/s] 66%|██████▌   | 329/500 [03:47<00:59,  2.87it/s] 66%|██████▌   | 331/500 [03:54<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:54<02:20,  1.18it/s] 67%|██████▋   | 335/500 [03:54<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:54<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:54<00:53,  3.01it/s] 68%|██████▊   | 341/500 [04:00<03:05,  1.16s/it] 69%|██████▊   | 343/500 [04:00<02:11,  1.20it/s] 69%|██████▉   | 345/500 [04:01<01:33,  1.65it/s]0.0016478156903758645
Valid Loss:  0.0024505499750375748
Epoch:  278  	Training Loss: 0.0020632350351661444
Test Loss:  0.0016477511962875724
Valid Loss:  0.002450469881296158
Epoch:  279  	Training Loss: 0.00206316402181983
Test Loss:  0.0016476890305057168
Valid Loss:  0.002450385596603155
Epoch:  280  	Training Loss: 0.0020630923099815845
Test Loss:  0.0016476226737722754
Valid Loss:  0.0024503078311681747
Epoch:  281  	Training Loss: 0.0020630210638046265
Test Loss:  0.001647554337978363
Valid Loss:  0.0024502230808138847
Epoch:  282  	Training Loss: 0.0020629516802728176
Test Loss:  0.0016474962467327714
Valid Loss:  0.002450142055749893
Epoch:  283  	Training Loss: 0.002062879502773285
Test Loss:  0.0016474304720759392
Valid Loss:  0.0024500624276697636
Epoch:  284  	Training Loss: 0.002062810119241476
Test Loss:  0.0016473685391247272
Valid Loss:  0.0024499823339283466
Epoch:  285  	Training Loss: 0.002062738174572587
Test Loss:  0.0016473042778670788
Valid Loss:  0.002449899446219206
Epoch:  286  	Training Loss: 0.002062666928395629
Test Loss:  0.0016472400166094303
Valid Loss:  0.002449819352477789
Epoch:  287  	Training Loss: 0.002062596147879958
Test Loss:  0.0016471764538437128
Valid Loss:  0.0024497390259057283
Epoch:  288  	Training Loss: 0.0020625279285013676
Test Loss:  0.0016471133567392826
Valid Loss:  0.002449656371027231
Epoch:  289  	Training Loss: 0.0020624552853405476
Test Loss:  0.0016470509581267834
Valid Loss:  0.0024495746474713087
Epoch:  290  	Training Loss: 0.002062385668978095
Test Loss:  0.001646985299885273
Valid Loss:  0.0024494933895766735
Epoch:  291  	Training Loss: 0.0020623148884624243
Test Loss:  0.0016469242982566357
Valid Loss:  0.002449413063004613
Epoch:  292  	Training Loss: 0.00206224387511611
Test Loss:  0.0016468607354909182
Valid Loss:  0.0024493332020938396
Epoch:  293  	Training Loss: 0.0020621726289391518
Test Loss:  0.0016467964742332697
Valid Loss:  0.002449252177029848
Epoch:  294  	Training Loss: 0.0020621030125766993
Test Loss:  0.001646734308451414
Valid Loss:  0.002449173480272293
Epoch:  295  	Training Loss: 0.002062033163383603
Test Loss:  0.0016466719098389149
Valid Loss:  0.002449090825393796
Epoch:  296  	Training Loss: 0.0020619628485292196
Test Loss:  0.00164660788141191
Valid Loss:  0.0024490095674991608
Epoch:  297  	Training Loss: 0.002061893232166767
Test Loss:  0.001646540011279285
Valid Loss:  0.002448929473757744
Epoch:  298  	Training Loss: 0.002061823382973671
Test Loss:  0.0016464811051264405
Valid Loss:  0.0024488535709679127
Epoch:  299  	Training Loss: 0.0020617530681192875
Test Loss:  0.0016464157961308956
Valid Loss:  0.002448768587782979
Epoch:  300  	Training Loss: 0.0020616818219423294
Test Loss:  0.0016463538631796837
Valid Loss:  0.0024486875627189875
Epoch:  301  	Training Loss: 0.0020616124384105206
Test Loss:  0.0016462914645671844
Valid Loss:  0.002448609098792076
Epoch:  302  	Training Loss: 0.0020615430548787117
Test Loss:  0.0016462288331240416
Valid Loss:  0.002448528539389372
Epoch:  303  	Training Loss: 0.002061472274363041
Test Loss:  0.0016461631748825312
Valid Loss:  0.0024484489113092422
Epoch:  304  	Training Loss: 0.0020614019595086575
Test Loss:  0.0016461026389151812
Valid Loss:  0.0024483678862452507
Epoch:  305  	Training Loss: 0.002061333041638136
Test Loss:  0.0016460367478430271
Valid Loss:  0.0024482919834554195
Epoch:  306  	Training Loss: 0.0020612631924450397
Test Loss:  0.001645977608859539
Valid Loss:  0.0024482067674398422
Epoch:  307  	Training Loss: 0.002061193808913231
Test Loss:  0.001645911717787385
Valid Loss:  0.0024481245782226324
Epoch:  308  	Training Loss: 0.002061125123873353
Test Loss:  0.0016458509489893913
Valid Loss:  0.0024480486754328012
Epoch:  309  	Training Loss: 0.0020610548090189695
Test Loss:  0.0016457890160381794
Valid Loss:  0.0024479692801833153
Epoch:  310  	Training Loss: 0.0020609847269952297
Test Loss:  0.0016457273159176111
Valid Loss:  0.0024478870909661055
Epoch:  311  	Training Loss: 0.002060915809124708
Test Loss:  0.0016456630546599627
Valid Loss:  0.002447807462885976
Epoch:  312  	Training Loss: 0.0020608450286090374
Test Loss:  0.0016455994918942451
Valid Loss:  0.002447727834805846
Epoch:  313  	Training Loss: 0.0020607770420610905
Test Loss:  0.0016455382574349642
Valid Loss:  0.0024476482067257166
Epoch:  314  	Training Loss: 0.0020607071928679943
Test Loss:  0.0016454783035442233
Valid Loss:  0.002447568578645587
Epoch:  315  	Training Loss: 0.0020606382749974728
Test Loss:  0.0016454106662422419
Valid Loss:  0.002447486389428377
Epoch:  316  	Training Loss: 0.0020605698227882385
Test Loss:  0.0016453498974442482
Valid Loss:  0.0024474107194691896
Epoch:  317  	Training Loss: 0.0020605013705790043
Test Loss:  0.0016452888958156109
Valid Loss:  0.002447329694405198
Epoch:  318  	Training Loss: 0.002060431055724621
Test Loss:  0.0016452264972031116
Valid Loss:  0.0024472482036799192
Epoch:  319  	Training Loss: 0.002060361672192812
Test Loss:  0.0016451622359454632
Valid Loss:  0.002447172300890088
Epoch:  320  	Training Loss: 0.0020602927543222904
Test Loss:  0.0016451016999781132
Valid Loss:  0.0024470940697938204
Epoch:  321  	Training Loss: 0.0020602236036211252
Test Loss:  0.0016450416296720505
Valid Loss:  0.002447017002850771
Epoch:  322  	Training Loss: 0.00206015445291996
Test Loss:  0.0016449805116280913
Valid Loss:  0.002446934347972274
Epoch:  323  	Training Loss: 0.0020600866992026567
Test Loss:  0.0016449176473543048
Valid Loss:  0.0024468563497066498
Epoch:  324  	Training Loss: 0.0020600170828402042
Test Loss:  0.0016448532696813345
Valid Loss:  0.002446774858981371
Epoch:  325  	Training Loss: 0.002059949329122901
Test Loss:  0.0016447955276817083
Valid Loss:  0.002446698024868965
Epoch:  326  	Training Loss: 0.002059880644083023
Test Loss:  0.0016447306843474507
Valid Loss:  0.002446621423587203
Epoch:  327  	Training Loss: 0.002059811959043145
Test Loss:  0.0016446709632873535
Valid Loss:  0.002446542028337717
Epoch:  328  	Training Loss: 0.00205974280834198
Test Loss:  0.0016446072841063142
Valid Loss:  0.002446463331580162
Epoch:  329  	Training Loss: 0.0020596738904714584
Test Loss:  0.0016445470973849297
Valid Loss:  0.0024463834706693888
Epoch:  330  	Training Loss: 0.0020596047397702932
Test Loss:  0.0016444853972643614
Valid Loss:  0.0024463047739118338
Epoch:  331  	Training Loss: 0.00205953698605299
Test Loss:  0.001644423813559115
Valid Loss:  0.002446227241307497
Epoch:  332  	Training Loss: 0.002059468999505043
Test Loss:  0.0016443575732409954
Valid Loss:  0.002446145983412862
Epoch:  333  	Training Loss: 0.002059399615973234
Test Loss:  0.001644291216507554
Valid Loss:  0.0024460661225020885
Epoch:  334  	Training Loss: 0.002059332560747862
Test Loss:  0.0016442341729998589
Valid Loss:  0.0024459902197122574
Epoch:  335  	Training Loss: 0.0020592636428773403
Test Loss:  0.0016441729385405779
Valid Loss:  0.0024459119886159897
Epoch:  336  	Training Loss: 0.002059195190668106
Test Loss:  0.0016441128682345152
Valid Loss:  0.0024458335246890783
Epoch:  337  	Training Loss: 0.002059127204120159
Test Loss:  0.0016440526815131307
Valid Loss:  0.002445751568302512
Epoch:  338  	Training Loss: 0.002059058053418994
Test Loss:  0.0016439887695014477
Valid Loss:  0.002445676364004612
Epoch:  339  	Training Loss: 0.002058990765362978
Test Loss:  0.0016439304454252124
Valid Loss:  0.0024455967359244823
Epoch:  340  	Training Loss: 0.0020589230116456747
Test Loss:  0.0016438676975667477
Valid Loss:  0.0024455199018120766
Epoch:  341  	Training Loss: 0.0020588552579283714
Test Loss:  0.0016438064631074667
Valid Loss:  0.0024454412050545216
Epoch:  342  	Training Loss: 0.0020587854087352753
Test Loss:  0.0016437498852610588
Valid Loss:  0.002445363672450185
Epoch:  343  	Training Loss: 0.0020587188191711903
Test Loss:  0.0016436867881566286
Valid Loss:  0.0024452852085232735
Epoch:  344  	Training Loss: 0.0020586508326232433
Test Loss:  0.0016436269506812096
Valid Loss:  0.002445208840072155
Epoch:  345  	Training Loss: 0.0020585847087204456
Test Loss:  0.0016435657162219286
Valid Loss:  0.0024451324716210365
Epoch:  346  	Training Loss: 0.0020585162565112114
 69%|██████▉   | 347/500 [04:01<01:07,  2.26it/s] 70%|██████▉   | 349/500 [04:01<00:49,  3.03it/s] 70%|███████   | 351/500 [04:07<02:54,  1.17s/it] 71%|███████   | 353/500 [04:07<02:03,  1.19it/s] 71%|███████   | 355/500 [04:07<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:07<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:08<00:46,  3.03it/s] 72%|███████▏  | 361/500 [04:14<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:14<01:54,  1.19it/s] 73%|███████▎  | 365/500 [04:14<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:14<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:14<00:43,  3.03it/s] 74%|███████▍  | 371/500 [04:21<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:21<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:21<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:21<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:21<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:28<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:28<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:28<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:28<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:28<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:34<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:34<01:28,  1.20it/s] 79%|███████▉  | 395/500 [04:34<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:35<00:45,  2.27it/s] 80%|███████▉  | 399/500 [04:35<00:33,  3.06it/s] 80%|████████  | 401/500 [04:41<01:57,  1.19s/it] 81%|████████  | 403/500 [04:41<01:22,  1.17it/s] 81%|████████  | 405/500 [04:41<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:42<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:42<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:48<01:46,  1.20s/it] 83%|████████▎ | 413/500 [04:48<01:14,  1.16it/s]Test Loss:  0.001643502851948142
Valid Loss:  0.002445052843540907
Epoch:  347  	Training Loss: 0.0020584482699632645
Test Loss:  0.0016434427816420794
Valid Loss:  0.0024449783377349377
Epoch:  348  	Training Loss: 0.002058381214737892
Test Loss:  0.001643375726416707
Valid Loss:  0.002444896847009659
Epoch:  349  	Training Loss: 0.0020583118312060833
Test Loss:  0.001643317868001759
Valid Loss:  0.002444818615913391
Epoch:  350  	Training Loss: 0.0020582445431500673
Test Loss:  0.0016432604752480984
Valid Loss:  0.0024447424802929163
Epoch:  351  	Training Loss: 0.0020581758581101894
Test Loss:  0.00164319877512753
Valid Loss:  0.002444665879011154
Epoch:  352  	Training Loss: 0.002058109501376748
Test Loss:  0.001643134979531169
Valid Loss:  0.00244458531960845
Epoch:  353  	Training Loss: 0.002058042911812663
Test Loss:  0.00164307770319283
Valid Loss:  0.0024445063900202513
Epoch:  354  	Training Loss: 0.002057974925264716
Test Loss:  0.0016430150717496872
Valid Loss:  0.002444428624585271
Epoch:  355  	Training Loss: 0.0020579067058861256
Test Loss:  0.001642953953705728
Valid Loss:  0.002444353885948658
Epoch:  356  	Training Loss: 0.0020578382536768913
Test Loss:  0.0016428926028311253
Valid Loss:  0.002444275189191103
Epoch:  357  	Training Loss: 0.0020577723626047373
Test Loss:  0.0016428329981863499
Valid Loss:  0.002444199286401272
Epoch:  358  	Training Loss: 0.002057704608887434
Test Loss:  0.0016427726950496435
Valid Loss:  0.0024441201239824295
Epoch:  359  	Training Loss: 0.0020576377864927053
Test Loss:  0.001642715185880661
Valid Loss:  0.0024440428242087364
Epoch:  360  	Training Loss: 0.0020575695671141148
Test Loss:  0.0016426515066996217
Valid Loss:  0.002443965058773756
Epoch:  361  	Training Loss: 0.002057502744719386
Test Loss:  0.001642592833377421
Valid Loss:  0.002443886362016201
Epoch:  362  	Training Loss: 0.0020574331283569336
Test Loss:  0.0016425246139988303
Valid Loss:  0.0024438060354441404
Epoch:  363  	Training Loss: 0.0020573679357767105
Test Loss:  0.0016424695495516062
Valid Loss:  0.002443732926622033
Epoch:  364  	Training Loss: 0.002057299017906189
Test Loss:  0.0016424087807536125
Valid Loss:  0.002443654229864478
Epoch:  365  	Training Loss: 0.002057232428342104
Test Loss:  0.0016423488268628716
Valid Loss:  0.0024435766972601414
Epoch:  366  	Training Loss: 0.002057167235761881
Test Loss:  0.0016422879416495562
Valid Loss:  0.002443500328809023
Epoch:  367  	Training Loss: 0.0020570997148752213
Test Loss:  0.00164222891908139
Valid Loss:  0.0024434246588498354
Epoch:  368  	Training Loss: 0.0020570310298353434
Test Loss:  0.001642167684622109
Valid Loss:  0.002443346194922924
Epoch:  369  	Training Loss: 0.0020569651387631893
Test Loss:  0.0016421076143160462
Valid Loss:  0.002443270292133093
Epoch:  370  	Training Loss: 0.0020568971522152424
Test Loss:  0.0016420474275946617
Valid Loss:  0.0024431929923594
Epoch:  371  	Training Loss: 0.002056831493973732
Test Loss:  0.0016419879393652081
Valid Loss:  0.002443116158246994
Epoch:  372  	Training Loss: 0.0020567653700709343
Test Loss:  0.0016419277526438236
Valid Loss:  0.0024430397897958755
Epoch:  373  	Training Loss: 0.0020566964522004128
Test Loss:  0.0016418620944023132
Valid Loss:  0.002442961558699608
Epoch:  374  	Training Loss: 0.0020566312596201897
Test Loss:  0.0016418088926002383
Valid Loss:  0.0024428912438452244
Epoch:  375  	Training Loss: 0.0020565653685480356
Test Loss:  0.001641746493987739
Valid Loss:  0.0024428111501038074
Epoch:  376  	Training Loss: 0.0020564980804920197
Test Loss:  0.0016416878206655383
Valid Loss:  0.002442736877128482
Epoch:  377  	Training Loss: 0.00205643055960536
Test Loss:  0.0016416284488514066
Valid Loss:  0.0024426591116935015
Epoch:  378  	Training Loss: 0.0020563644357025623
Test Loss:  0.0016415688442066312
Valid Loss:  0.0024425836745649576
Epoch:  379  	Training Loss: 0.0020562990102916956
Test Loss:  0.0016415093559771776
Valid Loss:  0.002442503347992897
Epoch:  380  	Training Loss: 0.0020562305580824614
Test Loss:  0.0016414490528404713
Valid Loss:  0.002442427910864353
Epoch:  381  	Training Loss: 0.0020561651326715946
Test Loss:  0.001641388051211834
Valid Loss:  0.0024423543363809586
Epoch:  382  	Training Loss: 0.002056099008768797
Test Loss:  0.0016413283301517367
Valid Loss:  0.00244227796792984
Epoch:  383  	Training Loss: 0.0020560328848659992
Test Loss:  0.0016412711702287197
Valid Loss:  0.0024422015994787216
Epoch:  384  	Training Loss: 0.002055967226624489
Test Loss:  0.001641209702938795
Valid Loss:  0.0024421242997050285
Epoch:  385  	Training Loss: 0.0020559015683829784
Test Loss:  0.001641150563955307
Valid Loss:  0.0024420488625764847
Epoch:  386  	Training Loss: 0.0020558354444801807
Test Loss:  0.001641090726479888
Valid Loss:  0.002441973192617297
Epoch:  387  	Training Loss: 0.0020557697862386703
Test Loss:  0.0016410317039117217
Valid Loss:  0.0024418989196419716
Epoch:  388  	Training Loss: 0.0020557024981826544
Test Loss:  0.0016409740783274174
Valid Loss:  0.0024418230168521404
Epoch:  389  	Training Loss: 0.0020556370727717876
Test Loss:  0.0016409131931141019
Valid Loss:  0.002441743854433298
Epoch:  390  	Training Loss: 0.0020555718801915646
Test Loss:  0.0016408544033765793
Valid Loss:  0.002441670745611191
Epoch:  391  	Training Loss: 0.0020555048249661922
Test Loss:  0.0016407951479777694
Valid Loss:  0.002441597171127796
Epoch:  392  	Training Loss: 0.0020554373040795326
Test Loss:  0.0016407372895628214
Valid Loss:  0.0024415194056928158
Epoch:  393  	Training Loss: 0.0020553735084831715
Test Loss:  0.0016406753566116095
Valid Loss:  0.0024414444342255592
Epoch:  394  	Training Loss: 0.002055307850241661
Test Loss:  0.0016406169161200523
Valid Loss:  0.00244136992841959
Epoch:  395  	Training Loss: 0.002055242657661438
Test Loss:  0.0016405583592131734
Valid Loss:  0.002441295888274908
Epoch:  396  	Training Loss: 0.002055177930742502
Test Loss:  0.0016405010828748345
Valid Loss:  0.0024412181228399277
Epoch:  397  	Training Loss: 0.0020551104098558426
Test Loss:  0.0016404378693550825
Valid Loss:  0.00244114245288074
Epoch:  398  	Training Loss: 0.002055046148598194
Test Loss:  0.0016403808258473873
Valid Loss:  0.0024410688783973455
Epoch:  399  	Training Loss: 0.002054979559034109
Test Loss:  0.0016403216868638992
Valid Loss:  0.002440991811454296
Epoch:  400  	Training Loss: 0.0020549141336232424
Test Loss:  0.0016402618493884802
Valid Loss:  0.002440917771309614
Epoch:  401  	Training Loss: 0.0020548489410430193
Test Loss:  0.0016402024775743484
Valid Loss:  0.0024408409371972084
Epoch:  402  	Training Loss: 0.002054783748462796
Test Loss:  0.0016401439206674695
Valid Loss:  0.002440767828375101
Epoch:  403  	Training Loss: 0.002054717391729355
Test Loss:  0.0016400846652686596
Valid Loss:  0.0024406909942626953
Epoch:  404  	Training Loss: 0.0020546521991491318
Test Loss:  0.001640027156099677
Valid Loss:  0.0024406174197793007
Epoch:  405  	Training Loss: 0.0020545872393995523
Test Loss:  0.0016399672022089362
Valid Loss:  0.0024405389558523893
Epoch:  406  	Training Loss: 0.002054520882666111
Test Loss:  0.0016399105079472065
Valid Loss:  0.002440469339489937
Epoch:  407  	Training Loss: 0.0020544566214084625
Test Loss:  0.0016398528823629022
Valid Loss:  0.002440391108393669
Epoch:  408  	Training Loss: 0.002054392360150814
Test Loss:  0.0016397919971495867
Valid Loss:  0.002440317068248987
Epoch:  409  	Training Loss: 0.0020543255377560854
Test Loss:  0.0016397314611822367
Valid Loss:  0.002440238371491432
Epoch:  410  	Training Loss: 0.0020542610436677933
Test Loss:  0.0016396749997511506
Valid Loss:  0.0024401661939918995
Epoch:  411  	Training Loss: 0.0020541977137327194
Test Loss:  0.0016396178398281336
Valid Loss:  0.002440091921016574
Epoch:  412  	Training Loss: 0.0020541308913379908
Test Loss:  0.001639561727643013
Valid Loss:  0.0024400190450251102
Epoch:  413  	Training Loss: 0.0020540673285722733
Test Loss:  0.001639502472244203
Valid Loss:  0.002439944539219141
Epoch:  414  	Training Loss: 0.002054001670330763
Test Loss:  0.0016394434496760368
Valid Loss:  0.0024398707319051027
Epoch:  415  	Training Loss: 0.0020539378747344017
 83%|████████▎ | 415/500 [04:48<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:49<00:37,  2.20it/s] 84%|████████▍ | 419/500 [04:49<00:27,  2.96it/s] 84%|████████▍ | 421/500 [04:55<01:34,  1.19s/it] 85%|████████▍ | 423/500 [04:55<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:55<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:55<00:33,  2.21it/s] 86%|████████▌ | 429/500 [04:56<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:02<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:02<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:02<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:02<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:02<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:09<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:09<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:09<00:34,  1.59it/s] 89%|████████▉ | 447/500 [05:09<00:24,  2.18it/s] 90%|████████▉ | 449/500 [05:09<00:17,  2.94it/s] 90%|█████████ | 451/500 [05:16<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:16<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:16<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:16<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:16<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:22<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:23<00:30,  1.19it/s] 93%|█████████▎| 465/500 [05:23<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:23<00:14,  2.26it/s] 94%|█████████▍| 469/500 [05:23<00:10,  3.03it/s] 94%|█████████▍| 471/500 [05:29<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:29<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:30<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:30<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:30<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:36<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:36<00:14,  1.18it/s]Test Loss:  0.0016393862897530198
Valid Loss:  0.002439795760437846
Epoch:  416  	Training Loss: 0.0020538726821541786
Test Loss:  0.0016393224941566586
Valid Loss:  0.0024397168308496475
Epoch:  417  	Training Loss: 0.0020538067910820246
Test Loss:  0.0016392673132941127
Valid Loss:  0.002439647912979126
Epoch:  418  	Training Loss: 0.002053743228316307
Test Loss:  0.0016392100369557738
Valid Loss:  0.0024395729415118694
Epoch:  419  	Training Loss: 0.002053676638752222
Test Loss:  0.0016391495009884238
Valid Loss:  0.002439497271552682
Epoch:  420  	Training Loss: 0.0020536130759865046
Test Loss:  0.0016390938544645905
Valid Loss:  0.0024394243955612183
Epoch:  421  	Training Loss: 0.002053549513220787
Test Loss:  0.001639035064727068
Valid Loss:  0.0024393494240939617
Epoch:  422  	Training Loss: 0.002053483622148633
Test Loss:  0.0016389719676226377
Valid Loss:  0.0024392707273364067
Epoch:  423  	Training Loss: 0.0020534179639071226
Test Loss:  0.0016389177180826664
Valid Loss:  0.0024392004124820232
Epoch:  424  	Training Loss: 0.0020533541683107615
Test Loss:  0.0016388604417443275
Valid Loss:  0.0024391256738454103
Epoch:  425  	Training Loss: 0.002053289208561182
Test Loss:  0.0016388020012527704
Valid Loss:  0.0024390514008700848
Epoch:  426  	Training Loss: 0.002053225878626108
Test Loss:  0.0016387442592531443
Valid Loss:  0.00243897526524961
Epoch:  427  	Training Loss: 0.0020531611517071724
Test Loss:  0.0016386869829148054
Valid Loss:  0.002438903786242008
Epoch:  428  	Training Loss: 0.0020530959591269493
Test Loss:  0.0016386262141168118
Valid Loss:  0.0024388269521296024
Epoch:  429  	Training Loss: 0.00205303099937737
Test Loss:  0.0016385703347623348
Valid Loss:  0.002438755938783288
Epoch:  430  	Training Loss: 0.0020529665052890778
Test Loss:  0.0016385128255933523
Valid Loss:  0.0024386767763644457
Epoch:  431  	Training Loss: 0.0020529008470475674
Test Loss:  0.0016384542686864734
Valid Loss:  0.0024386048316955566
Epoch:  432  	Training Loss: 0.0020528375171124935
Test Loss:  0.0016383938491344452
Valid Loss:  0.0024385331198573112
Epoch:  433  	Training Loss: 0.002052772557362914
Test Loss:  0.0016383363399654627
Valid Loss:  0.0024384595453739166
Epoch:  434  	Training Loss: 0.002052708761766553
Test Loss:  0.0016382762696594
Valid Loss:  0.0024383841082453728
Epoch:  435  	Training Loss: 0.002052645431831479
Test Loss:  0.001638223184272647
Valid Loss:  0.0024383142590522766
Epoch:  436  	Training Loss: 0.0020525814034044743
Test Loss:  0.001638164627365768
Valid Loss:  0.002438236027956009
Epoch:  437  	Training Loss: 0.0020525166764855385
Test Loss:  0.00163810676895082
Valid Loss:  0.0024381629191339016
Epoch:  438  	Training Loss: 0.0020524528808891773
Test Loss:  0.0016380499582737684
Valid Loss:  0.002438091207295656
Epoch:  439  	Training Loss: 0.002052387921139598
Test Loss:  0.0016379927983507514
Valid Loss:  0.002438017399981618
Epoch:  440  	Training Loss: 0.0020523248240351677
Test Loss:  0.0016379293520003557
Valid Loss:  0.002437944058328867
Epoch:  441  	Training Loss: 0.0020522605627775192
Test Loss:  0.0016378785949200392
Valid Loss:  0.0024378690868616104
Epoch:  442  	Training Loss: 0.00205219560302794
Test Loss:  0.0016378219006583095
Valid Loss:  0.0024377964437007904
Epoch:  443  	Training Loss: 0.002052133437246084
Test Loss:  0.0016377635765820742
Valid Loss:  0.002437721937894821
Epoch:  444  	Training Loss: 0.0020520694088190794
Test Loss:  0.0016377081628888845
Valid Loss:  0.002437648130580783
Epoch:  445  	Training Loss: 0.0020520046819001436
Test Loss:  0.0016376443672925234
Valid Loss:  0.0024375775828957558
Epoch:  446  	Training Loss: 0.002051940653473139
Test Loss:  0.0016375898849219084
Valid Loss:  0.0024375030770897865
Epoch:  447  	Training Loss: 0.0020518782548606396
Test Loss:  0.0016375351697206497
Valid Loss:  0.002437431598082185
Epoch:  448  	Training Loss: 0.002051813993602991
Test Loss:  0.0016374759143218398
Valid Loss:  0.002437357557937503
Epoch:  449  	Training Loss: 0.0020517511293292046
Test Loss:  0.001637419918552041
Valid Loss:  0.002437285613268614
Epoch:  450  	Training Loss: 0.002051685471087694
Test Loss:  0.0016373591497540474
Valid Loss:  0.0024372136685997248
Epoch:  451  	Training Loss: 0.0020516235381364822
Test Loss:  0.0016373032703995705
Valid Loss:  0.002437140792608261
Epoch:  452  	Training Loss: 0.0020515599753707647
Test Loss:  0.0016372459940612316
Valid Loss:  0.002437063492834568
Epoch:  453  	Training Loss: 0.0020514964126050472
Test Loss:  0.0016371902311220765
Valid Loss:  0.0024369910825043917
Epoch:  454  	Training Loss: 0.0020514330826699734
Test Loss:  0.0016371321398764849
Valid Loss:  0.0024369170423597097
Epoch:  455  	Training Loss: 0.002051369985565543
Test Loss:  0.0016370713710784912
Valid Loss:  0.0024368460290133953
Epoch:  456  	Training Loss: 0.002051306189969182
Test Loss:  0.001637020381167531
Valid Loss:  0.0024367724545300007
Epoch:  457  	Training Loss: 0.002051243092864752
Test Loss:  0.0016369624063372612
Valid Loss:  0.0024367033038288355
Epoch:  458  	Training Loss: 0.0020511802285909653
Test Loss:  0.0016369044315069914
Valid Loss:  0.00243662903085351
Epoch:  459  	Training Loss: 0.002051115967333317
Test Loss:  0.0016368471551686525
Valid Loss:  0.0024365545250475407
Epoch:  460  	Training Loss: 0.0020510535687208176
Test Loss:  0.001636788947507739
Valid Loss:  0.002436480950564146
Epoch:  461  	Training Loss: 0.0020509883761405945
Test Loss:  0.001636734465137124
Valid Loss:  0.0024364085402339697
Epoch:  462  	Training Loss: 0.002050926210358739
Test Loss:  0.0016366768395528197
Valid Loss:  0.002436336362734437
Epoch:  463  	Training Loss: 0.0020508633460849524
Test Loss:  0.0016366234049201012
Valid Loss:  0.002436266513541341
Epoch:  464  	Training Loss: 0.0020508000161498785
Test Loss:  0.0016365647315979004
Valid Loss:  0.0024361955001950264
Epoch:  465  	Training Loss: 0.0020507373847067356
Test Loss:  0.001636503147892654
Valid Loss:  0.0024361186660826206
Epoch:  466  	Training Loss: 0.0020506735891103745
Test Loss:  0.0016364523908123374
Valid Loss:  0.0024360492825508118
Epoch:  467  	Training Loss: 0.0020506104920059443
Test Loss:  0.0016363956965506077
Valid Loss:  0.0024359766393899918
Epoch:  468  	Training Loss: 0.0020505492575466633
Test Loss:  0.0016363373724743724
Valid Loss:  0.0024359035305678844
Epoch:  469  	Training Loss: 0.002050484996289015
Test Loss:  0.0016362756723538041
Valid Loss:  0.0024358276277780533
Epoch:  470  	Training Loss: 0.002050421666353941
Test Loss:  0.0016362247988581657
Valid Loss:  0.00243575987406075
Epoch:  471  	Training Loss: 0.002050359034910798
Test Loss:  0.0016361676389351487
Valid Loss:  0.002435685833916068
Epoch:  472  	Training Loss: 0.0020502950064837933
Test Loss:  0.0016361098969355226
Valid Loss:  0.002435613190755248
Epoch:  473  	Training Loss: 0.0020502335391938686
Test Loss:  0.0016360492445528507
Valid Loss:  0.002435538452118635
Epoch:  474  	Training Loss: 0.0020501697435975075
Test Loss:  0.0016359988367184997
Valid Loss:  0.0024354723282158375
Epoch:  475  	Training Loss: 0.002050107577815652
Test Loss:  0.0016359409783035517
Valid Loss:  0.002435399452224374
Epoch:  476  	Training Loss: 0.002050044946372509
Test Loss:  0.001635886263102293
Valid Loss:  0.0024353228509426117
Epoch:  477  	Training Loss: 0.002049983013421297
Test Loss:  0.0016358293360099196
Valid Loss:  0.0024352525360882282
Epoch:  478  	Training Loss: 0.0020499196834862232
Test Loss:  0.0016357674030587077
Valid Loss:  0.0024351789616048336
Epoch:  479  	Training Loss: 0.002049855887889862
Test Loss:  0.001635716063901782
Valid Loss:  0.002435112837702036
Epoch:  480  	Training Loss: 0.00204979395493865
Test Loss:  0.0016356606502085924
Valid Loss:  0.00243503600358963
Epoch:  481  	Training Loss: 0.002049731556326151
Test Loss:  0.0016356040723621845
Valid Loss:  0.0024349670857191086
Epoch:  482  	Training Loss: 0.0020496691577136517
Test Loss:  0.0016355460975319147
Valid Loss:  0.00243489071726799
Epoch:  483  	Training Loss: 0.0020496074575930834
Test Loss:  0.0016354926628991961
Valid Loss:  0.0024348238948732615
 97%|█████████▋| 485/500 [05:36<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:37<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:37<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:43<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:43<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:43<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:43<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:43<00:00,  3.01it/s]100%|██████████| 500/500 [05:44<00:00,  1.45it/s]
Epoch:  484  	Training Loss: 0.002049543894827366
Test Loss:  0.0016354381805285811
Valid Loss:  0.002434752183035016
Epoch:  485  	Training Loss: 0.0020494821947067976
Test Loss:  0.0016353798564523458
Valid Loss:  0.002434678841382265
Epoch:  486  	Training Loss: 0.0020494204945862293
Test Loss:  0.0016353195533156395
Valid Loss:  0.0024346034042537212
Epoch:  487  	Training Loss: 0.002049356931820512
Test Loss:  0.0016352685634046793
Valid Loss:  0.0024345361161977053
Epoch:  488  	Training Loss: 0.0020492952316999435
Test Loss:  0.0016352126840502024
Valid Loss:  0.002434465801343322
Epoch:  489  	Training Loss: 0.0020492319017648697
Test Loss:  0.0016351533122360706
Valid Loss:  0.0024343887344002724
Epoch:  490  	Training Loss: 0.0020491699688136578
Test Loss:  0.0016351010417565703
Valid Loss:  0.0024343200493603945
Epoch:  491  	Training Loss: 0.002049107104539871
Test Loss:  0.001635044114664197
Valid Loss:  0.002434247173368931
Epoch:  492  	Training Loss: 0.002049045404419303
Test Loss:  0.0016349863726645708
Valid Loss:  0.002434174995869398
Epoch:  493  	Training Loss: 0.002048984169960022
Test Loss:  0.001634928397834301
Valid Loss:  0.0024341046810150146
Epoch:  494  	Training Loss: 0.002048920840024948
Test Loss:  0.0016348755452781916
Valid Loss:  0.0024340341333299875
Epoch:  495  	Training Loss: 0.0020488600712269545
Test Loss:  0.0016348203644156456
Valid Loss:  0.0024339635856449604
Epoch:  496  	Training Loss: 0.0020487969741225243
Test Loss:  0.0016347640193998814
Valid Loss:  0.0024338907096534967
Epoch:  497  	Training Loss: 0.002048735972493887
Test Loss:  0.0016347034834325314
Valid Loss:  0.0024338141083717346
Epoch:  498  	Training Loss: 0.002048671944066882
Test Loss:  0.0016346522606909275
Valid Loss:  0.002433749381452799
Epoch:  499  	Training Loss: 0.002048611408099532
Test Loss:  0.0016345957992598414
Valid Loss:  0.002433674642816186
Epoch:  500  	Training Loss: 0.0020485487766563892
Test Loss:  0.0016345351468771696
Valid Loss:  0.0024336043279618025
seed is  5
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:42,  6.22s/it]  1%|          | 3/500 [00:06<13:52,  1.67s/it]  1%|          | 5/500 [00:06<07:04,  1.17it/s]  1%|▏         | 7/500 [00:06<04:21,  1.89it/s]  2%|▏         | 9/500 [00:06<02:58,  2.76it/s]  2%|▏         | 11/500 [00:13<10:59,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:20<09:51,  1.23s/it]  5%|▍         | 23/500 [00:20<06:58,  1.14it/s]  5%|▌         | 25/500 [00:20<04:59,  1.59it/s]  5%|▌         | 27/500 [00:20<03:37,  2.18it/s]  6%|▌         | 29/500 [00:20<02:39,  2.94it/s]  6%|▌         | 31/500 [00:27<09:11,  1.18s/it]  7%|▋         | 33/500 [00:27<06:34,  1.19it/s]  7%|▋         | 35/500 [00:27<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<09:05,  1.19s/it]  9%|▊         | 43/500 [00:34<06:28,  1.18it/s]  9%|▉         | 45/500 [00:34<04:39,  1.63it/s]  9%|▉         | 47/500 [00:34<03:23,  2.23it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:59,  1.20s/it] 11%|█         | 53/500 [00:41<06:24,  1.16it/s] 11%|█         | 55/500 [00:41<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.96it/s] 12%|█▏        | 61/500 [00:47<08:51,  1.21s/it] 13%|█▎        | 63/500 [00:48<06:19,  1.15it/s] 13%|█▎        | 65/500 [00:48<04:32,  1.59it/s] 13%|█▎        | 67/500 [00:48<03:18,  2.18it/s] 14%|█▍        | 69/500 [00:48<02:26,  2.94it/s]Epoch:  1  	Training Loss: 0.2061637043952942
Test Loss:  0.1331665813922882
Valid Loss:  0.13582193851470947
Epoch:  2  	Training Loss: 0.12830491364002228
Test Loss:  0.11050547659397125
Valid Loss:  0.11324428021907806
Epoch:  3  	Training Loss: 0.10684086382389069
Test Loss:  0.09624850004911423
Valid Loss:  0.09897194802761078
Epoch:  4  	Training Loss: 0.09327255189418793
Test Loss:  0.08375658094882965
Valid Loss:  0.08644767105579376
Epoch:  5  	Training Loss: 0.08137540519237518
Test Loss:  0.07291537523269653
Valid Loss:  0.07557078450918198
Epoch:  6  	Training Loss: 0.07107100635766983
Test Loss:  0.06359082460403442
Valid Loss:  0.06620313227176666
Epoch:  7  	Training Loss: 0.062213052064180374
Test Loss:  0.055584363639354706
Valid Loss:  0.05814236402511597
Epoch:  8  	Training Loss: 0.054606784135103226
Test Loss:  0.048701733350753784
Valid Loss:  0.051192186772823334
Epoch:  9  	Training Loss: 0.048064980655908585
Test Loss:  0.04277839511632919
Valid Loss:  0.045189596712589264
Epoch:  10  	Training Loss: 0.042429693043231964
Test Loss:  0.03766921907663345
Valid Loss:  0.03999878466129303
Epoch:  11  	Training Loss: 0.03756837546825409
Test Loss:  0.03325904905796051
Valid Loss:  0.035503849387168884
Epoch:  12  	Training Loss: 0.033366650342941284
Test Loss:  0.02560528740286827
Valid Loss:  0.02782244235277176
Epoch:  13  	Training Loss: 0.026353606954216957
Test Loss:  0.02074597403407097
Valid Loss:  0.0229683518409729
Epoch:  14  	Training Loss: 0.022021587938070297
Test Loss:  0.017235636711120605
Valid Loss:  0.01936466060578823
Epoch:  15  	Training Loss: 0.01874924823641777
Test Loss:  0.014562119729816914
Valid Loss:  0.01657542772591114
Epoch:  16  	Training Loss: 0.016200702637434006
Test Loss:  0.012547345831990242
Valid Loss:  0.014443594962358475
Epoch:  17  	Training Loss: 0.014198830351233482
Test Loss:  0.011002309620380402
Valid Loss:  0.012766415253281593
Epoch:  18  	Training Loss: 0.012630282901227474
Test Loss:  0.009782006964087486
Valid Loss:  0.01143212802708149
Epoch:  19  	Training Loss: 0.01138409785926342
Test Loss:  0.008777805604040623
Valid Loss:  0.010339582338929176
Epoch:  20  	Training Loss: 0.010369687341153622
Test Loss:  0.007940989919006824
Valid Loss:  0.009443283081054688
Epoch:  21  	Training Loss: 0.009523168206214905
Test Loss:  0.007234865799546242
Valid Loss:  0.008693777024745941
Epoch:  22  	Training Loss: 0.008802970871329308
Test Loss:  0.006654414813965559
Valid Loss:  0.008082657121121883
Epoch:  23  	Training Loss: 0.00826238002628088
Test Loss:  0.006188733037561178
Valid Loss:  0.007575660012662411
Epoch:  24  	Training Loss: 0.007760985288769007
Test Loss:  0.005903932265937328
Valid Loss:  0.007253903895616531
Epoch:  25  	Training Loss: 0.007445898838341236
Test Loss:  0.005654463544487953
Valid Loss:  0.006978674326092005
Epoch:  26  	Training Loss: 0.00717740785330534
Test Loss:  0.005426967516541481
Valid Loss:  0.006738146301358938
Epoch:  27  	Training Loss: 0.00694262096658349
Test Loss:  0.005223612301051617
Valid Loss:  0.006528632715344429
Epoch:  28  	Training Loss: 0.006731127388775349
Test Loss:  0.0050417035818099976
Valid Loss:  0.006340701598674059
Epoch:  29  	Training Loss: 0.0065409941598773
Test Loss:  0.004875746089965105
Valid Loss:  0.006167848594486713
Epoch:  30  	Training Loss: 0.0063662175089120865
Test Loss:  0.004721280187368393
Valid Loss:  0.0060064708814024925
Epoch:  31  	Training Loss: 0.006204863544553518
Test Loss:  0.004577682353556156
Valid Loss:  0.005855601280927658
Epoch:  32  	Training Loss: 0.00605426449328661
Test Loss:  0.004239619709551334
Valid Loss:  0.005315402522683144
Epoch:  33  	Training Loss: 0.005397019442170858
Test Loss:  0.0040946160443127155
Valid Loss:  0.0050770798698067665
Epoch:  34  	Training Loss: 0.005067074205726385
Test Loss:  0.003957434091717005
Valid Loss:  0.004875464364886284
Epoch:  35  	Training Loss: 0.004846069496124983
Test Loss:  0.0038639833219349384
Valid Loss:  0.004727266728878021
Epoch:  36  	Training Loss: 0.0046811532229185104
Test Loss:  0.0037544844672083855
Valid Loss:  0.004599189385771751
Epoch:  37  	Training Loss: 0.00455037597566843
Test Loss:  0.003652771469205618
Valid Loss:  0.004497338552027941
Epoch:  38  	Training Loss: 0.004441333469003439
Test Loss:  0.0035545402206480503
Valid Loss:  0.004407866857945919
Epoch:  39  	Training Loss: 0.00434798002243042
Test Loss:  0.0034637227654457092
Valid Loss:  0.00432850094512105
Epoch:  40  	Training Loss: 0.004265372641384602
Test Loss:  0.003376828273758292
Valid Loss:  0.004254825878888369
Epoch:  41  	Training Loss: 0.0041920775547623634
Test Loss:  0.0033031757920980453
Valid Loss:  0.004193199798464775
Epoch:  42  	Training Loss: 0.004125709645450115
Test Loss:  0.0030149673111736774
Valid Loss:  0.0038739515002816916
Epoch:  43  	Training Loss: 0.0038658599369227886
Test Loss:  0.002797467401251197
Valid Loss:  0.0036269607953727245
Epoch:  44  	Training Loss: 0.003650437109172344
Test Loss:  0.002650771290063858
Valid Loss:  0.003454801393672824
Epoch:  45  	Training Loss: 0.0034948019310832024
Test Loss:  0.002550877630710602
Valid Loss:  0.003330943873152137
Epoch:  46  	Training Loss: 0.003372290637344122
Test Loss:  0.0024577840231359005
Valid Loss:  0.0032178594265133142
Epoch:  47  	Training Loss: 0.003258556593209505
Test Loss:  0.0023709209635853767
Valid Loss:  0.0031130213756114244
Epoch:  48  	Training Loss: 0.0031512395944446325
Test Loss:  0.0022860653698444366
Valid Loss:  0.00301107089035213
Epoch:  49  	Training Loss: 0.003050019731745124
Test Loss:  0.0022077797912061214
Valid Loss:  0.0029161234851926565
Epoch:  50  	Training Loss: 0.002953419927507639
Test Loss:  0.0021354439668357372
Valid Loss:  0.0028262492269277573
Epoch:  51  	Training Loss: 0.002861049259081483
Test Loss:  0.0020668162032961845
Valid Loss:  0.002740794327110052
Epoch:  52  	Training Loss: 0.0027730707079172134
Test Loss:  0.001955596264451742
Valid Loss:  0.002583189867436886
Epoch:  53  	Training Loss: 0.0025777213741093874
Test Loss:  0.0018977298168465495
Valid Loss:  0.0024902706500142813
Epoch:  54  	Training Loss: 0.0024570540990680456
Test Loss:  0.0018354818457737565
Valid Loss:  0.0024074180983006954
Epoch:  55  	Training Loss: 0.0023549553006887436
Test Loss:  0.001773191848769784
Valid Loss:  0.0023304689675569534
Epoch:  56  	Training Loss: 0.0022649189922958612
Test Loss:  0.0017131762579083443
Valid Loss:  0.0022594837937504053
Epoch:  57  	Training Loss: 0.0021837521344423294
Test Loss:  0.0016555801266804338
Valid Loss:  0.002193060703575611
Epoch:  58  	Training Loss: 0.0021098367869853973
Test Loss:  0.0016001926269382238
Valid Loss:  0.002130354754626751
Epoch:  59  	Training Loss: 0.002042100764811039
Test Loss:  0.0015482943272218108
Valid Loss:  0.0020724725909531116
Epoch:  60  	Training Loss: 0.0019796532578766346
Test Loss:  0.0015006419271230698
Valid Loss:  0.0020198195707052946
Epoch:  61  	Training Loss: 0.001922088791616261
Test Loss:  0.0014548395993188024
Valid Loss:  0.00197006156668067
Epoch:  62  	Training Loss: 0.001869288505986333
Test Loss:  0.00130537711083889
Valid Loss:  0.0018196754390373826
Epoch:  63  	Training Loss: 0.0017536315135657787
Test Loss:  0.00119851715862751
Valid Loss:  0.001708165043964982
Epoch:  64  	Training Loss: 0.0016645417781546712
Test Loss:  0.0011175888357684016
Valid Loss:  0.0016194414347410202
Epoch:  65  	Training Loss: 0.001590259955264628
Test Loss:  0.0010558312060311437
Valid Loss:  0.0015480912989005446
Epoch:  66  	Training Loss: 0.0015288223512470722
Test Loss:  0.0010087747359648347
Valid Loss:  0.0014906700234860182
Epoch:  67  	Training Loss: 0.0014768671244382858
Test Loss:  0.0009700523805804551
Valid Loss:  0.0014412195887416601
Epoch:  68  	Training Loss: 0.001429619500413537
Test Loss:  0.000936666619963944
Valid Loss:  0.0013966963160783052
Epoch:  69  	Training Loss: 0.0013855502475053072
Test Loss:  0.0009072081884369254
Valid Loss:  0.0013563047396019101
Epoch:  70  	Training Loss: 0.0013450335245579481
Test Loss:  0.0008808298734948039
Valid Loss:  0.0013198137748986483
Epoch:  71  	Training Loss: 0.001307599595747888
Test Loss:  14%|█▍        | 71/500 [00:54<08:40,  1.21s/it] 15%|█▍        | 73/500 [00:55<06:11,  1.15it/s] 15%|█▌        | 75/500 [00:55<04:27,  1.59it/s] 15%|█▌        | 77/500 [00:55<03:14,  2.18it/s] 16%|█▌        | 79/500 [00:55<02:24,  2.92it/s] 16%|█▌        | 81/500 [01:02<08:31,  1.22s/it] 17%|█▋        | 83/500 [01:02<06:05,  1.14it/s] 17%|█▋        | 85/500 [01:02<04:22,  1.58it/s] 17%|█▋        | 87/500 [01:02<03:11,  2.16it/s] 18%|█▊        | 89/500 [01:02<02:21,  2.91it/s] 18%|█▊        | 91/500 [01:08<08:11,  1.20s/it] 19%|█▊        | 93/500 [01:09<05:53,  1.15it/s] 19%|█▉        | 95/500 [01:09<04:16,  1.58it/s] 19%|█▉        | 97/500 [01:09<03:08,  2.13it/s] 20%|█▉        | 99/500 [01:09<02:21,  2.83it/s] 20%|██        | 101/500 [01:16<08:05,  1.22s/it] 21%|██        | 103/500 [01:16<05:46,  1.15it/s] 21%|██        | 105/500 [01:16<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:16<03:01,  2.17it/s] 22%|██▏       | 109/500 [01:16<02:13,  2.92it/s] 22%|██▏       | 111/500 [01:22<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:23<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:23<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:23<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:23<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:29<07:18,  1.16s/it] 25%|██▍       | 123/500 [01:29<05:13,  1.20it/s] 25%|██▌       | 125/500 [01:29<03:45,  1.66it/s] 25%|██▌       | 127/500 [01:30<02:44,  2.27it/s] 26%|██▌       | 129/500 [01:30<02:01,  3.04it/s] 26%|██▌       | 131/500 [01:36<07:27,  1.21s/it] 27%|██▋       | 133/500 [01:36<05:19,  1.15it/s] 27%|██▋       | 135/500 [01:36<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:37<02:47,  2.17it/s] 28%|██▊       | 139/500 [01:37<02:03,  2.92it/s] 0.000856216880492866
Valid Loss:  0.001285833539441228
Epoch:  72  	Training Loss: 0.0012723538093268871
Test Loss:  0.0008308044634759426
Valid Loss:  0.0012384168803691864
Epoch:  73  	Training Loss: 0.0012069297954440117
Test Loss:  0.0008057401864789426
Valid Loss:  0.001195671851746738
Epoch:  74  	Training Loss: 0.0011516541708260775
Test Loss:  0.0007808860973455012
Valid Loss:  0.0011562289437279105
Epoch:  75  	Training Loss: 0.0011034681228920817
Test Loss:  0.0007566650165244937
Valid Loss:  0.0011195896659046412
Epoch:  76  	Training Loss: 0.0010607321746647358
Test Loss:  0.0007333749672397971
Valid Loss:  0.0010854718275368214
Epoch:  77  	Training Loss: 0.001022392068989575
Test Loss:  0.0007111651357263327
Valid Loss:  0.0010532294400036335
Epoch:  78  	Training Loss: 0.0009873069357126951
Test Loss:  0.0006909024668857455
Valid Loss:  0.001023759599775076
Epoch:  79  	Training Loss: 0.0009557045414112508
Test Loss:  0.0006729274755343795
Valid Loss:  0.000997317023575306
Epoch:  80  	Training Loss: 0.0009272887837141752
Test Loss:  0.0006562464986927807
Valid Loss:  0.000973082787822932
Epoch:  81  	Training Loss: 0.0009014536044560373
Test Loss:  0.000640859070699662
Valid Loss:  0.0009507765062153339
Epoch:  82  	Training Loss: 0.0008778879418969154
Test Loss:  0.0006483697216026485
Valid Loss:  0.0009445559699088335
Epoch:  83  	Training Loss: 0.0008620965527370572
Test Loss:  0.0006495628622360528
Valid Loss:  0.0009370329789817333
Epoch:  84  	Training Loss: 0.0008498275419697165
Test Loss:  0.0006468603387475014
Valid Loss:  0.0009283817489631474
Epoch:  85  	Training Loss: 0.00083923403872177
Test Loss:  0.00064229522831738
Valid Loss:  0.0009193582227453589
Epoch:  86  	Training Loss: 0.0008295640582218766
Test Loss:  0.0006370512419380248
Valid Loss:  0.0009105009958148003
Epoch:  87  	Training Loss: 0.0008205586345866323
Test Loss:  0.0006315086502581835
Valid Loss:  0.0009018798591569066
Epoch:  88  	Training Loss: 0.0008121301652863622
Test Loss:  0.0006259068613871932
Valid Loss:  0.0008935949299484491
Epoch:  89  	Training Loss: 0.0008043085690587759
Test Loss:  0.0006203383090905845
Valid Loss:  0.0008857643697410822
Epoch:  90  	Training Loss: 0.0007970205042511225
Test Loss:  0.0006149850087240338
Valid Loss:  0.0008783087832853198
Epoch:  91  	Training Loss: 0.0007901043863967061
Test Loss:  0.000609933864325285
Valid Loss:  0.0008712248527444899
Epoch:  92  	Training Loss: 0.0007835642900317907
Test Loss:  0.0005804994143545628
Valid Loss:  0.0008442199323326349
Epoch:  93  	Training Loss: 0.0007636209484189749
Test Loss:  0.0005589618813246489
Valid Loss:  0.0008229590021073818
Epoch:  94  	Training Loss: 0.0007464123191311955
Test Loss:  0.0005418710643425584
Valid Loss:  0.0008048134623095393
Epoch:  95  	Training Loss: 0.0007308773929253221
Test Loss:  0.0005281195626594126
Valid Loss:  0.0007888516993261874
Epoch:  96  	Training Loss: 0.0007166778086684644
Test Loss:  0.0005166224436834455
Valid Loss:  0.0007746602641418576
Epoch:  97  	Training Loss: 0.0007036748575046659
Test Loss:  0.0005064845317974687
Valid Loss:  0.0007615979993715882
Epoch:  98  	Training Loss: 0.0006914904806762934
Test Loss:  0.000497448374517262
Valid Loss:  0.0007495669415220618
Epoch:  99  	Training Loss: 0.0006802309071645141
Test Loss:  0.0004892491269856691
Valid Loss:  0.0007383179618045688
Epoch:  100  	Training Loss: 0.0006695561460219324
Test Loss:  0.00048165422049351037
Valid Loss:  0.0007278209086507559
Epoch:  101  	Training Loss: 0.0006594254518859088
Test Loss:  0.00047469144919887185
Valid Loss:  0.0007182067492976785
Epoch:  102  	Training Loss: 0.0006499681621789932
Test Loss:  0.00046809797640889883
Valid Loss:  0.0007107729907147586
Epoch:  103  	Training Loss: 0.000643018982373178
Test Loss:  0.000462040479760617
Valid Loss:  0.0007039328338578343
Epoch:  104  	Training Loss: 0.0006363859283737838
Test Loss:  0.00045643700286746025
Valid Loss:  0.0006974371499381959
Epoch:  105  	Training Loss: 0.000630076858215034
Test Loss:  0.0004513015737757087
Valid Loss:  0.0006913227261975408
Epoch:  106  	Training Loss: 0.0006241381051950157
Test Loss:  0.0004464278172235936
Valid Loss:  0.0006854487000964582
Epoch:  107  	Training Loss: 0.0006184012745507061
Test Loss:  0.0004418146563693881
Valid Loss:  0.0006798100657761097
Epoch:  108  	Training Loss: 0.0006129038520157337
Test Loss:  0.00043732367339544
Valid Loss:  0.0006744358688592911
Epoch:  109  	Training Loss: 0.0006075361743569374
Test Loss:  0.00043301310506649315
Valid Loss:  0.0006693461327813566
Epoch:  110  	Training Loss: 0.0006023788591846824
Test Loss:  0.00042878853855654597
Valid Loss:  0.0006644246750511229
Epoch:  111  	Training Loss: 0.0005972967483103275
Test Loss:  0.0004242915310896933
Valid Loss:  0.0006595782469958067
Epoch:  112  	Training Loss: 0.0005921403644606471
Test Loss:  0.00043072804692201316
Valid Loss:  0.0006484412588179111
Epoch:  113  	Training Loss: 0.0005762748187407851
Test Loss:  0.00042948953341692686
Valid Loss:  0.0006368199246935546
Epoch:  114  	Training Loss: 0.000563311274163425
Test Loss:  0.0004252997459843755
Valid Loss:  0.000625101150944829
Epoch:  115  	Training Loss: 0.0005517602548934519
Test Loss:  0.0004199994436930865
Valid Loss:  0.0006139771430753171
Epoch:  116  	Training Loss: 0.000541337882168591
Test Loss:  0.00041409936966374516
Valid Loss:  0.0006036096601746976
Epoch:  117  	Training Loss: 0.0005317109171301126
Test Loss:  0.00040799181442707777
Valid Loss:  0.0005937436362728477
Epoch:  118  	Training Loss: 0.0005226331995800138
Test Loss:  0.00040229325531981885
Valid Loss:  0.0005845844279974699
Epoch:  119  	Training Loss: 0.000514103623572737
Test Loss:  0.00039655526052229106
Valid Loss:  0.000576026039198041
Epoch:  120  	Training Loss: 0.000505944131873548
Test Loss:  0.0003908306243829429
Valid Loss:  0.0005677244043909013
Epoch:  121  	Training Loss: 0.000498102162964642
Test Loss:  0.0003854673122987151
Valid Loss:  0.0005597537383437157
Epoch:  122  	Training Loss: 0.0004905544919893146
Test Loss:  0.00038072862662374973
Valid Loss:  0.0005546805914491415
Epoch:  123  	Training Loss: 0.0004865214868914336
Test Loss:  0.0003767055459320545
Valid Loss:  0.0005499934777617455
Epoch:  124  	Training Loss: 0.0004826320509891957
Test Loss:  0.0003732528421096504
Valid Loss:  0.000545560207683593
Epoch:  125  	Training Loss: 0.00047884407103993
Test Loss:  0.0003704004629980773
Valid Loss:  0.0005413980688899755
Epoch:  126  	Training Loss: 0.0004751149099320173
Test Loss:  0.0003676585329230875
Valid Loss:  0.0005373455351218581
Epoch:  127  	Training Loss: 0.0004714509705081582
Test Loss:  0.0003648792626336217
Valid Loss:  0.0005333516746759415
Epoch:  128  	Training Loss: 0.00046789695625193417
Test Loss:  0.00036250584525987506
Valid Loss:  0.0005296311574056745
Epoch:  129  	Training Loss: 0.0004645208246074617
Test Loss:  0.0003600975323934108
Valid Loss:  0.0005260154139250517
Epoch:  130  	Training Loss: 0.00046122432104311883
Test Loss:  0.00035767711233347654
Valid Loss:  0.0005224855849519372
Epoch:  131  	Training Loss: 0.00045799987856298685
Test Loss:  0.0003552661510184407
Valid Loss:  0.0005190854426473379
Epoch:  132  	Training Loss: 0.0004548283468466252
Test Loss:  0.0003419134591240436
Valid Loss:  0.0004982069367542863
Epoch:  133  	Training Loss: 0.0004348919610492885
Test Loss:  0.0003273893380537629
Valid Loss:  0.0004784261982422322
Epoch:  134  	Training Loss: 0.00041626449092291296
Test Loss:  0.0003128548851236701
Valid Loss:  0.0004600235552061349
Epoch:  135  	Training Loss: 0.0003989943361375481
Test Loss:  0.0002986614708788693
Valid Loss:  0.00044295808766037226
Epoch:  136  	Training Loss: 0.00038311717798933387
Test Loss:  0.0002854323829524219
Valid Loss:  0.0004274224629625678
Epoch:  137  	Training Loss: 0.00036873892531730235
Test Loss:  0.00027348747244104743
Valid Loss:  0.0004131531168241054
Epoch:  138  	Training Loss: 0.00035590221523307264
Test Loss:  0.0002625321503728628
Valid Loss:  0.0004006273811683059
Epoch:  139  	Training Loss: 0.00034508371027186513
Test Loss:  0.0002528215991333127
Valid Loss:  0.0003903286124113947
 28%|██▊       | 141/500 [01:43<07:07,  1.19s/it] 29%|██▊       | 143/500 [01:43<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:43<03:39,  1.61it/s] 29%|██▉       | 147/500 [01:44<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:44<01:58,  2.97it/s] 30%|███       | 151/500 [01:50<06:57,  1.20s/it] 31%|███       | 153/500 [01:50<04:59,  1.16it/s] 31%|███       | 155/500 [01:50<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:50<02:36,  2.20it/s] 32%|███▏      | 159/500 [01:51<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:57<06:40,  1.18s/it] 33%|███▎      | 163/500 [01:57<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:57<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:57<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:57<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:04<06:39,  1.21s/it] 35%|███▍      | 173/500 [02:04<04:45,  1.15it/s] 35%|███▌      | 175/500 [02:04<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:04<02:28,  2.17it/s] 36%|███▌      | 179/500 [02:05<01:49,  2.92it/s] 36%|███▌      | 181/500 [02:11<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:11<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:11<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:11<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:11<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:18<06:06,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:18<03:07,  1.62it/s] 39%|███▉      | 197/500 [02:18<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:18<01:41,  2.97it/s] 40%|████      | 201/500 [02:25<05:58,  1.20s/it] 41%|████      | 203/500 [02:25<04:16,  1.16it/s] 41%|████      | 205/500 [02:25<03:06,  1.58it/s]Epoch:  140  	Training Loss: 0.00033629321842454374
Test Loss:  0.0002445528516545892
Valid Loss:  0.0003810733905993402
Epoch:  141  	Training Loss: 0.00032826681854203343
Test Loss:  0.0002372021262999624
Valid Loss:  0.00037271634209901094
Epoch:  142  	Training Loss: 0.00032113370252773166
Test Loss:  0.00023616963881067932
Valid Loss:  0.0003713680198416114
Epoch:  143  	Training Loss: 0.0003198203630745411
Test Loss:  0.0002352007431909442
Valid Loss:  0.0003700545057654381
Epoch:  144  	Training Loss: 0.00031854421831667423
Test Loss:  0.00023423516540788114
Valid Loss:  0.0003687661956064403
Epoch:  145  	Training Loss: 0.00031728908652439713
Test Loss:  0.0002332752337679267
Valid Loss:  0.00036749657010659575
Epoch:  146  	Training Loss: 0.0003160567721351981
Test Loss:  0.00023238804715219885
Valid Loss:  0.0003662788076326251
Epoch:  147  	Training Loss: 0.0003148632822558284
Test Loss:  0.00023149684420786798
Valid Loss:  0.0003650796425063163
Epoch:  148  	Training Loss: 0.00031368524651043117
Test Loss:  0.00023059740487951785
Valid Loss:  0.000363900326192379
Epoch:  149  	Training Loss: 0.0003125231887679547
Test Loss:  0.00022973214800003916
Valid Loss:  0.000362761493306607
Epoch:  150  	Training Loss: 0.00031139026395976543
Test Loss:  0.0002289279509568587
Valid Loss:  0.0003616780450101942
Epoch:  151  	Training Loss: 0.00031029683304950595
Test Loss:  0.0002281126071466133
Valid Loss:  0.0003606317040976137
Epoch:  152  	Training Loss: 0.0003092213883064687
Test Loss:  0.000221032474655658
Valid Loss:  0.0003520451136864722
Epoch:  153  	Training Loss: 0.0003020003787241876
Test Loss:  0.00021494200336746871
Valid Loss:  0.00034450768725946546
Epoch:  154  	Training Loss: 0.0002954730298370123
Test Loss:  0.00020957681408617646
Valid Loss:  0.0003379496920388192
Epoch:  155  	Training Loss: 0.0002894946373999119
Test Loss:  0.00020459084771573544
Valid Loss:  0.0003319733077660203
Epoch:  156  	Training Loss: 0.00028413982363417745
Test Loss:  0.00020001217490062118
Valid Loss:  0.00032682641176506877
Epoch:  157  	Training Loss: 0.0002794250031001866
Test Loss:  0.00019586054258979857
Valid Loss:  0.000322124978993088
Epoch:  158  	Training Loss: 0.00027501798467710614
Test Loss:  0.00019220251124352217
Valid Loss:  0.00031770626083016396
Epoch:  159  	Training Loss: 0.0002708452520892024
Test Loss:  0.00018877614638768137
Valid Loss:  0.0003135165316052735
Epoch:  160  	Training Loss: 0.0002669273526407778
Test Loss:  0.0001857144816312939
Valid Loss:  0.0003096332657150924
Epoch:  161  	Training Loss: 0.00026324199279770255
Test Loss:  0.00018149019160773605
Valid Loss:  0.00030568591319024563
Epoch:  162  	Training Loss: 0.00025988148991018534
Test Loss:  0.00017970509361475706
Valid Loss:  0.00030385470017790794
Epoch:  163  	Training Loss: 0.00025817088317126036
Test Loss:  0.0001779853628249839
Valid Loss:  0.0003020880976691842
Epoch:  164  	Training Loss: 0.00025652715703472495
Test Loss:  0.00017637292330618948
Valid Loss:  0.0003004060126841068
Epoch:  165  	Training Loss: 0.0002549389027990401
Test Loss:  0.00017474874039180577
Valid Loss:  0.00029875439940951765
Epoch:  166  	Training Loss: 0.0002534084487706423
Test Loss:  0.0001732329255901277
Valid Loss:  0.0002971513895317912
Epoch:  167  	Training Loss: 0.00025191454915329814
Test Loss:  0.00017179430869873613
Valid Loss:  0.0002955961390398443
Epoch:  168  	Training Loss: 0.0002504639560356736
Test Loss:  0.00017043361731339246
Valid Loss:  0.0002940833510365337
Epoch:  169  	Training Loss: 0.0002490518963895738
Test Loss:  0.00016913771105464548
Valid Loss:  0.00029262210591696203
Epoch:  170  	Training Loss: 0.0002476872759871185
Test Loss:  0.00016788608627393842
Valid Loss:  0.00029119401006028056
Epoch:  171  	Training Loss: 0.0002463447453919798
Test Loss:  0.00016670036711730063
Valid Loss:  0.0002897978120017797
Epoch:  172  	Training Loss: 0.00024502299493178725
Test Loss:  0.0001641960407141596
Valid Loss:  0.00028698734240606427
Epoch:  173  	Training Loss: 0.00024243959342129529
Test Loss:  0.00016192856128327549
Valid Loss:  0.0002843115944415331
Epoch:  174  	Training Loss: 0.0002399564255028963
Test Loss:  0.0001598013041075319
Valid Loss:  0.0002817325294017792
Epoch:  175  	Training Loss: 0.00023754723952151835
Test Loss:  0.00015776153304614127
Valid Loss:  0.0002792326849885285
Epoch:  176  	Training Loss: 0.00023521184630226344
Test Loss:  0.00015581092156935483
Valid Loss:  0.00027681549545377493
Epoch:  177  	Training Loss: 0.0002329508715774864
Test Loss:  0.00015396690287161618
Valid Loss:  0.00027448596665635705
Epoch:  178  	Training Loss: 0.00023078048252500594
Test Loss:  0.00015222025103867054
Valid Loss:  0.0002722656645346433
Epoch:  179  	Training Loss: 0.0002286946401000023
Test Loss:  0.00015055177209433168
Valid Loss:  0.0002701057237572968
Epoch:  180  	Training Loss: 0.00022667166194878519
Test Loss:  0.0001489318674430251
Valid Loss:  0.00026800326304510236
Epoch:  181  	Training Loss: 0.00022470980184152722
Test Loss:  0.0001473379961680621
Valid Loss:  0.00026595857343636453
Epoch:  182  	Training Loss: 0.00022280530538409948
Test Loss:  0.00014643404574599117
Valid Loss:  0.00026510024326853454
Epoch:  183  	Training Loss: 0.00022208494192454964
Test Loss:  0.0001456493919249624
Valid Loss:  0.0002643062616698444
Epoch:  184  	Training Loss: 0.00022139109205454588
Test Loss:  0.000144954290590249
Valid Loss:  0.0002635661221574992
Epoch:  185  	Training Loss: 0.0002207267243647948
Test Loss:  0.0001443586515961215
Valid Loss:  0.0002628721413202584
Epoch:  186  	Training Loss: 0.00022008834639564157
Test Loss:  0.00014379111235029995
Valid Loss:  0.00026220697327516973
Epoch:  187  	Training Loss: 0.00021946814376860857
Test Loss:  0.00014326015661936253
Valid Loss:  0.00026156261446885765
Epoch:  188  	Training Loss: 0.00021886976901441813
Test Loss:  0.00014274823479354382
Valid Loss:  0.0002609329530969262
Epoch:  189  	Training Loss: 0.00021828590251971036
Test Loss:  0.00014225850463844836
Valid Loss:  0.000260316242929548
Epoch:  190  	Training Loss: 0.00021771533647552133
Test Loss:  0.00014179747086018324
Valid Loss:  0.0002597292768768966
Epoch:  191  	Training Loss: 0.00021716189803555608
Test Loss:  0.00014136837853584439
Valid Loss:  0.0002591600059531629
Epoch:  192  	Training Loss: 0.00021662437939085066
Test Loss:  0.0001392909762216732
Valid Loss:  0.000256382510997355
Epoch:  193  	Training Loss: 0.00021406191808637232
Test Loss:  0.00013731121725868434
Valid Loss:  0.0002537355467211455
Epoch:  194  	Training Loss: 0.0002116012037731707
Test Loss:  0.00013546219270210713
Valid Loss:  0.0002512003411538899
Epoch:  195  	Training Loss: 0.00020923453848809004
Test Loss:  0.00013366388157010078
Valid Loss:  0.0002487518358975649
Epoch:  196  	Training Loss: 0.00020694811246357858
Test Loss:  0.00013195982319302857
Valid Loss:  0.00024639390176162124
Epoch:  197  	Training Loss: 0.00020473822951316833
Test Loss:  0.00013034192670602351
Valid Loss:  0.00024411495542153716
Epoch:  198  	Training Loss: 0.00020259925804566592
Test Loss:  0.00012876145774498582
Valid Loss:  0.0002419019874650985
Epoch:  199  	Training Loss: 0.00020052808395121247
Test Loss:  0.00012723708641715348
Valid Loss:  0.0002397561038378626
Epoch:  200  	Training Loss: 0.00019851973047479987
Test Loss:  0.00012577077723108232
Valid Loss:  0.0002376752090640366
Epoch:  201  	Training Loss: 0.00019657390657812357
Test Loss:  0.00012439649435691535
Valid Loss:  0.00023566614254377782
Epoch:  202  	Training Loss: 0.00019468978280201554
Test Loss:  0.0001235495146829635
Valid Loss:  0.00023427004634868354
Epoch:  203  	Training Loss: 0.00019371489179320633
Test Loss:  0.00012342972331680357
Valid Loss:  0.00023357302416116
Epoch:  204  	Training Loss: 0.00019298092229291797
Test Loss:  0.00012319607776589692
Valid Loss:  0.0002328663831576705
Epoch:  205  	Training Loss: 0.0001922644441947341
Test Loss:  0.00012285752745810896
Valid Loss:  0.00023214929387904704
Epoch:  206  	Training Loss: 0.00019155809422954917
Test Loss:  0.00012244906974956393
Valid Loss:  0.00023142306599766016
 41%|████▏     | 207/500 [02:25<02:17,  2.13it/s] 42%|████▏     | 209/500 [02:25<01:42,  2.83it/s] 42%|████▏     | 211/500 [02:32<05:49,  1.21s/it] 43%|████▎     | 213/500 [02:32<04:10,  1.15it/s] 43%|████▎     | 215/500 [02:32<03:01,  1.57it/s] 43%|████▎     | 217/500 [02:32<02:13,  2.13it/s] 44%|████▍     | 219/500 [02:32<01:39,  2.82it/s] 44%|████▍     | 221/500 [02:39<05:36,  1.21s/it] 45%|████▍     | 223/500 [02:39<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:39<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:39<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:39<01:31,  2.95it/s] 46%|████▌     | 231/500 [02:46<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:46<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:46<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:46<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:46<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:52<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:53<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:53<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:53<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:53<01:24,  2.98it/s] 50%|█████     | 251/500 [02:59<04:51,  1.17s/it] 51%|█████     | 253/500 [02:59<03:27,  1.19it/s] 51%|█████     | 255/500 [03:00<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:00<01:47,  2.25it/s] 52%|█████▏    | 259/500 [03:00<01:19,  3.03it/s] 52%|█████▏    | 261/500 [03:06<04:47,  1.20s/it] 53%|█████▎    | 263/500 [03:06<03:25,  1.15it/s] 53%|█████▎    | 265/500 [03:07<02:28,  1.58it/s] 53%|█████▎    | 267/500 [03:07<01:49,  2.13it/s] 54%|█████▍    | 269/500 [03:07<01:21,  2.83it/s] 54%|█████▍    | 271/500 [03:13<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:13<03:15,  1.16it/s]Epoch:  207  	Training Loss: 0.00019085992244072258
Test Loss:  0.00012199846969451755
Valid Loss:  0.00023069583403412253
Epoch:  208  	Training Loss: 0.00019016937585547566
Test Loss:  0.00012151706323493272
Valid Loss:  0.00022996912593953311
Epoch:  209  	Training Loss: 0.0001894862507469952
Test Loss:  0.00012101697939215228
Valid Loss:  0.00022924510994926095
Epoch:  210  	Training Loss: 0.00018881077994592488
Test Loss:  0.00012050537043251097
Valid Loss:  0.00022852506663184613
Epoch:  211  	Training Loss: 0.0001881431817309931
Test Loss:  0.00011995987733826041
Valid Loss:  0.000227805896429345
Epoch:  212  	Training Loss: 0.0001874846057035029
Test Loss:  0.00012080537271685898
Valid Loss:  0.00022793642710894346
Epoch:  213  	Training Loss: 0.00018743248074315488
Test Loss:  0.00012138280726503581
Valid Loss:  0.00022803197498433292
Epoch:  214  	Training Loss: 0.00018740148516371846
Test Loss:  0.00012177130702184513
Valid Loss:  0.0002280967019032687
Epoch:  215  	Training Loss: 0.0001873791334219277
Test Loss:  0.00012203095684526488
Valid Loss:  0.0002281377383042127
Epoch:  216  	Training Loss: 0.00018736132187768817
Test Loss:  0.00012220175995025784
Valid Loss:  0.00022816608543507755
Epoch:  217  	Training Loss: 0.00018734580953605473
Test Loss:  0.00012231266009621322
Valid Loss:  0.00022818215074948967
Epoch:  218  	Training Loss: 0.0001873310684459284
Test Loss:  0.00012238274211995304
Valid Loss:  0.00022818964498583227
Epoch:  219  	Training Loss: 0.0001873169676400721
Test Loss:  0.00012242542288731784
Valid Loss:  0.00022819377772975713
Epoch:  220  	Training Loss: 0.00018730366718955338
Test Loss:  0.000122447672765702
Valid Loss:  0.0002281932975165546
Epoch:  221  	Training Loss: 0.00018729025032371283
Test Loss:  0.00012245636025909334
Valid Loss:  0.00022819000878371298
Epoch:  222  	Training Loss: 0.00018727773567661643
Test Loss:  0.00011949591134907678
Valid Loss:  0.0002260793262394145
Epoch:  223  	Training Loss: 0.00018562888726592064
Test Loss:  0.00011699850438162684
Valid Loss:  0.00022417792933993042
Epoch:  224  	Training Loss: 0.00018411301425658166
Test Loss:  0.00011489749886095524
Valid Loss:  0.00022245095169637352
Epoch:  225  	Training Loss: 0.00018270491273142397
Test Loss:  0.00011308510147500783
Valid Loss:  0.00022084859665483236
Epoch:  226  	Training Loss: 0.00018137051665689796
Test Loss:  0.0001115241611842066
Valid Loss:  0.0002193552500102669
Epoch:  227  	Training Loss: 0.00018009742780122906
Test Loss:  0.0001101472444133833
Valid Loss:  0.00021793361520394683
Epoch:  228  	Training Loss: 0.00017886798013933003
Test Loss:  0.00010891522833844647
Valid Loss:  0.0002165777113987133
Epoch:  229  	Training Loss: 0.0001776757708285004
Test Loss:  0.00010779958392959088
Valid Loss:  0.00021527844364754856
Epoch:  230  	Training Loss: 0.00017651704547461122
Test Loss:  0.00010677406680770218
Valid Loss:  0.0002140255965059623
Epoch:  231  	Training Loss: 0.00017538524116389453
Test Loss:  0.00010582256072666496
Valid Loss:  0.00021281294175423682
Epoch:  232  	Training Loss: 0.00017427645798306912
Test Loss:  0.00010719860438257456
Valid Loss:  0.00021249533165246248
Epoch:  233  	Training Loss: 0.0001736376725602895
Test Loss:  0.00010806565114762634
Valid Loss:  0.0002121766156051308
Epoch:  234  	Training Loss: 0.00017311301780864596
Test Loss:  0.00010856536391656846
Valid Loss:  0.00021184477373026311
Epoch:  235  	Training Loss: 0.0001726432383293286
Test Loss:  0.00010881507478188723
Valid Loss:  0.00021149456733837724
Epoch:  236  	Training Loss: 0.00017220439622178674
Test Loss:  0.00010888556425925344
Valid Loss:  0.00021112331887707114
Epoch:  237  	Training Loss: 0.00017178113921545446
Test Loss:  0.00010884161747526377
Valid Loss:  0.0002107400941895321
Epoch:  238  	Training Loss: 0.00017136833048425615
Test Loss:  0.00010871660197153687
Valid Loss:  0.00021034679957665503
Epoch:  239  	Training Loss: 0.00017096410738304257
Test Loss:  0.00010854301217477769
Valid Loss:  0.0002099526027450338
Epoch:  240  	Training Loss: 0.00017056413344107568
Test Loss:  0.00010833636042661965
Valid Loss:  0.0002095576492138207
Epoch:  241  	Training Loss: 0.00017017032951116562
Test Loss:  0.00010810639651026577
Valid Loss:  0.00020916262292303145
Epoch:  242  	Training Loss: 0.00016978256462607533
Test Loss:  0.00010640654363669455
Valid Loss:  0.00020782873616553843
Epoch:  243  	Training Loss: 0.00016865009092725813
Test Loss:  0.00010504210513317958
Valid Loss:  0.00020660384325310588
Epoch:  244  	Training Loss: 0.00016756988770794123
Test Loss:  0.00010390288662165403
Valid Loss:  0.00020545774896163493
Epoch:  245  	Training Loss: 0.00016652735939715058
Test Loss:  0.00010291752550983801
Valid Loss:  0.00020437082275748253
Epoch:  246  	Training Loss: 0.00016551994485780597
Test Loss:  0.00010205186117673293
Valid Loss:  0.0002033319033216685
Epoch:  247  	Training Loss: 0.00016454156138934195
Test Loss:  0.00010125590779352933
Valid Loss:  0.00020233420946169645
Epoch:  248  	Training Loss: 0.0001635884982533753
Test Loss:  0.00010051840945379809
Valid Loss:  0.00020136589591857046
Epoch:  249  	Training Loss: 0.00016266107559204102
Test Loss:  9.982007031794637e-05
Valid Loss:  0.0002004278067033738
Epoch:  250  	Training Loss: 0.0001617549278307706
Test Loss:  9.916613635141402e-05
Valid Loss:  0.000199516536667943
Epoch:  251  	Training Loss: 0.00016087375115603209
Test Loss:  9.853573283180594e-05
Valid Loss:  0.00019862658518832177
Epoch:  252  	Training Loss: 0.00016001204494386911
Test Loss:  9.857535042101517e-05
Valid Loss:  0.00019783229799941182
Epoch:  253  	Training Loss: 0.00015912619710434228
Test Loss:  9.777832747204229e-05
Valid Loss:  0.0001968632423086092
Epoch:  254  	Training Loss: 0.00015827309107407928
Test Loss:  9.774466161616147e-05
Valid Loss:  0.00019608766888268292
Epoch:  255  	Training Loss: 0.00015742293908260763
Test Loss:  9.718097862787545e-05
Valid Loss:  0.00019521800277289003
Epoch:  256  	Training Loss: 0.0001566007558722049
Test Loss:  9.662375668995082e-05
Valid Loss:  0.00019436210277490318
Epoch:  257  	Training Loss: 0.00015579606406390667
Test Loss:  9.619956836104393e-05
Valid Loss:  0.00019355829863343388
Epoch:  258  	Training Loss: 0.00015500810695812106
Test Loss:  9.559780301060528e-05
Valid Loss:  0.00019272191275376827
Epoch:  259  	Training Loss: 0.00015423665172420442
Test Loss:  9.51627007452771e-05
Valid Loss:  0.00019194137712474912
Epoch:  260  	Training Loss: 0.00015348120359703898
Test Loss:  9.456622501602396e-05
Valid Loss:  0.00019113061716780066
Epoch:  261  	Training Loss: 0.00015273952158167958
Test Loss:  9.413999214302748e-05
Valid Loss:  0.00019037560559809208
Epoch:  262  	Training Loss: 0.00015201096539385617
Test Loss:  9.385703015141189e-05
Valid Loss:  0.00018951408856082708
Epoch:  263  	Training Loss: 0.00015116909344214946
Test Loss:  9.345127182314172e-05
Valid Loss:  0.00018865492893382907
Epoch:  264  	Training Loss: 0.00015035260003060102
Test Loss:  9.298256190959364e-05
Valid Loss:  0.00018780837126541883
Epoch:  265  	Training Loss: 0.00014955649385228753
Test Loss:  9.24843261600472e-05
Valid Loss:  0.00018697584164328873
Epoch:  266  	Training Loss: 0.00014877927605994046
Test Loss:  9.198025509249419e-05
Valid Loss:  0.00018616425222717226
Epoch:  267  	Training Loss: 0.00014802123769186437
Test Loss:  9.147856326308101e-05
Valid Loss:  0.000185367651283741
Epoch:  268  	Training Loss: 0.00014728037058375776
Test Loss:  9.098746522795409e-05
Valid Loss:  0.00018459220882505178
Epoch:  269  	Training Loss: 0.00014655894483439624
Test Loss:  9.05077249626629e-05
Valid Loss:  0.000183837502845563
Epoch:  270  	Training Loss: 0.00014585375902242959
Test Loss:  9.004001913126558e-05
Valid Loss:  0.00018309711595065892
Epoch:  271  	Training Loss: 0.0001451635325793177
Test Loss:  8.958303078543395e-05
Valid Loss:  0.00018237515178043395
Epoch:  272  	Training Loss: 0.00014448896399699152
Test Loss:  8.916316437534988e-05
Valid Loss:  0.0001817874435801059
Epoch:  273  	Training Loss: 0.00014394574100151658
Test Loss:  8.876944048097357e-05
Valid Loss:  0.00018121216271538287
 55%|█████▌    | 275/500 [03:14<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:14<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:14<01:16,  2.90it/s] 56%|█████▌    | 281/500 [03:20<04:27,  1.22s/it] 57%|█████▋    | 283/500 [03:21<03:10,  1.14it/s] 57%|█████▋    | 285/500 [03:21<02:16,  1.58it/s] 57%|█████▋    | 287/500 [03:21<01:38,  2.16it/s] 58%|█████▊    | 289/500 [03:21<01:12,  2.90it/s] 58%|█████▊    | 291/500 [03:27<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:28<02:59,  1.16it/s] 59%|█████▉    | 295/500 [03:28<02:08,  1.59it/s] 59%|█████▉    | 297/500 [03:28<01:33,  2.18it/s] 60%|█████▉    | 299/500 [03:28<01:08,  2.94it/s] 60%|██████    | 301/500 [03:34<04:00,  1.21s/it] 61%|██████    | 303/500 [03:35<02:50,  1.15it/s] 61%|██████    | 305/500 [03:35<02:02,  1.60it/s] 61%|██████▏   | 307/500 [03:35<01:28,  2.18it/s] 62%|██████▏   | 309/500 [03:35<01:06,  2.89it/s] 62%|██████▏   | 311/500 [03:41<03:47,  1.20s/it] 63%|██████▎   | 313/500 [03:42<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:42<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:42<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:42<01:01,  2.95it/s] 64%|██████▍   | 321/500 [03:48<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:48<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:49<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:49<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:49<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:55<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:55<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:55<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:55<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:56<00:53,  3.01it/s]Epoch:  274  	Training Loss: 0.00014341107453219593
Test Loss:  8.839568181429058e-05
Valid Loss:  0.00018064668984152377
Epoch:  275  	Training Loss: 0.0001428843243047595
Test Loss:  8.803411037661135e-05
Valid Loss:  0.00018008865299634635
Epoch:  276  	Training Loss: 0.00014236499555408955
Test Loss:  8.768331463215873e-05
Valid Loss:  0.000179538648808375
Epoch:  277  	Training Loss: 0.0001418533211108297
Test Loss:  8.734253788134083e-05
Valid Loss:  0.00017899932572618127
Epoch:  278  	Training Loss: 0.00014134933007881045
Test Loss:  8.70085132191889e-05
Valid Loss:  0.00017846790433395654
Epoch:  279  	Training Loss: 0.00014085265866015106
Test Loss:  8.668129157740623e-05
Valid Loss:  0.0001779459125827998
Epoch:  280  	Training Loss: 0.00014036321954336017
Test Loss:  8.635928679723293e-05
Valid Loss:  0.00017742827185429633
Epoch:  281  	Training Loss: 0.00013988110003992915
Test Loss:  8.603144669905305e-05
Valid Loss:  0.00017691848916001618
Epoch:  282  	Training Loss: 0.000139403942739591
Test Loss:  8.601672016084194e-05
Valid Loss:  0.00017661129822954535
Epoch:  283  	Training Loss: 0.0001390994293615222
Test Loss:  8.596292173024267e-05
Valid Loss:  0.0001763029576977715
Epoch:  284  	Training Loss: 0.00013879976177122444
Test Loss:  8.587948104832321e-05
Valid Loss:  0.0001759970182320103
Epoch:  285  	Training Loss: 0.00013850460527464747
Test Loss:  8.577780681662261e-05
Valid Loss:  0.00017569109331816435
Epoch:  286  	Training Loss: 0.00013821209722664207
Test Loss:  8.566430187784135e-05
Valid Loss:  0.00017538591055199504
Epoch:  287  	Training Loss: 0.0001379234454361722
Test Loss:  8.554232772439718e-05
Valid Loss:  0.00017508408927824348
Epoch:  288  	Training Loss: 0.00013763882452622056
Test Loss:  8.541558054275811e-05
Valid Loss:  0.00017478381050750613
Epoch:  289  	Training Loss: 0.0001373570557916537
Test Loss:  8.528651233064011e-05
Valid Loss:  0.00017448773724026978
Epoch:  290  	Training Loss: 0.00013707975449506193
Test Loss:  8.515547960996628e-05
Valid Loss:  0.00017419279902242124
Epoch:  291  	Training Loss: 0.00013680526171810925
Test Loss:  8.503229764755815e-05
Valid Loss:  0.00017390142602380365
Epoch:  292  	Training Loss: 0.00013653477071784437
Test Loss:  8.467295265290886e-05
Valid Loss:  0.00017359363846480846
Epoch:  293  	Training Loss: 0.00013631006004288793
Test Loss:  8.436354983132333e-05
Valid Loss:  0.00017330021364614367
Epoch:  294  	Training Loss: 0.00013609268353320658
Test Loss:  8.40871871332638e-05
Valid Loss:  0.00017301205662079155
Epoch:  295  	Training Loss: 0.00013587654393631965
Test Loss:  8.38351043057628e-05
Valid Loss:  0.0001727306080283597
Epoch:  296  	Training Loss: 0.0001356618304271251
Test Loss:  8.359813364222646e-05
Valid Loss:  0.00017245547496713698
Epoch:  297  	Training Loss: 0.0001354501728201285
Test Loss:  8.338663610629737e-05
Valid Loss:  0.00017218547873198986
Epoch:  298  	Training Loss: 0.0001352441031485796
Test Loss:  8.319759217556566e-05
Valid Loss:  0.00017193076200783253
Epoch:  299  	Training Loss: 0.000135040856548585
Test Loss:  8.301544585265219e-05
Valid Loss:  0.0001716814294923097
Epoch:  300  	Training Loss: 0.00013483932707458735
Test Loss:  8.285022340714931e-05
Valid Loss:  0.00017144157027360052
Epoch:  301  	Training Loss: 0.00013464181392919272
Test Loss:  8.269424870377406e-05
Valid Loss:  0.0001712043595034629
Epoch:  302  	Training Loss: 0.00013444750220514834
Test Loss:  8.266467193607241e-05
Valid Loss:  0.00017094152281060815
Epoch:  303  	Training Loss: 0.00013419090828392655
Test Loss:  8.259508467745036e-05
Valid Loss:  0.0001706753537291661
Epoch:  304  	Training Loss: 0.00013393894187174737
Test Loss:  8.24935341370292e-05
Valid Loss:  0.00017040844250004739
Epoch:  305  	Training Loss: 0.0001336887653451413
Test Loss:  8.237399742938578e-05
Valid Loss:  0.00017014064360409975
Epoch:  306  	Training Loss: 0.00013344144099391997
Test Loss:  8.223637996707112e-05
Valid Loss:  0.00016987297567538917
Epoch:  307  	Training Loss: 0.00013319707068149
Test Loss:  8.208998769987375e-05
Valid Loss:  0.00016960642824415118
Epoch:  308  	Training Loss: 0.0001329542719759047
Test Loss:  8.193706162273884e-05
Valid Loss:  0.000169343373272568
Epoch:  309  	Training Loss: 0.00013271329225972295
Test Loss:  8.178177813533694e-05
Valid Loss:  0.0001690806820988655
Epoch:  310  	Training Loss: 0.00013247478636913002
Test Loss:  8.16227329778485e-05
Valid Loss:  0.00016881735064089298
Epoch:  311  	Training Loss: 0.00013223718269728124
Test Loss:  8.146122854668647e-05
Valid Loss:  0.00016855642024893314
Epoch:  312  	Training Loss: 0.00013200024841353297
Test Loss:  8.132842049235478e-05
Valid Loss:  0.00016827802755869925
Epoch:  313  	Training Loss: 0.00013174513878766447
Test Loss:  8.118224650388584e-05
Valid Loss:  0.0001680026762187481
Epoch:  314  	Training Loss: 0.00013149267761036754
Test Loss:  8.102938591036946e-05
Valid Loss:  0.00016772857634350657
Epoch:  315  	Training Loss: 0.00013124235556460917
Test Loss:  8.087466994766146e-05
Valid Loss:  0.00016745590255595744
Epoch:  316  	Training Loss: 0.00013099427451379597
Test Loss:  8.071996853686869e-05
Valid Loss:  0.00016718616825528443
Epoch:  317  	Training Loss: 0.00013075029710307717
Test Loss:  8.056333172135055e-05
Valid Loss:  0.0001669188350206241
Epoch:  318  	Training Loss: 0.0001305089972447604
Test Loss:  8.040990360314026e-05
Valid Loss:  0.0001666540338192135
Epoch:  319  	Training Loss: 0.0001302689197473228
Test Loss:  8.025536226341501e-05
Valid Loss:  0.0001663911680225283
Epoch:  320  	Training Loss: 0.000130030995933339
Test Loss:  8.010402962099761e-05
Valid Loss:  0.00016612999024800956
Epoch:  321  	Training Loss: 0.0001297948620049283
Test Loss:  7.99547997303307e-05
Valid Loss:  0.00016587169375270605
Epoch:  322  	Training Loss: 0.0001295626861974597
Test Loss:  7.97737593529746e-05
Valid Loss:  0.00016561736993025988
Epoch:  323  	Training Loss: 0.00012932703248225152
Test Loss:  7.960136281326413e-05
Valid Loss:  0.00016536307521164417
Epoch:  324  	Training Loss: 0.00012909292127005756
Test Loss:  7.942366937641054e-05
Valid Loss:  0.00016511345165781677
Epoch:  325  	Training Loss: 0.00012885997421108186
Test Loss:  7.925351383164525e-05
Valid Loss:  0.00016486310050822794
Epoch:  326  	Training Loss: 0.00012862806033808738
Test Loss:  7.908682164270431e-05
Valid Loss:  0.00016461522318422794
Epoch:  327  	Training Loss: 0.00012839862029068172
Test Loss:  7.892757275840268e-05
Valid Loss:  0.00016437043086625636
Epoch:  328  	Training Loss: 0.00012817136303056031
Test Loss:  7.87710741860792e-05
Valid Loss:  0.00016412771947216243
Epoch:  329  	Training Loss: 0.00012794576468877494
Test Loss:  7.86191230872646e-05
Valid Loss:  0.0001638860849197954
Epoch:  330  	Training Loss: 0.00012772309128195047
Test Loss:  7.846759399399161e-05
Valid Loss:  0.0001636492379475385
Epoch:  331  	Training Loss: 0.0001275009853998199
Test Loss:  7.831623952370137e-05
Valid Loss:  0.00016341055743396282
Epoch:  332  	Training Loss: 0.0001272808585781604
Test Loss:  7.804864435456693e-05
Valid Loss:  0.00016312679508700967
Epoch:  333  	Training Loss: 0.00012705143308266997
Test Loss:  7.780837040627375e-05
Valid Loss:  0.0001628520549274981
Epoch:  334  	Training Loss: 0.00012682544183917344
Test Loss:  7.758434367133304e-05
Valid Loss:  0.000162580021424219
Epoch:  335  	Training Loss: 0.0001266017643501982
Test Loss:  7.737300620647147e-05
Valid Loss:  0.00016231324116233736
Epoch:  336  	Training Loss: 0.00012638006592169404
Test Loss:  7.717851985944435e-05
Valid Loss:  0.0001620494294911623
Epoch:  337  	Training Loss: 0.0001261601282749325
Test Loss:  7.699633715674281e-05
Valid Loss:  0.00016178839723579586
Epoch:  338  	Training Loss: 0.00012594167492352426
Test Loss:  7.68230966059491e-05
Valid Loss:  0.00016153670731000602
Epoch:  339  	Training Loss: 0.000125722392112948
Test Loss:  7.665701559744775e-05
Valid Loss:  0.00016128885908983648
Epoch:  340  	Training Loss: 0.00012550537940114737
Test Loss:  7.649952749488875e-05
Valid Loss:  0.0001610440231161192
Epoch:  341  	Training Loss: 0.00012528977822512388
Test Loss:   68%|██████▊   | 341/500 [04:02<03:10,  1.20s/it] 69%|██████▊   | 343/500 [04:02<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:02<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:02<01:09,  2.20it/s] 70%|██████▉   | 349/500 [04:03<00:51,  2.96it/s] 70%|███████   | 351/500 [04:09<02:58,  1.20s/it] 71%|███████   | 353/500 [04:09<02:07,  1.16it/s] 71%|███████   | 355/500 [04:09<01:31,  1.59it/s] 71%|███████▏  | 357/500 [04:10<01:06,  2.14it/s] 72%|███████▏  | 359/500 [04:10<00:49,  2.83it/s] 72%|███████▏  | 361/500 [04:16<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:16<01:57,  1.16it/s] 73%|███████▎  | 365/500 [04:16<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:16<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:17<00:44,  2.97it/s] 74%|███████▍  | 371/500 [04:23<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:23<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:23<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:23<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:23<00:41,  2.89it/s] 76%|███████▌  | 381/500 [04:30<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:30<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:30<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:30<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:30<00:37,  3.00it/s] 78%|███████▊  | 391/500 [04:37<02:08,  1.17s/it] 79%|███████▊  | 393/500 [04:37<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:37<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:37<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:37<00:33,  3.02it/s] 80%|████████  | 401/500 [04:43<01:57,  1.18s/it] 81%|████████  | 403/500 [04:44<01:22,  1.18it/s] 81%|████████  | 405/500 [04:44<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:44<00:41,  2.22it/s]7.634433131897822e-05
Valid Loss:  0.00016080084606073797
Epoch:  342  	Training Loss: 0.00012507665087468922
Test Loss:  7.631510379724205e-05
Valid Loss:  0.00016053731087595224
Epoch:  343  	Training Loss: 0.0001248146581929177
Test Loss:  7.623257261002436e-05
Valid Loss:  0.00016028209938667715
Epoch:  344  	Training Loss: 0.00012455732212401927
Test Loss:  7.607160659972578e-05
Valid Loss:  0.00015999181778170168
Epoch:  345  	Training Loss: 0.00012430173228494823
Test Loss:  7.594775524921715e-05
Valid Loss:  0.0001597371301613748
Epoch:  346  	Training Loss: 0.00012405042070895433
Test Loss:  7.576508505735546e-05
Valid Loss:  0.00015944878396112472
Epoch:  347  	Training Loss: 0.00012380076805129647
Test Loss:  7.563304097857326e-05
Valid Loss:  0.00015919982979539782
Epoch:  348  	Training Loss: 0.0001235528034158051
Test Loss:  7.54474604036659e-05
Valid Loss:  0.00015892097144387662
Epoch:  349  	Training Loss: 0.000123307341709733
Test Loss:  7.531867595389485e-05
Valid Loss:  0.0001586802100064233
Epoch:  350  	Training Loss: 0.00012306412099860609
Test Loss:  7.514037133660167e-05
Valid Loss:  0.00015840769628994167
Epoch:  351  	Training Loss: 0.00012282503303140402
Test Loss:  7.501601066906005e-05
Valid Loss:  0.000158171373186633
Epoch:  352  	Training Loss: 0.00012258844799362123
Test Loss:  7.486189861083403e-05
Valid Loss:  0.00015797378728166223
Epoch:  353  	Training Loss: 0.0001224329462274909
Test Loss:  7.478725456167012e-05
Valid Loss:  0.00015780777903273702
Epoch:  354  	Training Loss: 0.00012228800915181637
Test Loss:  7.468197145499289e-05
Valid Loss:  0.00015763948613312095
Epoch:  355  	Training Loss: 0.000122146331705153
Test Loss:  7.45628058211878e-05
Valid Loss:  0.00015747522411402315
Epoch:  356  	Training Loss: 0.00012200631317682564
Test Loss:  7.443875074386597e-05
Valid Loss:  0.0001573106274008751
Epoch:  357  	Training Loss: 0.00012186718231532723
Test Loss:  7.430986443068832e-05
Valid Loss:  0.00015714732580818236
Epoch:  358  	Training Loss: 0.00012172931019449607
Test Loss:  7.418097084155306e-05
Valid Loss:  0.0001569851883687079
Epoch:  359  	Training Loss: 0.00012159279140178114
Test Loss:  7.405445649055764e-05
Valid Loss:  0.00015682686353102326
Epoch:  360  	Training Loss: 0.00012145732762292027
Test Loss:  7.393102714559063e-05
Valid Loss:  0.00015666906256228685
Epoch:  361  	Training Loss: 0.00012132337724324316
Test Loss:  7.380935130640864e-05
Valid Loss:  0.00015651172725483775
Epoch:  362  	Training Loss: 0.00012118983431719244
Test Loss:  7.362711039604619e-05
Valid Loss:  0.00015627637912984937
Epoch:  363  	Training Loss: 0.00012098074512323365
Test Loss:  7.346667553065345e-05
Valid Loss:  0.00015604367945343256
Epoch:  364  	Training Loss: 0.00012077312567271292
Test Loss:  7.3315626650583e-05
Valid Loss:  0.00015581463230773807
Epoch:  365  	Training Loss: 0.00012056649575242773
Test Loss:  7.317077688639984e-05
Valid Loss:  0.00015558605082333088
Epoch:  366  	Training Loss: 0.00012036086991429329
Test Loss:  7.302494486793876e-05
Valid Loss:  0.00015535729471594095
Epoch:  367  	Training Loss: 0.0001201530103571713
Test Loss:  7.288188498932868e-05
Valid Loss:  0.0001551292953081429
Epoch:  368  	Training Loss: 0.00011994657688774168
Test Loss:  7.274116796907037e-05
Valid Loss:  0.0001549033186165616
Epoch:  369  	Training Loss: 0.00011974197695963085
Test Loss:  7.260169513756409e-05
Valid Loss:  0.00015467860794160515
Epoch:  370  	Training Loss: 0.00011953793000429869
Test Loss:  7.246398308780044e-05
Valid Loss:  0.0001544544502394274
Epoch:  371  	Training Loss: 0.00011933501809835434
Test Loss:  7.232903590193018e-05
Valid Loss:  0.0001542315585538745
Epoch:  372  	Training Loss: 0.00011913264461327344
Test Loss:  7.24876081221737e-05
Valid Loss:  0.0001541765668662265
Epoch:  373  	Training Loss: 0.00011908201850019395
Test Loss:  7.26021607988514e-05
Valid Loss:  0.00015412253560498357
Epoch:  374  	Training Loss: 0.00011903513222932816
Test Loss:  7.268328045029193e-05
Valid Loss:  0.0001540720695629716
Epoch:  375  	Training Loss: 0.00011899190576514229
Test Loss:  7.273504888871685e-05
Valid Loss:  0.00015402099234052002
Epoch:  376  	Training Loss: 0.00011894942144863307
Test Loss:  7.276858377736062e-05
Valid Loss:  0.0001539742515888065
Epoch:  377  	Training Loss: 0.00011890817404491827
Test Loss:  7.278859993675724e-05
Valid Loss:  0.00015392774366773665
Epoch:  378  	Training Loss: 0.00011886794527526945
Test Loss:  7.279716373886913e-05
Valid Loss:  0.00015388187603093684
Epoch:  379  	Training Loss: 0.0001188283204101026
Test Loss:  7.27976585039869e-05
Valid Loss:  0.00015383577556349337
Epoch:  380  	Training Loss: 0.00011878941586473957
Test Loss:  7.27904262021184e-05
Valid Loss:  0.00015379025717265904
Epoch:  381  	Training Loss: 0.0001187506495625712
Test Loss:  7.278118573594838e-05
Valid Loss:  0.000153744884300977
Epoch:  382  	Training Loss: 0.00011871170863742009
Test Loss:  7.245373853947967e-05
Valid Loss:  0.00015359363169409335
Epoch:  383  	Training Loss: 0.00011859543883474544
Test Loss:  7.224301225505769e-05
Valid Loss:  0.00015345276915468276
Epoch:  384  	Training Loss: 0.00011848462600028142
Test Loss:  7.209474279079586e-05
Valid Loss:  0.0001533174072392285
Epoch:  385  	Training Loss: 0.00011837635247502476
Test Loss:  7.19799572834745e-05
Valid Loss:  0.00015318312216550112
Epoch:  386  	Training Loss: 0.00011827015259768814
Test Loss:  7.188531890278682e-05
Valid Loss:  0.00015305206761695445
Epoch:  387  	Training Loss: 0.00011816574988188222
Test Loss:  7.180109969340265e-05
Valid Loss:  0.0001529239525552839
Epoch:  388  	Training Loss: 0.00011806155816884711
Test Loss:  7.172061305027455e-05
Valid Loss:  0.00015279623039532453
Epoch:  389  	Training Loss: 0.00011795848695328459
Test Loss:  7.164511771406978e-05
Valid Loss:  0.0001526717096567154
Epoch:  390  	Training Loss: 0.00011785620881710202
Test Loss:  7.157296204240993e-05
Valid Loss:  0.0001525472616776824
Epoch:  391  	Training Loss: 0.00011775502935051918
Test Loss:  7.150518649723381e-05
Valid Loss:  0.0001524245599284768
Epoch:  392  	Training Loss: 0.0001176546502392739
Test Loss:  7.13124536559917e-05
Valid Loss:  0.00015220115892589092
Epoch:  393  	Training Loss: 0.00011747250391636044
Test Loss:  7.116263441275805e-05
Valid Loss:  0.00015198424807749689
Epoch:  394  	Training Loss: 0.00011729412653949112
Test Loss:  7.104561518644914e-05
Valid Loss:  0.0001517797791166231
Epoch:  395  	Training Loss: 0.00011712561536114663
Test Loss:  7.09487430867739e-05
Valid Loss:  0.00015158479800447822
Epoch:  396  	Training Loss: 0.00011696635920088738
Test Loss:  7.082663069013506e-05
Valid Loss:  0.00015135767171159387
Epoch:  397  	Training Loss: 0.00011681053001666442
Test Loss:  7.07596045685932e-05
Valid Loss:  0.00015117813018150628
Epoch:  398  	Training Loss: 0.00011665764031931758
Test Loss:  7.069436833262444e-05
Valid Loss:  0.00015100784366950393
Epoch:  399  	Training Loss: 0.00011650803207885474
Test Loss:  7.059609924908727e-05
Valid Loss:  0.00015080778393894434
Epoch:  400  	Training Loss: 0.000116361552500166
Test Loss:  7.05841594026424e-05
Valid Loss:  0.00015068380162119865
Epoch:  401  	Training Loss: 0.00011621882731560618
Test Loss:  7.044579979265109e-05
Valid Loss:  0.00015045783948153257
Epoch:  402  	Training Loss: 0.00011607823398662731
Test Loss:  7.025535160209984e-05
Valid Loss:  0.00015031217481009662
Epoch:  403  	Training Loss: 0.00011593088129302487
Test Loss:  7.008329703239724e-05
Valid Loss:  0.0001501687802374363
Epoch:  404  	Training Loss: 0.00011578578414628282
Test Loss:  6.992644193815067e-05
Valid Loss:  0.00015003119187895209
Epoch:  405  	Training Loss: 0.00011564412852749228
Test Loss:  6.978229794185609e-05
Valid Loss:  0.00014989783812779933
Epoch:  406  	Training Loss: 0.00011550478666322306
Test Loss:  6.96491842973046e-05
Valid Loss:  0.0001497667544754222
Epoch:  407  	Training Loss: 0.00011536772944964468
Test Loss:  6.952671537874267e-05
Valid Loss:  0.0001496387121733278
Epoch:  408  	Training Loss: 0.00011523273133207113
Test Loss:  6.941257015569136e-05
Valid Loss:  0.00014951269258745015
 82%|████████▏ | 409/500 [04:44<00:30,  2.97it/s] 82%|████████▏ | 411/500 [04:50<01:45,  1.19s/it] 83%|████████▎ | 413/500 [04:50<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:51<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:51<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:51<00:27,  2.99it/s] 84%|████████▍ | 421/500 [04:57<01:34,  1.20s/it] 85%|████████▍ | 423/500 [04:57<01:06,  1.15it/s] 85%|████████▌ | 425/500 [04:58<00:47,  1.58it/s] 85%|████████▌ | 427/500 [04:58<00:34,  2.13it/s] 86%|████████▌ | 429/500 [04:58<00:25,  2.83it/s] 86%|████████▌ | 431/500 [05:04<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:05<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:05<00:40,  1.59it/s] 87%|████████▋ | 437/500 [05:05<00:29,  2.17it/s] 88%|████████▊ | 439/500 [05:05<00:20,  2.92it/s] 88%|████████▊ | 441/500 [05:11<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:11<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:11<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:12<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:12<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:18<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:18<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:18<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:18<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:18<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:25<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:25<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:25<00:22,  1.59it/s] 93%|█████████▎| 467/500 [05:25<00:15,  2.14it/s] 94%|█████████▍| 469/500 [05:26<00:10,  2.84it/s] 94%|█████████▍| 471/500 [05:32<00:35,  1.21s/it] 95%|█████████▍| 473/500 [05:32<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:32<00:15,  1.60it/s]Epoch:  409  	Training Loss: 0.00011510015610838309
Test Loss:  6.930725066922605e-05
Valid Loss:  0.00014939098036848009
Epoch:  410  	Training Loss: 0.00011496849765535444
Test Loss:  6.920679879840463e-05
Valid Loss:  0.0001492702285759151
Epoch:  411  	Training Loss: 0.00011484010610729456
Test Loss:  6.911250238772482e-05
Valid Loss:  0.00014915417705196887
Epoch:  412  	Training Loss: 0.00011471342440927401
Test Loss:  6.918325379956514e-05
Valid Loss:  0.0001490230642957613
Epoch:  413  	Training Loss: 0.00011459067900432274
Test Loss:  6.922806642251089e-05
Valid Loss:  0.0001488969719503075
Epoch:  414  	Training Loss: 0.0001144726702477783
Test Loss:  6.92526446073316e-05
Valid Loss:  0.00014877066132612526
Epoch:  415  	Training Loss: 0.00011435721535235643
Test Loss:  6.92622852511704e-05
Valid Loss:  0.00014864595141261816
Epoch:  416  	Training Loss: 0.00011424324475228786
Test Loss:  6.925834168214351e-05
Valid Loss:  0.00014852148888166994
Epoch:  417  	Training Loss: 0.0001141314278356731
Test Loss:  6.924712943146005e-05
Valid Loss:  0.00014839897630736232
Epoch:  418  	Training Loss: 0.00011402073141653091
Test Loss:  6.922835018485785e-05
Valid Loss:  0.0001482785155531019
Epoch:  419  	Training Loss: 0.0001139112573582679
Test Loss:  6.920399027876556e-05
Valid Loss:  0.0001481572980992496
Epoch:  420  	Training Loss: 0.00011380360228940845
Test Loss:  6.917674909345806e-05
Valid Loss:  0.00014803744852542877
Epoch:  421  	Training Loss: 0.00011369720596121624
Test Loss:  6.914688128745183e-05
Valid Loss:  0.00014792243018746376
Epoch:  422  	Training Loss: 0.00011359314521541819
Test Loss:  6.920587475178763e-05
Valid Loss:  0.00014784513041377068
Epoch:  423  	Training Loss: 0.00011352909496054053
Test Loss:  6.924237823113799e-05
Valid Loss:  0.0001477678888477385
Epoch:  424  	Training Loss: 0.00011346660903654993
Test Loss:  6.926459172973409e-05
Valid Loss:  0.0001476911420468241
Epoch:  425  	Training Loss: 0.00011340515629854053
Test Loss:  6.927858339622617e-05
Valid Loss:  0.00014761247439309955
Epoch:  426  	Training Loss: 0.00011334476585034281
Test Loss:  6.928668153705075e-05
Valid Loss:  0.00014753660070709884
Epoch:  427  	Training Loss: 0.00011328533582855016
Test Loss:  6.929110531928018e-05
Valid Loss:  0.00014745970838703215
Epoch:  428  	Training Loss: 0.00011322654609102756
Test Loss:  6.92938338033855e-05
Valid Loss:  0.00014738398022018373
Epoch:  429  	Training Loss: 0.00011316922609694302
Test Loss:  6.929485243745148e-05
Valid Loss:  0.0001473095326218754
Epoch:  430  	Training Loss: 0.00011311226990073919
Test Loss:  6.929341179784387e-05
Valid Loss:  0.00014723271306138486
Epoch:  431  	Training Loss: 0.00011305586667731404
Test Loss:  6.929192750249058e-05
Valid Loss:  0.00014715893485117704
Epoch:  432  	Training Loss: 0.00011300019832560793
Test Loss:  6.944734923308715e-05
Valid Loss:  0.00014703279884997755
Epoch:  433  	Training Loss: 0.00011290682596154511
Test Loss:  6.950846000108868e-05
Valid Loss:  0.0001469130365876481
Epoch:  434  	Training Loss: 0.0001128198200603947
Test Loss:  6.951696559553966e-05
Valid Loss:  0.00014679538435302675
Epoch:  435  	Training Loss: 0.00011273535346845165
Test Loss:  6.949503585929051e-05
Valid Loss:  0.00014668054063804448
Epoch:  436  	Training Loss: 0.00011265173088759184
Test Loss:  6.945682980585843e-05
Valid Loss:  0.00014656501298304647
Epoch:  437  	Training Loss: 0.00011256966536166146
Test Loss:  6.940845923963934e-05
Valid Loss:  0.00014645214832853526
Epoch:  438  	Training Loss: 0.00011248735245317221
Test Loss:  6.936035788385198e-05
Valid Loss:  0.00014633801765739918
Epoch:  439  	Training Loss: 0.00011240574531257153
Test Loss:  6.930716335773468e-05
Valid Loss:  0.00014622515300288796
Epoch:  440  	Training Loss: 0.00011232470569666475
Test Loss:  6.925230263732374e-05
Valid Loss:  0.00014611371443606913
Epoch:  441  	Training Loss: 0.00011224437912460417
Test Loss:  6.919808947714046e-05
Valid Loss:  0.00014600163558498025
Epoch:  442  	Training Loss: 0.00011216376151423901
Test Loss:  6.882018351461738e-05
Valid Loss:  0.00014584104064852
Epoch:  443  	Training Loss: 0.0001120124725275673
Test Loss:  6.850474164821208e-05
Valid Loss:  0.00014569830091204494
Epoch:  444  	Training Loss: 0.00011187136988155544
Test Loss:  6.8240100517869e-05
Valid Loss:  0.000145566591527313
Epoch:  445  	Training Loss: 0.00011173885286552832
Test Loss:  6.801661947974935e-05
Valid Loss:  0.00014544514124281704
Epoch:  446  	Training Loss: 0.00011161184374941513
Test Loss:  6.782544369343668e-05
Valid Loss:  0.00014533042849507183
Epoch:  447  	Training Loss: 0.0001114889164455235
Test Loss:  6.766094884369522e-05
Valid Loss:  0.00014522240962833166
Epoch:  448  	Training Loss: 0.00011136972170788795
Test Loss:  6.751788896508515e-05
Valid Loss:  0.0001451167045161128
Epoch:  449  	Training Loss: 0.000111252891656477
Test Loss:  6.739293166901916e-05
Valid Loss:  0.000145016674650833
Epoch:  450  	Training Loss: 0.00011113923392258584
Test Loss:  6.728366861352697e-05
Valid Loss:  0.0001449195551685989
Epoch:  451  	Training Loss: 0.00011102679127361625
Test Loss:  6.718661461491138e-05
Valid Loss:  0.00014482601545751095
Epoch:  452  	Training Loss: 0.0001109170843847096
Test Loss:  6.738842057529837e-05
Valid Loss:  0.00014466076390817761
Epoch:  453  	Training Loss: 0.00011077205999754369
Test Loss:  6.751701585017145e-05
Valid Loss:  0.00014451149036176503
Epoch:  454  	Training Loss: 0.00011064090358559042
Test Loss:  6.759147072443739e-05
Valid Loss:  0.00014437084610108286
Epoch:  455  	Training Loss: 0.00011051602632505819
Test Loss:  6.762715929653496e-05
Valid Loss:  0.0001442383072571829
Epoch:  456  	Training Loss: 0.00011039535456802696
Test Loss:  6.763598503312096e-05
Valid Loss:  0.00014410907169803977
Epoch:  457  	Training Loss: 0.00011027720756828785
Test Loss:  6.762327393516898e-05
Valid Loss:  0.00014398276107385755
Epoch:  458  	Training Loss: 0.00011016051576007158
Test Loss:  6.759571260772645e-05
Valid Loss:  0.00014385861868504435
Epoch:  459  	Training Loss: 0.00011004522821167484
Test Loss:  6.755551294190809e-05
Valid Loss:  0.00014373472367879003
Epoch:  460  	Training Loss: 0.00010993051546392962
Test Loss:  6.750588363502175e-05
Valid Loss:  0.0001436162128811702
Epoch:  461  	Training Loss: 0.00010981770901707932
Test Loss:  6.745091377524659e-05
Valid Loss:  0.00014349482080433518
Epoch:  462  	Training Loss: 0.00010970419680234045
Test Loss:  6.732995097991079e-05
Valid Loss:  0.0001433649886166677
Epoch:  463  	Training Loss: 0.0001095732077374123
Test Loss:  6.723131809849292e-05
Valid Loss:  0.00014323668438009918
Epoch:  464  	Training Loss: 0.00010944537643808872
Test Loss:  6.714980554534122e-05
Valid Loss:  0.00014310938422568142
Epoch:  465  	Training Loss: 0.0001093197861337103
Test Loss:  6.708140426781029e-05
Valid Loss:  0.00014298470341600478
Epoch:  466  	Training Loss: 0.00010919547639787197
Test Loss:  6.702321843476966e-05
Valid Loss:  0.00014285864017438143
Epoch:  467  	Training Loss: 0.00010907341493293643
Test Loss:  6.697293429169804e-05
Valid Loss:  0.00014273630222305655
Epoch:  468  	Training Loss: 0.00010895283048739657
Test Loss:  6.692739407299086e-05
Valid Loss:  0.0001426135713700205
Epoch:  469  	Training Loss: 0.00010883326467592269
Test Loss:  6.688787834718823e-05
Valid Loss:  0.00014249577361624688
Epoch:  470  	Training Loss: 0.0001087155396817252
Test Loss:  6.684786785626784e-05
Valid Loss:  0.00014237468712963164
Epoch:  471  	Training Loss: 0.00010859909525606781
Test Loss:  6.68109641992487e-05
Valid Loss:  0.0001422567875124514
Epoch:  472  	Training Loss: 0.00010848412057384849
Test Loss:  6.668869173154235e-05
Valid Loss:  0.0001421097113052383
Epoch:  473  	Training Loss: 0.00010834576096385717
Test Loss:  6.660393410129473e-05
Valid Loss:  0.00014196758274920285
Epoch:  474  	Training Loss: 0.00010821088653756306
Test Loss:  6.654365279246122e-05
Valid Loss:  0.00014183029998093843
Epoch:  475  	Training Loss: 0.00010807853686856106
Test Loss:  6.649941497016698e-05
Valid Loss:  0.00014169298810884356
Epoch:  476  	Training Loss: 0.00010794833360705525
 95%|█████████▌| 477/500 [05:32<00:10,  2.18it/s] 96%|█████████▌| 479/500 [05:32<00:07,  2.94it/s] 96%|█████████▌| 481/500 [05:39<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:39<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:39<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:39<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:39<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:46<00:10,  1.22s/it] 99%|█████████▊| 493/500 [05:46<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:46<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:46<00:01,  2.17it/s]100%|█████████▉| 499/500 [05:46<00:00,  2.93it/s]100%|██████████| 500/500 [05:46<00:00,  1.44it/s]
Test Loss:  6.646543624810874e-05
Valid Loss:  0.00014155761164147407
Epoch:  477  	Training Loss: 0.00010781938908621669
Test Loss:  6.643941742368042e-05
Valid Loss:  0.00014142529107630253
Epoch:  478  	Training Loss: 0.00010769153595902026
Test Loss:  6.641494110226631e-05
Valid Loss:  0.0001412954879924655
Epoch:  479  	Training Loss: 0.00010756785195553675
Test Loss:  6.639461207669228e-05
Valid Loss:  0.0001411670382367447
Epoch:  480  	Training Loss: 0.00010744418977992609
Test Loss:  6.637451588176191e-05
Valid Loss:  0.0001410420227330178
Epoch:  481  	Training Loss: 0.00010732415830716491
Test Loss:  6.635914905928075e-05
Valid Loss:  0.00014091806951910257
Epoch:  482  	Training Loss: 0.00010720480349846184
Test Loss:  6.636482430621982e-05
Valid Loss:  0.00014083222777117044
Epoch:  483  	Training Loss: 0.0001071271180990152
Test Loss:  6.635954923694953e-05
Valid Loss:  0.00014074771024752408
Epoch:  484  	Training Loss: 0.00010705113527365029
Test Loss:  6.634970486629754e-05
Valid Loss:  0.0001406657975167036
Epoch:  485  	Training Loss: 0.00010697591642383486
Test Loss:  6.633755401708186e-05
Valid Loss:  0.0001405834045726806
Epoch:  486  	Training Loss: 0.00010690191993489861
Test Loss:  6.632009171880782e-05
Valid Loss:  0.00014050165191292763
Epoch:  487  	Training Loss: 0.00010682836000341922
Test Loss:  6.630124698858708e-05
Valid Loss:  0.00014042042312212288
Epoch:  488  	Training Loss: 0.000106755607703235
Test Loss:  6.628174014622346e-05
Valid Loss:  0.00014033955812919885
Epoch:  489  	Training Loss: 0.00010668335016816854
Test Loss:  6.626112008234486e-05
Valid Loss:  0.00014026201097294688
Epoch:  490  	Training Loss: 0.00010661143460310996
Test Loss:  6.623966328334063e-05
Valid Loss:  0.00014018092770129442
Epoch:  491  	Training Loss: 0.00010654005745891482
Test Loss:  6.621739885304123e-05
Valid Loss:  0.00014010310405865312
Epoch:  492  	Training Loss: 0.0001064693569787778
Test Loss:  6.640350329689682e-05
Valid Loss:  0.00013995563494972885
Epoch:  493  	Training Loss: 0.00010635914077283815
Test Loss:  6.65172265144065e-05
Valid Loss:  0.00013983355893287808
Epoch:  494  	Training Loss: 0.0001062643714249134
Test Loss:  6.657825724687427e-05
Valid Loss:  0.00013972463784739375
Epoch:  495  	Training Loss: 0.0001061763905454427
Test Loss:  6.660353392362595e-05
Valid Loss:  0.00013962233788333833
Epoch:  496  	Training Loss: 0.0001060915383277461
Test Loss:  6.660357030341402e-05
Valid Loss:  0.00013952612061984837
Epoch:  497  	Training Loss: 0.00010600863606669009
Test Loss:  6.658781785517931e-05
Valid Loss:  0.00013943342491984367
Epoch:  498  	Training Loss: 0.00010592608305159956
Test Loss:  6.656151526840404e-05
Valid Loss:  0.0001393423299305141
Epoch:  499  	Training Loss: 0.00010584563278825954
Test Loss:  6.652707088505849e-05
Valid Loss:  0.0001392535341437906
Epoch:  500  	Training Loss: 0.00010576535714790225
Test Loss:  6.648917042184621e-05
Valid Loss:  0.00013916513125877827
seed is  6
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 15.06it/s]  1%|          | 4/500 [00:00<00:33, 14.78it/s]  1%|          | 6/500 [00:00<00:32, 15.31it/s]  2%|▏         | 8/500 [00:00<00:32, 14.95it/s]  2%|▏         | 10/500 [00:00<00:31, 15.35it/s]  2%|▏         | 12/500 [00:00<00:31, 15.62it/s]  3%|▎         | 14/500 [00:00<00:30, 15.81it/s]  3%|▎         | 16/500 [00:01<00:30, 15.98it/s]  4%|▎         | 18/500 [00:01<00:30, 15.68it/s]  4%|▍         | 20/500 [00:01<00:30, 15.87it/s]  4%|▍         | 22/500 [00:01<00:29, 16.03it/s]  5%|▍         | 24/500 [00:01<00:29, 16.16it/s]  5%|▌         | 26/500 [00:01<00:29, 16.21it/s]  6%|▌         | 28/500 [00:01<00:29, 16.19it/s]  6%|▌         | 30/500 [00:01<00:29, 16.18it/s]  6%|▋         | 32/500 [00:02<00:28, 16.30it/s]  7%|▋         | 34/500 [00:02<00:28, 16.32it/s]  7%|▋         | 36/500 [00:02<00:28, 16.37it/s]  8%|▊         | 38/500 [00:02<00:28, 16.39it/s]  8%|▊         | 40/500 [00:02<00:28, 16.33it/s]  8%|▊         | 42/500 [00:02<00:28, 16.31it/s]  9%|▉         | 44/500 [00:02<00:27, 16.35it/s]  9%|▉         | 46/500 [00:02<00:27, 16.41it/s] 10%|▉         | 48/500 [00:02<00:27, 16.45it/s] 10%|█         | 50/500 [00:03<00:27, 16.53it/s] 10%|█         | 52/500 [00:03<00:27, 16.49it/s] 11%|█         | 54/500 [00:03<00:27, 16.38it/s] 11%|█         | 56/500 [00:03<00:27, 16.39it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.40it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.42it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.31it/s] 13%|█▎        | 64/500 [00:03<00:27, 15.86it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.75it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.63it/s] 14%|█▍        | 70/500 [00:04<00:29, 14.49it/s] 14%|█▍        | 72/500 [00:04<00:30, 14.12it/s] 15%|█▍        | 74/500 [00:04<00:31, 13.53it/s] 15%|█▌        | 76/500 [00:04<00:32, 13.09it/s] 16%|█▌        | 78/500 [00:05<00:32, 12.86it/s] 16%|█▌        | 80/500 [00:05<00:33, 12.55it/s] 16%|█▋        | 82/500 [00:05<00:33, 12.47it/s] 17%|█▋        | 84/500 [00:05<00:33, 12.40it/s] 17%|█▋        | 86/500 [00:05<00:33, 12.34it/s] 18%|█▊        | 88/500 [00:05<00:33, 12.38it/s] 18%|█▊        | 90/500 [00:05<00:31, 13.16it/s] 18%|█▊        | 92/500 [00:06<00:29, 14.00it/s] 19%|█▉        | 94/500 [00:06<00:28, 14.38it/s] 19%|█▉        | 96/500 [00:06<00:28, 14.31it/s] 20%|█▉        | 98/500 [00:06<00:27, 14.83it/s] 20%|██        | 100/500 [00:06<00:26, 15.31it/s] 20%|██        | 102/500 [00:06<00:25, 15.60it/s] 21%|██        | 104/500 [00:06<00:24, 15.85it/s] 21%|██        | 106/500 [00:06<00:24, 16.04it/s] 22%|██▏       | 108/500 [00:07<00:24, 16.15it/s] 22%|██▏       | 110/500 [00:07<00:24, 15.86it/s] 22%|██▏       | 112/500 [00:07<00:24, 16.01it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.09it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.12it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.16it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.24it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.28it/s] 25%|██▍       | 124/500 [00:08<00:23, 16.32it/s]Epoch:  1  	Training Loss: 0.02478910982608795
Test Loss:  79.09754180908203
Valid Loss:  79.13819885253906
Epoch:  2  	Training Loss: 79.16827392578125
Test Loss:  28236212224.0
Valid Loss:  28037105664.0
Epoch:  3  	Training Loss: 27871531008.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:22, 16.30it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.29it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.27it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.33it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.36it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.33it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.22it/s] 28%|██▊       | 140/500 [00:09<00:22, 16.25it/s] 28%|██▊       | 142/500 [00:09<00:22, 16.05it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.83it/s] 29%|██▉       | 146/500 [00:09<00:24, 14.35it/s] 30%|██▉       | 148/500 [00:09<00:24, 14.32it/s] 30%|███       | 150/500 [00:09<00:23, 14.71it/s] 30%|███       | 152/500 [00:09<00:23, 14.94it/s] 31%|███       | 154/500 [00:10<00:22, 15.06it/s] 31%|███       | 156/500 [00:10<00:23, 14.55it/s] 32%|███▏      | 158/500 [00:10<00:23, 14.78it/s] 32%|███▏      | 160/500 [00:10<00:22, 15.10it/s] 32%|███▏      | 162/500 [00:10<00:22, 15.36it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.61it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.68it/s] 34%|███▎      | 168/500 [00:10<00:20, 15.93it/s] 34%|███▍      | 170/500 [00:11<00:20, 16.15it/s] 34%|███▍      | 172/500 [00:11<00:20, 16.28it/s] 35%|███▍      | 174/500 [00:11<00:19, 16.34it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.31it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.22it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.09it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.10it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.18it/s] 37%|███▋      | 186/500 [00:12<00:19, 16.26it/s] 38%|███▊      | 188/500 [00:12<00:19, 16.33it/s] 38%|███▊      | 190/500 [00:12<00:18, 16.41it/s] 38%|███▊      | 192/500 [00:12<00:18, 16.22it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.14it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.08it/s] 40%|███▉      | 198/500 [00:12<00:18, 15.98it/s] 40%|████      | 200/500 [00:12<00:19, 15.24it/s] 40%|████      | 202/500 [00:13<00:21, 14.16it/s] 41%|████      | 204/500 [00:13<00:21, 13.62it/s] 41%|████      | 206/500 [00:13<00:20, 14.35it/s] 42%|████▏     | 208/500 [00:13<00:19, 14.97it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.40it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.67it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.88it/s] 43%|████▎     | 216/500 [00:13<00:17, 15.91it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.02it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.15it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.23it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.31it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.12it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.22it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.24it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.15it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.17it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.81it/s] 48%|████▊     | 238/500 [00:15<00:16, 15.77it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.72it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.82it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.76it/s] 49%|████▉     | 246/500 [00:15<00:15, 15.94it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.06it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 15.96it/s] 50%|█████     | 252/500 [00:16<00:15, 16.02it/s] 51%|█████     | 254/500 [00:16<00:15, 16.19it/s] 51%|█████     | 256/500 [00:16<00:15, 16.25it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.37it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.85it/s] 52%|█████▏    | 262/500 [00:16<00:14, 15.96it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.06it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.13it/s] 54%|█████▎    | 268/500 [00:17<00:15, 15.07it/s] 54%|█████▍    | 270/500 [00:17<00:16, 14.07it/s] 54%|█████▍    | 272/500 [00:17<00:17, 13.30it/s] 55%|█████▍    | 274/500 [00:17<00:17, 12.95it/s] 55%|█████▌    | 276/500 [00:17<00:17, 12.79it/s] 56%|█████▌    | 278/500 [00:18<00:17, 12.56it/s] 56%|█████▌    | 280/500 [00:18<00:17, 12.51it/s] 56%|█████▋    | 282/500 [00:18<00:17, 12.46it/s] 57%|█████▋    | 284/500 [00:18<00:17, 12.40it/s] 57%|█████▋    | 286/500 [00:18<00:17, 12.41it/s] 58%|█████▊    | 288/500 [00:18<00:17, 12.39it/s] 58%|█████▊    | 290/500 [00:19<00:16, 12.38it/s] 58%|█████▊    | 292/500 [00:19<00:16, 12.39it/s] 59%|█████▉    | 294/500 [00:19<00:16, 12.34it/s] 59%|█████▉    | 296/500 [00:19<00:16, 12.35it/s] 60%|█████▉    | 298/500 [00:19<00:16, 12.32it/s] 60%|██████    | 300/500 [00:19<00:16, 12.28it/s] 60%|██████    | 302/500 [00:20<00:16, 12.31it/s] 61%|██████    | 304/500 [00:20<00:15, 12.33it/s] 61%|██████    | 306/500 [00:20<00:15, 12.31it/s] 62%|██████▏   | 308/500 [00:20<00:15, 12.30it/s] 62%|██████▏   | 310/500 [00:20<00:15, 12.27it/s] 62%|██████▏   | 312/500 [00:20<00:15, 12.31it/s] 63%|██████▎   | 314/500 [00:21<00:15, 12.31it/s] 63%|██████▎   | 316/500 [00:21<00:14, 12.32it/s] 64%|██████▎   | 318/500 [00:21<00:14, 12.29it/s] 64%|██████▍   | 320/500 [00:21<00:14, 12.29it/s] 64%|██████▍   | 322/500 [00:21<00:14, 12.30it/s] 65%|██████▍   | 324/500 [00:21<00:14, 12.31it/s] 65%|██████▌   | 326/500 [00:21<00:14, 12.34it/s] 66%|██████▌   | 328/500 [00:22<00:13, 12.34it/s] 66%|██████▌   | 330/500 [00:22<00:13, 12.33it/s] 66%|██████▋   | 332/500 [00:22<00:13, 12.32it/s] 67%|██████▋   | 334/500 [00:22<00:13, 12.33it/s] 67%|██████▋   | 336/500 [00:22<00:13, 12.35it/s] 68%|██████▊   | 338/500 [00:22<00:13, 12.33it/s] 68%|██████▊   | 340/500 [00:23<00:12, 12.33it/s] 68%|██████▊   | 342/500 [00:23<00:12, 12.34it/s] 69%|██████▉   | 344/500 [00:23<00:12, 12.36it/s] 69%|██████▉   | 346/500 [00:23<00:11, 13.02it/s] 70%|██████▉   | 348/500 [00:23<00:11, 13.63it/s] 70%|███████   | 350/500 [00:23<00:11, 13.63it/s] 70%|███████   | 352/500 [00:23<00:10, 14.04it/s] 71%|███████   | 354/500 [00:24<00:10, 14.34it/s] 71%|███████   | 356/500 [00:24<00:09, 14.87it/s] 72%|███████▏  | 358/500 [00:24<00:09, 15.33it/s] 72%|███████▏  | 360/500 [00:24<00:08, 15.64it/s] 72%|███████▏  | 362/500 [00:24<00:08, 15.91it/s] 73%|███████▎  | 364/500 [00:24<00:08, 16.01it/s] 73%|███████▎  | 366/500 [00:24<00:08, 16.10it/s] 74%|███████▎  | 368/500 [00:24<00:08, 16.18it/s] 74%|███████▍  | 370/500 [00:25<00:08, 15.83it/s] 74%|███████▍  | 372/500 [00:25<00:08, 14.36it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:25<00:09, 13.69it/s] 75%|███████▌  | 376/500 [00:25<00:09, 13.27it/s] 76%|███████▌  | 378/500 [00:25<00:09, 13.29it/s] 76%|███████▌  | 380/500 [00:25<00:09, 13.08it/s] 76%|███████▋  | 382/500 [00:26<00:08, 13.20it/s] 77%|███████▋  | 384/500 [00:26<00:08, 12.92it/s] 77%|███████▋  | 386/500 [00:26<00:08, 12.74it/s] 78%|███████▊  | 388/500 [00:26<00:08, 12.64it/s] 78%|███████▊  | 390/500 [00:26<00:08, 12.48it/s] 78%|███████▊  | 392/500 [00:26<00:08, 12.43it/s] 79%|███████▉  | 394/500 [00:26<00:08, 13.02it/s] 79%|███████▉  | 396/500 [00:27<00:07, 13.87it/s] 80%|███████▉  | 398/500 [00:27<00:07, 14.50it/s] 80%|████████  | 400/500 [00:27<00:06, 15.03it/s] 80%|████████  | 402/500 [00:27<00:06, 15.48it/s] 81%|████████  | 404/500 [00:27<00:06, 15.82it/s] 81%|████████  | 406/500 [00:27<00:05, 16.05it/s] 82%|████████▏ | 408/500 [00:27<00:05, 16.22it/s] 82%|████████▏ | 410/500 [00:27<00:05, 16.26it/s] 82%|████████▏ | 412/500 [00:28<00:05, 16.32it/s] 83%|████████▎ | 414/500 [00:28<00:05, 16.29it/s] 83%|████████▎ | 416/500 [00:28<00:05, 16.28it/s] 84%|████████▎ | 418/500 [00:28<00:05, 16.32it/s] 84%|████████▍ | 420/500 [00:28<00:04, 16.35it/s] 84%|████████▍ | 422/500 [00:28<00:04, 15.82it/s] 85%|████████▍ | 424/500 [00:28<00:05, 14.55it/s] 85%|████████▌ | 426/500 [00:29<00:05, 14.48it/s] 86%|████████▌ | 428/500 [00:29<00:04, 15.00it/s] 86%|████████▌ | 430/500 [00:29<00:04, 15.08it/s] 86%|████████▋ | 432/500 [00:29<00:04, 14.13it/s] 87%|████████▋ | 434/500 [00:29<00:04, 13.54it/s] 87%|████████▋ | 436/500 [00:29<00:04, 13.09it/s] 88%|████████▊ | 438/500 [00:29<00:04, 12.89it/s] 88%|████████▊ | 440/500 [00:30<00:04, 13.58it/s] 88%|████████▊ | 442/500 [00:30<00:04, 14.15it/s] 89%|████████▉ | 444/500 [00:30<00:03, 14.69it/s] 89%|████████▉ | 446/500 [00:30<00:03, 15.12it/s] 90%|████████▉ | 448/500 [00:30<00:03, 15.48it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.73it/s] 90%|█████████ | 452/500 [00:30<00:03, 15.73it/s] 91%|█████████ | 454/500 [00:30<00:02, 15.64it/s] 91%|█████████ | 456/500 [00:31<00:02, 15.91it/s] 92%|█████████▏| 458/500 [00:31<00:02, 16.09it/s] 92%|█████████▏| 460/500 [00:31<00:02, 16.15it/s] 92%|█████████▏| 462/500 [00:31<00:02, 16.06it/s] 93%|█████████▎| 464/500 [00:31<00:02, 16.01it/s] 93%|█████████▎| 466/500 [00:31<00:02, 16.18it/s] 94%|█████████▎| 468/500 [00:31<00:01, 16.29it/s] 94%|█████████▍| 470/500 [00:31<00:01, 16.33it/s] 94%|█████████▍| 472/500 [00:32<00:01, 16.39it/s] 95%|█████████▍| 474/500 [00:32<00:01, 16.02it/s] 95%|█████████▌| 476/500 [00:32<00:01, 16.03it/s] 96%|█████████▌| 478/500 [00:32<00:01, 16.18it/s] 96%|█████████▌| 480/500 [00:32<00:01, 16.29it/s] 96%|█████████▋| 482/500 [00:32<00:01, 16.29it/s] 97%|█████████▋| 484/500 [00:32<00:00, 16.29it/s] 97%|█████████▋| 486/500 [00:32<00:00, 16.32it/s] 98%|█████████▊| 488/500 [00:33<00:00, 16.34it/s] 98%|█████████▊| 490/500 [00:33<00:00, 16.41it/s] 98%|█████████▊| 492/500 [00:33<00:00, 16.45it/s] 99%|█████████▉| 494/500 [00:33<00:00, 16.33it/s] 99%|█████████▉| 496/500 [00:33<00:00, 16.44it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:33<00:00, 16.43it/s]100%|██████████| 500/500 [00:33<00:00, 16.46it/s]100%|██████████| 500/500 [00:33<00:00, 14.82it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  6
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:30,  6.19s/it]  1%|          | 3/500 [00:06<13:50,  1.67s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<10:46,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:36,  1.20s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:58,  1.59it/s]  5%|▌         | 27/500 [00:20<03:36,  2.18it/s]  6%|▌         | 29/500 [00:20<02:39,  2.94it/s]  6%|▌         | 31/500 [00:26<09:17,  1.19s/it]  7%|▋         | 33/500 [00:26<06:37,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:33<09:09,  1.20s/it]  9%|▊         | 43/500 [00:33<06:35,  1.16it/s]  9%|▉         | 45/500 [00:34<04:46,  1.59it/s]  9%|▉         | 47/500 [00:34<03:31,  2.14it/s] 10%|▉         | 49/500 [00:34<02:38,  2.84it/s] 10%|█         | 51/500 [00:40<08:58,  1.20s/it] 11%|█         | 53/500 [00:40<06:25,  1.16it/s] 11%|█         | 55/500 [00:41<04:37,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:47<08:46,  1.20s/it] 13%|█▎        | 63/500 [00:47<06:18,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:34,  1.58it/s] 13%|█▎        | 67/500 [00:48<03:22,  2.14it/s] 14%|█▍        | 69/500 [00:48<02:32,  2.83it/s] 14%|█▍        | 71/500 [00:54<08:43,  1.22s/it]Epoch:  1  	Training Loss: 0.02478910982608795
Test Loss:  0.44266611337661743
Valid Loss:  0.450479656457901
Epoch:  2  	Training Loss: 0.4570506513118744
Test Loss:  3.9116806983947754
Valid Loss:  3.8434042930603027
Epoch:  3  	Training Loss: 3.730052947998047
Test Loss:  0.03619628772139549
Valid Loss:  0.040726013481616974
Epoch:  4  	Training Loss: 0.03899862617254257
Test Loss:  0.036194831132888794
Valid Loss:  0.040724560618400574
Epoch:  5  	Training Loss: 0.03899729624390602
Test Loss:  0.03619338199496269
Valid Loss:  0.040723107755184174
Epoch:  6  	Training Loss: 0.03899596631526947
Test Loss:  0.036191925406455994
Valid Loss:  0.04072165489196777
Epoch:  7  	Training Loss: 0.03899464011192322
Test Loss:  0.036190472543239594
Valid Loss:  0.04072020202875137
Epoch:  8  	Training Loss: 0.038993313908576965
Test Loss:  0.03618901968002319
Valid Loss:  0.04071874916553497
Epoch:  9  	Training Loss: 0.03899198770523071
Test Loss:  0.03618756681680679
Valid Loss:  0.04071729630231857
Epoch:  10  	Training Loss: 0.03899066150188446
Test Loss:  0.036186110228300095
Valid Loss:  0.04071584716439247
Epoch:  11  	Training Loss: 0.03898933529853821
Test Loss:  0.03618466109037399
Valid Loss:  0.04071439802646637
Epoch:  12  	Training Loss: 0.038988009095191956
Test Loss:  0.036170899868011475
Valid Loss:  0.04069991782307625
Epoch:  13  	Training Loss: 0.0389740988612175
Test Loss:  0.036157142370939255
Valid Loss:  0.04068545252084732
Epoch:  14  	Training Loss: 0.03896019235253334
Test Loss:  0.03614338859915733
Valid Loss:  0.040670983493328094
Epoch:  15  	Training Loss: 0.03894629329442978
Test Loss:  0.03612963855266571
Valid Loss:  0.040656521916389465
Epoch:  16  	Training Loss: 0.038932397961616516
Test Loss:  0.03611588478088379
Valid Loss:  0.040642060339450836
Epoch:  17  	Training Loss: 0.03891850262880325
Test Loss:  0.03610214963555336
Valid Loss:  0.040627606213092804
Epoch:  18  	Training Loss: 0.03890461474657059
Test Loss:  0.03608841821551323
Valid Loss:  0.04061315953731537
Epoch:  19  	Training Loss: 0.03889073431491852
Test Loss:  0.03607485443353653
Valid Loss:  0.04059888422489166
Epoch:  20  	Training Loss: 0.03887706249952316
Test Loss:  0.036061495542526245
Valid Loss:  0.04058480262756348
Epoch:  21  	Training Loss: 0.038863539695739746
Test Loss:  0.03604816645383835
Valid Loss:  0.040570758283138275
Epoch:  22  	Training Loss: 0.03885003179311752
Test Loss:  0.03603469207882881
Valid Loss:  0.04055655002593994
Epoch:  23  	Training Loss: 0.038836363703012466
Test Loss:  0.03602122515439987
Valid Loss:  0.0405423641204834
Epoch:  24  	Training Loss: 0.0388227142393589
Test Loss:  0.036007776856422424
Valid Loss:  0.040528200566768646
Epoch:  25  	Training Loss: 0.038809068500995636
Test Loss:  0.03599432855844498
Valid Loss:  0.0405140295624733
Epoch:  26  	Training Loss: 0.03879542648792267
Test Loss:  0.035980887711048126
Valid Loss:  0.040499866008758545
Epoch:  27  	Training Loss: 0.038781795650720596
Test Loss:  0.03596746549010277
Valid Loss:  0.04048571735620499
Epoch:  28  	Training Loss: 0.03876817226409912
Test Loss:  0.03595404326915741
Valid Loss:  0.04047156870365143
Epoch:  29  	Training Loss: 0.038754552602767944
Test Loss:  0.03594063222408295
Valid Loss:  0.04045742750167847
Epoch:  30  	Training Loss: 0.038740936666727066
Test Loss:  0.035927221179008484
Valid Loss:  0.0404432937502861
Epoch:  31  	Training Loss: 0.038727328181266785
Test Loss:  0.03591381758451462
Valid Loss:  0.04042915999889374
Epoch:  32  	Training Loss: 0.0387137234210968
Test Loss:  0.035899657756090164
Valid Loss:  0.0404142364859581
Epoch:  33  	Training Loss: 0.038699351251125336
Test Loss:  0.03588550537824631
Valid Loss:  0.04039931669831276
Epoch:  34  	Training Loss: 0.03868498653173447
Test Loss:  0.035871364176273346
Valid Loss:  0.04038439691066742
Epoch:  35  	Training Loss: 0.03867063671350479
Test Loss:  0.03585723042488098
Valid Loss:  0.04036949574947357
Epoch:  36  	Training Loss: 0.038656286895275116
Test Loss:  0.03584309294819832
Valid Loss:  0.04035460203886032
Epoch:  37  	Training Loss: 0.03864194452762604
Test Loss:  0.03582896664738655
Valid Loss:  0.04033970460295677
Epoch:  38  	Training Loss: 0.038627609610557556
Test Loss:  0.03581485524773598
Valid Loss:  0.04032482951879501
Epoch:  39  	Training Loss: 0.03861328214406967
Test Loss:  0.0358007475733757
Valid Loss:  0.04030995070934296
Epoch:  40  	Training Loss: 0.038598962128162384
Test Loss:  0.03578663617372513
Valid Loss:  0.0402950756251812
Epoch:  41  	Training Loss: 0.03858464956283569
Test Loss:  0.03577253967523575
Valid Loss:  0.04028021916747093
Epoch:  42  	Training Loss: 0.0385703444480896
Test Loss:  0.03575798124074936
Valid Loss:  0.04026486352086067
Epoch:  43  	Training Loss: 0.0385555662214756
Test Loss:  0.035743433982133865
Valid Loss:  0.040249526500701904
Epoch:  44  	Training Loss: 0.0385407954454422
Test Loss:  0.03572888672351837
Valid Loss:  0.04023418575525284
Epoch:  45  	Training Loss: 0.038526035845279694
Test Loss:  0.035714343190193176
Valid Loss:  0.04021886736154556
Epoch:  46  	Training Loss: 0.038511279970407486
Test Loss:  0.035699810832738876
Valid Loss:  0.04020354151725769
Epoch:  47  	Training Loss: 0.038496531546115875
Test Loss:  0.03568528592586517
Valid Loss:  0.040188226848840714
Epoch:  48  	Training Loss: 0.03848178684711456
Test Loss:  0.03567076474428177
Valid Loss:  0.040172919631004333
Epoch:  49  	Training Loss: 0.038467053323984146
Test Loss:  0.03565625101327896
Valid Loss:  0.040157612413167953
Epoch:  50  	Training Loss: 0.03845232352614403
Test Loss:  0.03564174845814705
Valid Loss:  0.040142327547073364
Epoch:  51  	Training Loss: 0.038437604904174805
Test Loss:  0.035627253353595734
Valid Loss:  0.04012703895568848
Epoch:  52  	Training Loss: 0.03842289000749588
Test Loss:  0.03561244532465935
Valid Loss:  0.040111422538757324
Epoch:  53  	Training Loss: 0.038407858461141586
Test Loss:  0.03559763729572296
Valid Loss:  0.04009581357240677
Epoch:  54  	Training Loss: 0.03839282691478729
Test Loss:  0.03558284416794777
Valid Loss:  0.04008020460605621
Epoch:  55  	Training Loss: 0.038377806544303894
Test Loss:  0.035568054765462875
Valid Loss:  0.04006461426615715
Epoch:  56  	Training Loss: 0.038362786173820496
Test Loss:  0.03555326908826828
Valid Loss:  0.04004901647567749
Epoch:  57  	Training Loss: 0.03834778070449829
Test Loss:  0.03553849831223488
Valid Loss:  0.04003344476222992
Epoch:  58  	Training Loss: 0.038332778960466385
Test Loss:  0.03552372753620148
Valid Loss:  0.04001786559820175
Epoch:  59  	Training Loss: 0.038317784667015076
Test Loss:  0.03550896793603897
Valid Loss:  0.04000229761004448
Epoch:  60  	Training Loss: 0.03830280154943466
Test Loss:  0.03549421206116676
Valid Loss:  0.0399867407977581
Epoch:  61  	Training Loss: 0.03828781843185425
Test Loss:  0.035479459911584854
Valid Loss:  0.03997118026018143
Epoch:  62  	Training Loss: 0.03827284276485443
Test Loss:  0.03546448424458504
Valid Loss:  0.03995538502931595
Epoch:  63  	Training Loss: 0.03825763240456581
Test Loss:  0.03544950857758522
Valid Loss:  0.03993958979845047
Epoch:  64  	Training Loss: 0.03824242576956749
Test Loss:  0.035434540361166
Valid Loss:  0.03992380201816559
Epoch:  65  	Training Loss: 0.038227230310440063
Test Loss:  0.03541957959532738
Valid Loss:  0.039908021688461304
Epoch:  66  	Training Loss: 0.038212038576602936
Test Loss:  0.03540463000535965
Valid Loss:  0.03989225625991821
Epoch:  67  	Training Loss: 0.038196854293346405
Test Loss:  0.03538968414068222
Valid Loss:  0.03987649083137512
Epoch:  68  	Training Loss: 0.03818167746067047
Test Loss:  0.03537474200129509
Valid Loss:  0.03986073285341263
Epoch:  69  	Training Loss: 0.038166508078575134
Test Loss:  0.03535981848835945
Valid Loss:  0.03984498977661133
Epoch:  70  	Training Loss: 0.038151346147060394
Test Loss:  0.035344891250133514
Valid Loss:  0.03982924669981003
Epoch:  71  	Training Loss: 0.03813619166612625
Test Loss:  0.03532997518777847
Valid Loss:  0.03981351479887962
Epoch:  72  	Training Loss: 0.0381210520863533
Test Loss:  0.035314857959747314
Valid Loss:  0.039797574281692505
 15%|█▍        | 73/500 [00:55<06:16,  1.13it/s] 15%|█▌        | 75/500 [00:55<04:33,  1.56it/s] 15%|█▌        | 77/500 [00:55<03:20,  2.11it/s] 16%|█▌        | 79/500 [00:55<02:27,  2.85it/s] 16%|█▌        | 81/500 [01:01<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:02<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:02<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:02<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:02<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:08<08:13,  1.21s/it] 19%|█▊        | 93/500 [01:09<05:52,  1.15it/s] 19%|█▉        | 95/500 [01:09<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.18it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.94it/s] 20%|██        | 101/500 [01:15<07:52,  1.18s/it] 21%|██        | 103/500 [01:15<05:37,  1.18it/s] 21%|██        | 105/500 [01:16<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:16<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:16<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:22<07:39,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:22<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:23<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:29<07:25,  1.18s/it] 25%|██▍       | 123/500 [01:29<05:18,  1.19it/s] 25%|██▌       | 125/500 [01:29<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:29<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:29<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:36<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:36<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:36<03:48,  1.59it/s] 27%|██▋       | 137/500 [01:36<02:48,  2.15it/s] 28%|██▊       | 139/500 [01:37<02:06,  2.85it/s] 28%|██▊       | 141/500 [01:43<07:24,  1.24s/it] 29%|██▊       | 143/500 [01:43<05:16,  1.13it/s]Epoch:  73  	Training Loss: 0.03810570761561394
Test Loss:  0.03529975190758705
Valid Loss:  0.03978164494037628
Epoch:  74  	Training Loss: 0.03809037059545517
Test Loss:  0.03528464585542679
Valid Loss:  0.03976571559906006
Epoch:  75  	Training Loss: 0.038075048476457596
Test Loss:  0.03526955842971802
Valid Loss:  0.039749808609485626
Epoch:  76  	Training Loss: 0.03805973008275032
Test Loss:  0.03525448217988014
Valid Loss:  0.0397338941693306
Epoch:  77  	Training Loss: 0.03804442286491394
Test Loss:  0.03523939847946167
Valid Loss:  0.03971799835562706
Epoch:  78  	Training Loss: 0.03802911937236786
Test Loss:  0.03522432595491409
Valid Loss:  0.03970210999250412
Epoch:  79  	Training Loss: 0.03801382705569267
Test Loss:  0.03520926460623741
Valid Loss:  0.03968622535467148
Epoch:  80  	Training Loss: 0.037998538464307785
Test Loss:  0.03519420698285103
Valid Loss:  0.039670348167419434
Epoch:  81  	Training Loss: 0.037983257323503494
Test Loss:  0.03517916053533554
Valid Loss:  0.039654478430747986
Epoch:  82  	Training Loss: 0.0379679836332798
Test Loss:  0.0351640060544014
Valid Loss:  0.03963850066065788
Epoch:  83  	Training Loss: 0.03795260563492775
Test Loss:  0.03514885902404785
Valid Loss:  0.039622530341148376
Epoch:  84  	Training Loss: 0.037937238812446594
Test Loss:  0.0351337268948555
Valid Loss:  0.039606571197509766
Epoch:  85  	Training Loss: 0.03792187571525574
Test Loss:  0.03511859476566315
Valid Loss:  0.039590612053871155
Epoch:  86  	Training Loss: 0.037906523793935776
Test Loss:  0.03510347381234169
Valid Loss:  0.039574671536684036
Epoch:  87  	Training Loss: 0.03789117932319641
Test Loss:  0.03508835285902023
Valid Loss:  0.03955873101949692
Epoch:  88  	Training Loss: 0.037875838577747345
Test Loss:  0.03507325053215027
Valid Loss:  0.039542801678180695
Epoch:  89  	Training Loss: 0.037860509008169174
Test Loss:  0.0350581556558609
Valid Loss:  0.03952687978744507
Epoch:  90  	Training Loss: 0.0378451906144619
Test Loss:  0.03504306077957153
Valid Loss:  0.03951096907258034
Epoch:  91  	Training Loss: 0.03782987594604492
Test Loss:  0.03502797335386276
Valid Loss:  0.03949505835771561
Epoch:  92  	Training Loss: 0.03781456500291824
Test Loss:  0.0350128710269928
Valid Loss:  0.039479129016399384
Epoch:  93  	Training Loss: 0.03779923915863037
Test Loss:  0.03499777242541313
Valid Loss:  0.039463210850954056
Epoch:  94  	Training Loss: 0.0377839133143425
Test Loss:  0.03498268872499466
Valid Loss:  0.039447296410799026
Epoch:  95  	Training Loss: 0.03776859864592552
Test Loss:  0.03496760502457619
Valid Loss:  0.03943139314651489
Epoch:  96  	Training Loss: 0.03775329142808914
Test Loss:  0.03495253622531891
Valid Loss:  0.039415497332811356
Epoch:  97  	Training Loss: 0.03773798793554306
Test Loss:  0.03493746370077133
Valid Loss:  0.03939960524439812
Epoch:  98  	Training Loss: 0.03772269934415817
Test Loss:  0.03492239862680435
Valid Loss:  0.03938371688127518
Epoch:  99  	Training Loss: 0.037707410752773285
Test Loss:  0.034907348453998566
Valid Loss:  0.03936784341931343
Epoch:  100  	Training Loss: 0.03769213706254959
Test Loss:  0.03489230200648308
Valid Loss:  0.03935197740793228
Epoch:  101  	Training Loss: 0.037676867097616196
Test Loss:  0.034877270460128784
Valid Loss:  0.03933612257242203
Epoch:  102  	Training Loss: 0.0376616008579731
Test Loss:  0.0348622128367424
Valid Loss:  0.03932024538516998
Epoch:  103  	Training Loss: 0.037646323442459106
Test Loss:  0.034847158938646317
Valid Loss:  0.03930436819791794
Epoch:  104  	Training Loss: 0.03763105347752571
Test Loss:  0.034832119941711426
Valid Loss:  0.03928850591182709
Epoch:  105  	Training Loss: 0.03761579096317291
Test Loss:  0.034817084670066833
Valid Loss:  0.03927265480160713
Epoch:  106  	Training Loss: 0.03760053589940071
Test Loss:  0.03480205312371254
Valid Loss:  0.039256803691387177
Epoch:  107  	Training Loss: 0.037585288286209106
Test Loss:  0.03478703275322914
Valid Loss:  0.03924097120761871
Epoch:  108  	Training Loss: 0.0375700443983078
Test Loss:  0.03477202355861664
Valid Loss:  0.03922513127326965
Epoch:  109  	Training Loss: 0.03755480796098709
Test Loss:  0.03475701063871384
Valid Loss:  0.03920930624008179
Epoch:  110  	Training Loss: 0.03753958269953728
Test Loss:  0.03474200889468193
Valid Loss:  0.039193492382764816
Epoch:  111  	Training Loss: 0.03752436116337776
Test Loss:  0.03472701832652092
Valid Loss:  0.039177682250738144
Epoch:  112  	Training Loss: 0.03750915080308914
Test Loss:  0.03471214696764946
Valid Loss:  0.03916199505329132
Epoch:  113  	Training Loss: 0.03749405965209007
Test Loss:  0.034697286784648895
Valid Loss:  0.03914631903171539
Epoch:  114  	Training Loss: 0.0374789759516716
Test Loss:  0.03468243032693863
Valid Loss:  0.03913065418601036
Epoch:  115  	Training Loss: 0.037463899701833725
Test Loss:  0.03466757759451866
Valid Loss:  0.03911498934030533
Epoch:  116  	Training Loss: 0.03744883090257645
Test Loss:  0.03465273231267929
Valid Loss:  0.03909933567047119
Epoch:  117  	Training Loss: 0.037433769553899765
Test Loss:  0.034637901932001114
Valid Loss:  0.03908368945121765
Epoch:  118  	Training Loss: 0.03741871565580368
Test Loss:  0.034623075276613235
Valid Loss:  0.03906805440783501
Epoch:  119  	Training Loss: 0.03740367293357849
Test Loss:  0.034608252346515656
Valid Loss:  0.03905242308974266
Epoch:  120  	Training Loss: 0.0373886339366436
Test Loss:  0.03459344059228897
Valid Loss:  0.03903680294752121
Epoch:  121  	Training Loss: 0.03737360239028931
Test Loss:  0.03457863628864288
Valid Loss:  0.039021190255880356
Epoch:  122  	Training Loss: 0.03735858201980591
Test Loss:  0.034563884139060974
Valid Loss:  0.03900563344359398
Epoch:  123  	Training Loss: 0.03734361752867699
Test Loss:  0.03454914316534996
Valid Loss:  0.0389900878071785
Epoch:  124  	Training Loss: 0.03732866048812866
Test Loss:  0.034534405916929245
Valid Loss:  0.038974545896053314
Epoch:  125  	Training Loss: 0.037313707172870636
Test Loss:  0.03451967239379883
Valid Loss:  0.038959015160799026
Epoch:  126  	Training Loss: 0.037298768758773804
Test Loss:  0.03450495004653931
Valid Loss:  0.03894348815083504
Epoch:  127  	Training Loss: 0.03728383034467697
Test Loss:  0.03449023887515068
Valid Loss:  0.03892797231674194
Epoch:  128  	Training Loss: 0.03726890683174133
Test Loss:  0.03447553515434265
Valid Loss:  0.038912467658519745
Epoch:  129  	Training Loss: 0.037253983318805695
Test Loss:  0.03446083515882492
Valid Loss:  0.038896963000297546
Epoch:  130  	Training Loss: 0.03723907470703125
Test Loss:  0.03444614261388779
Valid Loss:  0.03888146951794624
Epoch:  131  	Training Loss: 0.0372241735458374
Test Loss:  0.03443145751953125
Valid Loss:  0.03886598348617554
Epoch:  132  	Training Loss: 0.03720927610993385
Test Loss:  0.03441689908504486
Valid Loss:  0.038850635290145874
Epoch:  133  	Training Loss: 0.03719450533390045
Test Loss:  0.03440234810113907
Valid Loss:  0.03883528709411621
Epoch:  134  	Training Loss: 0.03717973828315735
Test Loss:  0.03438780456781387
Valid Loss:  0.03881995379924774
Epoch:  135  	Training Loss: 0.03716498613357544
Test Loss:  0.03437326103448868
Valid Loss:  0.03880462050437927
Epoch:  136  	Training Loss: 0.03715023770928383
Test Loss:  0.03435873985290527
Valid Loss:  0.0387892983853817
Epoch:  137  	Training Loss: 0.03713550046086311
Test Loss:  0.03434421122074127
Valid Loss:  0.03877398371696472
Epoch:  138  	Training Loss: 0.0371207669377327
Test Loss:  0.03432970494031906
Valid Loss:  0.03875867277383804
Epoch:  139  	Training Loss: 0.03710604086518288
Test Loss:  0.034315187484025955
Valid Loss:  0.03874337300658226
Epoch:  140  	Training Loss: 0.03709131479263306
Test Loss:  0.03430068492889404
Valid Loss:  0.038728076964616776
Epoch:  141  	Training Loss: 0.03707660734653473
Test Loss:  0.034286193549633026
Valid Loss:  0.038712792098522186
Epoch:  142  	Training Loss: 0.037061907351017
Test Loss:  0.03427184373140335
Valid Loss:  0.038697659969329834
Epoch:  143  	Training Loss: 0.03704734891653061
Test Loss:  0.03425750881433487
Valid Loss:  0.03868253529071808
Epoch:  144  	Training Loss: 0.03703279793262482
Test Loss:  0.03424317389726639
 29%|██▉       | 145/500 [01:43<03:47,  1.56it/s] 29%|██▉       | 147/500 [01:44<02:45,  2.14it/s] 30%|██▉       | 149/500 [01:44<02:01,  2.88it/s] 30%|███       | 151/500 [01:50<06:50,  1.18s/it] 31%|███       | 153/500 [01:50<04:53,  1.18it/s] 31%|███       | 155/500 [01:50<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:50<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:50<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:57<06:42,  1.19s/it] 33%|███▎      | 163/500 [01:57<04:47,  1.17it/s] 33%|███▎      | 165/500 [01:57<03:26,  1.62it/s] 33%|███▎      | 167/500 [01:57<02:30,  2.22it/s] 34%|███▍      | 169/500 [01:57<01:51,  2.98it/s] 34%|███▍      | 171/500 [02:04<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:04<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:04<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:04<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:04<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:10<06:14,  1.17s/it] 37%|███▋      | 183/500 [02:11<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:11<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:11<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:11<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:17<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:17<04:21,  1.18it/s] 39%|███▉      | 195/500 [02:18<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:18<02:19,  2.17it/s] 40%|███▉      | 199/500 [02:18<01:44,  2.87it/s] 40%|████      | 201/500 [02:24<06:00,  1.20s/it] 41%|████      | 203/500 [02:25<04:16,  1.16it/s] 41%|████      | 205/500 [02:25<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:25<02:13,  2.19it/s] 42%|████▏     | 209/500 [02:25<01:38,  2.95it/s] 42%|████▏     | 211/500 [02:32<05:53,  1.22s/it] 43%|████▎     | 213/500 [02:32<04:13,  1.13it/s] 43%|████▎     | 215/500 [02:32<03:02,  1.56it/s]Valid Loss:  0.03866742178797722
Epoch:  145  	Training Loss: 0.03701826184988022
Test Loss:  0.0342288464307785
Valid Loss:  0.03865231201052666
Epoch:  146  	Training Loss: 0.03700372204184532
Test Loss:  0.034214526414871216
Valid Loss:  0.038637205958366394
Epoch:  147  	Training Loss: 0.03698919713497162
Test Loss:  0.034200213849544525
Valid Loss:  0.038622111082077026
Epoch:  148  	Training Loss: 0.036974672228097916
Test Loss:  0.034185901284217834
Valid Loss:  0.03860701993107796
Epoch:  149  	Training Loss: 0.03696015477180481
Test Loss:  0.03417160362005234
Valid Loss:  0.038591936230659485
Epoch:  150  	Training Loss: 0.0369456447660923
Test Loss:  0.03415730595588684
Valid Loss:  0.03857685998082161
Epoch:  151  	Training Loss: 0.03693114593625069
Test Loss:  0.034143026918172836
Valid Loss:  0.03856179863214493
Epoch:  152  	Training Loss: 0.03691665828227997
Test Loss:  0.03412890434265137
Valid Loss:  0.03854690492153168
Epoch:  153  	Training Loss: 0.036902330815792084
Test Loss:  0.03411480039358139
Valid Loss:  0.038532011210918427
Epoch:  154  	Training Loss: 0.036888010799884796
Test Loss:  0.03410068526864052
Valid Loss:  0.03851713612675667
Epoch:  155  	Training Loss: 0.036873698234558105
Test Loss:  0.03408658877015114
Valid Loss:  0.03850226104259491
Epoch:  156  	Training Loss: 0.03685939311981201
Test Loss:  0.03407249599695206
Valid Loss:  0.03848739713430405
Epoch:  157  	Training Loss: 0.036845095455646515
Test Loss:  0.03405841439962387
Valid Loss:  0.03847254067659378
Epoch:  158  	Training Loss: 0.036830801516771317
Test Loss:  0.03404432535171509
Valid Loss:  0.038457684218883514
Epoch:  159  	Training Loss: 0.03681651130318642
Test Loss:  0.034030258655548096
Valid Loss:  0.03844284266233444
Epoch:  160  	Training Loss: 0.03680223599076271
Test Loss:  0.034016191959381104
Valid Loss:  0.03842800855636597
Epoch:  161  	Training Loss: 0.0367879644036293
Test Loss:  0.03400213271379471
Valid Loss:  0.03841317445039749
Epoch:  162  	Training Loss: 0.03677370399236679
Test Loss:  0.03398826718330383
Valid Loss:  0.03839854896068573
Epoch:  163  	Training Loss: 0.0367596335709095
Test Loss:  0.03397440165281296
Valid Loss:  0.038383934646844864
Epoch:  164  	Training Loss: 0.036745570600032806
Test Loss:  0.03396054729819298
Valid Loss:  0.0383693128824234
Epoch:  165  	Training Loss: 0.03673151880502701
Test Loss:  0.033946692943573
Valid Loss:  0.03835470974445343
Epoch:  166  	Training Loss: 0.03671746701002121
Test Loss:  0.03393285349011421
Valid Loss:  0.03834010660648346
Epoch:  167  	Training Loss: 0.036703430116176605
Test Loss:  0.033919014036655426
Valid Loss:  0.03832551836967468
Epoch:  168  	Training Loss: 0.036689393222332
Test Loss:  0.033905185759067535
Valid Loss:  0.038310930132865906
Epoch:  169  	Training Loss: 0.03667536377906799
Test Loss:  0.03389136120676994
Valid Loss:  0.038296349346637726
Epoch:  170  	Training Loss: 0.03666134178638458
Test Loss:  0.03387754410505295
Valid Loss:  0.03828177973628044
Epoch:  171  	Training Loss: 0.03664732724428177
Test Loss:  0.03386373072862625
Valid Loss:  0.03826721012592316
Epoch:  172  	Training Loss: 0.03663332015275955
Test Loss:  0.033850107342004776
Valid Loss:  0.03825284168124199
Epoch:  173  	Training Loss: 0.03661949932575226
Test Loss:  0.033836476504802704
Valid Loss:  0.03823847323656082
Epoch:  174  	Training Loss: 0.03660568594932556
Test Loss:  0.03382286801934242
Valid Loss:  0.03822411596775055
Epoch:  175  	Training Loss: 0.03659188002347946
Test Loss:  0.03380925953388214
Valid Loss:  0.03820975869894028
Epoch:  176  	Training Loss: 0.03657807409763336
Test Loss:  0.033795662224292755
Valid Loss:  0.0381954163312912
Epoch:  177  	Training Loss: 0.036564283072948456
Test Loss:  0.03378206118941307
Valid Loss:  0.03818107768893242
Epoch:  178  	Training Loss: 0.03655049204826355
Test Loss:  0.03376847505569458
Valid Loss:  0.038166746497154236
Epoch:  179  	Training Loss: 0.03653671592473984
Test Loss:  0.03375488519668579
Valid Loss:  0.03815241903066635
Epoch:  180  	Training Loss: 0.03652293607592583
Test Loss:  0.033741310238838196
Valid Loss:  0.038138099014759064
Epoch:  181  	Training Loss: 0.03650916367769241
Test Loss:  0.0337277427315712
Valid Loss:  0.03812378644943237
Epoch:  182  	Training Loss: 0.036495402455329895
Test Loss:  0.03371436893939972
Valid Loss:  0.038109682500362396
Epoch:  183  	Training Loss: 0.036481842398643494
Test Loss:  0.03370100259780884
Valid Loss:  0.038095586001873016
Epoch:  184  	Training Loss: 0.03646828234195709
Test Loss:  0.03368764370679855
Valid Loss:  0.03808149695396423
Epoch:  185  	Training Loss: 0.036454737186431885
Test Loss:  0.033674292266368866
Valid Loss:  0.03806741163134575
Epoch:  186  	Training Loss: 0.03644118830561638
Test Loss:  0.03366094082593918
Valid Loss:  0.03805333375930786
Epoch:  187  	Training Loss: 0.03642765060067177
Test Loss:  0.033647604286670685
Valid Loss:  0.03803925961256027
Epoch:  188  	Training Loss: 0.036414120346307755
Test Loss:  0.03363426774740219
Valid Loss:  0.03802519291639328
Epoch:  189  	Training Loss: 0.03640059381723404
Test Loss:  0.033620938658714294
Valid Loss:  0.03801113739609718
Epoch:  190  	Training Loss: 0.03638707101345062
Test Loss:  0.033607613295316696
Valid Loss:  0.03799708932638168
Epoch:  191  	Training Loss: 0.0363735631108284
Test Loss:  0.03359429910778999
Valid Loss:  0.037983037531375885
Epoch:  192  	Training Loss: 0.03636005148291588
Test Loss:  0.03358117491006851
Valid Loss:  0.0379692018032074
Epoch:  193  	Training Loss: 0.03634675219655037
Test Loss:  0.03356806933879852
Valid Loss:  0.03795537352561951
Epoch:  194  	Training Loss: 0.03633346036076546
Test Loss:  0.033554963767528534
Valid Loss:  0.03794155642390251
Epoch:  195  	Training Loss: 0.036320172250270844
Test Loss:  0.03354186192154884
Valid Loss:  0.037927739322185516
Epoch:  196  	Training Loss: 0.03630688786506653
Test Loss:  0.03352876380085945
Valid Loss:  0.03791392594575882
Epoch:  197  	Training Loss: 0.03629361465573311
Test Loss:  0.033515673130750656
Valid Loss:  0.03790012001991272
Epoch:  198  	Training Loss: 0.03628034144639969
Test Loss:  0.03350258618593216
Valid Loss:  0.037886328995227814
Epoch:  199  	Training Loss: 0.036267075687646866
Test Loss:  0.03348951041698456
Valid Loss:  0.03787253051996231
Epoch:  200  	Training Loss: 0.03625381737947464
Test Loss:  0.033476438373327255
Valid Loss:  0.0378587506711483
Epoch:  201  	Training Loss: 0.03624056652188301
Test Loss:  0.03346336632966995
Valid Loss:  0.03784497082233429
Epoch:  202  	Training Loss: 0.03622732311487198
Test Loss:  0.033450499176979065
Valid Loss:  0.037831395864486694
Epoch:  203  	Training Loss: 0.03621426597237587
Test Loss:  0.03343762829899788
Valid Loss:  0.0378178209066391
Epoch:  204  	Training Loss: 0.03620121255517006
Test Loss:  0.03342475742101669
Valid Loss:  0.037804245948791504
Epoch:  205  	Training Loss: 0.036188170313835144
Test Loss:  0.033411905169487
Valid Loss:  0.0377906858921051
Epoch:  206  	Training Loss: 0.03617513179779053
Test Loss:  0.03339904546737671
Valid Loss:  0.0377771258354187
Epoch:  207  	Training Loss: 0.03616210073232651
Test Loss:  0.033386196941137314
Valid Loss:  0.037763580679893494
Epoch:  208  	Training Loss: 0.03614906966686249
Test Loss:  0.033373355865478516
Valid Loss:  0.037750035524368286
Epoch:  209  	Training Loss: 0.036136046051979065
Test Loss:  0.03336051478981972
Valid Loss:  0.03773649036884308
Epoch:  210  	Training Loss: 0.03612302988767624
Test Loss:  0.03334768861532211
Valid Loss:  0.037722960114479065
Epoch:  211  	Training Loss: 0.03611002117395401
Test Loss:  0.03333486244082451
Valid Loss:  0.03770943731069565
Epoch:  212  	Training Loss: 0.03609701246023178
Test Loss:  0.03332221508026123
Valid Loss:  0.037696097046136856
Epoch:  213  	Training Loss: 0.03608419746160507
Test Loss:  0.03330957144498825
Valid Loss:  0.03768276423215866
Epoch:  214  	Training Loss: 0.036071378737688065
Test Loss:  0.03329693153500557
Valid Loss:  0.037669435143470764
Epoch:  215  	Training Loss: 0.036058567464351654
Test Loss:  0.033284302800893784
Valid Loss:  0.03765611723065376
 43%|████▎     | 217/500 [02:32<02:12,  2.13it/s] 44%|████▍     | 219/500 [02:32<01:37,  2.88it/s] 44%|████▍     | 221/500 [02:38<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:39<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:39<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:39<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:39<01:33,  2.89it/s] 46%|████▌     | 231/500 [02:45<05:23,  1.20s/it] 47%|████▋     | 233/500 [02:46<03:51,  1.15it/s] 47%|████▋     | 235/500 [02:46<02:47,  1.58it/s] 47%|████▋     | 237/500 [02:46<02:03,  2.13it/s] 48%|████▊     | 239/500 [02:46<01:32,  2.82it/s] 48%|████▊     | 241/500 [02:52<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:42,  1.15it/s] 49%|████▉     | 245/500 [02:53<02:41,  1.58it/s] 49%|████▉     | 247/500 [02:53<01:58,  2.14it/s] 50%|████▉     | 249/500 [02:53<01:27,  2.88it/s] 50%|█████     | 251/500 [03:00<05:05,  1.23s/it] 51%|█████     | 253/500 [03:00<03:37,  1.14it/s] 51%|█████     | 255/500 [03:00<02:35,  1.57it/s] 51%|█████▏    | 257/500 [03:00<01:52,  2.15it/s] 52%|█████▏    | 259/500 [03:00<01:23,  2.90it/s] 52%|█████▏    | 261/500 [03:07<04:45,  1.19s/it] 53%|█████▎    | 263/500 [03:07<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:07<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:07<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:07<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:13<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:14<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:14<02:21,  1.59it/s] 55%|█████▌    | 277/500 [03:14<01:43,  2.15it/s] 56%|█████▌    | 279/500 [03:14<01:17,  2.85it/s] 56%|█████▌    | 281/500 [03:21<04:26,  1.22s/it] 57%|█████▋    | 283/500 [03:21<03:10,  1.14it/s] 57%|█████▋    | 285/500 [03:21<02:17,  1.56it/s]Epoch:  216  	Training Loss: 0.03604576736688614
Test Loss:  0.033271677792072296
Valid Loss:  0.03764279931783676
Epoch:  217  	Training Loss: 0.036032967269420624
Test Loss:  0.03325905650854111
Valid Loss:  0.03762948885560036
Epoch:  218  	Training Loss: 0.03602017089724541
Test Loss:  0.033246442675590515
Valid Loss:  0.03761618584394455
Epoch:  219  	Training Loss: 0.036007385700941086
Test Loss:  0.03323383256793022
Valid Loss:  0.03760288655757904
Epoch:  220  	Training Loss: 0.03599460422992706
Test Loss:  0.033221226185560226
Valid Loss:  0.03758959472179413
Epoch:  221  	Training Loss: 0.03598183020949364
Test Loss:  0.03320862725377083
Valid Loss:  0.037576306611299515
Epoch:  222  	Training Loss: 0.03596905618906021
Test Loss:  0.033196255564689636
Valid Loss:  0.0375632643699646
Epoch:  223  	Training Loss: 0.03595651686191559
Test Loss:  0.03318389505147934
Valid Loss:  0.037550218403339386
Epoch:  224  	Training Loss: 0.035943981260061264
Test Loss:  0.03317153453826904
Valid Loss:  0.03753717988729477
Epoch:  225  	Training Loss: 0.03593145310878754
Test Loss:  0.03315918147563934
Valid Loss:  0.037524156272411346
Epoch:  226  	Training Loss: 0.03591892868280411
Test Loss:  0.03314683213829994
Valid Loss:  0.037511132657527924
Epoch:  227  	Training Loss: 0.035906411707401276
Test Loss:  0.03313449025154114
Valid Loss:  0.0374981164932251
Epoch:  228  	Training Loss: 0.035893894731998444
Test Loss:  0.03312215209007263
Valid Loss:  0.037485092878341675
Epoch:  229  	Training Loss: 0.03588138520717621
Test Loss:  0.033109817653894424
Valid Loss:  0.03747209161520004
Epoch:  230  	Training Loss: 0.03586888685822487
Test Loss:  0.033097486943006516
Valid Loss:  0.03745909035205841
Epoch:  231  	Training Loss: 0.03585638850927353
Test Loss:  0.0330851674079895
Valid Loss:  0.03744608908891678
Epoch:  232  	Training Loss: 0.035843897610902786
Test Loss:  0.033073052763938904
Valid Loss:  0.03743331879377365
Epoch:  233  	Training Loss: 0.03583161532878876
Test Loss:  0.0330609455704689
Valid Loss:  0.037420544773340225
Epoch:  234  	Training Loss: 0.035819344222545624
Test Loss:  0.0330488458275795
Valid Loss:  0.037407778203487396
Epoch:  235  	Training Loss: 0.03580707311630249
Test Loss:  0.033036746084690094
Valid Loss:  0.03739502280950546
Epoch:  236  	Training Loss: 0.03579481691122055
Test Loss:  0.03302465006709099
Valid Loss:  0.03738226369023323
Epoch:  237  	Training Loss: 0.03578255698084831
Test Loss:  0.03301255777478218
Valid Loss:  0.03736951947212219
Epoch:  238  	Training Loss: 0.03577030450105667
Test Loss:  0.03300047665834427
Valid Loss:  0.037356771528720856
Epoch:  239  	Training Loss: 0.03575805574655533
Test Loss:  0.032988399267196655
Valid Loss:  0.037344031035900116
Epoch:  240  	Training Loss: 0.03574581444263458
Test Loss:  0.03297632932662964
Valid Loss:  0.03733130171895027
Epoch:  241  	Training Loss: 0.035733580589294434
Test Loss:  0.03296426683664322
Valid Loss:  0.03731857240200043
Epoch:  242  	Training Loss: 0.035721346735954285
Test Loss:  0.03295232355594635
Valid Loss:  0.037305980920791626
Epoch:  243  	Training Loss: 0.03570924699306488
Test Loss:  0.03294038027524948
Valid Loss:  0.03729339689016342
Epoch:  244  	Training Loss: 0.035697150975465775
Test Loss:  0.032928451895713806
Valid Loss:  0.03728081285953522
Epoch:  245  	Training Loss: 0.035685062408447266
Test Loss:  0.03291652351617813
Valid Loss:  0.03726823255419731
Epoch:  246  	Training Loss: 0.035672977566719055
Test Loss:  0.03290460258722305
Valid Loss:  0.0372556671500206
Epoch:  247  	Training Loss: 0.03566090017557144
Test Loss:  0.03289268910884857
Valid Loss:  0.03724309802055359
Epoch:  248  	Training Loss: 0.03564882278442383
Test Loss:  0.03288077563047409
Valid Loss:  0.03723054379224777
Epoch:  249  	Training Loss: 0.03563675284385681
Test Loss:  0.032868869602680206
Valid Loss:  0.037217989563941956
Epoch:  250  	Training Loss: 0.03562469035387039
Test Loss:  0.03285696730017662
Valid Loss:  0.03720543161034584
Epoch:  251  	Training Loss: 0.03561262786388397
Test Loss:  0.03284507244825363
Valid Loss:  0.03719288855791092
Epoch:  252  	Training Loss: 0.03560057654976845
Test Loss:  0.03283335268497467
Valid Loss:  0.03718053176999092
Epoch:  253  	Training Loss: 0.03558870404958725
Test Loss:  0.032821640372276306
Valid Loss:  0.03716818988323212
Epoch:  254  	Training Loss: 0.03557684272527695
Test Loss:  0.03280993551015854
Valid Loss:  0.037155844271183014
Epoch:  255  	Training Loss: 0.035564981400966644
Test Loss:  0.03279822692275047
Valid Loss:  0.03714349865913391
Epoch:  256  	Training Loss: 0.03555312752723694
Test Loss:  0.0327865332365036
Valid Loss:  0.037131167948246
Epoch:  257  	Training Loss: 0.03554127737879753
Test Loss:  0.03277484327554703
Valid Loss:  0.03711883723735809
Epoch:  258  	Training Loss: 0.03552943468093872
Test Loss:  0.032763153314590454
Valid Loss:  0.03710651397705078
Epoch:  259  	Training Loss: 0.03551759570837021
Test Loss:  0.03275146707892418
Valid Loss:  0.037094198167324066
Epoch:  260  	Training Loss: 0.0355057567358017
Test Loss:  0.0327397882938385
Valid Loss:  0.03708188235759735
Epoch:  261  	Training Loss: 0.03549392893910408
Test Loss:  0.03272812068462372
Valid Loss:  0.037069570273160934
Epoch:  262  	Training Loss: 0.035482101142406464
Test Loss:  0.03271663188934326
Valid Loss:  0.03705746307969093
Epoch:  263  	Training Loss: 0.03547046706080437
Test Loss:  0.032705157995224
Valid Loss:  0.037045352160930634
Epoch:  264  	Training Loss: 0.03545883297920227
Test Loss:  0.03269368037581444
Valid Loss:  0.03703325241804123
Epoch:  265  	Training Loss: 0.03544720262289047
Test Loss:  0.032682210206985474
Valid Loss:  0.037021152675151825
Epoch:  266  	Training Loss: 0.03543557971715927
Test Loss:  0.03267073631286621
Valid Loss:  0.03700906038284302
Epoch:  267  	Training Loss: 0.03542396053671837
Test Loss:  0.03265927731990814
Valid Loss:  0.03699697554111481
Epoch:  268  	Training Loss: 0.035412345081567764
Test Loss:  0.03264781832695007
Valid Loss:  0.0369848906993866
Epoch:  269  	Training Loss: 0.03540073335170746
Test Loss:  0.0326363667845726
Valid Loss:  0.03697281330823898
Epoch:  270  	Training Loss: 0.03538913279771805
Test Loss:  0.03262491524219513
Valid Loss:  0.03696073964238167
Epoch:  271  	Training Loss: 0.03537753224372864
Test Loss:  0.03261347487568855
Valid Loss:  0.03694867342710495
Epoch:  272  	Training Loss: 0.035365935415029526
Test Loss:  0.03260218724608421
Valid Loss:  0.036936771124601364
Epoch:  273  	Training Loss: 0.035354506224393845
Test Loss:  0.03259090334177017
Valid Loss:  0.036924876272678375
Epoch:  274  	Training Loss: 0.03534308075904846
Test Loss:  0.03257962316274643
Valid Loss:  0.036912985146045685
Epoch:  275  	Training Loss: 0.035331662744283676
Test Loss:  0.032568350434303284
Valid Loss:  0.03690109774470329
Epoch:  276  	Training Loss: 0.03532024472951889
Test Loss:  0.03255707398056984
Valid Loss:  0.0368892177939415
Epoch:  277  	Training Loss: 0.0353088304400444
Test Loss:  0.03254581615328789
Valid Loss:  0.0368773452937603
Epoch:  278  	Training Loss: 0.03529742360115051
Test Loss:  0.03253455460071564
Valid Loss:  0.0368654727935791
Epoch:  279  	Training Loss: 0.03528602421283722
Test Loss:  0.032523300498723984
Valid Loss:  0.0368536114692688
Epoch:  280  	Training Loss: 0.035274628549814224
Test Loss:  0.03251204639673233
Valid Loss:  0.0368417464196682
Epoch:  281  	Training Loss: 0.03526323288679123
Test Loss:  0.03250080347061157
Valid Loss:  0.036829885095357895
Epoch:  282  	Training Loss: 0.03525184839963913
Test Loss:  0.03248972445726395
Valid Loss:  0.03681819885969162
Epoch:  283  	Training Loss: 0.035240620374679565
Test Loss:  0.03247864544391632
Valid Loss:  0.03680651634931564
Epoch:  284  	Training Loss: 0.03522939234972
Test Loss:  0.03246757388114929
Valid Loss:  0.036794837564229965
Epoch:  285  	Training Loss: 0.035218171775341034
Test Loss:  0.03245650976896286
Valid Loss:  0.036783166229724884
Epoch:  286  	Training Loss: 0.03520695120096207
Test Loss:  0.03244543820619583
Valid Loss:  0.036771491169929504
Epoch:  287  	Training Loss: 0.035195738077163696
Test Loss:   57%|█████▋    | 287/500 [03:21<01:40,  2.11it/s] 58%|█████▊    | 289/500 [03:21<01:14,  2.83it/s] 58%|█████▊    | 291/500 [03:28<04:17,  1.23s/it] 59%|█████▊    | 293/500 [03:28<03:02,  1.13it/s] 59%|█████▉    | 295/500 [03:28<02:10,  1.57it/s] 59%|█████▉    | 297/500 [03:28<01:34,  2.15it/s] 60%|█████▉    | 299/500 [03:28<01:09,  2.88it/s] 60%|██████    | 301/500 [03:35<03:57,  1.19s/it] 61%|██████    | 303/500 [03:35<02:48,  1.17it/s] 61%|██████    | 305/500 [03:35<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:35<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:35<01:04,  2.96it/s] 62%|██████▏   | 311/500 [03:42<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:42<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:42<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:42<01:24,  2.16it/s] 64%|██████▍   | 319/500 [03:42<01:03,  2.86it/s] 64%|██████▍   | 321/500 [03:49<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:49<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:49<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:49<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:49<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:55<03:20,  1.18s/it] 67%|██████▋   | 333/500 [03:56<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:56<01:43,  1.60it/s] 67%|██████▋   | 337/500 [03:56<01:15,  2.16it/s] 68%|██████▊   | 339/500 [03:56<00:55,  2.89it/s] 68%|██████▊   | 341/500 [04:03<03:11,  1.21s/it] 69%|██████▊   | 343/500 [04:03<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:03<01:36,  1.60it/s] 69%|██████▉   | 347/500 [04:03<01:09,  2.19it/s] 70%|██████▉   | 349/500 [04:03<00:51,  2.95it/s] 70%|███████   | 351/500 [04:10<03:00,  1.21s/it] 71%|███████   | 353/500 [04:10<02:08,  1.15it/s] 71%|███████   | 355/500 [04:10<01:31,  1.59it/s] 71%|███████▏  | 357/500 [04:10<01:05,  2.17it/s]0.032434381544589996
Valid Loss:  0.03675982356071472
Epoch:  288  	Training Loss: 0.03518453240394592
Test Loss:  0.03242332860827446
Valid Loss:  0.036748163402080536
Epoch:  289  	Training Loss: 0.03517333045601845
Test Loss:  0.03241227939724922
Valid Loss:  0.03673650696873665
Epoch:  290  	Training Loss: 0.03516213223338127
Test Loss:  0.03240123391151428
Valid Loss:  0.03672485798597336
Epoch:  291  	Training Loss: 0.03515093773603439
Test Loss:  0.03239019587635994
Valid Loss:  0.036713212728500366
Epoch:  292  	Training Loss: 0.035139746963977814
Test Loss:  0.03237927705049515
Valid Loss:  0.03670169785618782
Epoch:  293  	Training Loss: 0.03512869030237198
Test Loss:  0.03236836940050125
Valid Loss:  0.03669019043445587
Epoch:  294  	Training Loss: 0.03511764109134674
Test Loss:  0.03235745429992676
Valid Loss:  0.03667868673801422
Epoch:  295  	Training Loss: 0.0351065918803215
Test Loss:  0.03234655410051346
Valid Loss:  0.036667194217443466
Epoch:  296  	Training Loss: 0.03509555011987686
Test Loss:  0.03233565762639046
Valid Loss:  0.036655694246292114
Epoch:  297  	Training Loss: 0.03508450835943222
Test Loss:  0.03232475742697716
Valid Loss:  0.036644212901592255
Epoch:  298  	Training Loss: 0.035073474049568176
Test Loss:  0.03231386840343475
Valid Loss:  0.0366327241063118
Epoch:  299  	Training Loss: 0.03506244719028473
Test Loss:  0.032302986830472946
Valid Loss:  0.036621250212192535
Epoch:  300  	Training Loss: 0.03505142033100128
Test Loss:  0.03229210525751114
Valid Loss:  0.036609772592782974
Epoch:  301  	Training Loss: 0.03504040092229843
Test Loss:  0.03228122740983963
Valid Loss:  0.03659829869866371
Epoch:  302  	Training Loss: 0.03502938151359558
Test Loss:  0.03227052465081215
Valid Loss:  0.03658701851963997
Epoch:  303  	Training Loss: 0.03501854091882706
Test Loss:  0.032259825617074966
Valid Loss:  0.03657573461532593
Epoch:  304  	Training Loss: 0.03500771149992943
Test Loss:  0.03224913030862808
Valid Loss:  0.03656446188688278
Epoch:  305  	Training Loss: 0.0349968783557415
Test Loss:  0.032238446176052094
Valid Loss:  0.036553189158439636
Epoch:  306  	Training Loss: 0.03498605638742447
Test Loss:  0.03222775459289551
Valid Loss:  0.03654191642999649
Epoch:  307  	Training Loss: 0.03497523069381714
Test Loss:  0.03221707418560982
Valid Loss:  0.03653065487742424
Epoch:  308  	Training Loss: 0.034964416176080704
Test Loss:  0.032206401228904724
Valid Loss:  0.03651939705014229
Epoch:  309  	Training Loss: 0.03495360165834427
Test Loss:  0.03219572827219963
Valid Loss:  0.036508142948150635
Epoch:  310  	Training Loss: 0.03494279459118843
Test Loss:  0.032185059040784836
Valid Loss:  0.03649689257144928
Epoch:  311  	Training Loss: 0.03493199124932289
Test Loss:  0.03217439353466034
Valid Loss:  0.03648564964532852
Epoch:  312  	Training Loss: 0.03492119163274765
Test Loss:  0.0321638360619545
Valid Loss:  0.03647451102733612
Epoch:  313  	Training Loss: 0.03491049259901047
Test Loss:  0.03215327858924866
Valid Loss:  0.036463379859924316
Epoch:  314  	Training Loss: 0.03489980846643448
Test Loss:  0.032142721116542816
Valid Loss:  0.03645225241780281
Epoch:  315  	Training Loss: 0.03488911688327789
Test Loss:  0.03213217854499817
Valid Loss:  0.036441124975681305
Epoch:  316  	Training Loss: 0.034878432750701904
Test Loss:  0.032121628522872925
Valid Loss:  0.036430004984140396
Epoch:  317  	Training Loss: 0.03486775606870651
Test Loss:  0.032111089676618576
Valid Loss:  0.036418888717889786
Epoch:  318  	Training Loss: 0.03485707938671112
Test Loss:  0.032100554555654526
Valid Loss:  0.036407776176929474
Epoch:  319  	Training Loss: 0.03484640643000603
Test Loss:  0.032090019434690475
Valid Loss:  0.03639666736125946
Epoch:  320  	Training Loss: 0.03483574092388153
Test Loss:  0.03207949176430702
Valid Loss:  0.036385565996170044
Epoch:  321  	Training Loss: 0.03482507914304733
Test Loss:  0.03206896781921387
Valid Loss:  0.03637446463108063
Epoch:  322  	Training Loss: 0.034814417362213135
Test Loss:  0.032058604061603546
Valid Loss:  0.03636354207992554
Epoch:  323  	Training Loss: 0.03480392321944237
Test Loss:  0.03204824775457382
Valid Loss:  0.03635261580348015
Epoch:  324  	Training Loss: 0.0347934290766716
Test Loss:  0.032037895172834396
Valid Loss:  0.03634169325232506
Epoch:  325  	Training Loss: 0.03478294610977173
Test Loss:  0.03202754259109497
Valid Loss:  0.03633078187704086
Epoch:  326  	Training Loss: 0.03477246314287186
Test Loss:  0.032017193734645844
Valid Loss:  0.03631986677646637
Epoch:  327  	Training Loss: 0.034761976450681686
Test Loss:  0.03200685232877731
Valid Loss:  0.03630895912647247
Epoch:  328  	Training Loss: 0.03475150465965271
Test Loss:  0.03199651464819908
Valid Loss:  0.03629805147647858
Epoch:  329  	Training Loss: 0.03474103659391403
Test Loss:  0.03198618441820145
Valid Loss:  0.036287158727645874
Epoch:  330  	Training Loss: 0.034730568528175354
Test Loss:  0.03197585046291351
Valid Loss:  0.036276258528232574
Epoch:  331  	Training Loss: 0.03472010791301727
Test Loss:  0.03196552023291588
Valid Loss:  0.03626536577939987
Epoch:  332  	Training Loss: 0.03470964729785919
Test Loss:  0.03195532038807869
Valid Loss:  0.036254607141017914
Epoch:  333  	Training Loss: 0.03469931334257126
Test Loss:  0.0319451242685318
Valid Loss:  0.03624385595321655
Epoch:  334  	Training Loss: 0.03468899056315422
Test Loss:  0.031934935599565506
Valid Loss:  0.03623311221599579
Epoch:  335  	Training Loss: 0.03467866778373718
Test Loss:  0.03192474693059921
Valid Loss:  0.03622236102819443
Epoch:  336  	Training Loss: 0.03466834872961044
Test Loss:  0.03191455826163292
Valid Loss:  0.03621162474155426
Epoch:  337  	Training Loss: 0.0346580371260643
Test Loss:  0.03190437704324722
Valid Loss:  0.03620088845491409
Epoch:  338  	Training Loss: 0.034647729247808456
Test Loss:  0.031894199550151825
Valid Loss:  0.036190152168273926
Epoch:  339  	Training Loss: 0.03463742136955261
Test Loss:  0.03188402205705643
Valid Loss:  0.036179423332214355
Epoch:  340  	Training Loss: 0.034627120941877365
Test Loss:  0.031873855739831924
Valid Loss:  0.036168694496154785
Epoch:  341  	Training Loss: 0.034616824239492416
Test Loss:  0.03186368569731712
Valid Loss:  0.03615797683596611
Epoch:  342  	Training Loss: 0.034606531262397766
Test Loss:  0.03185364976525307
Valid Loss:  0.03614738583564758
Epoch:  343  	Training Loss: 0.034596361219882965
Test Loss:  0.031843602657318115
Valid Loss:  0.036136794835329056
Epoch:  344  	Training Loss: 0.03458619490265846
Test Loss:  0.03183357045054436
Valid Loss:  0.036126211285591125
Epoch:  345  	Training Loss: 0.03457603231072426
Test Loss:  0.0318235382437706
Valid Loss:  0.036115631461143494
Epoch:  346  	Training Loss: 0.03456587344408035
Test Loss:  0.03181350976228714
Valid Loss:  0.03610505163669586
Epoch:  347  	Training Loss: 0.03455571457743645
Test Loss:  0.03180348500609398
Valid Loss:  0.03609447926282883
Epoch:  348  	Training Loss: 0.03454556316137314
Test Loss:  0.03179346024990082
Valid Loss:  0.03608391433954239
Epoch:  349  	Training Loss: 0.03453541919589043
Test Loss:  0.031783439218997955
Valid Loss:  0.03607334941625595
Epoch:  350  	Training Loss: 0.034525275230407715
Test Loss:  0.03177342563867569
Valid Loss:  0.03606278449296951
Epoch:  351  	Training Loss: 0.0345151349902153
Test Loss:  0.03176341950893402
Valid Loss:  0.03605223074555397
Epoch:  352  	Training Loss: 0.034505002200603485
Test Loss:  0.03175351768732071
Valid Loss:  0.03604179620742798
Epoch:  353  	Training Loss: 0.03449498116970062
Test Loss:  0.03174362704157829
Valid Loss:  0.036031365394592285
Epoch:  354  	Training Loss: 0.03448496758937836
Test Loss:  0.031733736395835876
Valid Loss:  0.03602093458175659
Epoch:  355  	Training Loss: 0.03447496145963669
Test Loss:  0.03172384947538376
Valid Loss:  0.036010511219501495
Epoch:  356  	Training Loss: 0.03446495532989502
Test Loss:  0.03171397000551224
Valid Loss:  0.036000095307826996
Epoch:  357  	Training Loss: 0.03445494920015335
Test Loss:  0.03170408681035042
Valid Loss:  0.0359896719455719
Epoch:  358  	Training Loss: 0.03444495424628258
Test Loss:  0.031694211065769196
Valid Loss:   72%|███████▏  | 359/500 [04:10<00:48,  2.93it/s] 72%|███████▏  | 361/500 [04:16<02:44,  1.18s/it] 72%|███████▏  | 362/500 [04:17<02:16,  1.01it/s] 73%|███████▎  | 364/500 [04:17<01:33,  1.45it/s] 73%|███████▎  | 366/500 [04:17<01:06,  2.03it/s] 74%|███████▎  | 368/500 [04:17<00:48,  2.74it/s] 74%|███████▍  | 370/500 [04:17<00:36,  3.60it/s] 74%|███████▍  | 372/500 [04:24<02:28,  1.16s/it] 75%|███████▍  | 374/500 [04:24<01:43,  1.21it/s] 75%|███████▌  | 376/500 [04:24<01:13,  1.69it/s] 76%|███████▌  | 378/500 [04:24<00:52,  2.31it/s] 76%|███████▌  | 380/500 [04:24<00:38,  3.09it/s] 76%|███████▋  | 382/500 [04:30<02:18,  1.17s/it] 77%|███████▋  | 384/500 [04:30<01:37,  1.19it/s] 77%|███████▋  | 386/500 [04:31<01:08,  1.65it/s] 78%|███████▊  | 388/500 [04:31<00:49,  2.26it/s] 78%|███████▊  | 390/500 [04:31<00:36,  3.04it/s] 78%|███████▊  | 392/500 [04:37<02:05,  1.16s/it] 79%|███████▉  | 394/500 [04:37<01:28,  1.20it/s] 79%|███████▉  | 396/500 [04:37<01:02,  1.66it/s] 80%|███████▉  | 398/500 [04:37<00:44,  2.27it/s] 80%|████████  | 400/500 [04:38<00:32,  3.05it/s] 80%|████████  | 402/500 [04:44<01:56,  1.19s/it] 81%|████████  | 404/500 [04:44<01:21,  1.17it/s] 81%|████████  | 406/500 [04:44<00:57,  1.62it/s] 82%|████████▏ | 408/500 [04:44<00:41,  2.22it/s] 82%|████████▏ | 410/500 [04:44<00:30,  2.97it/s] 82%|████████▏ | 412/500 [04:51<01:45,  1.20s/it] 83%|████████▎ | 414/500 [04:51<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:51<00:51,  1.62it/s] 84%|████████▎ | 418/500 [04:51<00:37,  2.21it/s] 84%|████████▍ | 420/500 [04:51<00:26,  2.98it/s] 84%|████████▍ | 422/500 [04:58<01:31,  1.18s/it] 85%|████████▍ | 424/500 [04:58<01:04,  1.18it/s] 85%|████████▌ | 426/500 [04:58<00:45,  1.63it/s] 86%|████████▌ | 428/500 [04:58<00:32,  2.19it/s]0.035979263484478
Epoch:  359  	Training Loss: 0.034434959292411804
Test Loss:  0.03168433904647827
Valid Loss:  0.035968855023384094
Epoch:  360  	Training Loss: 0.03442496806383133
Test Loss:  0.031674470752477646
Valid Loss:  0.03595844656229019
Epoch:  361  	Training Loss: 0.03441498428583145
Test Loss:  0.03166460618376732
Valid Loss:  0.035948049277067184
Epoch:  362  	Training Loss: 0.03440500423312187
Test Loss:  0.03165486454963684
Valid Loss:  0.035937778651714325
Epoch:  363  	Training Loss: 0.034395135939121246
Test Loss:  0.03164512664079666
Valid Loss:  0.035927511751651764
Epoch:  364  	Training Loss: 0.03438528627157211
Test Loss:  0.03163539245724678
Valid Loss:  0.0359172448515892
Epoch:  365  	Training Loss: 0.03437543660402298
Test Loss:  0.0316256619989872
Valid Loss:  0.035906992852687836
Epoch:  366  	Training Loss: 0.034365586936473846
Test Loss:  0.03161593899130821
Valid Loss:  0.03589673712849617
Epoch:  367  	Training Loss: 0.03435574471950531
Test Loss:  0.03160621598362923
Valid Loss:  0.0358864888548851
Epoch:  368  	Training Loss: 0.03434590622782707
Test Loss:  0.03159650042653084
Valid Loss:  0.035876233130693436
Epoch:  369  	Training Loss: 0.03433607146143913
Test Loss:  0.03158678114414215
Valid Loss:  0.035865992307662964
Epoch:  370  	Training Loss: 0.03432624042034149
Test Loss:  0.03157707303762436
Valid Loss:  0.03585575520992279
Epoch:  371  	Training Loss: 0.03431641310453415
Test Loss:  0.03156736120581627
Valid Loss:  0.03584551811218262
Epoch:  372  	Training Loss: 0.03430658578872681
Test Loss:  0.031557776033878326
Valid Loss:  0.03583541139960289
Epoch:  373  	Training Loss: 0.03429688513278961
Test Loss:  0.031548187136650085
Valid Loss:  0.03582530468702316
Epoch:  374  	Training Loss: 0.034287188202142715
Test Loss:  0.03153861314058304
Valid Loss:  0.035815201699733734
Epoch:  375  	Training Loss: 0.03427749499678612
Test Loss:  0.03152903541922569
Valid Loss:  0.0358051098883152
Epoch:  376  	Training Loss: 0.03426780551671982
Test Loss:  0.031519461423158646
Valid Loss:  0.03579501807689667
Epoch:  377  	Training Loss: 0.034258123487234116
Test Loss:  0.0315098911523819
Valid Loss:  0.03578492999076843
Epoch:  378  	Training Loss: 0.03424844145774841
Test Loss:  0.031500332057476044
Valid Loss:  0.035774845629930496
Epoch:  379  	Training Loss: 0.03423876687884331
Test Loss:  0.031490765511989594
Valid Loss:  0.03576476499438286
Epoch:  380  	Training Loss: 0.0342290885746479
Test Loss:  0.03148120641708374
Valid Loss:  0.03575468435883522
Epoch:  381  	Training Loss: 0.034219421446323395
Test Loss:  0.031471654772758484
Valid Loss:  0.03574461117386818
Epoch:  382  	Training Loss: 0.034209754317998886
Test Loss:  0.03146218881011009
Valid Loss:  0.035734623670578
Epoch:  383  	Training Loss: 0.03420017287135124
Test Loss:  0.0314527228474617
Valid Loss:  0.03572464734315872
Epoch:  384  	Training Loss: 0.0341905876994133
Test Loss:  0.03144326061010361
Valid Loss:  0.03571466729044914
Epoch:  385  	Training Loss: 0.034181009978055954
Test Loss:  0.03143380209803581
Valid Loss:  0.03570469096302986
Epoch:  386  	Training Loss: 0.03417143598198891
Test Loss:  0.031424347311258316
Valid Loss:  0.03569471836090088
Epoch:  387  	Training Loss: 0.03416186571121216
Test Loss:  0.03141489624977112
Valid Loss:  0.035684749484062195
Epoch:  388  	Training Loss: 0.03415229916572571
Test Loss:  0.03140544891357422
Valid Loss:  0.035674791783094406
Epoch:  389  	Training Loss: 0.034142736345529556
Test Loss:  0.03139600157737732
Valid Loss:  0.03566482663154602
Epoch:  390  	Training Loss: 0.034133173525333405
Test Loss:  0.03138655796647072
Valid Loss:  0.03565487265586853
Epoch:  391  	Training Loss: 0.03412361815571785
Test Loss:  0.03137712553143501
Valid Loss:  0.03564491122961044
Epoch:  392  	Training Loss: 0.034114059060811996
Test Loss:  0.03136780485510826
Valid Loss:  0.0356350913643837
Epoch:  393  	Training Loss: 0.03410463035106659
Test Loss:  0.03135848790407181
Valid Loss:  0.035625264048576355
Epoch:  394  	Training Loss: 0.034095197916030884
Test Loss:  0.03134917840361595
Valid Loss:  0.03561544418334961
Epoch:  395  	Training Loss: 0.034085772931575775
Test Loss:  0.031339868903160095
Valid Loss:  0.035605624318122864
Epoch:  396  	Training Loss: 0.034076347947120667
Test Loss:  0.03133056312799454
Valid Loss:  0.035595811903476715
Epoch:  397  	Training Loss: 0.034066926687955856
Test Loss:  0.03132125735282898
Valid Loss:  0.03558599576354027
Epoch:  398  	Training Loss: 0.03405751287937164
Test Loss:  0.03131195902824402
Valid Loss:  0.035576194524765015
Epoch:  399  	Training Loss: 0.03404809907078743
Test Loss:  0.031302664428949356
Valid Loss:  0.03556638956069946
Epoch:  400  	Training Loss: 0.034038688987493515
Test Loss:  0.031293369829654694
Valid Loss:  0.03555658832192421
Epoch:  401  	Training Loss: 0.0340292826294899
Test Loss:  0.03128408268094063
Valid Loss:  0.035546790808439255
Epoch:  402  	Training Loss: 0.03401987999677658
Test Loss:  0.03127489238977432
Valid Loss:  0.035537101328372955
Epoch:  403  	Training Loss: 0.03401058167219162
Test Loss:  0.031265705823898315
Valid Loss:  0.03552740812301636
Epoch:  404  	Training Loss: 0.03400128334760666
Test Loss:  0.03125652298331261
Valid Loss:  0.035517722368240356
Epoch:  405  	Training Loss: 0.0339919850230217
Test Loss:  0.031247340142726898
Valid Loss:  0.035508036613464355
Epoch:  406  	Training Loss: 0.033982694149017334
Test Loss:  0.031238164752721786
Valid Loss:  0.03549836203455925
Epoch:  407  	Training Loss: 0.03397340327501297
Test Loss:  0.031228989362716675
Valid Loss:  0.035488687455654144
Epoch:  408  	Training Loss: 0.0339641198515892
Test Loss:  0.03121981769800186
Valid Loss:  0.03547901287674904
Epoch:  409  	Training Loss: 0.033954836428165436
Test Loss:  0.03121064603328705
Valid Loss:  0.03546934947371483
Epoch:  410  	Training Loss: 0.03394555300474167
Test Loss:  0.031201481819152832
Valid Loss:  0.03545967489480972
Epoch:  411  	Training Loss: 0.0339362807571888
Test Loss:  0.031192323192954063
Valid Loss:  0.03545001149177551
Epoch:  412  	Training Loss: 0.033927008509635925
Test Loss:  0.031183253973722458
Valid Loss:  0.03544045239686966
Epoch:  413  	Training Loss: 0.033917829394340515
Test Loss:  0.031174186617136
Valid Loss:  0.035430893301963806
Epoch:  414  	Training Loss: 0.0339086540043354
Test Loss:  0.03116512857377529
Valid Loss:  0.035421330481767654
Epoch:  415  	Training Loss: 0.03389947861433029
Test Loss:  0.03115607053041458
Valid Loss:  0.0354117751121521
Epoch:  416  	Training Loss: 0.033890314400196075
Test Loss:  0.03114701434969902
Valid Loss:  0.03540223091840744
Epoch:  417  	Training Loss: 0.03388115018606186
Test Loss:  0.031137963756918907
Valid Loss:  0.03539268672466278
Epoch:  418  	Training Loss: 0.03387198597192764
Test Loss:  0.031128915026783943
Valid Loss:  0.03538313880562782
Epoch:  419  	Training Loss: 0.033862825483083725
Test Loss:  0.031119871884584427
Valid Loss:  0.03537359833717346
Epoch:  420  	Training Loss: 0.03385366499423981
Test Loss:  0.03111082687973976
Valid Loss:  0.0353640615940094
Epoch:  421  	Training Loss: 0.033844511955976486
Test Loss:  0.031101787462830544
Valid Loss:  0.03535452485084534
Epoch:  422  	Training Loss: 0.03383536636829376
Test Loss:  0.03109285980463028
Valid Loss:  0.035345107316970825
Epoch:  423  	Training Loss: 0.033826328814029694
Test Loss:  0.031083930283784866
Valid Loss:  0.035335689783096313
Epoch:  424  	Training Loss: 0.033817291259765625
Test Loss:  0.0310750063508749
Valid Loss:  0.0353262796998024
Epoch:  425  	Training Loss: 0.03380826115608215
Test Loss:  0.031066086143255234
Valid Loss:  0.035316869616508484
Epoch:  426  	Training Loss: 0.03379923105239868
Test Loss:  0.031057175248861313
Valid Loss:  0.03530747443437576
Epoch:  427  	Training Loss: 0.03379020839929581
Test Loss:  0.031048256903886795
Valid Loss:  0.03529806807637215
Epoch:  428  	Training Loss: 0.03378118574619293
Test Loss:  0.031039346009492874
Valid Loss:  0.03528866916894913
Epoch:  429  	Training Loss: 0.03377216309309006
Test Loss:  0.031030435115098953
Valid Loss:  0.03527927026152611
 86%|████████▌ | 430/500 [04:58<00:23,  2.93it/s] 86%|████████▋ | 432/500 [05:05<01:20,  1.18s/it] 87%|████████▋ | 434/500 [05:05<00:55,  1.18it/s] 87%|████████▋ | 436/500 [05:05<00:39,  1.63it/s] 88%|████████▊ | 438/500 [05:05<00:27,  2.23it/s] 88%|████████▊ | 440/500 [05:05<00:20,  3.00it/s] 88%|████████▊ | 442/500 [05:11<01:07,  1.17s/it] 89%|████████▉ | 444/500 [05:11<00:46,  1.19it/s] 89%|████████▉ | 446/500 [05:12<00:32,  1.64it/s] 90%|████████▉ | 448/500 [05:12<00:23,  2.25it/s] 90%|█████████ | 450/500 [05:12<00:16,  3.02it/s] 90%|█████████ | 452/500 [05:18<00:57,  1.19s/it] 91%|█████████ | 454/500 [05:18<00:39,  1.16it/s] 91%|█████████ | 456/500 [05:19<00:27,  1.59it/s] 92%|█████████▏| 458/500 [05:19<00:19,  2.15it/s] 92%|█████████▏| 460/500 [05:19<00:14,  2.85it/s] 92%|█████████▏| 462/500 [05:25<00:45,  1.19s/it] 93%|█████████▎| 464/500 [05:25<00:30,  1.17it/s] 93%|█████████▎| 466/500 [05:25<00:20,  1.63it/s] 94%|█████████▎| 468/500 [05:26<00:14,  2.22it/s] 94%|█████████▍| 470/500 [05:26<00:10,  2.96it/s] 94%|█████████▍| 472/500 [05:32<00:33,  1.20s/it] 95%|█████████▍| 474/500 [05:32<00:22,  1.16it/s] 95%|█████████▌| 476/500 [05:32<00:15,  1.59it/s] 96%|█████████▌| 478/500 [05:33<00:10,  2.18it/s] 96%|█████████▌| 480/500 [05:33<00:06,  2.93it/s] 96%|█████████▋| 482/500 [05:39<00:21,  1.19s/it] 97%|█████████▋| 484/500 [05:39<00:13,  1.17it/s] 97%|█████████▋| 486/500 [05:39<00:08,  1.62it/s] 98%|█████████▊| 488/500 [05:39<00:05,  2.22it/s] 98%|█████████▊| 490/500 [05:40<00:03,  2.98it/s] 98%|█████████▊| 492/500 [05:46<00:09,  1.18s/it] 99%|█████████▉| 494/500 [05:46<00:05,  1.18it/s] 99%|█████████▉| 496/500 [05:46<00:02,  1.63it/s]100%|█████████▉| 498/500 [05:46<00:00,  2.23it/s]100%|██████████| 500/500 [05:46<00:00,  2.99it/s]100%|██████████| 500/500 [05:46<00:00,  1.44it/s]
Epoch:  430  	Training Loss: 0.03376314789056778
Test Loss:  0.03102152980864048
Valid Loss:  0.035269878804683685
Epoch:  431  	Training Loss: 0.0337541401386261
Test Loss:  0.031012630090117455
Valid Loss:  0.03526049107313156
Epoch:  432  	Training Loss: 0.03374512493610382
Test Loss:  0.031003843992948532
Valid Loss:  0.03525121882557869
Epoch:  433  	Training Loss: 0.03373623266816139
Test Loss:  0.030995048582553864
Valid Loss:  0.035241950303316116
Epoch:  434  	Training Loss: 0.033727336674928665
Test Loss:  0.03098626807332039
Valid Loss:  0.03523268550634384
Epoch:  435  	Training Loss: 0.033718448132276535
Test Loss:  0.030977483838796616
Valid Loss:  0.035223424434661865
Epoch:  436  	Training Loss: 0.0337095633149147
Test Loss:  0.03096870519220829
Valid Loss:  0.03521416336297989
Epoch:  437  	Training Loss: 0.03370067477226257
Test Loss:  0.030959930270910263
Valid Loss:  0.03520490974187851
Epoch:  438  	Training Loss: 0.03369179368019104
Test Loss:  0.030951159074902534
Valid Loss:  0.03519565612077713
Epoch:  439  	Training Loss: 0.033682920038700104
Test Loss:  0.030942386016249657
Valid Loss:  0.03518640995025635
Epoch:  440  	Training Loss: 0.03367404267191887
Test Loss:  0.030933622270822525
Valid Loss:  0.03517715632915497
Epoch:  441  	Training Loss: 0.03366516903042793
Test Loss:  0.030924856662750244
Valid Loss:  0.03516791760921478
Epoch:  442  	Training Loss: 0.033656299114227295
Test Loss:  0.03091619536280632
Valid Loss:  0.035158783197402954
Epoch:  443  	Training Loss: 0.03364753723144531
Test Loss:  0.030907541513442993
Valid Loss:  0.035149648785591125
Epoch:  444  	Training Loss: 0.03363877534866333
Test Loss:  0.030898889526724815
Valid Loss:  0.03514052927494049
Epoch:  445  	Training Loss: 0.033630017191171646
Test Loss:  0.030890239402651787
Valid Loss:  0.03513140231370926
Epoch:  446  	Training Loss: 0.03362126648426056
Test Loss:  0.030881594866514206
Valid Loss:  0.035122282803058624
Epoch:  447  	Training Loss: 0.033612512052059174
Test Loss:  0.030872944742441177
Valid Loss:  0.03511316329240799
Epoch:  448  	Training Loss: 0.033603765070438385
Test Loss:  0.030864307656884193
Valid Loss:  0.03510405123233795
Epoch:  449  	Training Loss: 0.033595018088817596
Test Loss:  0.03085566684603691
Valid Loss:  0.035094935446977615
Epoch:  450  	Training Loss: 0.033586274832487106
Test Loss:  0.030847031623125076
Valid Loss:  0.035085827112197876
Epoch:  451  	Training Loss: 0.033577531576156616
Test Loss:  0.03083840012550354
Valid Loss:  0.035076722502708435
Epoch:  452  	Training Loss: 0.03356879949569702
Test Loss:  0.030829863622784615
Valid Loss:  0.035067714750766754
Epoch:  453  	Training Loss: 0.03356015682220459
Test Loss:  0.03082132712006569
Valid Loss:  0.03505871444940567
Epoch:  454  	Training Loss: 0.03355151787400246
Test Loss:  0.03081279993057251
Valid Loss:  0.035049714148044586
Epoch:  455  	Training Loss: 0.03354288265109062
Test Loss:  0.03080427274107933
Valid Loss:  0.0350407212972641
Epoch:  456  	Training Loss: 0.03353424742817879
Test Loss:  0.0307957511395216
Valid Loss:  0.03503173217177391
Epoch:  457  	Training Loss: 0.03352561593055725
Test Loss:  0.030787229537963867
Valid Loss:  0.03502274304628372
Epoch:  458  	Training Loss: 0.03351699560880661
Test Loss:  0.030778711661696434
Valid Loss:  0.03501375392079353
Epoch:  459  	Training Loss: 0.03350836783647537
Test Loss:  0.030770193785429
Valid Loss:  0.035004764795303345
Epoch:  460  	Training Loss: 0.03349974751472473
Test Loss:  0.030761681497097015
Valid Loss:  0.03499578684568405
Epoch:  461  	Training Loss: 0.03349112719297409
Test Loss:  0.03075317293405533
Valid Loss:  0.03498680144548416
Epoch:  462  	Training Loss: 0.03348251432180405
Test Loss:  0.030744750052690506
Valid Loss:  0.03497792035341263
Epoch:  463  	Training Loss: 0.03347398340702057
Test Loss:  0.030736317858099937
Valid Loss:  0.0349690318107605
Epoch:  464  	Training Loss: 0.033465463668107986
Test Loss:  0.030727902427315712
Valid Loss:  0.034960150718688965
Epoch:  465  	Training Loss: 0.033456943929195404
Test Loss:  0.030719485133886337
Valid Loss:  0.03495127707719803
Epoch:  466  	Training Loss: 0.03344842419028282
Test Loss:  0.03071107156574726
Valid Loss:  0.034942399710416794
Epoch:  467  	Training Loss: 0.033439911901950836
Test Loss:  0.030702654272317886
Valid Loss:  0.03493352234363556
Epoch:  468  	Training Loss: 0.03343139588832855
Test Loss:  0.030694246292114258
Valid Loss:  0.03492465615272522
Epoch:  469  	Training Loss: 0.033422887325286865
Test Loss:  0.03068583831191063
Valid Loss:  0.03491578996181488
Epoch:  470  	Training Loss: 0.03341438248753548
Test Loss:  0.0306774340569973
Valid Loss:  0.03490692377090454
Epoch:  471  	Training Loss: 0.03340587764978409
Test Loss:  0.03066903166472912
Valid Loss:  0.0348980650305748
Epoch:  472  	Training Loss: 0.033397376537323
Test Loss:  0.030660754069685936
Valid Loss:  0.0348893366754055
Epoch:  473  	Training Loss: 0.033389005810022354
Test Loss:  0.030652474611997604
Valid Loss:  0.03488060459494591
Epoch:  474  	Training Loss: 0.03338062763214111
Test Loss:  0.03064420074224472
Valid Loss:  0.03487187251448631
Epoch:  475  	Training Loss: 0.03337226063013077
Test Loss:  0.030635926872491837
Valid Loss:  0.034863147884607315
Epoch:  476  	Training Loss: 0.033363889902830124
Test Loss:  0.03062766045331955
Valid Loss:  0.034854426980018616
Epoch:  477  	Training Loss: 0.03335551917552948
Test Loss:  0.030619388446211815
Valid Loss:  0.034845706075429916
Epoch:  478  	Training Loss: 0.03334715589880943
Test Loss:  0.030611127614974976
Valid Loss:  0.03483698517084122
Epoch:  479  	Training Loss: 0.033338792622089386
Test Loss:  0.030602864921092987
Valid Loss:  0.034828267991542816
Epoch:  480  	Training Loss: 0.03333043307065964
Test Loss:  0.030594602227211
Valid Loss:  0.03481955826282501
Epoch:  481  	Training Loss: 0.03332207724452019
Test Loss:  0.030586350709199905
Valid Loss:  0.03481085225939751
Epoch:  482  	Training Loss: 0.033313728868961334
Test Loss:  0.030578147619962692
Valid Loss:  0.03480220586061478
Epoch:  483  	Training Loss: 0.03330543264746666
Test Loss:  0.03056994639337063
Valid Loss:  0.03479355573654175
Epoch:  484  	Training Loss: 0.033297136425971985
Test Loss:  0.030561748892068863
Valid Loss:  0.03478490933775902
Epoch:  485  	Training Loss: 0.03328884392976761
Test Loss:  0.030553553253412247
Valid Loss:  0.034776266664266586
Epoch:  486  	Training Loss: 0.03328055888414383
Test Loss:  0.03054536134004593
Valid Loss:  0.03476763144135475
Epoch:  487  	Training Loss: 0.03327226638793945
Test Loss:  0.03053717315196991
Valid Loss:  0.03475899249315262
Epoch:  488  	Training Loss: 0.03326398506760597
Test Loss:  0.03052898310124874
Valid Loss:  0.034750353544950485
Epoch:  489  	Training Loss: 0.03325570374727249
Test Loss:  0.03052080050110817
Valid Loss:  0.03474172204732895
Epoch:  490  	Training Loss: 0.03324741870164871
Test Loss:  0.03051261603832245
Valid Loss:  0.03473309427499771
Epoch:  491  	Training Loss: 0.03323914855718613
Test Loss:  0.030504437163472176
Valid Loss:  0.03472446650266647
Epoch:  492  	Training Loss: 0.033230870962142944
Test Loss:  0.030496327206492424
Valid Loss:  0.034715913236141205
Epoch:  493  	Training Loss: 0.03322267159819603
Test Loss:  0.03048822097480297
Valid Loss:  0.03470736742019653
Epoch:  494  	Training Loss: 0.033214472234249115
Test Loss:  0.030480116605758667
Valid Loss:  0.03469882160425186
Epoch:  495  	Training Loss: 0.0332062765955925
Test Loss:  0.03047201596200466
Valid Loss:  0.03469027578830719
Epoch:  496  	Training Loss: 0.03319808095693588
Test Loss:  0.030463913455605507
Valid Loss:  0.034681737422943115
Epoch:  497  	Training Loss: 0.03318989276885986
Test Loss:  0.0304558165371418
Valid Loss:  0.03467319533228874
Epoch:  498  	Training Loss: 0.03318169713020325
Test Loss:  0.030447721481323242
Valid Loss:  0.034664660692214966
Epoch:  499  	Training Loss: 0.033173512667417526
Test Loss:  0.030439626425504684
Valid Loss:  0.03465612605214119
Epoch:  500  	Training Loss: 0.033165328204631805
Test Loss:  0.030431542545557022
Valid Loss:  0.03464759141206741
seed is  6
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:55,  6.24s/it]  1%|          | 3/500 [00:06<13:48,  1.67s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:19<13:02,  1.61s/it]  3%|▎         | 17/500 [00:19<09:03,  1.13s/it]  4%|▍         | 19/500 [00:19<06:22,  1.26it/s]  4%|▍         | 21/500 [00:25<12:04,  1.51s/it]  5%|▍         | 23/500 [00:26<08:30,  1.07s/it]  5%|▌         | 25/500 [00:26<06:03,  1.31it/s]  5%|▌         | 27/500 [00:26<04:21,  1.81it/s]  6%|▌         | 29/500 [00:26<03:10,  2.47it/s]  6%|▌         | 31/500 [00:33<09:58,  1.28s/it]  7%|▋         | 33/500 [00:33<07:05,  1.10it/s]  7%|▋         | 35/500 [00:33<05:05,  1.52it/s]  7%|▋         | 37/500 [00:33<03:42,  2.09it/s]  8%|▊         | 39/500 [00:33<02:43,  2.82it/s]  8%|▊         | 41/500 [00:40<09:33,  1.25s/it]  9%|▊         | 43/500 [00:40<06:49,  1.12it/s]  9%|▉         | 45/500 [00:40<04:54,  1.54it/s]  9%|▉         | 47/500 [00:40<03:37,  2.09it/s] 10%|▉         | 49/500 [00:40<02:42,  2.77it/s] 10%|█         | 51/500 [00:47<09:02,  1.21s/it] 11%|█         | 53/500 [00:47<06:27,  1.15it/s] 11%|█         | 55/500 [00:47<04:38,  1.60it/s] 11%|█▏        | 57/500 [00:47<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:47<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:54<08:40,  1.18s/it] 13%|█▎        | 63/500 [00:54<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:54<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:54<03:14,  2.22it/s]Epoch:  1  	Training Loss: 0.02478910982608795
Test Loss:  0.012132569216191769
Valid Loss:  0.017023831605911255
Epoch:  2  	Training Loss: 0.01985522359609604
Test Loss:  0.014464693143963814
Valid Loss:  0.017703324556350708
Epoch:  3  	Training Loss: 0.016670573502779007
Test Loss:  0.016007643193006516
Valid Loss:  0.019192401319742203
Epoch:  4  	Training Loss: 0.021894801408052444
Test Loss:  0.024634670466184616
Valid Loss:  0.027098534628748894
Epoch:  5  	Training Loss: 0.024478387087583542
Test Loss:  0.0035036157350987196
Valid Loss:  0.005835740361362696
Epoch:  6  	Training Loss: 0.006598931737244129
Test Loss:  0.003501574043184519
Valid Loss:  0.005410975776612759
Epoch:  7  	Training Loss: 0.005011519882827997
Test Loss:  0.0020853003952652216
Valid Loss:  0.0040093157440423965
Epoch:  8  	Training Loss: 0.004129818640649319
Test Loss:  0.0022041371557861567
Valid Loss:  0.003909253515303135
Epoch:  9  	Training Loss: 0.0036598225124180317
Test Loss:  0.0018257987685501575
Valid Loss:  0.0034330307971686125
Epoch:  10  	Training Loss: 0.003345903940498829
Test Loss:  0.0019297951366752386
Valid Loss:  0.003411913523450494
Epoch:  11  	Training Loss: 0.0031330627389252186
Test Loss:  0.0017347396351397038
Valid Loss:  0.003163930494338274
Epoch:  12  	Training Loss: 0.0029741963371634483
Test Loss:  0.0033462452702224255
Valid Loss:  0.004099871031939983
Epoch:  13  	Training Loss: 0.003183855442330241
Test Loss:  0.005155390594154596
Valid Loss:  0.007123654242604971
Epoch:  14  	Training Loss: 0.008133245632052422
Test Loss:  0.02939402312040329
Valid Loss:  0.028160156682133675
Epoch:  15  	Training Loss: 0.023209840059280396
Test Loss:  0.004492897540330887
Valid Loss:  0.006500544026494026
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.00743813905864954
Test Loss:  0.001831753645092249
Valid Loss:  0.0032356493175029755
Epoch:  17  	Training Loss: 0.003070390783250332
Test Loss:  0.0019881059415638447
Valid Loss:  0.0032601598650217056
Epoch:  18  	Training Loss: 0.002874938305467367
Test Loss:  0.0019920249469578266
Valid Loss:  0.0032278592698276043
Epoch:  19  	Training Loss: 0.002825478557497263
Test Loss:  0.001989569514989853
Valid Loss:  0.00319938687607646
Epoch:  20  	Training Loss: 0.0027866982854902744
Test Loss:  0.0019912580028176308
Valid Loss:  0.0031800309661775827
Epoch:  21  	Training Loss: 0.0027581825852394104
Test Loss:  0.0019949800334870815
Valid Loss:  0.003166218288242817
Epoch:  22  	Training Loss: 0.002734486712142825
Test Loss:  0.0019455950241535902
Valid Loss:  0.0030839722603559494
Epoch:  23  	Training Loss: 0.002660099882632494
Test Loss:  0.001944329938851297
Valid Loss:  0.0030485186725854874
Epoch:  24  	Training Loss: 0.002607752336189151
Test Loss:  0.0019418997690081596
Valid Loss:  0.003024832345545292
Epoch:  25  	Training Loss: 0.0025707287713885307
Test Loss:  0.001942586386576295
Valid Loss:  0.003010465996339917
Epoch:  26  	Training Loss: 0.00254653487354517
Test Loss:  0.0019098380580544472
Valid Loss:  0.002977879950776696
Epoch:  27  	Training Loss: 0.0025283577851951122
Test Loss:  0.0019496340537443757
Valid Loss:  0.0029910998418927193
Epoch:  28  	Training Loss: 0.0025099688209593296
Test Loss:  0.001907972153276205
Valid Loss:  0.0029556192457675934
Epoch:  29  	Training Loss: 0.002496810629963875
Test Loss:  0.0019411130342632532
Valid Loss:  0.002965998835861683
Epoch:  30  	Training Loss: 0.0024823511485010386
Test Loss:  0.00191208824981004
Valid Loss:  0.0029395592864602804
Epoch:  31  	Training Loss: 0.0024707885459065437
Test Loss:  0.0019277497194707394
Valid Loss:  0.0029417655896395445
Epoch:  32  	Training Loss: 0.0024596587754786015
Test Loss:  0.0019289389019832015
Valid Loss:  0.0029376463498920202
Epoch:  33  	Training Loss: 0.002455561188980937
Test Loss:  0.0019375062547624111
Valid Loss:  0.002939069177955389
Epoch:  34  	Training Loss: 0.0024523583706468344
Test Loss:  0.0019352472154423594
Valid Loss:  0.0029343764763325453
Epoch:  35  	Training Loss: 0.0024498319253325462
Test Loss:  0.0019394226837903261
Valid Loss:  0.0029341161716729403
Epoch:  36  	Training Loss: 0.0024477564729750156
Test Loss:  0.0019383984617888927
Valid Loss:  0.002930999966338277
Epoch:  37  	Training Loss: 0.0024460176937282085
Test Loss:  0.0019395771669223905
Valid Loss:  0.0029295296408236027
Epoch:  38  	Training Loss: 0.0024445545859634876
Test Loss:  0.001941476482897997
Valid Loss:  0.0029287722427397966
Epoch:  39  	Training Loss: 0.0024432879872620106
Test Loss:  0.0019421433098614216
Valid Loss:  0.002927470253780484
Epoch:  40  	Training Loss: 0.002442187163978815
Test Loss:  0.0019426846411079168
Valid Loss:  0.0029262853786349297
Epoch:  41  	Training Loss: 0.002441226039081812
Test Loss:  0.0019431465771049261
Valid Loss:  0.002925206208601594
Epoch:  42  	Training Loss: 0.002440372481942177
Test Loss:  0.0019065255764871836
Valid Loss:  0.0028975135646760464
Epoch:  43  	Training Loss: 0.0024360993411391973
Test Loss:  0.0019345709588378668
Valid Loss:  0.0029134335927665234
Epoch:  44  	Training Loss: 0.0024336508940905333
Test Loss:  0.0019262873101979494
Valid Loss:  0.0029066167771816254
Epoch:  45  	Training Loss: 0.0024321838282048702
Test Loss:  0.0019367970526218414
Valid Loss:  0.0029120284598320723
Epoch:  46  	Training Loss: 0.0024311214219778776
Test Loss:  0.001937010558322072
Valid Loss:  0.0029112529009580612
Epoch:  47  	Training Loss: 0.002430447842925787
Test Loss:  0.0019377863500267267
Valid Loss:  0.002910890616476536
Epoch:  48  	Training Loss: 0.0024298913776874542
Test Loss:  0.0019383239559829235
Valid Loss:  0.002910470124334097
Epoch:  49  	Training Loss: 0.002429419197142124
Test Loss:  0.0019386943895369768
Valid Loss:  0.002910114359110594
Epoch:  50  	Training Loss: 0.0024289684370160103
Test Loss:  0.0019390999805182219
Valid Loss:  0.0029098056256771088
Epoch:  51  	Training Loss: 0.0024285379331558943
Test Loss:  0.0019395726267248392
Valid Loss:  0.0029095818754285574
Epoch:  52  	Training Loss: 0.0024281626101583242
Test Loss:  0.0020055172499269247
Valid Loss:  0.0028896420262753963
Epoch:  53  	Training Loss: 0.0023790658451616764
Test Loss:  0.0017850466538220644
Valid Loss:  0.0027603437192738056
Epoch:  54  	Training Loss: 0.0023469559382647276
Test Loss:  0.0019252212950959802
Valid Loss:  0.0027718828059732914
Epoch:  55  	Training Loss: 0.0022768634371459484
Test Loss:  0.001727231778204441
Valid Loss:  0.002656851662322879
Epoch:  56  	Training Loss: 0.002246776595711708
Test Loss:  0.0018055622931569815
Valid Loss:  0.002648863010108471
Epoch:  57  	Training Loss: 0.0021923016756772995
Test Loss:  0.0016314727254211903
Valid Loss:  0.0025221379473805428
Epoch:  58  	Training Loss: 0.0021355096250772476
Test Loss:  0.0017012341413646936
Valid Loss:  0.002528698416426778
Epoch:  59  	Training Loss: 0.002095673233270645
Test Loss:  0.0016119489446282387
Valid Loss:  0.0024643586948513985
Epoch:  60  	Training Loss: 0.002064573112875223
Test Loss:  0.0016163713298738003
Valid Loss:  0.0024484433233737946
Epoch:  61  	Training Loss: 0.0020395671017467976
Test Loss:  0.0015789044555276632
Valid Loss:  0.0024138714652508497
Epoch:  62  	Training Loss: 0.002016616053879261
Test Loss:  0.001569133484736085
Valid Loss:  0.002405156847089529
Epoch:  63  	Training Loss: 0.0020054548513144255
Test Loss:  0.001554842572659254
Valid Loss:  0.0023933802731335163
Epoch:  64  	Training Loss: 0.0019981996156275272
Test Loss:  0.0015532639808952808
Valid Loss:  0.0023904636036604643
Epoch:  65  	Training Loss: 0.0019905504304915667
Test Loss:  0.0015436506364494562
Valid Loss:  0.0023817685432732105
Epoch:  66  	Training Loss: 0.001983998343348503
Test Loss:  0.001541227102279663
Valid Loss:  0.0023799799382686615
Epoch:  67  	Training Loss: 0.0019785729236900806
Test Loss:  0.0015181166818365455
Valid Loss:  0.002361592138186097
Epoch:  68  	Training Loss: 0.0019737309776246548
Test Loss:  0.0015251479344442487
Valid Loss:  0.0023637553676962852
Epoch:  69  	Training Loss: 0.0019670568872243166
Test Loss:   14%|█▍        | 69/500 [00:54<02:24,  2.99it/s] 14%|█▍        | 71/500 [01:00<08:30,  1.19s/it] 15%|█▍        | 73/500 [01:01<06:03,  1.17it/s] 15%|█▌        | 75/500 [01:01<04:21,  1.62it/s] 15%|█▌        | 77/500 [01:01<03:12,  2.20it/s] 16%|█▌        | 79/500 [01:01<02:24,  2.91it/s] 16%|█▌        | 81/500 [01:07<08:20,  1.19s/it] 17%|█▋        | 83/500 [01:08<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:08<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:08<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:08<02:17,  2.98it/s] 18%|█▊        | 91/500 [01:14<07:55,  1.16s/it] 19%|█▊        | 93/500 [01:14<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:14<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:15<03:03,  2.20it/s] 20%|█▉        | 99/500 [01:15<02:17,  2.91it/s] 20%|██        | 101/500 [01:21<08:01,  1.21s/it] 21%|██        | 103/500 [01:21<05:42,  1.16it/s] 21%|██        | 105/500 [01:21<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:22<03:01,  2.16it/s] 22%|██▏       | 109/500 [01:22<02:16,  2.87it/s] 22%|██▏       | 111/500 [01:28<07:47,  1.20s/it] 23%|██▎       | 113/500 [01:28<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:28<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:29<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:29<02:09,  2.94it/s] 24%|██▍       | 121/500 [01:35<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:35<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:35<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:35<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:36<02:07,  2.92it/s] 26%|██▌       | 131/500 [01:42<07:27,  1.21s/it] 27%|██▋       | 133/500 [01:42<05:18,  1.15it/s] 27%|██▋       | 135/500 [01:42<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:42<02:46,  2.18it/s]0.0015237219631671906
Valid Loss:  0.0023605371825397015
Epoch:  70  	Training Loss: 0.0019611429888755083
Test Loss:  0.0015200878260657191
Valid Loss:  0.0023560787085443735
Epoch:  71  	Training Loss: 0.0019555753096938133
Test Loss:  0.0015153565909713507
Valid Loss:  0.002350834896788001
Epoch:  72  	Training Loss: 0.0019502615323290229
Test Loss:  0.0015198151813820004
Valid Loss:  0.002349729649722576
Epoch:  73  	Training Loss: 0.0019458811730146408
Test Loss:  0.0015207759570330381
Valid Loss:  0.002347338944673538
Epoch:  74  	Training Loss: 0.0019419658929109573
Test Loss:  0.001520755933597684
Valid Loss:  0.002344537526369095
Epoch:  75  	Training Loss: 0.0019381981110200286
Test Loss:  0.0015193256549537182
Valid Loss:  0.002341093961149454
Epoch:  76  	Training Loss: 0.0019345410401001573
Test Loss:  0.0015175481094047427
Valid Loss:  0.002337479032576084
Epoch:  77  	Training Loss: 0.0019309574272483587
Test Loss:  0.001514342613518238
Valid Loss:  0.002333429642021656
Epoch:  78  	Training Loss: 0.0019274840597063303
Test Loss:  0.0015113764675334096
Valid Loss:  0.002329519484192133
Epoch:  79  	Training Loss: 0.0019240512046962976
Test Loss:  0.0015085681807249784
Valid Loss:  0.0023256870917975903
Epoch:  80  	Training Loss: 0.0019206609576940536
Test Loss:  0.0015058706048876047
Valid Loss:  0.0023219031281769276
Epoch:  81  	Training Loss: 0.0019172881729900837
Test Loss:  0.0015032249502837658
Valid Loss:  0.0023181692231446505
Epoch:  82  	Training Loss: 0.001913935411721468
Test Loss:  0.0014906481374055147
Valid Loss:  0.0023054489865899086
Epoch:  83  	Training Loss: 0.0019079199992120266
Test Loss:  0.0014868499711155891
Valid Loss:  0.0022992240265011787
Epoch:  84  	Training Loss: 0.0019037433667108417
Test Loss:  0.0014824585523456335
Valid Loss:  0.0022937790490686893
Epoch:  85  	Training Loss: 0.0019006953807547688
Test Loss:  0.0014804140664637089
Valid Loss:  0.002290015574544668
Epoch:  86  	Training Loss: 0.0018982234178110957
Test Loss:  0.0014804607490077615
Valid Loss:  0.002287923824042082
Epoch:  87  	Training Loss: 0.0018961220048367977
Test Loss:  0.0014782778453081846
Valid Loss:  0.0022857561707496643
Epoch:  88  	Training Loss: 0.0018947320058941841
Test Loss:  0.0014767107786610723
Valid Loss:  0.0022842134349048138
Epoch:  89  	Training Loss: 0.0018935753032565117
Test Loss:  0.0014765580417588353
Valid Loss:  0.0022833896800875664
Epoch:  90  	Training Loss: 0.0018926149932667613
Test Loss:  0.0014765486121177673
Valid Loss:  0.0022827964276075363
Epoch:  91  	Training Loss: 0.001891684951260686
Test Loss:  0.001477010315284133
Valid Loss:  0.0022824397310614586
Epoch:  92  	Training Loss: 0.0018908027559518814
Test Loss:  0.0014759479090571404
Valid Loss:  0.0022740131244063377
Epoch:  93  	Training Loss: 0.0018810119945555925
Test Loss:  0.0014703217893838882
Valid Loss:  0.002266064751893282
Epoch:  94  	Training Loss: 0.001873764325864613
Test Loss:  0.0014651273377239704
Valid Loss:  0.002260457258671522
Epoch:  95  	Training Loss: 0.001869106199592352
Test Loss:  0.0014620734145864844
Valid Loss:  0.0022561540827155113
Epoch:  96  	Training Loss: 0.0018654813757166266
Test Loss:  0.0014591857325285673
Valid Loss:  0.002252470003440976
Epoch:  97  	Training Loss: 0.0018627906683832407
Test Loss:  0.0014570860657840967
Valid Loss:  0.0022497535683214664
Epoch:  98  	Training Loss: 0.0018605489749461412
Test Loss:  0.001455554156564176
Valid Loss:  0.0022476324811577797
Epoch:  99  	Training Loss: 0.0018586708465591073
Test Loss:  0.0014541433192789555
Valid Loss:  0.0022457093000411987
Epoch:  100  	Training Loss: 0.0018571726977825165
Test Loss:  0.0014527493622153997
Valid Loss:  0.0022440175525844097
Epoch:  101  	Training Loss: 0.0018559328746050596
Test Loss:  0.001451715361326933
Valid Loss:  0.0022426678333431482
Epoch:  102  	Training Loss: 0.0018549320520833135
Test Loss:  0.0014454094925895333
Valid Loss:  0.002234895247966051
Epoch:  103  	Training Loss: 0.001852294197306037
Test Loss:  0.0014422242529690266
Valid Loss:  0.0022324081510305405
Epoch:  104  	Training Loss: 0.0018510982627049088
Test Loss:  0.0014427739661186934
Valid Loss:  0.0022323483135551214
Epoch:  105  	Training Loss: 0.0018503780011087656
Test Loss:  0.0014429906150326133
Valid Loss:  0.0022322670556604862
Epoch:  106  	Training Loss: 0.0018499826546758413
Test Loss:  0.001443603541702032
Valid Loss:  0.002232697792351246
Epoch:  107  	Training Loss: 0.0018497086130082607
Test Loss:  0.0014435413759201765
Valid Loss:  0.002232664031907916
Epoch:  108  	Training Loss: 0.0018494757823646069
Test Loss:  0.0014430934097617865
Valid Loss:  0.002232647966593504
Epoch:  109  	Training Loss: 0.0018492856761440635
Test Loss:  0.0014431534800678492
Valid Loss:  0.002232705242931843
Epoch:  110  	Training Loss: 0.0018491162918508053
Test Loss:  0.001442610751837492
Valid Loss:  0.0022324835881590843
Epoch:  111  	Training Loss: 0.0018489790381863713
Test Loss:  0.0014430079609155655
Valid Loss:  0.0022332046646624804
Epoch:  112  	Training Loss: 0.0018488668138161302
Test Loss:  0.0014441944658756256
Valid Loss:  0.0022064773365855217
Epoch:  113  	Training Loss: 0.0018168617971241474
Test Loss:  0.0014086011797189713
Valid Loss:  0.0021767658181488514
Epoch:  114  	Training Loss: 0.0018054535612463951
Test Loss:  0.001404070295393467
Valid Loss:  0.0021682954393327236
Epoch:  115  	Training Loss: 0.0017992360517382622
Test Loss:  0.0013950492721050978
Valid Loss:  0.0021601535845547915
Epoch:  116  	Training Loss: 0.0017949054017663002
Test Loss:  0.001391169149428606
Valid Loss:  0.002155912108719349
Epoch:  117  	Training Loss: 0.0017913372721523046
Test Loss:  0.0013845828361809254
Valid Loss:  0.002151367487385869
Epoch:  118  	Training Loss: 0.0017881602980196476
Test Loss:  0.001383402617648244
Valid Loss:  0.0021493511740118265
Epoch:  119  	Training Loss: 0.00178531336132437
Test Loss:  0.0013780801091343164
Valid Loss:  0.0021458351984620094
Epoch:  120  	Training Loss: 0.0017828367417678237
Test Loss:  0.0013767210766673088
Valid Loss:  0.002144160447642207
Epoch:  121  	Training Loss: 0.0017805001698434353
Test Loss:  0.0013750729849562049
Valid Loss:  0.002142302691936493
Epoch:  122  	Training Loss: 0.0017783441580832005
Test Loss:  0.001373564125970006
Valid Loss:  0.002140066120773554
Epoch:  123  	Training Loss: 0.0017745626391842961
Test Loss:  0.001371676567941904
Valid Loss:  0.002139356452971697
Epoch:  124  	Training Loss: 0.0017728492384776473
Test Loss:  0.0013696252135559916
Valid Loss:  0.0021385392174124718
Epoch:  125  	Training Loss: 0.0017722187330946326
Test Loss:  0.0013684045989066362
Valid Loss:  0.002138003706932068
Epoch:  126  	Training Loss: 0.00177168776281178
Test Loss:  0.001367318443953991
Valid Loss:  0.002137279137969017
Epoch:  127  	Training Loss: 0.0017711741384118795
Test Loss:  0.0013666512677446008
Valid Loss:  0.002136822324246168
Epoch:  128  	Training Loss: 0.0017706808866932988
Test Loss:  0.0013660548720508814
Valid Loss:  0.0021363762207329273
Epoch:  129  	Training Loss: 0.0017702023033052683
Test Loss:  0.001365480711683631
Valid Loss:  0.002136098686605692
Epoch:  130  	Training Loss: 0.0017697386210784316
Test Loss:  0.0013647754676640034
Valid Loss:  0.0021355035714805126
Epoch:  131  	Training Loss: 0.0017692761030048132
Test Loss:  0.0013641943223774433
Valid Loss:  0.002135160844773054
Epoch:  132  	Training Loss: 0.0017688297666609287
Test Loss:  0.0013583071995526552
Valid Loss:  0.002126426203176379
Epoch:  133  	Training Loss: 0.0017602713778614998
Test Loss:  0.0013529655989259481
Valid Loss:  0.0021193057764321566
Epoch:  134  	Training Loss: 0.0017532440833747387
Test Loss:  0.0013480455381795764
Valid Loss:  0.0021131224930286407
Epoch:  135  	Training Loss: 0.001747698406688869
Test Loss:  0.0013434626162052155
Valid Loss:  0.0021076169796288013
Epoch:  136  	Training Loss: 0.0017432942986488342
Test Loss:  0.0013393252156674862
Valid Loss:  0.002102439058944583
Epoch:  137  	Training Loss: 0.0017395064933225513
Test Loss:  0.0013357055140659213
Valid Loss:  0.0020981202833354473
Epoch:  138  	Training Loss: 0.0017362963408231735
 28%|██▊       | 139/500 [01:43<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:49<06:56,  1.16s/it] 29%|██▊       | 143/500 [01:49<04:57,  1.20it/s] 29%|██▉       | 145/500 [01:49<03:34,  1.66it/s] 29%|██▉       | 147/500 [01:49<02:36,  2.26it/s] 30%|██▉       | 149/500 [01:49<01:55,  3.04it/s] 30%|███       | 151/500 [01:56<06:47,  1.17s/it] 31%|███       | 153/500 [01:56<04:50,  1.19it/s] 31%|███       | 155/500 [01:56<03:28,  1.65it/s] 31%|███▏      | 157/500 [01:56<02:31,  2.26it/s] 32%|███▏      | 159/500 [01:56<01:52,  3.03it/s] 32%|███▏      | 161/500 [02:02<06:31,  1.16s/it] 33%|███▎      | 163/500 [02:02<04:39,  1.21it/s] 33%|███▎      | 165/500 [02:02<03:20,  1.67it/s] 33%|███▎      | 167/500 [02:03<02:26,  2.28it/s] 34%|███▍      | 169/500 [02:03<01:48,  3.06it/s] 34%|███▍      | 171/500 [02:09<06:34,  1.20s/it] 35%|███▍      | 173/500 [02:09<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:09<03:22,  1.61it/s] 35%|███▌      | 177/500 [02:10<02:28,  2.17it/s] 36%|███▌      | 179/500 [02:10<01:51,  2.87it/s] 36%|███▌      | 181/500 [02:16<06:25,  1.21s/it] 37%|███▋      | 183/500 [02:16<04:34,  1.15it/s] 37%|███▋      | 185/500 [02:17<03:17,  1.59it/s] 37%|███▋      | 187/500 [02:17<02:23,  2.18it/s] 38%|███▊      | 189/500 [02:17<01:46,  2.93it/s] 38%|███▊      | 191/500 [02:23<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:23<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:23<03:06,  1.63it/s] 39%|███▉      | 197/500 [02:23<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:24<01:43,  2.91it/s] 40%|████      | 201/500 [02:30<05:57,  1.19s/it] 41%|████      | 203/500 [02:30<04:14,  1.17it/s] 41%|████      | 205/500 [02:30<03:02,  1.62it/s]Test Loss:  0.0013331992086023092
Valid Loss:  0.0020948618184775114
Epoch:  139  	Training Loss: 0.001733387354761362
Test Loss:  0.001330027123913169
Valid Loss:  0.0020917830988764763
Epoch:  140  	Training Loss: 0.001731021562591195
Test Loss:  0.0013277062680572271
Valid Loss:  0.0020891455933451653
Epoch:  141  	Training Loss: 0.0017288066446781158
Test Loss:  0.0013261416461318731
Valid Loss:  0.0020870002917945385
Epoch:  142  	Training Loss: 0.0017268287483602762
Test Loss:  0.0013020735932514071
Valid Loss:  0.0020632329396903515
Epoch:  143  	Training Loss: 0.001707189017906785
Test Loss:  0.0012872058432549238
Valid Loss:  0.002049430273473263
Epoch:  144  	Training Loss: 0.001694970764219761
Test Loss:  0.0012772692134603858
Valid Loss:  0.002042006002739072
Epoch:  145  	Training Loss: 0.001688772113993764
Test Loss:  0.0012723066611215472
Valid Loss:  0.002037503058090806
Epoch:  146  	Training Loss: 0.001683437149040401
Test Loss:  0.001266074599698186
Valid Loss:  0.0020330867264419794
Epoch:  147  	Training Loss: 0.0016789331566542387
Test Loss:  0.0012639634078368545
Valid Loss:  0.002030271338298917
Epoch:  148  	Training Loss: 0.0016751198563724756
Test Loss:  0.0012583485804498196
Valid Loss:  0.0020264354534447193
Epoch:  149  	Training Loss: 0.0016718667466193438
Test Loss:  0.001256434479728341
Valid Loss:  0.00202420842833817
Epoch:  150  	Training Loss: 0.0016690625343471766
Test Loss:  0.00125396519433707
Valid Loss:  0.0020215963013470173
Epoch:  151  	Training Loss: 0.0016665542498230934
Test Loss:  0.001252662972547114
Valid Loss:  0.0020194838289171457
Epoch:  152  	Training Loss: 0.0016644393326714635
Test Loss:  0.0012717547360807657
Valid Loss:  0.0020147780887782574
Epoch:  153  	Training Loss: 0.001649100217036903
Test Loss:  0.001265721395611763
Valid Loss:  0.0020034778863191605
Epoch:  154  	Training Loss: 0.0016427816590294242
Test Loss:  0.0012584311189129949
Valid Loss:  0.0019947513937950134
Epoch:  155  	Training Loss: 0.0016390192322432995
Test Loss:  0.0012526155915111303
Valid Loss:  0.001988608157262206
Epoch:  156  	Training Loss: 0.0016364606563001871
Test Loss:  0.0012469959910959005
Valid Loss:  0.0019837655127048492
Epoch:  157  	Training Loss: 0.0016345815965905786
Test Loss:  0.001244815532118082
Valid Loss:  0.0019814292900264263
Epoch:  158  	Training Loss: 0.0016329181380569935
Test Loss:  0.0012441164581105113
Valid Loss:  0.001979544758796692
Epoch:  159  	Training Loss: 0.0016313886735588312
Test Loss:  0.0012411047937348485
Valid Loss:  0.0019770488142967224
Epoch:  160  	Training Loss: 0.0016299712006002665
Test Loss:  0.0012401689309626818
Valid Loss:  0.0019760059658437967
Epoch:  161  	Training Loss: 0.001628694823011756
Test Loss:  0.0012379976687952876
Valid Loss:  0.0019741556607186794
Epoch:  162  	Training Loss: 0.0016275325324386358
Test Loss:  0.0012411067727953196
Valid Loss:  0.001972656697034836
Epoch:  163  	Training Loss: 0.0016235251678153872
Test Loss:  0.0012377272360026836
Valid Loss:  0.0019680217374116182
Epoch:  164  	Training Loss: 0.0016199396923184395
Test Loss:  0.0012361523695290089
Valid Loss:  0.001963989809155464
Epoch:  165  	Training Loss: 0.001616430003196001
Test Loss:  0.0012315143831074238
Valid Loss:  0.001958883600309491
Epoch:  166  	Training Loss: 0.0016130681615322828
Test Loss:  0.0012299366062507033
Valid Loss:  0.0019553215242922306
Epoch:  167  	Training Loss: 0.0016098171472549438
Test Loss:  0.0012272743042558432
Valid Loss:  0.0019514851737767458
Epoch:  168  	Training Loss: 0.0016065973322838545
Test Loss:  0.0012247426202520728
Valid Loss:  0.0019477270543575287
Epoch:  169  	Training Loss: 0.0016034736763685942
Test Loss:  0.001222529448568821
Valid Loss:  0.0019442883785814047
Epoch:  170  	Training Loss: 0.0016003744676709175
Test Loss:  0.0012172497808933258
Valid Loss:  0.001938577275723219
Epoch:  171  	Training Loss: 0.001597458845935762
Test Loss:  0.0012174835428595543
Valid Loss:  0.0019366133492439985
Epoch:  172  	Training Loss: 0.0015944913029670715
Test Loss:  0.0011927880113944411
Valid Loss:  0.0019192667677998543
Epoch:  173  	Training Loss: 0.0015834482619538903
Test Loss:  0.0011823282111436129
Valid Loss:  0.001911516534164548
Epoch:  174  	Training Loss: 0.0015752362087368965
Test Loss:  0.0011749271070584655
Valid Loss:  0.0019060876220464706
Epoch:  175  	Training Loss: 0.0015690559521317482
Test Loss:  0.0011685640783980489
Valid Loss:  0.0019010102842003107
Epoch:  176  	Training Loss: 0.001563929719850421
Test Loss:  0.0011637882562354207
Valid Loss:  0.0018967656651511788
Epoch:  177  	Training Loss: 0.001559730269946158
Test Loss:  0.001159770879894495
Valid Loss:  0.0018936864798888564
Epoch:  178  	Training Loss: 0.0015559555031359196
Test Loss:  0.0011562906438484788
Valid Loss:  0.0018908679485321045
Epoch:  179  	Training Loss: 0.0015526164788752794
Test Loss:  0.0011531151831150055
Valid Loss:  0.001888226717710495
Epoch:  180  	Training Loss: 0.0015496881678700447
Test Loss:  0.001150263356976211
Valid Loss:  0.0018858280964195728
Epoch:  181  	Training Loss: 0.001547115040011704
Test Loss:  0.0011479270178824663
Valid Loss:  0.0018836379749700427
Epoch:  182  	Training Loss: 0.0015449058264493942
Test Loss:  0.001138559659011662
Valid Loss:  0.0018319294322282076
Epoch:  183  	Training Loss: 0.0014859919901937246
Test Loss:  0.0011036130599677563
Valid Loss:  0.0017816436011344194
Epoch:  184  	Training Loss: 0.0014445732813328505
Test Loss:  0.0010686132591217756
Valid Loss:  0.001738035585731268
Epoch:  185  	Training Loss: 0.001411269186064601
Test Loss:  0.0010408207308501005
Valid Loss:  0.001700997119769454
Epoch:  186  	Training Loss: 0.0013848177623003721
Test Loss:  0.0010171686299145222
Valid Loss:  0.0016736268298700452
Epoch:  187  	Training Loss: 0.0013678711839020252
Test Loss:  0.0010001850314438343
Valid Loss:  0.0016525336541235447
Epoch:  188  	Training Loss: 0.0013543561799451709
Test Loss:  0.0009860384743660688
Valid Loss:  0.0016347091877833009
Epoch:  189  	Training Loss: 0.001342998817563057
Test Loss:  0.0009750801837071776
Valid Loss:  0.0016217863885685802
Epoch:  190  	Training Loss: 0.0013333801180124283
Test Loss:  0.0009668883285485208
Valid Loss:  0.0016117433551698923
Epoch:  191  	Training Loss: 0.001325527555309236
Test Loss:  0.0009587411768734455
Valid Loss:  0.0016039640177041292
Epoch:  192  	Training Loss: 0.0013191038742661476
Test Loss:  0.0009352978086099029
Valid Loss:  0.0015880909049883485
Epoch:  193  	Training Loss: 0.001308541395701468
Test Loss:  0.0009312237380072474
Valid Loss:  0.0015833843499422073
Epoch:  194  	Training Loss: 0.0013010605471208692
Test Loss:  0.00092395453248173
Valid Loss:  0.0015764160780236125
Epoch:  195  	Training Loss: 0.0012949096271768212
Test Loss:  0.0009199524647556245
Valid Loss:  0.0015712060267105699
Epoch:  196  	Training Loss: 0.0012893707025796175
Test Loss:  0.0009157156455330551
Valid Loss:  0.0015659956261515617
Epoch:  197  	Training Loss: 0.0012843119911849499
Test Loss:  0.000912003917619586
Valid Loss:  0.001560934935696423
Epoch:  198  	Training Loss: 0.0012795409420505166
Test Loss:  0.0009082702454179525
Valid Loss:  0.0015558674931526184
Epoch:  199  	Training Loss: 0.0012750583700835705
Test Loss:  0.000905063294339925
Valid Loss:  0.0015509887598454952
Epoch:  200  	Training Loss: 0.001270814100280404
Test Loss:  0.0009016829426400363
Valid Loss:  0.001546474639326334
Epoch:  201  	Training Loss: 0.0012668365379795432
Test Loss:  0.000898716039955616
Valid Loss:  0.0015420407289639115
Epoch:  202  	Training Loss: 0.001262983656488359
Test Loss:  0.0009018589043989778
Valid Loss:  0.0015388010069727898
Epoch:  203  	Training Loss: 0.0012587248347699642
Test Loss:  0.0008985105087049305
Valid Loss:  0.001533029368147254
Epoch:  204  	Training Loss: 0.0012556046713143587
Test Loss:  0.0008968599140644073
Valid Loss:  0.001529099652543664
Epoch:  205  	Training Loss: 0.0012531254906207323
Test Loss:  0.0008950878400355577
Valid Loss:  0.0015256615588441491
Epoch:  206  	Training Loss: 0.0012512891553342342
Test Loss:  0.0008942681597545743
Valid Loss:  0.0015229657292366028
 41%|████▏     | 207/500 [02:30<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:31<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:37<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:37<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:37<02:53,  1.65it/s] 43%|████▎     | 217/500 [02:37<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:37<01:32,  3.03it/s] 44%|████▍     | 221/500 [02:43<05:23,  1.16s/it] 45%|████▍     | 223/500 [02:44<03:51,  1.20it/s] 45%|████▌     | 225/500 [02:44<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:44<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:44<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:50<05:19,  1.19s/it] 47%|████▋     | 233/500 [02:51<03:47,  1.17it/s] 47%|████▋     | 235/500 [02:51<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:51<01:58,  2.21it/s] 48%|████▊     | 239/500 [02:51<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:57<05:01,  1.16s/it] 49%|████▊     | 243/500 [02:57<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:57<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:58<01:52,  2.26it/s] 50%|████▉     | 249/500 [02:58<01:22,  3.03it/s] 50%|█████     | 251/500 [03:04<04:53,  1.18s/it] 51%|█████     | 253/500 [03:04<03:29,  1.18it/s] 51%|█████     | 255/500 [03:04<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:04<01:48,  2.23it/s] 52%|█████▏    | 259/500 [03:05<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:11<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:11<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:11<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:11<01:46,  2.19it/s] 54%|█████▍    | 269/500 [03:11<01:19,  2.90it/s] 54%|█████▍    | 271/500 [03:18<04:30,  1.18s/it] 55%|█████▍    | 273/500 [03:18<03:12,  1.18it/s]Epoch:  207  	Training Loss: 0.0012497466523200274
Test Loss:  0.0008928999886848032
Valid Loss:  0.0015204956289380789
Epoch:  208  	Training Loss: 0.001248534070327878
Test Loss:  0.00089173240121454
Valid Loss:  0.0015186475357040763
Epoch:  209  	Training Loss: 0.0012475166004151106
Test Loss:  0.0008905096910893917
Valid Loss:  0.0015172787243500352
Epoch:  210  	Training Loss: 0.0012467345222830772
Test Loss:  0.0008897400693967938
Valid Loss:  0.0015163210919126868
Epoch:  211  	Training Loss: 0.0012460225261747837
Test Loss:  0.0008896642248146236
Valid Loss:  0.0015157097950577736
Epoch:  212  	Training Loss: 0.0012453383533284068
Test Loss:  0.0008895541541278362
Valid Loss:  0.001512819086201489
Epoch:  213  	Training Loss: 0.0012392636854201555
Test Loss:  0.0008848564466461539
Valid Loss:  0.00150685990229249
Epoch:  214  	Training Loss: 0.0012336139334365726
Test Loss:  0.000880260078702122
Valid Loss:  0.0015010936185717583
Epoch:  215  	Training Loss: 0.0012280893279239535
Test Loss:  0.0008753178990446031
Valid Loss:  0.0014949995093047619
Epoch:  216  	Training Loss: 0.001222661230713129
Test Loss:  0.0008704285719431937
Valid Loss:  0.0014888262376189232
Epoch:  217  	Training Loss: 0.0012173071736469865
Test Loss:  0.0008657881990075111
Valid Loss:  0.0014827798586338758
Epoch:  218  	Training Loss: 0.001212019706144929
Test Loss:  0.0008610824006609619
Valid Loss:  0.0014765659580007195
Epoch:  219  	Training Loss: 0.0012067805510014296
Test Loss:  0.0008567506447434425
Valid Loss:  0.0014706156216561794
Epoch:  220  	Training Loss: 0.0012015888933092356
Test Loss:  0.0008522137068212032
Valid Loss:  0.00146439578384161
Epoch:  221  	Training Loss: 0.0011964414734393358
Test Loss:  0.0008484395802952349
Valid Loss:  0.0014589206548407674
Epoch:  222  	Training Loss: 0.0011913494672626257
Test Loss:  0.0008432946633547544
Valid Loss:  0.0014528315514326096
Epoch:  223  	Training Loss: 0.0011864537373185158
Test Loss:  0.0008391351439058781
Valid Loss:  0.0014472589828073978
Epoch:  224  	Training Loss: 0.0011816852493211627
Test Loss:  0.0008353376179002225
Valid Loss:  0.0014418610371649265
Epoch:  225  	Training Loss: 0.001177016762085259
Test Loss:  0.0008318035979755223
Valid Loss:  0.0014366997638717294
Epoch:  226  	Training Loss: 0.0011723809875547886
Test Loss:  0.000827950076200068
Valid Loss:  0.0014312121784314513
Epoch:  227  	Training Loss: 0.0011677814181894064
Test Loss:  0.0008244807831943035
Valid Loss:  0.0014260350726544857
Epoch:  228  	Training Loss: 0.0011632107198238373
Test Loss:  0.0008209023508243263
Valid Loss:  0.0014208334032446146
Epoch:  229  	Training Loss: 0.0011586658656597137
Test Loss:  0.0008173336973413825
Valid Loss:  0.001415714737959206
Epoch:  230  	Training Loss: 0.0011541484855115414
Test Loss:  0.0008138824487105012
Valid Loss:  0.0014106908347457647
Epoch:  231  	Training Loss: 0.0011496625375002623
Test Loss:  0.0008101710700429976
Valid Loss:  0.0014056175714358687
Epoch:  232  	Training Loss: 0.0011452139588072896
Test Loss:  0.0008067003218457103
Valid Loss:  0.001398142660036683
Epoch:  233  	Training Loss: 0.0011399006471037865
Test Loss:  0.0008065232541412115
Valid Loss:  0.0013930564746260643
Epoch:  234  	Training Loss: 0.0011359830386936665
Test Loss:  0.0008029374293982983
Valid Loss:  0.0013893481809645891
Epoch:  235  	Training Loss: 0.0011344787199050188
Test Loss:  0.0008030289318412542
Valid Loss:  0.0013874724972993135
Epoch:  236  	Training Loss: 0.001133139245212078
Test Loss:  0.000802715600002557
Valid Loss:  0.0013857122976332903
Epoch:  237  	Training Loss: 0.0011318931356072426
Test Loss:  0.0008025285787880421
Valid Loss:  0.001384055009111762
Epoch:  238  	Training Loss: 0.001130803138948977
Test Loss:  0.0008019923698157072
Valid Loss:  0.0013825948117300868
Epoch:  239  	Training Loss: 0.0011297663440927863
Test Loss:  0.0008023849804885685
Valid Loss:  0.0013816606951877475
Epoch:  240  	Training Loss: 0.0011288139503449202
Test Loss:  0.0008015495259314775
Valid Loss:  0.0013804311165586114
Epoch:  241  	Training Loss: 0.0011278819292783737
Test Loss:  0.0008019623928703368
Valid Loss:  0.0013796559069305658
Epoch:  242  	Training Loss: 0.0011269603855907917
Test Loss:  0.0008056314545683563
Valid Loss:  0.0013658071402460337
Epoch:  243  	Training Loss: 0.001108762458898127
Test Loss:  0.0007888643303886056
Valid Loss:  0.0013500404311344028
Epoch:  244  	Training Loss: 0.0010974700562655926
Test Loss:  0.0007778962608426809
Valid Loss:  0.0013376553542912006
Epoch:  245  	Training Loss: 0.001088268356397748
Test Loss:  0.0007698670960962772
Valid Loss:  0.0013277651742100716
Epoch:  246  	Training Loss: 0.001080766785889864
Test Loss:  0.0007618401432409883
Valid Loss:  0.0013190105091780424
Epoch:  247  	Training Loss: 0.001074260100722313
Test Loss:  0.0007569502340629697
Valid Loss:  0.0013124126708135009
Epoch:  248  	Training Loss: 0.0010684472508728504
Test Loss:  0.0007521257502958179
Valid Loss:  0.0013065115781500936
Epoch:  249  	Training Loss: 0.0010634090285748243
Test Loss:  0.0007468881667591631
Valid Loss:  0.0013008880196139216
Epoch:  250  	Training Loss: 0.0010588990990072489
Test Loss:  0.0007431628764607012
Valid Loss:  0.0012960621388629079
Epoch:  251  	Training Loss: 0.0010547058191150427
Test Loss:  0.0007396398577839136
Valid Loss:  0.0012914328835904598
Epoch:  252  	Training Loss: 0.0010508839040994644
Test Loss:  0.0007358897128142416
Valid Loss:  0.0012881772127002478
Epoch:  253  	Training Loss: 0.0010471894638612866
Test Loss:  0.0007321713492274284
Valid Loss:  0.0012846726458519697
Epoch:  254  	Training Loss: 0.0010437972377985716
Test Loss:  0.0007289240602403879
Valid Loss:  0.001281369593925774
Epoch:  255  	Training Loss: 0.0010406309738755226
Test Loss:  0.0007253735093399882
Valid Loss:  0.0012779479147866368
Epoch:  256  	Training Loss: 0.0010376658756285906
Test Loss:  0.000722740194760263
Valid Loss:  0.0012748147128149867
Epoch:  257  	Training Loss: 0.0010348125360906124
Test Loss:  0.0007200038526207209
Valid Loss:  0.0012716236524283886
Epoch:  258  	Training Loss: 0.0010320900473743677
Test Loss:  0.0007166220457293093
Valid Loss:  0.0012683519162237644
Epoch:  259  	Training Loss: 0.001029430772177875
Test Loss:  0.0007141985697671771
Valid Loss:  0.0012654492165893316
Epoch:  260  	Training Loss: 0.0010268701007589698
Test Loss:  0.0007119094952940941
Valid Loss:  0.0012625288218259811
Epoch:  261  	Training Loss: 0.001024383120238781
Test Loss:  0.0007097769994288683
Valid Loss:  0.0012596301967278123
Epoch:  262  	Training Loss: 0.0010219380492344499
Test Loss:  0.0007028926629573107
Valid Loss:  0.0012509035877883434
Epoch:  263  	Training Loss: 0.0010178805096074939
Test Loss:  0.0007007226813584566
Valid Loss:  0.0012452991213649511
Epoch:  264  	Training Loss: 0.0010145388077944517
Test Loss:  0.0006994028808549047
Valid Loss:  0.0012407919857650995
Epoch:  265  	Training Loss: 0.0010116193443536758
Test Loss:  0.0006987634114921093
Valid Loss:  0.0012371683260425925
Epoch:  266  	Training Loss: 0.0010090804425999522
Test Loss:  0.0006975620053708553
Valid Loss:  0.0012336631771177053
Epoch:  267  	Training Loss: 0.0010068484116345644
Test Loss:  0.0006968607776798308
Valid Loss:  0.0012308803852647543
Epoch:  268  	Training Loss: 0.0010048921685665846
Test Loss:  0.000696081668138504
Valid Loss:  0.0012282730313017964
Epoch:  269  	Training Loss: 0.001003054203465581
Test Loss:  0.0006952782277949154
Valid Loss:  0.0012258270289748907
Epoch:  270  	Training Loss: 0.0010013272985816002
Test Loss:  0.0006945893401280046
Valid Loss:  0.0012237189803272486
Epoch:  271  	Training Loss: 0.0009997235611081123
Test Loss:  0.0006940636085346341
Valid Loss:  0.0012216612230986357
Epoch:  272  	Training Loss: 0.0009981556795537472
Test Loss:  0.0006904600886628032
Valid Loss:  0.0012117939768359065
Epoch:  273  	Training Loss: 0.0009883067104965448
Test Loss:  0.0006847545737400651
Valid Loss:  0.001202999847009778
Epoch:  274  	Training Loss: 0.0009812730131670833
Test Loss:  0.0006799624534323812
Valid Loss:  0.0011956662638112903
Epoch:  275  	Training Loss: 0.0009756165090948343
Test Loss:  55%|█████▌    | 275/500 [03:18<02:18,  1.63it/s] 55%|█████▌    | 277/500 [03:18<01:40,  2.23it/s] 56%|█████▌    | 279/500 [03:18<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:25<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:25<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:25<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:25<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:25<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:31<04:05,  1.18s/it] 59%|█████▊    | 293/500 [03:32<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:32<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:32<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:32<01:06,  3.01it/s] 60%|██████    | 301/500 [03:38<03:52,  1.17s/it] 61%|██████    | 303/500 [03:38<02:45,  1.19it/s] 61%|██████    | 305/500 [03:38<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:39<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:39<01:03,  3.03it/s] 62%|██████▏   | 311/500 [03:45<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:45<02:37,  1.18it/s] 63%|██████▎   | 315/500 [03:45<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:46<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:46<01:02,  2.90it/s] 64%|██████▍   | 321/500 [03:52<03:35,  1.21s/it] 65%|██████▍   | 323/500 [03:52<02:33,  1.16it/s] 65%|██████▌   | 325/500 [03:52<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:53<01:19,  2.19it/s] 66%|██████▌   | 329/500 [03:53<00:58,  2.94it/s] 66%|██████▌   | 331/500 [03:59<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:59<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:59<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:59<01:13,  2.23it/s] 68%|██████▊   | 339/500 [03:59<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:06<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:06<02:14,  1.17it/s] 0.000675440882332623
Valid Loss:  0.001189107308164239
Epoch:  276  	Training Loss: 0.0009706808486953378
Test Loss:  0.0006717651267535985
Valid Loss:  0.0011832078453153372
Epoch:  277  	Training Loss: 0.0009661263320595026
Test Loss:  0.0006687324494123459
Valid Loss:  0.001178104430437088
Epoch:  278  	Training Loss: 0.0009618072072044015
Test Loss:  0.0006654940079897642
Valid Loss:  0.0011732331477105618
Epoch:  279  	Training Loss: 0.0009576054872013628
Test Loss:  0.0006619783816859126
Valid Loss:  0.0011684761848300695
Epoch:  280  	Training Loss: 0.0009536235593259335
Test Loss:  0.0006589462282136083
Valid Loss:  0.0011640067677944899
Epoch:  281  	Training Loss: 0.0009497326682321727
Test Loss:  0.0006554423598572612
Valid Loss:  0.0011595088290050626
Epoch:  282  	Training Loss: 0.0009459995781071484
Test Loss:  0.0006488808430731297
Valid Loss:  0.0011557912221178412
Epoch:  283  	Training Loss: 0.0009444245952181518
Test Loss:  0.0006465637707151473
Valid Loss:  0.0011542283464223146
Epoch:  284  	Training Loss: 0.0009429880883544683
Test Loss:  0.0006450517103075981
Valid Loss:  0.0011530680349096656
Epoch:  285  	Training Loss: 0.0009416339453309774
Test Loss:  0.0006436614203266799
Valid Loss:  0.0011519580148160458
Epoch:  286  	Training Loss: 0.0009403171134181321
Test Loss:  0.0006423210725188255
Valid Loss:  0.0011508628958836198
Epoch:  287  	Training Loss: 0.0009390490595251322
Test Loss:  0.0006411280483007431
Valid Loss:  0.0011498031672090292
Epoch:  288  	Training Loss: 0.0009378415998071432
Test Loss:  0.000639971811324358
Valid Loss:  0.00114875053986907
Epoch:  289  	Training Loss: 0.0009366588201373816
Test Loss:  0.0006388777983374894
Valid Loss:  0.0011477201478555799
Epoch:  290  	Training Loss: 0.0009355211514048278
Test Loss:  0.0006379401893354952
Valid Loss:  0.001146762166172266
Epoch:  291  	Training Loss: 0.0009344791760668159
Test Loss:  0.0006367109599523246
Valid Loss:  0.0011457446962594986
Epoch:  292  	Training Loss: 0.0009334780042991042
Test Loss:  0.0006429589120671153
Valid Loss:  0.0011459076777100563
Epoch:  293  	Training Loss: 0.0009321279358118773
Test Loss:  0.0006410900386981666
Valid Loss:  0.0011429612059146166
Epoch:  294  	Training Loss: 0.0009312289766967297
Test Loss:  0.0006407206528820097
Valid Loss:  0.0011410315055400133
Epoch:  295  	Training Loss: 0.0009305448620580137
Test Loss:  0.000639917328953743
Valid Loss:  0.0011393162421882153
Epoch:  296  	Training Loss: 0.0009300328092649579
Test Loss:  0.0006386215100064874
Valid Loss:  0.0011379041243344545
Epoch:  297  	Training Loss: 0.0009296569041907787
Test Loss:  0.0006387543980963528
Valid Loss:  0.0011372024891898036
Epoch:  298  	Training Loss: 0.0009292935719713569
Test Loss:  0.0006387410685420036
Valid Loss:  0.001136472448706627
Epoch:  299  	Training Loss: 0.0009289397276006639
Test Loss:  0.0006384665030054748
Valid Loss:  0.0011357497423887253
Epoch:  300  	Training Loss: 0.0009286488639190793
Test Loss:  0.0006373749929480255
Valid Loss:  0.0011350092245265841
Epoch:  301  	Training Loss: 0.0009284060215577483
Test Loss:  0.000637485645711422
Valid Loss:  0.0011348009575158358
Epoch:  302  	Training Loss: 0.0009281683014705777
Test Loss:  0.0006368473405018449
Valid Loss:  0.0011322700884193182
Epoch:  303  	Training Loss: 0.0009216490434482694
Test Loss:  0.0006291919853538275
Valid Loss:  0.0011265482753515244
Epoch:  304  	Training Loss: 0.0009161712368950248
Test Loss:  0.0006239959038794041
Valid Loss:  0.0011224665213376284
Epoch:  305  	Training Loss: 0.0009114993736147881
Test Loss:  0.0006191676948219538
Valid Loss:  0.0011187081690877676
Epoch:  306  	Training Loss: 0.0009075416019186378
Test Loss:  0.0006148958927951753
Valid Loss:  0.0011153614614158869
Epoch:  307  	Training Loss: 0.0009039855794981122
Test Loss:  0.0006109970854595304
Valid Loss:  0.0011122077703475952
Epoch:  308  	Training Loss: 0.0009008194319903851
Test Loss:  0.000607579480856657
Valid Loss:  0.001109242788515985
Epoch:  309  	Training Loss: 0.0008979531121440232
Test Loss:  0.0006044047186151147
Valid Loss:  0.001106509007513523
Epoch:  310  	Training Loss: 0.0008953631622716784
Test Loss:  0.0006014498067088425
Valid Loss:  0.0011038519442081451
Epoch:  311  	Training Loss: 0.0008929253090173006
Test Loss:  0.0005990300560370088
Valid Loss:  0.001101515139453113
Epoch:  312  	Training Loss: 0.0008906546281650662
Test Loss:  0.000601659994572401
Valid Loss:  0.0010981597006320953
Epoch:  313  	Training Loss: 0.0008878649678081274
Test Loss:  0.0006018884014338255
Valid Loss:  0.001094569219276309
Epoch:  314  	Training Loss: 0.0008859159424901009
Test Loss:  0.0006021126755513251
Valid Loss:  0.0010917417239397764
Epoch:  315  	Training Loss: 0.0008844792027957737
Test Loss:  0.0006014251266606152
Valid Loss:  0.0010893867583945394
Epoch:  316  	Training Loss: 0.0008833692409098148
Test Loss:  0.000601688283495605
Valid Loss:  0.0010877733584493399
Epoch:  317  	Training Loss: 0.0008823462412692606
Test Loss:  0.0006020430009812117
Valid Loss:  0.0010863780044019222
Epoch:  318  	Training Loss: 0.0008814880857244134
Test Loss:  0.0006020512664690614
Valid Loss:  0.001085130963474512
Epoch:  319  	Training Loss: 0.0008807388367131352
Test Loss:  0.0006019884021952748
Valid Loss:  0.0010839365422725677
Epoch:  320  	Training Loss: 0.0008800220675766468
Test Loss:  0.000602282234467566
Valid Loss:  0.0010829113889485598
Epoch:  321  	Training Loss: 0.0008793839951977134
Test Loss:  0.0006025310140103102
Valid Loss:  0.001082065049558878
Epoch:  322  	Training Loss: 0.0008788139093667269
Test Loss:  0.0005914057837799191
Valid Loss:  0.0010737022385001183
Epoch:  323  	Training Loss: 0.0008729273686185479
Test Loss:  0.0005879502277821302
Valid Loss:  0.001069666352123022
Epoch:  324  	Training Loss: 0.0008682042825967073
Test Loss:  0.0005836514174006879
Valid Loss:  0.0010655175428837538
Epoch:  325  	Training Loss: 0.0008639965089969337
Test Loss:  0.0005803530802950263
Valid Loss:  0.0010620130924507976
Epoch:  326  	Training Loss: 0.0008603483438491821
Test Loss:  0.0005770979914814234
Valid Loss:  0.0010585385607555509
Epoch:  327  	Training Loss: 0.0008570351055823267
Test Loss:  0.000573958910536021
Valid Loss:  0.001055229688063264
Epoch:  328  	Training Loss: 0.0008540928829461336
Test Loss:  0.0005714051658287644
Valid Loss:  0.0010522889206185937
Epoch:  329  	Training Loss: 0.0008514036890119314
Test Loss:  0.0005691855913028121
Valid Loss:  0.001049710437655449
Epoch:  330  	Training Loss: 0.0008489609463140368
Test Loss:  0.0005670927930623293
Valid Loss:  0.0010472019203007221
Epoch:  331  	Training Loss: 0.0008466719882562757
Test Loss:  0.0005651823012158275
Valid Loss:  0.001044758129864931
Epoch:  332  	Training Loss: 0.0008444806444458663
Test Loss:  0.0005641384050250053
Valid Loss:  0.0010399504099041224
Epoch:  333  	Training Loss: 0.0008393104653805494
Test Loss:  0.0005598151474259794
Valid Loss:  0.0010343232424929738
Epoch:  334  	Training Loss: 0.0008348239935003221
Test Loss:  0.0005560029530897737
Valid Loss:  0.001029179198667407
Epoch:  335  	Training Loss: 0.0008308145916089416
Test Loss:  0.0005526184686459601
Valid Loss:  0.0010244380682706833
Epoch:  336  	Training Loss: 0.0008271802798844874
Test Loss:  0.0005492819473147392
Valid Loss:  0.0010201900731772184
Epoch:  337  	Training Loss: 0.0008239249000325799
Test Loss:  0.0005462486296892166
Valid Loss:  0.0010163274127990007
Epoch:  338  	Training Loss: 0.0008208501385524869
Test Loss:  0.0005436755600385368
Valid Loss:  0.0010130682494491339
Epoch:  339  	Training Loss: 0.000817934051156044
Test Loss:  0.0005413187900558114
Valid Loss:  0.0010100428480654955
Epoch:  340  	Training Loss: 0.0008151719812303782
Test Loss:  0.0005390766309574246
Valid Loss:  0.0010070635471493006
Epoch:  341  	Training Loss: 0.0008124930318444967
Test Loss:  0.000536983017809689
Valid Loss:  0.0010042001958936453
Epoch:  342  	Training Loss: 0.000809919903986156
Test Loss:  0.000541878049261868
Valid Loss:  0.0010024732910096645
Epoch:  343  	Training Loss: 0.0008063315181061625
Test Loss:  0.0005399358924478292
Valid Loss:  0.0009982730261981487
 69%|██████▉   | 345/500 [04:06<01:35,  1.62it/s] 69%|██████▉   | 347/500 [04:06<01:09,  2.21it/s] 70%|██████▉   | 349/500 [04:06<00:50,  2.96it/s] 70%|███████   | 351/500 [04:13<02:59,  1.20s/it] 71%|███████   | 353/500 [04:13<02:06,  1.16it/s] 71%|███████   | 355/500 [04:13<01:30,  1.60it/s] 71%|███████▏  | 357/500 [04:13<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:13<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:20<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:20<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:20<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:20<01:01,  2.15it/s] 74%|███████▍  | 369/500 [04:20<00:45,  2.87it/s] 74%|███████▍  | 371/500 [04:27<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:27<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:27<01:17,  1.60it/s] 75%|███████▌  | 377/500 [04:27<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:27<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:34<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:34<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:34<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:34<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:34<00:37,  2.97it/s] 78%|███████▊  | 391/500 [04:41<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:41<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:41<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:41<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:41<00:33,  2.97it/s] 80%|████████  | 401/500 [04:47<01:55,  1.17s/it] 81%|████████  | 403/500 [04:48<01:21,  1.19it/s] 81%|████████  | 405/500 [04:48<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:48<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:48<00:30,  3.03it/s] 82%|████████▏ | 411/500 [04:54<01:44,  1.17s/it]Epoch:  344  	Training Loss: 0.0008033427875488997
Test Loss:  0.0005385198164731264
Valid Loss:  0.0009948363294824958
Epoch:  345  	Training Loss: 0.0008007099386304617
Test Loss:  0.0005369348218664527
Valid Loss:  0.000991625478491187
Epoch:  346  	Training Loss: 0.0007984066614881158
Test Loss:  0.0005352346342988312
Valid Loss:  0.000988626736216247
Epoch:  347  	Training Loss: 0.0007963420357555151
Test Loss:  0.0005337879410944879
Valid Loss:  0.000985970487818122
Epoch:  348  	Training Loss: 0.0007944090757519007
Test Loss:  0.000532422331161797
Valid Loss:  0.0009835397358983755
Epoch:  349  	Training Loss: 0.0007925787940621376
Test Loss:  0.0005310128326527774
Valid Loss:  0.0009812337812036276
Epoch:  350  	Training Loss: 0.0007908890256658196
Test Loss:  0.0005294283619150519
Valid Loss:  0.000979181844741106
Epoch:  351  	Training Loss: 0.0007893558358773589
Test Loss:  0.0005284640938043594
Valid Loss:  0.0009773934725672007
Epoch:  352  	Training Loss: 0.0007878643227741122
Test Loss:  0.0005284007638692856
Valid Loss:  0.0009756941581144929
Epoch:  353  	Training Loss: 0.0007867314852774143
Test Loss:  0.0005280625773593783
Valid Loss:  0.0009740188834257424
Epoch:  354  	Training Loss: 0.0007857268792577088
Test Loss:  0.0005279309116303921
Valid Loss:  0.0009725757408887148
Epoch:  355  	Training Loss: 0.000784838106483221
Test Loss:  0.0005274009890854359
Valid Loss:  0.0009711281163617969
Epoch:  356  	Training Loss: 0.000784077390562743
Test Loss:  0.0005270717665553093
Valid Loss:  0.0009698893409222364
Epoch:  357  	Training Loss: 0.0007833852432668209
Test Loss:  0.0005270075635053217
Valid Loss:  0.0009688335121609271
Epoch:  358  	Training Loss: 0.0007827416993677616
Test Loss:  0.0005266938242129982
Valid Loss:  0.0009677699999883771
Epoch:  359  	Training Loss: 0.0007821446051821113
Test Loss:  0.0005263440543785691
Valid Loss:  0.0009667878621257842
Epoch:  360  	Training Loss: 0.0007815954159013927
Test Loss:  0.000526205578353256
Valid Loss:  0.0009659123606979847
Epoch:  361  	Training Loss: 0.0007810851093381643
Test Loss:  0.0005256450967863202
Valid Loss:  0.0009650262072682381
Epoch:  362  	Training Loss: 0.0007806363282725215
Test Loss:  0.000515920459292829
Valid Loss:  0.0009585596853867173
Epoch:  363  	Training Loss: 0.0007763452595099807
Test Loss:  0.0005121706635691226
Valid Loss:  0.0009553309064358473
Epoch:  364  	Training Loss: 0.0007726011099293828
Test Loss:  0.0005087698809802532
Valid Loss:  0.0009523412445560098
Epoch:  365  	Training Loss: 0.0007692000945098698
Test Loss:  0.000505533185787499
Valid Loss:  0.0009494709083810449
Epoch:  366  	Training Loss: 0.0007660405826754868
Test Loss:  0.0005025247810408473
Valid Loss:  0.0009469501674175262
Epoch:  367  	Training Loss: 0.0007631243206560612
Test Loss:  0.0004993340116925538
Valid Loss:  0.0009443335584364831
Epoch:  368  	Training Loss: 0.0007605057908222079
Test Loss:  0.0004958540084771812
Valid Loss:  0.0009409775957465172
Epoch:  369  	Training Loss: 0.000758129870519042
Test Loss:  0.0004949980648234487
Valid Loss:  0.0009400894632562995
Epoch:  370  	Training Loss: 0.0007557658245787024
Test Loss:  0.0004909819690510631
Valid Loss:  0.0009364619618281722
Epoch:  371  	Training Loss: 0.0007536208140663803
Test Loss:  0.0004903695080429316
Valid Loss:  0.0009352746419608593
Epoch:  372  	Training Loss: 0.000751499377656728
Test Loss:  0.0004885053494945168
Valid Loss:  0.0009334403439424932
Epoch:  373  	Training Loss: 0.0007493693847209215
Test Loss:  0.0004884758964180946
Valid Loss:  0.000932855240534991
Epoch:  374  	Training Loss: 0.000747421698179096
Test Loss:  0.000486882432596758
Valid Loss:  0.0009314016788266599
Epoch:  375  	Training Loss: 0.0007456450257450342
Test Loss:  0.0004851668782066554
Valid Loss:  0.0009299066150560975
Epoch:  376  	Training Loss: 0.0007439809269271791
Test Loss:  0.0004834739083889872
Valid Loss:  0.0009284388506785035
Epoch:  377  	Training Loss: 0.0007424060604535043
Test Loss:  0.0004819472669623792
Valid Loss:  0.0009270930895581841
Epoch:  378  	Training Loss: 0.0007409732788801193
Test Loss:  0.00048042350681498647
Valid Loss:  0.0009257575729861856
Epoch:  379  	Training Loss: 0.000739583745598793
Test Loss:  0.0004789549275301397
Valid Loss:  0.0009244599496014416
Epoch:  380  	Training Loss: 0.0007382447365671396
Test Loss:  0.00047759589506313205
Valid Loss:  0.000923238112591207
Epoch:  381  	Training Loss: 0.0007370013045147061
Test Loss:  0.0004763292381539941
Valid Loss:  0.0009220796637237072
Epoch:  382  	Training Loss: 0.0007358297007158399
Test Loss:  0.0004751498345285654
Valid Loss:  0.0009180331835523248
Epoch:  383  	Training Loss: 0.0007318154675886035
Test Loss:  0.00047349510714411736
Valid Loss:  0.0009150895057246089
Epoch:  384  	Training Loss: 0.00072910834569484
Test Loss:  0.0004714631650131196
Valid Loss:  0.0009122751071117818
Epoch:  385  	Training Loss: 0.0007268363842740655
Test Loss:  0.0004697021213360131
Valid Loss:  0.0009097711881622672
Epoch:  386  	Training Loss: 0.0007247756002470851
Test Loss:  0.0004678847035393119
Valid Loss:  0.0009074130211956799
Epoch:  387  	Training Loss: 0.0007228975300677121
Test Loss:  0.0004662395513150841
Valid Loss:  0.0009052784880623221
Epoch:  388  	Training Loss: 0.0007210878538899124
Test Loss:  0.00046461581951007247
Valid Loss:  0.0009032631060108542
Epoch:  389  	Training Loss: 0.0007193639175966382
Test Loss:  0.00046339607797563076
Valid Loss:  0.0009014118695631623
Epoch:  390  	Training Loss: 0.000717696500942111
Test Loss:  0.0004620935069397092
Valid Loss:  0.0008995964308269322
Epoch:  391  	Training Loss: 0.0007160992827266455
Test Loss:  0.0004609184106811881
Valid Loss:  0.0008978517726063728
Epoch:  392  	Training Loss: 0.0007145184790715575
Test Loss:  0.00046316650696098804
Valid Loss:  0.000894873752258718
Epoch:  393  	Training Loss: 0.0007101952796801925
Test Loss:  0.0004582598921842873
Valid Loss:  0.0008882897673174739
Epoch:  394  	Training Loss: 0.0007062189397402108
Test Loss:  0.000457515794551
Valid Loss:  0.0008844073163345456
Epoch:  395  	Training Loss: 0.0007024930091574788
Test Loss:  0.0004547982243821025
Valid Loss:  0.0008795991307124496
Epoch:  396  	Training Loss: 0.0006989269750192761
Test Loss:  0.00045257172314450145
Valid Loss:  0.0008753295405767858
Epoch:  397  	Training Loss: 0.000695540220476687
Test Loss:  0.0004502795054577291
Valid Loss:  0.0008712448761798441
Epoch:  398  	Training Loss: 0.0006922588218003511
Test Loss:  0.0004483830416575074
Valid Loss:  0.0008674722048453987
Epoch:  399  	Training Loss: 0.0006890331860631704
Test Loss:  0.00044644498848356307
Valid Loss:  0.0008637684513814747
Epoch:  400  	Training Loss: 0.0006859359564259648
Test Loss:  0.00044473991147242486
Valid Loss:  0.000860258936882019
Epoch:  401  	Training Loss: 0.0006829501362517476
Test Loss:  0.0004427562525961548
Valid Loss:  0.0008567578624933958
Epoch:  402  	Training Loss: 0.0006800671108067036
Test Loss:  0.0004416131414473057
Valid Loss:  0.0008534549851901829
Epoch:  403  	Training Loss: 0.0006776269292458892
Test Loss:  0.0004396683652885258
Valid Loss:  0.0008500542026013136
Epoch:  404  	Training Loss: 0.0006754592759534717
Test Loss:  0.000438298680819571
Valid Loss:  0.0008471410255879164
Epoch:  405  	Training Loss: 0.0006736001232638955
Test Loss:  0.00043714395724236965
Valid Loss:  0.0008444806444458663
Epoch:  406  	Training Loss: 0.0006718964432366192
Test Loss:  0.00043588835978880525
Valid Loss:  0.000841979868710041
Epoch:  407  	Training Loss: 0.0006703641265630722
Test Loss:  0.0004345323541201651
Valid Loss:  0.0008397627389058471
Epoch:  408  	Training Loss: 0.0006690199952572584
Test Loss:  0.0004338161670602858
Valid Loss:  0.0008379160426557064
Epoch:  409  	Training Loss: 0.0006677488563582301
Test Loss:  0.0004322064050938934
Valid Loss:  0.0008361118379980326
Epoch:  410  	Training Loss: 0.0006666916888207197
Test Loss:  0.0004316202539484948
Valid Loss:  0.0008348008850589395
Epoch:  411  	Training Loss: 0.0006656507612206042
Test Loss:  0.00043098360765725374
Valid Loss:  0.0008334728190675378
 83%|████████▎ | 413/500 [04:54<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:54<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:55<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:55<00:26,  3.02it/s] 84%|████████▍ | 421/500 [05:01<01:32,  1.17s/it] 85%|████████▍ | 423/500 [05:01<01:04,  1.20it/s] 85%|████████▌ | 425/500 [05:01<00:45,  1.66it/s] 85%|████████▌ | 427/500 [05:01<00:32,  2.26it/s] 86%|████████▌ | 429/500 [05:01<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:08<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:08<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:08<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:08<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:08<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:15<01:11,  1.20s/it] 89%|████████▊ | 443/500 [05:15<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:15<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:15<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:15<00:17,  2.95it/s] 90%|█████████ | 451/500 [05:22<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:22<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:22<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:22<00:19,  2.19it/s] 92%|█████████▏| 459/500 [05:22<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:29<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:29<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:29<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:29<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:29<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:36<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:36<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:36<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:36<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:36<00:07,  2.98it/s]Epoch:  412  	Training Loss: 0.0006646423134952784
Test Loss:  0.0004317286075092852
Valid Loss:  0.0008322658250108361
Epoch:  413  	Training Loss: 0.0006627303082495928
Test Loss:  0.0004315274127293378
Valid Loss:  0.0008306497475132346
Epoch:  414  	Training Loss: 0.0006609963020309806
Test Loss:  0.0004301700973883271
Valid Loss:  0.0008288038079626858
Epoch:  415  	Training Loss: 0.0006593969883397222
Test Loss:  0.00042883268906734884
Valid Loss:  0.0008269647369161248
Epoch:  416  	Training Loss: 0.000657809607218951
Test Loss:  0.00042768497951328754
Valid Loss:  0.0008252246771007776
Epoch:  417  	Training Loss: 0.000656257092487067
Test Loss:  0.00042679638136178255
Valid Loss:  0.0008235422428697348
Epoch:  418  	Training Loss: 0.0006547555094584823
Test Loss:  0.0004254415107425302
Valid Loss:  0.0008218091679736972
Epoch:  419  	Training Loss: 0.0006533360574394464
Test Loss:  0.00042429810855537653
Valid Loss:  0.000820159271825105
Epoch:  420  	Training Loss: 0.000651927781291306
Test Loss:  0.00042327120900154114
Valid Loss:  0.0008185672922991216
Epoch:  421  	Training Loss: 0.0006505394703708589
Test Loss:  0.00042249856051057577
Valid Loss:  0.0008170861983671784
Epoch:  422  	Training Loss: 0.0006491889944300056
Test Loss:  0.0004214129876345396
Valid Loss:  0.0008144725579768419
Epoch:  423  	Training Loss: 0.000647270935587585
Test Loss:  0.0004204612341709435
Valid Loss:  0.0008120411075651646
Epoch:  424  	Training Loss: 0.0006454432150349021
Test Loss:  0.0004195862857159227
Valid Loss:  0.0008097327081486583
Epoch:  425  	Training Loss: 0.0006436755647882819
Test Loss:  0.0004188038583379239
Valid Loss:  0.0008075988152995706
Epoch:  426  	Training Loss: 0.0006419793935492635
Test Loss:  0.0004177127266302705
Valid Loss:  0.0008054698118939996
Epoch:  427  	Training Loss: 0.0006403409061022103
Test Loss:  0.0004166698199696839
Valid Loss:  0.0008034505881369114
Epoch:  428  	Training Loss: 0.0006387552712112665
Test Loss:  0.00041588518070057034
Valid Loss:  0.0008016658830456436
Epoch:  429  	Training Loss: 0.0006372265052050352
Test Loss:  0.00041514667100273073
Valid Loss:  0.0007999726221896708
Epoch:  430  	Training Loss: 0.0006357628153637052
Test Loss:  0.00041440146742388606
Valid Loss:  0.0007982897805050015
Epoch:  431  	Training Loss: 0.0006343533168546855
Test Loss:  0.000413635338190943
Valid Loss:  0.0007966018747538328
Epoch:  432  	Training Loss: 0.0006329587195068598
Test Loss:  0.0004142261459492147
Valid Loss:  0.0007960769580677152
Epoch:  433  	Training Loss: 0.0006314785568974912
Test Loss:  0.0004124566912651062
Valid Loss:  0.0007940528448671103
Epoch:  434  	Training Loss: 0.0006300747627392411
Test Loss:  0.00041207027970813215
Valid Loss:  0.000793193350546062
Epoch:  435  	Training Loss: 0.0006287130527198315
Test Loss:  0.00041007212712429464
Valid Loss:  0.00079109868966043
Epoch:  436  	Training Loss: 0.0006275162450037897
Test Loss:  0.00040988385444507003
Valid Loss:  0.000790364108979702
Epoch:  437  	Training Loss: 0.0006263618124648929
Test Loss:  0.0004085399559698999
Valid Loss:  0.0007887723622843623
Epoch:  438  	Training Loss: 0.0006252372986637056
Test Loss:  0.0004077990888617933
Valid Loss:  0.0007874564034864306
Epoch:  439  	Training Loss: 0.0006241567898541689
Test Loss:  0.0004073267919011414
Valid Loss:  0.0007865329971536994
Epoch:  440  	Training Loss: 0.0006231562001630664
Test Loss:  0.0004062099033035338
Valid Loss:  0.0007850051624700427
Epoch:  441  	Training Loss: 0.0006221714429557323
Test Loss:  0.00040558987529948354
Valid Loss:  0.0007837474113330245
Epoch:  442  	Training Loss: 0.0006212143343873322
Test Loss:  0.0004049890849273652
Valid Loss:  0.0007809179369360209
Epoch:  443  	Training Loss: 0.0006182371871545911
Test Loss:  0.0004025131347589195
Valid Loss:  0.0007774499827064574
Epoch:  444  	Training Loss: 0.000615499506238848
Test Loss:  0.000400520337279886
Valid Loss:  0.0007742122979834676
Epoch:  445  	Training Loss: 0.0006128670647740364
Test Loss:  0.0003986919764429331
Valid Loss:  0.0007710467325523496
Epoch:  446  	Training Loss: 0.0006103210034780204
Test Loss:  0.0003960596222896129
Valid Loss:  0.000767851248383522
Epoch:  447  	Training Loss: 0.0006079063168726861
Test Loss:  0.00039428757736459374
Valid Loss:  0.0007650073384866118
Epoch:  448  	Training Loss: 0.0006055617704987526
Test Loss:  0.00039261626079678535
Valid Loss:  0.0007622046396136284
Epoch:  449  	Training Loss: 0.0006032493547536433
Test Loss:  0.00039070917409844697
Valid Loss:  0.0007594255730509758
Epoch:  450  	Training Loss: 0.0006010368233546615
Test Loss:  0.000389297551009804
Valid Loss:  0.0007568852161057293
Epoch:  451  	Training Loss: 0.000598873826675117
Test Loss:  0.0003879149444401264
Valid Loss:  0.000754367676563561
Epoch:  452  	Training Loss: 0.000596740806940943
Test Loss:  0.0003820347774308175
Valid Loss:  0.000749704078771174
Epoch:  453  	Training Loss: 0.0005938647664152086
Test Loss:  0.00038001270149834454
Valid Loss:  0.000746927922591567
Epoch:  454  	Training Loss: 0.000591362826526165
Test Loss:  0.0003780815750360489
Valid Loss:  0.0007442894857376814
Epoch:  455  	Training Loss: 0.0005890422035008669
Test Loss:  0.00037642742972820997
Valid Loss:  0.000741889700293541
Epoch:  456  	Training Loss: 0.0005868494044989347
Test Loss:  0.0003748851304408163
Valid Loss:  0.0007396972505375743
Epoch:  457  	Training Loss: 0.0005848030559718609
Test Loss:  0.00037340924609452486
Valid Loss:  0.0007375889690592885
Epoch:  458  	Training Loss: 0.0005828546127304435
Test Loss:  0.00037202733801677823
Valid Loss:  0.0007355652051046491
Epoch:  459  	Training Loss: 0.0005810117581859231
Test Loss:  0.0003705515409819782
Valid Loss:  0.0007335261907428503
Epoch:  460  	Training Loss: 0.000579244748223573
Test Loss:  0.0003691499587148428
Valid Loss:  0.000731556152459234
Epoch:  461  	Training Loss: 0.0005775540485046804
Test Loss:  0.00036789666046388447
Valid Loss:  0.0007296880939975381
Epoch:  462  	Training Loss: 0.0005759269697591662
Test Loss:  0.0003727662260644138
Valid Loss:  0.0007254289812408388
Epoch:  463  	Training Loss: 0.0005696688313037157
Test Loss:  0.00037456059362739325
Valid Loss:  0.000722007651347667
Epoch:  464  	Training Loss: 0.0005658705485984683
Test Loss:  0.0003738664963748306
Valid Loss:  0.0007190823089331388
Epoch:  465  	Training Loss: 0.0005630783853121102
Test Loss:  0.0003725862770806998
Valid Loss:  0.0007161989342421293
Epoch:  466  	Training Loss: 0.0005604830221273005
Test Loss:  0.00037073303246870637
Valid Loss:  0.0007133339531719685
Epoch:  467  	Training Loss: 0.0005580151919275522
Test Loss:  0.0003686739946715534
Valid Loss:  0.0007104894611984491
Epoch:  468  	Training Loss: 0.0005556393880397081
Test Loss:  0.0003665983967948705
Valid Loss:  0.0007077049231156707
Epoch:  469  	Training Loss: 0.0005533124785870314
Test Loss:  0.00036445946898311377
Valid Loss:  0.00070495146792382
Epoch:  470  	Training Loss: 0.0005510647315531969
Test Loss:  0.0003624610253609717
Valid Loss:  0.0007022740901447833
Epoch:  471  	Training Loss: 0.0005488400347530842
Test Loss:  0.000360520847607404
Valid Loss:  0.0006996545707806945
Epoch:  472  	Training Loss: 0.0005466534057632089
Test Loss:  0.00034749857150018215
Valid Loss:  0.0006917302380315959
Epoch:  473  	Training Loss: 0.0005444285343401134
Test Loss:  0.0003479149308986962
Valid Loss:  0.0006901181186549366
Epoch:  474  	Training Loss: 0.0005427047144621611
Test Loss:  0.00034641200909391046
Valid Loss:  0.0006877669948153198
Epoch:  475  	Training Loss: 0.0005410859594121575
Test Loss:  0.0003456463455222547
Valid Loss:  0.0006857704138383269
Epoch:  476  	Training Loss: 0.0005395416519604623
Test Loss:  0.00034454790875315666
Valid Loss:  0.0006837816908955574
Epoch:  477  	Training Loss: 0.0005381606752052903
Test Loss:  0.0003436543920543045
Valid Loss:  0.0006819557165727019
Epoch:  478  	Training Loss: 0.0005368612473830581
Test Loss:  0.00034291771589778364
Valid Loss:  0.0006802006391808391
Epoch:  479  	Training Loss: 0.0005356057081371546
Test Loss:  0.0003420533030293882
Valid Loss:  0.0006784624420106411
 96%|█████████▌| 481/500 [05:42<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:43<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:43<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:43<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:43<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:49<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:49<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:50<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:50<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:50<00:00,  2.98it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
Epoch:  480  	Training Loss: 0.0005344413802959025
Test Loss:  0.0003412279183976352
Valid Loss:  0.0006768084713257849
Epoch:  481  	Training Loss: 0.0005333464941941202
Test Loss:  0.0003405901079531759
Valid Loss:  0.0006752278422936797
Epoch:  482  	Training Loss: 0.0005322813522070646
Test Loss:  0.00033521009027026594
Valid Loss:  0.0006712020840495825
Epoch:  483  	Training Loss: 0.0005308251129463315
Test Loss:  0.00033439428079873323
Valid Loss:  0.0006692560855299234
Epoch:  484  	Training Loss: 0.0005295504815876484
Test Loss:  0.00033368373988196254
Valid Loss:  0.0006674414034932852
Epoch:  485  	Training Loss: 0.0005283185746520758
Test Loss:  0.00033293323940597475
Valid Loss:  0.0006657213089056313
Epoch:  486  	Training Loss: 0.0005271231639198959
Test Loss:  0.00033221679041162133
Valid Loss:  0.0006640715873800218
Epoch:  487  	Training Loss: 0.0005259565077722073
Test Loss:  0.00033155997516587377
Valid Loss:  0.0006625401438213885
Epoch:  488  	Training Loss: 0.0005248398520052433
Test Loss:  0.00033079151762649417
Valid Loss:  0.0006610330892726779
Epoch:  489  	Training Loss: 0.0005237511359155178
Test Loss:  0.00033018685644492507
Valid Loss:  0.0006596140447072685
Epoch:  490  	Training Loss: 0.0005226716748438776
Test Loss:  0.00032964147976599634
Valid Loss:  0.0006582144997082651
Epoch:  491  	Training Loss: 0.0005216136341914535
Test Loss:  0.00032890355214476585
Valid Loss:  0.0006568136159330606
Epoch:  492  	Training Loss: 0.0005205942434258759
Test Loss:  0.0003266147105023265
Valid Loss:  0.0006544186035171151
Epoch:  493  	Training Loss: 0.0005180832231417298
Test Loss:  0.00032473294413648546
Valid Loss:  0.0006521029863506556
Epoch:  494  	Training Loss: 0.0005157084669917822
Test Loss:  0.00032281927997246385
Valid Loss:  0.0006497196736745536
Epoch:  495  	Training Loss: 0.000513400649651885
Test Loss:  0.0003209940332453698
Valid Loss:  0.0006473439862020314
Epoch:  496  	Training Loss: 0.0005111430073156953
Test Loss:  0.00031924102222546935
Valid Loss:  0.0006449798820540309
Epoch:  497  	Training Loss: 0.0005089381011202931
Test Loss:  0.00031753219082020223
Valid Loss:  0.0006426091422326863
Epoch:  498  	Training Loss: 0.0005067652673460543
Test Loss:  0.0003158634062856436
Valid Loss:  0.0006402344442903996
Epoch:  499  	Training Loss: 0.0005046199657954276
Test Loss:  0.0003142306813970208
Valid Loss:  0.0006378565449267626
Epoch:  500  	Training Loss: 0.0005024979473091662
Test Loss:  0.0003126292140223086
Valid Loss:  0.0006354789948090911
seed is  7
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 15.07it/s]  1%|          | 4/500 [00:00<00:31, 15.52it/s]  1%|          | 6/500 [00:00<00:35, 13.90it/s]  2%|▏         | 8/500 [00:00<00:37, 13.08it/s]  2%|▏         | 10/500 [00:00<00:38, 12.80it/s]  2%|▏         | 12/500 [00:00<00:36, 13.41it/s]  3%|▎         | 14/500 [00:01<00:34, 14.28it/s]  3%|▎         | 16/500 [00:01<00:32, 14.79it/s]  4%|▎         | 18/500 [00:01<00:31, 15.23it/s]  4%|▍         | 20/500 [00:01<00:30, 15.56it/s]  4%|▍         | 22/500 [00:01<00:30, 15.71it/s]  5%|▍         | 24/500 [00:01<00:32, 14.60it/s]  5%|▌         | 26/500 [00:01<00:34, 13.85it/s]  6%|▌         | 28/500 [00:01<00:35, 13.37it/s]  6%|▌         | 30/500 [00:02<00:36, 12.97it/s]  6%|▋         | 32/500 [00:02<00:36, 12.77it/s]  7%|▋         | 34/500 [00:02<00:36, 12.65it/s]  7%|▋         | 36/500 [00:02<00:36, 12.57it/s]  8%|▊         | 38/500 [00:02<00:35, 13.06it/s]  8%|▊         | 40/500 [00:02<00:33, 13.55it/s]  8%|▊         | 42/500 [00:03<00:32, 14.09it/s]  9%|▉         | 44/500 [00:03<00:31, 14.71it/s]  9%|▉         | 46/500 [00:03<00:29, 15.18it/s] 10%|▉         | 48/500 [00:03<00:29, 15.55it/s] 10%|█         | 50/500 [00:03<00:29, 15.50it/s] 10%|█         | 52/500 [00:03<00:28, 15.57it/s] 11%|█         | 54/500 [00:03<00:28, 15.49it/s] 11%|█         | 56/500 [00:03<00:28, 15.55it/s] 12%|█▏        | 58/500 [00:04<00:30, 14.48it/s] 12%|█▏        | 60/500 [00:04<00:29, 14.87it/s] 12%|█▏        | 62/500 [00:04<00:28, 15.25it/s] 13%|█▎        | 64/500 [00:04<00:28, 15.55it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.55it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.82it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.92it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.99it/s] 15%|█▍        | 74/500 [00:05<00:26, 16.06it/s] 15%|█▌        | 76/500 [00:05<00:26, 16.16it/s] 16%|█▌        | 78/500 [00:05<00:26, 16.13it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.22it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.31it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.35it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.39it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.41it/s] 18%|█▊        | 90/500 [00:06<00:24, 16.47it/s] 18%|█▊        | 92/500 [00:06<00:24, 16.43it/s] 19%|█▉        | 94/500 [00:06<00:24, 16.32it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.35it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.33it/s] 20%|██        | 100/500 [00:06<00:24, 16.42it/s] 20%|██        | 102/500 [00:06<00:24, 16.38it/s] 21%|██        | 104/500 [00:06<00:24, 16.41it/s] 21%|██        | 106/500 [00:07<00:23, 16.43it/s] 22%|██▏       | 108/500 [00:07<00:24, 16.30it/s] 22%|██▏       | 110/500 [00:07<00:23, 16.31it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.18it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.25it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.31it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.31it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.31it/s] 24%|██▍       | 122/500 [00:08<00:23, 16.15it/s] 25%|██▍       | 124/500 [00:08<00:23, 16.20it/s]Epoch:  1  	Training Loss: 0.2545188069343567
Test Loss:  5851.01806640625
Valid Loss:  5859.0517578125
Epoch:  2  	Training Loss: 5854.4423828125
Test Loss:  2.2686206236033024e+17
Valid Loss:  2.2525067653021696e+17
Epoch:  3  	Training Loss: 2.236760899798958e+17
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 16.22it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.29it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.39it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.34it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.34it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.39it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.39it/s] 28%|██▊       | 140/500 [00:09<00:21, 16.46it/s] 28%|██▊       | 142/500 [00:09<00:21, 16.43it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.41it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.39it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.39it/s] 30%|███       | 150/500 [00:09<00:21, 16.30it/s] 30%|███       | 152/500 [00:09<00:21, 16.15it/s] 31%|███       | 154/500 [00:09<00:21, 15.83it/s] 31%|███       | 156/500 [00:10<00:22, 15.63it/s] 32%|███▏      | 158/500 [00:10<00:21, 15.59it/s] 32%|███▏      | 160/500 [00:10<00:22, 15.36it/s] 32%|███▏      | 162/500 [00:10<00:22, 15.27it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.46it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.75it/s] 34%|███▎      | 168/500 [00:10<00:21, 15.16it/s] 34%|███▍      | 170/500 [00:11<00:21, 15.34it/s] 34%|███▍      | 172/500 [00:11<00:20, 15.62it/s] 35%|███▍      | 174/500 [00:11<00:20, 15.65it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.87it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.95it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.04it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.11it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.18it/s] 37%|███▋      | 186/500 [00:12<00:19, 16.01it/s] 38%|███▊      | 188/500 [00:12<00:19, 16.04it/s] 38%|███▊      | 190/500 [00:12<00:19, 16.15it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.20it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.81it/s] 39%|███▉      | 196/500 [00:12<00:20, 14.57it/s] 40%|███▉      | 198/500 [00:12<00:20, 14.51it/s] 40%|████      | 200/500 [00:12<00:20, 14.93it/s] 40%|████      | 202/500 [00:13<00:19, 15.38it/s] 41%|████      | 204/500 [00:13<00:18, 15.63it/s] 41%|████      | 206/500 [00:13<00:18, 15.78it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.86it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.93it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.98it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.08it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.17it/s] 44%|████▎     | 218/500 [00:14<00:18, 15.14it/s] 44%|████▍     | 220/500 [00:14<00:19, 14.16it/s] 44%|████▍     | 222/500 [00:14<00:20, 13.57it/s] 45%|████▍     | 224/500 [00:14<00:20, 13.79it/s] 45%|████▌     | 226/500 [00:14<00:18, 14.49it/s] 46%|████▌     | 228/500 [00:14<00:18, 14.89it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.28it/s] 46%|████▋     | 232/500 [00:15<00:17, 15.59it/s] 47%|████▋     | 234/500 [00:15<00:16, 15.82it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.99it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.11it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.16it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.22it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.28it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.36it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.37it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.31it/s] 50%|█████     | 252/500 [00:16<00:15, 16.40it/s] 51%|█████     | 254/500 [00:16<00:14, 16.40it/s] 51%|█████     | 256/500 [00:16<00:14, 16.46it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.45it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.44it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.24it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.24it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.34it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.38it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.33it/s] 54%|█████▍    | 272/500 [00:17<00:13, 16.43it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.44it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.45it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.39it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.40it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.75it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.74it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.92it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.98it/s] 58%|█████▊    | 290/500 [00:18<00:13, 16.02it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.14it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.82it/s] 59%|█████▉    | 296/500 [00:18<00:13, 15.66it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.74it/s] 60%|██████    | 300/500 [00:19<00:12, 15.95it/s] 60%|██████    | 302/500 [00:19<00:12, 16.15it/s] 61%|██████    | 304/500 [00:19<00:12, 16.23it/s] 61%|██████    | 306/500 [00:19<00:11, 16.30it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.28it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.33it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.22it/s] 63%|██████▎   | 314/500 [00:20<00:11, 16.36it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.41it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.38it/s] 64%|██████▍   | 320/500 [00:20<00:10, 16.40it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.36it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.40it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.08it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.06it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.15it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.23it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.01it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.09it/s] 68%|██████▊   | 338/500 [00:21<00:10, 16.05it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.13it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.20it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.04it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.12it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.19it/s] 70%|███████   | 350/500 [00:22<00:09, 16.23it/s] 70%|███████   | 352/500 [00:22<00:09, 16.01it/s] 71%|███████   | 354/500 [00:22<00:09, 16.08it/s] 71%|███████   | 356/500 [00:22<00:08, 16.16it/s] 72%|███████▏  | 358/500 [00:22<00:08, 15.94it/s] 72%|███████▏  | 360/500 [00:22<00:09, 14.33it/s] 72%|███████▏  | 362/500 [00:23<00:10, 13.68it/s] 73%|███████▎  | 364/500 [00:23<00:10, 13.24it/s] 73%|███████▎  | 366/500 [00:23<00:10, 12.92it/s] 74%|███████▎  | 368/500 [00:23<00:10, 12.74it/s] 74%|███████▍  | 370/500 [00:23<00:10, 12.63it/s] 74%|███████▍  | 372/500 [00:23<00:10, 12.53it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:10, 12.44it/s] 75%|███████▌  | 376/500 [00:24<00:10, 12.36it/s] 76%|███████▌  | 378/500 [00:24<00:09, 12.31it/s] 76%|███████▌  | 380/500 [00:24<00:09, 12.18it/s] 76%|███████▋  | 382/500 [00:24<00:09, 12.67it/s] 77%|███████▋  | 384/500 [00:24<00:08, 13.42it/s] 77%|███████▋  | 386/500 [00:25<00:08, 14.17it/s] 78%|███████▊  | 388/500 [00:25<00:07, 14.68it/s] 78%|███████▊  | 390/500 [00:25<00:07, 15.14it/s] 78%|███████▊  | 392/500 [00:25<00:07, 15.40it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.62it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.77it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.00it/s] 80%|████████  | 400/500 [00:25<00:06, 15.95it/s] 80%|████████  | 402/500 [00:26<00:06, 16.08it/s] 81%|████████  | 404/500 [00:26<00:05, 16.21it/s] 81%|████████  | 406/500 [00:26<00:05, 16.28it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.34it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.27it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.05it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.90it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.07it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.22it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.77it/s] 84%|████████▍ | 422/500 [00:27<00:04, 15.93it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.12it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.22it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.27it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.35it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.35it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.32it/s] 87%|████████▋ | 436/500 [00:28<00:03, 16.38it/s] 88%|████████▊ | 438/500 [00:28<00:03, 16.40it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.39it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.40it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.42it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.37it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.32it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.29it/s] 90%|█████████ | 452/500 [00:29<00:02, 16.28it/s] 91%|█████████ | 454/500 [00:29<00:02, 16.17it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.21it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.05it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.98it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.05it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.94it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.04it/s] 94%|█████████▎| 468/500 [00:30<00:01, 16.13it/s] 94%|█████████▍| 470/500 [00:30<00:01, 16.13it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.15it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.19it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.21it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.25it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.32it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.10it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.10it/s] 97%|█████████▋| 486/500 [00:31<00:00, 15.89it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.91it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.05it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.19it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.22it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.15it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.14it/s]100%|██████████| 500/500 [00:32<00:00, 15.95it/s]100%|██████████| 500/500 [00:32<00:00, 15.59it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  7
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:57,  6.25s/it]  1%|          | 3/500 [00:06<13:53,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<11:04,  1.36s/it]  3%|▎         | 13/500 [00:13<07:32,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:44,  2.93it/s]  4%|▍         | 21/500 [00:20<09:30,  1.19s/it]  5%|▍         | 23/500 [00:20<06:45,  1.18it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:26<09:19,  1.19s/it]  7%|▋         | 33/500 [00:27<06:41,  1.16it/s]  7%|▋         | 35/500 [00:27<04:52,  1.59it/s]  7%|▋         | 37/500 [00:27<03:35,  2.15it/s]  8%|▊         | 39/500 [00:27<02:41,  2.85it/s]  8%|▊         | 41/500 [00:33<08:59,  1.18s/it]  9%|▊         | 43/500 [00:33<06:26,  1.18it/s]  9%|▉         | 45/500 [00:34<04:38,  1.64it/s]  9%|▉         | 47/500 [00:34<03:22,  2.23it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:40<08:43,  1.17s/it] 11%|█         | 53/500 [00:40<06:13,  1.20it/s] 11%|█         | 55/500 [00:40<04:28,  1.66it/s] 11%|█▏        | 57/500 [00:40<03:15,  2.26it/s] 12%|█▏        | 59/500 [00:41<02:24,  3.04it/s] 12%|█▏        | 61/500 [00:47<08:33,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.97it/s] 14%|█▍        | 71/500 [00:54<08:19,  1.16s/it] 15%|█▍        | 73/500 [00:54<05:56,  1.20it/s]Epoch:  1  	Training Loss: 0.2545188069343567
Test Loss:  7.861483573913574
Valid Loss:  7.774306774139404
Epoch:  2  	Training Loss: 7.722202777862549
Test Loss:  0.2774210572242737
Valid Loss:  0.27710673213005066
Epoch:  3  	Training Loss: 0.26330986618995667
Test Loss:  0.2770637273788452
Valid Loss:  0.2767549157142639
Epoch:  4  	Training Loss: 0.2629721760749817
Test Loss:  0.27670690417289734
Valid Loss:  0.276403546333313
Epoch:  5  	Training Loss: 0.26263493299484253
Test Loss:  0.27635055780410767
Valid Loss:  0.27605265378952026
Epoch:  6  	Training Loss: 0.2622981667518616
Test Loss:  0.2759947180747986
Valid Loss:  0.27570226788520813
Epoch:  7  	Training Loss: 0.2619618773460388
Test Loss:  0.27563929557800293
Valid Loss:  0.2753523588180542
Epoch:  8  	Training Loss: 0.2616260349750519
Test Loss:  0.27532345056533813
Valid Loss:  0.27504634857177734
Epoch:  9  	Training Loss: 0.2613379955291748
Test Loss:  0.27530378103256226
Valid Loss:  0.27502942085266113
Epoch:  10  	Training Loss: 0.26131772994995117
Test Loss:  0.27530354261398315
Valid Loss:  0.2750287652015686
Epoch:  11  	Training Loss: 0.2613169848918915
Test Loss:  0.275303453207016
Valid Loss:  0.2750285863876343
Epoch:  12  	Training Loss: 0.26131677627563477
Test Loss:  0.27530336380004883
Valid Loss:  0.27502843737602234
Epoch:  13  	Training Loss: 0.2613166272640228
Test Loss:  0.27530327439308167
Valid Loss:  0.2750283181667328
Epoch:  14  	Training Loss: 0.2613165080547333
Test Loss:  0.2753031849861145
Valid Loss:  0.2750282287597656
Epoch:  15  	Training Loss: 0.2613164186477661
Test Loss:  0.27530306577682495
Valid Loss:  0.27502813935279846
Epoch:  16  	Training Loss: 0.26131629943847656
Test Loss:  0.2753029763698578
Valid Loss:  0.2750280499458313
Epoch:  17  	Training Loss: 0.2613162398338318
Test Loss:  0.2753028869628906
Valid Loss:  0.27502793073654175
Epoch:  18  	Training Loss: 0.26131612062454224
Test Loss:  0.2753027677536011
Valid Loss:  0.2750278115272522
Epoch:  19  	Training Loss: 0.26131606101989746
Test Loss:  0.2753027081489563
Valid Loss:  0.2750277519226074
Epoch:  20  	Training Loss: 0.2613159418106079
Test Loss:  0.27530258893966675
Valid Loss:  0.27502763271331787
Epoch:  21  	Training Loss: 0.26131585240364075
Test Loss:  0.275302529335022
Valid Loss:  0.2750275135040283
Epoch:  22  	Training Loss: 0.2613157629966736
Test Loss:  0.2753024101257324
Valid Loss:  0.27502745389938354
Epoch:  23  	Training Loss: 0.2613156735897064
Test Loss:  0.27530232071876526
Valid Loss:  0.275027334690094
Epoch:  24  	Training Loss: 0.26131558418273926
Test Loss:  0.2753022313117981
Valid Loss:  0.27502724528312683
Epoch:  25  	Training Loss: 0.2613154649734497
Test Loss:  0.27530211210250854
Valid Loss:  0.27502715587615967
Epoch:  26  	Training Loss: 0.26131540536880493
Test Loss:  0.27530205249786377
Valid Loss:  0.2750270366668701
Epoch:  27  	Training Loss: 0.2613152861595154
Test Loss:  0.2753019332885742
Valid Loss:  0.27502694725990295
Epoch:  28  	Training Loss: 0.26131516695022583
Test Loss:  0.27530187368392944
Valid Loss:  0.2750268578529358
Epoch:  29  	Training Loss: 0.26131510734558105
Test Loss:  0.2753017544746399
Valid Loss:  0.275026798248291
Epoch:  30  	Training Loss: 0.2613150179386139
Test Loss:  0.27530166506767273
Valid Loss:  0.27502667903900146
Epoch:  31  	Training Loss: 0.26131492853164673
Test Loss:  0.27530157566070557
Valid Loss:  0.2750265896320343
Epoch:  32  	Training Loss: 0.2613148093223572
Test Loss:  0.275301456451416
Valid Loss:  0.27502650022506714
Epoch:  33  	Training Loss: 0.26131471991539
Test Loss:  0.27530133724212646
Valid Loss:  0.2750263810157776
Epoch:  34  	Training Loss: 0.26131463050842285
Test Loss:  0.2753012776374817
Valid Loss:  0.27502626180648804
Epoch:  35  	Training Loss: 0.2613145411014557
Test Loss:  0.2753011882305145
Valid Loss:  0.27502620220184326
Epoch:  36  	Training Loss: 0.2613144516944885
Test Loss:  0.275301069021225
Valid Loss:  0.2750260829925537
Epoch:  37  	Training Loss: 0.26131436228752136
Test Loss:  0.2753009796142578
Valid Loss:  0.27502599358558655
Epoch:  38  	Training Loss: 0.2613142430782318
Test Loss:  0.27530092000961304
Valid Loss:  0.2750259041786194
Epoch:  39  	Training Loss: 0.26131415367126465
Test Loss:  0.2753008008003235
Valid Loss:  0.2750258147716522
Epoch:  40  	Training Loss: 0.2613140642642975
Test Loss:  0.2753007113933563
Valid Loss:  0.27502572536468506
Epoch:  41  	Training Loss: 0.2613139748573303
Test Loss:  0.27530062198638916
Valid Loss:  0.2750256061553955
Epoch:  42  	Training Loss: 0.26131388545036316
Test Loss:  0.275300532579422
Valid Loss:  0.27502551674842834
Epoch:  43  	Training Loss: 0.261313796043396
Test Loss:  0.27530044317245483
Valid Loss:  0.2750254273414612
Epoch:  44  	Training Loss: 0.26131370663642883
Test Loss:  0.2753003239631653
Valid Loss:  0.27502530813217163
Epoch:  45  	Training Loss: 0.26131361722946167
Test Loss:  0.2753002643585205
Valid Loss:  0.27502524852752686
Epoch:  46  	Training Loss: 0.2613134980201721
Test Loss:  0.27530014514923096
Valid Loss:  0.2750251293182373
Epoch:  47  	Training Loss: 0.26131343841552734
Test Loss:  0.2753000557422638
Valid Loss:  0.27502503991127014
Epoch:  48  	Training Loss: 0.2613133192062378
Test Loss:  0.27529996633529663
Valid Loss:  0.275024950504303
Epoch:  49  	Training Loss: 0.26131322979927063
Test Loss:  0.27529987692832947
Valid Loss:  0.2750248312950134
Epoch:  50  	Training Loss: 0.26131314039230347
Test Loss:  0.2752997875213623
Valid Loss:  0.27502474188804626
Epoch:  51  	Training Loss: 0.2613130509853363
Test Loss:  0.27529966831207275
Valid Loss:  0.2750246524810791
Epoch:  52  	Training Loss: 0.26131296157836914
Test Loss:  0.2752995789051056
Valid Loss:  0.27502453327178955
Epoch:  53  	Training Loss: 0.261312872171402
Test Loss:  0.2752994894981384
Valid Loss:  0.2750244438648224
Epoch:  54  	Training Loss: 0.2613127827644348
Test Loss:  0.2752993702888489
Valid Loss:  0.2750243544578552
Epoch:  55  	Training Loss: 0.26131266355514526
Test Loss:  0.2752993106842041
Valid Loss:  0.2750242352485657
Epoch:  56  	Training Loss: 0.2613125741481781
Test Loss:  0.27529919147491455
Valid Loss:  0.2750241756439209
Epoch:  57  	Training Loss: 0.26131248474121094
Test Loss:  0.2752991020679474
Valid Loss:  0.27502405643463135
Epoch:  58  	Training Loss: 0.2613123953342438
Test Loss:  0.2752990126609802
Valid Loss:  0.2750239968299866
Epoch:  59  	Training Loss: 0.2613123059272766
Test Loss:  0.2752988934516907
Valid Loss:  0.275023877620697
Epoch:  60  	Training Loss: 0.26131218671798706
Test Loss:  0.2752988338470459
Valid Loss:  0.27502375841140747
Epoch:  61  	Training Loss: 0.2613121271133423
Test Loss:  0.27529874444007874
Valid Loss:  0.2750236690044403
Epoch:  62  	Training Loss: 0.26131200790405273
Test Loss:  0.2752986550331116
Valid Loss:  0.27502357959747314
Epoch:  63  	Training Loss: 0.26131191849708557
Test Loss:  0.275298535823822
Valid Loss:  0.27502351999282837
Epoch:  64  	Training Loss: 0.2613118290901184
Test Loss:  0.27529844641685486
Valid Loss:  0.2750234007835388
Epoch:  65  	Training Loss: 0.26131170988082886
Test Loss:  0.2752983272075653
Valid Loss:  0.27502328157424927
Epoch:  66  	Training Loss: 0.2613116204738617
Test Loss:  0.27529826760292053
Valid Loss:  0.2750232219696045
Epoch:  67  	Training Loss: 0.2613115608692169
Test Loss:  0.27529817819595337
Valid Loss:  0.27502310276031494
Epoch:  68  	Training Loss: 0.26131147146224976
Test Loss:  0.2752980589866638
Valid Loss:  0.2750230133533478
Epoch:  69  	Training Loss: 0.2613113522529602
Test Loss:  0.27529799938201904
Valid Loss:  0.2750229239463806
Epoch:  70  	Training Loss: 0.26131126284599304
Test Loss:  0.2752978801727295
Valid Loss:  0.27502280473709106
Epoch:  71  	Training Loss: 0.2613111734390259
Test Loss:  0.27529776096343994
Valid Loss:  0.2750227451324463
Epoch:  72  	Training Loss: 0.26131105422973633
Test Loss:  0.27529770135879517
Valid Loss:  0.27502262592315674
Epoch:  73  	Training Loss: 0.26131099462509155
Test Loss:  0.2752975821495056
Valid Loss:  0.2750225067138672
Epoch:  74  	Training Loss: 0.261310875415802
Test Loss:  0.27529749274253845
Valid Loss:   15%|█▌        | 75/500 [00:54<04:16,  1.66it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.26it/s] 16%|█▌        | 79/500 [00:54<02:18,  3.04it/s] 16%|█▌        | 81/500 [01:01<08:14,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.63it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<08:07,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:08<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.97it/s] 20%|██        | 101/500 [01:14<07:55,  1.19s/it] 21%|██        | 103/500 [01:15<05:39,  1.17it/s] 21%|██        | 105/500 [01:15<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:15<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:15<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:21<07:52,  1.22s/it] 23%|██▎       | 113/500 [01:22<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:22<04:02,  1.59it/s] 23%|██▎       | 117/500 [01:22<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:22<02:10,  2.92it/s] 24%|██▍       | 121/500 [01:28<07:28,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:29<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:29<02:47,  2.22it/s] 26%|██▌       | 129/500 [01:29<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:35<07:22,  1.20s/it] 27%|██▋       | 133/500 [01:35<05:15,  1.16it/s] 27%|██▋       | 135/500 [01:36<03:47,  1.60it/s] 27%|██▋       | 137/500 [01:36<02:47,  2.16it/s] 28%|██▊       | 139/500 [01:36<02:05,  2.87it/s] 28%|██▊       | 141/500 [01:42<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:38,  1.62it/s] 29%|██▉       | 147/500 [01:43<02:38,  2.22it/s]0.2750224471092224
Epoch:  75  	Training Loss: 0.26131078600883484
Test Loss:  0.2752974033355713
Valid Loss:  0.27502232789993286
Epoch:  76  	Training Loss: 0.2613106966018677
Test Loss:  0.2752973139286041
Valid Loss:  0.2750222384929657
Epoch:  77  	Training Loss: 0.2613105773925781
Test Loss:  0.27529722452163696
Valid Loss:  0.27502214908599854
Epoch:  78  	Training Loss: 0.26131051778793335
Test Loss:  0.2752971053123474
Valid Loss:  0.27502205967903137
Epoch:  79  	Training Loss: 0.2613103985786438
Test Loss:  0.27529704570770264
Valid Loss:  0.2750219702720642
Epoch:  80  	Training Loss: 0.261310338973999
Test Loss:  0.2752969264984131
Valid Loss:  0.27502185106277466
Epoch:  81  	Training Loss: 0.2613102197647095
Test Loss:  0.2752968370914459
Valid Loss:  0.2750217616558075
Epoch:  82  	Training Loss: 0.2613101601600647
Test Loss:  0.27529677748680115
Valid Loss:  0.27502167224884033
Epoch:  83  	Training Loss: 0.26131004095077515
Test Loss:  0.2752966284751892
Valid Loss:  0.2750215530395508
Epoch:  84  	Training Loss: 0.261309951543808
Test Loss:  0.27529656887054443
Valid Loss:  0.2750214636325836
Epoch:  85  	Training Loss: 0.2613098621368408
Test Loss:  0.2752964496612549
Valid Loss:  0.27502137422561646
Epoch:  86  	Training Loss: 0.26130974292755127
Test Loss:  0.2752963900566101
Valid Loss:  0.2750212550163269
Epoch:  87  	Training Loss: 0.2613096535205841
Test Loss:  0.27529627084732056
Valid Loss:  0.27502119541168213
Epoch:  88  	Training Loss: 0.26130959391593933
Test Loss:  0.2752962112426758
Valid Loss:  0.2750210762023926
Epoch:  89  	Training Loss: 0.2613094747066498
Test Loss:  0.27529609203338623
Valid Loss:  0.275020956993103
Epoch:  90  	Training Loss: 0.2613093852996826
Test Loss:  0.2752959728240967
Valid Loss:  0.27502089738845825
Epoch:  91  	Training Loss: 0.26130926609039307
Test Loss:  0.2752959132194519
Valid Loss:  0.2750207781791687
Epoch:  92  	Training Loss: 0.2613092064857483
Test Loss:  0.27529579401016235
Valid Loss:  0.27502068877220154
Epoch:  93  	Training Loss: 0.26130908727645874
Test Loss:  0.2752957344055176
Valid Loss:  0.2750205993652344
Epoch:  94  	Training Loss: 0.26130902767181396
Test Loss:  0.275295615196228
Valid Loss:  0.2750204801559448
Epoch:  95  	Training Loss: 0.2613089084625244
Test Loss:  0.27529552578926086
Valid Loss:  0.27502042055130005
Epoch:  96  	Training Loss: 0.26130884885787964
Test Loss:  0.2752954363822937
Valid Loss:  0.2750203013420105
Epoch:  97  	Training Loss: 0.2613087296485901
Test Loss:  0.27529534697532654
Valid Loss:  0.27502021193504333
Epoch:  98  	Training Loss: 0.2613086402416229
Test Loss:  0.2752952575683594
Valid Loss:  0.27502012252807617
Epoch:  99  	Training Loss: 0.26130855083465576
Test Loss:  0.2752951383590698
Valid Loss:  0.2750200033187866
Epoch:  100  	Training Loss: 0.2613084316253662
Test Loss:  0.27529504895210266
Valid Loss:  0.27501994371414185
Epoch:  101  	Training Loss: 0.26130837202072144
Test Loss:  0.2752949595451355
Valid Loss:  0.2750198245048523
Epoch:  102  	Training Loss: 0.2613082528114319
Test Loss:  0.27529484033584595
Valid Loss:  0.27501973509788513
Epoch:  103  	Training Loss: 0.2613081932067871
Test Loss:  0.27529478073120117
Valid Loss:  0.27501964569091797
Epoch:  104  	Training Loss: 0.26130807399749756
Test Loss:  0.2752946615219116
Valid Loss:  0.2750195264816284
Epoch:  105  	Training Loss: 0.261307954788208
Test Loss:  0.27529457211494446
Valid Loss:  0.27501940727233887
Epoch:  106  	Training Loss: 0.26130789518356323
Test Loss:  0.2752944827079773
Valid Loss:  0.2750193476676941
Epoch:  107  	Training Loss: 0.2613077759742737
Test Loss:  0.27529439330101013
Valid Loss:  0.27501922845840454
Epoch:  108  	Training Loss: 0.2613076865673065
Test Loss:  0.27529430389404297
Valid Loss:  0.2750191390514374
Epoch:  109  	Training Loss: 0.26130759716033936
Test Loss:  0.2752941846847534
Valid Loss:  0.2750190496444702
Epoch:  110  	Training Loss: 0.2613075077533722
Test Loss:  0.27529409527778625
Valid Loss:  0.27501893043518066
Epoch:  111  	Training Loss: 0.26130741834640503
Test Loss:  0.2752940058708191
Valid Loss:  0.2750188708305359
Epoch:  112  	Training Loss: 0.26130732893943787
Test Loss:  0.2752939462661743
Valid Loss:  0.27501875162124634
Epoch:  113  	Training Loss: 0.2613072395324707
Test Loss:  0.27529382705688477
Valid Loss:  0.2750186324119568
Epoch:  114  	Training Loss: 0.26130715012550354
Test Loss:  0.2752937376499176
Valid Loss:  0.275018572807312
Epoch:  115  	Training Loss: 0.2613070011138916
Test Loss:  0.27529364824295044
Valid Loss:  0.27501848340034485
Epoch:  116  	Training Loss: 0.2613069415092468
Test Loss:  0.2752935290336609
Valid Loss:  0.2750183939933777
Epoch:  117  	Training Loss: 0.26130685210227966
Test Loss:  0.27529340982437134
Valid Loss:  0.27501827478408813
Epoch:  118  	Training Loss: 0.2613067626953125
Test Loss:  0.27529335021972656
Valid Loss:  0.27501818537712097
Epoch:  119  	Training Loss: 0.26130664348602295
Test Loss:  0.2752932608127594
Valid Loss:  0.2750180959701538
Epoch:  120  	Training Loss: 0.2613065838813782
Test Loss:  0.27529317140579224
Valid Loss:  0.27501797676086426
Epoch:  121  	Training Loss: 0.2613064646720886
Test Loss:  0.2752930521965027
Valid Loss:  0.2750178873538971
Epoch:  122  	Training Loss: 0.26130637526512146
Test Loss:  0.2752929925918579
Valid Loss:  0.27501779794692993
Epoch:  123  	Training Loss: 0.2613062858581543
Test Loss:  0.27529287338256836
Valid Loss:  0.2750176787376404
Epoch:  124  	Training Loss: 0.26130619645118713
Test Loss:  0.2752927839756012
Valid Loss:  0.2750176191329956
Epoch:  125  	Training Loss: 0.26130610704421997
Test Loss:  0.27529269456863403
Valid Loss:  0.27501749992370605
Epoch:  126  	Training Loss: 0.2613059878349304
Test Loss:  0.27529260516166687
Valid Loss:  0.2750174105167389
Epoch:  127  	Training Loss: 0.26130592823028564
Test Loss:  0.2752925157546997
Valid Loss:  0.27501732110977173
Epoch:  128  	Training Loss: 0.2613058090209961
Test Loss:  0.27529239654541016
Valid Loss:  0.2750172019004822
Epoch:  129  	Training Loss: 0.26130571961402893
Test Loss:  0.275292307138443
Valid Loss:  0.275017112493515
Epoch:  130  	Training Loss: 0.26130563020706177
Test Loss:  0.27529221773147583
Valid Loss:  0.27501702308654785
Epoch:  131  	Training Loss: 0.2613055109977722
Test Loss:  0.27529212832450867
Valid Loss:  0.2750169038772583
Epoch:  132  	Training Loss: 0.26130545139312744
Test Loss:  0.2752920389175415
Valid Loss:  0.27501681447029114
Epoch:  133  	Training Loss: 0.2613053321838379
Test Loss:  0.27529194951057434
Valid Loss:  0.275016725063324
Epoch:  134  	Training Loss: 0.2613052427768707
Test Loss:  0.2752918601036072
Valid Loss:  0.2750166356563568
Epoch:  135  	Training Loss: 0.26130515336990356
Test Loss:  0.2752917408943176
Valid Loss:  0.27501654624938965
Epoch:  136  	Training Loss: 0.2613050639629364
Test Loss:  0.27529168128967285
Valid Loss:  0.2750164568424225
Epoch:  137  	Training Loss: 0.26130497455596924
Test Loss:  0.2752915620803833
Valid Loss:  0.2750163674354553
Epoch:  138  	Training Loss: 0.26130491495132446
Test Loss:  0.27529147267341614
Valid Loss:  0.27501624822616577
Epoch:  139  	Training Loss: 0.2613047957420349
Test Loss:  0.275291383266449
Valid Loss:  0.2750161588191986
Epoch:  140  	Training Loss: 0.26130470633506775
Test Loss:  0.2752912640571594
Valid Loss:  0.27501606941223145
Epoch:  141  	Training Loss: 0.2613046169281006
Test Loss:  0.27529120445251465
Valid Loss:  0.2750159502029419
Epoch:  142  	Training Loss: 0.26130449771881104
Test Loss:  0.2752910852432251
Valid Loss:  0.27501583099365234
Epoch:  143  	Training Loss: 0.26130440831184387
Test Loss:  0.27529099583625793
Valid Loss:  0.27501577138900757
Epoch:  144  	Training Loss: 0.2613043189048767
Test Loss:  0.27529090642929077
Valid Loss:  0.2750156819820404
Epoch:  145  	Training Loss: 0.26130419969558716
Test Loss:  0.2752908170223236
Valid Loss:  0.27501559257507324
Epoch:  146  	Training Loss: 0.2613041400909424
Test Loss:  0.27529069781303406
Valid Loss:  0.2750154733657837
Epoch:  147  	Training Loss: 0.26130402088165283
Test Loss:  0.2752906084060669
Valid Loss:  0.27501535415649414
 30%|██▉       | 149/500 [01:43<01:57,  2.99it/s] 30%|███       | 151/500 [01:49<06:42,  1.15s/it] 31%|███       | 153/500 [01:49<04:47,  1.21it/s] 31%|███       | 155/500 [01:49<03:26,  1.67it/s] 31%|███▏      | 157/500 [01:49<02:30,  2.28it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.01it/s] 32%|███▏      | 161/500 [01:56<06:39,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:47,  1.17it/s] 33%|███▎      | 165/500 [01:56<03:28,  1.61it/s] 33%|███▎      | 167/500 [01:56<02:33,  2.17it/s] 34%|███▍      | 169/500 [01:56<01:55,  2.87it/s] 34%|███▍      | 171/500 [02:03<06:36,  1.21s/it] 35%|███▍      | 173/500 [02:03<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:03<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:03<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:03<01:49,  2.93it/s] 36%|███▌      | 181/500 [02:10<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:10<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:10<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:10<02:24,  2.17it/s] 38%|███▊      | 189/500 [02:10<01:48,  2.88it/s] 38%|███▊      | 191/500 [02:17<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:17<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:17<03:07,  1.62it/s] 39%|███▉      | 197/500 [02:17<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:17<01:40,  2.99it/s] 40%|████      | 201/500 [02:24<05:59,  1.20s/it] 41%|████      | 203/500 [02:24<04:16,  1.16it/s] 41%|████      | 205/500 [02:24<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:24<02:13,  2.19it/s] 42%|████▏     | 209/500 [02:24<01:38,  2.95it/s] 42%|████▏     | 211/500 [02:30<05:45,  1.19s/it] 43%|████▎     | 213/500 [02:31<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:31<02:59,  1.59it/s] 43%|████▎     | 217/500 [02:31<02:12,  2.14it/s] 44%|████▍     | 219/500 [02:31<01:38,  2.84it/s]Epoch:  148  	Training Loss: 0.26130396127700806
Test Loss:  0.27529051899909973
Valid Loss:  0.27501529455184937
Epoch:  149  	Training Loss: 0.2613038420677185
Test Loss:  0.27529042959213257
Valid Loss:  0.2750151753425598
Epoch:  150  	Training Loss: 0.26130375266075134
Test Loss:  0.275290310382843
Valid Loss:  0.27501511573791504
Epoch:  151  	Training Loss: 0.2613036632537842
Test Loss:  0.27529025077819824
Valid Loss:  0.2750149965286255
Epoch:  152  	Training Loss: 0.26130354404449463
Test Loss:  0.2752901315689087
Valid Loss:  0.27501487731933594
Epoch:  153  	Training Loss: 0.26130348443984985
Test Loss:  0.27529004216194153
Valid Loss:  0.2750147879123688
Epoch:  154  	Training Loss: 0.2613033652305603
Test Loss:  0.27528995275497437
Valid Loss:  0.2750146985054016
Epoch:  155  	Training Loss: 0.2613033056259155
Test Loss:  0.2752898335456848
Valid Loss:  0.27501460909843445
Epoch:  156  	Training Loss: 0.261303186416626
Test Loss:  0.27528977394104004
Valid Loss:  0.2750145196914673
Epoch:  157  	Training Loss: 0.2613031268119812
Test Loss:  0.2752896547317505
Valid Loss:  0.27501440048217773
Epoch:  158  	Training Loss: 0.26130300760269165
Test Loss:  0.2752895951271057
Valid Loss:  0.27501434087753296
Epoch:  159  	Training Loss: 0.2613028883934021
Test Loss:  0.27528947591781616
Valid Loss:  0.275014191865921
Epoch:  160  	Training Loss: 0.2613028287887573
Test Loss:  0.275289386510849
Valid Loss:  0.27501413226127625
Epoch:  161  	Training Loss: 0.2613027095794678
Test Loss:  0.27528929710388184
Valid Loss:  0.2750140428543091
Epoch:  162  	Training Loss: 0.261302649974823
Test Loss:  0.2752892076969147
Valid Loss:  0.27501392364501953
Epoch:  163  	Training Loss: 0.26130253076553345
Test Loss:  0.2752891182899475
Valid Loss:  0.27501383423805237
Epoch:  164  	Training Loss: 0.2613024413585663
Test Loss:  0.27528899908065796
Valid Loss:  0.2750137448310852
Epoch:  165  	Training Loss: 0.2613023519515991
Test Loss:  0.2752889096736908
Valid Loss:  0.27501365542411804
Epoch:  166  	Training Loss: 0.26130223274230957
Test Loss:  0.27528882026672363
Valid Loss:  0.2750135362148285
Epoch:  167  	Training Loss: 0.2613021731376648
Test Loss:  0.27528873085975647
Valid Loss:  0.27501344680786133
Epoch:  168  	Training Loss: 0.26130205392837524
Test Loss:  0.2752886414527893
Valid Loss:  0.27501335740089417
Epoch:  169  	Training Loss: 0.26130199432373047
Test Loss:  0.27528852224349976
Valid Loss:  0.275013267993927
Epoch:  170  	Training Loss: 0.2613018751144409
Test Loss:  0.275288462638855
Valid Loss:  0.27501317858695984
Epoch:  171  	Training Loss: 0.26130175590515137
Test Loss:  0.27528834342956543
Valid Loss:  0.2750130891799927
Epoch:  172  	Training Loss: 0.2613016963005066
Test Loss:  0.27528825402259827
Valid Loss:  0.2750129699707031
Epoch:  173  	Training Loss: 0.26130157709121704
Test Loss:  0.2752881646156311
Valid Loss:  0.2750128507614136
Epoch:  174  	Training Loss: 0.2613014876842499
Test Loss:  0.27528804540634155
Valid Loss:  0.2750127911567688
Epoch:  175  	Training Loss: 0.2613013982772827
Test Loss:  0.2752879858016968
Valid Loss:  0.27501267194747925
Epoch:  176  	Training Loss: 0.26130130887031555
Test Loss:  0.2752878665924072
Valid Loss:  0.2750126123428345
Epoch:  177  	Training Loss: 0.2613012194633484
Test Loss:  0.27528780698776245
Valid Loss:  0.2750124931335449
Epoch:  178  	Training Loss: 0.2613011598587036
Test Loss:  0.2752876877784729
Valid Loss:  0.27501237392425537
Epoch:  179  	Training Loss: 0.26130104064941406
Test Loss:  0.27528759837150574
Valid Loss:  0.2750122845172882
Epoch:  180  	Training Loss: 0.2613009512424469
Test Loss:  0.2752875089645386
Valid Loss:  0.27501219511032104
Epoch:  181  	Training Loss: 0.26130086183547974
Test Loss:  0.2752874195575714
Valid Loss:  0.2750121057033539
Epoch:  182  	Training Loss: 0.2613007426261902
Test Loss:  0.27528733015060425
Valid Loss:  0.2750120162963867
Epoch:  183  	Training Loss: 0.2613006830215454
Test Loss:  0.2752872109413147
Valid Loss:  0.27501189708709717
Epoch:  184  	Training Loss: 0.26130056381225586
Test Loss:  0.27528712153434753
Valid Loss:  0.27501180768013
Epoch:  185  	Training Loss: 0.2613004744052887
Test Loss:  0.27528703212738037
Valid Loss:  0.27501171827316284
Epoch:  186  	Training Loss: 0.26130038499832153
Test Loss:  0.2752869427204132
Valid Loss:  0.2750115990638733
Epoch:  187  	Training Loss: 0.261300265789032
Test Loss:  0.27528685331344604
Valid Loss:  0.2750115394592285
Epoch:  188  	Training Loss: 0.2613002061843872
Test Loss:  0.2752867341041565
Valid Loss:  0.27501142024993896
Epoch:  189  	Training Loss: 0.26130008697509766
Test Loss:  0.2752866744995117
Valid Loss:  0.2750113308429718
Epoch:  190  	Training Loss: 0.2612999975681305
Test Loss:  0.27528655529022217
Valid Loss:  0.27501124143600464
Epoch:  191  	Training Loss: 0.26129990816116333
Test Loss:  0.275286465883255
Valid Loss:  0.2750111222267151
Epoch:  192  	Training Loss: 0.26129981875419617
Test Loss:  0.27528637647628784
Valid Loss:  0.2750110626220703
Epoch:  193  	Training Loss: 0.261299729347229
Test Loss:  0.2752862572669983
Valid Loss:  0.27501094341278076
Epoch:  194  	Training Loss: 0.26129963994026184
Test Loss:  0.2752861976623535
Valid Loss:  0.2750108242034912
Epoch:  195  	Training Loss: 0.2612995505332947
Test Loss:  0.27528607845306396
Valid Loss:  0.27501073479652405
Epoch:  196  	Training Loss: 0.2612994313240051
Test Loss:  0.2752860188484192
Valid Loss:  0.2750106453895569
Epoch:  197  	Training Loss: 0.26129934191703796
Test Loss:  0.27528589963912964
Valid Loss:  0.2750105559825897
Epoch:  198  	Training Loss: 0.2612992525100708
Test Loss:  0.2752857804298401
Valid Loss:  0.27501046657562256
Epoch:  199  	Training Loss: 0.26129916310310364
Test Loss:  0.2752857208251953
Valid Loss:  0.275010347366333
Epoch:  200  	Training Loss: 0.2612990736961365
Test Loss:  0.27528560161590576
Valid Loss:  0.27501025795936584
Epoch:  201  	Training Loss: 0.2612989544868469
Test Loss:  0.275285542011261
Valid Loss:  0.2750101685523987
Epoch:  202  	Training Loss: 0.26129889488220215
Test Loss:  0.27528542280197144
Valid Loss:  0.2750100791454315
Epoch:  203  	Training Loss: 0.2612987756729126
Test Loss:  0.2752853035926819
Valid Loss:  0.27500995993614197
Epoch:  204  	Training Loss: 0.2612987160682678
Test Loss:  0.2752852439880371
Valid Loss:  0.2750098705291748
Epoch:  205  	Training Loss: 0.26129859685897827
Test Loss:  0.27528515458106995
Valid Loss:  0.27500978112220764
Epoch:  206  	Training Loss: 0.2612985074520111
Test Loss:  0.2752850651741028
Valid Loss:  0.2750096917152405
Epoch:  207  	Training Loss: 0.26129841804504395
Test Loss:  0.27528494596481323
Valid Loss:  0.2750095725059509
Epoch:  208  	Training Loss: 0.2612983286380768
Test Loss:  0.27528488636016846
Valid Loss:  0.27500951290130615
Epoch:  209  	Training Loss: 0.2612982392311096
Test Loss:  0.2752847671508789
Valid Loss:  0.2750093936920166
Epoch:  210  	Training Loss: 0.26129812002182007
Test Loss:  0.27528467774391174
Valid Loss:  0.27500930428504944
Epoch:  211  	Training Loss: 0.2612980306148529
Test Loss:  0.2752845883369446
Valid Loss:  0.2750092148780823
Epoch:  212  	Training Loss: 0.26129794120788574
Test Loss:  0.27528446912765503
Valid Loss:  0.2750090956687927
Epoch:  213  	Training Loss: 0.2612978518009186
Test Loss:  0.27528437972068787
Valid Loss:  0.27500900626182556
Epoch:  214  	Training Loss: 0.2612977623939514
Test Loss:  0.2752842903137207
Valid Loss:  0.2750089168548584
Epoch:  215  	Training Loss: 0.26129767298698425
Test Loss:  0.27528420090675354
Valid Loss:  0.27500882744789124
Epoch:  216  	Training Loss: 0.2612975835800171
Test Loss:  0.2752841114997864
Valid Loss:  0.2750087082386017
Epoch:  217  	Training Loss: 0.26129746437072754
Test Loss:  0.2752839922904968
Valid Loss:  0.2750086188316345
Epoch:  218  	Training Loss: 0.2612973749637604
Test Loss:  0.27528393268585205
Valid Loss:  0.27500852942466736
Epoch:  219  	Training Loss: 0.2612972855567932
Test Loss:  0.2752838432788849
Valid Loss:  0.2750084400177002
Epoch:  220  	Training Loss: 0.26129716634750366
Test Loss:  0.27528372406959534
Valid Loss:  0.27500832080841064
 44%|████▍     | 221/500 [02:38<05:36,  1.21s/it] 45%|████▍     | 223/500 [02:38<04:01,  1.15it/s] 45%|████▌     | 225/500 [02:38<02:54,  1.57it/s] 45%|████▌     | 227/500 [02:38<02:08,  2.13it/s] 46%|████▌     | 229/500 [02:38<01:34,  2.87it/s] 46%|████▌     | 231/500 [02:44<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:44<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:45<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:45<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:45<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:51<05:01,  1.17s/it] 49%|████▊     | 243/500 [02:51<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:51<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:52<01:52,  2.25it/s] 50%|████▉     | 249/500 [02:52<01:23,  3.02it/s] 50%|█████     | 251/500 [02:58<04:52,  1.17s/it] 51%|█████     | 253/500 [02:58<03:28,  1.19it/s] 51%|█████     | 255/500 [02:58<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:58<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:58<01:20,  3.01it/s] 52%|█████▏    | 261/500 [03:05<04:43,  1.19s/it] 53%|█████▎    | 263/500 [03:05<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:05<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:05<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:05<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:12<04:31,  1.18s/it] 55%|█████▍    | 273/500 [03:12<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:12<02:18,  1.62it/s] 55%|█████▌    | 277/500 [03:12<01:40,  2.21it/s] 56%|█████▌    | 279/500 [03:12<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:19<04:23,  1.20s/it] 57%|█████▋    | 283/500 [03:19<03:07,  1.16it/s] 57%|█████▋    | 285/500 [03:19<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:19<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:19<01:11,  2.93it/s] 58%|█████▊    | 291/500 [03:26<04:12,  1.21s/it] 59%|█████▊    | 293/500 [03:26<02:59,  1.16it/s]Epoch:  221  	Training Loss: 0.2612971067428589
Test Loss:  0.2752836346626282
Valid Loss:  0.27500826120376587
Epoch:  222  	Training Loss: 0.26129698753356934
Test Loss:  0.275283545255661
Valid Loss:  0.2750081419944763
Epoch:  223  	Training Loss: 0.26129692792892456
Test Loss:  0.27528345584869385
Valid Loss:  0.27500802278518677
Epoch:  224  	Training Loss: 0.261296808719635
Test Loss:  0.2752833664417267
Valid Loss:  0.275007963180542
Epoch:  225  	Training Loss: 0.26129674911499023
Test Loss:  0.2752832770347595
Valid Loss:  0.27500784397125244
Epoch:  226  	Training Loss: 0.2612966299057007
Test Loss:  0.27528315782546997
Valid Loss:  0.27500778436660767
Epoch:  227  	Training Loss: 0.2612965404987335
Test Loss:  0.2752830684185028
Valid Loss:  0.2750076651573181
Epoch:  228  	Training Loss: 0.26129645109176636
Test Loss:  0.27528297901153564
Valid Loss:  0.27500754594802856
Epoch:  229  	Training Loss: 0.2612963616847992
Test Loss:  0.27528291940689087
Valid Loss:  0.2750074863433838
Epoch:  230  	Training Loss: 0.26129627227783203
Test Loss:  0.2752828001976013
Valid Loss:  0.27500736713409424
Epoch:  231  	Training Loss: 0.2612961530685425
Test Loss:  0.27528268098831177
Valid Loss:  0.2750072777271271
Epoch:  232  	Training Loss: 0.2612960636615753
Test Loss:  0.275282621383667
Valid Loss:  0.2750071883201599
Epoch:  233  	Training Loss: 0.26129597425460815
Test Loss:  0.27528250217437744
Valid Loss:  0.27500706911087036
Epoch:  234  	Training Loss: 0.261295884847641
Test Loss:  0.27528244256973267
Valid Loss:  0.2750070095062256
Epoch:  235  	Training Loss: 0.26129579544067383
Test Loss:  0.2752823233604431
Valid Loss:  0.27500689029693604
Epoch:  236  	Training Loss: 0.2612956762313843
Test Loss:  0.27528220415115356
Valid Loss:  0.2750067710876465
Epoch:  237  	Training Loss: 0.2612956166267395
Test Loss:  0.2752821445465088
Valid Loss:  0.2750066816806793
Epoch:  238  	Training Loss: 0.26129549741744995
Test Loss:  0.27528202533721924
Valid Loss:  0.27500659227371216
Epoch:  239  	Training Loss: 0.2612954378128052
Test Loss:  0.27528196573257446
Valid Loss:  0.275006502866745
Epoch:  240  	Training Loss: 0.2612953186035156
Test Loss:  0.2752818465232849
Valid Loss:  0.27500641345977783
Epoch:  241  	Training Loss: 0.26129522919654846
Test Loss:  0.27528175711631775
Valid Loss:  0.27500632405281067
Epoch:  242  	Training Loss: 0.2612951397895813
Test Loss:  0.2752816677093506
Valid Loss:  0.2750062048435211
Epoch:  243  	Training Loss: 0.26129505038261414
Test Loss:  0.27528154850006104
Valid Loss:  0.27500611543655396
Epoch:  244  	Training Loss: 0.261294960975647
Test Loss:  0.27528148889541626
Valid Loss:  0.2750060260295868
Epoch:  245  	Training Loss: 0.2612948417663574
Test Loss:  0.2752813696861267
Valid Loss:  0.27500593662261963
Epoch:  246  	Training Loss: 0.26129475235939026
Test Loss:  0.27528128027915955
Valid Loss:  0.2750058174133301
Epoch:  247  	Training Loss: 0.2612946629524231
Test Loss:  0.2752811908721924
Valid Loss:  0.2750057578086853
Epoch:  248  	Training Loss: 0.26129457354545593
Test Loss:  0.2752811014652252
Valid Loss:  0.27500563859939575
Epoch:  249  	Training Loss: 0.26129448413848877
Test Loss:  0.27528101205825806
Valid Loss:  0.2750055193901062
Epoch:  250  	Training Loss: 0.2612943947315216
Test Loss:  0.2752808928489685
Valid Loss:  0.2750054597854614
Epoch:  251  	Training Loss: 0.26129430532455444
Test Loss:  0.27528083324432373
Valid Loss:  0.2750053405761719
Epoch:  252  	Training Loss: 0.2612941861152649
Test Loss:  0.2752807140350342
Valid Loss:  0.2750052511692047
Epoch:  253  	Training Loss: 0.2612941265106201
Test Loss:  0.27528059482574463
Valid Loss:  0.27500516176223755
Epoch:  254  	Training Loss: 0.26129400730133057
Test Loss:  0.27528053522109985
Valid Loss:  0.275005042552948
Epoch:  255  	Training Loss: 0.2612939178943634
Test Loss:  0.2752804458141327
Valid Loss:  0.2750049829483032
Epoch:  256  	Training Loss: 0.26129382848739624
Test Loss:  0.2752803564071655
Valid Loss:  0.27500486373901367
Epoch:  257  	Training Loss: 0.2612937390804291
Test Loss:  0.275280237197876
Valid Loss:  0.2750047445297241
Epoch:  258  	Training Loss: 0.2612936198711395
Test Loss:  0.2752801477909088
Valid Loss:  0.27500468492507935
Epoch:  259  	Training Loss: 0.26129353046417236
Test Loss:  0.27528002858161926
Valid Loss:  0.2750045955181122
Epoch:  260  	Training Loss: 0.2612934410572052
Test Loss:  0.2752799391746521
Valid Loss:  0.275004506111145
Epoch:  261  	Training Loss: 0.26129335165023804
Test Loss:  0.2752798795700073
Valid Loss:  0.27500438690185547
Epoch:  262  	Training Loss: 0.2612932622432709
Test Loss:  0.2752797603607178
Valid Loss:  0.2750042974948883
Epoch:  263  	Training Loss: 0.2612931728363037
Test Loss:  0.275279700756073
Valid Loss:  0.27500420808792114
Epoch:  264  	Training Loss: 0.26129305362701416
Test Loss:  0.27527958154678345
Valid Loss:  0.2750040888786316
Epoch:  265  	Training Loss: 0.2612929940223694
Test Loss:  0.2752794623374939
Valid Loss:  0.27500399947166443
Epoch:  266  	Training Loss: 0.26129287481307983
Test Loss:  0.2752794027328491
Valid Loss:  0.27500391006469727
Epoch:  267  	Training Loss: 0.26129278540611267
Test Loss:  0.27527928352355957
Valid Loss:  0.2750037908554077
Epoch:  268  	Training Loss: 0.2612926959991455
Test Loss:  0.2752792239189148
Valid Loss:  0.27500370144844055
Epoch:  269  	Training Loss: 0.26129257678985596
Test Loss:  0.27527910470962524
Valid Loss:  0.2750036120414734
Epoch:  270  	Training Loss: 0.2612925171852112
Test Loss:  0.2752790153026581
Valid Loss:  0.27500349283218384
Epoch:  271  	Training Loss: 0.261292427778244
Test Loss:  0.2752789258956909
Valid Loss:  0.27500343322753906
Epoch:  272  	Training Loss: 0.26129230856895447
Test Loss:  0.27527883648872375
Valid Loss:  0.2750033140182495
Epoch:  273  	Training Loss: 0.2612922489643097
Test Loss:  0.2752787470817566
Valid Loss:  0.27500322461128235
Epoch:  274  	Training Loss: 0.26129215955734253
Test Loss:  0.27527862787246704
Valid Loss:  0.2750031352043152
Epoch:  275  	Training Loss: 0.261292040348053
Test Loss:  0.2752785384654999
Valid Loss:  0.27500301599502563
Epoch:  276  	Training Loss: 0.2612919211387634
Test Loss:  0.2752784490585327
Valid Loss:  0.27500292658805847
Epoch:  277  	Training Loss: 0.26129186153411865
Test Loss:  0.27527835965156555
Valid Loss:  0.2750028371810913
Epoch:  278  	Training Loss: 0.2612917721271515
Test Loss:  0.2752782702445984
Valid Loss:  0.27500271797180176
Epoch:  279  	Training Loss: 0.2612916827201843
Test Loss:  0.2752781808376312
Valid Loss:  0.275002658367157
Epoch:  280  	Training Loss: 0.2612915635108948
Test Loss:  0.27527809143066406
Valid Loss:  0.27500253915786743
Epoch:  281  	Training Loss: 0.26129150390625
Test Loss:  0.2752779722213745
Valid Loss:  0.27500247955322266
Epoch:  282  	Training Loss: 0.26129138469696045
Test Loss:  0.27527791261672974
Valid Loss:  0.2750023603439331
Epoch:  283  	Training Loss: 0.2612912952899933
Test Loss:  0.2752777934074402
Valid Loss:  0.27500227093696594
Epoch:  284  	Training Loss: 0.2612912058830261
Test Loss:  0.275277704000473
Valid Loss:  0.2750021815299988
Epoch:  285  	Training Loss: 0.2612910866737366
Test Loss:  0.27527761459350586
Valid Loss:  0.27500206232070923
Epoch:  286  	Training Loss: 0.2612910270690918
Test Loss:  0.2752775251865387
Valid Loss:  0.27500197291374207
Epoch:  287  	Training Loss: 0.26129090785980225
Test Loss:  0.27527743577957153
Valid Loss:  0.2750018835067749
Epoch:  288  	Training Loss: 0.26129084825515747
Test Loss:  0.275277316570282
Valid Loss:  0.27500176429748535
Epoch:  289  	Training Loss: 0.2612907290458679
Test Loss:  0.2752772271633148
Valid Loss:  0.2750016748905182
Epoch:  290  	Training Loss: 0.26129063963890076
Test Loss:  0.27527713775634766
Valid Loss:  0.275001585483551
Epoch:  291  	Training Loss: 0.2612905502319336
Test Loss:  0.2752770185470581
Valid Loss:  0.27500152587890625
Epoch:  292  	Training Loss: 0.26129043102264404
Test Loss:  0.27527692914009094
Valid Loss:  0.2750014066696167
Epoch:  293  	Training Loss: 0.2612903416156769
Test Loss:  0.2752768397331238
Valid Loss:  0.27500131726264954
 59%|█████▉    | 295/500 [03:26<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:26<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:26<01:08,  2.94it/s] 60%|██████    | 301/500 [03:32<03:53,  1.17s/it] 61%|██████    | 303/500 [03:33<02:46,  1.18it/s] 61%|██████    | 305/500 [03:33<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:33<01:28,  2.18it/s] 62%|██████▏   | 309/500 [03:33<01:06,  2.88it/s] 62%|██████▏   | 311/500 [03:40<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:40<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:40<01:55,  1.61it/s] 63%|██████▎   | 317/500 [03:40<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:40<01:01,  2.94it/s] 64%|██████▍   | 321/500 [03:46<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:47<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:47<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:47<01:19,  2.17it/s] 66%|██████▌   | 329/500 [03:47<00:58,  2.91it/s] 66%|██████▌   | 331/500 [03:53<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:53<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:54<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:54<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:54<00:53,  2.98it/s] 68%|██████▊   | 341/500 [04:00<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:00<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:00<01:34,  1.65it/s] 69%|██████▉   | 347/500 [04:01<01:08,  2.25it/s] 70%|██████▉   | 349/500 [04:01<00:49,  3.02it/s] 70%|███████   | 351/500 [04:07<02:55,  1.18s/it] 71%|███████   | 353/500 [04:07<02:04,  1.18it/s] 71%|███████   | 355/500 [04:07<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:07<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:07<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:14<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:14<01:54,  1.19it/s] 73%|███████▎  | 365/500 [04:14<01:21,  1.65it/s]Epoch:  294  	Training Loss: 0.2612902522087097
Test Loss:  0.275276780128479
Valid Loss:  0.2750012278556824
Epoch:  295  	Training Loss: 0.26129019260406494
Test Loss:  0.27527666091918945
Valid Loss:  0.2750011086463928
Epoch:  296  	Training Loss: 0.2612900733947754
Test Loss:  0.2752765715122223
Valid Loss:  0.27500101923942566
Epoch:  297  	Training Loss: 0.2612899839878082
Test Loss:  0.2752764821052551
Valid Loss:  0.2750009298324585
Epoch:  298  	Training Loss: 0.26128989458084106
Test Loss:  0.2752763628959656
Valid Loss:  0.27500081062316895
Epoch:  299  	Training Loss: 0.2612897753715515
Test Loss:  0.2752763032913208
Valid Loss:  0.2750007212162018
Epoch:  300  	Training Loss: 0.26128968596458435
Test Loss:  0.27527618408203125
Valid Loss:  0.2750006318092346
Epoch:  301  	Training Loss: 0.2612895965576172
Test Loss:  0.2752760648727417
Valid Loss:  0.27500051259994507
Epoch:  302  	Training Loss: 0.26128950715065
Test Loss:  0.2752760052680969
Valid Loss:  0.2750004231929779
Epoch:  303  	Training Loss: 0.26128941774368286
Test Loss:  0.27527591586112976
Valid Loss:  0.27500033378601074
Epoch:  304  	Training Loss: 0.2612893283367157
Test Loss:  0.2752758264541626
Valid Loss:  0.2750002443790436
Epoch:  305  	Training Loss: 0.26128923892974854
Test Loss:  0.27527570724487305
Valid Loss:  0.27500012516975403
Epoch:  306  	Training Loss: 0.261289119720459
Test Loss:  0.27527564764022827
Valid Loss:  0.27500003576278687
Epoch:  307  	Training Loss: 0.2612890601158142
Test Loss:  0.2752755284309387
Valid Loss:  0.2749999463558197
Epoch:  308  	Training Loss: 0.26128894090652466
Test Loss:  0.27527546882629395
Valid Loss:  0.27499985694885254
Epoch:  309  	Training Loss: 0.2612888514995575
Test Loss:  0.2752753496170044
Valid Loss:  0.2749997675418854
Epoch:  310  	Training Loss: 0.26128876209259033
Test Loss:  0.27527523040771484
Valid Loss:  0.2749996483325958
Epoch:  311  	Training Loss: 0.26128867268562317
Test Loss:  0.27527517080307007
Valid Loss:  0.27499955892562866
Epoch:  312  	Training Loss: 0.261288583278656
Test Loss:  0.2752750515937805
Valid Loss:  0.2749994695186615
Epoch:  313  	Training Loss: 0.26128846406936646
Test Loss:  0.27527496218681335
Valid Loss:  0.27499938011169434
Epoch:  314  	Training Loss: 0.2612884044647217
Test Loss:  0.2752748429775238
Valid Loss:  0.2749992609024048
Epoch:  315  	Training Loss: 0.26128828525543213
Test Loss:  0.27527478337287903
Valid Loss:  0.2749991714954376
Epoch:  316  	Training Loss: 0.26128819584846497
Test Loss:  0.27527469396591187
Valid Loss:  0.27499908208847046
Epoch:  317  	Training Loss: 0.2612881064414978
Test Loss:  0.2752745747566223
Valid Loss:  0.2749989628791809
Epoch:  318  	Training Loss: 0.26128798723220825
Test Loss:  0.27527451515197754
Valid Loss:  0.27499890327453613
Epoch:  319  	Training Loss: 0.2612879276275635
Test Loss:  0.275274395942688
Valid Loss:  0.2749987840652466
Epoch:  320  	Training Loss: 0.2612878084182739
Test Loss:  0.2752743363380432
Valid Loss:  0.2749986946582794
Epoch:  321  	Training Loss: 0.26128774881362915
Test Loss:  0.27527421712875366
Valid Loss:  0.27499860525131226
Epoch:  322  	Training Loss: 0.261287659406662
Test Loss:  0.2752741277217865
Valid Loss:  0.2749984860420227
Epoch:  323  	Training Loss: 0.26128754019737244
Test Loss:  0.27527403831481934
Valid Loss:  0.27499842643737793
Epoch:  324  	Training Loss: 0.2612874507904053
Test Loss:  0.2752739191055298
Valid Loss:  0.2749983072280884
Epoch:  325  	Training Loss: 0.2612873613834381
Test Loss:  0.2752738296985626
Valid Loss:  0.27499818801879883
Epoch:  326  	Training Loss: 0.26128727197647095
Test Loss:  0.27527374029159546
Valid Loss:  0.27499812841415405
Epoch:  327  	Training Loss: 0.2612871527671814
Test Loss:  0.2752736508846283
Valid Loss:  0.2749980092048645
Epoch:  328  	Training Loss: 0.2612870931625366
Test Loss:  0.27527356147766113
Valid Loss:  0.27499791979789734
Epoch:  329  	Training Loss: 0.26128700375556946
Test Loss:  0.2752734422683716
Valid Loss:  0.2749978303909302
Epoch:  330  	Training Loss: 0.2612868845462799
Test Loss:  0.2752733528614044
Valid Loss:  0.274997740983963
Epoch:  331  	Training Loss: 0.26128679513931274
Test Loss:  0.27527326345443726
Valid Loss:  0.27499765157699585
Epoch:  332  	Training Loss: 0.2612867057323456
Test Loss:  0.2752731740474701
Valid Loss:  0.2749975323677063
Epoch:  333  	Training Loss: 0.2612866163253784
Test Loss:  0.2752731144428253
Valid Loss:  0.2749974727630615
Epoch:  334  	Training Loss: 0.26128649711608887
Test Loss:  0.2752729654312134
Valid Loss:  0.274997353553772
Epoch:  335  	Training Loss: 0.2612864375114441
Test Loss:  0.2752729058265686
Valid Loss:  0.2749972343444824
Epoch:  336  	Training Loss: 0.26128631830215454
Test Loss:  0.27527278661727905
Valid Loss:  0.27499717473983765
Epoch:  337  	Training Loss: 0.2612862288951874
Test Loss:  0.2752726972103119
Valid Loss:  0.2749970555305481
Epoch:  338  	Training Loss: 0.2612861394882202
Test Loss:  0.2752726078033447
Valid Loss:  0.27499696612358093
Epoch:  339  	Training Loss: 0.26128605008125305
Test Loss:  0.2752724885940552
Valid Loss:  0.27499687671661377
Epoch:  340  	Training Loss: 0.2612859606742859
Test Loss:  0.2752724289894104
Valid Loss:  0.2749967873096466
Epoch:  341  	Training Loss: 0.26128584146499634
Test Loss:  0.27527230978012085
Valid Loss:  0.27499666810035706
Epoch:  342  	Training Loss: 0.2612857520580292
Test Loss:  0.2752722501754761
Valid Loss:  0.2749965786933899
Epoch:  343  	Training Loss: 0.261285662651062
Test Loss:  0.2752721309661865
Valid Loss:  0.27499645948410034
Epoch:  344  	Training Loss: 0.26128557324409485
Test Loss:  0.27527207136154175
Valid Loss:  0.27499639987945557
Epoch:  345  	Training Loss: 0.2612854838371277
Test Loss:  0.2752719521522522
Valid Loss:  0.274996280670166
Epoch:  346  	Training Loss: 0.26128536462783813
Test Loss:  0.27527186274528503
Valid Loss:  0.27499616146087646
Epoch:  347  	Training Loss: 0.26128530502319336
Test Loss:  0.27527177333831787
Valid Loss:  0.2749961018562317
Epoch:  348  	Training Loss: 0.2612851858139038
Test Loss:  0.2752716541290283
Valid Loss:  0.27499598264694214
Epoch:  349  	Training Loss: 0.26128512620925903
Test Loss:  0.27527159452438354
Valid Loss:  0.27499592304229736
Epoch:  350  	Training Loss: 0.2612850069999695
Test Loss:  0.275271475315094
Valid Loss:  0.2749958038330078
Epoch:  351  	Training Loss: 0.2612849175930023
Test Loss:  0.27527138590812683
Valid Loss:  0.27499571442604065
Epoch:  352  	Training Loss: 0.26128482818603516
Test Loss:  0.27527129650115967
Valid Loss:  0.2749956250190735
Epoch:  353  	Training Loss: 0.261284738779068
Test Loss:  0.2752711772918701
Valid Loss:  0.27499550580978394
Epoch:  354  	Training Loss: 0.26128464937210083
Test Loss:  0.27527111768722534
Valid Loss:  0.2749953866004944
Epoch:  355  	Training Loss: 0.2612845301628113
Test Loss:  0.2752709984779358
Valid Loss:  0.2749953269958496
Epoch:  356  	Training Loss: 0.2612844407558441
Test Loss:  0.27527090907096863
Valid Loss:  0.27499520778656006
Epoch:  357  	Training Loss: 0.26128438115119934
Test Loss:  0.27527081966400146
Valid Loss:  0.2749951481819153
Epoch:  358  	Training Loss: 0.2612842619419098
Test Loss:  0.2752707302570343
Valid Loss:  0.27499502897262573
Epoch:  359  	Training Loss: 0.2612841725349426
Test Loss:  0.27527064085006714
Valid Loss:  0.2749949097633362
Epoch:  360  	Training Loss: 0.2612840533256531
Test Loss:  0.2752705216407776
Valid Loss:  0.2749948501586914
Epoch:  361  	Training Loss: 0.2612839937210083
Test Loss:  0.2752704620361328
Valid Loss:  0.27499473094940186
Epoch:  362  	Training Loss: 0.26128387451171875
Test Loss:  0.27527034282684326
Valid Loss:  0.2749946415424347
Epoch:  363  	Training Loss: 0.2612837851047516
Test Loss:  0.2752702534198761
Valid Loss:  0.27499455213546753
Epoch:  364  	Training Loss: 0.2612836956977844
Test Loss:  0.27527016401290894
Valid Loss:  0.274994432926178
Epoch:  365  	Training Loss: 0.26128360629081726
Test Loss:  0.2752700448036194
Valid Loss:  0.2749943435192108
Epoch:  366  	Training Loss: 0.2612835168838501
Test Loss:  0.2752699851989746
Valid Loss:  0.27499425411224365
 73%|███████▎  | 367/500 [04:14<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:14<00:43,  3.03it/s] 74%|███████▍  | 371/500 [04:20<02:29,  1.16s/it] 75%|███████▍  | 373/500 [04:21<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:21<01:15,  1.64it/s] 75%|███████▌  | 377/500 [04:21<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:21<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:28<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:28<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:28<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:28<00:51,  2.18it/s] 78%|███████▊  | 389/500 [04:28<00:38,  2.88it/s] 78%|███████▊  | 391/500 [04:35<02:11,  1.20s/it] 79%|███████▊  | 393/500 [04:35<01:32,  1.15it/s] 79%|███████▉  | 395/500 [04:35<01:06,  1.58it/s] 79%|███████▉  | 397/500 [04:35<00:48,  2.13it/s] 80%|███████▉  | 399/500 [04:35<00:35,  2.83it/s] 80%|████████  | 401/500 [04:42<02:00,  1.22s/it] 81%|████████  | 403/500 [04:42<01:25,  1.14it/s] 81%|████████  | 405/500 [04:42<01:00,  1.56it/s] 81%|████████▏ | 407/500 [04:42<00:44,  2.11it/s] 82%|████████▏ | 409/500 [04:42<00:32,  2.79it/s] 82%|████████▏ | 411/500 [04:49<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:49<01:15,  1.15it/s] 83%|████████▎ | 415/500 [04:49<00:53,  1.59it/s] 83%|████████▎ | 417/500 [04:49<00:38,  2.18it/s] 84%|████████▍ | 419/500 [04:49<00:27,  2.93it/s] 84%|████████▍ | 421/500 [04:55<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:56<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:56<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:56<00:33,  2.18it/s] 86%|████████▌ | 429/500 [04:56<00:24,  2.88it/s] 86%|████████▌ | 431/500 [05:02<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:03<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:03<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:03<00:28,  2.19it/s]Epoch:  367  	Training Loss: 0.26128339767456055
Test Loss:  0.27526986598968506
Valid Loss:  0.2749941647052765
Epoch:  368  	Training Loss: 0.26128333806991577
Test Loss:  0.2752697765827179
Valid Loss:  0.2749940752983093
Epoch:  369  	Training Loss: 0.2612832188606262
Test Loss:  0.27526968717575073
Valid Loss:  0.27499398589134216
Epoch:  370  	Training Loss: 0.26128315925598145
Test Loss:  0.27526962757110596
Valid Loss:  0.274993896484375
Epoch:  371  	Training Loss: 0.2612830400466919
Test Loss:  0.2752695083618164
Valid Loss:  0.27499377727508545
Epoch:  372  	Training Loss: 0.26128295063972473
Test Loss:  0.27526938915252686
Valid Loss:  0.2749937176704407
Epoch:  373  	Training Loss: 0.26128286123275757
Test Loss:  0.2752692997455597
Valid Loss:  0.2749935984611511
Epoch:  374  	Training Loss: 0.2612827718257904
Test Loss:  0.27526921033859253
Valid Loss:  0.2749934792518616
Epoch:  375  	Training Loss: 0.26128265261650085
Test Loss:  0.27526912093162537
Valid Loss:  0.2749934196472168
Epoch:  376  	Training Loss: 0.2612825632095337
Test Loss:  0.2752690315246582
Valid Loss:  0.27499330043792725
Epoch:  377  	Training Loss: 0.26128247380256653
Test Loss:  0.27526894211769104
Valid Loss:  0.2749931812286377
Epoch:  378  	Training Loss: 0.26128238439559937
Test Loss:  0.2752688527107239
Valid Loss:  0.27499309182167053
Epoch:  379  	Training Loss: 0.2612822949886322
Test Loss:  0.2752687335014343
Valid Loss:  0.27499300241470337
Epoch:  380  	Training Loss: 0.26128220558166504
Test Loss:  0.27526864409446716
Valid Loss:  0.2749929130077362
Epoch:  381  	Training Loss: 0.2612820863723755
Test Loss:  0.2752685546875
Valid Loss:  0.27499282360076904
Epoch:  382  	Training Loss: 0.2612820267677307
Test Loss:  0.27526846528053284
Valid Loss:  0.2749927341938019
Epoch:  383  	Training Loss: 0.26128190755844116
Test Loss:  0.2752683758735657
Valid Loss:  0.2749926447868347
Epoch:  384  	Training Loss: 0.2612818479537964
Test Loss:  0.2752682864665985
Valid Loss:  0.27499252557754517
Epoch:  385  	Training Loss: 0.26128172874450684
Test Loss:  0.27526819705963135
Valid Loss:  0.274992436170578
Epoch:  386  	Training Loss: 0.2612816095352173
Test Loss:  0.2752680778503418
Valid Loss:  0.27499234676361084
Epoch:  387  	Training Loss: 0.2612815499305725
Test Loss:  0.27526795864105225
Valid Loss:  0.2749922275543213
Epoch:  388  	Training Loss: 0.26128146052360535
Test Loss:  0.27526789903640747
Valid Loss:  0.2749921381473541
Epoch:  389  	Training Loss: 0.2612813413143158
Test Loss:  0.2752677798271179
Valid Loss:  0.27499204874038696
Epoch:  390  	Training Loss: 0.26128125190734863
Test Loss:  0.27526772022247314
Valid Loss:  0.2749919295310974
Epoch:  391  	Training Loss: 0.26128116250038147
Test Loss:  0.2752676010131836
Valid Loss:  0.27499186992645264
Epoch:  392  	Training Loss: 0.2612810730934143
Test Loss:  0.2752675414085388
Valid Loss:  0.2749917507171631
Epoch:  393  	Training Loss: 0.26128095388412476
Test Loss:  0.27526742219924927
Valid Loss:  0.27499163150787354
Epoch:  394  	Training Loss: 0.26128089427948
Test Loss:  0.2752673327922821
Valid Loss:  0.27499157190322876
Epoch:  395  	Training Loss: 0.26128077507019043
Test Loss:  0.27526724338531494
Valid Loss:  0.2749914526939392
Epoch:  396  	Training Loss: 0.26128071546554565
Test Loss:  0.2752671241760254
Valid Loss:  0.27499136328697205
Epoch:  397  	Training Loss: 0.2612805962562561
Test Loss:  0.2752670645713806
Valid Loss:  0.2749912738800049
Epoch:  398  	Training Loss: 0.26128050684928894
Test Loss:  0.27526697516441345
Valid Loss:  0.27499115467071533
Epoch:  399  	Training Loss: 0.2612804174423218
Test Loss:  0.2752668261528015
Valid Loss:  0.27499109506607056
Epoch:  400  	Training Loss: 0.2612802982330322
Test Loss:  0.27526676654815674
Valid Loss:  0.274990975856781
Epoch:  401  	Training Loss: 0.26128023862838745
Test Loss:  0.2752666771411896
Valid Loss:  0.27499088644981384
Epoch:  402  	Training Loss: 0.2612801492214203
Test Loss:  0.2752665877342224
Valid Loss:  0.2749907970428467
Epoch:  403  	Training Loss: 0.2612800598144531
Test Loss:  0.27526649832725525
Valid Loss:  0.27499067783355713
Epoch:  404  	Training Loss: 0.2612799406051636
Test Loss:  0.2752664089202881
Valid Loss:  0.27499058842658997
Epoch:  405  	Training Loss: 0.2612798511981964
Test Loss:  0.27526628971099854
Valid Loss:  0.2749904990196228
Epoch:  406  	Training Loss: 0.26127976179122925
Test Loss:  0.27526620030403137
Valid Loss:  0.27499040961265564
Epoch:  407  	Training Loss: 0.2612796723842621
Test Loss:  0.2752661108970642
Valid Loss:  0.2749903202056885
Epoch:  408  	Training Loss: 0.2612795829772949
Test Loss:  0.27526602149009705
Valid Loss:  0.2749902009963989
Epoch:  409  	Training Loss: 0.26127949357032776
Test Loss:  0.2752659320831299
Valid Loss:  0.27499011158943176
Epoch:  410  	Training Loss: 0.2612794041633606
Test Loss:  0.27526581287384033
Valid Loss:  0.2749900221824646
Epoch:  411  	Training Loss: 0.26127928495407104
Test Loss:  0.27526575326919556
Valid Loss:  0.27498990297317505
Epoch:  412  	Training Loss: 0.2612791955471039
Test Loss:  0.275265634059906
Valid Loss:  0.2749898433685303
Epoch:  413  	Training Loss: 0.2612791061401367
Test Loss:  0.27526554465293884
Valid Loss:  0.2749897241592407
Epoch:  414  	Training Loss: 0.26127901673316956
Test Loss:  0.2752654552459717
Valid Loss:  0.27498963475227356
Epoch:  415  	Training Loss: 0.2612789273262024
Test Loss:  0.27526533603668213
Valid Loss:  0.2749895453453064
Epoch:  416  	Training Loss: 0.26127880811691284
Test Loss:  0.27526527643203735
Valid Loss:  0.27498942613601685
Epoch:  417  	Training Loss: 0.26127874851226807
Test Loss:  0.2752651572227478
Valid Loss:  0.2749893367290497
Epoch:  418  	Training Loss: 0.2612786293029785
Test Loss:  0.27526506781578064
Valid Loss:  0.2749892473220825
Epoch:  419  	Training Loss: 0.26127853989601135
Test Loss:  0.2752649784088135
Valid Loss:  0.27498915791511536
Epoch:  420  	Training Loss: 0.2612784504890442
Test Loss:  0.2752648890018463
Valid Loss:  0.2749890387058258
Epoch:  421  	Training Loss: 0.261278361082077
Test Loss:  0.27526479959487915
Valid Loss:  0.27498894929885864
Epoch:  422  	Training Loss: 0.26127827167510986
Test Loss:  0.2752646803855896
Valid Loss:  0.2749888598918915
Epoch:  423  	Training Loss: 0.2612781524658203
Test Loss:  0.27526459097862244
Valid Loss:  0.2749887704849243
Epoch:  424  	Training Loss: 0.26127809286117554
Test Loss:  0.2752645015716553
Valid Loss:  0.27498865127563477
Epoch:  425  	Training Loss: 0.261277973651886
Test Loss:  0.2752644121646881
Valid Loss:  0.27498859167099
Epoch:  426  	Training Loss: 0.2612779140472412
Test Loss:  0.27526432275772095
Valid Loss:  0.27498847246170044
Epoch:  427  	Training Loss: 0.26127779483795166
Test Loss:  0.2752642035484314
Valid Loss:  0.2749883830547333
Epoch:  428  	Training Loss: 0.2612777054309845
Test Loss:  0.27526411414146423
Valid Loss:  0.2749882936477661
Epoch:  429  	Training Loss: 0.26127761602401733
Test Loss:  0.27526402473449707
Valid Loss:  0.27498817443847656
Epoch:  430  	Training Loss: 0.26127752661705017
Test Loss:  0.2752639353275299
Valid Loss:  0.2749881148338318
Epoch:  431  	Training Loss: 0.261277437210083
Test Loss:  0.27526384592056274
Valid Loss:  0.27498799562454224
Epoch:  432  	Training Loss: 0.26127731800079346
Test Loss:  0.2752637565135956
Valid Loss:  0.2749879062175751
Epoch:  433  	Training Loss: 0.2612772285938263
Test Loss:  0.2752636671066284
Valid Loss:  0.2749878168106079
Epoch:  434  	Training Loss: 0.26127713918685913
Test Loss:  0.27526354789733887
Valid Loss:  0.27498769760131836
Epoch:  435  	Training Loss: 0.26127704977989197
Test Loss:  0.2752634882926941
Valid Loss:  0.2749876081943512
Epoch:  436  	Training Loss: 0.2612769603729248
Test Loss:  0.27526336908340454
Valid Loss:  0.27498751878738403
Epoch:  437  	Training Loss: 0.26127687096595764
Test Loss:  0.2752632796764374
Valid Loss:  0.2749873995780945
Epoch:  438  	Training Loss: 0.2612767815589905
Test Loss:  0.2752631902694702
Valid Loss:  0.2749873399734497
Epoch:  439  	Training Loss: 0.2612766623497009
Test Loss:  0.27526307106018066
Valid Loss:  0.27498722076416016
 88%|████████▊ | 439/500 [05:03<00:20,  2.95it/s] 88%|████████▊ | 441/500 [05:09<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:09<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:10<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:10<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:10<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:16<00:58,  1.18s/it] 91%|█████████ | 453/500 [05:16<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:17<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:17<00:19,  2.19it/s] 92%|█████████▏| 459/500 [05:17<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:23<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:23<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:23<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:24<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:24<00:10,  2.99it/s] 94%|█████████▍| 471/500 [05:30<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:30<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:30<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:30<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:31<00:07,  2.97it/s] 96%|█████████▌| 481/500 [05:37<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:37<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:37<00:05,  2.19it/s] 98%|█████████▊| 489/500 [05:37<00:03,  2.95it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:44<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:44<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:44<00:01,  2.14it/s]100%|█████████▉| 499/500 [05:45<00:00,  2.83it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
Epoch:  440  	Training Loss: 0.26127660274505615
Test Loss:  0.2752630114555359
Valid Loss:  0.2749871015548706
Epoch:  441  	Training Loss: 0.2612764835357666
Test Loss:  0.27526289224624634
Valid Loss:  0.27498704195022583
Epoch:  442  	Training Loss: 0.26127636432647705
Test Loss:  0.27526283264160156
Valid Loss:  0.2749869227409363
Epoch:  443  	Training Loss: 0.2612762749195099
Test Loss:  0.275262713432312
Valid Loss:  0.2749868631362915
Epoch:  444  	Training Loss: 0.2612762153148651
Test Loss:  0.27526259422302246
Valid Loss:  0.27498674392700195
Epoch:  445  	Training Loss: 0.26127612590789795
Test Loss:  0.2752625346183777
Valid Loss:  0.2749866247177124
Epoch:  446  	Training Loss: 0.2612760066986084
Test Loss:  0.2752624452114105
Valid Loss:  0.2749865651130676
Epoch:  447  	Training Loss: 0.26127591729164124
Test Loss:  0.27526235580444336
Valid Loss:  0.2749864459037781
Epoch:  448  	Training Loss: 0.2612758278846741
Test Loss:  0.2752622365951538
Valid Loss:  0.2749863564968109
Epoch:  449  	Training Loss: 0.2612757384777069
Test Loss:  0.27526214718818665
Valid Loss:  0.27498626708984375
Epoch:  450  	Training Loss: 0.26127564907073975
Test Loss:  0.2752620577812195
Valid Loss:  0.2749861478805542
Epoch:  451  	Training Loss: 0.2612755298614502
Test Loss:  0.27526193857192993
Valid Loss:  0.2749860882759094
Epoch:  452  	Training Loss: 0.2612754702568054
Test Loss:  0.27526187896728516
Valid Loss:  0.2749859690666199
Epoch:  453  	Training Loss: 0.26127535104751587
Test Loss:  0.275261789560318
Valid Loss:  0.2749858796596527
Epoch:  454  	Training Loss: 0.2612752914428711
Test Loss:  0.27526170015335083
Valid Loss:  0.27498579025268555
Epoch:  455  	Training Loss: 0.26127517223358154
Test Loss:  0.2752615809440613
Valid Loss:  0.274985671043396
Epoch:  456  	Training Loss: 0.26127511262893677
Test Loss:  0.27526146173477173
Valid Loss:  0.27498558163642883
Epoch:  457  	Training Loss: 0.2612749934196472
Test Loss:  0.27526140213012695
Valid Loss:  0.27498549222946167
Epoch:  458  	Training Loss: 0.26127487421035767
Test Loss:  0.2752613127231598
Valid Loss:  0.2749853730201721
Epoch:  459  	Training Loss: 0.2612747848033905
Test Loss:  0.27526119351387024
Valid Loss:  0.27498531341552734
Epoch:  460  	Training Loss: 0.2612747251987457
Test Loss:  0.2752611041069031
Valid Loss:  0.2749851942062378
Epoch:  461  	Training Loss: 0.2612746059894562
Test Loss:  0.2752609848976135
Valid Loss:  0.27498510479927063
Epoch:  462  	Training Loss: 0.261274516582489
Test Loss:  0.27526092529296875
Valid Loss:  0.27498501539230347
Epoch:  463  	Training Loss: 0.26127439737319946
Test Loss:  0.2752608060836792
Valid Loss:  0.2749848961830139
Epoch:  464  	Training Loss: 0.2612743377685547
Test Loss:  0.2752607464790344
Valid Loss:  0.27498477697372437
Epoch:  465  	Training Loss: 0.26127421855926514
Test Loss:  0.2752606272697449
Valid Loss:  0.2749847173690796
Epoch:  466  	Training Loss: 0.26127415895462036
Test Loss:  0.2752605378627777
Valid Loss:  0.2749846279621124
Epoch:  467  	Training Loss: 0.2612740397453308
Test Loss:  0.27526044845581055
Valid Loss:  0.2749845087528229
Epoch:  468  	Training Loss: 0.26127395033836365
Test Loss:  0.2752603590488434
Valid Loss:  0.2749844193458557
Epoch:  469  	Training Loss: 0.2612738609313965
Test Loss:  0.2752602696418762
Valid Loss:  0.27498432993888855
Epoch:  470  	Training Loss: 0.2612737715244293
Test Loss:  0.27526018023490906
Valid Loss:  0.2749842405319214
Epoch:  471  	Training Loss: 0.26127365231513977
Test Loss:  0.2752600908279419
Valid Loss:  0.27498412132263184
Epoch:  472  	Training Loss: 0.2612735629081726
Test Loss:  0.27525997161865234
Valid Loss:  0.27498406171798706
Epoch:  473  	Training Loss: 0.26127350330352783
Test Loss:  0.2752598822116852
Valid Loss:  0.2749839425086975
Epoch:  474  	Training Loss: 0.2612733840942383
Test Loss:  0.275259792804718
Valid Loss:  0.27498382329940796
Epoch:  475  	Training Loss: 0.2612732946872711
Test Loss:  0.27525967359542847
Valid Loss:  0.2749837338924408
Epoch:  476  	Training Loss: 0.26127320528030396
Test Loss:  0.2752596139907837
Valid Loss:  0.274983674287796
Epoch:  477  	Training Loss: 0.2612731158733368
Test Loss:  0.27525949478149414
Valid Loss:  0.2749835252761841
Epoch:  478  	Training Loss: 0.26127302646636963
Test Loss:  0.27525943517684937
Valid Loss:  0.2749834656715393
Epoch:  479  	Training Loss: 0.2612729072570801
Test Loss:  0.2752593159675598
Valid Loss:  0.27498334646224976
Epoch:  480  	Training Loss: 0.2612728178501129
Test Loss:  0.27525925636291504
Valid Loss:  0.274983286857605
Epoch:  481  	Training Loss: 0.26127272844314575
Test Loss:  0.2752591371536255
Valid Loss:  0.27498316764831543
Epoch:  482  	Training Loss: 0.2612726390361786
Test Loss:  0.27525901794433594
Valid Loss:  0.27498307824134827
Epoch:  483  	Training Loss: 0.2612725496292114
Test Loss:  0.27525895833969116
Valid Loss:  0.2749829888343811
Epoch:  484  	Training Loss: 0.26127246022224426
Test Loss:  0.2752588391304016
Valid Loss:  0.27498286962509155
Epoch:  485  	Training Loss: 0.2612723708152771
Test Loss:  0.27525874972343445
Valid Loss:  0.2749828100204468
Epoch:  486  	Training Loss: 0.26127228140830994
Test Loss:  0.2752586603164673
Valid Loss:  0.2749826908111572
Epoch:  487  	Training Loss: 0.2612721920013428
Test Loss:  0.27525854110717773
Valid Loss:  0.27498260140419006
Epoch:  488  	Training Loss: 0.2612720727920532
Test Loss:  0.27525848150253296
Valid Loss:  0.2749824821949005
Epoch:  489  	Training Loss: 0.26127198338508606
Test Loss:  0.2752583920955658
Valid Loss:  0.27498239278793335
Epoch:  490  	Training Loss: 0.2612718939781189
Test Loss:  0.27525827288627625
Valid Loss:  0.2749823033809662
Epoch:  491  	Training Loss: 0.26127177476882935
Test Loss:  0.2752581834793091
Valid Loss:  0.274982213973999
Epoch:  492  	Training Loss: 0.26127171516418457
Test Loss:  0.2752581238746643
Valid Loss:  0.2749820947647095
Epoch:  493  	Training Loss: 0.261271595954895
Test Loss:  0.27525800466537476
Valid Loss:  0.2749820053577423
Epoch:  494  	Training Loss: 0.26127150654792786
Test Loss:  0.2752578854560852
Valid Loss:  0.27498191595077515
Epoch:  495  	Training Loss: 0.2612714171409607
Test Loss:  0.27525782585144043
Valid Loss:  0.2749817967414856
Epoch:  496  	Training Loss: 0.26127132773399353
Test Loss:  0.2752577066421509
Valid Loss:  0.2749817371368408
Epoch:  497  	Training Loss: 0.26127123832702637
Test Loss:  0.2752576172351837
Valid Loss:  0.27498161792755127
Epoch:  498  	Training Loss: 0.2612711191177368
Test Loss:  0.27525752782821655
Valid Loss:  0.2749815285205841
Epoch:  499  	Training Loss: 0.26127102971076965
Test Loss:  0.2752574384212494
Valid Loss:  0.27498143911361694
Epoch:  500  	Training Loss: 0.2612709701061249
Test Loss:  0.2752573490142822
Valid Loss:  0.2749813199043274
seed is  7
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:16,  6.29s/it]  1%|          | 3/500 [00:06<13:56,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:15,  1.93it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:55,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:19<13:19,  1.65s/it]  3%|▎         | 17/500 [00:19<09:18,  1.16s/it]  4%|▍         | 19/500 [00:20<06:35,  1.21it/s]  4%|▍         | 21/500 [00:26<12:19,  1.54s/it]  5%|▍         | 23/500 [00:26<08:41,  1.09s/it]  5%|▌         | 25/500 [00:26<06:11,  1.28it/s]  5%|▌         | 27/500 [00:26<04:27,  1.77it/s]  6%|▌         | 29/500 [00:26<03:15,  2.41it/s]  6%|▌         | 31/500 [00:33<09:44,  1.25s/it]  7%|▋         | 33/500 [00:33<06:57,  1.12it/s]  7%|▋         | 35/500 [00:33<04:59,  1.55it/s]  7%|▋         | 37/500 [00:33<03:37,  2.13it/s]  8%|▊         | 39/500 [00:33<02:40,  2.87it/s]  8%|▊         | 41/500 [00:40<09:21,  1.22s/it]  9%|▊         | 43/500 [00:40<06:43,  1.13it/s]  9%|▉         | 45/500 [00:40<04:52,  1.55it/s]  9%|▉         | 47/500 [00:40<03:35,  2.10it/s] 10%|▉         | 49/500 [00:41<02:42,  2.78it/s] 10%|█         | 51/500 [00:47<08:57,  1.20s/it] 11%|█         | 53/500 [00:47<06:23,  1.16it/s] 11%|█         | 55/500 [00:47<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:47<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:47<02:29,  2.96it/s] 12%|█▏        | 61/500 [00:54<08:33,  1.17s/it] 13%|█▎        | 63/500 [00:54<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:54<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:54<03:12,  2.25it/s]Epoch:  1  	Training Loss: 0.2545188069343567
Test Loss:  0.022328022867441177
Valid Loss:  0.024470657110214233
Epoch:  2  	Training Loss: 0.02698274329304695
Test Loss:  0.018718421459197998
Valid Loss:  0.018451496958732605
Epoch:  3  	Training Loss: 0.015771079808473587
Test Loss:  0.005358988419175148
Valid Loss:  0.006876521278172731
Epoch:  4  	Training Loss: 0.007941709831357002
Test Loss:  0.005454556085169315
Valid Loss:  0.005726226139813662
Epoch:  5  	Training Loss: 0.00448372308164835
Test Loss:  0.0015718892682343721
Valid Loss:  0.002641107654199004
Epoch:  6  	Training Loss: 0.0029092729091644287
Test Loss:  0.0023976494558155537
Valid Loss:  0.002871687524020672
Epoch:  7  	Training Loss: 0.002188007114455104
Test Loss:  0.001045798882842064
Valid Loss:  0.001878170296549797
Epoch:  8  	Training Loss: 0.0018314430490136147
Test Loss:  0.0015735425986349583
Valid Loss:  0.002123502315953374
Epoch:  9  	Training Loss: 0.0016558135394006968
Test Loss:  0.001025786274112761
Valid Loss:  0.0017394288443028927
Epoch:  10  	Training Loss: 0.0015649438137188554
Test Loss:  0.001320547889918089
Valid Loss:  0.0018910393118858337
Epoch:  11  	Training Loss: 0.0015164560172706842
Test Loss:  0.001069157849997282
Valid Loss:  0.0017210885416716337
Epoch:  12  	Training Loss: 0.0014884474221616983
Test Loss:  0.0016296503599733114
Valid Loss:  0.0020742297638207674
Epoch:  13  	Training Loss: 0.0015916668344289064
Test Loss:  0.0018036667024716735
Valid Loss:  0.0027991090901196003
Epoch:  14  	Training Loss: 0.003135228995233774
Test Loss:  0.01371060125529766
Valid Loss:  0.013208115473389626
Epoch:  15  	Training Loss: 0.011090105399489403
Test Loss:  0.017918262630701065
Valid Loss:  0.019650056958198547
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.02120639570057392
Test Loss:  0.0020331908017396927
Valid Loss:  0.003059862181544304
Epoch:  17  	Training Loss: 0.003331216052174568
Test Loss:  0.002062528859823942
Valid Loss:  0.0029441576916724443
Epoch:  18  	Training Loss: 0.0030647835228592157
Test Loss:  0.0020861183293163776
Valid Loss:  0.002920387778431177
Epoch:  19  	Training Loss: 0.0029899361543357372
Test Loss:  0.0020728707313537598
Valid Loss:  0.002883706707507372
Epoch:  20  	Training Loss: 0.002926349174231291
Test Loss:  0.0020453978795558214
Valid Loss:  0.0028346586041152477
Epoch:  21  	Training Loss: 0.002862047404050827
Test Loss:  0.0020118094980716705
Valid Loss:  0.0027823755517601967
Epoch:  22  	Training Loss: 0.0027990792877972126
Test Loss:  0.002076726173982024
Valid Loss:  0.002677496522665024
Epoch:  23  	Training Loss: 0.0025232345797121525
Test Loss:  0.0017584343440830708
Valid Loss:  0.0024205083027482033
Epoch:  24  	Training Loss: 0.0023024987895041704
Test Loss:  0.0016643197741359472
Valid Loss:  0.002282608300447464
Epoch:  25  	Training Loss: 0.0021138200536370277
Test Loss:  0.001511462265625596
Valid Loss:  0.0021248310804367065
Epoch:  26  	Training Loss: 0.0019523598020896316
Test Loss:  0.0014268537051975727
Valid Loss:  0.002012556651607156
Epoch:  27  	Training Loss: 0.0018150168471038342
Test Loss:  0.0013234175276011229
Valid Loss:  0.0018947875360026956
Epoch:  28  	Training Loss: 0.0016950584249570966
Test Loss:  0.001253495691344142
Valid Loss:  0.0018027951009571552
Epoch:  29  	Training Loss: 0.0015912966337054968
Test Loss:  0.001185151282697916
Valid Loss:  0.001717579667456448
Epoch:  30  	Training Loss: 0.001501421444118023
Test Loss:  0.0011309079127386212
Valid Loss:  0.001653949380852282
Epoch:  31  	Training Loss: 0.0014301133342087269
Test Loss:  0.0010703355073928833
Valid Loss:  0.0015770294703543186
Epoch:  32  	Training Loss: 0.0013674870133399963
Test Loss:  0.001091766287572682
Valid Loss:  0.0015680842334404588
Epoch:  33  	Training Loss: 0.0012972027761861682
Test Loss:  0.0010598753578960896
Valid Loss:  0.0015271715819835663
Epoch:  34  	Training Loss: 0.0012630358105525374
Test Loss:  0.0010452966671437025
Valid Loss:  0.0015056433621793985
Epoch:  35  	Training Loss: 0.0012310284655541182
Test Loss:  0.0010090559953823686
Valid Loss:  0.0014636991545557976
Epoch:  36  	Training Loss: 0.0011998733971267939
Test Loss:  0.0009889748180285096
Valid Loss:  0.0014384801033884287
Epoch:  37  	Training Loss: 0.0011707141529768705
Test Loss:  0.0009586219093762338
Valid Loss:  0.0014035855419933796
Epoch:  38  	Training Loss: 0.001143003348261118
Test Loss:  0.0009372075437568128
Valid Loss:  0.0013782430905848742
Epoch:  39  	Training Loss: 0.0011165981413796544
Test Loss:  0.0009104797500185668
Valid Loss:  0.001347213052213192
Epoch:  40  	Training Loss: 0.0010912497527897358
Test Loss:  0.0008894825587049127
Valid Loss:  0.001322397030889988
Epoch:  41  	Training Loss: 0.0010666473535820842
Test Loss:  0.0008653626427985728
Valid Loss:  0.0012942225439473987
Epoch:  42  	Training Loss: 0.0010428812820464373
Test Loss:  0.0007730408105999231
Valid Loss:  0.0012038095155730844
Epoch:  43  	Training Loss: 0.001007300103083253
Test Loss:  0.0007884654332883656
Valid Loss:  0.001203284366056323
Epoch:  44  	Training Loss: 0.000980861485004425
Test Loss:  0.0007622112752869725
Valid Loss:  0.0011699298629537225
Epoch:  45  	Training Loss: 0.0009585969964973629
Test Loss:  0.0007544723339378834
Valid Loss:  0.0011522856075316668
Epoch:  46  	Training Loss: 0.0009401103015989065
Test Loss:  0.0007463296060450375
Valid Loss:  0.0011356906034052372
Epoch:  47  	Training Loss: 0.0009219426428899169
Test Loss:  0.0007349452935159206
Valid Loss:  0.0011185528710484505
Epoch:  48  	Training Loss: 0.0009068730287253857
Test Loss:  0.000719343894161284
Valid Loss:  0.0010968010174110532
Epoch:  49  	Training Loss: 0.0008930402109399438
Test Loss:  0.0007190157775767148
Valid Loss:  0.001089118653908372
Epoch:  50  	Training Loss: 0.0008782357326708734
Test Loss:  0.0007037037867121398
Valid Loss:  0.0010680761188268661
Epoch:  51  	Training Loss: 0.0008640224114060402
Test Loss:  0.0006976383738219738
Valid Loss:  0.0010572293540462852
Epoch:  52  	Training Loss: 0.0008510111947543919
Test Loss:  0.0006849452038295567
Valid Loss:  0.0010414763819426298
Epoch:  53  	Training Loss: 0.0008463582489639521
Test Loss:  0.0006874037208035588
Valid Loss:  0.001040761941112578
Epoch:  54  	Training Loss: 0.0008423064136877656
Test Loss:  0.0006854342645965517
Valid Loss:  0.0010358287254348397
Epoch:  55  	Training Loss: 0.000838669715449214
Test Loss:  0.000685273902490735
Valid Loss:  0.0010328864445909858
Epoch:  56  	Training Loss: 0.000835424056276679
Test Loss:  0.000684957776684314
Valid Loss:  0.001030307961627841
Epoch:  57  	Training Loss: 0.0008325710659846663
Test Loss:  0.0006846297765150666
Valid Loss:  0.0010278800036758184
Epoch:  58  	Training Loss: 0.0008300079498440027
Test Loss:  0.0006842415896244347
Valid Loss:  0.0010255026863887906
Epoch:  59  	Training Loss: 0.0008276340086013079
Test Loss:  0.0006842417642474174
Valid Loss:  0.001023649936541915
Epoch:  60  	Training Loss: 0.0008255269494839013
Test Loss:  0.0006840130663476884
Valid Loss:  0.0010216726223006845
Epoch:  61  	Training Loss: 0.0008235719287768006
Test Loss:  0.0006838345434516668
Valid Loss:  0.0010198348900303245
Epoch:  62  	Training Loss: 0.0008217510185204446
Test Loss:  0.0006616999744437635
Valid Loss:  0.0009958657901734114
Epoch:  63  	Training Loss: 0.0007892375579103827
Test Loss:  0.0006281213136389852
Valid Loss:  0.0009634217130951583
Epoch:  64  	Training Loss: 0.0007605738937854767
Test Loss:  0.0005995987448841333
Valid Loss:  0.0009338923846371472
Epoch:  65  	Training Loss: 0.000735445530153811
Test Loss:  0.000577921571675688
Valid Loss:  0.000912254792638123
Epoch:  66  	Training Loss: 0.0007143676048144698
Test Loss:  0.0005582761368714273
Valid Loss:  0.0008917474187910557
Epoch:  67  	Training Loss: 0.0006966957589611411
Test Loss:  0.0005421921378001571
Valid Loss:  0.0008751656278036535
Epoch:  68  	Training Loss: 0.000681344885379076
Test Loss:  0.0005268487147986889
Valid Loss:  0.0008583295275457203
Epoch:  69  	Training Loss: 0.0006675997283309698
Test Loss:  14%|█▍        | 69/500 [00:54<02:22,  3.03it/s] 14%|█▍        | 71/500 [01:00<08:24,  1.18s/it] 15%|█▍        | 73/500 [01:01<06:00,  1.18it/s] 15%|█▌        | 75/500 [01:01<04:19,  1.64it/s] 15%|█▌        | 77/500 [01:01<03:08,  2.24it/s] 16%|█▌        | 79/500 [01:01<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:07<08:11,  1.17s/it] 17%|█▋        | 83/500 [01:07<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:07<04:12,  1.65it/s] 17%|█▋        | 87/500 [01:08<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:08<02:17,  2.98it/s] 18%|█▊        | 91/500 [01:14<08:00,  1.18s/it] 19%|█▊        | 93/500 [01:14<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:14<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:14<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:15<02:15,  2.97it/s] 20%|██        | 101/500 [01:21<08:00,  1.20s/it] 21%|██        | 103/500 [01:21<05:43,  1.16it/s] 21%|██        | 105/500 [01:21<04:06,  1.60it/s] 21%|██▏       | 107/500 [01:21<03:00,  2.18it/s] 22%|██▏       | 109/500 [01:22<02:12,  2.94it/s] 22%|██▏       | 111/500 [01:28<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:28<05:26,  1.18it/s] 23%|██▎       | 115/500 [01:28<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:28<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:28<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:35<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:35<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:35<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:35<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:35<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:41<07:07,  1.16s/it] 27%|██▋       | 133/500 [01:42<05:05,  1.20it/s] 27%|██▋       | 135/500 [01:42<03:39,  1.66it/s] 0.0005136292311362922
Valid Loss:  0.0008427925640717149
Epoch:  70  	Training Loss: 0.000654734147246927
Test Loss:  0.0005008989246562123
Valid Loss:  0.0008274237043224275
Epoch:  71  	Training Loss: 0.000642348313704133
Test Loss:  0.000488816702272743
Valid Loss:  0.000813212594948709
Epoch:  72  	Training Loss: 0.0006308036390691996
Test Loss:  0.00047455253661610186
Valid Loss:  0.0007956012268550694
Epoch:  73  	Training Loss: 0.0006173460278660059
Test Loss:  0.0004632236959878355
Valid Loss:  0.0007808334194123745
Epoch:  74  	Training Loss: 0.0006046456983312964
Test Loss:  0.00045202835462987423
Valid Loss:  0.0007661286508664489
Epoch:  75  	Training Loss: 0.0005926143494434655
Test Loss:  0.0004413700371515006
Valid Loss:  0.0007524845423176885
Epoch:  76  	Training Loss: 0.0005811700830236077
Test Loss:  0.00043089065002277493
Valid Loss:  0.000739345676265657
Epoch:  77  	Training Loss: 0.0005701028276234865
Test Loss:  0.0004208344325888902
Valid Loss:  0.0007265926105901599
Epoch:  78  	Training Loss: 0.000559320324100554
Test Loss:  0.00041122143738903105
Valid Loss:  0.0007142670801840723
Epoch:  79  	Training Loss: 0.0005488740280270576
Test Loss:  0.0004018358886241913
Valid Loss:  0.0007022930076345801
Epoch:  80  	Training Loss: 0.0005385600961744785
Test Loss:  0.00039243733044713736
Valid Loss:  0.0006905441405251622
Epoch:  81  	Training Loss: 0.0005286418600007892
Test Loss:  0.00038363662315532565
Valid Loss:  0.0006793681532144547
Epoch:  82  	Training Loss: 0.0005190565716475248
Test Loss:  0.0003848617780022323
Valid Loss:  0.000676958414260298
Epoch:  83  	Training Loss: 0.0005094304797239602
Test Loss:  0.0003793186042457819
Valid Loss:  0.0006687365239486098
Epoch:  84  	Training Loss: 0.0005013664485886693
Test Loss:  0.0003721737302839756
Valid Loss:  0.0006590333068743348
Epoch:  85  	Training Loss: 0.0004936669138260186
Test Loss:  0.0003654806350823492
Valid Loss:  0.0006501186289824545
Epoch:  86  	Training Loss: 0.00048622782924212515
Test Loss:  0.0003574614238459617
Valid Loss:  0.0006398770492523909
Epoch:  87  	Training Loss: 0.0004790093225892633
Test Loss:  0.0003526101936586201
Valid Loss:  0.0006324914284050465
Epoch:  88  	Training Loss: 0.00047165059368126094
Test Loss:  0.00034603499807417393
Valid Loss:  0.0006237155757844448
Epoch:  89  	Training Loss: 0.00046434003161266446
Test Loss:  0.00033982054446823895
Valid Loss:  0.0006156725576147437
Epoch:  90  	Training Loss: 0.0004574158228933811
Test Loss:  0.00033220971818082035
Valid Loss:  0.0006059622974134982
Epoch:  91  	Training Loss: 0.00045048666652292013
Test Loss:  0.00032783893402665854
Valid Loss:  0.000599338673055172
Epoch:  92  	Training Loss: 0.0004433515714481473
Test Loss:  0.00031463257619179785
Valid Loss:  0.0005818342906422913
Epoch:  93  	Training Loss: 0.0004376572906039655
Test Loss:  0.0003165789821650833
Valid Loss:  0.0005815697368234396
Epoch:  94  	Training Loss: 0.0004346226342022419
Test Loss:  0.0003155514132231474
Valid Loss:  0.0005783338565379381
Epoch:  95  	Training Loss: 0.00043221726082265377
Test Loss:  0.0003153339494019747
Valid Loss:  0.0005762948421761394
Epoch:  96  	Training Loss: 0.0004301341250538826
Test Loss:  0.00031490891706198454
Valid Loss:  0.0005742290522903204
Epoch:  97  	Training Loss: 0.0004282556474208832
Test Loss:  0.0003144647052977234
Valid Loss:  0.0005722931819036603
Epoch:  98  	Training Loss: 0.0004265161987859756
Test Loss:  0.00031396280974149704
Valid Loss:  0.0005704093491658568
Epoch:  99  	Training Loss: 0.0004249010235071182
Test Loss:  0.0003133902791887522
Valid Loss:  0.0005685814539901912
Epoch:  100  	Training Loss: 0.0004233675717841834
Test Loss:  0.00031277743983082473
Valid Loss:  0.000566850183531642
Epoch:  101  	Training Loss: 0.0004219107795506716
Test Loss:  0.0003121854970231652
Valid Loss:  0.0005652583204209805
Epoch:  102  	Training Loss: 0.0004205020668450743
Test Loss:  0.0003132719430141151
Valid Loss:  0.0005648583173751831
Epoch:  103  	Training Loss: 0.0004179133102297783
Test Loss:  0.00031113310251384974
Valid Loss:  0.0005611685337498784
Epoch:  104  	Training Loss: 0.00041548896115273237
Test Loss:  0.0003096938889939338
Valid Loss:  0.0005581409204751253
Epoch:  105  	Training Loss: 0.00041311420500278473
Test Loss:  0.00030791215249337256
Valid Loss:  0.0005547485197894275
Epoch:  106  	Training Loss: 0.00041072629392147064
Test Loss:  0.0003062667674385011
Valid Loss:  0.0005513944197446108
Epoch:  107  	Training Loss: 0.00040823023300617933
Test Loss:  0.0003050446684937924
Valid Loss:  0.0005484226858243346
Epoch:  108  	Training Loss: 0.0004061140934936702
Test Loss:  0.00030449143378064036
Valid Loss:  0.0005465815775096416
Epoch:  109  	Training Loss: 0.0004044909728690982
Test Loss:  0.00030345976119861007
Valid Loss:  0.0005443809786811471
Epoch:  110  	Training Loss: 0.00040292064659297466
Test Loss:  0.00030239453190006316
Valid Loss:  0.0005422169342637062
Epoch:  111  	Training Loss: 0.00040138952317647636
Test Loss:  0.0003013369860127568
Valid Loss:  0.0005401103990152478
Epoch:  112  	Training Loss: 0.00039986855699680746
Test Loss:  0.0002932451316155493
Valid Loss:  0.000532659818418324
Epoch:  113  	Training Loss: 0.0003913990512955934
Test Loss:  0.0002837884530890733
Valid Loss:  0.0005229053786024451
Epoch:  114  	Training Loss: 0.00038399838376790285
Test Loss:  0.0002762372314464301
Valid Loss:  0.0005144367460161448
Epoch:  115  	Training Loss: 0.00037726486334577203
Test Loss:  0.0002696207957342267
Valid Loss:  0.0005066182930022478
Epoch:  116  	Training Loss: 0.00037125026574358344
Test Loss:  0.00026375477318651974
Valid Loss:  0.0004994564224034548
Epoch:  117  	Training Loss: 0.00036576695856638253
Test Loss:  0.00025848374934867024
Valid Loss:  0.0004926653346046805
Epoch:  118  	Training Loss: 0.00036067585460841656
Test Loss:  0.0002538143889978528
Valid Loss:  0.00048637096188031137
Epoch:  119  	Training Loss: 0.00035585311707109213
Test Loss:  0.00024939203285612166
Valid Loss:  0.00048037245869636536
Epoch:  120  	Training Loss: 0.0003510977257974446
Test Loss:  0.0002450149622745812
Valid Loss:  0.00047454156447201967
Epoch:  121  	Training Loss: 0.0003463934699539095
Test Loss:  0.00024093699175864458
Valid Loss:  0.0004689219640567899
Epoch:  122  	Training Loss: 0.0003418719570618123
Test Loss:  0.00023894282639957964
Valid Loss:  0.000465844408608973
Epoch:  123  	Training Loss: 0.00033991571399383247
Test Loss:  0.0002375044277869165
Valid Loss:  0.00046355623635463417
Epoch:  124  	Training Loss: 0.00033806730061769485
Test Loss:  0.00023602801957167685
Valid Loss:  0.0004610978940036148
Epoch:  125  	Training Loss: 0.00033624214120209217
Test Loss:  0.00023484644771087915
Valid Loss:  0.00045912625500932336
Epoch:  126  	Training Loss: 0.00033440382685512304
Test Loss:  0.00023347004025708884
Valid Loss:  0.00045682780910283327
Epoch:  127  	Training Loss: 0.00033260180498473346
Test Loss:  0.0002323152730241418
Valid Loss:  0.000454924360383302
Epoch:  128  	Training Loss: 0.0003308250452391803
Test Loss:  0.00023098435485735536
Valid Loss:  0.00045272137504070997
Epoch:  129  	Training Loss: 0.0003290970344096422
Test Loss:  0.00022988623823039234
Valid Loss:  0.00045091318315826356
Epoch:  130  	Training Loss: 0.00032733933767303824
Test Loss:  0.0002285899972775951
Valid Loss:  0.0004487740225158632
Epoch:  131  	Training Loss: 0.00032563391141593456
Test Loss:  0.00022752115910407156
Valid Loss:  0.00044699347927235067
Epoch:  132  	Training Loss: 0.00032390636624768376
Test Loss:  0.00022741383872926235
Valid Loss:  0.0004464894300326705
Epoch:  133  	Training Loss: 0.0003223791718482971
Test Loss:  0.00022703755530528724
Valid Loss:  0.00044579722452908754
Epoch:  134  	Training Loss: 0.0003210172289982438
Test Loss:  0.00022650236496701837
Valid Loss:  0.00044495306792669
Epoch:  135  	Training Loss: 0.000319760205456987
Test Loss:  0.00022581357916351408
Valid Loss:  0.00044395256554707885
Epoch:  136  	Training Loss: 0.0003185707319062203
Test Loss:  0.00022502991487272084
Valid Loss:  0.0004428196407388896
Epoch:  137  	Training Loss: 0.0003174146404489875
Test Loss:   27%|██▋       | 137/500 [01:42<02:39,  2.27it/s] 28%|██▊       | 139/500 [01:42<01:58,  3.06it/s] 28%|██▊       | 141/500 [01:48<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:49<05:07,  1.16it/s] 29%|██▉       | 145/500 [01:49<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:49<02:44,  2.15it/s] 30%|██▉       | 149/500 [01:49<02:03,  2.85it/s] 30%|███       | 151/500 [01:55<07:00,  1.21s/it] 31%|███       | 153/500 [01:56<05:00,  1.16it/s] 31%|███       | 155/500 [01:56<03:35,  1.60it/s] 31%|███▏      | 157/500 [01:56<02:36,  2.19it/s] 32%|███▏      | 159/500 [01:56<01:55,  2.94it/s] 32%|███▏      | 161/500 [02:02<06:35,  1.17s/it] 33%|███▎      | 163/500 [02:02<04:42,  1.19it/s] 33%|███▎      | 165/500 [02:02<03:22,  1.65it/s] 33%|███▎      | 167/500 [02:03<02:27,  2.26it/s] 34%|███▍      | 169/500 [02:03<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:09<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:09<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:09<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:10<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:10<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:16<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:16<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:16<03:11,  1.65it/s] 37%|███▋      | 187/500 [02:16<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:16<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:23<05:56,  1.15s/it] 39%|███▊      | 193/500 [02:23<04:14,  1.21it/s] 39%|███▉      | 195/500 [02:23<03:02,  1.67it/s] 39%|███▉      | 197/500 [02:23<02:12,  2.28it/s] 40%|███▉      | 199/500 [02:23<01:38,  3.06it/s] 40%|████      | 201/500 [02:29<05:50,  1.17s/it] 41%|████      | 203/500 [02:30<04:10,  1.18it/s]0.00022418354637920856
Valid Loss:  0.00044161573168821633
Epoch:  138  	Training Loss: 0.00031628209399059415
Test Loss:  0.00022329192142933607
Valid Loss:  0.00044036831241101027
Epoch:  139  	Training Loss: 0.0003151676501147449
Test Loss:  0.00022236353834159672
Valid Loss:  0.0004390875983517617
Epoch:  140  	Training Loss: 0.0003140647313557565
Test Loss:  0.00022141456429380924
Valid Loss:  0.000437790818978101
Epoch:  141  	Training Loss: 0.000312970660161227
Test Loss:  0.00022043497301638126
Valid Loss:  0.00043646039557643235
Epoch:  142  	Training Loss: 0.00031187146669253707
Test Loss:  0.00021147998631931841
Valid Loss:  0.0004251062637194991
Epoch:  143  	Training Loss: 0.0003071465471293777
Test Loss:  0.0002110819041263312
Valid Loss:  0.00042385258711874485
Epoch:  144  	Training Loss: 0.00030283245723694563
Test Loss:  0.00020565054728649557
Valid Loss:  0.0004161308752372861
Epoch:  145  	Training Loss: 0.0002986079780384898
Test Loss:  0.00020381278591230512
Valid Loss:  0.0004129852750338614
Epoch:  146  	Training Loss: 0.0002942743303719908
Test Loss:  0.00019977387273684144
Valid Loss:  0.0004072373267263174
Epoch:  147  	Training Loss: 0.00028997185290791094
Test Loss:  0.00019730086205527186
Valid Loss:  0.00040334899676963687
Epoch:  148  	Training Loss: 0.00028583360835909843
Test Loss:  0.00019387745123822242
Valid Loss:  0.00039776595076546073
Epoch:  149  	Training Loss: 0.0002818770590238273
Test Loss:  0.00019195012282580137
Valid Loss:  0.00039439150714315474
Epoch:  150  	Training Loss: 0.0002781343646347523
Test Loss:  0.000189267608220689
Valid Loss:  0.00039017375092953444
Epoch:  151  	Training Loss: 0.00027470587519928813
Test Loss:  0.00018734611512627453
Valid Loss:  0.0003869185457006097
Epoch:  152  	Training Loss: 0.00027147348737344146
Test Loss:  0.00018743230612017214
Valid Loss:  0.00038536370266228914
Epoch:  153  	Training Loss: 0.00026976747903972864
Test Loss:  0.00018739851657301188
Valid Loss:  0.0003837639233097434
Epoch:  154  	Training Loss: 0.0002683306811377406
Test Loss:  0.0001874265435617417
Valid Loss:  0.00038243638118728995
Epoch:  155  	Training Loss: 0.0002671658294275403
Test Loss:  0.0001875131856650114
Valid Loss:  0.0003813148650806397
Epoch:  156  	Training Loss: 0.0002661467297002673
Test Loss:  0.0001875843299785629
Valid Loss:  0.0003803310974035412
Epoch:  157  	Training Loss: 0.00026526860892772675
Test Loss:  0.00018765105050988495
Valid Loss:  0.0003794864169321954
Epoch:  158  	Training Loss: 0.00026449747383594513
Test Loss:  0.00018772383918985724
Valid Loss:  0.0003787444729823619
Epoch:  159  	Training Loss: 0.00026381289353594184
Test Loss:  0.00018777765217237175
Valid Loss:  0.00037809135392308235
Epoch:  160  	Training Loss: 0.0002632082614582032
Test Loss:  0.00018781634571496397
Valid Loss:  0.0003774860524572432
Epoch:  161  	Training Loss: 0.0002626671630423516
Test Loss:  0.0001878699113149196
Valid Loss:  0.00037696631625294685
Epoch:  162  	Training Loss: 0.00026217353297397494
Test Loss:  0.00018711881421040744
Valid Loss:  0.0003755169454962015
Epoch:  163  	Training Loss: 0.00026075978530570865
Test Loss:  0.00018595761503092945
Valid Loss:  0.0003736561629921198
Epoch:  164  	Training Loss: 0.0002593207755126059
Test Loss:  0.00018481866572983563
Valid Loss:  0.0003717913350556046
Epoch:  165  	Training Loss: 0.0002578417770564556
Test Loss:  0.00018362767877988517
Valid Loss:  0.000369881687220186
Epoch:  166  	Training Loss: 0.0002563863235991448
Test Loss:  0.00018243372323922813
Valid Loss:  0.0003679673536680639
Epoch:  167  	Training Loss: 0.00025493637076579034
Test Loss:  0.0001812435220927
Valid Loss:  0.0003660405636765063
Epoch:  168  	Training Loss: 0.00025350897340103984
Test Loss:  0.0001800681056920439
Valid Loss:  0.00036414049100130796
Epoch:  169  	Training Loss: 0.0002520997659303248
Test Loss:  0.0001788681256584823
Valid Loss:  0.00036225502844899893
Epoch:  170  	Training Loss: 0.00025070144329220057
Test Loss:  0.00017766820383258164
Valid Loss:  0.00036038184771314263
Epoch:  171  	Training Loss: 0.00024931487860158086
Test Loss:  0.00017647186177782714
Valid Loss:  0.0003585272643249482
Epoch:  172  	Training Loss: 0.00024794574710540473
Test Loss:  0.00016773205425124615
Valid Loss:  0.000348198926076293
Epoch:  173  	Training Loss: 0.00024103838950395584
Test Loss:  0.0001630768529139459
Valid Loss:  0.00034196890192106366
Epoch:  174  	Training Loss: 0.000236865394981578
Test Loss:  0.00015975341375451535
Valid Loss:  0.0003377591201569885
Epoch:  175  	Training Loss: 0.00023385198437608778
Test Loss:  0.0001570371096022427
Valid Loss:  0.0003339317627251148
Epoch:  176  	Training Loss: 0.00023114110808819532
Test Loss:  0.0001546373387100175
Valid Loss:  0.0003301883989479393
Epoch:  177  	Training Loss: 0.00022856867872178555
Test Loss:  0.00015250418800860643
Valid Loss:  0.00032667885534465313
Epoch:  178  	Training Loss: 0.00022610108135268092
Test Loss:  0.00015040230937302113
Valid Loss:  0.00032321858452633023
Epoch:  179  	Training Loss: 0.00022372309467755258
Test Loss:  0.00014857473433949053
Valid Loss:  0.0003200036007910967
Epoch:  180  	Training Loss: 0.00022142264060676098
Test Loss:  0.00014673153054900467
Valid Loss:  0.0003168049734085798
Epoch:  181  	Training Loss: 0.00021919532446190715
Test Loss:  0.00014510189066641033
Valid Loss:  0.0003138043684884906
Epoch:  182  	Training Loss: 0.000217003544094041
Test Loss:  0.00014377119077835232
Valid Loss:  0.00031074672006070614
Epoch:  183  	Training Loss: 0.00021462529548443854
Test Loss:  0.00014270792598836124
Valid Loss:  0.00030799140222370625
Epoch:  184  	Training Loss: 0.0002123127633240074
Test Loss:  0.00014128693146631122
Valid Loss:  0.0003050020895898342
Epoch:  185  	Training Loss: 0.0002100844867527485
Test Loss:  0.00014015260967426002
Valid Loss:  0.0003022971504833549
Epoch:  186  	Training Loss: 0.00020793185103684664
Test Loss:  0.0001388199016219005
Valid Loss:  0.00029947125585749745
Epoch:  187  	Training Loss: 0.00020585113088600338
Test Loss:  0.00013769743964076042
Valid Loss:  0.0002968627377413213
Epoch:  188  	Training Loss: 0.00020383947412483394
Test Loss:  0.0001364864583592862
Valid Loss:  0.00029422741499729455
Epoch:  189  	Training Loss: 0.0002019018866121769
Test Loss:  0.00013545507681556046
Valid Loss:  0.0002917444217018783
Epoch:  190  	Training Loss: 0.0001999995147343725
Test Loss:  0.0001342957839369774
Valid Loss:  0.0002890460309572518
Epoch:  191  	Training Loss: 0.00019801818416453898
Test Loss:  0.00013304084131959826
Valid Loss:  0.00028631649911403656
Epoch:  192  	Training Loss: 0.00019597512437030673
Test Loss:  0.00013149429287295789
Valid Loss:  0.0002832359168678522
Epoch:  193  	Training Loss: 0.00019383925246074796
Test Loss:  0.00012972086551599205
Valid Loss:  0.00027983018662780523
Epoch:  194  	Training Loss: 0.00019171614258084446
Test Loss:  0.00012815646186936647
Valid Loss:  0.00027665740344673395
Epoch:  195  	Training Loss: 0.00018961609748657793
Test Loss:  0.0001265002938453108
Valid Loss:  0.00027350836899131536
Epoch:  196  	Training Loss: 0.0001875564339570701
Test Loss:  0.00012497970601543784
Valid Loss:  0.00027056774706579745
Epoch:  197  	Training Loss: 0.00018554116832092404
Test Loss:  0.00012350182805676013
Valid Loss:  0.0002676407166291028
Epoch:  198  	Training Loss: 0.00018359595560468733
Test Loss:  0.00012210491695441306
Valid Loss:  0.0002646701177582145
Epoch:  199  	Training Loss: 0.0001817743614083156
Test Loss:  0.0001212429124279879
Valid Loss:  0.00026232076925225556
Epoch:  200  	Training Loss: 0.00018004715093411505
Test Loss:  0.00012003991287201643
Valid Loss:  0.00025956780882552266
Epoch:  201  	Training Loss: 0.0001784395717550069
Test Loss:  0.00011952145723626018
Valid Loss:  0.00025757448747754097
Epoch:  202  	Training Loss: 0.0001768855145201087
Test Loss:  0.0001183370768558234
Valid Loss:  0.00025552164879627526
Epoch:  203  	Training Loss: 0.00017576207756064832
Test Loss:  0.00011852358875330538
Valid Loss:  0.0002547238254919648
Epoch:  204  	Training Loss: 0.00017473532352596521
Test Loss:  0.00011784919479396194
Valid Loss:   41%|████      | 205/500 [02:30<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:30<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:30<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:36<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:36<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:37<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:37<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:37<01:37,  2.89it/s] 44%|████▍     | 221/500 [02:43<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:43<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:44<02:52,  1.60it/s] 45%|████▌     | 227/500 [02:44<02:06,  2.15it/s] 46%|████▌     | 229/500 [02:44<01:34,  2.85it/s] 46%|████▌     | 231/500 [02:50<05:28,  1.22s/it] 47%|████▋     | 233/500 [02:51<03:53,  1.14it/s] 47%|████▋     | 235/500 [02:51<02:47,  1.58it/s] 47%|████▋     | 237/500 [02:51<02:01,  2.17it/s] 48%|████▊     | 239/500 [02:51<01:29,  2.91it/s] 48%|████▊     | 241/500 [02:57<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:57<03:41,  1.16it/s] 49%|████▉     | 245/500 [02:58<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:58<01:55,  2.20it/s] 50%|████▉     | 249/500 [02:58<01:24,  2.96it/s] 50%|█████     | 251/500 [03:04<04:55,  1.19s/it] 51%|█████     | 253/500 [03:04<03:30,  1.17it/s] 51%|█████     | 255/500 [03:04<02:30,  1.62it/s] 51%|█████▏    | 257/500 [03:05<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:05<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:11<04:43,  1.19s/it] 53%|█████▎    | 263/500 [03:11<03:21,  1.17it/s] 53%|█████▎    | 265/500 [03:11<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:11<01:44,  2.22it/s] 54%|█████▍    | 269/500 [03:12<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:18<04:25,  1.16s/it]0.0002532426151446998
Epoch:  205  	Training Loss: 0.00017377363110426813
Test Loss:  0.00011763711518142372
Valid Loss:  0.00025220296811312437
Epoch:  206  	Training Loss: 0.00017285947978962213
Test Loss:  0.0001171059047919698
Valid Loss:  0.0002509339537937194
Epoch:  207  	Training Loss: 0.00017198531713802367
Test Loss:  0.0001167271620943211
Valid Loss:  0.00024982827017083764
Epoch:  208  	Training Loss: 0.00017113708599936217
Test Loss:  0.00011621748853940517
Valid Loss:  0.00024863186990842223
Epoch:  209  	Training Loss: 0.00017031392781063914
Test Loss:  0.00011575187090784311
Valid Loss:  0.00024749612202867866
Epoch:  210  	Training Loss: 0.00016951040015555918
Test Loss:  0.00011522551358211786
Valid Loss:  0.000246334879193455
Epoch:  211  	Training Loss: 0.00016872730338945985
Test Loss:  0.0001147143921116367
Valid Loss:  0.0002452100452501327
Epoch:  212  	Training Loss: 0.00016796331328805536
Test Loss:  0.00011463199916761369
Valid Loss:  0.0002443891135044396
Epoch:  213  	Training Loss: 0.00016710854833945632
Test Loss:  0.00011413736501708627
Valid Loss:  0.00024333180044777691
Epoch:  214  	Training Loss: 0.0001663252041907981
Test Loss:  0.00011356763570802286
Valid Loss:  0.00024223655054811388
Epoch:  215  	Training Loss: 0.00016555642650928348
Test Loss:  0.00011298948084004223
Valid Loss:  0.00024113894323818386
Epoch:  216  	Training Loss: 0.0001647954632062465
Test Loss:  0.00011242201435379684
Valid Loss:  0.00024005489831324667
Epoch:  217  	Training Loss: 0.00016404356574639678
Test Loss:  0.00011187267955392599
Valid Loss:  0.00023898138897493482
Epoch:  218  	Training Loss: 0.00016330069047398865
Test Loss:  0.00011134105443488806
Valid Loss:  0.0002379273355472833
Epoch:  219  	Training Loss: 0.0001625704171601683
Test Loss:  0.00011081957927672192
Valid Loss:  0.00023688198416493833
Epoch:  220  	Training Loss: 0.00016184663400053978
Test Loss:  0.00011030619498342276
Valid Loss:  0.00023584725568071008
Epoch:  221  	Training Loss: 0.00016112983576022089
Test Loss:  0.00010980026854667813
Valid Loss:  0.00023481996322516352
Epoch:  222  	Training Loss: 0.00016041903290897608
Test Loss:  0.00010911809658864513
Valid Loss:  0.00023361497733276337
Epoch:  223  	Training Loss: 0.00015968520892784
Test Loss:  0.00010860095062525943
Valid Loss:  0.00023252403480000794
Epoch:  224  	Training Loss: 0.00015896710101515055
Test Loss:  0.00010809940431499854
Valid Loss:  0.00023144888109527528
Epoch:  225  	Training Loss: 0.00015825757873244584
Test Loss:  0.00010759969882201403
Valid Loss:  0.0002303818182554096
Epoch:  226  	Training Loss: 0.00015755833010189235
Test Loss:  0.0001071012084139511
Valid Loss:  0.0002293287543579936
Epoch:  227  	Training Loss: 0.00015686964616179466
Test Loss:  0.00010660446423571557
Valid Loss:  0.0002282888162881136
Epoch:  228  	Training Loss: 0.000156190522830002
Test Loss:  0.00010610763274598867
Valid Loss:  0.00022725973394699395
Epoch:  229  	Training Loss: 0.0001555217895656824
Test Loss:  0.00010562265379121527
Valid Loss:  0.0002262523485114798
Epoch:  230  	Training Loss: 0.00015486472693737596
Test Loss:  0.00010513528832234442
Valid Loss:  0.00022525675012730062
Epoch:  231  	Training Loss: 0.0001542145328130573
Test Loss:  0.00010465847299201414
Valid Loss:  0.00022427691146731377
Epoch:  232  	Training Loss: 0.00015357142547145486
Test Loss:  0.00010324048344045877
Valid Loss:  0.00022216742218006402
Epoch:  233  	Training Loss: 0.0001525890256743878
Test Loss:  0.0001026550235110335
Valid Loss:  0.00022087193792685866
Epoch:  234  	Training Loss: 0.00015165780496317893
Test Loss:  0.00010157946235267445
Valid Loss:  0.000219194422243163
Epoch:  235  	Training Loss: 0.000150801963172853
Test Loss:  0.00010090882278745994
Valid Loss:  0.00021792571351397783
Epoch:  236  	Training Loss: 0.00015000948042143136
Test Loss:  0.00010012451093643904
Valid Loss:  0.00021653901785612106
Epoch:  237  	Training Loss: 0.00014922261470928788
Test Loss:  9.949447849066928e-05
Valid Loss:  0.0002152922679670155
Epoch:  238  	Training Loss: 0.00014847838610876352
Test Loss:  9.894003596855327e-05
Valid Loss:  0.00021418659889604896
Epoch:  239  	Training Loss: 0.00014776592433918267
Test Loss:  9.837612742558122e-05
Valid Loss:  0.00021304785332176834
Epoch:  240  	Training Loss: 0.0001470811985200271
Test Loss:  9.784058784134686e-05
Valid Loss:  0.00021199039474595338
Epoch:  241  	Training Loss: 0.0001464197994209826
Test Loss:  9.733227489050478e-05
Valid Loss:  0.00021096999989822507
Epoch:  242  	Training Loss: 0.00014577232650481164
Test Loss:  9.795006189960986e-05
Valid Loss:  0.00021054140233900398
Epoch:  243  	Training Loss: 0.0001450430427212268
Test Loss:  9.789640898816288e-05
Valid Loss:  0.00020985346054658294
Epoch:  244  	Training Loss: 0.00014445578563027084
Test Loss:  9.77308809524402e-05
Valid Loss:  0.00020914518972858787
Epoch:  245  	Training Loss: 0.00014391151489689946
Test Loss:  9.75339935394004e-05
Valid Loss:  0.00020845199469476938
Epoch:  246  	Training Loss: 0.00014340030611492693
Test Loss:  9.731363388709724e-05
Valid Loss:  0.00020777246390935034
Epoch:  247  	Training Loss: 0.00014291222032625228
Test Loss:  9.707508434075862e-05
Valid Loss:  0.0002070999180432409
Epoch:  248  	Training Loss: 0.00014244214980863035
Test Loss:  9.681866504251957e-05
Valid Loss:  0.00020643320749513805
Epoch:  249  	Training Loss: 0.0001419878681190312
Test Loss:  9.654992027208209e-05
Valid Loss:  0.0002057827077805996
Epoch:  250  	Training Loss: 0.00014154729433357716
Test Loss:  9.62731137406081e-05
Valid Loss:  0.00020514358766376972
Epoch:  251  	Training Loss: 0.00014111831842456013
Test Loss:  9.599412442184985e-05
Valid Loss:  0.0002045154251391068
Epoch:  252  	Training Loss: 0.00014070028555579484
Test Loss:  9.554007556289434e-05
Valid Loss:  0.00020388580742292106
Epoch:  253  	Training Loss: 0.00014034993364475667
Test Loss:  9.532026888336986e-05
Valid Loss:  0.0002033995115198195
Epoch:  254  	Training Loss: 0.00014002088573761284
Test Loss:  9.515875717625022e-05
Valid Loss:  0.000202951516257599
Epoch:  255  	Training Loss: 0.00013969902647659183
Test Loss:  9.501496970187873e-05
Valid Loss:  0.0002025167632382363
Epoch:  256  	Training Loss: 0.0001393829588778317
Test Loss:  9.487704664934427e-05
Valid Loss:  0.00020209146896377206
Epoch:  257  	Training Loss: 0.00013907185348216444
Test Loss:  9.474341641180217e-05
Valid Loss:  0.0002016735088545829
Epoch:  258  	Training Loss: 0.00013876365846954286
Test Loss:  9.461004810873419e-05
Valid Loss:  0.00020126027811784297
Epoch:  259  	Training Loss: 0.0001384580391459167
Test Loss:  9.44784696912393e-05
Valid Loss:  0.00020084864809177816
Epoch:  260  	Training Loss: 0.00013815885176882148
Test Loss:  9.434843377675861e-05
Valid Loss:  0.00020044557459186763
Epoch:  261  	Training Loss: 0.00013786531053483486
Test Loss:  9.422069706488401e-05
Valid Loss:  0.00020004523685202003
Epoch:  262  	Training Loss: 0.0001375741121592
Test Loss:  9.46323198149912e-05
Valid Loss:  0.00019986370170954615
Epoch:  263  	Training Loss: 0.0001373130944557488
Test Loss:  9.486732596997172e-05
Valid Loss:  0.0001996978826355189
Epoch:  264  	Training Loss: 0.00013715005479753017
Test Loss:  9.503243927611038e-05
Valid Loss:  0.00019956118194386363
Epoch:  265  	Training Loss: 0.00013703855802305043
Test Loss:  9.516524733044207e-05
Valid Loss:  0.00019945751409977674
Epoch:  266  	Training Loss: 0.0001369568199152127
Test Loss:  9.529406088404357e-05
Valid Loss:  0.00019938383775297552
Epoch:  267  	Training Loss: 0.00013689123443327844
Test Loss:  9.539126040181145e-05
Valid Loss:  0.00019931752467527986
Epoch:  268  	Training Loss: 0.00013684033183380961
Test Loss:  9.546606452204287e-05
Valid Loss:  0.00019925688684452325
Epoch:  269  	Training Loss: 0.00013680121628567576
Test Loss:  9.551939001539722e-05
Valid Loss:  0.0001991984318010509
Epoch:  270  	Training Loss: 0.00013676899834536016
Test Loss:  9.555404540151358e-05
Valid Loss:  0.0001991424651350826
Epoch:  271  	Training Loss: 0.0001367416261928156
Test Loss:  9.5571085694246e-05
Valid Loss:  0.00019908568356186152
 55%|█████▍    | 273/500 [03:18<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:18<02:15,  1.66it/s] 55%|█████▌    | 277/500 [03:18<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:18<01:12,  3.04it/s] 56%|█████▌    | 281/500 [03:24<04:13,  1.16s/it] 57%|█████▋    | 283/500 [03:25<03:00,  1.20it/s] 57%|█████▋    | 285/500 [03:25<02:09,  1.67it/s] 57%|█████▋    | 287/500 [03:25<01:33,  2.27it/s] 58%|█████▊    | 289/500 [03:25<01:09,  3.06it/s] 58%|█████▊    | 291/500 [03:31<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:31<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:32<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:32<01:30,  2.23it/s] 60%|█████▉    | 299/500 [03:32<01:06,  3.01it/s] 60%|██████    | 301/500 [03:38<03:57,  1.19s/it] 61%|██████    | 303/500 [03:38<02:48,  1.17it/s] 61%|██████    | 305/500 [03:39<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:39<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:39<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:45<03:47,  1.20s/it] 63%|██████▎   | 313/500 [03:45<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:46<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:46<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:46<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:52<03:28,  1.16s/it] 65%|██████▍   | 323/500 [03:52<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:52<01:45,  1.66it/s] 65%|██████▌   | 327/500 [03:52<01:16,  2.26it/s] 66%|██████▌   | 329/500 [03:52<00:56,  3.05it/s] 66%|██████▌   | 331/500 [03:59<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:59<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:59<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:59<01:12,  2.25it/s]Epoch:  272  	Training Loss: 0.00013671768829226494
Test Loss:  9.503255569143221e-05
Valid Loss:  0.00019844455528073013
Epoch:  273  	Training Loss: 0.00013626314466819167
Test Loss:  9.435111132916063e-05
Valid Loss:  0.00019784164032898843
Epoch:  274  	Training Loss: 0.0001359650050289929
Test Loss:  9.380904521094635e-05
Valid Loss:  0.00019745560712181032
Epoch:  275  	Training Loss: 0.00013578563812188804
Test Loss:  9.339132520835847e-05
Valid Loss:  0.00019716579117812216
Epoch:  276  	Training Loss: 0.00013566180132329464
Test Loss:  9.307668369729072e-05
Valid Loss:  0.00019693704962264746
Epoch:  277  	Training Loss: 0.0001355767308268696
Test Loss:  9.282634709961712e-05
Valid Loss:  0.00019674989744089544
Epoch:  278  	Training Loss: 0.00013550298172049224
Test Loss:  9.26224747672677e-05
Valid Loss:  0.00019658173550851643
Epoch:  279  	Training Loss: 0.0001354437117697671
Test Loss:  9.24577034311369e-05
Valid Loss:  0.0001964422408491373
Epoch:  280  	Training Loss: 0.0001353866682620719
Test Loss:  9.22983163036406e-05
Valid Loss:  0.00019630658789537847
Epoch:  281  	Training Loss: 0.00013533048331737518
Test Loss:  9.21438549994491e-05
Valid Loss:  0.00019618243095465004
Epoch:  282  	Training Loss: 0.000135278984089382
Test Loss:  9.168584801955149e-05
Valid Loss:  0.00019494330626912415
Epoch:  283  	Training Loss: 0.00013423943892121315
Test Loss:  9.082519682124257e-05
Valid Loss:  0.00019366550259292126
Epoch:  284  	Training Loss: 0.0001334621338173747
Test Loss:  9.006276377476752e-05
Valid Loss:  0.00019250722834840417
Epoch:  285  	Training Loss: 0.00013277931429911405
Test Loss:  8.94109471119009e-05
Valid Loss:  0.00019144057296216488
Epoch:  286  	Training Loss: 0.0001321649906458333
Test Loss:  8.879753295332193e-05
Valid Loss:  0.000190429127542302
Epoch:  287  	Training Loss: 0.0001316018169745803
Test Loss:  8.822025847621262e-05
Valid Loss:  0.00018949297373183072
Epoch:  288  	Training Loss: 0.00013106543337926269
Test Loss:  8.768248517299071e-05
Valid Loss:  0.0001885925594251603
Epoch:  289  	Training Loss: 0.0001305424520978704
Test Loss:  8.71906231623143e-05
Valid Loss:  0.0001877402828540653
Epoch:  290  	Training Loss: 0.00013004595530219376
Test Loss:  8.674633136251941e-05
Valid Loss:  0.00018693091988097876
Epoch:  291  	Training Loss: 0.00012956857972312719
Test Loss:  8.634172263555229e-05
Valid Loss:  0.00018616061424836516
Epoch:  292  	Training Loss: 0.00012910744408145547
Test Loss:  8.654383418615907e-05
Valid Loss:  0.0001853109715739265
Epoch:  293  	Training Loss: 0.00012834493827540427
Test Loss:  8.612270175945014e-05
Valid Loss:  0.0001842757046688348
Epoch:  294  	Training Loss: 0.00012764037819579244
Test Loss:  8.573670493206009e-05
Valid Loss:  0.00018326476856600493
Epoch:  295  	Training Loss: 0.00012695380428340286
Test Loss:  8.533500658813864e-05
Valid Loss:  0.0001822581107262522
Epoch:  296  	Training Loss: 0.0001262715959455818
Test Loss:  8.4915358456783e-05
Valid Loss:  0.0001812353148125112
Epoch:  297  	Training Loss: 0.00012558733578771353
Test Loss:  8.448355947621167e-05
Valid Loss:  0.00018022069707512856
Epoch:  298  	Training Loss: 0.00012491611414588988
Test Loss:  8.405606058659032e-05
Valid Loss:  0.0001792222901713103
Epoch:  299  	Training Loss: 0.00012425548629835248
Test Loss:  8.36285762488842e-05
Valid Loss:  0.00017823619418777525
Epoch:  300  	Training Loss: 0.00012360583059489727
Test Loss:  8.320809865836054e-05
Valid Loss:  0.0001772656396497041
Epoch:  301  	Training Loss: 0.00012296807835809886
Test Loss:  8.27965050120838e-05
Valid Loss:  0.00017631133960094303
Epoch:  302  	Training Loss: 0.0001223424478666857
Test Loss:  8.104302833089605e-05
Valid Loss:  0.0001746605703374371
Epoch:  303  	Training Loss: 0.00012162649363745004
Test Loss:  8.176891424227506e-05
Valid Loss:  0.00017414383182767779
Epoch:  304  	Training Loss: 0.00012094431440345943
Test Loss:  8.027754665818065e-05
Valid Loss:  0.00017267660587094724
Epoch:  305  	Training Loss: 0.00012029144272673875
Test Loss:  8.09243501862511e-05
Valid Loss:  0.00017215957632288337
Epoch:  306  	Training Loss: 0.00011967179307248443
Test Loss:  7.96162203187123e-05
Valid Loss:  0.0001708330528344959
Epoch:  307  	Training Loss: 0.00011907564476132393
Test Loss:  8.016187348403037e-05
Valid Loss:  0.00017031439347192645
Epoch:  308  	Training Loss: 0.00011850059672724456
Test Loss:  7.89819605415687e-05
Valid Loss:  0.00016907823737710714
Epoch:  309  	Training Loss: 0.00011792608711402863
Test Loss:  7.940239447634667e-05
Valid Loss:  0.00016851199325174093
Epoch:  310  	Training Loss: 0.00011736561282305047
Test Loss:  7.836434087948874e-05
Valid Loss:  0.00016738686827011406
Epoch:  311  	Training Loss: 0.00011682388139888644
Test Loss:  7.870813715271652e-05
Valid Loss:  0.00016682609566487372
Epoch:  312  	Training Loss: 0.0001162987609859556
Test Loss:  7.88876714068465e-05
Valid Loss:  0.00016606233839411288
Epoch:  313  	Training Loss: 0.00011579765850910917
Test Loss:  7.891295535955578e-05
Valid Loss:  0.0001654891821090132
Epoch:  314  	Training Loss: 0.00011538685066625476
Test Loss:  7.882685167714953e-05
Valid Loss:  0.0001649575715418905
Epoch:  315  	Training Loss: 0.00011500760592753068
Test Loss:  7.869786350056529e-05
Valid Loss:  0.00016442700871266425
Epoch:  316  	Training Loss: 0.00011463920236565173
Test Loss:  7.85534648457542e-05
Valid Loss:  0.0001639053225517273
Epoch:  317  	Training Loss: 0.0001142851760960184
Test Loss:  7.83987925387919e-05
Valid Loss:  0.00016338194836862385
Epoch:  318  	Training Loss: 0.00011394095054129139
Test Loss:  7.826024375390261e-05
Valid Loss:  0.0001628964819246903
Epoch:  319  	Training Loss: 0.00011360760254319757
Test Loss:  7.808150257915258e-05
Valid Loss:  0.00016238016542047262
Epoch:  320  	Training Loss: 0.00011327979154884815
Test Loss:  7.793853001203388e-05
Valid Loss:  0.0001619075337657705
Epoch:  321  	Training Loss: 0.000112958783574868
Test Loss:  7.77699751779437e-05
Valid Loss:  0.0001614177890587598
Epoch:  322  	Training Loss: 0.00011264417844358832
Test Loss:  7.647090387763456e-05
Valid Loss:  0.000159947550855577
Epoch:  323  	Training Loss: 0.0001118471918744035
Test Loss:  7.568005821667612e-05
Valid Loss:  0.00015877207624725997
Epoch:  324  	Training Loss: 0.00011117113172076643
Test Loss:  7.510349678341299e-05
Valid Loss:  0.0001577859657118097
Epoch:  325  	Training Loss: 0.00011057073425035924
Test Loss:  7.462167559424415e-05
Valid Loss:  0.00015689010615460575
Epoch:  326  	Training Loss: 0.00011000307858921587
Test Loss:  7.42254633223638e-05
Valid Loss:  0.0001560527307447046
Epoch:  327  	Training Loss: 0.00010946382826659828
Test Loss:  7.393264240818098e-05
Valid Loss:  0.00015528372023254633
Epoch:  328  	Training Loss: 0.00010894262959482148
Test Loss:  7.366135832853615e-05
Valid Loss:  0.0001545393606647849
Epoch:  329  	Training Loss: 0.00010843074414879084
Test Loss:  7.337994611589238e-05
Valid Loss:  0.00015380233526229858
Epoch:  330  	Training Loss: 0.00010792746616061777
Test Loss:  7.313226524274796e-05
Valid Loss:  0.00015308416914194822
Epoch:  331  	Training Loss: 0.0001074340398190543
Test Loss:  7.289570203283802e-05
Valid Loss:  0.00015238116611726582
Epoch:  332  	Training Loss: 0.00010694921365939081
Test Loss:  7.288223423529416e-05
Valid Loss:  0.00015158885798882693
Epoch:  333  	Training Loss: 0.0001063272065948695
Test Loss:  7.276186806848273e-05
Valid Loss:  0.0001508436253061518
Epoch:  334  	Training Loss: 0.00010577037755865604
Test Loss:  7.257526158355176e-05
Valid Loss:  0.00015009379421826452
Epoch:  335  	Training Loss: 0.0001052453662850894
Test Loss:  7.232459756778553e-05
Valid Loss:  0.00014934473438188434
Epoch:  336  	Training Loss: 0.00010474000737303868
Test Loss:  7.206507143564522e-05
Valid Loss:  0.00014860778173897415
Epoch:  337  	Training Loss: 0.00010424906940897927
Test Loss:  7.179409294622019e-05
Valid Loss:  0.00014788363478146493
Epoch:  338  	Training Loss: 0.00010376992577221245
Test Loss:  7.151167665142566e-05
Valid Loss:  0.0001471721043344587
Epoch:  339  	Training Loss: 0.00010330200893804431
Test Loss:   68%|██████▊   | 339/500 [03:59<00:53,  3.03it/s] 68%|██████▊   | 341/500 [04:05<03:05,  1.17s/it] 69%|██████▊   | 343/500 [04:06<02:12,  1.19it/s] 69%|██████▉   | 345/500 [04:06<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:06<01:09,  2.19it/s] 70%|██████▉   | 349/500 [04:06<00:51,  2.91it/s] 70%|███████   | 351/500 [04:12<02:55,  1.18s/it] 71%|███████   | 353/500 [04:13<02:04,  1.18it/s] 71%|███████   | 355/500 [04:13<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:13<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:13<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:19<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:19<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:20<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:20<01:01,  2.17it/s] 74%|███████▍  | 369/500 [04:20<00:45,  2.87it/s] 74%|███████▍  | 371/500 [04:26<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:26<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:27<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:27<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:27<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:33<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:33<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:33<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:34<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:34<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:40<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:40<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:40<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:40<00:46,  2.19it/s] 80%|███████▉  | 399/500 [04:41<00:34,  2.94it/s] 80%|████████  | 401/500 [04:47<01:57,  1.19s/it] 81%|████████  | 403/500 [04:47<01:23,  1.17it/s] 81%|████████  | 405/500 [04:47<00:58,  1.62it/s]7.122815441107377e-05
Valid Loss:  0.0001464750966988504
Epoch:  340  	Training Loss: 0.00010284214658895507
Test Loss:  7.093826570780948e-05
Valid Loss:  0.00014578879927285016
Epoch:  341  	Training Loss: 0.00010239279072266072
Test Loss:  7.06450518919155e-05
Valid Loss:  0.0001451147545594722
Epoch:  342  	Training Loss: 0.00010195351933361962
Test Loss:  7.07487779436633e-05
Valid Loss:  0.00014486008149106055
Epoch:  343  	Training Loss: 0.00010173427290283144
Test Loss:  7.075149187585339e-05
Valid Loss:  0.00014459813246503472
Epoch:  344  	Training Loss: 0.00010152572940569371
Test Loss:  7.070852734614164e-05
Valid Loss:  0.00014433365140575916
Epoch:  345  	Training Loss: 0.00010132225725101307
Test Loss:  7.064615783747286e-05
Valid Loss:  0.00014406844275072217
Epoch:  346  	Training Loss: 0.00010112213203683496
Test Loss:  7.057324546622112e-05
Valid Loss:  0.00014380645006895065
Epoch:  347  	Training Loss: 0.00010092483717016876
Test Loss:  7.049640407785773e-05
Valid Loss:  0.00014354477752931416
Epoch:  348  	Training Loss: 0.00010073004523292184
Test Loss:  7.041591743472964e-05
Valid Loss:  0.00014328595716506243
Epoch:  349  	Training Loss: 0.00010053779988083988
Test Loss:  7.033368456177413e-05
Valid Loss:  0.00014302835916168988
Epoch:  350  	Training Loss: 0.00010034762090072036
Test Loss:  7.024791557341814e-05
Valid Loss:  0.00014277358422987163
Epoch:  351  	Training Loss: 0.0001001594791887328
Test Loss:  7.016144809313118e-05
Valid Loss:  0.00014251895481720567
Epoch:  352  	Training Loss: 9.99726980808191e-05
Test Loss:  6.961243343539536e-05
Valid Loss:  0.00014210167864803225
Epoch:  353  	Training Loss: 9.975432476494461e-05
Test Loss:  6.94847694830969e-05
Valid Loss:  0.00014180254947859794
Epoch:  354  	Training Loss: 9.956295980373397e-05
Test Loss:  6.935571582289413e-05
Valid Loss:  0.00014151052164379507
Epoch:  355  	Training Loss: 9.937818686012179e-05
Test Loss:  6.922311149537563e-05
Valid Loss:  0.00014122443099040538
Epoch:  356  	Training Loss: 9.919879084918648e-05
Test Loss:  6.908746581757441e-05
Valid Loss:  0.0001409417891409248
Epoch:  357  	Training Loss: 9.902338206302375e-05
Test Loss:  6.894570833537728e-05
Valid Loss:  0.00014066227595321834
Epoch:  358  	Training Loss: 9.885080362437293e-05
Test Loss:  6.880135333631188e-05
Valid Loss:  0.00014038517838343978
Epoch:  359  	Training Loss: 9.868118650047109e-05
Test Loss:  6.865874456707388e-05
Valid Loss:  0.00014011297025717795
Epoch:  360  	Training Loss: 9.851461072685197e-05
Test Loss:  6.851153011666611e-05
Valid Loss:  0.0001398433232679963
Epoch:  361  	Training Loss: 9.834996308200061e-05
Test Loss:  6.836248212493956e-05
Valid Loss:  0.00013957457849755883
Epoch:  362  	Training Loss: 9.818775288295001e-05
Test Loss:  6.861452129669487e-05
Valid Loss:  0.00013912047143094242
Epoch:  363  	Training Loss: 9.785177826415747e-05
Test Loss:  6.851115904282779e-05
Valid Loss:  0.00013879247126169503
Epoch:  364  	Training Loss: 9.764906280906871e-05
Test Loss:  6.832914368715137e-05
Valid Loss:  0.00013849951210431755
Epoch:  365  	Training Loss: 9.747153671924025e-05
Test Loss:  6.814891821704805e-05
Valid Loss:  0.00013822548498865217
Epoch:  366  	Training Loss: 9.730465535540134e-05
Test Loss:  6.798638787586242e-05
Valid Loss:  0.00013796308485325426
Epoch:  367  	Training Loss: 9.714288171380758e-05
Test Loss:  6.783932622056454e-05
Valid Loss:  0.00013770998339168727
Epoch:  368  	Training Loss: 9.698378562461585e-05
Test Loss:  6.770562322344631e-05
Valid Loss:  0.00013746257172897458
Epoch:  369  	Training Loss: 9.682661038823426e-05
Test Loss:  6.75797273288481e-05
Valid Loss:  0.0001372189581161365
Epoch:  370  	Training Loss: 9.667103586252779e-05
Test Loss:  6.745931750629097e-05
Valid Loss:  0.00013697845861315727
Epoch:  371  	Training Loss: 9.651618893258274e-05
Test Loss:  6.734351336490363e-05
Valid Loss:  0.00013674006913788617
Epoch:  372  	Training Loss: 9.636166214477271e-05
Test Loss:  6.552402919624001e-05
Valid Loss:  0.00013566353300120682
Epoch:  373  	Training Loss: 9.575291915098205e-05
Test Loss:  6.553831190103665e-05
Valid Loss:  0.00013500580098479986
Epoch:  374  	Training Loss: 9.527638030704111e-05
Test Loss:  6.507793295895681e-05
Valid Loss:  0.00013436896551866084
Epoch:  375  	Training Loss: 9.486953786108643e-05
Test Loss:  6.480033334810287e-05
Valid Loss:  0.00013385283818934113
Epoch:  376  	Training Loss: 9.452160156797618e-05
Test Loss:  6.44880929030478e-05
Valid Loss:  0.0001333676336798817
Epoch:  377  	Training Loss: 9.421975119039416e-05
Test Loss:  6.426477921195328e-05
Valid Loss:  0.0001329376536887139
Epoch:  378  	Training Loss: 9.396370296599343e-05
Test Loss:  6.403120642062277e-05
Valid Loss:  0.00013253699580673128
Epoch:  379  	Training Loss: 9.372885688208044e-05
Test Loss:  6.38419805909507e-05
Valid Loss:  0.0001321909367106855
Epoch:  380  	Training Loss: 9.351439075544477e-05
Test Loss:  6.365440640365705e-05
Valid Loss:  0.00013188115553930402
Epoch:  381  	Training Loss: 9.331176988780499e-05
Test Loss:  6.350579496938735e-05
Valid Loss:  0.00013162389222998172
Epoch:  382  	Training Loss: 9.312464680988342e-05
Test Loss:  6.350086187012494e-05
Valid Loss:  0.00013148515427019447
Epoch:  383  	Training Loss: 9.304317063651979e-05
Test Loss:  6.346921873046085e-05
Valid Loss:  0.00013134807522874326
Epoch:  384  	Training Loss: 9.296698408434168e-05
Test Loss:  6.343323912005872e-05
Valid Loss:  0.00013121889787726104
Epoch:  385  	Training Loss: 9.28948720684275e-05
Test Loss:  6.339231913443655e-05
Valid Loss:  0.00013109369319863617
Epoch:  386  	Training Loss: 9.282555402023718e-05
Test Loss:  6.334549834718928e-05
Valid Loss:  0.00013097198097966611
Epoch:  387  	Training Loss: 9.27582586882636e-05
Test Loss:  6.329438474494964e-05
Valid Loss:  0.0001308532664552331
Epoch:  388  	Training Loss: 9.26932116271928e-05
Test Loss:  6.324027344817296e-05
Valid Loss:  0.0001307383645325899
Epoch:  389  	Training Loss: 9.263027459383011e-05
Test Loss:  6.318427040241659e-05
Valid Loss:  0.0001306258054682985
Epoch:  390  	Training Loss: 9.257002966478467e-05
Test Loss:  6.312664481811225e-05
Valid Loss:  0.00013051676796749234
Epoch:  391  	Training Loss: 9.251091978512704e-05
Test Loss:  6.306679279077798e-05
Valid Loss:  0.00013040969497524202
Epoch:  392  	Training Loss: 9.2452515673358e-05
Test Loss:  6.281051901169121e-05
Valid Loss:  0.00012963710469193757
Epoch:  393  	Training Loss: 9.188961848849431e-05
Test Loss:  6.177881732583046e-05
Valid Loss:  0.00012892798986285925
Epoch:  394  	Training Loss: 9.14768606889993e-05
Test Loss:  6.12902658758685e-05
Valid Loss:  0.0001283939927816391
Epoch:  395  	Training Loss: 9.114420390687883e-05
Test Loss:  6.0756785387638956e-05
Valid Loss:  0.00012791884364560246
Epoch:  396  	Training Loss: 9.085668716579676e-05
Test Loss:  6.0345366364344954e-05
Valid Loss:  0.0001274982059840113
Epoch:  397  	Training Loss: 9.060435695573688e-05
Test Loss:  5.998066990287043e-05
Valid Loss:  0.00012711439921986312
Epoch:  398  	Training Loss: 9.037739073392004e-05
Test Loss:  5.9664576838258654e-05
Valid Loss:  0.0001267643820028752
Epoch:  399  	Training Loss: 9.017283446155488e-05
Test Loss:  5.940561095485464e-05
Valid Loss:  0.00012644098023883998
Epoch:  400  	Training Loss: 8.998093835543841e-05
Test Loss:  5.9177207731409e-05
Valid Loss:  0.00012613204307854176
Epoch:  401  	Training Loss: 8.979602716863155e-05
Test Loss:  5.8966536016669124e-05
Valid Loss:  0.0001258343836525455
Epoch:  402  	Training Loss: 8.96158890100196e-05
Test Loss:  5.9148242144146934e-05
Valid Loss:  0.00012557832815218717
Epoch:  403  	Training Loss: 8.942308340920135e-05
Test Loss:  5.9116282500326633e-05
Valid Loss:  0.00012532825348898768
Epoch:  404  	Training Loss: 8.924370922613889e-05
Test Loss:  5.907641025260091e-05
Valid Loss:  0.00012508040526881814
Epoch:  405  	Training Loss: 8.906874427339062e-05
Test Loss:  5.9025565860792994e-05
Valid Loss:  0.00012483361933846027
Epoch:  406  	Training Loss: 8.889756281860173e-05
Test Loss:  5.896455331821926e-05
Valid Loss:  0.00012459041317924857
 81%|████████▏ | 407/500 [04:47<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:48<00:31,  2.91it/s] 82%|████████▏ | 411/500 [04:54<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:54<01:15,  1.15it/s] 83%|████████▎ | 415/500 [04:54<00:53,  1.58it/s] 83%|████████▎ | 417/500 [04:54<00:38,  2.16it/s] 84%|████████▍ | 419/500 [04:55<00:27,  2.91it/s] 84%|████████▍ | 421/500 [05:01<01:34,  1.20s/it] 85%|████████▍ | 423/500 [05:01<01:06,  1.15it/s] 85%|████████▌ | 425/500 [05:01<00:46,  1.60it/s] 85%|████████▌ | 427/500 [05:01<00:33,  2.18it/s] 86%|████████▌ | 429/500 [05:02<00:24,  2.94it/s] 86%|████████▌ | 431/500 [05:08<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:08<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:08<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:08<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:08<00:20,  2.91it/s] 88%|████████▊ | 441/500 [05:15<01:11,  1.20s/it] 89%|████████▊ | 443/500 [05:15<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:15<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:15<00:24,  2.13it/s] 90%|████████▉ | 449/500 [05:15<00:18,  2.83it/s] 90%|█████████ | 451/500 [05:22<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:22<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:22<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:22<00:19,  2.19it/s] 92%|█████████▏| 459/500 [05:22<00:13,  2.94it/s] 92%|█████████▏| 461/500 [05:29<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:29<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:29<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:29<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:29<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:35<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:36<00:22,  1.19it/s]Epoch:  407  	Training Loss: 8.872929174685851e-05
Test Loss:  5.890708416700363e-05
Valid Loss:  0.000124348807730712
Epoch:  408  	Training Loss: 8.856355270836502e-05
Test Loss:  5.884327765670605e-05
Valid Loss:  0.00012409628834575415
Epoch:  409  	Training Loss: 8.839975635055453e-05
Test Loss:  5.8774858189281076e-05
Valid Loss:  0.00012384419096633792
Epoch:  410  	Training Loss: 8.823775715427473e-05
Test Loss:  5.870165477972478e-05
Valid Loss:  0.0001235932286363095
Epoch:  411  	Training Loss: 8.80773295648396e-05
Test Loss:  5.8625253586797044e-05
Valid Loss:  0.0001233413495356217
Epoch:  412  	Training Loss: 8.791818981990218e-05
Test Loss:  5.8177116443403065e-05
Valid Loss:  0.00012313132174313068
Epoch:  413  	Training Loss: 8.778893970884383e-05
Test Loss:  5.83015862503089e-05
Valid Loss:  0.00012302125105634332
Epoch:  414  	Training Loss: 8.76961275935173e-05
Test Loss:  5.835830597789027e-05
Valid Loss:  0.0001229193585459143
Epoch:  415  	Training Loss: 8.761720528127626e-05
Test Loss:  5.842349128215574e-05
Valid Loss:  0.00012283024261705577
Epoch:  416  	Training Loss: 8.754976443015039e-05
Test Loss:  5.848576984135434e-05
Valid Loss:  0.00012275343760848045
Epoch:  417  	Training Loss: 8.749201515456662e-05
Test Loss:  5.85476664127782e-05
Valid Loss:  0.0001226855965796858
Epoch:  418  	Training Loss: 8.744206570554525e-05
Test Loss:  5.8606827224139124e-05
Valid Loss:  0.00012262622476555407
Epoch:  419  	Training Loss: 8.739950135350227e-05
Test Loss:  5.8664241805672646e-05
Valid Loss:  0.00012257223716005683
Epoch:  420  	Training Loss: 8.736269955988973e-05
Test Loss:  5.871931716683321e-05
Valid Loss:  0.00012252104352228343
Epoch:  421  	Training Loss: 8.733075810596347e-05
Test Loss:  5.877232615603134e-05
Valid Loss:  0.0001224748557433486
Epoch:  422  	Training Loss: 8.730318950256333e-05
Test Loss:  5.905036596232094e-05
Valid Loss:  0.00012216981849633157
Epoch:  423  	Training Loss: 8.70889489306137e-05
Test Loss:  5.905258876737207e-05
Valid Loss:  0.0001219297046191059
Epoch:  424  	Training Loss: 8.694625284988433e-05
Test Loss:  5.897512528463267e-05
Valid Loss:  0.00012171216076239944
Epoch:  425  	Training Loss: 8.682241605129093e-05
Test Loss:  5.88834700465668e-05
Valid Loss:  0.00012150864495197311
Epoch:  426  	Training Loss: 8.67081034812145e-05
Test Loss:  5.8798628742806613e-05
Valid Loss:  0.00012128844537073746
Epoch:  427  	Training Loss: 8.660011371830478e-05
Test Loss:  5.8700217778095976e-05
Valid Loss:  0.00012107841757824644
Epoch:  428  	Training Loss: 8.649627852719277e-05
Test Loss:  5.8611167332855985e-05
Valid Loss:  0.00012087539653293788
Epoch:  429  	Training Loss: 8.639570296509191e-05
Test Loss:  5.853105176356621e-05
Valid Loss:  0.00012067843636032194
Epoch:  430  	Training Loss: 8.629724470665678e-05
Test Loss:  5.845802661497146e-05
Valid Loss:  0.00012048652570229024
Epoch:  431  	Training Loss: 8.620146400062367e-05
Test Loss:  5.839042569277808e-05
Valid Loss:  0.00012029815115965903
Epoch:  432  	Training Loss: 8.610730583313853e-05
Test Loss:  5.77200589759741e-05
Valid Loss:  0.00011996527609881014
Epoch:  433  	Training Loss: 8.592147787567228e-05
Test Loss:  5.784324821433984e-05
Valid Loss:  0.00011970748892053962
Epoch:  434  	Training Loss: 8.575600077165291e-05
Test Loss:  5.7622492022346705e-05
Valid Loss:  0.00011943876597797498
Epoch:  435  	Training Loss: 8.559969865018502e-05
Test Loss:  5.7536930398782715e-05
Valid Loss:  0.00011918821837753057
Epoch:  436  	Training Loss: 8.544954471290112e-05
Test Loss:  5.738552863476798e-05
Valid Loss:  0.00011893898772541434
Epoch:  437  	Training Loss: 8.530371269444004e-05
Test Loss:  5.725388109567575e-05
Valid Loss:  0.00011870070738950744
Epoch:  438  	Training Loss: 8.51623626658693e-05
Test Loss:  5.7109573390334845e-05
Valid Loss:  0.00011847096175188199
Epoch:  439  	Training Loss: 8.502515265718102e-05
Test Loss:  5.6970922742038965e-05
Valid Loss:  0.00011824605462606996
Epoch:  440  	Training Loss: 8.489024185109884e-05
Test Loss:  5.6827208027243614e-05
Valid Loss:  0.00011802485096268356
Epoch:  441  	Training Loss: 8.475733920931816e-05
Test Loss:  5.668305675499141e-05
Valid Loss:  0.0001178065940621309
Epoch:  442  	Training Loss: 8.462681580567732e-05
Test Loss:  5.665604112436995e-05
Valid Loss:  0.00011742689821403474
Epoch:  443  	Training Loss: 8.441420504823327e-05
Test Loss:  5.63261128263548e-05
Valid Loss:  0.00011707909288816154
Epoch:  444  	Training Loss: 8.422421524301171e-05
Test Loss:  5.6117860367521644e-05
Valid Loss:  0.00011673933477140963
Epoch:  445  	Training Loss: 8.403790707234293e-05
Test Loss:  5.587376654148102e-05
Valid Loss:  0.00011641568562481552
Epoch:  446  	Training Loss: 8.386235276702791e-05
Test Loss:  5.566325125982985e-05
Valid Loss:  0.00011610590445343405
Epoch:  447  	Training Loss: 8.369376155314967e-05
Test Loss:  5.547223554458469e-05
Valid Loss:  0.00011580548016354442
Epoch:  448  	Training Loss: 8.353046723641455e-05
Test Loss:  5.529772533918731e-05
Valid Loss:  0.00011551464558579028
Epoch:  449  	Training Loss: 8.337135659530759e-05
Test Loss:  5.513294308912009e-05
Valid Loss:  0.00011523142165970057
Epoch:  450  	Training Loss: 8.321506902575493e-05
Test Loss:  5.4977514082565904e-05
Valid Loss:  0.00011495246144477278
Epoch:  451  	Training Loss: 8.306156087201089e-05
Test Loss:  5.4829368309583515e-05
Valid Loss:  0.00011467918375274166
Epoch:  452  	Training Loss: 8.291045378427953e-05
Test Loss:  5.4344658565241843e-05
Valid Loss:  0.00011435294436523691
Epoch:  453  	Training Loss: 8.265627548098564e-05
Test Loss:  5.434801278170198e-05
Valid Loss:  0.00011406923294998705
Epoch:  454  	Training Loss: 8.241715840995312e-05
Test Loss:  5.4226748034125194e-05
Valid Loss:  0.00011378371709724888
Epoch:  455  	Training Loss: 8.218415314331651e-05
Test Loss:  5.414060433395207e-05
Valid Loss:  0.00011350803833920509
Epoch:  456  	Training Loss: 8.195963164325804e-05
Test Loss:  5.4075149819254875e-05
Valid Loss:  0.00011323907529003918
Epoch:  457  	Training Loss: 8.174344839062542e-05
Test Loss:  5.400286318035796e-05
Valid Loss:  0.00011298292520223185
Epoch:  458  	Training Loss: 8.153053204296157e-05
Test Loss:  5.392845923779532e-05
Valid Loss:  0.00011274583812337369
Epoch:  459  	Training Loss: 8.132696530083194e-05
Test Loss:  5.385162148741074e-05
Valid Loss:  0.00011251564137637615
Epoch:  460  	Training Loss: 8.112972136586905e-05
Test Loss:  5.379487993195653e-05
Valid Loss:  0.00011229146912228316
Epoch:  461  	Training Loss: 8.093965880107135e-05
Test Loss:  5.3724721510661766e-05
Valid Loss:  0.0001120746455853805
Epoch:  462  	Training Loss: 8.075233199633658e-05
Test Loss:  5.386979319155216e-05
Valid Loss:  0.00011166978947585449
Epoch:  463  	Training Loss: 8.050578617257997e-05
Test Loss:  5.3399726311909035e-05
Valid Loss:  0.00011128377809654921
Epoch:  464  	Training Loss: 8.027185685932636e-05
Test Loss:  5.330907879397273e-05
Valid Loss:  0.00011090970656368881
Epoch:  465  	Training Loss: 8.004764094948769e-05
Test Loss:  5.303944635670632e-05
Valid Loss:  0.00011054935748688877
Epoch:  466  	Training Loss: 7.983050454640761e-05
Test Loss:  5.288952888804488e-05
Valid Loss:  0.00011019888188457116
Epoch:  467  	Training Loss: 7.961888331919909e-05
Test Loss:  5.268560562399216e-05
Valid Loss:  0.00010986003326252103
Epoch:  468  	Training Loss: 7.941431977087632e-05
Test Loss:  5.253279596217908e-05
Valid Loss:  0.0001095245243050158
Epoch:  469  	Training Loss: 7.921145879663527e-05
Test Loss:  5.23562848684378e-05
Valid Loss:  0.0001091934900614433
Epoch:  470  	Training Loss: 7.901168282842264e-05
Test Loss:  5.2195297030266374e-05
Valid Loss:  0.00010886767995543778
Epoch:  471  	Training Loss: 7.881678902776912e-05
Test Loss:  5.20363864779938e-05
Valid Loss:  0.00010854731954168528
Epoch:  472  	Training Loss: 7.862423080950975e-05
Test Loss:  5.191995296627283e-05
Valid Loss:  0.0001082785747712478
Epoch:  473  	Training Loss: 7.844972424209118e-05
Test Loss:  5.1803152018692344e-05
Valid Loss:  0.00010801589087350294
Epoch:  474  	Training Loss: 7.827697845641524e-05
Test Loss:  5.1689596148207784e-05
 95%|█████████▌| 475/500 [05:36<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:36<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:36<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:42<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:43<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:43<00:09,  1.58it/s] 97%|█████████▋| 487/500 [05:43<00:06,  2.14it/s] 98%|█████████▊| 489/500 [05:43<00:03,  2.83it/s] 98%|█████████▊| 491/500 [05:49<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:50<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:50<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:50<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:50<00:00,  2.97it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
Valid Loss:  0.00010775412374641746
Epoch:  475  	Training Loss: 7.810389070073143e-05
Test Loss:  5.1582966989371926e-05
Valid Loss:  0.00010749501234386116
Epoch:  476  	Training Loss: 7.793112308718264e-05
Test Loss:  5.1478105888236314e-05
Valid Loss:  0.0001072371524060145
Epoch:  477  	Training Loss: 7.775840640533715e-05
Test Loss:  5.13779632456135e-05
Valid Loss:  0.00010697582183638588
Epoch:  478  	Training Loss: 7.758682477287948e-05
Test Loss:  5.1280476327519864e-05
Valid Loss:  0.0001067164121195674
Epoch:  479  	Training Loss: 7.741669833194464e-05
Test Loss:  5.118321132613346e-05
Valid Loss:  0.00010645743168424815
Epoch:  480  	Training Loss: 7.724507304374129e-05
Test Loss:  5.108954064780846e-05
Valid Loss:  0.00010620067769195884
Epoch:  481  	Training Loss: 7.707493205089122e-05
Test Loss:  5.099800546304323e-05
Valid Loss:  0.00010594532068353146
Epoch:  482  	Training Loss: 7.690626080147922e-05
Test Loss:  5.113510269438848e-05
Valid Loss:  0.00010547929559834301
Epoch:  483  	Training Loss: 7.666509918635711e-05
Test Loss:  5.115709063829854e-05
Valid Loss:  0.00010512757580727339
Epoch:  484  	Training Loss: 7.646471203770489e-05
Test Loss:  5.118488479638472e-05
Valid Loss:  0.00010481810022611171
Epoch:  485  	Training Loss: 7.628889579791576e-05
Test Loss:  5.120683999848552e-05
Valid Loss:  0.00010452085552969947
Epoch:  486  	Training Loss: 7.612322951899841e-05
Test Loss:  5.120860441820696e-05
Valid Loss:  0.00010424615174997598
Epoch:  487  	Training Loss: 7.597536023240536e-05
Test Loss:  5.119733395986259e-05
Valid Loss:  0.00010399938764749095
Epoch:  488  	Training Loss: 7.583801925648004e-05
Test Loss:  5.1192386308684945e-05
Valid Loss:  0.00010377081343904138
Epoch:  489  	Training Loss: 7.57055968279019e-05
Test Loss:  5.1191524107707664e-05
Valid Loss:  0.00010354964615544304
Epoch:  490  	Training Loss: 7.558010111097246e-05
Test Loss:  5.117841647006571e-05
Valid Loss:  0.00010334818944102153
Epoch:  491  	Training Loss: 7.546042616013438e-05
Test Loss:  5.1176924898754805e-05
Valid Loss:  0.00010314966493751854
Epoch:  492  	Training Loss: 7.534347241744399e-05
Test Loss:  5.0807233492378145e-05
Valid Loss:  0.00010281499271513894
Epoch:  493  	Training Loss: 7.513123273383826e-05
Test Loss:  5.048236926086247e-05
Valid Loss:  0.00010250370542053133
Epoch:  494  	Training Loss: 7.493932935176417e-05
Test Loss:  5.0215632654726505e-05
Valid Loss:  0.00010221915727015585
Epoch:  495  	Training Loss: 7.476159953512251e-05
Test Loss:  4.999291559215635e-05
Valid Loss:  0.00010194385686190799
Epoch:  496  	Training Loss: 7.459011249011382e-05
Test Loss:  4.97788714710623e-05
Valid Loss:  0.00010168450535275042
Epoch:  497  	Training Loss: 7.44248682167381e-05
Test Loss:  4.960480146110058e-05
Valid Loss:  0.00010143213876290247
Epoch:  498  	Training Loss: 7.426519005093724e-05
Test Loss:  4.944081592839211e-05
Valid Loss:  0.0001011892018141225
Epoch:  499  	Training Loss: 7.410746184177697e-05
Test Loss:  4.9284724809695035e-05
Valid Loss:  0.00010095895413542166
Epoch:  500  	Training Loss: 7.395289139822125e-05
Test Loss:  4.91359387524426e-05
Valid Loss:  0.00010073414887301624
seed is  8
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.41it/s]  1%|          | 4/500 [00:00<00:31, 15.96it/s]  1%|          | 6/500 [00:00<00:30, 16.16it/s]  2%|▏         | 8/500 [00:00<00:30, 16.26it/s]  2%|▏         | 10/500 [00:00<00:30, 16.27it/s]  2%|▏         | 12/500 [00:00<00:30, 16.26it/s]  3%|▎         | 14/500 [00:00<00:29, 16.26it/s]  3%|▎         | 16/500 [00:00<00:29, 16.32it/s]  4%|▎         | 18/500 [00:01<00:29, 16.35it/s]  4%|▍         | 20/500 [00:01<00:29, 16.38it/s]  4%|▍         | 22/500 [00:01<00:29, 16.43it/s]  5%|▍         | 24/500 [00:01<00:28, 16.43it/s]  5%|▌         | 26/500 [00:01<00:28, 16.47it/s]  6%|▌         | 28/500 [00:01<00:28, 16.43it/s]  6%|▌         | 30/500 [00:01<00:28, 16.36it/s]  6%|▋         | 32/500 [00:01<00:29, 16.11it/s]  7%|▋         | 34/500 [00:02<00:28, 16.21it/s]  7%|▋         | 36/500 [00:02<00:28, 16.27it/s]  8%|▊         | 38/500 [00:02<00:28, 16.22it/s]  8%|▊         | 40/500 [00:02<00:28, 15.93it/s]  8%|▊         | 42/500 [00:02<00:28, 16.04it/s]  9%|▉         | 44/500 [00:02<00:28, 16.23it/s]  9%|▉         | 46/500 [00:02<00:28, 16.20it/s] 10%|▉         | 48/500 [00:02<00:27, 16.26it/s] 10%|█         | 50/500 [00:03<00:27, 16.31it/s] 10%|█         | 52/500 [00:03<00:27, 16.35it/s] 11%|█         | 54/500 [00:03<00:27, 16.41it/s] 11%|█         | 56/500 [00:03<00:27, 16.35it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.36it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.27it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.34it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.39it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.39it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.41it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.39it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.25it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.19it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.26it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.30it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.36it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.42it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.43it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.44it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.46it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.45it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.28it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.27it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.31it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.40it/s] 20%|██        | 100/500 [00:06<00:24, 16.18it/s] 20%|██        | 102/500 [00:06<00:24, 16.18it/s] 21%|██        | 104/500 [00:06<00:25, 15.78it/s] 21%|██        | 106/500 [00:06<00:24, 15.87it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.71it/s] 22%|██▏       | 110/500 [00:06<00:24, 15.78it/s] 22%|██▏       | 112/500 [00:06<00:24, 15.74it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.77it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.92it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.09it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.22it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.20it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.19it/s]Epoch:  1  	Training Loss: 0.030005238950252533
Test Loss:  41.052764892578125
Valid Loss:  41.094966888427734
Epoch:  2  	Training Loss: 41.24836730957031
Test Loss:  170226192.0
Valid Loss:  169506736.0
Epoch:  3  	Training Loss: 168298864.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.02it/s] 26%|██▌       | 128/500 [00:07<00:24, 15.25it/s] 26%|██▌       | 130/500 [00:08<00:26, 14.18it/s] 26%|██▋       | 132/500 [00:08<00:26, 13.70it/s] 27%|██▋       | 134/500 [00:08<00:27, 13.28it/s] 27%|██▋       | 136/500 [00:08<00:27, 13.00it/s] 28%|██▊       | 138/500 [00:08<00:28, 12.82it/s] 28%|██▊       | 140/500 [00:08<00:28, 12.59it/s] 28%|██▊       | 142/500 [00:09<00:28, 12.52it/s] 29%|██▉       | 144/500 [00:09<00:28, 12.41it/s] 29%|██▉       | 146/500 [00:09<00:28, 12.36it/s] 30%|██▉       | 148/500 [00:09<00:28, 12.38it/s] 30%|███       | 150/500 [00:09<00:28, 12.30it/s] 30%|███       | 152/500 [00:09<00:28, 12.31it/s] 31%|███       | 154/500 [00:10<00:28, 12.34it/s] 31%|███       | 156/500 [00:10<00:27, 12.35it/s] 32%|███▏      | 158/500 [00:10<00:27, 12.37it/s] 32%|███▏      | 160/500 [00:10<00:27, 12.38it/s] 32%|███▏      | 162/500 [00:10<00:27, 12.38it/s] 33%|███▎      | 164/500 [00:10<00:27, 12.40it/s] 33%|███▎      | 166/500 [00:10<00:27, 12.32it/s] 34%|███▎      | 168/500 [00:11<00:26, 12.32it/s] 34%|███▍      | 170/500 [00:11<00:27, 12.09it/s] 34%|███▍      | 172/500 [00:11<00:27, 12.09it/s] 35%|███▍      | 174/500 [00:11<00:26, 12.10it/s] 35%|███▌      | 176/500 [00:11<00:26, 12.18it/s] 36%|███▌      | 178/500 [00:11<00:26, 12.25it/s] 36%|███▌      | 180/500 [00:12<00:26, 12.31it/s] 36%|███▋      | 182/500 [00:12<00:25, 12.32it/s] 37%|███▋      | 184/500 [00:12<00:24, 12.99it/s] 37%|███▋      | 186/500 [00:12<00:22, 13.86it/s] 38%|███▊      | 188/500 [00:12<00:21, 14.47it/s] 38%|███▊      | 190/500 [00:12<00:20, 14.99it/s] 38%|███▊      | 192/500 [00:12<00:20, 15.39it/s] 39%|███▉      | 194/500 [00:13<00:19, 15.56it/s] 39%|███▉      | 196/500 [00:13<00:19, 15.80it/s] 40%|███▉      | 198/500 [00:13<00:18, 15.98it/s] 40%|████      | 200/500 [00:13<00:18, 16.11it/s] 40%|████      | 202/500 [00:13<00:18, 16.16it/s] 41%|████      | 204/500 [00:13<00:18, 15.64it/s] 41%|████      | 206/500 [00:13<00:18, 15.48it/s] 42%|████▏     | 208/500 [00:13<00:19, 15.36it/s] 42%|████▏     | 210/500 [00:14<00:18, 15.45it/s] 42%|████▏     | 212/500 [00:14<00:18, 15.68it/s] 43%|████▎     | 214/500 [00:14<00:17, 15.89it/s] 43%|████▎     | 216/500 [00:14<00:17, 16.04it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.07it/s] 44%|████▍     | 220/500 [00:14<00:17, 15.80it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.77it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.71it/s] 45%|████▌     | 226/500 [00:15<00:17, 15.67it/s] 46%|████▌     | 228/500 [00:15<00:17, 15.86it/s] 46%|████▌     | 230/500 [00:15<00:16, 15.89it/s] 46%|████▋     | 232/500 [00:15<00:16, 16.09it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.20it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.21it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.32it/s] 48%|████▊     | 240/500 [00:15<00:15, 16.35it/s] 48%|████▊     | 242/500 [00:16<00:15, 16.37it/s] 49%|████▉     | 244/500 [00:16<00:15, 16.24it/s] 49%|████▉     | 246/500 [00:16<00:15, 15.98it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.11it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.23it/s] 50%|█████     | 252/500 [00:16<00:15, 15.72it/s] 51%|█████     | 254/500 [00:16<00:15, 15.82it/s] 51%|█████     | 256/500 [00:16<00:15, 16.02it/s] 52%|█████▏    | 258/500 [00:17<00:15, 16.13it/s] 52%|█████▏    | 260/500 [00:17<00:15, 15.64it/s] 52%|█████▏    | 262/500 [00:17<00:14, 15.90it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.06it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.15it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.30it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.33it/s] 54%|█████▍    | 272/500 [00:17<00:13, 16.34it/s] 55%|█████▍    | 274/500 [00:18<00:13, 16.41it/s] 55%|█████▌    | 276/500 [00:18<00:13, 16.37it/s] 56%|█████▌    | 278/500 [00:18<00:13, 16.28it/s] 56%|█████▌    | 280/500 [00:18<00:13, 16.33it/s] 56%|█████▋    | 282/500 [00:18<00:13, 16.42it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.10it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.02it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.15it/s] 58%|█████▊    | 290/500 [00:19<00:12, 16.19it/s] 58%|█████▊    | 292/500 [00:19<00:12, 16.24it/s] 59%|█████▉    | 294/500 [00:19<00:12, 16.28it/s] 59%|█████▉    | 296/500 [00:19<00:12, 16.32it/s] 60%|█████▉    | 298/500 [00:19<00:12, 16.33it/s] 60%|██████    | 300/500 [00:19<00:12, 16.35it/s] 60%|██████    | 302/500 [00:19<00:12, 16.39it/s] 61%|██████    | 304/500 [00:19<00:12, 16.28it/s] 61%|██████    | 306/500 [00:20<00:11, 16.18it/s] 62%|██████▏   | 308/500 [00:20<00:11, 16.12it/s] 62%|██████▏   | 310/500 [00:20<00:11, 16.18it/s] 62%|██████▏   | 312/500 [00:20<00:11, 15.95it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.88it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.01it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.01it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.93it/s] 64%|██████▍   | 322/500 [00:21<00:11, 15.98it/s] 65%|██████▍   | 324/500 [00:21<00:11, 15.88it/s] 65%|██████▌   | 326/500 [00:21<00:10, 15.97it/s] 66%|██████▌   | 328/500 [00:21<00:10, 16.12it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.16it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.27it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.06it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.05it/s] 68%|██████▊   | 338/500 [00:22<00:10, 16.16it/s] 68%|██████▊   | 340/500 [00:22<00:09, 16.28it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.34it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.34it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.34it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.05it/s] 70%|███████   | 350/500 [00:22<00:09, 16.21it/s] 70%|███████   | 352/500 [00:22<00:09, 16.27it/s] 71%|███████   | 354/500 [00:22<00:08, 16.31it/s] 71%|███████   | 356/500 [00:23<00:08, 16.37it/s] 72%|███████▏  | 358/500 [00:23<00:08, 16.29it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.31it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.34it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.31it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.98it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.10it/s] 74%|███████▍  | 370/500 [00:23<00:08, 16.14it/s] 74%|███████▍  | 372/500 [00:24<00:07, 16.13it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 15.88it/s] 75%|███████▌  | 376/500 [00:24<00:07, 15.85it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.93it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.10it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.21it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.21it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.22it/s] 78%|███████▊  | 388/500 [00:25<00:06, 16.34it/s] 78%|███████▊  | 390/500 [00:25<00:06, 16.41it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.42it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.41it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.45it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.47it/s] 80%|████████  | 400/500 [00:25<00:06, 16.52it/s] 80%|████████  | 402/500 [00:25<00:06, 16.32it/s] 81%|████████  | 404/500 [00:26<00:06, 15.88it/s] 81%|████████  | 406/500 [00:26<00:05, 15.89it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.04it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.14it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.26it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.32it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.38it/s] 84%|████████▎ | 418/500 [00:26<00:04, 16.40it/s] 84%|████████▍ | 420/500 [00:27<00:04, 16.04it/s] 84%|████████▍ | 422/500 [00:27<00:04, 15.98it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.05it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.20it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.26it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.24it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.21it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.31it/s] 87%|████████▋ | 436/500 [00:28<00:03, 16.36it/s] 88%|████████▊ | 438/500 [00:28<00:03, 16.24it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.32it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.20it/s] 89%|████████▉ | 444/500 [00:28<00:03, 15.98it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.14it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.20it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.26it/s] 90%|█████████ | 452/500 [00:29<00:02, 16.28it/s] 91%|█████████ | 454/500 [00:29<00:02, 16.28it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.28it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.17it/s] 92%|█████████▏| 460/500 [00:29<00:02, 16.22it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.28it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.27it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.29it/s] 94%|█████████▎| 468/500 [00:30<00:01, 16.23it/s] 94%|█████████▍| 470/500 [00:30<00:01, 16.02it/s] 94%|█████████▍| 472/500 [00:30<00:01, 15.55it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.24it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.58it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.82it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.00it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.09it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.17it/s] 97%|█████████▋| 486/500 [00:31<00:00, 16.25it/s] 98%|█████████▊| 488/500 [00:31<00:00, 16.27it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.29it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.32it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.31it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.13it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.93it/s]100%|██████████| 500/500 [00:32<00:00, 15.98it/s]100%|██████████| 500/500 [00:32<00:00, 15.61it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  8
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:35,  6.32s/it]  1%|          | 3/500 [00:06<14:07,  1.70s/it]  1%|          | 5/500 [00:06<07:11,  1.15it/s]  1%|▏         | 7/500 [00:06<04:25,  1.86it/s]  2%|▏         | 9/500 [00:07<03:00,  2.72it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:30,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:48,  1.23s/it]  5%|▍         | 23/500 [00:20<06:59,  1.14it/s]  5%|▌         | 25/500 [00:20<05:03,  1.57it/s]  5%|▌         | 27/500 [00:20<03:42,  2.12it/s]  6%|▌         | 29/500 [00:21<02:47,  2.81it/s]  6%|▌         | 31/500 [00:27<09:31,  1.22s/it]  7%|▋         | 33/500 [00:27<06:47,  1.14it/s]  7%|▋         | 35/500 [00:27<04:53,  1.58it/s]  7%|▋         | 37/500 [00:27<03:33,  2.17it/s]  8%|▊         | 39/500 [00:28<02:37,  2.92it/s]  8%|▊         | 41/500 [00:34<09:03,  1.18s/it]  9%|▊         | 43/500 [00:34<06:27,  1.18it/s]  9%|▉         | 45/500 [00:34<04:39,  1.63it/s]  9%|▉         | 47/500 [00:34<03:23,  2.22it/s] 10%|▉         | 49/500 [00:34<02:30,  2.99it/s] 10%|█         | 51/500 [00:41<08:54,  1.19s/it] 11%|█         | 53/500 [00:41<06:21,  1.17it/s] 11%|█         | 55/500 [00:41<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:48<08:34,  1.17s/it] 13%|█▎        | 63/500 [00:48<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:48<04:29,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:18,  2.18it/s] 14%|█▍        | 69/500 [00:48<02:29,  2.88it/s] 14%|█▍        | 71/500 [00:55<08:31,  1.19s/it]Epoch:  1  	Training Loss: 0.030005237087607384
Test Loss:  0.41005903482437134
Valid Loss:  0.4179912805557251
Epoch:  2  	Training Loss: 0.42726781964302063
Test Loss:  1.554901123046875
Valid Loss:  1.5216766595840454
Epoch:  3  	Training Loss: 1.4659733772277832
Test Loss:  0.018560854718089104
Valid Loss:  0.026056010276079178
Epoch:  4  	Training Loss: 0.029573317617177963
Test Loss:  0.018542665988206863
Valid Loss:  0.026033561676740646
Epoch:  5  	Training Loss: 0.029549239203333855
Test Loss:  0.018524518236517906
Valid Loss:  0.026011163368821144
Epoch:  6  	Training Loss: 0.029525216668844223
Test Loss:  0.018506428226828575
Valid Loss:  0.025988822802901268
Epoch:  7  	Training Loss: 0.029501251876354218
Test Loss:  0.018488381057977676
Valid Loss:  0.02596653625369072
Epoch:  8  	Training Loss: 0.02947734110057354
Test Loss:  0.018470386043190956
Valid Loss:  0.025944311171770096
Epoch:  9  	Training Loss: 0.02945348061621189
Test Loss:  0.018452439457178116
Valid Loss:  0.025922143831849098
Epoch:  10  	Training Loss: 0.02942967787384987
Test Loss:  0.018434539437294006
Valid Loss:  0.02590002492070198
Epoch:  11  	Training Loss: 0.029405925422906876
Test Loss:  0.018416691571474075
Valid Loss:  0.02587796375155449
Epoch:  12  	Training Loss: 0.02938222885131836
Test Loss:  0.018381129950284958
Valid Loss:  0.025834279134869576
Epoch:  13  	Training Loss: 0.02933608740568161
Test Loss:  0.018345776945352554
Valid Loss:  0.025790832936763763
Epoch:  14  	Training Loss: 0.02929016575217247
Test Loss:  0.018310630694031715
Valid Loss:  0.025747615844011307
Epoch:  15  	Training Loss: 0.02924446389079094
Test Loss:  0.018275680020451546
Valid Loss:  0.025704629719257355
Epoch:  16  	Training Loss: 0.029198983684182167
Test Loss:  0.01824093796312809
Valid Loss:  0.02566186897456646
Epoch:  17  	Training Loss: 0.029153715819120407
Test Loss:  0.018206384032964706
Valid Loss:  0.02561933919787407
Epoch:  18  	Training Loss: 0.029108665883541107
Test Loss:  0.01817202754318714
Valid Loss:  0.02557702735066414
Epoch:  19  	Training Loss: 0.029063818976283073
Test Loss:  0.018137870356440544
Valid Loss:  0.025534935295581818
Epoch:  20  	Training Loss: 0.029019184410572052
Test Loss:  0.01810390129685402
Valid Loss:  0.025493063032627106
Epoch:  21  	Training Loss: 0.028974760323762894
Test Loss:  0.018070122227072716
Valid Loss:  0.025451406836509705
Epoch:  22  	Training Loss: 0.028930535539984703
Test Loss:  0.018037661910057068
Valid Loss:  0.025411268696188927
Epoch:  23  	Training Loss: 0.028887588530778885
Test Loss:  0.018005363643169403
Valid Loss:  0.025371307507157326
Epoch:  24  	Training Loss: 0.028844812884926796
Test Loss:  0.017973219975829124
Valid Loss:  0.0253315269947052
Epoch:  25  	Training Loss: 0.02880220301449299
Test Loss:  0.01794123649597168
Valid Loss:  0.02529192715883255
Epoch:  26  	Training Loss: 0.028759758919477463
Test Loss:  0.017909405753016472
Valid Loss:  0.025252558290958405
Epoch:  27  	Training Loss: 0.028717510402202606
Test Loss:  0.017877839505672455
Valid Loss:  0.025214053690433502
Epoch:  28  	Training Loss: 0.028676360845565796
Test Loss:  0.01784674823284149
Valid Loss:  0.025176048278808594
Epoch:  29  	Training Loss: 0.028636211529374123
Test Loss:  0.01781598851084709
Valid Loss:  0.02513829991221428
Epoch:  30  	Training Loss: 0.028596434742212296
Test Loss:  0.017785415053367615
Valid Loss:  0.025100767612457275
Epoch:  31  	Training Loss: 0.02855689451098442
Test Loss:  0.01775502599775791
Valid Loss:  0.025063520297408104
Epoch:  32  	Training Loss: 0.02851758897304535
Test Loss:  0.017725981771945953
Valid Loss:  0.025027835741639137
Epoch:  33  	Training Loss: 0.028479797765612602
Test Loss:  0.01769709587097168
Valid Loss:  0.024992328137159348
Epoch:  34  	Training Loss: 0.028442170470952988
Test Loss:  0.017668351531028748
Valid Loss:  0.024956997483968735
Epoch:  35  	Training Loss: 0.02840469777584076
Test Loss:  0.017639748752117157
Valid Loss:  0.024921834468841553
Epoch:  36  	Training Loss: 0.028367387130856514
Test Loss:  0.017611319199204445
Valid Loss:  0.024886801838874817
Epoch:  37  	Training Loss: 0.02833024226129055
Test Loss:  0.017583021894097328
Valid Loss:  0.024851929396390915
Epoch:  38  	Training Loss: 0.028293251991271973
Test Loss:  0.017554864287376404
Valid Loss:  0.024817219004034996
Epoch:  39  	Training Loss: 0.028256412595510483
Test Loss:  0.017526844516396523
Valid Loss:  0.024782977998256683
Epoch:  40  	Training Loss: 0.028219835832715034
Test Loss:  0.01749907061457634
Valid Loss:  0.024750128388404846
Epoch:  41  	Training Loss: 0.02818433754146099
Test Loss:  0.01747184619307518
Valid Loss:  0.024718569591641426
Epoch:  42  	Training Loss: 0.028150707483291626
Test Loss:  0.01745273545384407
Valid Loss:  0.024696679785847664
Epoch:  43  	Training Loss: 0.028126634657382965
Test Loss:  0.017433874309062958
Valid Loss:  0.024675004184246063
Epoch:  44  	Training Loss: 0.028103407472372055
Test Loss:  0.017415257170796394
Valid Loss:  0.024653535336256027
Epoch:  45  	Training Loss: 0.028080783784389496
Test Loss:  0.017396699637174606
Valid Loss:  0.024632137268781662
Epoch:  46  	Training Loss: 0.028058405965566635
Test Loss:  0.017378374934196472
Valid Loss:  0.024610910564661026
Epoch:  47  	Training Loss: 0.028036722913384438
Test Loss:  0.017360273748636246
Valid Loss:  0.024589888751506805
Epoch:  48  	Training Loss: 0.02801540493965149
Test Loss:  0.01734224520623684
Valid Loss:  0.024568913504481316
Epoch:  49  	Training Loss: 0.027994239702820778
Test Loss:  0.017324358224868774
Valid Loss:  0.024548321962356567
Epoch:  50  	Training Loss: 0.027973365038633347
Test Loss:  0.0173066146671772
Valid Loss:  0.024528002366423607
Epoch:  51  	Training Loss: 0.02795274928212166
Test Loss:  0.017289016395807266
Valid Loss:  0.024507753551006317
Epoch:  52  	Training Loss: 0.027932334691286087
Test Loss:  0.01727289706468582
Valid Loss:  0.024489209055900574
Epoch:  53  	Training Loss: 0.027913661673665047
Test Loss:  0.017257140949368477
Valid Loss:  0.0244707390666008
Epoch:  54  	Training Loss: 0.027895094826817513
Test Loss:  0.017241502180695534
Valid Loss:  0.02445235848426819
Epoch:  55  	Training Loss: 0.02787669748067856
Test Loss:  0.01722591184079647
Valid Loss:  0.0244340468198061
Epoch:  56  	Training Loss: 0.027858369052410126
Test Loss:  0.017210381105542183
Valid Loss:  0.024415796622633934
Epoch:  57  	Training Loss: 0.02784010022878647
Test Loss:  0.017194904386997223
Valid Loss:  0.024397622793912888
Epoch:  58  	Training Loss: 0.027821913361549377
Test Loss:  0.01717953011393547
Valid Loss:  0.024379530921578407
Epoch:  59  	Training Loss: 0.027803897857666016
Test Loss:  0.017164211720228195
Valid Loss:  0.024361515417695045
Epoch:  60  	Training Loss: 0.027785949409008026
Test Loss:  0.017148949205875397
Valid Loss:  0.024343565106391907
Epoch:  61  	Training Loss: 0.027768058702349663
Test Loss:  0.017133740708231926
Valid Loss:  0.02432567998766899
Epoch:  62  	Training Loss: 0.027750235050916672
Test Loss:  0.017118914052844048
Valid Loss:  0.024308260530233383
Epoch:  63  	Training Loss: 0.02773282676935196
Test Loss:  0.01710413582623005
Valid Loss:  0.02429090067744255
Epoch:  64  	Training Loss: 0.02771548181772232
Test Loss:  0.01708945259451866
Valid Loss:  0.024273626506328583
Epoch:  65  	Training Loss: 0.027698297053575516
Test Loss:  0.017074819654226303
Valid Loss:  0.02425641193985939
Epoch:  66  	Training Loss: 0.027681171894073486
Test Loss:  0.01706024631857872
Valid Loss:  0.024239227175712585
Epoch:  67  	Training Loss: 0.027664100751280785
Test Loss:  0.017045721411705017
Valid Loss:  0.024222105741500854
Epoch:  68  	Training Loss: 0.02764708921313286
Test Loss:  0.017031241208314896
Valid Loss:  0.0242050439119339
Epoch:  69  	Training Loss: 0.02763012796640396
Test Loss:  0.017016815021634102
Valid Loss:  0.024188045412302017
Epoch:  70  	Training Loss: 0.027613244950771332
Test Loss:  0.017002485692501068
Valid Loss:  0.024171121418476105
Epoch:  71  	Training Loss: 0.027596496045589447
Test Loss:  0.016988197341561317
Valid Loss:  0.024154264479875565
 15%|█▍        | 73/500 [00:55<06:07,  1.16it/s] 15%|█▌        | 75/500 [00:55<04:27,  1.59it/s] 15%|█▌        | 77/500 [00:55<03:16,  2.15it/s] 16%|█▌        | 79/500 [00:55<02:28,  2.84it/s] 16%|█▌        | 81/500 [01:02<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:02<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:18,  1.61it/s] 17%|█▋        | 87/500 [01:02<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:02<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:08<07:56,  1.17s/it] 19%|█▊        | 93/500 [01:08<05:43,  1.19it/s] 19%|█▉        | 95/500 [01:09<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:18,  2.89it/s] 20%|██        | 101/500 [01:15<07:54,  1.19s/it] 21%|██        | 103/500 [01:15<05:38,  1.17it/s] 21%|██        | 105/500 [01:16<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:16<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:16<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:22<07:48,  1.20s/it] 23%|██▎       | 113/500 [01:22<05:34,  1.16it/s] 23%|██▎       | 115/500 [01:23<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:23<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:29<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:30<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:30<02:52,  2.16it/s] 26%|██▌       | 129/500 [01:30<02:09,  2.86it/s] 26%|██▌       | 131/500 [01:36<07:21,  1.20s/it] 27%|██▋       | 133/500 [01:36<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:36<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:37<02:44,  2.21it/s] 28%|██▊       | 139/500 [01:37<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:43<07:03,  1.18s/it]Epoch:  72  	Training Loss: 0.02757980488240719
Test Loss:  0.016974497586488724
Valid Loss:  0.024138309061527252
Epoch:  73  	Training Loss: 0.02756379172205925
Test Loss:  0.01696089282631874
Valid Loss:  0.02412255108356476
Epoch:  74  	Training Loss: 0.027547895908355713
Test Loss:  0.016947325319051743
Valid Loss:  0.02410684898495674
Epoch:  75  	Training Loss: 0.027532052248716354
Test Loss:  0.016933808103203773
Valid Loss:  0.024091210216283798
Epoch:  76  	Training Loss: 0.027516264468431473
Test Loss:  0.016920339316129684
Valid Loss:  0.024075623601675034
Epoch:  77  	Training Loss: 0.02750055491924286
Test Loss:  0.01690695434808731
Valid Loss:  0.024060068652033806
Epoch:  78  	Training Loss: 0.027484942227602005
Test Loss:  0.016893621534109116
Valid Loss:  0.024044569581747055
Epoch:  79  	Training Loss: 0.02746938169002533
Test Loss:  0.016880327835679054
Valid Loss:  0.02402913197875023
Epoch:  80  	Training Loss: 0.027453875169157982
Test Loss:  0.016867084428668022
Valid Loss:  0.02401374652981758
Epoch:  81  	Training Loss: 0.027438420802354813
Test Loss:  0.016853883862495422
Valid Loss:  0.023998424410820007
Epoch:  82  	Training Loss: 0.02742302417755127
Test Loss:  0.016841426491737366
Valid Loss:  0.023983929306268692
Epoch:  83  	Training Loss: 0.027408476918935776
Test Loss:  0.016829010099172592
Valid Loss:  0.023969486355781555
Epoch:  84  	Training Loss: 0.02739397995173931
Test Loss:  0.016816630959510803
Valid Loss:  0.023955093696713448
Epoch:  85  	Training Loss: 0.02737952396273613
Test Loss:  0.016804296523332596
Valid Loss:  0.02394075319170952
Epoch:  86  	Training Loss: 0.02736511453986168
Test Loss:  0.016791993752121925
Valid Loss:  0.023926464840769768
Epoch:  87  	Training Loss: 0.02735074982047081
Test Loss:  0.016779731959104538
Valid Loss:  0.023912226781249046
Epoch:  88  	Training Loss: 0.02733643352985382
Test Loss:  0.016767509281635284
Valid Loss:  0.023898042738437653
Epoch:  89  	Training Loss: 0.027322160080075264
Test Loss:  0.016755320131778717
Valid Loss:  0.023883897811174393
Epoch:  90  	Training Loss: 0.02730792947113514
Test Loss:  0.016743168234825134
Valid Loss:  0.02386980876326561
Epoch:  91  	Training Loss: 0.027293739840388298
Test Loss:  0.01673106849193573
Valid Loss:  0.023855742067098618
Epoch:  92  	Training Loss: 0.027279600501060486
Test Loss:  0.016719747334718704
Valid Loss:  0.023842643946409225
Epoch:  93  	Training Loss: 0.0272663626819849
Test Loss:  0.016708459705114365
Valid Loss:  0.02382958121597767
Epoch:  94  	Training Loss: 0.0272531621158123
Test Loss:  0.016697203740477562
Valid Loss:  0.023816559463739395
Epoch:  95  	Training Loss: 0.027239995077252388
Test Loss:  0.01668597385287285
Valid Loss:  0.023803705349564552
Epoch:  96  	Training Loss: 0.02722686342895031
Test Loss:  0.01667477749288082
Valid Loss:  0.02379090152680874
Epoch:  97  	Training Loss: 0.027213770896196365
Test Loss:  0.01666361093521118
Valid Loss:  0.02377813309431076
Epoch:  98  	Training Loss: 0.027200711891055107
Test Loss:  0.01665247231721878
Valid Loss:  0.023765407502651215
Epoch:  99  	Training Loss: 0.027187690138816833
Test Loss:  0.016641369089484215
Valid Loss:  0.02375273033976555
Epoch:  100  	Training Loss: 0.027174700051546097
Test Loss:  0.01663029007613659
Valid Loss:  0.02374008670449257
Epoch:  101  	Training Loss: 0.027161750942468643
Test Loss:  0.016619239002466202
Valid Loss:  0.02372748591005802
Epoch:  102  	Training Loss: 0.027148835361003876
Test Loss:  0.016608674079179764
Valid Loss:  0.02371545508503914
Epoch:  103  	Training Loss: 0.02713646925985813
Test Loss:  0.016598135232925415
Valid Loss:  0.02370346337556839
Epoch:  104  	Training Loss: 0.027124131098389626
Test Loss:  0.016587618738412857
Valid Loss:  0.023691507056355476
Epoch:  105  	Training Loss: 0.027111824601888657
Test Loss:  0.016577132046222687
Valid Loss:  0.02367958426475525
Epoch:  106  	Training Loss: 0.027099551633000374
Test Loss:  0.016566669568419456
Valid Loss:  0.023667696863412857
Epoch:  107  	Training Loss: 0.027087340131402016
Test Loss:  0.016556287184357643
Valid Loss:  0.02365579828619957
Epoch:  108  	Training Loss: 0.02707519382238388
Test Loss:  0.016545988619327545
Valid Loss:  0.023643888533115387
Epoch:  109  	Training Loss: 0.027063123881816864
Test Loss:  0.016535714268684387
Valid Loss:  0.02363201417028904
Epoch:  110  	Training Loss: 0.027051089331507683
Test Loss:  0.01652546599507332
Valid Loss:  0.023620178923010826
Epoch:  111  	Training Loss: 0.027039088308811188
Test Loss:  0.016515258699655533
Valid Loss:  0.023608356714248657
Epoch:  112  	Training Loss: 0.02702711522579193
Test Loss:  0.0165052879601717
Valid Loss:  0.023596886545419693
Epoch:  113  	Training Loss: 0.02701544016599655
Test Loss:  0.016495343297719955
Valid Loss:  0.023585449904203415
Epoch:  114  	Training Loss: 0.02700379118323326
Test Loss:  0.016485434025526047
Valid Loss:  0.023574016988277435
Epoch:  115  	Training Loss: 0.026992177590727806
Test Loss:  0.016475535929203033
Valid Loss:  0.02356264740228653
Epoch:  116  	Training Loss: 0.026980586349964142
Test Loss:  0.016465676948428154
Valid Loss:  0.02355129085481167
Epoch:  117  	Training Loss: 0.026969026774168015
Test Loss:  0.01645582541823387
Valid Loss:  0.023539986461400986
Epoch:  118  	Training Loss: 0.026957495138049126
Test Loss:  0.016446009278297424
Valid Loss:  0.023528696969151497
Epoch:  119  	Training Loss: 0.026945989578962326
Test Loss:  0.016436215490102768
Valid Loss:  0.023517431691288948
Epoch:  120  	Training Loss: 0.026934515684843063
Test Loss:  0.016426432877779007
Valid Loss:  0.023506227880716324
Epoch:  121  	Training Loss: 0.02692306786775589
Test Loss:  0.016416683793067932
Valid Loss:  0.023495040833950043
Epoch:  122  	Training Loss: 0.026911651715636253
Test Loss:  0.016407201066613197
Valid Loss:  0.023484181612730026
Epoch:  123  	Training Loss: 0.02690054103732109
Test Loss:  0.016397740691900253
Valid Loss:  0.023473359644412994
Epoch:  124  	Training Loss: 0.026889456436038017
Test Loss:  0.01638830453157425
Valid Loss:  0.023462563753128052
Epoch:  125  	Training Loss: 0.026878394186496735
Test Loss:  0.01637888140976429
Valid Loss:  0.023451797664165497
Epoch:  126  	Training Loss: 0.02686735987663269
Test Loss:  0.016369478777050972
Valid Loss:  0.023441065102815628
Epoch:  127  	Training Loss: 0.026856347918510437
Test Loss:  0.016360094770789146
Valid Loss:  0.0234303530305624
Epoch:  128  	Training Loss: 0.02684536576271057
Test Loss:  0.01635073870420456
Valid Loss:  0.02341967448592186
Epoch:  129  	Training Loss: 0.026834402233362198
Test Loss:  0.016341395676136017
Valid Loss:  0.023409027606248856
Epoch:  130  	Training Loss: 0.026823464781045914
Test Loss:  0.016332074999809265
Valid Loss:  0.02339840680360794
Epoch:  131  	Training Loss: 0.02681255154311657
Test Loss:  0.016322769224643707
Valid Loss:  0.023387815803289413
Epoch:  132  	Training Loss: 0.026801664382219315
Test Loss:  0.016313685104250908
Valid Loss:  0.023377500474452972
Epoch:  133  	Training Loss: 0.026791036128997803
Test Loss:  0.016304614022374153
Valid Loss:  0.02336721308529377
Epoch:  134  	Training Loss: 0.02678043395280838
Test Loss:  0.01629555970430374
Valid Loss:  0.023356953635811806
Epoch:  135  	Training Loss: 0.02676985040307045
Test Loss:  0.01628652587532997
Valid Loss:  0.02334672212600708
Epoch:  136  	Training Loss: 0.02675929106771946
Test Loss:  0.016277510672807693
Valid Loss:  0.023336512967944145
Epoch:  137  	Training Loss: 0.02674875594675541
Test Loss:  0.01626851037144661
Valid Loss:  0.023326333612203598
Epoch:  138  	Training Loss: 0.026738241314888
Test Loss:  0.016259528696537018
Valid Loss:  0.02331617847084999
Epoch:  139  	Training Loss: 0.026727745309472084
Test Loss:  0.016250567510724068
Valid Loss:  0.023306051269173622
Epoch:  140  	Training Loss: 0.026717279106378555
Test Loss:  0.016241619363427162
Valid Loss:  0.023295942693948746
Epoch:  141  	Training Loss: 0.02670682780444622
Test Loss:  0.0162326879799366
Valid Loss:  0.023285865783691406
Epoch:  142  	Training Loss: 0.026696398854255676
Test Loss:  0.016223955899477005
Valid Loss:   29%|██▊       | 143/500 [01:43<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:43<03:39,  1.61it/s] 29%|██▉       | 147/500 [01:43<02:41,  2.18it/s] 30%|██▉       | 149/500 [01:44<02:01,  2.89it/s] 30%|███       | 151/500 [01:50<06:57,  1.20s/it] 31%|███       | 153/500 [01:50<04:58,  1.16it/s] 31%|███       | 155/500 [01:50<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:50<02:35,  2.20it/s] 32%|███▏      | 159/500 [01:51<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:57<06:36,  1.17s/it] 33%|███▎      | 163/500 [01:57<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:57<03:23,  1.64it/s] 33%|███▎      | 167/500 [01:57<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:57<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:03<06:21,  1.16s/it] 35%|███▍      | 173/500 [02:04<04:32,  1.20it/s] 35%|███▌      | 175/500 [02:04<03:15,  1.66it/s] 35%|███▌      | 177/500 [02:04<02:22,  2.27it/s] 36%|███▌      | 179/500 [02:04<01:45,  3.04it/s] 36%|███▌      | 181/500 [02:10<06:21,  1.20s/it] 37%|███▋      | 183/500 [02:11<04:33,  1.16it/s] 37%|███▋      | 185/500 [02:11<03:17,  1.59it/s] 37%|███▋      | 187/500 [02:11<02:25,  2.15it/s] 38%|███▊      | 189/500 [02:11<01:49,  2.85it/s] 38%|███▊      | 191/500 [02:17<06:09,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:18<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:18<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:18<01:41,  2.96it/s] 40%|████      | 201/500 [02:24<05:52,  1.18s/it] 41%|████      | 203/500 [02:24<04:10,  1.18it/s] 41%|████      | 205/500 [02:25<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:25<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:25<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:31<05:40,  1.18s/it]0.023276038467884064
Epoch:  143  	Training Loss: 0.02668619528412819
Test Loss:  0.016215238720178604
Valid Loss:  0.023266231641173363
Epoch:  144  	Training Loss: 0.026676012203097343
Test Loss:  0.016206540167331696
Valid Loss:  0.023256462067365646
Epoch:  145  	Training Loss: 0.02666585147380829
Test Loss:  0.016197852790355682
Valid Loss:  0.023246824741363525
Epoch:  146  	Training Loss: 0.026655707508325577
Test Loss:  0.01618926227092743
Valid Loss:  0.023237209767103195
Epoch:  147  	Training Loss: 0.026645580306649208
Test Loss:  0.016180727630853653
Valid Loss:  0.023227624595165253
Epoch:  148  	Training Loss: 0.02663547731935978
Test Loss:  0.016172226518392563
Valid Loss:  0.02321804128587246
Epoch:  149  	Training Loss: 0.026625392958521843
Test Loss:  0.016163723543286324
Valid Loss:  0.0232084970921278
Epoch:  150  	Training Loss: 0.0266153272241354
Test Loss:  0.01615525409579277
Valid Loss:  0.023198962211608887
Epoch:  151  	Training Loss: 0.026605281978845596
Test Loss:  0.016146797686815262
Valid Loss:  0.023189447820186615
Epoch:  152  	Training Loss: 0.026595257222652435
Test Loss:  0.016138548031449318
Valid Loss:  0.023180194199085236
Epoch:  153  	Training Loss: 0.026585470885038376
Test Loss:  0.01613030955195427
Valid Loss:  0.02317095920443535
Epoch:  154  	Training Loss: 0.02657570131123066
Test Loss:  0.016122089698910713
Valid Loss:  0.0231617484241724
Epoch:  155  	Training Loss: 0.026565950363874435
Test Loss:  0.0161138828843832
Valid Loss:  0.023152554407715797
Epoch:  156  	Training Loss: 0.02655623108148575
Test Loss:  0.016105730086565018
Valid Loss:  0.023143330588936806
Epoch:  157  	Training Loss: 0.026546571403741837
Test Loss:  0.016097594052553177
Valid Loss:  0.023134127259254456
Epoch:  158  	Training Loss: 0.026536932215094566
Test Loss:  0.01608947664499283
Valid Loss:  0.023124946281313896
Epoch:  159  	Training Loss: 0.026527315378189087
Test Loss:  0.016081370413303375
Valid Loss:  0.023115819320082664
Epoch:  160  	Training Loss: 0.02651771530508995
Test Loss:  0.016073280945420265
Valid Loss:  0.023106789216399193
Epoch:  161  	Training Loss: 0.026508130133152008
Test Loss:  0.016065217554569244
Valid Loss:  0.02309776097536087
Epoch:  162  	Training Loss: 0.026498572900891304
Test Loss:  0.016057323664426804
Valid Loss:  0.023088853806257248
Epoch:  163  	Training Loss: 0.026489216834306717
Test Loss:  0.016049453988671303
Valid Loss:  0.023079954087734222
Epoch:  164  	Training Loss: 0.02647988125681877
Test Loss:  0.0160415880382061
Valid Loss:  0.02307109162211418
Epoch:  165  	Training Loss: 0.02647056058049202
Test Loss:  0.016033750027418137
Valid Loss:  0.02306223288178444
Epoch:  166  	Training Loss: 0.026461277157068253
Test Loss:  0.016025954857468605
Valid Loss:  0.02305334061384201
Epoch:  167  	Training Loss: 0.02645203098654747
Test Loss:  0.01601818948984146
Valid Loss:  0.023044448345899582
Epoch:  168  	Training Loss: 0.02644280716776848
Test Loss:  0.016010422259569168
Valid Loss:  0.023035600781440735
Epoch:  169  	Training Loss: 0.02643360011279583
Test Loss:  0.01600268855690956
Valid Loss:  0.023026760667562485
Epoch:  170  	Training Loss: 0.026424411684274673
Test Loss:  0.0159949641674757
Valid Loss:  0.023017942905426025
Epoch:  171  	Training Loss: 0.026415247470140457
Test Loss:  0.01598726585507393
Valid Loss:  0.023009151220321655
Epoch:  172  	Training Loss: 0.026406096294522285
Test Loss:  0.0159797091037035
Valid Loss:  0.02300059050321579
Epoch:  173  	Training Loss: 0.026397164911031723
Test Loss:  0.015972185879945755
Valid Loss:  0.02299203909933567
Epoch:  174  	Training Loss: 0.026388252153992653
Test Loss:  0.015964681282639503
Valid Loss:  0.022983506321907043
Epoch:  175  	Training Loss: 0.026379358023405075
Test Loss:  0.01595718413591385
Valid Loss:  0.022974999621510506
Epoch:  176  	Training Loss: 0.02637047879397869
Test Loss:  0.015949703752994537
Valid Loss:  0.02296651154756546
Epoch:  177  	Training Loss: 0.026361621916294098
Test Loss:  0.01594223640859127
Valid Loss:  0.022958053275942802
Epoch:  178  	Training Loss: 0.026352781802415848
Test Loss:  0.015934787690639496
Valid Loss:  0.02294960990548134
Epoch:  179  	Training Loss: 0.026343971490859985
Test Loss:  0.01592739298939705
Valid Loss:  0.022941114380955696
Epoch:  180  	Training Loss: 0.026335198432207108
Test Loss:  0.015920015051960945
Valid Loss:  0.022932644933462143
Epoch:  181  	Training Loss: 0.026326444000005722
Test Loss:  0.015912652015686035
Valid Loss:  0.022924194112420082
Epoch:  182  	Training Loss: 0.02631770819425583
Test Loss:  0.01590537652373314
Valid Loss:  0.022915862500667572
Epoch:  183  	Training Loss: 0.026309067383408546
Test Loss:  0.015898117795586586
Valid Loss:  0.022907555103302002
Epoch:  184  	Training Loss: 0.026300443336367607
Test Loss:  0.01589086651802063
Valid Loss:  0.022899262607097626
Epoch:  185  	Training Loss: 0.02629183791577816
Test Loss:  0.015883633866906166
Valid Loss:  0.02289099618792534
Epoch:  186  	Training Loss: 0.026283245533704758
Test Loss:  0.015876412391662598
Valid Loss:  0.022882752120494843
Epoch:  187  	Training Loss: 0.026274675503373146
Test Loss:  0.015869205817580223
Valid Loss:  0.022874528542160988
Epoch:  188  	Training Loss: 0.02626611851155758
Test Loss:  0.015862010419368744
Valid Loss:  0.022866318002343178
Epoch:  189  	Training Loss: 0.026257582008838654
Test Loss:  0.01585482805967331
Valid Loss:  0.022858137264847755
Epoch:  190  	Training Loss: 0.026249058544635773
Test Loss:  0.01584765687584877
Valid Loss:  0.022849973291158676
Epoch:  191  	Training Loss: 0.026240551844239235
Test Loss:  0.015840519219636917
Valid Loss:  0.022841818630695343
Epoch:  192  	Training Loss: 0.026232067495584488
Test Loss:  0.015833444893360138
Valid Loss:  0.022833773866295815
Epoch:  193  	Training Loss: 0.02622365951538086
Test Loss:  0.01582639291882515
Valid Loss:  0.022825732827186584
Epoch:  194  	Training Loss: 0.026215270161628723
Test Loss:  0.01581934280693531
Valid Loss:  0.02281772904098034
Epoch:  195  	Training Loss: 0.02620689570903778
Test Loss:  0.015812311321496964
Valid Loss:  0.02280973270535469
Epoch:  196  	Training Loss: 0.026198532432317734
Test Loss:  0.015805300325155258
Valid Loss:  0.022801745682954788
Epoch:  197  	Training Loss: 0.02619018964469433
Test Loss:  0.015798283740878105
Valid Loss:  0.022793801501393318
Epoch:  198  	Training Loss: 0.026181858032941818
Test Loss:  0.01579129323363304
Valid Loss:  0.022785857319831848
Epoch:  199  	Training Loss: 0.02617354318499565
Test Loss:  0.015784313902258873
Valid Loss:  0.02277793362736702
Epoch:  200  	Training Loss: 0.026165243238210678
Test Loss:  0.0157773457467556
Valid Loss:  0.022770024836063385
Epoch:  201  	Training Loss: 0.0261569544672966
Test Loss:  0.01577039062976837
Valid Loss:  0.02276213839650154
Epoch:  202  	Training Loss: 0.026148688048124313
Test Loss:  0.015763528645038605
Valid Loss:  0.022754378616809845
Epoch:  203  	Training Loss: 0.02614053338766098
Test Loss:  0.015756681561470032
Valid Loss:  0.02274663932621479
Epoch:  204  	Training Loss: 0.02613239549100399
Test Loss:  0.015749843791127205
Valid Loss:  0.02273891121149063
Epoch:  205  	Training Loss: 0.026124272495508194
Test Loss:  0.015743017196655273
Valid Loss:  0.022731205448508263
Epoch:  206  	Training Loss: 0.026116162538528442
Test Loss:  0.015736203640699387
Valid Loss:  0.022723514586687088
Epoch:  207  	Training Loss: 0.026108067482709885
Test Loss:  0.015729399397969246
Valid Loss:  0.022715844213962555
Epoch:  208  	Training Loss: 0.02609998732805252
Test Loss:  0.01572260819375515
Valid Loss:  0.022708194330334663
Epoch:  209  	Training Loss: 0.02609192207455635
Test Loss:  0.0157158263027668
Valid Loss:  0.022700557485222816
Epoch:  210  	Training Loss: 0.026083867996931076
Test Loss:  0.015709049999713898
Valid Loss:  0.022692939266562462
Epoch:  211  	Training Loss: 0.026075836271047592
Test Loss:  0.015702344477176666
Valid Loss:  0.022685274481773376
Epoch:  212  	Training Loss: 0.02606784552335739
Test Loss:  0.015695691108703613
Valid Loss:  0.02267768420279026
Epoch:  213  	Training Loss: 0.026059918105602264
Test Loss:   43%|████▎     | 213/500 [02:31<04:02,  1.19it/s] 43%|████▎     | 215/500 [02:31<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:31<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:32<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:38<05:25,  1.17s/it] 45%|████▍     | 223/500 [02:38<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:38<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:38<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:38<01:29,  3.03it/s] 46%|████▌     | 231/500 [02:45<05:28,  1.22s/it] 47%|████▋     | 233/500 [02:45<03:54,  1.14it/s] 47%|████▋     | 235/500 [02:45<02:47,  1.58it/s] 47%|████▋     | 237/500 [02:45<02:01,  2.16it/s] 48%|████▊     | 239/500 [02:46<01:29,  2.91it/s] 48%|████▊     | 241/500 [02:52<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:52<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:52<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:52<01:53,  2.22it/s] 50%|████▉     | 249/500 [02:52<01:23,  2.99it/s] 50%|█████     | 251/500 [02:59<04:52,  1.17s/it] 51%|█████     | 253/500 [02:59<03:28,  1.19it/s] 51%|█████     | 255/500 [02:59<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:59<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:59<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:05<04:38,  1.16s/it] 53%|█████▎    | 263/500 [03:06<03:18,  1.19it/s] 53%|█████▎    | 265/500 [03:06<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:06<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:06<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:12<04:31,  1.18s/it] 55%|█████▍    | 273/500 [03:12<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:13<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:13<01:42,  2.17it/s] 56%|█████▌    | 279/500 [03:13<01:15,  2.93it/s] 56%|█████▌    | 281/500 [03:19<04:29,  1.23s/it] 57%|█████▋    | 283/500 [03:20<03:11,  1.13it/s]0.015689050778746605
Valid Loss:  0.02267010323703289
Epoch:  214  	Training Loss: 0.026052001863718033
Test Loss:  0.015682419762015343
Valid Loss:  0.022662553936243057
Epoch:  215  	Training Loss: 0.026044102385640144
Test Loss:  0.015675801783800125
Valid Loss:  0.02265501767396927
Epoch:  216  	Training Loss: 0.02603621780872345
Test Loss:  0.015669189393520355
Valid Loss:  0.022647500038146973
Epoch:  217  	Training Loss: 0.0260283462703228
Test Loss:  0.015662606805562973
Valid Loss:  0.022639978677034378
Epoch:  218  	Training Loss: 0.026020491495728493
Test Loss:  0.015656016767024994
Valid Loss:  0.02263249270617962
Epoch:  219  	Training Loss: 0.026012644171714783
Test Loss:  0.015649452805519104
Valid Loss:  0.02262500859797001
Epoch:  220  	Training Loss: 0.026004815474152565
Test Loss:  0.015642885118722916
Valid Loss:  0.022617558017373085
Epoch:  221  	Training Loss: 0.02599700167775154
Test Loss:  0.015636339783668518
Valid Loss:  0.02261010929942131
Epoch:  222  	Training Loss: 0.025989197194576263
Test Loss:  0.015629857778549194
Valid Loss:  0.022602776065468788
Epoch:  223  	Training Loss: 0.025981491431593895
Test Loss:  0.015623397193849087
Valid Loss:  0.022595439106225967
Epoch:  224  	Training Loss: 0.025973796844482422
Test Loss:  0.015616945922374725
Valid Loss:  0.022588124498724937
Epoch:  225  	Training Loss: 0.025966117158532143
Test Loss:  0.01561049371957779
Valid Loss:  0.022580832242965698
Epoch:  226  	Training Loss: 0.025958452373743057
Test Loss:  0.015604116022586823
Valid Loss:  0.02257348597049713
Epoch:  227  	Training Loss: 0.025950824841856956
Test Loss:  0.015597745776176453
Valid Loss:  0.02256615459918976
Epoch:  228  	Training Loss: 0.02594320848584175
Test Loss:  0.015591373667120934
Valid Loss:  0.022558853030204773
Epoch:  229  	Training Loss: 0.025935610756278038
Test Loss:  0.015585077926516533
Valid Loss:  0.02255149558186531
Epoch:  230  	Training Loss: 0.025928039103746414
Test Loss:  0.015578792430460453
Valid Loss:  0.022544153034687042
Epoch:  231  	Training Loss: 0.025920482352375984
Test Loss:  0.015572515316307545
Valid Loss:  0.022536829113960266
Epoch:  232  	Training Loss: 0.025912940502166748
Test Loss:  0.015566319227218628
Valid Loss:  0.02252960205078125
Epoch:  233  	Training Loss: 0.02590550109744072
Test Loss:  0.015560131520032883
Valid Loss:  0.022522395476698875
Epoch:  234  	Training Loss: 0.025898072868585587
Test Loss:  0.01555395033210516
Valid Loss:  0.022515207529067993
Epoch:  235  	Training Loss: 0.025890663266181946
Test Loss:  0.015547783114016056
Valid Loss:  0.022508028894662857
Epoch:  236  	Training Loss: 0.0258832648396492
Test Loss:  0.015541626140475273
Valid Loss:  0.02250087261199951
Epoch:  237  	Training Loss: 0.02587588131427765
Test Loss:  0.015535477548837662
Valid Loss:  0.022493736818432808
Epoch:  238  	Training Loss: 0.02586851269006729
Test Loss:  0.015529340133070946
Valid Loss:  0.02248661406338215
Epoch:  239  	Training Loss: 0.02586115337908268
Test Loss:  0.015523210167884827
Valid Loss:  0.022479508072137833
Epoch:  240  	Training Loss: 0.02585381269454956
Test Loss:  0.015517092309892178
Valid Loss:  0.02247241698205471
Epoch:  241  	Training Loss: 0.025846481323242188
Test Loss:  0.0155109828338027
Valid Loss:  0.02246534451842308
Epoch:  242  	Training Loss: 0.02583916485309601
Test Loss:  0.015504912473261356
Valid Loss:  0.022458314895629883
Epoch:  243  	Training Loss: 0.025831885635852814
Test Loss:  0.015498850494623184
Valid Loss:  0.022451307624578476
Epoch:  244  	Training Loss: 0.025824617594480515
Test Loss:  0.015492800623178482
Valid Loss:  0.022444313392043114
Epoch:  245  	Training Loss: 0.02581736445426941
Test Loss:  0.01548676285892725
Valid Loss:  0.022437334060668945
Epoch:  246  	Training Loss: 0.0258101224899292
Test Loss:  0.015480723232030869
Valid Loss:  0.02243037335574627
Epoch:  247  	Training Loss: 0.025802893564105034
Test Loss:  0.015474704094231129
Valid Loss:  0.022423427551984787
Epoch:  248  	Training Loss: 0.025795675814151764
Test Loss:  0.015468691475689411
Valid Loss:  0.0224164929240942
Epoch:  249  	Training Loss: 0.025788472965359688
Test Loss:  0.015462683513760567
Valid Loss:  0.022409576922655106
Epoch:  250  	Training Loss: 0.025781281292438507
Test Loss:  0.01545669324696064
Valid Loss:  0.022402673959732056
Epoch:  251  	Training Loss: 0.02577410265803337
Test Loss:  0.015450707636773586
Valid Loss:  0.022395789623260498
Epoch:  252  	Training Loss: 0.02576693519949913
Test Loss:  0.01544477604329586
Valid Loss:  0.022388970479369164
Epoch:  253  	Training Loss: 0.025759834796190262
Test Loss:  0.015438851900398731
Valid Loss:  0.022382162511348724
Epoch:  254  	Training Loss: 0.02575274556875229
Test Loss:  0.015432942658662796
Valid Loss:  0.022375373169779778
Epoch:  255  	Training Loss: 0.02574566751718521
Test Loss:  0.015427038073539734
Valid Loss:  0.022368596866726875
Epoch:  256  	Training Loss: 0.025738604366779327
Test Loss:  0.015421140938997269
Valid Loss:  0.022361839190125465
Epoch:  257  	Training Loss: 0.02573155239224434
Test Loss:  0.015415252186357975
Valid Loss:  0.022355088964104652
Epoch:  258  	Training Loss: 0.025724509730935097
Test Loss:  0.015409375540912151
Valid Loss:  0.022348355501890182
Epoch:  259  	Training Loss: 0.0257174801081419
Test Loss:  0.015403506346046925
Valid Loss:  0.022341642528772354
Epoch:  260  	Training Loss: 0.025710463523864746
Test Loss:  0.015397650189697742
Valid Loss:  0.022334938868880272
Epoch:  261  	Training Loss: 0.025703459978103638
Test Loss:  0.015391798689961433
Valid Loss:  0.022328250110149384
Epoch:  262  	Training Loss: 0.025696467608213425
Test Loss:  0.015385953709483147
Valid Loss:  0.02232157625257969
Epoch:  263  	Training Loss: 0.02568947896361351
Test Loss:  0.015380119904875755
Valid Loss:  0.022314907982945442
Epoch:  264  	Training Loss: 0.02568250708281994
Test Loss:  0.015374356880784035
Valid Loss:  0.02230820432305336
Epoch:  265  	Training Loss: 0.025675559416413307
Test Loss:  0.015368599444627762
Valid Loss:  0.022301513701677322
Epoch:  266  	Training Loss: 0.025668621063232422
Test Loss:  0.01536285225301981
Valid Loss:  0.02229483425617218
Epoch:  267  	Training Loss: 0.025661692023277283
Test Loss:  0.015357115305960178
Valid Loss:  0.02228817343711853
Epoch:  268  	Training Loss: 0.025654777884483337
Test Loss:  0.015351386740803719
Valid Loss:  0.02228151261806488
Epoch:  269  	Training Loss: 0.025647874921560287
Test Loss:  0.015345662832260132
Valid Loss:  0.022274866700172424
Epoch:  270  	Training Loss: 0.025640983134508133
Test Loss:  0.015339954756200314
Valid Loss:  0.022268231958150864
Epoch:  271  	Training Loss: 0.025634102523326874
Test Loss:  0.015334253199398518
Valid Loss:  0.022261615842580795
Epoch:  272  	Training Loss: 0.02562723308801651
Test Loss:  0.015328607521951199
Valid Loss:  0.0222550630569458
Epoch:  273  	Training Loss: 0.025620440021157265
Test Loss:  0.015322969295084476
Valid Loss:  0.022248525172472
Epoch:  274  	Training Loss: 0.025613661855459213
Test Loss:  0.015317393466830254
Valid Loss:  0.022241950035095215
Epoch:  275  	Training Loss: 0.025606900453567505
Test Loss:  0.015311832539737225
Valid Loss:  0.022235389798879623
Epoch:  276  	Training Loss: 0.025600150227546692
Test Loss:  0.015306277200579643
Valid Loss:  0.022228840738534927
Epoch:  277  	Training Loss: 0.025593414902687073
Test Loss:  0.015300729312002659
Valid Loss:  0.02222231589257717
Epoch:  278  	Training Loss: 0.0255866888910532
Test Loss:  0.015295193530619144
Valid Loss:  0.022215794771909714
Epoch:  279  	Training Loss: 0.02557997591793537
Test Loss:  0.015289664268493652
Valid Loss:  0.022209294140338898
Epoch:  280  	Training Loss: 0.02557327225804329
Test Loss:  0.015284141525626183
Valid Loss:  0.022202806547284126
Epoch:  281  	Training Loss: 0.02556658536195755
Test Loss:  0.015278630889952183
Valid Loss:  0.022196337580680847
Epoch:  282  	Training Loss: 0.025559909641742706
Test Loss:  0.015273148193955421
Valid Loss:  0.02218988910317421
Epoch:  283  	Training Loss: 0.025553259998559952
Test Loss:  0.015267671085894108
Valid Loss:  0.022183462977409363
 57%|█████▋    | 285/500 [03:20<02:17,  1.57it/s] 57%|█████▋    | 287/500 [03:20<01:39,  2.14it/s] 58%|█████▊    | 289/500 [03:20<01:12,  2.89it/s] 58%|█████▊    | 291/500 [03:26<04:06,  1.18s/it] 59%|█████▊    | 293/500 [03:26<02:54,  1.18it/s] 59%|█████▉    | 295/500 [03:27<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:27<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:27<01:06,  3.01it/s] 60%|██████    | 301/500 [03:33<03:58,  1.20s/it] 61%|██████    | 303/500 [03:33<02:49,  1.16it/s] 61%|██████    | 305/500 [03:34<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:34<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:34<01:04,  2.95it/s] 62%|██████▏   | 311/500 [03:40<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:40<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:40<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:41<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:41<01:01,  2.96it/s] 64%|██████▍   | 321/500 [03:47<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:47<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:47<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:47<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:48<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:54<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:54<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:54<01:40,  1.65it/s] 67%|██████▋   | 337/500 [03:54<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:54<00:53,  3.03it/s] 68%|██████▊   | 341/500 [04:01<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:01<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:01<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:01<01:10,  2.17it/s] 70%|██████▉   | 349/500 [04:01<00:52,  2.87it/s] 70%|███████   | 351/500 [04:08<02:57,  1.19s/it] 71%|███████   | 353/500 [04:08<02:05,  1.17it/s]Epoch:  284  	Training Loss: 0.025546621531248093
Test Loss:  0.015262200497090816
Valid Loss:  0.02217704989016056
Epoch:  285  	Training Loss: 0.025539997965097427
Test Loss:  0.015256743878126144
Valid Loss:  0.022170646116137505
Epoch:  286  	Training Loss: 0.025533385574817657
Test Loss:  0.015251287259161472
Valid Loss:  0.02216425910592079
Epoch:  287  	Training Loss: 0.025526780635118484
Test Loss:  0.015245847404003143
Valid Loss:  0.022157888859510422
Epoch:  288  	Training Loss: 0.025520185008645058
Test Loss:  0.015240410342812538
Valid Loss:  0.02215152606368065
Epoch:  289  	Training Loss: 0.025513609871268272
Test Loss:  0.015234981663525105
Valid Loss:  0.02214517816901207
Epoch:  290  	Training Loss: 0.025507040321826935
Test Loss:  0.015229565091431141
Valid Loss:  0.022138848900794983
Epoch:  291  	Training Loss: 0.025500483810901642
Test Loss:  0.0152241550385952
Valid Loss:  0.022132528945803642
Epoch:  292  	Training Loss: 0.025493934750556946
Test Loss:  0.015218783169984818
Valid Loss:  0.02212625928223133
Epoch:  293  	Training Loss: 0.025487449020147324
Test Loss:  0.01521342433989048
Valid Loss:  0.022120008245110512
Epoch:  294  	Training Loss: 0.025480974465608597
Test Loss:  0.015208074823021889
Valid Loss:  0.02211376652121544
Epoch:  295  	Training Loss: 0.025474514812231064
Test Loss:  0.015202733688056469
Valid Loss:  0.02210753783583641
Epoch:  296  	Training Loss: 0.025468062609434128
Test Loss:  0.015197396278381348
Valid Loss:  0.022101327776908875
Epoch:  297  	Training Loss: 0.025461621582508087
Test Loss:  0.015192067250609398
Valid Loss:  0.022095125168561935
Epoch:  298  	Training Loss: 0.025455191731452942
Test Loss:  0.015186765231192112
Valid Loss:  0.02208893559873104
Epoch:  299  	Training Loss: 0.02544877678155899
Test Loss:  0.015181516297161579
Valid Loss:  0.02208271436393261
Epoch:  300  	Training Loss: 0.02544238045811653
Test Loss:  0.015176275745034218
Valid Loss:  0.022076508030295372
Epoch:  301  	Training Loss: 0.02543598785996437
Test Loss:  0.015171043574810028
Valid Loss:  0.02207031473517418
Epoch:  302  	Training Loss: 0.025429610162973404
Test Loss:  0.015165832825005054
Valid Loss:  0.02206413634121418
Epoch:  303  	Training Loss: 0.025423254817724228
Test Loss:  0.015160622075200081
Valid Loss:  0.022057970985770226
Epoch:  304  	Training Loss: 0.02541690692305565
Test Loss:  0.015155426226556301
Valid Loss:  0.022051814943552017
Epoch:  305  	Training Loss: 0.025410570204257965
Test Loss:  0.015150237828493118
Valid Loss:  0.0220456812530756
Epoch:  306  	Training Loss: 0.025404244661331177
Test Loss:  0.015145054087042809
Valid Loss:  0.02203955315053463
Epoch:  307  	Training Loss: 0.025397934019565582
Test Loss:  0.015139883384108543
Valid Loss:  0.022033441811800003
Epoch:  308  	Training Loss: 0.025391630828380585
Test Loss:  0.0151347192004323
Valid Loss:  0.02202734537422657
Epoch:  309  	Training Loss: 0.025385338813066483
Test Loss:  0.015129568055272102
Valid Loss:  0.02202126756310463
Epoch:  310  	Training Loss: 0.025379057973623276
Test Loss:  0.015124419704079628
Valid Loss:  0.022015202790498734
Epoch:  311  	Training Loss: 0.025372792035341263
Test Loss:  0.01511927880346775
Valid Loss:  0.02200915291905403
Epoch:  312  	Training Loss: 0.025366531684994698
Test Loss:  0.01511418353766203
Valid Loss:  0.022003140300512314
Epoch:  313  	Training Loss: 0.025360316038131714
Test Loss:  0.015109091997146606
Valid Loss:  0.02199714258313179
Epoch:  314  	Training Loss: 0.025354113429784775
Test Loss:  0.015104014426469803
Valid Loss:  0.021991170942783356
Epoch:  315  	Training Loss: 0.02534792199730873
Test Loss:  0.015098942443728447
Valid Loss:  0.021985206753015518
Epoch:  316  	Training Loss: 0.025341741740703583
Test Loss:  0.015093877911567688
Valid Loss:  0.021979261189699173
Epoch:  317  	Training Loss: 0.02533557265996933
Test Loss:  0.015088824555277824
Valid Loss:  0.021973326802253723
Epoch:  318  	Training Loss: 0.025329412892460823
Test Loss:  0.015083778649568558
Valid Loss:  0.02196739986538887
Epoch:  319  	Training Loss: 0.02532326616346836
Test Loss:  0.01507873460650444
Valid Loss:  0.021961499005556107
Epoch:  320  	Training Loss: 0.025317130610346794
Test Loss:  0.015073706395924091
Valid Loss:  0.02195560559630394
Epoch:  321  	Training Loss: 0.025311008095741272
Test Loss:  0.015068684704601765
Valid Loss:  0.02194971963763237
Epoch:  322  	Training Loss: 0.025304894894361496
Test Loss:  0.015063696540892124
Valid Loss:  0.02194378152489662
Epoch:  323  	Training Loss: 0.025298776105046272
Test Loss:  0.015058672986924648
Valid Loss:  0.021937891840934753
Epoch:  324  	Training Loss: 0.025292668491601944
Test Loss:  0.015053706243634224
Valid Loss:  0.021931959316134453
Epoch:  325  	Training Loss: 0.02528657764196396
Test Loss:  0.015048745088279247
Valid Loss:  0.0219260361045599
Epoch:  326  	Training Loss: 0.02528049424290657
Test Loss:  0.015043795108795166
Valid Loss:  0.02192012593150139
Epoch:  327  	Training Loss: 0.025274425745010376
Test Loss:  0.0150388078764081
Valid Loss:  0.021914277225732803
Epoch:  328  	Training Loss: 0.02526836469769478
Test Loss:  0.01503387838602066
Valid Loss:  0.021908391267061234
Epoch:  329  	Training Loss: 0.025262314826250076
Test Loss:  0.015028947964310646
Valid Loss:  0.021902527660131454
Epoch:  330  	Training Loss: 0.02525627240538597
Test Loss:  0.015024028718471527
Valid Loss:  0.021896667778491974
Epoch:  331  	Training Loss: 0.025250248610973358
Test Loss:  0.015019113197922707
Valid Loss:  0.021890826523303986
Epoch:  332  	Training Loss: 0.025244228541851044
Test Loss:  0.01501421257853508
Valid Loss:  0.021884983405470848
Epoch:  333  	Training Loss: 0.025238215923309326
Test Loss:  0.015009322203695774
Valid Loss:  0.021879130974411964
Epoch:  334  	Training Loss: 0.025232210755348206
Test Loss:  0.015004437416791916
Valid Loss:  0.021873291581869125
Epoch:  335  	Training Loss: 0.02522621676325798
Test Loss:  0.014999555423855782
Valid Loss:  0.02186746522784233
Epoch:  336  	Training Loss: 0.02522023394703865
Test Loss:  0.014994687400758266
Valid Loss:  0.02186165191233158
Epoch:  337  	Training Loss: 0.025214262306690216
Test Loss:  0.014989828690886497
Valid Loss:  0.021855851635336876
Epoch:  338  	Training Loss: 0.025208301842212677
Test Loss:  0.014984974637627602
Valid Loss:  0.021850064396858215
Epoch:  339  	Training Loss: 0.025202345103025436
Test Loss:  0.014980129897594452
Valid Loss:  0.0218442901968956
Epoch:  340  	Training Loss: 0.025196408852934837
Test Loss:  0.014975295402109623
Valid Loss:  0.021838529035449028
Epoch:  341  	Training Loss: 0.025190476328134537
Test Loss:  0.014970466494560242
Valid Loss:  0.021832777187228203
Epoch:  342  	Training Loss: 0.02518455684185028
Test Loss:  0.01496566366404295
Valid Loss:  0.021827060729265213
Epoch:  343  	Training Loss: 0.02517867460846901
Test Loss:  0.014960870146751404
Valid Loss:  0.021821357309818268
Epoch:  344  	Training Loss: 0.025172807276248932
Test Loss:  0.014956087805330753
Valid Loss:  0.021815668791532516
Epoch:  345  	Training Loss: 0.025166943669319153
Test Loss:  0.014951308257877827
Valid Loss:  0.021809987723827362
Epoch:  346  	Training Loss: 0.025161094963550568
Test Loss:  0.014946534298360348
Valid Loss:  0.021804317831993103
Epoch:  347  	Training Loss: 0.02515525370836258
Test Loss:  0.014941774308681488
Valid Loss:  0.021798668429255486
Epoch:  348  	Training Loss: 0.025149423629045486
Test Loss:  0.014937017112970352
Valid Loss:  0.021793026477098465
Epoch:  349  	Training Loss: 0.02514360472559929
Test Loss:  0.014932269230484962
Valid Loss:  0.02178739383816719
Epoch:  350  	Training Loss: 0.02513779327273369
Test Loss:  0.01492752879858017
Valid Loss:  0.02178177610039711
Epoch:  351  	Training Loss: 0.02513199672102928
Test Loss:  0.0149227948859334
Valid Loss:  0.021776169538497925
Epoch:  352  	Training Loss: 0.025126203894615173
Test Loss:  0.014918102882802486
Valid Loss:  0.02177060768008232
Epoch:  353  	Training Loss: 0.02512047253549099
Test Loss:  0.014913409948348999
Valid Loss:  0.02176506072282791
Epoch:  354  	Training Loss: 0.0251147523522377
Test Loss:   71%|███████   | 355/500 [04:08<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:08<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:08<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:14<02:44,  1.19s/it] 73%|███████▎  | 363/500 [04:15<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:15<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:15<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:15<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:21<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:21<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:22<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:22<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:22<00:41,  2.93it/s] 76%|███████▌  | 381/500 [04:28<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:28<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:29<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:29<00:52,  2.17it/s] 78%|███████▊  | 389/500 [04:29<00:38,  2.91it/s] 78%|███████▊  | 391/500 [04:35<02:10,  1.19s/it] 79%|███████▊  | 393/500 [04:35<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:36<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:36<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:36<00:33,  2.98it/s] 80%|████████  | 401/500 [04:42<01:56,  1.18s/it] 81%|████████  | 403/500 [04:42<01:22,  1.18it/s] 81%|████████  | 405/500 [04:42<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:42<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:43<00:30,  2.95it/s] 82%|████████▏ | 411/500 [04:49<01:49,  1.23s/it] 83%|████████▎ | 413/500 [04:49<01:16,  1.14it/s] 83%|████████▎ | 415/500 [04:50<00:54,  1.57it/s] 83%|████████▎ | 417/500 [04:50<00:38,  2.15it/s] 84%|████████▍ | 419/500 [04:50<00:27,  2.90it/s] 84%|████████▍ | 421/500 [04:56<01:34,  1.20s/it] 85%|████████▍ | 423/500 [04:56<01:06,  1.16it/s]0.014908730052411556
Valid Loss:  0.021759523078799248
Epoch:  355  	Training Loss: 0.025109045207500458
Test Loss:  0.01490405760705471
Valid Loss:  0.021754000335931778
Epoch:  356  	Training Loss: 0.02510334551334381
Test Loss:  0.014899389818310738
Valid Loss:  0.021748486906290054
Epoch:  357  	Training Loss: 0.02509765699505806
Test Loss:  0.014894732274115086
Valid Loss:  0.021742988377809525
Epoch:  358  	Training Loss: 0.025091975927352905
Test Loss:  0.014890078455209732
Valid Loss:  0.02173749729990959
Epoch:  359  	Training Loss: 0.025086306035518646
Test Loss:  0.01488543301820755
Valid Loss:  0.021732019260525703
Epoch:  360  	Training Loss: 0.025080643594264984
Test Loss:  0.014880796894431114
Valid Loss:  0.021726557984948158
Epoch:  361  	Training Loss: 0.025074996054172516
Test Loss:  0.0148761672899127
Valid Loss:  0.02172110415995121
Epoch:  362  	Training Loss: 0.025069354102015495
Test Loss:  0.014871522784233093
Valid Loss:  0.021715622395277023
Epoch:  363  	Training Loss: 0.025063684210181236
Test Loss:  0.01486688107252121
Valid Loss:  0.02171015553176403
Epoch:  364  	Training Loss: 0.025058023631572723
Test Loss:  0.014862248674035072
Valid Loss:  0.021704696118831635
Epoch:  365  	Training Loss: 0.025052368640899658
Test Loss:  0.014857620000839233
Valid Loss:  0.021699246019124985
Epoch:  366  	Training Loss: 0.02504672110080719
Test Loss:  0.01485300250351429
Valid Loss:  0.021693818271160126
Epoch:  367  	Training Loss: 0.025041088461875916
Test Loss:  0.014848388731479645
Valid Loss:  0.021688388660550117
Epoch:  368  	Training Loss: 0.02503546141088009
Test Loss:  0.014843780547380447
Valid Loss:  0.0216829776763916
Epoch:  369  	Training Loss: 0.025029843673110008
Test Loss:  0.014839179813861847
Valid Loss:  0.021677574142813683
Epoch:  370  	Training Loss: 0.025024238973855972
Test Loss:  0.014834589324891567
Valid Loss:  0.02167218178510666
Epoch:  371  	Training Loss: 0.025018639862537384
Test Loss:  0.014830001629889011
Valid Loss:  0.02166679874062538
Epoch:  372  	Training Loss: 0.025013044476509094
Test Loss:  0.014825431630015373
Valid Loss:  0.021661432459950447
Epoch:  373  	Training Loss: 0.025007475167512894
Test Loss:  0.014820868149399757
Valid Loss:  0.02165607362985611
Epoch:  374  	Training Loss: 0.02500191703438759
Test Loss:  0.014816311188042164
Valid Loss:  0.02165072411298752
Epoch:  375  	Training Loss: 0.02499636635184288
Test Loss:  0.014811770059168339
Valid Loss:  0.02164538949728012
Epoch:  376  	Training Loss: 0.024990824982523918
Test Loss:  0.014807246625423431
Valid Loss:  0.021640067920088768
Epoch:  377  	Training Loss: 0.02498529478907585
Test Loss:  0.014802725985646248
Valid Loss:  0.02163476124405861
Epoch:  378  	Training Loss: 0.02497977204620838
Test Loss:  0.014798211865127087
Valid Loss:  0.021629463881254196
Epoch:  379  	Training Loss: 0.02497425675392151
Test Loss:  0.014793709851801395
Valid Loss:  0.021624183282256126
Epoch:  380  	Training Loss: 0.02496875263750553
Test Loss:  0.014789209701120853
Valid Loss:  0.021618906408548355
Epoch:  381  	Training Loss: 0.02496325597167015
Test Loss:  0.014784719794988632
Valid Loss:  0.021613646298646927
Epoch:  382  	Training Loss: 0.024957770481705666
Test Loss:  0.014780241996049881
Valid Loss:  0.021608391776680946
Epoch:  383  	Training Loss: 0.024952290579676628
Test Loss:  0.014775769785046577
Valid Loss:  0.021603140980005264
Epoch:  384  	Training Loss: 0.024946821853518486
Test Loss:  0.014771304093301296
Valid Loss:  0.021597908809781075
Epoch:  385  	Training Loss: 0.02494136244058609
Test Loss:  0.014766844920814037
Valid Loss:  0.02159268409013748
Epoch:  386  	Training Loss: 0.024935908615589142
Test Loss:  0.0147623922675848
Valid Loss:  0.021587468683719635
Epoch:  387  	Training Loss: 0.024930469691753387
Test Loss:  0.014757949858903885
Valid Loss:  0.021582266315817833
Epoch:  388  	Training Loss: 0.02492503449320793
Test Loss:  0.014753511175513268
Valid Loss:  0.021577075123786926
Epoch:  389  	Training Loss: 0.02491961233317852
Test Loss:  0.014749082736670971
Valid Loss:  0.021571895107626915
Epoch:  390  	Training Loss: 0.024914197623729706
Test Loss:  0.014744659885764122
Valid Loss:  0.0215667262673378
Epoch:  391  	Training Loss: 0.02490878850221634
Test Loss:  0.014740238897502422
Valid Loss:  0.02156156674027443
Epoch:  392  	Training Loss: 0.024903390556573868
Test Loss:  0.01473582349717617
Valid Loss:  0.021556392312049866
Epoch:  393  	Training Loss: 0.024897992610931396
Test Loss:  0.01473141461610794
Valid Loss:  0.021551230922341347
Epoch:  394  	Training Loss: 0.02489260397851467
Test Loss:  0.014727008529007435
Valid Loss:  0.021546080708503723
Epoch:  395  	Training Loss: 0.024887219071388245
Test Loss:  0.014722609892487526
Valid Loss:  0.021540943533182144
Epoch:  396  	Training Loss: 0.024881847202777863
Test Loss:  0.014718218706548214
Valid Loss:  0.021535810083150864
Epoch:  397  	Training Loss: 0.024876482784748077
Test Loss:  0.014713837765157223
Valid Loss:  0.021530695259571075
Epoch:  398  	Training Loss: 0.024871129542589188
Test Loss:  0.014709466136991978
Valid Loss:  0.021525558084249496
Epoch:  399  	Training Loss: 0.024865783751010895
Test Loss:  0.014705101028084755
Valid Loss:  0.02152043767273426
Epoch:  400  	Training Loss: 0.024860449135303497
Test Loss:  0.014700745232403278
Valid Loss:  0.02151532471179962
Epoch:  401  	Training Loss: 0.024855120107531548
Test Loss:  0.01469639502465725
Valid Loss:  0.021510222926735878
Epoch:  402  	Training Loss: 0.024849800392985344
Test Loss:  0.014692065306007862
Valid Loss:  0.021505137905478477
Epoch:  403  	Training Loss: 0.02484450861811638
Test Loss:  0.014687743037939072
Valid Loss:  0.02150006592273712
Epoch:  404  	Training Loss: 0.02483922615647316
Test Loss:  0.014683430083096027
Valid Loss:  0.02149500884115696
Epoch:  405  	Training Loss: 0.024833958595991135
Test Loss:  0.014679120853543282
Valid Loss:  0.021489953622221947
Epoch:  406  	Training Loss: 0.024828694760799408
Test Loss:  0.014674821868538857
Valid Loss:  0.02148490957915783
Epoch:  407  	Training Loss: 0.024823438376188278
Test Loss:  0.01467052847146988
Valid Loss:  0.021479880437254906
Epoch:  408  	Training Loss: 0.024818191304802895
Test Loss:  0.0146662387996912
Valid Loss:  0.02147486060857773
Epoch:  409  	Training Loss: 0.024812953546643257
Test Loss:  0.014661954715847969
Valid Loss:  0.021469846367836
Epoch:  410  	Training Loss: 0.024807725101709366
Test Loss:  0.014657678082585335
Valid Loss:  0.021464847028255463
Epoch:  411  	Training Loss: 0.024802502244710922
Test Loss:  0.014653412625193596
Valid Loss:  0.021459855139255524
Epoch:  412  	Training Loss: 0.024797290563583374
Test Loss:  0.014649132266640663
Valid Loss:  0.021454840898513794
Epoch:  413  	Training Loss: 0.024792056530714035
Test Loss:  0.014644861221313477
Valid Loss:  0.02144983597099781
Epoch:  414  	Training Loss: 0.024786826223134995
Test Loss:  0.014640597626566887
Valid Loss:  0.02144484594464302
Epoch:  415  	Training Loss: 0.024781608954072
Test Loss:  0.014636335894465446
Valid Loss:  0.02143985778093338
Epoch:  416  	Training Loss: 0.0247763954102993
Test Loss:  0.014632085338234901
Valid Loss:  0.021434884518384933
Epoch:  417  	Training Loss: 0.02477119490504265
Test Loss:  0.014627859927713871
Valid Loss:  0.02142992429435253
Epoch:  418  	Training Loss: 0.024765999987721443
Test Loss:  0.014623643830418587
Valid Loss:  0.021424973383545876
Epoch:  419  	Training Loss: 0.024760814383625984
Test Loss:  0.014619436115026474
Valid Loss:  0.021420026198029518
Epoch:  420  	Training Loss: 0.024755634367465973
Test Loss:  0.014615233056247234
Valid Loss:  0.021415095776319504
Epoch:  421  	Training Loss: 0.024750469252467155
Test Loss:  0.014611037448048592
Valid Loss:  0.021410170942544937
Epoch:  422  	Training Loss: 0.024745304137468338
Test Loss:  0.014606914483010769
Valid Loss:  0.021405329927802086
Epoch:  423  	Training Loss: 0.024740256369113922
Test Loss:  0.014602798037230968
Valid Loss:  0.02140050381422043
Epoch:  424  	Training Loss: 0.02473522163927555
Test Loss:  0.014598687179386616
Valid Loss:  0.021395672112703323
 85%|████████▌ | 425/500 [04:56<00:46,  1.60it/s] 85%|████████▌ | 427/500 [04:57<00:33,  2.19it/s] 86%|████████▌ | 429/500 [04:57<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:03<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:03<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:03<00:40,  1.59it/s] 87%|████████▋ | 437/500 [05:04<00:29,  2.15it/s] 88%|████████▊ | 439/500 [05:04<00:21,  2.88it/s] 88%|████████▊ | 441/500 [05:10<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:10<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:10<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:10<00:23,  2.21it/s] 90%|████████▉ | 449/500 [05:11<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:17<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:17<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:17<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:17<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:17<00:13,  2.96it/s] 92%|█████████▏| 461/500 [05:24<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:24<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:24<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:24<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:24<00:10,  2.93it/s] 94%|█████████▍| 471/500 [05:31<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:31<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:31<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:31<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:37<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:38<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:38<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:38<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:44<00:05,  1.18it/s]Epoch:  425  	Training Loss: 0.02473018690943718
Test Loss:  0.01459458377212286
Valid Loss:  0.02139086276292801
Epoch:  426  	Training Loss: 0.024725163355469704
Test Loss:  0.01459048967808485
Valid Loss:  0.02138606272637844
Epoch:  427  	Training Loss: 0.024720147252082825
Test Loss:  0.014586400240659714
Valid Loss:  0.02138126827776432
Epoch:  428  	Training Loss: 0.02471514418721199
Test Loss:  0.01458231545984745
Valid Loss:  0.021376486867666245
Epoch:  429  	Training Loss: 0.02471015229821205
Test Loss:  0.014578252099454403
Valid Loss:  0.021371690556406975
Epoch:  430  	Training Loss: 0.02470516785979271
Test Loss:  0.014574194326996803
Valid Loss:  0.021366897970438004
Epoch:  431  	Training Loss: 0.02470020018517971
Test Loss:  0.014570144936442375
Valid Loss:  0.02136213332414627
Epoch:  432  	Training Loss: 0.02469523437321186
Test Loss:  0.014566060155630112
Valid Loss:  0.02135731838643551
Epoch:  433  	Training Loss: 0.02469022199511528
Test Loss:  0.014561984688043594
Valid Loss:  0.021352512761950493
Epoch:  434  	Training Loss: 0.024685217067599297
Test Loss:  0.0145579157397151
Valid Loss:  0.021347716450691223
Epoch:  435  	Training Loss: 0.02468021959066391
Test Loss:  0.014553853310644627
Valid Loss:  0.0213429294526577
Epoch:  436  	Training Loss: 0.02467523142695427
Test Loss:  0.014549797400832176
Valid Loss:  0.02133815363049507
Epoch:  437  	Training Loss: 0.024670250713825226
Test Loss:  0.014545750804245472
Valid Loss:  0.02133338898420334
Epoch:  438  	Training Loss: 0.02466527745127678
Test Loss:  0.01454170886427164
Valid Loss:  0.021328631788492203
Epoch:  439  	Training Loss: 0.024660315364599228
Test Loss:  0.014537675306200981
Valid Loss:  0.02132388949394226
Epoch:  440  	Training Loss: 0.024655364453792572
Test Loss:  0.014533649198710918
Valid Loss:  0.021319158375263214
Epoch:  441  	Training Loss: 0.024650419130921364
Test Loss:  0.014529631473124027
Valid Loss:  0.021314430981874466
Epoch:  442  	Training Loss: 0.024645481258630753
Test Loss:  0.014525605365633965
Valid Loss:  0.021309690549969673
Epoch:  443  	Training Loss: 0.02464054338634014
Test Loss:  0.014521590434014797
Valid Loss:  0.021304963156580925
Epoch:  444  	Training Loss: 0.024635611101984978
Test Loss:  0.014517582952976227
Valid Loss:  0.021300245076417923
Epoch:  445  	Training Loss: 0.02463069185614586
Test Loss:  0.014513582922518253
Valid Loss:  0.021295540034770966
Epoch:  446  	Training Loss: 0.02462577447295189
Test Loss:  0.014509586617350578
Valid Loss:  0.021290842443704605
Epoch:  447  	Training Loss: 0.02462087571620941
Test Loss:  0.014505601488053799
Valid Loss:  0.02128615230321884
Epoch:  448  	Training Loss: 0.024615976959466934
Test Loss:  0.014501620084047318
Valid Loss:  0.021281475201249123
Epoch:  449  	Training Loss: 0.02461109310388565
Test Loss:  0.014497647061944008
Valid Loss:  0.02127681113779545
Epoch:  450  	Training Loss: 0.024606209248304367
Test Loss:  0.014493679627776146
Valid Loss:  0.021272150799632072
Epoch:  451  	Training Loss: 0.024601340293884277
Test Loss:  0.014489719644188881
Valid Loss:  0.02126750722527504
Epoch:  452  	Training Loss: 0.024596480652689934
Test Loss:  0.014485767111182213
Valid Loss:  0.021262820810079575
Epoch:  453  	Training Loss: 0.024591609835624695
Test Loss:  0.01448182575404644
Valid Loss:  0.021258138120174408
Epoch:  454  	Training Loss: 0.02458675391972065
Test Loss:  0.01447789091616869
Valid Loss:  0.021253470331430435
Epoch:  455  	Training Loss: 0.024581901729106903
Test Loss:  0.014473963528871536
Valid Loss:  0.02124880999326706
Epoch:  456  	Training Loss: 0.024577058851718903
Test Loss:  0.014470040798187256
Valid Loss:  0.02124415710568428
Epoch:  457  	Training Loss: 0.0245722234249115
Test Loss:  0.014466128312051296
Valid Loss:  0.021239517256617546
Epoch:  458  	Training Loss: 0.024567395448684692
Test Loss:  0.014462217688560486
Valid Loss:  0.021234888583421707
Epoch:  459  	Training Loss: 0.02456257864832878
Test Loss:  0.014458313584327698
Valid Loss:  0.021230269223451614
Epoch:  460  	Training Loss: 0.02455776557326317
Test Loss:  0.01445441972464323
Valid Loss:  0.021225661039352417
Epoch:  461  	Training Loss: 0.0245529655367136
Test Loss:  0.014450532384216785
Valid Loss:  0.021221056580543518
Epoch:  462  	Training Loss: 0.02454817108809948
Test Loss:  0.014446658082306385
Valid Loss:  0.021216461434960365
Epoch:  463  	Training Loss: 0.024543389678001404
Test Loss:  0.014442787505686283
Valid Loss:  0.02121187373995781
Epoch:  464  	Training Loss: 0.024538617581129074
Test Loss:  0.014438928104937077
Valid Loss:  0.02120729722082615
Epoch:  465  	Training Loss: 0.02453385666012764
Test Loss:  0.014435072429478168
Valid Loss:  0.021202730014920235
Epoch:  466  	Training Loss: 0.024529099464416504
Test Loss:  0.014431224204599857
Valid Loss:  0.021198172122240067
Epoch:  467  	Training Loss: 0.024524355307221413
Test Loss:  0.01442738063633442
Valid Loss:  0.021193625405430794
Epoch:  468  	Training Loss: 0.02451961487531662
Test Loss:  0.014423542656004429
Valid Loss:  0.021189086139202118
Epoch:  469  	Training Loss: 0.024514880031347275
Test Loss:  0.01441971492022276
Valid Loss:  0.02118455246090889
Epoch:  470  	Training Loss: 0.024510156363248825
Test Loss:  0.014415896497666836
Valid Loss:  0.021180041134357452
Epoch:  471  	Training Loss: 0.024505440145730972
Test Loss:  0.014412082731723785
Valid Loss:  0.021175526082515717
Epoch:  472  	Training Loss: 0.024500735104084015
Test Loss:  0.01440826803445816
Valid Loss:  0.02117100916802883
Epoch:  473  	Training Loss: 0.024496035650372505
Test Loss:  0.014404458925127983
Valid Loss:  0.021166499704122543
Epoch:  474  	Training Loss: 0.024491339921951294
Test Loss:  0.014400659129023552
Valid Loss:  0.02116200514137745
Epoch:  475  	Training Loss: 0.024486657232046127
Test Loss:  0.014396869577467442
Valid Loss:  0.021157514303922653
Epoch:  476  	Training Loss: 0.02448197826743126
Test Loss:  0.014393080957233906
Valid Loss:  0.021153032779693604
Epoch:  477  	Training Loss: 0.024477310478687286
Test Loss:  0.014389300718903542
Valid Loss:  0.02114856243133545
Epoch:  478  	Training Loss: 0.02447265014052391
Test Loss:  0.0143855269998312
Valid Loss:  0.02114410325884819
Epoch:  479  	Training Loss: 0.024467993527650833
Test Loss:  0.014381758868694305
Valid Loss:  0.021139655262231827
Epoch:  480  	Training Loss: 0.02446334809064865
Test Loss:  0.014377998188138008
Valid Loss:  0.021135209128260612
Epoch:  481  	Training Loss: 0.024458710104227066
Test Loss:  0.01437424123287201
Valid Loss:  0.021130772307515144
Epoch:  482  	Training Loss: 0.024454079568386078
Test Loss:  0.01437049824744463
Valid Loss:  0.02112632989883423
Epoch:  483  	Training Loss: 0.024449460208415985
Test Loss:  0.014366758987307549
Valid Loss:  0.021121904253959656
Epoch:  484  	Training Loss: 0.02444484643638134
Test Loss:  0.01436302624642849
Valid Loss:  0.02111748605966568
Epoch:  485  	Training Loss: 0.024440240114927292
Test Loss:  0.014359298162162304
Valid Loss:  0.0211130753159523
Epoch:  486  	Training Loss: 0.02443563938140869
Test Loss:  0.014355580322444439
Valid Loss:  0.02110867016017437
Epoch:  487  	Training Loss: 0.024431049823760986
Test Loss:  0.014351867139339447
Valid Loss:  0.02110428363084793
Epoch:  488  	Training Loss: 0.024426469579339027
Test Loss:  0.014348155818879604
Valid Loss:  0.02109989896416664
Epoch:  489  	Training Loss: 0.024421893060207367
Test Loss:  0.014344457536935806
Valid Loss:  0.0210955198854208
Epoch:  490  	Training Loss: 0.024417325854301453
Test Loss:  0.014340763911604881
Valid Loss:  0.021091153845191002
Epoch:  491  	Training Loss: 0.024412767961621284
Test Loss:  0.014337075874209404
Valid Loss:  0.02108680084347725
Epoch:  492  	Training Loss: 0.024408213794231415
Test Loss:  0.014333635568618774
Valid Loss:  0.021082744002342224
Epoch:  493  	Training Loss: 0.024403953924775124
Test Loss:  0.014330198988318443
Valid Loss:  0.021078698337078094
Epoch:  494  	Training Loss: 0.024399705231189728
Test Loss:  0.014326773583889008
Valid Loss:  0.021074654534459114
Epoch:  495  	Training Loss: 0.02439546212553978
Test Loss:  0.014323348179459572 99%|█████████▉| 495/500 [05:44<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:45<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:45<00:00,  3.00it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]

Valid Loss:  0.02107062377035618
Epoch:  496  	Training Loss: 0.02439122274518013
Test Loss:  0.014319933019578457
Valid Loss:  0.02106659486889839
Epoch:  497  	Training Loss: 0.024386994540691376
Test Loss:  0.014316518791019917
Valid Loss:  0.02106257528066635
Epoch:  498  	Training Loss: 0.02438277192413807
Test Loss:  0.014313111081719398
Valid Loss:  0.021058568730950356
Epoch:  499  	Training Loss: 0.02437855303287506
Test Loss:  0.014309724792838097
Valid Loss:  0.02105453982949257
Epoch:  500  	Training Loss: 0.024374350905418396
Test Loss:  0.014306340366601944
Valid Loss:  0.021050529554486275
seed is  8
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:32,  6.20s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.55it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.95it/s]  4%|▍         | 21/500 [00:20<09:42,  1.22s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:26<09:15,  1.18s/it]  7%|▋         | 33/500 [00:27<06:36,  1.18it/s]  7%|▋         | 35/500 [00:27<04:46,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:35,  2.97it/s]  8%|▊         | 41/500 [00:33<09:13,  1.21s/it]  9%|▊         | 43/500 [00:34<06:37,  1.15it/s]  9%|▉         | 45/500 [00:34<04:50,  1.57it/s]  9%|▉         | 47/500 [00:34<03:33,  2.12it/s] 10%|▉         | 49/500 [00:34<02:39,  2.82it/s] 10%|█         | 51/500 [00:40<09:02,  1.21s/it] 11%|█         | 53/500 [00:41<06:27,  1.15it/s] 11%|█         | 55/500 [00:41<04:38,  1.60it/s] 11%|█▏        | 57/500 [00:41<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:41<02:30,  2.93it/s] 12%|█▏        | 61/500 [00:47<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:48<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:48<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:48<02:23,  3.00it/s]Epoch:  1  	Training Loss: 0.030005237087607384
Test Loss:  0.00937797874212265
Valid Loss:  0.014009934850037098
Epoch:  2  	Training Loss: 0.016303330659866333
Test Loss:  0.04937652871012688
Valid Loss:  0.04874281585216522
Epoch:  3  	Training Loss: 0.04264300316572189
Test Loss:  0.018412180244922638
Valid Loss:  0.023051366209983826
Epoch:  4  	Training Loss: 0.026819106191396713
Test Loss:  0.01453061681240797
Valid Loss:  0.01925356313586235
Epoch:  5  	Training Loss: 0.022658130154013634
Test Loss:  0.013585032895207405
Valid Loss:  0.018387582153081894
Epoch:  6  	Training Loss: 0.021686628460884094
Test Loss:  0.013035273179411888
Valid Loss:  0.017910061404109
Epoch:  7  	Training Loss: 0.02112847939133644
Test Loss:  0.012711522169411182
Valid Loss:  0.017646659165620804
Epoch:  8  	Training Loss: 0.020801734179258347
Test Loss:  0.012503497302532196
Valid Loss:  0.017486155033111572
Epoch:  9  	Training Loss: 0.020591506734490395
Test Loss:  0.012360639870166779
Valid Loss:  0.017379077151417732
Epoch:  10  	Training Loss: 0.020443540066480637
Test Loss:  0.012252045795321465
Valid Loss:  0.017300408333539963
Epoch:  11  	Training Loss: 0.020329607650637627
Test Loss:  0.012127496302127838
Valid Loss:  0.01721324399113655
Epoch:  12  	Training Loss: 0.02020419016480446
Test Loss:  0.04418470710515976
Valid Loss:  0.0446709468960762
Epoch:  13  	Training Loss: 0.03897491842508316
Test Loss:  0.030351867899298668
Valid Loss:  0.035777851939201355
Epoch:  14  	Training Loss: 0.0404440276324749
Test Loss:  0.015654632821679115
Valid Loss:  0.021961823105812073
Epoch:  15  	Training Loss: 0.02573101595044136
Test Loss:  0.014500735327601433
Valid Loss:  0.02055129036307335
Epoch:  16  	Training Loss: 0.023928890004754066
Test Loss:  0.013533661141991615
Valid Loss:  0.019345242530107498
Epoch:  17  	Training Loss: 0.022386964410543442
Test Loss:  0.012668700888752937
Valid Loss:  0.01825430989265442
Epoch:  18  	Training Loss: 0.02100042998790741
Test Loss:  0.011869968846440315
Valid Loss:  0.01724335178732872
Epoch:  19  	Training Loss: 0.01972268521785736
Test Loss:  0.011099399998784065
Valid Loss:  0.016285231336951256
Epoch:  20  	Training Loss: 0.018505770713090897
Test Loss:  0.010292081162333488
Valid Loss:  0.015278580598533154
Epoch:  21  	Training Loss: 0.017284173518419266
Test Loss:  0.009472380392253399
Valid Loss:  0.014264513738453388
Epoch:  22  	Training Loss: 0.016083836555480957
Test Loss:  0.008657676167786121
Valid Loss:  0.01310667023062706
Epoch:  23  	Training Loss: 0.0143002113327384
Test Loss:  0.008316973224282265
Valid Loss:  0.012591258622705936
Epoch:  24  	Training Loss: 0.013566156849265099
Test Loss:  0.007955744862556458
Valid Loss:  0.012058448046445847
Epoch:  25  	Training Loss: 0.012889612466096878
Test Loss:  0.00775397103279829
Valid Loss:  0.011715047061443329
Epoch:  26  	Training Loss: 0.012419539503753185
Test Loss:  0.0076440139673650265
Valid Loss:  0.011503348127007484
Epoch:  27  	Training Loss: 0.012019041925668716
Test Loss:  0.007400174625217915
Valid Loss:  0.011149836704134941
Epoch:  28  	Training Loss: 0.01162626687437296
Test Loss:  0.007274179719388485
Valid Loss:  0.010914542712271214
Epoch:  29  	Training Loss: 0.011242902837693691
Test Loss:  0.007074328139424324
Valid Loss:  0.010634833946824074
Epoch:  30  	Training Loss: 0.01092803105711937
Test Loss:  0.006954682059586048
Valid Loss:  0.010419441387057304
Epoch:  31  	Training Loss: 0.01059621013700962
Test Loss:  0.006762346252799034
Valid Loss:  0.010158196091651917
Epoch:  32  	Training Loss: 0.010304713621735573
Test Loss:  0.0050251116044819355
Valid Loss:  0.008286461234092712
Epoch:  33  	Training Loss: 0.00885104201734066
Test Loss:  0.005299237556755543
Valid Loss:  0.0077072493731975555
Epoch:  34  	Training Loss: 0.00707185547798872
Test Loss:  0.0034199156798422337
Valid Loss:  0.005866529420018196
Epoch:  35  	Training Loss: 0.005859515629708767
Test Loss:  0.0038996899966150522
Valid Loss:  0.005893031135201454
Epoch:  36  	Training Loss: 0.00519934855401516
Test Loss:  0.0028786049224436283
Valid Loss:  0.004853065125644207
Epoch:  37  	Training Loss: 0.00457395613193512
Test Loss:  0.002765638753771782
Valid Loss:  0.004565897863358259
Epoch:  38  	Training Loss: 0.00419687619432807
Test Loss:  0.0025415662676095963
Valid Loss:  0.004251390695571899
Epoch:  39  	Training Loss: 0.003921427298337221
Test Loss:  0.0024157152511179447
Valid Loss:  0.004026729613542557
Epoch:  40  	Training Loss: 0.0036920751444995403
Test Loss:  0.002277111168950796
Valid Loss:  0.003807415021583438
Epoch:  41  	Training Loss: 0.003494324628263712
Test Loss:  0.002181373070925474
Valid Loss:  0.0036319829523563385
Epoch:  42  	Training Loss: 0.003319785464555025
Test Loss:  0.0023527168668806553
Valid Loss:  0.0036459281109273434
Epoch:  43  	Training Loss: 0.0031766716856509447
Test Loss:  0.0023904144763946533
Valid Loss:  0.003642742522060871
Epoch:  44  	Training Loss: 0.0031425815541297197
Test Loss:  0.002286474918946624
Valid Loss:  0.003568504936993122
Epoch:  45  	Training Loss: 0.0031272394116967916
Test Loss:  0.002394880633801222
Valid Loss:  0.0036066218744963408
Epoch:  46  	Training Loss: 0.0030922398436814547
Test Loss:  0.0023682028986513615
Valid Loss:  0.0035726032219827175
Epoch:  47  	Training Loss: 0.003069649450480938
Test Loss:  0.0023844484239816666
Valid Loss:  0.003565693274140358
Epoch:  48  	Training Loss: 0.003049817867577076
Test Loss:  0.002375244628638029
Valid Loss:  0.003547046333551407
Epoch:  49  	Training Loss: 0.003033390734344721
Test Loss:  0.0023635863326489925
Valid Loss:  0.0035278259310871363
Epoch:  50  	Training Loss: 0.0030193375423550606
Test Loss:  0.002371216658502817
Valid Loss:  0.003521301783621311
Epoch:  51  	Training Loss: 0.0030072564259171486
Test Loss:  0.002358857309445739
Valid Loss:  0.003504588734358549
Epoch:  52  	Training Loss: 0.0029971301555633545
Test Loss:  0.0024041002616286278
Valid Loss:  0.003486148314550519
Epoch:  53  	Training Loss: 0.0029590586200356483
Test Loss:  0.0022977287881076336
Valid Loss:  0.003417812753468752
Epoch:  54  	Training Loss: 0.0029526350554078817
Test Loss:  0.0023897422943264246
Valid Loss:  0.003462360240519047
Epoch:  55  	Training Loss: 0.00295213027857244
Test Loss:  0.0022492543794214725
Valid Loss:  0.00338280969299376
Epoch:  56  	Training Loss: 0.002951644593849778
Test Loss:  0.0024179713800549507
Valid Loss:  0.0034697744995355606
Epoch:  57  	Training Loss: 0.0029442557133734226
Test Loss:  0.002291846787557006
Valid Loss:  0.0033969732467085123
Epoch:  58  	Training Loss: 0.0029392321594059467
Test Loss:  0.00239397375844419
Valid Loss:  0.0034482614137232304
Epoch:  59  	Training Loss: 0.0029351101256906986
Test Loss:  0.002313795266672969
Valid Loss:  0.0034016012214124203
Epoch:  60  	Training Loss: 0.002932734787464142
Test Loss:  0.0023857848718762398
Valid Loss:  0.003437492996454239
Epoch:  61  	Training Loss: 0.0029298686422407627
Test Loss:  0.002342122606933117
Valid Loss:  0.0034115901216864586
Epoch:  62  	Training Loss: 0.0029279012233018875
Test Loss:  0.0023026594426482916
Valid Loss:  0.0033655643928796053
Epoch:  63  	Training Loss: 0.00287041743285954
Test Loss:  0.002234912943094969
Valid Loss:  0.003301618155092001
Epoch:  64  	Training Loss: 0.0028449688106775284
Test Loss:  0.002274103229865432
Valid Loss:  0.003321767086163163
Epoch:  65  	Training Loss: 0.0028418987058103085
Test Loss:  0.002271267119795084
Valid Loss:  0.003318015020340681
Epoch:  66  	Training Loss: 0.0028402297757565975
Test Loss:  0.0022801104933023453
Valid Loss:  0.0033217291347682476
Epoch:  67  	Training Loss: 0.002839004388079047
Test Loss:  0.0022720820270478725
Valid Loss:  0.003315835725516081
Epoch:  68  	Training Loss: 0.002838030457496643
Test Loss:  0.0022781877778470516
Valid Loss:  0.0033180760219693184
Epoch:  69  	Training Loss: 0.0028369836509227753
Test Loss:  0.002278998028486967
Valid Loss:  0.0033173654228448868
Epoch:  70  	Training Loss: 0.0028360888827592134
Test Loss:  0.002280028071254492
Valid Loss:  0.0033170755486935377
Epoch:  71  	Training Loss: 0.002835278632119298
Test Loss:   14%|█▍        | 71/500 [00:54<08:26,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:02,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:21,  1.63it/s] 15%|█▌        | 77/500 [00:55<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:01<08:07,  1.16s/it] 17%|█▋        | 83/500 [01:01<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.63it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.22it/s] 18%|█▊        | 89/500 [01:02<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:08<08:00,  1.17s/it] 19%|█▊        | 93/500 [01:08<05:43,  1.19it/s] 19%|█▉        | 95/500 [01:08<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:15<07:42,  1.16s/it] 21%|██        | 103/500 [01:15<05:30,  1.20it/s] 21%|██        | 105/500 [01:15<03:58,  1.66it/s] 21%|██▏       | 107/500 [01:15<02:53,  2.27it/s] 22%|██▏       | 109/500 [01:15<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:21<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:22<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:22<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:22<02:12,  2.87it/s] 24%|██▍       | 121/500 [01:28<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:53,  1.60it/s] 25%|██▌       | 127/500 [01:29<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:29<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:35<07:17,  1.19s/it] 27%|██▋       | 133/500 [01:35<05:12,  1.18it/s] 27%|██▋       | 135/500 [01:36<03:44,  1.63it/s] 27%|██▋       | 137/500 [01:36<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:36<02:00,  2.99it/s]0.002280280226841569
Valid Loss:  0.003316195448860526
Epoch:  72  	Training Loss: 0.0028345498722046614
Test Loss:  0.00222119502723217
Valid Loss:  0.0032380768097937107
Epoch:  73  	Training Loss: 0.0027935700491070747
Test Loss:  0.002249083947390318
Valid Loss:  0.003258409444242716
Epoch:  74  	Training Loss: 0.002777879126369953
Test Loss:  0.0022085560485720634
Valid Loss:  0.003219928592443466
Epoch:  75  	Training Loss: 0.002768066246062517
Test Loss:  0.002225938718765974
Valid Loss:  0.00323017337359488
Epoch:  76  	Training Loss: 0.002759319031611085
Test Loss:  0.0022149879951030016
Valid Loss:  0.0032164109870791435
Epoch:  77  	Training Loss: 0.0027523606549948454
Test Loss:  0.002216027583926916
Valid Loss:  0.003213042626157403
Epoch:  78  	Training Loss: 0.002746272599324584
Test Loss:  0.002212156541645527
Valid Loss:  0.0032046097330749035
Epoch:  79  	Training Loss: 0.002740579191595316
Test Loss:  0.002212472027167678
Valid Loss:  0.00320261437445879
Epoch:  80  	Training Loss: 0.0027356003411114216
Test Loss:  0.002205747412517667
Valid Loss:  0.0031939814798533916
Epoch:  81  	Training Loss: 0.00273065734654665
Test Loss:  0.002205049619078636
Valid Loss:  0.003190085291862488
Epoch:  82  	Training Loss: 0.002726128324866295
Test Loss:  0.002188802696764469
Valid Loss:  0.003178403014317155
Epoch:  83  	Training Loss: 0.002718291711062193
Test Loss:  0.002180578652769327
Valid Loss:  0.003172163385897875
Epoch:  84  	Training Loss: 0.0027131156530231237
Test Loss:  0.0021762014366686344
Valid Loss:  0.003168603405356407
Epoch:  85  	Training Loss: 0.0027094578836113214
Test Loss:  0.0021718814969062805
Valid Loss:  0.0031651684548705816
Epoch:  86  	Training Loss: 0.0027064750902354717
Test Loss:  0.0021702961530536413
Valid Loss:  0.0031633044127374887
Epoch:  87  	Training Loss: 0.002704053185880184
Test Loss:  0.002167381811887026
Valid Loss:  0.003160769585520029
Epoch:  88  	Training Loss: 0.00270208646543324
Test Loss:  0.00216696597635746
Valid Loss:  0.003159549552947283
Epoch:  89  	Training Loss: 0.002700416138395667
Test Loss:  0.002165301702916622
Valid Loss:  0.0031575257889926434
Epoch:  90  	Training Loss: 0.002699042670428753
Test Loss:  0.002165860030800104
Valid Loss:  0.003156594466418028
Epoch:  91  	Training Loss: 0.0026978112291544676
Test Loss:  0.0021660360507667065
Valid Loss:  0.0031556105241179466
Epoch:  92  	Training Loss: 0.0026967180892825127
Test Loss:  0.0019225586438551545
Valid Loss:  0.0028957799077033997
Epoch:  93  	Training Loss: 0.0025195961352437735
Test Loss:  0.0017758416943252087
Valid Loss:  0.0027207189705222845
Epoch:  94  	Training Loss: 0.0023811631835997105
Test Loss:  0.0016498586628586054
Valid Loss:  0.002575170248746872
Epoch:  95  	Training Loss: 0.002269570715725422
Test Loss:  0.0015683308010920882
Valid Loss:  0.002477570902556181
Epoch:  96  	Training Loss: 0.0021792431361973286
Test Loss:  0.0014918963424861431
Valid Loss:  0.0023955292999744415
Epoch:  97  	Training Loss: 0.002103665843605995
Test Loss:  0.0014331782003864646
Valid Loss:  0.0023280547466129065
Epoch:  98  	Training Loss: 0.002042209031060338
Test Loss:  0.0013790619559586048
Valid Loss:  0.00227546039968729
Epoch:  99  	Training Loss: 0.001993729267269373
Test Loss:  0.0013370598899200559
Valid Loss:  0.002235530409961939
Epoch:  100  	Training Loss: 0.001956815365701914
Test Loss:  0.0012999498285353184
Valid Loss:  0.002209094353020191
Epoch:  101  	Training Loss: 0.0019279590342193842
Test Loss:  0.001254179165698588
Valid Loss:  0.00217673322185874
Epoch:  102  	Training Loss: 0.0019051553681492805
Test Loss:  0.0012845552992075682
Valid Loss:  0.002180898329243064
Epoch:  103  	Training Loss: 0.0018842179561033845
Test Loss:  0.0012962482869625092
Valid Loss:  0.002178447786718607
Epoch:  104  	Training Loss: 0.0018741816747933626
Test Loss:  0.0013137406203895807
Valid Loss:  0.0021831654012203217
Epoch:  105  	Training Loss: 0.001869779429398477
Test Loss:  0.0013200428802520037
Valid Loss:  0.0021828520111739635
Epoch:  106  	Training Loss: 0.0018678755732253194
Test Loss:  0.001327418489381671
Valid Loss:  0.0021840385161340237
Epoch:  107  	Training Loss: 0.0018667224794626236
Test Loss:  0.0013290559872984886
Valid Loss:  0.0021834620274603367
Epoch:  108  	Training Loss: 0.001866198261268437
Test Loss:  0.0013330643996596336
Valid Loss:  0.0021846769377589226
Epoch:  109  	Training Loss: 0.0018658023327589035
Test Loss:  0.0013333475217223167
Valid Loss:  0.0021838860120624304
Epoch:  110  	Training Loss: 0.0018655906897038221
Test Loss:  0.0013360013253986835
Valid Loss:  0.0021849311888217926
Epoch:  111  	Training Loss: 0.0018655025633051991
Test Loss:  0.0013346733758226037
Valid Loss:  0.0021839113906025887
Epoch:  112  	Training Loss: 0.0018654600717127323
Test Loss:  0.001325179124251008
Valid Loss:  0.0021675536409020424
Epoch:  113  	Training Loss: 0.0018482215236872435
Test Loss:  0.0013117038179188967
Valid Loss:  0.0021382728591561317
Epoch:  114  	Training Loss: 0.0018182090716436505
Test Loss:  0.0012916846899315715
Valid Loss:  0.002101476304233074
Epoch:  115  	Training Loss: 0.0017785069067031145
Test Loss:  0.0012802360579371452
Valid Loss:  0.002071885857731104
Epoch:  116  	Training Loss: 0.0017480221576988697
Test Loss:  0.0012767326552420855
Valid Loss:  0.0020574850495904684
Epoch:  117  	Training Loss: 0.0017312881536781788
Test Loss:  0.0012778467498719692
Valid Loss:  0.0020505771972239017
Epoch:  118  	Training Loss: 0.001721671549603343
Test Loss:  0.0012809776235371828
Valid Loss:  0.002046348061412573
Epoch:  119  	Training Loss: 0.0017155706882476807
Test Loss:  0.0012836569221690297
Valid Loss:  0.0020427904091775417
Epoch:  120  	Training Loss: 0.0017110554035753012
Test Loss:  0.0012842707801610231
Valid Loss:  0.0020396513864398003
Epoch:  121  	Training Loss: 0.001707527437247336
Test Loss:  0.0012847494799643755
Valid Loss:  0.002037057653069496
Epoch:  122  	Training Loss: 0.0017044509295374155
Test Loss:  0.0012219224590808153
Valid Loss:  0.001994962338358164
Epoch:  123  	Training Loss: 0.001666949363425374
Test Loss:  0.0011802581138908863
Valid Loss:  0.00196518050506711
Epoch:  124  	Training Loss: 0.0016380895394831896
Test Loss:  0.0011507479939609766
Valid Loss:  0.0019420250318944454
Epoch:  125  	Training Loss: 0.001616857131011784
Test Loss:  0.0011238891165703535
Valid Loss:  0.0019201617687940598
Epoch:  126  	Training Loss: 0.0015988985542207956
Test Loss:  0.0011028004810214043
Valid Loss:  0.0019024075008928776
Epoch:  127  	Training Loss: 0.0015837191604077816
Test Loss:  0.001085505005903542
Valid Loss:  0.001887593069113791
Epoch:  128  	Training Loss: 0.0015706871636211872
Test Loss:  0.0010733354138210416
Valid Loss:  0.001877360395155847
Epoch:  129  	Training Loss: 0.0015591975534334779
Test Loss:  0.0010594847844913602
Valid Loss:  0.001866605831310153
Epoch:  130  	Training Loss: 0.0015493495156988502
Test Loss:  0.0010516097536310554
Valid Loss:  0.001859892625361681
Epoch:  131  	Training Loss: 0.001540744793601334
Test Loss:  0.001041519339196384
Valid Loss:  0.0018518457654863596
Epoch:  132  	Training Loss: 0.0015331299509853125
Test Loss:  0.001054559019394219
Valid Loss:  0.0018506975611671805
Epoch:  133  	Training Loss: 0.001521073980256915
Test Loss:  0.001048138365149498
Valid Loss:  0.0018284255638718605
Epoch:  134  	Training Loss: 0.0015007455367594957
Test Loss:  0.001046472112648189
Valid Loss:  0.0018248093547299504
Epoch:  135  	Training Loss: 0.0014989296905696392
Test Loss:  0.0010471041314303875
Valid Loss:  0.0018228139961138368
Epoch:  136  	Training Loss: 0.0014973940560594201
Test Loss:  0.0010450431145727634
Valid Loss:  0.0018203060608357191
Epoch:  137  	Training Loss: 0.0014961992856115103
Test Loss:  0.0010426021181046963
Valid Loss:  0.001818149583414197
Epoch:  138  	Training Loss: 0.0014952023047953844
Test Loss:  0.0010383445769548416
Valid Loss:  0.001814728369936347
Epoch:  139  	Training Loss: 0.0014943606220185757
Test Loss:  0.0010402408661320806
Valid Loss:  0.0018156201113015413
Epoch:  140  	Training Loss: 0.0014936577063053846
Test Loss:  0.0010286893229931593
 28%|██▊       | 141/500 [01:42<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:43<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:43<01:57,  3.00it/s] 30%|███       | 151/500 [01:49<06:48,  1.17s/it] 31%|███       | 153/500 [01:49<04:51,  1.19it/s] 31%|███       | 155/500 [01:49<03:29,  1.64it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:56<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:56<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:56<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.22it/s] 34%|███▍      | 169/500 [01:56<01:52,  2.94it/s] 34%|███▍      | 171/500 [02:03<06:26,  1.17s/it] 35%|███▍      | 173/500 [02:03<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:03<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:03<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:09<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:10<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:10<03:13,  1.62it/s] 37%|███▋      | 187/500 [02:10<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:10<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:16<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:16<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:16<03:05,  1.65it/s] 39%|███▉      | 197/500 [02:17<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:17<01:39,  3.03it/s] 40%|████      | 201/500 [02:23<05:48,  1.17s/it] 41%|████      | 203/500 [02:23<04:08,  1.19it/s] 41%|████      | 205/500 [02:23<02:59,  1.65it/s] 41%|████▏     | 207/500 [02:23<02:10,  2.25it/s]Valid Loss:  0.001808147644624114
Epoch:  141  	Training Loss: 0.0014932714402675629
Test Loss:  0.001035774126648903
Valid Loss:  0.0018115402199327946
Epoch:  142  	Training Loss: 0.0014924362767487764
Test Loss:  0.0010347279021516442
Valid Loss:  0.0018098686123266816
Epoch:  143  	Training Loss: 0.0014912602491676807
Test Loss:  0.0010342758614569902
Valid Loss:  0.0018086438067257404
Epoch:  144  	Training Loss: 0.001490163616836071
Test Loss:  0.0010341241722926497
Valid Loss:  0.0018077462445944548
Epoch:  145  	Training Loss: 0.0014891645405441523
Test Loss:  0.001034155604429543
Valid Loss:  0.0018069949001073837
Epoch:  146  	Training Loss: 0.0014882422983646393
Test Loss:  0.0010343074100092053
Valid Loss:  0.0018062845338135958
Epoch:  147  	Training Loss: 0.0014873608015477657
Test Loss:  0.0010346033377572894
Valid Loss:  0.0018056582193821669
Epoch:  148  	Training Loss: 0.0014865549746900797
Test Loss:  0.0010348729556426406
Valid Loss:  0.0018050784710794687
Epoch:  149  	Training Loss: 0.0014857770875096321
Test Loss:  0.0010351346572861075
Valid Loss:  0.0018045217730104923
Epoch:  150  	Training Loss: 0.0014850546140223742
Test Loss:  0.0010354097466915846
Valid Loss:  0.0018040180439129472
Epoch:  151  	Training Loss: 0.0014843789394944906
Test Loss:  0.001035671797581017
Valid Loss:  0.0018035511020570993
Epoch:  152  	Training Loss: 0.0014837344642728567
Test Loss:  0.001005204627290368
Valid Loss:  0.0017290700925514102
Epoch:  153  	Training Loss: 0.0014035941567271948
Test Loss:  0.0009538092417642474
Valid Loss:  0.0016544787213206291
Epoch:  154  	Training Loss: 0.001344029325991869
Test Loss:  0.0009157699532806873
Valid Loss:  0.0016093377489596605
Epoch:  155  	Training Loss: 0.0013175487983971834
Test Loss:  0.0009014903916977346
Valid Loss:  0.0015900684520602226
Epoch:  156  	Training Loss: 0.001304397126659751
Test Loss:  0.0008890035096555948
Valid Loss:  0.0015758844092488289
Epoch:  157  	Training Loss: 0.0012969837989658117
Test Loss:  0.0008830648148432374
Valid Loss:  0.0015675568720325828
Epoch:  158  	Training Loss: 0.00129184580873698
Test Loss:  0.0008796826004981995
Valid Loss:  0.0015615809243172407
Epoch:  159  	Training Loss: 0.001287512481212616
Test Loss:  0.0008753422880545259
Valid Loss:  0.0015560982283204794
Epoch:  160  	Training Loss: 0.0012838090769946575
Test Loss:  0.0008730656118132174
Valid Loss:  0.0015519032021984458
Epoch:  161  	Training Loss: 0.0012804260477423668
Test Loss:  0.0008683337364345789
Valid Loss:  0.001547425054013729
Epoch:  162  	Training Loss: 0.0012773217167705297
Test Loss:  0.0008510934421792626
Valid Loss:  0.001534626237116754
Epoch:  163  	Training Loss: 0.0012675144243985415
Test Loss:  0.000843683781567961
Valid Loss:  0.0015271882293745875
Epoch:  164  	Training Loss: 0.001258605858311057
Test Loss:  0.0008364192908629775
Valid Loss:  0.001519742887467146
Epoch:  165  	Training Loss: 0.0012503779726102948
Test Loss:  0.0008294280851259828
Valid Loss:  0.0015127265360206366
Epoch:  166  	Training Loss: 0.0012430964270606637
Test Loss:  0.000824692309834063
Valid Loss:  0.0015069692162796855
Epoch:  167  	Training Loss: 0.0012360895052552223
Test Loss:  0.000819118635263294
Valid Loss:  0.0015006434405222535
Epoch:  168  	Training Loss: 0.0012294247280806303
Test Loss:  0.0008140113204717636
Valid Loss:  0.0014948915923014283
Epoch:  169  	Training Loss: 0.0012231908040121198
Test Loss:  0.0008090114570222795
Valid Loss:  0.001489729154855013
Epoch:  170  	Training Loss: 0.0012171671260148287
Test Loss:  0.000804371084086597
Valid Loss:  0.001484798383899033
Epoch:  171  	Training Loss: 0.001211554161272943
Test Loss:  0.0007994893239811063
Valid Loss:  0.0014798552729189396
Epoch:  172  	Training Loss: 0.0012061697198078036
Test Loss:  0.0008046270813792944
Valid Loss:  0.0014692198019474745
Epoch:  173  	Training Loss: 0.0011941150296479464
Test Loss:  0.0008003129041753709
Valid Loss:  0.0014600525610148907
Epoch:  174  	Training Loss: 0.0011872880859300494
Test Loss:  0.0007946165278553963
Valid Loss:  0.0014534189831465483
Epoch:  175  	Training Loss: 0.0011831948067992926
Test Loss:  0.0007911628345027566
Valid Loss:  0.001448329072445631
Epoch:  176  	Training Loss: 0.0011800166685134172
Test Loss:  0.0007879291079007089
Valid Loss:  0.0014440333470702171
Epoch:  177  	Training Loss: 0.0011774911545217037
Test Loss:  0.0007856521988287568
Valid Loss:  0.0014407222624868155
Epoch:  178  	Training Loss: 0.0011752869468182325
Test Loss:  0.0007837973535060883
Valid Loss:  0.0014379463391378522
Epoch:  179  	Training Loss: 0.0011733483988791704
Test Loss:  0.0007820811588317156
Valid Loss:  0.0014354572631418705
Epoch:  180  	Training Loss: 0.0011716726003214717
Test Loss:  0.0007802344625815749
Valid Loss:  0.0014332528226077557
Epoch:  181  	Training Loss: 0.0011702049523591995
Test Loss:  0.0007789181545376778
Valid Loss:  0.0014314324362203479
Epoch:  182  	Training Loss: 0.0011689139064401388
Test Loss:  0.000769462960306555
Valid Loss:  0.0014238734729588032
Epoch:  183  	Training Loss: 0.0011622615857049823
Test Loss:  0.0007658457616344094
Valid Loss:  0.0014197741402313113
Epoch:  184  	Training Loss: 0.0011571113718673587
Test Loss:  0.0007613855414092541
Valid Loss:  0.001415088539943099
Epoch:  185  	Training Loss: 0.0011527487076818943
Test Loss:  0.0007586591527797282
Valid Loss:  0.0014113527722656727
Epoch:  186  	Training Loss: 0.001148831914179027
Test Loss:  0.0007551254821009934
Valid Loss:  0.0014074882492423058
Epoch:  187  	Training Loss: 0.0011453510960564017
Test Loss:  0.0007524455431848764
Valid Loss:  0.0014042176771908998
Epoch:  188  	Training Loss: 0.0011422901879996061
Test Loss:  0.0007501924410462379
Valid Loss:  0.001401182496920228
Epoch:  189  	Training Loss: 0.0011395936599001288
Test Loss:  0.0007479070918634534
Valid Loss:  0.001398466294631362
Epoch:  190  	Training Loss: 0.0011373513843864202
Test Loss:  0.000745912897400558
Valid Loss:  0.00139613205101341
Epoch:  191  	Training Loss: 0.0011353644076734781
Test Loss:  0.0007447336101904511
Valid Loss:  0.0013941805809736252
Epoch:  192  	Training Loss: 0.0011335625313222408
Test Loss:  0.0007479104679077864
Valid Loss:  0.0013915614690631628
Epoch:  193  	Training Loss: 0.001130031538195908
Test Loss:  0.000747238751500845
Valid Loss:  0.0013884198851883411
Epoch:  194  	Training Loss: 0.0011276861187070608
Test Loss:  0.0007458206964656711
Valid Loss:  0.0013853060081601143
Epoch:  195  	Training Loss: 0.00112576421815902
Test Loss:  0.0007443964132107794
Valid Loss:  0.0013825276400893927
Epoch:  196  	Training Loss: 0.001124120783060789
Test Loss:  0.0007425560615956783
Valid Loss:  0.0013799513690173626
Epoch:  197  	Training Loss: 0.0011226683855056763
Test Loss:  0.0007413725252263248
Valid Loss:  0.0013777916319668293
Epoch:  198  	Training Loss: 0.0011212807148694992
Test Loss:  0.0007400682661682367
Valid Loss:  0.0013758460991084576
Epoch:  199  	Training Loss: 0.0011199925793334842
Test Loss:  0.0007390471873804927
Valid Loss:  0.001374076004140079
Epoch:  200  	Training Loss: 0.0011187357595190406
Test Loss:  0.0007380174356512725
Valid Loss:  0.0013723834417760372
Epoch:  201  	Training Loss: 0.0011175269028171897
Test Loss:  0.0007370012463070452
Valid Loss:  0.0013707566540688276
Epoch:  202  	Training Loss: 0.0011163532035425305
Test Loss:  0.0007134323241189122
Valid Loss:  0.0013488112017512321
Epoch:  203  	Training Loss: 0.0011030395980924368
Test Loss:  0.0007064672536216676
Valid Loss:  0.0013390264939516783
Epoch:  204  	Training Loss: 0.0010933114681392908
Test Loss:  0.0007006455562077463
Valid Loss:  0.0013304043095558882
Epoch:  205  	Training Loss: 0.0010844815988093615
Test Loss:  0.0006956534925848246
Valid Loss:  0.0013229507021605968
Epoch:  206  	Training Loss: 0.0010765864280983806
Test Loss:  0.000690656597726047
Valid Loss:  0.0013158294605091214
Epoch:  207  	Training Loss: 0.001069273566827178
Test Loss:  0.0006857689004391432
Valid Loss:  0.001309082843363285
Epoch:  208  	Training Loss: 0.0010624369606375694
Test Loss:  0.0006814576918259263
Valid Loss:  0.0013030578847974539
 42%|████▏     | 209/500 [02:24<01:36,  3.03it/s] 42%|████▏     | 211/500 [02:30<05:35,  1.16s/it] 43%|████▎     | 213/500 [02:30<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:30<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:30<01:35,  2.94it/s] 44%|████▍     | 221/500 [02:37<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:37<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:37<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:37<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:50<09:25,  2.10s/it] 47%|████▋     | 233/500 [02:50<06:38,  1.49s/it] 47%|████▋     | 235/500 [02:50<04:42,  1.07s/it] 47%|████▋     | 237/500 [02:50<03:21,  1.31it/s] 48%|████▊     | 239/500 [02:50<02:24,  1.80it/s] 48%|████▊     | 241/500 [02:57<05:49,  1.35s/it] 49%|████▊     | 243/500 [02:57<04:07,  1.04it/s] 49%|████▉     | 245/500 [02:57<02:56,  1.44it/s] 49%|████▉     | 247/500 [02:57<02:07,  1.98it/s] 50%|████▉     | 249/500 [02:57<01:33,  2.69it/s] 50%|█████     | 251/500 [03:04<05:05,  1.23s/it] 51%|█████     | 253/500 [03:04<03:37,  1.13it/s] 51%|█████     | 255/500 [03:04<02:36,  1.57it/s] 51%|█████▏    | 257/500 [03:04<01:53,  2.15it/s] 52%|█████▏    | 259/500 [03:04<01:23,  2.90it/s] 52%|█████▏    | 261/500 [03:10<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:10<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:11<02:22,  1.64it/s] 53%|█████▎    | 267/500 [03:11<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:11<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:17<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:17<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:17<02:19,  1.62it/s]Epoch:  209  	Training Loss: 0.0010560471564531326
Test Loss:  0.0006763871060684323
Valid Loss:  0.0012965097557753325
Epoch:  210  	Training Loss: 0.001049978076480329
Test Loss:  0.0006713555776514113
Valid Loss:  0.0012899572029709816
Epoch:  211  	Training Loss: 0.00104412657674402
Test Loss:  0.0006669915746897459
Valid Loss:  0.0012841701973229647
Epoch:  212  	Training Loss: 0.0010385204805061221
Test Loss:  0.0006846357136964798
Valid Loss:  0.0012743246043100953
Epoch:  213  	Training Loss: 0.0010274816304445267
Test Loss:  0.0006769578903913498
Valid Loss:  0.0012620151974260807
Epoch:  214  	Training Loss: 0.001022281707264483
Test Loss:  0.0006756589282304049
Valid Loss:  0.001255874172784388
Epoch:  215  	Training Loss: 0.00101849518250674
Test Loss:  0.0006736865034326911
Valid Loss:  0.0012505203485488892
Epoch:  216  	Training Loss: 0.0010150804882869124
Test Loss:  0.0006717543583363295
Valid Loss:  0.0012458832934498787
Epoch:  217  	Training Loss: 0.0010119269136339426
Test Loss:  0.0006681046797893941
Valid Loss:  0.0012412769719958305
Epoch:  218  	Training Loss: 0.0010091461008414626
Test Loss:  0.0006667196284979582
Valid Loss:  0.0012377368984743953
Epoch:  219  	Training Loss: 0.0010064223315566778
Test Loss:  0.0006651621079072356
Valid Loss:  0.0012340012472122908
Epoch:  220  	Training Loss: 0.0010038225445896387
Test Loss:  0.0006629359559156001
Valid Loss:  0.0012303882976993918
Epoch:  221  	Training Loss: 0.00100133684463799
Test Loss:  0.0006616467144340277
Valid Loss:  0.0012271966552361846
Epoch:  222  	Training Loss: 0.0009989016689360142
Test Loss:  0.000654696486890316
Valid Loss:  0.0012213477166369557
Epoch:  223  	Training Loss: 0.0009971766266971827
Test Loss:  0.0006534533458761871
Valid Loss:  0.0012200060300529003
Epoch:  224  	Training Loss: 0.0009957030415534973
Test Loss:  0.0006459510186687112
Valid Loss:  0.0012138570891693234
Epoch:  225  	Training Loss: 0.00099510932341218
Test Loss:  0.0006489413790404797
Valid Loss:  0.0012136194854974747
Epoch:  226  	Training Loss: 0.0009935245616361499
Test Loss:  0.0006490786327049136
Valid Loss:  0.0012131285620853305
Epoch:  227  	Training Loss: 0.0009922656463459134
Test Loss:  0.0006449162028729916
Valid Loss:  0.0012093152618035674
Epoch:  228  	Training Loss: 0.000991558306850493
Test Loss:  0.0006463119643740356
Valid Loss:  0.0012104553170502186
Epoch:  229  	Training Loss: 0.0009907522471621633
Test Loss:  0.0006389901973307133
Valid Loss:  0.001204809290356934
Epoch:  230  	Training Loss: 0.0009907698258757591
Test Loss:  0.0006431920919567347
Valid Loss:  0.0012057200074195862
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.000989349908195436
Test Loss:  0.0006430025678128004
Valid Loss:  0.0012052957899868488
Epoch:  232  	Training Loss: 0.0009878348791971803
Test Loss:  0.0006440225406549871
Valid Loss:  0.001203347579576075
Epoch:  233  	Training Loss: 0.0009832351934164762
Test Loss:  0.0006418884731829166
Valid Loss:  0.0012004297459498048
Epoch:  234  	Training Loss: 0.000978966010734439
Test Loss:  0.0006359272520057857
Valid Loss:  0.0011948756873607635
Epoch:  235  	Training Loss: 0.0009748203447088599
Test Loss:  0.0006346690934151411
Valid Loss:  0.0011917587835341692
Epoch:  236  	Training Loss: 0.0009706931305117905
Test Loss:  0.000632009468972683
Valid Loss:  0.0011880176607519388
Epoch:  237  	Training Loss: 0.0009666631813161075
Test Loss:  0.0006289414595812559
Valid Loss:  0.0011841420782729983
Epoch:  238  	Training Loss: 0.0009627004619687796
Test Loss:  0.0006248063873499632
Valid Loss:  0.0011794070014730096
Epoch:  239  	Training Loss: 0.0009588022949174047
Test Loss:  0.0006227631238289177
Valid Loss:  0.0011756711173802614
Epoch:  240  	Training Loss: 0.0009549421956762671
Test Loss:  0.0006200199713930488
Valid Loss:  0.0011716553708538413
Epoch:  241  	Training Loss: 0.0009511159732937813
Test Loss:  0.0006161088822409511
Valid Loss:  0.001166882342658937
Epoch:  242  	Training Loss: 0.0009473224054090679
Test Loss:  0.0006172735011205077
Valid Loss:  0.001165767665952444
Epoch:  243  	Training Loss: 0.0009466058108955622
Test Loss:  0.0006177338073030114
Valid Loss:  0.0011645103804767132
Epoch:  244  	Training Loss: 0.0009459825814701617
Test Loss:  0.0006174517911858857
Valid Loss:  0.0011631747474893928
Epoch:  245  	Training Loss: 0.0009454345563426614
Test Loss:  0.0006171355489641428
Valid Loss:  0.0011618954595178366
Epoch:  246  	Training Loss: 0.0009449147037230432
Test Loss:  0.0006168127874843776
Valid Loss:  0.001160676358267665
Epoch:  247  	Training Loss: 0.0009444178431294858
Test Loss:  0.0006164985243231058
Valid Loss:  0.0011595155810937285
Epoch:  248  	Training Loss: 0.0009439418208785355
Test Loss:  0.000616197066847235
Valid Loss:  0.0011584118474274874
Epoch:  249  	Training Loss: 0.0009434841922484338
Test Loss:  0.0006159135373309255
Valid Loss:  0.0011573596857488155
Epoch:  250  	Training Loss: 0.0009430657373741269
Test Loss:  0.0006152814603410661
Valid Loss:  0.0011563177686184645
Epoch:  251  	Training Loss: 0.0009426791220903397
Test Loss:  0.0006148348329588771
Valid Loss:  0.0011553713120520115
Epoch:  252  	Training Loss: 0.0009423026349395514
Test Loss:  0.00060867122374475
Valid Loss:  0.001148786162957549
Epoch:  253  	Training Loss: 0.0009372560889460146
Test Loss:  0.0006062730681151152
Valid Loss:  0.0011450767051428556
Epoch:  254  	Training Loss: 0.0009331080364063382
Test Loss:  0.0006013262900523841
Valid Loss:  0.0011393590830266476
Epoch:  255  	Training Loss: 0.0009291706373915076
Test Loss:  0.0005996371619403362
Valid Loss:  0.001136090955697
Epoch:  256  	Training Loss: 0.0009254181059077382
Test Loss:  0.0005961123388260603
Valid Loss:  0.0011319555342197418
Epoch:  257  	Training Loss: 0.0009218432824127376
Test Loss:  0.0005928425816819072
Valid Loss:  0.0011279963655397296
Epoch:  258  	Training Loss: 0.0009184432565234601
Test Loss:  0.0005896445945836604
Valid Loss:  0.0011241361498832703
Epoch:  259  	Training Loss: 0.0009151221020147204
Test Loss:  0.0005865793209522963
Valid Loss:  0.0011203811736777425
Epoch:  260  	Training Loss: 0.000911882147192955
Test Loss:  0.0005838545621372759
Valid Loss:  0.0011168424971401691
Epoch:  261  	Training Loss: 0.0009088581427931786
Test Loss:  0.0005810878938063979
Valid Loss:  0.0011134761152788997
Epoch:  262  	Training Loss: 0.0009058826835826039
Test Loss:  0.0005872262408956885
Valid Loss:  0.0011139799607917666
Epoch:  263  	Training Loss: 0.0009047909406945109
Test Loss:  0.000590182957239449
Valid Loss:  0.001114002661779523
Epoch:  264  	Training Loss: 0.0009040085133165121
Test Loss:  0.0005915775545872748
Valid Loss:  0.0011137202382087708
Epoch:  265  	Training Loss: 0.000903298903722316
Test Loss:  0.0005921488045714796
Valid Loss:  0.0011132692452520132
Epoch:  266  	Training Loss: 0.0009026128682307899
Test Loss:  0.0005922982818447053
Valid Loss:  0.001112731290049851
Epoch:  267  	Training Loss: 0.0009019646677188575
Test Loss:  0.0005912689957767725
Valid Loss:  0.001111998688429594
Epoch:  268  	Training Loss: 0.0009013465023599565
Test Loss:  0.0005906545557081699
Valid Loss:  0.0011113465297967196
Epoch:  269  	Training Loss: 0.0009007361950352788
Test Loss:  0.0005902012344449759
Valid Loss:  0.0011107237078249454
Epoch:  270  	Training Loss: 0.0009001288563013077
Test Loss:  0.00058994151186198
Valid Loss:  0.0011101241689175367
Epoch:  271  	Training Loss: 0.0008995331590995193
Test Loss:  0.0005897998926229775
Valid Loss:  0.0011095379013568163
Epoch:  272  	Training Loss: 0.000898949452675879
Test Loss:  0.000587291840929538
Valid Loss:  0.0011078561656177044
Epoch:  273  	Training Loss: 0.0008981316350400448
Test Loss:  0.0005855002091266215
Valid Loss:  0.0011064698919653893
Epoch:  274  	Training Loss: 0.0008973506628535688
Test Loss:  0.0005841669626533985
Valid Loss:  0.001105262665078044
Epoch:  275  	Training Loss: 0.0008965980960056186
Test Loss:  0.0005830668960697949
Valid Loss:  0.0011043405393138528
Epoch:  276  	Training Loss: 0.0008958727703429759
Test Loss:   55%|█████▌    | 277/500 [03:18<01:42,  2.18it/s] 56%|█████▌    | 279/500 [03:18<01:16,  2.89it/s] 56%|█████▌    | 281/500 [03:24<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:24<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:24<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:25<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:25<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:31<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:31<02:56,  1.18it/s] 59%|█████▉    | 295/500 [03:31<02:06,  1.63it/s] 59%|█████▉    | 297/500 [03:31<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:32<01:07,  2.98it/s] 60%|██████    | 301/500 [03:38<03:56,  1.19s/it] 61%|██████    | 303/500 [03:38<02:47,  1.17it/s] 61%|██████    | 305/500 [03:38<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:38<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:38<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:45<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:45<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:45<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:45<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:45<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:52<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:52<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:52<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:52<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:52<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:58<03:16,  1.17s/it] 67%|██████▋   | 333/500 [03:58<02:19,  1.19it/s] 67%|██████▋   | 335/500 [03:59<01:39,  1.65it/s] 67%|██████▋   | 337/500 [03:59<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:59<00:53,  3.03it/s] 68%|██████▊   | 341/500 [04:05<03:04,  1.16s/it] 69%|██████▊   | 343/500 [04:05<02:10,  1.20it/s]0.0005821719532832503
Valid Loss:  0.001103471964597702
Epoch:  277  	Training Loss: 0.0008951601921580732
Test Loss:  0.0005814358592033386
Valid Loss:  0.0011026497231796384
Epoch:  278  	Training Loss: 0.0008944696746766567
Test Loss:  0.0005807499401271343
Valid Loss:  0.0011017494834959507
Epoch:  279  	Training Loss: 0.0008937945822253823
Test Loss:  0.0005800354992970824
Valid Loss:  0.0011009526206180453
Epoch:  280  	Training Loss: 0.0008931383490562439
Test Loss:  0.0005794261232949793
Valid Loss:  0.0011001775274053216
Epoch:  281  	Training Loss: 0.0008924996363930404
Test Loss:  0.0005789268761873245
Valid Loss:  0.0010994949843734503
Epoch:  282  	Training Loss: 0.0008918741950765252
Test Loss:  0.000572604185435921
Valid Loss:  0.0010963405948132277
Epoch:  283  	Training Loss: 0.0008914403151720762
Test Loss:  0.0005695384461432695
Valid Loss:  0.0010947708506137133
Epoch:  284  	Training Loss: 0.0008912203484214842
Test Loss:  0.0005679879686795175
Valid Loss:  0.0010938711930066347
Epoch:  285  	Training Loss: 0.0008910415344871581
Test Loss:  0.0005655914428643882
Valid Loss:  0.0010921536013484001
Epoch:  286  	Training Loss: 0.0008904893766157329
Test Loss:  0.0005505307344719768
Valid Loss:  0.0010803812183439732
Epoch:  287  	Training Loss: 0.0008839750080369413
Test Loss:  0.0005164618487469852
Valid Loss:  0.0010485458187758923
Epoch:  288  	Training Loss: 0.0008651202078908682
Test Loss:  0.0004973801551386714
Valid Loss:  0.0010275489185005426
Epoch:  289  	Training Loss: 0.0008552701910957694
Test Loss:  0.0004983738763257861
Valid Loss:  0.0010246532037854195
Epoch:  290  	Training Loss: 0.0008522993884980679
Test Loss:  0.0005015971837565303
Valid Loss:  0.0010245307348668575
Epoch:  291  	Training Loss: 0.0008502955315634608
Test Loss:  0.0005045345751568675
Valid Loss:  0.001024418044835329
Epoch:  292  	Training Loss: 0.0008486557053402066
Test Loss:  0.0005167830968275666
Valid Loss:  0.0010233876528218389
Epoch:  293  	Training Loss: 0.0008385046967305243
Test Loss:  0.0005239314050413668
Valid Loss:  0.0010230387561023235
Epoch:  294  	Training Loss: 0.0008324134396389127
Test Loss:  0.0005280338227748871
Valid Loss:  0.0010226238518953323
Epoch:  295  	Training Loss: 0.000828040880151093
Test Loss:  0.000529854791238904
Valid Loss:  0.001021823612973094
Epoch:  296  	Training Loss: 0.0008245697245001793
Test Loss:  0.000530094257555902
Valid Loss:  0.0010205854196101427
Epoch:  297  	Training Loss: 0.0008216287242248654
Test Loss:  0.0005297041498124599
Valid Loss:  0.0010190655011683702
Epoch:  298  	Training Loss: 0.0008189682266674936
Test Loss:  0.0005288611864671111
Valid Loss:  0.001017312053591013
Epoch:  299  	Training Loss: 0.0008165041799657047
Test Loss:  0.0005277207819744945
Valid Loss:  0.001015375484712422
Epoch:  300  	Training Loss: 0.0008141805301420391
Test Loss:  0.0005266193766146898
Valid Loss:  0.001013415865600109
Epoch:  301  	Training Loss: 0.0008119564154185355
Test Loss:  0.0005253836279734969
Valid Loss:  0.0010114036267623305
Epoch:  302  	Training Loss: 0.0008097856771200895
Test Loss:  0.0005196715937927365
Valid Loss:  0.0010075586615130305
Epoch:  303  	Training Loss: 0.0008077391539700329
Test Loss:  0.0005158478743396699
Valid Loss:  0.0010045906528830528
Epoch:  304  	Training Loss: 0.0008058949606493115
Test Loss:  0.0005131972138769925
Valid Loss:  0.0010021174093708396
Epoch:  305  	Training Loss: 0.0008041460532695055
Test Loss:  0.0005111749051138759
Valid Loss:  0.000999901443719864
Epoch:  306  	Training Loss: 0.000802486902102828
Test Loss:  0.0005094570224173367
Valid Loss:  0.000997839029878378
Epoch:  307  	Training Loss: 0.0008008797885850072
Test Loss:  0.000507925171405077
Valid Loss:  0.0009958583395928144
Epoch:  308  	Training Loss: 0.0007993599865585566
Test Loss:  0.0005065785953775048
Valid Loss:  0.000994000118225813
Epoch:  309  	Training Loss: 0.0007978971116244793
Test Loss:  0.0005054213106632233
Valid Loss:  0.000992214074358344
Epoch:  310  	Training Loss: 0.0007964608957991004
Test Loss:  0.000504329102113843
Valid Loss:  0.0009904514299705625
Epoch:  311  	Training Loss: 0.0007950729923322797
Test Loss:  0.0005031639011576772
Valid Loss:  0.0009887188207358122
Epoch:  312  	Training Loss: 0.0007937439950183034
Test Loss:  0.0004999700468033552
Valid Loss:  0.000986700877547264
Epoch:  313  	Training Loss: 0.0007931332802399993
Test Loss:  0.0004977296339347959
Valid Loss:  0.0009851473150774837
Epoch:  314  	Training Loss: 0.0007925912505015731
Test Loss:  0.000496121181640774
Valid Loss:  0.000983899226412177
Epoch:  315  	Training Loss: 0.0007920817588455975
Test Loss:  0.0004949365393258631
Valid Loss:  0.0009828497422859073
Epoch:  316  	Training Loss: 0.0007915887981653214
Test Loss:  0.0004939993377774954
Valid Loss:  0.0009819334372878075
Epoch:  317  	Training Loss: 0.0007911147549748421
Test Loss:  0.000493265688419342
Valid Loss:  0.000981111777946353
Epoch:  318  	Training Loss: 0.0007906460086815059
Test Loss:  0.0004926684778183699
Valid Loss:  0.0009803553111851215
Epoch:  319  	Training Loss: 0.0007901816279627383
Test Loss:  0.0004921298823319376
Valid Loss:  0.0009796411031857133
Epoch:  320  	Training Loss: 0.0007897278992459178
Test Loss:  0.0004916646284982562
Valid Loss:  0.0009789635660126805
Epoch:  321  	Training Loss: 0.0007892751600593328
Test Loss:  0.0004912501899525523
Valid Loss:  0.0009783104760572314
Epoch:  322  	Training Loss: 0.0007888242835178971
Test Loss:  0.0004879662301391363
Valid Loss:  0.0009762907866388559
Epoch:  323  	Training Loss: 0.000787554366979748
Test Loss:  0.0004855826264247298
Valid Loss:  0.0009747139411047101
Epoch:  324  	Training Loss: 0.0007863703649491072
Test Loss:  0.00048374681500718
Valid Loss:  0.0009734092163853347
Epoch:  325  	Training Loss: 0.0007852423004806042
Test Loss:  0.00048229642561636865
Valid Loss:  0.0009722767863422632
Epoch:  326  	Training Loss: 0.000784165458753705
Test Loss:  0.00048106344183906913
Valid Loss:  0.0009712451719678938
Epoch:  327  	Training Loss: 0.0007831284310668707
Test Loss:  0.00047999934758991003
Valid Loss:  0.0009703119285404682
Epoch:  328  	Training Loss: 0.0007821519393473864
Test Loss:  0.0004789976228494197
Valid Loss:  0.0009694142499938607
Epoch:  329  	Training Loss: 0.0007811877876520157
Test Loss:  0.00047810355317778885
Valid Loss:  0.0009685418335720897
Epoch:  330  	Training Loss: 0.0007802511681802571
Test Loss:  0.00047732627717778087
Valid Loss:  0.0009677964262664318
Epoch:  331  	Training Loss: 0.0007793507538735867
Test Loss:  0.0004765642515849322
Valid Loss:  0.0009670979343354702
Epoch:  332  	Training Loss: 0.0007784678600728512
Test Loss:  0.0004838328168261796
Valid Loss:  0.000966657476965338
Epoch:  333  	Training Loss: 0.0007763198227621615
Test Loss:  0.00048615969717502594
Valid Loss:  0.0009650310967117548
Epoch:  334  	Training Loss: 0.0007748776115477085
Test Loss:  0.00048616647836752236
Valid Loss:  0.0009629250271245837
Epoch:  335  	Training Loss: 0.0007736568804830313
Test Loss:  0.000485598313389346
Valid Loss:  0.0009607899701222777
Epoch:  336  	Training Loss: 0.0007725373725406826
Test Loss:  0.00048484336002729833
Valid Loss:  0.0009587281965650618
Epoch:  337  	Training Loss: 0.0007714833482168615
Test Loss:  0.0004840515903197229
Valid Loss:  0.0009567723609507084
Epoch:  338  	Training Loss: 0.0007705052266828716
Test Loss:  0.0004830237594433129
Valid Loss:  0.0009549101814627647
Epoch:  339  	Training Loss: 0.0007696013199165463
Test Loss:  0.0004821858019568026
Valid Loss:  0.0009531922405585647
Epoch:  340  	Training Loss: 0.000768731813877821
Test Loss:  0.0004814440617337823
Valid Loss:  0.0009515826241113245
Epoch:  341  	Training Loss: 0.000767890946008265
Test Loss:  0.0004807280784007162
Valid Loss:  0.0009500481537543237
Epoch:  342  	Training Loss: 0.0007670749328099191
Test Loss:  0.00048027836601249874
Valid Loss:  0.0009485765476711094
Epoch:  343  	Training Loss: 0.0007658573449589312
Test Loss:  0.0004801627655979246
Valid Loss:  0.0009474661783315241
Epoch:  344  	Training Loss: 0.0007647384190931916
Test Loss:  0.00047930041910149157
Valid Loss:   69%|██████▉   | 345/500 [04:05<01:33,  1.66it/s] 69%|██████▉   | 347/500 [04:05<01:07,  2.27it/s] 70%|██████▉   | 349/500 [04:06<00:49,  3.04it/s] 70%|███████   | 351/500 [04:12<02:55,  1.18s/it] 71%|███████   | 353/500 [04:12<02:04,  1.18it/s] 71%|███████   | 355/500 [04:12<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:12<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:12<00:48,  2.93it/s] 72%|███████▏  | 361/500 [04:19<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:19<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:19<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:19<01:00,  2.18it/s] 74%|███████▍  | 369/500 [04:19<00:44,  2.94it/s] 74%|███████▍  | 371/500 [04:26<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:26<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:26<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:26<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:26<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:32<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:33<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:33<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:33<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:33<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:39<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:39<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:40<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:40<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:40<00:33,  2.99it/s] 80%|████████  | 401/500 [04:46<01:56,  1.18s/it] 81%|████████  | 403/500 [04:46<01:22,  1.17it/s] 81%|████████  | 405/500 [04:46<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:47<00:43,  2.16it/s] 82%|████████▏ | 409/500 [04:47<00:31,  2.86it/s] 82%|████████▏ | 411/500 [04:53<01:45,  1.19s/it]0.000946218438912183
Epoch:  345  	Training Loss: 0.0007636711234226823
Test Loss:  0.00047851086128503084
Valid Loss:  0.000944988860283047
Epoch:  346  	Training Loss: 0.0007626260630786419
Test Loss:  0.0004777595750056207
Valid Loss:  0.0009437680128030479
Epoch:  347  	Training Loss: 0.0007616059738211334
Test Loss:  0.0004770111700054258
Valid Loss:  0.0009425380267202854
Epoch:  348  	Training Loss: 0.0007605943246744573
Test Loss:  0.0004763106117025018
Valid Loss:  0.000941311358474195
Epoch:  349  	Training Loss: 0.0007596059585921466
Test Loss:  0.00047561299288645387
Valid Loss:  0.0009400739800184965
Epoch:  350  	Training Loss: 0.0007586271385662258
Test Loss:  0.000474948319606483
Valid Loss:  0.0009388880571350455
Epoch:  351  	Training Loss: 0.000757689937017858
Test Loss:  0.00047429546248167753
Valid Loss:  0.0009377177339047194
Epoch:  352  	Training Loss: 0.0007567570428363979
Test Loss:  0.000473438500193879
Valid Loss:  0.0009372089989483356
Epoch:  353  	Training Loss: 0.0007564506959170103
Test Loss:  0.0004726878833025694
Valid Loss:  0.0009367438033223152
Epoch:  354  	Training Loss: 0.0007561527309007943
Test Loss:  0.00047203293070197105
Valid Loss:  0.0009363212157040834
Epoch:  355  	Training Loss: 0.0007558665238320827
Test Loss:  0.000471450766781345
Valid Loss:  0.000935926684178412
Epoch:  356  	Training Loss: 0.0007555847405456007
Test Loss:  0.0004708828346338123
Valid Loss:  0.0009355501388199627
Epoch:  357  	Training Loss: 0.0007553088944405317
Test Loss:  0.0004703738377429545
Valid Loss:  0.0009351969929412007
Epoch:  358  	Training Loss: 0.0007550399750471115
Test Loss:  0.0004699231358245015
Valid Loss:  0.000934867886826396
Epoch:  359  	Training Loss: 0.000754779321141541
Test Loss:  0.0004695138777606189
Valid Loss:  0.0009345568832941353
Epoch:  360  	Training Loss: 0.0007545204134657979
Test Loss:  0.0004691404465120286
Valid Loss:  0.0009342579869553447
Epoch:  361  	Training Loss: 0.0007542645907960832
Test Loss:  0.00046879806905053556
Valid Loss:  0.0009339718380942941
Epoch:  362  	Training Loss: 0.0007540116203017533
Test Loss:  0.00046775807277299464
Valid Loss:  0.0009311498724855483
Epoch:  363  	Training Loss: 0.0007511032745242119
Test Loss:  0.0004661122802644968
Valid Loss:  0.0009283971739932895
Epoch:  364  	Training Loss: 0.0007482741493731737
Test Loss:  0.00046426200424320996
Valid Loss:  0.0009256197372451425
Epoch:  365  	Training Loss: 0.0007455212762579322
Test Loss:  0.00046234921319410205
Valid Loss:  0.0009228501003235579
Epoch:  366  	Training Loss: 0.0007428646786138415
Test Loss:  0.0004605331632774323
Valid Loss:  0.000920166028663516
Epoch:  367  	Training Loss: 0.0007403365452773869
Test Loss:  0.00045850564492866397
Valid Loss:  0.000917481433134526
Epoch:  368  	Training Loss: 0.0007378783775493503
Test Loss:  0.0004564779519569129
Valid Loss:  0.0009148436365649104
Epoch:  369  	Training Loss: 0.000735483889002353
Test Loss:  0.0004546201671473682
Valid Loss:  0.0009122878545895219
Epoch:  370  	Training Loss: 0.0007331589004024863
Test Loss:  0.00045272152055986226
Valid Loss:  0.0009097567526623607
Epoch:  371  	Training Loss: 0.0007308725616894662
Test Loss:  0.00045090614003129303
Valid Loss:  0.0009072570246644318
Epoch:  372  	Training Loss: 0.0007286095060408115
Test Loss:  0.0004476814647205174
Valid Loss:  0.0008997131371870637
Epoch:  373  	Training Loss: 0.0007220880943350494
Test Loss:  0.00044499553041532636
Valid Loss:  0.0008930657641030848
Epoch:  374  	Training Loss: 0.0007159230299293995
Test Loss:  0.00044174454524181783
Valid Loss:  0.0008864615228958428
Epoch:  375  	Training Loss: 0.0007099389331415296
Test Loss:  0.00043832598021253943
Valid Loss:  0.0008798115304671228
Epoch:  376  	Training Loss: 0.0007040922064334154
Test Loss:  0.00043482083128765225
Valid Loss:  0.0008732569986023009
Epoch:  377  	Training Loss: 0.0006983684143051505
Test Loss:  0.00043113948777318
Valid Loss:  0.0008666833164170384
Epoch:  378  	Training Loss: 0.0006927414215169847
Test Loss:  0.00042753206798806787
Valid Loss:  0.0008602610323578119
Epoch:  379  	Training Loss: 0.000687211228068918
Test Loss:  0.0004240049165673554
Valid Loss:  0.0008539975387975574
Epoch:  380  	Training Loss: 0.0006817805115133524
Test Loss:  0.00042027627932839096
Valid Loss:  0.0008476388757117093
Epoch:  381  	Training Loss: 0.0006764235440641642
Test Loss:  0.0004165384452790022
Valid Loss:  0.0008412693277932703
Epoch:  382  	Training Loss: 0.0006711403839290142
Test Loss:  0.00041483057430014014
Valid Loss:  0.0008397714700549841
Epoch:  383  	Training Loss: 0.0006704923580400646
Test Loss:  0.00041350434185005724
Valid Loss:  0.0008384346729144454
Epoch:  384  	Training Loss: 0.0006698881625197828
Test Loss:  0.00041228128247894347
Valid Loss:  0.0008372188895009458
Epoch:  385  	Training Loss: 0.0006693334435112774
Test Loss:  0.0004113299073651433
Valid Loss:  0.0008361390209756792
Epoch:  386  	Training Loss: 0.0006687995628453791
Test Loss:  0.00041055245674215257
Valid Loss:  0.0008351391879841685
Epoch:  387  	Training Loss: 0.0006682787789031863
Test Loss:  0.0004097972414456308
Valid Loss:  0.0008342091459780931
Epoch:  388  	Training Loss: 0.0006677950732409954
Test Loss:  0.0004090006113983691
Valid Loss:  0.0008333656587637961
Epoch:  389  	Training Loss: 0.0006673546158708632
Test Loss:  0.0004083589883521199
Valid Loss:  0.0008325878297910094
Epoch:  390  	Training Loss: 0.0006669190479442477
Test Loss:  0.00040781800635159016
Valid Loss:  0.0008318539476022124
Epoch:  391  	Training Loss: 0.0006664892425760627
Test Loss:  0.00040736107621341944
Valid Loss:  0.0008311787387356162
Epoch:  392  	Training Loss: 0.0006660630460828543
Test Loss:  0.00040230294689536095
Valid Loss:  0.0008273294079117477
Epoch:  393  	Training Loss: 0.0006644092500209808
Test Loss:  0.000399828830268234
Valid Loss:  0.0008248180383816361
Epoch:  394  	Training Loss: 0.0006629976560361683
Test Loss:  0.00039847433799877763
Valid Loss:  0.0008228986989706755
Epoch:  395  	Training Loss: 0.0006616965401917696
Test Loss:  0.0003975886502303183
Valid Loss:  0.0008213134715333581
Epoch:  396  	Training Loss: 0.0006604737136512995
Test Loss:  0.0003968512173742056
Valid Loss:  0.0008198502473533154
Epoch:  397  	Training Loss: 0.0006592986173927784
Test Loss:  0.00039620482129976153
Valid Loss:  0.0008184565231204033
Epoch:  398  	Training Loss: 0.0006581639754585922
Test Loss:  0.00039558846037834883
Valid Loss:  0.000817099935375154
Epoch:  399  	Training Loss: 0.0006570567493326962
Test Loss:  0.0003949945094063878
Valid Loss:  0.0008158269338309765
Epoch:  400  	Training Loss: 0.0006559755420312285
Test Loss:  0.0003944259078707546
Valid Loss:  0.000814572093077004
Epoch:  401  	Training Loss: 0.00065491849090904
Test Loss:  0.000393870344851166
Valid Loss:  0.0008133492665365338
Epoch:  402  	Training Loss: 0.0006538776215165854
Test Loss:  0.00039388082223013043
Valid Loss:  0.0008115930831991136
Epoch:  403  	Training Loss: 0.0006493786349892616
Test Loss:  0.00039355785702355206
Valid Loss:  0.000810116296634078
Epoch:  404  	Training Loss: 0.0006459200521931052
Test Loss:  0.00039297828334383667
Valid Loss:  0.0008087351452559233
Epoch:  405  	Training Loss: 0.0006430881330743432
Test Loss:  0.0003922403557226062
Valid Loss:  0.0008075006771832705
Epoch:  406  	Training Loss: 0.000640665995888412
Test Loss:  0.00039133388781920075
Valid Loss:  0.000806239026132971
Epoch:  407  	Training Loss: 0.000638539728242904
Test Loss:  0.00039027142338454723
Valid Loss:  0.0008049462921917439
Epoch:  408  	Training Loss: 0.0006366275483742356
Test Loss:  0.0003890221705660224
Valid Loss:  0.0008036299841478467
Epoch:  409  	Training Loss: 0.000634887081105262
Test Loss:  0.00038771197432652116
Valid Loss:  0.0008023082045838237
Epoch:  410  	Training Loss: 0.0006332879420369864
Test Loss:  0.00038633905933238566
Valid Loss:  0.0008009806042537093
Epoch:  411  	Training Loss: 0.000631792820058763
Test Loss:  0.0003849926288239658
Valid Loss:  0.0007996708154678345
Epoch:  412  	Training Loss: 0.0006304123671725392
Test Loss:  0.00038302503526210785
Valid Loss:  0.0007945854449644685
 83%|████████▎ | 413/500 [04:53<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:53<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:54<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:54<00:27,  2.98it/s] 84%|████████▍ | 421/500 [05:00<01:31,  1.16s/it] 85%|████████▍ | 423/500 [05:00<01:04,  1.20it/s] 85%|████████▌ | 425/500 [05:00<00:45,  1.65it/s] 85%|████████▌ | 427/500 [05:00<00:32,  2.26it/s] 86%|████████▌ | 429/500 [05:00<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:07<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:07<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:07<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:07<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:07<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:14<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:14<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:14<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:14<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:14<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:21<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:21<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:21<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:21<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:21<00:13,  2.96it/s] 92%|█████████▏| 461/500 [05:27<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:27<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:28<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:28<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:28<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:34<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:34<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:34<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:35<00:06,  3.02it/s]Epoch:  413  	Training Loss: 0.0006269292789511383
Test Loss:  0.0003805706510320306
Valid Loss:  0.0007898688782006502
Epoch:  414  	Training Loss: 0.0006239076610654593
Test Loss:  0.0003782707790378481
Valid Loss:  0.0007855925941839814
Epoch:  415  	Training Loss: 0.0006211751606315374
Test Loss:  0.00037625705590471625
Valid Loss:  0.0007817308651283383
Epoch:  416  	Training Loss: 0.0006187290418893099
Test Loss:  0.00037433189572766423
Valid Loss:  0.0007781988242641091
Epoch:  417  	Training Loss: 0.0006164846126921475
Test Loss:  0.00037260816316120327
Valid Loss:  0.0007749538635835052
Epoch:  418  	Training Loss: 0.0006143867503851652
Test Loss:  0.00037104266812093556
Valid Loss:  0.0007719463901594281
Epoch:  419  	Training Loss: 0.000612420029938221
Test Loss:  0.00036955042742192745
Valid Loss:  0.000769111211411655
Epoch:  420  	Training Loss: 0.0006105427164584398
Test Loss:  0.0003680518129840493
Valid Loss:  0.0007664297008886933
Epoch:  421  	Training Loss: 0.0006087599322199821
Test Loss:  0.000366668013157323
Valid Loss:  0.0007638976094312966
Epoch:  422  	Training Loss: 0.0006070387316867709
Test Loss:  0.00036504503805190325
Valid Loss:  0.0007616734365001321
Epoch:  423  	Training Loss: 0.0006050561787560582
Test Loss:  0.0003635743341874331
Valid Loss:  0.0007595876813866198
Epoch:  424  	Training Loss: 0.0006032759556546807
Test Loss:  0.0003623170778155327
Valid Loss:  0.0007577912765555084
Epoch:  425  	Training Loss: 0.000601678213570267
Test Loss:  0.0003609929990489036
Valid Loss:  0.0007561020320281386
Epoch:  426  	Training Loss: 0.0006003554444760084
Test Loss:  0.00035998053499497473
Valid Loss:  0.0007546226843260229
Epoch:  427  	Training Loss: 0.0005991304642520845
Test Loss:  0.00035898236092180014
Valid Loss:  0.0007532505551353097
Epoch:  428  	Training Loss: 0.0005981040303595364
Test Loss:  0.0003582206554710865
Valid Loss:  0.0007520646322518587
Epoch:  429  	Training Loss: 0.0005971264326944947
Test Loss:  0.00035773401032201946
Valid Loss:  0.0007512209704145789
Epoch:  430  	Training Loss: 0.0005962333525530994
Test Loss:  0.0003573253925424069
Valid Loss:  0.0007503821980208158
Epoch:  431  	Training Loss: 0.0005953867803327739
Test Loss:  0.0003570442786440253
Valid Loss:  0.0007496777689084411
Epoch:  432  	Training Loss: 0.0005946450983174145
Test Loss:  0.00035854626912623644
Valid Loss:  0.0007482905639335513
Epoch:  433  	Training Loss: 0.0005929983453825116
Test Loss:  0.00035933670005761087
Valid Loss:  0.0007468555704690516
Epoch:  434  	Training Loss: 0.0005915065994486213
Test Loss:  0.0003595725283958018
Valid Loss:  0.0007453678990714252
Epoch:  435  	Training Loss: 0.000590104260481894
Test Loss:  0.0003594597219489515
Valid Loss:  0.0007438546745106578
Epoch:  436  	Training Loss: 0.0005887560546398163
Test Loss:  0.00035910640144720674
Valid Loss:  0.0007423327188007534
Epoch:  437  	Training Loss: 0.0005874451017007232
Test Loss:  0.00035858701448887587
Valid Loss:  0.0007408077362924814
Epoch:  438  	Training Loss: 0.0005861604586243629
Test Loss:  0.00035794914583675563
Valid Loss:  0.0007392914849333465
Epoch:  439  	Training Loss: 0.0005849007284268737
Test Loss:  0.0003571953275240958
Valid Loss:  0.0007377835572697222
Epoch:  440  	Training Loss: 0.0005836598575115204
Test Loss:  0.0003563975333236158
Valid Loss:  0.0007362925098277628
Epoch:  441  	Training Loss: 0.000582435866817832
Test Loss:  0.00035556795774027705
Valid Loss:  0.0007348176441155374
Epoch:  442  	Training Loss: 0.0005812232266180217
Test Loss:  0.0003516581782605499
Valid Loss:  0.000732513377442956
Epoch:  443  	Training Loss: 0.0005801980150863528
Test Loss:  0.00034907914232462645
Valid Loss:  0.0007308233762159944
Epoch:  444  	Training Loss: 0.0005793010350316763
Test Loss:  0.0003472918178886175
Valid Loss:  0.0007294791284948587
Epoch:  445  	Training Loss: 0.0005784592358395457
Test Loss:  0.00034599320497363806
Valid Loss:  0.0007283407030627131
Epoch:  446  	Training Loss: 0.000577647122554481
Test Loss:  0.00034497922752052546
Valid Loss:  0.0007273212540894747
Epoch:  447  	Training Loss: 0.0005768536357209086
Test Loss:  0.0003441520093474537
Valid Loss:  0.0007263877196237445
Epoch:  448  	Training Loss: 0.0005760876229032874
Test Loss:  0.0003434241225477308
Valid Loss:  0.0007254962110891938
Epoch:  449  	Training Loss: 0.0005753262666985393
Test Loss:  0.0003427608753554523
Valid Loss:  0.000724632409401238
Epoch:  450  	Training Loss: 0.0005745694506913424
Test Loss:  0.0003421535366214812
Valid Loss:  0.0007237853715196252
Epoch:  451  	Training Loss: 0.0005738197942264378
Test Loss:  0.00034159276401624084
Valid Loss:  0.0007229659822769463
Epoch:  452  	Training Loss: 0.0005730855045840144
Test Loss:  0.00034144232631661
Valid Loss:  0.0007224266300909221
Epoch:  453  	Training Loss: 0.0005727015086449683
Test Loss:  0.0003412882797420025
Valid Loss:  0.0007218875689432025
Epoch:  454  	Training Loss: 0.0005723239737562835
Test Loss:  0.00034110163687728345
Valid Loss:  0.0007213432691060007
Epoch:  455  	Training Loss: 0.0005719531327486038
Test Loss:  0.0003408743068575859
Valid Loss:  0.0007207999005913734
Epoch:  456  	Training Loss: 0.0005715941078960896
Test Loss:  0.0003406361793167889
Valid Loss:  0.0007202583365142345
Epoch:  457  	Training Loss: 0.0005712389247491956
Test Loss:  0.0003403898444958031
Valid Loss:  0.0007197209633886814
Epoch:  458  	Training Loss: 0.0005708883982151747
Test Loss:  0.000340170954586938
Valid Loss:  0.0007191936601884663
Epoch:  459  	Training Loss: 0.0005705432267859578
Test Loss:  0.00033994647674262524
Valid Loss:  0.0007186688017100096
Epoch:  460  	Training Loss: 0.0005702023627236485
Test Loss:  0.00033971507218666375
Valid Loss:  0.0007181473192758858
Epoch:  461  	Training Loss: 0.0005698659224435687
Test Loss:  0.00033947115298360586
Valid Loss:  0.000717631948646158
Epoch:  462  	Training Loss: 0.0005695353611372411
Test Loss:  0.0003402972361072898
Valid Loss:  0.000717796094249934
Epoch:  463  	Training Loss: 0.0005693986895494163
Test Loss:  0.0003410695935599506
Valid Loss:  0.0007179505773819983
Epoch:  464  	Training Loss: 0.0005692770937457681
Test Loss:  0.00034178965142928064
Valid Loss:  0.0007180911488831043
Epoch:  465  	Training Loss: 0.0005691684200428426
Test Loss:  0.00034246285213157535
Valid Loss:  0.0007182214758358896
Epoch:  466  	Training Loss: 0.0005690718535333872
Test Loss:  0.0003430910292081535
Valid Loss:  0.0007183414418250322
Epoch:  467  	Training Loss: 0.0005689846584573388
Test Loss:  0.00034366868203505874
Valid Loss:  0.0007184503483586013
Epoch:  468  	Training Loss: 0.0005689086392521858
Test Loss:  0.0003442079178057611
Valid Loss:  0.0007185498834587634
Epoch:  469  	Training Loss: 0.0005688403034582734
Test Loss:  0.00034471176331862807
Valid Loss:  0.0007186413276940584
Epoch:  470  	Training Loss: 0.0005687783705070615
Test Loss:  0.0003451807424426079
Valid Loss:  0.0007187235169112682
Epoch:  471  	Training Loss: 0.0005687214434146881
Test Loss:  0.00034561665961518884
Valid Loss:  0.0007187962764874101
Epoch:  472  	Training Loss: 0.0005686691729351878
Test Loss:  0.00034336469252593815
Valid Loss:  0.0007172313053160906
Epoch:  473  	Training Loss: 0.0005679515306837857
Test Loss:  0.00034175009932368994
Valid Loss:  0.0007159397937357426
Epoch:  474  	Training Loss: 0.0005672772531397641
Test Loss:  0.0003405489260330796
Valid Loss:  0.0007148202275857329
Epoch:  475  	Training Loss: 0.0005666260840371251
Test Loss:  0.00033961437293328345
Valid Loss:  0.0007138111395761371
Epoch:  476  	Training Loss: 0.0005659841699525714
Test Loss:  0.00033885365701280534
Valid Loss:  0.0007128759752959013
Epoch:  477  	Training Loss: 0.0005653498228639364
Test Loss:  0.00033820749376900494
Valid Loss:  0.0007119891233742237
Epoch:  478  	Training Loss: 0.0005647190846502781
Test Loss:  0.00033764130785129964
Valid Loss:  0.0007111368468031287
Epoch:  479  	Training Loss: 0.0005640916060656309
Test Loss:  0.0003371291677467525
Valid Loss:  0.0007103070383891463
Epoch:  480  	Training Loss: 0.0005634689587168396
Test Loss:  0.00033661373890936375
Valid Loss:  0.0007094922475516796
 96%|█████████▌| 481/500 [05:41<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:41<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:41<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:48<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:48<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:48<00:00,  2.99it/s]100%|██████████| 500/500 [05:48<00:00,  1.43it/s]
Epoch:  481  	Training Loss: 0.0005628499202430248
Test Loss:  0.0003361362614668906
Valid Loss:  0.0007086960249580443
Epoch:  482  	Training Loss: 0.0005622344324365258
Test Loss:  0.00033622983028180897
Valid Loss:  0.0007077306509017944
Epoch:  483  	Training Loss: 0.0005615522968582809
Test Loss:  0.0003362260467838496
Valid Loss:  0.000706763647031039
Epoch:  484  	Training Loss: 0.0005609015352092683
Test Loss:  0.00033617904409766197
Valid Loss:  0.0007059128256514668
Epoch:  485  	Training Loss: 0.0005603053141385317
Test Loss:  0.0003360478731337935
Valid Loss:  0.0007050645654089749
Epoch:  486  	Training Loss: 0.0005597312701866031
Test Loss:  0.0003359160618856549
Valid Loss:  0.0007042594370432198
Epoch:  487  	Training Loss: 0.0005591702647507191
Test Loss:  0.0003357122768647969
Valid Loss:  0.0007034444133751094
Epoch:  488  	Training Loss: 0.0005586253246292472
Test Loss:  0.0003355260705575347
Valid Loss:  0.0007026762468740344
Epoch:  489  	Training Loss: 0.0005580895813181996
Test Loss:  0.000335297838319093
Valid Loss:  0.0007019011536613107
Epoch:  490  	Training Loss: 0.0005575584946200252
Test Loss:  0.0003350639599375427
Valid Loss:  0.0007011331035755575
Epoch:  491  	Training Loss: 0.0005570336943492293
Test Loss:  0.0003348565078340471
Valid Loss:  0.0007003734936006367
Epoch:  492  	Training Loss: 0.0005565305473282933
Test Loss:  0.00033429154427722096
Valid Loss:  0.0006999721517786384
Epoch:  493  	Training Loss: 0.0005561970174312592
Test Loss:  0.00033380178501829505
Valid Loss:  0.0006996014853939414
Epoch:  494  	Training Loss: 0.0005558718694373965
Test Loss:  0.000333367963321507
Valid Loss:  0.0006992518901824951
Epoch:  495  	Training Loss: 0.0005555521929636598
Test Loss:  0.00033297520712949336
Valid Loss:  0.0006989187095314264
Epoch:  496  	Training Loss: 0.000555237929802388
Test Loss:  0.0003326160949654877
Valid Loss:  0.0006985996151342988
Epoch:  497  	Training Loss: 0.0005549297202378511
Test Loss:  0.0003322690899949521
Valid Loss:  0.0006982896011322737
Epoch:  498  	Training Loss: 0.0005546303000301123
Test Loss:  0.00033195072319358587
Valid Loss:  0.0006979925674386322
Epoch:  499  	Training Loss: 0.0005543348379433155
Test Loss:  0.00033165578497573733
Valid Loss:  0.0006977035664021969
Epoch:  500  	Training Loss: 0.0005540440324693918
Test Loss:  0.00033137574791908264
Valid Loss:  0.0006974225398153067
seed is  9
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 15.07it/s]  1%|          | 4/500 [00:00<00:31, 15.63it/s]  1%|          | 6/500 [00:00<00:31, 15.92it/s]  2%|▏         | 8/500 [00:00<00:30, 16.13it/s]  2%|▏         | 10/500 [00:00<00:30, 16.28it/s]  2%|▏         | 12/500 [00:00<00:29, 16.37it/s]  3%|▎         | 14/500 [00:00<00:30, 16.18it/s]  3%|▎         | 16/500 [00:00<00:30, 15.97it/s]  4%|▎         | 18/500 [00:01<00:29, 16.09it/s]  4%|▍         | 20/500 [00:01<00:29, 16.22it/s]  4%|▍         | 22/500 [00:01<00:29, 16.01it/s]  5%|▍         | 24/500 [00:01<00:30, 15.66it/s]  5%|▌         | 26/500 [00:01<00:30, 15.79it/s]  6%|▌         | 28/500 [00:01<00:30, 15.59it/s]  6%|▌         | 30/500 [00:01<00:30, 15.57it/s]  6%|▋         | 32/500 [00:02<00:29, 15.78it/s]  7%|▋         | 34/500 [00:02<00:29, 15.88it/s]  7%|▋         | 36/500 [00:02<00:29, 15.88it/s]  8%|▊         | 38/500 [00:02<00:28, 16.06it/s]  8%|▊         | 40/500 [00:02<00:28, 16.23it/s]  8%|▊         | 42/500 [00:02<00:28, 16.21it/s]  9%|▉         | 44/500 [00:02<00:28, 16.03it/s]  9%|▉         | 46/500 [00:02<00:28, 16.07it/s] 10%|▉         | 48/500 [00:03<00:27, 16.19it/s] 10%|█         | 50/500 [00:03<00:27, 16.28it/s] 10%|█         | 52/500 [00:03<00:27, 16.35it/s] 11%|█         | 54/500 [00:03<00:27, 16.47it/s] 11%|█         | 56/500 [00:03<00:26, 16.52it/s] 12%|█▏        | 58/500 [00:03<00:27, 15.99it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.69it/s] 12%|█▏        | 62/500 [00:03<00:27, 15.80it/s] 13%|█▎        | 64/500 [00:03<00:27, 15.93it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.90it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.14it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.26it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.30it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.33it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.40it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.46it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.39it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.84it/s] 17%|█▋        | 84/500 [00:05<00:28, 14.65it/s] 17%|█▋        | 86/500 [00:05<00:29, 13.91it/s] 18%|█▊        | 88/500 [00:05<00:30, 13.61it/s] 18%|█▊        | 90/500 [00:05<00:28, 14.34it/s] 18%|█▊        | 92/500 [00:05<00:27, 14.91it/s] 19%|█▉        | 94/500 [00:05<00:26, 15.31it/s] 19%|█▉        | 96/500 [00:06<00:26, 15.33it/s] 20%|█▉        | 98/500 [00:06<00:26, 15.30it/s] 20%|██        | 100/500 [00:06<00:25, 15.48it/s] 20%|██        | 102/500 [00:06<00:25, 15.54it/s] 21%|██        | 104/500 [00:06<00:25, 15.32it/s] 21%|██        | 106/500 [00:06<00:26, 15.01it/s] 22%|██▏       | 108/500 [00:06<00:26, 15.05it/s] 22%|██▏       | 110/500 [00:06<00:25, 15.47it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.61it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.90it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.89it/s] 24%|██▎       | 118/500 [00:07<00:25, 14.80it/s] 24%|██▍       | 120/500 [00:07<00:27, 14.00it/s] 24%|██▍       | 122/500 [00:07<00:27, 13.53it/s] 25%|██▍       | 124/500 [00:08<00:28, 13.17it/s]Epoch:  1  	Training Loss: 0.08466490358114243
Test Loss:  1881.4736328125
Valid Loss:  1877.499267578125
Epoch:  2  	Training Loss: 1872.6630859375
Test Loss:  734756295671808.0
Valid Loss:  729686623649792.0
Epoch:  3  	Training Loss: 724566284435456.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:26, 13.98it/s] 26%|██▌       | 128/500 [00:08<00:25, 14.64it/s] 26%|██▌       | 130/500 [00:08<00:24, 15.18it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.48it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.58it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.46it/s] 28%|██▊       | 138/500 [00:08<00:23, 15.27it/s] 28%|██▊       | 140/500 [00:09<00:23, 15.52it/s] 28%|██▊       | 142/500 [00:09<00:22, 15.75it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.94it/s] 29%|██▉       | 146/500 [00:09<00:22, 16.07it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.15it/s] 30%|███       | 150/500 [00:09<00:21, 16.13it/s] 30%|███       | 152/500 [00:09<00:21, 16.02it/s] 31%|███       | 154/500 [00:09<00:21, 16.12it/s] 31%|███       | 156/500 [00:09<00:21, 16.09it/s] 32%|███▏      | 158/500 [00:10<00:21, 15.79it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.73it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.87it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.08it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.02it/s] 34%|███▎      | 168/500 [00:10<00:21, 15.21it/s] 34%|███▍      | 170/500 [00:10<00:22, 14.43it/s] 34%|███▍      | 172/500 [00:11<00:22, 14.52it/s] 35%|███▍      | 174/500 [00:11<00:23, 13.66it/s] 35%|███▌      | 176/500 [00:11<00:24, 13.19it/s] 36%|███▌      | 178/500 [00:11<00:24, 12.97it/s] 36%|███▌      | 180/500 [00:11<00:23, 13.84it/s] 36%|███▋      | 182/500 [00:11<00:21, 14.47it/s] 37%|███▋      | 184/500 [00:11<00:21, 14.87it/s] 37%|███▋      | 186/500 [00:12<00:20, 15.19it/s] 38%|███▊      | 188/500 [00:12<00:20, 15.51it/s] 38%|███▊      | 190/500 [00:12<00:19, 15.72it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.89it/s] 39%|███▉      | 194/500 [00:12<00:19, 16.08it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.20it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.19it/s] 40%|████      | 200/500 [00:12<00:18, 16.28it/s] 40%|████      | 202/500 [00:13<00:18, 16.19it/s] 41%|████      | 204/500 [00:13<00:18, 16.31it/s] 41%|████      | 206/500 [00:13<00:18, 16.05it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.97it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.16it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.27it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.28it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.39it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.15it/s] 44%|████▍     | 220/500 [00:14<00:18, 15.03it/s] 44%|████▍     | 222/500 [00:14<00:18, 15.40it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.61it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.86it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.02it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.12it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.25it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.26it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.17it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.26it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.14it/s] 48%|████▊     | 242/500 [00:15<00:16, 16.11it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.88it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.03it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.05it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.05it/s] 50%|█████     | 252/500 [00:16<00:15, 16.15it/s] 51%|█████     | 254/500 [00:16<00:15, 16.25it/s] 51%|█████     | 256/500 [00:16<00:15, 16.23it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.33it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.35it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.36it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.38it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.28it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.08it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.92it/s] 54%|█████▍    | 272/500 [00:17<00:14, 15.85it/s] 55%|█████▍    | 274/500 [00:17<00:14, 16.00it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.90it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.13it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.20it/s] 56%|█████▋    | 282/500 [00:18<00:14, 15.28it/s] 57%|█████▋    | 284/500 [00:18<00:14, 14.94it/s] 57%|█████▋    | 286/500 [00:18<00:14, 15.18it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.37it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.60it/s] 58%|█████▊    | 292/500 [00:18<00:13, 14.89it/s] 59%|█████▉    | 294/500 [00:18<00:13, 14.79it/s] 59%|█████▉    | 296/500 [00:18<00:13, 15.22it/s] 60%|█████▉    | 298/500 [00:19<00:13, 15.52it/s] 60%|██████    | 300/500 [00:19<00:12, 15.73it/s] 60%|██████    | 302/500 [00:19<00:12, 15.65it/s] 61%|██████    | 304/500 [00:19<00:12, 15.79it/s] 61%|██████    | 306/500 [00:19<00:12, 15.64it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.71it/s] 62%|██████▏   | 310/500 [00:19<00:12, 15.73it/s] 62%|██████▏   | 312/500 [00:19<00:11, 15.90it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.98it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.07it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.07it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.19it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.29it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.35it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.38it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.36it/s] 66%|██████▌   | 330/500 [00:21<00:11, 15.18it/s] 66%|██████▋   | 332/500 [00:21<00:11, 14.20it/s] 67%|██████▋   | 334/500 [00:21<00:12, 13.61it/s] 67%|██████▋   | 336/500 [00:21<00:12, 13.24it/s] 68%|██████▊   | 338/500 [00:21<00:12, 12.97it/s] 68%|██████▊   | 340/500 [00:21<00:12, 12.84it/s] 68%|██████▊   | 342/500 [00:22<00:11, 13.61it/s] 69%|██████▉   | 344/500 [00:22<00:10, 14.39it/s] 69%|██████▉   | 346/500 [00:22<00:10, 14.99it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.38it/s] 70%|███████   | 350/500 [00:22<00:09, 15.43it/s] 70%|███████   | 352/500 [00:22<00:10, 14.41it/s] 71%|███████   | 354/500 [00:22<00:10, 13.51it/s] 71%|███████   | 356/500 [00:23<00:11, 13.07it/s] 72%|███████▏  | 358/500 [00:23<00:10, 13.58it/s] 72%|███████▏  | 360/500 [00:23<00:09, 14.25it/s] 72%|███████▏  | 362/500 [00:23<00:09, 14.84it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.35it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.75it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.93it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.54it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.22it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:08, 15.42it/s] 75%|███████▌  | 376/500 [00:24<00:07, 15.71it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.96it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.07it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.23it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.27it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.23it/s] 78%|███████▊  | 388/500 [00:25<00:06, 16.00it/s] 78%|███████▊  | 390/500 [00:25<00:06, 16.09it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.06it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.62it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.73it/s] 80%|███████▉  | 398/500 [00:25<00:06, 15.56it/s] 80%|████████  | 400/500 [00:25<00:06, 15.31it/s] 80%|████████  | 402/500 [00:25<00:06, 15.32it/s] 81%|████████  | 404/500 [00:26<00:06, 15.58it/s] 81%|████████  | 406/500 [00:26<00:05, 15.79it/s] 82%|████████▏ | 408/500 [00:26<00:05, 15.88it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.00it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.92it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.25it/s] 83%|████████▎ | 416/500 [00:26<00:05, 15.48it/s] 84%|████████▎ | 418/500 [00:26<00:05, 15.41it/s] 84%|████████▍ | 420/500 [00:27<00:05, 14.92it/s] 84%|████████▍ | 422/500 [00:27<00:05, 15.21it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.57it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.83it/s] 86%|████████▌ | 428/500 [00:27<00:04, 14.97it/s] 86%|████████▌ | 430/500 [00:27<00:04, 14.94it/s] 86%|████████▋ | 432/500 [00:27<00:04, 15.34it/s] 87%|████████▋ | 434/500 [00:27<00:04, 15.67it/s] 87%|████████▋ | 436/500 [00:28<00:04, 15.85it/s] 88%|████████▊ | 438/500 [00:28<00:03, 15.95it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.05it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.15it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.18it/s] 89%|████████▉ | 446/500 [00:28<00:03, 15.21it/s] 90%|████████▉ | 448/500 [00:28<00:03, 14.45it/s] 90%|█████████ | 450/500 [00:29<00:03, 14.52it/s] 90%|█████████ | 452/500 [00:29<00:03, 13.69it/s] 91%|█████████ | 454/500 [00:29<00:03, 13.28it/s] 91%|█████████ | 456/500 [00:29<00:03, 13.58it/s] 92%|█████████▏| 458/500 [00:29<00:02, 14.31it/s] 92%|█████████▏| 460/500 [00:29<00:02, 14.87it/s] 92%|█████████▏| 462/500 [00:29<00:02, 14.27it/s] 93%|█████████▎| 464/500 [00:30<00:02, 13.53it/s] 93%|█████████▎| 466/500 [00:30<00:02, 13.16it/s] 94%|█████████▎| 468/500 [00:30<00:02, 12.92it/s] 94%|█████████▍| 470/500 [00:30<00:02, 12.76it/s] 94%|█████████▍| 472/500 [00:30<00:02, 12.76it/s] 95%|█████████▍| 474/500 [00:30<00:01, 13.63it/s] 95%|█████████▌| 476/500 [00:30<00:01, 14.27it/s] 96%|█████████▌| 478/500 [00:31<00:01, 14.80it/s] 96%|█████████▌| 480/500 [00:31<00:01, 14.29it/s] 96%|█████████▋| 482/500 [00:31<00:01, 13.60it/s] 97%|█████████▋| 484/500 [00:31<00:01, 13.20it/s] 97%|█████████▋| 486/500 [00:31<00:01, 12.96it/s] 98%|█████████▊| 488/500 [00:31<00:00, 12.77it/s] 98%|█████████▊| 490/500 [00:32<00:00, 12.65it/s] 98%|█████████▊| 492/500 [00:32<00:00, 12.61it/s] 99%|█████████▉| 494/500 [00:32<00:00, 13.50it/s] 99%|█████████▉| 496/500 [00:32<00:00, 14.18it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 14.62it/s]100%|██████████| 500/500 [00:32<00:00, 15.07it/s]100%|██████████| 500/500 [00:32<00:00, 15.29it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  9
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:25,  6.30s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:48,  2.86it/s]  4%|▍         | 21/500 [00:26<17:22,  2.18s/it]  5%|▍         | 23/500 [00:26<12:12,  1.53s/it]  5%|▌         | 25/500 [00:33<16:15,  2.05s/it]  5%|▌         | 27/500 [00:33<11:27,  1.45s/it]  6%|▌         | 29/500 [00:33<08:07,  1.03s/it]  6%|▌         | 29/500 [00:43<08:07,  1.03s/it]  6%|▌         | 31/500 [00:45<20:31,  2.62s/it]  7%|▋         | 33/500 [00:46<14:26,  1.86s/it]  7%|▋         | 35/500 [00:52<17:29,  2.26s/it]  7%|▋         | 37/500 [00:52<12:21,  1.60s/it]  8%|▊         | 39/500 [00:52<08:45,  1.14s/it]  8%|▊         | 39/500 [01:03<08:45,  1.14s/it]  8%|▊         | 41/500 [01:05<20:13,  2.64s/it]  9%|▊         | 43/500 [01:05<14:15,  1.87s/it]  9%|▉         | 45/500 [01:11<17:08,  2.26s/it]  9%|▉         | 47/500 [01:11<12:06,  1.60s/it] 10%|▉         | 49/500 [01:11<08:35,  1.14s/it] 10%|▉         | 49/500 [01:23<08:35,  1.14s/it] 10%|█         | 51/500 [01:24<20:01,  2.68s/it] 11%|█         | 53/500 [01:24<14:07,  1.89s/it] 11%|█         | 55/500 [01:30<16:55,  2.28s/it] 11%|█▏        | 57/500 [01:31<11:59,  1.62s/it] 12%|█▏        | 59/500 [01:31<08:32,  1.16s/it] 12%|█▏        | 61/500 [01:43<19:29,  2.67s/it] 13%|█▎        | 63/500 [01:43<13:44,  1.89s/it]Epoch:  1  	Training Loss: 0.08466490358114243
Test Loss:  39.50725173950195
Valid Loss:  39.13603973388672
Epoch:  2  	Training Loss: 38.56419372558594
Test Loss:  21.55016326904297
Valid Loss:  21.212892532348633
Epoch:  3  	Training Loss: 20.805660247802734
Test Loss:  0.8034787178039551
Valid Loss:  0.7874437570571899
Epoch:  4  	Training Loss: 0.7592126727104187
Test Loss:  0.16881819069385529
Valid Loss:  0.17074492573738098
Epoch:  5  	Training Loss: 0.1627427339553833
Test Loss:  0.1688181757926941
Valid Loss:  0.170744851231575
Epoch:  6  	Training Loss: 0.16274268925189972
Test Loss:  0.1688181757926941
Valid Loss:  0.17074477672576904
Epoch:  7  	Training Loss: 0.16274264454841614
Test Loss:  0.1688181459903717
Valid Loss:  0.17074474692344666
Epoch:  8  	Training Loss: 0.16274262964725494
Test Loss:  0.1688181310892105
Valid Loss:  0.17074471712112427
Epoch:  9  	Training Loss: 0.16274261474609375
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  10  	Training Loss: 0.16274258494377136
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  11  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  12  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  13  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  14  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  15  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  16  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  17  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  18  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  19  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  20  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  22  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  23  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  24  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  25  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  27  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  28  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  29  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  30  	Training Loss: 0.16274255514144897
Test Loss:  0.16881808638572693
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  32  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  33  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  34  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  35  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  37  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  38  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  39  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  40  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  42  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  43  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  44  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  45  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  47  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  48  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  49  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  50  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  52  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  53  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074471712112427
Epoch:  54  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  55  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  57  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  58  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  59  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  60  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  62  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  63  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
 13%|█▎        | 65/500 [01:49<16:20,  2.25s/it] 13%|█▎        | 67/500 [01:50<11:34,  1.60s/it] 14%|█▍        | 69/500 [01:50<08:13,  1.15s/it] 14%|█▍        | 71/500 [02:02<19:15,  2.69s/it] 15%|█▍        | 73/500 [02:03<13:35,  1.91s/it] 15%|█▌        | 75/500 [02:09<16:15,  2.29s/it] 15%|█▌        | 77/500 [02:09<11:28,  1.63s/it] 16%|█▌        | 79/500 [02:09<08:07,  1.16s/it] 16%|█▌        | 81/500 [02:22<18:57,  2.71s/it] 17%|█▋        | 83/500 [02:22<13:20,  1.92s/it] 17%|█▋        | 85/500 [02:28<15:51,  2.29s/it] 17%|█▋        | 87/500 [02:28<11:11,  1.63s/it] 18%|█▊        | 89/500 [02:29<07:55,  1.16s/it] 18%|█▊        | 91/500 [02:41<18:15,  2.68s/it] 19%|█▊        | 93/500 [02:41<12:51,  1.90s/it] 19%|█▉        | 95/500 [02:48<15:24,  2.28s/it] 19%|█▉        | 97/500 [02:48<10:54,  1.62s/it] 20%|█▉        | 99/500 [02:48<07:46,  1.16s/it] 20%|██        | 101/500 [03:01<18:05,  2.72s/it] 21%|██        | 103/500 [03:01<12:44,  1.92s/it] 21%|██        | 105/500 [03:07<15:02,  2.29s/it] 21%|██▏       | 107/500 [03:07<10:38,  1.62s/it] 22%|██▏       | 109/500 [03:07<07:31,  1.16s/it] 22%|██▏       | 111/500 [03:20<17:28,  2.70s/it] 23%|██▎       | 113/500 [03:20<12:18,  1.91s/it] 23%|██▎       | 115/500 [03:26<14:45,  2.30s/it] 23%|██▎       | 117/500 [03:27<10:24,  1.63s/it] 24%|██▍       | 119/500 [03:27<07:23,  1.17s/it] 24%|██▍       | 121/500 [03:39<16:48,  2.66s/it]Epoch:  64  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  65  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  67  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  68  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  69  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  70  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  72  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  73  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  74  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  75  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  77  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  78  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  79  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  80  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  82  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  83  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  84  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  85  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  87  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  88  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  89  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  90  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  92  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  93  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  94  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  95  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  97  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  98  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  99  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  100  	Training Loss: 0.16274255514144897
Test Loss:  0.16881808638572693
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  102  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  103  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  104  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  105  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  107  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  108  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  109  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  110  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  112  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  113  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  114  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  115  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  117  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  118  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  119  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  120  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  122  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  123  	Training Loss: 0.16274255514144897
Test Loss:   25%|██▍       | 123/500 [03:39<11:52,  1.89s/it] 25%|██▌       | 125/500 [03:45<14:08,  2.26s/it] 25%|██▌       | 127/500 [03:46<09:58,  1.60s/it] 26%|██▌       | 129/500 [03:46<07:03,  1.14s/it] 26%|██▌       | 131/500 [03:58<16:22,  2.66s/it] 27%|██▋       | 133/500 [03:58<11:33,  1.89s/it] 27%|██▋       | 135/500 [04:05<13:48,  2.27s/it] 27%|██▋       | 137/500 [04:05<09:44,  1.61s/it] 28%|██▊       | 139/500 [04:05<06:54,  1.15s/it] 28%|██▊       | 141/500 [04:18<16:06,  2.69s/it] 29%|██▊       | 143/500 [04:18<11:20,  1.91s/it] 29%|██▉       | 145/500 [04:24<13:29,  2.28s/it] 29%|██▉       | 147/500 [04:24<09:33,  1.62s/it] 30%|██▉       | 149/500 [04:24<06:46,  1.16s/it] 30%|███       | 151/500 [04:37<15:36,  2.68s/it] 31%|███       | 153/500 [04:37<10:58,  1.90s/it] 31%|███       | 155/500 [04:43<13:03,  2.27s/it] 31%|███▏      | 157/500 [04:43<09:12,  1.61s/it] 32%|███▏      | 159/500 [04:43<06:31,  1.15s/it] 32%|███▏      | 161/500 [04:56<15:06,  2.67s/it] 33%|███▎      | 163/500 [04:56<10:38,  1.89s/it] 33%|███▎      | 165/500 [05:02<12:40,  2.27s/it] 33%|███▎      | 167/500 [05:03<08:57,  1.61s/it] 34%|███▍      | 169/500 [05:03<06:22,  1.15s/it] 34%|███▍      | 169/500 [05:13<06:22,  1.15s/it] 34%|███▍      | 171/500 [05:16<15:00,  2.74s/it] 35%|███▍      | 173/500 [05:16<10:33,  1.94s/it] 35%|███▌      | 175/500 [05:22<12:28,  2.30s/it] 35%|███▌      | 177/500 [05:22<08:47,  1.63s/it] 36%|███▌      | 179/500 [05:22<06:13,  1.16s/it] 36%|███▌      | 179/500 [05:33<06:13,  1.16s/it] 36%|███▌      | 181/500 [05:35<14:27,  2.72s/it]0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  124  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  125  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  127  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  128  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  129  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  130  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  132  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  133  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  134  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  135  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  137  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  138  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  139  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  140  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  142  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  143  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  144  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  145  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  147  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  148  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  149  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  150  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  152  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  153  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  154  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  155  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  157  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  158  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  159  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  160  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  162  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  163  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  164  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  165  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  167  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  168  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  169  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  170  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  172  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  173  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  174  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  175  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  177  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  178  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  179  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  180  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  182  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
 37%|███▋      | 183/500 [05:35<10:10,  1.93s/it] 37%|███▋      | 185/500 [05:42<12:10,  2.32s/it] 37%|███▋      | 187/500 [05:42<08:34,  1.64s/it] 38%|███▊      | 189/500 [05:42<06:04,  1.17s/it] 38%|███▊      | 189/500 [05:53<06:04,  1.17s/it] 38%|███▊      | 191/500 [05:54<13:53,  2.70s/it] 39%|███▊      | 193/500 [05:55<09:46,  1.91s/it] 39%|███▉      | 195/500 [06:01<11:32,  2.27s/it] 39%|███▉      | 197/500 [06:01<08:07,  1.61s/it] 40%|███▉      | 199/500 [06:01<05:45,  1.15s/it] 40%|███▉      | 199/500 [06:13<05:45,  1.15s/it] 40%|████      | 201/500 [06:14<13:18,  2.67s/it] 41%|████      | 203/500 [06:14<09:22,  1.89s/it] 41%|████      | 205/500 [06:20<11:06,  2.26s/it] 41%|████▏     | 207/500 [06:20<07:49,  1.60s/it] 42%|████▏     | 209/500 [06:20<05:32,  1.14s/it] 42%|████▏     | 211/500 [06:33<12:59,  2.70s/it] 43%|████▎     | 213/500 [06:33<09:09,  1.91s/it] 43%|████▎     | 215/500 [06:39<10:50,  2.28s/it] 43%|████▎     | 217/500 [06:39<07:38,  1.62s/it] 44%|████▍     | 219/500 [06:40<05:24,  1.15s/it] 44%|████▍     | 221/500 [06:52<12:26,  2.67s/it] 45%|████▍     | 223/500 [06:52<08:44,  1.89s/it] 45%|████▌     | 225/500 [06:58<10:24,  2.27s/it] 45%|████▌     | 227/500 [06:59<07:21,  1.62s/it] 46%|████▌     | 229/500 [06:59<05:11,  1.15s/it] 46%|████▌     | 231/500 [07:12<12:10,  2.72s/it] 47%|████▋     | 233/500 [07:12<08:33,  1.92s/it] 47%|████▋     | 235/500 [07:18<10:09,  2.30s/it] 47%|████▋     | 237/500 [07:18<07:09,  1.63s/it] 48%|████▊     | 239/500 [07:18<05:03,  1.16s/it]Valid Loss:  0.17074468731880188
Epoch:  183  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  184  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  185  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  187  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  188  	Training Loss: 0.16274255514144897
Test Loss:  0.16881808638572693
Valid Loss:  0.17074468731880188
Epoch:  189  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  190  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  192  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  193  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  194  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  195  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  197  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  198  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  199  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  200  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  202  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  203  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  204  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  205  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  207  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  208  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  209  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  210  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  212  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  213  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  214  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  215  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  217  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  218  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  219  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  220  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  222  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  223  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  224  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  225  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  227  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074471712112427
Epoch:  228  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  229  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  230  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  232  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  233  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  234  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  235  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  237  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  238  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  239  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  240  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:   48%|████▊     | 241/500 [07:31<11:37,  2.69s/it] 49%|████▊     | 243/500 [07:31<08:10,  1.91s/it] 49%|████▉     | 245/500 [07:37<09:49,  2.31s/it] 49%|████▉     | 247/500 [07:38<06:56,  1.65s/it] 50%|████▉     | 249/500 [07:38<04:55,  1.18s/it] 50%|█████     | 250/500 [07:44<08:40,  2.08s/it] 50%|█████     | 251/500 [07:51<12:16,  2.96s/it] 51%|█████     | 253/500 [07:51<07:50,  1.90s/it] 51%|█████     | 255/500 [07:57<09:38,  2.36s/it] 51%|█████▏    | 257/500 [07:57<06:31,  1.61s/it] 52%|█████▏    | 259/500 [07:57<04:29,  1.12s/it] 52%|█████▏    | 260/500 [08:04<08:20,  2.08s/it] 52%|█████▏    | 261/500 [08:10<11:47,  2.96s/it] 53%|█████▎    | 263/500 [08:10<07:25,  1.88s/it] 53%|█████▎    | 265/500 [08:17<09:06,  2.33s/it] 53%|█████▎    | 267/500 [08:17<06:07,  1.58s/it] 54%|█████▍    | 269/500 [08:17<04:12,  1.09s/it] 54%|█████▍    | 270/500 [08:23<07:53,  2.06s/it] 54%|█████▍    | 271/500 [08:29<11:15,  2.95s/it] 55%|█████▍    | 273/500 [08:30<07:04,  1.87s/it] 55%|█████▌    | 275/500 [08:36<08:44,  2.33s/it] 55%|█████▌    | 277/500 [08:36<05:52,  1.58s/it] 56%|█████▌    | 279/500 [08:36<04:01,  1.09s/it] 56%|█████▌    | 281/500 [08:49<09:55,  2.72s/it] 57%|█████▋    | 283/500 [08:49<06:51,  1.90s/it] 57%|█████▋    | 285/500 [08:55<08:06,  2.26s/it] 57%|█████▋    | 287/500 [08:55<05:39,  1.59s/it] 58%|█████▊    | 289/500 [08:55<03:58,  1.13s/it] 58%|█████▊    | 291/500 [09:08<09:14,  2.65s/it] 59%|█████▊    | 293/500 [09:08<06:28,  1.88s/it] 59%|█████▉    | 295/500 [09:14<07:40,  2.25s/it] 59%|█████▉    | 297/500 [09:14<05:23,  1.59s/it] 60%|█████▉    | 299/500 [09:14<03:48,  1.13s/it]0.17074468731880188
Epoch:  242  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  243  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  244  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  245  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  247  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  248  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  249  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  250  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  252  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  253  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  254  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  255  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  257  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  258  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  259  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  260  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  262  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  263  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  264  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  265  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  267  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  268  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  269  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  270  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  272  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  273  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  274  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  275  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  277  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  278  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  279  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  280  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  282  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  283  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  284  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  285  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  287  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  288  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  289  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  290  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  292  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  293  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  294  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  295  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  297  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  298  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  299  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  300  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
 60%|██████    | 301/500 [09:27<08:48,  2.65s/it] 61%|██████    | 303/500 [09:27<06:10,  1.88s/it] 61%|██████    | 305/500 [09:33<07:20,  2.26s/it] 61%|██████▏   | 307/500 [09:33<05:09,  1.60s/it] 62%|██████▏   | 309/500 [09:33<03:38,  1.14s/it] 62%|██████▏   | 309/500 [09:44<03:38,  1.14s/it] 62%|██████▏   | 311/500 [09:46<08:24,  2.67s/it] 63%|██████▎   | 313/500 [09:46<05:53,  1.89s/it] 63%|██████▎   | 315/500 [09:52<07:00,  2.27s/it] 63%|██████▎   | 317/500 [09:52<04:54,  1.61s/it] 64%|██████▍   | 319/500 [09:53<03:27,  1.15s/it] 64%|██████▍   | 319/500 [10:04<03:27,  1.15s/it] 64%|██████▍   | 321/500 [10:05<07:56,  2.66s/it] 65%|██████▍   | 323/500 [10:05<05:33,  1.89s/it] 65%|██████▌   | 325/500 [10:11<06:36,  2.26s/it] 65%|██████▌   | 327/500 [10:12<04:37,  1.61s/it] 66%|██████▌   | 329/500 [10:12<03:15,  1.14s/it] 66%|██████▌   | 329/500 [10:24<03:15,  1.14s/it] 66%|██████▌   | 331/500 [10:24<07:32,  2.68s/it] 67%|██████▋   | 333/500 [10:24<05:16,  1.89s/it] 67%|██████▋   | 335/500 [10:31<06:15,  2.28s/it] 67%|██████▋   | 337/500 [10:31<04:23,  1.61s/it] 68%|██████▊   | 339/500 [10:31<03:05,  1.15s/it] 68%|██████▊   | 341/500 [10:43<07:02,  2.66s/it] 69%|██████▊   | 343/500 [10:43<04:55,  1.88s/it] 69%|██████▉   | 345/500 [10:50<05:50,  2.26s/it] 69%|██████▉   | 347/500 [10:50<04:05,  1.60s/it] 70%|██████▉   | 349/500 [10:50<02:52,  1.14s/it] 70%|███████   | 351/500 [11:02<06:37,  2.67s/it] 71%|███████   | 353/500 [11:03<04:37,  1.89s/it] 71%|███████   | 355/500 [11:09<05:27,  2.26s/it] 71%|███████▏  | 357/500 [11:09<03:49,  1.60s/it] 72%|███████▏  | 359/500 [11:09<02:40,  1.14s/it]Epoch:  301  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  302  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  303  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  304  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  305  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  307  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  308  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  309  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  310  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  312  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  313  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  314  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  315  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  317  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  318  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  319  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  320  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  322  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  323  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  324  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  325  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  327  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  328  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  329  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  330  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  332  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  333  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  334  	Training Loss: 0.16274255514144897
Test Loss:  0.16881808638572693
Valid Loss:  0.17074468731880188
Epoch:  335  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  337  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  338  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  339  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  340  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  342  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  343  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  344  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  345  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  347  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  348  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  349  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  350  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  352  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  353  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  354  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  355  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  357  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  358  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  359  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  360  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
 72%|███████▏  | 361/500 [11:21<06:05,  2.63s/it] 73%|███████▎  | 363/500 [11:21<04:15,  1.86s/it] 73%|███████▎  | 365/500 [11:28<05:01,  2.23s/it] 73%|███████▎  | 367/500 [11:28<03:30,  1.58s/it] 74%|███████▍  | 369/500 [11:28<02:27,  1.13s/it] 74%|███████▍  | 371/500 [11:40<05:37,  2.62s/it] 75%|███████▍  | 373/500 [11:40<03:55,  1.85s/it] 75%|███████▌  | 375/500 [11:46<04:38,  2.23s/it] 75%|███████▌  | 377/500 [11:47<03:14,  1.58s/it] 76%|███████▌  | 379/500 [11:47<02:16,  1.13s/it] 76%|███████▌  | 381/500 [11:59<05:13,  2.64s/it] 77%|███████▋  | 383/500 [11:59<03:38,  1.87s/it] 77%|███████▋  | 385/500 [12:06<04:19,  2.26s/it] 77%|███████▋  | 387/500 [12:06<03:00,  1.60s/it] 78%|███████▊  | 389/500 [12:06<02:06,  1.14s/it] 78%|███████▊  | 391/500 [12:18<04:49,  2.66s/it] 79%|███████▊  | 393/500 [12:18<03:21,  1.88s/it] 79%|███████▉  | 395/500 [12:25<03:56,  2.25s/it] 79%|███████▉  | 397/500 [12:25<02:44,  1.60s/it] 80%|███████▉  | 399/500 [12:25<01:55,  1.14s/it] 80%|████████  | 401/500 [12:37<04:23,  2.66s/it] 81%|████████  | 403/500 [12:37<03:02,  1.88s/it] 81%|████████  | 405/500 [12:44<03:34,  2.26s/it] 81%|████████▏ | 407/500 [12:44<02:28,  1.60s/it] 82%|████████▏ | 409/500 [12:44<01:43,  1.14s/it] 82%|████████▏ | 411/500 [12:56<03:57,  2.67s/it] 83%|████████▎ | 413/500 [12:57<02:44,  1.89s/it] 83%|████████▎ | 415/500 [13:03<03:11,  2.25s/it] 83%|████████▎ | 417/500 [13:03<02:12,  1.59s/it] 84%|████████▍ | 419/500 [13:03<01:32,  1.14s/it]**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  362  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  363  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  364  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  365  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  367  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  368  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  369  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  370  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  372  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  373  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  374  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  375  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  377  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  378  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  379  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  380  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  382  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  383  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  384  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  385  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  387  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  388  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  389  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  390  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  392  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  393  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  394  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  395  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  397  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  398  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  399  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  400  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  402  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  403  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  404  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  405  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  407  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  408  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  409  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  410  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  412  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  413  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  414  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  415  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  417  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  418  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  419  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
 84%|████████▍ | 419/500 [13:14<01:32,  1.14s/it] 84%|████████▍ | 421/500 [13:15<03:27,  2.63s/it] 85%|████████▍ | 423/500 [13:15<02:23,  1.86s/it] 85%|████████▌ | 425/500 [13:22<02:47,  2.23s/it] 85%|████████▌ | 427/500 [13:22<01:55,  1.58s/it] 86%|████████▌ | 429/500 [13:22<01:20,  1.13s/it] 86%|████████▌ | 429/500 [13:34<01:20,  1.13s/it] 86%|████████▌ | 431/500 [13:34<03:01,  2.63s/it] 87%|████████▋ | 433/500 [13:34<02:05,  1.87s/it] 87%|████████▋ | 435/500 [13:41<02:26,  2.25s/it] 87%|████████▋ | 437/500 [13:41<01:40,  1.60s/it] 88%|████████▊ | 439/500 [13:41<01:09,  1.14s/it] 88%|████████▊ | 441/500 [13:53<02:35,  2.64s/it] 89%|████████▊ | 443/500 [13:53<01:46,  1.87s/it] 89%|████████▉ | 445/500 [14:00<02:03,  2.24s/it] 89%|████████▉ | 447/500 [14:00<01:24,  1.59s/it] 90%|████████▉ | 449/500 [14:00<00:57,  1.13s/it] 90%|█████████ | 451/500 [14:12<02:10,  2.67s/it] 91%|█████████ | 453/500 [14:12<01:28,  1.89s/it] 91%|█████████ | 455/500 [14:19<01:41,  2.25s/it] 91%|█████████▏| 457/500 [14:19<01:08,  1.59s/it] 92%|█████████▏| 459/500 [14:19<00:46,  1.14s/it] 92%|█████████▏| 461/500 [14:31<01:43,  2.65s/it] 93%|█████████▎| 463/500 [14:31<01:09,  1.88s/it] 93%|█████████▎| 465/500 [14:38<01:18,  2.25s/it] 93%|█████████▎| 467/500 [14:38<00:52,  1.60s/it] 94%|█████████▍| 469/500 [14:38<00:35,  1.14s/it] 94%|█████████▍| 471/500 [14:50<01:15,  2.61s/it] 95%|█████████▍| 473/500 [14:50<00:49,  1.85s/it] 95%|█████████▌| 475/500 [14:50<00:32,  1.31s/it] 95%|█████████▌| 477/500 [14:50<00:21,  1.06it/s] 96%|█████████▌| 479/500 [14:51<00:14,  1.48it/s]Epoch:  420  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  422  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  423  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  424  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  425  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  427  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  428  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  429  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  430  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  432  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  433  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  434  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  435  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  437  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  438  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  439  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  440  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.1627425253391266
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  442  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  443  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  444  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  445  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  447  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  448  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  449  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  450  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  452  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  453  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  454  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  455  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  457  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  458  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  459  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  460  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  462  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  463  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  464  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  465  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  467  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  468  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  469  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  470  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
Epoch:  472  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  473  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  474  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  475  	Training Loss: 0.16274254024028778
Test Loss:  0.16881808638572693
Valid Loss:  0.17074468731880188
Epoch:  476  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  477  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  478  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  479  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
 96%|█████████▌| 481/500 [15:03<00:44,  2.32s/it] 97%|█████████▋| 483/500 [15:03<00:27,  1.64s/it] 97%|█████████▋| 485/500 [15:09<00:31,  2.08s/it] 97%|█████████▋| 487/500 [15:09<00:19,  1.47s/it] 98%|█████████▊| 489/500 [15:09<00:11,  1.05s/it] 98%|█████████▊| 491/500 [15:22<00:23,  2.58s/it] 99%|█████████▊| 493/500 [15:22<00:12,  1.83s/it] 99%|█████████▉| 495/500 [15:28<00:11,  2.21s/it] 99%|█████████▉| 497/500 [15:28<00:04,  1.57s/it]100%|█████████▉| 499/500 [15:28<00:01,  1.12s/it]100%|██████████| 500/500 [15:35<00:00,  1.87s/it]
Epoch:  480  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  482  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  483  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  484  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  485  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  487  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  488  	Training Loss: 0.16274254024028778
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  489  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  490  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  492  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  493  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  494  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074470221996307
Epoch:  495  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074470221996307
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  497  	Training Loss: 0.16274254024028778
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
Epoch:  498  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  499  	Training Loss: 0.16274255514144897
Test Loss:  0.16881810128688812
Valid Loss:  0.17074468731880188
Epoch:  500  	Training Loss: 0.16274255514144897
Test Loss:  0.16881811618804932
Valid Loss:  0.17074468731880188
**************************************************learning rate decay**************************************************
seed is  9
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:28,  6.07s/it]  1%|          | 3/500 [00:06<13:26,  1.62s/it]  1%|          | 5/500 [00:06<06:47,  1.22it/s]  1%|▏         | 7/500 [00:06<04:08,  1.99it/s]  2%|▏         | 9/500 [00:06<02:46,  2.95it/s]  2%|▏         | 11/500 [00:12<10:38,  1.31s/it]  3%|▎         | 13/500 [00:12<07:15,  1.12it/s]  3%|▎         | 15/500 [00:13<05:04,  1.60it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:24,  1.18s/it]  5%|▍         | 23/500 [00:19<06:40,  1.19it/s]  5%|▌         | 25/500 [00:26<12:18,  1.55s/it]  5%|▌         | 27/500 [00:26<08:45,  1.11s/it]  6%|▌         | 29/500 [00:26<06:17,  1.25it/s]  6%|▌         | 30/500 [00:32<13:40,  1.75s/it]  6%|▌         | 31/500 [00:38<20:39,  2.64s/it]  7%|▋         | 33/500 [00:38<13:14,  1.70s/it]  7%|▋         | 35/500 [00:38<08:49,  1.14s/it]  7%|▋         | 37/500 [00:39<06:03,  1.27it/s]  8%|▊         | 39/500 [00:39<04:16,  1.80it/s]  8%|▊         | 41/500 [00:45<10:26,  1.36s/it]  9%|▊         | 43/500 [00:45<07:20,  1.04it/s]  9%|▉         | 45/500 [00:45<05:13,  1.45it/s]  9%|▉         | 47/500 [00:45<03:45,  2.01it/s] 10%|▉         | 49/500 [00:46<02:45,  2.72it/s] 10%|█         | 51/500 [00:52<08:57,  1.20s/it] 11%|█         | 53/500 [00:52<06:23,  1.17it/s] 11%|█         | 55/500 [00:52<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:52<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:52<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:59<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:59<06:05,  1.19it/s] 13%|█▎        | 65/500 [00:59<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:59<03:12,  2.25it/s]Epoch:  1  	Training Loss: 0.08466490358114243
Test Loss:  2.0515024662017822
Valid Loss:  2.0533862113952637
Epoch:  2  	Training Loss: 2.037123680114746
Test Loss:  22.539302825927734
Valid Loss:  21.980056762695312
Epoch:  3  	Training Loss: 21.537948608398438
Test Loss:  0.23041583597660065
Valid Loss:  0.253643274307251
Epoch:  4  	Training Loss: 0.26825767755508423
Test Loss:  0.22531872987747192
Valid Loss:  0.24935974180698395
Epoch:  5  	Training Loss: 0.26302504539489746
Test Loss:  0.2207372486591339
Valid Loss:  0.2454168200492859
Epoch:  6  	Training Loss: 0.25845932960510254
Test Loss:  0.21653993427753448
Valid Loss:  0.24174083769321442
Epoch:  7  	Training Loss: 0.25427326560020447
Test Loss:  0.21254509687423706
Valid Loss:  0.2381644994020462
Epoch:  8  	Training Loss: 0.250253826379776
Test Loss:  0.20875215530395508
Valid Loss:  0.23467861115932465
Epoch:  9  	Training Loss: 0.24640436470508575
Test Loss:  0.205189049243927
Valid Loss:  0.23132070899009705
Epoch:  10  	Training Loss: 0.2427261471748352
Test Loss:  0.20171822607517242
Valid Loss:  0.22806425392627716
Epoch:  11  	Training Loss: 0.23915407061576843
Test Loss:  0.19836372137069702
Valid Loss:  0.22486720979213715
Epoch:  12  	Training Loss: 0.23565632104873657
Test Loss:  0.33424705266952515
Valid Loss:  0.3242400288581848
Epoch:  13  	Training Loss: 0.3056491017341614
Test Loss:  0.01142424251884222
Valid Loss:  0.01789935678243637
Epoch:  14  	Training Loss: 0.020121783018112183
Test Loss:  0.010329186916351318
Valid Loss:  0.016057584434747696
Epoch:  15  	Training Loss: 0.01793745905160904
Test Loss:  0.006552625447511673
Valid Loss:  0.011347685009241104
Epoch:  16  	Training Loss: 0.01264245342463255
Test Loss:  0.0045254104770720005
Valid Loss:  0.00864725187420845
Epoch:  17  	Training Loss: 0.009438112378120422
Test Loss:  0.0034988170955330133
Valid Loss:  0.007046331185847521
Epoch:  18  	Training Loss: 0.007464948575943708
Test Loss:  0.0030206639785319567
Valid Loss:  0.006065422669053078
Epoch:  19  	Training Loss: 0.0062170778401196
Test Loss:  0.0028217299841344357
Valid Loss:  0.005460843909531832
Epoch:  20  	Training Loss: 0.005420972127467394
Test Loss:  0.0027594652492552996
Valid Loss:  0.005062154494225979
Epoch:  21  	Training Loss: 0.004872484132647514
Test Loss:  0.0027073132805526257
Valid Loss:  0.004750434309244156
Epoch:  22  	Training Loss: 0.004440368618816137
Test Loss:  0.006531526800245047
Valid Loss:  0.006700670812278986
Epoch:  23  	Training Loss: 0.00522149121388793
Test Loss:  0.00517824525013566
Valid Loss:  0.007340720389038324
Epoch:  24  	Training Loss: 0.008102732710540295
Test Loss:  0.003417165717110038
Valid Loss:  0.003329726867377758
Epoch:  25  	Training Loss: 0.0030041802674531937
Test Loss:  0.0014891724567860365
Valid Loss:  0.0027805680874735117
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0026760902255773544
Test Loss:  0.0028301679994910955
Valid Loss:  0.0033610863611102104
Epoch:  27  	Training Loss: 0.0026324628852307796
Test Loss:  0.0014104401925578713
Valid Loss:  0.002649081638082862
Epoch:  28  	Training Loss: 0.0026662228628993034
Test Loss:  0.0033936265390366316
Valid Loss:  0.0036735530011355877
Epoch:  29  	Training Loss: 0.0028747981414198875
Test Loss:  0.0016481918282806873
Valid Loss:  0.0029384749941527843
Epoch:  30  	Training Loss: 0.0030998012516647577
Test Loss:  0.0042230114340782166
Valid Loss:  0.004311778582632542
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.003412386169657111
Test Loss:  0.0035456332843750715
Valid Loss:  0.003770744428038597
Epoch:  32  	Training Loss: 0.002944229869171977
Test Loss:  0.0016956505132839084
Valid Loss:  0.00225156731903553
Epoch:  33  	Training Loss: 0.0018326598219573498
Test Loss:  0.0014552585780620575
Valid Loss:  0.0020788833498954773
Epoch:  34  	Training Loss: 0.0017473356565460563
Test Loss:  0.0013816696591675282
Valid Loss:  0.002014736644923687
Epoch:  35  	Training Loss: 0.0016999796498566866
Test Loss:  0.0013295732205733657
Valid Loss:  0.0019651618786156178
Epoch:  36  	Training Loss: 0.0016562530072405934
Test Loss:  0.0013107447884976864
Valid Loss:  0.0019395406125113368
Epoch:  37  	Training Loss: 0.0016248223837465048
Test Loss:  0.0012837884714826941
Valid Loss:  0.001910362159833312
Epoch:  38  	Training Loss: 0.0015953555703163147
Test Loss:  0.0012573272688314319
Valid Loss:  0.0018816185183823109
Epoch:  39  	Training Loss: 0.0015670818975195289
Test Loss:  0.001232230686582625
Valid Loss:  0.0018539396114647388
Epoch:  40  	Training Loss: 0.0015401793643832207
Test Loss:  0.0012084707850590348
Valid Loss:  0.0018271713051944971
Epoch:  41  	Training Loss: 0.00151441537309438
Test Loss:  0.0011858859797939658
Valid Loss:  0.0018012161599472165
Epoch:  42  	Training Loss: 0.0014895970234647393
Test Loss:  0.001184996566735208
Valid Loss:  0.001798003911972046
Epoch:  43  	Training Loss: 0.0014840292278677225
Test Loss:  0.0011825886322185397
Valid Loss:  0.0017941209953278303
Epoch:  44  	Training Loss: 0.0014788631815463305
Test Loss:  0.0011792110744863749
Valid Loss:  0.001789699075743556
Epoch:  45  	Training Loss: 0.0014738645404577255
Test Loss:  0.0011751595884561539
Valid Loss:  0.0017849807627499104
Epoch:  46  	Training Loss: 0.0014690645039081573
Test Loss:  0.001170682837255299
Valid Loss:  0.0017801420763134956
Epoch:  47  	Training Loss: 0.0014643885660916567
Test Loss:  0.0011659541632980108
Valid Loss:  0.0017752182902768254
Epoch:  48  	Training Loss: 0.001459833001717925
Test Loss:  0.0011610856745392084
Valid Loss:  0.00177034642547369
Epoch:  49  	Training Loss: 0.001455408986657858
Test Loss:  0.0011562082218006253
Valid Loss:  0.0017654825933277607
Epoch:  50  	Training Loss: 0.0014511115150526166
Test Loss:  0.001151347765699029
Valid Loss:  0.0017607099143788218
Epoch:  51  	Training Loss: 0.0014468688750639558
Test Loss:  0.0011466431897133589
Valid Loss:  0.0017559798434376717
Epoch:  52  	Training Loss: 0.0014426952693611383
Test Loss:  0.0011396572226658463
Valid Loss:  0.0017515942454338074
Epoch:  53  	Training Loss: 0.0014404304092749953
Test Loss:  0.0011337373871356249
Valid Loss:  0.0017478035297244787
Epoch:  54  	Training Loss: 0.0014383373782038689
Test Loss:  0.001128652598708868
Valid Loss:  0.0017446433193981647
Epoch:  55  	Training Loss: 0.0014363820664584637
Test Loss:  0.0011242134496569633
Valid Loss:  0.0017420684453099966
Epoch:  56  	Training Loss: 0.001434683334082365
Test Loss:  0.0011203442700207233
Valid Loss:  0.0017398698255419731
Epoch:  57  	Training Loss: 0.0014331958955153823
Test Loss:  0.0011169046629220247
Valid Loss:  0.001737902406603098
Epoch:  58  	Training Loss: 0.001431817072443664
Test Loss:  0.0011138370027765632
Valid Loss:  0.0017362142680212855
Epoch:  59  	Training Loss: 0.001430572709068656
Test Loss:  0.0011111004278063774
Valid Loss:  0.0017347079701721668
Epoch:  60  	Training Loss: 0.0014293949352577329
Test Loss:  0.0011086183367297053
Valid Loss:  0.0017333412542939186
Epoch:  61  	Training Loss: 0.001428273506462574
Test Loss:  0.0011063471902161837
Valid Loss:  0.001732093165628612
Epoch:  62  	Training Loss: 0.0014272042317315936
Test Loss:  0.0011059918906539679
Valid Loss:  0.0017048438312485814
Epoch:  63  	Training Loss: 0.0014050197787582874
Test Loss:  0.0010999400401487947
Valid Loss:  0.0016868163365870714
Epoch:  64  	Training Loss: 0.0013909819535911083
Test Loss:  0.0010864508803933859
Valid Loss:  0.0016723203007131815
Epoch:  65  	Training Loss: 0.0013805718626827002
Test Loss:  0.001073735998943448
Valid Loss:  0.0016589886508882046
Epoch:  66  	Training Loss: 0.00137050892226398
Test Loss:  0.001062672003172338
Valid Loss:  0.0016469541005790234
Epoch:  67  	Training Loss: 0.0013609097804874182
Test Loss:  0.001052661333233118
Valid Loss:  0.001636020839214325
Epoch:  68  	Training Loss: 0.0013514896854758263
Test Loss:  0.0010434479918330908
Valid Loss:  0.0016254277434200048
 14%|█▍        | 69/500 [00:59<02:22,  3.03it/s] 14%|█▍        | 71/500 [01:05<08:20,  1.17s/it] 15%|█▍        | 73/500 [01:05<05:57,  1.19it/s] 15%|█▌        | 75/500 [01:06<04:17,  1.65it/s] 15%|█▌        | 77/500 [01:06<03:07,  2.25it/s] 16%|█▌        | 79/500 [01:06<02:18,  3.03it/s] 16%|█▌        | 81/500 [01:12<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:12<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:12<04:12,  1.65it/s] 17%|█▋        | 87/500 [01:12<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:13<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:19<07:54,  1.16s/it] 19%|█▊        | 93/500 [01:19<05:39,  1.20it/s] 19%|█▉        | 95/500 [01:19<04:04,  1.66it/s] 19%|█▉        | 97/500 [01:19<02:57,  2.26it/s] 20%|█▉        | 99/500 [01:19<02:11,  3.04it/s] 20%|██        | 101/500 [01:26<07:43,  1.16s/it] 21%|██        | 103/500 [01:26<05:30,  1.20it/s] 21%|██        | 105/500 [01:26<03:57,  1.66it/s] 21%|██▏       | 107/500 [01:26<02:53,  2.27it/s] 22%|██▏       | 109/500 [01:26<02:08,  3.05it/s] 22%|██▏       | 111/500 [01:32<07:30,  1.16s/it] 23%|██▎       | 113/500 [01:32<05:21,  1.20it/s] 23%|██▎       | 115/500 [01:33<03:51,  1.66it/s] 23%|██▎       | 117/500 [01:33<02:48,  2.27it/s] 24%|██▍       | 119/500 [01:33<02:05,  3.04it/s] 24%|██▍       | 121/500 [01:39<07:18,  1.16s/it] 25%|██▍       | 123/500 [01:39<05:13,  1.20it/s] 25%|██▌       | 125/500 [01:39<03:45,  1.66it/s] 25%|██▌       | 127/500 [01:39<02:45,  2.26it/s] 26%|██▌       | 129/500 [01:40<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:46<07:11,  1.17s/it] 27%|██▋       | 133/500 [01:46<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:46<03:41,  1.65it/s]Epoch:  69  	Training Loss: 0.0013420735485851765
Test Loss:  0.0010344183538109064
Valid Loss:  0.0016142119420692325
Epoch:  70  	Training Loss: 0.001332191633991897
Test Loss:  0.0010253767250105739
Valid Loss:  0.0016027919482439756
Epoch:  71  	Training Loss: 0.0013220830587670207
Test Loss:  0.001017552800476551
Valid Loss:  0.0015916700940579176
Epoch:  72  	Training Loss: 0.0013118496863171458
Test Loss:  0.001016730908304453
Valid Loss:  0.001561241107992828
Epoch:  73  	Training Loss: 0.0012837615795433521
Test Loss:  0.0010173022747039795
Valid Loss:  0.0015382214915007353
Epoch:  74  	Training Loss: 0.0012658140622079372
Test Loss:  0.0010166560532525182
Valid Loss:  0.0015202404465526342
Epoch:  75  	Training Loss: 0.0012537454022094607
Test Loss:  0.0010138486977666616
Valid Loss:  0.0015061752637848258
Epoch:  76  	Training Loss: 0.0012446007458493114
Test Loss:  0.0010090168798342347
Valid Loss:  0.0014944158028811216
Epoch:  77  	Training Loss: 0.0012376827653497458
Test Loss:  0.0010026798117905855
Valid Loss:  0.001484425156377256
Epoch:  78  	Training Loss: 0.0012317823711782694
Test Loss:  0.0009956692811101675
Valid Loss:  0.0014756124000996351
Epoch:  79  	Training Loss: 0.0012264593970030546
Test Loss:  0.0009885320905596018
Valid Loss:  0.0014674405101686716
Epoch:  80  	Training Loss: 0.0012214253656566143
Test Loss:  0.0009813786018639803
Valid Loss:  0.0014603276504203677
Epoch:  81  	Training Loss: 0.0012166163651272655
Test Loss:  0.0009747021249495447
Valid Loss:  0.0014534518122673035
Epoch:  82  	Training Loss: 0.0012118653394281864
Test Loss:  0.0008579283603467047
Valid Loss:  0.0013790836092084646
Epoch:  83  	Training Loss: 0.0011735025327652693
Test Loss:  0.0008332458091899753
Valid Loss:  0.0013563312822952867
Epoch:  84  	Training Loss: 0.0011572882067412138
Test Loss:  0.0008195770205929875
Valid Loss:  0.0013396311551332474
Epoch:  85  	Training Loss: 0.001142721390351653
Test Loss:  0.000807533273473382
Valid Loss:  0.001324221258983016
Epoch:  86  	Training Loss: 0.0011292225681245327
Test Loss:  0.0007966249249875546
Valid Loss:  0.0013098889030516148
Epoch:  87  	Training Loss: 0.001116700703278184
Test Loss:  0.0007866650703363121
Valid Loss:  0.0012964915949851274
Epoch:  88  	Training Loss: 0.001105059520341456
Test Loss:  0.0007772519020363688
Valid Loss:  0.0012838887050747871
Epoch:  89  	Training Loss: 0.001094111823476851
Test Loss:  0.000768458703532815
Valid Loss:  0.00127206661272794
Epoch:  90  	Training Loss: 0.0010836428264155984
Test Loss:  0.0007602719706483185
Valid Loss:  0.001261059776879847
Epoch:  91  	Training Loss: 0.0010738540440797806
Test Loss:  0.0007526271510869265
Valid Loss:  0.001250942936167121
Epoch:  92  	Training Loss: 0.0010646991431713104
Test Loss:  0.000752496300265193
Valid Loss:  0.0012487992644309998
Epoch:  93  	Training Loss: 0.0010618064552545547
Test Loss:  0.0007522891974076629
Valid Loss:  0.0012466930784285069
Epoch:  94  	Training Loss: 0.0010589984012767673
Test Loss:  0.0007520281942561269
Valid Loss:  0.0012446327600628138
Epoch:  95  	Training Loss: 0.0010562674142420292
Test Loss:  0.0007516953046433628
Valid Loss:  0.0012426087632775307
Epoch:  96  	Training Loss: 0.0010536046465858817
Test Loss:  0.0007512943702749908
Valid Loss:  0.001240610727109015
Epoch:  97  	Training Loss: 0.0010510033462196589
Test Loss:  0.0007508262060582638
Valid Loss:  0.0012386355083435774
Epoch:  98  	Training Loss: 0.001048459205776453
Test Loss:  0.0007502951775677502
Valid Loss:  0.0012366764713078737
Epoch:  99  	Training Loss: 0.0010459680343046784
Test Loss:  0.0007497036713175476
Valid Loss:  0.0012347375741228461
Epoch:  100  	Training Loss: 0.0010435264557600021
Test Loss:  0.0007490575080737472
Valid Loss:  0.001232813228853047
Epoch:  101  	Training Loss: 0.0010411326074972749
Test Loss:  0.0007483507506549358
Valid Loss:  0.0012309136800467968
Epoch:  102  	Training Loss: 0.0010387911461293697
Test Loss:  0.000734816596377641
Valid Loss:  0.0012082569301128387
Epoch:  103  	Training Loss: 0.0010146175045520067
Test Loss:  0.0007257935358211398
Valid Loss:  0.0011897711083292961
Epoch:  104  	Training Loss: 0.0009975357679650187
Test Loss:  0.0007215617806650698
Valid Loss:  0.0011799478670582175
Epoch:  105  	Training Loss: 0.0009904056787490845
Test Loss:  0.0007173190242610872
Valid Loss:  0.001173108466900885
Epoch:  106  	Training Loss: 0.000984501326456666
Test Loss:  0.0007132210885174572
Valid Loss:  0.0011667259968817234
Epoch:  107  	Training Loss: 0.0009788647294044495
Test Loss:  0.0007092715241014957
Valid Loss:  0.0011607882333919406
Epoch:  108  	Training Loss: 0.0009736176580190659
Test Loss:  0.0007053953595459461
Valid Loss:  0.0011551749194040895
Epoch:  109  	Training Loss: 0.0009686002740636468
Test Loss:  0.0007016051094979048
Valid Loss:  0.0011499534593895078
Epoch:  110  	Training Loss: 0.0009637728799134493
Test Loss:  0.0006977589218877256
Valid Loss:  0.0011448648292571306
Epoch:  111  	Training Loss: 0.0009590190020389855
Test Loss:  0.0006940186722204089
Valid Loss:  0.0011399679351598024
Epoch:  112  	Training Loss: 0.0009545585489831865
Test Loss:  0.0006837254040874541
Valid Loss:  0.001132145756855607
Epoch:  113  	Training Loss: 0.0009474013932049274
Test Loss:  0.0006755639333277941
Valid Loss:  0.0011256784200668335
Epoch:  114  	Training Loss: 0.0009409367339685559
Test Loss:  0.0006688254652544856
Valid Loss:  0.0011201100423932076
Epoch:  115  	Training Loss: 0.0009350131149403751
Test Loss:  0.0006631626165471971
Valid Loss:  0.0011152640217915177
Epoch:  116  	Training Loss: 0.0009294738993048668
Test Loss:  0.0006583413342013955
Valid Loss:  0.0011109437327831984
Epoch:  117  	Training Loss: 0.0009242428932338953
Test Loss:  0.0006541046313941479
Valid Loss:  0.0011069870088249445
Epoch:  118  	Training Loss: 0.0009192850557155907
Test Loss:  0.0006503189215436578
Valid Loss:  0.0011033174814656377
Epoch:  119  	Training Loss: 0.00091457215603441
Test Loss:  0.0006468872306868434
Valid Loss:  0.0010998868383467197
Epoch:  120  	Training Loss: 0.0009100785246118903
Test Loss:  0.0006437378469854593
Valid Loss:  0.0010966567788273096
Epoch:  121  	Training Loss: 0.0009057875722646713
Test Loss:  0.000640826765447855
Valid Loss:  0.0010935988975688815
Epoch:  122  	Training Loss: 0.0009016727562993765
Test Loss:  0.0006482484750449657
Valid Loss:  0.001093127066269517
Epoch:  123  	Training Loss: 0.0008908378658816218
Test Loss:  0.0006531234248541296
Valid Loss:  0.001092738937586546
Epoch:  124  	Training Loss: 0.0008831055602058768
Test Loss:  0.0006557215237990022
Valid Loss:  0.0010918756015598774
Epoch:  125  	Training Loss: 0.0008770513813942671
Test Loss:  0.0006565180374309421
Valid Loss:  0.001090450445190072
Epoch:  126  	Training Loss: 0.0008719580946490169
Test Loss:  0.0006559807807207108
Valid Loss:  0.0010885425144806504
Epoch:  127  	Training Loss: 0.0008674663258716464
Test Loss:  0.0006545000360347331
Valid Loss:  0.0010862757917493582
Epoch:  128  	Training Loss: 0.0008633853867650032
Test Loss:  0.0006523920455947518
Valid Loss:  0.001083774957805872
Epoch:  129  	Training Loss: 0.0008596080588176847
Test Loss:  0.0006498782895505428
Valid Loss:  0.0010811323300004005
Epoch:  130  	Training Loss: 0.0008560774731449783
Test Loss:  0.0006471244851127267
Valid Loss:  0.0010784243931993842
Epoch:  131  	Training Loss: 0.0008527630707249045
Test Loss:  0.0006442427402362227
Valid Loss:  0.0010756925912573934
Epoch:  132  	Training Loss: 0.0008496352820657194
Test Loss:  0.0006088593509048223
Valid Loss:  0.0010508757550269365
Epoch:  133  	Training Loss: 0.0008384301909245551
Test Loss:  0.00059202138800174
Valid Loss:  0.0010371936950832605
Epoch:  134  	Training Loss: 0.0008313057478517294
Test Loss:  0.0005819801008328795
Valid Loss:  0.0010273728985339403
Epoch:  135  	Training Loss: 0.0008251161780208349
Test Loss:  0.0005746937822550535
Valid Loss:  0.0010191748151555657
Epoch:  136  	Training Loss: 0.0008192828390747309
Test Loss:  0.0005686474032700062
Valid Loss:  0.0010117827914655209
Epoch:  137  	Training Loss: 0.0008136810502037406
Test Loss:  0.0005632357206195593
 27%|██▋       | 137/500 [01:46<02:41,  2.25it/s] 28%|██▊       | 139/500 [01:46<01:59,  3.03it/s] 28%|██▊       | 141/500 [01:52<06:53,  1.15s/it] 29%|██▊       | 143/500 [01:53<04:55,  1.21it/s] 29%|██▉       | 145/500 [01:53<03:32,  1.67it/s] 29%|██▉       | 147/500 [01:53<02:34,  2.28it/s] 30%|██▉       | 149/500 [01:53<01:54,  3.05it/s] 30%|███       | 151/500 [01:59<06:48,  1.17s/it] 31%|███       | 153/500 [01:59<04:51,  1.19it/s] 31%|███       | 155/500 [02:00<03:30,  1.64it/s] 31%|███▏      | 157/500 [02:00<02:33,  2.24it/s] 32%|███▏      | 159/500 [02:00<01:53,  3.01it/s] 32%|███▏      | 161/500 [02:06<06:32,  1.16s/it] 33%|███▎      | 163/500 [02:06<04:40,  1.20it/s] 33%|███▎      | 165/500 [02:06<03:21,  1.66it/s] 33%|███▎      | 167/500 [02:06<02:26,  2.27it/s] 34%|███▍      | 169/500 [02:07<01:50,  3.01it/s] 34%|███▍      | 171/500 [02:13<06:20,  1.16s/it] 35%|███▍      | 173/500 [02:13<04:32,  1.20it/s] 35%|███▌      | 175/500 [02:13<03:16,  1.65it/s] 35%|███▌      | 177/500 [02:13<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:13<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:19<06:10,  1.16s/it] 37%|███▋      | 183/500 [02:20<04:25,  1.20it/s] 37%|███▋      | 185/500 [02:20<03:10,  1.65it/s] 37%|███▋      | 187/500 [02:20<02:18,  2.25it/s] 38%|███▊      | 189/500 [02:20<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:26<05:58,  1.16s/it] 39%|███▊      | 193/500 [02:26<04:15,  1.20it/s] 39%|███▉      | 195/500 [02:26<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:27<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:27<01:39,  3.04it/s] 40%|████      | 201/500 [02:33<05:45,  1.16s/it] 41%|████      | 203/500 [02:33<04:06,  1.20it/s] 41%|████      | 205/500 [02:33<02:57,  1.66it/s]Valid Loss:  0.00100486830342561
Epoch:  138  	Training Loss: 0.000808269833214581
Test Loss:  0.0005582100711762905
Valid Loss:  0.0009983261115849018
Epoch:  139  	Training Loss: 0.0008030880708247423
Test Loss:  0.0005534541560336947
Valid Loss:  0.0009920938173308969
Epoch:  140  	Training Loss: 0.0007981317467056215
Test Loss:  0.0005489257164299488
Valid Loss:  0.0009861397556960583
Epoch:  141  	Training Loss: 0.0007933718152344227
Test Loss:  0.0005446277209557593
Valid Loss:  0.0009804277215152979
Epoch:  142  	Training Loss: 0.0007888071704655886
Test Loss:  0.000552603742107749
Valid Loss:  0.0009817832615226507
Epoch:  143  	Training Loss: 0.0007816980360075831
Test Loss:  0.0005589121719822288
Valid Loss:  0.000983281759545207
Epoch:  144  	Training Loss: 0.0007770385127514601
Test Loss:  0.0005635625566355884
Valid Loss:  0.0009844553424045444
Epoch:  145  	Training Loss: 0.0007737255655229092
Test Loss:  0.0005667542573064566
Valid Loss:  0.0009851566283032298
Epoch:  146  	Training Loss: 0.0007711606449447572
Test Loss:  0.0005687568336725235
Valid Loss:  0.0009853655938059092
Epoch:  147  	Training Loss: 0.0007690198253840208
Test Loss:  0.0005698261084035039
Valid Loss:  0.000985143706202507
Epoch:  148  	Training Loss: 0.0007671294151805341
Test Loss:  0.0005701855407096446
Valid Loss:  0.000984578626230359
Epoch:  149  	Training Loss: 0.0007653908687643707
Test Loss:  0.0005700142355635762
Valid Loss:  0.000983747304417193
Epoch:  150  	Training Loss: 0.0007637524977326393
Test Loss:  0.0005694461870007217
Valid Loss:  0.0009827211033552885
Epoch:  151  	Training Loss: 0.0007622074335813522
Test Loss:  0.0005685799987986684
Valid Loss:  0.000981563120149076
Epoch:  152  	Training Loss: 0.0007607347797602415
Test Loss:  0.0005395894404500723
Valid Loss:  0.0009630080312490463
Epoch:  153  	Training Loss: 0.000754848588258028
Test Loss:  0.0005286246305331588
Valid Loss:  0.0009562745690345764
Epoch:  154  	Training Loss: 0.0007531583542004228
Test Loss:  0.000524104805663228
Valid Loss:  0.000953438226133585
Epoch:  155  	Training Loss: 0.000752216437831521
Test Loss:  0.0005220893654040992
Valid Loss:  0.0009520553867332637
Epoch:  156  	Training Loss: 0.000751429470255971
Test Loss:  0.0005210882518440485
Valid Loss:  0.0009512590477243066
Epoch:  157  	Training Loss: 0.0007506959955208004
Test Loss:  0.0005205124616622925
Valid Loss:  0.000950711197219789
Epoch:  158  	Training Loss: 0.0007499968633055687
Test Loss:  0.0005201195599511266
Valid Loss:  0.0009502770844846964
Epoch:  159  	Training Loss: 0.0007493292214348912
Test Loss:  0.0005198107101023197
Valid Loss:  0.000949900015257299
Epoch:  160  	Training Loss: 0.0007486877148039639
Test Loss:  0.0005195469711907208
Valid Loss:  0.0009495574631728232
Epoch:  161  	Training Loss: 0.000748074147850275
Test Loss:  0.000519309367518872
Valid Loss:  0.0009492379613220692
Epoch:  162  	Training Loss: 0.0007474852027371526
Test Loss:  0.0005176240811124444
Valid Loss:  0.0009423153242096305
Epoch:  163  	Training Loss: 0.0007396855507977307
Test Loss:  0.000516094034537673
Valid Loss:  0.0009361725533381104
Epoch:  164  	Training Loss: 0.0007328223437070847
Test Loss:  0.0005146801704540849
Valid Loss:  0.00093068927526474
Epoch:  165  	Training Loss: 0.0007267564069479704
Test Loss:  0.0005133481463417411
Valid Loss:  0.0009258014615625143
Epoch:  166  	Training Loss: 0.0007214044453576207
Test Loss:  0.0005120794521644711
Valid Loss:  0.0009214195306412876
Epoch:  167  	Training Loss: 0.0007166598225012422
Test Loss:  0.0005108390469104052
Valid Loss:  0.0009174374863505363
Epoch:  168  	Training Loss: 0.0007123604300431907
Test Loss:  0.0005096168024465442
Valid Loss:  0.0009137754095718265
Epoch:  169  	Training Loss: 0.0007084464887157083
Test Loss:  0.0005084074218757451
Valid Loss:  0.0009103674674406648
Epoch:  170  	Training Loss: 0.0007048571715131402
Test Loss:  0.0005072150961495936
Valid Loss:  0.0009071896784007549
Epoch:  171  	Training Loss: 0.0007015669252723455
Test Loss:  0.0005059667164459825
Valid Loss:  0.0009042270248755813
Epoch:  172  	Training Loss: 0.0006985379732213914
Test Loss:  0.0005069326725788414
Valid Loss:  0.0009033106616698205
Epoch:  173  	Training Loss: 0.0006951902760192752
Test Loss:  0.0005064952420070767
Valid Loss:  0.0009017229313030839
Epoch:  174  	Training Loss: 0.0006922690663486719
Test Loss:  0.0005052436026744545
Valid Loss:  0.0008997573750093579
Epoch:  175  	Training Loss: 0.0006896218401379883
Test Loss:  0.0005035517970100045
Valid Loss:  0.0008976053795777261
Epoch:  176  	Training Loss: 0.0006871892837807536
Test Loss:  0.0005016447394154966
Valid Loss:  0.0008954064687713981
Epoch:  177  	Training Loss: 0.000684932223521173
Test Loss:  0.0004996542702428997
Valid Loss:  0.0008932147175073624
Epoch:  178  	Training Loss: 0.0006828242912888527
Test Loss:  0.0004976668860763311
Valid Loss:  0.0008910685428418219
Epoch:  179  	Training Loss: 0.0006808534963056445
Test Loss:  0.0004957322962582111
Valid Loss:  0.0008889883756637573
Epoch:  180  	Training Loss: 0.0006790068582631648
Test Loss:  0.0004938719794154167
Valid Loss:  0.0008869819575920701
Epoch:  181  	Training Loss: 0.0006772669730708003
Test Loss:  0.0004920709179714322
Valid Loss:  0.0008850517333485186
Epoch:  182  	Training Loss: 0.000675632560160011
Test Loss:  0.0004931195289827883
Valid Loss:  0.00087698083370924
Epoch:  183  	Training Loss: 0.000666875159367919
Test Loss:  0.0004925638204440475
Valid Loss:  0.0008724784711375833
Epoch:  184  	Training Loss: 0.0006634281016886234
Test Loss:  0.00049071095418185
Valid Loss:  0.0008684729691594839
Epoch:  185  	Training Loss: 0.0006610062555409968
Test Loss:  0.00048813672037795186
Valid Loss:  0.0008647549548186362
Epoch:  186  	Training Loss: 0.0006589051918126643
Test Loss:  0.00048532572691328824
Valid Loss:  0.0008612354286015034
Epoch:  187  	Training Loss: 0.0006569198449142277
Test Loss:  0.00048277602763846517
Valid Loss:  0.0008579695131629705
Epoch:  188  	Training Loss: 0.000655057025142014
Test Loss:  0.0004801914910785854
Valid Loss:  0.0008548754849471152
Epoch:  189  	Training Loss: 0.0006532545667141676
Test Loss:  0.00047773055848665535
Valid Loss:  0.0008520599221810699
Epoch:  190  	Training Loss: 0.0006515400018543005
Test Loss:  0.00047579602687619627
Valid Loss:  0.0008494590292684734
Epoch:  191  	Training Loss: 0.0006499788723886013
Test Loss:  0.0004740108270198107
Valid Loss:  0.0008470186730846763
Epoch:  192  	Training Loss: 0.0006484939949586987
Test Loss:  0.00044405055814422667
Valid Loss:  0.0008234611595980823
Epoch:  193  	Training Loss: 0.0006355346413329244
Test Loss:  0.0004348187067080289
Valid Loss:  0.0008133918745443225
Epoch:  194  	Training Loss: 0.0006262764800339937
Test Loss:  0.0004283891757950187
Valid Loss:  0.0008053964702412486
Epoch:  195  	Training Loss: 0.0006182640790939331
Test Loss:  0.0004229280457366258
Valid Loss:  0.0007982786628417671
Epoch:  196  	Training Loss: 0.0006112006376497447
Test Loss:  0.00041812111157923937
Valid Loss:  0.0007917745970189571
Epoch:  197  	Training Loss: 0.0006048810901120305
Test Loss:  0.00041382043855264783
Valid Loss:  0.0007857432938180864
Epoch:  198  	Training Loss: 0.0005991444922983646
Test Loss:  0.00040993146831169724
Valid Loss:  0.0007800977327860892
Epoch:  199  	Training Loss: 0.0005938778049312532
Test Loss:  0.00040636613266542554
Valid Loss:  0.000774754211306572
Epoch:  200  	Training Loss: 0.0005889834137633443
Test Loss:  0.0004030487034469843
Valid Loss:  0.0007696488173678517
Epoch:  201  	Training Loss: 0.0005843917606398463
Test Loss:  0.00039996340638026595
Valid Loss:  0.000764751632232219
Epoch:  202  	Training Loss: 0.0005800536600872874
Test Loss:  0.0003940659807994962
Valid Loss:  0.000759231043048203
Epoch:  203  	Training Loss: 0.0005774637684226036
Test Loss:  0.00038997840601950884
Valid Loss:  0.0007549852598458529
Epoch:  204  	Training Loss: 0.0005751292337663472
Test Loss:  0.00038691371446475387
Valid Loss:  0.000751452287659049
Epoch:  205  	Training Loss: 0.0005728973774239421
Test Loss:  0.00038442996446974576
Valid Loss:  0.0007483219960704446
 41%|████▏     | 207/500 [02:33<02:09,  2.27it/s] 42%|████▏     | 209/500 [02:33<01:35,  3.04it/s] 42%|████▏     | 211/500 [02:40<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:40<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:40<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:40<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:40<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:46<05:24,  1.16s/it] 45%|████▍     | 223/500 [02:47<03:51,  1.20it/s] 45%|████▌     | 225/500 [02:47<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:47<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:47<01:29,  3.04it/s] 46%|████▌     | 231/500 [02:53<05:13,  1.16s/it] 47%|████▋     | 233/500 [02:53<03:43,  1.20it/s] 47%|████▋     | 235/500 [02:53<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:54<01:56,  2.26it/s] 48%|████▊     | 239/500 [02:54<01:26,  3.03it/s] 48%|████▊     | 241/500 [03:00<05:02,  1.17s/it] 49%|████▊     | 243/500 [03:00<03:35,  1.19it/s] 49%|████▉     | 245/500 [03:00<02:34,  1.65it/s] 49%|████▉     | 247/500 [03:00<01:52,  2.25it/s] 50%|████▉     | 249/500 [03:01<01:23,  3.02it/s] 50%|█████     | 251/500 [03:07<04:51,  1.17s/it] 51%|█████     | 253/500 [03:07<03:27,  1.19it/s] 51%|█████     | 255/500 [03:07<02:29,  1.64it/s] 51%|█████▏    | 257/500 [03:07<01:48,  2.24it/s] 52%|█████▏    | 259/500 [03:07<01:20,  3.01it/s] 52%|█████▏    | 261/500 [03:14<04:40,  1.18s/it] 53%|█████▎    | 263/500 [03:14<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:14<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:14<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:14<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:20<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:21<03:10,  1.19it/s]Epoch:  206  	Training Loss: 0.0005707094096578658
Test Loss:  0.00038226600736379623
Valid Loss:  0.0007454094593413174
Epoch:  207  	Training Loss: 0.0005685426876880229
Test Loss:  0.0003802846185863018
Valid Loss:  0.0007426294032484293
Epoch:  208  	Training Loss: 0.0005663946503773332
Test Loss:  0.0003784281434491277
Valid Loss:  0.0007399414316751063
Epoch:  209  	Training Loss: 0.0005642690230160952
Test Loss:  0.00037666739081032574
Valid Loss:  0.0007373307016678154
Epoch:  210  	Training Loss: 0.0005621713353320956
Test Loss:  0.00037501263432204723
Valid Loss:  0.0007348405779339373
Epoch:  211  	Training Loss: 0.000560108688659966
Test Loss:  0.0003734302590601146
Valid Loss:  0.0007324345642700791
Epoch:  212  	Training Loss: 0.0005581071018241346
Test Loss:  0.00037585198879241943
Valid Loss:  0.0007334265392273664
Epoch:  213  	Training Loss: 0.0005571221117861569
Test Loss:  0.00037712950143031776
Valid Loss:  0.0007337785791605711
Epoch:  214  	Training Loss: 0.0005563672166317701
Test Loss:  0.00037770887138321996
Valid Loss:  0.0007337363203987479
Epoch:  215  	Training Loss: 0.000555729609914124
Test Loss:  0.0003778770915232599
Valid Loss:  0.0007334655383601785
Epoch:  216  	Training Loss: 0.0005551638314500451
Test Loss:  0.00037780916318297386
Valid Loss:  0.0007330724038183689
Epoch:  217  	Training Loss: 0.0005546535830944777
Test Loss:  0.00037761125713586807
Valid Loss:  0.0007326214108616114
Epoch:  218  	Training Loss: 0.0005541886202991009
Test Loss:  0.00037734408397227526
Valid Loss:  0.0007321481825783849
Epoch:  219  	Training Loss: 0.0005537626566365361
Test Loss:  0.00037704576971009374
Valid Loss:  0.0007316753035411239
Epoch:  220  	Training Loss: 0.0005533716175705194
Test Loss:  0.00037673403858207166
Valid Loss:  0.0007312124944292009
Epoch:  221  	Training Loss: 0.0005530113121494651
Test Loss:  0.00037642178358510137
Valid Loss:  0.0007307669147849083
Epoch:  222  	Training Loss: 0.0005526785971596837
Test Loss:  0.00037651642924174666
Valid Loss:  0.000730469124391675
Epoch:  223  	Training Loss: 0.0005521049024537206
Test Loss:  0.0003766473091673106
Valid Loss:  0.0007301821606233716
Epoch:  224  	Training Loss: 0.0005515575176104903
Test Loss:  0.0003767856687773019
Valid Loss:  0.0007299127173610032
Epoch:  225  	Training Loss: 0.000551047211047262
Test Loss:  0.0003769509494304657
Valid Loss:  0.0007296786643564701
Epoch:  226  	Training Loss: 0.000550557509995997
Test Loss:  0.00037717304076068103
Valid Loss:  0.0007294776733033359
Epoch:  227  	Training Loss: 0.0005501060513779521
Test Loss:  0.00037739265826530755
Valid Loss:  0.0007292927475646138
Epoch:  228  	Training Loss: 0.0005496972007676959
Test Loss:  0.0003776067169383168
Valid Loss:  0.000729119754396379
Epoch:  229  	Training Loss: 0.0005493193166330457
Test Loss:  0.0003778200480155647
Valid Loss:  0.0007289541536010802
Epoch:  230  	Training Loss: 0.0005489561008289456
Test Loss:  0.000378031050786376
Valid Loss:  0.0007287944899871945
Epoch:  231  	Training Loss: 0.0005486143636517227
Test Loss:  0.0003782368148677051
Valid Loss:  0.0007286477484740317
Epoch:  232  	Training Loss: 0.0005483051645569503
Test Loss:  0.00037574133602902293
Valid Loss:  0.0007249299669638276
Epoch:  233  	Training Loss: 0.0005454072961583734
Test Loss:  0.00037336425157263875
Valid Loss:  0.000721388089004904
Epoch:  234  	Training Loss: 0.0005426604184322059
Test Loss:  0.00037109898403286934
Valid Loss:  0.0007180094835348427
Epoch:  235  	Training Loss: 0.0005400547524914145
Test Loss:  0.0003689407021738589
Valid Loss:  0.0007147873402573168
Epoch:  236  	Training Loss: 0.0005375748150981963
Test Loss:  0.0003668839344754815
Valid Loss:  0.0007117012282833457
Epoch:  237  	Training Loss: 0.0005352040752768517
Test Loss:  0.0003649246646091342
Valid Loss:  0.0007087564445100725
Epoch:  238  	Training Loss: 0.0005329485866241157
Test Loss:  0.0003630575374700129
Valid Loss:  0.000705940299667418
Epoch:  239  	Training Loss: 0.0005308000836521387
Test Loss:  0.00036127783823758364
Valid Loss:  0.0007032478461042047
Epoch:  240  	Training Loss: 0.0005287527455948293
Test Loss:  0.0003595800371840596
Valid Loss:  0.0007006700616329908
Epoch:  241  	Training Loss: 0.0005268001696094871
Test Loss:  0.00035796075826510787
Valid Loss:  0.000698201241903007
Epoch:  242  	Training Loss: 0.0005249354289844632
Test Loss:  0.00035685166949406266
Valid Loss:  0.0006966042565181851
Epoch:  243  	Training Loss: 0.000523807539138943
Test Loss:  0.0003559082397259772
Valid Loss:  0.0006951542454771698
Epoch:  244  	Training Loss: 0.0005227333749644458
Test Loss:  0.00035507636494003236
Valid Loss:  0.0006938006263226271
Epoch:  245  	Training Loss: 0.0005217061843723059
Test Loss:  0.0003543214115779847
Valid Loss:  0.0006925200577825308
Epoch:  246  	Training Loss: 0.0005207346985116601
Test Loss:  0.0003536110743880272
Valid Loss:  0.000691292982082814
Epoch:  247  	Training Loss: 0.0005197987193241715
Test Loss:  0.00035293016117066145
Valid Loss:  0.0006901079905219376
Epoch:  248  	Training Loss: 0.0005188996437937021
Test Loss:  0.00035226382897235453
Valid Loss:  0.0006889600772410631
Epoch:  249  	Training Loss: 0.0005180427106097341
Test Loss:  0.00035161618143320084
Valid Loss:  0.0006878835847601295
Epoch:  250  	Training Loss: 0.0005172112141735852
Test Loss:  0.00035101850517094135
Valid Loss:  0.0006868670461699367
Epoch:  251  	Training Loss: 0.0005164028843864799
Test Loss:  0.0003504602937027812
Valid Loss:  0.0006858725100755692
Epoch:  252  	Training Loss: 0.0005156253464519978
Test Loss:  0.0003501447499729693
Valid Loss:  0.0006854665116406977
Epoch:  253  	Training Loss: 0.0005153856473043561
Test Loss:  0.0003498599398881197
Valid Loss:  0.0006850826321169734
Epoch:  254  	Training Loss: 0.0005151553777977824
Test Loss:  0.0003495989367365837
Valid Loss:  0.0006847155746072531
Epoch:  255  	Training Loss: 0.0005149322096258402
Test Loss:  0.0003493658732622862
Valid Loss:  0.0006843798910267651
Epoch:  256  	Training Loss: 0.0005147155607119203
Test Loss:  0.00034915542346425354
Valid Loss:  0.0006840581772848964
Epoch:  257  	Training Loss: 0.0005145047325640917
Test Loss:  0.00034896720899268985
Valid Loss:  0.0006837545079179108
Epoch:  258  	Training Loss: 0.0005143052549101412
Test Loss:  0.0003487953217700124
Valid Loss:  0.0006834625382907689
Epoch:  259  	Training Loss: 0.0005141150904819369
Test Loss:  0.0003486345231067389
Valid Loss:  0.000683180580381304
Epoch:  260  	Training Loss: 0.0005139322602190077
Test Loss:  0.0003484842600300908
Valid Loss:  0.0006829111371189356
Epoch:  261  	Training Loss: 0.0005137561238370836
Test Loss:  0.00034835663973353803
Valid Loss:  0.0006826627068221569
Epoch:  262  	Training Loss: 0.0005135888932272792
Test Loss:  0.00034879488521255553
Valid Loss:  0.0006799332331866026
Epoch:  263  	Training Loss: 0.0005094449734315276
Test Loss:  0.00034893208066932857
Valid Loss:  0.0006774276262149215
Epoch:  264  	Training Loss: 0.0005058785900473595
Test Loss:  0.0003488491056486964
Valid Loss:  0.0006751278415322304
Epoch:  265  	Training Loss: 0.0005027911392971873
Test Loss:  0.0003486073692329228
Valid Loss:  0.0006730066379532218
Epoch:  266  	Training Loss: 0.000500067020766437
Test Loss:  0.0003482485481072217
Valid Loss:  0.000671011337544769
Epoch:  267  	Training Loss: 0.0004975952324457467
Test Loss:  0.0003478186554275453
Valid Loss:  0.0006691685994155705
Epoch:  268  	Training Loss: 0.0004953921306878328
Test Loss:  0.0003473337856121361
Valid Loss:  0.0006674366304650903
Epoch:  269  	Training Loss: 0.0004933737218379974
Test Loss:  0.000346774875652045
Valid Loss:  0.0006658269558101892
Epoch:  270  	Training Loss: 0.000491553801111877
Test Loss:  0.0003461508604232222
Valid Loss:  0.0006643174565397203
Epoch:  271  	Training Loss: 0.0004898847546428442
Test Loss:  0.0003455287078395486
Valid Loss:  0.0006629031850025058
Epoch:  272  	Training Loss: 0.000488363322801888
Test Loss:  0.00034387491177767515
Valid Loss:  0.0006609255215153098
Epoch:  273  	Training Loss: 0.0004871294950135052
Test Loss:  0.0003423705929890275
Valid Loss:  0.0006590664852410555
 55%|█████▌    | 275/500 [03:21<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:21<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:21<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:27<04:14,  1.16s/it] 57%|█████▋    | 283/500 [03:27<03:01,  1.20it/s] 57%|█████▋    | 285/500 [03:27<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:28<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:28<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:34<04:05,  1.18s/it] 59%|█████▊    | 293/500 [03:34<02:54,  1.18it/s] 59%|█████▉    | 295/500 [03:34<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:34<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:35<01:07,  2.99it/s] 60%|██████    | 301/500 [03:41<03:50,  1.16s/it] 61%|██████    | 303/500 [03:41<02:44,  1.20it/s] 61%|██████    | 305/500 [03:41<01:57,  1.65it/s] 61%|██████▏   | 307/500 [03:41<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:41<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:48<03:42,  1.18s/it] 63%|██████▎   | 313/500 [03:48<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:48<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:48<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:48<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:54<03:28,  1.16s/it] 65%|██████▍   | 323/500 [03:54<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:55<01:45,  1.65it/s] 65%|██████▌   | 327/500 [03:55<01:16,  2.26it/s] 66%|██████▌   | 329/500 [03:55<00:56,  3.04it/s] 66%|██████▌   | 331/500 [04:01<03:16,  1.16s/it] 67%|██████▋   | 333/500 [04:01<02:19,  1.20it/s] 67%|██████▋   | 335/500 [04:01<01:39,  1.65it/s] 67%|██████▋   | 337/500 [04:01<01:12,  2.25it/s] 68%|██████▊   | 339/500 [04:02<00:53,  3.03it/s]Epoch:  274  	Training Loss: 0.0004859447362832725
Test Loss:  0.00034100277116522193
Valid Loss:  0.0006573123391717672
Epoch:  275  	Training Loss: 0.00048479452379979193
Test Loss:  0.0003397440887056291
Valid Loss:  0.0006556477746926248
Epoch:  276  	Training Loss: 0.0004836735315620899
Test Loss:  0.00033857874223031104
Valid Loss:  0.0006540622562170029
Epoch:  277  	Training Loss: 0.0004825792566407472
Test Loss:  0.0003374909283593297
Valid Loss:  0.0006525424541905522
Epoch:  278  	Training Loss: 0.00048150832299143076
Test Loss:  0.00033647159580141306
Valid Loss:  0.0006510820239782333
Epoch:  279  	Training Loss: 0.00048045843141153455
Test Loss:  0.0003355087828822434
Valid Loss:  0.0006496714195236564
Epoch:  280  	Training Loss: 0.00047942926175892353
Test Loss:  0.00033459486439824104
Valid Loss:  0.0006483048782683909
Epoch:  281  	Training Loss: 0.00047841810737736523
Test Loss:  0.0003337250673212111
Valid Loss:  0.0006469775689765811
Epoch:  282  	Training Loss: 0.00047742287279106677
Test Loss:  0.0003204609383828938
Valid Loss:  0.0006337917875498533
Epoch:  283  	Training Loss: 0.00047058556810952723
Test Loss:  0.00031121360370889306
Valid Loss:  0.0006245007971301675
Epoch:  284  	Training Loss: 0.00046510720858350396
Test Loss:  0.0003038378490600735
Valid Loss:  0.0006170364795252681
Epoch:  285  	Training Loss: 0.00046059544547460973
Test Loss:  0.00029765034560114145
Valid Loss:  0.0006107712397351861
Epoch:  286  	Training Loss: 0.00045679020695388317
Test Loss:  0.000292387034278363
Valid Loss:  0.0006053815013729036
Epoch:  287  	Training Loss: 0.00045353444875217974
Test Loss:  0.00028785428730770946
Valid Loss:  0.0006006861221976578
Epoch:  288  	Training Loss: 0.00045072814100421965
Test Loss:  0.00028390769148245454
Valid Loss:  0.0005965695600025356
Epoch:  289  	Training Loss: 0.00044825527584180236
Test Loss:  0.0002804581308737397
Valid Loss:  0.0005929129547439516
Epoch:  290  	Training Loss: 0.0004460355849005282
Test Loss:  0.0002774178283289075
Valid Loss:  0.0005896229413338006
Epoch:  291  	Training Loss: 0.00044402614003047347
Test Loss:  0.00027472723741084337
Valid Loss:  0.0005866444553248584
Epoch:  292  	Training Loss: 0.00044217193499207497
Test Loss:  0.0002745612000580877
Valid Loss:  0.0005864950362592936
Epoch:  293  	Training Loss: 0.0004415918665472418
Test Loss:  0.00027441399288363755
Valid Loss:  0.0005863927071914077
Epoch:  294  	Training Loss: 0.0004412531852722168
Test Loss:  0.0002742497017607093
Valid Loss:  0.0005862697726115584
Epoch:  295  	Training Loss: 0.00044101898674853146
Test Loss:  0.00027404705178923905
Valid Loss:  0.0005861088866367936
Epoch:  296  	Training Loss: 0.0004408328386489302
Test Loss:  0.00027380959363654256
Valid Loss:  0.0005859102820977569
Epoch:  297  	Training Loss: 0.0004406714579090476
Test Loss:  0.0002735468151513487
Valid Loss:  0.0005856830975972116
Epoch:  298  	Training Loss: 0.0004405237268656492
Test Loss:  0.0002732675347942859
Valid Loss:  0.0005854377523064613
Epoch:  299  	Training Loss: 0.00044038431951776147
Test Loss:  0.0002729782718233764
Valid Loss:  0.0005851778551004827
Epoch:  300  	Training Loss: 0.00044025032548233867
Test Loss:  0.0002726832462940365
Valid Loss:  0.0005849130684509873
Epoch:  301  	Training Loss: 0.0004401228507049382
Test Loss:  0.00027238327311351895
Valid Loss:  0.000584633438847959
Epoch:  302  	Training Loss: 0.00044000043999403715
Test Loss:  0.0002724509686231613
Valid Loss:  0.0005840407102368772
Epoch:  303  	Training Loss: 0.0004388376837596297
Test Loss:  0.00027245318051427603
Valid Loss:  0.0005834057228639722
Epoch:  304  	Training Loss: 0.00043772050412371755
Test Loss:  0.0002724019577726722
Valid Loss:  0.0005827386630699039
Epoch:  305  	Training Loss: 0.0004366395005490631
Test Loss:  0.00027230559499002993
Valid Loss:  0.0005820463411509991
Epoch:  306  	Training Loss: 0.0004355894634500146
Test Loss:  0.00027217064052820206
Valid Loss:  0.0005813305615447462
Epoch:  307  	Training Loss: 0.0004345666675362736
Test Loss:  0.0002720021875575185
Valid Loss:  0.0005806011613458395
Epoch:  308  	Training Loss: 0.0004335683770477772
Test Loss:  0.0002718040777835995
Valid Loss:  0.0005798560450784862
Epoch:  309  	Training Loss: 0.0004325907793827355
Test Loss:  0.00027157936710864305
Valid Loss:  0.0005790997529402375
Epoch:  310  	Training Loss: 0.0004316325066611171
Test Loss:  0.0002713307912927121
Valid Loss:  0.0005783338565379381
Epoch:  311  	Training Loss: 0.0004306916380301118
Test Loss:  0.00027105730259791017
Valid Loss:  0.0005775586469098926
Epoch:  312  	Training Loss: 0.0004297659615986049
Test Loss:  0.00026791502023115754
Valid Loss:  0.0005737695610150695
Epoch:  313  	Training Loss: 0.0004276603285688907
Test Loss:  0.00026566124870441854
Valid Loss:  0.0005708239041268826
Epoch:  314  	Training Loss: 0.0004257293476257473
Test Loss:  0.00026380596682429314
Valid Loss:  0.0005682589253410697
Epoch:  315  	Training Loss: 0.0004238532856106758
Test Loss:  0.0002621574676595628
Valid Loss:  0.0005658911541104317
Epoch:  316  	Training Loss: 0.000422004668507725
Test Loss:  0.00026062512188218534
Valid Loss:  0.000563634792342782
Epoch:  317  	Training Loss: 0.0004201785195618868
Test Loss:  0.0002591668744571507
Valid Loss:  0.0005614510737359524
Epoch:  318  	Training Loss: 0.0004183721321169287
Test Loss:  0.0002577580453362316
Valid Loss:  0.0005593192181549966
Epoch:  319  	Training Loss: 0.0004165850405115634
Test Loss:  0.000256378814810887
Valid Loss:  0.0005572112859226763
Epoch:  320  	Training Loss: 0.0004148157313466072
Test Loss:  0.0002550322387833148
Valid Loss:  0.000555122853256762
Epoch:  321  	Training Loss: 0.0004130635061301291
Test Loss:  0.0002537174732424319
Valid Loss:  0.0005530572379939258
Epoch:  322  	Training Loss: 0.0004113282193429768
Test Loss:  0.00025634700432419777
Valid Loss:  0.0005522151477634907
Epoch:  323  	Training Loss: 0.00040694786002859473
Test Loss:  0.00025788205675780773
Valid Loss:  0.0005511530325748026
Epoch:  324  	Training Loss: 0.0004038612241856754
Test Loss:  0.0002585435868240893
Valid Loss:  0.0005497690290212631
Epoch:  325  	Training Loss: 0.0004013894940726459
Test Loss:  0.0002586140763014555
Valid Loss:  0.0005481548141688108
Epoch:  326  	Training Loss: 0.00039926404133439064
Test Loss:  0.00025832292158156633
Valid Loss:  0.0005464214482344687
Epoch:  327  	Training Loss: 0.00039737141923978925
Test Loss:  0.0002578275161795318
Valid Loss:  0.0005446536233648658
Epoch:  328  	Training Loss: 0.0003956600558012724
Test Loss:  0.00025722989812493324
Valid Loss:  0.0005429066950455308
Epoch:  329  	Training Loss: 0.0003941014292649925
Test Loss:  0.0002565926988609135
Valid Loss:  0.0005412154132500291
Epoch:  330  	Training Loss: 0.0003926766512449831
Test Loss:  0.00025595282204449177
Valid Loss:  0.0005395972402766347
Epoch:  331  	Training Loss: 0.0003913714026566595
Test Loss:  0.00025533101870678365
Valid Loss:  0.0005380630609579384
Epoch:  332  	Training Loss: 0.00039017386734485626
Test Loss:  0.00025306089082732797
Valid Loss:  0.0005354860331863165
Epoch:  333  	Training Loss: 0.000388854939956218
Test Loss:  0.0002512339560780674
Valid Loss:  0.0005332989967428148
Epoch:  334  	Training Loss: 0.00038766214856877923
Test Loss:  0.00024973496329039335
Valid Loss:  0.0005314027657732368
Epoch:  335  	Training Loss: 0.0003865554463118315
Test Loss:  0.00024848018074408174
Valid Loss:  0.0005297233001329005
Epoch:  336  	Training Loss: 0.00038551155012100935
Test Loss:  0.00024741224478930235
Valid Loss:  0.0005282118218019605
Epoch:  337  	Training Loss: 0.0003845149767585099
Test Loss:  0.00024648732505738735
Valid Loss:  0.0005268302629701793
Epoch:  338  	Training Loss: 0.00038355286233127117
Test Loss:  0.000245672301389277
Valid Loss:  0.000525551091413945
Epoch:  339  	Training Loss: 0.00038261382724158466
Test Loss:  0.0002449435705784708
Valid Loss:  0.0005243169725872576
Epoch:  340  	Training Loss: 0.00038170136394910514
Test Loss:  0.00024428393226116896
Valid Loss:  0.000523135531693697
Epoch:  341  	Training Loss: 0.00038080153171904385
Test Loss:  0.00024367720470763743
Valid Loss:  68%|██████▊   | 341/500 [04:08<03:04,  1.16s/it] 69%|██████▊   | 343/500 [04:08<02:10,  1.20it/s] 69%|██████▉   | 345/500 [04:08<01:33,  1.66it/s] 69%|██████▉   | 347/500 [04:08<01:07,  2.27it/s] 70%|██████▉   | 349/500 [04:08<00:49,  3.05it/s] 70%|███████   | 351/500 [04:15<02:53,  1.16s/it] 71%|███████   | 353/500 [04:15<02:02,  1.20it/s] 71%|███████   | 355/500 [04:15<01:27,  1.66it/s] 71%|███████▏  | 357/500 [04:15<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:15<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:21<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:21<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:22<01:22,  1.65it/s] 73%|███████▎  | 367/500 [04:22<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:22<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:28<02:30,  1.16s/it] 75%|███████▍  | 373/500 [04:28<01:46,  1.20it/s] 75%|███████▌  | 375/500 [04:28<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:28<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:29<00:39,  3.04it/s] 76%|███████▌  | 381/500 [04:35<02:17,  1.16s/it] 77%|███████▋  | 383/500 [04:35<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:35<01:09,  1.66it/s] 77%|███████▋  | 387/500 [04:35<00:49,  2.27it/s] 78%|███████▊  | 389/500 [04:35<00:36,  3.04it/s] 78%|███████▊  | 391/500 [04:42<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:42<01:29,  1.20it/s] 79%|███████▉  | 395/500 [04:42<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:42<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:42<00:33,  3.03it/s] 80%|████████  | 401/500 [04:48<01:54,  1.15s/it] 81%|████████  | 403/500 [04:48<01:20,  1.20it/s] 81%|████████  | 405/500 [04:49<00:57,  1.66it/s] 81%|████████▏ | 407/500 [04:49<00:40,  2.27it/s] 0.0005220083985477686
Epoch:  342  	Training Loss: 0.0003799253609031439
Test Loss:  0.00024053780362010002
Valid Loss:  0.000517401669640094
Epoch:  343  	Training Loss: 0.0003779887920245528
Test Loss:  0.00024011352797970176
Valid Loss:  0.0005154954851604998
Epoch:  344  	Training Loss: 0.00037644151598215103
Test Loss:  0.00023989917826838791
Valid Loss:  0.0005139141576364636
Epoch:  345  	Training Loss: 0.0003750900796148926
Test Loss:  0.00023973995121195912
Valid Loss:  0.0005125019233673811
Epoch:  346  	Training Loss: 0.00037390534998849034
Test Loss:  0.0002396179479546845
Valid Loss:  0.0005112297367304564
Epoch:  347  	Training Loss: 0.00037286424776539207
Test Loss:  0.00023952152696438134
Valid Loss:  0.0005100785056129098
Epoch:  348  	Training Loss: 0.00037194538163021207
Test Loss:  0.0002394437906332314
Valid Loss:  0.0005090328631922603
Epoch:  349  	Training Loss: 0.0003711329773068428
Test Loss:  0.0002393780305283144
Valid Loss:  0.0005080766277387738
Epoch:  350  	Training Loss: 0.00037041009636595845
Test Loss:  0.00023931844043545425
Valid Loss:  0.0005071996711194515
Epoch:  351  	Training Loss: 0.0003697642241604626
Test Loss:  0.0002392612223047763
Valid Loss:  0.0005063913995400071
Epoch:  352  	Training Loss: 0.0003691848833113909
Test Loss:  0.00023976905504241586
Valid Loss:  0.000506536744069308
Epoch:  353  	Training Loss: 0.0003686162526719272
Test Loss:  0.0002402209647698328
Valid Loss:  0.0005066723679192364
Epoch:  354  	Training Loss: 0.00036812174948863685
Test Loss:  0.00024061897420324385
Valid Loss:  0.0005067960009910166
Epoch:  355  	Training Loss: 0.00036768976133316755
Test Loss:  0.00024096807464957237
Valid Loss:  0.0005069088074378669
Epoch:  356  	Training Loss: 0.0003673297178465873
Test Loss:  0.00024127030337695032
Valid Loss:  0.0005070045590400696
Epoch:  357  	Training Loss: 0.0003670085279736668
Test Loss:  0.0002415486960671842
Valid Loss:  0.0005070818588137627
Epoch:  358  	Training Loss: 0.00036672051646746695
Test Loss:  0.00024178711464628577
Valid Loss:  0.000507146178279072
Epoch:  359  	Training Loss: 0.00036646879743784666
Test Loss:  0.0002419875527266413
Valid Loss:  0.0005071944906376302
Epoch:  360  	Training Loss: 0.0003662389062810689
Test Loss:  0.00024215363373514265
Valid Loss:  0.0005072262138128281
Epoch:  361  	Training Loss: 0.0003660285728983581
Test Loss:  0.00024228882102761418
Valid Loss:  0.0005072468193247914
Epoch:  362  	Training Loss: 0.00036584300687536597
Test Loss:  0.00023484756820835173
Valid Loss:  0.0004995967610739172
Epoch:  363  	Training Loss: 0.0003639613278210163
Test Loss:  0.00023254042025655508
Valid Loss:  0.0004970619338564575
Epoch:  364  	Training Loss: 0.00036312593147158623
Test Loss:  0.00023135053925216198
Valid Loss:  0.0004956484772264957
Epoch:  365  	Training Loss: 0.00036237231688573956
Test Loss:  0.00023043918190523982
Valid Loss:  0.000494506792165339
Epoch:  366  	Training Loss: 0.0003616256290115416
Test Loss:  0.00022960758360568434
Valid Loss:  0.0004934432217851281
Epoch:  367  	Training Loss: 0.0003609006816986948
Test Loss:  0.00022881609038449824
Valid Loss:  0.0004924135864712298
Epoch:  368  	Training Loss: 0.0003602028591558337
Test Loss:  0.00022808421636000276
Valid Loss:  0.0004914405290037394
Epoch:  369  	Training Loss: 0.0003595199959818274
Test Loss:  0.00022739445557817817
Valid Loss:  0.0004904955276288092
Epoch:  370  	Training Loss: 0.00035885750548914075
Test Loss:  0.0002267252712044865
Valid Loss:  0.000489570084027946
Epoch:  371  	Training Loss: 0.0003582192293833941
Test Loss:  0.0002260993205709383
Valid Loss:  0.0004886763053946197
Epoch:  372  	Training Loss: 0.0003576292365323752
Test Loss:  0.0002261343615828082
Valid Loss:  0.00048811465967446566
Epoch:  373  	Training Loss: 0.00035694835241883993
Test Loss:  0.00022591929882764816
Valid Loss:  0.00048731386777944863
Epoch:  374  	Training Loss: 0.0003562887432053685
Test Loss:  0.0002257230516988784
Valid Loss:  0.000486542732687667
Epoch:  375  	Training Loss: 0.00035564834251999855
Test Loss:  0.00022554135648533702
Valid Loss:  0.0004857905732933432
Epoch:  376  	Training Loss: 0.00035502651007846
Test Loss:  0.0002253697020933032
Valid Loss:  0.00048505811719223857
Epoch:  377  	Training Loss: 0.00035442213993519545
Test Loss:  0.000225210256758146
Valid Loss:  0.00048434443306177855
Epoch:  378  	Training Loss: 0.00035383374779485166
Test Loss:  0.00022506104141939431
Valid Loss:  0.0004836485895793885
Epoch:  379  	Training Loss: 0.00035326185752637684
Test Loss:  0.00022492322023026645
Valid Loss:  0.0004829693352803588
Epoch:  380  	Training Loss: 0.0003527051885612309
Test Loss:  0.00022479469771496952
Valid Loss:  0.0004823066992685199
Epoch:  381  	Training Loss: 0.00035216298419982195
Test Loss:  0.00022467589587904513
Valid Loss:  0.0004816590226255357
Epoch:  382  	Training Loss: 0.00035162665881216526
Test Loss:  0.00022522505605593324
Valid Loss:  0.00048139470163732767
Epoch:  383  	Training Loss: 0.0003502243780530989
Test Loss:  0.00022500462364405394
Valid Loss:  0.0004804051714017987
Epoch:  384  	Training Loss: 0.00034894145210273564
Test Loss:  0.00022448880190495402
Valid Loss:  0.0004791347892023623
Epoch:  385  	Training Loss: 0.00034767447505146265
Test Loss:  0.0002238644810859114
Valid Loss:  0.00047776332939974964
Epoch:  386  	Training Loss: 0.0003464376204647124
Test Loss:  0.00022321561118587852
Valid Loss:  0.0004763754550367594
Epoch:  387  	Training Loss: 0.0003452356904745102
Test Loss:  0.00022259286197368056
Valid Loss:  0.0004750144144054502
Epoch:  388  	Training Loss: 0.000344037136528641
Test Loss:  0.000222007351112552
Valid Loss:  0.0004736668197438121
Epoch:  389  	Training Loss: 0.000342854589689523
Test Loss:  0.0002214473788626492
Valid Loss:  0.0004723442834801972
Epoch:  390  	Training Loss: 0.00034169957507401705
Test Loss:  0.00022090029960963875
Valid Loss:  0.00047105076373554766
Epoch:  391  	Training Loss: 0.00034056033473461866
Test Loss:  0.00022037350572645664
Valid Loss:  0.0004697831464000046
Epoch:  392  	Training Loss: 0.0003394316590856761
Test Loss:  0.00021621528139803559
Valid Loss:  0.0004661210405174643
Epoch:  393  	Training Loss: 0.00033530592918395996
Test Loss:  0.00021142969490028918
Valid Loss:  0.0004614153294824064
Epoch:  394  	Training Loss: 0.00033218454336747527
Test Loss:  0.00020747720554936677
Valid Loss:  0.00045751628931611776
Epoch:  395  	Training Loss: 0.0003296437207609415
Test Loss:  0.00020415628387127072
Valid Loss:  0.0004542263050097972
Epoch:  396  	Training Loss: 0.000327634799759835
Test Loss:  0.00020143143774475902
Valid Loss:  0.0004515119071584195
Epoch:  397  	Training Loss: 0.00032602346618659794
Test Loss:  0.00019916510791517794
Valid Loss:  0.0004491794388741255
Epoch:  398  	Training Loss: 0.0003246451378799975
Test Loss:  0.00019713697838597
Valid Loss:  0.00044709740905091166
Epoch:  399  	Training Loss: 0.0003234124160371721
Test Loss:  0.00019532645819708705
Valid Loss:  0.000445112818852067
Epoch:  400  	Training Loss: 0.000322378589771688
Test Loss:  0.00019378949946258217
Valid Loss:  0.00044339438318274915
Epoch:  401  	Training Loss: 0.0003214973257854581
Test Loss:  0.0001924258831422776
Valid Loss:  0.0004418891330715269
Epoch:  402  	Training Loss: 0.00032072761678136885
Test Loss:  0.0001914392050821334
Valid Loss:  0.0004402469494380057
Epoch:  403  	Training Loss: 0.0003200022329110652
Test Loss:  0.00019109035201836377
Valid Loss:  0.0004393681592773646
Epoch:  404  	Training Loss: 0.0003193208249285817
Test Loss:  0.0001908387494040653
Valid Loss:  0.00043860531877726316
Epoch:  405  	Training Loss: 0.0003186539397574961
Test Loss:  0.00019060772319789976
Valid Loss:  0.00043787111644633114
Epoch:  406  	Training Loss: 0.00031800061697140336
Test Loss:  0.0001903808442875743
Valid Loss:  0.00043714523781090975
Epoch:  407  	Training Loss: 0.000317358470056206
Test Loss:  0.00019015817088074982
Valid Loss:  0.00043642843957059085
Epoch:  408  	Training Loss: 0.00031672773184254766
Test Loss:  0.00018993922276422381
Valid Loss:  0.0004357173456810415
Epoch:  409  	Training Loss: 0.00031610700534656644
 82%|████████▏ | 409/500 [04:49<00:29,  3.05it/s] 82%|████████▏ | 411/500 [04:55<01:42,  1.16s/it] 83%|████████▎ | 413/500 [04:55<01:12,  1.20it/s] 83%|████████▎ | 415/500 [04:55<00:51,  1.66it/s] 83%|████████▎ | 417/500 [04:55<00:36,  2.27it/s] 84%|████████▍ | 419/500 [04:55<00:26,  3.05it/s] 84%|████████▍ | 421/500 [05:02<01:31,  1.16s/it] 85%|████████▍ | 423/500 [05:02<01:04,  1.20it/s] 85%|████████▌ | 425/500 [05:02<00:45,  1.65it/s] 85%|████████▌ | 427/500 [05:02<00:32,  2.26it/s] 86%|████████▌ | 429/500 [05:02<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:09<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:09<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:09<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:09<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:09<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:15<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:16<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:16<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:16<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:16<00:16,  3.00it/s] 90%|█████████ | 451/500 [05:22<00:56,  1.16s/it] 91%|█████████ | 453/500 [05:22<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:22<00:27,  1.66it/s] 91%|█████████▏| 457/500 [05:23<00:19,  2.26it/s] 92%|█████████▏| 459/500 [05:23<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:29<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:29<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:29<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:29<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:29<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:36<00:33,  1.15s/it] 95%|█████████▍| 473/500 [05:36<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:36<00:15,  1.66it/s]Test Loss:  0.00018972286488860846
Valid Loss:  0.0004350130329839885
Epoch:  410  	Training Loss: 0.0003154960577376187
Test Loss:  0.000189508413313888
Valid Loss:  0.00043431512312963605
Epoch:  411  	Training Loss: 0.00031489518005400896
Test Loss:  0.00018930004443973303
Valid Loss:  0.000433631066698581
Epoch:  412  	Training Loss: 0.0003143048379570246
Test Loss:  0.00018870925123337656
Valid Loss:  0.0004332058597356081
Epoch:  413  	Training Loss: 0.00031357293482869864
Test Loss:  0.00018767797155305743
Valid Loss:  0.00043215937330387533
Epoch:  414  	Training Loss: 0.00031303876312449574
Test Loss:  0.00018666815594770014
Valid Loss:  0.0004311002267058939
Epoch:  415  	Training Loss: 0.00031260441755875945
Test Loss:  0.00018576733418740332
Valid Loss:  0.0004301499284338206
Epoch:  416  	Training Loss: 0.0003122466732747853
Test Loss:  0.00018495976109988987
Valid Loss:  0.0004293202655389905
Epoch:  417  	Training Loss: 0.0003119368338957429
Test Loss:  0.00018421447020955384
Valid Loss:  0.00042857241351157427
Epoch:  418  	Training Loss: 0.0003116801381111145
Test Loss:  0.00018353461928199977
Valid Loss:  0.00042791265877895057
Epoch:  419  	Training Loss: 0.00031146666151471436
Test Loss:  0.0001829332031775266
Valid Loss:  0.0004273320664651692
Epoch:  420  	Training Loss: 0.0003112865670118481
Test Loss:  0.00018240055942442268
Valid Loss:  0.0004268259508535266
Epoch:  421  	Training Loss: 0.00031112576834857464
Test Loss:  0.0001819112221710384
Valid Loss:  0.0004263588634785265
Epoch:  422  	Training Loss: 0.00031099014449864626
Test Loss:  0.00018181881750933826
Valid Loss:  0.00042486112215556204
Epoch:  423  	Training Loss: 0.00030878756660968065
Test Loss:  0.0001812588016036898
Valid Loss:  0.00042287021642550826
Epoch:  424  	Training Loss: 0.0003067865618504584
Test Loss:  0.0001807408989407122
Valid Loss:  0.0004209764883853495
Epoch:  425  	Training Loss: 0.00030494589009322226
Test Loss:  0.00018028849444817752
Valid Loss:  0.00041920525836758316
Epoch:  426  	Training Loss: 0.00030324695399031043
Test Loss:  0.00017989637854043394
Valid Loss:  0.0004175448848400265
Epoch:  427  	Training Loss: 0.000301673193462193
Test Loss:  0.00017955517978407443
Valid Loss:  0.0004159831441938877
Epoch:  428  	Training Loss: 0.00030021124985069036
Test Loss:  0.00017925682186614722
Valid Loss:  0.0004145053098909557
Epoch:  429  	Training Loss: 0.00029884878313168883
Test Loss:  0.0001790020032785833
Valid Loss:  0.00041311047971248627
Epoch:  430  	Training Loss: 0.00029757508309558034
Test Loss:  0.00017878148355521262
Valid Loss:  0.00041178520768880844
Epoch:  431  	Training Loss: 0.0002963803999591619
Test Loss:  0.00017858964565675706
Valid Loss:  0.0004105207626707852
Epoch:  432  	Training Loss: 0.00029525600257329643
Test Loss:  0.00017882688553072512
Valid Loss:  0.0004105415428057313
Epoch:  433  	Training Loss: 0.00029488722793757915
Test Loss:  0.00017905114509630948
Valid Loss:  0.0004105519037693739
Epoch:  434  	Training Loss: 0.00029454444302245975
Test Loss:  0.00017926015425473452
Valid Loss:  0.000410552165703848
Epoch:  435  	Training Loss: 0.00029422418447211385
Test Loss:  0.00017945411673281342
Valid Loss:  0.0004105425614397973
Epoch:  436  	Training Loss: 0.00029392100987024605
Test Loss:  0.00017963509890250862
Valid Loss:  0.0004105243715457618
Epoch:  437  	Training Loss: 0.0002936287201009691
Test Loss:  0.0001797998120309785
Valid Loss:  0.00041049590799957514
Epoch:  438  	Training Loss: 0.00029335019644349813
Test Loss:  0.00017995017697103322
Valid Loss:  0.00041045600664801896
Epoch:  439  	Training Loss: 0.00029308436205610633
Test Loss:  0.00018008871120400727
Valid Loss:  0.00041041040094569325
Epoch:  440  	Training Loss: 0.0002928244648501277
Test Loss:  0.00018021329015027732
Valid Loss:  0.0004103526589460671
Epoch:  441  	Training Loss: 0.00029257353162392974
Test Loss:  0.00018032584921456873
Valid Loss:  0.00041028554551303387
Epoch:  442  	Training Loss: 0.00029233063105493784
Test Loss:  0.0001780405582394451
Valid Loss:  0.00040671374881640077
Epoch:  443  	Training Loss: 0.0002910628099925816
Test Loss:  0.0001773777767084539
Valid Loss:  0.00040504816570319235
Epoch:  444  	Training Loss: 0.000290057243546471
Test Loss:  0.00017703692719805986
Valid Loss:  0.0004037885810248554
Epoch:  445  	Training Loss: 0.0002891102631110698
Test Loss:  0.0001767731155268848
Valid Loss:  0.00040264311246573925
Epoch:  446  	Training Loss: 0.0002882080734707415
Test Loss:  0.00017653167014941573
Valid Loss:  0.00040154947782866657
Epoch:  447  	Training Loss: 0.00028734366060234606
Test Loss:  0.00017630119691602886
Valid Loss:  0.0004004899237770587
Epoch:  448  	Training Loss: 0.00028651533648371696
Test Loss:  0.0001760790473781526
Valid Loss:  0.0003994605503976345
Epoch:  449  	Training Loss: 0.00028572071460075676
Test Loss:  0.0001758641010383144
Valid Loss:  0.0003984581562690437
Epoch:  450  	Training Loss: 0.0002849557204172015
Test Loss:  0.000175654495251365
Valid Loss:  0.0003974805003963411
Epoch:  451  	Training Loss: 0.00028421811293810606
Test Loss:  0.00017545103037264198
Valid Loss:  0.0003965265932492912
Epoch:  452  	Training Loss: 0.0002835056802723557
Test Loss:  0.00017592177027836442
Valid Loss:  0.0003961652982980013
Epoch:  453  	Training Loss: 0.00028249656315892935
Test Loss:  0.00017597232363186777
Valid Loss:  0.0003953656414523721
Epoch:  454  	Training Loss: 0.0002815542393364012
Test Loss:  0.00017585991008672863
Valid Loss:  0.0003943961055483669
Epoch:  455  	Training Loss: 0.00028062655474059284
Test Loss:  0.00017567438771948218
Valid Loss:  0.0003933630941901356
Epoch:  456  	Training Loss: 0.00027972477255389094
Test Loss:  0.00017546600429341197
Valid Loss:  0.0003923217300325632
Epoch:  457  	Training Loss: 0.0002788362908177078
Test Loss:  0.00017524822033010423
Valid Loss:  0.0003912883112207055
Epoch:  458  	Training Loss: 0.00027795915957540274
Test Loss:  0.00017502534319646657
Valid Loss:  0.0003902635653503239
Epoch:  459  	Training Loss: 0.00027709989808499813
Test Loss:  0.00017481207032687962
Valid Loss:  0.0003892540989909321
Epoch:  460  	Training Loss: 0.0002762582153081894
Test Loss:  0.00017460380331613123
Valid Loss:  0.00038826154195703566
Epoch:  461  	Training Loss: 0.00027543294709175825
Test Loss:  0.00017441174713894725
Valid Loss:  0.00038728624349460006
Epoch:  462  	Training Loss: 0.00027460703859105706
Test Loss:  0.0001731587981339544
Valid Loss:  0.0003855914401356131
Epoch:  463  	Training Loss: 0.0002739981282502413
Test Loss:  0.00017232770915143192
Valid Loss:  0.00038440970820374787
Epoch:  464  	Training Loss: 0.00027345019043423235
Test Loss:  0.00017168719205074012
Valid Loss:  0.00038345379289239645
Epoch:  465  	Training Loss: 0.0002729221014305949
Test Loss:  0.000171154853887856
Valid Loss:  0.0003826166794169694
Epoch:  466  	Training Loss: 0.0002724119112826884
Test Loss:  0.00017066049622371793
Valid Loss:  0.00038183407741598785
Epoch:  467  	Training Loss: 0.0002719115000218153
Test Loss:  0.00017018978542182595
Valid Loss:  0.00038107874570414424
Epoch:  468  	Training Loss: 0.00027143603074364364
Test Loss:  0.00016975728794932365
Valid Loss:  0.0003803671570494771
Epoch:  469  	Training Loss: 0.000270978023763746
Test Loss:  0.0001693381927907467
Valid Loss:  0.00037967762909829617
Epoch:  470  	Training Loss: 0.00027053270605392754
Test Loss:  0.0001689514028839767
Valid Loss:  0.0003790291375480592
Epoch:  471  	Training Loss: 0.00027010287158191204
Test Loss:  0.00016860218602232635
Valid Loss:  0.0003783983120229095
Epoch:  472  	Training Loss: 0.00026968520251102746
Test Loss:  0.00016862548363860697
Valid Loss:  0.00037827284540981054
Epoch:  473  	Training Loss: 0.0002695189614314586
Test Loss:  0.0001686318137217313
Valid Loss:  0.000378126569557935
Epoch:  474  	Training Loss: 0.00026935513596981764
Test Loss:  0.00016862814663909376
Valid Loss:  0.0003779703110922128
Epoch:  475  	Training Loss: 0.00026919564697891474
Test Loss:  0.00016861141193658113
Valid Loss:  0.0003778006648644805
Epoch:  476  	Training Loss: 0.0002690365945454687
Test Loss:  0.00016858761955518275
Valid Loss:  95%|█████████▌| 477/500 [05:36<00:10,  2.26it/s] 96%|█████████▌| 479/500 [05:36<00:06,  3.03it/s] 96%|█████████▌| 481/500 [05:42<00:21,  1.15s/it] 97%|█████████▋| 483/500 [05:42<00:14,  1.21it/s] 97%|█████████▋| 485/500 [05:43<00:08,  1.67it/s] 97%|█████████▋| 487/500 [05:43<00:05,  2.26it/s] 98%|█████████▊| 489/500 [05:43<00:03,  3.04it/s] 98%|█████████▊| 491/500 [05:49<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:49<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:49<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:50<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:50<00:00,  3.01it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
 0.00037762089050374925
Epoch:  477  	Training Loss: 0.0002688798413146287
Test Loss:  0.0001685587631072849
Valid Loss:  0.00037743354914709926
Epoch:  478  	Training Loss: 0.0002687270171009004
Test Loss:  0.00016852589033078402
Valid Loss:  0.0003772430936805904
Epoch:  479  	Training Loss: 0.0002685759391169995
Test Loss:  0.00016848871018737555
Valid Loss:  0.0003770473413169384
Epoch:  480  	Training Loss: 0.00026842544320970774
Test Loss:  0.00016844685887917876
Valid Loss:  0.00037684699054807425
Epoch:  481  	Training Loss: 0.0002682758495211601
Test Loss:  0.0001684046583250165
Valid Loss:  0.000376646377844736
Epoch:  482  	Training Loss: 0.000268127623712644
Test Loss:  0.00016814577975310385
Valid Loss:  0.00037648918805643916
Epoch:  483  	Training Loss: 0.00026594498194754124
Test Loss:  0.00016831961693242192
Valid Loss:  0.0003766523441299796
Epoch:  484  	Training Loss: 0.0002648003865033388
Test Loss:  0.00016856309957802296
Valid Loss:  0.00037680473178625107
Epoch:  485  	Training Loss: 0.00026413361774757504
Test Loss:  0.00016872884589247406
Valid Loss:  0.00037683715345337987
Epoch:  486  	Training Loss: 0.0002636813442222774
Test Loss:  0.000168806582223624
Valid Loss:  0.00037676870124414563
Epoch:  487  	Training Loss: 0.0002633151307236403
Test Loss:  0.0001688174670562148
Valid Loss:  0.00037660941598005593
Epoch:  488  	Training Loss: 0.00026299318415112793
Test Loss:  0.00016877331654541194
Valid Loss:  0.000376381678506732
Epoch:  489  	Training Loss: 0.0002626915229484439
Test Loss:  0.00016868709644768387
Valid Loss:  0.0003761026600841433
Epoch:  490  	Training Loss: 0.00026239879662171006
Test Loss:  0.00016857187438290566
Valid Loss:  0.00037578813498839736
Epoch:  491  	Training Loss: 0.0002621111343614757
Test Loss:  0.00016843725461512804
Valid Loss:  0.00037545087980106473
Epoch:  492  	Training Loss: 0.00026182629517279565
Test Loss:  0.00016697678074706346
Valid Loss:  0.00037373590748757124
Epoch:  493  	Training Loss: 0.00026115740183740854
Test Loss:  0.00016577249334659427
Valid Loss:  0.0003722877590917051
Epoch:  494  	Training Loss: 0.00026062075630761683
Test Loss:  0.00016477401368319988
Valid Loss:  0.00037105288356542587
Epoch:  495  	Training Loss: 0.00026018323842436075
Test Loss:  0.00016394199337810278
Valid Loss:  0.00036999303847551346
Epoch:  496  	Training Loss: 0.0002598199644125998
Test Loss:  0.00016324639727827162
Valid Loss:  0.0003690746671054512
Epoch:  497  	Training Loss: 0.0002595131518319249
Test Loss:  0.00016266218153759837
Valid Loss:  0.0003682733222376555
Epoch:  498  	Training Loss: 0.00025924909277819097
Test Loss:  0.00016216948279179633
Valid Loss:  0.00036756915505975485
Epoch:  499  	Training Loss: 0.0002590176009107381
Test Loss:  0.00016175254131667316
Valid Loss:  0.00036694540176540613
Epoch:  500  	Training Loss: 0.0002588106435723603
Test Loss:  0.00016139866784214973
Valid Loss:  0.00036638882011175156
seed is  10
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:35, 14.17it/s]  1%|          | 4/500 [00:00<00:32, 15.13it/s]  1%|          | 6/500 [00:00<00:31, 15.60it/s]  2%|▏         | 8/500 [00:00<00:31, 15.77it/s]  2%|▏         | 10/500 [00:00<00:31, 15.74it/s]  2%|▏         | 12/500 [00:00<00:30, 15.98it/s]  3%|▎         | 14/500 [00:00<00:30, 15.89it/s]  3%|▎         | 16/500 [00:01<00:30, 16.07it/s]  4%|▎         | 18/500 [00:01<00:29, 16.20it/s]  4%|▍         | 20/500 [00:01<00:29, 16.31it/s]  4%|▍         | 22/500 [00:01<00:29, 16.33it/s]  5%|▍         | 24/500 [00:01<00:29, 16.32it/s]  5%|▌         | 26/500 [00:01<00:29, 16.33it/s]  6%|▌         | 28/500 [00:01<00:28, 16.36it/s]  6%|▌         | 30/500 [00:01<00:28, 16.32it/s]  6%|▋         | 32/500 [00:01<00:28, 16.16it/s]  7%|▋         | 34/500 [00:02<00:29, 15.76it/s]  7%|▋         | 36/500 [00:02<00:29, 15.60it/s]  8%|▊         | 38/500 [00:02<00:29, 15.80it/s]  8%|▊         | 40/500 [00:02<00:28, 15.95it/s]  8%|▊         | 42/500 [00:02<00:28, 16.09it/s]  9%|▉         | 44/500 [00:02<00:28, 16.21it/s]  9%|▉         | 46/500 [00:02<00:27, 16.25it/s] 10%|▉         | 48/500 [00:02<00:28, 16.09it/s] 10%|█         | 50/500 [00:03<00:27, 16.10it/s] 10%|█         | 52/500 [00:03<00:28, 15.98it/s] 11%|█         | 54/500 [00:03<00:28, 15.58it/s] 11%|█         | 56/500 [00:03<00:28, 15.72it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.39it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.70it/s] 12%|█▏        | 62/500 [00:03<00:27, 15.93it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.87it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.93it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.89it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.91it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.91it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.86it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.90it/s] 16%|█▌        | 78/500 [00:04<00:27, 15.56it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.70it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.49it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.64it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.73it/s] 18%|█▊        | 88/500 [00:05<00:27, 14.96it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.27it/s] 18%|█▊        | 92/500 [00:05<00:27, 15.09it/s] 19%|█▉        | 94/500 [00:05<00:26, 15.41it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.67it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.88it/s] 20%|██        | 100/500 [00:06<00:25, 15.91it/s] 20%|██        | 102/500 [00:06<00:24, 15.94it/s] 21%|██        | 104/500 [00:06<00:24, 15.96it/s] 21%|██        | 106/500 [00:06<00:24, 16.05it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.04it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.05it/s] 22%|██▏       | 112/500 [00:07<00:24, 16.06it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.09it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.19it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.24it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.33it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.38it/s] 25%|██▍       | 124/500 [00:07<00:24, 15.41it/s]Epoch:  1  	Training Loss: 0.06514871120452881
Test Loss:  578.8358764648438
Valid Loss:  579.1568603515625
Epoch:  2  	Training Loss: 580.2716064453125
Test Loss:  1550005960704.0
Valid Loss:  1539829268480.0
Epoch:  3  	Training Loss: 1528812535808.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:24, 15.07it/s] 26%|██▌       | 128/500 [00:08<00:24, 15.42it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.74it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.93it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.02it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.80it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.92it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.09it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.16it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.88it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.12it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.17it/s] 30%|███       | 150/500 [00:09<00:21, 16.21it/s] 30%|███       | 152/500 [00:09<00:21, 16.30it/s] 31%|███       | 154/500 [00:09<00:21, 15.84it/s] 31%|███       | 156/500 [00:09<00:21, 15.83it/s] 32%|███▏      | 158/500 [00:09<00:21, 15.79it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.80it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.80it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.04it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.83it/s] 34%|███▎      | 168/500 [00:10<00:20, 15.94it/s] 34%|███▍      | 170/500 [00:10<00:20, 15.96it/s] 34%|███▍      | 172/500 [00:10<00:21, 15.34it/s] 35%|███▍      | 174/500 [00:10<00:20, 15.60it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.68it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.35it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.54it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.63it/s] 37%|███▋      | 184/500 [00:11<00:19, 15.81it/s] 37%|███▋      | 186/500 [00:11<00:19, 15.83it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.95it/s] 38%|███▊      | 190/500 [00:11<00:19, 15.85it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.94it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.89it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.41it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.63it/s] 40%|████      | 200/500 [00:12<00:19, 15.61it/s] 40%|████      | 202/500 [00:12<00:18, 15.83it/s] 41%|████      | 204/500 [00:12<00:18, 16.05it/s] 41%|████      | 206/500 [00:12<00:18, 15.77it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.91it/s] 42%|████▏     | 210/500 [00:13<00:18, 16.01it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.14it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.12it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.11it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.11it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.02it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.14it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.88it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.99it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.10it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.21it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.33it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.19it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.06it/s] 48%|████▊     | 238/500 [00:14<00:16, 15.97it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.08it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.22it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.84it/s] 49%|████▉     | 246/500 [00:15<00:15, 15.96it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.10it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.09it/s] 50%|█████     | 252/500 [00:15<00:15, 16.21it/s] 51%|█████     | 254/500 [00:15<00:15, 15.45it/s] 51%|█████     | 256/500 [00:16<00:15, 15.61it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.61it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.54it/s] 52%|█████▏    | 262/500 [00:16<00:15, 15.75it/s] 53%|█████▎    | 264/500 [00:16<00:14, 15.95it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.05it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.15it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.23it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.05it/s] 55%|█████▍    | 274/500 [00:17<00:14, 16.01it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.96it/s] 56%|█████▌    | 278/500 [00:17<00:13, 15.87it/s] 56%|█████▌    | 280/500 [00:17<00:14, 14.81it/s] 56%|█████▋    | 282/500 [00:17<00:14, 14.92it/s] 57%|█████▋    | 284/500 [00:17<00:14, 15.33it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.62it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.81it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.89it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.89it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.67it/s] 59%|█████▉    | 296/500 [00:18<00:13, 15.66it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.75it/s] 60%|██████    | 300/500 [00:18<00:12, 15.77it/s] 60%|██████    | 302/500 [00:19<00:12, 15.78it/s] 61%|██████    | 304/500 [00:19<00:12, 15.82it/s] 61%|██████    | 306/500 [00:19<00:12, 16.07it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.08it/s] 62%|██████▏   | 310/500 [00:19<00:12, 14.80it/s] 62%|██████▏   | 312/500 [00:19<00:13, 13.97it/s] 63%|██████▎   | 314/500 [00:19<00:13, 13.44it/s] 63%|██████▎   | 316/500 [00:20<00:13, 13.27it/s] 64%|██████▎   | 318/500 [00:20<00:12, 14.05it/s] 64%|██████▍   | 320/500 [00:20<00:12, 14.67it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.17it/s] 65%|██████▍   | 324/500 [00:20<00:11, 14.86it/s] 65%|██████▌   | 326/500 [00:20<00:11, 15.23it/s] 66%|██████▌   | 328/500 [00:20<00:11, 15.55it/s] 66%|██████▌   | 330/500 [00:20<00:10, 15.72it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.57it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.79it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.78it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.93it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.07it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.14it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.23it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.32it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.30it/s] 70%|███████   | 350/500 [00:22<00:09, 16.10it/s] 70%|███████   | 352/500 [00:22<00:09, 16.15it/s] 71%|███████   | 354/500 [00:22<00:09, 16.09it/s] 71%|███████   | 356/500 [00:22<00:08, 16.09it/s] 72%|███████▏  | 358/500 [00:22<00:08, 15.80it/s] 72%|███████▏  | 360/500 [00:22<00:09, 15.16it/s] 72%|███████▏  | 362/500 [00:22<00:08, 15.51it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.59it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.64it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.88it/s] 74%|███████▍  | 370/500 [00:23<00:08, 16.01it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.91it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 15.96it/s] 75%|███████▌  | 376/500 [00:23<00:08, 14.62it/s] 76%|███████▌  | 378/500 [00:24<00:08, 13.85it/s] 76%|███████▌  | 380/500 [00:24<00:08, 14.01it/s] 76%|███████▋  | 382/500 [00:24<00:08, 14.35it/s] 77%|███████▋  | 384/500 [00:24<00:07, 14.68it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.13it/s] 78%|███████▊  | 388/500 [00:24<00:07, 15.38it/s] 78%|███████▊  | 390/500 [00:24<00:07, 15.68it/s] 78%|███████▊  | 392/500 [00:24<00:06, 15.54it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.45it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.71it/s] 80%|███████▉  | 398/500 [00:25<00:06, 15.85it/s] 80%|████████  | 400/500 [00:25<00:06, 15.96it/s] 80%|████████  | 402/500 [00:25<00:06, 15.93it/s] 81%|████████  | 404/500 [00:25<00:06, 15.89it/s] 81%|████████  | 406/500 [00:25<00:05, 15.70it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.90it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.04it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.02it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.12it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.09it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.17it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.22it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.27it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.28it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.30it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.35it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.39it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.41it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.39it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.43it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.28it/s] 88%|████████▊ | 440/500 [00:27<00:03, 15.82it/s] 88%|████████▊ | 442/500 [00:28<00:03, 15.95it/s] 89%|████████▉ | 444/500 [00:28<00:03, 15.93it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.12it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.24it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.31it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.18it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.21it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.32it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.20it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.47it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.49it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.61it/s] 93%|█████████▎| 466/500 [00:29<00:02, 15.38it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.68it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.72it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.64it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.80it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.68it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.85it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.68it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.47it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.53it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.46it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.23it/s] 98%|█████████▊| 490/500 [00:31<00:00, 15.39it/s] 98%|█████████▊| 492/500 [00:31<00:00, 15.53it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.74it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.95it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.78it/s]100%|██████████| 500/500 [00:31<00:00, 15.90it/s]100%|██████████| 500/500 [00:31<00:00, 15.77it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  10
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:28,  6.07s/it]  1%|          | 3/500 [00:06<13:27,  1.62s/it]  1%|          | 5/500 [00:06<06:47,  1.21it/s]  1%|▏         | 7/500 [00:06<04:07,  1.99it/s]  2%|▏         | 9/500 [00:06<02:45,  2.96it/s]  2%|▏         | 11/500 [00:12<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:24,  1.18s/it]  5%|▍         | 23/500 [00:19<06:40,  1.19it/s]  5%|▌         | 25/500 [00:19<04:48,  1.65it/s]  5%|▌         | 27/500 [00:20<03:30,  2.25it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:05,  1.16s/it]  7%|▋         | 33/500 [00:26<06:29,  1.20it/s]  7%|▋         | 35/500 [00:26<04:40,  1.66it/s]  7%|▋         | 37/500 [00:26<03:24,  2.26it/s]  8%|▊         | 39/500 [00:26<02:31,  3.04it/s]  8%|▊         | 41/500 [00:33<08:49,  1.15s/it]  9%|▊         | 43/500 [00:33<06:18,  1.21it/s]  9%|▉         | 45/500 [00:33<04:32,  1.67it/s]  9%|▉         | 47/500 [00:33<03:18,  2.28it/s] 10%|▉         | 49/500 [00:33<02:27,  3.07it/s] 10%|█         | 51/500 [00:39<08:43,  1.17s/it] 11%|█         | 53/500 [00:39<06:14,  1.19it/s] 11%|█         | 55/500 [00:40<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:16,  2.25it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.03it/s] 12%|█▏        | 61/500 [00:46<08:29,  1.16s/it] 13%|█▎        | 63/500 [00:46<06:04,  1.20it/s] 13%|█▎        | 65/500 [00:46<04:22,  1.66it/s] 13%|█▎        | 67/500 [00:46<03:11,  2.27it/s] 14%|█▍        | 69/500 [00:47<02:21,  3.04it/s] 14%|█▍        | 71/500 [00:53<08:16,  1.16s/it]Epoch:  1  	Training Loss: 0.06514871120452881
Test Loss:  13.95853328704834
Valid Loss:  13.855243682861328
Epoch:  2  	Training Loss: 13.701787948608398
Test Loss:  0.08713728189468384
Valid Loss:  0.09091761708259583
Epoch:  3  	Training Loss: 0.08525336533784866
Test Loss:  0.0849565714597702
Valid Loss:  0.08875191956758499
Epoch:  4  	Training Loss: 0.08322027325630188
Test Loss:  0.08283460140228271
Valid Loss:  0.0866444855928421
Epoch:  5  	Training Loss: 0.08124300837516785
Test Loss:  0.08076991885900497
Valid Loss:  0.08459390699863434
Epoch:  6  	Training Loss: 0.07932017743587494
Test Loss:  0.07876115292310715
Valid Loss:  0.08259879797697067
Epoch:  7  	Training Loss: 0.07745043933391571
Test Loss:  0.0768069326877594
Valid Loss:  0.08065780997276306
Epoch:  8  	Training Loss: 0.0756324827671051
Test Loss:  0.07490594685077667
Valid Loss:  0.07876960933208466
Epoch:  9  	Training Loss: 0.07386501133441925
Test Loss:  0.07305686175823212
Valid Loss:  0.07693290710449219
Epoch:  10  	Training Loss: 0.07214675843715668
Test Loss:  0.07126031816005707
Valid Loss:  0.07515520602464676
Epoch:  11  	Training Loss: 0.07048133760690689
Test Loss:  0.06981098651885986
Valid Loss:  0.0737314373254776
Epoch:  12  	Training Loss: 0.06920693814754486
Test Loss:  0.06890459358692169
Valid Loss:  0.0728483721613884
Epoch:  13  	Training Loss: 0.06838612258434296
Test Loss:  0.06804640591144562
Valid Loss:  0.07199874520301819
Epoch:  14  	Training Loss: 0.0675939992070198
Test Loss:  0.06721004098653793
Valid Loss:  0.07116841524839401
Epoch:  15  	Training Loss: 0.06681805849075317
Test Loss:  0.0663931742310524
Valid Loss:  0.0703592523932457
Epoch:  16  	Training Loss: 0.06606290489435196
Test Loss:  0.06586524844169617
Valid Loss:  0.06985139846801758
Epoch:  17  	Training Loss: 0.0656089261174202
Test Loss:  0.06543677300214767
Valid Loss:  0.0694318562746048
Epoch:  18  	Training Loss: 0.06522133946418762
Test Loss:  0.06501606851816177
Valid Loss:  0.0690215677022934
Epoch:  19  	Training Loss: 0.06484029442071915
Test Loss:  0.06478181481361389
Valid Loss:  0.06880562007427216
Epoch:  20  	Training Loss: 0.06467342376708984
Test Loss:  0.06476056575775146
Valid Loss:  0.06879346072673798
Epoch:  21  	Training Loss: 0.06466393917798996
Test Loss:  0.06475192308425903
Valid Loss:  0.06878800690174103
Epoch:  22  	Training Loss: 0.06466009467840195
Test Loss:  0.06474846601486206
Valid Loss:  0.06878542900085449
Epoch:  23  	Training Loss: 0.06465804576873779
Test Loss:  0.06474628299474716
Valid Loss:  0.06878401339054108
Epoch:  24  	Training Loss: 0.0646568164229393
Test Loss:  0.06474480032920837
Valid Loss:  0.06878316402435303
Epoch:  25  	Training Loss: 0.06465578079223633
Test Loss:  0.0647437572479248
Valid Loss:  0.06878253072500229
Epoch:  26  	Training Loss: 0.06465481221675873
Test Loss:  0.06474285572767258
Valid Loss:  0.06878195703029633
Epoch:  27  	Training Loss: 0.06465396285057068
Test Loss:  0.06474214792251587
Valid Loss:  0.06878133863210678
Epoch:  28  	Training Loss: 0.06465315073728561
Test Loss:  0.06474152207374573
Valid Loss:  0.06878072768449783
Epoch:  29  	Training Loss: 0.06465237587690353
Test Loss:  0.06474094092845917
Valid Loss:  0.06878013908863068
Epoch:  30  	Training Loss: 0.06465165317058563
Test Loss:  0.06474055349826813
Valid Loss:  0.06877952069044113
Epoch:  31  	Training Loss: 0.06465095281600952
Test Loss:  0.06474006175994873
Valid Loss:  0.06877891719341278
Epoch:  32  	Training Loss: 0.06465025246143341
Test Loss:  0.06473975628614426
Valid Loss:  0.06877832859754562
Epoch:  33  	Training Loss: 0.0646495670080185
Test Loss:  0.06473952531814575
Valid Loss:  0.06877771764993668
Epoch:  34  	Training Loss: 0.06464889645576477
Test Loss:  0.06473925709724426
Valid Loss:  0.06877714395523071
Epoch:  35  	Training Loss: 0.06464824825525284
Test Loss:  0.06473909318447113
Valid Loss:  0.06877653300762177
Epoch:  36  	Training Loss: 0.0646476000547409
Test Loss:  0.0647389143705368
Valid Loss:  0.06877591460943222
Epoch:  37  	Training Loss: 0.06464692950248718
Test Loss:  0.06473864614963531
Valid Loss:  0.06877534836530685
Epoch:  38  	Training Loss: 0.06464628875255585
Test Loss:  0.06473846733570099
Valid Loss:  0.0687747597694397
Epoch:  39  	Training Loss: 0.06464562565088272
Test Loss:  0.06473830342292786
Valid Loss:  0.06877416372299194
Epoch:  40  	Training Loss: 0.06464497745037079
Test Loss:  0.06473807245492935
Valid Loss:  0.06877359747886658
Epoch:  41  	Training Loss: 0.06464435905218124
Test Loss:  0.0647379457950592
Valid Loss:  0.06877297908067703
Epoch:  42  	Training Loss: 0.0646437257528305
Test Loss:  0.06473782658576965
Valid Loss:  0.0687723457813263
Epoch:  43  	Training Loss: 0.06464308500289917
Test Loss:  0.06473761796951294
Valid Loss:  0.06877176463603973
Epoch:  44  	Training Loss: 0.06464245170354843
Test Loss:  0.06473749876022339
Valid Loss:  0.06877114623785019
Epoch:  45  	Training Loss: 0.0646418035030365
Test Loss:  0.06473739445209503
Valid Loss:  0.06877051293849945
Epoch:  46  	Training Loss: 0.06464117020368576
Test Loss:  0.06473717093467712
Valid Loss:  0.06876993179321289
Epoch:  47  	Training Loss: 0.06464053690433502
Test Loss:  0.06473705917596817
Valid Loss:  0.06876931339502335
Epoch:  48  	Training Loss: 0.06463989615440369
Test Loss:  0.06473694741725922
Valid Loss:  0.0687686949968338
Epoch:  49  	Training Loss: 0.06463926285505295
Test Loss:  0.06473672389984131
Valid Loss:  0.06876811385154724
Epoch:  50  	Training Loss: 0.06463862955570221
Test Loss:  0.06473661214113235
Valid Loss:  0.0687674880027771
Epoch:  51  	Training Loss: 0.06463798880577087
Test Loss:  0.06473648548126221
Valid Loss:  0.06876687705516815
Epoch:  52  	Training Loss: 0.06463735550642014
Test Loss:  0.06473641097545624
Valid Loss:  0.06876629590988159
Epoch:  53  	Training Loss: 0.06463676691055298
Test Loss:  0.0647362470626831
Valid Loss:  0.06876575946807861
Epoch:  54  	Training Loss: 0.06463617086410522
Test Loss:  0.06473616510629654
Valid Loss:  0.06876517832279205
Epoch:  55  	Training Loss: 0.06463557481765747
Test Loss:  0.06473609060049057
Valid Loss:  0.06876461207866669
Epoch:  56  	Training Loss: 0.06463497877120972
Test Loss:  0.0647360235452652
Valid Loss:  0.06876404583454132
Epoch:  57  	Training Loss: 0.06463439762592316
Test Loss:  0.06473584473133087
Valid Loss:  0.06876350939273834
Epoch:  58  	Training Loss: 0.0646338015794754
Test Loss:  0.0647357702255249
Valid Loss:  0.06876292824745178
Epoch:  59  	Training Loss: 0.06463320553302765
Test Loss:  0.06473571062088013
Valid Loss:  0.06876233965158463
Epoch:  60  	Training Loss: 0.0646326094865799
Test Loss:  0.06473564356565475
Valid Loss:  0.06876175850629807
Epoch:  61  	Training Loss: 0.06463202089071274
Test Loss:  0.06473546475172043
Valid Loss:  0.06876122951507568
Epoch:  62  	Training Loss: 0.06463143229484558
Test Loss:  0.06473538279533386
Valid Loss:  0.06876063346862793
Epoch:  63  	Training Loss: 0.06463082134723663
Test Loss:  0.0647353082895279
Valid Loss:  0.06876002997159958
Epoch:  64  	Training Loss: 0.06463021039962769
Test Loss:  0.06473521888256073
Valid Loss:  0.06875944882631302
Epoch:  65  	Training Loss: 0.06462959945201874
Test Loss:  0.06473518162965775
Valid Loss:  0.06875881552696228
Epoch:  66  	Training Loss: 0.06462900340557098
Test Loss:  0.06473502516746521
Valid Loss:  0.06875823438167572
Epoch:  67  	Training Loss: 0.06462839990854263
Test Loss:  0.06473493576049805
Valid Loss:  0.06875763088464737
Epoch:  68  	Training Loss: 0.06462778896093369
Test Loss:  0.06473487615585327
Valid Loss:  0.06875701248645782
Epoch:  69  	Training Loss: 0.06462718546390533
Test Loss:  0.06473483145236969
Valid Loss:  0.06875638663768768
Epoch:  70  	Training Loss: 0.06462658196687698
Test Loss:  0.06473477184772491
Valid Loss:  0.06875576823949814
Epoch:  71  	Training Loss: 0.06462597846984863
Test Loss:  0.06473468244075775
Valid Loss:  0.06875517964363098
Epoch:  72  	Training Loss: 0.06462537497282028
Test Loss:  0.06473450362682343
Valid Loss:  0.06875459104776382
Epoch:  73  	Training Loss: 0.06462477147579193
Test Loss:  0.06473445892333984
Valid Loss:   15%|█▍        | 73/500 [00:53<05:54,  1.20it/s] 15%|█▌        | 75/500 [00:53<04:15,  1.66it/s] 15%|█▌        | 77/500 [00:53<03:06,  2.27it/s] 16%|█▌        | 79/500 [00:53<02:18,  3.04it/s] 16%|█▌        | 81/500 [01:00<08:12,  1.18s/it] 17%|█▋        | 83/500 [01:00<05:51,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:00<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:00<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:06<07:54,  1.16s/it] 19%|█▊        | 93/500 [01:06<05:38,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:04,  1.66it/s] 19%|█▉        | 97/500 [01:07<02:57,  2.27it/s] 20%|█▉        | 99/500 [01:07<02:11,  3.05it/s] 20%|██        | 101/500 [01:13<07:50,  1.18s/it] 21%|██        | 103/500 [01:13<05:35,  1.18it/s] 21%|██        | 105/500 [01:13<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:14<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:20<07:44,  1.19s/it] 23%|██▎       | 113/500 [01:20<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:20<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:21<02:55,  2.19it/s] 24%|██▍       | 119/500 [01:21<02:09,  2.94it/s] 24%|██▍       | 121/500 [01:27<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:27<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:27<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:27<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:28<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:34<07:17,  1.19s/it] 27%|██▋       | 133/500 [01:34<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:34<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:34<02:44,  2.21it/s] 28%|██▊       | 139/500 [01:34<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:41<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:41<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:41<03:36,  1.64it/s]0.06875394284725189
Epoch:  74  	Training Loss: 0.06462416052818298
Test Loss:  0.06473435461521149
Valid Loss:  0.06875337660312653
Epoch:  75  	Training Loss: 0.06462355703115463
Test Loss:  0.06473429501056671
Valid Loss:  0.06875275075435638
Epoch:  76  	Training Loss: 0.06462295353412628
Test Loss:  0.06473422050476074
Valid Loss:  0.06875212490558624
Epoch:  77  	Training Loss: 0.06462235003709793
Test Loss:  0.06473416090011597
Valid Loss:  0.0687514990568161
Epoch:  78  	Training Loss: 0.06462173908948898
Test Loss:  0.06473404914140701
Valid Loss:  0.06875091791152954
Epoch:  79  	Training Loss: 0.06462113559246063
Test Loss:  0.06473398953676224
Valid Loss:  0.0687502920627594
Epoch:  80  	Training Loss: 0.06462053209543228
Test Loss:  0.06473380327224731
Valid Loss:  0.06874971091747284
Epoch:  81  	Training Loss: 0.06461992859840393
Test Loss:  0.06473374366760254
Valid Loss:  0.0687490776181221
Epoch:  82  	Training Loss: 0.06461931765079498
Test Loss:  0.06473363935947418
Valid Loss:  0.06874851882457733
Epoch:  83  	Training Loss: 0.06461872160434723
Test Loss:  0.06473356485366821
Valid Loss:  0.06874790787696838
Epoch:  84  	Training Loss: 0.06461812555789948
Test Loss:  0.06473350524902344
Valid Loss:  0.06874729692935944
Epoch:  85  	Training Loss: 0.06461753696203232
Test Loss:  0.06473343819379807
Valid Loss:  0.06874669343233109
Epoch:  86  	Training Loss: 0.06461694091558456
Test Loss:  0.06473333388566971
Valid Loss:  0.06874610483646393
Epoch:  87  	Training Loss: 0.06461634486913681
Test Loss:  0.06473325937986374
Valid Loss:  0.06874550879001617
Epoch:  88  	Training Loss: 0.06461575627326965
Test Loss:  0.06473319232463837
Valid Loss:  0.06874491274356842
Epoch:  89  	Training Loss: 0.0646151602268219
Test Loss:  0.0647331178188324
Valid Loss:  0.06874428689479828
Epoch:  90  	Training Loss: 0.06461456418037415
Test Loss:  0.06473304331302643
Valid Loss:  0.06874369829893112
Epoch:  91  	Training Loss: 0.06461396813392639
Test Loss:  0.06473294645547867
Valid Loss:  0.06874311715364456
Epoch:  92  	Training Loss: 0.06461337953805923
Test Loss:  0.0647328644990921
Valid Loss:  0.0687425285577774
Epoch:  93  	Training Loss: 0.06461279094219208
Test Loss:  0.06473280489444733
Valid Loss:  0.06874190270900726
Epoch:  94  	Training Loss: 0.06461219489574432
Test Loss:  0.06473272293806076
Valid Loss:  0.0687413141131401
Epoch:  95  	Training Loss: 0.06461159884929657
Test Loss:  0.0647326409816742
Valid Loss:  0.06874071061611176
Epoch:  96  	Training Loss: 0.06461100280284882
Test Loss:  0.06473253667354584
Valid Loss:  0.06874014437198639
Epoch:  97  	Training Loss: 0.06461042165756226
Test Loss:  0.06473246216773987
Valid Loss:  0.06873954832553864
Epoch:  98  	Training Loss: 0.0646098256111145
Test Loss:  0.0647323876619339
Valid Loss:  0.06873893737792969
Epoch:  99  	Training Loss: 0.06460924446582794
Test Loss:  0.06473230570554733
Valid Loss:  0.06873834133148193
Epoch:  100  	Training Loss: 0.06460864841938019
Test Loss:  0.06473222374916077
Valid Loss:  0.06873776018619537
Epoch:  101  	Training Loss: 0.06460805982351303
Test Loss:  0.0647321492433548
Valid Loss:  0.06873714923858643
Epoch:  102  	Training Loss: 0.06460747122764587
Test Loss:  0.06473207473754883
Valid Loss:  0.06873657554388046
Epoch:  103  	Training Loss: 0.06460689008235931
Test Loss:  0.06473197042942047
Valid Loss:  0.0687360167503357
Epoch:  104  	Training Loss: 0.06460632383823395
Test Loss:  0.0647318959236145
Valid Loss:  0.06873543560504913
Epoch:  105  	Training Loss: 0.06460574269294739
Test Loss:  0.06473181396722794
Valid Loss:  0.06873486936092377
Epoch:  106  	Training Loss: 0.06460516154766083
Test Loss:  0.06473173946142197
Valid Loss:  0.06873426586389542
Epoch:  107  	Training Loss: 0.06460459530353546
Test Loss:  0.0647316575050354
Valid Loss:  0.06873369961977005
Epoch:  108  	Training Loss: 0.0646040141582489
Test Loss:  0.06473159790039062
Valid Loss:  0.0687331110239029
Epoch:  109  	Training Loss: 0.06460344791412354
Test Loss:  0.06473150849342346
Valid Loss:  0.06873252987861633
Epoch:  110  	Training Loss: 0.06460286676883698
Test Loss:  0.06473143398761749
Valid Loss:  0.06873196363449097
Epoch:  111  	Training Loss: 0.06460230052471161
Test Loss:  0.06473135948181152
Valid Loss:  0.06873137503862381
Epoch:  112  	Training Loss: 0.06460171937942505
Test Loss:  0.06473125517368317
Valid Loss:  0.06873077154159546
Epoch:  113  	Training Loss: 0.0646011233329773
Test Loss:  0.06473114341497421
Valid Loss:  0.0687301829457283
Epoch:  114  	Training Loss: 0.06460052728652954
Test Loss:  0.06473101675510406
Valid Loss:  0.06872960925102234
Epoch:  115  	Training Loss: 0.06459993124008179
Test Loss:  0.06473089754581451
Valid Loss:  0.06872900575399399
Epoch:  116  	Training Loss: 0.06459932029247284
Test Loss:  0.06473077833652496
Valid Loss:  0.06872841715812683
Epoch:  117  	Training Loss: 0.06459872424602509
Test Loss:  0.0647306814789772
Valid Loss:  0.06872780621051788
Epoch:  118  	Training Loss: 0.06459812819957733
Test Loss:  0.06473056972026825
Valid Loss:  0.06872720271348953
Epoch:  119  	Training Loss: 0.06459753215312958
Test Loss:  0.0647304505109787
Valid Loss:  0.06872661411762238
Epoch:  120  	Training Loss: 0.06459693610668182
Test Loss:  0.06473034620285034
Valid Loss:  0.06872598826885223
Epoch:  121  	Training Loss: 0.06459633260965347
Test Loss:  0.06473022699356079
Valid Loss:  0.06872540712356567
Epoch:  122  	Training Loss: 0.06459573656320572
Test Loss:  0.06473015248775482
Valid Loss:  0.06872481852769852
Epoch:  123  	Training Loss: 0.06459516286849976
Test Loss:  0.06473006308078766
Valid Loss:  0.06872424483299255
Epoch:  124  	Training Loss: 0.06459459662437439
Test Loss:  0.0647299736738205
Valid Loss:  0.06872367858886719
Epoch:  125  	Training Loss: 0.06459401547908783
Test Loss:  0.06472987681627274
Valid Loss:  0.06872311979532242
Epoch:  126  	Training Loss: 0.06459344923496246
Test Loss:  0.06472979485988617
Valid Loss:  0.06872253119945526
Epoch:  127  	Training Loss: 0.0645928755402565
Test Loss:  0.064729705452919
Valid Loss:  0.06872197985649109
Epoch:  128  	Training Loss: 0.06459230184555054
Test Loss:  0.06472960859537125
Valid Loss:  0.06872141361236572
Epoch:  129  	Training Loss: 0.06459173560142517
Test Loss:  0.06472951173782349
Valid Loss:  0.06872086226940155
Epoch:  130  	Training Loss: 0.0645911693572998
Test Loss:  0.06472943723201752
Valid Loss:  0.0687202736735344
Epoch:  131  	Training Loss: 0.06459058821201324
Test Loss:  0.06472934037446976
Valid Loss:  0.06871971487998962
Epoch:  132  	Training Loss: 0.06459002196788788
Test Loss:  0.0647292286157608
Valid Loss:  0.06871915608644485
Epoch:  133  	Training Loss: 0.06458945572376251
Test Loss:  0.06472914665937424
Valid Loss:  0.0687185749411583
Epoch:  134  	Training Loss: 0.06458888947963715
Test Loss:  0.06472904980182648
Valid Loss:  0.06871801614761353
Epoch:  135  	Training Loss: 0.06458832323551178
Test Loss:  0.06472894549369812
Valid Loss:  0.06871746480464935
Epoch:  136  	Training Loss: 0.06458776444196701
Test Loss:  0.06472884118556976
Valid Loss:  0.06871691346168518
Epoch:  137  	Training Loss: 0.06458719074726105
Test Loss:  0.064728744328022
Valid Loss:  0.06871636211872101
Epoch:  138  	Training Loss: 0.06458663195371628
Test Loss:  0.06472864747047424
Valid Loss:  0.06871578097343445
Epoch:  139  	Training Loss: 0.06458606570959091
Test Loss:  0.06472854316234589
Valid Loss:  0.06871522963047028
Epoch:  140  	Training Loss: 0.06458549946546555
Test Loss:  0.06472843885421753
Valid Loss:  0.0687146782875061
Epoch:  141  	Training Loss: 0.06458494067192078
Test Loss:  0.06472834199666977
Valid Loss:  0.06871412694454193
Epoch:  142  	Training Loss: 0.06458438187837601
Test Loss:  0.06472820788621902
Valid Loss:  0.06871352344751358
Epoch:  143  	Training Loss: 0.06458377838134766
Test Loss:  0.06472811102867126
Valid Loss:  0.06871290504932404
Epoch:  144  	Training Loss: 0.0645831823348999
Test Loss:  0.06472797691822052
Valid Loss:  0.06871232390403748
Epoch:  145  	Training Loss: 0.06458258628845215
Test Loss:  0.06472782790660858
Valid Loss:  0.06871174275875092
 29%|██▉       | 147/500 [01:41<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:41<01:56,  3.01it/s] 30%|███       | 151/500 [01:48<06:50,  1.18s/it] 31%|███       | 153/500 [01:48<04:52,  1.18it/s] 31%|███       | 155/500 [01:48<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:48<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:48<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:54<06:33,  1.16s/it] 33%|███▎      | 163/500 [01:54<04:40,  1.20it/s] 33%|███▎      | 165/500 [01:55<03:21,  1.66it/s] 33%|███▎      | 167/500 [01:55<02:26,  2.27it/s] 34%|███▍      | 169/500 [01:55<01:48,  3.04it/s] 34%|███▍      | 171/500 [02:01<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:01<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:01<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:01<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:08<06:12,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:08<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:08<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:08<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:15<05:58,  1.16s/it] 39%|███▊      | 193/500 [02:15<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:15<03:03,  1.66it/s] 39%|███▉      | 197/500 [02:15<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:15<01:39,  3.04it/s] 40%|████      | 201/500 [02:21<05:49,  1.17s/it] 41%|████      | 203/500 [02:22<04:09,  1.19it/s] 41%|████      | 205/500 [02:22<02:59,  1.65it/s] 41%|████▏     | 207/500 [02:22<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.03it/s] 42%|████▏     | 211/500 [02:28<05:32,  1.15s/it] 43%|████▎     | 213/500 [02:28<03:57,  1.21it/s] 43%|████▎     | 215/500 [02:28<02:51,  1.67it/s] 43%|████▎     | 217/500 [02:28<02:04,  2.28it/s]Epoch:  146  	Training Loss: 0.0645819827914238
Test Loss:  0.06472768634557724
Valid Loss:  0.06871116161346436
Epoch:  147  	Training Loss: 0.06458137929439545
Test Loss:  0.0647275447845459
Valid Loss:  0.0687105804681778
Epoch:  148  	Training Loss: 0.06458078324794769
Test Loss:  0.06472741067409515
Valid Loss:  0.06871001422405243
Epoch:  149  	Training Loss: 0.06458018720149994
Test Loss:  0.06472727656364441
Valid Loss:  0.06870941817760468
Epoch:  150  	Training Loss: 0.06457959115505219
Test Loss:  0.06472712010145187
Valid Loss:  0.06870885193347931
Epoch:  151  	Training Loss: 0.06457898020744324
Test Loss:  0.06472703069448471
Valid Loss:  0.06870824843645096
Epoch:  152  	Training Loss: 0.06457839906215668
Test Loss:  0.06472692638635635
Valid Loss:  0.06870770454406738
Epoch:  153  	Training Loss: 0.06457782536745071
Test Loss:  0.0647268295288086
Valid Loss:  0.0687071681022644
Epoch:  154  	Training Loss: 0.06457726657390594
Test Loss:  0.06472672522068024
Valid Loss:  0.06870662420988083
Epoch:  155  	Training Loss: 0.06457670032978058
Test Loss:  0.06472662091255188
Valid Loss:  0.06870608776807785
Epoch:  156  	Training Loss: 0.06457613408565521
Test Loss:  0.0647265613079071
Valid Loss:  0.06870551407337189
Epoch:  157  	Training Loss: 0.06457557529211044
Test Loss:  0.06472645699977875
Valid Loss:  0.06870497763156891
Epoch:  158  	Training Loss: 0.06457501649856567
Test Loss:  0.0647263452410698
Valid Loss:  0.06870444118976593
Epoch:  159  	Training Loss: 0.06457445025444031
Test Loss:  0.06472624093294144
Valid Loss:  0.06870390474796295
Epoch:  160  	Training Loss: 0.06457388401031494
Test Loss:  0.06472615897655487
Valid Loss:  0.06870335340499878
Epoch:  161  	Training Loss: 0.06457332521677017
Test Loss:  0.0647260919213295
Valid Loss:  0.06870277971029282
Epoch:  162  	Training Loss: 0.0645727664232254
Test Loss:  0.06472598016262054
Valid Loss:  0.06870224326848984
Epoch:  163  	Training Loss: 0.06457220017910004
Test Loss:  0.064725860953331
Valid Loss:  0.06870169937610626
Epoch:  164  	Training Loss: 0.06457163393497467
Test Loss:  0.06472574919462204
Valid Loss:  0.06870116293430328
Epoch:  165  	Training Loss: 0.0645710676908493
Test Loss:  0.06472567468881607
Valid Loss:  0.06870059669017792
Epoch:  166  	Training Loss: 0.06457049399614334
Test Loss:  0.06472556293010712
Valid Loss:  0.06870006024837494
Epoch:  167  	Training Loss: 0.06456993520259857
Test Loss:  0.06472544372081757
Valid Loss:  0.06869951635599136
Epoch:  168  	Training Loss: 0.0645693689584732
Test Loss:  0.06472532451152802
Valid Loss:  0.06869898736476898
Epoch:  169  	Training Loss: 0.06456879526376724
Test Loss:  0.06472525000572205
Valid Loss:  0.06869840621948242
Epoch:  170  	Training Loss: 0.06456823647022247
Test Loss:  0.0647251307964325
Valid Loss:  0.06869788467884064
Epoch:  171  	Training Loss: 0.0645676702260971
Test Loss:  0.06472501158714294
Valid Loss:  0.06869734823703766
Epoch:  172  	Training Loss: 0.06456710398197174
Test Loss:  0.06472492218017578
Valid Loss:  0.0686967670917511
Epoch:  173  	Training Loss: 0.06456653028726578
Test Loss:  0.06472478806972504
Valid Loss:  0.06869621574878693
Epoch:  174  	Training Loss: 0.06456594169139862
Test Loss:  0.0647246465086937
Valid Loss:  0.06869567185640335
Epoch:  175  	Training Loss: 0.06456536054611206
Test Loss:  0.06472456455230713
Valid Loss:  0.06869509816169739
Epoch:  176  	Training Loss: 0.0645647943019867
Test Loss:  0.06472441554069519
Valid Loss:  0.06869453191757202
Epoch:  177  	Training Loss: 0.06456420570611954
Test Loss:  0.06472428888082504
Valid Loss:  0.06869398057460785
Epoch:  178  	Training Loss: 0.06456363201141357
Test Loss:  0.06472419202327728
Valid Loss:  0.06869340687990189
Epoch:  179  	Training Loss: 0.06456305086612701
Test Loss:  0.06472405791282654
Valid Loss:  0.06869286298751831
Epoch:  180  	Training Loss: 0.06456247717142105
Test Loss:  0.0647239089012146
Valid Loss:  0.06869232654571533
Epoch:  181  	Training Loss: 0.06456190347671509
Test Loss:  0.06472381204366684
Valid Loss:  0.06869173794984818
Epoch:  182  	Training Loss: 0.06456131488084793
Test Loss:  0.06472370028495789
Valid Loss:  0.06869122385978699
Epoch:  183  	Training Loss: 0.06456076353788376
Test Loss:  0.06472359597682953
Valid Loss:  0.0686907097697258
Epoch:  184  	Training Loss: 0.06456021964550018
Test Loss:  0.06472352892160416
Valid Loss:  0.06869016587734222
Epoch:  185  	Training Loss: 0.06455966830253601
Test Loss:  0.0647234246134758
Valid Loss:  0.06868965178728104
Epoch:  186  	Training Loss: 0.06455911695957184
Test Loss:  0.06472335755825043
Valid Loss:  0.06868910789489746
Epoch:  187  	Training Loss: 0.06455856561660767
Test Loss:  0.06472324579954147
Valid Loss:  0.06868860125541687
Epoch:  188  	Training Loss: 0.0645580142736435
Test Loss:  0.06472313404083252
Valid Loss:  0.06868807971477509
Epoch:  189  	Training Loss: 0.06455747038125992
Test Loss:  0.06472305953502655
Valid Loss:  0.0686875432729721
Epoch:  190  	Training Loss: 0.06455692648887634
Test Loss:  0.064722940325737
Valid Loss:  0.06868703663349152
Epoch:  191  	Training Loss: 0.06455637514591217
Test Loss:  0.06472287327051163
Valid Loss:  0.06868650764226913
Epoch:  192  	Training Loss: 0.064555823802948
Test Loss:  0.06472274661064148
Valid Loss:  0.06868600845336914
Epoch:  193  	Training Loss: 0.06455527245998383
Test Loss:  0.06472267210483551
Valid Loss:  0.06868546456098557
Epoch:  194  	Training Loss: 0.06455471366643906
Test Loss:  0.06472253799438477
Valid Loss:  0.06868496537208557
Epoch:  195  	Training Loss: 0.06455415487289429
Test Loss:  0.0647224709391594
Valid Loss:  0.06868442893028259
Epoch:  196  	Training Loss: 0.06455360352993011
Test Loss:  0.06472233682870865
Valid Loss:  0.0686839297413826
Epoch:  197  	Training Loss: 0.06455305218696594
Test Loss:  0.06472232937812805
Valid Loss:  0.06868331879377365
Epoch:  198  	Training Loss: 0.06455250084400177
Test Loss:  0.06472228467464447
Valid Loss:  0.06868276000022888
Epoch:  199  	Training Loss: 0.0645519495010376
Test Loss:  0.0647222101688385
Valid Loss:  0.0686822235584259
Epoch:  200  	Training Loss: 0.06455139815807343
Test Loss:  0.06472215801477432
Valid Loss:  0.06868165731430054
Epoch:  201  	Training Loss: 0.06455085426568985
Test Loss:  0.06472206860780716
Valid Loss:  0.06868113577365875
Epoch:  202  	Training Loss: 0.06455030292272568
Test Loss:  0.06472200900316238
Valid Loss:  0.06868056952953339
Epoch:  203  	Training Loss: 0.0645497515797615
Test Loss:  0.06472191214561462
Valid Loss:  0.06868003308773041
Epoch:  204  	Training Loss: 0.06454919278621674
Test Loss:  0.06472186744213104
Valid Loss:  0.06867947429418564
Epoch:  205  	Training Loss: 0.06454864144325256
Test Loss:  0.06472184509038925
Valid Loss:  0.0686788558959961
Epoch:  206  	Training Loss: 0.06454809010028839
Test Loss:  0.06472171097993851
Valid Loss:  0.06867837905883789
Epoch:  207  	Training Loss: 0.06454753875732422
Test Loss:  0.06472168117761612
Valid Loss:  0.06867776811122894
Epoch:  208  	Training Loss: 0.06454698741436005
Test Loss:  0.06472161412239075
Valid Loss:  0.06867721676826477
Epoch:  209  	Training Loss: 0.06454643607139587
Test Loss:  0.06472152471542358
Valid Loss:  0.06867669522762299
Epoch:  210  	Training Loss: 0.0645458772778511
Test Loss:  0.0647214949131012
Valid Loss:  0.06867608428001404
Epoch:  211  	Training Loss: 0.06454532593488693
Test Loss:  0.06472136080265045
Valid Loss:  0.06867560744285583
Epoch:  212  	Training Loss: 0.06454478204250336
Test Loss:  0.06472130119800568
Valid Loss:  0.0686749815940857
Epoch:  213  	Training Loss: 0.0645442008972168
Test Loss:  0.06472121924161911
Valid Loss:  0.06867440044879913
Epoch:  214  	Training Loss: 0.06454362720251083
Test Loss:  0.06472116708755493
Valid Loss:  0.06867378950119019
Epoch:  215  	Training Loss: 0.06454305350780487
Test Loss:  0.06472104042768478
Valid Loss:  0.06867323815822601
Epoch:  216  	Training Loss: 0.06454247981309891
Test Loss:  0.06472093611955643
Valid Loss:  0.06867264956235886
Epoch:  217  	Training Loss: 0.06454189866781235
Test Loss:  0.06472088396549225
Valid Loss:  0.06867203861474991
 44%|████▍     | 219/500 [02:29<01:31,  3.06it/s] 44%|████▍     | 221/500 [02:35<05:23,  1.16s/it] 45%|████▍     | 223/500 [02:35<03:50,  1.20it/s] 45%|████▌     | 225/500 [02:35<02:45,  1.66it/s] 45%|████▌     | 227/500 [02:35<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:35<01:29,  3.04it/s] 46%|████▌     | 231/500 [02:42<05:13,  1.16s/it] 47%|████▋     | 233/500 [02:42<03:43,  1.20it/s] 47%|████▋     | 235/500 [02:42<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:42<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:42<01:26,  3.03it/s] 48%|████▊     | 241/500 [02:48<05:00,  1.16s/it] 49%|████▊     | 243/500 [02:48<03:34,  1.20it/s] 49%|████▉     | 245/500 [02:49<02:33,  1.66it/s] 49%|████▉     | 247/500 [02:49<01:51,  2.26it/s] 50%|████▉     | 249/500 [02:49<01:22,  3.04it/s] 50%|█████     | 251/500 [02:55<04:49,  1.16s/it] 51%|█████     | 253/500 [02:55<03:26,  1.20it/s] 51%|█████     | 255/500 [02:55<02:28,  1.65it/s] 51%|█████▏    | 257/500 [02:55<01:47,  2.26it/s] 52%|█████▏    | 259/500 [02:56<01:19,  3.03it/s] 52%|█████▏    | 261/500 [03:02<04:36,  1.16s/it] 53%|█████▎    | 263/500 [03:02<03:17,  1.20it/s] 53%|█████▎    | 265/500 [03:02<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:02<01:42,  2.27it/s] 54%|█████▍    | 269/500 [03:02<01:15,  3.05it/s] 54%|█████▍    | 271/500 [03:08<04:24,  1.15s/it] 55%|█████▍    | 273/500 [03:09<03:07,  1.21it/s] 55%|█████▌    | 275/500 [03:09<02:14,  1.67it/s] 55%|█████▌    | 277/500 [03:09<01:37,  2.28it/s] 56%|█████▌    | 279/500 [03:09<01:12,  3.06it/s] 56%|█████▌    | 281/500 [03:15<04:11,  1.15s/it] 57%|█████▋    | 283/500 [03:15<02:58,  1.21it/s] 57%|█████▋    | 285/500 [03:15<02:08,  1.68it/s] 57%|█████▋    | 287/500 [03:15<01:32,  2.29it/s] 58%|█████▊    | 289/500 [03:16<01:08,  3.07it/s]Epoch:  218  	Training Loss: 0.06454132497310638
Test Loss:  0.0647207498550415
Valid Loss:  0.06867150217294693
Epoch:  219  	Training Loss: 0.06454074382781982
Test Loss:  0.06472065299749374
Valid Loss:  0.06867092847824097
Epoch:  220  	Training Loss: 0.06454017758369446
Test Loss:  0.06472059339284897
Valid Loss:  0.06867031753063202
Epoch:  221  	Training Loss: 0.0645395964384079
Test Loss:  0.06472046673297882
Valid Loss:  0.06866978108882904
Epoch:  222  	Training Loss: 0.06453903019428253
Test Loss:  0.06472038477659225
Valid Loss:  0.06866922974586487
Epoch:  223  	Training Loss: 0.06453847885131836
Test Loss:  0.06472036242485046
Valid Loss:  0.0686686635017395
Epoch:  224  	Training Loss: 0.06453794240951538
Test Loss:  0.06472032517194748
Valid Loss:  0.06866807490587234
Epoch:  225  	Training Loss: 0.06453739106655121
Test Loss:  0.06472016870975494
Valid Loss:  0.06866760551929474
Epoch:  226  	Training Loss: 0.06453683972358704
Test Loss:  0.06472013890743256
Valid Loss:  0.06866703182458878
Epoch:  227  	Training Loss: 0.06453629583120346
Test Loss:  0.06472010165452957
Valid Loss:  0.06866646558046341
Epoch:  228  	Training Loss: 0.06453575193881989
Test Loss:  0.064720019698143
Valid Loss:  0.06866592913866043
Epoch:  229  	Training Loss: 0.06453520804643631
Test Loss:  0.06471990048885345
Valid Loss:  0.06866542249917984
Epoch:  230  	Training Loss: 0.06453466415405273
Test Loss:  0.06471987068653107
Valid Loss:  0.06866484880447388
Epoch:  231  	Training Loss: 0.06453411281108856
Test Loss:  0.06471982598304749
Valid Loss:  0.06866428256034851
Epoch:  232  	Training Loss: 0.06453357636928558
Test Loss:  0.06471972167491913
Valid Loss:  0.06866372376680374
Epoch:  233  	Training Loss: 0.06453300267457962
Test Loss:  0.06471966207027435
Valid Loss:  0.06866312026977539
Epoch:  234  	Training Loss: 0.06453242152929306
Test Loss:  0.06471958756446838
Valid Loss:  0.06866252422332764
Epoch:  235  	Training Loss: 0.0645318478345871
Test Loss:  0.06471945345401764
Valid Loss:  0.06866200268268585
Epoch:  236  	Training Loss: 0.06453128159046173
Test Loss:  0.06471933424472809
Valid Loss:  0.06866143643856049
Epoch:  237  	Training Loss: 0.06453070044517517
Test Loss:  0.06471927464008331
Valid Loss:  0.06866084039211273
Epoch:  238  	Training Loss: 0.0645301342010498
Test Loss:  0.06471920758485794
Valid Loss:  0.06866025924682617
Epoch:  239  	Training Loss: 0.06452956050634384
Test Loss:  0.06471913307905197
Valid Loss:  0.06865965574979782
Epoch:  240  	Training Loss: 0.06452898681163788
Test Loss:  0.0647190511226654
Valid Loss:  0.06865906715393066
Epoch:  241  	Training Loss: 0.06452842056751251
Test Loss:  0.06471887975931168
Valid Loss:  0.06865859031677246
Epoch:  242  	Training Loss: 0.06452785432338715
Test Loss:  0.0647188201546669
Valid Loss:  0.0686580240726471
Epoch:  243  	Training Loss: 0.06452730298042297
Test Loss:  0.06471875309944153
Valid Loss:  0.06865745782852173
Epoch:  244  	Training Loss: 0.0645267516374588
Test Loss:  0.06471870094537735
Valid Loss:  0.06865689158439636
Epoch:  245  	Training Loss: 0.06452620029449463
Test Loss:  0.06471863389015198
Valid Loss:  0.0686563178896904
Epoch:  246  	Training Loss: 0.06452564895153046
Test Loss:  0.06471854448318481
Valid Loss:  0.06865578889846802
Epoch:  247  	Training Loss: 0.06452510505914688
Test Loss:  0.06471848487854004
Valid Loss:  0.06865523755550385
Epoch:  248  	Training Loss: 0.06452455371618271
Test Loss:  0.06471841037273407
Valid Loss:  0.06865467131137848
Epoch:  249  	Training Loss: 0.06452400237321854
Test Loss:  0.0647183507680893
Valid Loss:  0.06865410506725311
Epoch:  250  	Training Loss: 0.06452345848083496
Test Loss:  0.06471828371286392
Valid Loss:  0.06865354627370834
Epoch:  251  	Training Loss: 0.06452290713787079
Test Loss:  0.06471814215183258
Valid Loss:  0.06865306198596954
Epoch:  252  	Training Loss: 0.06452236324548721
Test Loss:  0.06471807509660721
Valid Loss:  0.06865249574184418
Epoch:  253  	Training Loss: 0.06452181190252304
Test Loss:  0.06471800804138184
Valid Loss:  0.06865193694829941
Epoch:  254  	Training Loss: 0.06452126055955887
Test Loss:  0.06471788883209229
Valid Loss:  0.06865141540765762
Epoch:  255  	Training Loss: 0.0645207092165947
Test Loss:  0.06471781432628632
Valid Loss:  0.06865085661411285
Epoch:  256  	Training Loss: 0.06452015787363052
Test Loss:  0.06471774727106094
Valid Loss:  0.06865029782056808
Epoch:  257  	Training Loss: 0.06451960653066635
Test Loss:  0.06471767276525497
Valid Loss:  0.06864973902702332
Epoch:  258  	Training Loss: 0.06451905518770218
Test Loss:  0.064717598259449
Valid Loss:  0.06864918768405914
Epoch:  259  	Training Loss: 0.064518503844738
Test Loss:  0.06471751630306244
Valid Loss:  0.06864862889051437
Epoch:  260  	Training Loss: 0.06451794505119324
Test Loss:  0.06471744179725647
Valid Loss:  0.0686480700969696
Epoch:  261  	Training Loss: 0.06451740115880966
Test Loss:  0.0647173672914505
Valid Loss:  0.06864753365516663
Epoch:  262  	Training Loss: 0.06451684981584549
Test Loss:  0.06471728533506393
Valid Loss:  0.06864698231220245
Epoch:  263  	Training Loss: 0.06451631337404251
Test Loss:  0.06471721082925797
Valid Loss:  0.06864643096923828
Epoch:  264  	Training Loss: 0.06451576948165894
Test Loss:  0.0647171288728714
Valid Loss:  0.0686458945274353
Epoch:  265  	Training Loss: 0.06451523303985596
Test Loss:  0.06471704691648483
Valid Loss:  0.06864535808563232
Epoch:  266  	Training Loss: 0.06451468169689178
Test Loss:  0.06471696496009827
Valid Loss:  0.06864480674266815
Epoch:  267  	Training Loss: 0.0645141452550888
Test Loss:  0.0647168904542923
Valid Loss:  0.06864427030086517
Epoch:  268  	Training Loss: 0.06451360136270523
Test Loss:  0.06471680104732513
Valid Loss:  0.0686437338590622
Epoch:  269  	Training Loss: 0.06451305747032166
Test Loss:  0.06471671909093857
Valid Loss:  0.06864319741725922
Epoch:  270  	Training Loss: 0.06451252102851868
Test Loss:  0.064716637134552
Valid Loss:  0.06864265352487564
Epoch:  271  	Training Loss: 0.0645119771361351
Test Loss:  0.06471654772758484
Valid Loss:  0.06864212453365326
Epoch:  272  	Training Loss: 0.06451143324375153
Test Loss:  0.06471645832061768
Valid Loss:  0.06864156574010849
Epoch:  273  	Training Loss: 0.06451088190078735
Test Loss:  0.06471635401248932
Valid Loss:  0.06864102184772491
Epoch:  274  	Training Loss: 0.06451032310724258
Test Loss:  0.06471625715494156
Valid Loss:  0.06864047050476074
Epoch:  275  	Training Loss: 0.06450976431369781
Test Loss:  0.0647161602973938
Valid Loss:  0.06863991916179657
Epoch:  276  	Training Loss: 0.06450921297073364
Test Loss:  0.06471605598926544
Valid Loss:  0.0686393678188324
Epoch:  277  	Training Loss: 0.06450864672660828
Test Loss:  0.06471595168113708
Valid Loss:  0.06863881647586823
Epoch:  278  	Training Loss: 0.06450808793306351
Test Loss:  0.0647159293293953
Valid Loss:  0.06863820552825928
Epoch:  279  	Training Loss: 0.06450753659009933
Test Loss:  0.06471583247184753
Valid Loss:  0.0686376690864563
Epoch:  280  	Training Loss: 0.06450698524713516
Test Loss:  0.06471572816371918
Valid Loss:  0.06863711774349213
Epoch:  281  	Training Loss: 0.06450643390417099
Test Loss:  0.06471562385559082
Valid Loss:  0.06863658130168915
Epoch:  282  	Training Loss: 0.06450587511062622
Test Loss:  0.06471554934978485
Valid Loss:  0.06863605976104736
Epoch:  283  	Training Loss: 0.06450535356998444
Test Loss:  0.06471546739339828
Valid Loss:  0.06863555312156677
Epoch:  284  	Training Loss: 0.06450481712818146
Test Loss:  0.06471538543701172
Valid Loss:  0.06863503903150558
Epoch:  285  	Training Loss: 0.06450429558753967
Test Loss:  0.06471538543701172
Valid Loss:  0.06863445043563843
Epoch:  286  	Training Loss: 0.0645037591457367
Test Loss:  0.06471529603004456
Valid Loss:  0.06863393634557724
Epoch:  287  	Training Loss: 0.06450323760509491
Test Loss:  0.06471522152423859
Valid Loss:  0.06863342225551605
Epoch:  288  	Training Loss: 0.06450270861387253
Test Loss:  0.06471513211727142
Valid Loss:  0.06863291561603546
Epoch:  289  	Training Loss: 0.06450217217206955
Test Loss:  0.06471504271030426
Valid Loss:  0.06863240897655487
 58%|█████▊    | 291/500 [03:22<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:22<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:22<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:22<01:30,  2.23it/s] 60%|█████▉    | 299/500 [03:22<01:06,  3.00it/s] 60%|██████    | 301/500 [03:29<03:50,  1.16s/it] 61%|██████    | 303/500 [03:29<02:44,  1.20it/s] 61%|██████    | 305/500 [03:29<01:57,  1.66it/s] 61%|██████▏   | 307/500 [03:29<01:25,  2.26it/s] 62%|██████▏   | 309/500 [03:29<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:35<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:36<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:36<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:36<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:36<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:42<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:42<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:43<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:43<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:43<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:49<03:15,  1.15s/it] 67%|██████▋   | 333/500 [03:49<02:18,  1.21it/s] 67%|██████▋   | 335/500 [03:49<01:39,  1.66it/s] 67%|██████▋   | 337/500 [03:49<01:11,  2.27it/s] 68%|██████▊   | 339/500 [03:50<00:52,  3.05it/s] 68%|██████▊   | 341/500 [03:56<03:02,  1.15s/it] 69%|██████▊   | 343/500 [03:56<02:09,  1.21it/s] 69%|██████▉   | 345/500 [03:56<01:32,  1.68it/s] 69%|██████▉   | 347/500 [03:56<01:06,  2.29it/s] 70%|██████▉   | 349/500 [03:56<00:49,  3.08it/s] 70%|███████   | 351/500 [04:02<02:50,  1.14s/it] 71%|███████   | 353/500 [04:02<02:00,  1.22it/s] 71%|███████   | 355/500 [04:03<01:26,  1.68it/s] 71%|███████▏  | 357/500 [04:03<01:02,  2.28it/s] 72%|███████▏  | 359/500 [04:03<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:09<02:43,  1.17s/it]Epoch:  290  	Training Loss: 0.06450164318084717
Test Loss:  0.06471504271030426
Valid Loss:  0.06863183528184891
Epoch:  291  	Training Loss: 0.06450112164020538
Test Loss:  0.0647149533033371
Valid Loss:  0.06863133609294891
Epoch:  292  	Training Loss: 0.0645006000995636
Test Loss:  0.06471489369869232
Valid Loss:  0.06863084435462952
Epoch:  293  	Training Loss: 0.06450009346008301
Test Loss:  0.06471481919288635
Valid Loss:  0.06863036751747131
Epoch:  294  	Training Loss: 0.06449957937002182
Test Loss:  0.06471474468708038
Valid Loss:  0.06862987577915192
Epoch:  295  	Training Loss: 0.06449908018112183
Test Loss:  0.06471473723649979
Valid Loss:  0.06862932443618774
Epoch:  296  	Training Loss: 0.06449855864048004
Test Loss:  0.06471467018127441
Valid Loss:  0.06862883269786835
Epoch:  297  	Training Loss: 0.06449805200099945
Test Loss:  0.06471459567546844
Valid Loss:  0.06862835586071014
Epoch:  298  	Training Loss: 0.06449754536151886
Test Loss:  0.06471451371908188
Valid Loss:  0.06862787902355194
Epoch:  299  	Training Loss: 0.06449703872203827
Test Loss:  0.06471451371908188
Valid Loss:  0.06862732768058777
Epoch:  300  	Training Loss: 0.06449653208255768
Test Loss:  0.06471443176269531
Valid Loss:  0.06862685084342957
Epoch:  301  	Training Loss: 0.0644960105419159
Test Loss:  0.06471435725688934
Valid Loss:  0.06862637400627136
Epoch:  302  	Training Loss: 0.0644955113530159
Test Loss:  0.06471427530050278
Valid Loss:  0.06862588226795197
Epoch:  303  	Training Loss: 0.06449499726295471
Test Loss:  0.06471425294876099
Valid Loss:  0.0686253234744072
Epoch:  304  	Training Loss: 0.06449446827173233
Test Loss:  0.06471417099237442
Valid Loss:  0.0686248391866684
Epoch:  305  	Training Loss: 0.06449395418167114
Test Loss:  0.06471408158540726
Valid Loss:  0.06862436234951019
Epoch:  306  	Training Loss: 0.06449344009160995
Test Loss:  0.06471406668424606
Valid Loss:  0.06862379610538483
Epoch:  307  	Training Loss: 0.06449291855096817
Test Loss:  0.0647139772772789
Valid Loss:  0.06862331181764603
Epoch:  308  	Training Loss: 0.06449240446090698
Test Loss:  0.06471388787031174
Valid Loss:  0.06862282752990723
Epoch:  309  	Training Loss: 0.0644918903708458
Test Loss:  0.06471388041973114
Valid Loss:  0.06862227618694305
Epoch:  310  	Training Loss: 0.06449136883020401
Test Loss:  0.06471377611160278
Valid Loss:  0.06862179934978485
Epoch:  311  	Training Loss: 0.06449085474014282
Test Loss:  0.06471369415521622
Valid Loss:  0.06862132251262665
Epoch:  312  	Training Loss: 0.06449034065008163
Test Loss:  0.06471364200115204
Valid Loss:  0.06862074881792068
Epoch:  313  	Training Loss: 0.06448979675769806
Test Loss:  0.06471352279186249
Valid Loss:  0.06862024962902069
Epoch:  314  	Training Loss: 0.06448926031589508
Test Loss:  0.06471340358257294
Valid Loss:  0.0686197429895401
Epoch:  315  	Training Loss: 0.0644887238740921
Test Loss:  0.06471335887908936
Valid Loss:  0.06861916184425354
Epoch:  316  	Training Loss: 0.06448818743228912
Test Loss:  0.06471323221921921
Valid Loss:  0.06861867010593414
Epoch:  317  	Training Loss: 0.06448764353990555
Test Loss:  0.06471315026283264
Valid Loss:  0.06861813366413116
Epoch:  318  	Training Loss: 0.06448710709810257
Test Loss:  0.06471310555934906
Valid Loss:  0.0686175599694252
Epoch:  319  	Training Loss: 0.064486563205719
Test Loss:  0.06471297889947891
Valid Loss:  0.06861706078052521
Epoch:  320  	Training Loss: 0.06448602676391602
Test Loss:  0.06471285223960876
Valid Loss:  0.06861656904220581
Epoch:  321  	Training Loss: 0.06448549032211304
Test Loss:  0.06471283733844757
Valid Loss:  0.06861597299575806
Epoch:  322  	Training Loss: 0.06448495388031006
Test Loss:  0.06471274793148041
Valid Loss:  0.06861549615859985
Epoch:  323  	Training Loss: 0.06448443979024887
Test Loss:  0.06471271067857742
Valid Loss:  0.06861494481563568
Epoch:  324  	Training Loss: 0.06448392570018768
Test Loss:  0.06471261382102966
Valid Loss:  0.06861448287963867
Epoch:  325  	Training Loss: 0.0644834041595459
Test Loss:  0.06471262872219086
Valid Loss:  0.06861387193202972
Epoch:  326  	Training Loss: 0.06448288261890411
Test Loss:  0.0647125318646431
Valid Loss:  0.06861340254545212
Epoch:  327  	Training Loss: 0.06448236107826233
Test Loss:  0.06471242010593414
Valid Loss:  0.06861293315887451
Epoch:  328  	Training Loss: 0.06448185443878174
Test Loss:  0.06471242010593414
Valid Loss:  0.06861235946416855
Epoch:  329  	Training Loss: 0.06448133289813995
Test Loss:  0.06471233814954758
Valid Loss:  0.06861187517642975
Epoch:  330  	Training Loss: 0.06448081135749817
Test Loss:  0.06471230089664459
Valid Loss:  0.06861132383346558
Epoch:  331  	Training Loss: 0.06448029726743698
Test Loss:  0.06471222639083862
Valid Loss:  0.06861083209514618
Epoch:  332  	Training Loss: 0.0644797831773758
Test Loss:  0.06471219658851624
Valid Loss:  0.06861026585102081
Epoch:  333  	Training Loss: 0.06447926163673401
Test Loss:  0.06471206247806549
Valid Loss:  0.06860978901386261
Epoch:  334  	Training Loss: 0.06447872519493103
Test Loss:  0.06471206992864609
Valid Loss:  0.06860921531915665
Epoch:  335  	Training Loss: 0.06447821110486984
Test Loss:  0.06471193581819534
Valid Loss:  0.06860874593257904
Epoch:  336  	Training Loss: 0.06447768211364746
Test Loss:  0.06471191346645355
Valid Loss:  0.06860817968845367
Epoch:  337  	Training Loss: 0.06447716057300568
Test Loss:  0.06471182405948639
Valid Loss:  0.06860768049955368
Epoch:  338  	Training Loss: 0.06447663903236389
Test Loss:  0.06471177190542221
Valid Loss:  0.0686071515083313
Epoch:  339  	Training Loss: 0.0644761174917221
Test Loss:  0.06471164524555206
Valid Loss:  0.06860664486885071
Epoch:  340  	Training Loss: 0.06447559595108032
Test Loss:  0.06471165269613266
Valid Loss:  0.06860609352588654
Epoch:  341  	Training Loss: 0.06447508186101913
Test Loss:  0.06471151113510132
Valid Loss:  0.06860561668872833
Epoch:  342  	Training Loss: 0.06447455286979675
Test Loss:  0.06471151113510132
Valid Loss:  0.06860502809286118
Epoch:  343  	Training Loss: 0.06447402387857437
Test Loss:  0.06471136957406998
Valid Loss:  0.06860455125570297
Epoch:  344  	Training Loss: 0.06447349488735199
Test Loss:  0.0647113025188446
Valid Loss:  0.0686040148139
Epoch:  345  	Training Loss: 0.0644729733467102
Test Loss:  0.06471122801303864
Valid Loss:  0.06860348582267761
Epoch:  346  	Training Loss: 0.06447244435548782
Test Loss:  0.06471115350723267
Valid Loss:  0.06860294938087463
Epoch:  347  	Training Loss: 0.06447192281484604
Test Loss:  0.06471113860607147
Valid Loss:  0.06860238313674927
Epoch:  348  	Training Loss: 0.06447139382362366
Test Loss:  0.06471101194620132
Valid Loss:  0.06860190629959106
Epoch:  349  	Training Loss: 0.06447087228298187
Test Loss:  0.06471098959445953
Valid Loss:  0.0686013400554657
Epoch:  350  	Training Loss: 0.06447035074234009
Test Loss:  0.06471086293458939
Valid Loss:  0.0686008483171463
Epoch:  351  	Training Loss: 0.0644698217511177
Test Loss:  0.06471078842878342
Valid Loss:  0.06860032677650452
Epoch:  352  	Training Loss: 0.06446930021047592
Test Loss:  0.06471076607704163
Valid Loss:  0.06859976053237915
Epoch:  353  	Training Loss: 0.06446877866983414
Test Loss:  0.06471063196659088
Valid Loss:  0.06859927624464035
Epoch:  354  	Training Loss: 0.06446824967861176
Test Loss:  0.06471061706542969
Valid Loss:  0.06859871745109558
Epoch:  355  	Training Loss: 0.06446772813796997
Test Loss:  0.06471048295497894
Valid Loss:  0.06859824061393738
Epoch:  356  	Training Loss: 0.06446720659732819
Test Loss:  0.06471046060323715
Valid Loss:  0.06859767436981201
Epoch:  357  	Training Loss: 0.0644666850566864
Test Loss:  0.06471038609743118
Valid Loss:  0.06859716027975082
Epoch:  358  	Training Loss: 0.06446616351604462
Test Loss:  0.06471030414104462
Valid Loss:  0.06859664618968964
Epoch:  359  	Training Loss: 0.06446563452482224
Test Loss:  0.06471022963523865
Valid Loss:  0.06859612464904785
Epoch:  360  	Training Loss: 0.06446511298418045
Test Loss:  0.06471021473407745
Valid Loss:  0.06859554350376129
Epoch:  361  	Training Loss: 0.06446459144353867
Test Loss:  0.06471006572246552
Valid Loss:  0.06859508156776428
 73%|███████▎  | 363/500 [04:09<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:09<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:10<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:10<00:43,  3.00it/s] 74%|███████▍  | 371/500 [04:16<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:16<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:16<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:16<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:16<00:39,  3.03it/s] 76%|███████▌  | 381/500 [04:23<02:18,  1.16s/it] 77%|███████▋  | 383/500 [04:23<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:23<01:09,  1.66it/s] 77%|███████▋  | 387/500 [04:23<00:50,  2.26it/s] 78%|███████▊  | 389/500 [04:23<00:36,  3.04it/s] 78%|███████▊  | 391/500 [04:29<02:05,  1.16s/it] 79%|███████▊  | 393/500 [04:29<01:28,  1.20it/s] 79%|███████▉  | 395/500 [04:30<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:30<00:45,  2.27it/s] 80%|███████▉  | 399/500 [04:30<00:33,  3.05it/s] 80%|████████  | 401/500 [04:36<01:54,  1.16s/it] 81%|████████  | 403/500 [04:36<01:20,  1.21it/s] 81%|████████  | 405/500 [04:36<00:56,  1.67it/s] 81%|████████▏ | 407/500 [04:36<00:40,  2.28it/s] 82%|████████▏ | 409/500 [04:37<00:29,  3.06it/s] 82%|████████▏ | 411/500 [04:43<01:42,  1.15s/it] 83%|████████▎ | 413/500 [04:43<01:11,  1.22it/s] 83%|████████▎ | 415/500 [04:43<00:50,  1.68it/s] 83%|████████▎ | 417/500 [04:43<00:36,  2.29it/s] 84%|████████▍ | 419/500 [04:43<00:26,  3.08it/s] 84%|████████▍ | 421/500 [04:49<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:50<01:04,  1.20it/s] 85%|████████▌ | 425/500 [04:50<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:50<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:50<00:23,  3.01it/s] 86%|████████▌ | 431/500 [04:56<01:21,  1.18s/it] 87%|████████▋ | 433/500 [04:56<00:56,  1.18it/s]Epoch:  362  	Training Loss: 0.06446407735347748
Test Loss:  0.06471005082130432
Valid Loss:  0.06859452277421951
Epoch:  363  	Training Loss: 0.0644635483622551
Test Loss:  0.06470998376607895
Valid Loss:  0.06859400868415833
Epoch:  364  	Training Loss: 0.06446303427219391
Test Loss:  0.06470987945795059
Valid Loss:  0.06859353184700012
Epoch:  365  	Training Loss: 0.06446252018213272
Test Loss:  0.06470982730388641
Valid Loss:  0.06859299540519714
Epoch:  366  	Training Loss: 0.06446200609207153
Test Loss:  0.06470979750156403
Valid Loss:  0.06859245896339417
Epoch:  367  	Training Loss: 0.06446148455142975
Test Loss:  0.06470970809459686
Valid Loss:  0.06859195232391357
Epoch:  368  	Training Loss: 0.06446097791194916
Test Loss:  0.0647096186876297
Valid Loss:  0.06859145313501358
Epoch:  369  	Training Loss: 0.06446045637130737
Test Loss:  0.0647096112370491
Valid Loss:  0.06859087944030762
Epoch:  370  	Training Loss: 0.06445994228124619
Test Loss:  0.06470952928066254
Valid Loss:  0.06859038770198822
Epoch:  371  	Training Loss: 0.064459428191185
Test Loss:  0.06470943987369537
Valid Loss:  0.06858988851308823
Epoch:  372  	Training Loss: 0.06445890665054321
Test Loss:  0.0647093653678894
Valid Loss:  0.06858938932418823
Epoch:  373  	Training Loss: 0.06445840001106262
Test Loss:  0.06470933556556702
Valid Loss:  0.06858882308006287
Epoch:  374  	Training Loss: 0.06445787847042084
Test Loss:  0.06470929086208344
Valid Loss:  0.06858827918767929
Epoch:  375  	Training Loss: 0.06445736438035965
Test Loss:  0.0647091493010521
Valid Loss:  0.06858783215284348
Epoch:  376  	Training Loss: 0.06445685029029846
Test Loss:  0.06470909714698792
Valid Loss:  0.0685872957110405
Epoch:  377  	Training Loss: 0.06445632874965668
Test Loss:  0.06470906734466553
Valid Loss:  0.06858672201633453
Epoch:  378  	Training Loss: 0.06445580720901489
Test Loss:  0.06470898538827896
Valid Loss:  0.06858623027801514
Epoch:  379  	Training Loss: 0.0644553005695343
Test Loss:  0.06470894813537598
Valid Loss:  0.06858567893505096
Epoch:  380  	Training Loss: 0.06445478647947311
Test Loss:  0.06470879912376404
Valid Loss:  0.06858524680137634
Epoch:  381  	Training Loss: 0.06445427238941193
Test Loss:  0.06470875442028046
Valid Loss:  0.06858469545841217
Epoch:  382  	Training Loss: 0.06445375084877014
Test Loss:  0.06470870971679688
Valid Loss:  0.06858417391777039
Epoch:  383  	Training Loss: 0.06445323675870895
Test Loss:  0.06470862776041031
Valid Loss:  0.068583644926548
Epoch:  384  	Training Loss: 0.06445272266864777
Test Loss:  0.06470859050750732
Valid Loss:  0.06858308613300323
Epoch:  385  	Training Loss: 0.06445220112800598
Test Loss:  0.06470845639705658
Valid Loss:  0.06858263164758682
Epoch:  386  	Training Loss: 0.06445169448852539
Test Loss:  0.06470838189125061
Valid Loss:  0.06858210265636444
Epoch:  387  	Training Loss: 0.0644511729478836
Test Loss:  0.06470832228660583
Valid Loss:  0.06858158856630325
Epoch:  388  	Training Loss: 0.06445065885782242
Test Loss:  0.06470827758312225
Valid Loss:  0.06858102977275848
Epoch:  389  	Training Loss: 0.06445014476776123
Test Loss:  0.0647081807255745
Valid Loss:  0.06858054548501968
Epoch:  390  	Training Loss: 0.06444962322711945
Test Loss:  0.06470813602209091
Valid Loss:  0.06857998669147491
Epoch:  391  	Training Loss: 0.06444910168647766
Test Loss:  0.06470809876918793
Valid Loss:  0.06857945024967194
Epoch:  392  	Training Loss: 0.06444859504699707
Test Loss:  0.06470796465873718
Valid Loss:  0.06857900321483612
Epoch:  393  	Training Loss: 0.06444809585809708
Test Loss:  0.06470789015293121
Valid Loss:  0.06857849657535553
Epoch:  394  	Training Loss: 0.06444758176803589
Test Loss:  0.06470783054828644
Valid Loss:  0.06857798993587494
Epoch:  395  	Training Loss: 0.0644470751285553
Test Loss:  0.06470779329538345
Valid Loss:  0.06857745349407196
Epoch:  396  	Training Loss: 0.06444656848907471
Test Loss:  0.06470775604248047
Valid Loss:  0.06857691705226898
Epoch:  397  	Training Loss: 0.06444606930017471
Test Loss:  0.06470765173435211
Valid Loss:  0.06857644021511078
Epoch:  398  	Training Loss: 0.06444555521011353
Test Loss:  0.06470760703086853
Valid Loss:  0.0685759112238884
Epoch:  399  	Training Loss: 0.06444505602121353
Test Loss:  0.06470755487680435
Valid Loss:  0.06857539713382721
Epoch:  400  	Training Loss: 0.06444454938173294
Test Loss:  0.06470751017332077
Valid Loss:  0.06857487559318542
Epoch:  401  	Training Loss: 0.06444404274225235
Test Loss:  0.0647074282169342
Valid Loss:  0.06857437640428543
Epoch:  402  	Training Loss: 0.06444353610277176
Test Loss:  0.06470734626054764
Valid Loss:  0.06857385486364365
Epoch:  403  	Training Loss: 0.06444300711154938
Test Loss:  0.06470727920532227
Valid Loss:  0.06857331097126007
Epoch:  404  	Training Loss: 0.06444248557090759
Test Loss:  0.06470714509487152
Valid Loss:  0.06857283413410187
Epoch:  405  	Training Loss: 0.06444196403026581
Test Loss:  0.06470701098442078
Valid Loss:  0.06857234239578247
Epoch:  406  	Training Loss: 0.06444144248962402
Test Loss:  0.064706951379776
Valid Loss:  0.0685717910528183
Epoch:  407  	Training Loss: 0.06444092094898224
Test Loss:  0.06470687687397003
Valid Loss:  0.06857124716043472
Epoch:  408  	Training Loss: 0.06444039940834045
Test Loss:  0.06470679491758347
Valid Loss:  0.06857073307037354
Epoch:  409  	Training Loss: 0.06443987041711807
Test Loss:  0.0647067278623581
Valid Loss:  0.06857019662857056
Epoch:  410  	Training Loss: 0.06443934142589569
Test Loss:  0.06470666825771332
Valid Loss:  0.06856965273618698
Epoch:  411  	Training Loss: 0.0644388273358345
Test Loss:  0.06470654904842377
Valid Loss:  0.06856915354728699
Epoch:  412  	Training Loss: 0.06443830579519272
Test Loss:  0.0647064819931984
Valid Loss:  0.06856866180896759
Epoch:  413  	Training Loss: 0.06443780660629272
Test Loss:  0.06470643728971481
Valid Loss:  0.0685681477189064
Epoch:  414  	Training Loss: 0.06443730741739273
Test Loss:  0.06470639258623123
Valid Loss:  0.06856763362884521
Epoch:  415  	Training Loss: 0.06443680822849274
Test Loss:  0.06470632553100586
Valid Loss:  0.06856715679168701
Epoch:  416  	Training Loss: 0.06443631649017334
Test Loss:  0.06470628082752228
Valid Loss:  0.06856665015220642
Epoch:  417  	Training Loss: 0.06443581730127335
Test Loss:  0.0647062212228775
Valid Loss:  0.06856614351272583
Epoch:  418  	Training Loss: 0.06443532556295395
Test Loss:  0.06470613181591034
Valid Loss:  0.06856566667556763
Epoch:  419  	Training Loss: 0.06443482637405396
Test Loss:  0.06470606476068497
Valid Loss:  0.06856518983840942
Epoch:  420  	Training Loss: 0.06443433463573456
Test Loss:  0.06470600515604019
Valid Loss:  0.06856468319892883
Epoch:  421  	Training Loss: 0.06443383544683456
Test Loss:  0.06470595300197601
Valid Loss:  0.06856417655944824
Epoch:  422  	Training Loss: 0.06443334370851517
Test Loss:  0.06470587849617004
Valid Loss:  0.06856366246938705
Epoch:  423  	Training Loss: 0.06443282961845398
Test Loss:  0.06470580399036407
Valid Loss:  0.06856317818164825
Epoch:  424  	Training Loss: 0.06443232297897339
Test Loss:  0.06470572203397751
Valid Loss:  0.06856265664100647
Epoch:  425  	Training Loss: 0.0644318163394928
Test Loss:  0.06470564752817154
Valid Loss:  0.06856214255094528
Epoch:  426  	Training Loss: 0.06443130970001221
Test Loss:  0.06470558047294617
Valid Loss:  0.0685616210103035
Epoch:  427  	Training Loss: 0.06443080306053162
Test Loss:  0.064705491065979
Valid Loss:  0.0685611367225647
Epoch:  428  	Training Loss: 0.06443028897047043
Test Loss:  0.06470540910959244
Valid Loss:  0.0685606375336647
Epoch:  429  	Training Loss: 0.06442978233098984
Test Loss:  0.06470533460378647
Valid Loss:  0.06856012344360352
Epoch:  430  	Training Loss: 0.06442927569150925
Test Loss:  0.06470520794391632
Valid Loss:  0.06855963915586472
Epoch:  431  	Training Loss: 0.06442876905202866
Test Loss:  0.06470513343811035
Valid Loss:  0.06855913251638412
Epoch:  432  	Training Loss: 0.06442825496196747
Test Loss:  0.0647050142288208
Valid Loss:  0.06855863332748413
Epoch:  433  	Training Loss: 0.06442774087190628
Test Loss:  0.06470492482185364
Valid Loss:  0.06855811178684235
 87%|████████▋ | 435/500 [04:57<00:39,  1.63it/s] 87%|████████▋ | 437/500 [04:57<00:28,  2.23it/s] 88%|████████▊ | 439/500 [04:57<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:03<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:03<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:03<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:04<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:04<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:10<00:57,  1.16s/it] 91%|█████████ | 453/500 [05:10<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:10<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:10<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:10<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:17<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:17<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:17<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:17<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:17<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:23<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:24<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:24<00:15,  1.66it/s] 95%|█████████▌| 477/500 [05:24<00:10,  2.26it/s] 96%|█████████▌| 479/500 [05:24<00:06,  3.04it/s] 96%|█████████▌| 481/500 [05:30<00:22,  1.16s/it] 97%|█████████▋| 483/500 [05:30<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:30<00:09,  1.66it/s] 97%|█████████▋| 487/500 [05:31<00:05,  2.26it/s] 98%|█████████▊| 489/500 [05:31<00:03,  3.04it/s] 98%|█████████▊| 491/500 [05:37<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:37<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:37<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:37<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:38<00:00,  3.02it/s]100%|██████████| 500/500 [05:38<00:00,  1.48it/s]
Epoch:  434  	Training Loss: 0.0644272193312645
Test Loss:  0.06470483541488647
Valid Loss:  0.06855759024620056
Epoch:  435  	Training Loss: 0.06442669779062271
Test Loss:  0.06470473855733871
Valid Loss:  0.06855707615613937
Epoch:  436  	Training Loss: 0.06442618370056152
Test Loss:  0.06470464169979095
Valid Loss:  0.06855656206607819
Epoch:  437  	Training Loss: 0.06442566215991974
Test Loss:  0.0647045373916626
Valid Loss:  0.06855607032775879
Epoch:  438  	Training Loss: 0.06442514806985855
Test Loss:  0.06470444053411484
Valid Loss:  0.068555548787117
Epoch:  439  	Training Loss: 0.06442463397979736
Test Loss:  0.06470434367656708
Valid Loss:  0.06855504214763641
Epoch:  440  	Training Loss: 0.06442411243915558
Test Loss:  0.06470423936843872
Valid Loss:  0.06855452805757523
Epoch:  441  	Training Loss: 0.06442359834909439
Test Loss:  0.06470414996147156
Valid Loss:  0.06855401396751404
Epoch:  442  	Training Loss: 0.0644230768084526
Test Loss:  0.06470407545566559
Valid Loss:  0.06855352222919464
Epoch:  443  	Training Loss: 0.06442258507013321
Test Loss:  0.06470397114753723
Valid Loss:  0.06855306029319763
Epoch:  444  	Training Loss: 0.06442209333181381
Test Loss:  0.06470389664173126
Valid Loss:  0.06855257600545883
Epoch:  445  	Training Loss: 0.06442159414291382
Test Loss:  0.06470382213592529
Valid Loss:  0.06855209171772003
Epoch:  446  	Training Loss: 0.06442110240459442
Test Loss:  0.06470374017953873
Valid Loss:  0.06855160742998123
Epoch:  447  	Training Loss: 0.06442060321569443
Test Loss:  0.06470365822315216
Valid Loss:  0.06855110824108124
Epoch:  448  	Training Loss: 0.06442009657621384
Test Loss:  0.064703568816185
Valid Loss:  0.06855062395334244
Epoch:  449  	Training Loss: 0.06441960483789444
Test Loss:  0.06470347940921783
Valid Loss:  0.06855013966560364
Epoch:  450  	Training Loss: 0.06441910564899445
Test Loss:  0.06470339000225067
Valid Loss:  0.06854968518018723
Epoch:  451  	Training Loss: 0.06441861391067505
Test Loss:  0.06470330059528351
Valid Loss:  0.06854920834302902
Epoch:  452  	Training Loss: 0.06441812217235565
Test Loss:  0.06470321118831635
Valid Loss:  0.06854872405529022
Epoch:  453  	Training Loss: 0.06441762298345566
Test Loss:  0.06470319628715515
Valid Loss:  0.06854817271232605
Epoch:  454  	Training Loss: 0.06441712379455566
Test Loss:  0.06470310688018799
Valid Loss:  0.06854768097400665
Epoch:  455  	Training Loss: 0.06441662460565567
Test Loss:  0.06470301747322083
Valid Loss:  0.06854720413684845
Epoch:  456  	Training Loss: 0.06441613286733627
Test Loss:  0.06470300257205963
Valid Loss:  0.06854666024446487
Epoch:  457  	Training Loss: 0.06441563367843628
Test Loss:  0.06470290571451187
Valid Loss:  0.06854617595672607
Epoch:  458  	Training Loss: 0.06441513448953629
Test Loss:  0.06470280885696411
Valid Loss:  0.06854569911956787
Epoch:  459  	Training Loss: 0.06441464275121689
Test Loss:  0.06470270454883575
Valid Loss:  0.06854525208473206
Epoch:  460  	Training Loss: 0.06441415101289749
Test Loss:  0.06470268964767456
Valid Loss:  0.06854471564292908
Epoch:  461  	Training Loss: 0.06441366672515869
Test Loss:  0.0647025853395462
Valid Loss:  0.06854423135519028
Epoch:  462  	Training Loss: 0.0644131600856781
Test Loss:  0.06470249593257904
Valid Loss:  0.06854376196861267
Epoch:  463  	Training Loss: 0.0644126683473587
Test Loss:  0.06470248103141785
Valid Loss:  0.0685432180762291
Epoch:  464  	Training Loss: 0.06441216915845871
Test Loss:  0.06470237672328949
Valid Loss:  0.06854274868965149
Epoch:  465  	Training Loss: 0.06441167742013931
Test Loss:  0.06470227986574173
Valid Loss:  0.06854227185249329
Epoch:  466  	Training Loss: 0.06441117823123932
Test Loss:  0.06470225751399994
Valid Loss:  0.06854173541069031
Epoch:  467  	Training Loss: 0.06441068649291992
Test Loss:  0.06470216065645218
Valid Loss:  0.0685412585735321
Epoch:  468  	Training Loss: 0.06441019475460052
Test Loss:  0.06470206379890442
Valid Loss:  0.0685407966375351
Epoch:  469  	Training Loss: 0.06440970301628113
Test Loss:  0.06470204144716263
Valid Loss:  0.06854026019573212
Epoch:  470  	Training Loss: 0.06440920382738113
Test Loss:  0.06470193713903427
Valid Loss:  0.06853978335857391
Epoch:  471  	Training Loss: 0.06440870463848114
Test Loss:  0.06470184028148651
Valid Loss:  0.0685393214225769
Epoch:  472  	Training Loss: 0.06440822035074234
Test Loss:  0.06470182538032532
Valid Loss:  0.06853880733251572
Epoch:  473  	Training Loss: 0.06440773606300354
Test Loss:  0.06470174342393875
Valid Loss:  0.0685383602976799
Epoch:  474  	Training Loss: 0.06440725922584534
Test Loss:  0.06470173597335815
Valid Loss:  0.06853783875703812
Epoch:  475  	Training Loss: 0.06440678238868713
Test Loss:  0.0647016391158104
Valid Loss:  0.0685373991727829
Epoch:  476  	Training Loss: 0.06440630555152893
Test Loss:  0.06470154970884323
Valid Loss:  0.06853695213794708
Epoch:  477  	Training Loss: 0.06440582871437073
Test Loss:  0.06470153480768204
Valid Loss:  0.0685364305973053
Epoch:  478  	Training Loss: 0.06440534442663193
Test Loss:  0.06470143795013428
Valid Loss:  0.06853598356246948
Epoch:  479  	Training Loss: 0.06440486758947372
Test Loss:  0.06470142304897308
Valid Loss:  0.0685354620218277
Epoch:  480  	Training Loss: 0.06440439075231552
Test Loss:  0.06470132619142532
Valid Loss:  0.06853503733873367
Epoch:  481  	Training Loss: 0.06440390646457672
Test Loss:  0.06470122933387756
Valid Loss:  0.06853458285331726
Epoch:  482  	Training Loss: 0.06440343707799911
Test Loss:  0.06470120698213577
Valid Loss:  0.06853406876325607
Epoch:  483  	Training Loss: 0.06440295279026031
Test Loss:  0.06470109522342682
Valid Loss:  0.06853362172842026
Epoch:  484  	Training Loss: 0.06440246850252151
Test Loss:  0.06470108032226562
Valid Loss:  0.06853311508893967
Epoch:  485  	Training Loss: 0.06440199166536331
Test Loss:  0.06470097601413727
Valid Loss:  0.06853266805410385
Epoch:  486  	Training Loss: 0.06440150737762451
Test Loss:  0.06470094621181488
Valid Loss:  0.06853215396404266
Epoch:  487  	Training Loss: 0.06440102308988571
Test Loss:  0.06470083445310593
Valid Loss:  0.06853170692920685
Epoch:  488  	Training Loss: 0.06440053880214691
Test Loss:  0.06470081210136414
Valid Loss:  0.06853120774030685
Epoch:  489  	Training Loss: 0.06440006196498871
Test Loss:  0.06470070034265518
Valid Loss:  0.06853075325489044
Epoch:  490  	Training Loss: 0.0643995851278305
Test Loss:  0.06470067799091339
Valid Loss:  0.06853025406599045
Epoch:  491  	Training Loss: 0.0643991008400917
Test Loss:  0.06470055878162384
Valid Loss:  0.06852981448173523
Epoch:  492  	Training Loss: 0.0643986165523529
Test Loss:  0.06470051407814026
Valid Loss:  0.06852929294109344
Epoch:  493  	Training Loss: 0.06439812481403351
Test Loss:  0.06470039486885071
Valid Loss:  0.06852883845567703
Epoch:  494  	Training Loss: 0.06439762562513351
Test Loss:  0.06470034271478653
Valid Loss:  0.06852832436561584
Epoch:  495  	Training Loss: 0.06439714133739471
Test Loss:  0.06470021605491638
Valid Loss:  0.06852786242961884
Epoch:  496  	Training Loss: 0.06439664214849472
Test Loss:  0.0647001713514328
Valid Loss:  0.06852735579013824
Epoch:  497  	Training Loss: 0.06439615041017532
Test Loss:  0.06470004469156265
Valid Loss:  0.06852690875530243
Epoch:  498  	Training Loss: 0.06439565122127533
Test Loss:  0.06469998508691788
Valid Loss:  0.06852638721466064
Epoch:  499  	Training Loss: 0.06439516693353653
Test Loss:  0.06469985842704773
Valid Loss:  0.06852594017982483
Epoch:  500  	Training Loss: 0.06439466774463654
Test Loss:  0.06469981372356415
Valid Loss:  0.06852543354034424
seed is  10
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:42,  6.22s/it]  1%|          | 3/500 [00:06<13:47,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:35,  1.30s/it]  3%|▎         | 13/500 [00:13<07:13,  1.12it/s]  3%|▎         | 15/500 [00:13<05:02,  1.60it/s]  3%|▎         | 17/500 [00:13<03:36,  2.23it/s]  4%|▍         | 19/500 [00:13<02:38,  3.04it/s]  4%|▍         | 21/500 [00:19<09:36,  1.20s/it]  5%|▍         | 23/500 [00:19<06:49,  1.16it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:26<09:08,  1.17s/it]  7%|▋         | 33/500 [00:26<06:30,  1.19it/s]  7%|▋         | 35/500 [00:26<04:41,  1.65it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<08:51,  1.16s/it]  9%|▊         | 43/500 [00:33<06:20,  1.20it/s]  9%|▉         | 45/500 [00:33<04:33,  1.66it/s]  9%|▉         | 47/500 [00:33<03:19,  2.27it/s] 10%|▉         | 49/500 [00:33<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:47,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.19it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.00it/s] 12%|█▏        | 61/500 [00:46<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.22it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.99it/s]Epoch:  1  	Training Loss: 0.06514871120452881
Test Loss:  0.12896296381950378
Valid Loss:  0.13543617725372314
Epoch:  2  	Training Loss: 0.14696520566940308
Test Loss:  0.7867609858512878
Valid Loss:  0.7647727727890015
Epoch:  3  	Training Loss: 0.731986939907074
Test Loss:  0.03722463920712471
Valid Loss:  0.04459746927022934
Epoch:  4  	Training Loss: 0.05204944312572479
Test Loss:  0.037157557904720306
Valid Loss:  0.044552065432071686
Epoch:  5  	Training Loss: 0.051977984607219696
Test Loss:  0.03710119053721428
Valid Loss:  0.044509753584861755
Epoch:  6  	Training Loss: 0.05191643163561821
Test Loss:  0.03705048933625221
Valid Loss:  0.04447136074304581
Epoch:  7  	Training Loss: 0.05186738818883896
Test Loss:  0.0370064452290535
Valid Loss:  0.04443758353590965
Epoch:  8  	Training Loss: 0.05182754248380661
Test Loss:  0.03697141632437706
Valid Loss:  0.044405706226825714
Epoch:  9  	Training Loss: 0.05178981274366379
Test Loss:  0.036940425634384155
Valid Loss:  0.04437536001205444
Epoch:  10  	Training Loss: 0.05175324156880379
Test Loss:  0.03691631555557251
Valid Loss:  0.04434589296579361
Epoch:  11  	Training Loss: 0.051719263195991516
Test Loss:  0.03689495474100113
Valid Loss:  0.04431885480880737
Epoch:  12  	Training Loss: 0.05168983340263367
Test Loss:  0.03440280258655548
Valid Loss:  0.03857152909040451
Epoch:  13  	Training Loss: 0.03658965975046158
Test Loss:  0.010385644622147083
Valid Loss:  0.01362565066665411
Epoch:  14  	Training Loss: 0.01343593094497919
Test Loss:  0.007173607125878334
Valid Loss:  0.010217566043138504
Epoch:  15  	Training Loss: 0.010446871630847454
Test Loss:  0.005845910403877497
Valid Loss:  0.008740943856537342
Epoch:  16  	Training Loss: 0.009152722544968128
Test Loss:  0.005095859989523888
Valid Loss:  0.007860378362238407
Epoch:  17  	Training Loss: 0.008352255448698997
Test Loss:  0.004537858068943024
Valid Loss:  0.007187270559370518
Epoch:  18  	Training Loss: 0.007701139897108078
Test Loss:  0.004178491421043873
Valid Loss:  0.0067266495898365974
Epoch:  19  	Training Loss: 0.007206863258033991
Test Loss:  0.0039059026166796684
Valid Loss:  0.006360583007335663
Epoch:  20  	Training Loss: 0.006784607656300068
Test Loss:  0.003679781686514616
Valid Loss:  0.00604785792529583
Epoch:  21  	Training Loss: 0.00640869652852416
Test Loss:  0.0034853299148380756
Valid Loss:  0.00577259436249733
Epoch:  22  	Training Loss: 0.0060699027962982655
Test Loss:  0.0034617879427969456
Valid Loss:  0.005200718529522419
Epoch:  23  	Training Loss: 0.0046940753236413
Test Loss:  0.002515756990760565
Valid Loss:  0.004256878979504108
Epoch:  24  	Training Loss: 0.00421531917527318
Test Loss:  0.0028850985690951347
Valid Loss:  0.004398079123347998
Epoch:  25  	Training Loss: 0.0038940398953855038
Test Loss:  0.0022926421370357275
Valid Loss:  0.003870248794555664
Epoch:  26  	Training Loss: 0.0036269137635827065
Test Loss:  0.0024939514696598053
Valid Loss:  0.003922092262655497
Epoch:  27  	Training Loss: 0.0034471419639885426
Test Loss:  0.002182245720177889
Valid Loss:  0.0036340057849884033
Epoch:  28  	Training Loss: 0.0033003492280840874
Test Loss:  0.002320163417607546
Valid Loss:  0.0036652940325438976
Epoch:  29  	Training Loss: 0.003185985144227743
Test Loss:  0.0021216794848442078
Valid Loss:  0.003477811813354492
Epoch:  30  	Training Loss: 0.0030910936184227467
Test Loss:  0.002214947249740362
Valid Loss:  0.003496121149510145
Epoch:  31  	Training Loss: 0.0030144955962896347
Test Loss:  0.0021046402398496866
Valid Loss:  0.0033831733744591475
Epoch:  32  	Training Loss: 0.00295101385563612
Test Loss:  0.0018158233724534512
Valid Loss:  0.003143582260236144
Epoch:  33  	Training Loss: 0.002896616468206048
Test Loss:  0.0019833289552479982
Valid Loss:  0.00325384340249002
Epoch:  34  	Training Loss: 0.0028659168165177107
Test Loss:  0.001853795605711639
Valid Loss:  0.003147341776639223
Epoch:  35  	Training Loss: 0.002843561815097928
Test Loss:  0.0019335721153765917
Valid Loss:  0.0031961812637746334
Epoch:  36  	Training Loss: 0.002825787290930748
Test Loss:  0.0018767041619867086
Valid Loss:  0.003145604394376278
Epoch:  37  	Training Loss: 0.002810866106301546
Test Loss:  0.0019154353067278862
Valid Loss:  0.003165643196552992
Epoch:  38  	Training Loss: 0.002797818509861827
Test Loss:  0.00189127994235605
Valid Loss:  0.003140644170343876
Epoch:  39  	Training Loss: 0.0027861353009939194
Test Loss:  0.0019103873055428267
Valid Loss:  0.0031474451534450054
Epoch:  40  	Training Loss: 0.0027755633927881718
Test Loss:  0.001900476636365056
Valid Loss:  0.0031333575025200844
Epoch:  41  	Training Loss: 0.0027657411992549896
Test Loss:  0.0019113150192424655
Valid Loss:  0.003134758211672306
Epoch:  42  	Training Loss: 0.002756561618298292
Test Loss:  0.0019025057554244995
Valid Loss:  0.0029650062788277864
Epoch:  43  	Training Loss: 0.00249514845199883
Test Loss:  0.0017634860705584288
Valid Loss:  0.002753984183073044
Epoch:  44  	Training Loss: 0.0023143754806369543
Test Loss:  0.001728430506773293
Valid Loss:  0.0026650759391486645
Epoch:  45  	Training Loss: 0.002237987704575062
Test Loss:  0.0017037990037351847
Valid Loss:  0.0026242011226713657
Epoch:  46  	Training Loss: 0.0022052074782550335
Test Loss:  0.0016998592764139175
Valid Loss:  0.0026073926128447056
Epoch:  47  	Training Loss: 0.002190573839470744
Test Loss:  0.0016962471418082714
Valid Loss:  0.0025954097509384155
Epoch:  48  	Training Loss: 0.0021816277876496315
Test Loss:  0.001692990306764841
Valid Loss:  0.002588114235550165
Epoch:  49  	Training Loss: 0.0021750659216195345
Test Loss:  0.0016922764480113983
Valid Loss:  0.0025832215324044228
Epoch:  50  	Training Loss: 0.0021694577299058437
Test Loss:  0.0016891745617613196
Valid Loss:  0.002578138839453459
Epoch:  51  	Training Loss: 0.0021653594449162483
Test Loss:  0.0016852624248713255
Valid Loss:  0.002573994919657707
Epoch:  52  	Training Loss: 0.0021622139029204845
Test Loss:  0.001663111848756671
Valid Loss:  0.0025586956180632114
Epoch:  53  	Training Loss: 0.002149735577404499
Test Loss:  0.0016470642294734716
Valid Loss:  0.0025471390690654516
Epoch:  54  	Training Loss: 0.0021405068691819906
Test Loss:  0.0016341566806659102
Valid Loss:  0.0025370842777192593
Epoch:  55  	Training Loss: 0.002133006229996681
Test Loss:  0.00162420142441988
Valid Loss:  0.0025297447573393583
Epoch:  56  	Training Loss: 0.0021264508832246065
Test Loss:  0.0016155634075403214
Valid Loss:  0.002523465547710657
Epoch:  57  	Training Loss: 0.0021207588724792004
Test Loss:  0.0016082259826362133
Valid Loss:  0.002517807763069868
Epoch:  58  	Training Loss: 0.002115788869559765
Test Loss:  0.0016015733126550913
Valid Loss:  0.0025126999244093895
Epoch:  59  	Training Loss: 0.0021115404088050127
Test Loss:  0.0015955220442265272
Valid Loss:  0.0025079986080527306
Epoch:  60  	Training Loss: 0.0021077897399663925
Test Loss:  0.001590759726241231
Valid Loss:  0.002504034200683236
Epoch:  61  	Training Loss: 0.002104786690324545
Test Loss:  0.0015870890347287059
Valid Loss:  0.0025008847005665302
Epoch:  62  	Training Loss: 0.0021021030843257904
Test Loss:  0.0015606434317305684
Valid Loss:  0.002480095252394676
Epoch:  63  	Training Loss: 0.0020927563309669495
Test Loss:  0.001578784198500216
Valid Loss:  0.002489557024091482
Epoch:  64  	Training Loss: 0.0020884519908577204
Test Loss:  0.0015405314043164253
Valid Loss:  0.00246395543217659
Epoch:  65  	Training Loss: 0.002087515313178301
Test Loss:  0.0016206245636567473
Valid Loss:  0.002515689004212618
Epoch:  66  	Training Loss: 0.002089319285005331
Test Loss:  0.0014905461575835943
Valid Loss:  0.00243353471159935
Epoch:  67  	Training Loss: 0.0020952417980879545
Test Loss:  0.0017264120979234576
Valid Loss:  0.0025899363681674004
Epoch:  68  	Training Loss: 0.0021079147700220346
Test Loss:  0.0014031410682946444
Valid Loss:  0.0023990217596292496
Epoch:  69  	Training Loss: 0.002147497609257698
Test Loss:  0.002067907713353634
Valid Loss:  0.002858214545994997
Epoch:  70  	Training Loss: 0.0022347320336848497
Test Loss:  0.0013820326421409845
Valid Loss:  0.0025042924098670483
 14%|█▍        | 71/500 [00:59<15:02,  2.10s/it] 15%|█▍        | 73/500 [01:00<10:38,  1.49s/it] 15%|█▌        | 75/500 [01:00<07:34,  1.07s/it] 15%|█▌        | 77/500 [01:00<05:27,  1.29it/s] 16%|█▌        | 79/500 [01:00<03:56,  1.78it/s] 16%|█▌        | 81/500 [01:06<09:19,  1.34s/it] 17%|█▋        | 83/500 [01:06<06:38,  1.05it/s] 17%|█▋        | 85/500 [01:07<04:45,  1.45it/s] 17%|█▋        | 87/500 [01:07<03:27,  1.99it/s] 18%|█▊        | 89/500 [01:07<02:32,  2.70it/s] 18%|█▊        | 91/500 [01:13<08:06,  1.19s/it] 19%|█▊        | 93/500 [01:13<05:47,  1.17it/s] 19%|█▉        | 95/500 [01:13<04:09,  1.62it/s] 19%|█▉        | 97/500 [01:13<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:14<02:14,  2.98it/s] 20%|██        | 101/500 [01:20<07:48,  1.17s/it] 21%|██        | 103/500 [01:20<05:34,  1.19it/s] 21%|██        | 105/500 [01:20<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:20<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:20<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:27<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:27<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:27<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:27<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:27<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:34<07:25,  1.18s/it] 25%|██▍       | 123/500 [01:34<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:34<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:34<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:34<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:40<07:07,  1.16s/it] 27%|██▋       | 133/500 [01:40<05:05,  1.20it/s] 27%|██▋       | 135/500 [01:40<03:39,  1.66it/s] 27%|██▋       | 137/500 [01:41<02:39,  2.27it/s]**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.0024571483954787254
Test Loss:  0.0016051136190071702
Valid Loss:  0.002445784630253911
Epoch:  72  	Training Loss: 0.002148031024262309
Test Loss:  0.0016215263167396188
Valid Loss:  0.0024379270616918802
Epoch:  73  	Training Loss: 0.0021218773908913136
Test Loss:  0.001615307992324233
Valid Loss:  0.0024312192108482122
Epoch:  74  	Training Loss: 0.0021123618353158236
Test Loss:  0.0016123020322993398
Valid Loss:  0.0024282755330204964
Epoch:  75  	Training Loss: 0.0021040551364421844
Test Loss:  0.0016035885782912374
Valid Loss:  0.002422163262963295
Epoch:  76  	Training Loss: 0.0020965146832168102
Test Loss:  0.0015989007661119103
Valid Loss:  0.00241847918368876
Epoch:  77  	Training Loss: 0.002089644316583872
Test Loss:  0.0015932556707412004
Valid Loss:  0.0024144966155290604
Epoch:  78  	Training Loss: 0.002083384431898594
Test Loss:  0.0015883625019341707
Valid Loss:  0.002410935005173087
Epoch:  79  	Training Loss: 0.002077688928693533
Test Loss:  0.0015846421010792255
Valid Loss:  0.002408599713817239
Epoch:  80  	Training Loss: 0.00207250053063035
Test Loss:  0.0015795243671163917
Valid Loss:  0.002405300736427307
Epoch:  81  	Training Loss: 0.002067780587822199
Test Loss:  0.0015763293486088514
Valid Loss:  0.002403218299150467
Epoch:  82  	Training Loss: 0.002063484862446785
Test Loss:  0.0015582181513309479
Valid Loss:  0.0023919520899653435
Epoch:  83  	Training Loss: 0.0020588370971381664
Test Loss:  0.0015656789764761925
Valid Loss:  0.002395786577835679
Epoch:  84  	Training Loss: 0.0020551420748233795
Test Loss:  0.0015544573543593287
Valid Loss:  0.0023891343735158443
Epoch:  85  	Training Loss: 0.002052017953246832
Test Loss:  0.0015589309623464942
Valid Loss:  0.0023909984156489372
Epoch:  86  	Training Loss: 0.0020494454074651003
Test Loss:  0.001552389468997717
Valid Loss:  0.002387214917689562
Epoch:  87  	Training Loss: 0.0020472644828259945
Test Loss:  0.0015536705031991005
Valid Loss:  0.0023874605540186167
Epoch:  88  	Training Loss: 0.002045386703684926
Test Loss:  0.00155052007175982
Valid Loss:  0.00238563260063529
Epoch:  89  	Training Loss: 0.0020437422208487988
Test Loss:  0.0015504423063248396
Valid Loss:  0.002385429572314024
Epoch:  90  	Training Loss: 0.002042254665866494
Test Loss:  0.0015488730277866125
Valid Loss:  0.0023848116397857666
Epoch:  91  	Training Loss: 0.002040926832705736
Test Loss:  0.0015466344775632024
Valid Loss:  0.0023828530684113503
Epoch:  92  	Training Loss: 0.0020396632608026266
Test Loss:  0.001550892717204988
Valid Loss:  0.00236720172688365
Epoch:  93  	Training Loss: 0.0020071843173354864
Test Loss:  0.0015357256634160876
Valid Loss:  0.0023575183004140854
Epoch:  94  	Training Loss: 0.002001915592700243
Test Loss:  0.001533026690594852
Valid Loss:  0.002356413984671235
Epoch:  95  	Training Loss: 0.0019985786639153957
Test Loss:  0.001530948793515563
Valid Loss:  0.0023555755615234375
Epoch:  96  	Training Loss: 0.0019959164783358574
Test Loss:  0.001529241562820971
Valid Loss:  0.0023549767211079597
Epoch:  97  	Training Loss: 0.0019937565084546804
Test Loss:  0.0015280621591955423
Valid Loss:  0.0023548139724880457
Epoch:  98  	Training Loss: 0.0019919932819902897
Test Loss:  0.0015266257105395198
Valid Loss:  0.0023544805590063334
Epoch:  99  	Training Loss: 0.001990675926208496
Test Loss:  0.0015253315214067698
Valid Loss:  0.0023542321287095547
Epoch:  100  	Training Loss: 0.0019896277226507664
Test Loss:  0.0015245559625327587
Valid Loss:  0.002354258205741644
Epoch:  101  	Training Loss: 0.0019887166563421488
Test Loss:  0.0015238207997754216
Valid Loss:  0.002354274969547987
Epoch:  102  	Training Loss: 0.001987921306863427
Test Loss:  0.0015322113176807761
Valid Loss:  0.002354217693209648
Epoch:  103  	Training Loss: 0.0019854335114359856
Test Loss:  0.0015370554756373167
Valid Loss:  0.0023540761321783066
Epoch:  104  	Training Loss: 0.0019836369901895523
Test Loss:  0.0015399230178445578
Valid Loss:  0.0023532183840870857
Epoch:  105  	Training Loss: 0.00198228913359344
Test Loss:  0.0015417044050991535
Valid Loss:  0.0023519652895629406
Epoch:  106  	Training Loss: 0.0019810351077467203
Test Loss:  0.0015427609905600548
Valid Loss:  0.002350475639104843
Epoch:  107  	Training Loss: 0.0019799708388745785
Test Loss:  0.0015415351372212172
Valid Loss:  0.002348469104617834
Epoch:  108  	Training Loss: 0.0019791945815086365
Test Loss:  0.001540854456834495
Valid Loss:  0.0023466572165489197
Epoch:  109  	Training Loss: 0.001978459535166621
Test Loss:  0.001539431745186448
Valid Loss:  0.0023447838611900806
Epoch:  110  	Training Loss: 0.0019778625573962927
Test Loss:  0.0015384448925033212
Valid Loss:  0.0023431465961039066
Epoch:  111  	Training Loss: 0.001977283041924238
Test Loss:  0.0015377632807940245
Valid Loss:  0.002341681392863393
Epoch:  112  	Training Loss: 0.0019767237827181816
Test Loss:  0.001487380126491189
Valid Loss:  0.0022861086763441563
Epoch:  113  	Training Loss: 0.001921044080518186
Test Loss:  0.001471692812629044
Valid Loss:  0.002273879013955593
Epoch:  114  	Training Loss: 0.001900870236568153
Test Loss:  0.001465729670599103
Valid Loss:  0.002269347896799445
Epoch:  115  	Training Loss: 0.001891485066153109
Test Loss:  0.0014611585065722466
Valid Loss:  0.0022658463567495346
Epoch:  116  	Training Loss: 0.0018856528913602233
Test Loss:  0.0014565328601747751
Valid Loss:  0.0022623264230787754
Epoch:  117  	Training Loss: 0.0018816071096807718
Test Loss:  0.001453276490792632
Valid Loss:  0.0022594090551137924
Epoch:  118  	Training Loss: 0.00187876436393708
Test Loss:  0.0014509670436382294
Valid Loss:  0.0022567971609532833
Epoch:  119  	Training Loss: 0.0018766280263662338
Test Loss:  0.0014489558525383472
Valid Loss:  0.0022550057619810104
Epoch:  120  	Training Loss: 0.001874914625659585
Test Loss:  0.0014475048519670963
Valid Loss:  0.002254054881632328
Epoch:  121  	Training Loss: 0.0018738831859081984
Test Loss:  0.0014458616496995091
Valid Loss:  0.002252973848953843
Epoch:  122  	Training Loss: 0.0018730051815509796
Test Loss:  0.0014922635164111853
Valid Loss:  0.0022100266069173813
Epoch:  123  	Training Loss: 0.0018168759997934103
Test Loss:  0.0013926686951890588
Valid Loss:  0.0021514473482966423
Epoch:  124  	Training Loss: 0.001798936864361167
Test Loss:  0.001426899223588407
Valid Loss:  0.002158096991479397
Epoch:  125  	Training Loss: 0.0017826331313699484
Test Loss:  0.001388259930536151
Valid Loss:  0.0021289316937327385
Epoch:  126  	Training Loss: 0.001767877722159028
Test Loss:  0.001391223049722612
Valid Loss:  0.002120377030223608
Epoch:  127  	Training Loss: 0.0017534465296193957
Test Loss:  0.0013699163682758808
Valid Loss:  0.002100368496030569
Epoch:  128  	Training Loss: 0.0017393253510817885
Test Loss:  0.0013628257438540459
Valid Loss:  0.002087383298203349
Epoch:  129  	Training Loss: 0.001725431764498353
Test Loss:  0.001349844504147768
Valid Loss:  0.002071214374154806
Epoch:  130  	Training Loss: 0.001711773918941617
Test Loss:  0.0013387391809374094
Valid Loss:  0.00205634324811399
Epoch:  131  	Training Loss: 0.001698257401585579
Test Loss:  0.0013271903153508902
Valid Loss:  0.0020412674639374018
Epoch:  132  	Training Loss: 0.0016849539242684841
Test Loss:  0.001338365487754345
Valid Loss:  0.002042432315647602
Epoch:  133  	Training Loss: 0.0016824047779664397
Test Loss:  0.0013317798729985952
Valid Loss:  0.002037939615547657
Epoch:  134  	Training Loss: 0.0016804204788058996
Test Loss:  0.0013292524963617325
Valid Loss:  0.0020353638101369143
Epoch:  135  	Training Loss: 0.001678528729826212
Test Loss:  0.0013246729504317045
Valid Loss:  0.002032399643212557
Epoch:  136  	Training Loss: 0.0016767161432653666
Test Loss:  0.0013223912101238966
Valid Loss:  0.0020302501507103443
Epoch:  137  	Training Loss: 0.0016749785281717777
Test Loss:  0.0013179541565477848
Valid Loss:  0.0020275935530662537
Epoch:  138  	Training Loss: 0.0016733151860535145
Test Loss:  0.0013157331850379705
Valid Loss:  0.0020256382413208485
 28%|██▊       | 139/500 [01:41<01:58,  3.05it/s] 28%|██▊       | 141/500 [01:47<06:53,  1.15s/it] 29%|██▊       | 143/500 [01:47<04:55,  1.21it/s] 29%|██▉       | 145/500 [01:47<03:33,  1.66it/s] 29%|██▉       | 147/500 [01:47<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:48<01:58,  2.95it/s] 30%|███       | 151/500 [01:54<06:44,  1.16s/it] 31%|███       | 153/500 [01:54<04:48,  1.20it/s] 31%|███       | 155/500 [02:00<08:40,  1.51s/it] 31%|███▏      | 157/500 [02:00<06:09,  1.08s/it] 32%|███▏      | 159/500 [02:00<04:23,  1.29it/s] 32%|███▏      | 161/500 [02:06<08:19,  1.47s/it] 33%|███▎      | 163/500 [02:07<05:54,  1.05s/it] 33%|███▎      | 165/500 [02:07<04:13,  1.32it/s] 33%|███▎      | 167/500 [02:07<03:03,  1.82it/s] 34%|███▍      | 169/500 [02:07<02:13,  2.47it/s] 34%|███▍      | 171/500 [02:13<06:39,  1.21s/it] 35%|███▍      | 173/500 [02:13<04:44,  1.15it/s] 35%|███▌      | 175/500 [02:14<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:14<02:28,  2.17it/s] 36%|███▌      | 179/500 [02:14<01:49,  2.92it/s] 36%|███▌      | 181/500 [02:20<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:20<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:20<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:21<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:21<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:27<05:58,  1.16s/it] 39%|███▊      | 193/500 [02:27<04:15,  1.20it/s] 39%|███▉      | 195/500 [02:27<03:04,  1.66it/s] 39%|███▉      | 197/500 [02:27<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:27<01:39,  3.03it/s] 40%|████      | 201/500 [02:34<05:48,  1.16s/it] 41%|████      | 203/500 [02:34<04:08,  1.19it/s] 41%|████      | 205/500 [02:34<02:59,  1.65it/s]Epoch:  139  	Training Loss: 0.0016717084217816591
Test Loss:  0.0013140009250491858
Valid Loss:  0.002023687120527029
Epoch:  140  	Training Loss: 0.0016701251734048128
Test Loss:  0.0013125002151355147
Valid Loss:  0.002021686639636755
Epoch:  141  	Training Loss: 0.0016685633454471827
Test Loss:  0.0013084508245810866
Valid Loss:  0.002019141335040331
Epoch:  142  	Training Loss: 0.0016670923214405775
Test Loss:  0.0012643705122172832
Valid Loss:  0.0019915758166462183
Epoch:  143  	Training Loss: 0.001659478759393096
Test Loss:  0.0012432411313056946
Valid Loss:  0.0019793054088950157
Epoch:  144  	Training Loss: 0.0016573199536651373
Test Loss:  0.0012326915748417377
Valid Loss:  0.0019733423832803965
Epoch:  145  	Training Loss: 0.0016563364770263433
Test Loss:  0.001227296655997634
Valid Loss:  0.0019702708814293146
Epoch:  146  	Training Loss: 0.001655680127441883
Test Loss:  0.0012243568198755383
Valid Loss:  0.0019685872830450535
Epoch:  147  	Training Loss: 0.001655147410929203
Test Loss:  0.0012226823018863797
Valid Loss:  0.0019676063675433397
Epoch:  148  	Training Loss: 0.0016546647530049086
Test Loss:  0.0012216530740261078
Valid Loss:  0.0019670131150633097
Epoch:  149  	Training Loss: 0.0016542121302336454
Test Loss:  0.001220964826643467
Valid Loss:  0.001966605894267559
Epoch:  150  	Training Loss: 0.0016537837218493223
Test Loss:  0.0012203969527035952
Valid Loss:  0.0019662887789309025
Epoch:  151  	Training Loss: 0.0016533785965293646
Test Loss:  0.0012199347838759422
Valid Loss:  0.0019660419784486294
Epoch:  152  	Training Loss: 0.0016529890708625317
Test Loss:  0.001260061515495181
Valid Loss:  0.0019493266008794308
Epoch:  153  	Training Loss: 0.0016231955960392952
Test Loss:  0.0010387366637587547
Valid Loss:  0.0018534990958869457
Epoch:  154  	Training Loss: 0.0016550791915506124
Test Loss:  0.002356378361582756
Valid Loss:  0.00271607656031847
Epoch:  155  	Training Loss: 0.002118798904120922
Test Loss:  0.002544206567108631
Valid Loss:  0.0039584762416779995
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.004446923732757568
Test Loss:  0.0010073682060465217
Valid Loss:  0.001849548309110105
Epoch:  157  	Training Loss: 0.0016694304067641497
Test Loss:  0.001191536895930767
Valid Loss:  0.0019158381037414074
Epoch:  158  	Training Loss: 0.001634897431358695
Test Loss:  0.0010899591725319624
Valid Loss:  0.0018494692631065845
Epoch:  159  	Training Loss: 0.0016165226697921753
Test Loss:  0.0011873205658048391
Valid Loss:  0.0018875114619731903
Epoch:  160  	Training Loss: 0.0016052091959863901
Test Loss:  0.0011246686335653067
Valid Loss:  0.0018608972895890474
Epoch:  161  	Training Loss: 0.001606637379154563
Test Loss:  0.001184600405395031
Valid Loss:  0.0018850897904485464
Epoch:  162  	Training Loss: 0.0015997288282960653
Test Loss:  0.0011805328540503979
Valid Loss:  0.0018850027117878199
Epoch:  163  	Training Loss: 0.0015972068067640066
Test Loss:  0.0011823918903246522
Valid Loss:  0.0018863612785935402
Epoch:  164  	Training Loss: 0.0015954264672473073
Test Loss:  0.0011835125042125583
Valid Loss:  0.0018872050568461418
Epoch:  165  	Training Loss: 0.001593936001881957
Test Loss:  0.001184461172670126
Valid Loss:  0.0018876055255532265
Epoch:  166  	Training Loss: 0.0015925795305520296
Test Loss:  0.0011837189085781574
Valid Loss:  0.001887306571006775
Epoch:  167  	Training Loss: 0.001591284992173314
Test Loss:  0.0011824166867882013
Valid Loss:  0.0018867457984015346
Epoch:  168  	Training Loss: 0.0015900543658062816
Test Loss:  0.001181038562208414
Valid Loss:  0.0018861800199374557
Epoch:  169  	Training Loss: 0.0015889180358499289
Test Loss:  0.0011796094477176666
Valid Loss:  0.001885569654405117
Epoch:  170  	Training Loss: 0.0015878092963248491
Test Loss:  0.0011782476212829351
Valid Loss:  0.0018849493935704231
Epoch:  171  	Training Loss: 0.0015867159236222506
Test Loss:  0.0011769746197387576
Valid Loss:  0.001884328667074442
Epoch:  172  	Training Loss: 0.001585640013217926
Test Loss:  0.0011327997781336308
Valid Loss:  0.0018559286836534739
Epoch:  173  	Training Loss: 0.0015624666120857
Test Loss:  0.0011143460869789124
Valid Loss:  0.0018366524018347263
Epoch:  174  	Training Loss: 0.001543816993944347
Test Loss:  0.0011000391095876694
Valid Loss:  0.0018190618138760328
Epoch:  175  	Training Loss: 0.0015269640134647489
Test Loss:  0.0010868620593100786
Valid Loss:  0.0018023040611296892
Epoch:  176  	Training Loss: 0.0015114827547222376
Test Loss:  0.0010783250909298658
Valid Loss:  0.0017880257219076157
Epoch:  177  	Training Loss: 0.0014971254859119654
Test Loss:  0.0010688954498618841
Valid Loss:  0.0017743530916050076
Epoch:  178  	Training Loss: 0.0014836511109024286
Test Loss:  0.0010591992177069187
Valid Loss:  0.0017612488009035587
Epoch:  179  	Training Loss: 0.0014709983952343464
Test Loss:  0.0010495624737814069
Valid Loss:  0.0017487388104200363
Epoch:  180  	Training Loss: 0.001459193415939808
Test Loss:  0.0010433709248900414
Valid Loss:  0.0017376345349475741
Epoch:  181  	Training Loss: 0.001447940245270729
Test Loss:  0.0010361572494730353
Valid Loss:  0.0017264154739677906
Epoch:  182  	Training Loss: 0.001437172177247703
Test Loss:  0.0010324177565053105
Valid Loss:  0.0017216830747202039
Epoch:  183  	Training Loss: 0.001432469580322504
Test Loss:  0.0010294175008311868
Valid Loss:  0.0017193477833643556
Epoch:  184  	Training Loss: 0.0014307382516562939
Test Loss:  0.001026715850457549
Valid Loss:  0.0017174738459289074
Epoch:  185  	Training Loss: 0.0014291279949247837
Test Loss:  0.0010242639109492302
Valid Loss:  0.001715722493827343
Epoch:  186  	Training Loss: 0.001427647192031145
Test Loss:  0.0010221174452453852
Valid Loss:  0.0017140841810032725
Epoch:  187  	Training Loss: 0.0014262733748182654
Test Loss:  0.0010200184769928455
Valid Loss:  0.0017124783480539918
Epoch:  188  	Training Loss: 0.0014249635860323906
Test Loss:  0.001018146751448512
Valid Loss:  0.001711040735244751
Epoch:  189  	Training Loss: 0.001423822483047843
Test Loss:  0.0010163014521822333
Valid Loss:  0.001709622680209577
Epoch:  190  	Training Loss: 0.0014227028004825115
Test Loss:  0.0010145747801288962
Valid Loss:  0.001708292867988348
Epoch:  191  	Training Loss: 0.0014217098942026496
Test Loss:  0.0010131474118679762
Valid Loss:  0.0017070998437702656
Epoch:  192  	Training Loss: 0.0014208138454705477
Test Loss:  0.0010152374161407351
Valid Loss:  0.001708106603473425
Epoch:  193  	Training Loss: 0.0014207467902451754
Test Loss:  0.0010167513974010944
Valid Loss:  0.0017088177846744657
Epoch:  194  	Training Loss: 0.0014206990599632263
Test Loss:  0.0010178487282246351
Valid Loss:  0.001709313248284161
Epoch:  195  	Training Loss: 0.001420663553290069
Test Loss:  0.0010186078725382686
Valid Loss:  0.001709643518552184
Epoch:  196  	Training Loss: 0.0014206401538103819
Test Loss:  0.001019121496938169
Valid Loss:  0.0017098580719903111
Epoch:  197  	Training Loss: 0.0014206237392500043
Test Loss:  0.0010195032227784395
Valid Loss:  0.0017099995166063309
Epoch:  198  	Training Loss: 0.0014206081395968795
Test Loss:  0.0010197923984378576
Valid Loss:  0.0017100893892347813
Epoch:  199  	Training Loss: 0.0014205933548510075
Test Loss:  0.0010200097458437085
Valid Loss:  0.001710142008960247
Epoch:  200  	Training Loss: 0.0014205814804881811
Test Loss:  0.0010201376862823963
Valid Loss:  0.0017101597040891647
Epoch:  201  	Training Loss: 0.0014205724000930786
Test Loss:  0.0010202451376244426
Valid Loss:  0.0017101631965488195
Epoch:  202  	Training Loss: 0.0014205633196979761
Test Loss:  0.0010203461861237884
Valid Loss:  0.0017100905533879995
Epoch:  203  	Training Loss: 0.001420473912730813
Test Loss:  0.001020444673486054
Valid Loss:  0.0017100386321544647
Epoch:  204  	Training Loss: 0.0014203930040821433
Test Loss:  0.0010205315193161368
Valid Loss:  0.0017099831020459533
Epoch:  205  	Training Loss: 0.0014203202445060015
Test Loss:  0.0010206035804003477
Valid Loss:  0.0017099236138164997
Epoch:  206  	Training Loss: 0.0014202604070305824
Test Loss:  0.0010206622537225485
 41%|████▏     | 207/500 [02:34<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:34<01:36,  3.02it/s] 42%|████▏     | 211/500 [02:40<05:33,  1.15s/it] 43%|████▎     | 213/500 [02:40<03:58,  1.21it/s] 43%|████▎     | 215/500 [02:41<02:51,  1.67it/s] 43%|████▎     | 217/500 [02:41<02:04,  2.27it/s] 44%|████▍     | 219/500 [02:41<01:31,  3.06it/s] 44%|████▍     | 221/500 [02:47<05:23,  1.16s/it] 45%|████▍     | 223/500 [02:47<03:50,  1.20it/s] 45%|████▌     | 225/500 [02:47<02:46,  1.66it/s] 45%|████▌     | 227/500 [02:47<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:48<01:29,  3.04it/s] 46%|████▌     | 231/500 [02:54<05:13,  1.16s/it] 47%|████▋     | 233/500 [02:54<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:54<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:54<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:54<01:26,  3.02it/s] 48%|████▊     | 241/500 [03:01<05:02,  1.17s/it] 49%|████▊     | 243/500 [03:01<03:35,  1.19it/s] 49%|████▉     | 245/500 [03:01<02:34,  1.65it/s] 49%|████▉     | 247/500 [03:01<01:52,  2.24it/s] 50%|████▉     | 249/500 [03:01<01:23,  3.00it/s] 50%|█████     | 251/500 [03:07<04:53,  1.18s/it] 51%|█████     | 253/500 [03:08<03:28,  1.18it/s] 51%|█████     | 255/500 [03:08<02:29,  1.63it/s] 51%|█████▏    | 257/500 [03:08<01:48,  2.23it/s] 52%|█████▏    | 259/500 [03:08<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:14<04:37,  1.16s/it] 53%|█████▎    | 263/500 [03:14<03:17,  1.20it/s] 53%|█████▎    | 265/500 [03:14<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:15<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:15<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:21<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:21<03:10,  1.19it/s]Valid Loss:  0.0017098613316193223
Epoch:  207  	Training Loss: 0.0014202074380591512
Test Loss:  0.001020696829073131
Valid Loss:  0.001709798234514892
Epoch:  208  	Training Loss: 0.001420165179297328
Test Loss:  0.0010207132436335087
Valid Loss:  0.0017097389791160822
Epoch:  209  	Training Loss: 0.0014201313024386764
Test Loss:  0.0010207367595285177
Valid Loss:  0.001709687290713191
Epoch:  210  	Training Loss: 0.001420099986717105
Test Loss:  0.001020729192532599
Valid Loss:  0.0017096404917538166
Epoch:  211  	Training Loss: 0.0014200785662978888
Test Loss:  0.0010207259329035878
Valid Loss:  0.0017095981165766716
Epoch:  212  	Training Loss: 0.0014200570294633508
Test Loss:  0.0010395478457212448
Valid Loss:  0.00170988985337317
Epoch:  213  	Training Loss: 0.0014138729311525822
Test Loss:  0.0010359580628573895
Valid Loss:  0.0017026254208758473
Epoch:  214  	Training Loss: 0.0014106498565524817
Test Loss:  0.0010307049378752708
Valid Loss:  0.0016962308436632156
Epoch:  215  	Training Loss: 0.001408212585374713
Test Loss:  0.0010285490425303578
Valid Loss:  0.001692210673354566
Epoch:  216  	Training Loss: 0.001406382885761559
Test Loss:  0.0010278478730469942
Valid Loss:  0.001689074095338583
Epoch:  217  	Training Loss: 0.0014049308374524117
Test Loss:  0.0010258386610075831
Valid Loss:  0.001686052419245243
Epoch:  218  	Training Loss: 0.0014039321104064584
Test Loss:  0.0010249270126223564
Valid Loss:  0.0016838586889207363
Epoch:  219  	Training Loss: 0.0014031361788511276
Test Loss:  0.0010241026757284999
Valid Loss:  0.0016820055898278952
Epoch:  220  	Training Loss: 0.0014025263953953981
Test Loss:  0.0010228395694866776
Valid Loss:  0.0016804552869871259
Epoch:  221  	Training Loss: 0.001402081223204732
Test Loss:  0.0010227863676846027
Valid Loss:  0.00167950545437634
Epoch:  222  	Training Loss: 0.0014016516506671906
Test Loss:  0.0010227563325315714
Valid Loss:  0.0016795003321021795
Epoch:  223  	Training Loss: 0.0014015019405633211
Test Loss:  0.0010227386374026537
Valid Loss:  0.0016795056872069836
Epoch:  224  	Training Loss: 0.0014013608451932669
Test Loss:  0.001022703479975462
Valid Loss:  0.0016795075498521328
Epoch:  225  	Training Loss: 0.0014012226602062583
Test Loss:  0.0010226663434877992
Valid Loss:  0.001679510110989213
Epoch:  226  	Training Loss: 0.0014010966988280416
Test Loss:  0.0010226208250969648
Valid Loss:  0.0016795143019407988
Epoch:  227  	Training Loss: 0.0014009731821715832
Test Loss:  0.0010225656442344189
Valid Loss:  0.0016795126721262932
Epoch:  228  	Training Loss: 0.0014008559519425035
Test Loss:  0.0010225018486380577
Valid Loss:  0.0016795083647593856
Epoch:  229  	Training Loss: 0.0014007436111569405
Test Loss:  0.0010224306024610996
Valid Loss:  0.0016794990515336394
Epoch:  230  	Training Loss: 0.0014006358105689287
Test Loss:  0.00102235225494951
Valid Loss:  0.0016794846160337329
Epoch:  231  	Training Loss: 0.0014005316188558936
Test Loss:  0.0010222666896879673
Valid Loss:  0.001679467735812068
Epoch:  232  	Training Loss: 0.0014004302211105824
Test Loss:  0.0010004766518250108
Valid Loss:  0.001662032213062048
Epoch:  233  	Training Loss: 0.0013871812261641026
Test Loss:  0.0009843853767961264
Valid Loss:  0.0016480956692248583
Epoch:  234  	Training Loss: 0.001375412568449974
Test Loss:  0.000971446861512959
Valid Loss:  0.0016365230549126863
Epoch:  235  	Training Loss: 0.0013650343753397465
Test Loss:  0.0009603667422197759
Valid Loss:  0.0016261027194559574
Epoch:  236  	Training Loss: 0.0013556336052715778
Test Loss:  0.0009503850596956909
Valid Loss:  0.0016162896063178778
Epoch:  237  	Training Loss: 0.0013468130491673946
Test Loss:  0.0009419950074516237
Valid Loss:  0.0016070771962404251
Epoch:  238  	Training Loss: 0.0013384615303948522
Test Loss:  0.0009340128162875772
Valid Loss:  0.0015981908654794097
Epoch:  239  	Training Loss: 0.001330612343735993
Test Loss:  0.0009268285939469934
Valid Loss:  0.001589863677509129
Epoch:  240  	Training Loss: 0.0013232275377959013
Test Loss:  0.0009203711524605751
Valid Loss:  0.0015818062238395214
Epoch:  241  	Training Loss: 0.0013160549569875002
Test Loss:  0.0009146628435701132
Valid Loss:  0.0015747356228530407
Epoch:  242  	Training Loss: 0.0013091687578707933
Test Loss:  0.0009296705247834325
Valid Loss:  0.0015743381809443235
Epoch:  243  	Training Loss: 0.0013020187616348267
Test Loss:  0.0009280905942432582
Valid Loss:  0.0015681461663916707
Epoch:  244  	Training Loss: 0.0012971735559403896
Test Loss:  0.0009235205943696201
Valid Loss:  0.0015614102594554424
Epoch:  245  	Training Loss: 0.0012932985555380583
Test Loss:  0.0009195425664074719
Valid Loss:  0.0015554782003164291
Epoch:  246  	Training Loss: 0.0012899484718218446
Test Loss:  0.0009159620385617018
Valid Loss:  0.0015501842135563493
Epoch:  247  	Training Loss: 0.0012870170176029205
Test Loss:  0.0009126191143877804
Valid Loss:  0.0015455330722033978
Epoch:  248  	Training Loss: 0.0012845409801229835
Test Loss:  0.0009101451141759753
Valid Loss:  0.001541384495794773
Epoch:  249  	Training Loss: 0.0012822303688153625
Test Loss:  0.0009063027100637555
Valid Loss:  0.0015373288188129663
Epoch:  250  	Training Loss: 0.001280162250623107
Test Loss:  0.0009044975740835071
Valid Loss:  0.0015346065629273653
Epoch:  251  	Training Loss: 0.0012781748082488775
Test Loss:  0.0009030506480485201
Valid Loss:  0.0015321417013183236
Epoch:  252  	Training Loss: 0.0012763056438416243
Test Loss:  0.0008986209286376834
Valid Loss:  0.0015281096566468477
Epoch:  253  	Training Loss: 0.0012735524214804173
Test Loss:  0.0008947583264671266
Valid Loss:  0.001524411141872406
Epoch:  254  	Training Loss: 0.0012711614836007357
Test Loss:  0.0008919266401790082
Valid Loss:  0.0015217470936477184
Epoch:  255  	Training Loss: 0.001269419095478952
Test Loss:  0.000889582559466362
Valid Loss:  0.0015194176230579615
Epoch:  256  	Training Loss: 0.001267903600819409
Test Loss:  0.0008877093205228448
Valid Loss:  0.0015175065491348505
Epoch:  257  	Training Loss: 0.0012665285030379891
Test Loss:  0.000886087364051491
Valid Loss:  0.0015159243484959006
Epoch:  258  	Training Loss: 0.0012653068406507373
Test Loss:  0.0008848494617268443
Valid Loss:  0.0015146824298426509
Epoch:  259  	Training Loss: 0.0012642263900488615
Test Loss:  0.0008839003276079893
Valid Loss:  0.0015135470312088728
Epoch:  260  	Training Loss: 0.001263227080926299
Test Loss:  0.0008831435698084533
Valid Loss:  0.0015125760110095143
Epoch:  261  	Training Loss: 0.0012622883077710867
Test Loss:  0.000882504100445658
Valid Loss:  0.001511701731942594
Epoch:  262  	Training Loss: 0.0012613919097930193
Test Loss:  0.0008936994126997888
Valid Loss:  0.0015165172517299652
Epoch:  263  	Training Loss: 0.001259749522432685
Test Loss:  0.0008982151048257947
Valid Loss:  0.0015191975980997086
Epoch:  264  	Training Loss: 0.0012588412500917912
Test Loss:  0.000900705112144351
Valid Loss:  0.0015209004050120711
Epoch:  265  	Training Loss: 0.0012581916525959969
Test Loss:  0.000902029627468437
Valid Loss:  0.001521967351436615
Epoch:  266  	Training Loss: 0.0012576805893331766
Test Loss:  0.0009026984916999936
Valid Loss:  0.0015226334799081087
Epoch:  267  	Training Loss: 0.0012572512496262789
Test Loss:  0.0009030018700286746
Valid Loss:  0.001523016719147563
Epoch:  268  	Training Loss: 0.0012568748788908124
Test Loss:  0.00090309779625386
Valid Loss:  0.0015232001896947622
Epoch:  269  	Training Loss: 0.001256533432751894
Test Loss:  0.0009030774817802012
Valid Loss:  0.0015232348814606667
Epoch:  270  	Training Loss: 0.0012562153860926628
Test Loss:  0.0009029958164319396
Valid Loss:  0.0015231823781505227
Epoch:  271  	Training Loss: 0.0012559155002236366
Test Loss:  0.0009028789354488254
Valid Loss:  0.0015230563003569841
Epoch:  272  	Training Loss: 0.001255626673810184
Test Loss:  0.0008840906666591763
Valid Loss:  0.0015106976497918367
Epoch:  273  	Training Loss: 0.0012474614195525646
Test Loss:  0.0008722671773284674
Valid Loss:  0.0015028626658022404
Epoch:  274  	Training Loss: 0.001240844838321209
Test Loss:  0.0008634462137706578
Valid Loss:  0.001496878918260336
 55%|█████▌    | 275/500 [03:21<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:21<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:21<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:28<04:14,  1.16s/it] 57%|█████▋    | 283/500 [03:28<03:00,  1.20it/s] 57%|█████▋    | 285/500 [03:28<02:09,  1.66it/s] 57%|█████▋    | 287/500 [03:28<01:34,  2.26it/s] 58%|█████▊    | 289/500 [03:28<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:34<04:03,  1.17s/it] 59%|█████▊    | 293/500 [03:35<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:35<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:35<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:35<01:06,  3.02it/s] 60%|██████    | 301/500 [03:41<03:52,  1.17s/it] 61%|██████    | 303/500 [03:41<02:46,  1.18it/s] 61%|██████    | 305/500 [03:42<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:42<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:42<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:48<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:48<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:48<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:48<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:49<01:00,  3.02it/s] 64%|██████▍   | 321/500 [03:55<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:55<02:30,  1.17it/s] 65%|██████▌   | 325/500 [03:55<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:55<01:18,  2.22it/s] 66%|██████▌   | 329/500 [03:56<00:57,  2.98it/s] 66%|██████▌   | 331/500 [04:02<03:18,  1.17s/it] 67%|██████▋   | 333/500 [04:02<02:20,  1.19it/s] 67%|██████▋   | 335/500 [04:02<01:40,  1.64it/s] 67%|██████▋   | 337/500 [04:02<01:12,  2.24it/s] 68%|██████▊   | 339/500 [04:02<00:53,  3.02it/s] 68%|██████▊   | 341/500 [04:09<03:05,  1.17s/it]Epoch:  275  	Training Loss: 0.0012352081248536706
Test Loss:  0.0008562040165998042
Valid Loss:  0.0014918810920789838
Epoch:  276  	Training Loss: 0.0012302249670028687
Test Loss:  0.0008499693358317018
Valid Loss:  0.001487528090365231
Epoch:  277  	Training Loss: 0.0012257941998541355
Test Loss:  0.0008447951404377818
Valid Loss:  0.001483590924181044
Epoch:  278  	Training Loss: 0.0012217671610414982
Test Loss:  0.0008403066312894225
Valid Loss:  0.001480126054957509
Epoch:  279  	Training Loss: 0.0012183277867734432
Test Loss:  0.0008360169013030827
Valid Loss:  0.001476805191487074
Epoch:  280  	Training Loss: 0.0012151104165241122
Test Loss:  0.0008321906207129359
Valid Loss:  0.00147363287396729
Epoch:  281  	Training Loss: 0.0012121221516281366
Test Loss:  0.0008291836129501462
Valid Loss:  0.001471053808927536
Epoch:  282  	Training Loss: 0.0012093961704522371
Test Loss:  0.0008153825183399022
Valid Loss:  0.0014573851367458701
Epoch:  283  	Training Loss: 0.0012024566531181335
Test Loss:  0.0008080960251390934
Valid Loss:  0.0014496550429612398
Epoch:  284  	Training Loss: 0.001198548125103116
Test Loss:  0.0008037754450924695
Valid Loss:  0.001445127883926034
Epoch:  285  	Training Loss: 0.0011959840776398778
Test Loss:  0.0008021246176213026
Valid Loss:  0.0014425731496885419
Epoch:  286  	Training Loss: 0.00119445426389575
Test Loss:  0.0008015974308364093
Valid Loss:  0.0014410462463274598
Epoch:  287  	Training Loss: 0.0011933539062738419
Test Loss:  0.000801674323156476
Valid Loss:  0.0014400561340153217
Epoch:  288  	Training Loss: 0.00119260442443192
Test Loss:  0.0008022962138056755
Valid Loss:  0.0014397925697267056
Epoch:  289  	Training Loss: 0.0011921338737010956
Test Loss:  0.0008034529164433479
Valid Loss:  0.001440170919522643
Epoch:  290  	Training Loss: 0.0011918407399207354
Test Loss:  0.0008045819122344255
Valid Loss:  0.001440569874830544
Epoch:  291  	Training Loss: 0.0011916094226762652
Test Loss:  0.0008057374507188797
Valid Loss:  0.0014409897848963737
Epoch:  292  	Training Loss: 0.0011914214119315147
Test Loss:  0.0008085875888355076
Valid Loss:  0.0014423708198592067
Epoch:  293  	Training Loss: 0.001191096380352974
Test Loss:  0.0008007939904928207
Valid Loss:  0.0014375923201441765
Epoch:  294  	Training Loss: 0.0011908924207091331
Test Loss:  0.0008086764719337225
Valid Loss:  0.0014412906020879745
Epoch:  295  	Training Loss: 0.0011901662219315767
Test Loss:  0.0008099052938632667
Valid Loss:  0.0014415411278605461
Epoch:  296  	Training Loss: 0.0011898011434823275
Test Loss:  0.0008104664739221334
Valid Loss:  0.001441443688236177
Epoch:  297  	Training Loss: 0.0011894057970494032
Test Loss:  0.0008107480243779719
Valid Loss:  0.0014412153977900743
Epoch:  298  	Training Loss: 0.0011889419984072447
Test Loss:  0.0008132845396175981
Valid Loss:  0.0014422269305214286
Epoch:  299  	Training Loss: 0.0011883755214512348
Test Loss:  0.0008119873236864805
Valid Loss:  0.0014409574214369059
Epoch:  300  	Training Loss: 0.001187565503641963
Test Loss:  0.0008137348340824246
Valid Loss:  0.0014412362361326814
Epoch:  301  	Training Loss: 0.0011865608394145966
Test Loss:  0.0008118774276226759
Valid Loss:  0.0014394109603017569
Epoch:  302  	Training Loss: 0.001185231376439333
Test Loss:  0.0008155907271429896
Valid Loss:  0.00144152098800987
Epoch:  303  	Training Loss: 0.0011850704904645681
Test Loss:  0.0008154771057888865
Valid Loss:  0.0014415059704333544
Epoch:  304  	Training Loss: 0.0011849571019411087
Test Loss:  0.0008153244853019714
Valid Loss:  0.0014414639445021749
Epoch:  305  	Training Loss: 0.0011848550057038665
Test Loss:  0.0008151864167302847
Valid Loss:  0.0014414199395105243
Epoch:  306  	Training Loss: 0.0011847608257085085
Test Loss:  0.000815057021100074
Valid Loss:  0.0014413747703656554
Epoch:  307  	Training Loss: 0.0011846793349832296
Test Loss:  0.0008149408968165517
Valid Loss:  0.0014413343742489815
Epoch:  308  	Training Loss: 0.0011846073903143406
Test Loss:  0.0008148347260430455
Valid Loss:  0.0014412931632250547
Epoch:  309  	Training Loss: 0.0011845428962260485
Test Loss:  0.0008147331536747515
Valid Loss:  0.0014412552118301392
Epoch:  310  	Training Loss: 0.0011844889959320426
Test Loss:  0.0008146393811330199
Valid Loss:  0.0014412279706448317
Epoch:  311  	Training Loss: 0.0011844417313113809
Test Loss:  0.0008145584724843502
Valid Loss:  0.001441210275515914
Epoch:  312  	Training Loss: 0.0011844041291624308
Test Loss:  0.0008213315741159022
Valid Loss:  0.001439225161448121
Epoch:  313  	Training Loss: 0.0011782676447182894
Test Loss:  0.0008262494811788201
Valid Loss:  0.0014374526217579842
Epoch:  314  	Training Loss: 0.0011741598136723042
Test Loss:  0.0008299871115013957
Valid Loss:  0.001435798010788858
Epoch:  315  	Training Loss: 0.0011711285915225744
Test Loss:  0.0008323269430547953
Valid Loss:  0.0014343932271003723
Epoch:  316  	Training Loss: 0.001168836490251124
Test Loss:  0.0008343460503965616
Valid Loss:  0.0014331205748021603
Epoch:  317  	Training Loss: 0.0011668921215459704
Test Loss:  0.0008354735909961164
Valid Loss:  0.0014316326705738902
Epoch:  318  	Training Loss: 0.001165230991318822
Test Loss:  0.0008354884339496493
Valid Loss:  0.0014299529138952494
Epoch:  319  	Training Loss: 0.0011639033909887075
Test Loss:  0.0008355659083463252
Valid Loss:  0.0014282879419624805
Epoch:  320  	Training Loss: 0.0011626570485532284
Test Loss:  0.00083509786054492
Valid Loss:  0.0014266325160861015
Epoch:  321  	Training Loss: 0.0011615206021815538
Test Loss:  0.0008342150831595063
Valid Loss:  0.0014249470550566912
Epoch:  322  	Training Loss: 0.0011605031322687864
Test Loss:  0.0008334123995155096
Valid Loss:  0.0014244173653423786
Epoch:  323  	Training Loss: 0.0011603960301727057
Test Loss:  0.000832659425213933
Valid Loss:  0.001423925394192338
Epoch:  324  	Training Loss: 0.0011602998711168766
Test Loss:  0.0008319569169543684
Valid Loss:  0.0014234669506549835
Epoch:  325  	Training Loss: 0.0011602111626416445
Test Loss:  0.0008312965510413051
Valid Loss:  0.0014230402885004878
Epoch:  326  	Training Loss: 0.0011601262958720326
Test Loss:  0.0008306775125674903
Valid Loss:  0.0014226422645151615
Epoch:  327  	Training Loss: 0.0011600492289289832
Test Loss:  0.0008300929330289364
Valid Loss:  0.0014222650788724422
Epoch:  328  	Training Loss: 0.0011599764693528414
Test Loss:  0.0008295414736494422
Valid Loss:  0.0014219097793102264
Epoch:  329  	Training Loss: 0.0011599077843129635
Test Loss:  0.0008290201658383012
Valid Loss:  0.0014215768314898014
Epoch:  330  	Training Loss: 0.0011598418932408094
Test Loss:  0.0008285272633656859
Valid Loss:  0.0014212618116289377
Epoch:  331  	Training Loss: 0.0011597792617976665
Test Loss:  0.00082806107820943
Valid Loss:  0.00142096565105021
Epoch:  332  	Training Loss: 0.0011597189586609602
Test Loss:  0.0008238028967753053
Valid Loss:  0.001418492873199284
Epoch:  333  	Training Loss: 0.0011592931114137173
Test Loss:  0.0008202395401895046
Valid Loss:  0.0014164532767608762
Epoch:  334  	Training Loss: 0.0011589662171900272
Test Loss:  0.000817246560472995
Valid Loss:  0.001414765021763742
Epoch:  335  	Training Loss: 0.0011587099870666862
Test Loss:  0.0008147257613018155
Valid Loss:  0.0014133604709059
Epoch:  336  	Training Loss: 0.001158504281193018
Test Loss:  0.0008125935564748943
Valid Loss:  0.0014121877029538155
Epoch:  337  	Training Loss: 0.0011583357118070126
Test Loss:  0.0008107878966256976
Valid Loss:  0.0014112091157585382
Epoch:  338  	Training Loss: 0.0011581943836063147
Test Loss:  0.0008092501666396856
Valid Loss:  0.0014103888534009457
Epoch:  339  	Training Loss: 0.0011580719146877527
Test Loss:  0.0008079381659626961
Valid Loss:  0.0014096994418650866
Epoch:  340  	Training Loss: 0.0011579645797610283
Test Loss:  0.0008068146998994052
Valid Loss:  0.001409119926393032
Epoch:  341  	Training Loss: 0.0011578688863664865
Test Loss:  0.0008058488019742072
Valid Loss:  0.0014086298178881407
Epoch:  342  	Training Loss: 0.0011577815748751163
Test Loss:  0.0008114873198792338
Valid Loss:  0.0014060820685699582
Epoch:  343  	Training Loss: 0.0011531786294654012
Test Loss:   69%|██████▊   | 343/500 [04:09<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:09<01:34,  1.65it/s] 69%|██████▉   | 347/500 [04:09<01:08,  2.25it/s] 70%|██████▉   | 349/500 [04:09<00:49,  3.02it/s] 70%|███████   | 351/500 [04:15<02:54,  1.17s/it] 71%|███████   | 353/500 [04:15<02:03,  1.19it/s] 71%|███████   | 355/500 [04:16<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:16<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:16<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:22<02:40,  1.16s/it] 73%|███████▎  | 363/500 [04:22<01:53,  1.21it/s] 73%|███████▎  | 365/500 [04:22<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:23<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:23<00:44,  2.93it/s] 74%|███████▍  | 371/500 [04:29<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:29<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:29<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:29<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:30<00:41,  2.95it/s] 76%|███████▌  | 381/500 [04:36<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:36<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:36<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:36<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:36<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:43<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:43<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:43<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:43<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:43<00:33,  3.02it/s] 80%|████████  | 401/500 [04:49<01:56,  1.18s/it] 81%|████████  | 403/500 [04:50<01:22,  1.18it/s] 81%|████████  | 405/500 [04:50<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:50<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:50<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:56<01:44,  1.18s/it]0.000808459531981498
Valid Loss:  0.0013999565271660686
Epoch:  344  	Training Loss: 0.0011492789490148425
Test Loss:  0.0008056143415160477
Valid Loss:  0.0013947933912277222
Epoch:  345  	Training Loss: 0.0011461350368335843
Test Loss:  0.0008044952992349863
Valid Loss:  0.001390532124787569
Epoch:  346  	Training Loss: 0.0011432520113885403
Test Loss:  0.0008026913274079561
Valid Loss:  0.0013863933272659779
Epoch:  347  	Training Loss: 0.0011406909907236695
Test Loss:  0.0008010040037333965
Valid Loss:  0.0013826638460159302
Epoch:  348  	Training Loss: 0.0011383972596377134
Test Loss:  0.0007993274484761059
Valid Loss:  0.0013792705722153187
Epoch:  349  	Training Loss: 0.0011363293742761016
Test Loss:  0.0007969725411385298
Valid Loss:  0.0013761826558038592
Epoch:  350  	Training Loss: 0.0011345960665494204
Test Loss:  0.0007962653762660921
Valid Loss:  0.0013739862479269505
Epoch:  351  	Training Loss: 0.0011329376138746738
Test Loss:  0.0007956443005241454
Valid Loss:  0.0013718667905777693
Epoch:  352  	Training Loss: 0.0011313988361507654
Test Loss:  0.0007927407859824598
Valid Loss:  0.0013698203256353736
Epoch:  353  	Training Loss: 0.0011291960254311562
Test Loss:  0.0007899879710748792
Valid Loss:  0.0013678804971277714
Epoch:  354  	Training Loss: 0.0011271347757428885
Test Loss:  0.0007873722352087498
Valid Loss:  0.001365974429063499
Epoch:  355  	Training Loss: 0.001125187030993402
Test Loss:  0.0007849118555895984
Valid Loss:  0.0013641160912811756
Epoch:  356  	Training Loss: 0.001123401103541255
Test Loss:  0.0007826784276403487
Valid Loss:  0.0013624249259009957
Epoch:  357  	Training Loss: 0.001121816225349903
Test Loss:  0.0007804763736203313
Valid Loss:  0.0013607817236334085
Epoch:  358  	Training Loss: 0.0011202641762793064
Test Loss:  0.0007784225163049996
Valid Loss:  0.0013592209434136748
Epoch:  359  	Training Loss: 0.0011187591589987278
Test Loss:  0.000776682689320296
Valid Loss:  0.0013578487560153008
Epoch:  360  	Training Loss: 0.001117355190217495
Test Loss:  0.0007750334916636348
Valid Loss:  0.0013567202258855104
Epoch:  361  	Training Loss: 0.001115980208851397
Test Loss:  0.000773416250012815
Valid Loss:  0.001355613931082189
Epoch:  362  	Training Loss: 0.0011146755423396826
Test Loss:  0.0007729459321126342
Valid Loss:  0.001355498330667615
Epoch:  363  	Training Loss: 0.001114573678933084
Test Loss:  0.0007724985480308533
Valid Loss:  0.0013553875032812357
Epoch:  364  	Training Loss: 0.0011144827585667372
Test Loss:  0.0007720732828602195
Valid Loss:  0.0013552849413827062
Epoch:  365  	Training Loss: 0.0011144024319946766
Test Loss:  0.0007716730469837785
Valid Loss:  0.0013551899464800954
Epoch:  366  	Training Loss: 0.0011143304873257875
Test Loss:  0.0007712969672866166
Valid Loss:  0.0013551019364967942
Epoch:  367  	Training Loss: 0.0011142670409753919
Test Loss:  0.000770944869145751
Valid Loss:  0.0013550231233239174
Epoch:  368  	Training Loss: 0.001114210463128984
Test Loss:  0.0007706136675551534
Valid Loss:  0.0013549489667639136
Epoch:  369  	Training Loss: 0.0011141598224639893
Test Loss:  0.0007703040027990937
Valid Loss:  0.001354882842861116
Epoch:  370  	Training Loss: 0.0011141153518110514
Test Loss:  0.0007700137794017792
Valid Loss:  0.0013548205606639385
Epoch:  371  	Training Loss: 0.0011140760034322739
Test Loss:  0.0007697410765103996
Valid Loss:  0.0013547646813094616
Epoch:  372  	Training Loss: 0.0011140407295897603
Test Loss:  0.0007868397515267134
Valid Loss:  0.0013542115921154618
Epoch:  373  	Training Loss: 0.0011090594343841076
Test Loss:  0.0007877309108152986
Valid Loss:  0.0013505241367965937
Epoch:  374  	Training Loss: 0.001106401439756155
Test Loss:  0.0007857228629291058
Valid Loss:  0.0013463122304528952
Epoch:  375  	Training Loss: 0.0011042485712096095
Test Loss:  0.0007833173149265349
Valid Loss:  0.0013423345517367125
Epoch:  376  	Training Loss: 0.0011024163104593754
Test Loss:  0.0007804211927577853
Valid Loss:  0.0013386141508817673
Epoch:  377  	Training Loss: 0.0011008939472958446
Test Loss:  0.000778396031819284
Valid Loss:  0.0013353670947253704
Epoch:  378  	Training Loss: 0.0010995129123330116
Test Loss:  0.0007763351313769817
Valid Loss:  0.0013323903549462557
Epoch:  379  	Training Loss: 0.0010983203537762165
Test Loss:  0.0007745665498077869
Valid Loss:  0.0013297372497618198
Epoch:  380  	Training Loss: 0.0010972641175612807
Test Loss:  0.000772639294154942
Valid Loss:  0.0013273048680275679
Epoch:  381  	Training Loss: 0.0010963988024741411
Test Loss:  0.000771266408264637
Valid Loss:  0.0013251849450170994
Epoch:  382  	Training Loss: 0.0010955840116366744
Test Loss:  0.0007594421040266752
Valid Loss:  0.0013166884891688824
Epoch:  383  	Training Loss: 0.0010890892008319497
Test Loss:  0.000749496859498322
Valid Loss:  0.0013097419869154692
Epoch:  384  	Training Loss: 0.001083642477169633
Test Loss:  0.0007406300865113735
Valid Loss:  0.0013036348391324282
Epoch:  385  	Training Loss: 0.0010786066995933652
Test Loss:  0.00073283351957798
Valid Loss:  0.0012982221087440848
Epoch:  386  	Training Loss: 0.0010742014274001122
Test Loss:  0.0007258227560669184
Valid Loss:  0.001293310197070241
Epoch:  387  	Training Loss: 0.0010701885912567377
Test Loss:  0.0007194731151685119
Valid Loss:  0.0012888213386759162
Epoch:  388  	Training Loss: 0.0010664921719580889
Test Loss:  0.0007139066583476961
Valid Loss:  0.001284710830077529
Epoch:  389  	Training Loss: 0.001063111238181591
Test Loss:  0.0007088631391525269
Valid Loss:  0.0012808487517759204
Epoch:  390  	Training Loss: 0.0010599424131214619
Test Loss:  0.0007044257363304496
Valid Loss:  0.0012774050701409578
Epoch:  391  	Training Loss: 0.001057109097018838
Test Loss:  0.0007002479396760464
Valid Loss:  0.0012741312384605408
Epoch:  392  	Training Loss: 0.001054361229762435
Test Loss:  0.0007327076746150851
Valid Loss:  0.0012838083785027266
Epoch:  393  	Training Loss: 0.001049270504154265
Test Loss:  0.0007196619408205152
Valid Loss:  0.0012731708120554686
Epoch:  394  	Training Loss: 0.0010463485959917307
Test Loss:  0.0007302190642803907
Valid Loss:  0.0012750568566843867
Epoch:  395  	Training Loss: 0.00104440376162529
Test Loss:  0.000729601364582777
Valid Loss:  0.0012725255219265819
Epoch:  396  	Training Loss: 0.00104286998976022
Test Loss:  0.0007291077636182308
Valid Loss:  0.0012701760279014707
Epoch:  397  	Training Loss: 0.0010414235293865204
Test Loss:  0.0007279678829945624
Valid Loss:  0.0012678238563239574
Epoch:  398  	Training Loss: 0.001040071016177535
Test Loss:  0.0007274654344655573
Valid Loss:  0.0012657766928896308
Epoch:  399  	Training Loss: 0.0010387818329036236
Test Loss:  0.0007263298612087965
Valid Loss:  0.0012636916944757104
Epoch:  400  	Training Loss: 0.0010375839192420244
Test Loss:  0.0007258423720486462
Valid Loss:  0.0012618759647011757
Epoch:  401  	Training Loss: 0.0010364247718825936
Test Loss:  0.0007240689010359347
Valid Loss:  0.0012599272886291146
Epoch:  402  	Training Loss: 0.001035450492054224
Test Loss:  0.0007267419714480639
Valid Loss:  0.0012607394019141793
Epoch:  403  	Training Loss: 0.0010337017010897398
Test Loss:  0.0007285791216418147
Valid Loss:  0.0012610293924808502
Epoch:  404  	Training Loss: 0.001031970721669495
Test Loss:  0.0007298671989701688
Valid Loss:  0.0012605711817741394
Epoch:  405  	Training Loss: 0.0010300823487341404
Test Loss:  0.0007306894985958934
Valid Loss:  0.0012595702428370714
Epoch:  406  	Training Loss: 0.0010280153946951032
Test Loss:  0.0007311978843063116
Valid Loss:  0.0012582845520228148
Epoch:  407  	Training Loss: 0.0010258605470880866
Test Loss:  0.0007313326350413263
Valid Loss:  0.0012567017693072557
Epoch:  408  	Training Loss: 0.0010236883535981178
Test Loss:  0.0007312300149351358
Valid Loss:  0.001254800707101822
Epoch:  409  	Training Loss: 0.0010213686618953943
Test Loss:  0.0007308432832360268
Valid Loss:  0.0012526694918051362
Epoch:  410  	Training Loss: 0.0010186946019530296
Test Loss:  0.0007299413555301726
Valid Loss:  0.0012500541051849723
Epoch:  411  	Training Loss: 0.001015590038150549
Test Loss:  0.0007289263885468245
Valid Loss:  0.0012470633955672383
 83%|████████▎ | 413/500 [04:56<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:57<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:57<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:57<00:27,  2.99it/s] 84%|████████▍ | 421/500 [05:03<01:31,  1.16s/it] 85%|████████▍ | 423/500 [05:03<01:04,  1.20it/s] 85%|████████▌ | 425/500 [05:03<00:45,  1.66it/s] 85%|████████▌ | 427/500 [05:03<00:32,  2.26it/s] 86%|████████▌ | 429/500 [05:04<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:10<01:20,  1.16s/it] 87%|████████▋ | 433/500 [05:10<00:55,  1.20it/s] 87%|████████▋ | 435/500 [05:10<00:39,  1.66it/s] 87%|████████▋ | 437/500 [05:10<00:27,  2.27it/s] 88%|████████▊ | 439/500 [05:10<00:20,  3.04it/s] 88%|████████▊ | 441/500 [05:16<01:08,  1.16s/it] 89%|████████▊ | 443/500 [05:17<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:17<00:33,  1.66it/s] 89%|████████▉ | 447/500 [05:17<00:23,  2.26it/s] 90%|████████▉ | 449/500 [05:17<00:16,  3.04it/s] 90%|█████████ | 451/500 [05:23<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:23<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:24<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:24<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:24<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:30<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:30<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:30<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:31<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:31<00:10,  2.97it/s] 94%|█████████▍| 471/500 [05:37<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:37<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:37<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:37<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:38<00:07,  3.00it/s]Epoch:  412  	Training Loss: 0.0010123858228325844
Test Loss:  0.0007225134177133441
Valid Loss:  0.0012409290065988898
Epoch:  413  	Training Loss: 0.0010086104739457369
Test Loss:  0.000716989510692656
Valid Loss:  0.0012352969497442245
Epoch:  414  	Training Loss: 0.0010048099793493748
Test Loss:  0.0007121038506738842
Valid Loss:  0.0012300347443670034
Epoch:  415  	Training Loss: 0.00100099784322083
Test Loss:  0.0007077313493937254
Valid Loss:  0.0012250819709151983
Epoch:  416  	Training Loss: 0.0009972060797736049
Test Loss:  0.0007036931347101927
Valid Loss:  0.0012203422375023365
Epoch:  417  	Training Loss: 0.0009934155968949199
Test Loss:  0.0006999492761678994
Valid Loss:  0.001215783297084272
Epoch:  418  	Training Loss: 0.0009896648116409779
Test Loss:  0.0006964268395677209
Valid Loss:  0.001211371272802353
Epoch:  419  	Training Loss: 0.0009859750280156732
Test Loss:  0.0006930854870006442
Valid Loss:  0.0012071192031726241
Epoch:  420  	Training Loss: 0.0009824195876717567
Test Loss:  0.0006899117724969983
Valid Loss:  0.001203005202114582
Epoch:  421  	Training Loss: 0.000978990225121379
Test Loss:  0.0006868579075671732
Valid Loss:  0.0011989593040198088
Epoch:  422  	Training Loss: 0.0009756344952620566
Test Loss:  0.0006716841598972678
Valid Loss:  0.0011906186118721962
Epoch:  423  	Training Loss: 0.0009746981086209416
Test Loss:  0.0006677367491647601
Valid Loss:  0.0011884893756359816
Epoch:  424  	Training Loss: 0.0009745280840434134
Test Loss:  0.0006666217232123017
Valid Loss:  0.001187864108942449
Epoch:  425  	Training Loss: 0.0009744130657054484
Test Loss:  0.0006662565283477306
Valid Loss:  0.001187640242278576
Epoch:  426  	Training Loss: 0.0009743024129420519
Test Loss:  0.0006660835351794958
Valid Loss:  0.001187518355436623
Epoch:  427  	Training Loss: 0.0009741995017975569
Test Loss:  0.0006659631617367268
Valid Loss:  0.0011874240590259433
Epoch:  428  	Training Loss: 0.000974099850282073
Test Loss:  0.0006658535567112267
Valid Loss:  0.0011873350013047457
Epoch:  429  	Training Loss: 0.0009740020614117384
Test Loss:  0.0006657505873590708
Valid Loss:  0.001187251415103674
Epoch:  430  	Training Loss: 0.000973908172454685
Test Loss:  0.0006656472105532885
Valid Loss:  0.0011871658498421311
Epoch:  431  	Training Loss: 0.0009738138178363442
Test Loss:  0.0006655485485680401
Valid Loss:  0.0011870843591168523
Epoch:  432  	Training Loss: 0.0009737252839840949
Test Loss:  0.0006667638663202524
Valid Loss:  0.0011877501383423805
Epoch:  433  	Training Loss: 0.0009735130006447434
Test Loss:  0.0006664473912678659
Valid Loss:  0.0011876177741214633
Epoch:  434  	Training Loss: 0.0009733126498758793
Test Loss:  0.0006663312669843435
Valid Loss:  0.0011875907657667994
Epoch:  435  	Training Loss: 0.0009731205063872039
Test Loss:  0.0006661960505880415
Valid Loss:  0.0011875552590936422
Epoch:  436  	Training Loss: 0.0009729367448017001
Test Loss:  0.0006660702638328075
Valid Loss:  0.0011875261552631855
Epoch:  437  	Training Loss: 0.0009727609576657414
Test Loss:  0.0006659487262368202
Valid Loss:  0.001187499612569809
Epoch:  438  	Training Loss: 0.000972592388279736
Test Loss:  0.0006658321362920105
Valid Loss:  0.0011874777264893055
Epoch:  439  	Training Loss: 0.0009724305127747357
Test Loss:  0.0006657207268290222
Valid Loss:  0.0011874573538079858
Epoch:  440  	Training Loss: 0.0009722759714350104
Test Loss:  0.000665613915771246
Valid Loss:  0.0011874419869855046
Epoch:  441  	Training Loss: 0.0009721278911456466
Test Loss:  0.0006655108882114291
Valid Loss:  0.0011874295305460691
Epoch:  442  	Training Loss: 0.000971985689830035
Test Loss:  0.0006745828432030976
Valid Loss:  0.001191804651170969
Epoch:  443  	Training Loss: 0.0009709973237477243
Test Loss:  0.000679791672155261
Valid Loss:  0.001194440177641809
Epoch:  444  	Training Loss: 0.0009706622804515064
Test Loss:  0.0006828769110143185
Valid Loss:  0.001195963122881949
Epoch:  445  	Training Loss: 0.0009705210104584694
Test Loss:  0.000684722326695919
Valid Loss:  0.0011968177277594805
Epoch:  446  	Training Loss: 0.0009704423137009144
Test Loss:  0.0006858301348984241
Valid Loss:  0.0011972803622484207
Epoch:  447  	Training Loss: 0.0009703842806629837
Test Loss:  0.0006865235627628863
Valid Loss:  0.0011975214583799243
Epoch:  448  	Training Loss: 0.0009703345131129026
Test Loss:  0.0006869666976854205
Valid Loss:  0.0011976348469033837
Epoch:  449  	Training Loss: 0.0009702873066999018
Test Loss:  0.0006872607045806944
Valid Loss:  0.0011976780369877815
Epoch:  450  	Training Loss: 0.0009702421957626939
Test Loss:  0.0006874639657326043
Valid Loss:  0.0011976789683103561
Epoch:  451  	Training Loss: 0.0009701971430331469
Test Loss:  0.0006876096595078707
Valid Loss:  0.0011976583627983928
Epoch:  452  	Training Loss: 0.0009701526141725481
Test Loss:  0.0006701505044475198
Valid Loss:  0.0011834402102977037
Epoch:  453  	Training Loss: 0.0009656910551711917
Test Loss:  0.0006671013543382287
Valid Loss:  0.0011780629865825176
Epoch:  454  	Training Loss: 0.0009623621590435505
Test Loss:  0.0006658552447333932
Valid Loss:  0.001174787525087595
Epoch:  455  	Training Loss: 0.0009598605101928115
Test Loss:  0.0006653270102106035
Valid Loss:  0.001172167481854558
Epoch:  456  	Training Loss: 0.0009578389581292868
Test Loss:  0.0006637244368903339
Valid Loss:  0.0011696545407176018
Epoch:  457  	Training Loss: 0.0009562473278492689
Test Loss:  0.0006625051610171795
Valid Loss:  0.0011677236761897802
Epoch:  458  	Training Loss: 0.0009549310198053718
Test Loss:  0.0006619531195610762
Valid Loss:  0.0011662511387839913
Epoch:  459  	Training Loss: 0.0009537646546959877
Test Loss:  0.0006616351893171668
Valid Loss:  0.0011649805819615722
Epoch:  460  	Training Loss: 0.0009527268703095615
Test Loss:  0.0006614266312681139
Valid Loss:  0.0011637834832072258
Epoch:  461  	Training Loss: 0.0009518193546682596
Test Loss:  0.0006612311117351055
Valid Loss:  0.001162656582891941
Epoch:  462  	Training Loss: 0.0009510155068710446
Test Loss:  0.0006579980254173279
Valid Loss:  0.001160808140411973
Epoch:  463  	Training Loss: 0.0009505891939625144
Test Loss:  0.0006574104772880673
Valid Loss:  0.0011602825252339244
Epoch:  464  	Training Loss: 0.0009502084576524794
Test Loss:  0.0006572813726961613
Valid Loss:  0.0011599096469581127
Epoch:  465  	Training Loss: 0.0009498447761870921
Test Loss:  0.0006572852144017816
Valid Loss:  0.0011595849646255374
Epoch:  466  	Training Loss: 0.0009495168924331665
Test Loss:  0.0006566534284502268
Valid Loss:  0.0011591339716687799
Epoch:  467  	Training Loss: 0.0009492442477494478
Test Loss:  0.0006565237417817116
Valid Loss:  0.0011589037021622062
Epoch:  468  	Training Loss: 0.0009489879012107849
Test Loss:  0.0006564867217093706
Valid Loss:  0.0011586949694901705
Epoch:  469  	Training Loss: 0.0009487434872426093
Test Loss:  0.0006564866052940488
Valid Loss:  0.0011584821622818708
Epoch:  470  	Training Loss: 0.0009485089685767889
Test Loss:  0.000656512682326138
Valid Loss:  0.0011582639999687672
Epoch:  471  	Training Loss: 0.0009482831810601056
Test Loss:  0.0006565597141161561
Valid Loss:  0.0011580388527363539
Epoch:  472  	Training Loss: 0.0009480633307248354
Test Loss:  0.0006554126157425344
Valid Loss:  0.0011568765621632338
Epoch:  473  	Training Loss: 0.0009467971394769847
Test Loss:  0.000654082337860018
Valid Loss:  0.0011557000689208508
Epoch:  474  	Training Loss: 0.0009456387488171458
Test Loss:  0.0006531458930112422
Valid Loss:  0.001154674799181521
Epoch:  475  	Training Loss: 0.0009445846080780029
Test Loss:  0.0006520168390125036
Valid Loss:  0.0011536332312971354
Epoch:  476  	Training Loss: 0.0009436435648240149
Test Loss:  0.0006512296386063099
Valid Loss:  0.001152734155766666
Epoch:  477  	Training Loss: 0.0009427485056221485
Test Loss:  0.0006506390054710209
Valid Loss:  0.0011519691906869411
Epoch:  478  	Training Loss: 0.0009418994886800647
Test Loss:  0.0006501645548269153
Valid Loss:  0.001151256961748004
Epoch:  479  	Training Loss: 0.0009410951752215624
Test Loss:  0.0006497488357126713
Valid Loss:  0.0011505333241075277
Epoch:  480  	Training Loss: 0.0009403332369402051
Test Loss:   96%|█████████▌| 481/500 [05:44<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:44<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:44<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:44<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:44<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:50<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:51<00:05,  1.21it/s] 99%|█████████▉| 495/500 [05:51<00:03,  1.67it/s] 99%|█████████▉| 497/500 [05:51<00:01,  2.27it/s]100%|█████████▉| 499/500 [05:51<00:00,  3.05it/s]100%|██████████| 500/500 [05:57<00:00,  1.40it/s]
0.0006493700784631073
Valid Loss:  0.0011498081730678678
Epoch:  481  	Training Loss: 0.0009396150708198547
Test Loss:  0.0006486587808467448
Valid Loss:  0.0011490063043311238
Epoch:  482  	Training Loss: 0.0009389625629410148
Test Loss:  0.0006474567926488817
Valid Loss:  0.001148182898759842
Epoch:  483  	Training Loss: 0.000938417564611882
Test Loss:  0.000646656088065356
Valid Loss:  0.0011475664796307683
Epoch:  484  	Training Loss: 0.0009378883405588567
Test Loss:  0.0006460127187892795
Valid Loss:  0.0011470294557511806
Epoch:  485  	Training Loss: 0.0009373967768624425
Test Loss:  0.0006455071270465851
Valid Loss:  0.001146551687270403
Epoch:  486  	Training Loss: 0.0009369347244501114
Test Loss:  0.0006450590444728732
Valid Loss:  0.0011461148969829082
Epoch:  487  	Training Loss: 0.0009364949073642492
Test Loss:  0.0006446170154958963
Valid Loss:  0.0011456937063485384
Epoch:  488  	Training Loss: 0.0009360721451230347
Test Loss:  0.000644234474748373
Valid Loss:  0.0011452825274318457
Epoch:  489  	Training Loss: 0.0009356698137708008
Test Loss:  0.0006438994314521551
Valid Loss:  0.0011448916047811508
Epoch:  490  	Training Loss: 0.0009352770284749568
Test Loss:  0.0006435718387365341
Valid Loss:  0.0011444941628724337
Epoch:  491  	Training Loss: 0.0009349071187898517
Test Loss:  0.000643316947389394
Valid Loss:  0.0011441146489232779
Epoch:  492  	Training Loss: 0.0009345493745058775
Test Loss:  0.0006427375483326614
Valid Loss:  0.0011437761131674051
Epoch:  493  	Training Loss: 0.0009345459402538836
Test Loss:  0.0006424424354918301
Valid Loss:  0.0011436063796281815
Epoch:  494  	Training Loss: 0.0009345449507236481
Test Loss:  0.0006422866135835648
Valid Loss:  0.0011435204651206732
Epoch:  495  	Training Loss: 0.0009345446014776826
Test Loss:  0.0006422015139833093
Valid Loss:  0.0011434750631451607
Epoch:  496  	Training Loss: 0.000934544310439378
Test Loss:  0.0006421502330340445
Valid Loss:  0.001143449218943715
Epoch:  497  	Training Loss: 0.0009345444268546999
Test Loss:  0.0006421164143830538
Valid Loss:  0.0011434336192905903
Epoch:  498  	Training Loss: 0.0009345440194010735
Test Loss:  0.0006420912104658782
Valid Loss:  0.001143425120972097
Epoch:  499  	Training Loss: 0.0009345441358163953
Test Loss:  0.0006420707795768976
Valid Loss:  0.0011434173211455345
Epoch:  500  	Training Loss: 0.0009345438447780907
Test Loss:  0.0006420533754862845
Valid Loss:  0.0011434112675487995
**************************************************learning rate decay**************************************************
seed is  11
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:36, 13.72it/s]  1%|          | 4/500 [00:00<00:32, 15.23it/s]  1%|          | 6/500 [00:00<00:36, 13.62it/s]  2%|▏         | 8/500 [00:00<00:37, 13.01it/s]  2%|▏         | 10/500 [00:00<00:35, 13.90it/s]  2%|▏         | 12/500 [00:00<00:33, 14.64it/s]  3%|▎         | 14/500 [00:00<00:32, 15.07it/s]  3%|▎         | 16/500 [00:01<00:31, 15.37it/s]  4%|▎         | 18/500 [00:01<00:33, 14.59it/s]  4%|▍         | 20/500 [00:01<00:32, 14.90it/s]  4%|▍         | 22/500 [00:01<00:31, 15.21it/s]  5%|▍         | 24/500 [00:01<00:30, 15.49it/s]  5%|▌         | 26/500 [00:01<00:30, 15.64it/s]  6%|▌         | 28/500 [00:01<00:29, 15.84it/s]  6%|▌         | 30/500 [00:01<00:29, 16.02it/s]  6%|▋         | 32/500 [00:02<00:29, 15.94it/s]  7%|▋         | 34/500 [00:02<00:29, 16.05it/s]  7%|▋         | 36/500 [00:02<00:28, 16.13it/s]  8%|▊         | 38/500 [00:02<00:28, 16.18it/s]  8%|▊         | 40/500 [00:02<00:28, 16.23it/s]  8%|▊         | 42/500 [00:02<00:28, 16.31it/s]  9%|▉         | 44/500 [00:02<00:27, 16.31it/s]  9%|▉         | 46/500 [00:02<00:28, 16.20it/s] 10%|▉         | 48/500 [00:03<00:28, 15.99it/s] 10%|█         | 50/500 [00:03<00:28, 15.98it/s] 10%|█         | 52/500 [00:03<00:27, 16.01it/s] 11%|█         | 54/500 [00:03<00:27, 16.09it/s] 11%|█         | 56/500 [00:03<00:27, 16.16it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.25it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.23it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.27it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.29it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.24it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.08it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.09it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.99it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.07it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.25it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.22it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.93it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.75it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.88it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.69it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.69it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.67it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.82it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.82it/s] 19%|█▉        | 96/500 [00:06<00:25, 16.02it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.99it/s] 20%|██        | 100/500 [00:06<00:25, 15.59it/s] 20%|██        | 102/500 [00:06<00:25, 15.65it/s] 21%|██        | 104/500 [00:06<00:25, 15.44it/s] 21%|██        | 106/500 [00:06<00:25, 15.38it/s] 22%|██▏       | 108/500 [00:06<00:25, 15.65it/s] 22%|██▏       | 110/500 [00:07<00:24, 15.88it/s] 22%|██▏       | 112/500 [00:07<00:24, 16.07it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.18it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.30it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.02it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.16it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.21it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.18it/s]Epoch:  1  	Training Loss: 0.03226286917924881
Test Loss:  128.2908935546875
Valid Loss:  128.4314727783203
Epoch:  2  	Training Loss: 128.69544982910156
Test Loss:  1927277696.0
Valid Loss:  1918956160.0
Epoch:  3  	Training Loss: 1907880960.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.01it/s] 26%|██▌       | 128/500 [00:08<00:23, 16.00it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.97it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.97it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.11it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.14it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.16it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.21it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.16it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.21it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.22it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.25it/s] 30%|███       | 150/500 [00:09<00:21, 16.26it/s] 30%|███       | 152/500 [00:09<00:21, 16.22it/s] 31%|███       | 154/500 [00:09<00:21, 16.12it/s] 31%|███       | 156/500 [00:09<00:21, 16.21it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.15it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.17it/s] 32%|███▏      | 162/500 [00:10<00:21, 16.09it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.10it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.21it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.29it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.08it/s] 34%|███▍      | 172/500 [00:10<00:20, 15.75it/s] 35%|███▍      | 174/500 [00:10<00:20, 15.74it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.80it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.78it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.98it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.75it/s] 37%|███▋      | 184/500 [00:11<00:19, 15.88it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.08it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.19it/s] 38%|███▊      | 190/500 [00:11<00:19, 15.99it/s] 38%|███▊      | 192/500 [00:12<00:20, 15.06it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.30it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.57it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.42it/s] 40%|████      | 200/500 [00:12<00:19, 15.21it/s] 40%|████      | 202/500 [00:12<00:19, 15.58it/s] 41%|████      | 204/500 [00:12<00:18, 15.78it/s] 41%|████      | 206/500 [00:13<00:18, 15.92it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.93it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.64it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.60it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.12it/s] 43%|████▎     | 216/500 [00:13<00:19, 14.65it/s] 44%|████▎     | 218/500 [00:13<00:18, 15.09it/s] 44%|████▍     | 220/500 [00:13<00:18, 15.44it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.70it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.67it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.85it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.61it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.67it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.90it/s] 47%|████▋     | 234/500 [00:14<00:16, 15.94it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.02it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.08it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.94it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.53it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.67it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.81it/s] 50%|████▉     | 248/500 [00:15<00:15, 15.93it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.03it/s] 50%|█████     | 252/500 [00:15<00:15, 16.06it/s] 51%|█████     | 254/500 [00:16<00:15, 15.94it/s] 51%|█████     | 256/500 [00:16<00:15, 15.78it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.93it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.03it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.19it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.10it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.84it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.01it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.13it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.17it/s] 55%|█████▍    | 274/500 [00:17<00:14, 16.00it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.98it/s] 56%|█████▌    | 278/500 [00:17<00:13, 15.95it/s] 56%|█████▌    | 280/500 [00:17<00:13, 15.88it/s] 56%|█████▋    | 282/500 [00:17<00:13, 15.99it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.02it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.09it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.11it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.20it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.13it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.03it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.04it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.06it/s] 60%|██████    | 300/500 [00:18<00:12, 15.95it/s] 60%|██████    | 302/500 [00:19<00:12, 15.80it/s] 61%|██████    | 304/500 [00:19<00:12, 15.71it/s] 61%|██████    | 306/500 [00:19<00:12, 15.88it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.05it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.05it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.12it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.15it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.03it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.03it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.34it/s] 64%|██████▍   | 322/500 [00:20<00:12, 14.37it/s] 65%|██████▍   | 324/500 [00:20<00:12, 14.67it/s] 65%|██████▌   | 326/500 [00:20<00:12, 14.27it/s] 66%|██████▌   | 328/500 [00:20<00:11, 14.64it/s] 66%|██████▌   | 330/500 [00:20<00:11, 15.11it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.46it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.69it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.86it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.85it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.98it/s] 68%|██████▊   | 342/500 [00:21<00:10, 15.64it/s] 69%|██████▉   | 344/500 [00:21<00:09, 15.74it/s] 69%|██████▉   | 346/500 [00:21<00:09, 15.86it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.81it/s] 70%|███████   | 350/500 [00:22<00:09, 15.90it/s] 70%|███████   | 352/500 [00:22<00:09, 15.11it/s] 71%|███████   | 354/500 [00:22<00:09, 15.35it/s] 71%|███████   | 356/500 [00:22<00:09, 15.63it/s] 72%|███████▏  | 358/500 [00:22<00:08, 15.81it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.03it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.14it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.19it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.13it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.12it/s] 74%|███████▍  | 370/500 [00:23<00:08, 16.13it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.82it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 15.90it/s] 75%|███████▌  | 376/500 [00:23<00:07, 15.62it/s] 76%|███████▌  | 378/500 [00:23<00:07, 15.52it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.62it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.87it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.04it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.14it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.21it/s] 78%|███████▊  | 390/500 [00:24<00:06, 15.94it/s] 78%|███████▊  | 392/500 [00:24<00:06, 15.85it/s] 79%|███████▉  | 394/500 [00:24<00:06, 15.88it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.92it/s] 80%|███████▉  | 398/500 [00:25<00:06, 15.74it/s] 80%|████████  | 400/500 [00:25<00:06, 15.67it/s] 80%|████████  | 402/500 [00:25<00:06, 15.23it/s] 81%|████████  | 404/500 [00:25<00:06, 15.57it/s] 81%|████████  | 406/500 [00:25<00:05, 15.76it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.82it/s] 82%|████████▏ | 410/500 [00:25<00:06, 15.00it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.04it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.33it/s] 83%|████████▎ | 416/500 [00:26<00:05, 15.60it/s] 84%|████████▎ | 418/500 [00:26<00:05, 15.47it/s] 84%|████████▍ | 420/500 [00:26<00:05, 15.76it/s] 84%|████████▍ | 422/500 [00:26<00:04, 15.95it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.13it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.17it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.08it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.00it/s] 86%|████████▋ | 432/500 [00:27<00:04, 15.70it/s] 87%|████████▋ | 434/500 [00:27<00:04, 15.82it/s] 87%|████████▋ | 436/500 [00:27<00:04, 15.93it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.05it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.13it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.20it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.22it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.20it/s] 90%|████████▉ | 448/500 [00:28<00:03, 14.91it/s] 90%|█████████ | 450/500 [00:28<00:03, 15.12it/s] 90%|█████████ | 452/500 [00:28<00:03, 15.40it/s] 91%|█████████ | 454/500 [00:28<00:02, 15.58it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.67it/s] 92%|█████████▏| 458/500 [00:28<00:02, 15.77it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.90it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.90it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.96it/s] 93%|█████████▎| 466/500 [00:29<00:02, 15.93it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.03it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.09it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.07it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.82it/s] 95%|█████████▌| 476/500 [00:30<00:01, 14.69it/s] 96%|█████████▌| 478/500 [00:30<00:01, 14.99it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.25it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.48it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.54it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.53it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.59it/s] 98%|█████████▊| 490/500 [00:31<00:00, 15.54it/s] 98%|█████████▊| 492/500 [00:31<00:00, 15.63it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.71it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.75it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.91it/s]100%|██████████| 500/500 [00:31<00:00, 15.81it/s]100%|██████████| 500/500 [00:31<00:00, 15.78it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  11
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:17,  6.17s/it]  1%|          | 3/500 [00:06<13:40,  1.65s/it]  1%|          | 5/500 [00:06<06:54,  1.20it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.92it/s]  2%|▏         | 11/500 [00:13<10:49,  1.33s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:08,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.99it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:17,  1.19s/it]  7%|▋         | 33/500 [00:26<06:38,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.62it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<08:59,  1.18s/it]  9%|▊         | 43/500 [00:33<06:25,  1.18it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:33<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:46,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.02it/s] 12%|█▏        | 61/500 [00:47<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:54<08:23,  1.17s/it]Epoch:  1  	Training Loss: 0.03226287290453911
Test Loss:  1.2275340557098389
Valid Loss:  1.2332677841186523
Epoch:  2  	Training Loss: 1.236870288848877
Test Loss:  1.0168302059173584
Valid Loss:  0.9999002814292908
Epoch:  3  	Training Loss: 0.9580033421516418
Test Loss:  0.10803112387657166
Valid Loss:  0.10948838293552399
Epoch:  4  	Training Loss: 0.101556196808815
Test Loss:  0.03224627673625946
Valid Loss:  0.03673044592142105
Epoch:  5  	Training Loss: 0.035322658717632294
Test Loss:  0.03128501772880554
Valid Loss:  0.03590991720557213
Epoch:  6  	Training Loss: 0.034879960119724274
Test Loss:  0.03097555786371231
Valid Loss:  0.035115864127874374
Epoch:  7  	Training Loss: 0.033955372869968414
Test Loss:  0.03129494562745094
Valid Loss:  0.034789055585861206
Epoch:  8  	Training Loss: 0.03335916996002197
Test Loss:  0.030740289017558098
Valid Loss:  0.03450495004653931
Epoch:  9  	Training Loss: 0.03323192894458771
Test Loss:  0.031045060604810715
Valid Loss:  0.0344846285879612
Epoch:  10  	Training Loss: 0.033071719110012054
Test Loss:  0.03079412318766117
Valid Loss:  0.03431423008441925
Epoch:  11  	Training Loss: 0.03295140713453293
Test Loss:  0.030864406377077103
Valid Loss:  0.034251850098371506
Epoch:  12  	Training Loss: 0.032842621207237244
Test Loss:  0.030777666717767715
Valid Loss:  0.03414507955312729
Epoch:  13  	Training Loss: 0.03274066746234894
Test Loss:  0.0307395588606596
Valid Loss:  0.03405587747693062
Epoch:  14  	Training Loss: 0.03264429047703743
Test Loss:  0.030725836753845215
Valid Loss:  0.033978864550590515
Epoch:  15  	Training Loss: 0.032553043216466904
Test Loss:  0.030650362372398376
Valid Loss:  0.03388180211186409
Epoch:  16  	Training Loss: 0.03246568888425827
Test Loss:  0.030634913593530655
Valid Loss:  0.0338098369538784
Epoch:  17  	Training Loss: 0.03238213434815407
Test Loss:  0.030596010386943817
Valid Loss:  0.03373086452484131
Epoch:  18  	Training Loss: 0.032302405685186386
Test Loss:  0.030549872666597366
Valid Loss:  0.033654697239398956
Epoch:  19  	Training Loss: 0.03222522512078285
Test Loss:  0.030511928722262383
Valid Loss:  0.03358379751443863
Epoch:  20  	Training Loss: 0.032151319086551666
Test Loss:  0.03046673722565174
Valid Loss:  0.03351251780986786
Epoch:  21  	Training Loss: 0.032079827040433884
Test Loss:  0.0304364413022995
Valid Loss:  0.03344690054655075
Epoch:  22  	Training Loss: 0.03201126679778099
Test Loss:  0.030394170433282852
Valid Loss:  0.0333792082965374
Epoch:  23  	Training Loss: 0.03194472938776016
Test Loss:  0.03036041557788849
Valid Loss:  0.033315762877464294
Epoch:  24  	Training Loss: 0.03188077360391617
Test Loss:  0.03032064251601696
Valid Loss:  0.033251721411943436
Epoch:  25  	Training Loss: 0.0318191796541214
Test Loss:  0.03029380366206169
Valid Loss:  0.03319351747632027
Epoch:  26  	Training Loss: 0.03175962343811989
Test Loss:  0.03025529533624649
Valid Loss:  0.03313262015581131
Epoch:  27  	Training Loss: 0.03170166164636612
Test Loss:  0.030225370079278946
Valid Loss:  0.0330759733915329
Epoch:  28  	Training Loss: 0.031645823270082474
Test Loss:  0.03021031618118286
Valid Loss:  0.033026184886693954
Epoch:  29  	Training Loss: 0.031592365354299545
Test Loss:  0.030181219801306725
Valid Loss:  0.03297265246510506
Epoch:  30  	Training Loss: 0.03154066950082779
Test Loss:  0.03014458529651165
Valid Loss:  0.032916951924562454
Epoch:  31  	Training Loss: 0.03149045258760452
Test Loss:  0.030122682452201843
Valid Loss:  0.0328684076666832
Epoch:  32  	Training Loss: 0.031441885977983475
Test Loss:  0.03009241446852684
Valid Loss:  0.03281807526946068
Epoch:  33  	Training Loss: 0.03139452636241913
Test Loss:  0.030056513845920563
Valid Loss:  0.03276646137237549
Epoch:  34  	Training Loss: 0.031348176300525665
Test Loss:  0.030030887573957443
Valid Loss:  0.03271913900971413
Epoch:  35  	Training Loss: 0.03130326420068741
Test Loss:  0.030003465712070465
Valid Loss:  0.03267154097557068
Epoch:  36  	Training Loss: 0.031259387731552124
Test Loss:  0.029971467331051826
Valid Loss:  0.03262268751859665
Epoch:  37  	Training Loss: 0.031216531991958618
Test Loss:  0.029951762408018112
Valid Loss:  0.03257947415113449
Epoch:  38  	Training Loss: 0.03117501176893711
Test Loss:  0.029927723109722137
Valid Loss:  0.032534293830394745
Epoch:  39  	Training Loss: 0.031134484335780144
Test Loss:  0.029909949749708176
Valid Loss:  0.0324929878115654
Epoch:  40  	Training Loss: 0.031095128506422043
Test Loss:  0.02988988161087036
Valid Loss:  0.032450977712869644
Epoch:  41  	Training Loss: 0.03105677291750908
Test Loss:  0.029865972697734833
Valid Loss:  0.03240734338760376
Epoch:  42  	Training Loss: 0.031019063666462898
Test Loss:  0.0298395324498415
Valid Loss:  0.032362762838602066
Epoch:  43  	Training Loss: 0.030981918796896935
Test Loss:  0.029811564832925797
Valid Loss:  0.03231917321681976
Epoch:  44  	Training Loss: 0.0309454258531332
Test Loss:  0.02979186922311783
Valid Loss:  0.03228026628494263
Epoch:  45  	Training Loss: 0.030909942463040352
Test Loss:  0.029771815985441208
Valid Loss:  0.032241519540548325
Epoch:  46  	Training Loss: 0.030875155702233315
Test Loss:  0.02974938601255417
Valid Loss:  0.03220238536596298
Epoch:  47  	Training Loss: 0.03084082342684269
Test Loss:  0.029725676402449608
Valid Loss:  0.03216532990336418
Epoch:  48  	Training Loss: 0.030806927010416985
Test Loss:  0.029708608984947205
Valid Loss:  0.03213127702474594
Epoch:  49  	Training Loss: 0.030774133279919624
Test Loss:  0.029697325080633163
Valid Loss:  0.03209948167204857
Epoch:  50  	Training Loss: 0.030742323026061058
Test Loss:  0.0296839140355587
Valid Loss:  0.03206779807806015
Epoch:  51  	Training Loss: 0.03071141242980957
Test Loss:  0.02967544086277485
Valid Loss:  0.032038263976573944
Epoch:  52  	Training Loss: 0.030681440606713295
Test Loss:  0.029656151309609413
Valid Loss:  0.03200729936361313
Epoch:  53  	Training Loss: 0.030652545392513275
Test Loss:  0.029656589031219482
Valid Loss:  0.031980715692043304
Epoch:  54  	Training Loss: 0.03062400594353676
Test Loss:  0.029635488986968994
Valid Loss:  0.03195073455572128
Epoch:  55  	Training Loss: 0.030596492812037468
Test Loss:  0.029630469158291817
Valid Loss:  0.0319242998957634
Epoch:  56  	Training Loss: 0.030569514259696007
Test Loss:  0.029620423913002014
Valid Loss:  0.03189770504832268
Epoch:  57  	Training Loss: 0.030543435364961624
Test Loss:  0.029606804251670837
Valid Loss:  0.03187093511223793
Epoch:  58  	Training Loss: 0.030517878010869026
Test Loss:  0.02959069050848484
Valid Loss:  0.03184404969215393
Epoch:  59  	Training Loss: 0.030492667108774185
Test Loss:  0.029572851955890656
Valid Loss:  0.03181709349155426
Epoch:  60  	Training Loss: 0.03046770766377449
Test Loss:  0.029553845524787903
Valid Loss:  0.031790152192115784
Epoch:  61  	Training Loss: 0.03044295869767666
Test Loss:  0.02953406795859337
Valid Loss:  0.03176324814558029
Epoch:  62  	Training Loss: 0.030418388545513153
Test Loss:  0.029513809829950333
Valid Loss:  0.03173646703362465
Epoch:  63  	Training Loss: 0.03039401024580002
Test Loss:  0.02949325367808342
Valid Loss:  0.03170980140566826
Epoch:  64  	Training Loss: 0.030369833111763
Test Loss:  0.02947887033224106
Valid Loss:  0.03168470412492752
Epoch:  65  	Training Loss: 0.030346345156431198
Test Loss:  0.029464224353432655
Valid Loss:  0.031659845262765884
Epoch:  66  	Training Loss: 0.030323565006256104
Test Loss:  0.029462259262800217
Valid Loss:  0.031638361513614655
Epoch:  67  	Training Loss: 0.030301205813884735
Test Loss:  0.029442274942994118
Valid Loss:  0.03161301836371422
Epoch:  68  	Training Loss: 0.03027941659092903
Test Loss:  0.029436709359288216
Valid Loss:  0.031591493636369705
Epoch:  69  	Training Loss: 0.030257942155003548
Test Loss:  0.029427077621221542
Valid Loss:  0.031569428741931915
Epoch:  70  	Training Loss: 0.03023703210055828
Test Loss:  0.029414504766464233
Valid Loss:  0.03154692053794861
Epoch:  71  	Training Loss: 0.030216466635465622
Test Loss:  0.029399847611784935
Valid Loss:  0.03152412548661232
Epoch:  72  	Training Loss: 0.030196137726306915
Test Loss:  0.029383786022663116
Valid Loss:   15%|█▍        | 73/500 [00:54<05:59,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:06,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:47,  1.20it/s] 17%|█▋        | 85/500 [01:01<04:10,  1.65it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:17,  3.00it/s] 18%|█▊        | 91/500 [01:07<07:58,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:07<04:06,  1.65it/s] 19%|█▉        | 97/500 [01:07<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:08<02:12,  3.02it/s] 20%|██        | 101/500 [01:14<07:54,  1.19s/it] 21%|██        | 103/500 [01:14<05:39,  1.17it/s] 21%|██        | 105/500 [01:14<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:14<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:15<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:21<07:33,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:23,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:21<02:49,  2.26it/s] 24%|██▍       | 119/500 [01:21<02:05,  3.03it/s] 24%|██▍       | 121/500 [01:27<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.25it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.00it/s] 26%|██▌       | 131/500 [01:34<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:34<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:35<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:41<07:01,  1.17s/it]0.03150118514895439
Epoch:  73  	Training Loss: 0.030176004394888878
Test Loss:  0.02936672419309616
Valid Loss:  0.0314781479537487
Epoch:  74  	Training Loss: 0.030156007036566734
Test Loss:  0.02934896945953369
Valid Loss:  0.03145505487918854
Epoch:  75  	Training Loss: 0.030136123299598694
Test Loss:  0.029330775141716003
Valid Loss:  0.03143196925520897
Epoch:  76  	Training Loss: 0.030116353183984756
Test Loss:  0.02931229956448078
Valid Loss:  0.03140930086374283
Epoch:  77  	Training Loss: 0.03009670600295067
Test Loss:  0.029293648898601532
Valid Loss:  0.03138786926865578
Epoch:  78  	Training Loss: 0.030077151954174042
Test Loss:  0.029275014996528625
Valid Loss:  0.03136805072426796
Epoch:  79  	Training Loss: 0.030057702213525772
Test Loss:  0.02925742045044899
Valid Loss:  0.03134942799806595
Epoch:  80  	Training Loss: 0.03003835491836071
Test Loss:  0.029239973053336143
Valid Loss:  0.03133119270205498
Epoch:  81  	Training Loss: 0.030019119381904602
Test Loss:  0.029222717508673668
Valid Loss:  0.03131314739584923
Epoch:  82  	Training Loss: 0.029999971389770508
Test Loss:  0.02920570783317089
Valid Loss:  0.03129518777132034
Epoch:  83  	Training Loss: 0.029980909079313278
Test Loss:  0.029190264642238617
Valid Loss:  0.031277336180210114
Epoch:  84  	Training Loss: 0.02996220253407955
Test Loss:  0.02917882800102234
Valid Loss:  0.03125886246562004
Epoch:  85  	Training Loss: 0.02994374744594097
Test Loss:  0.029166799038648605
Valid Loss:  0.03124082274734974
Epoch:  86  	Training Loss: 0.029925508424639702
Test Loss:  0.029155312106013298
Valid Loss:  0.031223487108945847
Epoch:  87  	Training Loss: 0.02990749478340149
Test Loss:  0.02914314717054367
Valid Loss:  0.03120661899447441
Epoch:  88  	Training Loss: 0.029889609664678574
Test Loss:  0.029130559414625168
Valid Loss:  0.031190264970064163
Epoch:  89  	Training Loss: 0.029871854931116104
Test Loss:  0.029117655009031296
Valid Loss:  0.031174182891845703
Epoch:  90  	Training Loss: 0.02985432930290699
Test Loss:  0.02910787984728813
Valid Loss:  0.03115699253976345
Epoch:  91  	Training Loss: 0.02983706444501877
Test Loss:  0.0290970541536808
Valid Loss:  0.03114045225083828
Epoch:  92  	Training Loss: 0.029820045456290245
Test Loss:  0.02908630296587944
Valid Loss:  0.031123990193009377
Epoch:  93  	Training Loss: 0.02980315312743187
Test Loss:  0.029074806720018387
Valid Loss:  0.03110796958208084
Epoch:  94  	Training Loss: 0.029786400496959686
Test Loss:  0.029062781482934952
Valid Loss:  0.031092286109924316
Epoch:  95  	Training Loss: 0.02976974844932556
Test Loss:  0.029050376266241074
Valid Loss:  0.03107684850692749
Epoch:  96  	Training Loss: 0.0297531858086586
Test Loss:  0.02903771959245205
Valid Loss:  0.031061595305800438
Epoch:  97  	Training Loss: 0.029736699536442757
Test Loss:  0.02902490273118019
Valid Loss:  0.03104650415480137
Epoch:  98  	Training Loss: 0.029720298945903778
Test Loss:  0.029011981561779976
Valid Loss:  0.031031534075737
Epoch:  99  	Training Loss: 0.029703974723815918
Test Loss:  0.028999000787734985
Valid Loss:  0.031016668304800987
Epoch:  100  	Training Loss: 0.029687723144888878
Test Loss:  0.028985992074012756
Valid Loss:  0.03100188449025154
Epoch:  101  	Training Loss: 0.02967170812189579
Test Loss:  0.028976140543818474
Valid Loss:  0.03098612278699875
Epoch:  102  	Training Loss: 0.029655903577804565
Test Loss:  0.02896636351943016
Valid Loss:  0.030970647931098938
Epoch:  103  	Training Loss: 0.029640372842550278
Test Loss:  0.028955746442079544
Valid Loss:  0.030955608934164047
Epoch:  104  	Training Loss: 0.02962496690452099
Test Loss:  0.02894456684589386
Valid Loss:  0.030940880998969078
Epoch:  105  	Training Loss: 0.029609668999910355
Test Loss:  0.028932973742485046
Valid Loss:  0.030926402658224106
Epoch:  106  	Training Loss: 0.029594454914331436
Test Loss:  0.02892109379172325
Valid Loss:  0.03091210499405861
Epoch:  107  	Training Loss: 0.029579322785139084
Test Loss:  0.02890903875231743
Valid Loss:  0.03089796006679535
Epoch:  108  	Training Loss: 0.029564272612333298
Test Loss:  0.028896864503622055
Valid Loss:  0.030883945524692535
Epoch:  109  	Training Loss: 0.02954929694533348
Test Loss:  0.028884630650281906
Valid Loss:  0.03087003156542778
Epoch:  110  	Training Loss: 0.029534392058849335
Test Loss:  0.028872357681393623
Valid Loss:  0.030856214463710785
Epoch:  111  	Training Loss: 0.02951955795288086
Test Loss:  0.028860077261924744
Valid Loss:  0.030842473730444908
Epoch:  112  	Training Loss: 0.029504796490073204
Test Loss:  0.028847873210906982
Valid Loss:  0.03082888387143612
Epoch:  113  	Training Loss: 0.02949024923145771
Test Loss:  0.028838621452450752
Valid Loss:  0.030814476311206818
Epoch:  114  	Training Loss: 0.029475893825292587
Test Loss:  0.02882857248187065
Valid Loss:  0.030800435692071915
Epoch:  115  	Training Loss: 0.029461689293384552
Test Loss:  0.028818735852837563
Valid Loss:  0.030786432325839996
Epoch:  116  	Training Loss: 0.029447605833411217
Test Loss:  0.028808286413550377
Valid Loss:  0.030772700905799866
Epoch:  117  	Training Loss: 0.029433604329824448
Test Loss:  0.02879742532968521
Valid Loss:  0.030759168788790703
Epoch:  118  	Training Loss: 0.029419664293527603
Test Loss:  0.028786253184080124
Valid Loss:  0.03074578568339348
Epoch:  119  	Training Loss: 0.029405783861875534
Test Loss:  0.028774943202733994
Valid Loss:  0.030732523649930954
Epoch:  120  	Training Loss: 0.029391948133707047
Test Loss:  0.02876407466828823
Valid Loss:  0.03071936033666134
Epoch:  121  	Training Loss: 0.029378168284893036
Test Loss:  0.028753209859132767
Valid Loss:  0.03070627711713314
Epoch:  122  	Training Loss: 0.029364556074142456
Test Loss:  0.028744583949446678
Valid Loss:  0.030692484229803085
Epoch:  123  	Training Loss: 0.029351044446229935
Test Loss:  0.028735913336277008
Valid Loss:  0.030678819864988327
Epoch:  124  	Training Loss: 0.029337652027606964
Test Loss:  0.028726615011692047
Valid Loss:  0.030665462836623192
Epoch:  125  	Training Loss: 0.029324352741241455
Test Loss:  0.02871686965227127
Valid Loss:  0.03065231814980507
Epoch:  126  	Training Loss: 0.029311126098036766
Test Loss:  0.028706800192594528
Valid Loss:  0.03063933551311493
Epoch:  127  	Training Loss: 0.029297955334186554
Test Loss:  0.02869650162756443
Valid Loss:  0.030626486986875534
Epoch:  128  	Training Loss: 0.02928483858704567
Test Loss:  0.0286860428750515
Valid Loss:  0.030613739043474197
Epoch:  129  	Training Loss: 0.029271766543388367
Test Loss:  0.028675472363829613
Valid Loss:  0.030601058155298233
Epoch:  130  	Training Loss: 0.029258737340569496
Test Loss:  0.0286648441106081
Valid Loss:  0.030588462948799133
Epoch:  131  	Training Loss: 0.029245762154459953
Test Loss:  0.02865416556596756
Valid Loss:  0.030575916171073914
Epoch:  132  	Training Loss: 0.029232824221253395
Test Loss:  0.028643455356359482
Valid Loss:  0.03056339919567108
Epoch:  133  	Training Loss: 0.02921990305185318
Test Loss:  0.028632752597332
Valid Loss:  0.030550949275493622
Epoch:  134  	Training Loss: 0.029207035899162292
Test Loss:  0.028622061014175415
Valid Loss:  0.03053855150938034
Epoch:  135  	Training Loss: 0.029194224625825882
Test Loss:  0.028611373156309128
Valid Loss:  0.030526194721460342
Epoch:  136  	Training Loss: 0.029181456193327904
Test Loss:  0.02860071510076523
Valid Loss:  0.03051389753818512
Epoch:  137  	Training Loss: 0.029168829321861267
Test Loss:  0.02859223261475563
Valid Loss:  0.030501078814268112
Epoch:  138  	Training Loss: 0.029156329110264778
Test Loss:  0.028583765029907227
Valid Loss:  0.030488360673189163
Epoch:  139  	Training Loss: 0.029143953695893288
Test Loss:  0.02857488952577114
Valid Loss:  0.030475879088044167
Epoch:  140  	Training Loss: 0.029131658375263214
Test Loss:  0.02856583334505558
Valid Loss:  0.030463572591543198
Epoch:  141  	Training Loss: 0.029119428247213364
Test Loss:  0.02855663374066353
Valid Loss:  0.03045140765607357
Epoch:  142  	Training Loss: 0.029107261449098587
Test Loss:  0.028547128662467003
Valid Loss:  0.030439212918281555
Epoch:  143  	Training Loss: 0.029095018282532692
Test Loss:  0.028537530452013016
Valid Loss:   29%|██▊       | 143/500 [01:41<05:01,  1.19it/s] 29%|██▉       | 145/500 [01:41<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:42<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.01it/s] 30%|███       | 151/500 [01:48<06:49,  1.17s/it] 31%|███       | 153/500 [01:48<04:52,  1.19it/s] 31%|███       | 155/500 [01:48<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:48<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:55<06:35,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:23,  1.65it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:55<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:02<06:26,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:08<06:10,  1.16s/it] 37%|███▋      | 183/500 [02:08<04:25,  1.20it/s] 37%|███▋      | 185/500 [02:09<03:10,  1.65it/s] 37%|███▋      | 187/500 [02:09<02:18,  2.25it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:15<05:58,  1.16s/it] 39%|███▊      | 193/500 [02:15<04:15,  1.20it/s] 39%|███▉      | 195/500 [02:15<03:04,  1.66it/s] 39%|███▉      | 197/500 [02:15<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:16<01:39,  3.03it/s] 40%|████      | 201/500 [02:22<05:51,  1.17s/it] 41%|████      | 203/500 [02:22<04:10,  1.19it/s] 41%|████      | 205/500 [02:22<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:22<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:29<05:33,  1.16s/it] 43%|████▎     | 213/500 [02:29<03:58,  1.21it/s]0.03042711317539215
Epoch:  144  	Training Loss: 0.029082829132676125
Test Loss:  0.0285295769572258
Valid Loss:  0.03041461668908596
Epoch:  145  	Training Loss: 0.02907080203294754
Test Loss:  0.02852112054824829
Valid Loss:  0.03040235862135887
Epoch:  146  	Training Loss: 0.02905888855457306
Test Loss:  0.02851274609565735
Valid Loss:  0.030390143394470215
Epoch:  147  	Training Loss: 0.029047053307294846
Test Loss:  0.028504010289907455
Valid Loss:  0.03037811443209648
Epoch:  148  	Training Loss: 0.029035290703177452
Test Loss:  0.02849500998854637
Valid Loss:  0.0303662046790123
Epoch:  149  	Training Loss: 0.02902357652783394
Test Loss:  0.028485817834734917
Valid Loss:  0.030354397371411324
Epoch:  150  	Training Loss: 0.02901190146803856
Test Loss:  0.02847648784518242
Valid Loss:  0.03034267947077751
Epoch:  151  	Training Loss: 0.02900027483701706
Test Loss:  0.028467070311307907
Valid Loss:  0.03033103235065937
Epoch:  152  	Training Loss: 0.028988685458898544
Test Loss:  0.02845771424472332
Valid Loss:  0.0303195733577013
Epoch:  153  	Training Loss: 0.02897725999355316
Test Loss:  0.0284483190625906
Valid Loss:  0.030308162793517113
Epoch:  154  	Training Loss: 0.028965868055820465
Test Loss:  0.028438903391361237
Valid Loss:  0.030296802520751953
Epoch:  155  	Training Loss: 0.028954513370990753
Test Loss:  0.028429480269551277
Valid Loss:  0.030285481363534927
Epoch:  156  	Training Loss: 0.028943192213773727
Test Loss:  0.02842005342245102
Valid Loss:  0.030274201184511185
Epoch:  157  	Training Loss: 0.028931912034749985
Test Loss:  0.028410635888576508
Valid Loss:  0.030262954533100128
Epoch:  158  	Training Loss: 0.028920665383338928
Test Loss:  0.02840122953057289
Valid Loss:  0.030251746997237206
Epoch:  159  	Training Loss: 0.028909452259540558
Test Loss:  0.028391825035214424
Valid Loss:  0.030240561813116074
Epoch:  160  	Training Loss: 0.028898267075419426
Test Loss:  0.0283824410289526
Valid Loss:  0.030229467898607254
Epoch:  161  	Training Loss: 0.02888711914420128
Test Loss:  0.028373081237077713
Valid Loss:  0.03021880052983761
Epoch:  162  	Training Loss: 0.028876008465886116
Test Loss:  0.02836405485868454
Valid Loss:  0.030208367854356766
Epoch:  163  	Training Loss: 0.028865071013569832
Test Loss:  0.02835533581674099
Valid Loss:  0.030197961255908012
Epoch:  164  	Training Loss: 0.028854165226221085
Test Loss:  0.028346650302410126
Valid Loss:  0.03018758073449135
Epoch:  165  	Training Loss: 0.028843287378549576
Test Loss:  0.028337983414530754
Valid Loss:  0.030177224427461624
Epoch:  166  	Training Loss: 0.028832443058490753
Test Loss:  0.028329335153102875
Valid Loss:  0.030166897922754288
Epoch:  167  	Training Loss: 0.028821632266044617
Test Loss:  0.02832070365548134
Valid Loss:  0.030156591907143593
Epoch:  168  	Training Loss: 0.028810851275920868
Test Loss:  0.0283120796084404
Valid Loss:  0.030146311968564987
Epoch:  169  	Training Loss: 0.02880009636282921
Test Loss:  0.02830347791314125
Valid Loss:  0.03013606369495392
Epoch:  170  	Training Loss: 0.028789378702640533
Test Loss:  0.028294891119003296
Valid Loss:  0.03012584149837494
Epoch:  171  	Training Loss: 0.028778688982129097
Test Loss:  0.028286319226026535
Valid Loss:  0.03011564165353775
Epoch:  172  	Training Loss: 0.028768029063940048
Test Loss:  0.028277698904275894
Valid Loss:  0.03010539710521698
Epoch:  173  	Training Loss: 0.028757333755493164
Test Loss:  0.02826908975839615
Valid Loss:  0.030095171183347702
Epoch:  174  	Training Loss: 0.028746668249368668
Test Loss:  0.028260499238967896
Valid Loss:  0.030084963887929916
Epoch:  175  	Training Loss: 0.028736025094985962
Test Loss:  0.028251921758055687
Valid Loss:  0.030074788257479668
Epoch:  176  	Training Loss: 0.02872541919350624
Test Loss:  0.028243355453014374
Valid Loss:  0.030064627528190613
Epoch:  177  	Training Loss: 0.028714831918478012
Test Loss:  0.02823479473590851
Valid Loss:  0.030054491013288498
Epoch:  178  	Training Loss: 0.02870428003370762
Test Loss:  0.02822626568377018
Valid Loss:  0.030044380575418472
Epoch:  179  	Training Loss: 0.028693759813904762
Test Loss:  0.02821773663163185
Valid Loss:  0.03003428876399994
Epoch:  180  	Training Loss: 0.028683263808488846
Test Loss:  0.028209222480654716
Valid Loss:  0.030024223029613495
Epoch:  181  	Training Loss: 0.02867279388010502
Test Loss:  0.02820073440670967
Valid Loss:  0.03001418709754944
Epoch:  182  	Training Loss: 0.028662361204624176
Test Loss:  0.028192058205604553
Valid Loss:  0.030004043132066727
Epoch:  183  	Training Loss: 0.028651850298047066
Test Loss:  0.02818342112004757
Valid Loss:  0.029993925243616104
Epoch:  184  	Training Loss: 0.02864137664437294
Test Loss:  0.028174811974167824
Valid Loss:  0.02998405694961548
Epoch:  185  	Training Loss: 0.0286309365183115
Test Loss:  0.028166214004158974
Valid Loss:  0.029974281787872314
Epoch:  186  	Training Loss: 0.028620518743991852
Test Loss:  0.02815764583647251
Valid Loss:  0.029964536428451538
Epoch:  187  	Training Loss: 0.028610147535800934
Test Loss:  0.028149103745818138
Valid Loss:  0.029954856261610985
Epoch:  188  	Training Loss: 0.028599804267287254
Test Loss:  0.028140580281615257
Valid Loss:  0.02994523197412491
Epoch:  189  	Training Loss: 0.028589535504579544
Test Loss:  0.028133045881986618
Valid Loss:  0.029934778809547424
Epoch:  190  	Training Loss: 0.02857932820916176
Test Loss:  0.028125276789069176
Valid Loss:  0.02992461435496807
Epoch:  191  	Training Loss: 0.02856917679309845
Test Loss:  0.028117334470152855
Valid Loss:  0.029914647340774536
Epoch:  192  	Training Loss: 0.028559081256389618
Test Loss:  0.028109686449170113
Valid Loss:  0.02990470454096794
Epoch:  193  	Training Loss: 0.028549112379550934
Test Loss:  0.028101861476898193
Valid Loss:  0.02989494428038597
Epoch:  194  	Training Loss: 0.028539203107357025
Test Loss:  0.028094913810491562
Valid Loss:  0.02988453023135662
Epoch:  195  	Training Loss: 0.028529338538646698
Test Loss:  0.028087878599762917
Valid Loss:  0.029874255880713463
Epoch:  196  	Training Loss: 0.02851954847574234
Test Loss:  0.028080526739358902
Valid Loss:  0.02986428514122963
Epoch:  197  	Training Loss: 0.02850981429219246
Test Loss:  0.028072945773601532
Valid Loss:  0.029854530468583107
Epoch:  198  	Training Loss: 0.028500119224190712
Test Loss:  0.028065195307135582
Valid Loss:  0.029844939708709717
Epoch:  199  	Training Loss: 0.028490450233221054
Test Loss:  0.028057314455509186
Valid Loss:  0.02983546070754528
Epoch:  200  	Training Loss: 0.028480803593993187
Test Loss:  0.028049340471625328
Valid Loss:  0.029826076701283455
Epoch:  201  	Training Loss: 0.02847117930650711
Test Loss:  0.028041299432516098
Valid Loss:  0.02981676533818245
Epoch:  202  	Training Loss: 0.028461571782827377
Test Loss:  0.02803318202495575
Valid Loss:  0.02980748564004898
Epoch:  203  	Training Loss: 0.028451966121792793
Test Loss:  0.028025032952427864
Valid Loss:  0.029798245057463646
Epoch:  204  	Training Loss: 0.028442397713661194
Test Loss:  0.028017865493893623
Valid Loss:  0.02978835068643093
Epoch:  205  	Training Loss: 0.028432901948690414
Test Loss:  0.028010686859488487
Valid Loss:  0.029778512194752693
Epoch:  206  	Training Loss: 0.028423454612493515
Test Loss:  0.028003238141536713
Valid Loss:  0.02976888231933117
Epoch:  207  	Training Loss: 0.028414035215973854
Test Loss:  0.02799559384584427
Valid Loss:  0.029759418219327927
Epoch:  208  	Training Loss: 0.02840464562177658
Test Loss:  0.027987806126475334
Valid Loss:  0.02975008264183998
Epoch:  209  	Training Loss: 0.028395282104611397
Test Loss:  0.027979902923107147
Valid Loss:  0.0297408290207386
Epoch:  210  	Training Loss: 0.02838592603802681
Test Loss:  0.02797193080186844
Valid Loss:  0.029731648042798042
Epoch:  211  	Training Loss: 0.02837659791111946
Test Loss:  0.027963902801275253
Valid Loss:  0.02972252294421196
Epoch:  212  	Training Loss: 0.028367280960083008
Test Loss:  0.02795582078397274
Valid Loss:  0.02971341460943222
Epoch:  213  	Training Loss: 0.028357967734336853
Test Loss:  0.027947714552283287
Valid Loss:  0.029704343527555466
Epoch:  214  	Training Loss: 0.028348669409751892
Test Loss:   43%|████▎     | 215/500 [02:29<02:51,  1.67it/s] 43%|████▎     | 217/500 [02:29<02:04,  2.28it/s] 44%|████▍     | 219/500 [02:29<01:31,  3.05it/s] 44%|████▍     | 221/500 [02:35<05:24,  1.16s/it] 45%|████▍     | 223/500 [02:35<03:51,  1.20it/s] 45%|████▌     | 225/500 [02:36<02:46,  1.66it/s] 45%|████▌     | 227/500 [02:36<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:36<01:29,  3.04it/s] 46%|████▌     | 231/500 [02:42<05:08,  1.15s/it] 47%|████▋     | 233/500 [02:42<03:40,  1.21it/s] 47%|████▋     | 235/500 [02:42<02:38,  1.67it/s] 47%|████▋     | 237/500 [02:42<01:55,  2.29it/s] 48%|████▊     | 239/500 [02:43<01:25,  3.07it/s] 48%|████▊     | 241/500 [02:49<05:01,  1.16s/it] 49%|████▊     | 243/500 [02:49<03:34,  1.20it/s] 49%|████▉     | 245/500 [02:49<02:34,  1.66it/s] 49%|████▉     | 247/500 [02:49<01:51,  2.26it/s] 50%|████▉     | 249/500 [02:49<01:22,  3.04it/s] 50%|█████     | 251/500 [02:56<04:51,  1.17s/it] 51%|█████     | 253/500 [02:56<03:27,  1.19it/s] 51%|█████     | 255/500 [02:56<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:56<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:56<01:20,  3.01it/s] 52%|█████▏    | 261/500 [03:02<04:43,  1.18s/it] 53%|█████▎    | 263/500 [03:03<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:03<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:03<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:03<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:09<04:26,  1.16s/it] 55%|█████▍    | 273/500 [03:09<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:09<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:10<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:10<01:12,  3.03it/s] 56%|█████▌    | 281/500 [03:16<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:16<03:02,  1.19it/s]0.027939600870013237
Valid Loss:  0.02969532087445259
Epoch:  215  	Training Loss: 0.02833940088748932
Test Loss:  0.027931489050388336
Valid Loss:  0.029686324298381805
Epoch:  216  	Training Loss: 0.028330154716968536
Test Loss:  0.027923382818698883
Valid Loss:  0.02967735007405281
Epoch:  217  	Training Loss: 0.028320927172899246
Test Loss:  0.02791527286171913
Valid Loss:  0.029668400064110756
Epoch:  218  	Training Loss: 0.028311725705862045
Test Loss:  0.027907175943255424
Valid Loss:  0.029659468680620193
Epoch:  219  	Training Loss: 0.028302542865276337
Test Loss:  0.027899086475372314
Valid Loss:  0.02965056523680687
Epoch:  220  	Training Loss: 0.02829338237643242
Test Loss:  0.02789100632071495
Valid Loss:  0.02964167296886444
Epoch:  221  	Training Loss: 0.028284244239330292
Test Loss:  0.02788293920457363
Valid Loss:  0.02963295206427574
Epoch:  222  	Training Loss: 0.028275124728679657
Test Loss:  0.027874857187271118
Valid Loss:  0.02962433360517025
Epoch:  223  	Training Loss: 0.028265997767448425
Test Loss:  0.027866866439580917
Valid Loss:  0.029615726321935654
Epoch:  224  	Training Loss: 0.028256887570023537
Test Loss:  0.027859032154083252
Valid Loss:  0.0296071358025074
Epoch:  225  	Training Loss: 0.028247792273759842
Test Loss:  0.027851225808262825
Valid Loss:  0.029598550871014595
Epoch:  226  	Training Loss: 0.028238710016012192
Test Loss:  0.02784343995153904
Valid Loss:  0.029589978978037834
Epoch:  227  	Training Loss: 0.02822968363761902
Test Loss:  0.02783634513616562
Valid Loss:  0.029580650851130486
Epoch:  228  	Training Loss: 0.02822069823741913
Test Loss:  0.02782927080988884
Valid Loss:  0.029571346938610077
Epoch:  229  	Training Loss: 0.02821176126599312
Test Loss:  0.027822021394968033
Valid Loss:  0.02956227771937847
Epoch:  230  	Training Loss: 0.028202859684824944
Test Loss:  0.027814645320177078
Valid Loss:  0.029553379863500595
Epoch:  231  	Training Loss: 0.02819398231804371
Test Loss:  0.02780718356370926
Valid Loss:  0.02954459935426712
Epoch:  232  	Training Loss: 0.028185123577713966
Test Loss:  0.027799755334854126
Valid Loss:  0.029536018148064613
Epoch:  233  	Training Loss: 0.028176382184028625
Test Loss:  0.02779228240251541
Valid Loss:  0.029527515172958374
Epoch:  234  	Training Loss: 0.028167659416794777
Test Loss:  0.02778477780520916
Valid Loss:  0.02951907180249691
Epoch:  235  	Training Loss: 0.028158992528915405
Test Loss:  0.027778176590800285
Valid Loss:  0.02950982004404068
Epoch:  236  	Training Loss: 0.028150398284196854
Test Loss:  0.027771150693297386
Valid Loss:  0.029501022771000862
Epoch:  237  	Training Loss: 0.02814183384180069
Test Loss:  0.027764182537794113
Valid Loss:  0.029492218047380447
Epoch:  238  	Training Loss: 0.02813330665230751
Test Loss:  0.02775707095861435
Valid Loss:  0.029483579099178314
Epoch:  239  	Training Loss: 0.02812480553984642
Test Loss:  0.02774985507130623
Valid Loss:  0.02947506681084633
Epoch:  240  	Training Loss: 0.028116323053836823
Test Loss:  0.027742570266127586
Valid Loss:  0.029466666281223297
Epoch:  241  	Training Loss: 0.028107866644859314
Test Loss:  0.027735229581594467
Valid Loss:  0.029458336532115936
Epoch:  242  	Training Loss: 0.028099428862333298
Test Loss:  0.027727851644158363
Valid Loss:  0.029450085014104843
Epoch:  243  	Training Loss: 0.028091030195355415
Test Loss:  0.027720455080270767
Valid Loss:  0.029441874474287033
Epoch:  244  	Training Loss: 0.02808264270424843
Test Loss:  0.02771303616464138
Valid Loss:  0.02943369373679161
Epoch:  245  	Training Loss: 0.028074270114302635
Test Loss:  0.027705613523721695
Valid Loss:  0.02942555397748947
Epoch:  246  	Training Loss: 0.028065919876098633
Test Loss:  0.027699057012796402
Valid Loss:  0.02941661700606346
Epoch:  247  	Training Loss: 0.028057627379894257
Test Loss:  0.027691390365362167
Valid Loss:  0.02940872311592102
Epoch:  248  	Training Loss: 0.028049349784851074
Test Loss:  0.02768467552959919
Valid Loss:  0.029399989172816277
Epoch:  249  	Training Loss: 0.02804110199213028
Test Loss:  0.02767777256667614
Valid Loss:  0.02939145267009735
Epoch:  250  	Training Loss: 0.028032876551151276
Test Loss:  0.027670733630657196
Valid Loss:  0.02938305400311947
Epoch:  251  	Training Loss: 0.028024666011333466
Test Loss:  0.027663594111800194
Valid Loss:  0.029374759644269943
Epoch:  252  	Training Loss: 0.028016475960612297
Test Loss:  0.027656272053718567
Valid Loss:  0.029366416856646538
Epoch:  253  	Training Loss: 0.028008168563246727
Test Loss:  0.027648895978927612
Valid Loss:  0.029358133673667908
Epoch:  254  	Training Loss: 0.0279998779296875
Test Loss:  0.02764148637652397
Valid Loss:  0.029349908232688904
Epoch:  255  	Training Loss: 0.027991607785224915
Test Loss:  0.02763405442237854
Valid Loss:  0.029341720044612885
Epoch:  256  	Training Loss: 0.027983350679278374
Test Loss:  0.02762659452855587
Valid Loss:  0.029333559796214104
Epoch:  257  	Training Loss: 0.027975110337138176
Test Loss:  0.02761983312666416
Valid Loss:  0.029324855655431747
Epoch:  258  	Training Loss: 0.027966918423771858
Test Loss:  0.0276130773127079
Valid Loss:  0.029316194355487823
Epoch:  259  	Training Loss: 0.027958765625953674
Test Loss:  0.027606148272752762
Valid Loss:  0.02930770255625248
Epoch:  260  	Training Loss: 0.02795064076781273
Test Loss:  0.027599267661571503
Valid Loss:  0.029299195855855942
Epoch:  261  	Training Loss: 0.027942538261413574
Test Loss:  0.027592066675424576
Valid Loss:  0.029290974140167236
Epoch:  262  	Training Loss: 0.027934476733207703
Test Loss:  0.027585702016949654
Valid Loss:  0.029282141476869583
Epoch:  263  	Training Loss: 0.027926424518227577
Test Loss:  0.02757890149950981
Valid Loss:  0.02927369624376297
Epoch:  264  	Training Loss: 0.02791842445731163
Test Loss:  0.027571406215429306
Valid Loss:  0.029265768826007843
Epoch:  265  	Training Loss: 0.02791043370962143
Test Loss:  0.027564648538827896
Valid Loss:  0.029257316142320633
Epoch:  266  	Training Loss: 0.02790245972573757
Test Loss:  0.027557725086808205
Valid Loss:  0.02924901805818081
Epoch:  267  	Training Loss: 0.0278945155441761
Test Loss:  0.027550682425498962
Valid Loss:  0.029240816831588745
Epoch:  268  	Training Loss: 0.027886584401130676
Test Loss:  0.027543550357222557
Valid Loss:  0.029232710599899292
Epoch:  269  	Training Loss: 0.027878671884536743
Test Loss:  0.02753634750843048
Valid Loss:  0.02922465279698372
Epoch:  270  	Training Loss: 0.027870766818523407
Test Loss:  0.02752910926938057
Valid Loss:  0.02921665832400322
Epoch:  271  	Training Loss: 0.027862882241606712
Test Loss:  0.027521822601556778
Valid Loss:  0.029208693653345108
Epoch:  272  	Training Loss: 0.027855001389980316
Test Loss:  0.02751455269753933
Valid Loss:  0.029200788587331772
Epoch:  273  	Training Loss: 0.027847152203321457
Test Loss:  0.02750726416707039
Valid Loss:  0.029192905873060226
Epoch:  274  	Training Loss: 0.02783932536840439
Test Loss:  0.027499960735440254
Valid Loss:  0.029185039922595024
Epoch:  275  	Training Loss: 0.02783149853348732
Test Loss:  0.027492647990584373
Valid Loss:  0.029177188873291016
Epoch:  276  	Training Loss: 0.02782367914915085
Test Loss:  0.027485322207212448
Valid Loss:  0.029169350862503052
Epoch:  277  	Training Loss: 0.027815867215394974
Test Loss:  0.027478013187646866
Valid Loss:  0.029161527752876282
Epoch:  278  	Training Loss: 0.027808070182800293
Test Loss:  0.02747068554162979
Valid Loss:  0.02915370836853981
Epoch:  279  	Training Loss: 0.027800273150205612
Test Loss:  0.027463361620903015
Valid Loss:  0.029145900160074234
Epoch:  280  	Training Loss: 0.027792487293481827
Test Loss:  0.027456043288111687
Valid Loss:  0.02913809008896351
Epoch:  281  	Training Loss: 0.02778470329940319
Test Loss:  0.027448732405900955
Valid Loss:  0.029130306094884872
Epoch:  282  	Training Loss: 0.027776941657066345
Test Loss:  0.027441423386335373
Valid Loss:  0.02912253886461258
Epoch:  283  	Training Loss: 0.02776920050382614
Test Loss:  0.027434125542640686
Valid Loss:  0.02911478281021118
Epoch:  284  	Training Loss: 0.027761470526456833
Test Loss:  0.027426835149526596
Valid Loss:  0.02910703793168068
 57%|█████▋    | 285/500 [03:16<02:10,  1.64it/s] 57%|█████▋    | 287/500 [03:16<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:16<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:23<04:03,  1.16s/it] 59%|█████▊    | 293/500 [03:23<02:53,  1.20it/s] 59%|█████▉    | 295/500 [03:23<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:23<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:23<01:06,  3.02it/s] 60%|██████    | 301/500 [03:30<03:55,  1.18s/it] 61%|██████    | 303/500 [03:30<02:47,  1.18it/s] 61%|██████    | 305/500 [03:30<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:30<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:30<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:36<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:36<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:37<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:37<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:37<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:43<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:43<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:43<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:44<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:44<00:56,  3.00it/s] 66%|██████▌   | 331/500 [03:50<03:16,  1.16s/it] 67%|██████▋   | 333/500 [03:50<02:19,  1.20it/s] 67%|██████▋   | 335/500 [03:50<01:39,  1.66it/s] 67%|██████▋   | 337/500 [03:50<01:12,  2.26it/s] 68%|██████▊   | 339/500 [03:50<00:52,  3.04it/s] 68%|██████▊   | 341/500 [03:57<03:05,  1.16s/it] 69%|██████▊   | 343/500 [03:57<02:11,  1.20it/s] 69%|██████▉   | 345/500 [03:57<01:33,  1.66it/s] 69%|██████▉   | 347/500 [03:57<01:07,  2.26it/s] 70%|██████▉   | 349/500 [03:57<00:49,  3.04it/s] 70%|███████   | 351/500 [04:03<02:54,  1.17s/it] 71%|███████   | 353/500 [04:04<02:03,  1.19it/s]Epoch:  285  	Training Loss: 0.02775375358760357
Test Loss:  0.027419552206993103
Valid Loss:  0.029099291190505028
Epoch:  286  	Training Loss: 0.027746044099330902
Test Loss:  0.027412276715040207
Valid Loss:  0.02909155562520027
Epoch:  287  	Training Loss: 0.02773834392428398
Test Loss:  0.02740500494837761
Valid Loss:  0.029083827510476112
Epoch:  288  	Training Loss: 0.027730654925107956
Test Loss:  0.027397742494940758
Valid Loss:  0.0290761087089777
Epoch:  289  	Training Loss: 0.027722975239157677
Test Loss:  0.027390481904149055
Valid Loss:  0.029068395495414734
Epoch:  290  	Training Loss: 0.027715303003787994
Test Loss:  0.02738322876393795
Valid Loss:  0.029060684144496918
Epoch:  291  	Training Loss: 0.027707643806934357
Test Loss:  0.02737598493695259
Valid Loss:  0.029052987694740295
Epoch:  292  	Training Loss: 0.027699992060661316
Test Loss:  0.027368705719709396
Valid Loss:  0.029045244678854942
Epoch:  293  	Training Loss: 0.02769232913851738
Test Loss:  0.027362078428268433
Valid Loss:  0.029037099331617355
Epoch:  294  	Training Loss: 0.027684682980179787
Test Loss:  0.02735530585050583
Valid Loss:  0.02902907319366932
Epoch:  295  	Training Loss: 0.027677059173583984
Test Loss:  0.027348577976226807
Valid Loss:  0.029021022841334343
Epoch:  296  	Training Loss: 0.027669452130794525
Test Loss:  0.027341730892658234
Valid Loss:  0.029013078659772873
Epoch:  297  	Training Loss: 0.027661865577101707
Test Loss:  0.027334794402122498
Valid Loss:  0.029005208984017372
Epoch:  298  	Training Loss: 0.027654293924570084
Test Loss:  0.02732779085636139
Valid Loss:  0.02899739518761635
Epoch:  299  	Training Loss: 0.027646739035844803
Test Loss:  0.027320731431245804
Valid Loss:  0.028989627957344055
Epoch:  300  	Training Loss: 0.02763918973505497
Test Loss:  0.027313638478517532
Valid Loss:  0.028981897979974747
Epoch:  301  	Training Loss: 0.027631696313619614
Test Loss:  0.027308162301778793
Valid Loss:  0.028973236680030823
Epoch:  302  	Training Loss: 0.027624208480119705
Test Loss:  0.02730015106499195
Valid Loss:  0.02896532416343689
Epoch:  303  	Training Loss: 0.027616256847977638
Test Loss:  0.027293913066387177
Valid Loss:  0.028956443071365356
Epoch:  304  	Training Loss: 0.02760840579867363
Test Loss:  0.02728564664721489
Valid Loss:  0.028948701918125153
Epoch:  305  	Training Loss: 0.02760050818324089
Test Loss:  0.02727922797203064
Valid Loss:  0.02893996797502041
Epoch:  306  	Training Loss: 0.02759263664484024
Test Loss:  0.02727215737104416
Valid Loss:  0.028931595385074615
Epoch:  307  	Training Loss: 0.02758481726050377
Test Loss:  0.027263984084129333
Valid Loss:  0.028923846781253815
Epoch:  308  	Training Loss: 0.027576996013522148
Test Loss:  0.0272572822868824
Valid Loss:  0.02891533076763153
Epoch:  309  	Training Loss: 0.027569185942411423
Test Loss:  0.02725035697221756
Valid Loss:  0.028906961902976036
Epoch:  310  	Training Loss: 0.027561403810977936
Test Loss:  0.02724328637123108
Valid Loss:  0.028898686170578003
Epoch:  311  	Training Loss: 0.02755364030599594
Test Loss:  0.02723608911037445
Valid Loss:  0.028890490531921387
Epoch:  312  	Training Loss: 0.02754589170217514
Test Loss:  0.027229174971580505
Valid Loss:  0.028882712125778198
Epoch:  313  	Training Loss: 0.0275384820997715
Test Loss:  0.027222169563174248
Valid Loss:  0.028874967247247696
Epoch:  314  	Training Loss: 0.02753107063472271
Test Loss:  0.02721511386334896
Valid Loss:  0.028867268934845924
Epoch:  315  	Training Loss: 0.027523674070835114
Test Loss:  0.027208011597394943
Valid Loss:  0.028859585523605347
Epoch:  316  	Training Loss: 0.027516277506947517
Test Loss:  0.027200885117053986
Valid Loss:  0.028851933777332306
Epoch:  317  	Training Loss: 0.027508893981575966
Test Loss:  0.027193738147616386
Valid Loss:  0.028844304382801056
Epoch:  318  	Training Loss: 0.027501516044139862
Test Loss:  0.027186565101146698
Valid Loss:  0.028836671262979507
Epoch:  319  	Training Loss: 0.02749413251876831
Test Loss:  0.027179384604096413
Valid Loss:  0.028829067945480347
Epoch:  320  	Training Loss: 0.027486763894557953
Test Loss:  0.02717220038175583
Valid Loss:  0.028821460902690887
Epoch:  321  	Training Loss: 0.027479398995637894
Test Loss:  0.027164995670318604
Valid Loss:  0.028813861310482025
Epoch:  322  	Training Loss: 0.027472028508782387
Test Loss:  0.027157966047525406
Valid Loss:  0.02880645915865898
Epoch:  323  	Training Loss: 0.0274648480117321
Test Loss:  0.027150942012667656
Valid Loss:  0.02879907563328743
Epoch:  324  	Training Loss: 0.02745768427848816
Test Loss:  0.02714391052722931
Valid Loss:  0.02879168651998043
Epoch:  325  	Training Loss: 0.02745051309466362
Test Loss:  0.02713688276708126
Valid Loss:  0.02878429926931858
Epoch:  326  	Training Loss: 0.027443349361419678
Test Loss:  0.027129855006933212
Valid Loss:  0.028776925057172775
Epoch:  327  	Training Loss: 0.027436191216111183
Test Loss:  0.02712283283472061
Valid Loss:  0.028769543394446373
Epoch:  328  	Training Loss: 0.027429034933447838
Test Loss:  0.02711581438779831
Valid Loss:  0.028762180358171463
Epoch:  329  	Training Loss: 0.02742188796401024
Test Loss:  0.027108803391456604
Valid Loss:  0.028754813596606255
Epoch:  330  	Training Loss: 0.027414750307798386
Test Loss:  0.0271017923951149
Valid Loss:  0.028747450560331345
Epoch:  331  	Training Loss: 0.027407608926296234
Test Loss:  0.027094781398773193
Valid Loss:  0.028740087524056435
Epoch:  332  	Training Loss: 0.02740047499537468
Test Loss:  0.027087345719337463
Valid Loss:  0.028732266277074814
Epoch:  333  	Training Loss: 0.027392910793423653
Test Loss:  0.027080554515123367
Valid Loss:  0.028724193572998047
Epoch:  334  	Training Loss: 0.027385398745536804
Test Loss:  0.027073003351688385
Valid Loss:  0.02871648594737053
Epoch:  335  	Training Loss: 0.027377896010875702
Test Loss:  0.02706628292798996
Valid Loss:  0.02870842255651951
Epoch:  336  	Training Loss: 0.027370411902666092
Test Loss:  0.02705942839384079
Valid Loss:  0.02870044857263565
Epoch:  337  	Training Loss: 0.02736295759677887
Test Loss:  0.027052469551563263
Valid Loss:  0.028692573308944702
Epoch:  338  	Training Loss: 0.027355538681149483
Test Loss:  0.027045436203479767
Valid Loss:  0.02868475392460823
Epoch:  339  	Training Loss: 0.027348138391971588
Test Loss:  0.027038346976041794
Valid Loss:  0.028676990419626236
Epoch:  340  	Training Loss: 0.027340754866600037
Test Loss:  0.027031220495700836
Valid Loss:  0.028669271618127823
Epoch:  341  	Training Loss: 0.027333395555615425
Test Loss:  0.027024079114198685
Valid Loss:  0.02866159752011299
Epoch:  342  	Training Loss: 0.027326064184308052
Test Loss:  0.027017373591661453
Valid Loss:  0.028654437512159348
Epoch:  343  	Training Loss: 0.027319200336933136
Test Loss:  0.027011271566152573
Valid Loss:  0.02864704839885235
Epoch:  344  	Training Loss: 0.027312373742461205
Test Loss:  0.02700440213084221
Valid Loss:  0.02863999456167221
Epoch:  345  	Training Loss: 0.02730555087327957
Test Loss:  0.026998333632946014
Valid Loss:  0.02863261103630066
Epoch:  346  	Training Loss: 0.027298729866743088
Test Loss:  0.026992101222276688
Valid Loss:  0.028625305742025375
Epoch:  347  	Training Loss: 0.027291927486658096
Test Loss:  0.026985757052898407
Valid Loss:  0.028618071228265762
Epoch:  348  	Training Loss: 0.027285145595669746
Test Loss:  0.026979316025972366
Valid Loss:  0.02861088141798973
Epoch:  349  	Training Loss: 0.027278369292616844
Test Loss:  0.026972800493240356
Valid Loss:  0.028603723272681236
Epoch:  350  	Training Loss: 0.02727160044014454
Test Loss:  0.02696623094379902
Valid Loss:  0.02859659679234028
Epoch:  351  	Training Loss: 0.02726483717560768
Test Loss:  0.026959622278809547
Valid Loss:  0.028589501976966858
Epoch:  352  	Training Loss: 0.02725808322429657
Test Loss:  0.02695346623659134
Valid Loss:  0.028582913801074028
Epoch:  353  	Training Loss: 0.027251796796917915
Test Loss:  0.02694728597998619
Valid Loss:  0.02857634238898754
Epoch:  354  	Training Loss: 0.02724551409482956
Test Loss:  0.026941098272800446
Valid Loss:  0.028569787740707397
Epoch:  355  	Training Loss: 0.02723923698067665
Test Loss:   71%|███████   | 355/500 [04:04<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:04<01:03,  2.23it/s] 72%|███████▏  | 359/500 [04:04<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:10<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:10<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:11<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:11<00:58,  2.26it/s] 74%|███████▍  | 369/500 [04:11<00:43,  3.03it/s] 74%|███████▍  | 371/500 [04:17<02:30,  1.16s/it] 75%|███████▍  | 373/500 [04:17<01:46,  1.20it/s] 75%|███████▌  | 375/500 [04:17<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:17<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:18<00:39,  3.04it/s] 76%|███████▌  | 381/500 [04:24<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:24<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:24<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:24<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:24<00:36,  3.03it/s] 78%|███████▊  | 391/500 [04:30<02:05,  1.16s/it] 79%|███████▊  | 393/500 [04:31<01:28,  1.20it/s] 79%|███████▉  | 395/500 [04:31<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:31<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:31<00:33,  3.04it/s] 80%|████████  | 401/500 [04:37<01:54,  1.16s/it] 81%|████████  | 403/500 [04:37<01:20,  1.20it/s] 81%|████████  | 405/500 [04:38<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:38<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:38<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:44<01:43,  1.16s/it] 83%|████████▎ | 413/500 [04:44<01:12,  1.20it/s] 83%|████████▎ | 415/500 [04:44<00:51,  1.66it/s] 83%|████████▎ | 417/500 [04:44<00:36,  2.26it/s] 84%|████████▍ | 419/500 [04:45<00:26,  3.04it/s] 84%|████████▍ | 421/500 [04:51<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:51<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:51<00:45,  1.65it/s]0.026934895664453506
Valid Loss:  0.0285632461309433
Epoch:  356  	Training Loss: 0.027232972905039787
Test Loss:  0.02692868933081627
Valid Loss:  0.028556711971759796
Epoch:  357  	Training Loss: 0.027226712554693222
Test Loss:  0.02692248299717903
Valid Loss:  0.028550192713737488
Epoch:  358  	Training Loss: 0.027220461517572403
Test Loss:  0.026916271075606346
Valid Loss:  0.028543680906295776
Epoch:  359  	Training Loss: 0.02721421606838703
Test Loss:  0.026910066604614258
Valid Loss:  0.028537176549434662
Epoch:  360  	Training Loss: 0.027207978069782257
Test Loss:  0.02690386027097702
Valid Loss:  0.028530683368444443
Epoch:  361  	Training Loss: 0.02720174938440323
Test Loss:  0.02689765952527523
Valid Loss:  0.02852420136332512
Epoch:  362  	Training Loss: 0.027195526286959648
Test Loss:  0.026890654116868973
Valid Loss:  0.02851688861846924
Epoch:  363  	Training Loss: 0.027188550680875778
Test Loss:  0.026884401217103004
Valid Loss:  0.02850930765271187
Epoch:  364  	Training Loss: 0.027181575074791908
Test Loss:  0.026877988129854202
Valid Loss:  0.028501804918050766
Epoch:  365  	Training Loss: 0.02717461995780468
Test Loss:  0.02687128446996212
Valid Loss:  0.028494417667388916
Epoch:  366  	Training Loss: 0.027167674154043198
Test Loss:  0.026864686980843544
Valid Loss:  0.028487006202340126
Epoch:  367  	Training Loss: 0.02716074138879776
Test Loss:  0.026858005672693253
Valid Loss:  0.02847963571548462
Epoch:  368  	Training Loss: 0.027153821662068367
Test Loss:  0.026851262897253036
Valid Loss:  0.028472304344177246
Epoch:  369  	Training Loss: 0.02714690752327442
Test Loss:  0.02684447541832924
Valid Loss:  0.028464997187256813
Epoch:  370  	Training Loss: 0.02714000642299652
Test Loss:  0.026837652549147606
Valid Loss:  0.02845771238207817
Epoch:  371  	Training Loss: 0.027133110910654068
Test Loss:  0.026830807328224182
Valid Loss:  0.02845044434070587
Epoch:  372  	Training Loss: 0.02712622657418251
Test Loss:  0.02682407945394516
Valid Loss:  0.028443314135074615
Epoch:  373  	Training Loss: 0.027119453996419907
Test Loss:  0.026817331090569496
Valid Loss:  0.02843618579208851
Epoch:  374  	Training Loss: 0.0271126888692379
Test Loss:  0.02681056782603264
Valid Loss:  0.028429072350263596
Epoch:  375  	Training Loss: 0.02710592746734619
Test Loss:  0.026803795248270035
Valid Loss:  0.02842196449637413
Epoch:  376  	Training Loss: 0.027099162340164185
Test Loss:  0.02679702267050743
Valid Loss:  0.02841486968100071
Epoch:  377  	Training Loss: 0.027092410251498222
Test Loss:  0.02679024636745453
Valid Loss:  0.028407782316207886
Epoch:  378  	Training Loss: 0.027085667476058006
Test Loss:  0.026783475652337074
Valid Loss:  0.02840070240199566
Epoch:  379  	Training Loss: 0.02707892656326294
Test Loss:  0.026776697486639023
Valid Loss:  0.02839362435042858
Epoch:  380  	Training Loss: 0.02707219123840332
Test Loss:  0.026769917458295822
Valid Loss:  0.02838655188679695
Epoch:  381  	Training Loss: 0.027065452188253403
Test Loss:  0.026763148605823517
Valid Loss:  0.028379488736391068
Epoch:  382  	Training Loss: 0.027058729901909828
Test Loss:  0.02675647661089897
Valid Loss:  0.02837255783379078
Epoch:  383  	Training Loss: 0.027052126824855804
Test Loss:  0.026749813929200172
Valid Loss:  0.02836562693119049
Epoch:  384  	Training Loss: 0.027045534923672676
Test Loss:  0.02674316242337227
Valid Loss:  0.028358712792396545
Epoch:  385  	Training Loss: 0.027038943022489548
Test Loss:  0.026736512780189514
Valid Loss:  0.028351787477731705
Epoch:  386  	Training Loss: 0.027032360434532166
Test Loss:  0.026729874312877655
Valid Loss:  0.028344877064228058
Epoch:  387  	Training Loss: 0.027025779709219933
Test Loss:  0.026723241433501244
Valid Loss:  0.028337974101305008
Epoch:  388  	Training Loss: 0.027019210159778595
Test Loss:  0.026716619729995728
Valid Loss:  0.028331076726317406
Epoch:  389  	Training Loss: 0.027012649923563004
Test Loss:  0.02671000361442566
Valid Loss:  0.028324183076620102
Epoch:  390  	Training Loss: 0.02700609341263771
Test Loss:  0.02670339308679104
Valid Loss:  0.028317300602793694
Epoch:  391  	Training Loss: 0.026999540627002716
Test Loss:  0.026696782559156418
Valid Loss:  0.028310410678386688
Epoch:  392  	Training Loss: 0.02699299156665802
Test Loss:  0.026690136641263962
Valid Loss:  0.028303489089012146
Epoch:  393  	Training Loss: 0.026986410841345787
Test Loss:  0.026683490723371506
Valid Loss:  0.028296563774347305
Epoch:  394  	Training Loss: 0.026979828253388405
Test Loss:  0.02667684108018875
Valid Loss:  0.028289638459682465
Epoch:  395  	Training Loss: 0.026973247528076172
Test Loss:  0.026670193299651146
Valid Loss:  0.028282716870307922
Epoch:  396  	Training Loss: 0.026966670528054237
Test Loss:  0.026663554832339287
Valid Loss:  0.02827579714357853
Epoch:  397  	Training Loss: 0.026960093528032303
Test Loss:  0.02665691077709198
Valid Loss:  0.028268873691558838
Epoch:  398  	Training Loss: 0.02695351280272007
Test Loss:  0.02665027044713497
Valid Loss:  0.028261950239539146
Epoch:  399  	Training Loss: 0.026946935802698135
Test Loss:  0.026643622666597366
Valid Loss:  0.028255034238100052
Epoch:  400  	Training Loss: 0.02694036439061165
Test Loss:  0.026636986061930656
Valid Loss:  0.02824811451137066
Epoch:  401  	Training Loss: 0.026933789253234863
Test Loss:  0.026630349457263947
Valid Loss:  0.028241218999028206
Epoch:  402  	Training Loss: 0.026927219703793526
Test Loss:  0.02662375010550022
Valid Loss:  0.02823439985513687
Epoch:  403  	Training Loss: 0.026920679956674576
Test Loss:  0.026617160066962242
Valid Loss:  0.02822759374976158
Epoch:  404  	Training Loss: 0.026914147660136223
Test Loss:  0.026610568165779114
Valid Loss:  0.02822078764438629
Epoch:  405  	Training Loss: 0.02690761722624302
Test Loss:  0.026603981852531433
Valid Loss:  0.028213992714881897
Epoch:  406  	Training Loss: 0.026901092380285263
Test Loss:  0.026597395539283752
Valid Loss:  0.028207194060087204
Epoch:  407  	Training Loss: 0.026894569396972656
Test Loss:  0.026590818539261818
Valid Loss:  0.028200404718518257
Epoch:  408  	Training Loss: 0.026888053864240646
Test Loss:  0.026584241539239883
Valid Loss:  0.02819361537694931
Epoch:  409  	Training Loss: 0.026881542056798935
Test Loss:  0.026577668264508247
Valid Loss:  0.02818683162331581
Epoch:  410  	Training Loss: 0.026875032112002373
Test Loss:  0.02657109498977661
Valid Loss:  0.02818004973232746
Epoch:  411  	Training Loss: 0.026868529617786407
Test Loss:  0.026564529165625572
Valid Loss:  0.028173275291919708
Epoch:  412  	Training Loss: 0.026862025260925293
Test Loss:  0.02655784785747528
Valid Loss:  0.02816639095544815
Epoch:  413  	Training Loss: 0.026855431497097015
Test Loss:  0.026551172137260437
Valid Loss:  0.028159506618976593
Epoch:  414  	Training Loss: 0.026848837733268738
Test Loss:  0.026544494554400444
Valid Loss:  0.028152618557214737
Epoch:  415  	Training Loss: 0.026842240244150162
Test Loss:  0.02653782069683075
Valid Loss:  0.028145739808678627
Epoch:  416  	Training Loss: 0.02683565393090248
Test Loss:  0.0265311598777771
Valid Loss:  0.028138861060142517
Epoch:  417  	Training Loss: 0.02682906575500965
Test Loss:  0.02652449533343315
Valid Loss:  0.028131980448961258
Epoch:  418  	Training Loss: 0.02682248316705227
Test Loss:  0.0265178382396698
Valid Loss:  0.028125105425715446
Epoch:  419  	Training Loss: 0.026815904304385185
Test Loss:  0.026511171832680702
Valid Loss:  0.028118222951889038
Epoch:  420  	Training Loss: 0.026809317991137505
Test Loss:  0.0265045166015625
Valid Loss:  0.028111349791288376
Epoch:  421  	Training Loss: 0.02680274099111557
Test Loss:  0.026497863233089447
Valid Loss:  0.028104476630687714
Epoch:  422  	Training Loss: 0.026796167716383934
Test Loss:  0.026491302996873856
Valid Loss:  0.028097685426473618
Epoch:  423  	Training Loss: 0.026789668947458267
Test Loss:  0.026484746485948563
Valid Loss:  0.02809090167284012
Epoch:  424  	Training Loss: 0.026783181354403496
Test Loss:  0.02647818997502327
Valid Loss:  0.028084121644496918
Epoch:  425  	Training Loss: 0.026776690036058426
Test Loss:  0.026471640914678574
Valid Loss:  0.028077343478798866
 85%|████████▌ | 427/500 [04:51<00:32,  2.25it/s] 86%|████████▌ | 429/500 [04:51<00:23,  3.02it/s] 86%|████████▌ | 431/500 [04:57<01:20,  1.16s/it] 87%|████████▋ | 433/500 [04:58<00:55,  1.20it/s] 87%|████████▋ | 435/500 [04:58<00:39,  1.65it/s] 87%|████████▋ | 437/500 [04:58<00:27,  2.26it/s] 88%|████████▊ | 439/500 [04:58<00:20,  3.03it/s] 88%|████████▊ | 441/500 [05:04<01:08,  1.16s/it] 89%|████████▊ | 443/500 [05:04<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:04<00:33,  1.67it/s] 89%|████████▉ | 447/500 [05:05<00:23,  2.27it/s] 90%|████████▉ | 449/500 [05:05<00:16,  3.05it/s] 90%|█████████ | 451/500 [05:11<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:11<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:11<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:11<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:12<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:18<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:18<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:18<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:18<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:18<00:10,  2.99it/s] 94%|█████████▍| 471/500 [05:25<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:25<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:25<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:25<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:25<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:31<00:21,  1.16s/it] 97%|█████████▋| 483/500 [05:32<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:32<00:09,  1.66it/s] 97%|█████████▋| 487/500 [05:32<00:05,  2.26it/s] 98%|█████████▊| 489/500 [05:32<00:03,  3.04it/s] 98%|█████████▊| 491/500 [05:38<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:38<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:38<00:03,  1.65it/s]Epoch:  426  	Training Loss: 0.026770206168293953
Test Loss:  0.02646508999168873
Valid Loss:  0.02807057648897171
Epoch:  427  	Training Loss: 0.026763727888464928
Test Loss:  0.02645854279398918
Valid Loss:  0.028063803911209106
Epoch:  428  	Training Loss: 0.02675725147128105
Test Loss:  0.026452001184225082
Valid Loss:  0.028057046234607697
Epoch:  429  	Training Loss: 0.026750782504677773
Test Loss:  0.026445459574460983
Valid Loss:  0.02805028110742569
Epoch:  430  	Training Loss: 0.026744313538074493
Test Loss:  0.02643892541527748
Valid Loss:  0.028043527156114578
Epoch:  431  	Training Loss: 0.02673785388469696
Test Loss:  0.026432394981384277
Valid Loss:  0.028036776930093765
Epoch:  432  	Training Loss: 0.026731394231319427
Test Loss:  0.026425888761878014
Valid Loss:  0.028030062094330788
Epoch:  433  	Training Loss: 0.02672497183084488
Test Loss:  0.026419389992952347
Valid Loss:  0.028023354709148407
Epoch:  434  	Training Loss: 0.02671855315566063
Test Loss:  0.02641289308667183
Valid Loss:  0.028016645461320877
Epoch:  435  	Training Loss: 0.026712138205766678
Test Loss:  0.02640639804303646
Valid Loss:  0.02800993248820305
Epoch:  436  	Training Loss: 0.026705721393227577
Test Loss:  0.026399914175271988
Valid Loss:  0.028003234416246414
Epoch:  437  	Training Loss: 0.026699315756559372
Test Loss:  0.026393435895442963
Valid Loss:  0.027996530756354332
Epoch:  438  	Training Loss: 0.026692913845181465
Test Loss:  0.026386959478259087
Valid Loss:  0.027989840134978294
Epoch:  439  	Training Loss: 0.026686521247029305
Test Loss:  0.02638048306107521
Valid Loss:  0.027983151376247406
Epoch:  440  	Training Loss: 0.026680126786231995
Test Loss:  0.02637401595711708
Valid Loss:  0.02797646075487137
Epoch:  441  	Training Loss: 0.026673737913370132
Test Loss:  0.0263675469905138
Valid Loss:  0.027969777584075928
Epoch:  442  	Training Loss: 0.02666735276579857
Test Loss:  0.026361137628555298
Valid Loss:  0.027963150292634964
Epoch:  443  	Training Loss: 0.026661023497581482
Test Loss:  0.026354728266596794
Valid Loss:  0.027956528589129448
Epoch:  444  	Training Loss: 0.02665470354259014
Test Loss:  0.026348324492573738
Valid Loss:  0.02794991247355938
Epoch:  445  	Training Loss: 0.0266483835875988
Test Loss:  0.02634192444384098
Valid Loss:  0.02794329635798931
Epoch:  446  	Training Loss: 0.02664206549525261
Test Loss:  0.02633552812039852
Valid Loss:  0.027936682105064392
Epoch:  447  	Training Loss: 0.026635754853487015
Test Loss:  0.02632913738489151
Valid Loss:  0.027930065989494324
Epoch:  448  	Training Loss: 0.02662944421172142
Test Loss:  0.026322735473513603
Valid Loss:  0.027923449873924255
Epoch:  449  	Training Loss: 0.026623127982020378
Test Loss:  0.02631635032594204
Valid Loss:  0.027916844934225082
Epoch:  450  	Training Loss: 0.02661682292819023
Test Loss:  0.026309961453080177
Valid Loss:  0.02791023626923561
Epoch:  451  	Training Loss: 0.02661052532494068
Test Loss:  0.02630358189344406
Valid Loss:  0.027903636917471886
Epoch:  452  	Training Loss: 0.026604223996400833
Test Loss:  0.026297185570001602
Valid Loss:  0.027897000312805176
Epoch:  453  	Training Loss: 0.026597898453474045
Test Loss:  0.026290791109204292
Valid Loss:  0.02789037674665451
Epoch:  454  	Training Loss: 0.026591578498482704
Test Loss:  0.026284392923116684
Valid Loss:  0.027883747592568398
Epoch:  455  	Training Loss: 0.026585258543491364
Test Loss:  0.026278002187609673
Valid Loss:  0.02787712961435318
Epoch:  456  	Training Loss: 0.02657894603908062
Test Loss:  0.026271605864167213
Valid Loss:  0.027870509773492813
Epoch:  457  	Training Loss: 0.026572629809379578
Test Loss:  0.0262652188539505
Valid Loss:  0.027863893657922745
Epoch:  458  	Training Loss: 0.026566321030259132
Test Loss:  0.02625882625579834
Valid Loss:  0.027857273817062378
Epoch:  459  	Training Loss: 0.02656000852584839
Test Loss:  0.026252444833517075
Valid Loss:  0.027850663289427757
Epoch:  460  	Training Loss: 0.02655370719730854
Test Loss:  0.026246054098010063
Valid Loss:  0.027844050899147987
Epoch:  461  	Training Loss: 0.026547398418188095
Test Loss:  0.026239676401019096
Valid Loss:  0.027837444096803665
Epoch:  462  	Training Loss: 0.026541100814938545
Test Loss:  0.026233844459056854
Valid Loss:  0.027831388637423515
Epoch:  463  	Training Loss: 0.026535313576459885
Test Loss:  0.02622801810503006
Valid Loss:  0.02782534621655941
Epoch:  464  	Training Loss: 0.02652953751385212
Test Loss:  0.02622218430042267
Valid Loss:  0.027819301933050156
Epoch:  465  	Training Loss: 0.026523757725954056
Test Loss:  0.026216357946395874
Valid Loss:  0.02781325951218605
Epoch:  466  	Training Loss: 0.02651798538863659
Test Loss:  0.026210535317659378
Valid Loss:  0.02780722826719284
Epoch:  467  	Training Loss: 0.02651221677660942
Test Loss:  0.02620471641421318
Valid Loss:  0.02780120074748993
Epoch:  468  	Training Loss: 0.0265064537525177
Test Loss:  0.026198893785476685
Valid Loss:  0.027795176953077316
Epoch:  469  	Training Loss: 0.02650069072842598
Test Loss:  0.026193073019385338
Valid Loss:  0.027789149433374405
Epoch:  470  	Training Loss: 0.026494931429624557
Test Loss:  0.026187267154455185
Valid Loss:  0.027783138677477837
Epoch:  471  	Training Loss: 0.02648918330669403
Test Loss:  0.026181451976299286
Valid Loss:  0.02777712419629097
Epoch:  472  	Training Loss: 0.026483435183763504
Test Loss:  0.026175275444984436
Valid Loss:  0.027770724147558212
Epoch:  473  	Training Loss: 0.026477329432964325
Test Loss:  0.026169106364250183
Valid Loss:  0.027764340862631798
Epoch:  474  	Training Loss: 0.026471229270100594
Test Loss:  0.026162929832935333
Valid Loss:  0.02775793895125389
Epoch:  475  	Training Loss: 0.026465127244591713
Test Loss:  0.026156749576330185
Valid Loss:  0.02775154635310173
Epoch:  476  	Training Loss: 0.026459025219082832
Test Loss:  0.02615058235824108
Valid Loss:  0.027745164930820465
Epoch:  477  	Training Loss: 0.026452936232089996
Test Loss:  0.026144783943891525
Valid Loss:  0.027738578617572784
Epoch:  478  	Training Loss: 0.026446841657161713
Test Loss:  0.02613852545619011
Valid Loss:  0.027732226997613907
Epoch:  479  	Training Loss: 0.026440750807523727
Test Loss:  0.026132667437195778
Valid Loss:  0.027725692838430405
Epoch:  480  	Training Loss: 0.02643466740846634
Test Loss:  0.026126733049750328
Valid Loss:  0.02771918475627899
Epoch:  481  	Training Loss: 0.026428580284118652
Test Loss:  0.026120740920305252
Valid Loss:  0.027712710201740265
Epoch:  482  	Training Loss: 0.026422500610351562
Test Loss:  0.026114536449313164
Valid Loss:  0.02770593948662281
Epoch:  483  	Training Loss: 0.026416178792715073
Test Loss:  0.026108281686902046
Valid Loss:  0.027699202299118042
Epoch:  484  	Training Loss: 0.02640986256301403
Test Loss:  0.026101989671587944
Valid Loss:  0.027692483738064766
Epoch:  485  	Training Loss: 0.026403551921248436
Test Loss:  0.026095665991306305
Valid Loss:  0.02768579125404358
Epoch:  486  	Training Loss: 0.02639724314212799
Test Loss:  0.026089314371347427
Valid Loss:  0.027679093182086945
Epoch:  487  	Training Loss: 0.026390930637717247
Test Loss:  0.02608296275138855
Valid Loss:  0.0276724174618721
Epoch:  488  	Training Loss: 0.0263846293091774
Test Loss:  0.02607659623026848
Valid Loss:  0.027665764093399048
Epoch:  489  	Training Loss: 0.026378335431218147
Test Loss:  0.02607022598385811
Valid Loss:  0.027659105136990547
Epoch:  490  	Training Loss: 0.026372045278549194
Test Loss:  0.026063859462738037
Valid Loss:  0.027652457356452942
Epoch:  491  	Training Loss: 0.02636575885117054
Test Loss:  0.02605747990310192
Valid Loss:  0.027645817026495934
Epoch:  492  	Training Loss: 0.026359474286437035
Test Loss:  0.026051079854369164
Valid Loss:  0.027639171108603477
Epoch:  493  	Training Loss: 0.026353180408477783
Test Loss:  0.02604469284415245
Valid Loss:  0.02763253077864647
Epoch:  494  	Training Loss: 0.026346897706389427
Test Loss:  0.026038307696580887
Valid Loss:  0.027625899761915207
Epoch:  495  	Training Loss: 0.02634062059223652
Test Loss:  0.026031920686364174
Valid Loss:  0.027619272470474243
Epoch:  496  	Training Loss: 0.02633434720337391
Test Loss:  0.02602553740143776 99%|█████████▉| 497/500 [05:39<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:39<00:00,  2.99it/s]100%|██████████| 500/500 [05:39<00:00,  1.47it/s]

Valid Loss:  0.027612652629613876
Epoch:  497  	Training Loss: 0.026328083127737045
Test Loss:  0.026019619777798653
Valid Loss:  0.027605831623077393
Epoch:  498  	Training Loss: 0.02632182464003563
Test Loss:  0.026013128459453583
Valid Loss:  0.027599260210990906
Epoch:  499  	Training Loss: 0.02631556987762451
Test Loss:  0.026007138192653656
Valid Loss:  0.0275924913585186
Epoch:  500  	Training Loss: 0.026309320703148842
Test Loss:  0.026001064106822014
Valid Loss:  0.027585767209529877
seed is  11
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:56,  6.12s/it]  1%|          | 3/500 [00:06<13:35,  1.64s/it]  1%|          | 5/500 [00:06<06:51,  1.20it/s]  1%|▏         | 7/500 [00:06<04:09,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.94it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:25<17:00,  2.13s/it]  5%|▍         | 23/500 [00:26<11:57,  1.50s/it]  5%|▌         | 25/500 [00:26<08:27,  1.07s/it]  5%|▌         | 27/500 [00:26<06:02,  1.31it/s]  6%|▌         | 29/500 [00:26<04:21,  1.80it/s]  6%|▌         | 31/500 [00:32<10:21,  1.32s/it]  7%|▋         | 33/500 [00:32<07:22,  1.05it/s]  7%|▋         | 35/500 [00:32<05:17,  1.47it/s]  7%|▋         | 37/500 [00:33<03:50,  2.01it/s]  8%|▊         | 39/500 [00:33<02:49,  2.72it/s]  8%|▊         | 41/500 [00:39<09:14,  1.21s/it]  9%|▊         | 43/500 [00:39<06:36,  1.15it/s]  9%|▉         | 45/500 [00:39<04:44,  1.60it/s]  9%|▉         | 47/500 [00:39<03:27,  2.18it/s] 10%|▉         | 49/500 [00:40<02:34,  2.92it/s] 10%|█         | 51/500 [00:46<08:47,  1.18s/it] 11%|█         | 53/500 [00:46<06:17,  1.18it/s] 11%|█         | 55/500 [00:46<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:46<03:18,  2.24it/s] 12%|█▏        | 59/500 [00:46<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:53<08:30,  1.16s/it] 13%|█▎        | 63/500 [00:53<06:05,  1.20it/s] 13%|█▎        | 65/500 [00:53<04:22,  1.65it/s] 13%|█▎        | 67/500 [00:53<03:11,  2.26it/s]Epoch:  1  	Training Loss: 0.03226287290453911
Test Loss:  0.11254313588142395
Valid Loss:  0.115699402987957
Epoch:  2  	Training Loss: 0.12374499440193176
Test Loss:  0.018678613007068634
Valid Loss:  0.019727442413568497
Epoch:  3  	Training Loss: 0.017100390046834946
Test Loss:  0.008200740441679955
Valid Loss:  0.01025174930691719
Epoch:  4  	Training Loss: 0.009639715775847435
Test Loss:  0.006829679943621159
Valid Loss:  0.009053710848093033
Epoch:  5  	Training Loss: 0.008899148553609848
Test Loss:  0.006406459026038647
Valid Loss:  0.008631624281406403
Epoch:  6  	Training Loss: 0.008566680364310741
Test Loss:  0.006168503314256668
Valid Loss:  0.008364446461200714
Epoch:  7  	Training Loss: 0.008302904665470123
Test Loss:  0.0060174353420734406
Valid Loss:  0.008180634118616581
Epoch:  8  	Training Loss: 0.008108619600534439
Test Loss:  0.006042480003088713
Valid Loss:  0.008184624835848808
Epoch:  9  	Training Loss: 0.008071038872003555
Test Loss:  0.006025135517120361
Valid Loss:  0.008159075863659382
Epoch:  10  	Training Loss: 0.008036112412810326
Test Loss:  0.005998965352773666
Valid Loss:  0.00812737736850977
Epoch:  11  	Training Loss: 0.008001187816262245
Test Loss:  0.005968762561678886
Valid Loss:  0.008093196898698807
Epoch:  12  	Training Loss: 0.007966248318552971
Test Loss:  0.0030903532169759274
Valid Loss:  0.004233594983816147
Epoch:  13  	Training Loss: 0.0037014721892774105
Test Loss:  0.0014585850294679403
Valid Loss:  0.0026217426639050245
Epoch:  14  	Training Loss: 0.002697763731703162
Test Loss:  0.00814438983798027
Valid Loss:  0.00787996407598257
Epoch:  15  	Training Loss: 0.006232962012290955
Test Loss:  0.02776968665421009
Valid Loss:  0.030480889603495598
Epoch:  16  	Training Loss: 0.034228865057229996
Test Loss:  0.06360575556755066
Valid Loss:  0.06049416959285736
Epoch:  17  	Training Loss: 0.055157825350761414
Test Loss:  0.002924182452261448
Valid Loss:  0.004282612353563309
Epoch:  18  	Training Loss: 0.003629302605986595
Test Loss:  0.0023119384422898293
Valid Loss:  0.0037214942276477814
Epoch:  19  	Training Loss: 0.0032991738989949226
Test Loss:  0.002181801712140441
Valid Loss:  0.0035323714837431908
Epoch:  20  	Training Loss: 0.0031182928942143917
Test Loss:  0.0020857553463429213
Valid Loss:  0.0033738045021891594
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.002960256300866604
Test Loss:  0.0020507010631263256
Valid Loss:  0.0030799400992691517
Epoch:  22  	Training Loss: 0.002585803624242544
Test Loss:  0.001953935017809272
Valid Loss:  0.0029038647189736366
Epoch:  23  	Training Loss: 0.0023874556645751
Test Loss:  0.0018436904065310955
Valid Loss:  0.002739452291280031
Epoch:  24  	Training Loss: 0.0022230164613574743
Test Loss:  0.0017564143054187298
Valid Loss:  0.0026203072629868984
Epoch:  25  	Training Loss: 0.0021214731968939304
Test Loss:  0.0016975256148725748
Valid Loss:  0.0025472561828792095
Epoch:  26  	Training Loss: 0.0020603027660399675
Test Loss:  0.0016555702313780785
Valid Loss:  0.0024911919608712196
Epoch:  27  	Training Loss: 0.0020197934936732054
Test Loss:  0.001624302240088582
Valid Loss:  0.002448643557727337
Epoch:  28  	Training Loss: 0.001991879427805543
Test Loss:  0.0015997111331671476
Valid Loss:  0.0024177127052098513
Epoch:  29  	Training Loss: 0.0019716056995093822
Test Loss:  0.0015791633632034063
Valid Loss:  0.002393182832747698
Epoch:  30  	Training Loss: 0.0019557843916118145
Test Loss:  0.0015647565014660358
Valid Loss:  0.0023728401865810156
Epoch:  31  	Training Loss: 0.0019426003564149141
Test Loss:  0.0015474683605134487
Valid Loss:  0.0023542020935565233
Epoch:  32  	Training Loss: 0.0019313573138788342
Test Loss:  0.0015232148580253124
Valid Loss:  0.0023265003692358732
Epoch:  33  	Training Loss: 0.0019106233958154917
Test Loss:  0.0015098410658538342
Valid Loss:  0.0023147682659327984
Epoch:  34  	Training Loss: 0.0019045977387577295
Test Loss:  0.0015024091117084026
Valid Loss:  0.0023084948770701885
Epoch:  35  	Training Loss: 0.0019000608008354902
Test Loss:  0.0014977464452385902
Valid Loss:  0.002303773071616888
Epoch:  36  	Training Loss: 0.0018958111759275198
Test Loss:  0.001494083204306662
Valid Loss:  0.0022996561601758003
Epoch:  37  	Training Loss: 0.0018917314009740949
Test Loss:  0.0014907894656062126
Valid Loss:  0.002295824233442545
Epoch:  38  	Training Loss: 0.0018878140253946185
Test Loss:  0.0014877954963594675
Valid Loss:  0.002292177639901638
Epoch:  39  	Training Loss: 0.0018840383272618055
Test Loss:  0.0014853314496576786
Valid Loss:  0.002288880292326212
Epoch:  40  	Training Loss: 0.0018804898718371987
Test Loss:  0.0014830955769866705
Valid Loss:  0.0022858879528939724
Epoch:  41  	Training Loss: 0.0018771649338304996
Test Loss:  0.0014780799392610788
Valid Loss:  0.0022816136479377747
Epoch:  42  	Training Loss: 0.0018740769010037184
Test Loss:  0.0014226367929950356
Valid Loss:  0.0021518494468182325
Epoch:  43  	Training Loss: 0.0017266746144741774
Test Loss:  0.0012941875029355288
Valid Loss:  0.0020184507593512535
Epoch:  44  	Training Loss: 0.0016292709624394774
Test Loss:  0.0012351765763014555
Valid Loss:  0.001944167772307992
Epoch:  45  	Training Loss: 0.0015732516767457128
Test Loss:  0.0011793274898082018
Valid Loss:  0.0018853881629183888
Epoch:  46  	Training Loss: 0.001536229276098311
Test Loss:  0.0011541331186890602
Valid Loss:  0.0018532181857153773
Epoch:  47  	Training Loss: 0.0015092918183654547
Test Loss:  0.0011226587230339646
Valid Loss:  0.0018259232165291905
Epoch:  48  	Training Loss: 0.0014902286930009723
Test Loss:  0.0011089022736996412
Valid Loss:  0.0018075883854180574
Epoch:  49  	Training Loss: 0.001474014949053526
Test Loss:  0.001094768987968564
Valid Loss:  0.0017894848715513945
Epoch:  50  	Training Loss: 0.0014594938838854432
Test Loss:  0.0010810219682753086
Valid Loss:  0.0017727385275065899
Epoch:  51  	Training Loss: 0.0014459487283602357
Test Loss:  0.0010677666869014502
Valid Loss:  0.0017571088392287493
Epoch:  52  	Training Loss: 0.0014331222046166658
Test Loss:  0.0010450483532622457
Valid Loss:  0.0017296437872573733
Epoch:  53  	Training Loss: 0.0014143839944154024
Test Loss:  0.0010491578141227365
Valid Loss:  0.0017231206875294447
Epoch:  54  	Training Loss: 0.0014046537689864635
Test Loss:  0.0010441571939736605
Valid Loss:  0.0017146854661405087
Epoch:  55  	Training Loss: 0.0013965698890388012
Test Loss:  0.0010360919404774904
Valid Loss:  0.0017056931974366307
Epoch:  56  	Training Loss: 0.0013889770489186049
Test Loss:  0.0010302728042006493
Valid Loss:  0.0016976618207991123
Epoch:  57  	Training Loss: 0.0013817358994856477
Test Loss:  0.0010245302692055702
Valid Loss:  0.0016901493072509766
Epoch:  58  	Training Loss: 0.0013748288620263338
Test Loss:  0.0010190698085352778
Valid Loss:  0.0016830076929181814
Epoch:  59  	Training Loss: 0.001368315308354795
Test Loss:  0.0010143890976905823
Valid Loss:  0.0016758441925048828
Epoch:  60  	Training Loss: 0.0013618965167552233
Test Loss:  0.0010078761260956526
Valid Loss:  0.0016683629946783185
Epoch:  61  	Training Loss: 0.0013555993791669607
Test Loss:  0.0010032688733190298
Valid Loss:  0.0016614684136584401
Epoch:  62  	Training Loss: 0.0013493967708200216
Test Loss:  0.0009888161439448595
Valid Loss:  0.0016472168499603868
Epoch:  63  	Training Loss: 0.0013372545363381505
Test Loss:  0.000977549934759736
Valid Loss:  0.0016342155868187547
Epoch:  64  	Training Loss: 0.00132568902336061
Test Loss:  0.0009675920591689646
Valid Loss:  0.0016216430813074112
Epoch:  65  	Training Loss: 0.0013143657706677914
Test Loss:  0.0009582106140442193
Valid Loss:  0.0016091866418719292
Epoch:  66  	Training Loss: 0.0013032112037763
Test Loss:  0.0009493065299466252
Valid Loss:  0.0015967001672834158
Epoch:  67  	Training Loss: 0.0012922435998916626
Test Loss:  0.0009400442941114306
Valid Loss:  0.0015842508291825652
Epoch:  68  	Training Loss: 0.0012816516682505608
Test Loss:  0.0009326293366029859
Valid Loss:  0.0015726732090115547
Epoch:  69  	Training Loss: 0.0012714432086795568
Test Loss:   14%|█▍        | 69/500 [00:53<02:22,  3.03it/s] 14%|█▍        | 71/500 [00:59<08:23,  1.17s/it] 15%|█▍        | 73/500 [01:00<05:59,  1.19it/s] 15%|█▌        | 75/500 [01:00<04:18,  1.64it/s] 15%|█▌        | 77/500 [01:00<03:08,  2.24it/s] 16%|█▌        | 79/500 [01:00<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:06<08:08,  1.16s/it] 17%|█▋        | 83/500 [01:06<05:48,  1.20it/s] 17%|█▋        | 85/500 [01:06<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:07<03:02,  2.26it/s] 18%|█▊        | 89/500 [01:07<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:13<07:58,  1.17s/it] 19%|█▊        | 93/500 [01:13<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:13<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:13<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:13<02:12,  3.02it/s] 20%|██        | 101/500 [01:20<07:44,  1.16s/it] 21%|██        | 103/500 [01:20<05:32,  1.20it/s] 21%|██        | 105/500 [01:20<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:20<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:20<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:27<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:27<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:27<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:27<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:27<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:33<07:20,  1.16s/it] 25%|██▍       | 123/500 [01:33<05:15,  1.19it/s] 25%|██▌       | 125/500 [01:34<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:34<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:34<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:40<07:09,  1.16s/it] 27%|██▋       | 133/500 [01:40<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:40<03:40,  1.65it/s] 27%|██▋       | 137/500 [01:40<02:40,  2.26it/s]0.000924102496355772
Valid Loss:  0.0015607536770403385
Epoch:  70  	Training Loss: 0.0012613668804988265
Test Loss:  0.0009162466158159077
Valid Loss:  0.0015490363584831357
Epoch:  71  	Training Loss: 0.0012513688998296857
Test Loss:  0.0009067641803994775
Valid Loss:  0.0015369760803878307
Epoch:  72  	Training Loss: 0.0012414557859301567
Test Loss:  0.0008859082008711994
Valid Loss:  0.0015211679274216294
Epoch:  73  	Training Loss: 0.0012323912233114243
Test Loss:  0.0008760520722717047
Valid Loss:  0.0015105451457202435
Epoch:  74  	Training Loss: 0.0012237938353791833
Test Loss:  0.0008679951424710453
Valid Loss:  0.001500804559327662
Epoch:  75  	Training Loss: 0.0012153364950791001
Test Loss:  0.0008610646473243833
Valid Loss:  0.001491565490141511
Epoch:  76  	Training Loss: 0.0012069721706211567
Test Loss:  0.0008545186137780547
Valid Loss:  0.001482573919929564
Epoch:  77  	Training Loss: 0.00119880517013371
Test Loss:  0.0008481517434120178
Valid Loss:  0.0014736702432855964
Epoch:  78  	Training Loss: 0.0011907079024240375
Test Loss:  0.0008415349293500185
Valid Loss:  0.0014645402552559972
Epoch:  79  	Training Loss: 0.0011824887478724122
Test Loss:  0.0008353733574040234
Valid Loss:  0.0014555201632902026
Epoch:  80  	Training Loss: 0.0011745458468794823
Test Loss:  0.0008279421599581838
Valid Loss:  0.0014460200909525156
Epoch:  81  	Training Loss: 0.001166599104180932
Test Loss:  0.0008218314033001661
Valid Loss:  0.0014373459853231907
Epoch:  82  	Training Loss: 0.0011587622575461864
Test Loss:  0.0007960484363138676
Valid Loss:  0.0013863859931007028
Epoch:  83  	Training Loss: 0.0011114412918686867
Test Loss:  0.0007728312048129737
Valid Loss:  0.0013425196520984173
Epoch:  84  	Training Loss: 0.0010765551123768091
Test Loss:  0.0007534839678555727
Valid Loss:  0.0013061012141406536
Epoch:  85  	Training Loss: 0.0010505481623113155
Test Loss:  0.0007370391977019608
Valid Loss:  0.001275656744837761
Epoch:  86  	Training Loss: 0.0010288755875080824
Test Loss:  0.0007235060329549015
Valid Loss:  0.0012489499058574438
Epoch:  87  	Training Loss: 0.001010183128528297
Test Loss:  0.000712698558345437
Valid Loss:  0.0012255500769242644
Epoch:  88  	Training Loss: 0.0009939493611454964
Test Loss:  0.0007025441154837608
Valid Loss:  0.001204932457767427
Epoch:  89  	Training Loss: 0.0009813844226300716
Test Loss:  0.0006939760642126203
Valid Loss:  0.0011907242005690932
Epoch:  90  	Training Loss: 0.0009712986648082733
Test Loss:  0.0006867165211588144
Valid Loss:  0.0011780206114053726
Epoch:  91  	Training Loss: 0.0009615943417884409
Test Loss:  0.0006801564013585448
Valid Loss:  0.0011658911826089025
Epoch:  92  	Training Loss: 0.0009524709894321859
Test Loss:  0.000691272784024477
Valid Loss:  0.0011629161890596151
Epoch:  93  	Training Loss: 0.00094275560695678
Test Loss:  0.0006833123043179512
Valid Loss:  0.0011529203038662672
Epoch:  94  	Training Loss: 0.0009350992040708661
Test Loss:  0.0006768648745492101
Valid Loss:  0.0011443786788731813
Epoch:  95  	Training Loss: 0.0009280206868425012
Test Loss:  0.0006696184864267707
Valid Loss:  0.0011359851341694593
Epoch:  96  	Training Loss: 0.0009213963057845831
Test Loss:  0.0006627672119066119
Valid Loss:  0.0011281665647402406
Epoch:  97  	Training Loss: 0.0009152130223810673
Test Loss:  0.0006567951058968902
Valid Loss:  0.00112084299325943
Epoch:  98  	Training Loss: 0.0009091395186260343
Test Loss:  0.0006521118339151144
Valid Loss:  0.0011140626156702638
Epoch:  99  	Training Loss: 0.0009032555390149355
Test Loss:  0.0006468137726187706
Valid Loss:  0.0011070433538407087
Epoch:  100  	Training Loss: 0.000897483725566417
Test Loss:  0.0006409999914467335
Valid Loss:  0.0011000402737408876
Epoch:  101  	Training Loss: 0.0008918469538912177
Test Loss:  0.000635989592410624
Valid Loss:  0.0010934430174529552
Epoch:  102  	Training Loss: 0.0008863319526426494
Test Loss:  0.0006152383866719902
Valid Loss:  0.0010671636555343866
Epoch:  103  	Training Loss: 0.0008630218799225986
Test Loss:  0.000602435611654073
Valid Loss:  0.001040781382471323
Epoch:  104  	Training Loss: 0.0008347973925992846
Test Loss:  0.0005785779212601483
Valid Loss:  0.0010057243052870035
Epoch:  105  	Training Loss: 0.0008038096129894257
Test Loss:  0.0005551758222281933
Valid Loss:  0.0009697898058220744
Epoch:  106  	Training Loss: 0.0007692978833802044
Test Loss:  0.0005222945474088192
Valid Loss:  0.0009248167043551803
Epoch:  107  	Training Loss: 0.0007317583658732474
Test Loss:  0.0004959028447046876
Valid Loss:  0.0008890802273526788
Epoch:  108  	Training Loss: 0.0007010865956544876
Test Loss:  0.0004711283545475453
Valid Loss:  0.000856614438816905
Epoch:  109  	Training Loss: 0.0006734523922204971
Test Loss:  0.00044905010145157576
Valid Loss:  0.0008282465278171003
Epoch:  110  	Training Loss: 0.0006498916773125529
Test Loss:  0.00042815349297598004
Valid Loss:  0.0008033872582018375
Epoch:  111  	Training Loss: 0.0006299745291471481
Test Loss:  0.000411604210967198
Valid Loss:  0.0007825425127521157
Epoch:  112  	Training Loss: 0.0006123228813521564
Test Loss:  0.000401900993892923
Valid Loss:  0.000775469234213233
Epoch:  113  	Training Loss: 0.0006093589472584426
Test Loss:  0.00039982469752430916
Valid Loss:  0.0007719449931755662
Epoch:  114  	Training Loss: 0.0006068568909540772
Test Loss:  0.0003980306501034647
Valid Loss:  0.0007688861805945635
Epoch:  115  	Training Loss: 0.0006045466288924217
Test Loss:  0.00039609349914826453
Valid Loss:  0.0007658523973077536
Epoch:  116  	Training Loss: 0.0006024056347087026
Test Loss:  0.0003942563198506832
Valid Loss:  0.000763214542530477
Epoch:  117  	Training Loss: 0.0006003712769597769
Test Loss:  0.000392652815207839
Valid Loss:  0.0007608095183968544
Epoch:  118  	Training Loss: 0.0005984109593555331
Test Loss:  0.00039091467624530196
Valid Loss:  0.0007584644481539726
Epoch:  119  	Training Loss: 0.0005964729934930801
Test Loss:  0.00038946967106312513
Valid Loss:  0.0007562343962490559
Epoch:  120  	Training Loss: 0.000594589626416564
Test Loss:  0.0003879159630741924
Valid Loss:  0.000753927743062377
Epoch:  121  	Training Loss: 0.0005927379825152457
Test Loss:  0.0003862258745357394
Valid Loss:  0.0007516237674281001
Epoch:  122  	Training Loss: 0.0005909247556701303
Test Loss:  0.00039158720755949616
Valid Loss:  0.0007511965231969953
Epoch:  123  	Training Loss: 0.0005864286795258522
Test Loss:  0.00038986452273093164
Valid Loss:  0.0007478888146579266
Epoch:  124  	Training Loss: 0.0005827991990372539
Test Loss:  0.00038734852569177747
Valid Loss:  0.000744221149943769
Epoch:  125  	Training Loss: 0.0005794687895104289
Test Loss:  0.00038507592398673296
Valid Loss:  0.0007408297969959676
Epoch:  126  	Training Loss: 0.0005764031084254384
Test Loss:  0.0003830157220363617
Valid Loss:  0.0007377332076430321
Epoch:  127  	Training Loss: 0.0005734930164180696
Test Loss:  0.0003808971378020942
Valid Loss:  0.0007346941856667399
Epoch:  128  	Training Loss: 0.0005708476528525352
Test Loss:  0.00037904834607616067
Valid Loss:  0.000731964479200542
Epoch:  129  	Training Loss: 0.000568414106965065
Test Loss:  0.00037716032238677144
Valid Loss:  0.0007294589886441827
Epoch:  130  	Training Loss: 0.0005662210751324892
Test Loss:  0.00037567008985206485
Valid Loss:  0.0007271732902154326
Epoch:  131  	Training Loss: 0.0005641388706862926
Test Loss:  0.00037426577182486653
Valid Loss:  0.0007249173359014094
Epoch:  132  	Training Loss: 0.000562199333216995
Test Loss:  0.0003671138547360897
Valid Loss:  0.0007173263584263623
Epoch:  133  	Training Loss: 0.0005576045950874686
Test Loss:  0.00036496168468147516
Valid Loss:  0.0007123527466319501
Epoch:  134  	Training Loss: 0.0005533485673367977
Test Loss:  0.0003626780235208571
Valid Loss:  0.0007078032358549535
Epoch:  135  	Training Loss: 0.0005494027864187956
Test Loss:  0.0003605539968702942
Valid Loss:  0.0007037157192826271
Epoch:  136  	Training Loss: 0.000545716262422502
Test Loss:  0.00035837641917169094
Valid Loss:  0.0006999423494562507
Epoch:  137  	Training Loss: 0.0005422963295131922
Test Loss:  0.0003568583633750677
Valid Loss:  0.0006964073400013149
 28%|██▊       | 139/500 [01:41<01:59,  3.03it/s] 28%|██▊       | 141/500 [01:47<07:01,  1.17s/it] 29%|██▊       | 143/500 [01:47<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:47<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:47<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:47<01:57,  3.00it/s] 30%|███       | 151/500 [01:54<06:49,  1.17s/it] 31%|███       | 153/500 [01:54<04:52,  1.19it/s] 31%|███       | 155/500 [01:54<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:54<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:54<01:53,  3.00it/s] 32%|███▏      | 161/500 [02:00<06:32,  1.16s/it] 33%|███▎      | 163/500 [02:01<04:40,  1.20it/s] 33%|███▎      | 165/500 [02:01<03:21,  1.66it/s] 33%|███▎      | 167/500 [02:01<02:26,  2.27it/s] 34%|███▍      | 169/500 [02:01<01:48,  3.04it/s] 34%|███▍      | 171/500 [02:07<06:21,  1.16s/it] 35%|███▍      | 173/500 [02:07<04:32,  1.20it/s] 35%|███▌      | 175/500 [02:07<03:15,  1.66it/s] 35%|███▌      | 177/500 [02:08<02:22,  2.26it/s] 36%|███▌      | 179/500 [02:08<01:45,  3.03it/s] 36%|███▌      | 181/500 [02:14<06:09,  1.16s/it] 37%|███▋      | 183/500 [02:14<04:23,  1.20it/s] 37%|███▋      | 185/500 [02:14<03:09,  1.66it/s] 37%|███▋      | 187/500 [02:14<02:17,  2.27it/s] 38%|███▊      | 189/500 [02:14<01:42,  3.04it/s] 38%|███▊      | 191/500 [02:21<05:58,  1.16s/it] 39%|███▊      | 193/500 [02:21<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:21<03:03,  1.66it/s] 39%|███▉      | 197/500 [02:21<02:13,  2.27it/s] 40%|███▉      | 199/500 [02:21<01:39,  3.03it/s] 40%|████      | 201/500 [02:27<05:49,  1.17s/it] 41%|████      | 203/500 [02:27<04:09,  1.19it/s]Epoch:  138  	Training Loss: 0.0005390436272136867
Test Loss:  0.0003554718568921089
Valid Loss:  0.0006930411327630281
Epoch:  139  	Training Loss: 0.0005360761424526572
Test Loss:  0.00035419451887719333
Valid Loss:  0.0006899194559082389
Epoch:  140  	Training Loss: 0.0005334363668225706
Test Loss:  0.00035294174449518323
Valid Loss:  0.0006869554053992033
Epoch:  141  	Training Loss: 0.0005309361149556935
Test Loss:  0.00035168445901945233
Valid Loss:  0.0006843848968856037
Epoch:  142  	Training Loss: 0.0005287132225930691
Test Loss:  0.00035035150358453393
Valid Loss:  0.0006820418639108539
Epoch:  143  	Training Loss: 0.0005264617502689362
Test Loss:  0.00034975417656823993
Valid Loss:  0.0006799679831601679
Epoch:  144  	Training Loss: 0.0005243837367743254
Test Loss:  0.0003488082729745656
Valid Loss:  0.0006776467198505998
Epoch:  145  	Training Loss: 0.0005224539781920612
Test Loss:  0.00034793003578670323
Valid Loss:  0.00067535211564973
Epoch:  146  	Training Loss: 0.0005206373753026128
Test Loss:  0.0003473932156339288
Valid Loss:  0.0006723786937072873
Epoch:  147  	Training Loss: 0.0005188330542296171
Test Loss:  0.0003578159958124161
Valid Loss:  0.0006780641851946712
Epoch:  148  	Training Loss: 0.0005184460896998644
Test Loss:  0.0003379149711690843
Valid Loss:  0.0006665507098659873
Epoch:  149  	Training Loss: 0.0005166473565623164
Test Loss:  0.00034674128983169794
Valid Loss:  0.0006679196376353502
Epoch:  150  	Training Loss: 0.0005147398915141821
Test Loss:  0.0003538896271493286
Valid Loss:  0.000672031776048243
Epoch:  151  	Training Loss: 0.0005143499001860619
Test Loss:  0.00033711432479321957
Valid Loss:  0.0006620715139433742
Epoch:  152  	Training Loss: 0.0005127171170897782
Test Loss:  0.0003380528651177883
Valid Loss:  0.0006491919048130512
Epoch:  153  	Training Loss: 0.0004966886481270194
Test Loss:  0.0003210310824215412
Valid Loss:  0.0006310989265330136
Epoch:  154  	Training Loss: 0.0004844089853577316
Test Loss:  0.0003117728920187801
Valid Loss:  0.0006184716476127505
Epoch:  155  	Training Loss: 0.0004749339132104069
Test Loss:  0.0003031733212992549
Valid Loss:  0.0006079504964873195
Epoch:  156  	Training Loss: 0.0004679127596318722
Test Loss:  0.0002958373515866697
Valid Loss:  0.0005997238913550973
Epoch:  157  	Training Loss: 0.00046235034824348986
Test Loss:  0.0002904499415308237
Valid Loss:  0.0005928962491452694
Epoch:  158  	Training Loss: 0.00045726497774012387
Test Loss:  0.00028545601526275277
Valid Loss:  0.0005865689017809927
Epoch:  159  	Training Loss: 0.00045265821972861886
Test Loss:  0.00028133473824709654
Valid Loss:  0.0005808488931506872
Epoch:  160  	Training Loss: 0.0004484335076995194
Test Loss:  0.0002772264997474849
Valid Loss:  0.0005754837766289711
Epoch:  161  	Training Loss: 0.00044453327427618206
Test Loss:  0.0002737085451371968
Valid Loss:  0.0005705132498405874
Epoch:  162  	Training Loss: 0.0004408704407978803
Test Loss:  0.00026710820384323597
Valid Loss:  0.0005635358393192291
Epoch:  163  	Training Loss: 0.00043566408567130566
Test Loss:  0.00026284920750185847
Valid Loss:  0.0005581677542068064
Epoch:  164  	Training Loss: 0.00043088389793410897
Test Loss:  0.0002590747899375856
Valid Loss:  0.0005532705690711737
Epoch:  165  	Training Loss: 0.0004265343304723501
Test Loss:  0.00025588838616386056
Valid Loss:  0.000548624899238348
Epoch:  166  	Training Loss: 0.0004225042648613453
Test Loss:  0.0002529545745346695
Valid Loss:  0.0005443789414130151
Epoch:  167  	Training Loss: 0.0004190014733467251
Test Loss:  0.0002502411953173578
Valid Loss:  0.0005405365955084562
Epoch:  168  	Training Loss: 0.0004158629453741014
Test Loss:  0.0002475560177117586
Valid Loss:  0.0005371585721150041
Epoch:  169  	Training Loss: 0.0004132337053306401
Test Loss:  0.00024529031361453235
Valid Loss:  0.0005341963842511177
Epoch:  170  	Training Loss: 0.00041081354720517993
Test Loss:  0.0002431797911413014
Valid Loss:  0.0005314776208251715
Epoch:  171  	Training Loss: 0.00040852228994481266
Test Loss:  0.0002413941256236285
Valid Loss:  0.0005289365071803331
Epoch:  172  	Training Loss: 0.0004062932566739619
Test Loss:  0.00023799121845513582
Valid Loss:  0.0005212733522057533
Epoch:  173  	Training Loss: 0.0003974424034822732
Test Loss:  0.0002352286537643522
Valid Loss:  0.0005153522361069918
Epoch:  174  	Training Loss: 0.00039122108137235045
Test Loss:  0.00023332523414865136
Valid Loss:  0.0005113545339554548
Epoch:  175  	Training Loss: 0.00038663853774778545
Test Loss:  0.00023149016487877816
Valid Loss:  0.0005074895452708006
Epoch:  176  	Training Loss: 0.0003825270105153322
Test Loss:  0.00022937095491215587
Valid Loss:  0.0005036030197516084
Epoch:  177  	Training Loss: 0.0003787453460972756
Test Loss:  0.00022710613848175853
Valid Loss:  0.0004995163180865347
Epoch:  178  	Training Loss: 0.00037484406493604183
Test Loss:  0.0002249175449833274
Valid Loss:  0.0004954303149133921
Epoch:  179  	Training Loss: 0.0003710083838086575
Test Loss:  0.00022267087479121983
Valid Loss:  0.0004913787706755102
Epoch:  180  	Training Loss: 0.0003672675811685622
Test Loss:  0.00022041905322112143
Valid Loss:  0.00048743560910224915
Epoch:  181  	Training Loss: 0.0003636634210124612
Test Loss:  0.0002182438038289547
Valid Loss:  0.00048361701192334294
Epoch:  182  	Training Loss: 0.0003602100186981261
Test Loss:  0.00021305971313267946
Valid Loss:  0.0004795839195139706
Epoch:  183  	Training Loss: 0.00035855566966347396
Test Loss:  0.0002086955209961161
Valid Loss:  0.0004747585626319051
Epoch:  184  	Training Loss: 0.0003557070158421993
Test Loss:  0.00020436420163605362
Valid Loss:  0.0004688646295107901
Epoch:  185  	Training Loss: 0.0003518504381645471
Test Loss:  0.00020181361469440162
Valid Loss:  0.00046437897253781557
Epoch:  186  	Training Loss: 0.00034890067763626575
Test Loss:  0.00020071087055839598
Valid Loss:  0.0004615739162545651
Epoch:  187  	Training Loss: 0.0003472731332294643
Test Loss:  0.0002003334229812026
Valid Loss:  0.00046003470197319984
Epoch:  188  	Training Loss: 0.00034624585532583296
Test Loss:  0.00019978963246103376
Valid Loss:  0.00045883265556767583
Epoch:  189  	Training Loss: 0.00034539197804406285
Test Loss:  0.0001993782352656126
Valid Loss:  0.00045786809641867876
Epoch:  190  	Training Loss: 0.0003446338523644954
Test Loss:  0.00019897855236195028
Valid Loss:  0.000457016663858667
Epoch:  191  	Training Loss: 0.0003439174615778029
Test Loss:  0.00019853218691423535
Valid Loss:  0.0004561662208288908
Epoch:  192  	Training Loss: 0.00034321966813877225
Test Loss:  0.00019712926587089896
Valid Loss:  0.0004549339646473527
Epoch:  193  	Training Loss: 0.0003420988214202225
Test Loss:  0.0001964882976608351
Valid Loss:  0.00045404082629829645
Epoch:  194  	Training Loss: 0.0003410195931792259
Test Loss:  0.00019595271442085505
Valid Loss:  0.0004531922750174999
Epoch:  195  	Training Loss: 0.00033997069112956524
Test Loss:  0.00019544106908142567
Valid Loss:  0.00045235687866806984
Epoch:  196  	Training Loss: 0.00033894876833073795
Test Loss:  0.00019494419393595308
Valid Loss:  0.000451526022516191
Epoch:  197  	Training Loss: 0.0003379525733180344
Test Loss:  0.00019446041551418602
Valid Loss:  0.00045069935731589794
Epoch:  198  	Training Loss: 0.00033697811886668205
Test Loss:  0.0001939931244123727
Valid Loss:  0.0004498781345319003
Epoch:  199  	Training Loss: 0.0003360315167810768
Test Loss:  0.0001935325126396492
Valid Loss:  0.0004490598803386092
Epoch:  200  	Training Loss: 0.00033510802313685417
Test Loss:  0.00019307549518998712
Valid Loss:  0.0004482399963308126
Epoch:  201  	Training Loss: 0.0003342014388181269
Test Loss:  0.00019262521527707577
Valid Loss:  0.0004474227025639266
Epoch:  202  	Training Loss: 0.0003333105705678463
Test Loss:  0.00019387337670195848
Valid Loss:  0.0004462591023184359
Epoch:  203  	Training Loss: 0.00033165811328217387
Test Loss:  0.00019186234567314386
Valid Loss:  0.0004437796014826745
Epoch:  204  	Training Loss: 0.0003300446842331439
Test Loss:  0.0001914685999508947
Valid Loss:  0.0004419758333824575
Epoch:  205  	Training Loss: 0.00032844243105500937
Test Loss:  0.0001902158692246303
 41%|████      | 205/500 [02:28<02:59,  1.65it/s] 41%|████▏     | 207/500 [02:28<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:28<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:34<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:34<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:34<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:35<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:35<01:33,  2.99it/s] 44%|████▍     | 221/500 [02:41<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:41<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:41<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:41<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:42<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:48<05:13,  1.17s/it] 47%|████▋     | 233/500 [02:48<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:48<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:48<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:48<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:55<05:01,  1.16s/it] 49%|████▊     | 243/500 [02:55<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:55<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:55<01:52,  2.26it/s] 50%|████▉     | 249/500 [02:55<01:22,  3.04it/s] 50%|█████     | 251/500 [03:01<04:50,  1.17s/it] 51%|█████     | 253/500 [03:01<03:26,  1.19it/s] 51%|█████     | 255/500 [03:02<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:02<01:47,  2.25it/s] 52%|█████▏    | 259/500 [03:02<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:08<04:38,  1.16s/it] 53%|█████▎    | 263/500 [03:08<03:18,  1.20it/s] 53%|█████▎    | 265/500 [03:08<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:08<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:09<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:15<04:26,  1.17s/it]Valid Loss:  0.00043976621236652136
Epoch:  206  	Training Loss: 0.0003268000145908445
Test Loss:  0.00018922550952993333
Valid Loss:  0.0004375893622636795
Epoch:  207  	Training Loss: 0.0003250514273531735
Test Loss:  0.000188012418220751
Valid Loss:  0.0004352542746346444
Epoch:  208  	Training Loss: 0.0003232282178942114
Test Loss:  0.0001868235704023391
Valid Loss:  0.0004329059738665819
Epoch:  209  	Training Loss: 0.0003213187155779451
Test Loss:  0.0001857815368566662
Valid Loss:  0.000430730520747602
Epoch:  210  	Training Loss: 0.0003195159661117941
Test Loss:  0.0001852588029578328
Valid Loss:  0.00042904363363049924
Epoch:  211  	Training Loss: 0.00031805771868675947
Test Loss:  0.00018480344442650676
Valid Loss:  0.00042752709123305976
Epoch:  212  	Training Loss: 0.0003166931273881346
Test Loss:  0.00018463071319274604
Valid Loss:  0.0004255186941009015
Epoch:  213  	Training Loss: 0.0003140541666653007
Test Loss:  0.00018269949941895902
Valid Loss:  0.00042231957195326686
Epoch:  214  	Training Loss: 0.00031188857974484563
Test Loss:  0.00018520717276260257
Valid Loss:  0.0004229219921398908
Epoch:  215  	Training Loss: 0.0003101245383732021
Test Loss:  0.00018105092749465257
Valid Loss:  0.00041868857806548476
Epoch:  216  	Training Loss: 0.00030789204174652696
Test Loss:  0.00018018345872405916
Valid Loss:  0.0004165839636698365
Epoch:  217  	Training Loss: 0.0003064077172894031
Test Loss:  0.00018285808619111776
Valid Loss:  0.00041725276969373226
Epoch:  218  	Training Loss: 0.00030490386416204274
Test Loss:  0.00017859152285382152
Valid Loss:  0.00041295052506029606
Epoch:  219  	Training Loss: 0.0003028149367310107
Test Loss:  0.00017773371655493975
Valid Loss:  0.0004109404399059713
Epoch:  220  	Training Loss: 0.0003015213878825307
Test Loss:  0.00018115331477019936
Valid Loss:  0.00041205561137758195
Epoch:  221  	Training Loss: 0.0003003588644787669
Test Loss:  0.0001761040766723454
Valid Loss:  0.00040749405161477625
Epoch:  222  	Training Loss: 0.00029836472822353244
Test Loss:  0.0001772418327163905
Valid Loss:  0.00040686261490918696
Epoch:  223  	Training Loss: 0.00029751716647297144
Test Loss:  0.00017748531536199152
Valid Loss:  0.00040602724766358733
Epoch:  224  	Training Loss: 0.000296791666187346
Test Loss:  0.00017731438856571913
Valid Loss:  0.0004050862626172602
Epoch:  225  	Training Loss: 0.0002960946876555681
Test Loss:  0.00017697582370601594
Valid Loss:  0.0004041054053232074
Epoch:  226  	Training Loss: 0.0002954074298031628
Test Loss:  0.00017657631542533636
Valid Loss:  0.0004031147400382906
Epoch:  227  	Training Loss: 0.00029472517780959606
Test Loss:  0.00017615864635445178
Valid Loss:  0.0004021243948955089
Epoch:  228  	Training Loss: 0.0002940475242212415
Test Loss:  0.00017572930664755404
Valid Loss:  0.00040113957948051393
Epoch:  229  	Training Loss: 0.00029337548767216504
Test Loss:  0.00017530142213217914
Valid Loss:  0.00040016346611082554
Epoch:  230  	Training Loss: 0.0002927089808508754
Test Loss:  0.00017487524019088596
Valid Loss:  0.00039919556002132595
Epoch:  231  	Training Loss: 0.0002920485567301512
Test Loss:  0.00017445810954086483
Valid Loss:  0.00039823853876441717
Epoch:  232  	Training Loss: 0.0002913920034188777
Test Loss:  0.0001721529697533697
Valid Loss:  0.0003960997855756432
Epoch:  233  	Training Loss: 0.00029022543458268046
Test Loss:  0.00017091182235162705
Valid Loss:  0.0003944438067264855
Epoch:  234  	Training Loss: 0.00028916518203914165
Test Loss:  0.00017006185953505337
Valid Loss:  0.00039297412149608135
Epoch:  235  	Training Loss: 0.0002881318796426058
Test Loss:  0.00016937017790041864
Valid Loss:  0.00039159110747277737
Epoch:  236  	Training Loss: 0.0002871143806260079
Test Loss:  0.00016873070853762329
Valid Loss:  0.00039024840225465596
Epoch:  237  	Training Loss: 0.0002861077373381704
Test Loss:  0.00016811085515655577
Valid Loss:  0.00038892996963113546
Epoch:  238  	Training Loss: 0.0002851077588275075
Test Loss:  0.00016750459326431155
Valid Loss:  0.0003876296686939895
Epoch:  239  	Training Loss: 0.00028411339735612273
Test Loss:  0.00016690039774402976
Valid Loss:  0.0003863437450490892
Epoch:  240  	Training Loss: 0.00028312692302279174
Test Loss:  0.0001662944268900901
Valid Loss:  0.00038506925920955837
Epoch:  241  	Training Loss: 0.00028214522171765566
Test Loss:  0.0001656856038607657
Valid Loss:  0.00038380181649699807
Epoch:  242  	Training Loss: 0.0002811680897139013
Test Loss:  0.00016494262672495097
Valid Loss:  0.0003797916870098561
Epoch:  243  	Training Loss: 0.0002782977535389364
Test Loss:  0.00016420597967226058
Valid Loss:  0.0003784053260460496
Epoch:  244  	Training Loss: 0.00027741878875531256
Test Loss:  0.00016357102140318602
Valid Loss:  0.00037708593299612403
Epoch:  245  	Training Loss: 0.00027655120356939733
Test Loss:  0.00016296913963742554
Valid Loss:  0.0003758088278118521
Epoch:  246  	Training Loss: 0.00027569240774028003
Test Loss:  0.00016239486285485327
Valid Loss:  0.0003745652502402663
Epoch:  247  	Training Loss: 0.0002748424303717911
Test Loss:  0.0001618461828911677
Valid Loss:  0.0003733480116352439
Epoch:  248  	Training Loss: 0.00027399908867664635
Test Loss:  0.00016131417942233384
Valid Loss:  0.00037215836346149445
Epoch:  249  	Training Loss: 0.00027316439081914723
Test Loss:  0.00016077928012236953
Valid Loss:  0.0003709925222210586
Epoch:  250  	Training Loss: 0.00027233746368438005
Test Loss:  0.00016027282981667668
Valid Loss:  0.00036984909093007445
Epoch:  251  	Training Loss: 0.0002715160371735692
Test Loss:  0.00015977746807038784
Valid Loss:  0.00036871928023174405
Epoch:  252  	Training Loss: 0.00027069958741776645
Test Loss:  0.0001603196724317968
Valid Loss:  0.0003677329805213958
Epoch:  253  	Training Loss: 0.00026953272754326463
Test Loss:  0.00016017181042116135
Valid Loss:  0.0003665498225018382
Epoch:  254  	Training Loss: 0.00026844762032851577
Test Loss:  0.0001598004309926182
Valid Loss:  0.00036529419594444335
Epoch:  255  	Training Loss: 0.00026739848544821143
Test Loss:  0.0001593398628756404
Valid Loss:  0.0003640036447905004
Epoch:  256  	Training Loss: 0.00026637149858288467
Test Loss:  0.00015882457955740392
Valid Loss:  0.00036268681287765503
Epoch:  257  	Training Loss: 0.0002653531264513731
Test Loss:  0.00015826791059225798
Valid Loss:  0.0003613363078329712
Epoch:  258  	Training Loss: 0.0002643336192704737
Test Loss:  0.0001576767535880208
Valid Loss:  0.0003599790798034519
Epoch:  259  	Training Loss: 0.00026332325069233775
Test Loss:  0.0001571143075125292
Valid Loss:  0.0003586439706850797
Epoch:  260  	Training Loss: 0.0002623353502713144
Test Loss:  0.0001565897255204618
Valid Loss:  0.00035733598633669317
Epoch:  261  	Training Loss: 0.00026139337569475174
Test Loss:  0.00015614679432474077
Valid Loss:  0.0003561197663657367
Epoch:  262  	Training Loss: 0.0002604994224384427
Test Loss:  0.00015274202451109886
Valid Loss:  0.00035334256244823337
Epoch:  263  	Training Loss: 0.0002594508114270866
Test Loss:  0.00015272715245373547
Valid Loss:  0.0003519830643199384
Epoch:  264  	Training Loss: 0.0002584887552075088
Test Loss:  0.0001500502257840708
Valid Loss:  0.00034876057179644704
Epoch:  265  	Training Loss: 0.00025632960023358464
Test Loss:  0.00014529380132444203
Valid Loss:  0.00034254189813509583
Epoch:  266  	Training Loss: 0.00025195820489898324
Test Loss:  0.00014377583283931017
Valid Loss:  0.0003379647387191653
Epoch:  267  	Training Loss: 0.0002485874865669757
Test Loss:  0.00014421166270039976
Valid Loss:  0.0003357018867973238
Epoch:  268  	Training Loss: 0.00024683389347046614
Test Loss:  0.0001442536449758336
Valid Loss:  0.0003339411923661828
Epoch:  269  	Training Loss: 0.00024555117124691606
Test Loss:  0.00014388964336831123
Valid Loss:  0.0003322836710140109
Epoch:  270  	Training Loss: 0.00024440622655674815
Test Loss:  0.00014364610251504928
Valid Loss:  0.0003309178864583373
Epoch:  271  	Training Loss: 0.00024339061928912997
Test Loss:  0.00014330667909234762
Valid Loss:  0.0003295741626061499
Epoch:  272  	Training Loss: 0.00024243604275397956
Test Loss:  0.0001432931749150157
Valid Loss:  0.0003283742116764188
 55%|█████▍    | 273/500 [03:15<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:15<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:15<01:38,  2.25it/s] 56%|█████▌    | 279/500 [03:15<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:22<04:17,  1.17s/it] 57%|█████▋    | 283/500 [03:22<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:22<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:22<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:22<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:28<04:02,  1.16s/it] 59%|█████▊    | 293/500 [03:29<02:52,  1.20it/s] 59%|█████▉    | 295/500 [03:29<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:29<01:29,  2.27it/s] 60%|█████▉    | 299/500 [03:29<01:05,  3.05it/s] 60%|██████    | 301/500 [03:35<03:49,  1.15s/it] 61%|██████    | 303/500 [03:35<02:43,  1.21it/s] 61%|██████    | 305/500 [03:35<01:56,  1.67it/s] 61%|██████▏   | 307/500 [03:35<01:24,  2.28it/s] 62%|██████▏   | 309/500 [03:36<01:02,  3.06it/s] 62%|██████▏   | 311/500 [03:42<03:38,  1.16s/it] 63%|██████▎   | 313/500 [03:42<02:35,  1.20it/s] 63%|██████▎   | 315/500 [03:42<01:51,  1.66it/s] 63%|██████▎   | 317/500 [03:42<01:20,  2.27it/s] 64%|██████▍   | 319/500 [03:42<00:59,  3.04it/s] 64%|██████▍   | 321/500 [03:49<03:26,  1.15s/it] 65%|██████▍   | 323/500 [03:49<02:26,  1.21it/s] 65%|██████▌   | 325/500 [03:49<01:45,  1.67it/s] 65%|██████▌   | 327/500 [03:49<01:16,  2.27it/s] 66%|██████▌   | 329/500 [03:49<00:55,  3.06it/s] 66%|██████▌   | 331/500 [03:55<03:15,  1.16s/it] 67%|██████▋   | 333/500 [03:55<02:18,  1.20it/s] 67%|██████▋   | 335/500 [03:55<01:39,  1.66it/s] 67%|██████▋   | 337/500 [03:56<01:11,  2.26it/s] 68%|██████▊   | 339/500 [03:56<00:52,  3.04it/s]Epoch:  273  	Training Loss: 0.0002412751637166366
Test Loss:  0.0001447444228688255
Valid Loss:  0.00032871344592422247
Epoch:  274  	Training Loss: 0.00024041644064709544
Test Loss:  0.00014348505646921694
Valid Loss:  0.00032706643105484545
Epoch:  275  	Training Loss: 0.00023941633116919547
Test Loss:  0.0001446005771867931
Valid Loss:  0.0003272363101132214
Epoch:  276  	Training Loss: 0.000238700769841671
Test Loss:  0.00014313776046037674
Valid Loss:  0.00032589794136583805
Epoch:  277  	Training Loss: 0.00023804319789633155
Test Loss:  0.00014571599604096264
Valid Loss:  0.00032701349118724465
Epoch:  278  	Training Loss: 0.00023760111071169376
Test Loss:  0.0001428225077688694
Valid Loss:  0.0003243894607294351
Epoch:  279  	Training Loss: 0.00023639285063836724
Test Loss:  0.00014298174937721342
Valid Loss:  0.00032372947316616774
Epoch:  280  	Training Loss: 0.00023570357006974518
Test Loss:  0.0001427720271749422
Valid Loss:  0.0003229923895560205
Epoch:  281  	Training Loss: 0.00023503697593696415
Test Loss:  0.00014278863091021776
Valid Loss:  0.00032242413726635277
Epoch:  282  	Training Loss: 0.000234403763897717
Test Loss:  0.00013919381308369339
Valid Loss:  0.0003193034208379686
Epoch:  283  	Training Loss: 0.00023226378834806383
Test Loss:  0.000138726900331676
Valid Loss:  0.00031735451193526387
Epoch:  284  	Training Loss: 0.00023034658806864172
Test Loss:  0.00013769976794719696
Valid Loss:  0.00031527644023299217
Epoch:  285  	Training Loss: 0.00022857885051053017
Test Loss:  0.0001368273951811716
Valid Loss:  0.00031329301418736577
Epoch:  286  	Training Loss: 0.0002269070828333497
Test Loss:  0.0001359831658191979
Valid Loss:  0.0003113598795607686
Epoch:  287  	Training Loss: 0.00022532219009008259
Test Loss:  0.00013515600585378706
Valid Loss:  0.00030949211213737726
Epoch:  288  	Training Loss: 0.00022379300207830966
Test Loss:  0.00013434675929602236
Valid Loss:  0.0003076769062317908
Epoch:  289  	Training Loss: 0.00022231698676478118
Test Loss:  0.00013355691044125706
Valid Loss:  0.0003059352748095989
Epoch:  290  	Training Loss: 0.00022090450511313975
Test Loss:  0.00013279396807774901
Valid Loss:  0.0003042376774828881
Epoch:  291  	Training Loss: 0.00021955248666927218
Test Loss:  0.00013206267612986267
Valid Loss:  0.0003025737823918462
Epoch:  292  	Training Loss: 0.0002182314929086715
Test Loss:  0.00013163965195417404
Valid Loss:  0.0003003869205713272
Epoch:  293  	Training Loss: 0.00021664072119165212
Test Loss:  0.00013070240675006062
Valid Loss:  0.00029811979038640857
Epoch:  294  	Training Loss: 0.00021510364604182541
Test Loss:  0.00013011551345698535
Valid Loss:  0.0002961161662824452
Epoch:  295  	Training Loss: 0.00021360043319873512
Test Loss:  0.0001288296189159155
Valid Loss:  0.00029378326144069433
Epoch:  296  	Training Loss: 0.0002121106954291463
Test Loss:  0.0001283206802327186
Valid Loss:  0.00029188109328970313
Epoch:  297  	Training Loss: 0.00021065387409180403
Test Loss:  0.00012713375326711684
Valid Loss:  0.0002896571240853518
Epoch:  298  	Training Loss: 0.00020920686074532568
Test Loss:  0.00012644933303818107
Valid Loss:  0.0002877014339901507
Epoch:  299  	Training Loss: 0.00020778756879735738
Test Loss:  0.0001255955285159871
Valid Loss:  0.00028570034191943705
Epoch:  300  	Training Loss: 0.00020638867863453925
Test Loss:  0.00012478596181608737
Valid Loss:  0.00028373938403092325
Epoch:  301  	Training Loss: 0.0002050094772130251
Test Loss:  0.00012400107516441494
Valid Loss:  0.0002818147768266499
Epoch:  302  	Training Loss: 0.00020364971715025604
Test Loss:  0.00012471740774344653
Valid Loss:  0.00028125965036451817
Epoch:  303  	Training Loss: 0.00020327084348537028
Test Loss:  0.0001248568732989952
Valid Loss:  0.0002808560966514051
Epoch:  304  	Training Loss: 0.00020298452000133693
Test Loss:  0.0001247842301381752
Valid Loss:  0.0002804931718856096
Epoch:  305  	Training Loss: 0.00020271122048143297
Test Loss:  0.0001246590109076351
Valid Loss:  0.0002801412483677268
Epoch:  306  	Training Loss: 0.0002024420100497082
Test Loss:  0.00012452078226488084
Valid Loss:  0.00027979648439213634
Epoch:  307  	Training Loss: 0.00020217528799548745
Test Loss:  0.00012438009434845299
Valid Loss:  0.0002794574829749763
Epoch:  308  	Training Loss: 0.00020191154908388853
Test Loss:  0.00012424145825207233
Valid Loss:  0.0002791217411868274
Epoch:  309  	Training Loss: 0.00020164871239103377
Test Loss:  0.00012408832844812423
Valid Loss:  0.0002787938283290714
Epoch:  310  	Training Loss: 0.0002013860794249922
Test Loss:  0.00012395162775646895
Valid Loss:  0.0002784699900075793
Epoch:  311  	Training Loss: 0.00020112560014240444
Test Loss:  0.00012381990381982177
Valid Loss:  0.0002781494113150984
Epoch:  312  	Training Loss: 0.00020086753647774458
Test Loss:  0.000123799400171265
Valid Loss:  0.00027771794702857733
Epoch:  313  	Training Loss: 0.00020044660777784884
Test Loss:  0.00012372717901598662
Valid Loss:  0.0002773029264062643
Epoch:  314  	Training Loss: 0.00020003481768071651
Test Loss:  0.00012363941641524434
Valid Loss:  0.00027689686976373196
Epoch:  315  	Training Loss: 0.0001996318023884669
Test Loss:  0.00012354686623439193
Valid Loss:  0.00027649541152641177
Epoch:  316  	Training Loss: 0.0001992374745896086
Test Loss:  0.00012345406867098063
Valid Loss:  0.0002761005889624357
Epoch:  317  	Training Loss: 0.00019884953508153558
Test Loss:  0.00012335253995843232
Valid Loss:  0.00027571330429054797
Epoch:  318  	Training Loss: 0.00019846919167321175
Test Loss:  0.00012325576972216368
Valid Loss:  0.00027532887179404497
Epoch:  319  	Training Loss: 0.00019809426157735288
Test Loss:  0.00012315937783569098
Valid Loss:  0.0002749486593529582
Epoch:  320  	Training Loss: 0.00019772478844970465
Test Loss:  0.00012306221469771117
Valid Loss:  0.0002745712408795953
Epoch:  321  	Training Loss: 0.00019735837122425437
Test Loss:  0.00012292386963963509
Valid Loss:  0.00027420310652814806
Epoch:  322  	Training Loss: 0.0001969905279111117
Test Loss:  0.00012092764518456534
Valid Loss:  0.0002726372913457453
Epoch:  323  	Training Loss: 0.00019593804609030485
Test Loss:  0.00012037953274557367
Valid Loss:  0.00027146004140377045
Epoch:  324  	Training Loss: 0.00019503958174027503
Test Loss:  0.00011999100388493389
Valid Loss:  0.00027033931110054255
Epoch:  325  	Training Loss: 0.0001941729715326801
Test Loss:  0.00011960179836023599
Valid Loss:  0.0002692335983738303
Epoch:  326  	Training Loss: 0.00019334512762725353
Test Loss:  0.00011920102406293154
Valid Loss:  0.0002681315236259252
Epoch:  327  	Training Loss: 0.00019253770005889237
Test Loss:  0.00011883700790349394
Valid Loss:  0.00026701553724706173
Epoch:  328  	Training Loss: 0.0001917328336276114
Test Loss:  0.00011841626837849617
Valid Loss:  0.00026589978369884193
Epoch:  329  	Training Loss: 0.0001909411366796121
Test Loss:  0.00011800590436905622
Valid Loss:  0.0002648174995556474
Epoch:  330  	Training Loss: 0.00019017665181308985
Test Loss:  0.00011761182395275682
Valid Loss:  0.00026379182236269116
Epoch:  331  	Training Loss: 0.00018943189934361726
Test Loss:  0.00011721748160198331
Valid Loss:  0.00026279129087924957
Epoch:  332  	Training Loss: 0.00018870169878937304
Test Loss:  0.0001183575441245921
Valid Loss:  0.0002622882602736354
Epoch:  333  	Training Loss: 0.0001882425567600876
Test Loss:  0.00011867615103255957
Valid Loss:  0.00026188313495367765
Epoch:  334  	Training Loss: 0.00018791390175465494
Test Loss:  0.00011870184971485287
Valid Loss:  0.0002614762051962316
Epoch:  335  	Training Loss: 0.00018759933300316334
Test Loss:  0.00011862444807775319
Valid Loss:  0.0002610613591969013
Epoch:  336  	Training Loss: 0.00018728575378190726
Test Loss:  0.00011850625742226839
Valid Loss:  0.00026063958648592234
Epoch:  337  	Training Loss: 0.00018697403720580041
Test Loss:  0.00011837200145237148
Valid Loss:  0.0002602142048999667
Epoch:  338  	Training Loss: 0.00018666358664631844
Test Loss:  0.00011823255044873804
Valid Loss:  0.0002597853890620172
Epoch:  339  	Training Loss: 0.00018635194282978773
Test Loss:  0.00011809005809482187
Valid Loss:  0.00025935337180271745
 68%|██████▊   | 341/500 [04:02<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:02<02:12,  1.19it/s] 69%|██████▉   | 345/500 [04:02<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:02<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:03<00:50,  3.01it/s] 70%|███████   | 351/500 [04:09<02:55,  1.18s/it] 71%|███████   | 353/500 [04:09<02:04,  1.18it/s] 71%|███████   | 355/500 [04:09<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:09<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:09<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:16<02:41,  1.16s/it] 73%|███████▎  | 363/500 [04:16<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:16<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:16<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:16<00:45,  2.91it/s] 74%|███████▍  | 371/500 [04:22<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:23<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:23<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:23<00:55,  2.24it/s] 76%|███████▌  | 379/500 [04:23<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:29<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:29<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:30<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:30<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:30<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:36<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:36<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:36<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:36<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:37<00:33,  3.01it/s] 80%|████████  | 401/500 [04:43<01:54,  1.16s/it] 81%|████████  | 403/500 [04:43<01:20,  1.20it/s] 81%|████████  | 405/500 [04:43<00:57,  1.65it/s]Epoch:  340  	Training Loss: 0.00018604016804601997
Test Loss:  0.00011794018791988492
Valid Loss:  0.0002589196665212512
Epoch:  341  	Training Loss: 0.00018572912085801363
Test Loss:  0.00011779226770158857
Valid Loss:  0.0002584857866168022
Epoch:  342  	Training Loss: 0.0001854166475823149
Test Loss:  0.0001160401152446866
Valid Loss:  0.0002574617392383516
Epoch:  343  	Training Loss: 0.00018487885245122015
Test Loss:  0.00011514240759424865
Valid Loss:  0.0002567170013207942
Epoch:  344  	Training Loss: 0.0001844907528720796
Test Loss:  0.00011462013208074495
Valid Loss:  0.0002560834982432425
Epoch:  345  	Training Loss: 0.00018414363148622215
Test Loss:  0.00011427261051721871
Valid Loss:  0.00025550712598487735
Epoch:  346  	Training Loss: 0.00018381301197223365
Test Loss:  0.00011401341180317104
Valid Loss:  0.0002549654454924166
Epoch:  347  	Training Loss: 0.00018349196761846542
Test Loss:  0.0001138006045948714
Valid Loss:  0.0002544493763707578
Epoch:  348  	Training Loss: 0.00018317910144105554
Test Loss:  0.00011360344069544226
Valid Loss:  0.00025395676493644714
Epoch:  349  	Training Loss: 0.00018287351122125983
Test Loss:  0.00011342881043674424
Valid Loss:  0.0002534790546633303
Epoch:  350  	Training Loss: 0.00018257071496918797
Test Loss:  0.00011326603998895735
Valid Loss:  0.00025301374262198806
Epoch:  351  	Training Loss: 0.00018227187683805823
Test Loss:  0.00011311226990073919
Valid Loss:  0.00025255861692130566
Epoch:  352  	Training Loss: 0.00018197624012827873
Test Loss:  0.00011365281534381211
Valid Loss:  0.0002518417895771563
Epoch:  353  	Training Loss: 0.00018144925707019866
Test Loss:  0.00011349408305250108
Valid Loss:  0.0002511462371330708
Epoch:  354  	Training Loss: 0.00018098033615387976
Test Loss:  0.0001132078468799591
Valid Loss:  0.0002504530712030828
Epoch:  355  	Training Loss: 0.00018051534425467253
Test Loss:  0.0001129057927755639
Valid Loss:  0.00024976435815915465
Epoch:  356  	Training Loss: 0.00018005467427428812
Test Loss:  0.0001126071801991202
Valid Loss:  0.0002490806800778955
Epoch:  357  	Training Loss: 0.00017959582328330725
Test Loss:  0.00011231050302740186
Valid Loss:  0.0002484000870026648
Epoch:  358  	Training Loss: 0.00017913941701408476
Test Loss:  0.00011201473535038531
Valid Loss:  0.0002477231901139021
Epoch:  359  	Training Loss: 0.00017868490249384195
Test Loss:  0.00011169943900313228
Valid Loss:  0.0002470562467351556
Epoch:  360  	Training Loss: 0.0001782316976459697
Test Loss:  0.00011140939022880048
Valid Loss:  0.00024639206822030246
Epoch:  361  	Training Loss: 0.0001777804282028228
Test Loss:  0.00011112212087027729
Valid Loss:  0.00024572983966208994
Epoch:  362  	Training Loss: 0.0001773318654159084
Test Loss:  0.00010974348697345704
Valid Loss:  0.0002444844867568463
Epoch:  363  	Training Loss: 0.00017649511573836207
Test Loss:  0.00010969953291350976
Valid Loss:  0.00024336545902770013
Epoch:  364  	Training Loss: 0.00017567709437571466
Test Loss:  0.00010911052959272638
Valid Loss:  0.00024220754858106375
Epoch:  365  	Training Loss: 0.00017486467550043017
Test Loss:  0.00010875255975406617
Valid Loss:  0.00024106225464493036
Epoch:  366  	Training Loss: 0.00017405202379450202
Test Loss:  0.00010826338257174939
Valid Loss:  0.00023991483612917364
Epoch:  367  	Training Loss: 0.00017324229702353477
Test Loss:  0.000107819345430471
Valid Loss:  0.00023877453349996358
Epoch:  368  	Training Loss: 0.00017243667389266193
Test Loss:  0.00010734966781456023
Valid Loss:  0.00023763402714394033
Epoch:  369  	Training Loss: 0.00017163832671940327
Test Loss:  0.00010688656766433269
Valid Loss:  0.0002365160034969449
Epoch:  370  	Training Loss: 0.0001708492636680603
Test Loss:  0.00010642407869454473
Valid Loss:  0.00023541238624602556
Epoch:  371  	Training Loss: 0.00017006960115395486
Test Loss:  0.00010597154323477298
Valid Loss:  0.00023431597219314426
Epoch:  372  	Training Loss: 0.00016929599223658442
Test Loss:  0.00010476783791091293
Valid Loss:  0.00023330390104092658
Epoch:  373  	Training Loss: 0.0001688453194219619
Test Loss:  0.00010455030133016407
Valid Loss:  0.00023283701739273965
Epoch:  374  	Training Loss: 0.00016860228788573295
Test Loss:  0.00010446932719787583
Valid Loss:  0.00023246760247275233
Epoch:  375  	Training Loss: 0.00016837184375617653
Test Loss:  0.00010434839350637048
Valid Loss:  0.00023211132793221623
Epoch:  376  	Training Loss: 0.0001681461144471541
Test Loss:  0.00010429347457829863
Valid Loss:  0.00023179486743174493
Epoch:  377  	Training Loss: 0.0001679236738709733
Test Loss:  0.00010420945181977004
Valid Loss:  0.00023147548199631274
Epoch:  378  	Training Loss: 0.00016770180081948638
Test Loss:  0.00010412752453703433
Valid Loss:  0.00023115001386031508
Epoch:  379  	Training Loss: 0.00016747607151046395
Test Loss:  0.00010402520274510607
Valid Loss:  0.000230826684855856
Epoch:  380  	Training Loss: 0.00016725313616916537
Test Loss:  0.00010398673475719988
Valid Loss:  0.00023053227050695568
Epoch:  381  	Training Loss: 0.00016703247092664242
Test Loss:  0.00010384730558143929
Valid Loss:  0.00023020931985229254
Epoch:  382  	Training Loss: 0.0001668125914875418
Test Loss:  0.0001027474645525217
Valid Loss:  0.0002291966520715505
Epoch:  383  	Training Loss: 0.00016635113570373505
Test Loss:  0.00010215682414127514
Valid Loss:  0.0002283670037286356
Epoch:  384  	Training Loss: 0.00016596372006461024
Test Loss:  0.00010163853585254401
Valid Loss:  0.00022763288870919496
Epoch:  385  	Training Loss: 0.0001656019885558635
Test Loss:  0.00010115384066011757
Valid Loss:  0.00022693643404636532
Epoch:  386  	Training Loss: 0.0001652443315833807
Test Loss:  0.00010060607746709138
Valid Loss:  0.00022618562798015773
Epoch:  387  	Training Loss: 0.00016487101675011218
Test Loss:  0.00010010797996073961
Valid Loss:  0.000225480500375852
Epoch:  388  	Training Loss: 0.0001645092124817893
Test Loss:  9.963408956537023e-05
Valid Loss:  0.00022482560598291457
Epoch:  389  	Training Loss: 0.0001641534036025405
Test Loss:  9.920053707901388e-05
Valid Loss:  0.00022420985624194145
Epoch:  390  	Training Loss: 0.00016380700981244445
Test Loss:  9.882235463010147e-05
Valid Loss:  0.00022365240147337317
Epoch:  391  	Training Loss: 0.00016347813652828336
Test Loss:  9.853535448201001e-05
Valid Loss:  0.0002231854887213558
Epoch:  392  	Training Loss: 0.00016316972323693335
Test Loss:  9.948985825758427e-05
Valid Loss:  0.00022249860921874642
Epoch:  393  	Training Loss: 0.0001623277203179896
Test Loss:  9.957393922377378e-05
Valid Loss:  0.0002218646986875683
Epoch:  394  	Training Loss: 0.00016165772103704512
Test Loss:  9.957305883290246e-05
Valid Loss:  0.00022123286908026785
Epoch:  395  	Training Loss: 0.00016105560644064099
Test Loss:  9.953607514034957e-05
Valid Loss:  0.0002205770870205015
Epoch:  396  	Training Loss: 0.00016049735131673515
Test Loss:  9.946383943315595e-05
Valid Loss:  0.00021990595269016922
Epoch:  397  	Training Loss: 0.00015996635193005204
Test Loss:  9.936685091815889e-05
Valid Loss:  0.00021922985615674406
Epoch:  398  	Training Loss: 0.0001594533969182521
Test Loss:  9.92390196188353e-05
Valid Loss:  0.00021854561055079103
Epoch:  399  	Training Loss: 0.00015895263641141355
Test Loss:  9.909611253533512e-05
Valid Loss:  0.0002178599825128913
Epoch:  400  	Training Loss: 0.00015846235328353941
Test Loss:  9.893401147564873e-05
Valid Loss:  0.0002171727392124012
Epoch:  401  	Training Loss: 0.00015798051026649773
Test Loss:  9.87570674624294e-05
Valid Loss:  0.00021648764959536493
Epoch:  402  	Training Loss: 0.00015750573948025703
Test Loss:  9.899475844576955e-05
Valid Loss:  0.0002161734737455845
Epoch:  403  	Training Loss: 0.00015726668061688542
Test Loss:  9.912124369293451e-05
Valid Loss:  0.00021585857030004263
Epoch:  404  	Training Loss: 0.00015704102406743914
Test Loss:  9.917415445670485e-05
Valid Loss:  0.00021553780243266374
Epoch:  405  	Training Loss: 0.0001568200095789507
Test Loss:  9.91745400824584e-05
Valid Loss:  0.00021520396694540977
Epoch:  406  	Training Loss: 0.0001565978891449049
Test Loss:  9.912952373269945e-05
Valid Loss:  0.00021485105389729142
 81%|████████▏ | 407/500 [04:43<00:41,  2.26it/s] 82%|████████▏ | 409/500 [04:43<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:50<01:43,  1.16s/it] 83%|████████▎ | 413/500 [04:50<01:12,  1.20it/s] 83%|████████▎ | 415/500 [04:50<00:51,  1.66it/s] 83%|████████▎ | 417/500 [04:50<00:36,  2.26it/s] 84%|████████▍ | 419/500 [04:50<00:26,  3.03it/s] 84%|████████▍ | 421/500 [04:56<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:57<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:57<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:57<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:57<00:23,  2.98it/s] 86%|████████▌ | 431/500 [05:03<01:20,  1.16s/it] 87%|████████▋ | 433/500 [05:03<00:55,  1.20it/s] 87%|████████▋ | 435/500 [05:03<00:39,  1.66it/s] 87%|████████▋ | 437/500 [05:04<00:27,  2.26it/s] 88%|████████▊ | 439/500 [05:04<00:20,  3.03it/s] 88%|████████▊ | 441/500 [05:10<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:10<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:10<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:10<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:11<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:17<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:17<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:17<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:17<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:17<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:24<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:24<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:24<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:24<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:24<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:30<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:31<00:22,  1.18it/s]Epoch:  407  	Training Loss: 0.0001563723781146109
Test Loss:  9.903424506774172e-05
Valid Loss:  0.00021447139442898333
Epoch:  408  	Training Loss: 0.00015613928553648293
Test Loss:  9.888072963804007e-05
Valid Loss:  0.00021406408632174134
Epoch:  409  	Training Loss: 0.00015588430687785149
Test Loss:  9.869534551398829e-05
Valid Loss:  0.00021361926337704062
Epoch:  410  	Training Loss: 0.000155603454913944
Test Loss:  9.841103747021407e-05
Valid Loss:  0.00021307487622834742
Epoch:  411  	Training Loss: 0.00015528484073001891
Test Loss:  9.808260801946744e-05
Valid Loss:  0.0002125059108948335
Epoch:  412  	Training Loss: 0.0001549445150885731
Test Loss:  9.801307169254869e-05
Valid Loss:  0.00021212473802734166
Epoch:  413  	Training Loss: 0.00015458057168871164
Test Loss:  9.80284676188603e-05
Valid Loss:  0.0002117247204296291
Epoch:  414  	Training Loss: 0.00015424250159412622
Test Loss:  9.803054126678035e-05
Valid Loss:  0.00021131354151293635
Epoch:  415  	Training Loss: 0.00015391834313049912
Test Loss:  9.801160194911063e-05
Valid Loss:  0.00021089438814669847
Epoch:  416  	Training Loss: 0.00015360259567387402
Test Loss:  9.79758842731826e-05
Valid Loss:  0.0002104717423208058
Epoch:  417  	Training Loss: 0.00015329317830037326
Test Loss:  9.792765922611579e-05
Valid Loss:  0.00021004510927014053
Epoch:  418  	Training Loss: 0.0001529876608401537
Test Loss:  9.786908776732162e-05
Valid Loss:  0.0002096165990224108
Epoch:  419  	Training Loss: 0.00015268524293787777
Test Loss:  9.780473192222416e-05
Valid Loss:  0.00020918974769301713
Epoch:  420  	Training Loss: 0.0001523862301837653
Test Loss:  9.773438796401024e-05
Valid Loss:  0.0002087648317683488
Epoch:  421  	Training Loss: 0.00015209068078547716
Test Loss:  9.76618830463849e-05
Valid Loss:  0.00020834070164710283
Epoch:  422  	Training Loss: 0.0001517977798357606
Test Loss:  9.65246872510761e-05
Valid Loss:  0.00020727640367113054
Epoch:  423  	Training Loss: 0.00015120046737138182
Test Loss:  9.578265598975122e-05
Valid Loss:  0.00020633439999073744
Epoch:  424  	Training Loss: 0.00015067421190906316
Test Loss:  9.511633834335953e-05
Valid Loss:  0.00020550782210193574
Epoch:  425  	Training Loss: 0.00015019347483757883
Test Loss:  9.453141683479771e-05
Valid Loss:  0.00020476063946262002
Epoch:  426  	Training Loss: 0.00014973948418628424
Test Loss:  9.402330033481121e-05
Valid Loss:  0.00020406748808454722
Epoch:  427  	Training Loss: 0.00014930464385543019
Test Loss:  9.355923975817859e-05
Valid Loss:  0.0002034095668932423
Epoch:  428  	Training Loss: 0.00014888028090354055
Test Loss:  9.311331814387813e-05
Valid Loss:  0.0002027719165198505
Epoch:  429  	Training Loss: 0.00014846234989818186
Test Loss:  9.270446753362194e-05
Valid Loss:  0.00020214595133438706
Epoch:  430  	Training Loss: 0.00014804743113927543
Test Loss:  9.231492731487378e-05
Valid Loss:  0.00020154326921328902
Epoch:  431  	Training Loss: 0.0001476387697039172
Test Loss:  9.19434241950512e-05
Valid Loss:  0.00020095553190913051
Epoch:  432  	Training Loss: 0.00014723687490914017
Test Loss:  9.269161091651767e-05
Valid Loss:  0.00020069735182914883
Epoch:  433  	Training Loss: 0.00014693901175633073
Test Loss:  9.324702841695398e-05
Valid Loss:  0.00020052675972692668
Epoch:  434  	Training Loss: 0.00014674568956252187
Test Loss:  9.365346340928227e-05
Valid Loss:  0.0002004000125452876
Epoch:  435  	Training Loss: 0.00014660245506092906
Test Loss:  9.395144297741354e-05
Valid Loss:  0.00020029483130201697
Epoch:  436  	Training Loss: 0.0001464853121433407
Test Loss:  9.416970715392381e-05
Valid Loss:  0.00020020396914333105
Epoch:  437  	Training Loss: 0.00014638420543633401
Test Loss:  9.432312072021887e-05
Valid Loss:  0.00020012818276882172
Epoch:  438  	Training Loss: 0.00014629552606493235
Test Loss:  9.443069575354457e-05
Valid Loss:  0.00020005993428640068
Epoch:  439  	Training Loss: 0.0001462156360503286
Test Loss:  9.45039646467194e-05
Valid Loss:  0.00019999616779386997
Epoch:  440  	Training Loss: 0.0001461416541133076
Test Loss:  9.455789404455572e-05
Valid Loss:  0.0001999381638597697
Epoch:  441  	Training Loss: 0.00014607116463594139
Test Loss:  9.459380817133933e-05
Valid Loss:  0.00019988371059298515
Epoch:  442  	Training Loss: 0.00014600584108848125
Test Loss:  9.304089326178655e-05
Valid Loss:  0.0001992040779441595
Epoch:  443  	Training Loss: 0.00014545021986123174
Test Loss:  9.253318421542645e-05
Valid Loss:  0.00019867587252520025
Epoch:  444  	Training Loss: 0.0001450320560252294
Test Loss:  9.229986608261243e-05
Valid Loss:  0.00019818622968159616
Epoch:  445  	Training Loss: 0.0001446473179385066
Test Loss:  9.213120210915804e-05
Valid Loss:  0.0001977274368982762
Epoch:  446  	Training Loss: 0.0001442917564418167
Test Loss:  9.198963380185887e-05
Valid Loss:  0.0001972895406652242
Epoch:  447  	Training Loss: 0.00014395618927665055
Test Loss:  9.186819806927815e-05
Valid Loss:  0.0001968658616533503
Epoch:  448  	Training Loss: 0.0001436302118236199
Test Loss:  9.175638115266338e-05
Valid Loss:  0.00019645041902549565
Epoch:  449  	Training Loss: 0.0001433078432455659
Test Loss:  9.163685899693519e-05
Valid Loss:  0.00019605454872362316
Epoch:  450  	Training Loss: 0.00014300226757768542
Test Loss:  9.152755956165493e-05
Valid Loss:  0.0001956657215487212
Epoch:  451  	Training Loss: 0.0001427008828613907
Test Loss:  9.142217459157109e-05
Valid Loss:  0.0001952915044967085
Epoch:  452  	Training Loss: 0.00014240326709114015
Test Loss:  9.119724563788623e-05
Valid Loss:  0.00019455896108411252
Epoch:  453  	Training Loss: 0.00014201980957295746
Test Loss:  9.065833000931889e-05
Valid Loss:  0.00019400150631554425
Epoch:  454  	Training Loss: 0.0001417098828824237
Test Loss:  9.013379894895479e-05
Valid Loss:  0.00019353057723492384
Epoch:  455  	Training Loss: 0.00014143734006211162
Test Loss:  8.965742745203897e-05
Valid Loss:  0.00019310624338686466
Epoch:  456  	Training Loss: 0.00014118908438831568
Test Loss:  8.922192500904202e-05
Valid Loss:  0.00019271697965450585
Epoch:  457  	Training Loss: 0.0001409576798323542
Test Loss:  8.882385736797005e-05
Valid Loss:  0.00019235580111853778
Epoch:  458  	Training Loss: 0.00014074168575461954
Test Loss:  8.846192213241011e-05
Valid Loss:  0.0001920239592436701
Epoch:  459  	Training Loss: 0.00014054114581085742
Test Loss:  8.814461762085557e-05
Valid Loss:  0.00019172178872395307
Epoch:  460  	Training Loss: 0.00014035304775461555
Test Loss:  8.784762758295983e-05
Valid Loss:  0.0001914350432343781
Epoch:  461  	Training Loss: 0.00014017234207130969
Test Loss:  8.756606257520616e-05
Valid Loss:  0.0001911694125737995
Epoch:  462  	Training Loss: 0.00013999821385368705
Test Loss:  8.812978921923786e-05
Valid Loss:  0.0001907320984173566
Epoch:  463  	Training Loss: 0.0001396079605910927
Test Loss:  8.852453902363777e-05
Valid Loss:  0.00019039219478145242
Epoch:  464  	Training Loss: 0.00013930242857895792
Test Loss:  8.878347580321133e-05
Valid Loss:  0.00019010105461347848
Epoch:  465  	Training Loss: 0.00013904186198487878
Test Loss:  8.895715291146189e-05
Valid Loss:  0.0001898423070088029
Epoch:  466  	Training Loss: 0.00013881019549444318
Test Loss:  8.905489085009322e-05
Valid Loss:  0.00018959435692522675
Epoch:  467  	Training Loss: 0.00013859466707799584
Test Loss:  8.908310701372102e-05
Valid Loss:  0.00018935062689706683
Epoch:  468  	Training Loss: 0.00013838971790391952
Test Loss:  8.907334267860278e-05
Valid Loss:  0.00018910357903223485
Epoch:  469  	Training Loss: 0.0001381860492983833
Test Loss:  8.902070112526417e-05
Valid Loss:  0.000188857622561045
Epoch:  470  	Training Loss: 0.0001379871682729572
Test Loss:  8.894750499166548e-05
Valid Loss:  0.00018861376156564802
Epoch:  471  	Training Loss: 0.00013778875290881842
Test Loss:  8.886826253728941e-05
Valid Loss:  0.0001883867516880855
Epoch:  472  	Training Loss: 0.00013759607099927962
Test Loss:  8.812570013105869e-05
Valid Loss:  0.00018803616694640368
Epoch:  473  	Training Loss: 0.0001372871920466423
Test Loss:  8.781912038102746e-05
Valid Loss:  0.0001876415335573256
Epoch:  474  	Training Loss: 0.00013701102579943836
Test Loss:   95%|█████████▌| 475/500 [05:31<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:31<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:37<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:38<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:38<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:38<00:03,  3.00it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:44<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:44<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:45<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:45<00:00,  2.99it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
8.75887053553015e-05
Valid Loss:  0.00018724850087892264
Epoch:  475  	Training Loss: 0.00013674405636265874
Test Loss:  8.738182077649981e-05
Valid Loss:  0.00018686425755731761
Epoch:  476  	Training Loss: 0.0001364826166536659
Test Loss:  8.719622564967722e-05
Valid Loss:  0.00018648200784809887
Epoch:  477  	Training Loss: 0.00013622290862258524
Test Loss:  8.7020467617549e-05
Valid Loss:  0.00018610345432534814
Epoch:  478  	Training Loss: 0.00013596718781627715
Test Loss:  8.683145279064775e-05
Valid Loss:  0.00018573904526419938
Epoch:  479  	Training Loss: 0.00013571530871558934
Test Loss:  8.665808127261698e-05
Valid Loss:  0.00018537393771111965
Epoch:  480  	Training Loss: 0.00013546476839110255
Test Loss:  8.649015217088163e-05
Valid Loss:  0.00018501051818020642
Epoch:  481  	Training Loss: 0.00013521520304493606
Test Loss:  8.632446406409144e-05
Valid Loss:  0.00018464976164977998
Epoch:  482  	Training Loss: 0.00013496653991751373
Test Loss:  8.477414667140692e-05
Valid Loss:  0.00018422790162730962
Epoch:  483  	Training Loss: 0.00013469072291627526
Test Loss:  8.456483919871971e-05
Valid Loss:  0.00018378932145424187
Epoch:  484  	Training Loss: 0.00013449275866150856
Test Loss:  8.412864553974941e-05
Valid Loss:  0.00018342630937695503
Epoch:  485  	Training Loss: 0.00013432151172310114
Test Loss:  8.379648352274671e-05
Valid Loss:  0.00018309650477021933
Epoch:  486  	Training Loss: 0.00013417079753708094
Test Loss:  8.348097617272288e-05
Valid Loss:  0.0001828039821702987
Epoch:  487  	Training Loss: 0.00013403654156718403
Test Loss:  8.320947381434962e-05
Valid Loss:  0.0001825356448534876
Epoch:  488  	Training Loss: 0.00013391321408562362
Test Loss:  8.295923908008263e-05
Valid Loss:  0.00018229000852443278
Epoch:  489  	Training Loss: 0.00013380017480812967
Test Loss:  8.272171544376761e-05
Valid Loss:  0.00018207263201475143
Epoch:  490  	Training Loss: 0.00013369895168580115
Test Loss:  8.25262104626745e-05
Valid Loss:  0.0001818661403376609
Epoch:  491  	Training Loss: 0.00013360209413804114
Test Loss:  8.233875269070268e-05
Valid Loss:  0.00018167209054809064
Epoch:  492  	Training Loss: 0.00013350859808269888
Test Loss:  8.305950177600607e-05
Valid Loss:  0.0001810480171116069
Epoch:  493  	Training Loss: 0.0001330098311882466
Test Loss:  8.32832811283879e-05
Valid Loss:  0.00018063531024381518
Epoch:  494  	Training Loss: 0.0001326415513176471
Test Loss:  8.334610902238637e-05
Valid Loss:  0.00018026905308943242
Epoch:  495  	Training Loss: 0.00013232222408987582
Test Loss:  8.333829464390874e-05
Valid Loss:  0.00017991472850553691
Epoch:  496  	Training Loss: 0.0001320329902227968
Test Loss:  8.328632975462824e-05
Valid Loss:  0.0001795641437638551
Epoch:  497  	Training Loss: 0.0001317613641731441
Test Loss:  8.319452172145247e-05
Valid Loss:  0.0001792193652363494
Epoch:  498  	Training Loss: 0.00013150452286936343
Test Loss:  8.308535325340927e-05
Valid Loss:  0.00017887049762066454
Epoch:  499  	Training Loss: 0.00013125466648489237
Test Loss:  8.295720908790827e-05
Valid Loss:  0.00017851914162747562
Epoch:  500  	Training Loss: 0.00013100981595925987
Test Loss:  8.281327609438449e-05
Valid Loss:  0.00017816663603298366
seed is  12
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.27it/s]  1%|          | 4/500 [00:00<00:31, 15.99it/s]  1%|          | 6/500 [00:00<00:30, 16.14it/s]  2%|▏         | 8/500 [00:00<00:30, 16.15it/s]  2%|▏         | 10/500 [00:00<00:30, 16.00it/s]  2%|▏         | 12/500 [00:00<00:30, 15.88it/s]  3%|▎         | 14/500 [00:00<00:30, 15.78it/s]  3%|▎         | 16/500 [00:01<00:31, 15.57it/s]  4%|▎         | 18/500 [00:01<00:33, 14.34it/s]  4%|▍         | 20/500 [00:01<00:33, 14.48it/s]  4%|▍         | 22/500 [00:01<00:31, 14.98it/s]  5%|▍         | 24/500 [00:01<00:31, 15.34it/s]  5%|▌         | 26/500 [00:01<00:30, 15.54it/s]  6%|▌         | 28/500 [00:01<00:30, 15.64it/s]  6%|▌         | 30/500 [00:01<00:29, 15.73it/s]  6%|▋         | 32/500 [00:02<00:29, 15.77it/s]  7%|▋         | 34/500 [00:02<00:29, 15.67it/s]  7%|▋         | 36/500 [00:02<00:29, 15.81it/s]  8%|▊         | 38/500 [00:02<00:29, 15.83it/s]  8%|▊         | 40/500 [00:02<00:29, 15.81it/s]  8%|▊         | 42/500 [00:02<00:28, 15.89it/s]  9%|▉         | 44/500 [00:02<00:28, 15.88it/s]  9%|▉         | 46/500 [00:02<00:28, 16.11it/s] 10%|▉         | 48/500 [00:03<00:28, 16.03it/s] 10%|█         | 50/500 [00:03<00:28, 15.89it/s] 10%|█         | 52/500 [00:03<00:27, 16.06it/s] 11%|█         | 54/500 [00:03<00:28, 15.46it/s] 11%|█         | 56/500 [00:03<00:29, 15.29it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.65it/s] 12%|█▏        | 60/500 [00:03<00:27, 15.75it/s] 12%|█▏        | 62/500 [00:03<00:27, 15.74it/s] 13%|█▎        | 64/500 [00:04<00:28, 15.48it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.76it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.74it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.73it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.42it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.72it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.75it/s] 16%|█▌        | 78/500 [00:04<00:27, 15.63it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.73it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.92it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.70it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.62it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.75it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.93it/s] 18%|█▊        | 92/500 [00:05<00:26, 15.56it/s] 19%|█▉        | 94/500 [00:06<00:25, 15.62it/s] 19%|█▉        | 96/500 [00:06<00:26, 15.39it/s] 20%|█▉        | 98/500 [00:06<00:26, 15.44it/s] 20%|██        | 100/500 [00:06<00:25, 15.66it/s] 20%|██        | 102/500 [00:06<00:25, 15.79it/s] 21%|██        | 104/500 [00:06<00:24, 15.92it/s] 21%|██        | 106/500 [00:06<00:24, 16.03it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.09it/s] 22%|██▏       | 110/500 [00:07<00:24, 16.15it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.21it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.09it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.99it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.41it/s] 24%|██▍       | 120/500 [00:07<00:24, 15.56it/s] 24%|██▍       | 122/500 [00:07<00:23, 15.88it/s] 25%|██▍       | 124/500 [00:07<00:23, 15.78it/s]Epoch:  1  	Training Loss: 0.1869736611843109
Test Loss:  5054.8896484375
Valid Loss:  5043.3095703125
Epoch:  2  	Training Loss: 5048.462890625
Test Loss:  2.8636680702184653e+17
Valid Loss:  2.8433525313110016e+17
Epoch:  3  	Training Loss: 2.8230418027669094e+17
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 15.98it/s] 26%|██▌       | 128/500 [00:08<00:23, 16.13it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.10it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.18it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.04it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.07it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.15it/s] 28%|██▊       | 140/500 [00:08<00:22, 15.99it/s] 28%|██▊       | 142/500 [00:09<00:22, 15.92it/s] 29%|██▉       | 144/500 [00:09<00:22, 16.02it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.14it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.12it/s] 30%|███       | 150/500 [00:09<00:21, 16.17it/s] 30%|███       | 152/500 [00:09<00:21, 16.31it/s] 31%|███       | 154/500 [00:09<00:21, 16.30it/s] 31%|███       | 156/500 [00:09<00:21, 16.35it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.06it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.17it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.47it/s] 33%|███▎      | 164/500 [00:10<00:23, 14.37it/s] 33%|███▎      | 166/500 [00:10<00:24, 13.70it/s] 34%|███▎      | 168/500 [00:10<00:24, 13.35it/s] 34%|███▍      | 170/500 [00:10<00:23, 13.96it/s] 34%|███▍      | 172/500 [00:11<00:22, 14.51it/s] 35%|███▍      | 174/500 [00:11<00:22, 14.64it/s] 35%|███▌      | 176/500 [00:11<00:21, 15.01it/s] 36%|███▌      | 178/500 [00:11<00:21, 15.19it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.60it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.81it/s] 37%|███▋      | 184/500 [00:11<00:19, 15.90it/s] 37%|███▋      | 186/500 [00:11<00:19, 15.91it/s] 38%|███▊      | 188/500 [00:12<00:19, 15.85it/s] 38%|███▊      | 190/500 [00:12<00:20, 15.34it/s] 38%|███▊      | 192/500 [00:12<00:21, 14.07it/s] 39%|███▉      | 194/500 [00:12<00:22, 13.43it/s] 39%|███▉      | 196/500 [00:12<00:21, 13.91it/s] 40%|███▉      | 198/500 [00:12<00:20, 14.60it/s] 40%|████      | 200/500 [00:12<00:19, 15.08it/s] 40%|████      | 202/500 [00:12<00:20, 14.86it/s] 41%|████      | 204/500 [00:13<00:19, 15.30it/s] 41%|████      | 206/500 [00:13<00:18, 15.64it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.87it/s] 42%|████▏     | 210/500 [00:13<00:18, 16.09it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.15it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.25it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.24it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.30it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.37it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.24it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.05it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.94it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.82it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.68it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.91it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.11it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.02it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.11it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.74it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.37it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.50it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.54it/s] 50%|████▉     | 248/500 [00:15<00:16, 15.65it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 15.77it/s] 50%|█████     | 252/500 [00:16<00:15, 15.92it/s] 51%|█████     | 254/500 [00:16<00:15, 15.94it/s] 51%|█████     | 256/500 [00:16<00:15, 15.99it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.85it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.89it/s] 52%|█████▏    | 262/500 [00:16<00:14, 15.92it/s] 53%|█████▎    | 264/500 [00:16<00:15, 15.69it/s] 53%|█████▎    | 266/500 [00:17<00:14, 15.70it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.77it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.93it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.04it/s] 55%|█████▍    | 274/500 [00:17<00:14, 16.13it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.55it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.37it/s] 56%|█████▌    | 280/500 [00:17<00:14, 15.47it/s] 56%|█████▋    | 282/500 [00:18<00:14, 15.56it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.79it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.90it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.84it/s] 58%|█████▊    | 290/500 [00:18<00:14, 14.74it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.25it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.50it/s] 59%|█████▉    | 296/500 [00:18<00:13, 15.67it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.81it/s] 60%|██████    | 300/500 [00:19<00:12, 15.96it/s] 60%|██████    | 302/500 [00:19<00:12, 16.10it/s] 61%|██████    | 304/500 [00:19<00:12, 16.12it/s] 61%|██████    | 306/500 [00:19<00:11, 16.23it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.27it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.24it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.18it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.99it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.94it/s] 64%|██████▎   | 318/500 [00:20<00:11, 15.90it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.68it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.87it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.03it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.11it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.06it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.14it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.01it/s] 67%|██████▋   | 334/500 [00:21<00:11, 15.00it/s] 67%|██████▋   | 336/500 [00:21<00:11, 14.62it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.05it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.41it/s] 68%|██████▊   | 342/500 [00:21<00:10, 15.69it/s] 69%|██████▉   | 344/500 [00:21<00:09, 15.90it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.02it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.09it/s] 70%|███████   | 350/500 [00:22<00:09, 15.56it/s] 70%|███████   | 352/500 [00:22<00:09, 15.66it/s] 71%|███████   | 354/500 [00:22<00:09, 15.59it/s] 71%|███████   | 356/500 [00:22<00:09, 15.54it/s] 72%|███████▏  | 358/500 [00:22<00:09, 15.49it/s] 72%|███████▏  | 360/500 [00:22<00:08, 15.65it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.42it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.39it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.64it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.71it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.59it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.69it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:08, 15.70it/s] 75%|███████▌  | 376/500 [00:24<00:07, 15.51it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.52it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.58it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.79it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.32it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.36it/s] 78%|███████▊  | 388/500 [00:24<00:07, 15.51it/s] 78%|███████▊  | 390/500 [00:24<00:07, 15.48it/s] 78%|███████▊  | 392/500 [00:25<00:06, 15.43it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.74it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.90it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.02it/s] 80%|████████  | 400/500 [00:25<00:06, 16.10it/s] 80%|████████  | 402/500 [00:25<00:06, 16.15it/s] 81%|████████  | 404/500 [00:25<00:06, 15.97it/s] 81%|████████  | 406/500 [00:25<00:05, 15.86it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.01it/s] 82%|████████▏ | 410/500 [00:26<00:06, 14.92it/s] 82%|████████▏ | 412/500 [00:26<00:06, 13.87it/s] 83%|████████▎ | 414/500 [00:26<00:06, 13.38it/s] 83%|████████▎ | 416/500 [00:26<00:06, 13.06it/s] 84%|████████▎ | 418/500 [00:26<00:06, 13.28it/s] 84%|████████▍ | 420/500 [00:26<00:05, 13.99it/s] 84%|████████▍ | 422/500 [00:27<00:05, 14.57it/s] 85%|████████▍ | 424/500 [00:27<00:05, 15.08it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.51it/s] 86%|████████▌ | 428/500 [00:27<00:04, 15.72it/s] 86%|████████▌ | 430/500 [00:27<00:04, 15.88it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.06it/s] 87%|████████▋ | 434/500 [00:27<00:04, 15.69it/s] 87%|████████▋ | 436/500 [00:27<00:04, 15.76it/s] 88%|████████▊ | 438/500 [00:28<00:03, 15.68it/s] 88%|████████▊ | 440/500 [00:28<00:03, 15.77it/s] 88%|████████▊ | 442/500 [00:28<00:03, 15.00it/s] 89%|████████▉ | 444/500 [00:28<00:03, 15.27it/s] 89%|████████▉ | 446/500 [00:28<00:03, 15.37it/s] 90%|████████▉ | 448/500 [00:28<00:03, 15.57it/s] 90%|█████████ | 450/500 [00:28<00:03, 15.84it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.02it/s] 91%|█████████ | 454/500 [00:29<00:02, 15.97it/s] 91%|█████████ | 456/500 [00:29<00:02, 15.54it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.59it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.49it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.05it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.26it/s] 93%|█████████▎| 466/500 [00:29<00:02, 15.54it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.48it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.73it/s] 94%|█████████▍| 472/500 [00:30<00:01, 15.91it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.69it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.81it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.39it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.64it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.60it/s] 97%|█████████▋| 484/500 [00:31<00:01, 15.77it/s] 97%|█████████▋| 486/500 [00:31<00:00, 15.91it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.98it/s] 98%|█████████▊| 490/500 [00:31<00:00, 15.99it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.00it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.98it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.94it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.90it/s]100%|██████████| 500/500 [00:32<00:00, 15.92it/s]100%|██████████| 500/500 [00:32<00:00, 15.61it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  12
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:32,  6.20s/it]  1%|          | 3/500 [00:06<13:43,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.92it/s]  2%|▏         | 11/500 [00:12<10:37,  1.30s/it]  3%|▎         | 13/500 [00:13<07:14,  1.12it/s]  3%|▎         | 15/500 [00:13<05:03,  1.60it/s]  3%|▎         | 17/500 [00:13<03:36,  2.23it/s]  4%|▍         | 19/500 [00:13<02:38,  3.03it/s]  4%|▍         | 21/500 [00:19<09:29,  1.19s/it]  5%|▍         | 23/500 [00:19<06:43,  1.18it/s]  5%|▌         | 25/500 [00:19<04:48,  1.64it/s]  5%|▌         | 27/500 [00:20<03:29,  2.25it/s]  6%|▌         | 29/500 [00:20<02:35,  3.04it/s]  6%|▌         | 31/500 [00:26<09:07,  1.17s/it]  7%|▋         | 33/500 [00:26<06:31,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.65it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:26<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<08:53,  1.16s/it]  9%|▊         | 43/500 [00:33<06:20,  1.20it/s]  9%|▉         | 45/500 [00:33<04:33,  1.66it/s]  9%|▉         | 47/500 [00:33<03:20,  2.26it/s] 10%|▉         | 49/500 [00:33<02:28,  3.03it/s] 10%|█         | 51/500 [00:39<08:42,  1.16s/it] 11%|█         | 53/500 [00:40<06:12,  1.20it/s] 11%|█         | 55/500 [00:40<04:28,  1.66it/s] 11%|█▏        | 57/500 [00:40<03:15,  2.26it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.04it/s] 12%|█▏        | 61/500 [00:46<08:25,  1.15s/it] 13%|█▎        | 63/500 [00:46<06:01,  1.21it/s] 13%|█▎        | 65/500 [00:46<04:20,  1.67it/s] 13%|█▎        | 67/500 [00:46<03:09,  2.28it/s] 14%|█▍        | 69/500 [00:47<02:21,  3.04it/s] 14%|█▍        | 71/500 [00:53<08:20,  1.17s/it] 15%|█▍        | 73/500 [00:53<05:58,  1.19it/s]Epoch:  1  	Training Loss: 0.1869736611843109
Test Loss:  8.694506645202637
Valid Loss:  8.60120964050293
Epoch:  2  	Training Loss: 8.536174774169922
Test Loss:  0.1964929848909378
Valid Loss:  0.19859251379966736
Epoch:  3  	Training Loss: 0.18852415680885315
Test Loss:  0.19645163416862488
Valid Loss:  0.19855044782161713
Epoch:  4  	Training Loss: 0.18848341703414917
Test Loss:  0.19641080498695374
Valid Loss:  0.19850927591323853
Epoch:  5  	Training Loss: 0.18844367563724518
Test Loss:  0.19637472927570343
Valid Loss:  0.19847223162651062
Epoch:  6  	Training Loss: 0.188408762216568
Test Loss:  0.19634169340133667
Valid Loss:  0.1984386444091797
Epoch:  7  	Training Loss: 0.18837636709213257
Test Loss:  0.19630968570709229
Valid Loss:  0.1984064131975174
Epoch:  8  	Training Loss: 0.18834500014781952
Test Loss:  0.1962786316871643
Valid Loss:  0.19837486743927002
Epoch:  9  	Training Loss: 0.188314288854599
Test Loss:  0.1962481439113617
Valid Loss:  0.1983436495065689
Epoch:  10  	Training Loss: 0.18828389048576355
Test Loss:  0.19621799886226654
Valid Loss:  0.19831277430057526
Epoch:  11  	Training Loss: 0.18825370073318481
Test Loss:  0.19618797302246094
Valid Loss:  0.19828200340270996
Epoch:  12  	Training Loss: 0.18822360038757324
Test Loss:  0.1961834728717804
Valid Loss:  0.19827760756015778
Epoch:  13  	Training Loss: 0.18821924924850464
Test Loss:  0.19617906212806702
Valid Loss:  0.19827330112457275
Epoch:  14  	Training Loss: 0.18821503221988678
Test Loss:  0.1961747109889984
Valid Loss:  0.19826899468898773
Epoch:  15  	Training Loss: 0.1882108449935913
Test Loss:  0.196170374751091
Valid Loss:  0.1982646882534027
Epoch:  16  	Training Loss: 0.18820667266845703
Test Loss:  0.19616606831550598
Valid Loss:  0.19826041162014008
Epoch:  17  	Training Loss: 0.18820253014564514
Test Loss:  0.19616174697875977
Valid Loss:  0.19825614988803864
Epoch:  18  	Training Loss: 0.18819838762283325
Test Loss:  0.19615745544433594
Valid Loss:  0.1982518881559372
Epoch:  19  	Training Loss: 0.18819427490234375
Test Loss:  0.19615314900875092
Valid Loss:  0.19824762642383575
Epoch:  20  	Training Loss: 0.18819016218185425
Test Loss:  0.19614887237548828
Valid Loss:  0.19824336469173431
Epoch:  21  	Training Loss: 0.18818607926368713
Test Loss:  0.19614461064338684
Valid Loss:  0.19823911786079407
Epoch:  22  	Training Loss: 0.18818199634552002
Test Loss:  0.1961398720741272
Valid Loss:  0.19823428988456726
Epoch:  23  	Training Loss: 0.18817730247974396
Test Loss:  0.19613510370254517
Valid Loss:  0.19822946190834045
Epoch:  24  	Training Loss: 0.18817263841629028
Test Loss:  0.19613036513328552
Valid Loss:  0.19822463393211365
Epoch:  25  	Training Loss: 0.1881679743528366
Test Loss:  0.19612562656402588
Valid Loss:  0.19821983575820923
Epoch:  26  	Training Loss: 0.18816331028938293
Test Loss:  0.19612088799476624
Valid Loss:  0.19821497797966003
Epoch:  27  	Training Loss: 0.18815864622592926
Test Loss:  0.1961161345243454
Valid Loss:  0.19821017980575562
Epoch:  28  	Training Loss: 0.18815398216247559
Test Loss:  0.19611141085624695
Valid Loss:  0.1982053518295288
Epoch:  29  	Training Loss: 0.1881493330001831
Test Loss:  0.1961066722869873
Valid Loss:  0.1982005387544632
Epoch:  30  	Training Loss: 0.18814468383789062
Test Loss:  0.19610191881656647
Valid Loss:  0.19819572567939758
Epoch:  31  	Training Loss: 0.18814001977443695
Test Loss:  0.19609719514846802
Valid Loss:  0.19819092750549316
Epoch:  32  	Training Loss: 0.18813538551330566
Test Loss:  0.19609224796295166
Valid Loss:  0.19818587601184845
Epoch:  33  	Training Loss: 0.1881304681301117
Test Loss:  0.1960872858762741
Valid Loss:  0.19818082451820374
Epoch:  34  	Training Loss: 0.1881255805492401
Test Loss:  0.19608233869075775
Valid Loss:  0.19817577302455902
Epoch:  35  	Training Loss: 0.18812069296836853
Test Loss:  0.1960774064064026
Valid Loss:  0.1981707364320755
Epoch:  36  	Training Loss: 0.18811580538749695
Test Loss:  0.19607245922088623
Valid Loss:  0.19816569983959198
Epoch:  37  	Training Loss: 0.18811093270778656
Test Loss:  0.19606751203536987
Valid Loss:  0.19816064834594727
Epoch:  38  	Training Loss: 0.18810604512691498
Test Loss:  0.19606256484985352
Valid Loss:  0.19815562665462494
Epoch:  39  	Training Loss: 0.1881011724472046
Test Loss:  0.19605764746665955
Valid Loss:  0.19815057516098022
Epoch:  40  	Training Loss: 0.188096284866333
Test Loss:  0.1960526704788208
Valid Loss:  0.1981455385684967
Epoch:  41  	Training Loss: 0.18809139728546143
Test Loss:  0.19604775309562683
Valid Loss:  0.19814050197601318
Epoch:  42  	Training Loss: 0.18808650970458984
Test Loss:  0.1960427314043045
Valid Loss:  0.1981353908777237
Epoch:  43  	Training Loss: 0.1880815625190735
Test Loss:  0.19603773951530457
Valid Loss:  0.1981302797794342
Epoch:  44  	Training Loss: 0.18807661533355713
Test Loss:  0.19603273272514343
Valid Loss:  0.1981251984834671
Epoch:  45  	Training Loss: 0.18807166814804077
Test Loss:  0.1960277408361435
Valid Loss:  0.1981200873851776
Epoch:  46  	Training Loss: 0.18806672096252441
Test Loss:  0.19602273404598236
Valid Loss:  0.19811497628688812
Epoch:  47  	Training Loss: 0.18806177377700806
Test Loss:  0.19601774215698242
Valid Loss:  0.19810989499092102
Epoch:  48  	Training Loss: 0.1880568116903305
Test Loss:  0.1960127353668213
Valid Loss:  0.19810478389263153
Epoch:  49  	Training Loss: 0.18805187940597534
Test Loss:  0.19600775837898254
Valid Loss:  0.19809967279434204
Epoch:  50  	Training Loss: 0.18804693222045898
Test Loss:  0.19600272178649902
Valid Loss:  0.19809459149837494
Epoch:  51  	Training Loss: 0.18804198503494263
Test Loss:  0.19599774479866028
Valid Loss:  0.19808948040008545
Epoch:  52  	Training Loss: 0.18803702294826508
Test Loss:  0.19599273800849915
Valid Loss:  0.19808438420295715
Epoch:  53  	Training Loss: 0.18803206086158752
Test Loss:  0.195987731218338
Valid Loss:  0.19807928800582886
Epoch:  54  	Training Loss: 0.18802712857723236
Test Loss:  0.19598275423049927
Valid Loss:  0.19807417690753937
Epoch:  55  	Training Loss: 0.188022181391716
Test Loss:  0.19597774744033813
Valid Loss:  0.19806909561157227
Epoch:  56  	Training Loss: 0.18801723420619965
Test Loss:  0.1959727555513382
Valid Loss:  0.19806398451328278
Epoch:  57  	Training Loss: 0.18801230192184448
Test Loss:  0.19596776366233826
Valid Loss:  0.19805888831615448
Epoch:  58  	Training Loss: 0.18800733983516693
Test Loss:  0.19596275687217712
Valid Loss:  0.198053777217865
Epoch:  59  	Training Loss: 0.18800240755081177
Test Loss:  0.19595776498317719
Valid Loss:  0.1980486810207367
Epoch:  60  	Training Loss: 0.1879974603652954
Test Loss:  0.19595278799533844
Valid Loss:  0.1980435848236084
Epoch:  61  	Training Loss: 0.18799251317977905
Test Loss:  0.1959477812051773
Valid Loss:  0.1980384886264801
Epoch:  62  	Training Loss: 0.1879875659942627
Test Loss:  0.19594278931617737
Valid Loss:  0.198033407330513
Epoch:  63  	Training Loss: 0.18798261880874634
Test Loss:  0.19593779742717743
Valid Loss:  0.1980283111333847
Epoch:  64  	Training Loss: 0.18797767162322998
Test Loss:  0.1959328055381775
Valid Loss:  0.19802320003509521
Epoch:  65  	Training Loss: 0.18797272443771362
Test Loss:  0.19592781364917755
Valid Loss:  0.19801810383796692
Epoch:  66  	Training Loss: 0.18796779215335846
Test Loss:  0.1959228217601776
Valid Loss:  0.19801302254199982
Epoch:  67  	Training Loss: 0.1879628449678421
Test Loss:  0.19591782987117767
Valid Loss:  0.19800792634487152
Epoch:  68  	Training Loss: 0.18795791268348694
Test Loss:  0.19591283798217773
Valid Loss:  0.19800281524658203
Epoch:  69  	Training Loss: 0.18795296549797058
Test Loss:  0.195907860994339
Valid Loss:  0.19799773395061493
Epoch:  70  	Training Loss: 0.18794801831245422
Test Loss:  0.19590285420417786
Valid Loss:  0.19799263775348663
Epoch:  71  	Training Loss: 0.18794307112693787
Test Loss:  0.19589786231517792
Valid Loss:  0.19798755645751953
Epoch:  72  	Training Loss: 0.1879381239414215
Test Loss:  0.19589293003082275
Valid Loss:  0.19798249006271362
Epoch:  73  	Training Loss: 0.18793323636054993
Test Loss:  0.1958879679441452
Valid Loss:  0.19797742366790771
 15%|█▌        | 75/500 [00:53<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:53<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:53<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:06,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:00<03:03,  2.26it/s] 18%|█▊        | 89/500 [01:00<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:06<07:54,  1.16s/it] 19%|█▊        | 93/500 [01:07<05:39,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:04,  1.66it/s] 19%|█▉        | 97/500 [01:07<02:58,  2.26it/s] 20%|█▉        | 99/500 [01:07<02:12,  3.04it/s] 20%|██        | 101/500 [01:13<07:43,  1.16s/it] 21%|██        | 103/500 [01:13<05:31,  1.20it/s] 21%|██        | 105/500 [01:13<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:14<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:20<07:34,  1.17s/it] 23%|██▎       | 113/500 [01:20<05:24,  1.19it/s] 23%|██▎       | 115/500 [01:20<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:20<02:49,  2.25it/s] 24%|██▍       | 119/500 [01:20<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:27<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:27<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:27<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:27<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:27<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:33<07:07,  1.16s/it] 27%|██▋       | 133/500 [01:34<05:05,  1.20it/s] 27%|██▋       | 135/500 [01:34<03:39,  1.66it/s] 27%|██▋       | 137/500 [01:34<02:40,  2.27it/s] 28%|██▊       | 139/500 [01:34<01:58,  3.05it/s] 28%|██▊       | 141/500 [01:40<06:58,  1.17s/it] 29%|██▊       | 143/500 [01:40<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:41<03:35,  1.65it/s]Epoch:  74  	Training Loss: 0.18792831897735596
Test Loss:  0.19588300585746765
Valid Loss:  0.1979723572731018
Epoch:  75  	Training Loss: 0.187923401594162
Test Loss:  0.1958780586719513
Valid Loss:  0.1979673206806183
Epoch:  76  	Training Loss: 0.1879185140132904
Test Loss:  0.19587311148643494
Valid Loss:  0.19796225428581238
Epoch:  77  	Training Loss: 0.18791359663009644
Test Loss:  0.19586816430091858
Valid Loss:  0.19795720279216766
Epoch:  78  	Training Loss: 0.18790867924690247
Test Loss:  0.19586318731307983
Valid Loss:  0.19795212149620056
Epoch:  79  	Training Loss: 0.1879037618637085
Test Loss:  0.19585824012756348
Valid Loss:  0.19794708490371704
Epoch:  80  	Training Loss: 0.18789887428283691
Test Loss:  0.19585329294204712
Valid Loss:  0.19794201850891113
Epoch:  81  	Training Loss: 0.18789397180080414
Test Loss:  0.19584834575653076
Valid Loss:  0.19793696701526642
Epoch:  82  	Training Loss: 0.18788906931877136
Test Loss:  0.1958434134721756
Valid Loss:  0.1979319453239441
Epoch:  83  	Training Loss: 0.18788418173789978
Test Loss:  0.19583846628665924
Valid Loss:  0.19792689383029938
Epoch:  84  	Training Loss: 0.187879279255867
Test Loss:  0.19583354890346527
Valid Loss:  0.19792187213897705
Epoch:  85  	Training Loss: 0.18787440657615662
Test Loss:  0.1958286017179489
Valid Loss:  0.19791682064533234
Epoch:  86  	Training Loss: 0.18786951899528503
Test Loss:  0.19582368433475494
Valid Loss:  0.19791178405284882
Epoch:  87  	Training Loss: 0.18786463141441345
Test Loss:  0.19581875205039978
Valid Loss:  0.1979067474603653
Epoch:  88  	Training Loss: 0.18785972893238068
Test Loss:  0.19581380486488342
Valid Loss:  0.19790171086788177
Epoch:  89  	Training Loss: 0.1878548562526703
Test Loss:  0.19580888748168945
Valid Loss:  0.19789667427539825
Epoch:  90  	Training Loss: 0.1878499686717987
Test Loss:  0.1958039402961731
Valid Loss:  0.19789165258407593
Epoch:  91  	Training Loss: 0.18784508109092712
Test Loss:  0.19579902291297913
Valid Loss:  0.1978866308927536
Epoch:  92  	Training Loss: 0.18784020841121674
Test Loss:  0.19579410552978516
Valid Loss:  0.19788160920143127
Epoch:  93  	Training Loss: 0.18783533573150635
Test Loss:  0.19578920304775238
Valid Loss:  0.19787660241127014
Epoch:  94  	Training Loss: 0.18783047795295715
Test Loss:  0.1957843005657196
Valid Loss:  0.197871595621109
Epoch:  95  	Training Loss: 0.18782562017440796
Test Loss:  0.19577938318252563
Valid Loss:  0.1978665590286255
Epoch:  96  	Training Loss: 0.18782076239585876
Test Loss:  0.19577446579933167
Valid Loss:  0.19786155223846436
Epoch:  97  	Training Loss: 0.18781590461730957
Test Loss:  0.19576957821846008
Valid Loss:  0.19785654544830322
Epoch:  98  	Training Loss: 0.187811017036438
Test Loss:  0.1957646608352661
Valid Loss:  0.1978515386581421
Epoch:  99  	Training Loss: 0.1878061592578888
Test Loss:  0.19575974345207214
Valid Loss:  0.19784651696681976
Epoch:  100  	Training Loss: 0.1878013014793396
Test Loss:  0.19575484097003937
Valid Loss:  0.19784151017665863
Epoch:  101  	Training Loss: 0.1877964437007904
Test Loss:  0.1957499384880066
Valid Loss:  0.1978364884853363
Epoch:  102  	Training Loss: 0.1877915859222412
Test Loss:  0.195745050907135
Valid Loss:  0.19783148169517517
Epoch:  103  	Training Loss: 0.18778672814369202
Test Loss:  0.19574016332626343
Valid Loss:  0.19782650470733643
Epoch:  104  	Training Loss: 0.1877819001674652
Test Loss:  0.19573526084423065
Valid Loss:  0.1978215128183365
Epoch:  105  	Training Loss: 0.1877770721912384
Test Loss:  0.19573037326335907
Valid Loss:  0.19781652092933655
Epoch:  106  	Training Loss: 0.1877722144126892
Test Loss:  0.19572550058364868
Valid Loss:  0.1978115439414978
Epoch:  107  	Training Loss: 0.18776735663414001
Test Loss:  0.1957205981016159
Valid Loss:  0.19780656695365906
Epoch:  108  	Training Loss: 0.1877625286579132
Test Loss:  0.19571571052074432
Valid Loss:  0.19780156016349792
Epoch:  109  	Training Loss: 0.1877576857805252
Test Loss:  0.19571082293987274
Valid Loss:  0.19779656827449799
Epoch:  110  	Training Loss: 0.1877528429031372
Test Loss:  0.19570595026016235
Valid Loss:  0.19779157638549805
Epoch:  111  	Training Loss: 0.1877480149269104
Test Loss:  0.19570103287696838
Valid Loss:  0.1977865844964981
Epoch:  112  	Training Loss: 0.1877431571483612
Test Loss:  0.19569618999958038
Valid Loss:  0.19778163731098175
Epoch:  113  	Training Loss: 0.1877383589744568
Test Loss:  0.19569134712219238
Valid Loss:  0.1977766752243042
Epoch:  114  	Training Loss: 0.18773356080055237
Test Loss:  0.1956864893436432
Valid Loss:  0.19777172803878784
Epoch:  115  	Training Loss: 0.18772873282432556
Test Loss:  0.1956816464662552
Valid Loss:  0.19776678085327148
Epoch:  116  	Training Loss: 0.18772393465042114
Test Loss:  0.1956768035888672
Valid Loss:  0.19776183366775513
Epoch:  117  	Training Loss: 0.18771913647651672
Test Loss:  0.195671945810318
Valid Loss:  0.19775688648223877
Epoch:  118  	Training Loss: 0.1877143383026123
Test Loss:  0.19566710293293
Valid Loss:  0.1977519392967224
Epoch:  119  	Training Loss: 0.18770954012870789
Test Loss:  0.195662260055542
Valid Loss:  0.19774699211120605
Epoch:  120  	Training Loss: 0.18770474195480347
Test Loss:  0.1956573873758316
Valid Loss:  0.1977420449256897
Epoch:  121  	Training Loss: 0.18769994378089905
Test Loss:  0.1956525593996048
Valid Loss:  0.19773708283901215
Epoch:  122  	Training Loss: 0.18769513070583344
Test Loss:  0.195647731423378
Valid Loss:  0.19773218035697937
Epoch:  123  	Training Loss: 0.1876903474330902
Test Loss:  0.19564291834831238
Valid Loss:  0.1977272480726242
Epoch:  124  	Training Loss: 0.18768557906150818
Test Loss:  0.19563809037208557
Valid Loss:  0.19772231578826904
Epoch:  125  	Training Loss: 0.18768081068992615
Test Loss:  0.19563326239585876
Valid Loss:  0.19771739840507507
Epoch:  126  	Training Loss: 0.18767604231834412
Test Loss:  0.19562844932079315
Valid Loss:  0.1977124810218811
Epoch:  127  	Training Loss: 0.18767127394676208
Test Loss:  0.19562363624572754
Valid Loss:  0.19770756363868713
Epoch:  128  	Training Loss: 0.18766650557518005
Test Loss:  0.19561882317066193
Valid Loss:  0.19770264625549316
Epoch:  129  	Training Loss: 0.18766172230243683
Test Loss:  0.19561398029327393
Valid Loss:  0.1976977288722992
Epoch:  130  	Training Loss: 0.1876569539308548
Test Loss:  0.1956091821193695
Valid Loss:  0.19769281148910522
Epoch:  131  	Training Loss: 0.18765218555927277
Test Loss:  0.1956043541431427
Valid Loss:  0.19768789410591125
Epoch:  132  	Training Loss: 0.18764740228652954
Test Loss:  0.19559958577156067
Valid Loss:  0.19768300652503967
Epoch:  133  	Training Loss: 0.1876426637172699
Test Loss:  0.19559480249881744
Valid Loss:  0.1976781189441681
Epoch:  134  	Training Loss: 0.18763792514801025
Test Loss:  0.19559001922607422
Valid Loss:  0.1976732313632965
Epoch:  135  	Training Loss: 0.1876331865787506
Test Loss:  0.1955852210521698
Valid Loss:  0.19766835868358612
Epoch:  136  	Training Loss: 0.18762844800949097
Test Loss:  0.19558043777942657
Valid Loss:  0.19766348600387573
Epoch:  137  	Training Loss: 0.18762372434139252
Test Loss:  0.19557565450668335
Valid Loss:  0.19765858352184296
Epoch:  138  	Training Loss: 0.18761898577213287
Test Loss:  0.19557087123394012
Valid Loss:  0.19765371084213257
Epoch:  139  	Training Loss: 0.18761423230171204
Test Loss:  0.1955660879611969
Valid Loss:  0.197648823261261
Epoch:  140  	Training Loss: 0.1876095086336136
Test Loss:  0.19556130468845367
Valid Loss:  0.1976439356803894
Epoch:  141  	Training Loss: 0.18760475516319275
Test Loss:  0.19555652141571045
Valid Loss:  0.19763904809951782
Epoch:  142  	Training Loss: 0.1876000165939331
Test Loss:  0.19555175304412842
Valid Loss:  0.19763419032096863
Epoch:  143  	Training Loss: 0.18759532272815704
Test Loss:  0.19554699957370758
Valid Loss:  0.19762933254241943
Epoch:  144  	Training Loss: 0.1875905990600586
Test Loss:  0.19554224610328674
Valid Loss:  0.19762448966503143
Epoch:  145  	Training Loss: 0.18758589029312134
Test Loss:  0.1955374777317047
Valid Loss:  0.19761963188648224
Epoch:  146  	Training Loss: 0.18758118152618408
Test Loss:  0.19553273916244507
Valid Loss:   29%|██▉       | 147/500 [01:41<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:41<01:56,  3.02it/s] 30%|███       | 151/500 [01:47<06:47,  1.17s/it] 31%|███       | 153/500 [01:47<04:51,  1.19it/s] 31%|███       | 155/500 [01:47<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:47<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:48<01:53,  3.01it/s] 32%|███▏      | 161/500 [01:54<06:35,  1.17s/it] 33%|███▎      | 163/500 [01:54<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:54<03:23,  1.65it/s] 33%|███▎      | 167/500 [01:54<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:54<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:01<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:01<04:38,  1.18it/s] 35%|███▌      | 175/500 [02:01<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:01<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:01<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:08<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:08<04:27,  1.18it/s] 37%|███▋      | 185/500 [02:08<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:08<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:08<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:14<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:14<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:15<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:15<01:40,  3.01it/s] 40%|████      | 201/500 [02:21<05:46,  1.16s/it] 41%|████      | 203/500 [02:21<04:06,  1.20it/s] 41%|████      | 205/500 [02:21<02:57,  1.67it/s] 41%|████▏     | 207/500 [02:21<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:28<05:42,  1.18s/it] 43%|████▎     | 213/500 [02:28<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:28<02:55,  1.63it/s] 43%|████▎     | 217/500 [02:28<02:07,  2.22it/s]0.19761475920677185
Epoch:  147  	Training Loss: 0.18757647275924683
Test Loss:  0.19552797079086304
Valid Loss:  0.19760990142822266
Epoch:  148  	Training Loss: 0.18757176399230957
Test Loss:  0.195523202419281
Valid Loss:  0.19760504364967346
Epoch:  149  	Training Loss: 0.18756705522537231
Test Loss:  0.19551846385002136
Valid Loss:  0.19760018587112427
Epoch:  150  	Training Loss: 0.18756234645843506
Test Loss:  0.19551369547843933
Valid Loss:  0.19759534299373627
Epoch:  151  	Training Loss: 0.1875576227903366
Test Loss:  0.1955089271068573
Valid Loss:  0.19759047031402588
Epoch:  152  	Training Loss: 0.18755291402339935
Test Loss:  0.19550417363643646
Valid Loss:  0.19758564233779907
Epoch:  153  	Training Loss: 0.1875482052564621
Test Loss:  0.19549943506717682
Valid Loss:  0.19758078455924988
Epoch:  154  	Training Loss: 0.18754351139068604
Test Loss:  0.1954946666955948
Valid Loss:  0.19757592678070068
Epoch:  155  	Training Loss: 0.18753880262374878
Test Loss:  0.19548992812633514
Valid Loss:  0.19757108390331268
Epoch:  156  	Training Loss: 0.18753409385681152
Test Loss:  0.1954851746559143
Valid Loss:  0.1975662261247635
Epoch:  157  	Training Loss: 0.18752939999103546
Test Loss:  0.19548040628433228
Valid Loss:  0.1975613832473755
Epoch:  158  	Training Loss: 0.1875246912240982
Test Loss:  0.19547566771507263
Valid Loss:  0.1975565254688263
Epoch:  159  	Training Loss: 0.18751998245716095
Test Loss:  0.1954709142446518
Valid Loss:  0.1975516825914383
Epoch:  160  	Training Loss: 0.1875152736902237
Test Loss:  0.19546616077423096
Valid Loss:  0.1975468397140503
Epoch:  161  	Training Loss: 0.18751057982444763
Test Loss:  0.19546140730381012
Valid Loss:  0.1975419819355011
Epoch:  162  	Training Loss: 0.18750587105751038
Test Loss:  0.19545669853687286
Valid Loss:  0.19753718376159668
Epoch:  163  	Training Loss: 0.1875012218952179
Test Loss:  0.1954519897699356
Valid Loss:  0.19753238558769226
Epoch:  164  	Training Loss: 0.18749654293060303
Test Loss:  0.19544729590415955
Valid Loss:  0.19752758741378784
Epoch:  165  	Training Loss: 0.18749189376831055
Test Loss:  0.1954425871372223
Valid Loss:  0.19752277433872223
Epoch:  166  	Training Loss: 0.18748724460601807
Test Loss:  0.19543787837028503
Valid Loss:  0.1975179761648178
Epoch:  167  	Training Loss: 0.18748259544372559
Test Loss:  0.19543316960334778
Valid Loss:  0.1975131779909134
Epoch:  168  	Training Loss: 0.1874779313802719
Test Loss:  0.19542847573757172
Valid Loss:  0.19750836491584778
Epoch:  169  	Training Loss: 0.18747326731681824
Test Loss:  0.19542376697063446
Valid Loss:  0.19750358164310455
Epoch:  170  	Training Loss: 0.18746861815452576
Test Loss:  0.1954190582036972
Valid Loss:  0.19749876856803894
Epoch:  171  	Training Loss: 0.18746395409107208
Test Loss:  0.19541436433792114
Valid Loss:  0.19749397039413452
Epoch:  172  	Training Loss: 0.1874593049287796
Test Loss:  0.19540968537330627
Valid Loss:  0.19748921692371368
Epoch:  173  	Training Loss: 0.1874547004699707
Test Loss:  0.1954050362110138
Valid Loss:  0.19748446345329285
Epoch:  174  	Training Loss: 0.1874500811100006
Test Loss:  0.19540037214756012
Valid Loss:  0.19747969508171082
Epoch:  175  	Training Loss: 0.18744546175003052
Test Loss:  0.19539570808410645
Valid Loss:  0.19747494161128998
Epoch:  176  	Training Loss: 0.18744084239006042
Test Loss:  0.19539104402065277
Valid Loss:  0.19747018814086914
Epoch:  177  	Training Loss: 0.18743622303009033
Test Loss:  0.1953863799571991
Valid Loss:  0.1974654197692871
Epoch:  178  	Training Loss: 0.18743160367012024
Test Loss:  0.19538170099258423
Valid Loss:  0.19746066629886627
Epoch:  179  	Training Loss: 0.18742698431015015
Test Loss:  0.19537705183029175
Valid Loss:  0.19745591282844543
Epoch:  180  	Training Loss: 0.18742239475250244
Test Loss:  0.19537240266799927
Valid Loss:  0.1974511593580246
Epoch:  181  	Training Loss: 0.18741776049137115
Test Loss:  0.1953677237033844
Valid Loss:  0.19744639098644257
Epoch:  182  	Training Loss: 0.18741315603256226
Test Loss:  0.1953630894422531
Valid Loss:  0.19744163751602173
Epoch:  183  	Training Loss: 0.18740855157375336
Test Loss:  0.19535842537879944
Valid Loss:  0.19743689894676208
Epoch:  184  	Training Loss: 0.18740394711494446
Test Loss:  0.19535379111766815
Valid Loss:  0.19743216037750244
Epoch:  185  	Training Loss: 0.18739935755729675
Test Loss:  0.19534912705421448
Valid Loss:  0.1974274218082428
Epoch:  186  	Training Loss: 0.18739476799964905
Test Loss:  0.1953444927930832
Valid Loss:  0.19742268323898315
Epoch:  187  	Training Loss: 0.18739016354084015
Test Loss:  0.1953398585319519
Valid Loss:  0.1974179446697235
Epoch:  188  	Training Loss: 0.18738555908203125
Test Loss:  0.19533520936965942
Valid Loss:  0.19741320610046387
Epoch:  189  	Training Loss: 0.18738096952438354
Test Loss:  0.19533056020736694
Valid Loss:  0.19740848243236542
Epoch:  190  	Training Loss: 0.18737636506557465
Test Loss:  0.19532591104507446
Valid Loss:  0.19740372896194458
Epoch:  191  	Training Loss: 0.18737179040908813
Test Loss:  0.19532126188278198
Valid Loss:  0.19739899039268494
Epoch:  192  	Training Loss: 0.18736717104911804
Test Loss:  0.19531665742397308
Valid Loss:  0.19739428162574768
Epoch:  193  	Training Loss: 0.18736262619495392
Test Loss:  0.19531205296516418
Valid Loss:  0.19738958775997162
Epoch:  194  	Training Loss: 0.1873580515384674
Test Loss:  0.19530744850635529
Valid Loss:  0.19738489389419556
Epoch:  195  	Training Loss: 0.18735350668430328
Test Loss:  0.1953028440475464
Valid Loss:  0.1973801851272583
Epoch:  196  	Training Loss: 0.18734896183013916
Test Loss:  0.1952982246875763
Valid Loss:  0.19737550616264343
Epoch:  197  	Training Loss: 0.18734440207481384
Test Loss:  0.1952936351299286
Valid Loss:  0.19737079739570618
Epoch:  198  	Training Loss: 0.18733984231948853
Test Loss:  0.1952890306711197
Valid Loss:  0.19736610352993011
Epoch:  199  	Training Loss: 0.1873352825641632
Test Loss:  0.1952844262123108
Valid Loss:  0.19736140966415405
Epoch:  200  	Training Loss: 0.1873307228088379
Test Loss:  0.19527983665466309
Valid Loss:  0.1973567008972168
Epoch:  201  	Training Loss: 0.18732616305351257
Test Loss:  0.195275217294693
Valid Loss:  0.19735200703144073
Epoch:  202  	Training Loss: 0.18732161819934845
Test Loss:  0.19527065753936768
Valid Loss:  0.19734734296798706
Epoch:  203  	Training Loss: 0.1873171031475067
Test Loss:  0.19526608288288116
Valid Loss:  0.19734269380569458
Epoch:  204  	Training Loss: 0.18731257319450378
Test Loss:  0.19526150822639465
Valid Loss:  0.1973380297422409
Epoch:  205  	Training Loss: 0.18730805814266205
Test Loss:  0.19525696337223053
Valid Loss:  0.19733339548110962
Epoch:  206  	Training Loss: 0.1873035579919815
Test Loss:  0.19525238871574402
Valid Loss:  0.19732873141765594
Epoch:  207  	Training Loss: 0.18729904294013977
Test Loss:  0.1952478289604187
Valid Loss:  0.19732406735420227
Epoch:  208  	Training Loss: 0.18729452788829803
Test Loss:  0.1952432543039322
Valid Loss:  0.1973194181919098
Epoch:  209  	Training Loss: 0.1872900128364563
Test Loss:  0.19523869454860687
Valid Loss:  0.1973147690296173
Epoch:  210  	Training Loss: 0.18728548288345337
Test Loss:  0.19523414969444275
Valid Loss:  0.19731009006500244
Epoch:  211  	Training Loss: 0.18728098273277283
Test Loss:  0.19522956013679504
Valid Loss:  0.19730544090270996
Epoch:  212  	Training Loss: 0.1872764527797699
Test Loss:  0.19522503018379211
Valid Loss:  0.19730080664157867
Epoch:  213  	Training Loss: 0.18727196753025055
Test Loss:  0.19522050023078918
Valid Loss:  0.1972961723804474
Epoch:  214  	Training Loss: 0.18726746737957
Test Loss:  0.19521594047546387
Valid Loss:  0.1972915530204773
Epoch:  215  	Training Loss: 0.18726298213005066
Test Loss:  0.19521141052246094
Valid Loss:  0.19728690385818481
Epoch:  216  	Training Loss: 0.18725848197937012
Test Loss:  0.19520685076713562
Valid Loss:  0.19728228449821472
Epoch:  217  	Training Loss: 0.18725398182868958
Test Loss:  0.1952023208141327
Valid Loss:  0.19727763533592224
Epoch:  218  	Training Loss: 0.18724949657917023
Test Loss:  0.19519777595996857
Valid Loss:  0.19727300107479095
 44%|████▍     | 219/500 [02:28<01:33,  2.99it/s] 44%|████▍     | 221/500 [02:35<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:35<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:35<02:47,  1.65it/s] 45%|████▌     | 227/500 [02:35<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:35<01:29,  3.03it/s] 46%|████▌     | 231/500 [02:41<05:13,  1.16s/it] 47%|████▋     | 233/500 [02:42<03:43,  1.20it/s] 47%|████▋     | 235/500 [02:42<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:42<01:58,  2.21it/s] 48%|████▊     | 239/500 [02:42<01:28,  2.95it/s] 48%|████▊     | 241/500 [02:48<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:49<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:49<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:49<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:49<01:24,  2.98it/s] 50%|█████     | 251/500 [02:55<04:49,  1.16s/it] 51%|█████     | 253/500 [02:55<03:25,  1.20it/s] 51%|█████     | 255/500 [02:55<02:27,  1.66it/s] 51%|█████▏    | 257/500 [02:55<01:47,  2.26it/s] 52%|█████▏    | 259/500 [02:56<01:19,  3.03it/s] 52%|█████▏    | 261/500 [03:02<04:37,  1.16s/it] 53%|█████▎    | 263/500 [03:02<03:17,  1.20it/s] 53%|█████▎    | 265/500 [03:02<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:02<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:02<01:16,  3.04it/s] 54%|█████▍    | 271/500 [03:09<04:25,  1.16s/it] 55%|█████▍    | 273/500 [03:09<03:08,  1.20it/s] 55%|█████▌    | 275/500 [03:09<02:15,  1.66it/s] 55%|█████▌    | 277/500 [03:09<01:38,  2.27it/s] 56%|█████▌    | 279/500 [03:09<01:12,  3.03it/s] 56%|█████▌    | 281/500 [03:15<04:14,  1.16s/it] 57%|█████▋    | 283/500 [03:15<03:01,  1.20it/s] 57%|█████▋    | 285/500 [03:16<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:16<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:16<01:11,  2.97it/s]Epoch:  219  	Training Loss: 0.1872449815273285
Test Loss:  0.19519323110580444
Valid Loss:  0.19726838171482086
Epoch:  220  	Training Loss: 0.18724051117897034
Test Loss:  0.19518868625164032
Valid Loss:  0.19726374745368958
Epoch:  221  	Training Loss: 0.1872360110282898
Test Loss:  0.1951841562986374
Valid Loss:  0.1972591131925583
Epoch:  222  	Training Loss: 0.18723151087760925
Test Loss:  0.19517964124679565
Valid Loss:  0.1972545087337494
Epoch:  223  	Training Loss: 0.1872270703315735
Test Loss:  0.1951751410961151
Valid Loss:  0.19724991917610168
Epoch:  224  	Training Loss: 0.18722259998321533
Test Loss:  0.19517064094543457
Valid Loss:  0.19724532961845398
Epoch:  225  	Training Loss: 0.18721815943717957
Test Loss:  0.19516614079475403
Valid Loss:  0.19724072515964508
Epoch:  226  	Training Loss: 0.1872137039899826
Test Loss:  0.1951616406440735
Valid Loss:  0.19723613560199738
Epoch:  227  	Training Loss: 0.18720924854278564
Test Loss:  0.19515714049339294
Valid Loss:  0.19723154604434967
Epoch:  228  	Training Loss: 0.18720480799674988
Test Loss:  0.1951526403427124
Valid Loss:  0.19722695648670197
Epoch:  229  	Training Loss: 0.18720033764839172
Test Loss:  0.19514812529087067
Valid Loss:  0.19722238183021545
Epoch:  230  	Training Loss: 0.18719589710235596
Test Loss:  0.19514362514019012
Valid Loss:  0.19721777737140656
Epoch:  231  	Training Loss: 0.1871914267539978
Test Loss:  0.1951391100883484
Valid Loss:  0.19721318781375885
Epoch:  232  	Training Loss: 0.18718698620796204
Test Loss:  0.19513466954231262
Valid Loss:  0.19720861315727234
Epoch:  233  	Training Loss: 0.18718256056308746
Test Loss:  0.19513019919395447
Valid Loss:  0.19720405340194702
Epoch:  234  	Training Loss: 0.1871781349182129
Test Loss:  0.19512571394443512
Valid Loss:  0.1971995085477829
Epoch:  235  	Training Loss: 0.1871737241744995
Test Loss:  0.19512125849723816
Valid Loss:  0.19719496369361877
Epoch:  236  	Training Loss: 0.18716931343078613
Test Loss:  0.19511678814888
Valid Loss:  0.19719040393829346
Epoch:  237  	Training Loss: 0.18716488778591156
Test Loss:  0.19511231780052185
Valid Loss:  0.19718584418296814
Epoch:  238  	Training Loss: 0.187160462141037
Test Loss:  0.1951078623533249
Valid Loss:  0.19718128442764282
Epoch:  239  	Training Loss: 0.1871560662984848
Test Loss:  0.19510337710380554
Valid Loss:  0.1971767544746399
Epoch:  240  	Training Loss: 0.18715164065361023
Test Loss:  0.19509893655776978
Valid Loss:  0.19717219471931458
Epoch:  241  	Training Loss: 0.18714721500873566
Test Loss:  0.19509446620941162
Valid Loss:  0.19716763496398926
Epoch:  242  	Training Loss: 0.18714281916618347
Test Loss:  0.19509002566337585
Valid Loss:  0.19716310501098633
Epoch:  243  	Training Loss: 0.1871384084224701
Test Loss:  0.1950855702161789
Valid Loss:  0.1971585750579834
Epoch:  244  	Training Loss: 0.1871340274810791
Test Loss:  0.19508112967014313
Valid Loss:  0.19715401530265808
Epoch:  245  	Training Loss: 0.18712961673736572
Test Loss:  0.19507667422294617
Valid Loss:  0.19714948534965515
Epoch:  246  	Training Loss: 0.18712523579597473
Test Loss:  0.1950722336769104
Valid Loss:  0.19714497029781342
Epoch:  247  	Training Loss: 0.18712082505226135
Test Loss:  0.19506779313087463
Valid Loss:  0.1971404254436493
Epoch:  248  	Training Loss: 0.18711642920970917
Test Loss:  0.19506333768367767
Valid Loss:  0.19713591039180756
Epoch:  249  	Training Loss: 0.18711203336715698
Test Loss:  0.1950589120388031
Valid Loss:  0.19713138043880463
Epoch:  250  	Training Loss: 0.187107652425766
Test Loss:  0.19505447149276733
Valid Loss:  0.1971268355846405
Epoch:  251  	Training Loss: 0.187103271484375
Test Loss:  0.19505003094673157
Valid Loss:  0.19712230563163757
Epoch:  252  	Training Loss: 0.18709886074066162
Test Loss:  0.1950456202030182
Valid Loss:  0.19711780548095703
Epoch:  253  	Training Loss: 0.18709449470043182
Test Loss:  0.19504119455814362
Valid Loss:  0.1971133053302765
Epoch:  254  	Training Loss: 0.18709012866020203
Test Loss:  0.19503678381443024
Valid Loss:  0.19710882008075714
Epoch:  255  	Training Loss: 0.18708577752113342
Test Loss:  0.19503237307071686
Valid Loss:  0.1971043348312378
Epoch:  256  	Training Loss: 0.18708141148090363
Test Loss:  0.19502796232700348
Valid Loss:  0.19709981977939606
Epoch:  257  	Training Loss: 0.18707704544067383
Test Loss:  0.1950235366821289
Valid Loss:  0.19709531962871552
Epoch:  258  	Training Loss: 0.18707269430160522
Test Loss:  0.19501912593841553
Valid Loss:  0.19709080457687378
Epoch:  259  	Training Loss: 0.18706831336021423
Test Loss:  0.19501473009586334
Valid Loss:  0.19708630442619324
Epoch:  260  	Training Loss: 0.18706394731998444
Test Loss:  0.19501030445098877
Valid Loss:  0.1970818042755127
Epoch:  261  	Training Loss: 0.18705959618091583
Test Loss:  0.19500590860843658
Valid Loss:  0.19707731902599335
Epoch:  262  	Training Loss: 0.18705524504184723
Test Loss:  0.1950015425682068
Valid Loss:  0.1970728635787964
Epoch:  263  	Training Loss: 0.18705090880393982
Test Loss:  0.194997176527977
Valid Loss:  0.19706842303276062
Epoch:  264  	Training Loss: 0.187046617269516
Test Loss:  0.1949928104877472
Valid Loss:  0.19706398248672485
Epoch:  265  	Training Loss: 0.18704229593276978
Test Loss:  0.1949884593486786
Valid Loss:  0.1970595121383667
Epoch:  266  	Training Loss: 0.18703797459602356
Test Loss:  0.1949840784072876
Valid Loss:  0.19705507159233093
Epoch:  267  	Training Loss: 0.18703368306159973
Test Loss:  0.1949797123670578
Valid Loss:  0.19705063104629517
Epoch:  268  	Training Loss: 0.18702936172485352
Test Loss:  0.1949753761291504
Valid Loss:  0.1970461905002594
Epoch:  269  	Training Loss: 0.1870250552892685
Test Loss:  0.1949710100889206
Valid Loss:  0.19704174995422363
Epoch:  270  	Training Loss: 0.18702074885368347
Test Loss:  0.1949666440486908
Valid Loss:  0.19703729450702667
Epoch:  271  	Training Loss: 0.18701642751693726
Test Loss:  0.194962278008461
Valid Loss:  0.1970328390598297
Epoch:  272  	Training Loss: 0.18701210618019104
Test Loss:  0.1949579417705536
Valid Loss:  0.19702842831611633
Epoch:  273  	Training Loss: 0.1870078444480896
Test Loss:  0.19495359063148499
Valid Loss:  0.19702400267124176
Epoch:  274  	Training Loss: 0.18700353801250458
Test Loss:  0.19494926929473877
Valid Loss:  0.1970195770263672
Epoch:  275  	Training Loss: 0.18699926137924194
Test Loss:  0.19494493305683136
Valid Loss:  0.19701513648033142
Epoch:  276  	Training Loss: 0.18699496984481812
Test Loss:  0.19494059681892395
Valid Loss:  0.19701072573661804
Epoch:  277  	Training Loss: 0.1869906783103943
Test Loss:  0.19493626058101654
Valid Loss:  0.19700631499290466
Epoch:  278  	Training Loss: 0.18698638677597046
Test Loss:  0.19493190944194794
Valid Loss:  0.1970018744468689
Epoch:  279  	Training Loss: 0.18698211014270782
Test Loss:  0.19492757320404053
Valid Loss:  0.19699746370315552
Epoch:  280  	Training Loss: 0.186977818608284
Test Loss:  0.1949232518672943
Valid Loss:  0.19699302315711975
Epoch:  281  	Training Loss: 0.18697352707386017
Test Loss:  0.1949189007282257
Valid Loss:  0.19698862731456757
Epoch:  282  	Training Loss: 0.18696923553943634
Test Loss:  0.19491459429264069
Valid Loss:  0.19698423147201538
Epoch:  283  	Training Loss: 0.1869649887084961
Test Loss:  0.19491028785705566
Valid Loss:  0.1969798356294632
Epoch:  284  	Training Loss: 0.18696072697639465
Test Loss:  0.19490599632263184
Valid Loss:  0.1969754546880722
Epoch:  285  	Training Loss: 0.1869564652442932
Test Loss:  0.19490167498588562
Valid Loss:  0.19697105884552002
Epoch:  286  	Training Loss: 0.18695223331451416
Test Loss:  0.1948973685503006
Valid Loss:  0.19696667790412903
Epoch:  287  	Training Loss: 0.18694797158241272
Test Loss:  0.19489306211471558
Valid Loss:  0.19696228206157684
Epoch:  288  	Training Loss: 0.18694370985031128
Test Loss:  0.19488877058029175
Valid Loss:  0.19695790112018585
Epoch:  289  	Training Loss: 0.18693944811820984
Test Loss:  0.19488444924354553
Valid Loss:  0.19695350527763367
Epoch:  290  	Training Loss: 0.1869351863861084
Test Loss:  0.1948801577091217
Valid Loss:  0.19694912433624268
Epoch:  291  	Training Loss: 0.18693093955516815
 58%|█████▊    | 291/500 [03:22<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:22<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:22<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:23<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:23<01:06,  3.00it/s] 60%|██████    | 301/500 [03:29<03:53,  1.18s/it] 61%|██████    | 303/500 [03:29<02:46,  1.19it/s] 61%|██████    | 305/500 [03:29<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:29<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:30<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:36<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:36<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:36<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:36<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:36<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:43<03:27,  1.16s/it] 65%|██████▍   | 323/500 [03:43<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:43<01:45,  1.66it/s] 65%|██████▌   | 327/500 [03:43<01:16,  2.26it/s] 66%|██████▌   | 329/500 [03:43<00:56,  3.03it/s] 66%|██████▌   | 331/500 [03:49<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:49<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:50<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:50<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:50<00:53,  3.02it/s] 68%|██████▊   | 341/500 [03:56<03:05,  1.16s/it] 69%|██████▊   | 343/500 [03:56<02:10,  1.20it/s] 69%|██████▉   | 345/500 [03:56<01:33,  1.66it/s] 69%|██████▉   | 347/500 [03:56<01:07,  2.26it/s] 70%|██████▉   | 349/500 [03:57<00:49,  3.04it/s] 70%|███████   | 351/500 [04:03<02:54,  1.17s/it] 71%|███████   | 353/500 [04:03<02:03,  1.19it/s] 71%|███████   | 355/500 [04:03<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:03<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:03<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:10<02:40,  1.15s/it]Test Loss:  0.1948758363723755
Valid Loss:  0.1969447284936905
Epoch:  292  	Training Loss: 0.1869266927242279
Test Loss:  0.19487157464027405
Valid Loss:  0.1969403773546219
Epoch:  293  	Training Loss: 0.18692246079444885
Test Loss:  0.19486728310585022
Valid Loss:  0.1969360113143921
Epoch:  294  	Training Loss: 0.186918243765831
Test Loss:  0.19486302137374878
Valid Loss:  0.1969316601753235
Epoch:  295  	Training Loss: 0.18691401183605194
Test Loss:  0.19485874474048615
Valid Loss:  0.1969272941350937
Epoch:  296  	Training Loss: 0.18690979480743408
Test Loss:  0.1948544681072235
Valid Loss:  0.19692294299602509
Epoch:  297  	Training Loss: 0.18690556287765503
Test Loss:  0.19485020637512207
Valid Loss:  0.19691859185695648
Epoch:  298  	Training Loss: 0.18690133094787598
Test Loss:  0.19484592974185944
Valid Loss:  0.19691422581672668
Epoch:  299  	Training Loss: 0.1868971288204193
Test Loss:  0.1948416531085968
Valid Loss:  0.19690987467765808
Epoch:  300  	Training Loss: 0.18689289689064026
Test Loss:  0.19483737647533417
Valid Loss:  0.19690552353858948
Epoch:  301  	Training Loss: 0.1868886798620224
Test Loss:  0.19483309984207153
Valid Loss:  0.19690115749835968
Epoch:  302  	Training Loss: 0.18688446283340454
Test Loss:  0.19482886791229248
Valid Loss:  0.19689685106277466
Epoch:  303  	Training Loss: 0.18688026070594788
Test Loss:  0.19482462108135223
Valid Loss:  0.19689252972602844
Epoch:  304  	Training Loss: 0.1868760883808136
Test Loss:  0.19482040405273438
Valid Loss:  0.19688822329044342
Epoch:  305  	Training Loss: 0.18687191605567932
Test Loss:  0.19481617212295532
Valid Loss:  0.1968839019536972
Epoch:  306  	Training Loss: 0.18686772882938385
Test Loss:  0.19481194019317627
Valid Loss:  0.19687959551811218
Epoch:  307  	Training Loss: 0.18686354160308838
Test Loss:  0.19480770826339722
Valid Loss:  0.19687527418136597
Epoch:  308  	Training Loss: 0.1868593692779541
Test Loss:  0.19480347633361816
Valid Loss:  0.19687095284461975
Epoch:  309  	Training Loss: 0.18685516715049744
Test Loss:  0.1947992444038391
Valid Loss:  0.19686664640903473
Epoch:  310  	Training Loss: 0.18685099482536316
Test Loss:  0.19479501247406006
Valid Loss:  0.1968623399734497
Epoch:  311  	Training Loss: 0.18684682250022888
Test Loss:  0.194790780544281
Valid Loss:  0.1968580186367035
Epoch:  312  	Training Loss: 0.1868426352739334
Test Loss:  0.19478659331798553
Valid Loss:  0.19685375690460205
Epoch:  313  	Training Loss: 0.18683849275112152
Test Loss:  0.19478240609169006
Valid Loss:  0.19684948027133942
Epoch:  314  	Training Loss: 0.18683435022830963
Test Loss:  0.1947782039642334
Valid Loss:  0.19684520363807678
Epoch:  315  	Training Loss: 0.18683020770549774
Test Loss:  0.19477403163909912
Valid Loss:  0.19684094190597534
Epoch:  316  	Training Loss: 0.18682608008384705
Test Loss:  0.19476982951164246
Valid Loss:  0.1968366801738739
Epoch:  317  	Training Loss: 0.18682193756103516
Test Loss:  0.19476564228534698
Valid Loss:  0.19683240354061127
Epoch:  318  	Training Loss: 0.18681780993938446
Test Loss:  0.1947614550590515
Valid Loss:  0.19682814180850983
Epoch:  319  	Training Loss: 0.18681365251541138
Test Loss:  0.19475725293159485
Valid Loss:  0.1968238651752472
Epoch:  320  	Training Loss: 0.18680952489376068
Test Loss:  0.19475308060646057
Valid Loss:  0.19681960344314575
Epoch:  321  	Training Loss: 0.1868053674697876
Test Loss:  0.1947488933801651
Valid Loss:  0.19681532680988312
Epoch:  322  	Training Loss: 0.1868012547492981
Test Loss:  0.19474472105503082
Valid Loss:  0.19681107997894287
Epoch:  323  	Training Loss: 0.1867971420288086
Test Loss:  0.19474056363105774
Valid Loss:  0.19680684804916382
Epoch:  324  	Training Loss: 0.1867930293083191
Test Loss:  0.19473639130592346
Valid Loss:  0.19680258631706238
Epoch:  325  	Training Loss: 0.1867889165878296
Test Loss:  0.19473223388195038
Valid Loss:  0.19679835438728333
Epoch:  326  	Training Loss: 0.1867847889661789
Test Loss:  0.1947280466556549
Valid Loss:  0.19679410755634308
Epoch:  327  	Training Loss: 0.1867806613445282
Test Loss:  0.19472388923168182
Valid Loss:  0.19678986072540283
Epoch:  328  	Training Loss: 0.1867765486240387
Test Loss:  0.19471973180770874
Valid Loss:  0.19678561389446259
Epoch:  329  	Training Loss: 0.1867724359035492
Test Loss:  0.19471555948257446
Valid Loss:  0.19678136706352234
Epoch:  330  	Training Loss: 0.1867683231830597
Test Loss:  0.19471140205860138
Valid Loss:  0.1967771053314209
Epoch:  331  	Training Loss: 0.1867642104625702
Test Loss:  0.1947072446346283
Valid Loss:  0.19677287340164185
Epoch:  332  	Training Loss: 0.1867600828409195
Test Loss:  0.1947031021118164
Valid Loss:  0.196768656373024
Epoch:  333  	Training Loss: 0.18675601482391357
Test Loss:  0.19469895958900452
Valid Loss:  0.19676443934440613
Epoch:  334  	Training Loss: 0.18675193190574646
Test Loss:  0.19469483196735382
Valid Loss:  0.19676023721694946
Epoch:  335  	Training Loss: 0.18674784898757935
Test Loss:  0.19469070434570312
Valid Loss:  0.1967560350894928
Epoch:  336  	Training Loss: 0.18674376606941223
Test Loss:  0.19468657672405243
Valid Loss:  0.19675183296203613
Epoch:  337  	Training Loss: 0.18673968315124512
Test Loss:  0.19468244910240173
Valid Loss:  0.19674763083457947
Epoch:  338  	Training Loss: 0.186735600233078
Test Loss:  0.19467830657958984
Valid Loss:  0.19674339890480042
Epoch:  339  	Training Loss: 0.18673153221607208
Test Loss:  0.19467419385910034
Valid Loss:  0.19673919677734375
Epoch:  340  	Training Loss: 0.18672746419906616
Test Loss:  0.19467005133628845
Valid Loss:  0.19673499464988708
Epoch:  341  	Training Loss: 0.18672338128089905
Test Loss:  0.19466592371463776
Valid Loss:  0.19673079252243042
Epoch:  342  	Training Loss: 0.18671929836273193
Test Loss:  0.19466185569763184
Valid Loss:  0.19672662019729614
Epoch:  343  	Training Loss: 0.1867152601480484
Test Loss:  0.19465774297714233
Valid Loss:  0.19672244787216187
Epoch:  344  	Training Loss: 0.18671122193336487
Test Loss:  0.19465366005897522
Valid Loss:  0.19671830534934998
Epoch:  345  	Training Loss: 0.18670718371868134
Test Loss:  0.1946495771408081
Valid Loss:  0.1967141181230545
Epoch:  346  	Training Loss: 0.1867031455039978
Test Loss:  0.1946454644203186
Valid Loss:  0.19670994579792023
Epoch:  347  	Training Loss: 0.18669909238815308
Test Loss:  0.1946413815021515
Valid Loss:  0.19670578837394714
Epoch:  348  	Training Loss: 0.18669506907463074
Test Loss:  0.19463731348514557
Valid Loss:  0.19670163094997406
Epoch:  349  	Training Loss: 0.1866910308599472
Test Loss:  0.19463321566581726
Valid Loss:  0.1966974437236786
Epoch:  350  	Training Loss: 0.18668699264526367
Test Loss:  0.19462911784648895
Valid Loss:  0.1966933012008667
Epoch:  351  	Training Loss: 0.18668295443058014
Test Loss:  0.19462503492832184
Valid Loss:  0.19668912887573242
Epoch:  352  	Training Loss: 0.1866789162158966
Test Loss:  0.19462096691131592
Valid Loss:  0.19668498635292053
Epoch:  353  	Training Loss: 0.18667489290237427
Test Loss:  0.19461689889431
Valid Loss:  0.19668084383010864
Epoch:  354  	Training Loss: 0.18667088449001312
Test Loss:  0.19461283087730408
Valid Loss:  0.19667670130729675
Epoch:  355  	Training Loss: 0.18666687607765198
Test Loss:  0.19460874795913696
Valid Loss:  0.19667255878448486
Epoch:  356  	Training Loss: 0.18666285276412964
Test Loss:  0.19460469484329224
Valid Loss:  0.19666841626167297
Epoch:  357  	Training Loss: 0.1866588294506073
Test Loss:  0.1946006417274475
Valid Loss:  0.19666427373886108
Epoch:  358  	Training Loss: 0.18665482103824615
Test Loss:  0.1945965588092804
Valid Loss:  0.196660116314888
Epoch:  359  	Training Loss: 0.186650812625885
Test Loss:  0.19459247589111328
Valid Loss:  0.1966559737920761
Epoch:  360  	Training Loss: 0.18664678931236267
Test Loss:  0.19458842277526855
Valid Loss:  0.19665181636810303
Epoch:  361  	Training Loss: 0.18664276599884033
Test Loss:  0.19458436965942383
Valid Loss:  0.19664768874645233
Epoch:  362  	Training Loss: 0.1866387575864792
Test Loss:  0.1945803165435791
Valid Loss:  0.19664359092712402
Epoch:  363  	Training Loss: 0.18663477897644043
Test Loss:  0.19457629323005676
Valid Loss:   73%|███████▎  | 363/500 [04:10<01:53,  1.21it/s] 73%|███████▎  | 365/500 [04:10<01:20,  1.67it/s] 73%|███████▎  | 367/500 [04:10<00:58,  2.28it/s] 74%|███████▍  | 369/500 [04:10<00:43,  3.04it/s] 74%|███████▍  | 371/500 [04:16<02:29,  1.16s/it] 75%|███████▍  | 373/500 [04:16<01:45,  1.20it/s] 75%|███████▌  | 375/500 [04:17<01:15,  1.66it/s] 75%|███████▌  | 377/500 [04:17<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:17<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:23<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:23<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:23<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:24<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:24<00:37,  3.00it/s] 78%|███████▊  | 391/500 [04:30<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:30<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:30<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:30<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:30<00:33,  2.99it/s] 80%|████████  | 401/500 [04:37<01:55,  1.17s/it] 81%|████████  | 403/500 [04:37<01:21,  1.19it/s] 81%|████████  | 405/500 [04:37<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:37<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:37<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:43<01:43,  1.16s/it] 83%|████████▎ | 413/500 [04:44<01:12,  1.19it/s] 83%|████████▎ | 415/500 [04:44<00:51,  1.65it/s] 83%|████████▎ | 417/500 [04:44<00:36,  2.26it/s] 84%|████████▍ | 419/500 [04:44<00:26,  3.03it/s] 84%|████████▍ | 421/500 [04:50<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:50<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:51<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:51<00:32,  2.25it/s] 86%|████████▌ | 429/500 [04:51<00:23,  3.02it/s] 86%|████████▌ | 431/500 [04:57<01:20,  1.16s/it] 87%|████████▋ | 433/500 [04:57<00:55,  1.20it/s] 87%|████████▋ | 435/500 [04:57<00:39,  1.64it/s]0.19663946330547333
Epoch:  364  	Training Loss: 0.18663078546524048
Test Loss:  0.19457224011421204
Valid Loss:  0.19663536548614502
Epoch:  365  	Training Loss: 0.18662679195404053
Test Loss:  0.1945682018995285
Valid Loss:  0.19663125276565552
Epoch:  366  	Training Loss: 0.18662282824516296
Test Loss:  0.19456419348716736
Valid Loss:  0.19662714004516602
Epoch:  367  	Training Loss: 0.186618834733963
Test Loss:  0.19456014037132263
Valid Loss:  0.1966230273246765
Epoch:  368  	Training Loss: 0.18661485612392426
Test Loss:  0.1945561021566391
Valid Loss:  0.196618914604187
Epoch:  369  	Training Loss: 0.1866108775138855
Test Loss:  0.19455207884311676
Valid Loss:  0.1966148018836975
Epoch:  370  	Training Loss: 0.18660688400268555
Test Loss:  0.19454805552959442
Valid Loss:  0.196610689163208
Epoch:  371  	Training Loss: 0.1866029053926468
Test Loss:  0.1945439875125885
Valid Loss:  0.1966065764427185
Epoch:  372  	Training Loss: 0.18659892678260803
Test Loss:  0.19454002380371094
Valid Loss:  0.19660250842571259
Epoch:  373  	Training Loss: 0.18659497797489166
Test Loss:  0.19453604519367218
Valid Loss:  0.19659845530986786
Epoch:  374  	Training Loss: 0.1865910291671753
Test Loss:  0.19453203678131104
Valid Loss:  0.19659438729286194
Epoch:  375  	Training Loss: 0.1865871101617813
Test Loss:  0.19452804327011108
Valid Loss:  0.19659031927585602
Epoch:  376  	Training Loss: 0.18658317625522614
Test Loss:  0.19452407956123352
Valid Loss:  0.1965862512588501
Epoch:  377  	Training Loss: 0.18657922744750977
Test Loss:  0.19452007114887238
Valid Loss:  0.19658219814300537
Epoch:  378  	Training Loss: 0.1865752935409546
Test Loss:  0.19451607763767242
Valid Loss:  0.19657813012599945
Epoch:  379  	Training Loss: 0.18657135963439941
Test Loss:  0.19451208412647247
Valid Loss:  0.19657409191131592
Epoch:  380  	Training Loss: 0.18656741082668304
Test Loss:  0.19450810551643372
Valid Loss:  0.1965700089931488
Epoch:  381  	Training Loss: 0.18656347692012787
Test Loss:  0.19450411200523376
Valid Loss:  0.19656595587730408
Epoch:  382  	Training Loss: 0.1865595281124115
Test Loss:  0.1945001482963562
Valid Loss:  0.19656190276145935
Epoch:  383  	Training Loss: 0.1865556240081787
Test Loss:  0.19449618458747864
Valid Loss:  0.19655786454677582
Epoch:  384  	Training Loss: 0.18655170500278473
Test Loss:  0.19449220597743988
Valid Loss:  0.19655382633209229
Epoch:  385  	Training Loss: 0.18654778599739075
Test Loss:  0.1944882571697235
Valid Loss:  0.19654978811740875
Epoch:  386  	Training Loss: 0.18654388189315796
Test Loss:  0.19448429346084595
Valid Loss:  0.19654574990272522
Epoch:  387  	Training Loss: 0.18653996288776398
Test Loss:  0.194480299949646
Valid Loss:  0.1965417116880417
Epoch:  388  	Training Loss: 0.1865360587835312
Test Loss:  0.19447635114192963
Valid Loss:  0.19653767347335815
Epoch:  389  	Training Loss: 0.1865321546792984
Test Loss:  0.19447237253189087
Valid Loss:  0.19653365015983582
Epoch:  390  	Training Loss: 0.18652823567390442
Test Loss:  0.1944684237241745
Valid Loss:  0.1965295970439911
Epoch:  391  	Training Loss: 0.18652433156967163
Test Loss:  0.19446444511413574
Valid Loss:  0.19652555882930756
Epoch:  392  	Training Loss: 0.18652042746543884
Test Loss:  0.19446054100990295
Valid Loss:  0.1965215653181076
Epoch:  393  	Training Loss: 0.18651655316352844
Test Loss:  0.19445662200450897
Valid Loss:  0.19651758670806885
Epoch:  394  	Training Loss: 0.18651267886161804
Test Loss:  0.19445271790027618
Valid Loss:  0.1965135931968689
Epoch:  395  	Training Loss: 0.18650883436203003
Test Loss:  0.1944487988948822
Valid Loss:  0.19650962948799133
Epoch:  396  	Training Loss: 0.18650496006011963
Test Loss:  0.19444489479064941
Valid Loss:  0.19650563597679138
Epoch:  397  	Training Loss: 0.18650110065937042
Test Loss:  0.19444097578525543
Valid Loss:  0.19650164246559143
Epoch:  398  	Training Loss: 0.18649724125862122
Test Loss:  0.19443705677986145
Valid Loss:  0.19649766385555267
Epoch:  399  	Training Loss: 0.18649336695671082
Test Loss:  0.19443315267562866
Valid Loss:  0.19649368524551392
Epoch:  400  	Training Loss: 0.1864895224571228
Test Loss:  0.1944292187690735
Valid Loss:  0.19648969173431396
Epoch:  401  	Training Loss: 0.1864856630563736
Test Loss:  0.1944253146648407
Valid Loss:  0.1964857280254364
Epoch:  402  	Training Loss: 0.1864818036556244
Test Loss:  0.1944214254617691
Valid Loss:  0.19648174941539764
Epoch:  403  	Training Loss: 0.18647795915603638
Test Loss:  0.1944175362586975
Valid Loss:  0.19647778570652008
Epoch:  404  	Training Loss: 0.18647411465644836
Test Loss:  0.19441364705562592
Valid Loss:  0.1964738368988037
Epoch:  405  	Training Loss: 0.18647028505802155
Test Loss:  0.19440974295139313
Valid Loss:  0.19646987318992615
Epoch:  406  	Training Loss: 0.18646645545959473
Test Loss:  0.19440585374832153
Valid Loss:  0.19646590948104858
Epoch:  407  	Training Loss: 0.1864626109600067
Test Loss:  0.19440197944641113
Valid Loss:  0.19646194577217102
Epoch:  408  	Training Loss: 0.1864587664604187
Test Loss:  0.19439809024333954
Valid Loss:  0.19645798206329346
Epoch:  409  	Training Loss: 0.1864549219608307
Test Loss:  0.19439420104026794
Valid Loss:  0.1964540183544159
Epoch:  410  	Training Loss: 0.18645107746124268
Test Loss:  0.19439029693603516
Valid Loss:  0.19645005464553833
Epoch:  411  	Training Loss: 0.18644726276397705
Test Loss:  0.19438642263412476
Valid Loss:  0.19644609093666077
Epoch:  412  	Training Loss: 0.18644341826438904
Test Loss:  0.19438254833221436
Valid Loss:  0.19644217193126678
Epoch:  413  	Training Loss: 0.1864396035671234
Test Loss:  0.19437867403030396
Valid Loss:  0.19643822312355042
Epoch:  414  	Training Loss: 0.1864357888698578
Test Loss:  0.19437479972839355
Valid Loss:  0.19643428921699524
Epoch:  415  	Training Loss: 0.18643197417259216
Test Loss:  0.19437094032764435
Valid Loss:  0.19643035531044006
Epoch:  416  	Training Loss: 0.18642815947532654
Test Loss:  0.19436705112457275
Valid Loss:  0.1964264065027237
Epoch:  417  	Training Loss: 0.1864243447780609
Test Loss:  0.19436319172382355
Valid Loss:  0.19642247259616852
Epoch:  418  	Training Loss: 0.1864205151796341
Test Loss:  0.19435933232307434
Valid Loss:  0.19641852378845215
Epoch:  419  	Training Loss: 0.18641671538352966
Test Loss:  0.19435545802116394
Valid Loss:  0.19641458988189697
Epoch:  420  	Training Loss: 0.18641290068626404
Test Loss:  0.19435159862041473
Valid Loss:  0.196410670876503
Epoch:  421  	Training Loss: 0.1864090859889984
Test Loss:  0.19434773921966553
Valid Loss:  0.19640673696994781
Epoch:  422  	Training Loss: 0.1864052712917328
Test Loss:  0.1943439096212387
Valid Loss:  0.19640283286571503
Epoch:  423  	Training Loss: 0.18640148639678955
Test Loss:  0.1943400800228119
Valid Loss:  0.19639894366264343
Epoch:  424  	Training Loss: 0.1863977313041687
Test Loss:  0.19433625042438507
Valid Loss:  0.19639506936073303
Epoch:  425  	Training Loss: 0.18639396131038666
Test Loss:  0.19433245062828064
Valid Loss:  0.19639115035533905
Epoch:  426  	Training Loss: 0.18639019131660461
Test Loss:  0.19432860612869263
Valid Loss:  0.19638727605342865
Epoch:  427  	Training Loss: 0.18638640642166138
Test Loss:  0.1943248063325882
Valid Loss:  0.19638337194919586
Epoch:  428  	Training Loss: 0.18638265132904053
Test Loss:  0.19432097673416138
Valid Loss:  0.19637951254844666
Epoch:  429  	Training Loss: 0.1863788664340973
Test Loss:  0.19431714713573456
Valid Loss:  0.19637560844421387
Epoch:  430  	Training Loss: 0.18637511134147644
Test Loss:  0.19431333243846893
Valid Loss:  0.19637170433998108
Epoch:  431  	Training Loss: 0.1863713413476944
Test Loss:  0.19430950284004211
Valid Loss:  0.19636783003807068
Epoch:  432  	Training Loss: 0.18636755645275116
Test Loss:  0.19430571794509888
Valid Loss:  0.19636395573616028
Epoch:  433  	Training Loss: 0.1863638162612915
Test Loss:  0.19430191814899445
Valid Loss:  0.19636009633541107
Epoch:  434  	Training Loss: 0.18636007606983185
Test Loss:  0.19429811835289001
Valid Loss:  0.19635622203350067
Epoch:  435  	Training Loss: 0.1863563358783722
Test Loss:  0.19429431855678558
Valid Loss:  0.19635236263275146
 87%|████████▋ | 437/500 [04:57<00:28,  2.22it/s] 88%|████████▊ | 439/500 [04:58<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:04<01:08,  1.16s/it] 89%|████████▊ | 443/500 [05:04<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:04<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:04<00:23,  2.26it/s] 90%|████████▉ | 449/500 [05:04<00:16,  3.03it/s] 90%|█████████ | 451/500 [05:11<00:56,  1.16s/it] 91%|█████████ | 453/500 [05:11<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:11<00:27,  1.66it/s] 91%|█████████▏| 457/500 [05:11<00:19,  2.26it/s] 92%|█████████▏| 459/500 [05:11<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:17<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:17<00:30,  1.19it/s] 93%|█████████▎| 465/500 [05:18<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:18<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:18<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:24<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:24<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:24<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:24<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:25<00:06,  3.03it/s] 96%|█████████▌| 481/500 [05:31<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:31<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:31<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:31<00:05,  2.26it/s] 98%|█████████▊| 489/500 [05:31<00:03,  3.04it/s] 98%|█████████▊| 491/500 [05:38<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:38<00:05,  1.20it/s] 99%|█████████▉| 495/500 [05:38<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:38<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:38<00:00,  3.03it/s]100%|██████████| 500/500 [05:38<00:00,  1.48it/s]
Epoch:  436  	Training Loss: 0.18635258078575134
Test Loss:  0.19429051876068115
Valid Loss:  0.19634848833084106
Epoch:  437  	Training Loss: 0.18634885549545288
Test Loss:  0.19428671896457672
Valid Loss:  0.19634464383125305
Epoch:  438  	Training Loss: 0.18634510040283203
Test Loss:  0.19428293406963348
Valid Loss:  0.19634076952934265
Epoch:  439  	Training Loss: 0.18634137511253357
Test Loss:  0.19427913427352905
Valid Loss:  0.19633689522743225
Epoch:  440  	Training Loss: 0.18633762001991272
Test Loss:  0.19427533447742462
Valid Loss:  0.19633303582668304
Epoch:  441  	Training Loss: 0.18633387982845306
Test Loss:  0.1942715346813202
Valid Loss:  0.19632917642593384
Epoch:  442  	Training Loss: 0.1863301396369934
Test Loss:  0.19426779448986053
Valid Loss:  0.1963253617286682
Epoch:  443  	Training Loss: 0.18632644414901733
Test Loss:  0.19426405429840088
Valid Loss:  0.1963215470314026
Epoch:  444  	Training Loss: 0.18632274866104126
Test Loss:  0.19426031410694122
Valid Loss:  0.19631774723529816
Epoch:  445  	Training Loss: 0.18631905317306519
Test Loss:  0.19425655901432037
Valid Loss:  0.19631394743919373
Epoch:  446  	Training Loss: 0.1863153725862503
Test Loss:  0.19425281882286072
Valid Loss:  0.1963101178407669
Epoch:  447  	Training Loss: 0.18631169199943542
Test Loss:  0.19424906373023987
Valid Loss:  0.19630631804466248
Epoch:  448  	Training Loss: 0.18630798161029816
Test Loss:  0.1942453235387802
Valid Loss:  0.19630250334739685
Epoch:  449  	Training Loss: 0.18630428612232208
Test Loss:  0.19424158334732056
Valid Loss:  0.19629868865013123
Epoch:  450  	Training Loss: 0.1863006055355072
Test Loss:  0.1942378431558609
Valid Loss:  0.1962948739528656
Epoch:  451  	Training Loss: 0.18629691004753113
Test Loss:  0.19423410296440125
Valid Loss:  0.19629108905792236
Epoch:  452  	Training Loss: 0.18629322946071625
Test Loss:  0.19423037767410278
Valid Loss:  0.19628727436065674
Epoch:  453  	Training Loss: 0.18628956377506256
Test Loss:  0.19422666728496552
Valid Loss:  0.1962835043668747
Epoch:  454  	Training Loss: 0.18628588318824768
Test Loss:  0.19422292709350586
Valid Loss:  0.19627970457077026
Epoch:  455  	Training Loss: 0.1862822324037552
Test Loss:  0.1942192167043686
Valid Loss:  0.19627593457698822
Epoch:  456  	Training Loss: 0.1862785518169403
Test Loss:  0.19421550631523132
Valid Loss:  0.19627214968204498
Epoch:  457  	Training Loss: 0.18627488613128662
Test Loss:  0.19421178102493286
Valid Loss:  0.19626834988594055
Epoch:  458  	Training Loss: 0.18627122044563293
Test Loss:  0.1942080557346344
Valid Loss:  0.19626456499099731
Epoch:  459  	Training Loss: 0.18626755475997925
Test Loss:  0.19420436024665833
Valid Loss:  0.19626078009605408
Epoch:  460  	Training Loss: 0.18626388907432556
Test Loss:  0.19420063495635986
Valid Loss:  0.19625699520111084
Epoch:  461  	Training Loss: 0.18626022338867188
Test Loss:  0.1941969096660614
Valid Loss:  0.1962532103061676
Epoch:  462  	Training Loss: 0.1862565577030182
Test Loss:  0.19419318437576294
Valid Loss:  0.19624944031238556
Epoch:  463  	Training Loss: 0.1862528920173645
Test Loss:  0.19418950378894806
Valid Loss:  0.1962457001209259
Epoch:  464  	Training Loss: 0.1862492561340332
Test Loss:  0.1941857933998108
Valid Loss:  0.19624191522598267
Epoch:  465  	Training Loss: 0.1862456053495407
Test Loss:  0.1941821128129959
Valid Loss:  0.19623816013336182
Epoch:  466  	Training Loss: 0.1862419694662094
Test Loss:  0.19417840242385864
Valid Loss:  0.19623440504074097
Epoch:  467  	Training Loss: 0.1862383335828781
Test Loss:  0.19417470693588257
Valid Loss:  0.19623063504695892
Epoch:  468  	Training Loss: 0.18623468279838562
Test Loss:  0.1941710114479065
Valid Loss:  0.19622686505317688
Epoch:  469  	Training Loss: 0.18623104691505432
Test Loss:  0.19416731595993042
Valid Loss:  0.19622310996055603
Epoch:  470  	Training Loss: 0.18622739613056183
Test Loss:  0.19416362047195435
Valid Loss:  0.1962193250656128
Epoch:  471  	Training Loss: 0.18622374534606934
Test Loss:  0.19415992498397827
Valid Loss:  0.19621556997299194
Epoch:  472  	Training Loss: 0.18622010946273804
Test Loss:  0.1941562294960022
Valid Loss:  0.1962118148803711
Epoch:  473  	Training Loss: 0.18621645867824554
Test Loss:  0.19415253400802612
Valid Loss:  0.19620805978775024
Epoch:  474  	Training Loss: 0.18621282279491425
Test Loss:  0.19414883852005005
Valid Loss:  0.1962043046951294
Epoch:  475  	Training Loss: 0.18620918691158295
Test Loss:  0.19414515793323517
Valid Loss:  0.19620054960250854
Epoch:  476  	Training Loss: 0.18620555102825165
Test Loss:  0.1941414773464203
Valid Loss:  0.1961967945098877
Epoch:  477  	Training Loss: 0.18620190024375916
Test Loss:  0.1941377818584442
Valid Loss:  0.19619305431842804
Epoch:  478  	Training Loss: 0.18619826436042786
Test Loss:  0.19413408637046814
Valid Loss:  0.196189284324646
Epoch:  479  	Training Loss: 0.18619462847709656
Test Loss:  0.19413039088249207
Valid Loss:  0.19618552923202515
Epoch:  480  	Training Loss: 0.18619099259376526
Test Loss:  0.19412671029567719
Valid Loss:  0.1961817741394043
Epoch:  481  	Training Loss: 0.18618735671043396
Test Loss:  0.19412299990653992
Valid Loss:  0.19617801904678345
Epoch:  482  	Training Loss: 0.18618372082710266
Test Loss:  0.194119393825531
Valid Loss:  0.19617432355880737
Epoch:  483  	Training Loss: 0.18618012964725494
Test Loss:  0.1941157579421997
Valid Loss:  0.1961706131696701
Epoch:  484  	Training Loss: 0.18617655336856842
Test Loss:  0.19411209225654602
Valid Loss:  0.19616693258285522
Epoch:  485  	Training Loss: 0.1861729621887207
Test Loss:  0.19410847127437592
Valid Loss:  0.19616323709487915
Epoch:  486  	Training Loss: 0.18616938591003418
Test Loss:  0.19410483539104462
Valid Loss:  0.19615954160690308
Epoch:  487  	Training Loss: 0.18616580963134766
Test Loss:  0.1941012144088745
Valid Loss:  0.1961558312177658
Epoch:  488  	Training Loss: 0.18616223335266113
Test Loss:  0.19409756362438202
Valid Loss:  0.19615215063095093
Epoch:  489  	Training Loss: 0.1861586570739746
Test Loss:  0.19409394264221191
Valid Loss:  0.19614842534065247
Epoch:  490  	Training Loss: 0.1861550509929657
Test Loss:  0.19409029185771942
Valid Loss:  0.1961447298526764
Epoch:  491  	Training Loss: 0.18615147471427917
Test Loss:  0.19408667087554932
Valid Loss:  0.1961410492658615
Epoch:  492  	Training Loss: 0.18614789843559265
Test Loss:  0.1940830647945404
Valid Loss:  0.19613738358020782
Epoch:  493  	Training Loss: 0.18614435195922852
Test Loss:  0.1940794736146927
Valid Loss:  0.19613373279571533
Epoch:  494  	Training Loss: 0.18614080548286438
Test Loss:  0.19407588243484497
Valid Loss:  0.19613006711006165
Epoch:  495  	Training Loss: 0.18613727390766144
Test Loss:  0.19407227635383606
Valid Loss:  0.19612640142440796
Epoch:  496  	Training Loss: 0.1861337274312973
Test Loss:  0.19406867027282715
Valid Loss:  0.19612273573875427
Epoch:  497  	Training Loss: 0.18613016605377197
Test Loss:  0.19406506419181824
Valid Loss:  0.19611907005310059
Epoch:  498  	Training Loss: 0.18612663447856903
Test Loss:  0.1940614879131317
Valid Loss:  0.1961154043674469
Epoch:  499  	Training Loss: 0.1861230880022049
Test Loss:  0.1940578818321228
Valid Loss:  0.1961117684841156
Epoch:  500  	Training Loss: 0.18611954152584076
Test Loss:  0.1940542757511139
Valid Loss:  0.19610810279846191
seed is  12
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:16,  6.16s/it]  1%|          | 3/500 [00:06<13:39,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.92it/s]  2%|▏         | 11/500 [00:12<10:38,  1.30s/it]  3%|▎         | 13/500 [00:13<07:15,  1.12it/s]  3%|▎         | 15/500 [00:13<05:03,  1.60it/s]  3%|▎         | 17/500 [00:13<03:36,  2.23it/s]  4%|▍         | 19/500 [00:13<02:39,  3.02it/s]  4%|▍         | 21/500 [00:19<09:30,  1.19s/it]  5%|▍         | 23/500 [00:19<06:44,  1.18it/s]  5%|▌         | 25/500 [00:19<04:49,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.25it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:06,  1.17s/it]  7%|▋         | 33/500 [00:26<06:30,  1.20it/s]  7%|▋         | 35/500 [00:26<04:41,  1.65it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:26<02:35,  2.97it/s]  8%|▊         | 41/500 [00:33<08:59,  1.17s/it]  9%|▊         | 43/500 [00:33<06:25,  1.19it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:33<03:22,  2.24it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:18,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:46<08:29,  1.16s/it] 13%|█▎        | 63/500 [00:46<06:04,  1.20it/s] 13%|█▎        | 65/500 [00:47<04:22,  1.66it/s] 13%|█▎        | 67/500 [00:47<03:11,  2.26it/s] 14%|█▍        | 69/500 [00:47<02:21,  3.04it/s]Epoch:  1  	Training Loss: 0.1869736611843109
Test Loss:  0.38915544748306274
Valid Loss:  0.39015600085258484
Epoch:  2  	Training Loss: 0.40030816197395325
Test Loss:  0.26647433638572693
Valid Loss:  0.264779269695282
Epoch:  3  	Training Loss: 0.2512020468711853
Test Loss:  0.02437407895922661
Valid Loss:  0.030286360532045364
Epoch:  4  	Training Loss: 0.032463811337947845
Test Loss:  0.01697014644742012
Valid Loss:  0.02225247584283352
Epoch:  5  	Training Loss: 0.02517450600862503
Test Loss:  0.014407197944819927
Valid Loss:  0.01892540231347084
Epoch:  6  	Training Loss: 0.02131979539990425
Test Loss:  0.01237468235194683
Valid Loss:  0.01634274050593376
Epoch:  7  	Training Loss: 0.01819191500544548
Test Loss:  0.010568847879767418
Valid Loss:  0.014073235914111137
Epoch:  8  	Training Loss: 0.015567253343760967
Test Loss:  0.009107108227908611
Valid Loss:  0.012218983843922615
Epoch:  9  	Training Loss: 0.013369079679250717
Test Loss:  0.007841911166906357
Valid Loss:  0.01062031090259552
Epoch:  10  	Training Loss: 0.011522646062076092
Test Loss:  0.006815032567828894
Valid Loss:  0.009308438748121262
Epoch:  11  	Training Loss: 0.009974062442779541
Test Loss:  0.005929694510996342
Valid Loss:  0.008181795477867126
Epoch:  12  	Training Loss: 0.008673937991261482
Test Loss:  0.005367925390601158
Valid Loss:  0.007368621416389942
Epoch:  13  	Training Loss: 0.00779841048642993
Test Loss:  0.0048271664418280125
Valid Loss:  0.006554334424436092
Epoch:  14  	Training Loss: 0.006884930655360222
Test Loss:  0.0041495393961668015
Valid Loss:  0.005679278634488583
Epoch:  15  	Training Loss: 0.0058441804721951485
Test Loss:  0.003580872667953372
Valid Loss:  0.004933787509799004
Epoch:  16  	Training Loss: 0.004961581900715828
Test Loss:  0.00322677381336689
Valid Loss:  0.004419323988258839
Epoch:  17  	Training Loss: 0.0043572112917900085
Test Loss:  0.0029879980720579624
Valid Loss:  0.004064585547894239
Epoch:  18  	Training Loss: 0.003957558888942003
Test Loss:  0.002778847236186266
Valid Loss:  0.003808210836723447
Epoch:  19  	Training Loss: 0.003668075893074274
Test Loss:  0.002600232372060418
Valid Loss:  0.0035968816373497248
Epoch:  20  	Training Loss: 0.0034378012642264366
Test Loss:  0.002451221225783229
Valid Loss:  0.0034261499531567097
Epoch:  21  	Training Loss: 0.003244208637624979
Test Loss:  0.0023241564631462097
Valid Loss:  0.003287488128989935
Epoch:  22  	Training Loss: 0.0030826865695416927
Test Loss:  0.0015083809848874807
Valid Loss:  0.002476319670677185
Epoch:  23  	Training Loss: 0.0024671810679137707
Test Loss:  0.001436218386515975
Valid Loss:  0.0023199536371976137
Epoch:  24  	Training Loss: 0.0022117113694548607
Test Loss:  0.0013258386170491576
Valid Loss:  0.002188236452639103
Epoch:  25  	Training Loss: 0.002080677542835474
Test Loss:  0.0012273913016542792
Valid Loss:  0.002070786664262414
Epoch:  26  	Training Loss: 0.0019833322148770094
Test Loss:  0.0012262770906090736
Valid Loss:  0.002034626668319106
Epoch:  27  	Training Loss: 0.0019063890213146806
Test Loss:  0.0011554084485396743
Valid Loss:  0.001953964587301016
Epoch:  28  	Training Loss: 0.0018433647928759456
Test Loss:  0.0011683987686410546
Valid Loss:  0.0019409493543207645
Epoch:  29  	Training Loss: 0.001794331124983728
Test Loss:  0.0011133381631225348
Valid Loss:  0.0018810284091159701
Epoch:  30  	Training Loss: 0.0017539217369630933
Test Loss:  0.0011337862815707922
Valid Loss:  0.0018774762284010649
Epoch:  31  	Training Loss: 0.0017177858389914036
Test Loss:  0.0010885586962103844
Valid Loss:  0.0018304551485925913
Epoch:  32  	Training Loss: 0.0016899930778890848
Test Loss:  0.001282532699406147
Valid Loss:  0.0018729204311966896
Epoch:  33  	Training Loss: 0.001568869687616825
Test Loss:  0.0011010784655809402
Valid Loss:  0.0017035219352692366
Epoch:  34  	Training Loss: 0.0014723918866366148
Test Loss:  0.00114613794721663
Valid Loss:  0.0016611868049949408
Epoch:  35  	Training Loss: 0.0013815779238939285
Test Loss:  0.00103074312210083
Valid Loss:  0.0015149893006309867
Epoch:  36  	Training Loss: 0.0012748403241857886
Test Loss:  0.0009875012328848243
Valid Loss:  0.001416570506989956
Epoch:  37  	Training Loss: 0.0011679180897772312
Test Loss:  0.0008865390555001795
Valid Loss:  0.0012986708898097277
Epoch:  38  	Training Loss: 0.0010678457329049706
Test Loss:  0.0008227742509916425
Valid Loss:  0.0012128038797527552
Epoch:  39  	Training Loss: 0.0009796274825930595
Test Loss:  0.0007441662019118667
Valid Loss:  0.0011248441878706217
Epoch:  40  	Training Loss: 0.0009076972492039204
Test Loss:  0.0006957673467695713
Valid Loss:  0.0010610600002110004
Epoch:  41  	Training Loss: 0.0008511543273925781
Test Loss:  0.00064564507920295
Valid Loss:  0.0010041918139904737
Epoch:  42  	Training Loss: 0.0008100511040538549
Test Loss:  0.0006210688152350485
Valid Loss:  0.0009575886651873589
Epoch:  43  	Training Loss: 0.0007653943030163646
Test Loss:  0.0005986611358821392
Valid Loss:  0.0009320323588326573
Epoch:  44  	Training Loss: 0.0007491089636459947
Test Loss:  0.0005808307905681431
Valid Loss:  0.0009108174126595259
Epoch:  45  	Training Loss: 0.0007364798802882433
Test Loss:  0.0005696042208001018
Valid Loss:  0.0008965050219558179
Epoch:  46  	Training Loss: 0.0007278001867234707
Test Loss:  0.0005611527012661099
Valid Loss:  0.0008852347964420915
Epoch:  47  	Training Loss: 0.0007208018796518445
Test Loss:  0.0005541646387428045
Valid Loss:  0.0008766547543928027
Epoch:  48  	Training Loss: 0.0007145764539018273
Test Loss:  0.0005467355949804187
Valid Loss:  0.0008682774496264756
Epoch:  49  	Training Loss: 0.0007095584878697991
Test Loss:  0.0005415126215666533
Valid Loss:  0.0008618322899565101
Epoch:  50  	Training Loss: 0.0007051209104247391
Test Loss:  0.0005366854020394385
Valid Loss:  0.000856804836075753
Epoch:  51  	Training Loss: 0.0007016424788162112
Test Loss:  0.0005311951972544193
Valid Loss:  0.0008520663250237703
Epoch:  52  	Training Loss: 0.0006986648077145219
Test Loss:  0.0005095922970212996
Valid Loss:  0.0008371203439310193
Epoch:  53  	Training Loss: 0.0006843504379503429
Test Loss:  0.000501310802064836
Valid Loss:  0.0008323357324115932
Epoch:  54  	Training Loss: 0.0006777250673621893
Test Loss:  0.0004958759527653456
Valid Loss:  0.0008298648754134774
Epoch:  55  	Training Loss: 0.000674303388223052
Test Loss:  0.000493185012601316
Valid Loss:  0.0008288972312584519
Epoch:  56  	Training Loss: 0.0006724399281665683
Test Loss:  0.0004904960514977574
Valid Loss:  0.0008278910536319017
Epoch:  57  	Training Loss: 0.0006712331669405103
Test Loss:  0.0004890059935860336
Valid Loss:  0.0008274084539152682
Epoch:  58  	Training Loss: 0.0006704378174617887
Test Loss:  0.00048748936387710273
Valid Loss:  0.0008269345853477716
Epoch:  59  	Training Loss: 0.0006698397337459028
Test Loss:  0.00048672815319150686
Valid Loss:  0.0008268060628324747
Epoch:  60  	Training Loss: 0.0006694038165733218
Test Loss:  0.0004858469474129379
Valid Loss:  0.0008265386568382382
Epoch:  61  	Training Loss: 0.0006690161535516381
Test Loss:  0.0004850502300541848
Valid Loss:  0.0008263018680736423
Epoch:  62  	Training Loss: 0.0006686695851385593
Test Loss:  0.0004892990691587329
Valid Loss:  0.0008193952962756157
Epoch:  63  	Training Loss: 0.0006559310713782907
Test Loss:  0.00045697568566538393
Valid Loss:  0.00079742242814973
Epoch:  64  	Training Loss: 0.0006457299459725618
Test Loss:  0.00046971827396191657
Valid Loss:  0.0007979645160958171
Epoch:  65  	Training Loss: 0.0006370521150529385
Test Loss:  0.00044226256432011724
Valid Loss:  0.0007795211276970804
Epoch:  66  	Training Loss: 0.0006291676545515656
Test Loss:  0.000454049208201468
Valid Loss:  0.0007807820220477879
Epoch:  67  	Training Loss: 0.0006219518254511058
Test Loss:  0.00042938912520185113
Valid Loss:  0.0007644316647201777
Epoch:  68  	Training Loss: 0.0006151892011985183
Test Loss:  0.00044090597657486796
Valid Loss:  0.0007659416296519339
Epoch:  69  	Training Loss: 0.0006086186622269452
Test Loss:  0.0004176157817710191
Valid Loss:  0.0007505200337618589
Epoch:  70  	Training Loss: 0.000602530431933701
Test Loss:  0.0004289004427846521
 14%|█▍        | 71/500 [00:53<08:15,  1.15s/it] 15%|█▍        | 73/500 [00:53<05:54,  1.21it/s] 15%|█▌        | 75/500 [00:53<04:15,  1.67it/s] 15%|█▌        | 77/500 [00:53<03:06,  2.27it/s] 16%|█▌        | 79/500 [00:54<02:17,  3.05it/s] 16%|█▌        | 81/500 [01:00<08:04,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:45,  1.21it/s] 17%|█▋        | 85/500 [01:00<04:08,  1.67it/s] 17%|█▋        | 87/500 [01:00<03:01,  2.28it/s] 18%|█▊        | 89/500 [01:00<02:14,  3.06it/s] 18%|█▊        | 91/500 [01:06<07:57,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:40,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:07<02:58,  2.26it/s] 20%|█▉        | 99/500 [01:07<02:12,  3.03it/s] 20%|██        | 101/500 [01:13<07:46,  1.17s/it] 21%|██        | 103/500 [01:13<05:33,  1.19it/s] 21%|██        | 105/500 [01:14<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.01it/s] 22%|██▏       | 111/500 [01:20<07:31,  1.16s/it] 23%|██▎       | 113/500 [01:20<05:22,  1.20it/s] 23%|██▎       | 115/500 [01:20<03:52,  1.66it/s] 23%|██▎       | 117/500 [01:20<02:49,  2.25it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:27<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:27<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:27<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:27<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:27<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:34<07:10,  1.17s/it] 27%|██▋       | 133/500 [01:34<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:34<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:34<02:41,  2.24it/s]Valid Loss:  0.0007522811647504568
Epoch:  71  	Training Loss: 0.0005965522723272443
Test Loss:  0.00040720257675275207
Valid Loss:  0.000737743335776031
Epoch:  72  	Training Loss: 0.0005908622406423092
Test Loss:  0.0004124616680201143
Valid Loss:  0.0007370023522526026
Epoch:  73  	Training Loss: 0.0005864819977432489
Test Loss:  0.00040719532989896834
Valid Loss:  0.0007314560934901237
Epoch:  74  	Training Loss: 0.0005829002475365996
Test Loss:  0.00040426134364679456
Valid Loss:  0.0007274778909049928
Epoch:  75  	Training Loss: 0.0005794647731818259
Test Loss:  0.0004013580037280917
Valid Loss:  0.0007239620899781585
Epoch:  76  	Training Loss: 0.0005763840163126588
Test Loss:  0.000396891962736845
Valid Loss:  0.0007188041927292943
Epoch:  77  	Training Loss: 0.0005735334707424045
Test Loss:  0.00039699277840554714
Valid Loss:  0.00071658322121948
Epoch:  78  	Training Loss: 0.0005705800140276551
Test Loss:  0.0003937497967854142
Valid Loss:  0.0007131467573344707
Epoch:  79  	Training Loss: 0.0005679638125002384
Test Loss:  0.00039087957702577114
Valid Loss:  0.0007094580214470625
Epoch:  80  	Training Loss: 0.0005654492415487766
Test Loss:  0.0003894881810992956
Valid Loss:  0.0007070978172123432
Epoch:  81  	Training Loss: 0.000563046894967556
Test Loss:  0.00038520825910381973
Valid Loss:  0.0007026309613138437
Epoch:  82  	Training Loss: 0.0005609203362837434
Test Loss:  0.0003863810561597347
Valid Loss:  0.000699712079949677
Epoch:  83  	Training Loss: 0.0005545977037400007
Test Loss:  0.000375280505977571
Valid Loss:  0.000690235523506999
Epoch:  84  	Training Loss: 0.000548782991245389
Test Loss:  0.0003760982071980834
Valid Loss:  0.000686934101395309
Epoch:  85  	Training Loss: 0.0005432571633718908
Test Loss:  0.0003668645804282278
Valid Loss:  0.0006783693097531796
Epoch:  86  	Training Loss: 0.0005380481015890837
Test Loss:  0.0003673548926599324
Valid Loss:  0.0006751730688847601
Epoch:  87  	Training Loss: 0.0005331645370461047
Test Loss:  0.00035950401797890663
Valid Loss:  0.0006676944904029369
Epoch:  88  	Training Loss: 0.0005285993684083223
Test Loss:  0.0003597369068302214
Valid Loss:  0.0006645104149356484
Epoch:  89  	Training Loss: 0.0005241901963017881
Test Loss:  0.000353070703567937
Valid Loss:  0.0006577273015864193
Epoch:  90  	Training Loss: 0.0005199549486860633
Test Loss:  0.00035286269849166274
Valid Loss:  0.00065453170100227
Epoch:  91  	Training Loss: 0.0005158529966138303
Test Loss:  0.0003469926305115223
Valid Loss:  0.0006484359037131071
Epoch:  92  	Training Loss: 0.0005118303233757615
Test Loss:  0.0003332846099510789
Valid Loss:  0.0006375309312716126
Epoch:  93  	Training Loss: 0.0005050207837484777
Test Loss:  0.00032684687175787985
Valid Loss:  0.0006312641780823469
Epoch:  94  	Training Loss: 0.0005003419937565923
Test Loss:  0.0003266913699917495
Valid Loss:  0.0006298305233940482
Epoch:  95  	Training Loss: 0.0004976917989552021
Test Loss:  0.00032646520412527025
Valid Loss:  0.0006286567659117281
Epoch:  96  	Training Loss: 0.000495783518999815
Test Loss:  0.00032675755210220814
Valid Loss:  0.0006283242255449295
Epoch:  97  	Training Loss: 0.0004942067316733301
Test Loss:  0.0003256509080529213
Valid Loss:  0.000627216708380729
Epoch:  98  	Training Loss: 0.0004927609115839005
Test Loss:  0.00032431643921881914
Valid Loss:  0.0006260115187615156
Epoch:  99  	Training Loss: 0.0004914342425763607
Test Loss:  0.0003235991462133825
Valid Loss:  0.000625318381935358
Epoch:  100  	Training Loss: 0.0004902133368887007
Test Loss:  0.0003222399391233921
Valid Loss:  0.0006241475930437446
Epoch:  101  	Training Loss: 0.0004890644922852516
Test Loss:  0.0003213176387362182
Valid Loss:  0.0006233551539480686
Epoch:  102  	Training Loss: 0.00048795680049806833
Test Loss:  0.0003293135669082403
Valid Loss:  0.0006171788554638624
Epoch:  103  	Training Loss: 0.0004766324127558619
Test Loss:  0.00031545234378427267
Valid Loss:  0.0005967578035779297
Epoch:  104  	Training Loss: 0.0004632344061974436
Test Loss:  0.0003116657608188689
Valid Loss:  0.0005907895974814892
Epoch:  105  	Training Loss: 0.0004599131061695516
Test Loss:  0.00030968463397584856
Valid Loss:  0.0005864804843440652
Epoch:  106  	Training Loss: 0.00045717484317719936
Test Loss:  0.00030784629052504897
Valid Loss:  0.0005827068816870451
Epoch:  107  	Training Loss: 0.00045475264778360724
Test Loss:  0.0003057325375266373
Valid Loss:  0.0005792465526610613
Epoch:  108  	Training Loss: 0.00045253257849253714
Test Loss:  0.00030415301444008946
Valid Loss:  0.0005762206856161356
Epoch:  109  	Training Loss: 0.00045038069947622716
Test Loss:  0.00030256796162575483
Valid Loss:  0.0005733605939894915
Epoch:  110  	Training Loss: 0.0004482711083255708
Test Loss:  0.00030104690813459456
Valid Loss:  0.0005706072552129626
Epoch:  111  	Training Loss: 0.00044618843821808696
Test Loss:  0.00029954389901831746
Valid Loss:  0.0005679305177181959
Epoch:  112  	Training Loss: 0.0004441283526830375
Test Loss:  0.0002982074220199138
Valid Loss:  0.0005652228719554842
Epoch:  113  	Training Loss: 0.00044213427463546395
Test Loss:  0.0002955355739686638
Valid Loss:  0.0005627335049211979
Epoch:  114  	Training Loss: 0.00044096281635574996
Test Loss:  0.000294026656774804
Valid Loss:  0.0005609734798781574
Epoch:  115  	Training Loss: 0.0004398800665512681
Test Loss:  0.0002929756010416895
Valid Loss:  0.0005594774265773594
Epoch:  116  	Training Loss: 0.00043883267790079117
Test Loss:  0.0002918229438364506
Valid Loss:  0.0005580328870564699
Epoch:  117  	Training Loss: 0.00043780592386610806
Test Loss:  0.000290962983854115
Valid Loss:  0.0005567478947341442
Epoch:  118  	Training Loss: 0.0004367886285763234
Test Loss:  0.00029018890927545726
Valid Loss:  0.0005555115058086812
Epoch:  119  	Training Loss: 0.00043577945325523615
Test Loss:  0.00028934626607224345
Valid Loss:  0.0005542694125324488
Epoch:  120  	Training Loss: 0.00043477577855810523
Test Loss:  0.00028856939752586186
Valid Loss:  0.0005530657945200801
Epoch:  121  	Training Loss: 0.00043378223199397326
Test Loss:  0.00028782227309420705
Valid Loss:  0.0005518792313523591
Epoch:  122  	Training Loss: 0.0004327933711465448
Test Loss:  0.00028199987718835473
Valid Loss:  0.0005417978391051292
Epoch:  123  	Training Loss: 0.0004242841387167573
Test Loss:  0.0002710373664740473
Valid Loss:  0.0005265946965664625
Epoch:  124  	Training Loss: 0.000413261994253844
Test Loss:  0.00027466745814308524
Valid Loss:  0.000525980198290199
Epoch:  125  	Training Loss: 0.00041106523713096976
Test Loss:  0.0002732937573455274
Valid Loss:  0.0005239050951786339
Epoch:  126  	Training Loss: 0.00040907482616603374
Test Loss:  0.00027141356258653104
Valid Loss:  0.0005214984994381666
Epoch:  127  	Training Loss: 0.00040716055082157254
Test Loss:  0.0002700909972190857
Valid Loss:  0.0005193238030187786
Epoch:  128  	Training Loss: 0.0004052851290907711
Test Loss:  0.0002685471554286778
Valid Loss:  0.0005170011427253485
Epoch:  129  	Training Loss: 0.000403435027692467
Test Loss:  0.0002672508708201349
Valid Loss:  0.000514832092449069
Epoch:  130  	Training Loss: 0.0004016041348222643
Test Loss:  0.00026585737941786647
Valid Loss:  0.0005127645563334227
Epoch:  131  	Training Loss: 0.0003998184693045914
Test Loss:  0.00026348925894126296
Valid Loss:  0.0005097371758893132
Epoch:  132  	Training Loss: 0.00039805268170312047
Test Loss:  0.0002607871138025075
Valid Loss:  0.0005073541542515159
Epoch:  133  	Training Loss: 0.0003967246157117188
Test Loss:  0.0002598032006062567
Valid Loss:  0.0005058833630755544
Epoch:  134  	Training Loss: 0.00039549398934468627
Test Loss:  0.0002586020855233073
Valid Loss:  0.0005044318968430161
Epoch:  135  	Training Loss: 0.00039431831100955606
Test Loss:  0.0002575577236711979
Valid Loss:  0.0005030719912610948
Epoch:  136  	Training Loss: 0.0003931605024263263
Test Loss:  0.00025657215155661106
Valid Loss:  0.0005017551593482494
Epoch:  137  	Training Loss: 0.000392043380998075
Test Loss:  0.0002555691753514111
Valid Loss:  0.0005004369304515421
Epoch:  138  	Training Loss: 0.0003909365914296359
Test Loss:  0.00025456922594457865
Valid Loss:  0.0004991341847926378
 28%|██▊       | 139/500 [01:34<01:59,  3.02it/s] 28%|██▊       | 141/500 [01:40<06:57,  1.16s/it] 29%|██▊       | 143/500 [01:41<04:58,  1.20it/s] 29%|██▉       | 145/500 [01:41<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:41<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:41<01:56,  3.00it/s] 30%|██▉       | 149/500 [01:53<01:56,  3.00it/s] 30%|███       | 151/500 [01:53<12:03,  2.07s/it] 31%|███       | 153/500 [01:53<08:30,  1.47s/it] 31%|███       | 155/500 [01:53<06:02,  1.05s/it] 31%|███▏      | 157/500 [01:54<04:18,  1.32it/s] 32%|███▏      | 159/500 [01:54<03:06,  1.83it/s] 32%|███▏      | 161/500 [02:00<07:23,  1.31s/it] 33%|███▎      | 163/500 [02:00<05:15,  1.07it/s] 33%|███▎      | 165/500 [02:00<03:45,  1.48it/s] 33%|███▎      | 167/500 [02:00<02:43,  2.04it/s] 34%|███▍      | 169/500 [02:00<02:00,  2.75it/s] 34%|███▍      | 171/500 [02:07<06:26,  1.17s/it] 35%|███▍      | 173/500 [02:07<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:07<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:07<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:07<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:13<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:13<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:14<03:11,  1.65it/s] 37%|███▋      | 187/500 [02:14<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:14<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:20<05:58,  1.16s/it] 39%|███▊      | 193/500 [02:20<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:20<03:03,  1.66it/s] 39%|███▉      | 197/500 [02:20<02:13,  2.26it/s] 40%|███▉      | 199/500 [02:21<01:38,  3.04it/s] 40%|████      | 201/500 [02:27<05:47,  1.16s/it] 41%|████      | 203/500 [02:27<04:07,  1.20it/s]Epoch:  139  	Training Loss: 0.0003898385330103338
Test Loss:  0.0002536547544877976
Valid Loss:  0.000497899018228054
Epoch:  140  	Training Loss: 0.00038875904283486307
Test Loss:  0.0002528795739635825
Valid Loss:  0.0004966946435160935
Epoch:  141  	Training Loss: 0.0003877133713103831
Test Loss:  0.00025217392249032855
Valid Loss:  0.0004955205367878079
Epoch:  142  	Training Loss: 0.0003866946208290756
Test Loss:  0.00024348529404960573
Valid Loss:  0.0004862460191361606
Epoch:  143  	Training Loss: 0.00038139522075653076
Test Loss:  0.0002502093557268381
Valid Loss:  0.0004876601160503924
Epoch:  144  	Training Loss: 0.0003790280898101628
Test Loss:  0.00023748178500682116
Valid Loss:  0.0004796131979674101
Epoch:  145  	Training Loss: 0.0003775114892050624
Test Loss:  0.0002555613173171878
Valid Loss:  0.0004883668152615428
Epoch:  146  	Training Loss: 0.00037673680344596505
Test Loss:  0.000225095049245283
Valid Loss:  0.0004720666620414704
Epoch:  147  	Training Loss: 0.0003776636440306902
Test Loss:  0.0002815218467731029
Valid Loss:  0.0005020312964916229
Epoch:  148  	Training Loss: 0.00038045644760131836
Test Loss:  0.000210271988180466
Valid Loss:  0.0004686661995947361
Epoch:  149  	Training Loss: 0.00038850013515911996
Test Loss:  0.0003515514254104346
Valid Loss:  0.0005511271301656961
Epoch:  150  	Training Loss: 0.0004083787789568305
Test Loss:  0.00022081189672462642
Valid Loss:  0.0005085117882117629
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.0004615470243152231
Test Loss:  0.0002038604288827628
Valid Loss:  0.0004721066216006875
Epoch:  152  	Training Loss: 0.0004087673733010888
Test Loss:  0.0002049208851531148
Valid Loss:  0.00044655182864516973
Epoch:  153  	Training Loss: 0.00036180944880470634
Test Loss:  0.00021413419744931161
Valid Loss:  0.00044111875467933714
Epoch:  154  	Training Loss: 0.000350072281435132
Test Loss:  0.00021931881201453507
Valid Loss:  0.0004407597880344838
Epoch:  155  	Training Loss: 0.00034790844074450433
Test Loss:  0.00022154411999508739
Valid Loss:  0.0004412289126776159
Epoch:  156  	Training Loss: 0.0003469385264907032
Test Loss:  0.00022156929480843246
Valid Loss:  0.0004403702332638204
Epoch:  157  	Training Loss: 0.00034610816510394216
Test Loss:  0.00022147144773043692
Valid Loss:  0.00043994607403874397
Epoch:  158  	Training Loss: 0.0003453057142905891
Test Loss:  0.0002210527891293168
Valid Loss:  0.00043938797898590565
Epoch:  159  	Training Loss: 0.0003445295733399689
Test Loss:  0.00022028056264389306
Valid Loss:  0.0004383492050692439
Epoch:  160  	Training Loss: 0.0003437765990383923
Test Loss:  0.00021998060401529074
Valid Loss:  0.00043777708197012544
Epoch:  161  	Training Loss: 0.00034303669235669076
Test Loss:  0.0002195029373979196
Valid Loss:  0.00043712224578484893
Epoch:  162  	Training Loss: 0.00034231197787448764
Test Loss:  0.00021958997240290046
Valid Loss:  0.00043672698666341603
Epoch:  163  	Training Loss: 0.00034128231345675886
Test Loss:  0.00021878158440813422
Valid Loss:  0.0004358846344985068
Epoch:  164  	Training Loss: 0.00034043716732412577
Test Loss:  0.00021852085774298757
Valid Loss:  0.00043527103844098747
Epoch:  165  	Training Loss: 0.00033970572985708714
Test Loss:  0.00021814195497427136
Valid Loss:  0.0004345743218436837
Epoch:  166  	Training Loss: 0.0003390500205568969
Test Loss:  0.00021788816957268864
Valid Loss:  0.000433909212006256
Epoch:  167  	Training Loss: 0.00033845030702650547
Test Loss:  0.00021759426454082131
Valid Loss:  0.000433220382547006
Epoch:  168  	Training Loss: 0.0003378943947609514
Test Loss:  0.00021739458316005766
Valid Loss:  0.0004325550689827651
Epoch:  169  	Training Loss: 0.0003373693907633424
Test Loss:  0.00021719584765378386
Valid Loss:  0.0004318774153944105
Epoch:  170  	Training Loss: 0.0003368706093169749
Test Loss:  0.00021702214144170284
Valid Loss:  0.0004312076198402792
Epoch:  171  	Training Loss: 0.0003363926662132144
Test Loss:  0.00021685015235561877
Valid Loss:  0.0004305387265048921
Epoch:  172  	Training Loss: 0.00033592828549444675
Test Loss:  0.00021781763643957675
Valid Loss:  0.00043053439003415406
Epoch:  173  	Training Loss: 0.0003357059904374182
Test Loss:  0.00021824879513587803
Valid Loss:  0.0004303415771573782
Epoch:  174  	Training Loss: 0.00033550866646692157
Test Loss:  0.00021838353131897748
Valid Loss:  0.00043006104533560574
Epoch:  175  	Training Loss: 0.0003353297943249345
Test Loss:  0.00021837884560227394
Valid Loss:  0.0004297454725019634
Epoch:  176  	Training Loss: 0.00033516038092784584
Test Loss:  0.00021834795188624412
Valid Loss:  0.00042942745494656265
Epoch:  177  	Training Loss: 0.00033499315031804144
Test Loss:  0.00021830579498782754
Valid Loss:  0.00042911243508569896
Epoch:  178  	Training Loss: 0.0003348292375449091
Test Loss:  0.00021826008742209524
Valid Loss:  0.00042880262481048703
Epoch:  179  	Training Loss: 0.0003346670127939433
Test Loss:  0.00021821510745212436
Valid Loss:  0.0004284985188860446
Epoch:  180  	Training Loss: 0.0003345068253111094
Test Loss:  0.0002181757881771773
Valid Loss:  0.0004282004083506763
Epoch:  181  	Training Loss: 0.0003343488206155598
Test Loss:  0.00021813857892993838
Valid Loss:  0.000427908351412043
Epoch:  182  	Training Loss: 0.00033419238752685487
Test Loss:  0.0002141656877938658
Valid Loss:  0.0004253624938428402
Epoch:  183  	Training Loss: 0.00033338560024276376
Test Loss:  0.00021458276023622602
Valid Loss:  0.00042512465734034777
Epoch:  184  	Training Loss: 0.00033270433777943254
Test Loss:  0.0002141420409316197
Valid Loss:  0.00042452712659724057
Epoch:  185  	Training Loss: 0.00033205654472112656
Test Loss:  0.0002136584371328354
Valid Loss:  0.00042391091119498014
Epoch:  186  	Training Loss: 0.0003314283094368875
Test Loss:  0.00021313985052984208
Valid Loss:  0.00042332103475928307
Epoch:  187  	Training Loss: 0.0003308323794044554
Test Loss:  0.00021270773140713573
Valid Loss:  0.0004227737372275442
Epoch:  188  	Training Loss: 0.0003302667464595288
Test Loss:  0.00021226293756626546
Valid Loss:  0.0004222187853883952
Epoch:  189  	Training Loss: 0.00032971161999739707
Test Loss:  0.00021183380158618093
Valid Loss:  0.0004216692759655416
Epoch:  190  	Training Loss: 0.0003291641769465059
Test Loss:  0.00021141284378245473
Valid Loss:  0.0004211198247503489
Epoch:  191  	Training Loss: 0.00032862473744899035
Test Loss:  0.00021100087906233966
Valid Loss:  0.000420573225710541
Epoch:  192  	Training Loss: 0.0003280912060290575
Test Loss:  0.00021127151558175683
Valid Loss:  0.0004197478701826185
Epoch:  193  	Training Loss: 0.0003270500455982983
Test Loss:  0.00021051419025752693
Valid Loss:  0.00041848912951536477
Epoch:  194  	Training Loss: 0.00032602515420876443
Test Loss:  0.00020974059589207172
Valid Loss:  0.00041723583126440644
Epoch:  195  	Training Loss: 0.00032500739325769246
Test Loss:  0.0002089709450956434
Valid Loss:  0.000415995717048645
Epoch:  196  	Training Loss: 0.00032399583142250776
Test Loss:  0.0002082064311252907
Valid Loss:  0.0004147683794144541
Epoch:  197  	Training Loss: 0.0003229903522878885
Test Loss:  0.00020744482753798366
Valid Loss:  0.00041355122812092304
Epoch:  198  	Training Loss: 0.0003219910722691566
Test Loss:  0.00020668968500103801
Valid Loss:  0.00041234405944123864
Epoch:  199  	Training Loss: 0.00032099688542075455
Test Loss:  0.00020593861700035632
Valid Loss:  0.0004111466114409268
Epoch:  200  	Training Loss: 0.00032000784995034337
Test Loss:  0.00020519252575468272
Valid Loss:  0.00040995795279741287
Epoch:  201  	Training Loss: 0.0003190247225575149
Test Loss:  0.00020445049449335784
Valid Loss:  0.0004087762499693781
Epoch:  202  	Training Loss: 0.0003180455241817981
Test Loss:  0.00020146757015027106
Valid Loss:  0.0004067850240971893
Epoch:  203  	Training Loss: 0.0003167115501128137
Test Loss:  0.00019995938055217266
Valid Loss:  0.0004055577446706593
Epoch:  204  	Training Loss: 0.0003155354061163962
Test Loss:  0.00019884009088855237
Valid Loss:  0.0004045589012093842
Epoch:  205  	Training Loss: 0.00031446845969185233
 41%|████      | 205/500 [02:27<02:58,  1.66it/s] 41%|████▏     | 207/500 [02:27<02:09,  2.26it/s] 42%|████▏     | 209/500 [02:27<01:36,  3.03it/s] 42%|████▏     | 211/500 [02:34<05:36,  1.17s/it] 43%|████▎     | 213/500 [02:34<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:34<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:34<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:34<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:40<05:22,  1.16s/it] 45%|████▍     | 223/500 [02:40<03:49,  1.20it/s] 45%|████▌     | 225/500 [02:41<02:45,  1.66it/s] 45%|████▌     | 227/500 [02:41<02:00,  2.27it/s] 46%|████▌     | 229/500 [02:41<01:29,  3.04it/s] 46%|████▌     | 231/500 [02:47<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:47<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:47<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:47<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:48<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:54<04:58,  1.15s/it] 49%|████▊     | 243/500 [02:54<03:32,  1.21it/s] 49%|████▉     | 245/500 [02:54<02:33,  1.67it/s] 49%|████▉     | 247/500 [02:54<01:51,  2.27it/s] 50%|████▉     | 249/500 [02:54<01:22,  3.05it/s] 50%|█████     | 251/500 [03:01<04:53,  1.18s/it] 51%|█████     | 253/500 [03:01<03:28,  1.18it/s] 51%|█████     | 255/500 [03:01<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:01<01:48,  2.23it/s] 52%|█████▏    | 259/500 [03:01<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:07<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:08<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:08<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:08<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:08<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:14<04:26,  1.16s/it]Test Loss:  0.00019787739438470453
Valid Loss:  0.00040367982001043856
Epoch:  206  	Training Loss: 0.0003134906874038279
Test Loss:  0.00019698162213899195
Valid Loss:  0.00040284014539793134
Epoch:  207  	Training Loss: 0.0003125796210952103
Test Loss:  0.00019615523342508823
Valid Loss:  0.000402051315177232
Epoch:  208  	Training Loss: 0.0003117385786026716
Test Loss:  0.00019544377573765814
Valid Loss:  0.00040134554728865623
Epoch:  209  	Training Loss: 0.00031096432940103114
Test Loss:  0.00019479698676150292
Valid Loss:  0.0004006758099421859
Epoch:  210  	Training Loss: 0.0003102330956608057
Test Loss:  0.0001942194503499195
Valid Loss:  0.0004000361659564078
Epoch:  211  	Training Loss: 0.00030954170506447554
Test Loss:  0.00019367210916243494
Valid Loss:  0.0003994427970610559
Epoch:  212  	Training Loss: 0.000308882532408461
Test Loss:  0.00019582163076847792
Valid Loss:  0.00039928260957822204
Epoch:  213  	Training Loss: 0.00030810257885605097
Test Loss:  0.0001968585856957361
Valid Loss:  0.00039888545870780945
Epoch:  214  	Training Loss: 0.0003075749264098704
Test Loss:  0.00019729897030629218
Valid Loss:  0.00039837523945607245
Epoch:  215  	Training Loss: 0.0003071559767704457
Test Loss:  0.00019739876734092832
Valid Loss:  0.00039780832594260573
Epoch:  216  	Training Loss: 0.0003067957004532218
Test Loss:  0.00019730506755877286
Valid Loss:  0.0003972262202296406
Epoch:  217  	Training Loss: 0.0003064831835217774
Test Loss:  0.00019720065756700933
Valid Loss:  0.00039667263627052307
Epoch:  218  	Training Loss: 0.0003061932511627674
Test Loss:  0.00019707423052750528
Valid Loss:  0.00039614635170437396
Epoch:  219  	Training Loss: 0.00030592759139835835
Test Loss:  0.0001968506840057671
Valid Loss:  0.0003956400614697486
Epoch:  220  	Training Loss: 0.00030567849171347916
Test Loss:  0.0001966844720300287
Valid Loss:  0.00039517891127616167
Epoch:  221  	Training Loss: 0.00030543742468580604
Test Loss:  0.00019651642651297152
Valid Loss:  0.00039474014192819595
Epoch:  222  	Training Loss: 0.0003052029060199857
Test Loss:  0.00019541458459571004
Valid Loss:  0.0003941615577787161
Epoch:  223  	Training Loss: 0.00030508730560541153
Test Loss:  0.0001947922573890537
Valid Loss:  0.00039382578688673675
Epoch:  224  	Training Loss: 0.00030499821878038347
Test Loss:  0.00019442086340859532
Valid Loss:  0.00039361289236694574
Epoch:  225  	Training Loss: 0.0003049209190066904
Test Loss:  0.00019418494775891304
Valid Loss:  0.00039346812991425395
Epoch:  226  	Training Loss: 0.0003048499929718673
Test Loss:  0.0001940210786415264
Valid Loss:  0.00039336102781817317
Epoch:  227  	Training Loss: 0.00030478465487249196
Test Loss:  0.00019389897352084517
Valid Loss:  0.000393275055103004
Epoch:  228  	Training Loss: 0.00030472438083961606
Test Loss:  0.00019380127196200192
Valid Loss:  0.0003932020044885576
Epoch:  229  	Training Loss: 0.0003046679776161909
Test Loss:  0.00019371752568986267
Valid Loss:  0.00039313684101216495
Epoch:  230  	Training Loss: 0.00030461541609838605
Test Loss:  0.00019364400941412896
Valid Loss:  0.00039307726547122
Epoch:  231  	Training Loss: 0.00030456617241725326
Test Loss:  0.00019357427663635463
Valid Loss:  0.00039302156073972583
Epoch:  232  	Training Loss: 0.00030452004284597933
Test Loss:  0.0001921043440233916
Valid Loss:  0.00039193264092318714
Epoch:  233  	Training Loss: 0.0003036711714230478
Test Loss:  0.00019137571507599205
Valid Loss:  0.0003912615356966853
Epoch:  234  	Training Loss: 0.00030295219039544463
Test Loss:  0.00019075011368840933
Valid Loss:  0.0003906498313881457
Epoch:  235  	Training Loss: 0.0003022804157808423
Test Loss:  0.00019015735597349703
Valid Loss:  0.00039006787119433284
Epoch:  236  	Training Loss: 0.0003016465052496642
Test Loss:  0.00018964069022331387
Valid Loss:  0.00038954426418058574
Epoch:  237  	Training Loss: 0.0003010619548149407
Test Loss:  0.00018912027007900178
Valid Loss:  0.00038903282256796956
Epoch:  238  	Training Loss: 0.00030049969791434705
Test Loss:  0.00018863045261241496
Valid Loss:  0.0003885789483319968
Epoch:  239  	Training Loss: 0.00029996156808920205
Test Loss:  0.00018817173258867115
Valid Loss:  0.00038816110463812947
Epoch:  240  	Training Loss: 0.0002994476817548275
Test Loss:  0.00018773645570036024
Valid Loss:  0.00038775368011556566
Epoch:  241  	Training Loss: 0.0002989550121128559
Test Loss:  0.0001873349247034639
Valid Loss:  0.00038736581336706877
Epoch:  242  	Training Loss: 0.0002984825987368822
Test Loss:  0.0001865866215666756
Valid Loss:  0.00038676324766129255
Epoch:  243  	Training Loss: 0.0002979202545247972
Test Loss:  0.00018598778115119785
Valid Loss:  0.000386239611543715
Epoch:  244  	Training Loss: 0.0002973776136059314
Test Loss:  0.0001854502479545772
Valid Loss:  0.00038575383950956166
Epoch:  245  	Training Loss: 0.00029685284243896604
Test Loss:  0.0001849498803494498
Valid Loss:  0.00038528809091076255
Epoch:  246  	Training Loss: 0.00029634227394126356
Test Loss:  0.00018447631737217307
Valid Loss:  0.00038485255208797753
Epoch:  247  	Training Loss: 0.0002958458208013326
Test Loss:  0.00018401662237010896
Valid Loss:  0.00038443139055743814
Epoch:  248  	Training Loss: 0.00029536205693148077
Test Loss:  0.00018357571389060467
Valid Loss:  0.0003840223071165383
Epoch:  249  	Training Loss: 0.00029489159351214767
Test Loss:  0.0001831556437537074
Valid Loss:  0.00038362841587513685
Epoch:  250  	Training Loss: 0.0002944375737570226
Test Loss:  0.00018274891772307456
Valid Loss:  0.00038325527566485107
Epoch:  251  	Training Loss: 0.00029399621416814625
Test Loss:  0.00018235268362332135
Valid Loss:  0.00038289898657239974
Epoch:  252  	Training Loss: 0.00029356760205700994
Test Loss:  0.0001840925106080249
Valid Loss:  0.000382868864107877
Epoch:  253  	Training Loss: 0.0002928976318798959
Test Loss:  0.0001842159836087376
Valid Loss:  0.00038217921974137425
Epoch:  254  	Training Loss: 0.0002923745196312666
Test Loss:  0.00018398962856736034
Valid Loss:  0.0003813758376054466
Epoch:  255  	Training Loss: 0.00029189998167566955
Test Loss:  0.00018370599718764424
Valid Loss:  0.00038058796781115234
Epoch:  256  	Training Loss: 0.0002914643846452236
Test Loss:  0.00018343371630180627
Valid Loss:  0.0003798426187131554
Epoch:  257  	Training Loss: 0.000291064236080274
Test Loss:  0.0001831839617807418
Valid Loss:  0.00037914319545961916
Epoch:  258  	Training Loss: 0.0002907007001340389
Test Loss:  0.00018293369794264436
Valid Loss:  0.000378484750399366
Epoch:  259  	Training Loss: 0.00029036926571279764
Test Loss:  0.00018272273882757872
Valid Loss:  0.0003778728423640132
Epoch:  260  	Training Loss: 0.00029006070690229535
Test Loss:  0.00018253590678796172
Valid Loss:  0.00037729740142822266
Epoch:  261  	Training Loss: 0.0002897715603467077
Test Loss:  0.00018236669711768627
Valid Loss:  0.00037675295607186854
Epoch:  262  	Training Loss: 0.0002895008656196296
Test Loss:  0.0001824119535740465
Valid Loss:  0.0003761288244277239
Epoch:  263  	Training Loss: 0.00028861616738140583
Test Loss:  0.0001816732983570546
Valid Loss:  0.0003751343465410173
Epoch:  264  	Training Loss: 0.00028776185354217887
Test Loss:  0.00018103900947608054
Valid Loss:  0.00037418323336169124
Epoch:  265  	Training Loss: 0.0002869494492188096
Test Loss:  0.00018043097225017846
Valid Loss:  0.000373237970052287
Epoch:  266  	Training Loss: 0.0002861808461602777
Test Loss:  0.00017987203318625689
Valid Loss:  0.00037231011083349586
Epoch:  267  	Training Loss: 0.00028542778454720974
Test Loss:  0.00017933466006070375
Valid Loss:  0.00037139817140996456
Epoch:  268  	Training Loss: 0.0002846872666850686
Test Loss:  0.00017881383246276528
Valid Loss:  0.00037050002720206976
Epoch:  269  	Training Loss: 0.0002839576918631792
Test Loss:  0.00017830452998168766
Valid Loss:  0.0003696130879689008
Epoch:  270  	Training Loss: 0.0002832406316883862
Test Loss:  0.0001778087462298572
Valid Loss:  0.00036873549106530845
Epoch:  271  	Training Loss: 0.0002825290139298886
Test Loss:  0.00017730589024722576
Valid Loss:  0.00036785571137443185
Epoch:  272  	Training Loss: 0.00028182752430438995
Test Loss:  0.00017598926206119359
 55%|█████▍    | 273/500 [03:14<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:14<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:15<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:15<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:21<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:21<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:21<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:21<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:22<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:28<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:28<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:28<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:28<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:28<01:06,  3.00it/s] 60%|██████    | 301/500 [03:34<03:49,  1.15s/it] 61%|██████    | 303/500 [03:35<02:43,  1.21it/s] 61%|██████    | 305/500 [03:35<01:57,  1.66it/s] 61%|██████▏   | 307/500 [03:35<01:25,  2.27it/s] 62%|██████▏   | 309/500 [03:35<01:02,  3.04it/s] 62%|██████▏   | 311/500 [03:41<03:40,  1.16s/it] 63%|██████▎   | 313/500 [03:41<02:36,  1.20it/s] 63%|██████▎   | 315/500 [03:42<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:42<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:42<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:48<03:28,  1.17s/it] 65%|██████▍   | 323/500 [03:48<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:48<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:48<01:17,  2.25it/s] 66%|██████▌   | 329/500 [03:49<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:55<03:16,  1.16s/it] 67%|██████▋   | 333/500 [03:55<02:19,  1.20it/s] 67%|██████▋   | 335/500 [03:55<01:39,  1.66it/s] 67%|██████▋   | 337/500 [03:55<01:12,  2.26it/s] 68%|██████▊   | 339/500 [03:55<00:53,  3.03it/s]Valid Loss:  0.00036676539457403123
Epoch:  273  	Training Loss: 0.00028119629132561386
Test Loss:  0.00017545075388625264
Valid Loss:  0.0003660419606603682
Epoch:  274  	Training Loss: 0.0002805770782288164
Test Loss:  0.00017498296801932156
Valid Loss:  0.0003653524909168482
Epoch:  275  	Training Loss: 0.00027996086282655597
Test Loss:  0.00017452501924708486
Valid Loss:  0.0003646675031632185
Epoch:  276  	Training Loss: 0.00027934813988395035
Test Loss:  0.00017407123232260346
Valid Loss:  0.00036398484371602535
Epoch:  277  	Training Loss: 0.0002787382691167295
Test Loss:  0.00017362055950798094
Valid Loss:  0.00036330544389784336
Epoch:  278  	Training Loss: 0.0002781336079351604
Test Loss:  0.00017317489255219698
Valid Loss:  0.00036262947833165526
Epoch:  279  	Training Loss: 0.0002775372704491019
Test Loss:  0.00017273094272240996
Valid Loss:  0.000361956306733191
Epoch:  280  	Training Loss: 0.00027694704476743937
Test Loss:  0.00017228734213858843
Valid Loss:  0.00036128467763774097
Epoch:  281  	Training Loss: 0.0002763594966381788
Test Loss:  0.0001718461571726948
Valid Loss:  0.0003606145619414747
Epoch:  282  	Training Loss: 0.00027577485889196396
Test Loss:  0.0001743030734360218
Valid Loss:  0.00035902042873203754
Epoch:  283  	Training Loss: 0.00027368083829060197
Test Loss:  0.000174785585841164
Valid Loss:  0.0003580283955670893
Epoch:  284  	Training Loss: 0.0002727197716012597
Test Loss:  0.0001745598710840568
Valid Loss:  0.00035698202555067837
Epoch:  285  	Training Loss: 0.00027195087750442326
Test Loss:  0.00017406942788511515
Valid Loss:  0.00035594156361185014
Epoch:  286  	Training Loss: 0.0002712529094424099
Test Loss:  0.00017344414663966745
Valid Loss:  0.00035494245821610093
Epoch:  287  	Training Loss: 0.00027059236890636384
Test Loss:  0.00017280461906921118
Valid Loss:  0.000353985873516649
Epoch:  288  	Training Loss: 0.0002699526958167553
Test Loss:  0.00017215331899933517
Valid Loss:  0.0003530699759721756
Epoch:  289  	Training Loss: 0.0002693265560083091
Test Loss:  0.0001715933030936867
Valid Loss:  0.00035220279823988676
Epoch:  290  	Training Loss: 0.00026870990404859185
Test Loss:  0.00017098576063290238
Valid Loss:  0.00035135296639055014
Epoch:  291  	Training Loss: 0.0002681002952158451
Test Loss:  0.00017046311404556036
Valid Loss:  0.00035054009640589356
Epoch:  292  	Training Loss: 0.0002674938295967877
Test Loss:  0.00016941287321969867
Valid Loss:  0.00034988249535672367
Epoch:  293  	Training Loss: 0.0002671795664355159
Test Loss:  0.000168648999533616
Valid Loss:  0.0003493530093692243
Epoch:  294  	Training Loss: 0.00026689365040510893
Test Loss:  0.00016807872452773154
Valid Loss:  0.00034891051473096013
Epoch:  295  	Training Loss: 0.0002666264190338552
Test Loss:  0.00016764254542067647
Valid Loss:  0.00034852285170927644
Epoch:  296  	Training Loss: 0.00026636943221092224
Test Loss:  0.00016730056086089462
Valid Loss:  0.00034818562562577426
Epoch:  297  	Training Loss: 0.00026612100191414356
Test Loss:  0.00016701382992323488
Valid Loss:  0.0003478739527054131
Epoch:  298  	Training Loss: 0.00026587958564050496
Test Loss:  0.00016677255916874856
Valid Loss:  0.00034757936373353004
Epoch:  299  	Training Loss: 0.00026564509607851505
Test Loss:  0.00016656627121847123
Valid Loss:  0.0003472965327091515
Epoch:  300  	Training Loss: 0.0002654168347362429
Test Loss:  0.00016637617954984307
Valid Loss:  0.00034702036646194756
Epoch:  301  	Training Loss: 0.0002651922986842692
Test Loss:  0.0001662017748458311
Valid Loss:  0.00034675077768042684
Epoch:  302  	Training Loss: 0.00026497564977034926
Test Loss:  0.00016481539933010936
Valid Loss:  0.0003456376143731177
Epoch:  303  	Training Loss: 0.00026461039669811726
Test Loss:  0.00016440858598798513
Valid Loss:  0.0003450250078458339
Epoch:  304  	Training Loss: 0.00026429767603985965
Test Loss:  0.00016425459762103856
Valid Loss:  0.00034453789703547955
Epoch:  305  	Training Loss: 0.0002640006714500487
Test Loss:  0.0001641353010199964
Valid Loss:  0.00034410617081448436
Epoch:  306  	Training Loss: 0.00026372564025223255
Test Loss:  0.0001640760019654408
Valid Loss:  0.0003437235136516392
Epoch:  307  	Training Loss: 0.00026346289087086916
Test Loss:  0.00016400768072344363
Valid Loss:  0.00034334848169237375
Epoch:  308  	Training Loss: 0.000263214111328125
Test Loss:  0.00016394199337810278
Valid Loss:  0.00034298471291549504
Epoch:  309  	Training Loss: 0.0002629838418215513
Test Loss:  0.0001639064576011151
Valid Loss:  0.0003426375042181462
Epoch:  310  	Training Loss: 0.00026276992866769433
Test Loss:  0.00016388669610023499
Valid Loss:  0.0003423316520638764
Epoch:  311  	Training Loss: 0.0002625756023917347
Test Loss:  0.00016384225455112755
Valid Loss:  0.00034202789538539946
Epoch:  312  	Training Loss: 0.0002623911132104695
Test Loss:  0.00016539859643671662
Valid Loss:  0.0003421517612878233
Epoch:  313  	Training Loss: 0.0002619863662403077
Test Loss:  0.00016579707153141499
Valid Loss:  0.0003418683772906661
Epoch:  314  	Training Loss: 0.00026168712065555155
Test Loss:  0.00016580485680606216
Valid Loss:  0.000341493112500757
Epoch:  315  	Training Loss: 0.00026142477872781456
Test Loss:  0.0001657464454183355
Valid Loss:  0.0003411196230445057
Epoch:  316  	Training Loss: 0.00026117792003788054
Test Loss:  0.00016569605213589966
Valid Loss:  0.00034075224539265037
Epoch:  317  	Training Loss: 0.00026094442000612617
Test Loss:  0.00016555259935557842
Valid Loss:  0.000340380851412192
Epoch:  318  	Training Loss: 0.00026073044864460826
Test Loss:  0.00016543909441679716
Valid Loss:  0.0003400322748348117
Epoch:  319  	Training Loss: 0.00026052611065097153
Test Loss:  0.00016533737652935088
Valid Loss:  0.0003396969987079501
Epoch:  320  	Training Loss: 0.0002603304455988109
Test Loss:  0.00016522947407793254
Valid Loss:  0.0003393758088350296
Epoch:  321  	Training Loss: 0.000260142725892365
Test Loss:  0.00016511348076164722
Valid Loss:  0.0003390693455003202
Epoch:  322  	Training Loss: 0.000259966793237254
Test Loss:  0.00016456760931760073
Valid Loss:  0.0003382465511094779
Epoch:  323  	Training Loss: 0.0002590777585282922
Test Loss:  0.00016386547940783203
Valid Loss:  0.00033735460601747036
Epoch:  324  	Training Loss: 0.0002582360175438225
Test Loss:  0.00016323398449458182
Valid Loss:  0.0003364630392752588
Epoch:  325  	Training Loss: 0.0002574383688624948
Test Loss:  0.00016260106349363923
Valid Loss:  0.0003355639346409589
Epoch:  326  	Training Loss: 0.000256658619036898
Test Loss:  0.00016198318917304277
Valid Loss:  0.00033466683817096055
Epoch:  327  	Training Loss: 0.00025589371216483414
Test Loss:  0.000161399831995368
Valid Loss:  0.000333784002577886
Epoch:  328  	Training Loss: 0.00025514070875942707
Test Loss:  0.0001608366728760302
Valid Loss:  0.0003329093742650002
Epoch:  329  	Training Loss: 0.00025439343880862
Test Loss:  0.0001602842239663005
Valid Loss:  0.00033203931525349617
Epoch:  330  	Training Loss: 0.00025365647161379457
Test Loss:  0.00015974520647432655
Valid Loss:  0.00033117595012299716
Epoch:  331  	Training Loss: 0.00025292474310845137
Test Loss:  0.0001592131011420861
Valid Loss:  0.00033031433122232556
Epoch:  332  	Training Loss: 0.0002521992428228259
Test Loss:  0.00015760361566208303
Valid Loss:  0.0003290930180810392
Epoch:  333  	Training Loss: 0.00025149283464998007
Test Loss:  0.00015670267748646438
Valid Loss:  0.0003282202815171331
Epoch:  334  	Training Loss: 0.0002508352044969797
Test Loss:  0.00015598221216350794
Valid Loss:  0.00032743997871875763
Epoch:  335  	Training Loss: 0.0002502062125131488
Test Loss:  0.00015534262638539076
Valid Loss:  0.00032670353539288044
Epoch:  336  	Training Loss: 0.00024960230803117156
Test Loss:  0.00015474468818865716
Valid Loss:  0.0003259893273934722
Epoch:  337  	Training Loss: 0.0002490223851054907
Test Loss:  0.00015419110422953963
Valid Loss:  0.000325306347804144
Epoch:  338  	Training Loss: 0.0002484662109054625
Test Loss:  0.0001536809140816331
Valid Loss:  0.0003246523847337812
Epoch:  339  	Training Loss: 0.0002479279937688261
Test Loss:  0.00015319118392653763
Valid Loss:  0.00032402834040112793
 68%|██████▊   | 341/500 [04:01<03:03,  1.15s/it] 69%|██████▊   | 343/500 [04:02<02:09,  1.21it/s] 69%|██████▉   | 345/500 [04:02<01:32,  1.67it/s] 69%|██████▉   | 347/500 [04:02<01:07,  2.28it/s] 70%|██████▉   | 349/500 [04:02<00:49,  3.06it/s] 70%|███████   | 351/500 [04:08<02:51,  1.15s/it] 71%|███████   | 353/500 [04:08<02:01,  1.21it/s] 71%|███████   | 355/500 [04:08<01:27,  1.66it/s] 71%|███████▏  | 357/500 [04:09<01:03,  2.27it/s] 72%|███████▏  | 359/500 [04:09<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:15<02:40,  1.15s/it] 73%|███████▎  | 363/500 [04:15<01:53,  1.21it/s] 73%|███████▎  | 365/500 [04:15<01:21,  1.67it/s] 73%|███████▎  | 367/500 [04:15<00:58,  2.27it/s] 74%|███████▍  | 369/500 [04:15<00:43,  3.04it/s] 74%|███████▍  | 371/500 [04:22<02:28,  1.15s/it] 75%|███████▍  | 373/500 [04:22<01:45,  1.21it/s] 75%|███████▌  | 375/500 [04:22<01:14,  1.67it/s] 75%|███████▌  | 377/500 [04:22<00:53,  2.28it/s] 76%|███████▌  | 379/500 [04:22<00:39,  3.06it/s] 76%|███████▌  | 381/500 [04:28<02:17,  1.15s/it] 77%|███████▋  | 383/500 [04:28<01:36,  1.21it/s] 77%|███████▋  | 385/500 [04:28<01:08,  1.67it/s] 77%|███████▋  | 387/500 [04:29<00:49,  2.28it/s] 78%|███████▊  | 389/500 [04:29<00:36,  3.07it/s] 78%|███████▊  | 391/500 [04:35<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:35<01:29,  1.20it/s] 79%|███████▉  | 395/500 [04:35<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:35<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:35<00:33,  3.04it/s] 80%|████████  | 401/500 [04:42<01:54,  1.16s/it] 81%|████████  | 403/500 [04:42<01:20,  1.20it/s] 81%|████████  | 405/500 [04:42<00:57,  1.66it/s]Epoch:  340  	Training Loss: 0.0002474016509950161
Test Loss:  0.00015273284225258976
Valid Loss:  0.000323423562804237
Epoch:  341  	Training Loss: 0.00024689131532795727
Test Loss:  0.00015231847646646202
Valid Loss:  0.00032283959444612265
Epoch:  342  	Training Loss: 0.00024639663752168417
Test Loss:  0.0001532461610622704
Valid Loss:  0.0003227446577511728
Epoch:  343  	Training Loss: 0.00024608103558421135
Test Loss:  0.00015381156117655337
Valid Loss:  0.0003225649707019329
Epoch:  344  	Training Loss: 0.00024583417689427733
Test Loss:  0.00015414721565321088
Valid Loss:  0.0003223350504413247
Epoch:  345  	Training Loss: 0.00024562637554481626
Test Loss:  0.0001543416001368314
Valid Loss:  0.0003220810031052679
Epoch:  346  	Training Loss: 0.0002454443310853094
Test Loss:  0.00015445073950104415
Valid Loss:  0.0003218205238226801
Epoch:  347  	Training Loss: 0.00024528050562366843
Test Loss:  0.00015451072249561548
Valid Loss:  0.000321560597512871
Epoch:  348  	Training Loss: 0.0002451307373121381
Test Loss:  0.0001545381237519905
Valid Loss:  0.00032130544423125684
Epoch:  349  	Training Loss: 0.00024499165010638535
Test Loss:  0.00015454675303772092
Valid Loss:  0.0003210569848306477
Epoch:  350  	Training Loss: 0.00024486053735017776
Test Loss:  0.0001545438717585057
Valid Loss:  0.0003208167618140578
Epoch:  351  	Training Loss: 0.0002447369624860585
Test Loss:  0.00015453413652721792
Valid Loss:  0.0003205850371159613
Epoch:  352  	Training Loss: 0.0002446189464535564
Test Loss:  0.00015313169569708407
Valid Loss:  0.0003195229801349342
Epoch:  353  	Training Loss: 0.00024420657427981496
Test Loss:  0.00015261906082741916
Valid Loss:  0.0003188388072885573
Epoch:  354  	Training Loss: 0.0002438258088659495
Test Loss:  0.00015231530414894223
Valid Loss:  0.0003182519576512277
Epoch:  355  	Training Loss: 0.00024345421115867794
Test Loss:  0.00015205959789454937
Valid Loss:  0.0003176999161951244
Epoch:  356  	Training Loss: 0.00024309044238179922
Test Loss:  0.00015181672642938793
Valid Loss:  0.000317166734021157
Epoch:  357  	Training Loss: 0.00024273237795569003
Test Loss:  0.000151585103594698
Valid Loss:  0.00031664688140153885
Epoch:  358  	Training Loss: 0.0002423785044811666
Test Loss:  0.00015135420835576952
Valid Loss:  0.00031613968894816935
Epoch:  359  	Training Loss: 0.00024202902568504214
Test Loss:  0.0001511292066425085
Valid Loss:  0.00031564367236569524
Epoch:  360  	Training Loss: 0.00024168225354515016
Test Loss:  0.00015090839588083327
Valid Loss:  0.0003151546115987003
Epoch:  361  	Training Loss: 0.00024133772240020335
Test Loss:  0.00015068979701027274
Valid Loss:  0.00031467346707358956
Epoch:  362  	Training Loss: 0.00024099524307530373
Test Loss:  0.00014979159459471703
Valid Loss:  0.0003141453489661217
Epoch:  363  	Training Loss: 0.0002408866712357849
Test Loss:  0.00014960457338020205
Valid Loss:  0.0003139281179755926
Epoch:  364  	Training Loss: 0.00024079455761238933
Test Loss:  0.00014955809456296265
Valid Loss:  0.00031377043342217803
Epoch:  365  	Training Loss: 0.00024070395738817751
Test Loss:  0.00014952919445931911
Valid Loss:  0.00031362753361463547
Epoch:  366  	Training Loss: 0.00024061641306616366
Test Loss:  0.0001495090837124735
Valid Loss:  0.0003134934522677213
Epoch:  367  	Training Loss: 0.00024053012020885944
Test Loss:  0.00014949956675991416
Valid Loss:  0.0003133661230094731
Epoch:  368  	Training Loss: 0.00024044701422099024
Test Loss:  0.00014947869931347668
Valid Loss:  0.000313239375827834
Epoch:  369  	Training Loss: 0.00024036636750679463
Test Loss:  0.00014946283772587776
Valid Loss:  0.00031311556813307106
Epoch:  370  	Training Loss: 0.00024028636107686907
Test Loss:  0.00014944057329557836
Valid Loss:  0.0003129931865260005
Epoch:  371  	Training Loss: 0.00024020890123210847
Test Loss:  0.00014941718836780638
Valid Loss:  0.00031287322053685784
Epoch:  372  	Training Loss: 0.00024013363872654736
Test Loss:  0.0001498293422628194
Valid Loss:  0.0003127523814328015
Epoch:  373  	Training Loss: 0.00023973538191057742
Test Loss:  0.00015002686996012926
Valid Loss:  0.00031256009242497385
Epoch:  374  	Training Loss: 0.00023936136858537793
Test Loss:  0.0001500743965152651
Valid Loss:  0.00031231503817252815
Epoch:  375  	Training Loss: 0.00023900032101664692
Test Loss:  0.00015002096188254654
Valid Loss:  0.00031203567050397396
Epoch:  376  	Training Loss: 0.0002386479900451377
Test Loss:  0.00014989898772910237
Valid Loss:  0.00031173008028417826
Epoch:  377  	Training Loss: 0.0002383019746048376
Test Loss:  0.00014973040379118174
Valid Loss:  0.0003114077844657004
Epoch:  378  	Training Loss: 0.00023796074674464762
Test Loss:  0.0001495328324381262
Valid Loss:  0.0003110745456069708
Epoch:  379  	Training Loss: 0.00023762427736073732
Test Loss:  0.00014931551413610578
Valid Loss:  0.0003107322845607996
Epoch:  380  	Training Loss: 0.00023729134409222752
Test Loss:  0.0001490829308750108
Valid Loss:  0.0003103847848251462
Epoch:  381  	Training Loss: 0.0002369610738242045
Test Loss:  0.00014884345000609756
Valid Loss:  0.0003100338508374989
Epoch:  382  	Training Loss: 0.0002366330591030419
Test Loss:  0.0001474260352551937
Valid Loss:  0.00030907089239917696
Epoch:  383  	Training Loss: 0.0002359299105592072
Test Loss:  0.00014652808022219688
Valid Loss:  0.0003083040355704725
Epoch:  384  	Training Loss: 0.00023530106409452856
Test Loss:  0.0001459531340515241
Valid Loss:  0.0003077762376051396
Epoch:  385  	Training Loss: 0.00023471703752875328
Test Loss:  0.00014513843052554876
Valid Loss:  0.0003070147358812392
Epoch:  386  	Training Loss: 0.0002341833896934986
Test Loss:  0.0001448250113753602
Valid Loss:  0.00030660582706332207
Epoch:  387  	Training Loss: 0.0002336786565138027
Test Loss:  0.00014434930926654488
Valid Loss:  0.0003061479947064072
Epoch:  388  	Training Loss: 0.0002331980795133859
Test Loss:  0.00014380444190464914
Valid Loss:  0.00030560040613636374
Epoch:  389  	Training Loss: 0.00023275033163372427
Test Loss:  0.0001435017038602382
Valid Loss:  0.00030521847656928003
Epoch:  390  	Training Loss: 0.0002323172811884433
Test Loss:  0.0001431540003977716
Valid Loss:  0.0003048212674912065
Epoch:  391  	Training Loss: 0.00023190784850157797
Test Loss:  0.0001428287650924176
Valid Loss:  0.0003044362529180944
Epoch:  392  	Training Loss: 0.0002315170131623745
Test Loss:  0.00014312796702142805
Valid Loss:  0.00030382192926481366
Epoch:  393  	Training Loss: 0.00023091719776857644
Test Loss:  0.00014296709559857845
Valid Loss:  0.00030306479311548173
Epoch:  394  	Training Loss: 0.00023037174833007157
Test Loss:  0.00014272908447310328
Valid Loss:  0.00030232654535211623
Epoch:  395  	Training Loss: 0.00022987292322795838
Test Loss:  0.00014247099170461297
Valid Loss:  0.0003016200789716095
Epoch:  396  	Training Loss: 0.00022940244525671005
Test Loss:  0.00014221624587662518
Valid Loss:  0.00030094190151430666
Epoch:  397  	Training Loss: 0.0002289508265675977
Test Loss:  0.00014196886331774294
Valid Loss:  0.00030029326444491744
Epoch:  398  	Training Loss: 0.00022851380344945937
Test Loss:  0.00014171672228258103
Valid Loss:  0.0002996589755639434
Epoch:  399  	Training Loss: 0.00022808452195022255
Test Loss:  0.00014146594912745059
Valid Loss:  0.0002990433422382921
Epoch:  400  	Training Loss: 0.00022766418987885118
Test Loss:  0.000141237978823483
Valid Loss:  0.00029847139376215637
Epoch:  401  	Training Loss: 0.00022725999588146806
Test Loss:  0.00014101510168984532
Valid Loss:  0.00029792566783726215
Epoch:  402  	Training Loss: 0.00022686632291879505
Test Loss:  0.00014081808330956846
Valid Loss:  0.0002976020332425833
Epoch:  403  	Training Loss: 0.00022640396491624415
Test Loss:  0.00014059111708775163
Valid Loss:  0.00029729431844316423
Epoch:  404  	Training Loss: 0.00022598897339776158
Test Loss:  0.0001403426576871425
Valid Loss:  0.00029699530568905175
Epoch:  405  	Training Loss: 0.00022559944773092866
Test Loss:  0.00014008520520292222
Valid Loss:  0.0002967000473290682
Epoch:  406  	Training Loss: 0.00022522365907207131
Test Loss:  0.00013983278768137097
Valid Loss:  0.0002964084851555526
 81%|████████▏ | 407/500 [04:42<00:40,  2.27it/s] 82%|████████▏ | 409/500 [04:42<00:29,  3.05it/s] 82%|████████▏ | 411/500 [04:48<01:42,  1.15s/it] 83%|████████▎ | 413/500 [04:48<01:11,  1.21it/s] 83%|████████▎ | 415/500 [04:49<00:50,  1.67it/s] 83%|████████▎ | 417/500 [04:49<00:36,  2.28it/s] 84%|████████▍ | 419/500 [04:49<00:26,  3.06it/s] 84%|████████▍ | 421/500 [04:55<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:55<01:04,  1.20it/s] 85%|████████▌ | 425/500 [04:55<00:45,  1.66it/s] 85%|████████▌ | 427/500 [04:55<00:32,  2.26it/s] 86%|████████▌ | 429/500 [04:56<00:23,  3.03it/s] 86%|████████▌ | 431/500 [05:02<01:19,  1.16s/it] 87%|████████▋ | 433/500 [05:02<00:55,  1.20it/s] 87%|████████▋ | 435/500 [05:02<00:39,  1.66it/s] 87%|████████▋ | 437/500 [05:02<00:27,  2.27it/s] 88%|████████▊ | 439/500 [05:02<00:20,  3.05it/s] 88%|████████▊ | 441/500 [05:08<01:07,  1.15s/it] 89%|████████▊ | 443/500 [05:09<00:47,  1.21it/s] 89%|████████▉ | 445/500 [05:09<00:32,  1.67it/s] 89%|████████▉ | 447/500 [05:09<00:23,  2.28it/s] 90%|████████▉ | 449/500 [05:09<00:16,  3.05it/s] 90%|█████████ | 451/500 [05:15<00:56,  1.15s/it] 91%|█████████ | 453/500 [05:15<00:38,  1.21it/s] 91%|█████████ | 455/500 [05:15<00:26,  1.68it/s] 91%|█████████▏| 457/500 [05:16<00:18,  2.29it/s] 92%|█████████▏| 459/500 [05:16<00:13,  3.07it/s] 92%|█████████▏| 461/500 [05:22<00:45,  1.16s/it] 93%|█████████▎| 463/500 [05:22<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.66it/s] 93%|█████████▎| 467/500 [05:22<00:14,  2.26it/s] 94%|█████████▍| 469/500 [05:22<00:10,  3.04it/s] 94%|█████████▍| 471/500 [05:29<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:29<00:22,  1.20it/s]Epoch:  407  	Training Loss: 0.00022486396483145654
Test Loss:  0.00013957454939372838
Valid Loss:  0.0002961198042612523
Epoch:  408  	Training Loss: 0.0002245198847958818
Test Loss:  0.00013931341527495533
Valid Loss:  0.00029583563446067274
Epoch:  409  	Training Loss: 0.00022419133165385574
Test Loss:  0.0001390499237459153
Valid Loss:  0.00029555667424574494
Epoch:  410  	Training Loss: 0.00022388195793610066
Test Loss:  0.00013878823665436357
Valid Loss:  0.00029528228333219886
Epoch:  411  	Training Loss: 0.00022358642308972776
Test Loss:  0.0001385345822200179
Valid Loss:  0.00029501249082386494
Epoch:  412  	Training Loss: 0.0002233005507150665
Test Loss:  0.00013916876923758537
Valid Loss:  0.00029453725437633693
Epoch:  413  	Training Loss: 0.00022269200417213142
Test Loss:  0.00013933077570982277
Valid Loss:  0.000293944263830781
Epoch:  414  	Training Loss: 0.00022214086493477225
Test Loss:  0.00013924452650826424
Valid Loss:  0.00029329280368983746
Epoch:  415  	Training Loss: 0.00022161455126479268
Test Loss:  0.00013903297076467425
Valid Loss:  0.00029262067982926965
Epoch:  416  	Training Loss: 0.00022110276040621102
Test Loss:  0.00013876115554012358
Valid Loss:  0.0002919459075201303
Epoch:  417  	Training Loss: 0.0002206018107244745
Test Loss:  0.00013846209913026541
Valid Loss:  0.00029127730522304773
Epoch:  418  	Training Loss: 0.00022011045075487345
Test Loss:  0.00013815503916703165
Valid Loss:  0.00029062206158414483
Epoch:  419  	Training Loss: 0.00021962885512039065
Test Loss:  0.00013784642214886844
Valid Loss:  0.0002899773826356977
Epoch:  420  	Training Loss: 0.00021915571414865553
Test Loss:  0.00013751580263487995
Valid Loss:  0.00028931896667927504
Epoch:  421  	Training Loss: 0.00021867823670618236
Test Loss:  0.0001370903046336025
Valid Loss:  0.0002885983558371663
Epoch:  422  	Training Loss: 0.00021815596846863627
Test Loss:  0.0001367241784464568
Valid Loss:  0.0002877971564885229
Epoch:  423  	Training Loss: 0.0002177416463382542
Test Loss:  0.00013651921472046524
Valid Loss:  0.00028716944507323205
Epoch:  424  	Training Loss: 0.00021735242626164109
Test Loss:  0.00013633680646307766
Valid Loss:  0.00028660736279562116
Epoch:  425  	Training Loss: 0.00021699002536479384
Test Loss:  0.00013605068670585752
Valid Loss:  0.00028598582139238715
Epoch:  426  	Training Loss: 0.00021664632367901504
Test Loss:  0.00013592901814263314
Valid Loss:  0.00028555357130244374
Epoch:  427  	Training Loss: 0.00021632041898556054
Test Loss:  0.00013572534953709692
Valid Loss:  0.0002850719611160457
Epoch:  428  	Training Loss: 0.00021604137145914137
Test Loss:  0.00013555257464759052
Valid Loss:  0.00028463127091526985
Epoch:  429  	Training Loss: 0.0002157778071705252
Test Loss:  0.00013539950305130333
Valid Loss:  0.00028422102332115173
Epoch:  430  	Training Loss: 0.000215522653888911
Test Loss:  0.00013526261318475008
Valid Loss:  0.0002838365617208183
Epoch:  431  	Training Loss: 0.00021527572243940085
Test Loss:  0.00013513327576220036
Valid Loss:  0.0002834705519489944
Epoch:  432  	Training Loss: 0.00021503906464204192
Test Loss:  0.00013511194265447557
Valid Loss:  0.0002833944163285196
Epoch:  433  	Training Loss: 0.0002149587671738118
Test Loss:  0.0001350844686385244
Valid Loss:  0.0002833169128280133
Epoch:  434  	Training Loss: 0.00021487983758561313
Test Loss:  0.00013505155220627785
Valid Loss:  0.0002832378086168319
Epoch:  435  	Training Loss: 0.0002148035855498165
Test Loss:  0.00013501549256034195
Valid Loss:  0.00028316385578364134
Epoch:  436  	Training Loss: 0.00021473046217579395
Test Loss:  0.0001349759113509208
Valid Loss:  0.0002830896992236376
Epoch:  437  	Training Loss: 0.000214658779441379
Test Loss:  0.00013493408914655447
Valid Loss:  0.00028301618294790387
Epoch:  438  	Training Loss: 0.0002145891048712656
Test Loss:  0.00013489049160853028
Valid Loss:  0.0002829433651641011
Epoch:  439  	Training Loss: 0.00021452255896292627
Test Loss:  0.00013484703958965838
Valid Loss:  0.00028287284658290446
Epoch:  440  	Training Loss: 0.00021445930178742856
Test Loss:  0.00013480213237926364
Valid Loss:  0.00028280133847147226
Epoch:  441  	Training Loss: 0.0002143967867596075
Test Loss:  0.00013475518790073693
Valid Loss:  0.00028273064526729286
Epoch:  442  	Training Loss: 0.00021433571237139404
Test Loss:  0.00013392955588642508
Valid Loss:  0.0002821341040544212
Epoch:  443  	Training Loss: 0.00021406717132776976
Test Loss:  0.00013343675527721643
Valid Loss:  0.0002816293854266405
Epoch:  444  	Training Loss: 0.00021369382739067078
Test Loss:  0.00013291076174937189
Valid Loss:  0.00028101232601329684
Epoch:  445  	Training Loss: 0.00021320489759091288
Test Loss:  0.00013246807793620974
Valid Loss:  0.0002804151445161551
Epoch:  446  	Training Loss: 0.00021271374134812504
Test Loss:  0.00013214064529165626
Valid Loss:  0.0002799139474518597
Epoch:  447  	Training Loss: 0.00021229058620519936
Test Loss:  0.00013190245954319835
Valid Loss:  0.00027945925830863416
Epoch:  448  	Training Loss: 0.00021193164866417646
Test Loss:  0.00013179733650758862
Valid Loss:  0.00027916007093153894
Epoch:  449  	Training Loss: 0.00021170878608245403
Test Loss:  0.00013173834304325283
Valid Loss:  0.00027893236256204545
Epoch:  450  	Training Loss: 0.00021153883426450193
Test Loss:  0.00013167341239750385
Valid Loss:  0.00027872034115716815
Epoch:  451  	Training Loss: 0.00021139725868124515
Test Loss:  0.00013162233517505229
Valid Loss:  0.0002785544202197343
Epoch:  452  	Training Loss: 0.00021127481886651367
Test Loss:  0.00013147719437256455
Valid Loss:  0.00027838675305247307
Epoch:  453  	Training Loss: 0.00021110635134391487
Test Loss:  0.00013133991160430014
Valid Loss:  0.00027822586707770824
Epoch:  454  	Training Loss: 0.00021094417024869472
Test Loss:  0.0001312096428591758
Valid Loss:  0.00027807243168354034
Epoch:  455  	Training Loss: 0.00021078938152641058
Test Loss:  0.00013108317216392606
Valid Loss:  0.00027792519540525973
Epoch:  456  	Training Loss: 0.00021064007887616754
Test Loss:  0.00013096045586280525
Valid Loss:  0.0002777852350845933
Epoch:  457  	Training Loss: 0.00021049471979495138
Test Loss:  0.00013084123202133924
Valid Loss:  0.000277649232884869
Epoch:  458  	Training Loss: 0.00021035282406955957
Test Loss:  0.0001307237835135311
Valid Loss:  0.0002775156171992421
Epoch:  459  	Training Loss: 0.00021021465363446623
Test Loss:  0.0001306107296841219
Valid Loss:  0.0002773868036456406
Epoch:  460  	Training Loss: 0.0002100801793858409
Test Loss:  0.00013049840345047414
Valid Loss:  0.00027725851396098733
Epoch:  461  	Training Loss: 0.00020994796068407595
Test Loss:  0.0001303874742006883
Valid Loss:  0.0002771338331513107
Epoch:  462  	Training Loss: 0.00020981776469852775
Test Loss:  0.0001320494047831744
Valid Loss:  0.0002763926167972386
Epoch:  463  	Training Loss: 0.00020874198526144028
Test Loss:  0.00013143039541319013
Valid Loss:  0.0002753895241767168
Epoch:  464  	Training Loss: 0.0002081091224681586
Test Loss:  0.0001309903454966843
Valid Loss:  0.0002745701349340379
Epoch:  465  	Training Loss: 0.0002075584779959172
Test Loss:  0.00013068555563222617
Valid Loss:  0.0002738253097049892
Epoch:  466  	Training Loss: 0.00020706960640382022
Test Loss:  0.00013039493933320045
Valid Loss:  0.0002731407876126468
Epoch:  467  	Training Loss: 0.00020663035684265196
Test Loss:  0.0001302416349062696
Valid Loss:  0.00027253589360043406
Epoch:  468  	Training Loss: 0.00020621241128537804
Test Loss:  0.00012999572209082544
Valid Loss:  0.0002719506446737796
Epoch:  469  	Training Loss: 0.00020583429432008415
Test Loss:  0.00012984176282770932
Valid Loss:  0.00027140561724081635
Epoch:  470  	Training Loss: 0.00020546346786431968
Test Loss:  0.00012966105714440346
Valid Loss:  0.00027087057242169976
Epoch:  471  	Training Loss: 0.00020510880858637393
Test Loss:  0.00012948313087690622
Valid Loss:  0.0002703499631024897
Epoch:  472  	Training Loss: 0.00020476419012993574
Test Loss:  0.00012752584007102996
Valid Loss:  0.00026905001141130924
Epoch:  473  	Training Loss: 0.00020415113249327987
Test Loss:  0.00012704853725153953
Valid Loss:  0.00026833463925868273
 95%|█████████▌| 475/500 [05:29<00:15,  1.66it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.27it/s] 96%|█████████▌| 479/500 [05:29<00:06,  3.05it/s] 96%|█████████▌| 481/500 [05:35<00:21,  1.15s/it] 97%|█████████▋| 483/500 [05:35<00:14,  1.21it/s] 97%|█████████▋| 485/500 [05:36<00:08,  1.67it/s] 97%|█████████▋| 487/500 [05:36<00:05,  2.29it/s] 98%|█████████▊| 489/500 [05:36<00:03,  3.08it/s] 98%|█████████▊| 491/500 [05:42<00:10,  1.15s/it] 99%|█████████▊| 493/500 [05:42<00:05,  1.21it/s] 99%|█████████▉| 495/500 [05:42<00:02,  1.67it/s] 99%|█████████▉| 497/500 [05:42<00:01,  2.28it/s]100%|█████████▉| 499/500 [05:42<00:00,  3.06it/s]100%|██████████| 500/500 [05:43<00:00,  1.46it/s]
Epoch:  474  	Training Loss: 0.00020358830806799233
Test Loss:  0.00012666940165217966
Valid Loss:  0.0002676581498235464
Epoch:  475  	Training Loss: 0.0002030362084042281
Test Loss:  0.00012630941637326032
Valid Loss:  0.0002669910900294781
Epoch:  476  	Training Loss: 0.00020249678345862776
Test Loss:  0.00012594496365636587
Valid Loss:  0.00026632752269506454
Epoch:  477  	Training Loss: 0.00020196018158458173
Test Loss:  0.00012559237075038254
Valid Loss:  0.00026567227905616164
Epoch:  478  	Training Loss: 0.00020143641449976712
Test Loss:  0.00012525197234936059
Valid Loss:  0.0002650220994837582
Epoch:  479  	Training Loss: 0.00020092245540581644
Test Loss:  0.00012493639951571822
Valid Loss:  0.00026439144858159125
Epoch:  480  	Training Loss: 0.0002004182751988992
Test Loss:  0.00012462236918509007
Valid Loss:  0.0002637626603245735
Epoch:  481  	Training Loss: 0.0001999191881623119
Test Loss:  0.0001243237202288583
Valid Loss:  0.00026314606657251716
Epoch:  482  	Training Loss: 0.00019943562801927328
Test Loss:  0.0001244736195076257
Valid Loss:  0.00026277470169588923
Epoch:  483  	Training Loss: 0.00019907306705135852
Test Loss:  0.00012430609785951674
Valid Loss:  0.00026229320792481303
Epoch:  484  	Training Loss: 0.00019871618133038282
Test Loss:  0.00012409963528625667
Valid Loss:  0.0002617954451125115
Epoch:  485  	Training Loss: 0.00019836115825455636
Test Loss:  0.00012389877520035952
Valid Loss:  0.000261301058344543
Epoch:  486  	Training Loss: 0.00019800805603154004
Test Loss:  0.00012368717580102384
Valid Loss:  0.000260803266428411
Epoch:  487  	Training Loss: 0.00019765604520216584
Test Loss:  0.0001234767842106521
Valid Loss:  0.0002603041648399085
Epoch:  488  	Training Loss: 0.00019730310305021703
Test Loss:  0.00012326033902354538
Valid Loss:  0.0002598018036223948
Epoch:  489  	Training Loss: 0.00019695027731359005
Test Loss:  0.0001230417110491544
Valid Loss:  0.00025930546689778566
Epoch:  490  	Training Loss: 0.00019660111865960062
Test Loss:  0.0001228342007379979
Valid Loss:  0.00025882694171741605
Epoch:  491  	Training Loss: 0.00019626005087047815
Test Loss:  0.0001226284948643297
Valid Loss:  0.00025836151326075196
Epoch:  492  	Training Loss: 0.00019592561875469983
Test Loss:  0.00012285173579584807
Valid Loss:  0.00025816215202212334
Epoch:  493  	Training Loss: 0.00019564000831451267
Test Loss:  0.00012286705896258354
Valid Loss:  0.00025789631763473153
Epoch:  494  	Training Loss: 0.0001953610626515001
Test Loss:  0.00012278056237846613
Valid Loss:  0.000257597683230415
Epoch:  495  	Training Loss: 0.00019508437253534794
Test Loss:  0.00012264651013538241
Valid Loss:  0.0002572828670963645
Epoch:  496  	Training Loss: 0.00019480881746858358
Test Loss:  0.00012248827260918915
Valid Loss:  0.00025695934891700745
Epoch:  497  	Training Loss: 0.00019453464483376592
Test Loss:  0.00012232025619596243
Valid Loss:  0.0002566338225733489
Epoch:  498  	Training Loss: 0.00019426093786023557
Test Loss:  0.0001221482380060479
Valid Loss:  0.0002563066373113543
Epoch:  499  	Training Loss: 0.0001939883513841778
Test Loss:  0.00012197462638141587
Valid Loss:  0.00025597852072678506
Epoch:  500  	Training Loss: 0.0001937166671268642
Test Loss:  0.00012180052726762369
Valid Loss:  0.000255650986218825
seed is  13
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:34, 14.23it/s]  1%|          | 4/500 [00:00<00:32, 15.38it/s]  1%|          | 6/500 [00:00<00:32, 15.11it/s]  2%|▏         | 8/500 [00:00<00:31, 15.66it/s]  2%|▏         | 10/500 [00:00<00:30, 15.95it/s]  2%|▏         | 12/500 [00:00<00:30, 16.04it/s]  3%|▎         | 14/500 [00:00<00:29, 16.21it/s]  3%|▎         | 16/500 [00:01<00:29, 16.23it/s]  4%|▎         | 18/500 [00:01<00:29, 16.25it/s]  4%|▍         | 20/500 [00:01<00:29, 16.21it/s]  4%|▍         | 22/500 [00:01<00:29, 16.13it/s]  5%|▍         | 24/500 [00:01<00:30, 15.84it/s]  5%|▌         | 26/500 [00:01<00:29, 15.93it/s]  6%|▌         | 28/500 [00:01<00:30, 15.60it/s]  6%|▌         | 30/500 [00:01<00:29, 15.81it/s]  6%|▋         | 32/500 [00:02<00:29, 15.93it/s]  7%|▋         | 34/500 [00:02<00:29, 16.05it/s]  7%|▋         | 36/500 [00:02<00:28, 16.03it/s]  8%|▊         | 38/500 [00:02<00:28, 16.08it/s]  8%|▊         | 40/500 [00:02<00:29, 15.80it/s]  8%|▊         | 42/500 [00:02<00:29, 15.69it/s]  9%|▉         | 44/500 [00:02<00:29, 15.60it/s]  9%|▉         | 46/500 [00:02<00:28, 15.83it/s] 10%|▉         | 48/500 [00:03<00:28, 15.79it/s] 10%|█         | 50/500 [00:03<00:28, 15.79it/s] 10%|█         | 52/500 [00:03<00:28, 15.78it/s] 11%|█         | 54/500 [00:03<00:27, 15.96it/s] 11%|█         | 56/500 [00:03<00:27, 16.09it/s] 12%|█▏        | 58/500 [00:03<00:27, 15.92it/s] 12%|█▏        | 60/500 [00:03<00:27, 15.92it/s] 12%|█▏        | 62/500 [00:03<00:27, 15.99it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.83it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.41it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.56it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.77it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.80it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.80it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.00it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.13it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.20it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.31it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.29it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.08it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.82it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.84it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.78it/s] 19%|█▉        | 94/500 [00:05<00:26, 15.31it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.62it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.76it/s] 20%|██        | 100/500 [00:06<00:25, 15.77it/s] 20%|██        | 102/500 [00:06<00:25, 15.70it/s] 21%|██        | 104/500 [00:06<00:25, 15.79it/s] 21%|██        | 106/500 [00:06<00:25, 15.29it/s] 22%|██▏       | 108/500 [00:06<00:25, 15.42it/s] 22%|██▏       | 110/500 [00:06<00:24, 15.66it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.67it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.91it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.98it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.02it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.13it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.19it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.27it/s]Epoch:  1  	Training Loss: 0.05115431919693947
Test Loss:  272.36773681640625
Valid Loss:  272.6930236816406
Epoch:  2  	Training Loss: 273.21282958984375
Test Loss:  9693595648.0
Valid Loss:  9645209600.0
Epoch:  3  	Training Loss: 9583562752.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.33it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.25it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.99it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.90it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.65it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.76it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.90it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.02it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.02it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.96it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.91it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.08it/s] 30%|███       | 150/500 [00:09<00:21, 16.05it/s] 30%|███       | 152/500 [00:09<00:21, 15.91it/s] 31%|███       | 154/500 [00:09<00:21, 15.98it/s] 31%|███       | 156/500 [00:09<00:21, 15.83it/s] 32%|███▏      | 158/500 [00:09<00:21, 15.69it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.88it/s] 32%|███▏      | 162/500 [00:10<00:21, 16.02it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.12it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.23it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.01it/s] 34%|███▍      | 170/500 [00:10<00:21, 15.40it/s] 34%|███▍      | 172/500 [00:10<00:21, 15.43it/s] 35%|███▍      | 174/500 [00:10<00:20, 15.72it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.80it/s] 36%|███▌      | 178/500 [00:11<00:21, 15.28it/s] 36%|███▌      | 180/500 [00:11<00:22, 14.08it/s] 36%|███▋      | 182/500 [00:11<00:22, 14.27it/s] 37%|███▋      | 184/500 [00:11<00:21, 14.52it/s] 37%|███▋      | 186/500 [00:11<00:22, 14.03it/s] 38%|███▊      | 188/500 [00:11<00:21, 14.24it/s] 38%|███▊      | 190/500 [00:12<00:20, 14.82it/s] 38%|███▊      | 192/500 [00:12<00:20, 15.20it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.31it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.35it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.64it/s] 40%|████      | 200/500 [00:12<00:18, 15.82it/s] 40%|████      | 202/500 [00:12<00:18, 15.96it/s] 41%|████      | 204/500 [00:12<00:18, 16.05it/s] 41%|████      | 206/500 [00:13<00:19, 14.86it/s] 42%|████▏     | 208/500 [00:13<00:19, 14.73it/s] 42%|████▏     | 210/500 [00:13<00:19, 15.16it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.50it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.77it/s] 43%|████▎     | 216/500 [00:13<00:17, 15.91it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.96it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.09it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.06it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.01it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.14it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.17it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.20it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.18it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.12it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.13it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.24it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.72it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.51it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.71it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.74it/s] 50%|████▉     | 248/500 [00:15<00:16, 15.16it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:16, 15.52it/s] 50%|█████     | 252/500 [00:16<00:15, 15.70it/s] 51%|█████     | 254/500 [00:16<00:15, 15.59it/s] 51%|█████     | 256/500 [00:16<00:15, 15.51it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.65it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.71it/s] 52%|█████▏    | 262/500 [00:16<00:14, 15.90it/s] 53%|█████▎    | 264/500 [00:16<00:14, 15.89it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.83it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.78it/s] 54%|█████▍    | 270/500 [00:17<00:15, 14.86it/s] 54%|█████▍    | 272/500 [00:17<00:16, 14.06it/s] 55%|█████▍    | 274/500 [00:17<00:15, 14.62it/s] 55%|█████▌    | 276/500 [00:17<00:15, 14.40it/s] 56%|█████▌    | 278/500 [00:17<00:15, 14.27it/s] 56%|█████▌    | 280/500 [00:17<00:15, 14.65it/s] 56%|█████▋    | 282/500 [00:18<00:15, 14.38it/s] 57%|█████▋    | 284/500 [00:18<00:14, 14.77it/s] 57%|█████▋    | 286/500 [00:18<00:14, 15.07it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.24it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.42it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.34it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.63it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.82it/s] 60%|█████▉    | 298/500 [00:19<00:12, 16.04it/s] 60%|██████    | 300/500 [00:19<00:12, 15.79it/s] 60%|██████    | 302/500 [00:19<00:12, 15.74it/s] 61%|██████    | 304/500 [00:19<00:12, 15.78it/s] 61%|██████    | 306/500 [00:19<00:12, 15.92it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.03it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.07it/s] 62%|██████▏   | 312/500 [00:19<00:11, 15.82it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.81it/s] 63%|██████▎   | 316/500 [00:20<00:12, 15.15it/s] 64%|██████▎   | 318/500 [00:20<00:11, 15.44it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.76it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.93it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.07it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.13it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.17it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.21it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.21it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.02it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.89it/s] 68%|██████▊   | 338/500 [00:21<00:10, 16.06it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.09it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.10it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.09it/s] 69%|██████▉   | 346/500 [00:22<00:09, 15.84it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.53it/s] 70%|███████   | 350/500 [00:22<00:09, 15.69it/s] 70%|███████   | 352/500 [00:22<00:09, 15.81it/s] 71%|███████   | 354/500 [00:22<00:09, 15.79it/s] 71%|███████   | 356/500 [00:22<00:09, 15.95it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.06it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.10it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.06it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.95it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.92it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.01it/s] 74%|███████▍  | 370/500 [00:23<00:08, 14.85it/s] 74%|███████▍  | 372/500 [00:23<00:09, 14.05it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:08, 14.46it/s] 75%|███████▌  | 376/500 [00:23<00:08, 14.97it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.33it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.59it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.78it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.73it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.16it/s] 78%|███████▊  | 388/500 [00:24<00:07, 15.48it/s] 78%|███████▊  | 390/500 [00:24<00:07, 15.64it/s] 78%|███████▊  | 392/500 [00:25<00:06, 15.66it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.82it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.56it/s] 80%|███████▉  | 398/500 [00:25<00:06, 15.81it/s] 80%|████████  | 400/500 [00:25<00:06, 15.75it/s] 80%|████████  | 402/500 [00:25<00:06, 15.67it/s] 81%|████████  | 404/500 [00:25<00:06, 15.43it/s] 81%|████████  | 406/500 [00:25<00:05, 15.68it/s] 82%|████████▏ | 408/500 [00:26<00:05, 15.87it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.91it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.55it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.44it/s] 83%|████████▎ | 416/500 [00:26<00:05, 15.26it/s] 84%|████████▎ | 418/500 [00:26<00:05, 15.54it/s] 84%|████████▍ | 420/500 [00:26<00:05, 15.57it/s] 84%|████████▍ | 422/500 [00:26<00:05, 15.36it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.52it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.83it/s] 86%|████████▌ | 428/500 [00:27<00:04, 15.80it/s] 86%|████████▌ | 430/500 [00:27<00:04, 15.93it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.02it/s] 87%|████████▋ | 434/500 [00:27<00:04, 15.71it/s] 87%|████████▋ | 436/500 [00:27<00:04, 15.86it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.01it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.09it/s] 88%|████████▊ | 442/500 [00:28<00:03, 15.94it/s] 89%|████████▉ | 444/500 [00:28<00:03, 15.90it/s] 89%|████████▉ | 446/500 [00:28<00:03, 15.48it/s] 90%|████████▉ | 448/500 [00:28<00:03, 15.37it/s] 90%|█████████ | 450/500 [00:28<00:03, 15.61it/s] 90%|█████████ | 452/500 [00:28<00:03, 15.84it/s] 91%|█████████ | 454/500 [00:28<00:02, 15.75it/s] 91%|█████████ | 456/500 [00:29<00:02, 15.72it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.17it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.49it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.74it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.81it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.00it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.06it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.09it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.02it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.05it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.00it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.08it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.93it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.71it/s] 97%|█████████▋| 484/500 [00:30<00:01, 14.44it/s] 97%|█████████▋| 486/500 [00:31<00:00, 14.60it/s] 98%|█████████▊| 488/500 [00:31<00:00, 13.96it/s] 98%|█████████▊| 490/500 [00:31<00:00, 14.23it/s] 98%|█████████▊| 492/500 [00:31<00:00, 14.24it/s] 99%|█████████▉| 494/500 [00:31<00:00, 14.78it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.19it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.31it/s]100%|██████████| 500/500 [00:31<00:00, 15.16it/s]100%|██████████| 500/500 [00:31<00:00, 15.64it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  13
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:16,  6.17s/it]  1%|          | 3/500 [00:06<13:40,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:12<10:37,  1.30s/it]  3%|▎         | 13/500 [00:13<07:14,  1.12it/s]  3%|▎         | 15/500 [00:13<05:03,  1.60it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:22,  1.17s/it]  5%|▍         | 23/500 [00:19<06:39,  1.19it/s]  5%|▌         | 25/500 [00:19<04:46,  1.66it/s]  5%|▌         | 27/500 [00:19<03:28,  2.27it/s]  6%|▌         | 29/500 [00:20<02:34,  3.06it/s]  6%|▌         | 31/500 [00:26<09:04,  1.16s/it]  7%|▋         | 33/500 [00:26<06:28,  1.20it/s]  7%|▋         | 35/500 [00:26<04:40,  1.66it/s]  7%|▋         | 37/500 [00:26<03:24,  2.26it/s]  8%|▊         | 39/500 [00:26<02:31,  3.04it/s]  8%|▊         | 41/500 [00:32<08:47,  1.15s/it]  9%|▊         | 43/500 [00:33<06:17,  1.21it/s]  9%|▉         | 45/500 [00:33<04:31,  1.67it/s]  9%|▉         | 47/500 [00:33<03:18,  2.28it/s] 10%|▉         | 49/500 [00:33<02:27,  3.07it/s] 10%|█         | 51/500 [00:39<08:47,  1.17s/it] 11%|█         | 53/500 [00:39<06:17,  1.18it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:46<08:35,  1.17s/it] 13%|█▎        | 63/500 [00:46<06:08,  1.19it/s] 13%|█▎        | 65/500 [00:46<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s]Epoch:  1  	Training Loss: 0.05115431919693947
Test Loss:  186.05905151367188
Valid Loss:  185.40618896484375
Epoch:  2  	Training Loss: 182.0388946533203
Test Loss:  8413.259765625
Valid Loss:  8298.1025390625
Epoch:  3  	Training Loss: 8164.83203125
Test Loss:  86.01222229003906
Valid Loss:  84.678466796875
Epoch:  4  	Training Loss: 83.10743713378906
Test Loss:  14.770221710205078
Valid Loss:  14.505430221557617
Epoch:  5  	Training Loss: 14.175602912902832
Test Loss:  2.5736238956451416
Valid Loss:  2.5137157440185547
Epoch:  6  	Training Loss: 2.4318366050720215
Test Loss:  0.4379209280014038
Valid Loss:  0.4233687222003937
Epoch:  7  	Training Loss: 0.39948755502700806
Test Loss:  0.07956770062446594
Valid Loss:  0.0764847993850708
Epoch:  8  	Training Loss: 0.06822051852941513
Test Loss:  0.018402209505438805
Valid Loss:  0.018762191757559776
Epoch:  9  	Training Loss: 0.015429787337779999
Test Loss:  0.007045664358884096
Valid Loss:  0.00856691598892212
Epoch:  10  	Training Loss: 0.006968441419303417
Test Loss:  0.004535946995019913
Valid Loss:  0.006458843592554331
Epoch:  11  	Training Loss: 0.005500003229826689
Test Loss:  0.003818335011601448
Valid Loss:  0.005866213236004114
Epoch:  12  	Training Loss: 0.005144000053405762
Test Loss:  0.003549605840817094
Valid Loss:  0.005617464892566204
Epoch:  13  	Training Loss: 0.004977370612323284
Test Loss:  0.003418888431042433
Valid Loss:  0.005468608811497688
Epoch:  14  	Training Loss: 0.004852938465774059
Test Loss:  0.003340532537549734
Valid Loss:  0.005359357222914696
Epoch:  15  	Training Loss: 0.0047468142583966255
Test Loss:  0.003285788930952549
Valid Loss:  0.0052706715650856495
Epoch:  16  	Training Loss: 0.004653899930417538
Test Loss:  0.0032436749897897243
Valid Loss:  0.005195198580622673
Epoch:  17  	Training Loss: 0.004572131671011448
Test Loss:  0.0032095578499138355
Valid Loss:  0.005129585973918438
Epoch:  18  	Training Loss: 0.0045001208782196045
Test Loss:  0.0031812540255486965
Valid Loss:  0.005071963183581829
Epoch:  19  	Training Loss: 0.0044366843067109585
Test Loss:  0.0031575094908475876
Valid Loss:  0.005021143704652786
Epoch:  20  	Training Loss: 0.0043807970359921455
Test Loss:  0.003137621097266674
Valid Loss:  0.004976241383701563
Epoch:  21  	Training Loss: 0.004331568721681833
Test Loss:  0.0031209567096084356
Valid Loss:  0.004936521872878075
Epoch:  22  	Training Loss: 0.004288202151656151
Test Loss:  0.003101141657680273
Valid Loss:  0.004897987004369497
Epoch:  23  	Training Loss: 0.004249945282936096
Test Loss:  0.003087736200541258
Valid Loss:  0.004865751601755619
Epoch:  24  	Training Loss: 0.0042162565514445305
Test Loss:  0.003077915869653225
Valid Loss:  0.004837943706661463
Epoch:  25  	Training Loss: 0.004186582285910845
Test Loss:  0.003070385195314884
Valid Loss:  0.0048135509714484215
Epoch:  26  	Training Loss: 0.004160436801612377
Test Loss:  0.003064571414142847
Valid Loss:  0.004792052786797285
Epoch:  27  	Training Loss: 0.0041374098509550095
Test Loss:  0.0030601287726312876
Valid Loss:  0.004773053340613842
Epoch:  28  	Training Loss: 0.004117127507925034
Test Loss:  0.0030567855574190617
Valid Loss:  0.004756208509206772
Epoch:  29  	Training Loss: 0.004099260084331036
Test Loss:  0.003054384607821703
Valid Loss:  0.004741286858916283
Epoch:  30  	Training Loss: 0.004083528183400631
Test Loss:  0.0030527617782354355
Valid Loss:  0.004728041589260101
Epoch:  31  	Training Loss: 0.00406967056915164
Test Loss:  0.0030517959967255592
Valid Loss:  0.004716285038739443
Epoch:  32  	Training Loss: 0.004057461395859718
Test Loss:  0.0030532930977642536
Valid Loss:  0.004706902429461479
Epoch:  33  	Training Loss: 0.0040466976352036
Test Loss:  0.003053952008485794
Valid Loss:  0.004697971045970917
Epoch:  34  	Training Loss: 0.0040372274816036224
Test Loss:  0.0030544933397322893
Valid Loss:  0.004689792171120644
Epoch:  35  	Training Loss: 0.0040288823656737804
Test Loss:  0.0030551522504538298
Valid Loss:  0.004682428669184446
Epoch:  36  	Training Loss: 0.004021536558866501
Test Loss:  0.003056003013625741
Valid Loss:  0.004675834905356169
Epoch:  37  	Training Loss: 0.004015061073005199
Test Loss:  0.003057014662772417
Valid Loss:  0.004669946152716875
Epoch:  38  	Training Loss: 0.004009362310171127
Test Loss:  0.0030582062900066376
Valid Loss:  0.004664696287363768
Epoch:  39  	Training Loss: 0.004004339687526226
Test Loss:  0.003059518290683627
Valid Loss:  0.004660007078200579
Epoch:  40  	Training Loss: 0.003999915439635515
Test Loss:  0.0030609280802309513
Valid Loss:  0.004655824974179268
Epoch:  41  	Training Loss: 0.00399602297693491
Test Loss:  0.0030623911879956722
Valid Loss:  0.004652084782719612
Epoch:  42  	Training Loss: 0.003992591518908739
Test Loss:  0.003063004929572344
Valid Loss:  0.004648266825824976
Epoch:  43  	Training Loss: 0.003989580553025007
Test Loss:  0.003064229618757963
Valid Loss:  0.0046451156958937645
Epoch:  44  	Training Loss: 0.003986923955380917
Test Loss:  0.0030657106544822454
Valid Loss:  0.0046424102038145065
Epoch:  45  	Training Loss: 0.003984587267041206
Test Loss:  0.0030672671273350716
Valid Loss:  0.0046400208957493305
Epoch:  46  	Training Loss: 0.0039825234562158585
Test Loss:  0.0030688585247844458
Valid Loss:  0.0046379053965210915
Epoch:  47  	Training Loss: 0.003980705514550209
Test Loss:  0.0030704373493790627
Valid Loss:  0.004636018071323633
Epoch:  48  	Training Loss: 0.003979106433689594
Test Loss:  0.003071976127102971
Valid Loss:  0.004634313751012087
Epoch:  49  	Training Loss: 0.003977695479989052
Test Loss:  0.003073486965149641
Valid Loss:  0.004632793832570314
Epoch:  50  	Training Loss: 0.003976450301706791
Test Loss:  0.003074956126511097
Valid Loss:  0.00463142478838563
Epoch:  51  	Training Loss: 0.003975355997681618
Test Loss:  0.003076387569308281
Valid Loss:  0.004630199167877436
Epoch:  52  	Training Loss: 0.003974391613155603
Test Loss:  0.0030788618605583906
Valid Loss:  0.004629683680832386
Epoch:  53  	Training Loss: 0.003973538987338543
Test Loss:  0.003080514492467046
Valid Loss:  0.004628857132047415
Epoch:  54  	Training Loss: 0.003972786478698254
Test Loss:  0.003081835573539138
Valid Loss:  0.004627984948456287
Epoch:  55  	Training Loss: 0.003972123377025127
Test Loss:  0.0030830218456685543
Valid Loss:  0.0046271467581391335
Epoch:  56  	Training Loss: 0.003971542697399855
Test Loss:  0.0030841310508549213
Valid Loss:  0.004626379813998938
Epoch:  57  	Training Loss: 0.003971030004322529
Test Loss:  0.0030851673800498247
Valid Loss:  0.004625661298632622
Epoch:  58  	Training Loss: 0.0039705755189061165
Test Loss:  0.0030861664563417435
Valid Loss:  0.004625020548701286
Epoch:  59  	Training Loss: 0.003970177844166756
Test Loss:  0.003087105229496956
Valid Loss:  0.004624428227543831
Epoch:  60  	Training Loss: 0.003969824872910976
Test Loss:  0.0030880053527653217
Valid Loss:  0.004623893182724714
Epoch:  61  	Training Loss: 0.00396951287984848
Test Loss:  0.003088862868025899
Valid Loss:  0.004623403772711754
Epoch:  62  	Training Loss: 0.003969241864979267
Test Loss:  0.003089657984673977
Valid Loss:  0.004622945096343756
Epoch:  63  	Training Loss: 0.003969002980738878
Test Loss:  0.0030904319137334824
Valid Loss:  0.0046225376427173615
Epoch:  64  	Training Loss: 0.003968789242208004
Test Loss:  0.003091174177825451
Valid Loss:  0.004622167907655239
Epoch:  65  	Training Loss: 0.003968602512031794
Test Loss:  0.003091867547482252
Valid Loss:  0.004621834959834814
Epoch:  66  	Training Loss: 0.003968438133597374
Test Loss:  0.003092530183494091
Valid Loss:  0.00462152436375618
Epoch:  67  	Training Loss: 0.003968291915953159
Test Loss:  0.0030931634828448296
Valid Loss:  0.0046212393790483475
Epoch:  68  	Training Loss: 0.003968164324760437
Test Loss:  0.003093764651566744
Valid Loss:  0.004620982334017754
Epoch:  69  	Training Loss: 0.003968053497374058
Test Loss:  0.003094324842095375
Valid Loss:  0.0046207415871322155
Epoch:  70  	Training Loss: 0.00396795105189085
Test Loss:  0.0030948584899306297
Valid Loss:  0.00462052458897233
Epoch:  71  	Training Loss: 0.003967864904552698
Test Loss:  0.0030953651294112206
Valid Loss:   14%|█▍        | 71/500 [00:53<08:17,  1.16s/it] 15%|█▍        | 73/500 [00:53<05:55,  1.20it/s] 15%|█▌        | 75/500 [00:53<04:16,  1.66it/s] 15%|█▌        | 77/500 [00:53<03:06,  2.26it/s] 16%|█▌        | 79/500 [00:53<02:18,  3.04it/s] 16%|█▌        | 81/500 [01:00<08:13,  1.18s/it] 17%|█▋        | 83/500 [01:00<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:00<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:00<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:00<02:16,  3.00it/s] 18%|█▊        | 91/500 [01:06<07:56,  1.16s/it] 19%|█▊        | 93/500 [01:07<05:39,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:04,  1.66it/s] 19%|█▉        | 97/500 [01:07<02:58,  2.26it/s] 20%|█▉        | 99/500 [01:07<02:11,  3.04it/s] 20%|██        | 101/500 [01:13<07:47,  1.17s/it] 21%|██        | 103/500 [01:13<05:34,  1.19it/s] 21%|██        | 105/500 [01:14<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:14<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:26<13:29,  2.08s/it] 23%|██▎       | 113/500 [01:26<09:32,  1.48s/it] 23%|██▎       | 115/500 [01:26<06:46,  1.05s/it] 23%|██▎       | 117/500 [01:27<04:50,  1.32it/s] 24%|██▍       | 119/500 [01:27<03:29,  1.82it/s] 24%|██▍       | 121/500 [01:39<14:09,  2.24s/it] 25%|██▍       | 123/500 [01:39<09:59,  1.59s/it] 25%|██▌       | 125/500 [01:45<12:47,  2.05s/it] 25%|██▌       | 127/500 [01:46<09:01,  1.45s/it] 26%|██▌       | 129/500 [01:46<06:24,  1.04s/it] 26%|██▌       | 131/500 [01:52<10:13,  1.66s/it] 27%|██▋       | 133/500 [01:52<07:15,  1.19s/it] 27%|██▋       | 135/500 [01:58<10:42,  1.76s/it]0.004620319232344627
Epoch:  72  	Training Loss: 0.003967789933085442
Test Loss:  0.0030953323002904654
Valid Loss:  0.004619857296347618
Epoch:  73  	Training Loss: 0.0039677186869084835
Test Loss:  0.0030955844558775425
Valid Loss:  0.004619593732059002
Epoch:  74  	Training Loss: 0.003967661876231432
Test Loss:  0.0030959725845605135
Valid Loss:  0.004619409330189228
Epoch:  75  	Training Loss: 0.003967611119151115
Test Loss:  0.0030963756144046783
Valid Loss:  0.004619268700480461
Epoch:  76  	Training Loss: 0.003967566415667534
Test Loss:  0.0030967816710472107
Valid Loss:  0.004619148559868336
Epoch:  77  	Training Loss: 0.003967526368796825
Test Loss:  0.003097186330705881
Valid Loss:  0.004619054030627012
Epoch:  78  	Training Loss: 0.003967490047216415
Test Loss:  0.003097555600106716
Valid Loss:  0.004618965554982424
Epoch:  79  	Training Loss: 0.003967462107539177
Test Loss:  0.003097902052104473
Valid Loss:  0.004618865437805653
Epoch:  80  	Training Loss: 0.003967429976910353
Test Loss:  0.0030982419848442078
Valid Loss:  0.004618796519935131
Epoch:  81  	Training Loss: 0.003967407159507275
Test Loss:  0.0030985563062131405
Valid Loss:  0.004618721082806587
Epoch:  82  	Training Loss: 0.003967382945120335
Test Loss:  0.003099071327596903
Valid Loss:  0.004618773236870766
Epoch:  83  	Training Loss: 0.0039673675782978535
Test Loss:  0.0030994275584816933
Valid Loss:  0.004618755541741848
Epoch:  84  	Training Loss: 0.003967350348830223
Test Loss:  0.0030997165013104677
Valid Loss:  0.004618709906935692
Epoch:  85  	Training Loss: 0.003967332653701305
Test Loss:  0.0030999546870589256
Valid Loss:  0.004618656821548939
Epoch:  86  	Training Loss: 0.003967323340475559
Test Loss:  0.0031001754105091095
Valid Loss:  0.004618598148226738
Epoch:  87  	Training Loss: 0.003967309836298227
Test Loss:  0.003100375644862652
Valid Loss:  0.004618538543581963
Epoch:  88  	Training Loss: 0.0039672995917499065
Test Loss:  0.0031005607452243567
Valid Loss:  0.004618490114808083
Epoch:  89  	Training Loss: 0.003967287950217724
Test Loss:  0.0031007411889731884
Valid Loss:  0.004618436563760042
Epoch:  90  	Training Loss: 0.0039672828279435635
Test Loss:  0.0031009134836494923
Valid Loss:  0.004618395119905472
Epoch:  91  	Training Loss: 0.003967272583395243
Test Loss:  0.00310106435790658
Valid Loss:  0.0046183522790670395
Epoch:  92  	Training Loss: 0.003967269789427519
Test Loss:  0.0031012152321636677
Valid Loss:  0.00461831409484148
Epoch:  93  	Training Loss: 0.003967263735830784
Test Loss:  0.0031013544648885727
Valid Loss:  0.00461828475818038
Epoch:  94  	Training Loss: 0.003967258147895336
Test Loss:  0.003101489506661892
Valid Loss:  0.004618252161890268
Epoch:  95  	Training Loss: 0.003967255353927612
Test Loss:  0.0031016103457659483
Valid Loss:  0.004618222825229168
Epoch:  96  	Training Loss: 0.003967250697314739
Test Loss:  0.0031017293222248554
Valid Loss:  0.004618194419890642
Epoch:  97  	Training Loss: 0.00396724883466959
Test Loss:  0.0031018282752484083
Valid Loss:  0.0046181571669876575
Epoch:  98  	Training Loss: 0.003967245575040579
Test Loss:  0.003101927926763892
Valid Loss:  0.004618133418262005
Epoch:  99  	Training Loss: 0.003967242315411568
Test Loss:  0.0031020273454487324
Valid Loss:  0.00461810827255249
Epoch:  100  	Training Loss: 0.003967238590121269
Test Loss:  0.003102115821093321
Valid Loss:  0.00461808405816555
Epoch:  101  	Training Loss: 0.00396723672747612
Test Loss:  0.0031022056937217712
Valid Loss:  0.004618068691343069
Epoch:  102  	Training Loss: 0.003967235796153545
Test Loss:  0.003102283226326108
Valid Loss:  0.004618043079972267
Epoch:  103  	Training Loss: 0.0039672343991696835
Test Loss:  0.0031023479532450438
Valid Loss:  0.0046180235221982
Epoch:  104  	Training Loss: 0.003967235796153545
Test Loss:  0.0031024201307445765
Valid Loss:  0.004618010018020868
Epoch:  105  	Training Loss: 0.003967233467847109
Test Loss:  0.0031024771742522717
Valid Loss:  0.004617993254214525
Epoch:  106  	Training Loss: 0.003967228811234236
Test Loss:  0.003102546324953437
Valid Loss:  0.004617979284375906
Epoch:  107  	Training Loss: 0.003967232536524534
Test Loss:  0.0031026089563965797
Valid Loss:  0.004617971368134022
Epoch:  108  	Training Loss: 0.003967232070863247
Test Loss:  0.003102656453847885
Valid Loss:  0.004617956001311541
Epoch:  109  	Training Loss: 0.0039672283455729485
Test Loss:  0.0031027086079120636
Valid Loss:  0.0046179452911019325
Epoch:  110  	Training Loss: 0.003967228811234236
Test Loss:  0.0031027591321617365
Valid Loss:  0.00461792666465044
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.003967226482927799
Test Loss:  0.0031027644872665405
Valid Loss:  0.004617919214069843
Epoch:  112  	Training Loss: 0.003967228811234236
Test Loss:  0.003102787071838975
Valid Loss:  0.004617912694811821
Epoch:  113  	Training Loss: 0.003967227414250374
Test Loss:  0.0031028115190565586
Valid Loss:  0.004617909900844097
Epoch:  114  	Training Loss: 0.003967227414250374
Test Loss:  0.0031028350349515676
Valid Loss:  0.004617906175553799
Epoch:  115  	Training Loss: 0.003967225551605225
Test Loss:  0.003102850168943405
Valid Loss:  0.004617901518940926
Epoch:  116  	Training Loss: 0.003967229276895523
Test Loss:  0.003102873917669058
Valid Loss:  0.0046178922057151794
Epoch:  117  	Training Loss: 0.0039672283455729485
Test Loss:  0.003102896735072136
Valid Loss:  0.004617893137037754
Epoch:  118  	Training Loss: 0.003967226482927799
Test Loss:  0.003102918155491352
Valid Loss:  0.004617887549102306
Epoch:  119  	Training Loss: 0.00396722462028265
Test Loss:  0.0031029300298541784
Valid Loss:  0.004617880564182997
Epoch:  120  	Training Loss: 0.003967225551605225
Test Loss:  0.0031029442325234413
Valid Loss:  0.004617879167199135
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.0039672269485890865
Test Loss:  0.0031029628589749336
Valid Loss:  0.004617874510586262
Epoch:  122  	Training Loss: 0.003967226017266512
Test Loss:  0.0031029751989990473
Valid Loss:  0.0046178861521184444
Epoch:  123  	Training Loss: 0.003967227879911661
Test Loss:  0.003102993592619896
Valid Loss:  0.004617875441908836
Epoch:  124  	Training Loss: 0.003967225551605225
Test Loss:  0.00310300150886178
Valid Loss:  0.0046178800985217094
Epoch:  125  	Training Loss: 0.003967227414250374
Test Loss:  0.0031030087266117334
Valid Loss:  0.004617877304553986
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.00396722462028265
Test Loss:  0.0031030126847326756
Valid Loss:  0.004617879167199135
Epoch:  127  	Training Loss: 0.003967227414250374
Test Loss:  0.00310301105491817
Valid Loss:  0.004617879167199135
Epoch:  128  	Training Loss: 0.003967227414250374
Test Loss:  0.003103011753410101
Valid Loss:  0.004617879632860422
Epoch:  129  	Training Loss: 0.003967225551605225
Test Loss:  0.003103015711531043
Valid Loss:  0.004617875441908836
Epoch:  130  	Training Loss: 0.003967223688960075
Test Loss:  0.003103022463619709
Valid Loss:  0.004617871716618538
Epoch:  131  	Training Loss: 0.003967223688960075
Test Loss:  0.003103025024756789
Valid Loss:  0.004617870785295963
Epoch:  132  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030315440148115
Valid Loss:  0.0046178726479411125
Epoch:  133  	Training Loss: 0.00396722462028265
Test Loss:  0.0031030329409986734
Valid Loss:  0.004617877770215273
Epoch:  134  	Training Loss: 0.003967226482927799
Test Loss:  0.00310303526930511
Valid Loss:  0.004617875907570124
Epoch:  135  	Training Loss: 0.003967225551605225
Test Loss:  0.003103038528934121
Valid Loss:  0.004617873579263687
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030485406517982
Valid Loss:  0.0046178731136024
Epoch:  137  	Training Loss: 0.0039672269485890865
Test Loss:   27%|██▋       | 137/500 [01:58<07:34,  1.25s/it] 28%|██▊       | 139/500 [01:59<05:23,  1.12it/s] 28%|██▊       | 141/500 [02:11<14:50,  2.48s/it] 29%|██▊       | 143/500 [02:11<10:26,  1.76s/it] 29%|██▉       | 145/500 [02:17<12:52,  2.18s/it] 29%|██▉       | 147/500 [02:17<09:06,  1.55s/it] 30%|██▉       | 149/500 [02:18<06:29,  1.11s/it] 30%|███       | 151/500 [02:30<15:34,  2.68s/it] 31%|███       | 153/500 [02:30<10:57,  1.89s/it] 31%|███       | 155/500 [02:37<13:02,  2.27s/it] 31%|███▏      | 157/500 [02:37<09:11,  1.61s/it] 32%|███▏      | 159/500 [02:37<06:30,  1.15s/it] 32%|███▏      | 161/500 [02:49<14:52,  2.63s/it] 33%|███▎      | 163/500 [02:49<10:27,  1.86s/it] 33%|███▎      | 165/500 [02:56<12:28,  2.23s/it] 33%|███▎      | 167/500 [02:56<08:47,  1.58s/it] 34%|███▍      | 169/500 [02:56<06:13,  1.13s/it] 34%|███▍      | 171/500 [03:08<14:26,  2.63s/it] 35%|███▍      | 173/500 [03:08<10:09,  1.86s/it] 35%|███▌      | 175/500 [03:15<12:11,  2.25s/it] 35%|███▌      | 177/500 [03:15<08:35,  1.60s/it] 36%|███▌      | 179/500 [03:15<06:04,  1.14s/it] 36%|███▌      | 181/500 [03:27<14:05,  2.65s/it] 37%|███▋      | 183/500 [03:27<09:55,  1.88s/it] 37%|███▋      | 185/500 [03:34<11:48,  2.25s/it] 37%|███▋      | 187/500 [03:34<08:19,  1.60s/it] 38%|███▊      | 189/500 [03:34<05:53,  1.14s/it] 38%|███▊      | 191/500 [03:46<13:31,  2.63s/it] 39%|███▊      | 193/500 [03:46<09:31,  1.86s/it]0.003103051334619522
Valid Loss:  0.004617872182279825
Epoch:  138  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030583195388317
Valid Loss:  0.004617871716618538
Epoch:  139  	Training Loss: 0.003967225551605225
Test Loss:  0.003103063441812992
Valid Loss:  0.004617881029844284
Epoch:  140  	Training Loss: 0.00396722462028265
Test Loss:  0.003103067632764578
Valid Loss:  0.004617881961166859
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.00396722462028265
Test Loss:  0.003103062976151705
Valid Loss:  0.004617879167199135
Epoch:  142  	Training Loss: 0.003967225085943937
Test Loss:  0.0031030585523694754
Valid Loss:  0.0046178800985217094
Epoch:  143  	Training Loss: 0.003967224154621363
Test Loss:  0.0031030522659420967
Valid Loss:  0.004617871716618538
Epoch:  144  	Training Loss: 0.00396722462028265
Test Loss:  0.003103045281022787
Valid Loss:  0.004617868922650814
Epoch:  145  	Training Loss: 0.003967224154621363
Test Loss:  0.003103039227426052
Valid Loss:  0.004617873579263687
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.00396722462028265
Test Loss:  0.0031030382961034775
Valid Loss:  0.004617868922650814
Epoch:  147  	Training Loss: 0.00396722462028265
Test Loss:  0.0031030364334583282
Valid Loss:  0.004617870785295963
Epoch:  148  	Training Loss: 0.003967226017266512
Test Loss:  0.003103032009676099
Valid Loss:  0.004617867060005665
Epoch:  149  	Training Loss: 0.003967227414250374
Test Loss:  0.003103031078353524
Valid Loss:  0.004617864266037941
Epoch:  150  	Training Loss: 0.003967226482927799
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  152  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  153  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  154  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  155  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  157  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  158  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  159  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  160  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  162  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  163  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  164  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  165  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  167  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  168  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  169  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  170  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  172  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  173  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  174  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  175  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  177  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  178  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  179  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  180  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  182  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  183  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  184  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  185  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  187  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  188  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  189  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  190  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  192  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  193  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  194  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  195  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:   39%|███▉      | 195/500 [03:52<11:20,  2.23s/it] 39%|███▉      | 197/500 [03:53<07:59,  1.58s/it] 40%|███▉      | 199/500 [03:53<05:39,  1.13s/it] 40%|████      | 201/500 [04:05<13:08,  2.64s/it] 41%|████      | 203/500 [04:05<09:14,  1.87s/it] 41%|████      | 205/500 [04:11<10:56,  2.23s/it] 41%|████▏     | 207/500 [04:11<07:42,  1.58s/it] 42%|████▏     | 209/500 [04:12<05:27,  1.13s/it] 42%|████▏     | 209/500 [04:22<05:27,  1.13s/it] 42%|████▏     | 211/500 [04:24<12:38,  2.62s/it] 43%|████▎     | 213/500 [04:24<08:53,  1.86s/it] 43%|████▎     | 215/500 [04:30<10:38,  2.24s/it] 43%|████▎     | 217/500 [04:30<07:30,  1.59s/it] 44%|████▍     | 219/500 [04:30<05:19,  1.14s/it] 44%|████▍     | 219/500 [04:42<05:19,  1.14s/it] 44%|████▍     | 221/500 [04:43<12:23,  2.67s/it] 45%|████▍     | 223/500 [04:43<08:43,  1.89s/it] 45%|████▌     | 225/500 [04:49<10:21,  2.26s/it] 45%|████▌     | 227/500 [04:49<07:17,  1.60s/it] 46%|████▌     | 229/500 [04:50<05:09,  1.14s/it] 46%|████▌     | 229/500 [05:02<05:09,  1.14s/it] 46%|████▌     | 231/500 [05:02<11:51,  2.65s/it] 47%|████▋     | 233/500 [05:02<08:20,  1.87s/it] 47%|████▋     | 235/500 [05:08<09:55,  2.25s/it] 47%|████▋     | 237/500 [05:08<06:58,  1.59s/it] 48%|████▊     | 239/500 [05:09<04:56,  1.13s/it] 48%|████▊     | 241/500 [05:21<11:22,  2.64s/it] 49%|████▊     | 243/500 [05:21<07:59,  1.87s/it] 49%|████▉     | 245/500 [05:27<09:28,  2.23s/it] 49%|████▉     | 247/500 [05:27<06:40,  1.58s/it] 50%|████▉     | 249/500 [05:27<04:43,  1.13s/it] 50%|█████     | 251/500 [05:40<10:57,  2.64s/it]0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  197  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  198  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  199  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  200  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  202  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  203  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  204  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  205  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  207  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  208  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  209  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  210  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.004617861472070217
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  212  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  213  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  214  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  215  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  217  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  218  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  219  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  220  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  222  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  223  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  224  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  225  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  227  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  228  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  229  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  230  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  232  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  233  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  234  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  235  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  237  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  238  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  239  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  240  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  242  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  243  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  244  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  245  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  247  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  248  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  249  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  250  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  252  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
 51%|█████     | 253/500 [05:40<07:41,  1.87s/it] 51%|█████     | 255/500 [05:46<09:13,  2.26s/it] 51%|█████▏    | 257/500 [05:46<06:30,  1.60s/it] 52%|█████▏    | 259/500 [05:47<04:35,  1.14s/it] 52%|█████▏    | 261/500 [05:59<10:27,  2.63s/it] 53%|█████▎    | 263/500 [05:59<07:21,  1.86s/it] 53%|█████▎    | 265/500 [06:05<08:44,  2.23s/it] 53%|█████▎    | 267/500 [06:05<06:08,  1.58s/it] 54%|█████▍    | 269/500 [06:05<04:20,  1.13s/it] 54%|█████▍    | 271/500 [06:18<10:03,  2.64s/it] 55%|█████▍    | 273/500 [06:18<07:03,  1.87s/it] 55%|█████▌    | 275/500 [06:24<08:24,  2.24s/it] 55%|█████▌    | 277/500 [06:24<05:54,  1.59s/it] 56%|█████▌    | 279/500 [06:24<04:10,  1.13s/it] 56%|█████▌    | 281/500 [06:37<09:39,  2.65s/it] 57%|█████▋    | 283/500 [06:37<06:46,  1.87s/it] 57%|█████▋    | 285/500 [06:43<08:01,  2.24s/it] 57%|█████▋    | 287/500 [06:43<05:38,  1.59s/it] 58%|█████▊    | 289/500 [06:43<03:59,  1.13s/it] 58%|█████▊    | 291/500 [06:56<09:12,  2.64s/it] 59%|█████▊    | 293/500 [06:56<06:27,  1.87s/it] 59%|█████▉    | 295/500 [07:02<07:37,  2.23s/it] 59%|█████▉    | 297/500 [07:02<05:21,  1.58s/it] 60%|█████▉    | 299/500 [07:02<03:46,  1.13s/it] 60%|██████    | 301/500 [07:14<08:41,  2.62s/it] 61%|██████    | 303/500 [07:14<06:05,  1.86s/it] 61%|██████    | 305/500 [07:21<07:14,  2.23s/it] 61%|██████▏   | 307/500 [07:21<05:05,  1.58s/it] 62%|██████▏   | 309/500 [07:21<03:35,  1.13s/it]Epoch:  253  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  254  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  255  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  257  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  258  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  259  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  260  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  262  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  263  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  264  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  265  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  267  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  268  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  269  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  270  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  272  	Training Loss: 0.003967225085943937
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  273  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  274  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  275  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  277  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  278  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  279  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  280  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  282  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  283  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  284  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  285  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  287  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  288  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  289  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  290  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  292  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  293  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  294  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  295  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  297  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  298  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  299  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  300  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  302  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  303  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  304  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  305  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  307  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  308  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  309  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  310  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
 62%|██████▏   | 309/500 [07:32<03:35,  1.13s/it] 62%|██████▏   | 311/500 [07:33<08:18,  2.64s/it] 63%|██████▎   | 313/500 [07:33<05:49,  1.87s/it] 63%|██████▎   | 315/500 [07:40<06:54,  2.24s/it] 63%|██████▎   | 317/500 [07:40<04:51,  1.59s/it] 64%|██████▍   | 319/500 [07:40<03:25,  1.13s/it] 64%|██████▍   | 319/500 [07:52<03:25,  1.13s/it] 64%|██████▍   | 321/500 [07:52<07:51,  2.64s/it] 65%|██████▍   | 323/500 [07:52<05:30,  1.87s/it] 65%|██████▌   | 325/500 [07:59<06:31,  2.24s/it] 65%|██████▌   | 327/500 [07:59<04:34,  1.59s/it] 66%|██████▌   | 329/500 [07:59<03:13,  1.13s/it] 66%|██████▌   | 331/500 [08:11<07:24,  2.63s/it] 67%|██████▋   | 333/500 [08:11<05:11,  1.86s/it] 67%|██████▋   | 335/500 [08:17<06:10,  2.25s/it] 67%|██████▋   | 337/500 [08:18<04:19,  1.59s/it] 68%|██████▊   | 339/500 [08:18<03:02,  1.13s/it] 68%|██████▊   | 341/500 [08:30<06:58,  2.63s/it] 69%|██████▊   | 343/500 [08:30<04:52,  1.86s/it] 69%|██████▉   | 345/500 [08:36<05:46,  2.24s/it] 69%|██████▉   | 347/500 [08:37<04:02,  1.59s/it] 70%|██████▉   | 349/500 [08:37<02:50,  1.13s/it] 70%|███████   | 351/500 [08:49<06:31,  2.63s/it] 71%|███████   | 353/500 [08:49<04:33,  1.86s/it] 71%|███████   | 355/500 [08:55<05:24,  2.24s/it] 71%|███████▏  | 357/500 [08:55<03:46,  1.59s/it] 72%|███████▏  | 359/500 [08:56<02:39,  1.13s/it] 72%|███████▏  | 361/500 [09:08<06:07,  2.64s/it] 73%|███████▎  | 363/500 [09:08<04:16,  1.87s/it] 73%|███████▎  | 365/500 [09:14<05:03,  2.25s/it] 73%|███████▎  | 367/500 [09:14<03:32,  1.60s/it]**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  312  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  313  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  314  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  315  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  317  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  318  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  319  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  320  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  322  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  323  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  324  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  325  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  327  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  328  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  329  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  330  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  332  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  333  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  334  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  335  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  337  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  338  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  339  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  340  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  342  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  343  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.004617861472070217
Epoch:  344  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  345  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  347  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.004617861472070217
Epoch:  348  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  349  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  350  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  352  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  353  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  354  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  355  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  357  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  358  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  359  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  360  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  362  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  363  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  364  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  365  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  367  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
 74%|███████▍  | 369/500 [09:15<02:29,  1.14s/it] 74%|███████▍  | 371/500 [09:27<05:40,  2.64s/it] 75%|███████▍  | 373/500 [09:27<03:57,  1.87s/it] 75%|███████▌  | 375/500 [09:33<04:42,  2.26s/it] 75%|███████▌  | 377/500 [09:33<03:16,  1.60s/it] 76%|███████▌  | 379/500 [09:34<02:18,  1.14s/it] 76%|███████▌  | 381/500 [09:46<05:13,  2.63s/it] 77%|███████▋  | 383/500 [09:46<03:38,  1.86s/it] 77%|███████▋  | 385/500 [09:52<04:20,  2.27s/it] 77%|███████▋  | 387/500 [09:53<03:01,  1.61s/it] 78%|███████▊  | 389/500 [09:53<02:07,  1.15s/it] 78%|███████▊  | 391/500 [10:05<04:50,  2.66s/it] 79%|███████▊  | 393/500 [10:05<03:21,  1.89s/it] 79%|███████▉  | 395/500 [10:11<03:55,  2.24s/it] 79%|███████▉  | 397/500 [10:12<02:43,  1.59s/it] 80%|███████▉  | 399/500 [10:12<01:54,  1.13s/it] 80%|███████▉  | 399/500 [10:22<01:54,  1.13s/it] 80%|████████  | 401/500 [10:24<04:24,  2.67s/it] 81%|████████  | 403/500 [10:24<03:03,  1.89s/it] 81%|████████  | 405/500 [10:30<03:33,  2.25s/it] 81%|████████▏ | 407/500 [10:31<02:28,  1.60s/it] 82%|████████▏ | 409/500 [10:31<01:43,  1.14s/it] 82%|████████▏ | 409/500 [10:42<01:43,  1.14s/it] 82%|████████▏ | 411/500 [10:43<03:53,  2.63s/it] 83%|████████▎ | 413/500 [10:43<02:42,  1.86s/it] 83%|████████▎ | 415/500 [10:49<03:10,  2.24s/it] 83%|████████▎ | 417/500 [10:50<02:11,  1.59s/it] 84%|████████▍ | 419/500 [10:50<01:31,  1.13s/it] 84%|████████▍ | 421/500 [11:02<03:27,  2.63s/it] 85%|████████▍ | 423/500 [11:02<02:23,  1.86s/it]Epoch:  368  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  369  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  370  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  372  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  373  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  374  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  375  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  377  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  378  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  379  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  380  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  382  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  383  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  384  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  385  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.004617861472070217
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  387  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  388  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  389  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  390  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  392  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  393  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  394  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  395  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  397  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  398  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  399  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  400  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  402  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  403  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  404  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.004617861472070217
Epoch:  405  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  407  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  408  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  409  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  410  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  412  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  413  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  414  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  415  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  417  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  418  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  419  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  420  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  422  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  423  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  424  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  425  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
 85%|████████▌ | 425/500 [11:08<02:48,  2.24s/it] 85%|████████▌ | 427/500 [11:08<01:56,  1.59s/it] 86%|████████▌ | 429/500 [11:09<01:20,  1.13s/it] 86%|████████▌ | 431/500 [11:21<03:01,  2.63s/it] 87%|████████▋ | 433/500 [11:21<02:04,  1.86s/it] 87%|████████▋ | 435/500 [11:27<02:24,  2.23s/it] 87%|████████▋ | 437/500 [11:27<01:39,  1.58s/it] 88%|████████▊ | 439/500 [11:27<01:08,  1.13s/it] 88%|████████▊ | 441/500 [11:40<02:35,  2.64s/it] 89%|████████▊ | 443/500 [11:40<01:46,  1.87s/it] 89%|████████▉ | 445/500 [11:46<02:02,  2.23s/it] 89%|████████▉ | 447/500 [11:46<01:23,  1.58s/it] 90%|████████▉ | 449/500 [11:46<00:57,  1.13s/it] 90%|█████████ | 451/500 [11:58<02:08,  2.61s/it] 91%|█████████ | 453/500 [11:59<01:26,  1.85s/it] 91%|█████████ | 455/500 [12:05<01:40,  2.22s/it] 91%|█████████▏| 457/500 [12:05<01:07,  1.58s/it] 92%|█████████▏| 459/500 [12:05<00:46,  1.12s/it] 92%|█████████▏| 461/500 [12:17<01:42,  2.63s/it] 93%|█████████▎| 463/500 [12:17<01:08,  1.86s/it] 93%|█████████▎| 465/500 [12:24<01:18,  2.24s/it] 93%|█████████▎| 467/500 [12:24<00:52,  1.59s/it] 94%|█████████▍| 469/500 [12:24<00:35,  1.13s/it] 94%|█████████▍| 471/500 [12:36<01:16,  2.63s/it] 95%|█████████▍| 473/500 [12:36<00:50,  1.86s/it] 95%|█████████▌| 475/500 [12:43<00:56,  2.24s/it] 95%|█████████▌| 477/500 [12:43<00:36,  1.59s/it] 96%|█████████▌| 479/500 [12:43<00:23,  1.13s/it] 96%|█████████▌| 481/500 [12:55<00:50,  2.65s/it]**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  427  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  428  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  429  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  430  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  432  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  433  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  434  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  435  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  437  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  438  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  439  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  440  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  442  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  443  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
Epoch:  444  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  445  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  447  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  448  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  449  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  450  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  452  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  453  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  454  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  455  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  457  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  458  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  459  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  460  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  462  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  463  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  464  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  465  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  467  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  468  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  469  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  470  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  472  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  473  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  474  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  475  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  477  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  478  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  479  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  480  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  482  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
 97%|█████████▋| 483/500 [12:55<00:31,  1.88s/it] 97%|█████████▋| 485/500 [13:02<00:34,  2.27s/it] 97%|█████████▋| 487/500 [13:02<00:20,  1.61s/it] 98%|█████████▊| 489/500 [13:02<00:12,  1.15s/it] 98%|█████████▊| 489/500 [13:12<00:12,  1.15s/it] 98%|█████████▊| 491/500 [13:14<00:23,  2.66s/it] 99%|█████████▊| 493/500 [13:15<00:13,  1.88s/it] 99%|█████████▉| 495/500 [13:21<00:11,  2.27s/it] 99%|█████████▉| 497/500 [13:21<00:04,  1.61s/it]100%|█████████▉| 499/500 [13:21<00:01,  1.15s/it]100%|██████████| 500/500 [13:27<00:00,  1.62s/it]
Epoch:  483  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  484  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  485  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  487  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  488  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  489  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  490  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
Epoch:  492  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  493  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.00461786100640893
Epoch:  494  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  495  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.0046178605407476425
Epoch:  497  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  498  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030280515551567
Valid Loss:  0.00461786100640893
Epoch:  499  	Training Loss: 0.003967225551605225
Test Loss:  0.003103028517216444
Valid Loss:  0.00461786100640893
Epoch:  500  	Training Loss: 0.003967225551605225
Test Loss:  0.0031030282843858004
Valid Loss:  0.0046178605407476425
**************************************************learning rate decay**************************************************
seed is  13
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:50,  6.23s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.93it/s]  2%|▏         | 9/500 [00:06<02:52,  2.85it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:20<09:43,  1.22s/it]  5%|▍         | 23/500 [00:20<06:54,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:40,  2.93it/s]  6%|▌         | 31/500 [00:27<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:39,  1.17it/s]  7%|▋         | 35/500 [00:33<11:57,  1.54s/it]  7%|▋         | 37/500 [00:33<08:29,  1.10s/it]  8%|▊         | 39/500 [00:33<06:04,  1.27it/s]  8%|▊         | 41/500 [00:39<11:23,  1.49s/it]  9%|▊         | 43/500 [00:40<08:06,  1.06s/it]  9%|▉         | 45/500 [00:40<05:48,  1.31it/s]  9%|▉         | 47/500 [00:40<04:11,  1.80it/s] 10%|▉         | 49/500 [00:40<03:04,  2.45it/s] 10%|█         | 51/500 [00:52<16:04,  2.15s/it] 11%|█         | 53/500 [00:53<11:21,  1.52s/it] 11%|█         | 55/500 [00:53<08:03,  1.09s/it] 11%|█▏        | 57/500 [00:53<05:46,  1.28it/s] 12%|█▏        | 59/500 [00:53<04:09,  1.77it/s] 12%|█▏        | 61/500 [00:59<09:50,  1.35s/it] 13%|█▎        | 63/500 [00:59<07:01,  1.04it/s] 13%|█▎        | 65/500 [01:00<05:02,  1.44it/s] 13%|█▎        | 67/500 [01:00<03:39,  1.97it/s] 14%|█▍        | 69/500 [01:00<02:41,  2.67it/s] 14%|█▍        | 71/500 [01:06<08:43,  1.22s/it]Epoch:  1  	Training Loss: 0.05115431919693947
Test Loss:  14.818037033081055
Valid Loss:  14.936091423034668
Epoch:  2  	Training Loss: 14.721381187438965
Test Loss:  4951.5625
Valid Loss:  4878.50390625
Epoch:  3  	Training Loss: 4805.3115234375
Test Loss:  37.422428131103516
Valid Loss:  40.01853942871094
Epoch:  4  	Training Loss: 40.37376403808594
Test Loss:  0.5369858145713806
Valid Loss:  0.6583273410797119
Epoch:  5  	Training Loss: 0.7459473609924316
Test Loss:  0.26569437980651855
Valid Loss:  0.31827425956726074
Epoch:  6  	Training Loss: 0.37949496507644653
Test Loss:  0.26996761560440063
Valid Loss:  0.31712543964385986
Epoch:  7  	Training Loss: 0.37561458349227905
Test Loss:  0.27075421810150146
Valid Loss:  0.3173671364784241
Epoch:  8  	Training Loss: 0.3755730390548706
Test Loss:  0.2708389163017273
Valid Loss:  0.3173949122428894
Epoch:  9  	Training Loss: 0.37557148933410645
Test Loss:  0.27084729075431824
Valid Loss:  0.31739670038223267
Epoch:  10  	Training Loss: 0.37557023763656616
Test Loss:  0.2708476781845093
Valid Loss:  0.31739571690559387
Epoch:  11  	Training Loss: 0.3755689859390259
Test Loss:  0.2708472013473511
Valid Loss:  0.3173944652080536
Epoch:  12  	Training Loss: 0.375567764043808
Test Loss:  0.2590676546096802
Valid Loss:  0.25875329971313477
Epoch:  13  	Training Loss: 0.24003919959068298
Test Loss:  0.774395763874054
Valid Loss:  0.7815039753913879
Epoch:  14  	Training Loss: 0.8071488738059998
Test Loss:  0.260427862405777
Valid Loss:  0.3201194107532501
Epoch:  15  	Training Loss: 0.38290542364120483
Test Loss:  0.2567342519760132
Valid Loss:  0.3091263771057129
Epoch:  16  	Training Loss: 0.368243932723999
Test Loss:  0.25830408930778503
Valid Loss:  0.30764180421829224
Epoch:  17  	Training Loss: 0.365162193775177
Test Loss:  0.25953200459480286
Valid Loss:  0.3075349032878876
Epoch:  18  	Training Loss: 0.36431053280830383
Test Loss:  0.26009953022003174
Valid Loss:  0.30751943588256836
Epoch:  19  	Training Loss: 0.36397039890289307
Test Loss:  0.26030635833740234
Valid Loss:  0.30746209621429443
Epoch:  20  	Training Loss: 0.3637735843658447
Test Loss:  0.2603677809238434
Valid Loss:  0.3073933720588684
Epoch:  21  	Training Loss: 0.36362820863723755
Test Loss:  0.2603536546230316
Valid Loss:  0.30733543634414673
Epoch:  22  	Training Loss: 0.3635224401950836
Test Loss:  2.6702404022216797
Valid Loss:  2.69620680809021
Epoch:  23  	Training Loss: 2.614759922027588
Test Loss:  0.38774797320365906
Valid Loss:  0.391251802444458
Epoch:  24  	Training Loss: 0.3489151895046234
Test Loss:  0.34662365913391113
Valid Loss:  0.36398911476135254
Epoch:  25  	Training Loss: 0.3087388873100281
Test Loss:  0.30957651138305664
Valid Loss:  0.3265858292579651
Epoch:  26  	Training Loss: 0.2777618169784546
Test Loss:  0.2869933247566223
Valid Loss:  0.30159732699394226
Epoch:  27  	Training Loss: 0.2630700469017029
Test Loss:  0.27545857429504395
Valid Loss:  0.2830946147441864
Epoch:  28  	Training Loss: 0.2533170282840729
Test Loss:  0.2700975835323334
Valid Loss:  0.26610833406448364
Epoch:  29  	Training Loss: 0.24683718383312225
Test Loss:  0.2673545479774475
Valid Loss:  0.25711703300476074
Epoch:  30  	Training Loss: 0.24382060766220093
Test Loss:  0.264576256275177
Valid Loss:  0.25127747654914856
Epoch:  31  	Training Loss: 0.24159279465675354
Test Loss:  0.2621539235115051
Valid Loss:  0.24782177805900574
Epoch:  32  	Training Loss: 0.24073314666748047
Test Loss:  1.0457446575164795
Valid Loss:  1.1256921291351318
Epoch:  33  	Training Loss: 1.2245283126831055
Test Loss:  0.27232640981674194
Valid Loss:  0.3032889664173126
Epoch:  34  	Training Loss: 0.3608936071395874
Test Loss:  0.271562397480011
Valid Loss:  0.3022649586200714
Epoch:  35  	Training Loss: 0.3595770299434662
Test Loss:  0.27037161588668823
Valid Loss:  0.30082830786705017
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.3577699065208435
Test Loss:  0.23417489230632782
Valid Loss:  0.25138068199157715
Epoch:  37  	Training Loss: 0.2919917106628418
Test Loss:  0.2228747010231018
Valid Loss:  0.23102492094039917
Epoch:  38  	Training Loss: 0.26035425066947937
Test Loss:  0.22021327912807465
Valid Loss:  0.2197754979133606
Epoch:  39  	Training Loss: 0.24023734033107758
Test Loss:  0.21357113122940063
Valid Loss:  0.20165225863456726
Epoch:  40  	Training Loss: 0.2167614996433258
Test Loss:  0.18528394401073456
Valid Loss:  0.17557206749916077
Epoch:  41  	Training Loss: 0.17616933584213257
Test Loss:  0.12976334989070892
Valid Loss:  0.13223519921302795
Epoch:  42  	Training Loss: 0.12823590636253357
Test Loss:  0.09746325016021729
Valid Loss:  0.10635524243116379
Epoch:  43  	Training Loss: 0.1012498140335083
Test Loss:  0.08871404081583023
Valid Loss:  0.10204798728227615
Epoch:  44  	Training Loss: 0.08868344128131866
Test Loss:  0.059346795082092285
Valid Loss:  0.0765836164355278
Epoch:  45  	Training Loss: 0.07973938435316086
Test Loss:  0.09303860366344452
Valid Loss:  0.1130521297454834
Epoch:  46  	Training Loss: 0.08362551033496857
Test Loss:  0.0630248486995697
Valid Loss:  0.08079886436462402
Epoch:  47  	Training Loss: 0.0954524576663971
Test Loss:  0.11936473846435547
Valid Loss:  0.1409730762243271
Epoch:  48  	Training Loss: 0.10256864130496979
Test Loss:  0.1021576076745987
Valid Loss:  0.11680136620998383
Epoch:  49  	Training Loss: 0.14250913262367249
Test Loss:  0.15891382098197937
Valid Loss:  0.1891964077949524
Epoch:  50  	Training Loss: 0.13574787974357605
Test Loss:  0.058766186237335205
Valid Loss:  0.07538747787475586
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.059821873903274536
Test Loss:  0.039128199219703674
Valid Loss:  0.055075425654649734
Epoch:  52  	Training Loss: 0.054689109325408936
Test Loss:  0.03674846142530441
Valid Loss:  0.05471501871943474
Epoch:  53  	Training Loss: 0.04542122781276703
Test Loss:  0.0300779826939106
Valid Loss:  0.04721749573945999
Epoch:  54  	Training Loss: 0.040844328701496124
Test Loss:  0.0294631514698267
Valid Loss:  0.04707132279872894
Epoch:  55  	Training Loss: 0.03793492913246155
Test Loss:  0.027692127972841263
Valid Loss:  0.044686902314424515
Epoch:  56  	Training Loss: 0.03602159768342972
Test Loss:  0.027058299630880356
Valid Loss:  0.0436517596244812
Epoch:  57  	Training Loss: 0.034541357308626175
Test Loss:  0.026291195303201675
Valid Loss:  0.042376790195703506
Epoch:  58  	Training Loss: 0.033419169485569
Test Loss:  0.025914032012224197
Valid Loss:  0.04172671213746071
Epoch:  59  	Training Loss: 0.03243878111243248
Test Loss:  0.025260822847485542
Valid Loss:  0.040531691163778305
Epoch:  60  	Training Loss: 0.031541306525468826
Test Loss:  0.025227181613445282
Valid Loss:  0.04028124362230301
Epoch:  61  	Training Loss: 0.03070860542356968
Test Loss:  0.024566298350691795
Valid Loss:  0.039081476628780365
Epoch:  62  	Training Loss: 0.030012257397174835
Test Loss:  0.023669365793466568
Valid Loss:  0.03741982579231262
Epoch:  63  	Training Loss: 0.029466506093740463
Test Loss:  0.02331170067191124
Valid Loss:  0.036512263119220734
Epoch:  64  	Training Loss: 0.029261048883199692
Test Loss:  0.02323554828763008
Valid Loss:  0.03630742430686951
Epoch:  65  	Training Loss: 0.029055848717689514
Test Loss:  0.023080945014953613
Valid Loss:  0.03593464940786362
Epoch:  66  	Training Loss: 0.0286826454102993
Test Loss:  0.022758573293685913
Valid Loss:  0.035330213606357574
Epoch:  67  	Training Loss: 0.028085272759199142
Test Loss:  0.022146642208099365
Valid Loss:  0.03426830470561981
Epoch:  68  	Training Loss: 0.027092233300209045
Test Loss:  0.021318409591913223
Valid Loss:  0.033258892595767975
Epoch:  69  	Training Loss: 0.025990232825279236
Test Loss:  0.020477311685681343
Valid Loss:  0.0323091521859169
Epoch:  70  	Training Loss: 0.024944324046373367
Test Loss:  0.01971246674656868
Valid Loss:  0.031496819108724594
Epoch:  71  	Training Loss: 0.024127621203660965
Test Loss:  0.019216440618038177
Valid Loss:  0.031023969873785973
 15%|█▍        | 73/500 [01:06<06:13,  1.14it/s] 15%|█▌        | 75/500 [01:07<04:28,  1.58it/s] 15%|█▌        | 77/500 [01:07<03:15,  2.16it/s] 16%|█▌        | 79/500 [01:07<02:24,  2.91it/s] 16%|█▌        | 81/500 [01:13<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:13<05:57,  1.17it/s] 17%|█▋        | 85/500 [01:13<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:14<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:14<02:20,  2.93it/s] 18%|█▊        | 91/500 [01:20<08:09,  1.20s/it] 19%|█▊        | 93/500 [01:20<05:49,  1.16it/s] 19%|█▉        | 95/500 [01:20<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:20<03:03,  2.20it/s] 20%|█▉        | 99/500 [01:21<02:17,  2.91it/s] 20%|██        | 101/500 [01:27<07:58,  1.20s/it] 21%|██        | 103/500 [01:27<05:44,  1.15it/s] 21%|██        | 105/500 [01:27<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:28<03:01,  2.17it/s] 22%|██▏       | 109/500 [01:28<02:14,  2.91it/s] 22%|██▏       | 111/500 [01:34<07:49,  1.21s/it] 23%|██▎       | 113/500 [01:34<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:34<04:04,  1.58it/s] 23%|██▎       | 117/500 [01:35<02:57,  2.16it/s] 24%|██▍       | 119/500 [01:35<02:11,  2.90it/s] 24%|██▍       | 121/500 [01:41<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:41<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:41<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:41<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:42<02:04,  2.99it/s] 26%|██▌       | 131/500 [01:48<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:48<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:54<09:29,  1.56s/it] 27%|██▋       | 137/500 [01:55<06:44,  1.11s/it] 28%|██▊       | 139/500 [01:55<04:49,  1.25it/s]Epoch:  72  	Training Loss: 0.02356896735727787
Test Loss:  0.019278675317764282
Valid Loss:  0.03115640953183174
Epoch:  73  	Training Loss: 0.02335467003285885
Test Loss:  0.019286837428808212
Valid Loss:  0.031183118000626564
Epoch:  74  	Training Loss: 0.023174723610281944
Test Loss:  0.019310221076011658
Valid Loss:  0.031237736344337463
Epoch:  75  	Training Loss: 0.023023584857583046
Test Loss:  0.01929517090320587
Valid Loss:  0.03125365823507309
Epoch:  76  	Training Loss: 0.022887658327817917
Test Loss:  0.01925887167453766
Valid Loss:  0.031248578801751137
Epoch:  77  	Training Loss: 0.022761818021535873
Test Loss:  0.01921284757554531
Valid Loss:  0.031229127198457718
Epoch:  78  	Training Loss: 0.022644422948360443
Test Loss:  0.019161414355039597
Valid Loss:  0.03120315633714199
Epoch:  79  	Training Loss: 0.0225349273532629
Test Loss:  0.019113952293992043
Valid Loss:  0.031154070049524307
Epoch:  80  	Training Loss: 0.02242061123251915
Test Loss:  0.019078072160482407
Valid Loss:  0.031096477061510086
Epoch:  81  	Training Loss: 0.022292109206318855
Test Loss:  0.019047332927584648
Valid Loss:  0.03105415403842926
Epoch:  82  	Training Loss: 0.02218020334839821
Test Loss:  0.018566016107797623
Valid Loss:  0.030375590547919273
Epoch:  83  	Training Loss: 0.021603306755423546
Test Loss:  0.018254920840263367
Valid Loss:  0.029894374310970306
Epoch:  84  	Training Loss: 0.02114708349108696
Test Loss:  0.01803687959909439
Valid Loss:  0.029485734179615974
Epoch:  85  	Training Loss: 0.020776957273483276
Test Loss:  0.01787509210407734
Valid Loss:  0.02915760688483715
Epoch:  86  	Training Loss: 0.020459923893213272
Test Loss:  0.017702139914035797
Valid Loss:  0.028887737542390823
Epoch:  87  	Training Loss: 0.02017548307776451
Test Loss:  0.017547760158777237
Valid Loss:  0.028618592768907547
Epoch:  88  	Training Loss: 0.019933493807911873
Test Loss:  0.017413822934031487
Valid Loss:  0.02836010418832302
Epoch:  89  	Training Loss: 0.019724208861589432
Test Loss:  0.017295436933636665
Valid Loss:  0.02812832221388817
Epoch:  90  	Training Loss: 0.019540168344974518
Test Loss:  0.01718873158097267
Valid Loss:  0.02790854312479496
Epoch:  91  	Training Loss: 0.019375745207071304
Test Loss:  0.017090730369091034
Valid Loss:  0.027675848454236984
Epoch:  92  	Training Loss: 0.019226614385843277
Test Loss:  0.016463015228509903
Valid Loss:  0.026455234736204147
Epoch:  93  	Training Loss: 0.018586086109280586
Test Loss:  0.015359010547399521
Valid Loss:  0.024911191314458847
Epoch:  94  	Training Loss: 0.018108677119016647
Test Loss:  0.015159019269049168
Valid Loss:  0.024318190291523933
Epoch:  95  	Training Loss: 0.017964694648981094
Test Loss:  0.014898382127285004
Valid Loss:  0.02406972274184227
Epoch:  96  	Training Loss: 0.017762165516614914
Test Loss:  0.015045934356749058
Valid Loss:  0.023973805829882622
Epoch:  97  	Training Loss: 0.017653871327638626
Test Loss:  0.014674574136734009
Valid Loss:  0.023710284382104874
Epoch:  98  	Training Loss: 0.01754395291209221
Test Loss:  0.015189014375209808
Valid Loss:  0.023820729926228523
Epoch:  99  	Training Loss: 0.017433831468224525
Test Loss:  0.014318821020424366
Valid Loss:  0.02329411916434765
Epoch:  100  	Training Loss: 0.017173798754811287
Test Loss:  0.014605538919568062
Valid Loss:  0.02286245860159397
Epoch:  101  	Training Loss: 0.01706290990114212
Test Loss:  0.014469927176833153
Valid Loss:  0.023548100143671036
Epoch:  102  	Training Loss: 0.016999024897813797
Test Loss:  0.014672594144940376
Valid Loss:  0.02366844192147255
Epoch:  103  	Training Loss: 0.016819391399621964
Test Loss:  0.014235885813832283
Valid Loss:  0.0230662003159523
Epoch:  104  	Training Loss: 0.016623342409729958
Test Loss:  0.014382928609848022
Valid Loss:  0.023088356480002403
Epoch:  105  	Training Loss: 0.01642628014087677
Test Loss:  0.013966880738735199
Valid Loss:  0.022544238716363907
Epoch:  106  	Training Loss: 0.016248255968093872
Test Loss:  0.014078603126108646
Valid Loss:  0.02252628654241562
Epoch:  107  	Training Loss: 0.016072813421487808
Test Loss:  0.013726724311709404
Valid Loss:  0.022052180022001266
Epoch:  108  	Training Loss: 0.015904132276773453
Test Loss:  0.013712290674448013
Valid Loss:  0.02193070948123932
Epoch:  109  	Training Loss: 0.01573571376502514
Test Loss:  0.013570062816143036
Valid Loss:  0.021687135100364685
Epoch:  110  	Training Loss: 0.015577731654047966
Test Loss:  0.013431400991976261
Valid Loss:  0.02146964892745018
Epoch:  111  	Training Loss: 0.015426729805767536
Test Loss:  0.013293759897351265
Valid Loss:  0.021255701780319214
Epoch:  112  	Training Loss: 0.01528147328644991
Test Loss:  0.01335784699767828
Valid Loss:  0.021272599697113037
Epoch:  113  	Training Loss: 0.015206561423838139
Test Loss:  0.013385375961661339
Valid Loss:  0.021244339644908905
Epoch:  114  	Training Loss: 0.015152201056480408
Test Loss:  0.013382169418036938
Valid Loss:  0.02119872346520424
Epoch:  115  	Training Loss: 0.01510506309568882
Test Loss:  0.013366181403398514
Valid Loss:  0.021147875115275383
Epoch:  116  	Training Loss: 0.015060018748044968
Test Loss:  0.013341586105525494
Valid Loss:  0.021093502640724182
Epoch:  117  	Training Loss: 0.015016061253845692
Test Loss:  0.013312038034200668
Valid Loss:  0.021036189049482346
Epoch:  118  	Training Loss: 0.014972815290093422
Test Loss:  0.013284464366734028
Valid Loss:  0.02098211646080017
Epoch:  119  	Training Loss: 0.01492998842149973
Test Loss:  0.013253195211291313
Valid Loss:  0.02092645689845085
Epoch:  120  	Training Loss: 0.014887481927871704
Test Loss:  0.013219580054283142
Valid Loss:  0.020869825035333633
Epoch:  121  	Training Loss: 0.014845253899693489
Test Loss:  0.013190224766731262
Valid Loss:  0.020817534998059273
Epoch:  122  	Training Loss: 0.014803312718868256
Test Loss:  0.013150284998118877
Valid Loss:  0.019892463460564613
Epoch:  123  	Training Loss: 0.014602269046008587
Test Loss:  0.012564820237457752
Valid Loss:  0.019855352118611336
Epoch:  124  	Training Loss: 0.014540866017341614
Test Loss:  0.012479517608880997
Valid Loss:  0.019598037004470825
Epoch:  125  	Training Loss: 0.014492964372038841
Test Loss:  0.01232464425265789
Valid Loss:  0.0195452980697155
Epoch:  126  	Training Loss: 0.014455817639827728
Test Loss:  0.01231116522103548
Valid Loss:  0.01940865069627762
Epoch:  127  	Training Loss: 0.014423210173845291
Test Loss:  0.012210899032652378
Valid Loss:  0.01938871666789055
Epoch:  128  	Training Loss: 0.014397329650819302
Test Loss:  0.012385178357362747
Valid Loss:  0.019219931215047836
Epoch:  129  	Training Loss: 0.014383438974618912
Test Loss:  0.01197703555226326
Valid Loss:  0.019495535641908646
Epoch:  130  	Training Loss: 0.014396351762115955
Test Loss:  0.012655291706323624
Valid Loss:  0.019009042531251907
Epoch:  131  	Training Loss: 0.014425604604184628
Test Loss:  0.011854312382638454
Valid Loss:  0.019668232649564743
Epoch:  132  	Training Loss: 0.014457662589848042
Test Loss:  0.011853877454996109
Valid Loss:  0.01907750777900219
Epoch:  133  	Training Loss: 0.014173631556332111
Test Loss:  0.01193436048924923
Valid Loss:  0.01877986639738083
Epoch:  134  	Training Loss: 0.013997502624988556
Test Loss:  0.012020384892821312
Valid Loss:  0.018578439950942993
Epoch:  135  	Training Loss: 0.013867368921637535
Test Loss:  0.012090306729078293
Valid Loss:  0.01841973513364792
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.01376131922006607
Test Loss:  0.01209950726479292
Valid Loss:  0.018344081938266754
Epoch:  137  	Training Loss: 0.013754731975495815
Test Loss:  0.012105380184948444
Valid Loss:  0.018306054174900055
Epoch:  138  	Training Loss: 0.0137523477897048
Test Loss:  0.012108507566154003
Valid Loss:  0.018286440521478653
Epoch:  139  	Training Loss: 0.013751097023487091
Test Loss:  0.012109927833080292
Valid Loss:  0.018276022747159004
Epoch:  140  	Training Loss: 0.01375015638768673
Test Loss:  0.012110413983464241
Valid Loss:  0.018270311877131462
Epoch:  141  	Training Loss: 0.013749325647950172
Test Loss:  0.012110412120819092
 28%|██▊       | 141/500 [02:01<09:07,  1.53s/it] 29%|██▊       | 143/500 [02:01<06:28,  1.09s/it] 29%|██▉       | 145/500 [02:01<04:37,  1.28it/s] 29%|██▉       | 147/500 [02:02<03:20,  1.76it/s] 30%|██▉       | 149/500 [02:02<02:26,  2.40it/s] 30%|███       | 151/500 [02:08<07:10,  1.23s/it] 31%|███       | 153/500 [02:08<05:06,  1.13it/s] 31%|███       | 155/500 [02:08<03:40,  1.57it/s] 31%|███▏      | 157/500 [02:08<02:39,  2.15it/s] 32%|███▏      | 159/500 [02:09<01:57,  2.89it/s] 32%|███▏      | 161/500 [02:15<06:44,  1.19s/it] 33%|███▎      | 163/500 [02:15<04:50,  1.16it/s] 33%|███▎      | 165/500 [02:15<03:30,  1.59it/s] 33%|███▎      | 167/500 [02:15<02:35,  2.15it/s] 34%|███▍      | 169/500 [02:16<01:56,  2.85it/s] 34%|███▍      | 171/500 [02:22<06:26,  1.18s/it] 35%|███▍      | 173/500 [02:22<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:22<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:22<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:22<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:29<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:29<04:29,  1.17it/s] 37%|███▋      | 185/500 [02:29<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:29<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:29<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:36<06:06,  1.18s/it] 39%|███▊      | 193/500 [02:36<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:36<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:36<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:36<01:40,  3.00it/s] 40%|████      | 201/500 [02:42<05:48,  1.17s/it] 41%|████      | 203/500 [02:42<04:08,  1.20it/s] 41%|████      | 205/500 [02:43<02:58,  1.66it/s] 41%|████▏     | 207/500 [02:43<02:09,  2.26it/s] 42%|████▏     | 209/500 [02:43<01:35,  3.04it/s] 42%|████▏     | 211/500 [02:49<05:37,  1.17s/it]Valid Loss:  0.018267033621668816
Epoch:  142  	Training Loss: 0.01374854613095522
Test Loss:  0.011783520691096783
Valid Loss:  0.01815766468644142
Epoch:  143  	Training Loss: 0.013548188842833042
Test Loss:  0.011540916748344898
Valid Loss:  0.01797044277191162
Epoch:  144  	Training Loss: 0.013392183929681778
Test Loss:  0.011348990723490715
Valid Loss:  0.017779285088181496
Epoch:  145  	Training Loss: 0.013259248808026314
Test Loss:  0.011193182319402695
Valid Loss:  0.01760159432888031
Epoch:  146  	Training Loss: 0.013141687959432602
Test Loss:  0.011063158512115479
Valid Loss:  0.01743617281317711
Epoch:  147  	Training Loss: 0.013034231960773468
Test Loss:  0.010960917919874191
Valid Loss:  0.017277827486395836
Epoch:  148  	Training Loss: 0.012941783294081688
Test Loss:  0.010875675827264786
Valid Loss:  0.01713261753320694
Epoch:  149  	Training Loss: 0.01285567320883274
Test Loss:  0.010794073343276978
Valid Loss:  0.016999222338199615
Epoch:  150  	Training Loss: 0.012769796885550022
Test Loss:  0.010726694017648697
Valid Loss:  0.016877245157957077
Epoch:  151  	Training Loss: 0.012690066359937191
Test Loss:  0.010670117102563381
Valid Loss:  0.01677165925502777
Epoch:  152  	Training Loss: 0.012615231797099113
Test Loss:  0.01069234311580658
Valid Loss:  0.01678408682346344
Epoch:  153  	Training Loss: 0.012607790529727936
Test Loss:  0.01071052998304367
Valid Loss:  0.016794482246041298
Epoch:  154  	Training Loss: 0.012602568604052067
Test Loss:  0.010726073756814003
Valid Loss:  0.016803905367851257
Epoch:  155  	Training Loss: 0.012598419561982155
Test Loss:  0.010739214718341827
Valid Loss:  0.01681186445057392
Epoch:  156  	Training Loss: 0.012595112435519695
Test Loss:  0.010750100016593933
Valid Loss:  0.016817793250083923
Epoch:  157  	Training Loss: 0.01259232871234417
Test Loss:  0.01075997855514288
Valid Loss:  0.01682295836508274
Epoch:  158  	Training Loss: 0.012589888647198677
Test Loss:  0.010766847990453243
Valid Loss:  0.016825174912810326
Epoch:  159  	Training Loss: 0.012587781064212322
Test Loss:  0.01077302172780037
Valid Loss:  0.01682700216770172
Epoch:  160  	Training Loss: 0.012585833668708801
Test Loss:  0.010778602212667465
Valid Loss:  0.01682845875620842
Epoch:  161  	Training Loss: 0.012584013864398003
Test Loss:  0.010783636942505836
Valid Loss:  0.01682957448065281
Epoch:  162  	Training Loss: 0.0125823263078928
Test Loss:  0.010935356840491295
Valid Loss:  0.01663871854543686
Epoch:  163  	Training Loss: 0.01252383179962635
Test Loss:  0.010832106694579124
Valid Loss:  0.016661709174513817
Epoch:  164  	Training Loss: 0.012476431205868721
Test Loss:  0.010812158696353436
Valid Loss:  0.016604285687208176
Epoch:  165  	Training Loss: 0.012430618517100811
Test Loss:  0.010791328735649586
Valid Loss:  0.01655341312289238
Epoch:  166  	Training Loss: 0.01238600816577673
Test Loss:  0.010766791179776192
Valid Loss:  0.01650693267583847
Epoch:  167  	Training Loss: 0.012342487461864948
Test Loss:  0.010742971673607826
Valid Loss:  0.016462579369544983
Epoch:  168  	Training Loss: 0.01229987945407629
Test Loss:  0.010720617137849331
Valid Loss:  0.01642034575343132
Epoch:  169  	Training Loss: 0.012258164584636688
Test Loss:  0.010698240250349045
Valid Loss:  0.016380006447434425
Epoch:  170  	Training Loss: 0.012217248789966106
Test Loss:  0.010676750913262367
Valid Loss:  0.016340861096978188
Epoch:  171  	Training Loss: 0.01217716559767723
Test Loss:  0.010655270889401436
Valid Loss:  0.016303203999996185
Epoch:  172  	Training Loss: 0.012137921527028084
Test Loss:  0.01069625373929739
Valid Loss:  0.016282832249999046
Epoch:  173  	Training Loss: 0.012096220627427101
Test Loss:  0.01072169654071331
Valid Loss:  0.01626800000667572
Epoch:  174  	Training Loss: 0.01206295844167471
Test Loss:  0.010754257440567017
Valid Loss:  0.016251031309366226
Epoch:  175  	Training Loss: 0.012036003172397614
Test Loss:  0.010777218267321587
Valid Loss:  0.016236426308751106
Epoch:  176  	Training Loss: 0.012013891711831093
Test Loss:  0.010802490636706352
Valid Loss:  0.016221148893237114
Epoch:  177  	Training Loss: 0.01199549250304699
Test Loss:  0.010822116397321224
Valid Loss:  0.016206668689846992
Epoch:  178  	Training Loss: 0.011979885399341583
Test Loss:  0.010841505602002144
Valid Loss:  0.016191376373171806
Epoch:  179  	Training Loss: 0.011964554898440838
Test Loss:  0.010860385373234749
Valid Loss:  0.01617409661412239
Epoch:  180  	Training Loss: 0.011948725208640099
Test Loss:  0.01087777130305767
Valid Loss:  0.01615581288933754
Epoch:  181  	Training Loss: 0.011934641748666763
Test Loss:  0.01089218445122242
Valid Loss:  0.01613759435713291
Epoch:  182  	Training Loss: 0.011921940371394157
Test Loss:  0.010871689766645432
Valid Loss:  0.016107354313135147
Epoch:  183  	Training Loss: 0.011919157579541206
Test Loss:  0.010856405831873417
Valid Loss:  0.016084766015410423
Epoch:  184  	Training Loss: 0.011917386204004288
Test Loss:  0.010844897478818893
Valid Loss:  0.016067806631326675
Epoch:  185  	Training Loss: 0.011916203424334526
Test Loss:  0.010836169123649597
Valid Loss:  0.016054805368185043
Epoch:  186  	Training Loss: 0.011915372684597969
Test Loss:  0.010829519480466843
Valid Loss:  0.01604473777115345
Epoch:  187  	Training Loss: 0.011914747767150402
Test Loss:  0.010824453085660934
Valid Loss:  0.016037093475461006
Epoch:  188  	Training Loss: 0.011914249509572983
Test Loss:  0.010820578783750534
Valid Loss:  0.01603127457201481
Epoch:  189  	Training Loss: 0.011913817375898361
Test Loss:  0.010817586444318295
Valid Loss:  0.01602683588862419
Epoch:  190  	Training Loss: 0.011913456954061985
Test Loss:  0.010815267451107502
Valid Loss:  0.016023438423871994
Epoch:  191  	Training Loss: 0.011913120746612549
Test Loss:  0.010813453234732151
Valid Loss:  0.016020826995372772
Epoch:  192  	Training Loss: 0.011912800371646881
Test Loss:  0.010791819542646408
Valid Loss:  0.016063395887613297
Epoch:  193  	Training Loss: 0.011896196752786636
Test Loss:  0.01076878048479557
Valid Loss:  0.016093801707029343
Epoch:  194  	Training Loss: 0.011883378960192204
Test Loss:  0.010746289044618607
Valid Loss:  0.016115201637148857
Epoch:  195  	Training Loss: 0.011872907169163227
Test Loss:  0.010723497718572617
Valid Loss:  0.016130711883306503
Epoch:  196  	Training Loss: 0.011863834224641323
Test Loss:  0.010700966231524944
Valid Loss:  0.016142114996910095
Epoch:  197  	Training Loss: 0.011855819262564182
Test Loss:  0.010679097846150398
Valid Loss:  0.016150662675499916
Epoch:  198  	Training Loss: 0.011848710477352142
Test Loss:  0.010658134706318378
Valid Loss:  0.016157284379005432
Epoch:  199  	Training Loss: 0.011842349544167519
Test Loss:  0.010638254694640636
Valid Loss:  0.016162436455488205
Epoch:  200  	Training Loss: 0.011836672201752663
Test Loss:  0.010619578883051872
Valid Loss:  0.01616692543029785
Epoch:  201  	Training Loss: 0.011831503361463547
Test Loss:  0.010602167807519436
Valid Loss:  0.016170956194400787
Epoch:  202  	Training Loss: 0.01182645559310913
Test Loss:  0.01057879813015461
Valid Loss:  0.015994910150766373
Epoch:  203  	Training Loss: 0.011768107302486897
Test Loss:  0.010576682165265083
Valid Loss:  0.015925370156764984
Epoch:  204  	Training Loss: 0.011725406162440777
Test Loss:  0.010578231886029243
Valid Loss:  0.015891607850790024
Epoch:  205  	Training Loss: 0.01168762892484665
Test Loss:  0.010580447502434254
Valid Loss:  0.015870945528149605
Epoch:  206  	Training Loss: 0.011652937158942223
Test Loss:  0.010582337155938148
Valid Loss:  0.015855776146054268
Epoch:  207  	Training Loss: 0.011620909906923771
Test Loss:  0.010583815164864063
Valid Loss:  0.015843261033296585
Epoch:  208  	Training Loss: 0.011591263115406036
Test Loss:  0.01058470644056797
Valid Loss:  0.01583249680697918
Epoch:  209  	Training Loss: 0.011563540436327457
Test Loss:  0.010585165582597256
Valid Loss:  0.01582062989473343
Epoch:  210  	Training Loss: 0.011536041274666786
Test Loss:  0.010585309937596321
Valid Loss:  0.01581125520169735
Epoch:  211  	Training Loss: 0.011509559117257595
Test Loss:  0.010585080832242966
Valid Loss:  0.015803419053554535
 43%|████▎     | 213/500 [02:49<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:49<02:53,  1.65it/s] 43%|████▎     | 217/500 [02:49<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:50<01:32,  3.02it/s] 44%|████▍     | 221/500 [02:56<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:56<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:56<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:56<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:56<01:30,  2.98it/s] 46%|████▌     | 231/500 [03:03<05:17,  1.18s/it] 47%|████▋     | 233/500 [03:03<03:46,  1.18it/s] 47%|████▋     | 235/500 [03:03<02:42,  1.63it/s] 47%|████▋     | 237/500 [03:03<01:57,  2.23it/s] 48%|████▊     | 239/500 [03:03<01:27,  2.98it/s] 48%|████▊     | 241/500 [03:10<05:02,  1.17s/it] 49%|████▊     | 243/500 [03:10<03:35,  1.19it/s] 49%|████▉     | 245/500 [03:10<02:34,  1.65it/s] 49%|████▉     | 247/500 [03:10<01:52,  2.25it/s] 50%|████▉     | 249/500 [03:10<01:23,  3.02it/s] 50%|█████     | 251/500 [03:16<04:52,  1.17s/it] 51%|█████     | 253/500 [03:16<03:28,  1.18it/s] 51%|█████     | 255/500 [03:17<02:29,  1.64it/s] 51%|█████▏    | 257/500 [03:17<01:48,  2.24it/s] 52%|█████▏    | 259/500 [03:17<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:23<04:37,  1.16s/it] 53%|█████▎    | 263/500 [03:23<03:18,  1.20it/s] 53%|█████▎    | 265/500 [03:23<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:24<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:24<01:19,  2.91it/s] 54%|█████▍    | 271/500 [03:30<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:30<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:30<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:31<01:41,  2.21it/s] 56%|█████▌    | 279/500 [03:31<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:37<04:24,  1.21s/it]Epoch:  212  	Training Loss: 0.011483563110232353
Test Loss:  0.010492049157619476
Valid Loss:  0.01576259545981884
Epoch:  213  	Training Loss: 0.0114107271656394
Test Loss:  0.01043703407049179
Valid Loss:  0.015734422951936722
Epoch:  214  	Training Loss: 0.011363804340362549
Test Loss:  0.010410608723759651
Valid Loss:  0.015721898525953293
Epoch:  215  	Training Loss: 0.011334702372550964
Test Loss:  0.01039745844900608
Valid Loss:  0.015713561326265335
Epoch:  216  	Training Loss: 0.01131418440490961
Test Loss:  0.010397890582680702
Valid Loss:  0.015699462965130806
Epoch:  217  	Training Loss: 0.011299493722617626
Test Loss:  0.0104047367349267
Valid Loss:  0.015684816986322403
Epoch:  218  	Training Loss: 0.011287601664662361
Test Loss:  0.010412536561489105
Valid Loss:  0.015670888125896454
Epoch:  219  	Training Loss: 0.011277280747890472
Test Loss:  0.01042090356349945
Valid Loss:  0.015657640993595123
Epoch:  220  	Training Loss: 0.011268245987594128
Test Loss:  0.010429475456476212
Valid Loss:  0.01564493589103222
Epoch:  221  	Training Loss: 0.011260240338742733
Test Loss:  0.010438041761517525
Valid Loss:  0.01563272997736931
Epoch:  222  	Training Loss: 0.011253082193434238
Test Loss:  0.010253248736262321
Valid Loss:  0.015109032392501831
Epoch:  223  	Training Loss: 0.011127427220344543
Test Loss:  0.010224634781479836
Valid Loss:  0.014999881386756897
Epoch:  224  	Training Loss: 0.011112561449408531
Test Loss:  0.010216085240244865
Valid Loss:  0.014968648552894592
Epoch:  225  	Training Loss: 0.011105568148195744
Test Loss:  0.010211985558271408
Valid Loss:  0.014954816550016403
Epoch:  226  	Training Loss: 0.011099861934781075
Test Loss:  0.010210921987891197
Valid Loss:  0.014948820695281029
Epoch:  227  	Training Loss: 0.011095279827713966
Test Loss:  0.010211583226919174
Valid Loss:  0.01494426280260086
Epoch:  228  	Training Loss: 0.011091649532318115
Test Loss:  0.01021595299243927
Valid Loss:  0.014943532645702362
Epoch:  229  	Training Loss: 0.011088600382208824
Test Loss:  0.010219573974609375
Valid Loss:  0.01494158711284399
Epoch:  230  	Training Loss: 0.01108582690358162
Test Loss:  0.010226154699921608
Valid Loss:  0.014941368252038956
Epoch:  231  	Training Loss: 0.011083412915468216
Test Loss:  0.01023191399872303
Valid Loss:  0.014940712600946426
Epoch:  232  	Training Loss: 0.011081097647547722
Test Loss:  0.01023249514400959
Valid Loss:  0.01494053564965725
Epoch:  233  	Training Loss: 0.0110796969383955
Test Loss:  0.010233408771455288
Valid Loss:  0.014942677691578865
Epoch:  234  	Training Loss: 0.011078353971242905
Test Loss:  0.010234393179416656
Valid Loss:  0.014945930801331997
Epoch:  235  	Training Loss: 0.01107703521847725
Test Loss:  0.01023534033447504
Valid Loss:  0.014949725940823555
Epoch:  236  	Training Loss: 0.01107574813067913
Test Loss:  0.010236196219921112
Valid Loss:  0.014953781850636005
Epoch:  237  	Training Loss: 0.011074482463300228
Test Loss:  0.01023695059120655
Valid Loss:  0.014957965351641178
Epoch:  238  	Training Loss: 0.011073248460888863
Test Loss:  0.01023760624229908
Valid Loss:  0.014962214976549149
Epoch:  239  	Training Loss: 0.01107203122228384
Test Loss:  0.010238151997327805
Valid Loss:  0.014966500923037529
Epoch:  240  	Training Loss: 0.011070841923356056
Test Loss:  0.010238605551421642
Valid Loss:  0.014970792457461357
Epoch:  241  	Training Loss: 0.01106967031955719
Test Loss:  0.010238971561193466
Valid Loss:  0.014975088648498058
Epoch:  242  	Training Loss: 0.011068525724112988
Test Loss:  0.010203327983617783
Valid Loss:  0.01496452558785677
Epoch:  243  	Training Loss: 0.011039219796657562
Test Loss:  0.010154359973967075
Valid Loss:  0.01495254784822464
Epoch:  244  	Training Loss: 0.011006874963641167
Test Loss:  0.010105866938829422
Valid Loss:  0.014940597116947174
Epoch:  245  	Training Loss: 0.010974996723234653
Test Loss:  0.010051758028566837
Valid Loss:  0.014926384203135967
Epoch:  246  	Training Loss: 0.010936375707387924
Test Loss:  0.010000983253121376
Valid Loss:  0.014912347309291363
Epoch:  247  	Training Loss: 0.010896747000515461
Test Loss:  0.009938610717654228
Valid Loss:  0.01489653717726469
Epoch:  248  	Training Loss: 0.010852374136447906
Test Loss:  0.00987559650093317
Valid Loss:  0.014881148934364319
Epoch:  249  	Training Loss: 0.010809723287820816
Test Loss:  0.00980827771127224
Valid Loss:  0.014864347875118256
Epoch:  250  	Training Loss: 0.010760202072560787
Test Loss:  0.009746009483933449
Valid Loss:  0.0148410489782691
Epoch:  251  	Training Loss: 0.010714864358305931
Test Loss:  0.00968838669359684
Valid Loss:  0.014813805930316448
Epoch:  252  	Training Loss: 0.010669760406017303
Test Loss:  0.009619742631912231
Valid Loss:  0.014741147868335247
Epoch:  253  	Training Loss: 0.01063590869307518
Test Loss:  0.009575843811035156
Valid Loss:  0.014706209301948547
Epoch:  254  	Training Loss: 0.01061773020774126
Test Loss:  0.009548665955662727
Valid Loss:  0.014685068279504776
Epoch:  255  	Training Loss: 0.010606417432427406
Test Loss:  0.009527234360575676
Valid Loss:  0.01467057317495346
Epoch:  256  	Training Loss: 0.010597188025712967
Test Loss:  0.009512769989669323
Valid Loss:  0.014663208276033401
Epoch:  257  	Training Loss: 0.010589974001049995
Test Loss:  0.009501410648226738
Valid Loss:  0.014660676009953022
Epoch:  258  	Training Loss: 0.010584764182567596
Test Loss:  0.009495224803686142
Valid Loss:  0.014661871828138828
Epoch:  259  	Training Loss: 0.010581300593912601
Test Loss:  0.009489200077950954
Valid Loss:  0.014661569148302078
Epoch:  260  	Training Loss: 0.010578235611319542
Test Loss:  0.009486699476838112
Valid Loss:  0.014664355665445328
Epoch:  261  	Training Loss: 0.010575870983302593
Test Loss:  0.009483898058533669
Valid Loss:  0.014667481184005737
Epoch:  262  	Training Loss: 0.010573661886155605
Test Loss:  0.009485073387622833
Valid Loss:  0.014668257907032967
Epoch:  263  	Training Loss: 0.010573402978479862
Test Loss:  0.009486149065196514
Valid Loss:  0.014668898656964302
Epoch:  264  	Training Loss: 0.010573145933449268
Test Loss:  0.009487142786383629
Valid Loss:  0.014669429510831833
Epoch:  265  	Training Loss: 0.010572889819741249
Test Loss:  0.009488064795732498
Valid Loss:  0.014669867232441902
Epoch:  266  	Training Loss: 0.010572632774710655
Test Loss:  0.009488928131759167
Valid Loss:  0.01467021182179451
Epoch:  267  	Training Loss: 0.01057237945497036
Test Loss:  0.009489738382399082
Valid Loss:  0.014670493081212044
Epoch:  268  	Training Loss: 0.010572127066552639
Test Loss:  0.00949050858616829
Valid Loss:  0.014670719392597675
Epoch:  269  	Training Loss: 0.010571877472102642
Test Loss:  0.009491244331002235
Valid Loss:  0.0146709019318223
Epoch:  270  	Training Loss: 0.010571625083684921
Test Loss:  0.009491946548223495
Valid Loss:  0.014671037904918194
Epoch:  271  	Training Loss: 0.010571375489234924
Test Loss:  0.009492628276348114
Valid Loss:  0.014671139419078827
Epoch:  272  	Training Loss: 0.010571155697107315
Test Loss:  0.009275870397686958
Valid Loss:  0.014742879197001457
Epoch:  273  	Training Loss: 0.010511276312172413
Test Loss:  0.009250449948012829
Valid Loss:  0.014738683588802814
Epoch:  274  	Training Loss: 0.010506503283977509
Test Loss:  0.009238004684448242
Valid Loss:  0.014730428345501423
Epoch:  275  	Training Loss: 0.010502742603421211
Test Loss:  0.009216590784490108
Valid Loss:  0.014733007177710533
Epoch:  276  	Training Loss: 0.010498285293579102
Test Loss:  0.009208894334733486
Valid Loss:  0.014725652523338795
Epoch:  277  	Training Loss: 0.010494798421859741
Test Loss:  0.009209200739860535
Valid Loss:  0.014715933240950108
Epoch:  278  	Training Loss: 0.010492062196135521
Test Loss:  0.009203310124576092
Valid Loss:  0.01471181120723486
Epoch:  279  	Training Loss: 0.010489745065569878
Test Loss:  0.009206513874232769
Valid Loss:  0.014704023487865925
Epoch:  280  	Training Loss: 0.010488086380064487
Test Loss:  0.00920003280043602
Valid Loss:  0.01470319926738739
Epoch:  281  	Training Loss: 0.01048678532242775
Test Loss:  0.009206307120621204
Valid Loss:  0.014696016907691956
Epoch:  282  	Training Loss: 0.010485595092177391 57%|█████▋    | 283/500 [03:37<03:08,  1.15it/s] 57%|█████▋    | 285/500 [03:37<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:38<01:37,  2.18it/s] 58%|█████▊    | 289/500 [03:38<01:11,  2.94it/s] 58%|█████▊    | 291/500 [03:44<04:02,  1.16s/it] 59%|█████▊    | 293/500 [03:44<02:52,  1.20it/s] 59%|█████▉    | 295/500 [03:44<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:44<01:29,  2.26it/s] 60%|█████▉    | 299/500 [03:44<01:06,  3.04it/s] 60%|██████    | 301/500 [03:51<03:53,  1.17s/it] 61%|██████    | 303/500 [03:51<02:47,  1.18it/s] 61%|██████    | 305/500 [03:51<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:51<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:51<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:57<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:58<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:58<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:58<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:58<01:00,  2.98it/s] 64%|██████▍   | 321/500 [04:04<03:28,  1.16s/it] 65%|██████▍   | 323/500 [04:04<02:27,  1.20it/s] 65%|██████▌   | 325/500 [04:04<01:45,  1.66it/s] 65%|██████▌   | 327/500 [04:05<01:16,  2.26it/s] 66%|██████▌   | 329/500 [04:05<00:56,  3.04it/s] 66%|██████▌   | 331/500 [04:11<03:20,  1.19s/it] 67%|██████▋   | 333/500 [04:11<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:11<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:12<01:13,  2.21it/s] 68%|██████▊   | 339/500 [04:12<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:18<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:18<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:18<01:35,  1.62it/s] 69%|██████▉   | 347/500 [04:18<01:09,  2.21it/s] 70%|██████▉   | 349/500 [04:19<00:50,  2.97it/s] 70%|███████   | 351/500 [04:25<02:56,  1.19s/it]
Test Loss:  0.009208672679960728
Valid Loss:  0.014696413651108742
Epoch:  283  	Training Loss: 0.010485242120921612
Test Loss:  0.009208226576447487
Valid Loss:  0.014694495126605034
Epoch:  284  	Training Loss: 0.010485006496310234
Test Loss:  0.009208085015416145
Valid Loss:  0.014692913740873337
Epoch:  285  	Training Loss: 0.01048477366566658
Test Loss:  0.009208121336996555
Valid Loss:  0.014691544696688652
Epoch:  286  	Training Loss: 0.010484542697668076
Test Loss:  0.00920826941728592
Valid Loss:  0.014690309762954712
Epoch:  287  	Training Loss: 0.010484311729669571
Test Loss:  0.009208493866026402
Valid Loss:  0.014689192175865173
Epoch:  288  	Training Loss: 0.010484082624316216
Test Loss:  0.009208778850734234
Valid Loss:  0.014688205905258656
Epoch:  289  	Training Loss: 0.010483872145414352
Test Loss:  0.009209102019667625
Valid Loss:  0.014687311835587025
Epoch:  290  	Training Loss: 0.010483670979738235
Test Loss:  0.009209422394633293
Valid Loss:  0.01468643918633461
Epoch:  291  	Training Loss: 0.010483482852578163
Test Loss:  0.00920899584889412
Valid Loss:  0.014684891328215599
Epoch:  292  	Training Loss: 0.010483283549547195
Test Loss:  0.00913221575319767
Valid Loss:  0.014455705881118774
Epoch:  293  	Training Loss: 0.010322345420718193
Test Loss:  0.009082719683647156
Valid Loss:  0.014281746000051498
Epoch:  294  	Training Loss: 0.010183279402554035
Test Loss:  0.009040528908371925
Valid Loss:  0.014119021594524384
Epoch:  295  	Training Loss: 0.010054271668195724
Test Loss:  0.008951671421527863
Valid Loss:  0.013973822817206383
Epoch:  296  	Training Loss: 0.009921381250023842
Test Loss:  0.008877276442945004
Valid Loss:  0.013807480223476887
Epoch:  297  	Training Loss: 0.009786653332412243
Test Loss:  0.00877944566309452
Valid Loss:  0.013660474680364132
Epoch:  298  	Training Loss: 0.00965394452214241
Test Loss:  0.008731616660952568
Valid Loss:  0.013499796390533447
Epoch:  299  	Training Loss: 0.009523259475827217
Test Loss:  0.008632946759462357
Valid Loss:  0.013356378301978111
Epoch:  300  	Training Loss: 0.009390912018716335
Test Loss:  0.008535820990800858
Valid Loss:  0.01317246351391077
Epoch:  301  	Training Loss: 0.00925365462899208
Test Loss:  0.008456787094473839
Valid Loss:  0.012983613647520542
Epoch:  302  	Training Loss: 0.009125741198658943
Test Loss:  0.008463993668556213
Valid Loss:  0.012925286777317524
Epoch:  303  	Training Loss: 0.009102009236812592
Test Loss:  0.008385580033063889
Valid Loss:  0.012867745943367481
Epoch:  304  	Training Loss: 0.009075911715626717
Test Loss:  0.008360285311937332
Valid Loss:  0.01281357929110527
Epoch:  305  	Training Loss: 0.009052341803908348
Test Loss:  0.008347121067345142
Valid Loss:  0.012769738212227821
Epoch:  306  	Training Loss: 0.009030809625983238
Test Loss:  0.0083345677703619
Valid Loss:  0.01273348182439804
Epoch:  307  	Training Loss: 0.0090106762945652
Test Loss:  0.008333759382367134
Valid Loss:  0.012700838968157768
Epoch:  308  	Training Loss: 0.008991606533527374
Test Loss:  0.008318401873111725
Valid Loss:  0.012669937685132027
Epoch:  309  	Training Loss: 0.008972574025392532
Test Loss:  0.008240511640906334
Valid Loss:  0.01261166948825121
Epoch:  310  	Training Loss: 0.008948261849582195
Test Loss:  0.008276060223579407
Valid Loss:  0.012577427551150322
Epoch:  311  	Training Loss: 0.00892579834908247
Test Loss:  0.008177299983799458
Valid Loss:  0.012506455183029175
Epoch:  312  	Training Loss: 0.008905062451958656
Test Loss:  0.008161092177033424
Valid Loss:  0.01226995512843132
Epoch:  313  	Training Loss: 0.008777862414717674
Test Loss:  0.008186710067093372
Valid Loss:  0.012124055065214634
Epoch:  314  	Training Loss: 0.008695466443896294
Test Loss:  0.008223417215049267
Valid Loss:  0.012020261958241463
Epoch:  315  	Training Loss: 0.008625557646155357
Test Loss:  0.008263522759079933
Valid Loss:  0.011936718598008156
Epoch:  316  	Training Loss: 0.008561254478991032
Test Loss:  0.008304465562105179
Valid Loss:  0.011868800967931747
Epoch:  317  	Training Loss: 0.008504806086421013
Test Loss:  0.008343687281012535
Valid Loss:  0.01181073673069477
Epoch:  318  	Training Loss: 0.008454369381070137
Test Loss:  0.00838319119066
Valid Loss:  0.011761083267629147
Epoch:  319  	Training Loss: 0.00840932410210371
Test Loss:  0.00842302292585373
Valid Loss:  0.011717092245817184
Epoch:  320  	Training Loss: 0.008369144052267075
Test Loss:  0.0084632383659482
Valid Loss:  0.011677777394652367
Epoch:  321  	Training Loss: 0.008333398960530758
Test Loss:  0.008503852412104607
Valid Loss:  0.011642489582300186
Epoch:  322  	Training Loss: 0.008301354013383389
Test Loss:  0.00820467621088028
Valid Loss:  0.011387205682694912
Epoch:  323  	Training Loss: 0.008053746074438095
Test Loss:  0.007922792807221413
Valid Loss:  0.011135542765259743
Epoch:  324  	Training Loss: 0.007856125012040138
Test Loss:  0.007656562142074108
Valid Loss:  0.010879367589950562
Epoch:  325  	Training Loss: 0.0076650334522128105
Test Loss:  0.007410000078380108
Valid Loss:  0.010636722669005394
Epoch:  326  	Training Loss: 0.007484240457415581
Test Loss:  0.007185129448771477
Valid Loss:  0.010396802797913551
Epoch:  327  	Training Loss: 0.00732044130563736
Test Loss:  0.006983591243624687
Valid Loss:  0.010182593017816544
Epoch:  328  	Training Loss: 0.0071721067652106285
Test Loss:  0.006808986887335777
Valid Loss:  0.009986994788050652
Epoch:  329  	Training Loss: 0.007031850516796112
Test Loss:  0.006652875803411007
Valid Loss:  0.00980107206851244
Epoch:  330  	Training Loss: 0.0069033922627568245
Test Loss:  0.006515955552458763
Valid Loss:  0.009627917781472206
Epoch:  331  	Training Loss: 0.0067877015098929405
Test Loss:  0.006403492763638496
Valid Loss:  0.009473716840147972
Epoch:  332  	Training Loss: 0.006685149855911732
Test Loss:  0.006303256377577782
Valid Loss:  0.009272037073969841
Epoch:  333  	Training Loss: 0.006620359141379595
Test Loss:  0.006260914262384176
Valid Loss:  0.009211312048137188
Epoch:  334  	Training Loss: 0.006606381386518478
Test Loss:  0.006225815042853355
Valid Loss:  0.00917682982981205
Epoch:  335  	Training Loss: 0.00659688888117671
Test Loss:  0.00619425717741251
Valid Loss:  0.009150401689112186
Epoch:  336  	Training Loss: 0.006588523741811514
Test Loss:  0.0061645591631531715
Valid Loss:  0.00912638008594513
Epoch:  337  	Training Loss: 0.00658146757632494
Test Loss:  0.006141038611531258
Valid Loss:  0.009104961529374123
Epoch:  338  	Training Loss: 0.006576265208423138
Test Loss:  0.006120513193309307
Valid Loss:  0.009086303412914276
Epoch:  339  	Training Loss: 0.0065718237310647964
Test Loss:  0.006100062280893326
Valid Loss:  0.009069249033927917
Epoch:  340  	Training Loss: 0.0065677231177687645
Test Loss:  0.0060809701681137085
Valid Loss:  0.009053485468029976
Epoch:  341  	Training Loss: 0.006564016453921795
Test Loss:  0.006062905304133892
Valid Loss:  0.009038681164383888
Epoch:  342  	Training Loss: 0.00656087975949049
Test Loss:  0.006062943488359451
Valid Loss:  0.009038788266479969
Epoch:  343  	Training Loss: 0.006560840643942356
Test Loss:  0.006062978878617287
Valid Loss:  0.009038899093866348
Epoch:  344  	Training Loss: 0.0065608033910393715
Test Loss:  0.0060630193911492825
Valid Loss:  0.009039007127285004
Epoch:  345  	Training Loss: 0.006560765206813812
Test Loss:  0.0060630543157458305
Valid Loss:  0.009039115160703659
Epoch:  346  	Training Loss: 0.006560726556926966
Test Loss:  0.00606309249997139
Valid Loss:  0.009039221331477165
Epoch:  347  	Training Loss: 0.006560687907040119
Test Loss:  0.006063127890229225
Valid Loss:  0.009039330296218395
Epoch:  348  	Training Loss: 0.006560651585459709
Test Loss:  0.006063167937099934
Valid Loss:  0.009039439260959625
Epoch:  349  	Training Loss: 0.006560612469911575
Test Loss:  0.006063202396035194
Valid Loss:  0.00903954915702343
Epoch:  350  	Training Loss: 0.006560576148331165
Test Loss:  0.006063242442905903
Valid Loss:  0.009039649739861488
Epoch:  351  	Training Loss: 0.0065605370327830315
Test Loss:  0.0060632796958088875
Valid Loss:  0.00903976522386074
Epoch:  352  	Training Loss: 0.006560497917234898
Test Loss:   71%|███████   | 353/500 [04:25<02:05,  1.17it/s] 71%|███████   | 355/500 [04:25<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:25<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:25<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:32<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:32<01:54,  1.19it/s] 73%|███████▎  | 365/500 [04:32<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:32<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:32<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:39<02:32,  1.19s/it] 75%|███████▍  | 373/500 [04:39<01:48,  1.18it/s] 75%|███████▌  | 375/500 [04:39<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:39<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:39<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:46<02:23,  1.20s/it] 77%|███████▋  | 383/500 [04:46<01:41,  1.16it/s] 77%|███████▋  | 385/500 [04:46<01:11,  1.60it/s] 77%|███████▋  | 387/500 [04:46<00:51,  2.19it/s] 78%|███████▊  | 389/500 [04:46<00:37,  2.95it/s] 78%|███████▊  | 391/500 [04:52<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:53<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:59<02:43,  1.55s/it] 79%|███████▉  | 397/500 [04:59<01:54,  1.11s/it] 80%|███████▉  | 399/500 [04:59<01:20,  1.26it/s] 80%|████████  | 401/500 [05:06<02:28,  1.50s/it] 81%|████████  | 403/500 [05:06<01:43,  1.07s/it] 81%|████████  | 405/500 [05:06<01:13,  1.29it/s] 81%|████████▏ | 407/500 [05:06<00:52,  1.78it/s] 82%|████████▏ | 409/500 [05:06<00:37,  2.42it/s] 82%|████████▏ | 411/500 [05:12<01:50,  1.24s/it] 83%|████████▎ | 413/500 [05:13<01:17,  1.13it/s] 83%|████████▎ | 415/500 [05:13<00:54,  1.56it/s] 83%|████████▎ | 417/500 [05:13<00:38,  2.13it/s] 84%|████████▍ | 419/500 [05:13<00:28,  2.88it/s]0.0061394344083964825
Valid Loss:  0.008975952863693237
Epoch:  353  	Training Loss: 0.006442632060497999
Test Loss:  0.006193908397108316
Valid Loss:  0.008930124342441559
Epoch:  354  	Training Loss: 0.006364504806697369
Test Loss:  0.006241988390684128
Valid Loss:  0.008891163393855095
Epoch:  355  	Training Loss: 0.006305885035544634
Test Loss:  0.0062747979536652565
Valid Loss:  0.008853118866682053
Epoch:  356  	Training Loss: 0.0062604681588709354
Test Loss:  0.006294682621955872
Valid Loss:  0.008795579895377159
Epoch:  357  	Training Loss: 0.0062247151508927345
Test Loss:  0.006315372884273529
Valid Loss:  0.008745694532990456
Epoch:  358  	Training Loss: 0.006196421571075916
Test Loss:  0.006326980888843536
Valid Loss:  0.008700760081410408
Epoch:  359  	Training Loss: 0.006173105910420418
Test Loss:  0.006339443381875753
Valid Loss:  0.008659949526190758
Epoch:  360  	Training Loss: 0.006152884103357792
Test Loss:  0.00634665647521615
Valid Loss:  0.008620981127023697
Epoch:  361  	Training Loss: 0.0061348602175712585
Test Loss:  0.006345110014081001
Valid Loss:  0.008584094233810902
Epoch:  362  	Training Loss: 0.006118545308709145
Test Loss:  0.006283302325755358
Valid Loss:  0.008508030325174332
Epoch:  363  	Training Loss: 0.00609397329390049
Test Loss:  0.006237872876226902
Valid Loss:  0.00845975149422884
Epoch:  364  	Training Loss: 0.006075579673051834
Test Loss:  0.006197748240083456
Valid Loss:  0.008420645259320736
Epoch:  365  	Training Loss: 0.0060584042221307755
Test Loss:  0.006160998251289129
Valid Loss:  0.00838646199554205
Epoch:  366  	Training Loss: 0.0060422783717513084
Test Loss:  0.006130590569227934
Valid Loss:  0.008356675505638123
Epoch:  367  	Training Loss: 0.006027632392942905
Test Loss:  0.006103625521063805
Valid Loss:  0.008329719305038452
Epoch:  368  	Training Loss: 0.006013345438987017
Test Loss:  0.006078253500163555
Valid Loss:  0.008306014351546764
Epoch:  369  	Training Loss: 0.005999578628689051
Test Loss:  0.006058541126549244
Valid Loss:  0.008283531293272972
Epoch:  370  	Training Loss: 0.005987223237752914
Test Loss:  0.006040843203663826
Valid Loss:  0.00826536025851965
Epoch:  371  	Training Loss: 0.005975185427814722
Test Loss:  0.006023966707289219
Valid Loss:  0.008248526602983475
Epoch:  372  	Training Loss: 0.005963323637843132
Test Loss:  0.006012829020619392
Valid Loss:  0.008208041079342365
Epoch:  373  	Training Loss: 0.0059496378526091576
Test Loss:  0.005988543853163719
Valid Loss:  0.008177286945283413
Epoch:  374  	Training Loss: 0.005938837304711342
Test Loss:  0.005976703949272633
Valid Loss:  0.008164126425981522
Epoch:  375  	Training Loss: 0.005930399056524038
Test Loss:  0.0059685250744223595
Valid Loss:  0.008155877701938152
Epoch:  376  	Training Loss: 0.005922693759202957
Test Loss:  0.005962463561445475
Valid Loss:  0.008151540532708168
Epoch:  377  	Training Loss: 0.005916360300034285
Test Loss:  0.005960424430668354
Valid Loss:  0.008148351684212685
Epoch:  378  	Training Loss: 0.005910865031182766
Test Loss:  0.0059617673978209496
Valid Loss:  0.008145371451973915
Epoch:  379  	Training Loss: 0.005906090606004
Test Loss:  0.005960511974990368
Valid Loss:  0.008141838945448399
Epoch:  380  	Training Loss: 0.005901399068534374
Test Loss:  0.005962898023426533
Valid Loss:  0.008138623088598251
Epoch:  381  	Training Loss: 0.005896901711821556
Test Loss:  0.0059646377339959145
Valid Loss:  0.008135058917105198
Epoch:  382  	Training Loss: 0.005892511457204819
Test Loss:  0.0059731500223279
Valid Loss:  0.0081023583188653
Epoch:  383  	Training Loss: 0.005866465158760548
Test Loss:  0.0059729525819420815
Valid Loss:  0.008068060502409935
Epoch:  384  	Training Loss: 0.005844089202582836
Test Loss:  0.005969921126961708
Valid Loss:  0.008033853024244308
Epoch:  385  	Training Loss: 0.00582449184730649
Test Loss:  0.0059682815335690975
Valid Loss:  0.008000647649168968
Epoch:  386  	Training Loss: 0.005807177163660526
Test Loss:  0.005965651478618383
Valid Loss:  0.007969236001372337
Epoch:  387  	Training Loss: 0.005791691597551107
Test Loss:  0.0059621818363666534
Valid Loss:  0.00793965719640255
Epoch:  388  	Training Loss: 0.0057777101173996925
Test Loss:  0.0059579238295555115
Valid Loss:  0.007911842316389084
Epoch:  389  	Training Loss: 0.0057649752125144005
Test Loss:  0.0059529198333621025
Valid Loss:  0.007885634899139404
Epoch:  390  	Training Loss: 0.0057534161023795605
Test Loss:  0.0059478431940078735
Valid Loss:  0.007860373705625534
Epoch:  391  	Training Loss: 0.005742999259382486
Test Loss:  0.005944449454545975
Valid Loss:  0.007837144657969475
Epoch:  392  	Training Loss: 0.0057335058227181435
Test Loss:  0.00604206882417202
Valid Loss:  0.008438898250460625
Epoch:  393  	Training Loss: 0.006441935896873474
Test Loss:  0.013386890292167664
Valid Loss:  0.013498815707862377
Epoch:  394  	Training Loss: 0.012098584324121475
Test Loss:  0.03644830361008644
Valid Loss:  0.04088587686419487
Epoch:  395  	Training Loss: 0.036084629595279694
Test Loss:  0.04705195128917694
Valid Loss:  0.0475185289978981
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.05312088131904602
Test Loss:  0.029192153364419937
Valid Loss:  0.031306616961956024
Epoch:  397  	Training Loss: 0.03384102135896683
Test Loss:  0.021605700254440308
Valid Loss:  0.02465464547276497
Epoch:  398  	Training Loss: 0.025120507925748825
Test Loss:  0.018431665375828743
Valid Loss:  0.021941520273685455
Epoch:  399  	Training Loss: 0.02108726277947426
Test Loss:  0.01694207265973091
Valid Loss:  0.02068714238703251
Epoch:  400  	Training Loss: 0.01899317465722561
Test Loss:  0.016081731766462326
Valid Loss:  0.01994824782013893
Epoch:  401  	Training Loss: 0.017703738063573837
Test Loss:  0.015480855479836464
Valid Loss:  0.019399866461753845
Epoch:  402  	Training Loss: 0.016786912456154823
Test Loss:  0.01517012994736433
Valid Loss:  0.019029732793569565
Epoch:  403  	Training Loss: 0.016483427956700325
Test Loss:  0.014902768656611443
Valid Loss:  0.018737822771072388
Epoch:  404  	Training Loss: 0.016235586255788803
Test Loss:  0.014677708968520164
Valid Loss:  0.018516426905989647
Epoch:  405  	Training Loss: 0.016042733564972878
Test Loss:  0.014493164606392384
Valid Loss:  0.018340032547712326
Epoch:  406  	Training Loss: 0.01588347740471363
Test Loss:  0.014338255859911442
Valid Loss:  0.018203508108854294
Epoch:  407  	Training Loss: 0.01574697531759739
Test Loss:  0.014212568290531635
Valid Loss:  0.01811671257019043
Epoch:  408  	Training Loss: 0.015631593763828278
Test Loss:  0.014115807600319386
Valid Loss:  0.018059831112623215
Epoch:  409  	Training Loss: 0.015548206865787506
Test Loss:  0.014057534746825695
Valid Loss:  0.01803126186132431
Epoch:  410  	Training Loss: 0.01547980960458517
Test Loss:  0.014012763276696205
Valid Loss:  0.018010184168815613
Epoch:  411  	Training Loss: 0.015425460413098335
Test Loss:  0.01397944986820221
Valid Loss:  0.01799572817981243
Epoch:  412  	Training Loss: 0.01537913829088211
Test Loss:  0.013834257610142231
Valid Loss:  0.01783391460776329
Epoch:  413  	Training Loss: 0.015283078886568546
Test Loss:  0.013706880621612072
Valid Loss:  0.01769152283668518
Epoch:  414  	Training Loss: 0.015201322734355927
Test Loss:  0.013594966381788254
Valid Loss:  0.017566021531820297
Epoch:  415  	Training Loss: 0.015131749212741852
Test Loss:  0.013496476225554943
Valid Loss:  0.017455225810408592
Epoch:  416  	Training Loss: 0.01507253386080265
Test Loss:  0.013409679755568504
Valid Loss:  0.017357274889945984
Epoch:  417  	Training Loss: 0.015022141858935356
Test Loss:  0.013333054259419441
Valid Loss:  0.017270516604185104
Epoch:  418  	Training Loss: 0.014979234896600246
Test Loss:  0.013265292160212994
Valid Loss:  0.017193539068102837
Epoch:  419  	Training Loss: 0.01494271494448185
Test Loss:  0.013205286115407944
Valid Loss:  0.017125152051448822
Epoch:  420  	Training Loss: 0.01491161435842514
Test Loss:  0.013152056373655796
Valid Loss:  0.01706428825855255
Epoch:  421  	Training Loss: 0.014885125681757927
Test Loss:  0.013104752637445927
 84%|████████▍ | 421/500 [05:19<01:33,  1.18s/it] 85%|████████▍ | 423/500 [05:19<01:05,  1.18it/s] 85%|████████▌ | 425/500 [05:19<00:46,  1.63it/s] 85%|████████▌ | 427/500 [05:20<00:32,  2.23it/s] 86%|████████▌ | 429/500 [05:20<00:23,  3.00it/s] 86%|████████▌ | 431/500 [05:26<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:26<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:26<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:26<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:27<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:33<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:33<00:48,  1.19it/s] 89%|████████▉ | 445/500 [05:33<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:33<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:33<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:40<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:40<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:40<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:40<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:40<00:13,  3.02it/s] 92%|█████████▏| 461/500 [05:47<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:47<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:47<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:47<00:15,  2.18it/s] 94%|█████████▍| 469/500 [05:47<00:10,  2.91it/s] 94%|█████████▍| 471/500 [05:53<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:54<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:54<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:54<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:54<00:06,  3.02it/s] 96%|█████████▌| 481/500 [06:00<00:22,  1.19s/it] 97%|█████████▋| 483/500 [06:00<00:14,  1.17it/s] 97%|█████████▋| 485/500 [06:01<00:09,  1.62it/s] 97%|█████████▋| 487/500 [06:01<00:05,  2.22it/s] 98%|█████████▊| 489/500 [06:01<00:03,  2.98it/s] 98%|█████████▊| 491/500 [06:07<00:10,  1.18s/it]Valid Loss:  0.01701004058122635
Epoch:  422  	Training Loss: 0.014862559735774994
Test Loss:  0.012488110922276974
Valid Loss:  0.01651499792933464
Epoch:  423  	Training Loss: 0.013942581601440907
Test Loss:  0.012075377628207207
Valid Loss:  0.016260767355561256
Epoch:  424  	Training Loss: 0.013339659199118614
Test Loss:  0.011823069304227829
Valid Loss:  0.01609683781862259
Epoch:  425  	Training Loss: 0.012947054579854012
Test Loss:  0.011636234819889069
Valid Loss:  0.015961885452270508
Epoch:  426  	Training Loss: 0.01263323612511158
Test Loss:  0.01146306935697794
Valid Loss:  0.01583832874894142
Epoch:  427  	Training Loss: 0.012383622117340565
Test Loss:  0.011299138888716698
Valid Loss:  0.01571214757859707
Epoch:  428  	Training Loss: 0.012173660099506378
Test Loss:  0.011158876121044159
Valid Loss:  0.015591269358992577
Epoch:  429  	Training Loss: 0.011989512480795383
Test Loss:  0.011026029475033283
Valid Loss:  0.015476103872060776
Epoch:  430  	Training Loss: 0.011828077957034111
Test Loss:  0.010897498577833176
Valid Loss:  0.015360584482550621
Epoch:  431  	Training Loss: 0.011688796803355217
Test Loss:  0.01077582873404026
Valid Loss:  0.015249915421009064
Epoch:  432  	Training Loss: 0.011565935797989368
Test Loss:  0.010810138657689095
Valid Loss:  0.015277799218893051
Epoch:  433  	Training Loss: 0.011509383097290993
Test Loss:  0.010849599726498127
Valid Loss:  0.015304330736398697
Epoch:  434  	Training Loss: 0.011468688026070595
Test Loss:  0.010884007439017296
Valid Loss:  0.015326032415032387
Epoch:  435  	Training Loss: 0.011437606066465378
Test Loss:  0.010912464931607246
Valid Loss:  0.01534350123256445
Epoch:  436  	Training Loss: 0.0114129688590765
Test Loss:  0.010935850441455841
Valid Loss:  0.015356119722127914
Epoch:  437  	Training Loss: 0.011392390355467796
Test Loss:  0.010954695753753185
Valid Loss:  0.015364071354269981
Epoch:  438  	Training Loss: 0.011374764144420624
Test Loss:  0.010969392955303192
Valid Loss:  0.015367870219051838
Epoch:  439  	Training Loss: 0.011358750984072685
Test Loss:  0.010980616323649883
Valid Loss:  0.015368219465017319
Epoch:  440  	Training Loss: 0.011344240978360176
Test Loss:  0.010989286005496979
Valid Loss:  0.015366626903414726
Epoch:  441  	Training Loss: 0.011332618072628975
Test Loss:  0.010996093042194843
Valid Loss:  0.015363804996013641
Epoch:  442  	Training Loss: 0.011322620324790478
Test Loss:  0.010751722380518913
Valid Loss:  0.015114287845790386
Epoch:  443  	Training Loss: 0.01118603814393282
Test Loss:  0.010551943443715572
Valid Loss:  0.014909571036696434
Epoch:  444  	Training Loss: 0.011081652715802193
Test Loss:  0.010387543588876724
Valid Loss:  0.014740264043211937
Epoch:  445  	Training Loss: 0.011001436039805412
Test Loss:  0.010251399129629135
Valid Loss:  0.014599191024899483
Epoch:  446  	Training Loss: 0.01093949656933546
Test Loss:  0.010137911885976791
Valid Loss:  0.014480706304311752
Epoch:  447  	Training Loss: 0.010891356505453587
Test Loss:  0.010042707435786724
Valid Loss:  0.014380408450961113
Epoch:  448  	Training Loss: 0.010853653773665428
Test Loss:  0.009962288662791252
Valid Loss:  0.01429479755461216
Epoch:  449  	Training Loss: 0.010823848657310009
Test Loss:  0.009893940761685371
Valid Loss:  0.014221156015992165
Epoch:  450  	Training Loss: 0.010800016112625599
Test Loss:  0.009835457429289818
Valid Loss:  0.014157278463244438
Epoch:  451  	Training Loss: 0.010780707001686096
Test Loss:  0.009785093367099762
Valid Loss:  0.014101428911089897
Epoch:  452  	Training Loss: 0.0107648316770792
Test Loss:  0.009783660992980003
Valid Loss:  0.014115533791482449
Epoch:  453  	Training Loss: 0.010725636035203934
Test Loss:  0.009781759232282639
Valid Loss:  0.014122654683887959
Epoch:  454  	Training Loss: 0.010695723816752434
Test Loss:  0.00978153571486473
Valid Loss:  0.014127325266599655
Epoch:  455  	Training Loss: 0.01067068986594677
Test Loss:  0.009782733395695686
Valid Loss:  0.014131216332316399
Epoch:  456  	Training Loss: 0.010648555122315884
Test Loss:  0.00978441908955574
Valid Loss:  0.014133665710687637
Epoch:  457  	Training Loss: 0.010628722608089447
Test Loss:  0.009784689173102379
Valid Loss:  0.014132214710116386
Epoch:  458  	Training Loss: 0.010611271485686302
Test Loss:  0.009784542955458164
Valid Loss:  0.01412886381149292
Epoch:  459  	Training Loss: 0.010594825260341167
Test Loss:  0.009783536195755005
Valid Loss:  0.014124259352684021
Epoch:  460  	Training Loss: 0.010579676367342472
Test Loss:  0.009780677035450935
Valid Loss:  0.014117978513240814
Epoch:  461  	Training Loss: 0.010565325617790222
Test Loss:  0.00977744348347187
Valid Loss:  0.014110170304775238
Epoch:  462  	Training Loss: 0.010551553219556808
Test Loss:  0.009663605131208897
Valid Loss:  0.013913707807660103
Epoch:  463  	Training Loss: 0.010424062609672546
Test Loss:  0.009565412066876888
Valid Loss:  0.01373883243650198
Epoch:  464  	Training Loss: 0.010315966792404652
Test Loss:  0.00947849452495575
Valid Loss:  0.013583745807409286
Epoch:  465  	Training Loss: 0.010223852470517159
Test Loss:  0.009408069774508476
Valid Loss:  0.013453642837703228
Epoch:  466  	Training Loss: 0.010143807157874107
Test Loss:  0.009348995983600616
Valid Loss:  0.013332820497453213
Epoch:  467  	Training Loss: 0.010071332566440105
Test Loss:  0.009287589229643345
Valid Loss:  0.013216482475399971
Epoch:  468  	Training Loss: 0.01000301819294691
Test Loss:  0.009227098897099495
Valid Loss:  0.013114562258124352
Epoch:  469  	Training Loss: 0.009942522272467613
Test Loss:  0.009173193946480751
Valid Loss:  0.013025705702602863
Epoch:  470  	Training Loss: 0.009888609871268272
Test Loss:  0.009122881107032299
Valid Loss:  0.012943428009748459
Epoch:  471  	Training Loss: 0.009839384816586971
Test Loss:  0.00907818041741848
Valid Loss:  0.012862577103078365
Epoch:  472  	Training Loss: 0.00979103147983551
Test Loss:  0.009107518941164017
Valid Loss:  0.012944725342094898
Epoch:  473  	Training Loss: 0.009741423651576042
Test Loss:  0.009138954803347588
Valid Loss:  0.013012249022722244
Epoch:  474  	Training Loss: 0.009715961292386055
Test Loss:  0.009165081195533276
Valid Loss:  0.013064786791801453
Epoch:  475  	Training Loss: 0.009703194722533226
Test Loss:  0.009188332594931126
Valid Loss:  0.013105071149766445
Epoch:  476  	Training Loss: 0.009696932509541512
Test Loss:  0.00920200627297163
Valid Loss:  0.013130519539117813
Epoch:  477  	Training Loss: 0.009693743661046028
Test Loss:  0.00921062845736742
Valid Loss:  0.013148737139999866
Epoch:  478  	Training Loss: 0.00969160906970501
Test Loss:  0.009217580780386925
Valid Loss:  0.013162123039364815
Epoch:  479  	Training Loss: 0.009690213948488235
Test Loss:  0.009221790358424187
Valid Loss:  0.01317162811756134
Epoch:  480  	Training Loss: 0.009689086116850376
Test Loss:  0.009224082343280315
Valid Loss:  0.013178355060517788
Epoch:  481  	Training Loss: 0.009688093326985836
Test Loss:  0.009225046262145042
Valid Loss:  0.013183113187551498
Epoch:  482  	Training Loss: 0.009687166661024094
Test Loss:  0.00918774027377367
Valid Loss:  0.013134850189089775
Epoch:  483  	Training Loss: 0.009663532488048077
Test Loss:  0.009152401238679886
Valid Loss:  0.013088343665003777
Epoch:  484  	Training Loss: 0.009640303440392017
Test Loss:  0.009118655696511269
Valid Loss:  0.013043345883488655
Epoch:  485  	Training Loss: 0.009617405943572521
Test Loss:  0.009086279198527336
Valid Loss:  0.012999673373997211
Epoch:  486  	Training Loss: 0.009594786912202835
Test Loss:  0.009055076166987419
Valid Loss:  0.012957146391272545
Epoch:  487  	Training Loss: 0.009572414681315422
Test Loss:  0.009024877101182938
Valid Loss:  0.012915635481476784
Epoch:  488  	Training Loss: 0.009550250135362148
Test Loss:  0.008995559066534042
Valid Loss:  0.012875033542513847
Epoch:  489  	Training Loss: 0.009528281167149544
Test Loss:  0.00896701030433178
Valid Loss:  0.012835228815674782
Epoch:  490  	Training Loss: 0.00950648169964552
Test Loss:  0.008939135819673538
Valid Loss:  0.012796154245734215
Epoch:  491  	Training Loss: 0.009484855458140373
Test Loss:  0.008912072516977787
Valid Loss:  0.012757554650306702
 99%|█████████▊| 493/500 [06:07<00:05,  1.17it/s] 99%|█████████▉| 495/500 [06:08<00:03,  1.60it/s] 99%|█████████▉| 497/500 [06:08<00:01,  2.18it/s]100%|█████████▉| 499/500 [06:08<00:00,  2.90it/s]100%|██████████| 500/500 [06:08<00:00,  1.36it/s]
Epoch:  492  	Training Loss: 0.009463384747505188
Test Loss:  0.008816394954919815
Valid Loss:  0.012655099853873253
Epoch:  493  	Training Loss: 0.009407298639416695
Test Loss:  0.008735481649637222
Valid Loss:  0.01256762444972992
Epoch:  494  	Training Loss: 0.009354827925562859
Test Loss:  0.008663328364491463
Valid Loss:  0.012488428503274918
Epoch:  495  	Training Loss: 0.00930445920675993
Test Loss:  0.008597705513238907
Valid Loss:  0.012414708733558655
Epoch:  496  	Training Loss: 0.009256075136363506
Test Loss:  0.008534546941518784
Valid Loss:  0.012340914458036423
Epoch:  497  	Training Loss: 0.009209167212247849
Test Loss:  0.008475013077259064
Valid Loss:  0.01227051205933094
Epoch:  498  	Training Loss: 0.009163212962448597
Test Loss:  0.008417662233114243
Valid Loss:  0.012202320620417595
Epoch:  499  	Training Loss: 0.009118091315031052
Test Loss:  0.008362013846635818
Valid Loss:  0.012135373428463936
Epoch:  500  	Training Loss: 0.009073376655578613
Test Loss:  0.008307783864438534
Valid Loss:  0.012069396674633026
seed is  14
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:41, 12.06it/s]  1%|          | 4/500 [00:00<00:35, 13.87it/s]  1%|          | 6/500 [00:00<00:33, 14.76it/s]  2%|▏         | 8/500 [00:00<00:32, 15.23it/s]  2%|▏         | 10/500 [00:00<00:31, 15.43it/s]  2%|▏         | 12/500 [00:00<00:32, 15.17it/s]  3%|▎         | 14/500 [00:00<00:32, 14.91it/s]  3%|▎         | 16/500 [00:01<00:31, 15.28it/s]  4%|▎         | 18/500 [00:01<00:31, 15.31it/s]  4%|▍         | 20/500 [00:01<00:31, 15.48it/s]  4%|▍         | 22/500 [00:01<00:30, 15.78it/s]  5%|▍         | 24/500 [00:01<00:29, 15.88it/s]  5%|▌         | 26/500 [00:01<00:29, 15.84it/s]  6%|▌         | 28/500 [00:01<00:29, 15.85it/s]  6%|▌         | 30/500 [00:01<00:29, 15.95it/s]  6%|▋         | 32/500 [00:02<00:29, 16.09it/s]  7%|▋         | 34/500 [00:02<00:28, 16.19it/s]  7%|▋         | 36/500 [00:02<00:28, 16.26it/s]  8%|▊         | 38/500 [00:02<00:28, 16.31it/s]  8%|▊         | 40/500 [00:02<00:28, 16.08it/s]  8%|▊         | 42/500 [00:02<00:29, 15.68it/s]  9%|▉         | 44/500 [00:02<00:28, 15.83it/s]  9%|▉         | 46/500 [00:02<00:28, 15.95it/s] 10%|▉         | 48/500 [00:03<00:28, 16.07it/s] 10%|█         | 50/500 [00:03<00:27, 16.08it/s] 10%|█         | 52/500 [00:03<00:27, 16.07it/s] 11%|█         | 54/500 [00:03<00:27, 15.97it/s] 11%|█         | 56/500 [00:03<00:27, 15.98it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.70it/s] 12%|█▏        | 60/500 [00:03<00:30, 14.55it/s] 12%|█▏        | 62/500 [00:04<00:32, 13.64it/s] 13%|█▎        | 64/500 [00:04<00:32, 13.31it/s] 13%|█▎        | 66/500 [00:04<00:31, 13.89it/s] 14%|█▎        | 68/500 [00:04<00:30, 14.30it/s] 14%|█▍        | 70/500 [00:04<00:29, 14.46it/s] 14%|█▍        | 72/500 [00:04<00:28, 14.88it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.31it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.56it/s] 16%|█▌        | 78/500 [00:05<00:26, 15.73it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.98it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.09it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.85it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.01it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.98it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.95it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.72it/s] 19%|█▉        | 94/500 [00:06<00:26, 15.35it/s] 19%|█▉        | 96/500 [00:06<00:28, 14.19it/s] 20%|█▉        | 98/500 [00:06<00:27, 14.82it/s] 20%|██        | 100/500 [00:06<00:26, 15.22it/s] 20%|██        | 102/500 [00:06<00:25, 15.47it/s] 21%|██        | 104/500 [00:06<00:25, 15.75it/s] 21%|██        | 106/500 [00:06<00:24, 15.95it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.11it/s] 22%|██▏       | 110/500 [00:07<00:24, 16.21it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.18it/s] 23%|██▎       | 114/500 [00:07<00:25, 15.28it/s] 23%|██▎       | 116/500 [00:07<00:25, 14.91it/s] 24%|██▎       | 118/500 [00:07<00:25, 15.26it/s] 24%|██▍       | 120/500 [00:07<00:24, 15.57it/s] 24%|██▍       | 122/500 [00:07<00:23, 15.78it/s] 25%|██▍       | 124/500 [00:08<00:23, 15.97it/s]Epoch:  1  	Training Loss: 0.2712118625640869
Test Loss:  4409.0390625
Valid Loss:  4412.267578125
Epoch:  2  	Training Loss: 4419.12158203125
Test Loss:  88451168862208.0
Valid Loss:  87830344761344.0
Epoch:  3  	Training Loss: 87204663656448.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 15.86it/s] 26%|██▌       | 128/500 [00:08<00:23, 16.01it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.77it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.82it/s] 27%|██▋       | 134/500 [00:08<00:24, 14.95it/s] 27%|██▋       | 136/500 [00:08<00:25, 14.06it/s] 28%|██▊       | 138/500 [00:08<00:25, 14.23it/s] 28%|██▊       | 140/500 [00:09<00:24, 14.79it/s] 28%|██▊       | 142/500 [00:09<00:23, 15.12it/s] 29%|██▉       | 144/500 [00:09<00:23, 15.29it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.49it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.75it/s] 30%|███       | 150/500 [00:09<00:21, 15.93it/s] 30%|███       | 152/500 [00:09<00:21, 16.05it/s] 31%|███       | 154/500 [00:09<00:21, 16.20it/s] 31%|███       | 156/500 [00:10<00:21, 16.27it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.23it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.16it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.10it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.17it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.24it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.30it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.26it/s] 34%|███▍      | 172/500 [00:11<00:20, 16.25it/s] 35%|███▍      | 174/500 [00:11<00:19, 16.32it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.24it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.29it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.27it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.07it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.18it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.22it/s] 38%|███▊      | 188/500 [00:12<00:19, 16.26it/s] 38%|███▊      | 190/500 [00:12<00:19, 16.16it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.11it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.19it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.27it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.22it/s] 40%|████      | 200/500 [00:12<00:18, 15.83it/s] 40%|████      | 202/500 [00:12<00:18, 15.84it/s] 41%|████      | 204/500 [00:13<00:18, 15.68it/s] 41%|████      | 206/500 [00:13<00:18, 15.81it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.97it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.16it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.16it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.08it/s] 43%|████▎     | 216/500 [00:13<00:17, 15.81it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.96it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.16it/s] 44%|████▍     | 222/500 [00:14<00:17, 16.24it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.26it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.30it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.16it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.14it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.26it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.11it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.18it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.09it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.20it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.17it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.09it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.18it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.29it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.33it/s] 50%|█████     | 252/500 [00:16<00:15, 16.27it/s] 51%|█████     | 254/500 [00:16<00:16, 14.97it/s] 51%|█████     | 256/500 [00:16<00:17, 13.98it/s] 52%|█████▏    | 258/500 [00:16<00:18, 13.41it/s] 52%|█████▏    | 260/500 [00:16<00:18, 13.05it/s] 52%|█████▏    | 262/500 [00:16<00:18, 12.83it/s] 53%|█████▎    | 264/500 [00:17<00:18, 12.70it/s] 53%|█████▎    | 266/500 [00:17<00:18, 12.52it/s] 54%|█████▎    | 268/500 [00:17<00:18, 12.43it/s] 54%|█████▍    | 270/500 [00:17<00:18, 12.40it/s] 54%|█████▍    | 272/500 [00:17<00:18, 12.39it/s] 55%|█████▍    | 274/500 [00:17<00:18, 12.31it/s] 55%|█████▌    | 276/500 [00:17<00:18, 12.28it/s] 56%|█████▌    | 278/500 [00:18<00:18, 12.15it/s] 56%|█████▌    | 280/500 [00:18<00:18, 11.95it/s] 56%|█████▋    | 282/500 [00:18<00:18, 11.90it/s] 57%|█████▋    | 284/500 [00:18<00:17, 12.42it/s] 57%|█████▋    | 286/500 [00:18<00:15, 13.40it/s] 58%|█████▊    | 288/500 [00:18<00:14, 14.18it/s] 58%|█████▊    | 290/500 [00:19<00:14, 14.85it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.27it/s] 59%|█████▉    | 294/500 [00:19<00:13, 15.50it/s] 59%|█████▉    | 296/500 [00:19<00:14, 14.51it/s] 60%|█████▉    | 298/500 [00:19<00:14, 13.71it/s] 60%|██████    | 300/500 [00:19<00:15, 13.17it/s] 60%|██████    | 302/500 [00:19<00:15, 12.99it/s] 61%|██████    | 304/500 [00:20<00:14, 13.30it/s] 61%|██████    | 306/500 [00:20<00:14, 13.68it/s] 62%|██████▏   | 308/500 [00:20<00:13, 14.40it/s] 62%|██████▏   | 310/500 [00:20<00:12, 14.82it/s] 62%|██████▏   | 312/500 [00:20<00:12, 15.24it/s] 63%|██████▎   | 314/500 [00:20<00:12, 15.43it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.59it/s] 64%|██████▎   | 318/500 [00:20<00:11, 15.59it/s] 64%|██████▍   | 320/500 [00:21<00:12, 14.34it/s] 64%|██████▍   | 322/500 [00:21<00:13, 13.60it/s] 65%|██████▍   | 324/500 [00:21<00:13, 13.10it/s] 65%|██████▌   | 326/500 [00:21<00:13, 12.74it/s] 66%|██████▌   | 328/500 [00:21<00:13, 13.13it/s] 66%|██████▌   | 330/500 [00:21<00:12, 13.98it/s] 66%|██████▋   | 332/500 [00:21<00:11, 14.30it/s] 67%|██████▋   | 334/500 [00:22<00:11, 14.86it/s] 67%|██████▋   | 336/500 [00:22<00:10, 15.27it/s] 68%|██████▊   | 338/500 [00:22<00:10, 15.50it/s] 68%|██████▊   | 340/500 [00:22<00:10, 15.82it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.03it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.06it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.00it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.10it/s] 70%|███████   | 350/500 [00:23<00:09, 16.25it/s] 70%|███████   | 352/500 [00:23<00:09, 16.32it/s] 71%|███████   | 354/500 [00:23<00:08, 16.27it/s] 71%|███████   | 356/500 [00:23<00:09, 15.64it/s] 72%|███████▏  | 358/500 [00:23<00:08, 15.87it/s] 72%|███████▏  | 360/500 [00:23<00:09, 15.38it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.55it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.76it/s] 73%|███████▎  | 366/500 [00:24<00:08, 15.90it/s] 74%|███████▎  | 368/500 [00:24<00:08, 15.85it/s] 74%|███████▍  | 370/500 [00:24<00:08, 16.00it/s] 74%|███████▍  | 372/500 [00:24<00:07, 16.14it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 16.22it/s] 75%|███████▌  | 376/500 [00:24<00:07, 16.20it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.08it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.10it/s] 76%|███████▋  | 382/500 [00:25<00:07, 15.88it/s] 77%|███████▋  | 384/500 [00:25<00:07, 15.94it/s] 77%|███████▋  | 386/500 [00:25<00:07, 16.05it/s] 78%|███████▊  | 388/500 [00:25<00:06, 16.15it/s] 78%|███████▊  | 390/500 [00:25<00:06, 16.23it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.37it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.47it/s] 79%|███████▉  | 396/500 [00:26<00:07, 14.27it/s] 80%|███████▉  | 398/500 [00:26<00:07, 13.59it/s] 80%|████████  | 400/500 [00:26<00:07, 12.82it/s] 80%|████████  | 402/500 [00:26<00:07, 12.62it/s] 81%|████████  | 404/500 [00:26<00:07, 12.71it/s] 81%|████████  | 406/500 [00:26<00:06, 13.63it/s] 82%|████████▏ | 408/500 [00:26<00:06, 14.33it/s] 82%|████████▏ | 410/500 [00:27<00:06, 14.93it/s] 82%|████████▏ | 412/500 [00:27<00:05, 15.30it/s] 83%|████████▎ | 414/500 [00:27<00:05, 15.49it/s] 83%|████████▎ | 416/500 [00:27<00:05, 15.79it/s] 84%|████████▎ | 418/500 [00:27<00:05, 15.59it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.39it/s] 84%|████████▍ | 422/500 [00:27<00:05, 15.54it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.58it/s] 85%|████████▌ | 426/500 [00:28<00:04, 15.46it/s] 86%|████████▌ | 428/500 [00:28<00:04, 15.71it/s] 86%|████████▌ | 430/500 [00:28<00:04, 15.92it/s] 86%|████████▋ | 432/500 [00:28<00:04, 16.05it/s] 87%|████████▋ | 434/500 [00:28<00:04, 16.22it/s] 87%|████████▋ | 436/500 [00:28<00:03, 16.27it/s] 88%|████████▊ | 438/500 [00:28<00:03, 16.30it/s] 88%|████████▊ | 440/500 [00:28<00:03, 15.41it/s] 88%|████████▊ | 442/500 [00:29<00:03, 15.58it/s] 89%|████████▉ | 444/500 [00:29<00:03, 15.75it/s] 89%|████████▉ | 446/500 [00:29<00:03, 15.78it/s] 90%|████████▉ | 448/500 [00:29<00:03, 15.97it/s] 90%|█████████ | 450/500 [00:29<00:03, 16.09it/s] 90%|█████████ | 452/500 [00:29<00:02, 16.20it/s] 91%|█████████ | 454/500 [00:29<00:02, 16.25it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.29it/s] 92%|█████████▏| 458/500 [00:30<00:02, 16.26it/s] 92%|█████████▏| 460/500 [00:30<00:02, 16.12it/s] 92%|█████████▏| 462/500 [00:30<00:02, 16.09it/s] 93%|█████████▎| 464/500 [00:30<00:02, 16.03it/s] 93%|█████████▎| 466/500 [00:30<00:02, 16.16it/s] 94%|█████████▎| 468/500 [00:30<00:01, 16.10it/s] 94%|█████████▍| 470/500 [00:30<00:01, 16.18it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.23it/s] 95%|█████████▍| 474/500 [00:31<00:01, 16.30it/s] 95%|█████████▌| 476/500 [00:31<00:01, 16.33it/s] 96%|█████████▌| 478/500 [00:31<00:01, 16.18it/s] 96%|█████████▌| 480/500 [00:31<00:01, 16.29it/s] 96%|█████████▋| 482/500 [00:31<00:01, 16.22it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.15it/s] 97%|█████████▋| 486/500 [00:31<00:00, 16.12it/s] 98%|█████████▊| 488/500 [00:31<00:00, 16.09it/s] 98%|█████████▊| 490/500 [00:32<00:00, 16.10it/s] 98%|█████████▊| 492/500 [00:32<00:00, 16.24it/s] 99%|█████████▉| 494/500 [00:32<00:00, 16.33it/s] 99%|█████████▉| 496/500 [00:32<00:00, 16.41it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 16.40it/s]100%|██████████| 500/500 [00:32<00:00, 16.45it/s]100%|██████████| 500/500 [00:32<00:00, 15.32it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  14
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:12,  6.16s/it]  1%|          | 3/500 [00:06<13:37,  1.65s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  2%|▏         | 12/500 [00:13<08:49,  1.08s/it]  3%|▎         | 14/500 [00:13<05:48,  1.39it/s]  3%|▎         | 16/500 [00:13<03:59,  2.02it/s]  4%|▎         | 18/500 [00:13<02:50,  2.82it/s]  4%|▍         | 20/500 [00:13<02:06,  3.78it/s]  4%|▍         | 22/500 [00:19<09:18,  1.17s/it]  5%|▍         | 24/500 [00:20<06:37,  1.20it/s]  5%|▌         | 26/500 [00:20<04:47,  1.65it/s]  6%|▌         | 28/500 [00:20<03:31,  2.23it/s]  6%|▌         | 30/500 [00:20<02:38,  2.96it/s]  6%|▋         | 32/500 [00:27<09:18,  1.19s/it]  7%|▋         | 34/500 [00:27<06:37,  1.17it/s]  7%|▋         | 36/500 [00:27<04:45,  1.62it/s]  8%|▊         | 38/500 [00:27<03:28,  2.22it/s]  8%|▊         | 40/500 [00:27<02:33,  2.99it/s]  8%|▊         | 42/500 [00:33<09:01,  1.18s/it]  9%|▉         | 44/500 [00:34<06:29,  1.17it/s]  9%|▉         | 46/500 [00:34<04:43,  1.60it/s] 10%|▉         | 48/500 [00:34<03:29,  2.16it/s] 10%|█         | 50/500 [00:34<02:37,  2.86it/s] 10%|█         | 52/500 [00:40<08:55,  1.20s/it] 11%|█         | 54/500 [00:41<06:22,  1.17it/s] 11%|█         | 56/500 [00:41<04:37,  1.60it/s] 12%|█▏        | 58/500 [00:41<03:22,  2.19it/s] 12%|█▏        | 60/500 [00:41<02:29,  2.94it/s] 12%|█▏        | 62/500 [00:47<08:37,  1.18s/it] 13%|█▎        | 64/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 66/500 [00:48<04:25,  1.63it/s] 14%|█▎        | 68/500 [00:48<03:13,  2.23it/s]Epoch:  1  	Training Loss: 0.2712118625640869
Test Loss:  0.023264247924089432
Valid Loss:  0.027567286044359207
Epoch:  2  	Training Loss: 0.02807679772377014
Test Loss:  0.012339983135461807
Valid Loss:  0.016420695930719376
Epoch:  3  	Training Loss: 0.01840895600616932
Test Loss:  0.010187150910496712
Valid Loss:  0.013738892041146755
Epoch:  4  	Training Loss: 0.015355083160102367
Test Loss:  0.008524898439645767
Valid Loss:  0.011622813530266285
Epoch:  5  	Training Loss: 0.01286864373832941
Test Loss:  0.007173012010753155
Valid Loss:  0.009893043898046017
Epoch:  6  	Training Loss: 0.010836378671228886
Test Loss:  0.006073201075196266
Valid Loss:  0.00847789365798235
Epoch:  7  	Training Loss: 0.009175712242722511
Test Loss:  0.005178867839276791
Valid Loss:  0.007321539800614119
Epoch:  8  	Training Loss: 0.007820541970431805
Test Loss:  0.004450025036931038
Valid Loss:  0.0063868556171655655
Epoch:  9  	Training Loss: 0.006734616123139858
Test Loss:  0.0038416446186602116
Valid Loss:  0.005602508783340454
Epoch:  10  	Training Loss: 0.005842696875333786
Test Loss:  0.003381546586751938
Valid Loss:  0.004986662417650223
Epoch:  11  	Training Loss: 0.005112179554998875
Test Loss:  0.0029952083714306355
Valid Loss:  0.004470823332667351
Epoch:  12  	Training Loss: 0.0045113638043403625
Test Loss:  0.0026844572275877
Valid Loss:  0.0040517705492675304
Epoch:  13  	Training Loss: 0.004019067622721195
Test Loss:  0.002425007289275527
Valid Loss:  0.0037040046881884336
Epoch:  14  	Training Loss: 0.0036193937994539738
Test Loss:  0.0022156366612762213
Valid Loss:  0.0034178842324763536
Epoch:  15  	Training Loss: 0.0032905228435993195
Test Loss:  0.0020495401695370674
Valid Loss:  0.003184364642947912
Epoch:  16  	Training Loss: 0.003019024385139346
Test Loss:  0.0019165583653375506
Valid Loss:  0.0029927848372608423
Epoch:  17  	Training Loss: 0.0027948219794780016
Test Loss:  0.0018052137456834316
Valid Loss:  0.002832617610692978
Epoch:  18  	Training Loss: 0.002610044553875923
Test Loss:  0.001714831218123436
Valid Loss:  0.002701300196349621
Epoch:  19  	Training Loss: 0.0024593439884483814
Test Loss:  0.0016428285744041204
Valid Loss:  0.002593187615275383
Epoch:  20  	Training Loss: 0.0023348722606897354
Test Loss:  0.001583677250891924
Valid Loss:  0.002502674236893654
Epoch:  21  	Training Loss: 0.002231855411082506
Test Loss:  0.0015373167116194963
Valid Loss:  0.0024283500388264656
Epoch:  22  	Training Loss: 0.002146410057321191
Test Loss:  0.0014997260877862573
Valid Loss:  0.0023663020692765713
Epoch:  23  	Training Loss: 0.0020754514262080193
Test Loss:  0.0014691940741613507
Valid Loss:  0.002314314479008317
Epoch:  24  	Training Loss: 0.0020164805464446545
Test Loss:  0.0014456131029874086
Valid Loss:  0.0022715111263096333
Epoch:  25  	Training Loss: 0.0019674175418913364
Test Loss:  0.0014259692979976535
Valid Loss:  0.00223513413220644
Epoch:  26  	Training Loss: 0.001926658907905221
Test Loss:  0.0014127653557807207
Valid Loss:  0.002206399803981185
Epoch:  27  	Training Loss: 0.001892800908535719
Test Loss:  0.0014005490811541677
Valid Loss:  0.0021811125334352255
Epoch:  28  	Training Loss: 0.0018646569224074483
Test Loss:  0.0013918733457103372
Valid Loss:  0.002160547534003854
Epoch:  29  	Training Loss: 0.0018412466160953045
Test Loss:  0.0013845555949956179
Valid Loss:  0.002142892684787512
Epoch:  30  	Training Loss: 0.0018217710312455893
Test Loss:  0.0013798426371067762
Valid Loss:  0.0021286988630890846
Epoch:  31  	Training Loss: 0.00180557812564075
Test Loss:  0.0013756330590695143
Valid Loss:  0.0021163057535886765
Epoch:  32  	Training Loss: 0.0017920993268489838
Test Loss:  0.0013722162693738937
Valid Loss:  0.00210562814027071
Epoch:  33  	Training Loss: 0.0017808249685913324
Test Loss:  0.0013695558300241828
Valid Loss:  0.0020964564755558968
Epoch:  34  	Training Loss: 0.0017713757697492838
Test Loss:  0.0013676104135811329
Valid Loss:  0.002088625216856599
Epoch:  35  	Training Loss: 0.0017634249525144696
Test Loss:  0.0013662307756021619
Valid Loss:  0.0020819026976823807
Epoch:  36  	Training Loss: 0.0017567728646099567
Test Loss:  0.0013668898027390242
Valid Loss:  0.0020772935822606087
Epoch:  37  	Training Loss: 0.001751232659444213
Test Loss:  0.001367846387438476
Valid Loss:  0.002073576906695962
Epoch:  38  	Training Loss: 0.0017466326244175434
Test Loss:  0.0013686190359294415
Valid Loss:  0.0020703254267573357
Epoch:  39  	Training Loss: 0.0017428152495995164
Test Loss:  0.0013689389452338219
Valid Loss:  0.002067256486043334
Epoch:  40  	Training Loss: 0.001739630475640297
Test Loss:  0.001371158054098487
Valid Loss:  0.0020657763816416264
Epoch:  41  	Training Loss: 0.0017370027489960194
Test Loss:  0.0013699957635253668
Valid Loss:  0.00206254911608994
Epoch:  42  	Training Loss: 0.001734802033752203
Test Loss:  0.0013718417612835765
Valid Loss:  0.0020614583045244217
Epoch:  43  	Training Loss: 0.0017329721013084054
Test Loss:  0.0013723220909014344
Valid Loss:  0.002059797989204526
Epoch:  44  	Training Loss: 0.0017314488068223
Test Loss:  0.0013727378100156784
Valid Loss:  0.002058309968560934
Epoch:  45  	Training Loss: 0.0017301751067861915
Test Loss:  0.0013731700601056218
Valid Loss:  0.0020570072811096907
Epoch:  46  	Training Loss: 0.0017291064141318202
Test Loss:  0.0013736083637923002
Valid Loss:  0.002055884338915348
Epoch:  47  	Training Loss: 0.0017282057087868452
Test Loss:  0.0013741458533331752
Valid Loss:  0.0020549502223730087
Epoch:  48  	Training Loss: 0.001727455179207027
Test Loss:  0.001375983003526926
Valid Loss:  0.0020549744367599487
Epoch:  49  	Training Loss: 0.0017268224619328976
Test Loss:  0.0013751874212175608
Valid Loss:  0.002053484320640564
Epoch:  50  	Training Loss: 0.001726297428831458
Test Loss:  0.001377043779939413
Valid Loss:  0.0020537259988486767
Epoch:  51  	Training Loss: 0.0017258551670238376
Test Loss:  0.001377372071146965
Valid Loss:  0.0020531355403363705
Epoch:  52  	Training Loss: 0.0017254820559173822
Test Loss:  0.001377871842123568
Valid Loss:  0.002052740193903446
Epoch:  53  	Training Loss: 0.0017251712270081043
Test Loss:  0.0013782549649477005
Valid Loss:  0.002052329946309328
Epoch:  54  	Training Loss: 0.0017249048687517643
Test Loss:  0.0013786007184535265
Valid Loss:  0.0020519504323601723
Epoch:  55  	Training Loss: 0.0017246820498257875
Test Loss:  0.0013789180666208267
Valid Loss:  0.002051612827926874
Epoch:  56  	Training Loss: 0.001724489382468164
Test Loss:  0.0013792108511552215
Valid Loss:  0.0020513110794126987
Epoch:  57  	Training Loss: 0.001724321860820055
Test Loss:  0.0013794837286695838
Valid Loss:  0.002051024232059717
Epoch:  58  	Training Loss: 0.0017241775058209896
Test Loss:  0.0013797299470752478
Valid Loss:  0.0020507704466581345
Epoch:  59  	Training Loss: 0.001724053523503244
Test Loss:  0.0013799567241221666
Valid Loss:  0.0020505227148532867
Epoch:  60  	Training Loss: 0.001723939087241888
Test Loss:  0.0013801692984998226
Valid Loss:  0.0020503015257418156
Epoch:  61  	Training Loss: 0.00172384362667799
Test Loss:  0.0013803578913211823
Valid Loss:  0.0020500842947512865
Epoch:  62  	Training Loss: 0.001723757479339838
Test Loss:  0.0013805241324007511
Valid Loss:  0.0020498959347605705
Epoch:  63  	Training Loss: 0.001723677502013743
Test Loss:  0.0013806810602545738
Valid Loss:  0.0020497427321970463
Epoch:  64  	Training Loss: 0.0017236025305464864
Test Loss:  0.0013808271614834666
Valid Loss:  0.0020496281795203686
Epoch:  65  	Training Loss: 0.00172354094684124
Test Loss:  0.0013816419523209333
Valid Loss:  0.0020499108359217644
Epoch:  66  	Training Loss: 0.001723484368994832
Test Loss:  0.0013815423008054495
Valid Loss:  0.0020496868528425694
Epoch:  67  	Training Loss: 0.0017234404804185033
Test Loss:  0.0013826873619109392
Valid Loss:  0.0020501764956861734
Epoch:  68  	Training Loss: 0.0017234018305316567
Test Loss:  0.0013825518544763327
Valid Loss:  0.0020499522797763348
Epoch:  69  	Training Loss: 0.0017233651597052813
Test Loss:  0.001381913316436112
Valid Loss:  0.002049473114311695
Epoch:  70  	Training Loss: 0.0017233318649232388
Test Loss:  0.0013832045951858163
 14%|█▍        | 70/500 [00:48<02:23,  2.99it/s] 14%|█▍        | 72/500 [00:54<08:17,  1.16s/it] 15%|█▍        | 74/500 [00:54<05:58,  1.19it/s] 15%|█▌        | 76/500 [00:54<04:20,  1.63it/s] 16%|█▌        | 78/500 [00:54<03:12,  2.19it/s] 16%|█▌        | 80/500 [00:55<02:25,  2.90it/s] 16%|█▋        | 82/500 [01:01<08:18,  1.19s/it] 17%|█▋        | 84/500 [01:01<05:55,  1.17it/s] 17%|█▋        | 86/500 [01:01<04:15,  1.62it/s] 18%|█▊        | 88/500 [01:01<03:06,  2.21it/s] 18%|█▊        | 90/500 [01:02<02:17,  2.97it/s] 18%|█▊        | 92/500 [01:08<08:04,  1.19s/it] 19%|█▉        | 94/500 [01:08<05:45,  1.18it/s] 19%|█▉        | 96/500 [01:08<04:08,  1.63it/s] 20%|█▉        | 98/500 [01:08<03:00,  2.22it/s] 20%|██        | 100/500 [01:08<02:13,  2.99it/s] 20%|██        | 102/500 [01:15<07:43,  1.17s/it] 21%|██        | 104/500 [01:15<05:30,  1.20it/s] 21%|██        | 106/500 [01:15<03:58,  1.65it/s] 22%|██▏       | 108/500 [01:15<02:54,  2.25it/s] 22%|██▏       | 110/500 [01:15<02:08,  3.03it/s] 22%|██▏       | 112/500 [01:21<07:29,  1.16s/it] 23%|██▎       | 114/500 [01:22<05:23,  1.19it/s] 23%|██▎       | 116/500 [01:22<03:55,  1.63it/s] 24%|██▎       | 118/500 [01:22<02:53,  2.20it/s] 24%|██▍       | 120/500 [01:22<02:08,  2.96it/s] 24%|██▍       | 122/500 [01:28<07:18,  1.16s/it] 25%|██▍       | 124/500 [01:28<05:12,  1.20it/s] 25%|██▌       | 126/500 [01:28<03:45,  1.66it/s] 26%|██▌       | 128/500 [01:29<02:43,  2.27it/s] 26%|██▌       | 130/500 [01:29<02:01,  3.05it/s] 26%|██▋       | 132/500 [01:35<07:13,  1.18s/it] 27%|██▋       | 134/500 [01:35<05:09,  1.18it/s] 27%|██▋       | 136/500 [01:41<09:22,  1.55s/it]Valid Loss:  0.002050087321549654
Epoch:  71  	Training Loss: 0.0017233049729838967
Test Loss:  0.0013828942319378257
Valid Loss:  0.002049790695309639
Epoch:  72  	Training Loss: 0.0017232790123671293
Test Loss:  0.0013832834083586931
Valid Loss:  0.0020499068778008223
Epoch:  73  	Training Loss: 0.0017232561949640512
Test Loss:  0.0013834949349984527
Valid Loss:  0.002049925271421671
Epoch:  74  	Training Loss: 0.0017232336103916168
Test Loss:  0.0013824797933921218
Valid Loss:  0.0020492677576839924
Epoch:  75  	Training Loss: 0.0017232183599844575
Test Loss:  0.0013835991267114878
Valid Loss:  0.002049837028607726
Epoch:  76  	Training Loss: 0.0017231968231499195
Test Loss:  0.0013836842263117433
Valid Loss:  0.002049799542874098
Epoch:  77  	Training Loss: 0.0017231798265129328
Test Loss:  0.001383741619065404
Valid Loss:  0.0020497615914791822
Epoch:  78  	Training Loss: 0.0017231653910130262
Test Loss:  0.0013837208971381187
Valid Loss:  0.0020496833603829145
Epoch:  79  	Training Loss: 0.001723152119666338
Test Loss:  0.0013834740966558456
Valid Loss:  0.0020494924392551184
Epoch:  80  	Training Loss: 0.0017231353558599949
Test Loss:  0.0013838682789355516
Valid Loss:  0.0020496598444879055
Epoch:  81  	Training Loss: 0.0017231233650818467
Test Loss:  0.0013837837614119053
Valid Loss:  0.0020495669450610876
Epoch:  82  	Training Loss: 0.001723109744489193
Test Loss:  0.001383936614729464
Valid Loss:  0.0020496074575930834
Epoch:  83  	Training Loss: 0.0017230988014489412
Test Loss:  0.0013839693274348974
Valid Loss:  0.0020495792850852013
Epoch:  84  	Training Loss: 0.0017230892553925514
Test Loss:  0.0013839956372976303
Valid Loss:  0.0020495611242949963
Epoch:  85  	Training Loss: 0.001723078778013587
Test Loss:  0.001384011935442686
Valid Loss:  0.002049530390650034
Epoch:  86  	Training Loss: 0.00172307004686445
Test Loss:  0.0013836260186508298
Valid Loss:  0.0020492866169661283
Epoch:  87  	Training Loss: 0.0017230617813766003
Test Loss:  0.001383353490382433
Valid Loss:  0.00204911339096725
Epoch:  88  	Training Loss: 0.0017230524681508541
Test Loss:  0.0013840354513376951
Valid Loss:  0.002049481961876154
Epoch:  89  	Training Loss: 0.001723042456433177
Test Loss:  0.0013840680476278067
Valid Loss:  0.0020494756754487753
Epoch:  90  	Training Loss: 0.00172303372528404
Test Loss:  0.001384080620482564
Valid Loss:  0.0020494572818279266
Epoch:  91  	Training Loss: 0.001723025692626834
Test Loss:  0.0013840972678735852
Valid Loss:  0.0020494384225457907
Epoch:  92  	Training Loss: 0.001723016845062375
Test Loss:  0.0013841054169461131
Valid Loss:  0.002049424685537815
Epoch:  93  	Training Loss: 0.0017230070661753416
Test Loss:  0.0013841188047081232
Valid Loss:  0.002049410482868552
Epoch:  94  	Training Loss: 0.001723001478239894
Test Loss:  0.001384131028316915
Valid Loss:  0.002049393020570278
Epoch:  95  	Training Loss: 0.0017229970544576645
Test Loss:  0.0013841353356838226
Valid Loss:  0.0020493855699896812
Epoch:  96  	Training Loss: 0.0017229863442480564
Test Loss:  0.0013841455802321434
Valid Loss:  0.002049372997134924
Epoch:  97  	Training Loss: 0.0017229811055585742
Test Loss:  0.0013841574545949697
Valid Loss:  0.0020493550691753626
Epoch:  98  	Training Loss: 0.0017229743534699082
Test Loss:  0.001384154660627246
Valid Loss:  0.002049348084256053
Epoch:  99  	Training Loss: 0.0017229665536433458
Test Loss:  0.00138417212292552
Valid Loss:  0.0020493369083851576
Epoch:  100  	Training Loss: 0.0017229614313691854
Test Loss:  0.0013841737527400255
Valid Loss:  0.002049323869869113
Epoch:  101  	Training Loss: 0.0017229549121111631
Test Loss:  0.001384181552566588
Valid Loss:  0.002049312461167574
Epoch:  102  	Training Loss: 0.0017229504883289337
Test Loss:  0.0013841863255947828
Valid Loss:  0.0020492998883128166
Epoch:  103  	Training Loss: 0.0017229437362402678
Test Loss:  0.0013841110048815608
Valid Loss:  0.002049253089353442
Epoch:  104  	Training Loss: 0.001722937449812889
Test Loss:  0.0013841880718246102
Valid Loss:  0.002049283590167761
Epoch:  105  	Training Loss: 0.001722931396216154
Test Loss:  0.0013841920299455523
Valid Loss:  0.002049271482974291
Epoch:  106  	Training Loss: 0.0017229270888492465
Test Loss:  0.0013841961044818163
Valid Loss:  0.0020492631010711193
Epoch:  107  	Training Loss: 0.0017229232471436262
Test Loss:  0.0013841947074979544
Valid Loss:  0.0020492528565227985
Epoch:  108  	Training Loss: 0.0017229149816557765
Test Loss:  0.0013842001790180802
Valid Loss:  0.002049241214990616
Epoch:  109  	Training Loss: 0.0017229097429662943
Test Loss:  0.001384200295433402
Valid Loss:  0.0020492388866841793
Epoch:  110  	Training Loss: 0.0017229067161679268
Test Loss:  0.0013842020416632295
Valid Loss:  0.0020492300391197205
Epoch:  111  	Training Loss: 0.0017229006625711918
Test Loss:  0.0013842058833688498
Valid Loss:  0.002049220260232687
Epoch:  112  	Training Loss: 0.0017228933284059167
Test Loss:  0.0013842085609212518
Valid Loss:  0.0020492207258939743
Epoch:  113  	Training Loss: 0.001722889021039009
Test Loss:  0.00138420844450593
Valid Loss:  0.002049213508144021
Epoch:  114  	Training Loss: 0.0017228822689503431
Test Loss:  0.0013842139160260558
Valid Loss:  0.002049204893410206
Epoch:  115  	Training Loss: 0.0017228793585672975
Test Loss:  0.0013842107728123665
Valid Loss:  0.0020492069888859987
Epoch:  116  	Training Loss: 0.0017228726064786315
Test Loss:  0.0013842182233929634
Valid Loss:  0.0020491965115070343
Epoch:  117  	Training Loss: 0.0017228701617568731
Test Loss:  0.001384219154715538
Valid Loss:  0.002049196045845747
Epoch:  118  	Training Loss: 0.0017228666692972183
Test Loss:  0.001383855240419507
Valid Loss:  0.002048994181677699
Epoch:  119  	Training Loss: 0.001722862245514989
Test Loss:  0.0013842037878930569
Valid Loss:  0.0020491876639425755
Epoch:  120  	Training Loss: 0.001722861547023058
Test Loss:  0.0013842154294252396
Valid Loss:  0.002049193251878023
Epoch:  121  	Training Loss: 0.0017228566575795412
Test Loss:  0.0013842153130099177
Valid Loss:  0.0020491962786763906
Epoch:  122  	Training Loss: 0.0017228552605956793
Test Loss:  0.0013842167099937797
Valid Loss:  0.002049186732620001
Epoch:  123  	Training Loss: 0.0017228557262569666
Test Loss:  0.0013842200860381126
Valid Loss:  0.0020491827744990587
Epoch:  124  	Training Loss: 0.0017228520009666681
Test Loss:  0.0013842233456671238
Valid Loss:  0.0020491809118539095
Epoch:  125  	Training Loss: 0.0017228464130312204
Test Loss:  0.0013842203188687563
Valid Loss:  0.0020491816103458405
Epoch:  126  	Training Loss: 0.001722845365293324
Test Loss:  0.0013842228800058365
Valid Loss:  0.0020491762552410364
Epoch:  127  	Training Loss: 0.001722840708680451
Test Loss:  0.0013842228800058365
Valid Loss:  0.0020491774193942547
Epoch:  128  	Training Loss: 0.0017228408250957727
Test Loss:  0.0013842242769896984
Valid Loss:  0.0020491727627813816
Epoch:  129  	Training Loss: 0.001722837914712727
Test Loss:  0.0013842267217114568
Valid Loss:  0.0020491727627813816
Epoch:  130  	Training Loss: 0.001722837216220796
Test Loss:  0.0013842233456671238
Valid Loss:  0.0020491634495556355
Epoch:  131  	Training Loss: 0.001722835237160325
Test Loss:  0.0013842270709574223
Valid Loss:  0.002049167873337865
Epoch:  132  	Training Loss: 0.0017228292999789119
Test Loss:  0.0013842309126630425
Valid Loss:  0.0020491615869104862
Epoch:  133  	Training Loss: 0.0017228306969627738
Test Loss:  0.0013842233456671238
Valid Loss:  0.002049162518233061
Epoch:  134  	Training Loss: 0.0017228256911039352
Test Loss:  0.001384229282848537
Valid Loss:  0.002049161121249199
Epoch:  135  	Training Loss: 0.001722824526950717
Test Loss:  0.001384225906804204
Valid Loss:  0.0020491578616201878
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.0017228221986442804
Test Loss:  0.0013842282351106405
Valid Loss:  0.002049159724265337
Epoch:  137  	Training Loss: 0.0017228228971362114
Test Loss:  0.0013842295156791806
Valid Loss:  0.0020491578616201878
Epoch:  138  	Training Loss: 0.0017228176584467292
Test Loss:  0.0013842293992638588
 28%|██▊       | 138/500 [01:42<06:38,  1.10s/it] 28%|██▊       | 140/500 [01:42<04:44,  1.26it/s] 28%|██▊       | 142/500 [01:48<08:54,  1.49s/it] 29%|██▉       | 144/500 [01:48<06:19,  1.06s/it] 29%|██▉       | 146/500 [01:54<09:54,  1.68s/it] 30%|██▉       | 148/500 [01:54<07:00,  1.19s/it] 30%|███       | 150/500 [01:55<04:59,  1.17it/s] 30%|███       | 152/500 [02:01<08:56,  1.54s/it] 31%|███       | 154/500 [02:01<06:19,  1.10s/it] 31%|███       | 156/500 [02:07<09:45,  1.70s/it] 32%|███▏      | 158/500 [02:07<06:54,  1.21s/it] 32%|███▏      | 160/500 [02:08<04:54,  1.15it/s] 32%|███▏      | 162/500 [02:14<08:47,  1.56s/it] 33%|███▎      | 164/500 [02:14<06:15,  1.12s/it] 33%|███▎      | 165/500 [02:20<11:25,  2.05s/it] 33%|███▎      | 167/500 [02:21<07:41,  1.39s/it] 34%|███▍      | 169/500 [02:21<05:19,  1.04it/s] 34%|███▍      | 171/500 [02:27<09:05,  1.66s/it] 35%|███▍      | 173/500 [02:27<06:20,  1.16s/it] 35%|███▌      | 175/500 [02:33<09:36,  1.77s/it] 35%|███▌      | 177/500 [02:34<06:45,  1.26s/it] 36%|███▌      | 179/500 [02:34<04:46,  1.12it/s] 36%|███▌      | 181/500 [02:40<08:20,  1.57s/it] 37%|███▋      | 183/500 [02:40<05:55,  1.12s/it] 37%|███▋      | 185/500 [02:46<09:04,  1.73s/it] 37%|███▋      | 187/500 [02:47<06:25,  1.23s/it] 38%|███▊      | 189/500 [02:47<04:34,  1.13it/s] 38%|███▊      | 190/500 [02:53<09:25,  1.82s/it] 38%|███▊      | 191/500 [02:59<13:59,  2.72s/it] 39%|███▊      | 193/500 [02:59<08:57,  1.75s/it] 39%|███▉      | 195/500 [02:59<05:57,  1.17s/it] 39%|███▉      | 197/500 [03:00<04:05,  1.24it/s] 40%|███▉      | 199/500 [03:00<02:52,  1.75it/s]Valid Loss:  0.0020491555333137512
Epoch:  139  	Training Loss: 0.0017228194046765566
Test Loss:  0.001384230563417077
Valid Loss:  0.0020491534378379583
Epoch:  140  	Training Loss: 0.0017228155629709363
Test Loss:  0.0013842284679412842
Valid Loss:  0.0020491527393460274
Epoch:  141  	Training Loss: 0.0017228148644790053
Test Loss:  0.0013842289336025715
Valid Loss:  0.0020491541363298893
Epoch:  142  	Training Loss: 0.0017228159122169018
Test Loss:  0.0013842256739735603
Valid Loss:  0.0020491494797170162
Epoch:  143  	Training Loss: 0.0017228121869266033
Test Loss:  0.0013842264888808131
Valid Loss:  0.0020491541363298893
Epoch:  144  	Training Loss: 0.0017228128854185343
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491555333137512
Epoch:  145  	Training Loss: 0.0017228128854185343
Test Loss:  0.0013842325424775481
Valid Loss:  0.0020491518080234528
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.0017228128854185343
Test Loss:  0.0013842283515259624
Valid Loss:  0.0020491494797170162
Epoch:  147  	Training Loss: 0.0017228126525878906
Test Loss:  0.0013842284679412842
Valid Loss:  0.0020491492468863726
Epoch:  148  	Training Loss: 0.0017228126525878906
Test Loss:  0.0013842300977557898
Valid Loss:  0.002049150876700878
Epoch:  149  	Training Loss: 0.001722812419757247
Test Loss:  0.001384227303788066
Valid Loss:  0.002049149014055729
Epoch:  150  	Training Loss: 0.001722811022773385
Test Loss:  0.0013842280022799969
Valid Loss:  0.00204914971254766
Epoch:  151  	Training Loss: 0.0017228096257895231
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491480827331543
Epoch:  152  	Training Loss: 0.0017228114884346724
Test Loss:  0.0013842262560501695
Valid Loss:  0.0020491513423621655
Epoch:  153  	Training Loss: 0.001722810440696776
Test Loss:  0.0013842269545421004
Valid Loss:  0.0020491480827331543
Epoch:  154  	Training Loss: 0.0017228112556040287
Test Loss:  0.0013842262560501695
Valid Loss:  0.0020491471514105797
Epoch:  155  	Training Loss: 0.0017228107899427414
Test Loss:  0.001384227187372744
Valid Loss:  0.0020491527393460274
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.0017228078795596957
Test Loss:  0.0013842281186953187
Valid Loss:  0.0020491494797170162
Epoch:  157  	Training Loss: 0.0017228074138984084
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491506438702345
Epoch:  158  	Training Loss: 0.0017228061333298683
Test Loss:  0.0013842276530340314
Valid Loss:  0.0020491471514105797
Epoch:  159  	Training Loss: 0.0017228061333298683
Test Loss:  0.0013842287007719278
Valid Loss:  0.0020491457544267178
Epoch:  160  	Training Loss: 0.001722807763144374
Test Loss:  0.0013842287007719278
Valid Loss:  0.0020491471514105797
Epoch:  161  	Training Loss: 0.001722806948237121
Test Loss:  0.0013842277694493532
Valid Loss:  0.002049145521596074
Epoch:  162  	Training Loss: 0.0017228081123903394
Test Loss:  0.0013842261396348476
Valid Loss:  0.002049146220088005
Epoch:  163  	Training Loss: 0.0017228079959750175
Test Loss:  0.001384227303788066
Valid Loss:  0.0020491464529186487
Epoch:  164  	Training Loss: 0.0017228071810677648
Test Loss:  0.001384226605296135
Valid Loss:  0.0020491466857492924
Epoch:  165  	Training Loss: 0.0017228074138984084
Test Loss:  0.0013842268381267786
Valid Loss:  0.0020491471514105797
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.0017228062497451901
Test Loss:  0.0013842275366187096
Valid Loss:  0.0020491457544267178
Epoch:  167  	Training Loss: 0.001722806366160512
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491480827331543
Epoch:  168  	Training Loss: 0.001722806366160512
Test Loss:  0.0013842307962477207
Valid Loss:  0.0020491494797170162
Epoch:  169  	Training Loss: 0.0017228057840839028
Test Loss:  0.0013842280022799969
Valid Loss:  0.0020491452887654305
Epoch:  170  	Training Loss: 0.0017228054348379374
Test Loss:  0.0013842283515259624
Valid Loss:  0.002049143658950925
Epoch:  171  	Training Loss: 0.00172280496917665
Test Loss:  0.0013842323096469045
Valid Loss:  0.0020491457544267178
Epoch:  172  	Training Loss: 0.0017228047363460064
Test Loss:  0.0013842331245541573
Valid Loss:  0.002049146220088005
Epoch:  173  	Training Loss: 0.0017228050855919719
Test Loss:  0.0013842297485098243
Valid Loss:  0.0020491457544267178
Epoch:  174  	Training Loss: 0.0017228054348379374
Test Loss:  0.001384227885864675
Valid Loss:  0.0020491480827331543
Epoch:  175  	Training Loss: 0.0017228053184226155
Test Loss:  0.001384230563417077
Valid Loss:  0.0020491459872573614
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.0017228052020072937
Test Loss:  0.0013842300977557898
Valid Loss:  0.0020491466857492924
Epoch:  177  	Training Loss: 0.0017228053184226155
Test Loss:  0.0013842300977557898
Valid Loss:  0.0020491466857492924
Epoch:  178  	Training Loss: 0.0017228050855919719
Test Loss:  0.001384231261909008
Valid Loss:  0.0020491466857492924
Epoch:  179  	Training Loss: 0.00172280496917665
Test Loss:  0.0013842321932315826
Valid Loss:  0.0020491464529186487
Epoch:  180  	Training Loss: 0.0017228060169145465
Test Loss:  0.001384231261909008
Valid Loss:  0.002049146220088005
Epoch:  181  	Training Loss: 0.0017228052020072937
Test Loss:  0.001384231261909008
Valid Loss:  0.0020491452887654305
Epoch:  182  	Training Loss: 0.001722805667668581
Test Loss:  0.001384230563417077
Valid Loss:  0.002049144357442856
Epoch:  183  	Training Loss: 0.0017228047363460064
Test Loss:  0.001384229864925146
Valid Loss:  0.0020491427276283503
Epoch:  184  	Training Loss: 0.00172280496917665
Test Loss:  0.0013842289336025715
Valid Loss:  0.0020491424947977066
Epoch:  185  	Training Loss: 0.0017228046199306846
Test Loss:  0.0013842284679412842
Valid Loss:  0.002049142960458994
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.0017228047363460064
Test Loss:  0.001384228584356606
Valid Loss:  0.0020491424947977066
Epoch:  187  	Training Loss: 0.0017228047363460064
Test Loss:  0.0013842284679412842
Valid Loss:  0.002049142261967063
Epoch:  188  	Training Loss: 0.00172280496917665
Test Loss:  0.0013842289336025715
Valid Loss:  0.0020491420291364193
Epoch:  189  	Training Loss: 0.0017228052020072937
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491424947977066
Epoch:  190  	Training Loss: 0.00172280496917665
Test Loss:  0.0013842296320945024
Valid Loss:  0.002049143658950925
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.0017228046199306846
Test Loss:  0.001384230563417077
Valid Loss:  0.0020491438917815685
Epoch:  192  	Training Loss: 0.0017228046199306846
Test Loss:  0.0013842303305864334
Valid Loss:  0.002049145055934787
Epoch:  193  	Training Loss: 0.0017228045035153627
Test Loss:  0.0013842307962477207
Valid Loss:  0.002049144823104143
Epoch:  194  	Training Loss: 0.0017228040378540754
Test Loss:  0.0013842309126630425
Valid Loss:  0.0020491452887654305
Epoch:  195  	Training Loss: 0.0017228040378540754
Test Loss:  0.001384231261909008
Valid Loss:  0.002049146220088005
Epoch:  196  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842314947396517
Valid Loss:  0.002049146220088005
Epoch:  197  	Training Loss: 0.0017228040378540754
Test Loss:  0.0013842310290783644
Valid Loss:  0.0020491459872573614
Epoch:  198  	Training Loss: 0.0017228040378540754
Test Loss:  0.0013842306798323989
Valid Loss:  0.002049145521596074
Epoch:  199  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842303305864334
Valid Loss:  0.0020491452887654305
Epoch:  200  	Training Loss: 0.001722804270684719
Test Loss:  0.001384230563417077
Valid Loss:  0.002049145521596074
 40%|███▉      | 199/500 [03:11<02:52,  1.75it/s] 40%|████      | 201/500 [03:12<11:39,  2.34s/it] 41%|████      | 203/500 [03:12<08:06,  1.64s/it] 41%|████      | 205/500 [03:12<05:40,  1.16s/it] 41%|████▏     | 207/500 [03:13<04:01,  1.21it/s] 42%|████▏     | 209/500 [03:13<02:52,  1.69it/s] 42%|████▏     | 211/500 [03:25<11:06,  2.31s/it] 43%|████▎     | 213/500 [03:25<07:48,  1.63s/it] 43%|████▎     | 215/500 [03:32<09:56,  2.09s/it] 43%|████▎     | 217/500 [03:32<07:01,  1.49s/it] 44%|████▍     | 219/500 [03:32<04:58,  1.06s/it] 44%|████▍     | 221/500 [03:44<12:08,  2.61s/it] 45%|████▍     | 223/500 [03:45<08:32,  1.85s/it] 45%|████▌     | 225/500 [03:51<10:16,  2.24s/it] 45%|████▌     | 227/500 [03:51<07:13,  1.59s/it] 46%|████▌     | 229/500 [03:51<05:06,  1.13s/it] 46%|████▌     | 231/500 [04:04<11:53,  2.65s/it] 47%|████▋     | 233/500 [04:04<08:21,  1.88s/it] 47%|████▋     | 235/500 [04:10<09:56,  2.25s/it] 47%|████▋     | 237/500 [04:10<06:59,  1.60s/it] 48%|████▊     | 239/500 [04:10<04:56,  1.14s/it] 48%|████▊     | 239/500 [04:21<04:56,  1.14s/it] 48%|████▊     | 241/500 [04:23<11:27,  2.65s/it] 49%|████▊     | 243/500 [04:23<08:03,  1.88s/it] 49%|████▉     | 245/500 [04:29<09:33,  2.25s/it] 49%|████▉     | 247/500 [04:29<06:44,  1.60s/it] 50%|████▉     | 249/500 [04:29<04:45,  1.14s/it] 50%|████▉     | 249/500 [04:41<04:45,  1.14s/it] 50%|█████     | 251/500 [04:42<11:02,  2.66s/it] 51%|█████     | 253/500 [04:42<07:45,  1.88s/it] 51%|█████     | 255/500 [04:48<09:20,  2.29s/it] 51%|█████▏    | 257/500 [04:48<06:35,  1.63s/it]**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.0017228045035153627
Test Loss:  0.0013842303305864334
Valid Loss:  0.0020491457544267178
Epoch:  202  	Training Loss: 0.001722804270684719
Test Loss:  0.001384230563417077
Valid Loss:  0.002049145521596074
Epoch:  203  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384230563417077
Valid Loss:  0.002049145521596074
Epoch:  204  	Training Loss: 0.001722804387100041
Test Loss:  0.001384230563417077
Valid Loss:  0.002049145521596074
Epoch:  205  	Training Loss: 0.001722804270684719
Test Loss:  0.001384230563417077
Valid Loss:  0.0020491457544267178
Epoch:  206  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842303305864334
Valid Loss:  0.0020491457544267178
Epoch:  207  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229864925146
Valid Loss:  0.0020491452887654305
Epoch:  208  	Training Loss: 0.0017228040378540754
Test Loss:  0.0013842297485098243
Valid Loss:  0.0020491452887654305
Epoch:  209  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842297485098243
Valid Loss:  0.0020491452887654305
Epoch:  210  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842297485098243
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842297485098243
Valid Loss:  0.002049145055934787
Epoch:  212  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842296320945024
Valid Loss:  0.002049144823104143
Epoch:  213  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842296320945024
Valid Loss:  0.002049145055934787
Epoch:  214  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842296320945024
Valid Loss:  0.002049144823104143
Epoch:  215  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842296320945024
Valid Loss:  0.002049145521596074
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842296320945024
Valid Loss:  0.002049145521596074
Epoch:  217  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842296320945024
Valid Loss:  0.002049145521596074
Epoch:  218  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842296320945024
Valid Loss:  0.002049145521596074
Epoch:  219  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842296320945024
Valid Loss:  0.0020491452887654305
Epoch:  220  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842296320945024
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  222  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  223  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  224  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  225  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  227  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  228  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  229  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  230  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  232  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  233  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  234  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  235  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  237  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  238  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  239  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  240  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  242  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.002049145521596074
Epoch:  243  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  244  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  245  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  247  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  248  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  249  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  250  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  252  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  253  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  254  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  255  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  257  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  258  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
 52%|█████▏    | 259/500 [04:49<04:40,  1.17s/it] 52%|█████▏    | 259/500 [05:01<04:40,  1.17s/it] 52%|█████▏    | 261/500 [05:01<10:43,  2.69s/it] 53%|█████▎    | 263/500 [05:01<07:31,  1.91s/it] 53%|█████▎    | 265/500 [05:08<08:52,  2.27s/it] 53%|█████▎    | 267/500 [05:08<06:16,  1.61s/it] 54%|█████▍    | 269/500 [05:08<04:27,  1.16s/it] 54%|█████▍    | 270/500 [05:14<07:54,  2.06s/it] 54%|█████▍    | 271/500 [05:21<11:10,  2.93s/it] 55%|█████▍    | 273/500 [05:21<07:08,  1.89s/it] 55%|█████▌    | 275/500 [05:27<08:40,  2.31s/it] 55%|█████▌    | 277/500 [05:27<05:51,  1.58s/it] 56%|█████▌    | 279/500 [05:27<04:01,  1.09s/it] 56%|█████▌    | 280/500 [05:33<07:32,  2.06s/it] 56%|█████▌    | 281/500 [05:40<10:43,  2.94s/it] 57%|█████▋    | 283/500 [05:40<06:44,  1.86s/it] 57%|█████▋    | 285/500 [05:46<08:15,  2.30s/it] 57%|█████▋    | 287/500 [05:46<05:32,  1.56s/it] 58%|█████▊    | 289/500 [05:46<03:48,  1.08s/it] 58%|█████▊    | 290/500 [05:53<07:07,  2.04s/it] 58%|█████▊    | 291/500 [05:59<10:09,  2.91s/it] 59%|█████▊    | 293/500 [05:59<06:22,  1.85s/it] 59%|█████▉    | 295/500 [06:05<07:46,  2.28s/it] 59%|█████▉    | 297/500 [06:05<05:12,  1.54s/it] 60%|█████▉    | 299/500 [06:05<03:34,  1.07s/it] 60%|██████    | 301/500 [06:18<08:54,  2.68s/it] 61%|██████    | 303/500 [06:18<06:08,  1.87s/it] 61%|██████    | 305/500 [06:24<07:19,  2.25s/it] 61%|██████▏   | 307/500 [06:24<05:06,  1.59s/it] 62%|██████▏   | 309/500 [06:24<03:34,  1.12s/it] 62%|██████▏   | 311/500 [06:37<08:27,  2.69s/it] 63%|██████▎   | 313/500 [06:37<05:54,  1.90s/it]Epoch:  259  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  260  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  262  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  263  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  264  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  265  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  267  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  268  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  269  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  270  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  272  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  273  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  274  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  275  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  277  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  278  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  279  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  280  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  282  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  283  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  284  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  285  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  287  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  288  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  289  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  290  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  292  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  293  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  294  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  295  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  297  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  298  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  299  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  300  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  302  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  303  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  304  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  305  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  307  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
Epoch:  308  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  309  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  310  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  312  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  313  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  314  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  315  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
 63%|██████▎   | 315/500 [06:43<07:01,  2.28s/it] 63%|██████▎   | 317/500 [06:44<04:56,  1.62s/it] 64%|██████▍   | 319/500 [06:44<03:29,  1.16s/it] 64%|██████▍   | 321/500 [06:56<07:59,  2.68s/it] 65%|██████▍   | 323/500 [06:56<05:35,  1.89s/it] 65%|██████▌   | 325/500 [07:03<06:36,  2.26s/it] 65%|██████▌   | 327/500 [07:03<04:37,  1.61s/it] 66%|██████▌   | 329/500 [07:03<03:16,  1.15s/it] 66%|██████▌   | 331/500 [07:15<07:30,  2.66s/it] 67%|██████▋   | 333/500 [07:15<05:14,  1.89s/it] 67%|██████▋   | 335/500 [07:22<06:10,  2.24s/it] 67%|██████▋   | 337/500 [07:22<04:19,  1.59s/it] 68%|██████▊   | 339/500 [07:22<03:02,  1.13s/it] 68%|██████▊   | 341/500 [07:34<07:01,  2.65s/it] 69%|██████▊   | 343/500 [07:34<04:54,  1.88s/it] 69%|██████▉   | 345/500 [07:41<05:48,  2.25s/it] 69%|██████▉   | 347/500 [07:41<04:04,  1.60s/it] 70%|██████▉   | 349/500 [07:41<02:51,  1.14s/it] 70%|██████▉   | 349/500 [07:51<02:51,  1.14s/it] 70%|███████   | 351/500 [07:53<06:35,  2.65s/it] 71%|███████   | 353/500 [07:53<04:36,  1.88s/it] 71%|███████   | 355/500 [08:00<05:27,  2.26s/it] 71%|███████▏  | 357/500 [08:00<03:49,  1.61s/it] 72%|███████▏  | 359/500 [08:00<02:42,  1.15s/it] 72%|███████▏  | 359/500 [08:11<02:42,  1.15s/it] 72%|███████▏  | 361/500 [08:13<06:12,  2.68s/it] 73%|███████▎  | 363/500 [08:13<04:19,  1.90s/it] 73%|███████▎  | 365/500 [08:19<05:06,  2.27s/it] 73%|███████▎  | 367/500 [08:19<03:34,  1.61s/it] 74%|███████▍  | 369/500 [08:19<02:30,  1.15s/it] 74%|███████▍  | 369/500 [08:31<02:30,  1.15s/it] 74%|███████▍  | 371/500 [08:32<05:47,  2.69s/it]**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  317  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  318  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  319  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  320  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  322  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  323  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  324  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  325  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  327  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  328  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  329  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  330  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  332  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  333  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  334  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  335  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  337  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  338  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  339  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  340  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  342  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  343  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  344  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
Epoch:  345  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
Epoch:  347  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  348  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  349  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  350  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  352  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  353  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  354  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  355  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  357  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  358  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
Epoch:  359  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  360  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  362  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  363  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  364  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  365  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  367  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  368  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  369  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  370  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.0017228040378540754
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  372  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:   75%|███████▍  | 373/500 [08:32<04:02,  1.91s/it] 75%|███████▌  | 375/500 [08:38<04:45,  2.28s/it] 75%|███████▌  | 377/500 [08:38<03:19,  1.62s/it] 76%|███████▌  | 379/500 [08:39<02:19,  1.15s/it] 76%|███████▌  | 381/500 [08:51<05:18,  2.68s/it] 77%|███████▋  | 383/500 [08:51<03:42,  1.90s/it] 77%|███████▋  | 385/500 [08:57<04:20,  2.26s/it] 77%|███████▋  | 387/500 [08:58<03:01,  1.61s/it] 78%|███████▊  | 389/500 [08:58<02:07,  1.14s/it] 78%|███████▊  | 391/500 [09:10<04:51,  2.67s/it] 79%|███████▊  | 393/500 [09:10<03:22,  1.89s/it] 79%|███████▉  | 395/500 [09:17<03:58,  2.27s/it] 79%|███████▉  | 397/500 [09:17<02:46,  1.61s/it] 80%|███████▉  | 399/500 [09:17<01:56,  1.15s/it] 80%|████████  | 401/500 [09:29<04:25,  2.68s/it] 81%|████████  | 403/500 [09:30<03:03,  1.90s/it] 81%|████████  | 405/500 [09:36<03:37,  2.29s/it] 81%|████████▏ | 407/500 [09:36<02:30,  1.62s/it] 82%|████████▏ | 409/500 [09:36<01:45,  1.15s/it] 82%|████████▏ | 411/500 [09:49<03:59,  2.69s/it] 83%|████████▎ | 413/500 [09:49<02:45,  1.91s/it] 83%|████████▎ | 415/500 [09:55<03:14,  2.29s/it] 83%|████████▎ | 417/500 [09:55<02:14,  1.62s/it] 84%|████████▍ | 419/500 [09:56<01:33,  1.16s/it] 84%|████████▍ | 421/500 [10:08<03:32,  2.69s/it] 85%|████████▍ | 423/500 [10:08<02:26,  1.90s/it] 85%|████████▌ | 425/500 [10:15<02:51,  2.28s/it] 85%|████████▌ | 427/500 [10:15<01:58,  1.62s/it] 86%|████████▌ | 429/500 [10:15<01:22,  1.16s/it]0.0020491452887654305
Epoch:  373  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  374  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  375  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  377  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  378  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  379  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  380  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  382  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  383  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  384  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  385  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  387  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  388  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  389  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  390  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  392  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  393  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  394  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  395  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  397  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  398  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  399  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  400  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  402  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  403  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  404  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  405  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  407  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  408  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  409  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  410  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  412  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  413  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  414  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  415  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.002049145521596074
Epoch:  417  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
Epoch:  418  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  419  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  420  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  422  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  423  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  424  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  425  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  427  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  428  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  429  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  430  	Training Loss: 0.001722804270684719
Test Loss:   86%|████████▌ | 431/500 [10:27<03:04,  2.67s/it] 87%|████████▋ | 433/500 [10:28<02:06,  1.89s/it] 87%|████████▋ | 435/500 [10:34<02:27,  2.27s/it] 87%|████████▋ | 437/500 [10:34<01:41,  1.61s/it] 88%|████████▊ | 439/500 [10:34<01:09,  1.15s/it] 88%|████████▊ | 441/500 [10:47<02:38,  2.69s/it] 89%|████████▊ | 443/500 [10:47<01:48,  1.90s/it] 89%|████████▉ | 445/500 [10:53<02:05,  2.28s/it] 89%|████████▉ | 447/500 [10:53<01:25,  1.62s/it] 90%|████████▉ | 449/500 [10:53<00:58,  1.15s/it] 90%|█████████ | 451/500 [11:06<02:13,  2.72s/it] 91%|█████████ | 453/500 [11:06<01:30,  1.93s/it] 91%|█████████ | 455/500 [11:13<01:43,  2.31s/it] 91%|█████████▏| 457/500 [11:13<01:10,  1.64s/it] 92%|█████████▏| 459/500 [11:13<00:47,  1.16s/it] 92%|█████████▏| 461/500 [11:25<01:44,  2.68s/it] 93%|█████████▎| 463/500 [11:26<01:10,  1.90s/it] 93%|█████████▎| 465/500 [11:32<01:20,  2.30s/it] 93%|█████████▎| 467/500 [11:32<00:53,  1.63s/it] 94%|█████████▍| 469/500 [11:32<00:36,  1.16s/it] 94%|█████████▍| 471/500 [11:45<01:18,  2.70s/it] 95%|█████████▍| 473/500 [11:45<00:51,  1.91s/it] 95%|█████████▌| 475/500 [11:45<00:33,  1.36s/it] 95%|█████████▌| 477/500 [11:45<00:22,  1.03it/s] 96%|█████████▌| 479/500 [11:45<00:14,  1.43it/s] 96%|█████████▌| 481/500 [11:58<00:45,  2.37s/it] 97%|█████████▋| 483/500 [11:58<00:28,  1.68s/it] 97%|█████████▋| 485/500 [12:05<00:32,  2.16s/it] 97%|█████████▋| 487/500 [12:05<00:19,  1.53s/it]0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
Epoch:  432  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  433  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  434  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  435  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  437  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  438  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  439  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  440  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  442  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  443  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  444  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  445  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  447  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  448  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  449  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  450  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  452  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  453  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  454  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  455  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  457  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
Epoch:  458  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  459  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  460  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  462  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  463  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  464  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  465  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842293992638588
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  467  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  468  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  469  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  470  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  472  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  473  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  474  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  475  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  476  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  477  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  478  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  479  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  480  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  482  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  483  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  484  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  485  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  487  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  488  	Training Loss: 0.001722804270684719
Test Loss:  98%|█████████▊| 489/500 [12:05<00:11,  1.09s/it] 98%|█████████▊| 491/500 [12:18<00:23,  2.66s/it] 99%|█████████▊| 493/500 [12:18<00:13,  1.89s/it] 99%|█████████▉| 495/500 [12:24<00:11,  2.27s/it] 99%|█████████▉| 497/500 [12:24<00:04,  1.61s/it]100%|█████████▉| 499/500 [12:24<00:01,  1.15s/it]100%|██████████| 500/500 [12:31<00:00,  1.50s/it]
 0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  489  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  490  	Training Loss: 0.0017228041542693973
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  492  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  493  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  494  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  495  	Training Loss: 0.0017228041542693973
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  497  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  498  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
Epoch:  499  	Training Loss: 0.001722804270684719
Test Loss:  0.0013842291664332151
Valid Loss:  0.0020491452887654305
Epoch:  500  	Training Loss: 0.001722804270684719
Test Loss:  0.001384229282848537
Valid Loss:  0.0020491452887654305
**************************************************learning rate decay**************************************************
seed is  14
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:35,  6.32s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:43,  2.94it/s]  4%|▍         | 21/500 [00:20<09:38,  1.21s/it]  5%|▍         | 23/500 [00:20<06:50,  1.16it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:22,  1.20s/it]  7%|▋         | 33/500 [00:27<06:43,  1.16it/s]  7%|▋         | 35/500 [00:27<04:53,  1.59it/s]  7%|▋         | 37/500 [00:27<03:35,  2.15it/s]  8%|▊         | 39/500 [00:27<02:39,  2.89it/s]  8%|▊         | 41/500 [00:33<08:59,  1.18s/it]  9%|▊         | 43/500 [00:33<06:25,  1.18it/s]  9%|▉         | 45/500 [00:34<04:37,  1.64it/s]  9%|▉         | 47/500 [00:34<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:30,  3.01it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:27,  3.00it/s] 12%|█▏        | 61/500 [00:47<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:29,  1.61it/s] 13%|█▎        | 67/500 [00:48<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:48<02:26,  2.95it/s]Epoch:  1  	Training Loss: 0.2712118625640869
Test Loss:  0.18580156564712524
Valid Loss:  0.18816739320755005
Epoch:  2  	Training Loss: 0.17892378568649292
Test Loss:  0.10380661487579346
Valid Loss:  0.1067657321691513
Epoch:  3  	Training Loss: 0.10132313519716263
Test Loss:  0.05989962816238403
Valid Loss:  0.06300737708806992
Epoch:  4  	Training Loss: 0.05992551147937775
Test Loss:  0.03641800209879875
Valid Loss:  0.03950520232319832
Epoch:  5  	Training Loss: 0.037888526916503906
Test Loss:  0.023676471784710884
Valid Loss:  0.026622846722602844
Epoch:  6  	Training Loss: 0.025937028229236603
Test Loss:  0.016407253220677376
Valid Loss:  0.019135037437081337
Epoch:  7  	Training Loss: 0.01902274414896965
Test Loss:  0.011825863271951675
Valid Loss:  0.014307249337434769
Epoch:  8  	Training Loss: 0.014504367485642433
Test Loss:  0.009029615670442581
Valid Loss:  0.01127864234149456
Epoch:  9  	Training Loss: 0.011602470651268959
Test Loss:  0.007238283287733793
Valid Loss:  0.00927571952342987
Epoch:  10  	Training Loss: 0.009634598158299923
Test Loss:  0.006034182850271463
Valid Loss:  0.0078972727060318
Epoch:  11  	Training Loss: 0.00824996642768383
Test Loss:  0.00516014639288187
Valid Loss:  0.006907131522893906
Epoch:  12  	Training Loss: 0.007227536290884018
Test Loss:  0.004879632033407688
Valid Loss:  0.0065958634950220585
Epoch:  13  	Training Loss: 0.006925308145582676
Test Loss:  0.004642024636268616
Valid Loss:  0.006329057272523642
Epoch:  14  	Training Loss: 0.006662602070719004
Test Loss:  0.004433420952409506
Valid Loss:  0.006091072224080563
Epoch:  15  	Training Loss: 0.006422202102839947
Test Loss:  0.0042564054019749165
Valid Loss:  0.005883393809199333
Epoch:  16  	Training Loss: 0.006212376058101654
Test Loss:  0.004123987164348364
Valid Loss:  0.005724250338971615
Epoch:  17  	Training Loss: 0.006043693982064724
Test Loss:  0.004000162705779076
Valid Loss:  0.005574525333940983
Epoch:  18  	Training Loss: 0.005883157718926668
Test Loss:  0.0038833245635032654
Valid Loss:  0.005432464648038149
Epoch:  19  	Training Loss: 0.005729488097131252
Test Loss:  0.003772228956222534
Valid Loss:  0.005296848248690367
Epoch:  20  	Training Loss: 0.005582015495747328
Test Loss:  0.0036668521352112293
Valid Loss:  0.005167366936802864
Epoch:  21  	Training Loss: 0.005440450273454189
Test Loss:  0.0035667496267706156
Valid Loss:  0.005043420009315014
Epoch:  22  	Training Loss: 0.005304083228111267
Test Loss:  0.0034938612952828407
Valid Loss:  0.004900301806628704
Epoch:  23  	Training Loss: 0.005068233702331781
Test Loss:  0.0033326493576169014
Valid Loss:  0.004690247122198343
Epoch:  24  	Training Loss: 0.004829671233892441
Test Loss:  0.0031935591250658035
Valid Loss:  0.004507140722125769
Epoch:  25  	Training Loss: 0.004625754430890083
Test Loss:  0.0030879571568220854
Valid Loss:  0.00436250539496541
Epoch:  26  	Training Loss: 0.0044538541696965694
Test Loss:  0.003001754404976964
Valid Loss:  0.004240157548338175
Epoch:  27  	Training Loss: 0.0043052202090620995
Test Loss:  0.0029087907169014215
Valid Loss:  0.00411810539662838
Epoch:  28  	Training Loss: 0.0041684783063828945
Test Loss:  0.0028308166656643152
Valid Loss:  0.00400756299495697
Epoch:  29  	Training Loss: 0.004037360195070505
Test Loss:  0.002753831911832094
Valid Loss:  0.0039000078104436398
Epoch:  30  	Training Loss: 0.003913304768502712
Test Loss:  0.002678223652765155
Valid Loss:  0.0037965199444442987
Epoch:  31  	Training Loss: 0.003796861506998539
Test Loss:  0.0025917680468410254
Valid Loss:  0.0036883060820400715
Epoch:  32  	Training Loss: 0.0036860662512481213
Test Loss:  0.002473237691447139
Valid Loss:  0.0035466011613607407
Epoch:  33  	Training Loss: 0.003539774566888809
Test Loss:  0.002375001087784767
Valid Loss:  0.0034256528597325087
Epoch:  34  	Training Loss: 0.0034090979024767876
Test Loss:  0.0022838918957859278
Valid Loss:  0.0033127623610198498
Epoch:  35  	Training Loss: 0.0032868676353245974
Test Loss:  0.002201112685725093
Valid Loss:  0.0032083517871797085
Epoch:  36  	Training Loss: 0.003173600882291794
Test Loss:  0.0021257316693663597
Valid Loss:  0.0031120548956096172
Epoch:  37  	Training Loss: 0.003070216625928879
Test Loss:  0.0020565600134432316
Valid Loss:  0.0030226740054786205
Epoch:  38  	Training Loss: 0.0029736487194895744
Test Loss:  0.001992853358387947
Valid Loss:  0.00293960259296
Epoch:  39  	Training Loss: 0.002882535569369793
Test Loss:  0.0019328717608004808
Valid Loss:  0.0028609083965420723
Epoch:  40  	Training Loss: 0.0027961088344454765
Test Loss:  0.0018774368800222874
Valid Loss:  0.002787141129374504
Epoch:  41  	Training Loss: 0.0027140940073877573
Test Loss:  0.00182303786277771
Valid Loss:  0.0027155601419508457
Epoch:  42  	Training Loss: 0.002636189805343747
Test Loss:  0.001730394084006548
Valid Loss:  0.002573810750618577
Epoch:  43  	Training Loss: 0.002456820569932461
Test Loss:  0.001673344406299293
Valid Loss:  0.002495009684935212
Epoch:  44  	Training Loss: 0.002362447092309594
Test Loss:  0.001623004674911499
Valid Loss:  0.0024252748116850853
Epoch:  45  	Training Loss: 0.0022833773400634527
Test Loss:  0.0015753586776554585
Valid Loss:  0.0023616489488631487
Epoch:  46  	Training Loss: 0.0022128098644316196
Test Loss:  0.0015289748553186655
Valid Loss:  0.002301191445440054
Epoch:  47  	Training Loss: 0.002148098312318325
Test Loss:  0.0014875943306833506
Valid Loss:  0.0022462033666670322
Epoch:  48  	Training Loss: 0.002088389825075865
Test Loss:  0.0014500903198495507
Valid Loss:  0.002195536158978939
Epoch:  49  	Training Loss: 0.0020328322425484657
Test Loss:  0.0014158627018332481
Valid Loss:  0.0021485397592186928
Epoch:  50  	Training Loss: 0.0019809198565781116
Test Loss:  0.0013846909860149026
Valid Loss:  0.0021048258058726788
Epoch:  51  	Training Loss: 0.0019322374137118459
Test Loss:  0.001354896230623126
Valid Loss:  0.0020633044186979532
Epoch:  52  	Training Loss: 0.0018865888705477118
Test Loss:  0.001308696111664176
Valid Loss:  0.002010983182117343
Epoch:  53  	Training Loss: 0.0018432640936225653
Test Loss:  0.001269577769562602
Valid Loss:  0.0019635455682873726
Epoch:  54  	Training Loss: 0.0018030500505119562
Test Loss:  0.0012342357076704502
Valid Loss:  0.0019191146129742265
Epoch:  55  	Training Loss: 0.001764276996254921
Test Loss:  0.0012049442157149315
Valid Loss:  0.0018801696132868528
Epoch:  56  	Training Loss: 0.0017298604361712933
Test Loss:  0.0011807548580691218
Valid Loss:  0.001846482278779149
Epoch:  57  	Training Loss: 0.0016988619463518262
Test Loss:  0.0011595290852710605
Valid Loss:  0.0018164702923968434
Epoch:  58  	Training Loss: 0.0016698818653821945
Test Loss:  0.0011404503602534533
Valid Loss:  0.0017888066358864307
Epoch:  59  	Training Loss: 0.0016423921333625913
Test Loss:  0.0011223620967939496
Valid Loss:  0.0017627141205593944
Epoch:  60  	Training Loss: 0.001616486581042409
Test Loss:  0.0011056982912123203
Valid Loss:  0.0017385624814778566
Epoch:  61  	Training Loss: 0.0015922528691589832
Test Loss:  0.0010901113273575902
Valid Loss:  0.0017159817507490516
Epoch:  62  	Training Loss: 0.0015692226588726044
Test Loss:  0.0010921282228082418
Valid Loss:  0.0016982484376057982
Epoch:  63  	Training Loss: 0.0015349638415500522
Test Loss:  0.0010950842406600714
Valid Loss:  0.0016848264494910836
Epoch:  64  	Training Loss: 0.001509820343926549
Test Loss:  0.0010927319526672363
Valid Loss:  0.0016701404238119721
Epoch:  65  	Training Loss: 0.0014882818795740604
Test Loss:  0.0010862583294510841
Valid Loss:  0.0016548301791772246
Epoch:  66  	Training Loss: 0.0014687873190268874
Test Loss:  0.001078146044164896
Valid Loss:  0.001639187685213983
Epoch:  67  	Training Loss: 0.0014504434075206518
Test Loss:  0.00106757041066885
Valid Loss:  0.0016226492589339614
Epoch:  68  	Training Loss: 0.0014332891441881657
Test Loss:  0.0010560634545981884
Valid Loss:  0.0016059402842074633
Epoch:  69  	Training Loss: 0.0014169702772051096
Test Loss:  0.0010443490464240313
Valid Loss:  0.0015894928947091103
Epoch:  70  	Training Loss: 0.0014013333711773157
Test Loss:  0.001032977132126689
Valid Loss:  0.0015735127963125706
 14%|█▍        | 71/500 [00:54<08:29,  1.19s/it] 15%|█▍        | 73/500 [00:54<06:04,  1.17it/s] 15%|█▌        | 75/500 [00:54<04:22,  1.62it/s] 15%|█▌        | 77/500 [00:54<03:11,  2.21it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:01<08:07,  1.16s/it] 17%|█▋        | 83/500 [01:01<05:48,  1.20it/s] 17%|█▋        | 85/500 [01:01<04:10,  1.65it/s] 17%|█▋        | 87/500 [01:01<03:02,  2.26it/s] 18%|█▊        | 89/500 [01:01<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:08<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:08<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:08<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:12,  3.02it/s] 20%|██        | 101/500 [01:14<07:56,  1.19s/it] 21%|██        | 103/500 [01:15<05:40,  1.17it/s] 21%|██        | 105/500 [01:15<04:04,  1.61it/s] 21%|██▏       | 107/500 [01:15<02:58,  2.20it/s] 22%|██▏       | 109/500 [01:15<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:21<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:29,  1.17it/s] 23%|██▎       | 115/500 [01:22<03:56,  1.62it/s] 23%|██▎       | 117/500 [01:22<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:22<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:28<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:11,  1.17s/it] 27%|██▋       | 133/500 [01:35<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:35<02:41,  2.25it/s]Epoch:  71  	Training Loss: 0.0013862932100892067
Test Loss:  0.0010220196563750505
Valid Loss:  0.0015580044128000736
Epoch:  72  	Training Loss: 0.0013717866968363523
Test Loss:  0.0010028814431279898
Valid Loss:  0.0015363224083557725
Epoch:  73  	Training Loss: 0.0013535713078454137
Test Loss:  0.0009871990187093616
Valid Loss:  0.0015175456646829844
Epoch:  74  	Training Loss: 0.001337305293418467
Test Loss:  0.0009739286615513265
Valid Loss:  0.0015009932685643435
Epoch:  75  	Training Loss: 0.0013227930758148432
Test Loss:  0.0009629592532292008
Valid Loss:  0.0014865142293274403
Epoch:  76  	Training Loss: 0.0013096083421260118
Test Loss:  0.0009536516736261547
Valid Loss:  0.0014737125020474195
Epoch:  77  	Training Loss: 0.0012976443395018578
Test Loss:  0.000945783278439194
Valid Loss:  0.0014623998431488872
Epoch:  78  	Training Loss: 0.0012866718461737037
Test Loss:  0.0009390550549142063
Valid Loss:  0.0014522494748234749
Epoch:  79  	Training Loss: 0.0012766519794240594
Test Loss:  0.0009332982590422034
Valid Loss:  0.001443210057914257
Epoch:  80  	Training Loss: 0.001267407787963748
Test Loss:  0.0009283191175200045
Valid Loss:  0.0014351096469908953
Epoch:  81  	Training Loss: 0.0012589022517204285
Test Loss:  0.000923706276807934
Valid Loss:  0.001427594106644392
Epoch:  82  	Training Loss: 0.001251113135367632
Test Loss:  0.000910088187083602
Valid Loss:  0.0014089446049183607
Epoch:  83  	Training Loss: 0.0012362587731331587
Test Loss:  0.0008982898434624076
Valid Loss:  0.0013953151647001505
Epoch:  84  	Training Loss: 0.0012265434488654137
Test Loss:  0.0008876278297975659
Valid Loss:  0.0013827994698658586
Epoch:  85  	Training Loss: 0.0012173119466751814
Test Loss:  0.0008778102928772569
Valid Loss:  0.0013710418716073036
Epoch:  86  	Training Loss: 0.001208475441671908
Test Loss:  0.0008690618560649455
Valid Loss:  0.001360059715807438
Epoch:  87  	Training Loss: 0.0011999185662716627
Test Loss:  0.0008612573146820068
Valid Loss:  0.001349849859252572
Epoch:  88  	Training Loss: 0.001191616291180253
Test Loss:  0.0008540662238374352
Valid Loss:  0.0013401559554040432
Epoch:  89  	Training Loss: 0.0011836230987682939
Test Loss:  0.0008474364876747131
Valid Loss:  0.001330980914644897
Epoch:  90  	Training Loss: 0.0011760917259380221
Test Loss:  0.0008413555333390832
Valid Loss:  0.0013224529102444649
Epoch:  91  	Training Loss: 0.001168921240605414
Test Loss:  0.0008356058970093727
Valid Loss:  0.0013144281692802906
Epoch:  92  	Training Loss: 0.001161996042355895
Test Loss:  0.0008435873314738274
Valid Loss:  0.0013118369970470667
Epoch:  93  	Training Loss: 0.0011511689517647028
Test Loss:  0.0008475391077809036
Valid Loss:  0.0013078313786536455
Epoch:  94  	Training Loss: 0.0011417563073337078
Test Loss:  0.0008488043094985187
Valid Loss:  0.001302957534790039
Epoch:  95  	Training Loss: 0.0011332505382597446
Test Loss:  0.000846607144922018
Valid Loss:  0.0012965695932507515
Epoch:  96  	Training Loss: 0.0011255091521888971
Test Loss:  0.0008437162032350898
Valid Loss:  0.001289944164454937
Epoch:  97  	Training Loss: 0.0011180626461282372
Test Loss:  0.0008402538951486349
Valid Loss:  0.001283115241676569
Epoch:  98  	Training Loss: 0.0011108540929853916
Test Loss:  0.0008366076508536935
Valid Loss:  0.0012764229904860258
Epoch:  99  	Training Loss: 0.001103925402276218
Test Loss:  0.0008328508120030165
Valid Loss:  0.0012699202634394169
Epoch:  100  	Training Loss: 0.001097215455956757
Test Loss:  0.0008292545098811388
Valid Loss:  0.0012637830805033445
Epoch:  101  	Training Loss: 0.0010906719835475087
Test Loss:  0.0008256961591541767
Valid Loss:  0.001257801428437233
Epoch:  102  	Training Loss: 0.0010843973141163588
Test Loss:  0.0008175730472430587
Valid Loss:  0.0012493182439357042
Epoch:  103  	Training Loss: 0.0010777695570141077
Test Loss:  0.0008105463930405676
Valid Loss:  0.0012421042192727327
Epoch:  104  	Training Loss: 0.00107187672983855
Test Loss:  0.0008041032124310732
Valid Loss:  0.0012357241939753294
Epoch:  105  	Training Loss: 0.001066545955836773
Test Loss:  0.00079818518133834
Valid Loss:  0.0012297400971874595
Epoch:  106  	Training Loss: 0.0010614297352731228
Test Loss:  0.0007928264676593244
Valid Loss:  0.0012240399373695254
Epoch:  107  	Training Loss: 0.0010564889525994658
Test Loss:  0.0007880633929744363
Valid Loss:  0.0012186234816908836
Epoch:  108  	Training Loss: 0.0010518128983676434
Test Loss:  0.0007836459553800523
Valid Loss:  0.0012134395074099302
Epoch:  109  	Training Loss: 0.0010473079746589065
Test Loss:  0.000779571128077805
Valid Loss:  0.001208489527925849
Epoch:  110  	Training Loss: 0.001042933203279972
Test Loss:  0.0007758173160254955
Valid Loss:  0.0012037826236337423
Epoch:  111  	Training Loss: 0.0010387690272182226
Test Loss:  0.0007723859162069857
Valid Loss:  0.0011993426596745849
Epoch:  112  	Training Loss: 0.0010347873903810978
Test Loss:  0.000758759502787143
Valid Loss:  0.0011769963894039392
Epoch:  113  	Training Loss: 0.0010149616282433271
Test Loss:  0.000744938850402832
Valid Loss:  0.0011563561856746674
Epoch:  114  	Training Loss: 0.0009972151601687074
Test Loss:  0.000731616048142314
Valid Loss:  0.0011373902671039104
Epoch:  115  	Training Loss: 0.0009809049079194665
Test Loss:  0.0007198775419965386
Valid Loss:  0.0011200790759176016
Epoch:  116  	Training Loss: 0.0009656468173488975
Test Loss:  0.0007093021413311362
Valid Loss:  0.0011041162069886923
Epoch:  117  	Training Loss: 0.0009513711556792259
Test Loss:  0.000699531112331897
Valid Loss:  0.0010895607993006706
Epoch:  118  	Training Loss: 0.0009381157578900456
Test Loss:  0.0006902983877807856
Valid Loss:  0.0010759311262518167
Epoch:  119  	Training Loss: 0.000925448548514396
Test Loss:  0.0006816411623731256
Valid Loss:  0.00106318318285048
Epoch:  120  	Training Loss: 0.0009133104467764497
Test Loss:  0.0006735635688528419
Valid Loss:  0.0010511125437915325
Epoch:  121  	Training Loss: 0.000901605118997395
Test Loss:  0.0006661339430138469
Valid Loss:  0.001039426657371223
Epoch:  122  	Training Loss: 0.000890446244738996
Test Loss:  0.0006604122463613749
Valid Loss:  0.0010305055184289813
Epoch:  123  	Training Loss: 0.000882242398802191
Test Loss:  0.0006559561006724834
Valid Loss:  0.0010230978950858116
Epoch:  124  	Training Loss: 0.0008750754641368985
Test Loss:  0.0006513204425573349
Valid Loss:  0.0010155447525903583
Epoch:  125  	Training Loss: 0.0008682515472173691
Test Loss:  0.0006460064323619008
Valid Loss:  0.0010073818266391754
Epoch:  126  	Training Loss: 0.0008612755336798728
Test Loss:  0.0006395631935447454
Valid Loss:  0.0009981500916182995
Epoch:  127  	Training Loss: 0.0008533093496225774
Test Loss:  0.0006322925910353661
Valid Loss:  0.0009880284778773785
Epoch:  128  	Training Loss: 0.0008446568390354514
Test Loss:  0.0006249776924960315
Valid Loss:  0.000977872172370553
Epoch:  129  	Training Loss: 0.0008355315658263862
Test Loss:  0.0006175823509693146
Valid Loss:  0.0009676308836787939
Epoch:  130  	Training Loss: 0.0008263055933639407
Test Loss:  0.0006106418441049755
Valid Loss:  0.0009581505437381566
Epoch:  131  	Training Loss: 0.0008174240356311202
Test Loss:  0.0006042305612936616
Valid Loss:  0.0009493206162005663
Epoch:  132  	Training Loss: 0.0008092103525996208
Test Loss:  0.0006043395260348916
Valid Loss:  0.0009466226329095662
Epoch:  133  	Training Loss: 0.0008050031028687954
Test Loss:  0.0006041560554876924
Valid Loss:  0.0009439288405701518
Epoch:  134  	Training Loss: 0.0008010644814930856
Test Loss:  0.0006039232248440385
Valid Loss:  0.0009415320819243789
Epoch:  135  	Training Loss: 0.0007974389009177685
Test Loss:  0.0006034263642504811
Valid Loss:  0.000939122517593205
Epoch:  136  	Training Loss: 0.0007940739160403609
Test Loss:  0.0006026025512255728
Valid Loss:  0.0009366496815346181
Epoch:  137  	Training Loss: 0.0007908509578555822
Test Loss:  0.0006014463142491877
Valid Loss:  0.0009341828990727663
Epoch:  138  	Training Loss: 0.0007877311436459422
Test Loss:  0.0006001242436468601
Valid Loss:  0.0009317385847680271
Epoch:  139  	Training Loss: 0.0007847748347558081
Test Loss:  0.0005989340716041625
Valid Loss:   28%|██▊       | 139/500 [01:36<01:59,  3.02it/s] 28%|██▊       | 141/500 [01:42<07:03,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:02,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:42<01:57,  3.00it/s] 30%|███       | 151/500 [01:49<06:44,  1.16s/it] 31%|███       | 153/500 [01:49<04:48,  1.20it/s] 31%|███       | 155/500 [01:49<03:27,  1.66it/s] 31%|███▏      | 157/500 [01:49<02:32,  2.26it/s] 32%|███▏      | 159/500 [01:49<01:52,  3.03it/s] 32%|███▏      | 161/500 [01:55<06:41,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:56<03:29,  1.60it/s] 33%|███▎      | 167/500 [01:56<02:34,  2.16it/s] 34%|███▍      | 169/500 [01:56<01:55,  2.86it/s] 34%|███▍      | 171/500 [02:03<06:37,  1.21s/it] 35%|███▍      | 173/500 [02:03<04:43,  1.15it/s] 35%|███▌      | 175/500 [02:03<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:03<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:03<01:49,  2.94it/s] 36%|███▌      | 181/500 [02:09<06:14,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:10<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:10<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.02it/s] 38%|███▊      | 191/500 [02:16<05:57,  1.16s/it] 39%|███▊      | 193/500 [02:16<04:15,  1.20it/s] 39%|███▉      | 195/500 [02:16<03:03,  1.66it/s] 39%|███▉      | 197/500 [02:16<02:13,  2.27it/s] 40%|███▉      | 199/500 [02:17<01:38,  3.05it/s] 40%|████      | 201/500 [02:23<05:53,  1.18s/it] 41%|████      | 203/500 [02:23<04:11,  1.18it/s] 41%|████      | 205/500 [02:23<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.23it/s]0.0009294225601479411
Epoch:  140  	Training Loss: 0.0007819595048204064
Test Loss:  0.000597564852796495
Valid Loss:  0.0009270395385101438
Epoch:  141  	Training Loss: 0.0007792175747454166
Test Loss:  0.0005960051203146577
Valid Loss:  0.0009246347472071648
Epoch:  142  	Training Loss: 0.0007765804184600711
Test Loss:  0.0005957275861874223
Valid Loss:  0.0009232318261638284
Epoch:  143  	Training Loss: 0.0007749283686280251
Test Loss:  0.0005952638457529247
Valid Loss:  0.0009217559127137065
Epoch:  144  	Training Loss: 0.0007733232341706753
Test Loss:  0.0005947179161012173
Valid Loss:  0.000920279766432941
Epoch:  145  	Training Loss: 0.0007717795670032501
Test Loss:  0.0005940858973190188
Valid Loss:  0.0009188505355268717
Epoch:  146  	Training Loss: 0.0007703108130954206
Test Loss:  0.000593440025113523
Valid Loss:  0.0009174493025057018
Epoch:  147  	Training Loss: 0.0007689119083806872
Test Loss:  0.0005927263991907239
Valid Loss:  0.0009161310736089945
Epoch:  148  	Training Loss: 0.0007675481028854847
Test Loss:  0.0005919820396229625
Valid Loss:  0.0009148761164397001
Epoch:  149  	Training Loss: 0.0007662347052246332
Test Loss:  0.0005912628257647157
Valid Loss:  0.0009136640001088381
Epoch:  150  	Training Loss: 0.0007649743929505348
Test Loss:  0.0005905871512368321
Valid Loss:  0.0009124960051849484
Epoch:  151  	Training Loss: 0.000763793068472296
Test Loss:  0.0005898758536204696
Valid Loss:  0.0009112615953199565
Epoch:  152  	Training Loss: 0.0007626496371813118
Test Loss:  0.0005798491183668375
Valid Loss:  0.0009022041340358555
Epoch:  153  	Training Loss: 0.0007571451715193689
Test Loss:  0.0005731460405513644
Valid Loss:  0.0008955614757724106
Epoch:  154  	Training Loss: 0.0007525253458879888
Test Loss:  0.0005682137561962008
Valid Loss:  0.0008902521221898496
Epoch:  155  	Training Loss: 0.0007483241497538984
Test Loss:  0.0005643615731969476
Valid Loss:  0.0008856658823788166
Epoch:  156  	Training Loss: 0.000744348973967135
Test Loss:  0.000561091466806829
Valid Loss:  0.0008816742920316756
Epoch:  157  	Training Loss: 0.0007407371886074543
Test Loss:  0.0005582118174061179
Valid Loss:  0.0008782190270721912
Epoch:  158  	Training Loss: 0.0007374761626124382
Test Loss:  0.0005555958487093449
Valid Loss:  0.0008752848953008652
Epoch:  159  	Training Loss: 0.0007344672339968383
Test Loss:  0.0005533776711672544
Valid Loss:  0.0008727301028557122
Epoch:  160  	Training Loss: 0.0007317123236134648
Test Loss:  0.0005511833005584776
Valid Loss:  0.0008702091290615499
Epoch:  161  	Training Loss: 0.0007291201618500054
Test Loss:  0.0005491091869771481
Valid Loss:  0.0008677630685269833
Epoch:  162  	Training Loss: 0.0007267058826982975
Test Loss:  0.000546279305126518
Valid Loss:  0.0008650370291434228
Epoch:  163  	Training Loss: 0.0007250865455716848
Test Loss:  0.0005452401237562299
Valid Loss:  0.0008633938268758357
Epoch:  164  	Training Loss: 0.0007236601086333394
Test Loss:  0.0005449190502986312
Valid Loss:  0.0008622261229902506
Epoch:  165  	Training Loss: 0.0007223246502690017
Test Loss:  0.000545283779501915
Valid Loss:  0.0008616272825747728
Epoch:  166  	Training Loss: 0.0007210110779851675
Test Loss:  0.0005442305700853467
Valid Loss:  0.00086016213754192
Epoch:  167  	Training Loss: 0.0007197619997896254
Test Loss:  0.0005443800473585725
Valid Loss:  0.0008595602703280747
Epoch:  168  	Training Loss: 0.0007185273570939898
Test Loss:  0.0005426813731901348
Valid Loss:  0.0008579285349696875
Epoch:  169  	Training Loss: 0.0007173429476097226
Test Loss:  0.0005424180417321622
Valid Loss:  0.0008572804508730769
Epoch:  170  	Training Loss: 0.0007161679677665234
Test Loss:  0.0005414721090346575
Valid Loss:  0.0008562148432247341
Epoch:  171  	Training Loss: 0.0007150697056204081
Test Loss:  0.0005405251285992563
Valid Loss:  0.0008551750215701759
Epoch:  172  	Training Loss: 0.0007140397210605443
Test Loss:  0.0005414089537225664
Valid Loss:  0.0008536133682355285
Epoch:  173  	Training Loss: 0.0007111566956155002
Test Loss:  0.0005415219347923994
Valid Loss:  0.0008520081755705178
Epoch:  174  	Training Loss: 0.0007087509147822857
Test Loss:  0.0005407503340393305
Valid Loss:  0.0008502494310960174
Epoch:  175  	Training Loss: 0.000706592109054327
Test Loss:  0.000539843924343586
Valid Loss:  0.0008484718855470419
Epoch:  176  	Training Loss: 0.0007045809179544449
Test Loss:  0.000538430642336607
Valid Loss:  0.0008465938153676689
Epoch:  177  	Training Loss: 0.0007027107640169561
Test Loss:  0.0005369429127313197
Valid Loss:  0.0008447323343716562
Epoch:  178  	Training Loss: 0.0007009911932982504
Test Loss:  0.0005355640314519405
Valid Loss:  0.0008429129375144839
Epoch:  179  	Training Loss: 0.0006993782008066773
Test Loss:  0.0005341096548363566
Valid Loss:  0.0008411201415583491
Epoch:  180  	Training Loss: 0.0006978202145546675
Test Loss:  0.0005325285019353032
Valid Loss:  0.0008393197786062956
Epoch:  181  	Training Loss: 0.000696340692229569
Test Loss:  0.0005310605047270656
Valid Loss:  0.0008376338519155979
Epoch:  182  	Training Loss: 0.0006949072703719139
Test Loss:  0.0005304922815412283
Valid Loss:  0.000837247702293098
Epoch:  183  	Training Loss: 0.0006948094815015793
Test Loss:  0.0005301249912008643
Valid Loss:  0.0008369640563614666
Epoch:  184  	Training Loss: 0.00069472286850214
Test Loss:  0.0005298979231156409
Valid Loss:  0.0008367500267922878
Epoch:  185  	Training Loss: 0.0006946427747607231
Test Loss:  0.0005297446623444557
Valid Loss:  0.0008365779067389667
Epoch:  186  	Training Loss: 0.0006945649511180818
Test Loss:  0.0005296707386150956
Valid Loss:  0.0008364629466086626
Epoch:  187  	Training Loss: 0.0006944964407011867
Test Loss:  0.0005296695162542164
Valid Loss:  0.0008363829692825675
Epoch:  188  	Training Loss: 0.0006944335764274001
Test Loss:  0.0005296955932863057
Valid Loss:  0.0008363195229321718
Epoch:  189  	Training Loss: 0.0006943729240447283
Test Loss:  0.0005297139286994934
Valid Loss:  0.0008362655062228441
Epoch:  190  	Training Loss: 0.0006943160551600158
Test Loss:  0.00052978954045102
Valid Loss:  0.0008362446678802371
Epoch:  191  	Training Loss: 0.0006942616309970617
Test Loss:  0.0005298451287671924
Valid Loss:  0.0008362224325537682
Epoch:  192  	Training Loss: 0.0006942092441022396
Test Loss:  0.0005243769846856594
Valid Loss:  0.0008319873595610261
Epoch:  193  	Training Loss: 0.0006910125957801938
Test Loss:  0.0005198182770982385
Valid Loss:  0.0008284063660539687
Epoch:  194  	Training Loss: 0.0006881207227706909
Test Loss:  0.0005160443251952529
Valid Loss:  0.0008254371350631118
Epoch:  195  	Training Loss: 0.000685474427882582
Test Loss:  0.0005128346383571625
Valid Loss:  0.0008229429950006306
Epoch:  196  	Training Loss: 0.0006829735357314348
Test Loss:  0.0005100731505081058
Valid Loss:  0.0008206586353480816
Epoch:  197  	Training Loss: 0.0006806815508753061
Test Loss:  0.000507750257384032
Valid Loss:  0.0008186522172763944
Epoch:  198  	Training Loss: 0.0006785631412640214
Test Loss:  0.0005056174704805017
Valid Loss:  0.0008167720516212285
Epoch:  199  	Training Loss: 0.0006765313446521759
Test Loss:  0.0005035775830037892
Valid Loss:  0.0008149181958287954
Epoch:  200  	Training Loss: 0.0006745540304109454
Test Loss:  0.0005015644710510969
Valid Loss:  0.0008130991482175887
Epoch:  201  	Training Loss: 0.000672645284794271
Test Loss:  0.0004994301125407219
Valid Loss:  0.0008112832438200712
Epoch:  202  	Training Loss: 0.0006708038854412735
Test Loss:  0.0004997167270630598
Valid Loss:  0.0008097845711745322
Epoch:  203  	Training Loss: 0.000669013534206897
Test Loss:  0.0005004009581170976
Valid Loss:  0.0008091981871984899
Epoch:  204  	Training Loss: 0.0006676525226794183
Test Loss:  0.0005002495599910617
Valid Loss:  0.0008084040600806475
Epoch:  205  	Training Loss: 0.000666473584715277
Test Loss:  0.0004995152121409774
Valid Loss:  0.0008076431695371866
Epoch:  206  	Training Loss: 0.000665405357722193
Test Loss:  0.0004987160209566355
Valid Loss:  0.0008068935130722821
Epoch:  207  	Training Loss: 0.0006644090171903372
Test Loss:  0.0004978809738531709
Valid Loss:  0.0008061383850872517
 42%|████▏     | 209/500 [02:23<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:30<05:42,  1.19s/it] 42%|████▏     | 212/500 [02:30<04:46,  1.01it/s] 43%|████▎     | 214/500 [02:30<03:16,  1.46it/s] 43%|████▎     | 216/500 [02:30<02:17,  2.06it/s] 44%|████▎     | 218/500 [02:30<01:39,  2.83it/s] 44%|████▍     | 220/500 [02:30<01:13,  3.79it/s] 44%|████▍     | 222/500 [02:37<05:23,  1.16s/it] 45%|████▍     | 224/500 [02:37<03:48,  1.21it/s] 45%|████▌     | 226/500 [02:37<02:43,  1.68it/s] 46%|████▌     | 228/500 [02:37<01:58,  2.30it/s] 46%|████▌     | 230/500 [02:37<01:27,  3.09it/s] 46%|████▋     | 232/500 [02:44<05:17,  1.18s/it] 47%|████▋     | 234/500 [02:44<03:45,  1.18it/s] 47%|████▋     | 236/500 [02:44<02:41,  1.63it/s] 48%|████▊     | 238/500 [02:44<01:57,  2.23it/s] 48%|████▊     | 240/500 [02:44<01:26,  3.00it/s] 48%|████▊     | 242/500 [02:51<05:07,  1.19s/it] 49%|████▉     | 244/500 [02:51<03:38,  1.17it/s] 49%|████▉     | 246/500 [02:51<02:36,  1.62it/s] 50%|████▉     | 248/500 [02:51<01:53,  2.21it/s] 50%|█████     | 250/500 [02:51<01:23,  2.98it/s] 50%|█████     | 252/500 [02:57<04:52,  1.18s/it] 51%|█████     | 254/500 [02:58<03:28,  1.18it/s] 51%|█████     | 256/500 [02:58<02:29,  1.64it/s] 52%|█████▏    | 258/500 [02:58<01:48,  2.23it/s] 52%|█████▏    | 260/500 [02:58<01:20,  3.00it/s] 52%|█████▏    | 262/500 [03:04<04:38,  1.17s/it] 53%|█████▎    | 264/500 [03:04<03:18,  1.19it/s] 53%|█████▎    | 266/500 [03:04<02:22,  1.65it/s] 54%|█████▎    | 268/500 [03:05<01:43,  2.25it/s] 54%|█████▍    | 270/500 [03:05<01:16,  3.02it/s] 54%|█████▍    | 272/500 [03:11<04:28,  1.18s/it] 55%|█████▍    | 274/500 [03:11<03:12,  1.18it/s]Epoch:  208  	Training Loss: 0.0006634887540712953
Test Loss:  0.0004971236921846867
Valid Loss:  0.0008054228965193033
Epoch:  209  	Training Loss: 0.0006626264075748622
Test Loss:  0.0004962541861459613
Valid Loss:  0.0008047363953664899
Epoch:  210  	Training Loss: 0.0006618187762796879
Test Loss:  0.0004954509204253554
Valid Loss:  0.000804076436907053
Epoch:  211  	Training Loss: 0.0006610301788896322
Test Loss:  0.0004946008557453752
Valid Loss:  0.0008033937192521989
Epoch:  212  	Training Loss: 0.0006602463545277715
Test Loss:  0.0004927943227812648
Valid Loss:  0.0008010344463400543
Epoch:  213  	Training Loss: 0.0006577955791726708
Test Loss:  0.0004909189883619547
Valid Loss:  0.0007987855933606625
Epoch:  214  	Training Loss: 0.0006556478329002857
Test Loss:  0.0004889317788183689
Valid Loss:  0.0007966235280036926
Epoch:  215  	Training Loss: 0.0006536192959174514
Test Loss:  0.0004869185504503548
Valid Loss:  0.000794560182839632
Epoch:  216  	Training Loss: 0.0006517094443552196
Test Loss:  0.00048488660831935704
Valid Loss:  0.0007925997488200665
Epoch:  217  	Training Loss: 0.0006499173468910158
Test Loss:  0.0004829674435313791
Valid Loss:  0.0007907096296548843
Epoch:  218  	Training Loss: 0.0006481739110313356
Test Loss:  0.00048132368829101324
Valid Loss:  0.0007889712578617036
Epoch:  219  	Training Loss: 0.0006465677870437503
Test Loss:  0.00047966689453460276
Valid Loss:  0.0007873158901929855
Epoch:  220  	Training Loss: 0.000645102933049202
Test Loss:  0.00047807616647332907
Valid Loss:  0.000785679672844708
Epoch:  221  	Training Loss: 0.000643667415715754
Test Loss:  0.00047661649296060205
Valid Loss:  0.0007841249462217093
Epoch:  222  	Training Loss: 0.0006422760197892785
Test Loss:  0.0004759912844747305
Valid Loss:  0.000783422845415771
Epoch:  223  	Training Loss: 0.0006415494717657566
Test Loss:  0.00047531197196803987
Valid Loss:  0.0007826891378499568
Epoch:  224  	Training Loss: 0.0006408363115042448
Test Loss:  0.0004745929327327758
Valid Loss:  0.0007819572929292917
Epoch:  225  	Training Loss: 0.0006401545251719654
Test Loss:  0.0004738793068099767
Valid Loss:  0.0007812408730387688
Epoch:  226  	Training Loss: 0.0006395004456862807
Test Loss:  0.00047312231617979705
Valid Loss:  0.0007804798660799861
Epoch:  227  	Training Loss: 0.0006388500914908946
Test Loss:  0.0004723809252027422
Valid Loss:  0.0007797607686370611
Epoch:  228  	Training Loss: 0.000638205383438617
Test Loss:  0.0004716358089353889
Valid Loss:  0.0007790504605509341
Epoch:  229  	Training Loss: 0.0006375674274750054
Test Loss:  0.00047095835907384753
Valid Loss:  0.0007783848559483886
Epoch:  230  	Training Loss: 0.0006369835464283824
Test Loss:  0.00047039627679623663
Valid Loss:  0.0007777740247547626
Epoch:  231  	Training Loss: 0.0006364062428474426
Test Loss:  0.00046986225061118603
Valid Loss:  0.0007771997479721904
Epoch:  232  	Training Loss: 0.0006358267855830491
Test Loss:  0.0004664821899496019
Valid Loss:  0.0007747626514174044
Epoch:  233  	Training Loss: 0.00063437654171139
Test Loss:  0.00046389695489779115
Valid Loss:  0.0007727947668172419
Epoch:  234  	Training Loss: 0.0006330470205284655
Test Loss:  0.00046165953972376883
Valid Loss:  0.0007710736244916916
Epoch:  235  	Training Loss: 0.0006317719235084951
Test Loss:  0.0004598054219968617
Valid Loss:  0.0007696668617427349
Epoch:  236  	Training Loss: 0.0006306229624897242
Test Loss:  0.00045838160440325737
Valid Loss:  0.0007684966549277306
Epoch:  237  	Training Loss: 0.0006295526982285082
Test Loss:  0.00045714093721471727
Valid Loss:  0.0007674697553738952
Epoch:  238  	Training Loss: 0.0006284993723966181
Test Loss:  0.00045597972348332405
Valid Loss:  0.0007664731238037348
Epoch:  239  	Training Loss: 0.0006274876068346202
Test Loss:  0.00045485139708034694
Valid Loss:  0.000765527889598161
Epoch:  240  	Training Loss: 0.0006265026750043035
Test Loss:  0.00045374437468126416
Valid Loss:  0.0007645980222150683
Epoch:  241  	Training Loss: 0.0006255394546315074
Test Loss:  0.0004526486445683986
Valid Loss:  0.0007636773516424
Epoch:  242  	Training Loss: 0.0006246140110306442
Test Loss:  0.0004516738699749112
Valid Loss:  0.000762611161917448
Epoch:  243  	Training Loss: 0.0006231543375179172
Test Loss:  0.0004505454271566123
Valid Loss:  0.0007614996284246445
Epoch:  244  	Training Loss: 0.0006217935588210821
Test Loss:  0.0004493789456319064
Valid Loss:  0.0007603715057484806
Epoch:  245  	Training Loss: 0.0006204851670190692
Test Loss:  0.000448075239546597
Valid Loss:  0.0007592048496007919
Epoch:  246  	Training Loss: 0.0006192339933477342
Test Loss:  0.000446818710770458
Valid Loss:  0.0007580714300274849
Epoch:  247  	Training Loss: 0.0006180568598210812
Test Loss:  0.00044563430128619075
Valid Loss:  0.0007569860899820924
Epoch:  248  	Training Loss: 0.000616911449469626
Test Loss:  0.00044443755177780986
Valid Loss:  0.0007559058722108603
Epoch:  249  	Training Loss: 0.0006157789030112326
Test Loss:  0.0004432443529367447
Valid Loss:  0.0007548525463789701
Epoch:  250  	Training Loss: 0.0006146900705061853
Test Loss:  0.0004421239427756518
Valid Loss:  0.0007538499776273966
Epoch:  251  	Training Loss: 0.0006136406445875764
Test Loss:  0.0004410655819810927
Valid Loss:  0.0007529124850407243
Epoch:  252  	Training Loss: 0.0006126267253421247
Test Loss:  0.0004406385705806315
Valid Loss:  0.0007520581712014973
Epoch:  253  	Training Loss: 0.0006109373643994331
Test Loss:  0.00044005486415699124
Valid Loss:  0.0007511735311709344
Epoch:  254  	Training Loss: 0.0006095769931562245
Test Loss:  0.0004394542775116861
Valid Loss:  0.0007503470405936241
Epoch:  255  	Training Loss: 0.0006084836204536259
Test Loss:  0.00043873023241758347
Valid Loss:  0.0007494671735912561
Epoch:  256  	Training Loss: 0.0006074960110709071
Test Loss:  0.0004380720783956349
Valid Loss:  0.0007486467948183417
Epoch:  257  	Training Loss: 0.000606588670052588
Test Loss:  0.00043735356302931905
Valid Loss:  0.0007478269981220365
Epoch:  258  	Training Loss: 0.0006057448335923254
Test Loss:  0.0004366683424450457
Valid Loss:  0.0007470296695828438
Epoch:  259  	Training Loss: 0.0006049378425814211
Test Loss:  0.00043588312109932303
Valid Loss:  0.0007461874047294259
Epoch:  260  	Training Loss: 0.0006041701999492943
Test Loss:  0.000435118650784716
Valid Loss:  0.0007453615544363856
Epoch:  261  	Training Loss: 0.0006034293910488486
Test Loss:  0.000434432877227664
Valid Loss:  0.0007445511291734874
Epoch:  262  	Training Loss: 0.0006027122144587338
Test Loss:  0.00043421797454357147
Valid Loss:  0.000743505428545177
Epoch:  263  	Training Loss: 0.000601554405875504
Test Loss:  0.0004336817655712366
Valid Loss:  0.0007423760835081339
Epoch:  264  	Training Loss: 0.0006004759343340993
Test Loss:  0.0004330878145992756
Valid Loss:  0.0007412657723762095
Epoch:  265  	Training Loss: 0.0005994263337925076
Test Loss:  0.00043245009146630764
Valid Loss:  0.0007401506300084293
Epoch:  266  	Training Loss: 0.0005984007148072124
Test Loss:  0.00043182962690480053
Valid Loss:  0.000739089329726994
Epoch:  267  	Training Loss: 0.0005974444793537259
Test Loss:  0.0004311216762289405
Valid Loss:  0.000737998983822763
Epoch:  268  	Training Loss: 0.0005965364398434758
Test Loss:  0.00043019576696678996
Valid Loss:  0.0007369042141363025
Epoch:  269  	Training Loss: 0.0005956898676231503
Test Loss:  0.00042935856617987156
Valid Loss:  0.0007358632865361869
Epoch:  270  	Training Loss: 0.0005948628531768918
Test Loss:  0.0004285590839572251
Valid Loss:  0.0007348536164499819
Epoch:  271  	Training Loss: 0.0005940509727224708
Test Loss:  0.00042778655188158154
Valid Loss:  0.0007338603027164936
Epoch:  272  	Training Loss: 0.0005932499188929796
Test Loss:  0.00042786134872585535
Valid Loss:  0.0007332413224503398
Epoch:  273  	Training Loss: 0.0005926165031269193
Test Loss:  0.00042796501656994224
Valid Loss:  0.0007326629711315036
Epoch:  274  	Training Loss: 0.00059203349519521
Test Loss:  0.0004280175198800862
Valid Loss:  0.0007320719305425882
Epoch:  275  	Training Loss: 0.0005914799403399229
Test Loss:  0.0004279215936549008
Valid Loss:  0.0007314669783227146
 55%|█████▌    | 276/500 [03:11<02:18,  1.62it/s] 56%|█████▌    | 278/500 [03:11<01:40,  2.22it/s] 56%|█████▌    | 280/500 [03:12<01:13,  2.98it/s] 56%|█████▋    | 282/500 [03:18<04:15,  1.17s/it] 57%|█████▋    | 284/500 [03:18<03:01,  1.19it/s] 57%|█████▋    | 286/500 [03:18<02:09,  1.65it/s] 58%|█████▊    | 288/500 [03:18<01:34,  2.25it/s] 58%|█████▊    | 290/500 [03:18<01:09,  3.02it/s] 58%|█████▊    | 292/500 [03:25<04:06,  1.19s/it] 59%|█████▉    | 294/500 [03:25<02:55,  1.18it/s] 59%|█████▉    | 296/500 [03:25<02:05,  1.63it/s] 60%|█████▉    | 298/500 [03:25<01:30,  2.22it/s] 60%|██████    | 300/500 [03:25<01:06,  2.99it/s] 60%|██████    | 302/500 [03:32<03:54,  1.18s/it] 61%|██████    | 304/500 [03:32<02:46,  1.18it/s] 61%|██████    | 306/500 [03:32<01:59,  1.63it/s] 62%|██████▏   | 308/500 [03:32<01:26,  2.23it/s] 62%|██████▏   | 310/500 [03:32<01:03,  2.99it/s] 62%|██████▏   | 312/500 [03:39<03:45,  1.20s/it] 63%|██████▎   | 314/500 [03:39<02:40,  1.16it/s] 63%|██████▎   | 316/500 [03:39<01:54,  1.60it/s] 64%|██████▎   | 318/500 [03:39<01:23,  2.19it/s] 64%|██████▍   | 320/500 [03:39<01:01,  2.93it/s] 64%|██████▍   | 322/500 [03:46<03:33,  1.20s/it] 65%|██████▍   | 324/500 [03:46<02:32,  1.15it/s] 65%|██████▌   | 326/500 [03:46<01:50,  1.58it/s] 66%|██████▌   | 328/500 [03:46<01:20,  2.14it/s] 66%|██████▌   | 330/500 [03:46<01:00,  2.83it/s] 66%|██████▋   | 332/500 [03:53<03:23,  1.21s/it] 67%|██████▋   | 334/500 [03:53<02:24,  1.15it/s] 67%|██████▋   | 336/500 [03:53<01:43,  1.59it/s] 68%|██████▊   | 338/500 [03:53<01:14,  2.18it/s] 68%|██████▊   | 340/500 [03:53<00:54,  2.93it/s] 68%|██████▊   | 342/500 [03:59<03:06,  1.18s/it]Epoch:  276  	Training Loss: 0.0005909851752221584
Test Loss:  0.0004278730775695294
Valid Loss:  0.0007309156935662031
Epoch:  277  	Training Loss: 0.0005905277794227004
Test Loss:  0.00042778579518198967
Valid Loss:  0.0007303741876967251
Epoch:  278  	Training Loss: 0.0005900840042158961
Test Loss:  0.00042761440272442997
Valid Loss:  0.0007298309355974197
Epoch:  279  	Training Loss: 0.000589665025472641
Test Loss:  0.00042738692718558013
Valid Loss:  0.0007292854716069996
Epoch:  280  	Training Loss: 0.0005892694462090731
Test Loss:  0.00042714946903288364
Valid Loss:  0.0007287401240319014
Epoch:  281  	Training Loss: 0.0005888917366974056
Test Loss:  0.00042684798245318234
Valid Loss:  0.0007282238220795989
Epoch:  282  	Training Loss: 0.0005885440041311085
Test Loss:  0.00042192667024210095
Valid Loss:  0.0007241284474730492
Epoch:  283  	Training Loss: 0.0005867329891771078
Test Loss:  0.0004200469411443919
Valid Loss:  0.0007222772110253572
Epoch:  284  	Training Loss: 0.0005857374053448439
Test Loss:  0.00041939615039154887
Valid Loss:  0.0007212259224615991
Epoch:  285  	Training Loss: 0.0005849828594364226
Test Loss:  0.00041906500700861216
Valid Loss:  0.0007204722496680915
Epoch:  286  	Training Loss: 0.0005842933896929026
Test Loss:  0.00041880898061208427
Valid Loss:  0.0007197617087513208
Epoch:  287  	Training Loss: 0.000583646644372493
Test Loss:  0.00041879902710206807
Valid Loss:  0.0007192543707787991
Epoch:  288  	Training Loss: 0.0005830315640196204
Test Loss:  0.0004187205049674958
Valid Loss:  0.000718725728802383
Epoch:  289  	Training Loss: 0.0005824309191666543
Test Loss:  0.00041853447328321636
Valid Loss:  0.0007181428372859955
Epoch:  290  	Training Loss: 0.0005818336503580213
Test Loss:  0.00041833060095086694
Valid Loss:  0.000717568676918745
Epoch:  291  	Training Loss: 0.0005812466260977089
Test Loss:  0.00041810068069025874
Valid Loss:  0.0007170051103457808
Epoch:  292  	Training Loss: 0.0005806667031720281
Test Loss:  0.00041599705582484603
Valid Loss:  0.0007150189485400915
Epoch:  293  	Training Loss: 0.0005789932329207659
Test Loss:  0.0004139977681916207
Valid Loss:  0.0007130943704396486
Epoch:  294  	Training Loss: 0.0005773557350039482
Test Loss:  0.00041212671203538775
Valid Loss:  0.0007112435414455831
Epoch:  295  	Training Loss: 0.0005757713806815445
Test Loss:  0.0004103725077584386
Valid Loss:  0.0007094694301486015
Epoch:  296  	Training Loss: 0.0005742445937357843
Test Loss:  0.0004087047418579459
Valid Loss:  0.0007077448535710573
Epoch:  297  	Training Loss: 0.0005727590760216117
Test Loss:  0.00040709617314860225
Valid Loss:  0.000706056016497314
Epoch:  298  	Training Loss: 0.0005713023128919303
Test Loss:  0.00040553638245910406
Valid Loss:  0.000704414676874876
Epoch:  299  	Training Loss: 0.0005698954337276518
Test Loss:  0.00040401576552540064
Valid Loss:  0.0007028154795989394
Epoch:  300  	Training Loss: 0.0005685076466761529
Test Loss:  0.0004025530652143061
Valid Loss:  0.0007012550486251712
Epoch:  301  	Training Loss: 0.0005671505932696164
Test Loss:  0.0004011988639831543
Valid Loss:  0.000699736992828548
Epoch:  302  	Training Loss: 0.0005658200825564563
Test Loss:  0.00040159851778298616
Valid Loss:  0.0006995965959504247
Epoch:  303  	Training Loss: 0.0005654627457261086
Test Loss:  0.00040186202386394143
Valid Loss:  0.0006993983406573534
Epoch:  304  	Training Loss: 0.0005651120445691049
Test Loss:  0.00040200300281867385
Valid Loss:  0.0006991419359110296
Epoch:  305  	Training Loss: 0.0005647683283314109
Test Loss:  0.00040208949940279126
Valid Loss:  0.0006988722598180175
Epoch:  306  	Training Loss: 0.0005644344491884112
Test Loss:  0.0004021086497232318
Valid Loss:  0.0006985828513279557
Epoch:  307  	Training Loss: 0.0005641035968437791
Test Loss:  0.00040211097802966833
Valid Loss:  0.0006982886698096991
Epoch:  308  	Training Loss: 0.0005637812428176403
Test Loss:  0.0004020584747195244
Valid Loss:  0.0006979728350415826
Epoch:  309  	Training Loss: 0.0005634648259729147
Test Loss:  0.00040197058115154505
Valid Loss:  0.000697641633450985
Epoch:  310  	Training Loss: 0.0005631523090414703
Test Loss:  0.00040185311809182167
Valid Loss:  0.0006973021663725376
Epoch:  311  	Training Loss: 0.0005628481740131974
Test Loss:  0.00040170131251215935
Valid Loss:  0.0006969526875764132
Epoch:  312  	Training Loss: 0.0005625556223094463
Test Loss:  0.0004012548888567835
Valid Loss:  0.000696119386702776
Epoch:  313  	Training Loss: 0.0005618203431367874
Test Loss:  0.0004008138203062117
Valid Loss:  0.0006953105330467224
Epoch:  314  	Training Loss: 0.0005610903026536107
Test Loss:  0.00040036559221334755
Valid Loss:  0.0006945161148905754
Epoch:  315  	Training Loss: 0.0005603616591542959
Test Loss:  0.0003998075262643397
Valid Loss:  0.0006936218123883009
Epoch:  316  	Training Loss: 0.0005596334813162684
Test Loss:  0.00039927451871335506
Valid Loss:  0.00069280038587749
Epoch:  317  	Training Loss: 0.000558914733119309
Test Loss:  0.00039868909516371787
Valid Loss:  0.0006919305305927992
Epoch:  318  	Training Loss: 0.0005581940058618784
Test Loss:  0.0003981413901783526
Valid Loss:  0.0006910991505719721
Epoch:  319  	Training Loss: 0.0005574781680479646
Test Loss:  0.0003975461586378515
Valid Loss:  0.0006902232998982072
Epoch:  320  	Training Loss: 0.0005567604675889015
Test Loss:  0.000396993535105139
Valid Loss:  0.0006893905228935182
Epoch:  321  	Training Loss: 0.000556044396944344
Test Loss:  0.00039639510214328766
Valid Loss:  0.0006885131588205695
Epoch:  322  	Training Loss: 0.0005553301307372749
Test Loss:  0.00039543051389046013
Valid Loss:  0.0006873748498037457
Epoch:  323  	Training Loss: 0.0005541482823900878
Test Loss:  0.00039445311995223165
Valid Loss:  0.0006862746085971594
Epoch:  324  	Training Loss: 0.000553012709133327
Test Loss:  0.0003934364940505475
Valid Loss:  0.0006851544603705406
Epoch:  325  	Training Loss: 0.0005519326659850776
Test Loss:  0.0003924178599845618
Valid Loss:  0.000684061087667942
Epoch:  326  	Training Loss: 0.0005508872563950717
Test Loss:  0.00039145126356743276
Valid Loss:  0.0006830099155195057
Epoch:  327  	Training Loss: 0.0005498994723893702
Test Loss:  0.0003906066995114088
Valid Loss:  0.0006820206763222814
Epoch:  328  	Training Loss: 0.0005489824106916785
Test Loss:  0.0003897465649060905
Valid Loss:  0.000681026722304523
Epoch:  329  	Training Loss: 0.0005480730324052274
Test Loss:  0.0003889375366270542
Valid Loss:  0.0006800579722039402
Epoch:  330  	Training Loss: 0.0005471855401992798
Test Loss:  0.0003881462325807661
Valid Loss:  0.0006791475461795926
Epoch:  331  	Training Loss: 0.0005463056149892509
Test Loss:  0.00038731686072424054
Valid Loss:  0.0006782404379919171
Epoch:  332  	Training Loss: 0.0005454457714222372
Test Loss:  0.0003864798927679658
Valid Loss:  0.0006773284985683858
Epoch:  333  	Training Loss: 0.0005446606664918363
Test Loss:  0.00038563201087526977
Valid Loss:  0.0006764448480680585
Epoch:  334  	Training Loss: 0.000543920265045017
Test Loss:  0.0003848914348054677
Valid Loss:  0.0006756279617547989
Epoch:  335  	Training Loss: 0.0005432252655737102
Test Loss:  0.0003840722783934325
Valid Loss:  0.0006748400628566742
Epoch:  336  	Training Loss: 0.0005425735143944621
Test Loss:  0.00038331851828843355
Valid Loss:  0.000674091512337327
Epoch:  337  	Training Loss: 0.0005419273511506617
Test Loss:  0.00038265465991571546
Valid Loss:  0.0006733807967975736
Epoch:  338  	Training Loss: 0.0005412939935922623
Test Loss:  0.00038196382229216397
Valid Loss:  0.0006726947613060474
Epoch:  339  	Training Loss: 0.0005407115677371621
Test Loss:  0.00038134108763188124
Valid Loss:  0.0006720410310663283
Epoch:  340  	Training Loss: 0.0005401402013376355
Test Loss:  0.00038072510506026447
Valid Loss:  0.0006714008050039411
Epoch:  341  	Training Loss: 0.0005395736079663038
Test Loss:  0.00038010242860764265
Valid Loss:  0.0006707882275804877
Epoch:  342  	Training Loss: 0.0005390222650021315
Test Loss:  0.0003797756799031049
Valid Loss:  0.0006697241915389895
Epoch:  343  	Training Loss: 0.0005379795329645276
Test Loss:  0.00037931810948066413
Valid Loss:  0.0006686255219392478
 69%|██████▉   | 344/500 [04:00<02:12,  1.18it/s] 69%|██████▉   | 346/500 [04:00<01:35,  1.61it/s] 70%|██████▉   | 348/500 [04:00<01:09,  2.20it/s] 70%|███████   | 350/500 [04:00<00:50,  2.95it/s] 70%|███████   | 352/500 [04:06<02:52,  1.17s/it] 71%|███████   | 354/500 [04:06<02:02,  1.20it/s] 71%|███████   | 356/500 [04:07<01:27,  1.65it/s] 72%|███████▏  | 358/500 [04:07<01:03,  2.23it/s] 72%|███████▏  | 360/500 [04:07<00:47,  2.94it/s] 72%|███████▏  | 362/500 [04:13<02:46,  1.20s/it] 73%|███████▎  | 364/500 [04:13<01:57,  1.16it/s] 73%|███████▎  | 366/500 [04:14<01:23,  1.60it/s] 74%|███████▎  | 368/500 [04:14<01:00,  2.19it/s] 74%|███████▍  | 370/500 [04:14<00:44,  2.94it/s] 74%|███████▍  | 372/500 [04:20<02:31,  1.18s/it] 75%|███████▍  | 374/500 [04:20<01:46,  1.18it/s] 75%|███████▌  | 376/500 [04:20<01:15,  1.63it/s] 76%|███████▌  | 378/500 [04:21<00:54,  2.23it/s] 76%|███████▌  | 380/500 [04:21<00:40,  2.99it/s] 76%|███████▋  | 382/500 [04:27<02:19,  1.18s/it] 77%|███████▋  | 384/500 [04:27<01:38,  1.18it/s] 77%|███████▋  | 386/500 [04:27<01:09,  1.64it/s] 78%|███████▊  | 388/500 [04:27<00:50,  2.24it/s] 78%|███████▊  | 390/500 [04:27<00:36,  3.01it/s] 78%|███████▊  | 392/500 [04:34<02:06,  1.17s/it] 79%|███████▉  | 394/500 [04:34<01:28,  1.20it/s] 79%|███████▉  | 396/500 [04:34<01:02,  1.65it/s] 80%|███████▉  | 398/500 [04:34<00:45,  2.26it/s] 80%|████████  | 400/500 [04:34<00:33,  3.00it/s] 80%|████████  | 402/500 [04:41<01:58,  1.20s/it] 81%|████████  | 404/500 [04:41<01:22,  1.16it/s] 81%|████████  | 406/500 [04:41<00:58,  1.60it/s] 82%|████████▏ | 408/500 [04:41<00:42,  2.19it/s] 82%|████████▏ | 410/500 [04:41<00:30,  2.94it/s]Epoch:  344  	Training Loss: 0.0005369748687371612
Test Loss:  0.0003787073655985296
Valid Loss:  0.0006675293552689254
Epoch:  345  	Training Loss: 0.0005359937786124647
Test Loss:  0.00037800203426741064
Valid Loss:  0.000666372012346983
Epoch:  346  	Training Loss: 0.0005350277642719448
Test Loss:  0.0003772786003537476
Valid Loss:  0.0006652347510680556
Epoch:  347  	Training Loss: 0.0005340705392882228
Test Loss:  0.00037652597529813647
Valid Loss:  0.000664104416500777
Epoch:  348  	Training Loss: 0.000533130660187453
Test Loss:  0.0003757088561542332
Valid Loss:  0.0006629567360505462
Epoch:  349  	Training Loss: 0.0005322156939655542
Test Loss:  0.00037493460695259273
Valid Loss:  0.0006618438055738807
Epoch:  350  	Training Loss: 0.0005313082365319133
Test Loss:  0.0003741532564163208
Valid Loss:  0.00066073436755687
Epoch:  351  	Training Loss: 0.0005304115475155413
Test Loss:  0.00037337368121370673
Valid Loss:  0.000659630517475307
Epoch:  352  	Training Loss: 0.0005295223090797663
Test Loss:  0.00037388410419225693
Valid Loss:  0.0006594096776098013
Epoch:  353  	Training Loss: 0.0005288319662213326
Test Loss:  0.00037399702705442905
Valid Loss:  0.0006590156117454171
Epoch:  354  	Training Loss: 0.0005283205537125468
Test Loss:  0.0003740007523447275
Valid Loss:  0.0006586217205040157
Epoch:  355  	Training Loss: 0.0005279108881950378
Test Loss:  0.00037384082679636776
Valid Loss:  0.0006582298665307462
Epoch:  356  	Training Loss: 0.0005275745643302798
Test Loss:  0.00037355220410972834
Valid Loss:  0.0006578168249689043
Epoch:  357  	Training Loss: 0.0005273081478662789
Test Loss:  0.0003732444893103093
Valid Loss:  0.0006574267754331231
Epoch:  358  	Training Loss: 0.000527077354490757
Test Loss:  0.0003730587777681649
Valid Loss:  0.0006571137928403914
Epoch:  359  	Training Loss: 0.0005268715904094279
Test Loss:  0.0003728386654984206
Valid Loss:  0.0006568070966750383
Epoch:  360  	Training Loss: 0.0005266947555355728
Test Loss:  0.00037257815711200237
Valid Loss:  0.0006565051153302193
Epoch:  361  	Training Loss: 0.0005265382351353765
Test Loss:  0.0003722942201420665
Valid Loss:  0.0006562232738360763
Epoch:  362  	Training Loss: 0.000526409363374114
Test Loss:  0.00037143408553674817
Valid Loss:  0.0006554973078891635
Epoch:  363  	Training Loss: 0.0005259827012196183
Test Loss:  0.00037077590241096914
Valid Loss:  0.0006548656383529305
Epoch:  364  	Training Loss: 0.000525598821695894
Test Loss:  0.0003702305257320404
Valid Loss:  0.0006542959017679095
Epoch:  365  	Training Loss: 0.0005252332775853574
Test Loss:  0.00036976224509999156
Valid Loss:  0.0006537772715091705
Epoch:  366  	Training Loss: 0.0005248928209766746
Test Loss:  0.0003692942555062473
Valid Loss:  0.000653279828839004
Epoch:  367  	Training Loss: 0.0005245663924142718
Test Loss:  0.00036887964233756065
Valid Loss:  0.0006528261583298445
Epoch:  368  	Training Loss: 0.0005242517800070345
Test Loss:  0.00036857338272966444
Valid Loss:  0.0006524363998323679
Epoch:  369  	Training Loss: 0.0005239548627287149
Test Loss:  0.0003682900278363377
Valid Loss:  0.000652062357403338
Epoch:  370  	Training Loss: 0.0005236582364886999
Test Loss:  0.0003680317313410342
Valid Loss:  0.000651724636554718
Epoch:  371  	Training Loss: 0.000523383030667901
Test Loss:  0.00036781717790290713
Valid Loss:  0.0006514176493510604
Epoch:  372  	Training Loss: 0.000523122726008296
Test Loss:  0.00036517615080811083
Valid Loss:  0.0006488960352726281
Epoch:  373  	Training Loss: 0.000521772017236799
Test Loss:  0.00036356644704937935
Valid Loss:  0.0006470921798609197
Epoch:  374  	Training Loss: 0.0005206862697377801
Test Loss:  0.0003626018879003823
Valid Loss:  0.0006456683040596545
Epoch:  375  	Training Loss: 0.0005197228165343404
Test Loss:  0.0003619859926402569
Valid Loss:  0.0006445525214076042
Epoch:  376  	Training Loss: 0.0005188289796933532
Test Loss:  0.00036146986531093717
Valid Loss:  0.0006435246905311942
Epoch:  377  	Training Loss: 0.000517985608894378
Test Loss:  0.0003610621497500688
Valid Loss:  0.0006425734027288854
Epoch:  378  	Training Loss: 0.0005171989323571324
Test Loss:  0.00036068621557205915
Valid Loss:  0.0006416934193111956
Epoch:  379  	Training Loss: 0.0005164546892046928
Test Loss:  0.000360303238267079
Valid Loss:  0.0006408388144336641
Epoch:  380  	Training Loss: 0.0005157466512173414
Test Loss:  0.00035996362566947937
Valid Loss:  0.0006400622078217566
Epoch:  381  	Training Loss: 0.0005150666693225503
Test Loss:  0.0003595831512939185
Valid Loss:  0.0006393033545464277
Epoch:  382  	Training Loss: 0.0005144153255969286
Test Loss:  0.00035978396772406995
Valid Loss:  0.0006389092304743826
Epoch:  383  	Training Loss: 0.0005136601394042373
Test Loss:  0.000359723053406924
Valid Loss:  0.0006384030566550791
Epoch:  384  	Training Loss: 0.0005129362107254565
Test Loss:  0.00035953475162386894
Valid Loss:  0.0006378019461408257
Epoch:  385  	Training Loss: 0.0005122206639498472
Test Loss:  0.0003592155990190804
Valid Loss:  0.0006371507188305259
Epoch:  386  	Training Loss: 0.0005115223466418684
Test Loss:  0.0003587660612538457
Valid Loss:  0.0006364595610648394
Epoch:  387  	Training Loss: 0.000510850572027266
Test Loss:  0.0003582870413083583
Valid Loss:  0.0006357636884786189
Epoch:  388  	Training Loss: 0.0005101998103782535
Test Loss:  0.00035778991878032684
Valid Loss:  0.0006350548355840147
Epoch:  389  	Training Loss: 0.0005095575470477343
Test Loss:  0.00035727908834815025
Valid Loss:  0.0006343316053971648
Epoch:  390  	Training Loss: 0.000508924713358283
Test Loss:  0.00035670632496476173
Valid Loss:  0.0006336042424663901
Epoch:  391  	Training Loss: 0.0005083048017695546
Test Loss:  0.0003561403718777001
Valid Loss:  0.0006328820018097758
Epoch:  392  	Training Loss: 0.0005076847737655044
Test Loss:  0.0003553102142177522
Valid Loss:  0.000631698640063405
Epoch:  393  	Training Loss: 0.0005062927957624197
Test Loss:  0.00035463995300233364
Valid Loss:  0.0006305365823209286
Epoch:  394  	Training Loss: 0.0005049991887062788
Test Loss:  0.0003539291210472584
Valid Loss:  0.0006293078185990453
Epoch:  395  	Training Loss: 0.0005037611699663103
Test Loss:  0.0003530699177645147
Valid Loss:  0.0006280374946072698
Epoch:  396  	Training Loss: 0.0005025707650929689
Test Loss:  0.0003522046026773751
Valid Loss:  0.0006267724093049765
Epoch:  397  	Training Loss: 0.0005014104535803199
Test Loss:  0.00035138303064741194
Valid Loss:  0.0006255373009480536
Epoch:  398  	Training Loss: 0.0005002794787287712
Test Loss:  0.00035046684206463397
Valid Loss:  0.00062424351926893
Epoch:  399  	Training Loss: 0.0004991578171029687
Test Loss:  0.0003496331919450313
Valid Loss:  0.0006230229046195745
Epoch:  400  	Training Loss: 0.0004980493104085326
Test Loss:  0.00034872174728661776
Valid Loss:  0.000621739833150059
Epoch:  401  	Training Loss: 0.000496959313750267
Test Loss:  0.0003477364662103355
Valid Loss:  0.0006204668316058815
Epoch:  402  	Training Loss: 0.000495895161293447
Test Loss:  0.00034602696541696787
Valid Loss:  0.0006192554137669504
Epoch:  403  	Training Loss: 0.0004952574381604791
Test Loss:  0.0003447018680162728
Valid Loss:  0.0006182400393299758
Epoch:  404  	Training Loss: 0.0004946424160152674
Test Loss:  0.0003436343395151198
Valid Loss:  0.0006173508008942008
Epoch:  405  	Training Loss: 0.0004940396756865084
Test Loss:  0.0003427383489906788
Valid Loss:  0.0006165542872622609
Epoch:  406  	Training Loss: 0.0004934546886943281
Test Loss:  0.00034200301161035895
Valid Loss:  0.000615827098954469
Epoch:  407  	Training Loss: 0.0004928767448291183
Test Loss:  0.000341326289344579
Valid Loss:  0.0006151283159852028
Epoch:  408  	Training Loss: 0.0004923028755001724
Test Loss:  0.00034071216941811144
Valid Loss:  0.000614458229392767
Epoch:  409  	Training Loss: 0.0004917440819554031
Test Loss:  0.0003401347203180194
Valid Loss:  0.0006137973978184164
Epoch:  410  	Training Loss: 0.0004911876749247313
Test Loss:  0.0003395747917238623
Valid Loss:  0.0006131493719294667
Epoch:  411  	Training Loss: 0.0004906374379061162
Test Loss:  0.0003390967031009495
Valid Loss:  0.0006125425570644438
 82%|████████▏ | 412/500 [04:48<01:44,  1.19s/it] 83%|████████▎ | 414/500 [04:48<01:13,  1.17it/s] 83%|████████▎ | 416/500 [04:48<00:51,  1.62it/s] 84%|████████▎ | 418/500 [04:48<00:37,  2.21it/s] 84%|████████▍ | 420/500 [04:48<00:27,  2.96it/s] 84%|████████▍ | 422/500 [04:54<01:31,  1.17s/it] 85%|████████▍ | 424/500 [04:55<01:03,  1.19it/s] 85%|████████▌ | 426/500 [04:55<00:44,  1.65it/s] 86%|████████▌ | 428/500 [04:55<00:32,  2.25it/s] 86%|████████▌ | 430/500 [04:55<00:23,  3.02it/s] 86%|████████▋ | 432/500 [05:01<01:19,  1.17s/it] 87%|████████▋ | 434/500 [05:01<00:55,  1.20it/s] 87%|████████▋ | 436/500 [05:01<00:38,  1.65it/s] 88%|████████▊ | 438/500 [05:02<00:27,  2.26it/s] 88%|████████▊ | 440/500 [05:02<00:19,  3.03it/s] 88%|████████▊ | 442/500 [05:08<01:07,  1.16s/it] 89%|████████▉ | 444/500 [05:08<00:46,  1.20it/s] 89%|████████▉ | 446/500 [05:08<00:32,  1.66it/s] 90%|████████▉ | 448/500 [05:08<00:23,  2.26it/s] 90%|█████████ | 450/500 [05:08<00:16,  3.04it/s] 90%|█████████ | 452/500 [05:15<00:56,  1.18s/it] 91%|█████████ | 454/500 [05:15<00:38,  1.19it/s] 91%|█████████ | 456/500 [05:15<00:26,  1.64it/s] 92%|█████████▏| 458/500 [05:15<00:18,  2.24it/s] 92%|█████████▏| 460/500 [05:15<00:13,  2.99it/s] 92%|█████████▏| 462/500 [05:22<00:44,  1.18s/it] 93%|█████████▎| 464/500 [05:22<00:30,  1.19it/s] 93%|█████████▎| 466/500 [05:22<00:20,  1.64it/s] 94%|█████████▎| 468/500 [05:22<00:14,  2.25it/s] 94%|█████████▍| 470/500 [05:22<00:09,  3.02it/s] 94%|█████████▍| 472/500 [05:28<00:32,  1.17s/it] 95%|█████████▍| 474/500 [05:28<00:21,  1.19it/s] 95%|█████████▌| 476/500 [05:29<00:14,  1.65it/s] 96%|█████████▌| 478/500 [05:29<00:09,  2.26it/s]Epoch:  412  	Training Loss: 0.0004901119973510504
Test Loss:  0.00033613911364227533
Valid Loss:  0.0006097065634094179
Epoch:  413  	Training Loss: 0.00048827158752828836
Test Loss:  0.0003346468729432672
Valid Loss:  0.0006078339647501707
Epoch:  414  	Training Loss: 0.00048684768262319267
Test Loss:  0.00033363921102136374
Valid Loss:  0.0006063444307073951
Epoch:  415  	Training Loss: 0.00048561152652837336
Test Loss:  0.0003328047750983387
Valid Loss:  0.0006050301599316299
Epoch:  416  	Training Loss: 0.0004844598879572004
Test Loss:  0.00033203201019205153
Valid Loss:  0.0006037958664819598
Epoch:  417  	Training Loss: 0.0004833781276829541
Test Loss:  0.0003313181223347783
Valid Loss:  0.0006026971386745572
Epoch:  418  	Training Loss: 0.0004823831550311297
Test Loss:  0.00033064521267078817
Valid Loss:  0.0006016740808263421
Epoch:  419  	Training Loss: 0.00048142625018954277
Test Loss:  0.0003299660747870803
Valid Loss:  0.000600675935856998
Epoch:  420  	Training Loss: 0.0004804955096915364
Test Loss:  0.00032928684959188104
Valid Loss:  0.0005996930412948132
Epoch:  421  	Training Loss: 0.00047958589857444167
Test Loss:  0.00032857657060958445
Valid Loss:  0.0005987058393657207
Epoch:  422  	Training Loss: 0.00047869072295725346
Test Loss:  0.0003289384476374835
Valid Loss:  0.0005982790607959032
Epoch:  423  	Training Loss: 0.0004776038695126772
Test Loss:  0.0003288698790129274
Valid Loss:  0.000597695354372263
Epoch:  424  	Training Loss: 0.00047656873357482255
Test Loss:  0.0003283420519437641
Valid Loss:  0.0005967788165435195
Epoch:  425  	Training Loss: 0.0004755861882586032
Test Loss:  0.00032775659929029644
Valid Loss:  0.000595953082665801
Epoch:  426  	Training Loss: 0.0004746574559248984
Test Loss:  0.00032690592342987657
Valid Loss:  0.0005949411424808204
Epoch:  427  	Training Loss: 0.00047375709982588887
Test Loss:  0.00032627128530293703
Valid Loss:  0.000594085780903697
Epoch:  428  	Training Loss: 0.0004728864296339452
Test Loss:  0.00032562794513069093
Valid Loss:  0.0005932042258791625
Epoch:  429  	Training Loss: 0.00047204384463839233
Test Loss:  0.0003249130677431822
Valid Loss:  0.0005922967684455216
Epoch:  430  	Training Loss: 0.00047124491538852453
Test Loss:  0.0003242190578021109
Valid Loss:  0.0005913992645218968
Epoch:  431  	Training Loss: 0.0004704552993644029
Test Loss:  0.00032355415169149637
Valid Loss:  0.0005905169527977705
Epoch:  432  	Training Loss: 0.00046967362868599594
Test Loss:  0.0003236083430238068
Valid Loss:  0.0005897929659113288
Epoch:  433  	Training Loss: 0.00046883203322067857
Test Loss:  0.00032341358019039035
Valid Loss:  0.0005889932508580387
Epoch:  434  	Training Loss: 0.00046801904682070017
Test Loss:  0.00032300647580996156
Valid Loss:  0.0005881240358576179
Epoch:  435  	Training Loss: 0.00046722975093871355
Test Loss:  0.00032254919642582536
Valid Loss:  0.0005872238543815911
Epoch:  436  	Training Loss: 0.00046644790563732386
Test Loss:  0.0003220621729269624
Valid Loss:  0.0005862849066033959
Epoch:  437  	Training Loss: 0.00046567991375923157
Test Loss:  0.0003214291937183589
Valid Loss:  0.0005852573085576296
Epoch:  438  	Training Loss: 0.0004649112524930388
Test Loss:  0.0003206515102647245
Valid Loss:  0.000584104098379612
Epoch:  439  	Training Loss: 0.0004641235282178968
Test Loss:  0.0003199310740455985
Valid Loss:  0.0005829571164213121
Epoch:  440  	Training Loss: 0.0004633297794498503
Test Loss:  0.0003187029215041548
Valid Loss:  0.0005814466276206076
Epoch:  441  	Training Loss: 0.00046240765368565917
Test Loss:  0.00031736880191601813
Valid Loss:  0.000579830608330667
Epoch:  442  	Training Loss: 0.00046141378697939217
Test Loss:  0.0003157606115564704
Valid Loss:  0.000578652776312083
Epoch:  443  	Training Loss: 0.0004607239388860762
Test Loss:  0.00031444866908714175
Valid Loss:  0.000577630358748138
Epoch:  444  	Training Loss: 0.00046006980119273067
Test Loss:  0.0003133415593765676
Valid Loss:  0.0005767153343185782
Epoch:  445  	Training Loss: 0.0004594361234921962
Test Loss:  0.000312374671921134
Valid Loss:  0.0005758822662755847
Epoch:  446  	Training Loss: 0.00045880716061219573
Test Loss:  0.0003115283034276217
Valid Loss:  0.0005751092103309929
Epoch:  447  	Training Loss: 0.00045818660873919725
Test Loss:  0.0003107677330262959
Valid Loss:  0.0005743888905271888
Epoch:  448  	Training Loss: 0.00045756896724924445
Test Loss:  0.00031005608616396785
Valid Loss:  0.0005736947059631348
Epoch:  449  	Training Loss: 0.0004569609882310033
Test Loss:  0.0003093966515734792
Valid Loss:  0.0005730330012738705
Epoch:  450  	Training Loss: 0.00045636200229637325
Test Loss:  0.0003088636149186641
Valid Loss:  0.0005724335205741227
Epoch:  451  	Training Loss: 0.00045577093260362744
Test Loss:  0.0003083326737396419
Valid Loss:  0.000571835320442915
Epoch:  452  	Training Loss: 0.00045518562546931207
Test Loss:  0.000309116265270859
Valid Loss:  0.0005715991137549281
Epoch:  453  	Training Loss: 0.0004547472344711423
Test Loss:  0.0003095814026892185
Valid Loss:  0.0005712488200515509
Epoch:  454  	Training Loss: 0.0004543465911410749
Test Loss:  0.0003098214801866561
Valid Loss:  0.0005708410171791911
Epoch:  455  	Training Loss: 0.00045397403300739825
Test Loss:  0.00030986100318841636
Valid Loss:  0.0005703805945813656
Epoch:  456  	Training Loss: 0.00045363279059529305
Test Loss:  0.000309807772282511
Valid Loss:  0.0005698995664715767
Epoch:  457  	Training Loss: 0.0004533011233434081
Test Loss:  0.0003096829168498516
Valid Loss:  0.000569410331081599
Epoch:  458  	Training Loss: 0.0004529783909674734
Test Loss:  0.00030954350950196385
Valid Loss:  0.0005689316894859076
Epoch:  459  	Training Loss: 0.0004526658449321985
Test Loss:  0.0003093690029345453
Valid Loss:  0.0005684781935997307
Epoch:  460  	Training Loss: 0.00045237873564474285
Test Loss:  0.00030914408853277564
Valid Loss:  0.0005680294707417488
Epoch:  461  	Training Loss: 0.00045210259850136936
Test Loss:  0.00030893675284460187
Valid Loss:  0.0005675875581800938
Epoch:  462  	Training Loss: 0.0004518275964073837
Test Loss:  0.0003089630918111652
Valid Loss:  0.0005671974504366517
Epoch:  463  	Training Loss: 0.0004511958686634898
Test Loss:  0.00030883646104484797
Valid Loss:  0.0005667407531291246
Epoch:  464  	Training Loss: 0.0004505944671109319
Test Loss:  0.00030862714629620314
Valid Loss:  0.0005662373150698841
Epoch:  465  	Training Loss: 0.0004500044451560825
Test Loss:  0.00030834664357826114
Valid Loss:  0.0005657079163938761
Epoch:  466  	Training Loss: 0.0004494254826568067
Test Loss:  0.0003080263268202543
Valid Loss:  0.0005651559331454337
Epoch:  467  	Training Loss: 0.0004488513804972172
Test Loss:  0.00030767469434067607
Valid Loss:  0.0005645858473144472
Epoch:  468  	Training Loss: 0.0004482929944060743
Test Loss:  0.0003072370891459286
Valid Loss:  0.0005639811861328781
Epoch:  469  	Training Loss: 0.00044774069101549685
Test Loss:  0.0003067866200581193
Valid Loss:  0.000563373148906976
Epoch:  470  	Training Loss: 0.0004471942665986717
Test Loss:  0.00030633423011749983
Valid Loss:  0.0005627578939311206
Epoch:  471  	Training Loss: 0.0004466605023480952
Test Loss:  0.00030587444780394435
Valid Loss:  0.0005621439777314663
Epoch:  472  	Training Loss: 0.0004461329663172364
Test Loss:  0.0003044199838768691
Valid Loss:  0.0005603071767836809
Epoch:  473  	Training Loss: 0.0004449316766113043
Test Loss:  0.00030327634885907173
Valid Loss:  0.000558665138669312
Epoch:  474  	Training Loss: 0.0004438146424945444
Test Loss:  0.0003022812306880951
Valid Loss:  0.0005571772926487029
Epoch:  475  	Training Loss: 0.00044276611879467964
Test Loss:  0.0003015028778463602
Valid Loss:  0.000555870239622891
Epoch:  476  	Training Loss: 0.0004417859308887273
Test Loss:  0.00030070223147049546
Valid Loss:  0.0005545921740122139
Epoch:  477  	Training Loss: 0.000440827920101583
Test Loss:  0.00030003744177520275
Valid Loss:  0.000553418998606503
Epoch:  478  	Training Loss: 0.0004399086465127766
Test Loss:  0.00029935187194496393
Valid Loss:  0.0005522529827430844
Epoch:  479  	Training Loss: 0.0004389975219964981
Test Loss:  0.0002986969193443656
Valid Loss:   96%|█████████▌| 480/500 [05:29<00:06,  3.03it/s] 96%|█████████▋| 482/500 [05:35<00:20,  1.16s/it] 97%|█████████▋| 484/500 [05:35<00:13,  1.20it/s] 97%|█████████▋| 486/500 [05:35<00:08,  1.66it/s] 98%|█████████▊| 488/500 [05:35<00:05,  2.27it/s] 98%|█████████▊| 490/500 [05:36<00:03,  3.05it/s] 98%|█████████▊| 492/500 [05:42<00:09,  1.17s/it] 99%|█████████▉| 494/500 [05:42<00:05,  1.19it/s] 99%|█████████▉| 496/500 [05:42<00:02,  1.65it/s]100%|█████████▉| 498/500 [05:42<00:00,  2.25it/s]100%|██████████| 500/500 [05:42<00:00,  3.02it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
0.0005511292838491499
Epoch:  480  	Training Loss: 0.00043810554780066013
Test Loss:  0.0002980329154524952
Valid Loss:  0.0005500057013705373
Epoch:  481  	Training Loss: 0.00043721942347474396
Test Loss:  0.00029743980849161744
Valid Loss:  0.0005489443428814411
Epoch:  482  	Training Loss: 0.00043634933535940945
Test Loss:  0.0002953721850644797
Valid Loss:  0.0005472000921145082
Epoch:  483  	Training Loss: 0.0004352415562607348
Test Loss:  0.00029370340052992105
Valid Loss:  0.0005456858198158443
Epoch:  484  	Training Loss: 0.00043420449947007
Test Loss:  0.0002922890998888761
Valid Loss:  0.0005442911060526967
Epoch:  485  	Training Loss: 0.0004332060634624213
Test Loss:  0.0002910922048613429
Valid Loss:  0.0005430384771898389
Epoch:  486  	Training Loss: 0.0004322576569393277
Test Loss:  0.0002900495892390609
Valid Loss:  0.0005418783985078335
Epoch:  487  	Training Loss: 0.00043134717270731926
Test Loss:  0.0002890843024943024
Valid Loss:  0.0005407602293416858
Epoch:  488  	Training Loss: 0.0004304626490920782
Test Loss:  0.00028820466832257807
Valid Loss:  0.0005397064378485084
Epoch:  489  	Training Loss: 0.0004296003608033061
Test Loss:  0.0002873929915949702
Valid Loss:  0.0005387119017541409
Epoch:  490  	Training Loss: 0.00042876688530668616
Test Loss:  0.00028667107108049095
Valid Loss:  0.0005377923371270299
Epoch:  491  	Training Loss: 0.0004279605927877128
Test Loss:  0.0002859845117200166
Valid Loss:  0.0005369021673686802
Epoch:  492  	Training Loss: 0.0004271655634511262
Test Loss:  0.00028704243595711887
Valid Loss:  0.0005359185743145645
Epoch:  493  	Training Loss: 0.00042543376912362874
Test Loss:  0.000287383736576885
Valid Loss:  0.0005354994209483266
Epoch:  494  	Training Loss: 0.0004246343160048127
Test Loss:  0.00028724141884595156
Valid Loss:  0.0005349746206775308
Epoch:  495  	Training Loss: 0.00042393404874019325
Test Loss:  0.00028684953576885164
Valid Loss:  0.0005343720549717546
Epoch:  496  	Training Loss: 0.00042325834510847926
Test Loss:  0.0002863809932023287
Valid Loss:  0.0005337427719496191
Epoch:  497  	Training Loss: 0.00042260289774276316
Test Loss:  0.00028572577866725624
Valid Loss:  0.0005330642452463508
Epoch:  498  	Training Loss: 0.0004219626425765455
Test Loss:  0.0002852814504876733
Valid Loss:  0.0005324380472302437
Epoch:  499  	Training Loss: 0.0004213295178487897
Test Loss:  0.0002847099967766553
Valid Loss:  0.0005317744798958302
Epoch:  500  	Training Loss: 0.0004207091114949435
Test Loss:  0.00028428679797798395
Valid Loss:  0.000531147001311183
seed is  15
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.35it/s]  1%|          | 4/500 [00:00<00:31, 15.88it/s]  1%|          | 6/500 [00:00<00:30, 16.19it/s]  2%|▏         | 8/500 [00:00<00:31, 15.84it/s]  2%|▏         | 10/500 [00:00<00:30, 15.90it/s]  2%|▏         | 12/500 [00:00<00:30, 15.97it/s]  3%|▎         | 14/500 [00:00<00:30, 16.09it/s]  3%|▎         | 16/500 [00:00<00:29, 16.21it/s]  4%|▎         | 18/500 [00:01<00:29, 16.32it/s]  4%|▍         | 20/500 [00:01<00:29, 16.35it/s]  4%|▍         | 22/500 [00:01<00:29, 16.38it/s]  5%|▍         | 24/500 [00:01<00:29, 16.40it/s]  5%|▌         | 26/500 [00:01<00:28, 16.42it/s]  6%|▌         | 28/500 [00:01<00:28, 16.44it/s]  6%|▌         | 30/500 [00:01<00:28, 16.36it/s]  6%|▋         | 32/500 [00:01<00:28, 16.18it/s]  7%|▋         | 34/500 [00:02<00:29, 16.00it/s]  7%|▋         | 36/500 [00:02<00:28, 16.15it/s]  8%|▊         | 38/500 [00:02<00:28, 16.09it/s]  8%|▊         | 40/500 [00:02<00:28, 16.19it/s]  8%|▊         | 42/500 [00:02<00:28, 16.27it/s]  9%|▉         | 44/500 [00:02<00:27, 16.30it/s]  9%|▉         | 46/500 [00:02<00:27, 16.36it/s] 10%|▉         | 48/500 [00:02<00:28, 16.03it/s] 10%|█         | 50/500 [00:03<00:28, 15.81it/s] 10%|█         | 52/500 [00:03<00:28, 15.84it/s] 11%|█         | 54/500 [00:03<00:27, 16.02it/s] 11%|█         | 56/500 [00:03<00:27, 16.20it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.27it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.35it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.46it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.43it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.41it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.33it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.29it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.27it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.10it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.95it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.11it/s] 16%|█▌        | 80/500 [00:04<00:26, 16.15it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.27it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.32it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.35it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.39it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.22it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.27it/s] 19%|█▉        | 94/500 [00:05<00:25, 16.12it/s] 19%|█▉        | 96/500 [00:05<00:25, 15.92it/s] 20%|█▉        | 98/500 [00:06<00:25, 16.05it/s] 20%|██        | 100/500 [00:06<00:24, 16.19it/s] 20%|██        | 102/500 [00:06<00:24, 16.28it/s] 21%|██        | 104/500 [00:06<00:24, 16.24it/s] 21%|██        | 106/500 [00:06<00:24, 16.15it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.31it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.33it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.36it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.28it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.08it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.18it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.28it/s] 24%|██▍       | 122/500 [00:07<00:23, 15.81it/s] 25%|██▍       | 124/500 [00:07<00:25, 14.81it/s]Epoch:  1  	Training Loss: 0.1085098385810852
Test Loss:  1901.3193359375
Valid Loss:  1903.820068359375
Epoch:  2  	Training Loss: 1904.827392578125
Test Loss:  72943325413376.0
Valid Loss:  72437039366144.0
Epoch:  3  	Training Loss: 71931642511360.0
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:24, 15.11it/s] 26%|██▌       | 128/500 [00:07<00:24, 15.48it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.76it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.92it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.79it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.98it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.00it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.04it/s] 28%|██▊       | 142/500 [00:08<00:22, 15.79it/s] 29%|██▉       | 144/500 [00:08<00:24, 14.70it/s] 29%|██▉       | 146/500 [00:09<00:23, 15.09it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.49it/s] 30%|███       | 150/500 [00:09<00:22, 15.76it/s] 30%|███       | 152/500 [00:09<00:22, 15.82it/s] 31%|███       | 154/500 [00:09<00:21, 15.91it/s] 31%|███       | 156/500 [00:09<00:21, 15.92it/s] 32%|███▏      | 158/500 [00:09<00:22, 15.49it/s] 32%|███▏      | 160/500 [00:09<00:21, 15.68it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.86it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.03it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.18it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.19it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.32it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.18it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.12it/s] 35%|███▌      | 176/500 [00:10<00:20, 16.20it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.11it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.19it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.13it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.08it/s] 37%|███▋      | 186/500 [00:11<00:20, 15.63it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.82it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.01it/s] 38%|███▊      | 192/500 [00:11<00:19, 16.18it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.26it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.27it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.13it/s] 40%|████      | 200/500 [00:12<00:18, 15.99it/s] 40%|████      | 202/500 [00:12<00:18, 15.93it/s] 41%|████      | 204/500 [00:12<00:18, 16.11it/s] 41%|████      | 206/500 [00:12<00:18, 16.18it/s] 42%|████▏     | 208/500 [00:12<00:18, 16.17it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.23it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.22it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.83it/s] 43%|████▎     | 216/500 [00:13<00:18, 15.11it/s] 44%|████▎     | 218/500 [00:13<00:18, 15.35it/s] 44%|████▍     | 220/500 [00:13<00:18, 15.52it/s] 44%|████▍     | 222/500 [00:13<00:18, 15.20it/s] 45%|████▍     | 224/500 [00:13<00:17, 15.45it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.72it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.87it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.87it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.02it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.15it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.21it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.22it/s] 48%|████▊     | 240/500 [00:14<00:16, 16.04it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.99it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.08it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.18it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.09it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.17it/s] 50%|█████     | 252/500 [00:15<00:15, 16.24it/s] 51%|█████     | 254/500 [00:15<00:15, 16.31it/s] 51%|█████     | 256/500 [00:15<00:14, 16.34it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.19it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.41it/s] 52%|█████▏    | 262/500 [00:16<00:15, 15.68it/s] 53%|█████▎    | 264/500 [00:16<00:15, 15.59it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.86it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.04it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.11it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.22it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.23it/s] 55%|█████▌    | 276/500 [00:17<00:15, 14.67it/s] 56%|█████▌    | 278/500 [00:17<00:16, 13.84it/s] 56%|█████▌    | 280/500 [00:17<00:16, 13.35it/s] 56%|█████▋    | 282/500 [00:17<00:16, 12.93it/s] 57%|█████▋    | 284/500 [00:17<00:16, 12.73it/s] 57%|█████▋    | 286/500 [00:18<00:16, 12.61it/s] 58%|█████▊    | 288/500 [00:18<00:16, 12.52it/s] 58%|█████▊    | 290/500 [00:18<00:16, 12.51it/s] 58%|█████▊    | 292/500 [00:18<00:15, 13.36it/s] 59%|█████▉    | 294/500 [00:18<00:14, 14.04it/s] 59%|█████▉    | 296/500 [00:18<00:13, 14.65it/s] 60%|█████▉    | 298/500 [00:18<00:14, 14.43it/s] 60%|██████    | 300/500 [00:19<00:13, 14.98it/s] 60%|██████    | 302/500 [00:19<00:12, 15.29it/s] 61%|██████    | 304/500 [00:19<00:12, 15.61it/s] 61%|██████    | 306/500 [00:19<00:12, 15.76it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.06it/s] 62%|██████▏   | 310/500 [00:19<00:12, 14.97it/s] 62%|██████▏   | 312/500 [00:19<00:12, 15.35it/s] 63%|██████▎   | 314/500 [00:19<00:11, 15.63it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.78it/s] 64%|██████▎   | 318/500 [00:20<00:11, 15.80it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.93it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.94it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.94it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.02it/s] 66%|██████▌   | 328/500 [00:20<00:11, 15.59it/s] 66%|██████▌   | 330/500 [00:20<00:11, 14.78it/s] 66%|██████▋   | 332/500 [00:21<00:11, 14.97it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.34it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.49it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.70it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.72it/s] 68%|██████▊   | 342/500 [00:21<00:10, 15.77it/s] 69%|██████▉   | 344/500 [00:21<00:09, 15.97it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.10it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.17it/s] 70%|███████   | 350/500 [00:22<00:09, 16.20it/s] 70%|███████   | 352/500 [00:22<00:09, 16.18it/s] 71%|███████   | 354/500 [00:22<00:09, 15.90it/s] 71%|███████   | 356/500 [00:22<00:09, 15.51it/s] 72%|███████▏  | 358/500 [00:22<00:09, 15.66it/s] 72%|███████▏  | 360/500 [00:22<00:09, 15.54it/s] 72%|███████▏  | 362/500 [00:22<00:08, 15.78it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.89it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.01it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.10it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.64it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.84it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.03it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.10it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.80it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.83it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.90it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.07it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.84it/s] 78%|███████▊  | 388/500 [00:24<00:07, 15.94it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.02it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.13it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.20it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.31it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.28it/s] 80%|████████  | 400/500 [00:25<00:06, 16.18it/s] 80%|████████  | 402/500 [00:25<00:06, 16.19it/s] 81%|████████  | 404/500 [00:25<00:05, 16.26it/s] 81%|████████  | 406/500 [00:25<00:05, 16.29it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.36it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.41it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.42it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.31it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.18it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.14it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.22it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.28it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.08it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.07it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.21it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.26it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.33it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.03it/s] 87%|████████▋ | 436/500 [00:27<00:04, 15.89it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.07it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.13it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.21it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.09it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.07it/s] 90%|████████▉ | 448/500 [00:28<00:03, 15.84it/s] 90%|█████████ | 450/500 [00:28<00:03, 15.97it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.03it/s] 91%|█████████ | 454/500 [00:28<00:02, 15.92it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.86it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.00it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.89it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.03it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.14it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.10it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.05it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.99it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.14it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.21it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.18it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.09it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.15it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.20it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.72it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.75it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.84it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.95it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.09it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.25it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.34it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.35it/s]100%|██████████| 500/500 [00:31<00:00, 16.34it/s]100%|██████████| 500/500 [00:31<00:00, 15.84it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  15
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:06,  6.15s/it]  1%|          | 3/500 [00:06<13:37,  1.64s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:12<10:43,  1.32s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:19<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:36,  3.02it/s]  6%|▌         | 31/500 [00:26<09:14,  1.18s/it]  7%|▋         | 33/500 [00:26<06:34,  1.18it/s]  7%|▋         | 35/500 [00:26<04:43,  1.64it/s]  7%|▋         | 37/500 [00:26<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:35,  2.96it/s]  8%|▊         | 41/500 [00:33<09:08,  1.20s/it]  9%|▊         | 43/500 [00:33<06:34,  1.16it/s]  9%|▉         | 45/500 [00:33<04:46,  1.59it/s]  9%|▉         | 47/500 [00:34<03:31,  2.15it/s] 10%|▉         | 49/500 [00:34<02:38,  2.84it/s] 10%|█         | 51/500 [00:40<08:55,  1.19s/it] 11%|█         | 53/500 [00:40<06:22,  1.17it/s] 11%|█         | 55/500 [00:40<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:36,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:54<08:25,  1.18s/it]Epoch:  1  	Training Loss: 0.1085098385810852
Test Loss:  354.8905029296875
Valid Loss:  350.9450378417969
Epoch:  2  	Training Loss: 345.3583068847656
Test Loss:  3.2729525566101074
Valid Loss:  3.2371044158935547
Epoch:  3  	Training Loss: 3.130230665206909
Test Loss:  2.5129435062408447
Valid Loss:  2.4863340854644775
Epoch:  4  	Training Loss: 2.399479389190674
Test Loss:  2.0178115367889404
Valid Loss:  1.9961644411087036
Epoch:  5  	Training Loss: 1.9230005741119385
Test Loss:  1.6240512132644653
Valid Loss:  1.606818675994873
Epoch:  6  	Training Loss: 1.5452229976654053
Test Loss:  1.3178236484527588
Valid Loss:  1.3039507865905762
Epoch:  7  	Training Loss: 1.2511963844299316
Test Loss:  1.070603370666504
Valid Loss:  1.0594141483306885
Epoch:  8  	Training Loss: 1.0142210721969604
Test Loss:  0.8705134391784668
Valid Loss:  0.8615046143531799
Epoch:  9  	Training Loss: 0.8227503299713135
Test Loss:  0.7084383964538574
Valid Loss:  0.7012625932693481
Epoch:  10  	Training Loss: 0.6679624319076538
Test Loss:  0.5771119594573975
Valid Loss:  0.5714802742004395
Epoch:  11  	Training Loss: 0.5428025126457214
Test Loss:  0.47066640853881836
Valid Loss:  0.46636760234832764
Epoch:  12  	Training Loss: 0.44160333275794983
Test Loss:  0.38955599069595337
Valid Loss:  0.386465847492218
Epoch:  13  	Training Loss: 0.3649020195007324
Test Loss:  0.3230084478855133
Valid Loss:  0.32092782855033875
Epoch:  14  	Training Loss: 0.30212944746017456
Test Loss:  0.26833903789520264
Valid Loss:  0.26710623502731323
Epoch:  15  	Training Loss: 0.2507110834121704
Test Loss:  0.22338375449180603
Valid Loss:  0.2228698581457138
Epoch:  16  	Training Loss: 0.20855744183063507
Test Loss:  0.18639430403709412
Valid Loss:  0.18649078905582428
Epoch:  17  	Training Loss: 0.1739835888147354
Test Loss:  0.15593382716178894
Valid Loss:  0.15654930472373962
Epoch:  18  	Training Loss: 0.1456129401922226
Test Loss:  0.1308322548866272
Valid Loss:  0.13189366459846497
Epoch:  19  	Training Loss: 0.12232335656881332
Test Loss:  0.11012761294841766
Valid Loss:  0.1115698590874672
Epoch:  20  	Training Loss: 0.10319310426712036
Test Loss:  0.09303665161132812
Valid Loss:  0.09480418264865875
Epoch:  21  	Training Loss: 0.08747094869613647
Test Loss:  0.07891435921192169
Valid Loss:  0.08095965534448624
Epoch:  22  	Training Loss: 0.07454093545675278
Test Loss:  0.06734231114387512
Valid Loss:  0.06961123645305634
Epoch:  23  	Training Loss: 0.06398223340511322
Test Loss:  0.057731688022613525
Valid Loss:  0.06019167602062225
Epoch:  24  	Training Loss: 0.05525834858417511
Test Loss:  0.049740493297576904
Valid Loss:  0.05236363038420677
Epoch:  25  	Training Loss: 0.0480436235666275
Test Loss:  0.04326116666197777
Valid Loss:  0.04618549346923828
Epoch:  26  	Training Loss: 0.042426884174346924
Test Loss:  0.04014158993959427
Valid Loss:  0.04305296391248703
Epoch:  27  	Training Loss: 0.04015630483627319
Test Loss:  0.039040908217430115
Valid Loss:  0.0419933944940567
Epoch:  28  	Training Loss: 0.03942028805613518
Test Loss:  0.038423821330070496
Valid Loss:  0.04153657704591751
Epoch:  29  	Training Loss: 0.03908424824476242
Test Loss:  0.03806835040450096
Valid Loss:  0.04134117811918259
Epoch:  30  	Training Loss: 0.03893684223294258
Test Loss:  0.037861429154872894
Valid Loss:  0.04121392220258713
Epoch:  31  	Training Loss: 0.03885703906416893
Test Loss:  0.03774801269173622
Valid Loss:  0.041152190417051315
Epoch:  32  	Training Loss: 0.038813404738903046
Test Loss:  0.03766999393701553
Valid Loss:  0.04110807925462723
Epoch:  33  	Training Loss: 0.03878490626811981
Test Loss:  0.03760991245508194
Valid Loss:  0.04107050597667694
Epoch:  34  	Training Loss: 0.03876271843910217
Test Loss:  0.03756612539291382
Valid Loss:  0.04104024916887283
Epoch:  35  	Training Loss: 0.0387439988553524
Test Loss:  0.037530891597270966
Valid Loss:  0.0410180389881134
Epoch:  36  	Training Loss: 0.038727112114429474
Test Loss:  0.03750161826610565
Valid Loss:  0.04099780321121216
Epoch:  37  	Training Loss: 0.03871183842420578
Test Loss:  0.0374782495200634
Valid Loss:  0.040979426354169846
Epoch:  38  	Training Loss: 0.03869764506816864
Test Loss:  0.037455275654792786
Valid Loss:  0.04096122086048126
Epoch:  39  	Training Loss: 0.03868388757109642
Test Loss:  0.037436164915561676
Valid Loss:  0.04094455763697624
Epoch:  40  	Training Loss: 0.03867113217711449
Test Loss:  0.03742068260908127
Valid Loss:  0.04092937707901001
Epoch:  41  	Training Loss: 0.03865872323513031
Test Loss:  0.03740528225898743
Valid Loss:  0.04091423749923706
Epoch:  42  	Training Loss: 0.038646355271339417
Test Loss:  0.03739442676305771
Valid Loss:  0.04090152308344841
Epoch:  43  	Training Loss: 0.03863545134663582
Test Loss:  0.03738362342119217
Valid Loss:  0.04088883846998215
Epoch:  44  	Training Loss: 0.038624778389930725
Test Loss:  0.03737591207027435
Valid Loss:  0.040877409279346466
Epoch:  45  	Training Loss: 0.03861427307128906
Test Loss:  0.037368111312389374
Valid Loss:  0.0408659353852272
Epoch:  46  	Training Loss: 0.038603805005550385
Test Loss:  0.0373634397983551
Valid Loss:  0.04085567593574524
Epoch:  47  	Training Loss: 0.038593534380197525
Test Loss:  0.0373586043715477
Valid Loss:  0.040845390409231186
Epoch:  48  	Training Loss: 0.03858333081007004
Test Loss:  0.037353768944740295
Valid Loss:  0.04083508998155594
Epoch:  49  	Training Loss: 0.03857317194342613
Test Loss:  0.037348873913288116
Valid Loss:  0.040824998170137405
Epoch:  50  	Training Loss: 0.0385630838572979
Test Loss:  0.037343814969062805
Valid Loss:  0.04081488400697708
Epoch:  51  	Training Loss: 0.03855304419994354
Test Loss:  0.03733863681554794
Valid Loss:  0.04080476239323616
Epoch:  52  	Training Loss: 0.03854309767484665
Test Loss:  0.037333399057388306
Valid Loss:  0.04079466313123703
Epoch:  53  	Training Loss: 0.038533229380846024
Test Loss:  0.03732805699110031
Valid Loss:  0.04078453779220581
Epoch:  54  	Training Loss: 0.03852339833974838
Test Loss:  0.03732256963849068
Valid Loss:  0.0407743826508522
Epoch:  55  	Training Loss: 0.03851359337568283
Test Loss:  0.037316981703042984
Valid Loss:  0.040764227509498596
Epoch:  56  	Training Loss: 0.038503848016262054
Test Loss:  0.037311289459466934
Valid Loss:  0.040754057466983795
Epoch:  57  	Training Loss: 0.038494132459163666
Test Loss:  0.03730550408363342
Valid Loss:  0.040743857622146606
Epoch:  58  	Training Loss: 0.038484424352645874
Test Loss:  0.03729960322380066
Valid Loss:  0.04073363542556763
Epoch:  59  	Training Loss: 0.038474809378385544
Test Loss:  0.037296030670404434
Valid Loss:  0.04072435572743416
Epoch:  60  	Training Loss: 0.03846530243754387
Test Loss:  0.03729229420423508
Valid Loss:  0.0407150574028492
Epoch:  61  	Training Loss: 0.03845585137605667
Test Loss:  0.03728834539651871
Valid Loss:  0.040705714374780655
Epoch:  62  	Training Loss: 0.03844643384218216
Test Loss:  0.03728447109460831
Valid Loss:  0.040696509182453156
Epoch:  63  	Training Loss: 0.03843717277050018
Test Loss:  0.0372806042432785
Valid Loss:  0.04068727791309357
Epoch:  64  	Training Loss: 0.03842795267701149
Test Loss:  0.03727659583091736
Valid Loss:  0.040678009390830994
Epoch:  65  	Training Loss: 0.038418762385845184
Test Loss:  0.03727244585752487
Valid Loss:  0.04066871851682663
Epoch:  66  	Training Loss: 0.03840962052345276
Test Loss:  0.03726816922426224
Valid Loss:  0.040659382939338684
Epoch:  67  	Training Loss: 0.03840051591396332
Test Loss:  0.03726375102996826
Valid Loss:  0.04064998775720596
Epoch:  68  	Training Loss: 0.038391441106796265
Test Loss:  0.03725920617580414
Valid Loss:  0.04064056649804115
Epoch:  69  	Training Loss: 0.03838241100311279
Test Loss:  0.037254542112350464
Valid Loss:  0.04063115268945694
Epoch:  70  	Training Loss: 0.038373418152332306
Test Loss:  0.037249840795993805
Valid Loss:  0.04062175378203392
Epoch:  71  	Training Loss: 0.038364484906196594
Test Loss:  0.037245068699121475
Valid Loss:  0.04061232507228851
Epoch:  72  	Training Loss: 0.038355596363544464
Test Loss:  0.037242427468299866
Valid Loss:  0.040603842586278915
Epoch:  73  	Training Loss: 0.03834676742553711
Test Loss:   15%|█▍        | 73/500 [00:54<06:00,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:13,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:51,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:07<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:43,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:07,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.00it/s] 20%|██        | 101/500 [01:14<07:54,  1.19s/it] 21%|██        | 103/500 [01:14<05:38,  1.17it/s] 21%|██        | 105/500 [01:14<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:15<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:15<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:21<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.02it/s] 24%|██▍       | 121/500 [01:28<07:36,  1.20s/it] 25%|██▍       | 123/500 [01:28<05:24,  1.16it/s] 25%|██▌       | 125/500 [01:28<03:53,  1.61it/s] 25%|██▌       | 127/500 [01:28<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:29<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:35<07:22,  1.20s/it] 27%|██▋       | 133/500 [01:35<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:35<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:35<02:44,  2.21it/s] 28%|██▊       | 139/500 [01:35<02:01,  2.97it/s] 28%|██▊       | 141/500 [01:42<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:02,  1.18it/s]0.03723963350057602
Valid Loss:  0.04059533402323723
Epoch:  74  	Training Loss: 0.03833799809217453
Test Loss:  0.03723667189478874
Valid Loss:  0.04058678820729256
Epoch:  75  	Training Loss: 0.03832927346229553
Test Loss:  0.03723354637622833
Valid Loss:  0.0405782014131546
Epoch:  76  	Training Loss: 0.03832058608531952
Test Loss:  0.03723026439547539
Valid Loss:  0.040569569915533066
Epoch:  77  	Training Loss: 0.03831193596124649
Test Loss:  0.03722682595252991
Valid Loss:  0.040560901165008545
Epoch:  78  	Training Loss: 0.038303326815366745
Test Loss:  0.03722324222326279
Valid Loss:  0.04055219143629074
Epoch:  79  	Training Loss: 0.038294754922389984
Test Loss:  0.037219613790512085
Valid Loss:  0.04054346680641174
Epoch:  80  	Training Loss: 0.03828622028231621
Test Loss:  0.037215977907180786
Valid Loss:  0.040534719824790955
Epoch:  81  	Training Loss: 0.03827773779630661
Test Loss:  0.037212252616882324
Valid Loss:  0.040525950491428375
Epoch:  82  	Training Loss: 0.03826930373907089
Test Loss:  0.03720854967832565
Valid Loss:  0.04051722586154938
Epoch:  83  	Training Loss: 0.03826093673706055
Test Loss:  0.03720490634441376
Valid Loss:  0.0405084565281868
Epoch:  84  	Training Loss: 0.038252584636211395
Test Loss:  0.03720126301050186
Valid Loss:  0.04049966484308243
Epoch:  85  	Training Loss: 0.03824426978826523
Test Loss:  0.03719921037554741
Valid Loss:  0.040491871535778046
Epoch:  86  	Training Loss: 0.03823607414960861
Test Loss:  0.03719702735543251
Valid Loss:  0.04048403352499008
Epoch:  87  	Training Loss: 0.038227926939725876
Test Loss:  0.03719474375247955
Valid Loss:  0.040476150810718536
Epoch:  88  	Training Loss: 0.03821982443332672
Test Loss:  0.03719233721494675
Valid Loss:  0.0404682531952858
Epoch:  89  	Training Loss: 0.03821176290512085
Test Loss:  0.03718981146812439
Valid Loss:  0.040460310876369476
Epoch:  90  	Training Loss: 0.03820374980568886
Test Loss:  0.03718716651201248
Valid Loss:  0.040452323853969574
Epoch:  91  	Training Loss: 0.038195766508579254
Test Loss:  0.03718440979719162
Valid Loss:  0.04044428840279579
Epoch:  92  	Training Loss: 0.038187816739082336
Test Loss:  0.0371815487742424
Valid Loss:  0.04043618217110634
Epoch:  93  	Training Loss: 0.03817986324429512
Test Loss:  0.03717859089374542
Valid Loss:  0.040428031235933304
Epoch:  94  	Training Loss: 0.03817196562886238
Test Loss:  0.03717555105686188
Valid Loss:  0.04041986167430878
Epoch:  95  	Training Loss: 0.038164108991622925
Test Loss:  0.037172406911849976
Valid Loss:  0.040411654859781265
Epoch:  96  	Training Loss: 0.03815628960728645
Test Loss:  0.03716915845870972
Valid Loss:  0.04040340706706047
Epoch:  97  	Training Loss: 0.03814849257469177
Test Loss:  0.037165820598602295
Valid Loss:  0.04039512947201729
Epoch:  98  	Training Loss: 0.03814072906970978
Test Loss:  0.03716238960623741
Valid Loss:  0.040386807173490524
Epoch:  99  	Training Loss: 0.03813299164175987
Test Loss:  0.03715885803103447
Valid Loss:  0.040378451347351074
Epoch:  100  	Training Loss: 0.038125280290842056
Test Loss:  0.037155263125896454
Valid Loss:  0.04037008434534073
Epoch:  101  	Training Loss: 0.03811760991811752
Test Loss:  0.03715156763792038
Valid Loss:  0.0403616800904274
Epoch:  102  	Training Loss: 0.03810996189713478
Test Loss:  0.037147894501686096
Valid Loss:  0.04035327211022377
Epoch:  103  	Training Loss: 0.03810230270028114
Test Loss:  0.037144146859645844
Valid Loss:  0.04034484550356865
Epoch:  104  	Training Loss: 0.038094669580459595
Test Loss:  0.03714030236005783
Valid Loss:  0.040336381644010544
Epoch:  105  	Training Loss: 0.03808704763650894
Test Loss:  0.03713638335466385
Valid Loss:  0.04032788425683975
Epoch:  106  	Training Loss: 0.038079455494880676
Test Loss:  0.0371323898434639
Valid Loss:  0.04031937196850777
Epoch:  107  	Training Loss: 0.0380718857049942
Test Loss:  0.03712833672761917
Valid Loss:  0.040310829877853394
Epoch:  108  	Training Loss: 0.03806433826684952
Test Loss:  0.03712421655654907
Valid Loss:  0.04030253365635872
Epoch:  109  	Training Loss: 0.03805682808160782
Test Loss:  0.0371200293302536
Valid Loss:  0.040294334292411804
Epoch:  110  	Training Loss: 0.0380493700504303
Test Loss:  0.03711749613285065
Valid Loss:  0.040286947041749954
Epoch:  111  	Training Loss: 0.03804203122854233
Test Loss:  0.03711484372615814
Valid Loss:  0.04027952626347542
Epoch:  112  	Training Loss: 0.038034725934267044
Test Loss:  0.037112217396497726
Valid Loss:  0.040272146463394165
Epoch:  113  	Training Loss: 0.03802748769521713
Test Loss:  0.03710947185754776
Valid Loss:  0.04026474058628082
Epoch:  114  	Training Loss: 0.03802027553319931
Test Loss:  0.03710681200027466
Valid Loss:  0.04025730490684509
Epoch:  115  	Training Loss: 0.03801310062408447
Test Loss:  0.03710407018661499
Valid Loss:  0.04024984687566757
Epoch:  116  	Training Loss: 0.03800594434142113
Test Loss:  0.03710123896598816
Valid Loss:  0.04024236649274826
Epoch:  117  	Training Loss: 0.03799881413578987
Test Loss:  0.03709834814071655
Valid Loss:  0.040234871208667755
Epoch:  118  	Training Loss: 0.0379917286336422
Test Loss:  0.03709537535905838
Valid Loss:  0.04022735357284546
Epoch:  119  	Training Loss: 0.03798466548323631
Test Loss:  0.03709232807159424
Valid Loss:  0.040219806134700775
Epoch:  120  	Training Loss: 0.03797762840986252
Test Loss:  0.037089236080646515
Valid Loss:  0.0402122437953949
Epoch:  121  	Training Loss: 0.037970613688230515
Test Loss:  0.03708607703447342
Valid Loss:  0.040204666554927826
Epoch:  122  	Training Loss: 0.0379636213183403
Test Loss:  0.03708292171359062
Valid Loss:  0.04019710794091225
Epoch:  123  	Training Loss: 0.037956662476062775
Test Loss:  0.037079714238643646
Valid Loss:  0.04018953815102577
Epoch:  124  	Training Loss: 0.037949733436107635
Test Loss:  0.037076424807310104
Valid Loss:  0.04018194228410721
Epoch:  125  	Training Loss: 0.03794281929731369
Test Loss:  0.03707307577133179
Valid Loss:  0.04017440229654312
Epoch:  126  	Training Loss: 0.037935927510261536
Test Loss:  0.0370696596801281
Valid Loss:  0.040167100727558136
Epoch:  127  	Training Loss: 0.03792905434966087
Test Loss:  0.03706619143486023
Valid Loss:  0.04015980288386345
Epoch:  128  	Training Loss: 0.0379222072660923
Test Loss:  0.03706268593668938
Valid Loss:  0.040152616798877716
Epoch:  129  	Training Loss: 0.037915393710136414
Test Loss:  0.037059128284454346
Valid Loss:  0.04014568030834198
Epoch:  130  	Training Loss: 0.037908606231212616
Test Loss:  0.03705568611621857
Valid Loss:  0.04013875126838684
Epoch:  131  	Training Loss: 0.03790184482932091
Test Loss:  0.03705362230539322
Valid Loss:  0.04013218730688095
Epoch:  132  	Training Loss: 0.037895217537879944
Test Loss:  0.037051498889923096
Valid Loss:  0.040125586092472076
Epoch:  133  	Training Loss: 0.03788856416940689
Test Loss:  0.03704928606748581
Valid Loss:  0.0401189923286438
Epoch:  134  	Training Loss: 0.037881962954998016
Test Loss:  0.03704824298620224
Valid Loss:  0.04011276364326477
Epoch:  135  	Training Loss: 0.037875398993492126
Test Loss:  0.03704709932208061
Valid Loss:  0.04010654240846634
Epoch:  136  	Training Loss: 0.037868887186050415
Test Loss:  0.03704460710287094
Valid Loss:  0.04009995236992836
Epoch:  137  	Training Loss: 0.03786240518093109
Test Loss:  0.03704329952597618
Valid Loss:  0.040093742311000824
Epoch:  138  	Training Loss: 0.037855952978134155
Test Loss:  0.03704189509153366
Valid Loss:  0.04008752852678299
Epoch:  139  	Training Loss: 0.0378495454788208
Test Loss:  0.03704040125012398
Valid Loss:  0.04008132219314575
Epoch:  140  	Training Loss: 0.03784317523241043
Test Loss:  0.03703881800174713
Valid Loss:  0.040075115859508514
Epoch:  141  	Training Loss: 0.037836842238903046
Test Loss:  0.03703714907169342
Valid Loss:  0.040068916976451874
Epoch:  142  	Training Loss: 0.03783054277300835
Test Loss:  0.037035275250673294
Valid Loss:  0.04006262868642807
Epoch:  143  	Training Loss: 0.03782422095537186
Test Loss:  0.0370333269238472
Valid Loss:  0.04005635529756546
Epoch:  144  	Training Loss: 0.03781794011592865
Test Loss:  0.03703130781650543
Valid Loss:  0.04005007445812225
 29%|██▉       | 145/500 [01:42<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:42<01:57,  2.99it/s] 30%|███       | 151/500 [01:49<06:48,  1.17s/it] 31%|███       | 153/500 [01:49<04:51,  1.19it/s] 31%|███       | 155/500 [01:49<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:49<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:49<01:52,  3.02it/s] 32%|███▏      | 161/500 [01:55<06:34,  1.16s/it] 33%|███▎      | 163/500 [01:55<04:41,  1.20it/s] 33%|███▎      | 165/500 [01:56<03:22,  1.65it/s] 33%|███▎      | 167/500 [01:56<02:27,  2.26it/s] 34%|███▍      | 169/500 [01:56<01:49,  3.04it/s] 34%|███▍      | 171/500 [02:02<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:03<02:25,  2.23it/s] 36%|███▌      | 179/500 [02:03<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:09<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:10<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:16<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:16<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:16<01:40,  2.99it/s] 40%|████      | 201/500 [02:23<05:51,  1.18s/it] 41%|████      | 203/500 [02:23<04:10,  1.19it/s] 41%|████      | 205/500 [02:23<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:23<02:12,  2.22it/s] 42%|████▏     | 209/500 [02:23<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:30<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:30<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:30<02:54,  1.64it/s]Epoch:  145  	Training Loss: 0.03781167417764664
Test Loss:  0.0370292067527771
Valid Loss:  0.04004379361867905
Epoch:  146  	Training Loss: 0.03780544176697731
Test Loss:  0.03702833130955696
Valid Loss:  0.04003792256116867
Epoch:  147  	Training Loss: 0.037799276411533356
Test Loss:  0.037026070058345795
Valid Loss:  0.040031641721725464
Epoch:  148  	Training Loss: 0.03779313340783119
Test Loss:  0.037025030702352524
Valid Loss:  0.04002578556537628
Epoch:  149  	Training Loss: 0.03778704255819321
Test Loss:  0.037023887038230896
Valid Loss:  0.0400199219584465
Epoch:  150  	Training Loss: 0.03778097406029701
Test Loss:  0.03702265024185181
Valid Loss:  0.040014058351516724
Epoch:  151  	Training Loss: 0.037774961441755295
Test Loss:  0.03702131658792496
Valid Loss:  0.040008194744586945
Epoch:  152  	Training Loss: 0.037768974900245667
Test Loss:  0.03701986372470856
Valid Loss:  0.04000231996178627
Epoch:  153  	Training Loss: 0.03776303678750992
Test Loss:  0.037018321454524994
Valid Loss:  0.03999645262956619
Epoch:  154  	Training Loss: 0.03775712102651596
Test Loss:  0.03701668977737427
Valid Loss:  0.03999057784676552
Epoch:  155  	Training Loss: 0.03775123879313469
Test Loss:  0.037014979869127274
Valid Loss:  0.039984725415706635
Epoch:  156  	Training Loss: 0.037745390087366104
Test Loss:  0.03701448068022728
Valid Loss:  0.039979271590709686
Epoch:  157  	Training Loss: 0.037739597260951996
Test Loss:  0.037012577056884766
Valid Loss:  0.03997345641255379
Epoch:  158  	Training Loss: 0.03773381933569908
Test Loss:  0.037011899054050446
Valid Loss:  0.03996799513697624
Epoch:  159  	Training Loss: 0.03772808983922005
Test Loss:  0.037009820342063904
Valid Loss:  0.03996226191520691
Epoch:  160  	Training Loss: 0.037722397595644
Test Loss:  0.037008970975875854
Valid Loss:  0.03995679318904877
Epoch:  161  	Training Loss: 0.03771672397851944
Test Loss:  0.03700801730155945
Valid Loss:  0.03995133191347122
Epoch:  162  	Training Loss: 0.03771108388900757
Test Loss:  0.037006936967372894
Valid Loss:  0.03994591161608696
Epoch:  163  	Training Loss: 0.03770552575588226
Test Loss:  0.03700576722621918
Valid Loss:  0.03994050621986389
Epoch:  164  	Training Loss: 0.037699997425079346
Test Loss:  0.03700451925396919
Valid Loss:  0.03993511572480202
Epoch:  165  	Training Loss: 0.03769451007246971
Test Loss:  0.037003181874752045
Valid Loss:  0.03992973640561104
Epoch:  166  	Training Loss: 0.037689052522182465
Test Loss:  0.03700175881385803
Valid Loss:  0.03992436081171036
Epoch:  167  	Training Loss: 0.03768362104892731
Test Loss:  0.03700025752186775
Valid Loss:  0.03991900011897087
Epoch:  168  	Training Loss: 0.037678226828575134
Test Loss:  0.0369986817240715
Valid Loss:  0.03991364687681198
Epoch:  169  	Training Loss: 0.037672873586416245
Test Loss:  0.03699834272265434
Valid Loss:  0.03990855813026428
Epoch:  170  	Training Loss: 0.037667542695999146
Test Loss:  0.03699657320976257
Valid Loss:  0.03990322723984718
Epoch:  171  	Training Loss: 0.03766225650906563
Test Loss:  0.036996059119701385
Valid Loss:  0.039898160845041275
Epoch:  172  	Training Loss: 0.037656985223293304
Test Loss:  0.0369952954351902
Valid Loss:  0.0398930162191391
Epoch:  173  	Training Loss: 0.03765169903635979
Test Loss:  0.0369931124150753
Valid Loss:  0.03988760709762573
Epoch:  174  	Training Loss: 0.03764643520116806
Test Loss:  0.03699220344424248
Valid Loss:  0.039882488548755646
Epoch:  175  	Training Loss: 0.03764119744300842
Test Loss:  0.03699120134115219
Valid Loss:  0.03987736999988556
Epoch:  176  	Training Loss: 0.03763599693775177
Test Loss:  0.03699010610580444
Valid Loss:  0.03987225145101547
Epoch:  177  	Training Loss: 0.03763081878423691
Test Loss:  0.03698892891407013
Valid Loss:  0.03986714780330658
Epoch:  178  	Training Loss: 0.03762567788362503
Test Loss:  0.036987677216529846
Valid Loss:  0.03986205533146858
Epoch:  179  	Training Loss: 0.03762057051062584
Test Loss:  0.036986351013183594
Valid Loss:  0.039856962859630585
Epoch:  180  	Training Loss: 0.03761547803878784
Test Loss:  0.03698495030403137
Valid Loss:  0.03985188156366348
Epoch:  181  	Training Loss: 0.03761042281985283
Test Loss:  0.036983467638492584
Valid Loss:  0.03984680026769638
Epoch:  182  	Training Loss: 0.037605393677949905
Test Loss:  0.03698195517063141
Valid Loss:  0.03984179347753525
Epoch:  183  	Training Loss: 0.037600450217723846
Test Loss:  0.03698037192225456
Valid Loss:  0.039836786687374115
Epoch:  184  	Training Loss: 0.03759553283452988
Test Loss:  0.03697871416807175
Valid Loss:  0.03983177989721298
Epoch:  185  	Training Loss: 0.0375906303524971
Test Loss:  0.03697698935866356
Valid Loss:  0.039826784282922745
Epoch:  186  	Training Loss: 0.037585750222206116
Test Loss:  0.03697519749403
Valid Loss:  0.03982178494334221
Epoch:  187  	Training Loss: 0.037580884993076324
Test Loss:  0.036973338574171066
Valid Loss:  0.03981678932905197
Epoch:  188  	Training Loss: 0.037576042115688324
Test Loss:  0.036971427500247955
Valid Loss:  0.03981179744005203
Epoch:  189  	Training Loss: 0.037571217864751816
Test Loss:  0.036969445645809174
Valid Loss:  0.039806805551052094
Epoch:  190  	Training Loss: 0.0375664085149765
Test Loss:  0.03696741536259651
Valid Loss:  0.03980182111263275
Epoch:  191  	Training Loss: 0.03756161406636238
Test Loss:  0.03696531802415848
Valid Loss:  0.03979683667421341
Epoch:  192  	Training Loss: 0.037556834518909454
Test Loss:  0.03696313500404358
Valid Loss:  0.039791833609342575
Epoch:  193  	Training Loss: 0.037552058696746826
Test Loss:  0.036960896104574203
Valid Loss:  0.03978683054447174
Epoch:  194  	Training Loss: 0.037547290325164795
Test Loss:  0.03695860505104065
Valid Loss:  0.03978182375431061
Epoch:  195  	Training Loss: 0.03754253685474396
Test Loss:  0.03695627301931381
Valid Loss:  0.03977682814002037
Epoch:  196  	Training Loss: 0.037537798285484314
Test Loss:  0.0369538888335228
Valid Loss:  0.03977183625102043
Epoch:  197  	Training Loss: 0.037533074617385864
Test Loss:  0.03695147484540939
Valid Loss:  0.039766862988471985
Epoch:  198  	Training Loss: 0.03752836957573891
Test Loss:  0.03694900870323181
Valid Loss:  0.03976189345121384
Epoch:  199  	Training Loss: 0.03752367943525314
Test Loss:  0.03694649785757065
Valid Loss:  0.03975692391395569
Epoch:  200  	Training Loss: 0.03751899674534798
Test Loss:  0.0369439497590065
Valid Loss:  0.03975196182727814
Epoch:  201  	Training Loss: 0.0375143326818943
Test Loss:  0.03694136440753937
Valid Loss:  0.03974699229001999
Epoch:  202  	Training Loss: 0.03750967979431152
Test Loss:  0.03693877160549164
Valid Loss:  0.03974205255508423
Epoch:  203  	Training Loss: 0.03750504553318024
Test Loss:  0.036936141550540924
Valid Loss:  0.03973710909485817
Epoch:  204  	Training Loss: 0.03750041872262955
Test Loss:  0.03693348914384842
Valid Loss:  0.039732180535793304
Epoch:  205  	Training Loss: 0.03749581798911095
Test Loss:  0.03693079203367233
Valid Loss:  0.03972725197672844
Epoch:  206  	Training Loss: 0.037491220980882645
Test Loss:  0.03692806512117386
Valid Loss:  0.039722323417663574
Epoch:  207  	Training Loss: 0.037486638873815536
Test Loss:  0.0369253046810627
Valid Loss:  0.03971739858388901
Epoch:  208  	Training Loss: 0.037482064217329025
Test Loss:  0.03692251071333885
Valid Loss:  0.03971247375011444
Epoch:  209  	Training Loss: 0.03747749328613281
Test Loss:  0.03691968694329262
Valid Loss:  0.03970755636692047
Epoch:  210  	Training Loss: 0.03747294098138809
Test Loss:  0.036916837096214294
Valid Loss:  0.0397026352584362
Epoch:  211  	Training Loss: 0.03746839612722397
Test Loss:  0.03691395744681358
Valid Loss:  0.03969773277640343
Epoch:  212  	Training Loss: 0.03746386617422104
Test Loss:  0.03691107779741287
Valid Loss:  0.039692848920822144
Epoch:  213  	Training Loss: 0.037459343671798706
Test Loss:  0.03690817207098007
Valid Loss:  0.03968796506524086
Epoch:  214  	Training Loss: 0.03745483234524727
Test Loss:  0.03690524399280548
Valid Loss:  0.03968308866024017
Epoch:  215  	Training Loss: 0.03745034337043762
Test Loss:  0.036903589963912964
Valid Loss:  0.03967854380607605
Epoch:  216  	Training Loss: 0.03744598478078842
 43%|████▎     | 217/500 [02:30<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:36<05:24,  1.16s/it] 45%|████▍     | 223/500 [02:36<03:51,  1.20it/s] 45%|████▌     | 225/500 [02:36<02:45,  1.66it/s] 45%|████▌     | 227/500 [02:37<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:37<01:29,  3.04it/s] 46%|████▌     | 231/500 [02:43<05:12,  1.16s/it] 47%|████▋     | 233/500 [02:43<03:42,  1.20it/s] 47%|████▋     | 235/500 [02:43<02:39,  1.66it/s] 47%|████▋     | 237/500 [02:43<01:55,  2.27it/s] 48%|████▊     | 239/500 [02:43<01:25,  3.05it/s] 48%|████▊     | 241/500 [02:50<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.00it/s] 50%|█████     | 251/500 [02:57<04:51,  1.17s/it] 51%|█████     | 253/500 [02:57<03:27,  1.19it/s] 51%|█████     | 255/500 [02:57<02:28,  1.64it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.25it/s] 52%|█████▏    | 259/500 [02:57<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:03<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:04<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:04<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:10<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:10<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:11<02:16,  1.64it/s] 55%|█████▌    | 277/500 [03:11<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:11<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:17<04:21,  1.19s/it] 57%|█████▋    | 283/500 [03:17<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:17<02:12,  1.62it/s]Test Loss:  0.036901865154504776
Valid Loss:  0.03967399522662163
Epoch:  217  	Training Loss: 0.03744163736701012
Test Loss:  0.03690008074045181
Valid Loss:  0.0396694540977478
Epoch:  218  	Training Loss: 0.037437308579683304
Test Loss:  0.03689824417233467
Valid Loss:  0.03966490924358368
Epoch:  219  	Training Loss: 0.03743300214409828
Test Loss:  0.03689635545015335
Valid Loss:  0.039660368114709854
Epoch:  220  	Training Loss: 0.037428732961416245
Test Loss:  0.03689570352435112
Valid Loss:  0.039656154811382294
Epoch:  221  	Training Loss: 0.037424489855766296
Test Loss:  0.036894962191581726
Valid Loss:  0.039651937782764435
Epoch:  222  	Training Loss: 0.037420276552438736
Test Loss:  0.03689408302307129
Valid Loss:  0.03964770585298538
Epoch:  223  	Training Loss: 0.037416085600852966
Test Loss:  0.036893121898174286
Valid Loss:  0.039643462747335434
Epoch:  224  	Training Loss: 0.03741191327571869
Test Loss:  0.036892086267471313
Valid Loss:  0.039639223366975784
Epoch:  225  	Training Loss: 0.0374077633023262
Test Loss:  0.03689099848270416
Valid Loss:  0.039634980261325836
Epoch:  226  	Training Loss: 0.0374036505818367
Test Loss:  0.036891136318445206
Valid Loss:  0.03963109850883484
Epoch:  227  	Training Loss: 0.03739955276250839
Test Loss:  0.03688986599445343
Valid Loss:  0.039626847952604294
Epoch:  228  	Training Loss: 0.03739547356963158
Test Loss:  0.03688983991742134
Valid Loss:  0.0396229550242424
Epoch:  229  	Training Loss: 0.03739143908023834
Test Loss:  0.03688839450478554
Valid Loss:  0.03961869701743126
Epoch:  230  	Training Loss: 0.03738740086555481
Test Loss:  0.03688821196556091
Valid Loss:  0.03961479663848877
Epoch:  231  	Training Loss: 0.03738340362906456
Test Loss:  0.03688661754131317
Valid Loss:  0.03961053490638733
Epoch:  232  	Training Loss: 0.0373794287443161
Test Loss:  0.03688621520996094
Valid Loss:  0.03960661590099335
Epoch:  233  	Training Loss: 0.03737546503543854
Test Loss:  0.03688572347164154
Valid Loss:  0.03960268944501877
Epoch:  234  	Training Loss: 0.03737153485417366
Test Loss:  0.036885153502225876
Valid Loss:  0.03959876671433449
Epoch:  235  	Training Loss: 0.037367627024650574
Test Loss:  0.03688448667526245
Valid Loss:  0.03959483280777931
Epoch:  236  	Training Loss: 0.03736373782157898
Test Loss:  0.036883749067783356
Valid Loss:  0.03959088772535324
Epoch:  237  	Training Loss: 0.037359870970249176
Test Loss:  0.0368829220533371
Valid Loss:  0.03958694636821747
Epoch:  238  	Training Loss: 0.037356019020080566
Test Loss:  0.036882027983665466
Valid Loss:  0.0395829938352108
Epoch:  239  	Training Loss: 0.03735218942165375
Test Loss:  0.036881059408187866
Valid Loss:  0.039579033851623535
Epoch:  240  	Training Loss: 0.03734837472438812
Test Loss:  0.03688003122806549
Valid Loss:  0.03957506641745567
Epoch:  241  	Training Loss: 0.03734458237886429
Test Loss:  0.036878958344459534
Valid Loss:  0.03957110643386841
Epoch:  242  	Training Loss: 0.037340812385082245
Test Loss:  0.036877818405628204
Valid Loss:  0.039567165076732635
Epoch:  243  	Training Loss: 0.03733709082007408
Test Loss:  0.0368766263127327
Valid Loss:  0.03956321254372597
Epoch:  244  	Training Loss: 0.03733338415622711
Test Loss:  0.03687537461519241
Valid Loss:  0.0395592600107193
Epoch:  245  	Training Loss: 0.037329696118831635
Test Loss:  0.03687407076358795
Valid Loss:  0.03955530747771263
Epoch:  246  	Training Loss: 0.037326015532016754
Test Loss:  0.036872707307338715
Valid Loss:  0.03955135494470596
Epoch:  247  	Training Loss: 0.03732234984636307
Test Loss:  0.036871276795864105
Valid Loss:  0.0395473949611187
Epoch:  248  	Training Loss: 0.037318695336580276
Test Loss:  0.03686979413032532
Valid Loss:  0.03954343870282173
Epoch:  249  	Training Loss: 0.03731507062911987
Test Loss:  0.03686825558543205
Valid Loss:  0.03953947871923447
Epoch:  250  	Training Loss: 0.03731144964694977
Test Loss:  0.03686666488647461
Valid Loss:  0.039535507559776306
Epoch:  251  	Training Loss: 0.03730784356594086
Test Loss:  0.036865025758743286
Valid Loss:  0.03953154385089874
Epoch:  252  	Training Loss: 0.03730425238609314
Test Loss:  0.03686331957578659
Valid Loss:  0.03952755406498909
Epoch:  253  	Training Loss: 0.037300653755664825
Test Loss:  0.03686157241463661
Valid Loss:  0.03952354937791824
Epoch:  254  	Training Loss: 0.03729706257581711
Test Loss:  0.03685976564884186
Valid Loss:  0.03951955586671829
Epoch:  255  	Training Loss: 0.03729349002242088
Test Loss:  0.03685792163014412
Valid Loss:  0.039515554904937744
Epoch:  256  	Training Loss: 0.037289924919605255
Test Loss:  0.0368560254573822
Valid Loss:  0.039511553943157196
Epoch:  257  	Training Loss: 0.03728637471795082
Test Loss:  0.0368540957570076
Valid Loss:  0.03950755298137665
Epoch:  258  	Training Loss: 0.03728283941745758
Test Loss:  0.036852121353149414
Valid Loss:  0.0395035482943058
Epoch:  259  	Training Loss: 0.03727930784225464
Test Loss:  0.036850109696388245
Valid Loss:  0.039499539881944656
Epoch:  260  	Training Loss: 0.037275783717632294
Test Loss:  0.03684808313846588
Valid Loss:  0.03949553146958351
Epoch:  261  	Training Loss: 0.037272270768880844
Test Loss:  0.036846011877059937
Valid Loss:  0.03949151560664177
Epoch:  262  	Training Loss: 0.03726876154541969
Test Loss:  0.036843929439783096
Valid Loss:  0.039487503468990326
Epoch:  263  	Training Loss: 0.03726525604724884
Test Loss:  0.036841802299022675
Valid Loss:  0.03948348015546799
Epoch:  264  	Training Loss: 0.037261754274368286
Test Loss:  0.036839645355939865
Valid Loss:  0.03947944939136505
Epoch:  265  	Training Loss: 0.03725825995206833
Test Loss:  0.03683745861053467
Valid Loss:  0.03947542607784271
Epoch:  266  	Training Loss: 0.03725477308034897
Test Loss:  0.036835238337516785
Valid Loss:  0.03947141021490097
Epoch:  267  	Training Loss: 0.0372513122856617
Test Loss:  0.03683299571275711
Valid Loss:  0.03946739435195923
Epoch:  268  	Training Loss: 0.03724786266684532
Test Loss:  0.03683071583509445
Valid Loss:  0.03946337848901749
Epoch:  269  	Training Loss: 0.037244416773319244
Test Loss:  0.036828406155109406
Valid Loss:  0.039459362626075745
Epoch:  270  	Training Loss: 0.03724097087979317
Test Loss:  0.03682607039809227
Valid Loss:  0.039455346763134
Epoch:  271  	Training Loss: 0.03723754733800888
Test Loss:  0.03682371973991394
Valid Loss:  0.03945132717490196
Epoch:  272  	Training Loss: 0.037234120070934296
Test Loss:  0.036821357905864716
Valid Loss:  0.039447300136089325
Epoch:  273  	Training Loss: 0.037230685353279114
Test Loss:  0.0368189662694931
Valid Loss:  0.03944326192140579
Epoch:  274  	Training Loss: 0.03722724691033363
Test Loss:  0.0368165522813797
Valid Loss:  0.03943922370672226
Epoch:  275  	Training Loss: 0.03722382336854935
Test Loss:  0.036814115941524506
Valid Loss:  0.03943518549203873
Epoch:  276  	Training Loss: 0.03722039982676506
Test Loss:  0.03681165352463722
Valid Loss:  0.03943115472793579
Epoch:  277  	Training Loss: 0.03721698373556137
Test Loss:  0.03680916875600815
Valid Loss:  0.03942723572254181
Epoch:  278  	Training Loss: 0.03721357509493828
Test Loss:  0.036806657910346985
Valid Loss:  0.03942350298166275
Epoch:  279  	Training Loss: 0.037210170179605484
Test Loss:  0.03680413216352463
Valid Loss:  0.03941977769136429
Epoch:  280  	Training Loss: 0.037206776440143585
Test Loss:  0.03680158406496048
Valid Loss:  0.039416052401065826
Epoch:  281  	Training Loss: 0.03720337897539139
Test Loss:  0.03679901361465454
Valid Loss:  0.03941234201192856
Epoch:  282  	Training Loss: 0.037199996411800385
Test Loss:  0.03679646924138069
Valid Loss:  0.03940892219543457
Epoch:  283  	Training Loss: 0.03719661384820938
Test Loss:  0.03679390996694565
Valid Loss:  0.03940552473068237
Epoch:  284  	Training Loss: 0.03719324618577957
Test Loss:  0.036791324615478516
Valid Loss:  0.039402127265930176
Epoch:  285  	Training Loss: 0.03718988969922066
Test Loss:  0.03678872808814049
Valid Loss:  0.03939874470233917
Epoch:  286  	Training Loss: 0.03718654066324234
Test Loss:  0.03678610920906067
Valid Loss:  0.03939563035964966
Epoch:  287  	Training Loss: 0.03718320280313492
Test Loss:  0.03678375482559204
Valid Loss:   57%|█████▋    | 287/500 [03:18<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:18<01:11,  2.97it/s] 58%|█████▊    | 291/500 [03:24<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:24<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:24<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:25<01:09,  2.91it/s] 60%|██████    | 301/500 [03:31<03:55,  1.18s/it] 61%|██████    | 303/500 [03:31<02:47,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:31<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:38<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:38<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:38<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:38<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:45<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:45<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:45<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:45<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:45<00:58,  2.95it/s] 66%|██████▌   | 331/500 [03:51<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:52<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:52<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:52<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:52<00:53,  2.98it/s] 68%|██████▊   | 341/500 [03:58<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:12,  1.19it/s] 69%|██████▉   | 345/500 [03:58<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:59<01:08,  2.25it/s] 70%|██████▉   | 349/500 [03:59<00:50,  3.02it/s] 70%|███████   | 351/500 [04:05<02:54,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s] 71%|███████   | 355/500 [04:05<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:05<01:03,  2.25it/s]0.03939257562160492
Epoch:  288  	Training Loss: 0.03717987984418869
Test Loss:  0.03678141534328461
Valid Loss:  0.03938952460885048
Epoch:  289  	Training Loss: 0.03717655688524246
Test Loss:  0.03677906095981598
Valid Loss:  0.039386481046676636
Epoch:  290  	Training Loss: 0.03717324510216713
Test Loss:  0.03677669167518616
Valid Loss:  0.03938344866037369
Epoch:  291  	Training Loss: 0.0371699258685112
Test Loss:  0.03677430748939514
Valid Loss:  0.03938041627407074
Epoch:  292  	Training Loss: 0.037166621536016464
Test Loss:  0.03677194565534592
Valid Loss:  0.039377376437187195
Epoch:  293  	Training Loss: 0.03716330975294113
Test Loss:  0.0367695689201355
Valid Loss:  0.039374347776174545
Epoch:  294  	Training Loss: 0.0371600016951561
Test Loss:  0.036767177283763885
Valid Loss:  0.03937133401632309
Epoch:  295  	Training Loss: 0.03715670853853226
Test Loss:  0.036764778196811676
Valid Loss:  0.03936833515763283
Epoch:  296  	Training Loss: 0.03715342655777931
Test Loss:  0.03676236420869827
Valid Loss:  0.039365340024232864
Epoch:  297  	Training Loss: 0.037150148302316666
Test Loss:  0.03675994277000427
Valid Loss:  0.0393623486161232
Epoch:  298  	Training Loss: 0.03714687377214432
Test Loss:  0.03675752133131027
Valid Loss:  0.03935937210917473
Epoch:  299  	Training Loss: 0.03714360296726227
Test Loss:  0.03675508871674538
Valid Loss:  0.039356399327516556
Epoch:  300  	Training Loss: 0.03714033216238022
Test Loss:  0.036752648651599884
Valid Loss:  0.03935343027114868
Epoch:  301  	Training Loss: 0.037137068808078766
Test Loss:  0.03675020486116409
Valid Loss:  0.0393504723906517
Epoch:  302  	Training Loss: 0.03713382035493851
Test Loss:  0.03674778714776039
Valid Loss:  0.03934749215841293
Epoch:  303  	Training Loss: 0.03713054955005646
Test Loss:  0.03674563765525818
Valid Loss:  0.039344511926174164
Epoch:  304  	Training Loss: 0.037127282470464706
Test Loss:  0.036744408309459686
Valid Loss:  0.03934140503406525
Epoch:  305  	Training Loss: 0.0371241420507431
Test Loss:  0.03674314171075821
Valid Loss:  0.03933831304311752
Epoch:  306  	Training Loss: 0.0371210053563118
Test Loss:  0.03674183785915375
Valid Loss:  0.039335235953330994
Epoch:  307  	Training Loss: 0.03711787611246109
Test Loss:  0.03674064576625824
Valid Loss:  0.03933217003941536
Epoch:  308  	Training Loss: 0.03711475431919098
Test Loss:  0.036739446222782135
Valid Loss:  0.03932911902666092
Epoch:  309  	Training Loss: 0.03711164742708206
Test Loss:  0.03673822805285454
Valid Loss:  0.03932608664035797
Epoch:  310  	Training Loss: 0.03710854426026344
Test Loss:  0.036736976355314255
Valid Loss:  0.03932305425405502
Epoch:  311  	Training Loss: 0.03710544854402542
Test Loss:  0.036735713481903076
Valid Loss:  0.039320047944784164
Epoch:  312  	Training Loss: 0.037102360278367996
Test Loss:  0.036734431982040405
Valid Loss:  0.039317063987255096
Epoch:  313  	Training Loss: 0.037099290639162064
Test Loss:  0.03673313558101654
Valid Loss:  0.03931409493088722
Epoch:  314  	Training Loss: 0.03709622472524643
Test Loss:  0.03673182427883148
Valid Loss:  0.039311133325099945
Epoch:  315  	Training Loss: 0.03709316998720169
Test Loss:  0.03673049062490463
Valid Loss:  0.03930823504924774
Epoch:  316  	Training Loss: 0.03709012269973755
Test Loss:  0.03672913461923599
Valid Loss:  0.03930549696087837
Epoch:  317  	Training Loss: 0.03708707541227341
Test Loss:  0.03672776743769646
Valid Loss:  0.0393027737736702
Epoch:  318  	Training Loss: 0.03708403557538986
Test Loss:  0.03672637790441513
Valid Loss:  0.039300065487623215
Epoch:  319  	Training Loss: 0.03708101063966751
Test Loss:  0.03672497346997261
Valid Loss:  0.03929737210273743
Epoch:  320  	Training Loss: 0.03707798197865486
Test Loss:  0.0367235504090786
Valid Loss:  0.03929469734430313
Epoch:  321  	Training Loss: 0.03707496076822281
Test Loss:  0.03672210872173309
Valid Loss:  0.039292022585868835
Epoch:  322  	Training Loss: 0.03707194700837135
Test Loss:  0.03672066330909729
Valid Loss:  0.039289362728595734
Epoch:  323  	Training Loss: 0.0370689257979393
Test Loss:  0.03671920299530029
Valid Loss:  0.03928671032190323
Epoch:  324  	Training Loss: 0.037065908312797546
Test Loss:  0.0367177277803421
Valid Loss:  0.03928406536579132
Epoch:  325  	Training Loss: 0.037062905728816986
Test Loss:  0.03671623766422272
Valid Loss:  0.03928143531084061
Epoch:  326  	Training Loss: 0.03705989196896553
Test Loss:  0.03671474754810333
Valid Loss:  0.03927881270647049
Epoch:  327  	Training Loss: 0.03705689683556557
Test Loss:  0.03671323508024216
Valid Loss:  0.039276208728551865
Epoch:  328  	Training Loss: 0.037053897976875305
Test Loss:  0.03671170771121979
Valid Loss:  0.03927361220121384
Epoch:  329  	Training Loss: 0.03705092892050743
Test Loss:  0.03671091049909592
Valid Loss:  0.039270736277103424
Epoch:  330  	Training Loss: 0.03704801946878433
Test Loss:  0.03671007603406906
Valid Loss:  0.0392678864300251
Epoch:  331  	Training Loss: 0.03704512119293213
Test Loss:  0.03670921176671982
Valid Loss:  0.03926505893468857
Epoch:  332  	Training Loss: 0.037042222917079926
Test Loss:  0.036708347499370575
Valid Loss:  0.03926226869225502
Epoch:  333  	Training Loss: 0.03703936189413071
Test Loss:  0.036707453429698944
Valid Loss:  0.03925950452685356
Epoch:  334  	Training Loss: 0.037036508321762085
Test Loss:  0.03670652583241463
Valid Loss:  0.03925677016377449
Epoch:  335  	Training Loss: 0.03703365847468376
Test Loss:  0.03670557588338852
Valid Loss:  0.03925405442714691
Epoch:  336  	Training Loss: 0.037030816078186035
Test Loss:  0.036704592406749725
Valid Loss:  0.03925137221813202
Epoch:  337  	Training Loss: 0.0370279923081398
Test Loss:  0.03670358657836914
Valid Loss:  0.039248693734407425
Epoch:  338  	Training Loss: 0.03702516853809357
Test Loss:  0.036702558398246765
Valid Loss:  0.03924604505300522
Epoch:  339  	Training Loss: 0.03702235594391823
Test Loss:  0.036701500415802
Valid Loss:  0.039243414998054504
Epoch:  340  	Training Loss: 0.037019550800323486
Test Loss:  0.036700423806905746
Valid Loss:  0.03924079239368439
Epoch:  341  	Training Loss: 0.03701674938201904
Test Loss:  0.0366993248462677
Valid Loss:  0.03923819586634636
Epoch:  342  	Training Loss: 0.03701396286487579
Test Loss:  0.03669818490743637
Valid Loss:  0.03923558443784714
Epoch:  343  	Training Loss: 0.037011146545410156
Test Loss:  0.036697015166282654
Valid Loss:  0.03923298418521881
Epoch:  344  	Training Loss: 0.03700833022594452
Test Loss:  0.03669583052396774
Valid Loss:  0.03923039510846138
Epoch:  345  	Training Loss: 0.037005528807640076
Test Loss:  0.03669463098049164
Valid Loss:  0.03922782838344574
Epoch:  346  	Training Loss: 0.03700273856520653
Test Loss:  0.036693401634693146
Valid Loss:  0.039225272834300995
Epoch:  347  	Training Loss: 0.03699994459748268
Test Loss:  0.036692164838314056
Valid Loss:  0.039222732186317444
Epoch:  348  	Training Loss: 0.03699716553092003
Test Loss:  0.036690905690193176
Valid Loss:  0.03922020271420479
Epoch:  349  	Training Loss: 0.03699438273906708
Test Loss:  0.036689624190330505
Valid Loss:  0.03921769559383392
Epoch:  350  	Training Loss: 0.036991603672504425
Test Loss:  0.03668832406401634
Valid Loss:  0.03921519219875336
Epoch:  351  	Training Loss: 0.036988839507102966
Test Loss:  0.036687012761831284
Valid Loss:  0.039212699979543686
Epoch:  352  	Training Loss: 0.03698607161641121
Test Loss:  0.03668570518493652
Valid Loss:  0.039210230112075806
Epoch:  353  	Training Loss: 0.03698332607746124
Test Loss:  0.03668438643217087
Valid Loss:  0.03920777887105942
Epoch:  354  	Training Loss: 0.036980584263801575
Test Loss:  0.03668304905295372
Valid Loss:  0.03920533508062363
Epoch:  355  	Training Loss: 0.03697784245014191
Test Loss:  0.03668169677257538
Valid Loss:  0.03920289874076843
Epoch:  356  	Training Loss: 0.036975108087062836
Test Loss:  0.03668033331632614
Valid Loss:  0.039200469851493835
Epoch:  357  	Training Loss: 0.03697238117456436
Test Loss:  0.036678947508335114
Valid Loss:  0.03919805958867073
Epoch:  358  	Training Loss: 0.03696965426206589
Test Loss:  0.03667755424976349
Valid Loss:  0.03919566050171852
 72%|███████▏  | 359/500 [04:06<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:12<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:12<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:12<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:12<01:00,  2.22it/s] 74%|███████▍  | 369/500 [04:12<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:19<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:19<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:19<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:19<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:26<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:26<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:26<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:26<00:51,  2.19it/s] 78%|███████▊  | 389/500 [04:26<00:37,  2.95it/s] 78%|███████▊  | 391/500 [04:32<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:33<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:33<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:33<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.01it/s] 80%|████████  | 401/500 [04:39<01:56,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.19it/s] 81%|████████  | 405/500 [04:39<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:40<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:40<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:46<01:43,  1.16s/it] 83%|████████▎ | 413/500 [04:46<01:12,  1.20it/s] 83%|████████▎ | 415/500 [04:46<00:51,  1.66it/s] 83%|████████▎ | 417/500 [04:46<00:36,  2.27it/s] 84%|████████▍ | 419/500 [04:46<00:26,  3.05it/s] 84%|████████▍ | 421/500 [04:53<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:53<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:53<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:53<00:23,  2.98it/s]Epoch:  359  	Training Loss: 0.03696693480014801
Test Loss:  0.03667614609003067
Valid Loss:  0.03919326514005661
Epoch:  360  	Training Loss: 0.03696421906352043
Test Loss:  0.036674730479717255
Valid Loss:  0.03919088467955589
Epoch:  361  	Training Loss: 0.03696150705218315
Test Loss:  0.036673303693532944
Valid Loss:  0.03918851166963577
Epoch:  362  	Training Loss: 0.03695879876613617
Test Loss:  0.03667185828089714
Valid Loss:  0.03918614238500595
Epoch:  363  	Training Loss: 0.03695608302950859
Test Loss:  0.03667038679122925
Valid Loss:  0.03918377310037613
Epoch:  364  	Training Loss: 0.03695337101817131
Test Loss:  0.036668919026851654
Valid Loss:  0.0391814224421978
Epoch:  365  	Training Loss: 0.03695065900683403
Test Loss:  0.036667436361312866
Valid Loss:  0.03917907178401947
Epoch:  366  	Training Loss: 0.03694795072078705
Test Loss:  0.036665938794612885
Valid Loss:  0.03917673975229263
Epoch:  367  	Training Loss: 0.03694525361061096
Test Loss:  0.0366644449532032
Valid Loss:  0.039174411445856094
Epoch:  368  	Training Loss: 0.036942556500434875
Test Loss:  0.036662936210632324
Valid Loss:  0.03917209059000015
Epoch:  369  	Training Loss: 0.03693985566496849
Test Loss:  0.03666141256690025
Valid Loss:  0.039169784635305405
Epoch:  370  	Training Loss: 0.036937166005373
Test Loss:  0.03665987774729729
Valid Loss:  0.039167486131191254
Epoch:  371  	Training Loss: 0.03693448007106781
Test Loss:  0.03665834665298462
Valid Loss:  0.0391651913523674
Epoch:  372  	Training Loss: 0.03693179786205292
Test Loss:  0.036656804382801056
Valid Loss:  0.039162904024124146
Epoch:  373  	Training Loss: 0.036929111927747726
Test Loss:  0.036655277013778687
Valid Loss:  0.03916062414646149
Epoch:  374  	Training Loss: 0.03692646697163582
Test Loss:  0.036654479801654816
Valid Loss:  0.039158109575510025
Epoch:  375  	Training Loss: 0.03692387789487839
Test Loss:  0.03665364906191826
Valid Loss:  0.039155613631010056
Epoch:  376  	Training Loss: 0.036921292543411255
Test Loss:  0.03665279597043991
Valid Loss:  0.03915313631296158
Epoch:  377  	Training Loss: 0.03691871464252472
Test Loss:  0.03665190935134888
Valid Loss:  0.039150677621364594
Epoch:  378  	Training Loss: 0.03691614419221878
Test Loss:  0.03665100038051605
Valid Loss:  0.039148230105638504
Epoch:  379  	Training Loss: 0.03691358491778374
Test Loss:  0.03665006533265114
Valid Loss:  0.03914579749107361
Epoch:  380  	Training Loss: 0.036911025643348694
Test Loss:  0.03664910048246384
Valid Loss:  0.039143383502960205
Epoch:  381  	Training Loss: 0.036908481270074844
Test Loss:  0.03664811700582504
Valid Loss:  0.039140984416007996
Epoch:  382  	Training Loss: 0.036905936896800995
Test Loss:  0.03664713352918625
Valid Loss:  0.03913863003253937
Epoch:  383  	Training Loss: 0.03690343350172043
Test Loss:  0.03664613515138626
Valid Loss:  0.039136290550231934
Epoch:  384  	Training Loss: 0.03690093010663986
Test Loss:  0.03664510324597359
Valid Loss:  0.03913397714495659
Epoch:  385  	Training Loss: 0.03689843416213989
Test Loss:  0.03664405643939972
Valid Loss:  0.03913167491555214
Epoch:  386  	Training Loss: 0.03689594566822052
Test Loss:  0.03664299473166466
Valid Loss:  0.039129387587308884
Epoch:  387  	Training Loss: 0.036893464624881744
Test Loss:  0.03664190694689751
Valid Loss:  0.039127103984355927
Epoch:  388  	Training Loss: 0.03689098358154297
Test Loss:  0.03664080798625946
Valid Loss:  0.03912484645843506
Epoch:  389  	Training Loss: 0.03688851743936539
Test Loss:  0.036639682948589325
Valid Loss:  0.03912259638309479
Epoch:  390  	Training Loss: 0.036886051297187805
Test Loss:  0.036638546735048294
Valid Loss:  0.039120350033044815
Epoch:  391  	Training Loss: 0.03688359260559082
Test Loss:  0.03663739189505577
Valid Loss:  0.039118122309446335
Epoch:  392  	Training Loss: 0.036881133913993835
Test Loss:  0.036636173725128174
Valid Loss:  0.03911585733294487
Epoch:  393  	Training Loss: 0.036878641694784164
Test Loss:  0.03663495182991028
Valid Loss:  0.0391136109828949
Epoch:  394  	Training Loss: 0.03687615320086479
Test Loss:  0.03663370758295059
Valid Loss:  0.03911137953400612
Epoch:  395  	Training Loss: 0.03687366843223572
Test Loss:  0.036632440984249115
Valid Loss:  0.03910914808511734
Epoch:  396  	Training Loss: 0.03687119111418724
Test Loss:  0.03663117438554764
Valid Loss:  0.03910692781209946
Epoch:  397  	Training Loss: 0.03686872124671936
Test Loss:  0.03662988543510437
Valid Loss:  0.03910472244024277
Epoch:  398  	Training Loss: 0.03686624765396118
Test Loss:  0.03662858158349991
Valid Loss:  0.039102524518966675
Epoch:  399  	Training Loss: 0.0368637815117836
Test Loss:  0.03662727028131485
Valid Loss:  0.03910033032298088
Epoch:  400  	Training Loss: 0.03686131536960602
Test Loss:  0.0366259440779686
Valid Loss:  0.03909815102815628
Epoch:  401  	Training Loss: 0.03685886040329933
Test Loss:  0.03662461042404175
Valid Loss:  0.03909597173333168
Epoch:  402  	Training Loss: 0.036856405436992645
Test Loss:  0.036623261868953705
Valid Loss:  0.03909379988908768
Epoch:  403  	Training Loss: 0.03685394674539566
Test Loss:  0.036621902137994766
Valid Loss:  0.03909163549542427
Epoch:  404  	Training Loss: 0.03685149550437927
Test Loss:  0.03662053495645523
Valid Loss:  0.03908947482705116
Epoch:  405  	Training Loss: 0.036849044263362885
Test Loss:  0.0366191528737545
Valid Loss:  0.03908732905983925
Epoch:  406  	Training Loss: 0.036846600472927094
Test Loss:  0.036617763340473175
Valid Loss:  0.03908518701791763
Epoch:  407  	Training Loss: 0.0368441566824913
Test Loss:  0.03661636263132095
Valid Loss:  0.039083048701286316
Epoch:  408  	Training Loss: 0.03684171661734581
Test Loss:  0.036614950746297836
Valid Loss:  0.039080917835235596
Epoch:  409  	Training Loss: 0.03683927655220032
Test Loss:  0.03661353513598442
Valid Loss:  0.03907879814505577
Epoch:  410  	Training Loss: 0.03683684766292572
Test Loss:  0.03661210462450981
Valid Loss:  0.039076678454875946
Epoch:  411  	Training Loss: 0.03683441877365112
Test Loss:  0.0366106741130352
Valid Loss:  0.03907456994056702
Epoch:  412  	Training Loss: 0.036831989884376526
Test Loss:  0.03660927712917328
Valid Loss:  0.03907250612974167
Epoch:  413  	Training Loss: 0.03682960569858551
Test Loss:  0.03660786896944046
Valid Loss:  0.03907043859362602
Epoch:  414  	Training Loss: 0.0368272140622139
Test Loss:  0.03660644590854645
Valid Loss:  0.03906837850809097
Epoch:  415  	Training Loss: 0.03682482987642288
Test Loss:  0.03660503029823303
Valid Loss:  0.03906632587313652
Epoch:  416  	Training Loss: 0.036822445690631866
Test Loss:  0.03660360723733902
Valid Loss:  0.039064280688762665
Epoch:  417  	Training Loss: 0.03682006895542145
Test Loss:  0.036602169275283813
Valid Loss:  0.039062242954969406
Epoch:  418  	Training Loss: 0.036817699670791626
Test Loss:  0.03660073131322861
Valid Loss:  0.039060212671756744
Epoch:  419  	Training Loss: 0.03681532293558121
Test Loss:  0.036599285900592804
Valid Loss:  0.03905818238854408
Epoch:  420  	Training Loss: 0.036812953650951385
Test Loss:  0.03659782558679581
Valid Loss:  0.03905615955591202
Epoch:  421  	Training Loss: 0.036810584366321564
Test Loss:  0.03659637272357941
Valid Loss:  0.03905414044857025
Epoch:  422  	Training Loss: 0.03680822625756264
Test Loss:  0.03659487143158913
Valid Loss:  0.0390520915389061
Epoch:  423  	Training Loss: 0.036805834621191025
Test Loss:  0.036593370139598846
Valid Loss:  0.03905004262924194
Epoch:  424  	Training Loss: 0.0368034765124321
Test Loss:  0.03659258782863617
Valid Loss:  0.039047807455062866
Epoch:  425  	Training Loss: 0.036801159381866455
Test Loss:  0.03659176826477051
Valid Loss:  0.039045579731464386
Epoch:  426  	Training Loss: 0.03679885342717171
Test Loss:  0.03659093379974365
Valid Loss:  0.0390433706343174
Epoch:  427  	Training Loss: 0.036796554923057556
Test Loss:  0.03659006953239441
Valid Loss:  0.039041172713041306
Epoch:  428  	Training Loss: 0.036794260144233704
Test Loss:  0.036589182913303375
Valid Loss:  0.03903898596763611
Epoch:  429  	Training Loss: 0.03679197281599045
Test Loss:  0.03658827394247055
Valid Loss:  0.03903681039810181
 86%|████████▌ | 431/500 [05:00<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:00<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:00<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:00<00:29,  2.17it/s] 88%|████████▊ | 439/500 [05:00<00:21,  2.87it/s] 88%|████████▊ | 441/500 [05:07<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:07<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:07<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:07<00:24,  2.21it/s] 90%|████████▉ | 449/500 [05:07<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:14<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:14<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:14<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:21<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:21<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:21<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:21<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:21<00:10,  2.97it/s] 94%|█████████▍| 471/500 [05:27<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:28<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:28<00:15,  1.60it/s] 95%|█████████▌| 477/500 [05:28<00:10,  2.19it/s] 96%|█████████▌| 479/500 [05:28<00:07,  2.95it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.21s/it] 97%|█████████▋| 483/500 [05:35<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:35<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:35<00:05,  2.18it/s] 98%|█████████▊| 489/500 [05:35<00:03,  2.93it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:42<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:42<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:42<00:01,  2.18it/s]100%|█████████▉| 499/500 [05:42<00:00,  2.92it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
Epoch:  430  	Training Loss: 0.03678968548774719
Test Loss:  0.03658733516931534
Valid Loss:  0.039034657180309296
Epoch:  431  	Training Loss: 0.036787405610084534
Test Loss:  0.03658638149499893
Valid Loss:  0.03903250768780708
Epoch:  432  	Training Loss: 0.03678512945771217
Test Loss:  0.03658539056777954
Valid Loss:  0.03903035819530487
Epoch:  433  	Training Loss: 0.036782845854759216
Test Loss:  0.036584384739398956
Valid Loss:  0.03902822360396385
Epoch:  434  	Training Loss: 0.036780573427677155
Test Loss:  0.03658335655927658
Valid Loss:  0.03902610018849373
Epoch:  435  	Training Loss: 0.03677830845117569
Test Loss:  0.03658230975270271
Valid Loss:  0.0390239879488945
Epoch:  436  	Training Loss: 0.036776039749383926
Test Loss:  0.03658124431967735
Valid Loss:  0.03902188688516617
Epoch:  437  	Training Loss: 0.03677377849817276
Test Loss:  0.0365801565349102
Valid Loss:  0.03901979327201843
Epoch:  438  	Training Loss: 0.03677152097225189
Test Loss:  0.036579057574272156
Valid Loss:  0.039017707109451294
Epoch:  439  	Training Loss: 0.03676926717162132
Test Loss:  0.03657793998718262
Valid Loss:  0.03901562839746475
Epoch:  440  	Training Loss: 0.03676701709628105
Test Loss:  0.03657680004835129
Valid Loss:  0.039013564586639404
Epoch:  441  	Training Loss: 0.03676477074623108
Test Loss:  0.036575645208358765
Valid Loss:  0.03901149332523346
Epoch:  442  	Training Loss: 0.03676252067089081
Test Loss:  0.03657449409365654
Valid Loss:  0.0390094630420208
Epoch:  443  	Training Loss: 0.03676028922200203
Test Loss:  0.03657332807779312
Valid Loss:  0.03900742530822754
Epoch:  444  	Training Loss: 0.03675805777311325
Test Loss:  0.03657213971018791
Valid Loss:  0.03900539129972458
Epoch:  445  	Training Loss: 0.03675583004951477
Test Loss:  0.0365709513425827
Valid Loss:  0.03900337964296341
Epoch:  446  	Training Loss: 0.03675360977649689
Test Loss:  0.036569736897945404
Valid Loss:  0.03900136053562164
Epoch:  447  	Training Loss: 0.036751389503479004
Test Loss:  0.036568526178598404
Valid Loss:  0.03899935632944107
Epoch:  448  	Training Loss: 0.03674917295575142
Test Loss:  0.036567285656929016
Valid Loss:  0.038997355848550797
Epoch:  449  	Training Loss: 0.036746956408023834
Test Loss:  0.03656604140996933
Valid Loss:  0.038995370268821716
Epoch:  450  	Training Loss: 0.03674474358558655
Test Loss:  0.03656481206417084
Valid Loss:  0.038993388414382935
Epoch:  451  	Training Loss: 0.03674253821372986
Test Loss:  0.03656370937824249
Valid Loss:  0.03899140655994415
Epoch:  452  	Training Loss: 0.03674033284187317
Test Loss:  0.03656260669231415
Valid Loss:  0.03898945450782776
Epoch:  453  	Training Loss: 0.03673814609646797
Test Loss:  0.0365615040063858
Valid Loss:  0.038987502455711365
Epoch:  454  	Training Loss: 0.03673596307635307
Test Loss:  0.036560382694005966
Valid Loss:  0.03898555785417557
Epoch:  455  	Training Loss: 0.036733776330947876
Test Loss:  0.03655926138162613
Valid Loss:  0.03898362070322037
Epoch:  456  	Training Loss: 0.036731600761413574
Test Loss:  0.0365581214427948
Valid Loss:  0.03898168355226517
Epoch:  457  	Training Loss: 0.036729443818330765
Test Loss:  0.03655756264925003
Valid Loss:  0.038979582488536835
Epoch:  458  	Training Loss: 0.03672732412815094
Test Loss:  0.036556974053382874
Valid Loss:  0.0389774851500988
Epoch:  459  	Training Loss: 0.03672520071268082
Test Loss:  0.036556363105773926
Valid Loss:  0.03897539898753166
Epoch:  460  	Training Loss: 0.03672309219837189
Test Loss:  0.036555737257003784
Valid Loss:  0.03897333890199661
Epoch:  461  	Training Loss: 0.03672099485993385
Test Loss:  0.036555081605911255
Valid Loss:  0.03897128626704216
Epoch:  462  	Training Loss: 0.03671889379620552
Test Loss:  0.03655442222952843
Valid Loss:  0.0389692559838295
Epoch:  463  	Training Loss: 0.03671681508421898
Test Loss:  0.03655373677611351
Valid Loss:  0.03896723687648773
Epoch:  464  	Training Loss: 0.03671473637223244
Test Loss:  0.0365530364215374
Valid Loss:  0.03896522894501686
Epoch:  465  	Training Loss: 0.03671266883611679
Test Loss:  0.0365523099899292
Valid Loss:  0.03896322846412659
Epoch:  466  	Training Loss: 0.036710597574710846
Test Loss:  0.0365515798330307
Valid Loss:  0.038961246609687805
Epoch:  467  	Training Loss: 0.036708537489175797
Test Loss:  0.036550819873809814
Valid Loss:  0.03895927220582962
Epoch:  468  	Training Loss: 0.036706484854221344
Test Loss:  0.036550045013427734
Valid Loss:  0.03895731270313263
Epoch:  469  	Training Loss: 0.03670443594455719
Test Loss:  0.03654926270246506
Valid Loss:  0.038955360651016235
Epoch:  470  	Training Loss: 0.03670239448547363
Test Loss:  0.03654845058917999
Valid Loss:  0.03895340859889984
Epoch:  471  	Training Loss: 0.03670034557580948
Test Loss:  0.03654763102531433
Valid Loss:  0.038951482623815536
Epoch:  472  	Training Loss: 0.03669831156730652
Test Loss:  0.03654678910970688
Valid Loss:  0.038949545472860336
Epoch:  473  	Training Loss: 0.036696262657642365
Test Loss:  0.03654593229293823
Valid Loss:  0.03894761949777603
Epoch:  474  	Training Loss: 0.036694228649139404
Test Loss:  0.03654506057500839
Valid Loss:  0.038945700973272324
Epoch:  475  	Training Loss: 0.03669218719005585
Test Loss:  0.03654417023062706
Valid Loss:  0.03894378989934921
Epoch:  476  	Training Loss: 0.03669015318155289
Test Loss:  0.036543264985084534
Valid Loss:  0.0389418825507164
Epoch:  477  	Training Loss: 0.03668811917304993
Test Loss:  0.03654235601425171
Valid Loss:  0.03893999382853508
Epoch:  478  	Training Loss: 0.03668609634041786
Test Loss:  0.03654143214225769
Valid Loss:  0.03893810510635376
Epoch:  479  	Training Loss: 0.0366840697824955
Test Loss:  0.03654048591852188
Valid Loss:  0.038936223834753036
Epoch:  480  	Training Loss: 0.03668205067515373
Test Loss:  0.03653953969478607
Valid Loss:  0.03893435001373291
Epoch:  481  	Training Loss: 0.036680035293102264
Test Loss:  0.03653858229517937
Valid Loss:  0.03893248736858368
Epoch:  482  	Training Loss: 0.036678019911050797
Test Loss:  0.03653758019208908
Valid Loss:  0.03893059864640236
Epoch:  483  	Training Loss: 0.03667598217725754
Test Loss:  0.036536574363708496
Valid Loss:  0.03892872482538223
Epoch:  484  	Training Loss: 0.036673955619335175
Test Loss:  0.036535557359457016
Valid Loss:  0.038926851004362106
Epoch:  485  	Training Loss: 0.03667192906141281
Test Loss:  0.03653452545404434
Valid Loss:  0.03892498090863228
Epoch:  486  	Training Loss: 0.03666990250349045
Test Loss:  0.03653348609805107
Valid Loss:  0.038923121988773346
Epoch:  487  	Training Loss: 0.036667875945568085
Test Loss:  0.0365324430167675
Valid Loss:  0.03892127424478531
Epoch:  488  	Training Loss: 0.036665864288806915
Test Loss:  0.03653138875961304
Valid Loss:  0.03891942650079727
Epoch:  489  	Training Loss: 0.03666384890675545
Test Loss:  0.03653032332658768
Valid Loss:  0.03891758620738983
Epoch:  490  	Training Loss: 0.03666183352470398
Test Loss:  0.03652925044298172
Valid Loss:  0.038915738463401794
Epoch:  491  	Training Loss: 0.03665982186794281
Test Loss:  0.036528173834085464
Valid Loss:  0.03891391679644585
Epoch:  492  	Training Loss: 0.03665781766176224
Test Loss:  0.0365271233022213
Valid Loss:  0.03891211375594139
Epoch:  493  	Training Loss: 0.03665583208203316
Test Loss:  0.03652606159448624
Valid Loss:  0.03891032189130783
Epoch:  494  	Training Loss: 0.036653853952884674
Test Loss:  0.036524996161460876
Valid Loss:  0.03890853375196457
Epoch:  495  	Training Loss: 0.03665187954902649
Test Loss:  0.03652392327785492
Valid Loss:  0.038906749337911606
Epoch:  496  	Training Loss: 0.036649905145168304
Test Loss:  0.036522842943668365
Valid Loss:  0.03890496864914894
Epoch:  497  	Training Loss: 0.03664793074131012
Test Loss:  0.03652176260948181
Valid Loss:  0.03890319913625717
Epoch:  498  	Training Loss: 0.03664596378803253
Test Loss:  0.036520667374134064
Valid Loss:  0.038901422172784805
Epoch:  499  	Training Loss: 0.036643993109464645
Test Loss:  0.03651956468820572
Valid Loss:  0.038899652659893036
Epoch:  500  	Training Loss: 0.03664202615618706
Test Loss:  0.036518462002277374
Valid Loss:  0.03889789432287216
seed is  15
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:51,  6.24s/it]  1%|          | 3/500 [00:06<13:48,  1.67s/it]  1%|          | 5/500 [00:06<06:57,  1.19it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:53,  2.82it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:30,  1.19s/it]  5%|▍         | 23/500 [00:20<06:45,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:14,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<08:54,  1.17s/it]  9%|▊         | 43/500 [00:33<06:22,  1.20it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:20,  2.26it/s] 10%|▉         | 49/500 [00:34<02:28,  3.03it/s] 10%|█         | 51/500 [00:40<08:41,  1.16s/it] 11%|█         | 53/500 [00:40<06:13,  1.20it/s] 11%|█         | 55/500 [00:46<11:27,  1.54s/it] 11%|█▏        | 57/500 [00:46<08:08,  1.10s/it] 12%|█▏        | 59/500 [00:47<05:48,  1.26it/s] 12%|█▏        | 61/500 [00:53<10:59,  1.50s/it] 13%|█▎        | 63/500 [00:53<07:49,  1.07s/it] 13%|█▎        | 65/500 [00:53<05:35,  1.30it/s] 13%|█▎        | 67/500 [00:53<04:02,  1.79it/s] 14%|█▍        | 69/500 [00:53<02:57,  2.43it/s]Epoch:  1  	Training Loss: 0.1085098385810852
Test Loss:  54.110374450683594
Valid Loss:  53.2591552734375
Epoch:  2  	Training Loss: 52.91616439819336
Test Loss:  761.7315673828125
Valid Loss:  755.065673828125
Epoch:  3  	Training Loss: 739.120361328125
Test Loss:  5.833368301391602
Valid Loss:  5.960195064544678
Epoch:  4  	Training Loss: 5.995092391967773
Test Loss:  5.832996368408203
Valid Loss:  5.959385871887207
Epoch:  5  	Training Loss: 5.994285583496094
Test Loss:  5.832605838775635
Valid Loss:  5.958538055419922
Epoch:  6  	Training Loss: 5.993451118469238
Test Loss:  5.8322014808654785
Valid Loss:  5.957669734954834
Epoch:  7  	Training Loss: 5.992591381072998
Test Loss:  5.831749439239502
Valid Loss:  5.9567646980285645
Epoch:  8  	Training Loss: 5.991709232330322
Test Loss:  5.831270694732666
Valid Loss:  5.955803394317627
Epoch:  9  	Training Loss: 5.990786552429199
Test Loss:  5.8307671546936035
Valid Loss:  5.95481014251709
Epoch:  10  	Training Loss: 5.989850997924805
Test Loss:  5.830240249633789
Valid Loss:  5.95379638671875
Epoch:  11  	Training Loss: 5.988886833190918
Test Loss:  5.829663276672363
Valid Loss:  5.952723503112793
Epoch:  12  	Training Loss: 5.987860679626465
Test Loss:  457.87237548828125
Valid Loss:  449.1541748046875
Epoch:  13  	Training Loss: 446.64508056640625
Test Loss:  0.8303499817848206
Valid Loss:  0.8344727158546448
Epoch:  14  	Training Loss: 0.8368018865585327
Test Loss:  0.8303436636924744
Valid Loss:  0.8344664573669434
Epoch:  15  	Training Loss: 0.8367959260940552
Test Loss:  0.830337405204773
Valid Loss:  0.8344600200653076
Epoch:  16  	Training Loss: 0.8367900252342224
Test Loss:  0.8303310871124268
Valid Loss:  0.8344537019729614
Epoch:  17  	Training Loss: 0.8367841243743896
Test Loss:  0.8303247690200806
Valid Loss:  0.8344473838806152
Epoch:  18  	Training Loss: 0.8367781639099121
Test Loss:  0.8303184509277344
Valid Loss:  0.8344410061836243
Epoch:  19  	Training Loss: 0.8367722630500793
Test Loss:  0.8303121328353882
Valid Loss:  0.8344346284866333
Epoch:  20  	Training Loss: 0.8367663621902466
Test Loss:  0.830305814743042
Valid Loss:  0.8344282507896423
Epoch:  21  	Training Loss: 0.8367605209350586
Test Loss:  0.8302994966506958
Valid Loss:  0.8344219923019409
Epoch:  22  	Training Loss: 0.836754560470581
Test Loss:  10.852293014526367
Valid Loss:  10.612627029418945
Epoch:  23  	Training Loss: 10.425865173339844
Test Loss:  0.9253311157226562
Valid Loss:  0.9310811758041382
Epoch:  24  	Training Loss: 0.9316774606704712
Test Loss:  0.4031774699687958
Valid Loss:  0.40486639738082886
Epoch:  25  	Training Loss: 0.415009081363678
Test Loss:  0.21894875168800354
Valid Loss:  0.2244495153427124
Epoch:  26  	Training Loss: 0.2401200532913208
Test Loss:  0.15511101484298706
Valid Loss:  0.165429025888443
Epoch:  27  	Training Loss: 0.18521460890769958
Test Loss:  0.1361500322818756
Valid Loss:  0.14885687828063965
Epoch:  28  	Training Loss: 0.17004722356796265
Test Loss:  0.1237918809056282
Valid Loss:  0.13958629965782166
Epoch:  29  	Training Loss: 0.16067945957183838
Test Loss:  0.11557398736476898
Valid Loss:  0.13349290192127228
Epoch:  30  	Training Loss: 0.1543804407119751
Test Loss:  0.10955561697483063
Valid Loss:  0.12900307774543762
Epoch:  31  	Training Loss: 0.14959287643432617
Test Loss:  0.1047993078827858
Valid Loss:  0.1253555715084076
Epoch:  32  	Training Loss: 0.1456468403339386
Test Loss:  0.020151538774371147
Valid Loss:  0.023434463888406754
Epoch:  33  	Training Loss: 0.02741195820271969
Test Loss:  0.010568633675575256
Valid Loss:  0.01319810003042221
Epoch:  34  	Training Loss: 0.015575462952256203
Test Loss:  0.007331734523177147
Valid Loss:  0.009693325497210026
Epoch:  35  	Training Loss: 0.011293170973658562
Test Loss:  0.005399477668106556
Valid Loss:  0.007417915388941765
Epoch:  36  	Training Loss: 0.008514839224517345
Test Loss:  0.0042105126194655895
Valid Loss:  0.0059870765544474125
Epoch:  37  	Training Loss: 0.006723739206790924
Test Loss:  0.003463117405772209
Valid Loss:  0.005073826294392347
Epoch:  38  	Training Loss: 0.005522192921489477
Test Loss:  0.0029827936086803675
Valid Loss:  0.004454462788999081
Epoch:  39  	Training Loss: 0.004701514262706041
Test Loss:  0.002656414173543453
Valid Loss:  0.00401612464338541
Epoch:  40  	Training Loss: 0.004124919883906841
Test Loss:  0.0024304683320224285
Valid Loss:  0.003697236767038703
Epoch:  41  	Training Loss: 0.003712346311658621
Test Loss:  0.002270066412165761
Valid Loss:  0.0034604358952492476
Epoch:  42  	Training Loss: 0.003403878305107355
Test Loss:  0.0020841339137405157
Valid Loss:  0.0027761515229940414
Epoch:  43  	Training Loss: 0.0025509526021778584
Test Loss:  0.0016090571880340576
Valid Loss:  0.0018013780936598778
Epoch:  44  	Training Loss: 0.0015942242462188005
Test Loss:  0.0011553318472579122
Valid Loss:  0.0013455767184495926
Epoch:  45  	Training Loss: 0.001067467499524355
Test Loss:  0.0009785230504348874
Valid Loss:  0.0012546671787276864
Epoch:  46  	Training Loss: 0.0009493845864199102
Test Loss:  0.0008952597854658961
Valid Loss:  0.0011803252855315804
Epoch:  47  	Training Loss: 0.0008990245405584574
Test Loss:  0.000831682002171874
Valid Loss:  0.001120084198191762
Epoch:  48  	Training Loss: 0.0008614193648099899
Test Loss:  0.0007831956027075648
Valid Loss:  0.0010697678662836552
Epoch:  49  	Training Loss: 0.0008334117592312396
Test Loss:  0.0007450106786563993
Valid Loss:  0.0010300728026777506
Epoch:  50  	Training Loss: 0.0008119651465676725
Test Loss:  0.0007124536787159741
Valid Loss:  0.0009990567341446877
Epoch:  51  	Training Loss: 0.0007952500600367785
Test Loss:  0.0006881589652039111
Valid Loss:  0.0009727537981234491
Epoch:  52  	Training Loss: 0.0007825951906852424
Test Loss:  0.0008733554277569056
Valid Loss:  0.0009557430166751146
Epoch:  53  	Training Loss: 0.0011285481741651893
Test Loss:  0.0037760285194963217
Valid Loss:  0.004341800697147846
Epoch:  54  	Training Loss: 0.0036005107685923576
Test Loss:  0.0058977073058485985
Valid Loss:  0.005516716744750738
Epoch:  55  	Training Loss: 0.0069403513334691525
Test Loss:  0.008791480213403702
Valid Loss:  0.009587086737155914
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.009447645395994186
Test Loss:  0.0009491072269156575
Valid Loss:  0.0010844317730516195
Epoch:  57  	Training Loss: 0.0008750077686272562
Test Loss:  0.000787210650742054
Valid Loss:  0.0009421419817954302
Epoch:  58  	Training Loss: 0.0007373521802946925
Test Loss:  0.0006737712537869811
Valid Loss:  0.0008263200870715082
Epoch:  59  	Training Loss: 0.0006474613328464329
Test Loss:  0.0005957039538770914
Valid Loss:  0.0007378908921964467
Epoch:  60  	Training Loss: 0.0005845205159857869
Test Loss:  0.0005379634676501155
Valid Loss:  0.0006732983747497201
Epoch:  61  	Training Loss: 0.0005404940457083285
Test Loss:  0.0004972878377884626
Valid Loss:  0.0006272594328038394
Epoch:  62  	Training Loss: 0.0005127879558131099
Test Loss:  0.0004573908809106797
Valid Loss:  0.0005691228434443474
Epoch:  63  	Training Loss: 0.0004895498277619481
Test Loss:  0.00043184898095205426
Valid Loss:  0.0005607976345345378
Epoch:  64  	Training Loss: 0.0004746603954117745
Test Loss:  0.00041064858669415116
Valid Loss:  0.000537283718585968
Epoch:  65  	Training Loss: 0.00046257683425210416
Test Loss:  0.00039316125912591815
Valid Loss:  0.0005299697513692081
Epoch:  66  	Training Loss: 0.0004508543061092496
Test Loss:  0.0003752281190827489
Valid Loss:  0.0005144808674231172
Epoch:  67  	Training Loss: 0.0004386059008538723
Test Loss:  0.00035946513526141644
Valid Loss:  0.0005060101393610239
Epoch:  68  	Training Loss: 0.00042793582542799413
Test Loss:  0.0003463418979663402
Valid Loss:  0.0004963753744959831
Epoch:  69  	Training Loss: 0.0004179114184807986
Test Loss:  0.00033302907831966877
Valid Loss:  0.0004903714871034026
Epoch:  70  	Training Loss: 0.0004075623000971973
Test Loss:  0.0003214168827980757
Valid Loss:  0.0004802643961738795
Epoch:  71  	Training Loss: 0.0003987295494880527
Test Loss:  0.00031257508089765906
 14%|█▍        | 71/500 [01:00<08:56,  1.25s/it] 15%|█▍        | 73/500 [01:00<06:22,  1.11it/s] 15%|█▌        | 75/500 [01:00<04:35,  1.55it/s] 15%|█▌        | 77/500 [01:00<03:20,  2.11it/s] 16%|█▌        | 79/500 [01:00<02:27,  2.85it/s] 16%|█▌        | 81/500 [01:07<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:07<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:07<04:17,  1.61it/s] 17%|█▋        | 87/500 [01:07<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:07<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:13<08:00,  1.17s/it] 19%|█▊        | 93/500 [01:14<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:14<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:14<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:14<02:12,  3.02it/s] 20%|██        | 101/500 [01:20<07:47,  1.17s/it] 21%|██        | 103/500 [01:20<05:33,  1.19it/s] 21%|██        | 105/500 [01:21<04:00,  1.65it/s] 21%|██▏       | 107/500 [01:21<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:21<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:27<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:27<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:27<03:58,  1.61it/s] 23%|██▎       | 117/500 [01:28<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:28<02:11,  2.90it/s] 24%|██▍       | 121/500 [01:34<07:32,  1.19s/it] 25%|██▍       | 123/500 [01:34<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:34<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:35<02:52,  2.16it/s] 26%|██▌       | 129/500 [01:35<02:10,  2.85it/s] 26%|██▌       | 131/500 [01:41<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:41<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:41<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:42<02:49,  2.15it/s]Valid Loss:  0.00047405800432898104
Epoch:  72  	Training Loss: 0.00039108513738028705
Test Loss:  0.00031060981564223766
Valid Loss:  0.0004708570777438581
Epoch:  73  	Training Loss: 0.0003890774678438902
Test Loss:  0.0003087259246967733
Valid Loss:  0.0004677698016166687
Epoch:  74  	Training Loss: 0.0003871300723403692
Test Loss:  0.00030690242419950664
Valid Loss:  0.0004648164613172412
Epoch:  75  	Training Loss: 0.00038522406248375773
Test Loss:  0.0003051362873520702
Valid Loss:  0.0004619358805939555
Epoch:  76  	Training Loss: 0.0003833575756289065
Test Loss:  0.00030342445825226605
Valid Loss:  0.00045912404311820865
Epoch:  77  	Training Loss: 0.0003815364616457373
Test Loss:  0.0003017808776348829
Valid Loss:  0.00045640597818419337
Epoch:  78  	Training Loss: 0.0003797753597609699
Test Loss:  0.0003001858713105321
Valid Loss:  0.00045374856563284993
Epoch:  79  	Training Loss: 0.000378049211576581
Test Loss:  0.00029863667441532016
Valid Loss:  0.0004511504084803164
Epoch:  80  	Training Loss: 0.0003763558343052864
Test Loss:  0.0002971491194330156
Valid Loss:  0.0004486373218242079
Epoch:  81  	Training Loss: 0.00037473614793270826
Test Loss:  0.0002957199758384377
Valid Loss:  0.00044620607513934374
Epoch:  82  	Training Loss: 0.00037316797534003854
Test Loss:  0.00029898519278503954
Valid Loss:  0.00044897006591781974
Epoch:  83  	Training Loss: 0.00037177035119384527
Test Loss:  0.0003010404179804027
Valid Loss:  0.0004507719713728875
Epoch:  84  	Training Loss: 0.00037136994069442153
Test Loss:  0.0003022194723598659
Valid Loss:  0.0004518176428973675
Epoch:  85  	Training Loss: 0.0003712486941367388
Test Loss:  0.0003028687206096947
Valid Loss:  0.00045239226892590523
Epoch:  86  	Training Loss: 0.00037120559136383235
Test Loss:  0.00030321942176669836
Valid Loss:  0.0004526990815065801
Epoch:  87  	Training Loss: 0.0003711844328790903
Test Loss:  0.00030340763623826206
Valid Loss:  0.00045285894884727895
Epoch:  88  	Training Loss: 0.00037116953171789646
Test Loss:  0.00030350766610354185
Valid Loss:  0.0004529394500423223
Epoch:  89  	Training Loss: 0.0003711568424478173
Test Loss:  0.00030356095521710813
Valid Loss:  0.0004529783327598125
Epoch:  90  	Training Loss: 0.0003711455501616001
Test Loss:  0.00030358979711309075
Valid Loss:  0.00045299495104700327
Epoch:  91  	Training Loss: 0.00037113495636731386
Test Loss:  0.00030360519303940237
Valid Loss:  0.0004529997822828591
Epoch:  92  	Training Loss: 0.00037112418795004487
Test Loss:  0.0003012106753885746
Valid Loss:  0.00044927565613761544
Epoch:  93  	Training Loss: 0.0003692748723551631
Test Loss:  0.0002992675290443003
Valid Loss:  0.00044606183655560017
Epoch:  94  	Training Loss: 0.00036756577901542187
Test Loss:  0.00029760217876173556
Valid Loss:  0.00044317281572148204
Epoch:  95  	Training Loss: 0.00036593718687072396
Test Loss:  0.00029609250486828387
Valid Loss:  0.00044046982657164335
Epoch:  96  	Training Loss: 0.0003643714589998126
Test Loss:  0.00029473419999703765
Valid Loss:  0.00043797065154649317
Epoch:  97  	Training Loss: 0.0003629040438681841
Test Loss:  0.0002934377989731729
Valid Loss:  0.0004355568962637335
Epoch:  98  	Training Loss: 0.00036147769424133003
Test Loss:  0.0002922120038419962
Valid Loss:  0.0004332483222242445
Epoch:  99  	Training Loss: 0.0003601151693146676
Test Loss:  0.0002910183684434742
Valid Loss:  0.00043099914910271764
Epoch:  100  	Training Loss: 0.00035878291237168014
Test Loss:  0.00028985398239456117
Valid Loss:  0.00042886973824352026
Epoch:  101  	Training Loss: 0.0003574796428438276
Test Loss:  0.00028874771669507027
Valid Loss:  0.0004267844487912953
Epoch:  102  	Training Loss: 0.00035620416747406125
Test Loss:  0.00028809020295739174
Valid Loss:  0.0004244967130944133
Epoch:  103  	Training Loss: 0.00035549342283047736
Test Loss:  0.0002880278043448925
Valid Loss:  0.00042323910747654736
Epoch:  104  	Training Loss: 0.0003549281682353467
Test Loss:  0.0002880723332054913
Valid Loss:  0.0004222713760100305
Epoch:  105  	Training Loss: 0.0003544227220118046
Test Loss:  0.00028812672826461494
Valid Loss:  0.0004214232321828604
Epoch:  106  	Training Loss: 0.000353964016539976
Test Loss:  0.0002881659602280706
Valid Loss:  0.00042064095032401383
Epoch:  107  	Training Loss: 0.0003535424475558102
Test Loss:  0.0002881838008761406
Valid Loss:  0.00041990773752331734
Epoch:  108  	Training Loss: 0.00035315094282850623
Test Loss:  0.0002881777472794056
Valid Loss:  0.00041921227239072323
Epoch:  109  	Training Loss: 0.00035278467112220824
Test Loss:  0.0002881503023672849
Valid Loss:  0.0004185485013294965
Epoch:  110  	Training Loss: 0.00035243824822828174
Test Loss:  0.00028810076764784753
Valid Loss:  0.00041791220428422093
Epoch:  111  	Training Loss: 0.00035210861824452877
Test Loss:  0.000288031151285395
Valid Loss:  0.00041730000521056354
Epoch:  112  	Training Loss: 0.0003517928416840732
Test Loss:  0.0002769702114164829
Valid Loss:  0.0004119969380553812
Epoch:  113  	Training Loss: 0.0003439543943386525
Test Loss:  0.00026902375975623727
Valid Loss:  0.00040462729521095753
Epoch:  114  	Training Loss: 0.0003385244053788483
Test Loss:  0.00026230470393784344
Valid Loss:  0.00039907475002110004
Epoch:  115  	Training Loss: 0.000333155388943851
Test Loss:  0.000257852632785216
Valid Loss:  0.00039350264705717564
Epoch:  116  	Training Loss: 0.0003292947367299348
Test Loss:  0.00025448601809330285
Valid Loss:  0.0003895325935445726
Epoch:  117  	Training Loss: 0.00032532497425563633
Test Loss:  0.00025143937091343105
Valid Loss:  0.00038629031041637063
Epoch:  118  	Training Loss: 0.000321082363370806
Test Loss:  0.0002490113256499171
Valid Loss:  0.0003828871122095734
Epoch:  119  	Training Loss: 0.0003169341944158077
Test Loss:  0.00024590195971541107
Valid Loss:  0.00037923664785921574
Epoch:  120  	Training Loss: 0.0003129163524135947
Test Loss:  0.00024360939278267324
Valid Loss:  0.00037509913090616465
Epoch:  121  	Training Loss: 0.0003093401319347322
Test Loss:  0.00024206659873016179
Valid Loss:  0.00037147977855056524
Epoch:  122  	Training Loss: 0.0003060739254578948
Test Loss:  0.00024063725140877068
Valid Loss:  0.0003682933747768402
Epoch:  123  	Training Loss: 0.0003044789773412049
Test Loss:  0.00023923964181449264
Valid Loss:  0.0003684797848109156
Epoch:  124  	Training Loss: 0.0003032572567462921
Test Loss:  0.000238491571508348
Valid Loss:  0.0003676398773677647
Epoch:  125  	Training Loss: 0.00030219333712011576
Test Loss:  0.00023769805557094514
Valid Loss:  0.00036774715408682823
Epoch:  126  	Training Loss: 0.00030097138369455934
Test Loss:  0.00023729448730591685
Valid Loss:  0.0003673486062325537
Epoch:  127  	Training Loss: 0.0002998644486069679
Test Loss:  0.00023717187286820263
Valid Loss:  0.0003665235126391053
Epoch:  128  	Training Loss: 0.00029903982067480683
Test Loss:  0.00023713480914011598
Valid Loss:  0.0003659171052277088
Epoch:  129  	Training Loss: 0.0002983640879392624
Test Loss:  0.00023716280702501535
Valid Loss:  0.00036538077984005213
Epoch:  130  	Training Loss: 0.00029776684823445976
Test Loss:  0.0002371960144955665
Valid Loss:  0.0003649293212220073
Epoch:  131  	Training Loss: 0.000297214079182595
Test Loss:  0.00023723195772618055
Valid Loss:  0.00036453004577197134
Epoch:  132  	Training Loss: 0.0002967114851344377
Test Loss:  0.00023687531938776374
Valid Loss:  0.00036415382055565715
Epoch:  133  	Training Loss: 0.0002961474237963557
Test Loss:  0.00023667645291425288
Valid Loss:  0.00036327922134660184
Epoch:  134  	Training Loss: 0.00029543580603785813
Test Loss:  0.00023613491794094443
Valid Loss:  0.00036266501410864294
Epoch:  135  	Training Loss: 0.00029466088744811714
Test Loss:  0.00023588305339217186
Valid Loss:  0.0003616661997511983
Epoch:  136  	Training Loss: 0.0002937967365141958
Test Loss:  0.00023514858912676573
Valid Loss:  0.0003610551939345896
Epoch:  137  	Training Loss: 0.00029285327764227986
Test Loss:  0.00023465347476303577
Valid Loss:  0.00036004369030706584
Epoch:  138  	Training Loss: 0.00029184488812461495
Test Loss:  0.00023398830671794713
Valid Loss:  0.00035921993548981845
 28%|██▊       | 139/500 [01:42<02:06,  2.84it/s] 28%|██▊       | 141/500 [01:48<07:13,  1.21s/it] 29%|██▊       | 143/500 [01:48<05:09,  1.15it/s] 29%|██▉       | 145/500 [01:48<03:42,  1.60it/s] 29%|██▉       | 147/500 [01:49<02:41,  2.18it/s] 30%|██▉       | 149/500 [01:49<02:00,  2.90it/s] 30%|███       | 151/500 [01:55<06:59,  1.20s/it] 31%|███       | 153/500 [01:55<04:58,  1.16it/s] 31%|███       | 155/500 [01:55<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:56<02:36,  2.20it/s] 32%|███▏      | 159/500 [01:56<01:55,  2.96it/s] 32%|███▏      | 161/500 [02:02<06:38,  1.17s/it] 33%|███▎      | 163/500 [02:02<04:44,  1.19it/s] 33%|███▎      | 165/500 [02:02<03:24,  1.64it/s] 33%|███▎      | 167/500 [02:02<02:28,  2.24it/s] 34%|███▍      | 169/500 [02:02<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:09<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:09<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:09<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:09<02:27,  2.18it/s] 36%|███▌      | 179/500 [02:09<01:51,  2.89it/s] 36%|███▌      | 181/500 [02:16<06:21,  1.19s/it] 37%|███▋      | 183/500 [02:16<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:16<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:16<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:16<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:23<06:08,  1.19s/it] 39%|███▊      | 193/500 [02:23<04:23,  1.16it/s] 39%|███▉      | 195/500 [02:29<07:51,  1.54s/it] 39%|███▉      | 197/500 [02:29<05:33,  1.10s/it] 40%|███▉      | 199/500 [02:29<03:58,  1.26it/s] 40%|████      | 201/500 [02:36<07:29,  1.50s/it] 41%|████      | 203/500 [02:36<05:20,  1.08s/it]Epoch:  139  	Training Loss: 0.0002908550959546119
Test Loss:  0.00023329557734541595
Valid Loss:  0.00035844542435370386
Epoch:  140  	Training Loss: 0.0002898721140809357
Test Loss:  0.00023262295871973038
Valid Loss:  0.0003577579918783158
Epoch:  141  	Training Loss: 0.0002889563038479537
Test Loss:  0.00023198302369564772
Valid Loss:  0.0003571923007257283
Epoch:  142  	Training Loss: 0.0002881280379369855
Test Loss:  0.0002312825818080455
Valid Loss:  0.0003560454351827502
Epoch:  143  	Training Loss: 0.0002864281996153295
Test Loss:  0.00023085696739144623
Valid Loss:  0.00035501853562891483
Epoch:  144  	Training Loss: 0.00028492434648796916
Test Loss:  0.00023065741697791964
Valid Loss:  0.00035418785410001874
Epoch:  145  	Training Loss: 0.0002837608917616308
Test Loss:  0.00023054426128510386
Valid Loss:  0.00035357498563826084
Epoch:  146  	Training Loss: 0.00028281594859436154
Test Loss:  0.00023047218564897776
Valid Loss:  0.0003531085094437003
Epoch:  147  	Training Loss: 0.0002820888184942305
Test Loss:  0.0002304260851815343
Valid Loss:  0.0003527799271978438
Epoch:  148  	Training Loss: 0.00028150901198387146
Test Loss:  0.0002304018707945943
Valid Loss:  0.0003525380452629179
Epoch:  149  	Training Loss: 0.00028101279167458415
Test Loss:  0.00023039568623062223
Valid Loss:  0.00035235227551311255
Epoch:  150  	Training Loss: 0.00028057105373591185
Test Loss:  0.0002304034132976085
Valid Loss:  0.0003521943581290543
Epoch:  151  	Training Loss: 0.0002801748050842434
Test Loss:  0.0002304204535903409
Valid Loss:  0.0003520818427205086
Epoch:  152  	Training Loss: 0.0002798174100462347
Test Loss:  0.00022954391897656024
Valid Loss:  0.00035109397140331566
Epoch:  153  	Training Loss: 0.00027770642191171646
Test Loss:  0.00022917904425412416
Valid Loss:  0.0003494177362881601
Epoch:  154  	Training Loss: 0.00027594270068220794
Test Loss:  0.00022891044500283897
Valid Loss:  0.00034792895894497633
Epoch:  155  	Training Loss: 0.0002742549986578524
Test Loss:  0.0002287223469465971
Valid Loss:  0.00034653209149837494
Epoch:  156  	Training Loss: 0.0002726237289607525
Test Loss:  0.0002285944065079093
Valid Loss:  0.00034518985194154084
Epoch:  157  	Training Loss: 0.0002710414701141417
Test Loss:  0.000228511358727701
Valid Loss:  0.0003439040738157928
Epoch:  158  	Training Loss: 0.0002695029543247074
Test Loss:  0.00022846669889986515
Valid Loss:  0.00034266707370989025
Epoch:  159  	Training Loss: 0.0002680061443243176
Test Loss:  0.00022845371859148145
Valid Loss:  0.0003414755337871611
Epoch:  160  	Training Loss: 0.0002665476640686393
Test Loss:  0.00022846678621135652
Valid Loss:  0.00034032465191558003
Epoch:  161  	Training Loss: 0.00026512498152442276
Test Loss:  0.00022848547087050974
Valid Loss:  0.0003392153012100607
Epoch:  162  	Training Loss: 0.00026373774744570255
Test Loss:  0.0002273103455081582
Valid Loss:  0.0003383360162843019
Epoch:  163  	Training Loss: 0.0002624483313411474
Test Loss:  0.00022621298558078706
Valid Loss:  0.00033726415131241083
Epoch:  164  	Training Loss: 0.0002612294629216194
Test Loss:  0.0002251777332276106
Valid Loss:  0.0003360621049068868
Epoch:  165  	Training Loss: 0.00026008134591393173
Test Loss:  0.00022419991728384048
Valid Loss:  0.0003349145990796387
Epoch:  166  	Training Loss: 0.00025899976026266813
Test Loss:  0.00022327699116431177
Valid Loss:  0.00033381927642039955
Epoch:  167  	Training Loss: 0.0002579761785455048
Test Loss:  0.0002224042546004057
Valid Loss:  0.0003327743033878505
Epoch:  168  	Training Loss: 0.000257008767221123
Test Loss:  0.00022158073261380196
Valid Loss:  0.00033177610021084547
Epoch:  169  	Training Loss: 0.0002560956636443734
Test Loss:  0.0002208029036410153
Valid Loss:  0.0003308221057523042
Epoch:  170  	Training Loss: 0.0002552319783717394
Test Loss:  0.00022006870131008327
Valid Loss:  0.0003299107775092125
Epoch:  171  	Training Loss: 0.00025441867182962596
Test Loss:  0.00021937466226518154
Valid Loss:  0.0003290403401479125
Epoch:  172  	Training Loss: 0.00025364835164509714
Test Loss:  0.0002199384180130437
Valid Loss:  0.00032842770451679826
Epoch:  173  	Training Loss: 0.0002526457537896931
Test Loss:  0.00022027271916158497
Valid Loss:  0.0003279005759395659
Epoch:  174  	Training Loss: 0.0002520681591704488
Test Loss:  0.0002204203774454072
Valid Loss:  0.0003273951297160238
Epoch:  175  	Training Loss: 0.0002516041568014771
Test Loss:  0.00022046550293453038
Valid Loss:  0.0003268422733526677
Epoch:  176  	Training Loss: 0.00025117461336776614
Test Loss:  0.0002204435004387051
Valid Loss:  0.00032626508618704975
Epoch:  177  	Training Loss: 0.0002507591852918267
Test Loss:  0.00022038858151063323
Valid Loss:  0.0003256780910305679
Epoch:  178  	Training Loss: 0.0002503528376109898
Test Loss:  0.00022033248387742788
Valid Loss:  0.0003250924637541175
Epoch:  179  	Training Loss: 0.00024995405692607164
Test Loss:  0.000220306174014695
Valid Loss:  0.0003245106490794569
Epoch:  180  	Training Loss: 0.0002495627268217504
Test Loss:  0.00022027874365448952
Valid Loss:  0.0003239353827666491
Epoch:  181  	Training Loss: 0.0002491784980520606
Test Loss:  0.0002202527248300612
Valid Loss:  0.00032336916774511337
Epoch:  182  	Training Loss: 0.0002488010795786977
Test Loss:  0.00021070934599265456
Valid Loss:  0.0003094671992585063
Epoch:  183  	Training Loss: 0.0002323604712728411
Test Loss:  0.00020228518405929208
Valid Loss:  0.00030198105378076434
Epoch:  184  	Training Loss: 0.0002239682653453201
Test Loss:  0.00019679643446579576
Valid Loss:  0.00029590268968604505
Epoch:  185  	Training Loss: 0.00021702359663322568
Test Loss:  0.00019182088726665825
Valid Loss:  0.00029080541571602225
Epoch:  186  	Training Loss: 0.00021157978335395455
Test Loss:  0.00018741362146101892
Valid Loss:  0.00028686810401268303
Epoch:  187  	Training Loss: 0.0002075053344015032
Test Loss:  0.00018441936117596924
Valid Loss:  0.00028400224982760847
Epoch:  188  	Training Loss: 0.00020491084433160722
Test Loss:  0.00018158549210056663
Valid Loss:  0.00028250718605704606
Epoch:  189  	Training Loss: 0.00020338462491054088
Test Loss:  0.00017965375445783138
Valid Loss:  0.0002808428253047168
Epoch:  190  	Training Loss: 0.00020216236589476466
Test Loss:  0.00017746913363225758
Valid Loss:  0.0002800333022605628
Epoch:  191  	Training Loss: 0.00020124443108215928
Test Loss:  0.00017621557344682515
Valid Loss:  0.00027893693186342716
Epoch:  192  	Training Loss: 0.00020041040261276066
Test Loss:  0.00017907671281136572
Valid Loss:  0.0002747596590779722
Epoch:  193  	Training Loss: 0.0001996636128751561
Test Loss:  0.0001771118404576555
Valid Loss:  0.0002798123168759048
Epoch:  194  	Training Loss: 0.00020070586469955742
Test Loss:  0.000186108925845474
Valid Loss:  0.0002768192789517343
Epoch:  195  	Training Loss: 0.0002038236998487264
Test Loss:  0.00018220972560811788
Valid Loss:  0.0002865022688638419
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.00020756039884872735
Test Loss:  0.00018109999655280262
Valid Loss:  0.0002858371299225837
Epoch:  197  	Training Loss: 0.0002071360795525834
Test Loss:  0.0001803375344024971
Valid Loss:  0.00028541265055537224
Epoch:  198  	Training Loss: 0.00020689409575425088
Test Loss:  0.00017980425036512315
Valid Loss:  0.0002851380268111825
Epoch:  199  	Training Loss: 0.0002067561581498012
Test Loss:  0.0001794257841538638
Valid Loss:  0.00028495595324784517
Epoch:  200  	Training Loss: 0.00020667712669819593
Test Loss:  0.00017915424541570246
Valid Loss:  0.00028483266942203045
Epoch:  201  	Training Loss: 0.0002066317101707682
Test Loss:  0.00017895668861456215
Valid Loss:  0.0002847478026524186
Epoch:  202  	Training Loss: 0.00020660538575612009
Test Loss:  0.00017684779595583677
Valid Loss:  0.00027913539088331163
Epoch:  203  	Training Loss: 0.00020144780864939094
Test Loss:  0.00017701121396385133
Valid Loss:  0.00027761890669353306
Epoch:  204  	Training Loss: 0.00020026430138386786
Test Loss:  0.00017733313143253326
Valid Loss:  0.0002768736449070275
Epoch:  205  	Training Loss: 0.00019961115322075784
 41%|████      | 205/500 [02:36<03:50,  1.28it/s] 41%|████▏     | 207/500 [02:36<02:45,  1.77it/s] 42%|████▏     | 209/500 [02:36<02:01,  2.39it/s] 42%|████▏     | 211/500 [02:43<06:01,  1.25s/it] 43%|████▎     | 213/500 [02:43<04:17,  1.12it/s] 43%|████▎     | 215/500 [02:43<03:04,  1.55it/s] 43%|████▎     | 217/500 [02:43<02:13,  2.12it/s] 44%|████▍     | 219/500 [02:43<01:38,  2.86it/s] 44%|████▍     | 221/500 [02:49<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:50<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:50<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:50<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:50<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:56<05:21,  1.19s/it] 47%|████▋     | 233/500 [02:57<03:48,  1.17it/s] 47%|████▋     | 235/500 [02:57<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:57<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:57<01:27,  2.98it/s] 48%|████▊     | 241/500 [03:03<05:06,  1.18s/it] 49%|████▊     | 243/500 [03:03<03:38,  1.18it/s] 49%|████▉     | 245/500 [03:04<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:04<01:53,  2.23it/s] 50%|████▉     | 249/500 [03:04<01:23,  3.00it/s] 50%|█████     | 251/500 [03:10<04:54,  1.18s/it] 51%|█████     | 253/500 [03:10<03:29,  1.18it/s] 51%|█████     | 255/500 [03:10<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:11<01:49,  2.23it/s] 52%|█████▏    | 259/500 [03:11<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:17<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:17<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:17<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:17<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:17<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:24<04:30,  1.18s/it]Test Loss:  0.00017761343042366207
Valid Loss:  0.00027628574753180146
Epoch:  206  	Training Loss: 0.00019904880900867283
Test Loss:  0.00017785304225981236
Valid Loss:  0.0002757855982054025
Epoch:  207  	Training Loss: 0.0001985474518733099
Test Loss:  0.0001780827878974378
Valid Loss:  0.00027533291722647846
Epoch:  208  	Training Loss: 0.00019809292280115187
Test Loss:  0.0001783123007044196
Valid Loss:  0.0002749118721112609
Epoch:  209  	Training Loss: 0.00019767196499742568
Test Loss:  0.00017853743338491768
Valid Loss:  0.0002745254896581173
Epoch:  210  	Training Loss: 0.0001972882600966841
Test Loss:  0.00017876455967780203
Valid Loss:  0.0002741625066846609
Epoch:  211  	Training Loss: 0.0001969300938071683
Test Loss:  0.00017899209342431277
Valid Loss:  0.00027382108964957297
Epoch:  212  	Training Loss: 0.00019659489043988287
Test Loss:  0.0001789923699107021
Valid Loss:  0.0002738206530921161
Epoch:  213  	Training Loss: 0.00019659458484966308
Test Loss:  0.0001789923699107021
Valid Loss:  0.00027382010011933744
Epoch:  214  	Training Loss: 0.00019659430836327374
Test Loss:  0.00017899232625495642
Valid Loss:  0.00027381989639252424
Epoch:  215  	Training Loss: 0.0001965938718058169
Test Loss:  0.0001789923699107021
Valid Loss:  0.00027381995460018516
Epoch:  216  	Training Loss: 0.0001965936680790037
Test Loss:  0.00017899239901453257
Valid Loss:  0.00027381980908103287
Epoch:  217  	Training Loss: 0.00019659340614452958
Test Loss:  0.0001789926755009219
Valid Loss:  0.0002738195180427283
Epoch:  218  	Training Loss: 0.00019659296958707273
Test Loss:  0.0001789927191566676
Valid Loss:  0.0002738193143159151
Epoch:  219  	Training Loss: 0.0001965926494449377
Test Loss:  0.00017899274826049805
Valid Loss:  0.0002738189650699496
Epoch:  220  	Training Loss: 0.00019659230019897223
Test Loss:  0.0001789928210200742
Valid Loss:  0.00027381881955079734
Epoch:  221  	Training Loss: 0.00019659196550492197
Test Loss:  0.00017899290833156556
Valid Loss:  0.0002738184994086623
Epoch:  222  	Training Loss: 0.00019659168901853263
Test Loss:  0.0001793950650608167
Valid Loss:  0.00027345234411768615
Epoch:  223  	Training Loss: 0.0001962879323400557
Test Loss:  0.00017967980238609016
Valid Loss:  0.0002732902066782117
Epoch:  224  	Training Loss: 0.00019615242490544915
Test Loss:  0.00017986228340305388
Valid Loss:  0.0002731913118623197
Epoch:  225  	Training Loss: 0.00019606234855018556
Test Loss:  0.000179980430402793
Valid Loss:  0.0002731157001107931
Epoch:  226  	Training Loss: 0.00019598528160713613
Test Loss:  0.00018006311438512057
Valid Loss:  0.0002730479754973203
Epoch:  227  	Training Loss: 0.00019591249292716384
Test Loss:  0.0001801252074074
Valid Loss:  0.0002729854895733297
Epoch:  228  	Training Loss: 0.00019584156689234078
Test Loss:  0.00018017811817117035
Valid Loss:  0.00027292518643662333
Epoch:  229  	Training Loss: 0.00019577209604904056
Test Loss:  0.00018022488802671432
Valid Loss:  0.00027286706608720124
Epoch:  230  	Training Loss: 0.00019570370204746723
Test Loss:  0.00018026962061412632
Valid Loss:  0.00027280941139906645
Epoch:  231  	Training Loss: 0.00019563641399145126
Test Loss:  0.0001803127524908632
Valid Loss:  0.0002727537357714027
Epoch:  232  	Training Loss: 0.00019557013001758605
Test Loss:  0.00018048033234663308
Valid Loss:  0.0002716167364269495
Epoch:  233  	Training Loss: 0.00019452330889180303
Test Loss:  0.00018030116916634142
Valid Loss:  0.00027119286824017763
Epoch:  234  	Training Loss: 0.0001941988302860409
Test Loss:  0.0001800695899873972
Valid Loss:  0.00027097927522845566
Epoch:  235  	Training Loss: 0.00019402953330427408
Test Loss:  0.00017991961794905365
Valid Loss:  0.0002708269748836756
Epoch:  236  	Training Loss: 0.00019390287343412638
Test Loss:  0.0001798569137463346
Valid Loss:  0.00027065500034950674
Epoch:  237  	Training Loss: 0.00019379344303160906
Test Loss:  0.00017982680583372712
Valid Loss:  0.0002704877406358719
Epoch:  238  	Training Loss: 0.00019369412621017545
Test Loss:  0.00017981343262363225
Valid Loss:  0.00027032545767724514
Epoch:  239  	Training Loss: 0.00019359943689778447
Test Loss:  0.00017981018754653633
Valid Loss:  0.00027016852982342243
Epoch:  240  	Training Loss: 0.0001935093750944361
Test Loss:  0.00017981312703341246
Valid Loss:  0.00027002335991710424
Epoch:  241  	Training Loss: 0.00019342690939083695
Test Loss:  0.0001798221201170236
Valid Loss:  0.0002698823227547109
Epoch:  242  	Training Loss: 0.00019334653916303068
Test Loss:  0.00017719680909067392
Valid Loss:  0.0002688064705580473
Epoch:  243  	Training Loss: 0.00019164502737112343
Test Loss:  0.00017598428530618548
Valid Loss:  0.0002685004146769643
Epoch:  244  	Training Loss: 0.0001910384016809985
Test Loss:  0.00017510296311229467
Valid Loss:  0.0002684157225303352
Epoch:  245  	Training Loss: 0.00019069632980972528
Test Loss:  0.00017461852985434234
Valid Loss:  0.0002684250066522509
Epoch:  246  	Training Loss: 0.00019057535973843187
Test Loss:  0.00017433171160519123
Valid Loss:  0.00026845105458050966
Epoch:  247  	Training Loss: 0.0001905319222714752
Test Loss:  0.00017415251932106912
Valid Loss:  0.0002684716018848121
Epoch:  248  	Training Loss: 0.00019051574054174125
Test Loss:  0.00017403668607585132
Valid Loss:  0.00026848685229197145
Epoch:  249  	Training Loss: 0.00019050968694500625
Test Loss:  0.0001739599829306826
Valid Loss:  0.0002684970968402922
Epoch:  250  	Training Loss: 0.00019050708215218037
Test Loss:  0.00017390894936397672
Valid Loss:  0.0002685030922293663
Epoch:  251  	Training Loss: 0.00019050639821216464
Test Loss:  0.00017387358820997179
Valid Loss:  0.0002685073995962739
Epoch:  252  	Training Loss: 0.0001905058161355555
Test Loss:  0.00017360511992592365
Valid Loss:  0.00026532745687291026
Epoch:  253  	Training Loss: 0.00018823117716237903
Test Loss:  0.00017398199997842312
Valid Loss:  0.0002650480601005256
Epoch:  254  	Training Loss: 0.00018789185560308397
Test Loss:  0.00017431838205084205
Valid Loss:  0.00026487724971957505
Epoch:  255  	Training Loss: 0.0001875749439932406
Test Loss:  0.00017467443831264973
Valid Loss:  0.0002647428773343563
Epoch:  256  	Training Loss: 0.000187277008080855
Test Loss:  0.00017503548588138074
Valid Loss:  0.0002645447966642678
Epoch:  257  	Training Loss: 0.00018700724467635155
Test Loss:  0.00017537176609039307
Valid Loss:  0.00026440818328410387
Epoch:  258  	Training Loss: 0.00018675552564673126
Test Loss:  0.00017571327043697238
Valid Loss:  0.00026422098744660616
Epoch:  259  	Training Loss: 0.00018652845756150782
Test Loss:  0.00017602468142285943
Valid Loss:  0.0002640999446157366
Epoch:  260  	Training Loss: 0.00018631630518939346
Test Loss:  0.00017632590606808662
Valid Loss:  0.00026400969363749027
Epoch:  261  	Training Loss: 0.00018611484847497195
Test Loss:  0.00017662371101323515
Valid Loss:  0.0002639340527821332
Epoch:  262  	Training Loss: 0.0001859306648839265
Test Loss:  0.00017598489648662508
Valid Loss:  0.00026340014301240444
Epoch:  263  	Training Loss: 0.00018530221132095903
Test Loss:  0.0001753619289956987
Valid Loss:  0.000262874411419034
Epoch:  264  	Training Loss: 0.00018468499183654785
Test Loss:  0.0001747540372889489
Valid Loss:  0.00026235729455947876
Epoch:  265  	Training Loss: 0.00018407843890599906
Test Loss:  0.00017415988259017467
Valid Loss:  0.0002618473954498768
Epoch:  266  	Training Loss: 0.00018348198500461876
Test Loss:  0.00017357974138576537
Valid Loss:  0.00026134622748941183
Epoch:  267  	Training Loss: 0.00018289548461325467
Test Loss:  0.00017301252228207886
Valid Loss:  0.0002608519862405956
Epoch:  268  	Training Loss: 0.00018231853027828038
Test Loss:  0.00017245812341570854
Valid Loss:  0.0002603661851026118
Epoch:  269  	Training Loss: 0.0001817516895243898
Test Loss:  0.00017191655933856964
Valid Loss:  0.0002598874852992594
Epoch:  270  	Training Loss: 0.00018119384185411036
Test Loss:  0.00017138634575530887
Valid Loss:  0.0002594159450381994
Epoch:  271  	Training Loss: 0.00018064500181935728
Test Loss:  0.00017086765728890896
Valid Loss:  0.00025895226281136274
Epoch:  272  	Training Loss: 0.0001801063190214336
Test Loss:   55%|█████▍    | 273/500 [03:24<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:24<02:19,  1.62it/s] 55%|█████▌    | 277/500 [03:24<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:24<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:31<04:14,  1.16s/it] 57%|█████▋    | 283/500 [03:31<03:01,  1.20it/s] 57%|█████▋    | 285/500 [03:31<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:31<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:31<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:37<04:02,  1.16s/it] 59%|█████▊    | 293/500 [03:37<02:52,  1.20it/s] 59%|█████▉    | 295/500 [03:38<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:38<01:29,  2.26it/s] 60%|█████▉    | 299/500 [03:38<01:06,  3.03it/s] 60%|██████    | 301/500 [03:44<03:52,  1.17s/it] 61%|██████    | 303/500 [03:44<02:45,  1.19it/s] 61%|██████    | 305/500 [03:44<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:44<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:45<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:51<03:39,  1.16s/it] 63%|██████▎   | 313/500 [03:51<02:36,  1.20it/s] 63%|██████▎   | 315/500 [03:51<01:51,  1.66it/s] 63%|██████▎   | 317/500 [03:51<01:20,  2.26it/s] 64%|██████▍   | 319/500 [03:51<00:59,  3.03it/s] 64%|██████▍   | 321/500 [03:58<03:28,  1.17s/it] 65%|██████▍   | 323/500 [03:58<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:58<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:58<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:58<00:57,  2.96it/s] 66%|██████▌   | 331/500 [04:05<03:20,  1.19s/it] 67%|██████▋   | 333/500 [04:05<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:05<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:05<01:13,  2.21it/s]0.0001703066227491945
Valid Loss:  0.00025861142785288393
Epoch:  273  	Training Loss: 0.0001796419091988355
Test Loss:  0.0001697607949608937
Valid Loss:  0.00025827769422903657
Epoch:  274  	Training Loss: 0.00017918815137818456
Test Loss:  0.0001692284713499248
Valid Loss:  0.0002579514984972775
Epoch:  275  	Training Loss: 0.00017874478362500668
Test Loss:  0.0001687100884737447
Valid Loss:  0.0002576317638158798
Epoch:  276  	Training Loss: 0.00017831112199928612
Test Loss:  0.00016820468590594828
Valid Loss:  0.00025731875211931765
Epoch:  277  	Training Loss: 0.00017788709374144673
Test Loss:  0.00016771203081589192
Valid Loss:  0.0002570128417573869
Epoch:  278  	Training Loss: 0.00017747178208082914
Test Loss:  0.00016723168664611876
Valid Loss:  0.00025671295588836074
Epoch:  279  	Training Loss: 0.00017706546350382268
Test Loss:  0.0001667626784183085
Valid Loss:  0.0002564192982390523
Epoch:  280  	Training Loss: 0.00017666758503764868
Test Loss:  0.00016630496247671545
Valid Loss:  0.0002561308501753956
Epoch:  281  	Training Loss: 0.000176277884747833
Test Loss:  0.00016585763660259545
Valid Loss:  0.0002558490086812526
Epoch:  282  	Training Loss: 0.00017589627532288432
Test Loss:  0.00016614212654531002
Valid Loss:  0.00025573305902071297
Epoch:  283  	Training Loss: 0.00017566789756529033
Test Loss:  0.00016634006169624627
Valid Loss:  0.00025569973513484
Epoch:  284  	Training Loss: 0.0001755410194164142
Test Loss:  0.00016646223957650363
Valid Loss:  0.0002556884428486228
Epoch:  285  	Training Loss: 0.0001754514960339293
Test Loss:  0.000166536497999914
Valid Loss:  0.0002556833205744624
Epoch:  286  	Training Loss: 0.00017539263353683054
Test Loss:  0.00016658120148349553
Valid Loss:  0.00025567918783053756
Epoch:  287  	Training Loss: 0.00017534504877403378
Test Loss:  0.00016660425171721727
Valid Loss:  0.00025567447301000357
Epoch:  288  	Training Loss: 0.0001752992975525558
Test Loss:  0.0001666151511017233
Valid Loss:  0.00025566850672475994
Epoch:  289  	Training Loss: 0.00017525529256090522
Test Loss:  0.000166618381626904
Valid Loss:  0.0002556621329858899
Epoch:  290  	Training Loss: 0.00017521182599011809
Test Loss:  0.00016661747940815985
Valid Loss:  0.00025565590476617217
Epoch:  291  	Training Loss: 0.00017516905791126192
Test Loss:  0.00016661500558257103
Valid Loss:  0.00025564880343154073
Epoch:  292  	Training Loss: 0.00017512717749923468
Test Loss:  0.00016666056762915105
Valid Loss:  0.00025532906875014305
Epoch:  293  	Training Loss: 0.00017495165229775012
Test Loss:  0.00016671500634402037
Valid Loss:  0.0002551354409661144
Epoch:  294  	Training Loss: 0.00017486521392129362
Test Loss:  0.0001667515462031588
Valid Loss:  0.00025509565602988005
Epoch:  295  	Training Loss: 0.00017480419774074107
Test Loss:  0.0001667942851781845
Valid Loss:  0.000255048944381997
Epoch:  296  	Training Loss: 0.0001747483911458403
Test Loss:  0.00016684457659721375
Valid Loss:  0.0002549508644733578
Epoch:  297  	Training Loss: 0.00017469664453528821
Test Loss:  0.00016688751929905266
Valid Loss:  0.0002549198688939214
Epoch:  298  	Training Loss: 0.00017464473785366863
Test Loss:  0.00016693651559762657
Valid Loss:  0.000254881102591753
Epoch:  299  	Training Loss: 0.00017459789523854852
Test Loss:  0.00016699223488103598
Valid Loss:  0.00025479120085947216
Epoch:  300  	Training Loss: 0.00017455338092986494
Test Loss:  0.00016703983419574797
Valid Loss:  0.00025476719019934535
Epoch:  301  	Training Loss: 0.00017450860468670726
Test Loss:  0.00016709696501493454
Valid Loss:  0.00025468901731073856
Epoch:  302  	Training Loss: 0.0001744702021824196
Test Loss:  0.00016455346485599875
Valid Loss:  0.00025366828776896
Epoch:  303  	Training Loss: 0.00017298245802521706
Test Loss:  0.00016314828826580197
Valid Loss:  0.00025314948288723826
Epoch:  304  	Training Loss: 0.00017219284200109541
Test Loss:  0.00016206930740736425
Valid Loss:  0.00025278067914769053
Epoch:  305  	Training Loss: 0.0001715704274829477
Test Loss:  0.00016139094077516347
Valid Loss:  0.00025250285398215055
Epoch:  306  	Training Loss: 0.0001711544900899753
Test Loss:  0.00016091839643195271
Valid Loss:  0.0002522464783396572
Epoch:  307  	Training Loss: 0.00017081793339457363
Test Loss:  0.0001605573925189674
Valid Loss:  0.000251991325058043
Epoch:  308  	Training Loss: 0.00017051276518031955
Test Loss:  0.00016025968943722546
Valid Loss:  0.00025173203903250396
Epoch:  309  	Training Loss: 0.00017022073734551668
Test Loss:  0.0001599993120180443
Valid Loss:  0.0002514695224817842
Epoch:  310  	Training Loss: 0.00016993515600915998
Test Loss:  0.0001597617520019412
Valid Loss:  0.0002512169594410807
Epoch:  311  	Training Loss: 0.00016965321265161037
Test Loss:  0.00015953830734360963
Valid Loss:  0.0002509636105969548
Epoch:  312  	Training Loss: 0.00016937445616349578
Test Loss:  0.00015847248141653836
Valid Loss:  0.00024933175882324576
Epoch:  313  	Training Loss: 0.00016798562137410045
Test Loss:  0.00015806054580025375
Valid Loss:  0.00024877573014236987
Epoch:  314  	Training Loss: 0.00016744327149353921
Test Loss:  0.00015769817400723696
Valid Loss:  0.00024841949925757945
Epoch:  315  	Training Loss: 0.0001670516503509134
Test Loss:  0.0001573457266204059
Valid Loss:  0.0002481531701050699
Epoch:  316  	Training Loss: 0.00016669572505634278
Test Loss:  0.00015699828509241343
Valid Loss:  0.00024789286544546485
Epoch:  317  	Training Loss: 0.0001663493603700772
Test Loss:  0.00015666332910768688
Valid Loss:  0.0002476817462593317
Epoch:  318  	Training Loss: 0.00016600813250988722
Test Loss:  0.0001563355908729136
Valid Loss:  0.00024745723931118846
Epoch:  319  	Training Loss: 0.00016567509737797081
Test Loss:  0.00015601349878124893
Valid Loss:  0.0002472274354659021
Epoch:  320  	Training Loss: 0.00016534715541638434
Test Loss:  0.00015569587412755936
Valid Loss:  0.0002469950122758746
Epoch:  321  	Training Loss: 0.00016502356447745115
Test Loss:  0.00015538228035438806
Valid Loss:  0.00024676404427737
Epoch:  322  	Training Loss: 0.00016470423724967986
Test Loss:  0.00015542309847660363
Valid Loss:  0.00024624718935228884
Epoch:  323  	Training Loss: 0.00016389391385018826
Test Loss:  0.00015543968765996397
Valid Loss:  0.00024575862335041165
Epoch:  324  	Training Loss: 0.00016313698142766953
Test Loss:  0.00015544515918008983
Valid Loss:  0.0002453041961416602
Epoch:  325  	Training Loss: 0.00016243661229964346
Test Loss:  0.0001554408809170127
Valid Loss:  0.00024488079361617565
Epoch:  326  	Training Loss: 0.0001617831294424832
Test Loss:  0.0001554240589030087
Valid Loss:  0.00024448265321552753
Epoch:  327  	Training Loss: 0.0001611606276128441
Test Loss:  0.00015539562446065247
Valid Loss:  0.00024410855257883668
Epoch:  328  	Training Loss: 0.00016056813183240592
Test Loss:  0.00015536103455815464
Valid Loss:  0.00024375764769501984
Epoch:  329  	Training Loss: 0.0001600123941898346
Test Loss:  0.00015531567623838782
Valid Loss:  0.00024342446704395115
Epoch:  330  	Training Loss: 0.00015947867359500378
Test Loss:  0.00015526090282946825
Valid Loss:  0.00024310752633027732
Epoch:  331  	Training Loss: 0.00015896515105850995
Test Loss:  0.0001551978348288685
Valid Loss:  0.00024280542857013643
Epoch:  332  	Training Loss: 0.0001584696292411536
Test Loss:  0.00015535688726231456
Valid Loss:  0.000242817826801911
Epoch:  333  	Training Loss: 0.00015844262088648975
Test Loss:  0.00015546962094958872
Valid Loss:  0.00024282184313051403
Epoch:  334  	Training Loss: 0.00015842584252823144
Test Loss:  0.00015555752906948328
Valid Loss:  0.0002428195730317384
Epoch:  335  	Training Loss: 0.000158412178279832
Test Loss:  0.000155629517394118
Valid Loss:  0.00024281424703076482
Epoch:  336  	Training Loss: 0.0001583998673595488
Test Loss:  0.00015569047536700964
Valid Loss:  0.0002428053121548146
Epoch:  337  	Training Loss: 0.00015838845865800977
Test Loss:  0.0001557443756610155
Valid Loss:  0.00024279461649712175
Epoch:  338  	Training Loss: 0.0001583776029292494
Test Loss:  0.0001557943323859945
Valid Loss:  0.00024278342607431114
Epoch:  339  	Training Loss: 0.00015836712555028498
Test Loss:  0.00015584059292450547
Valid Loss:  68%|██████▊   | 339/500 [04:05<00:54,  2.98it/s] 68%|██████▊   | 341/500 [04:11<03:08,  1.18s/it] 69%|██████▊   | 343/500 [04:12<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:12<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:12<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:12<00:50,  3.00it/s] 70%|███████   | 351/500 [04:18<02:54,  1.17s/it] 71%|███████   | 353/500 [04:18<02:03,  1.19it/s] 71%|███████   | 355/500 [04:18<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:19<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:19<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:25<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:25<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:25<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:25<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:26<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:32<02:29,  1.16s/it] 75%|███████▍  | 373/500 [04:32<01:46,  1.20it/s] 75%|███████▌  | 375/500 [04:32<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:32<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:32<00:39,  3.04it/s] 76%|███████▌  | 381/500 [04:39<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:39<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:39<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:39<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:39<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:45<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:45<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:46<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:46<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:46<00:33,  3.01it/s] 80%|████████  | 401/500 [04:52<01:55,  1.17s/it] 81%|████████  | 403/500 [04:52<01:21,  1.19it/s] 81%|████████  | 405/500 [04:52<00:57,  1.64it/s] 0.0002427720173727721
Epoch:  340  	Training Loss: 0.0001583568810019642
Test Loss:  0.0001558847725391388
Valid Loss:  0.0002427599101793021
Epoch:  341  	Training Loss: 0.0001583468692842871
Test Loss:  0.00015592729323543608
Valid Loss:  0.00024274818133562803
Epoch:  342  	Training Loss: 0.00015833741053938866
Test Loss:  0.00015595240984112024
Valid Loss:  0.000242647816776298
Epoch:  343  	Training Loss: 0.00015818316023796797
Test Loss:  0.00015608423564117402
Valid Loss:  0.00024262556689791381
Epoch:  344  	Training Loss: 0.00015806322335265577
Test Loss:  0.00015627825632691383
Valid Loss:  0.00024261450744234025
Epoch:  345  	Training Loss: 0.00015795101353432983
Test Loss:  0.0001564455305924639
Valid Loss:  0.00024256721371784806
Epoch:  346  	Training Loss: 0.00015785617870278656
Test Loss:  0.0001566058926982805
Valid Loss:  0.000242528913076967
Epoch:  347  	Training Loss: 0.00015776552027091384
Test Loss:  0.00015675363829359412
Valid Loss:  0.00024249701527878642
Epoch:  348  	Training Loss: 0.00015768161392770708
Test Loss:  0.00015687680570408702
Valid Loss:  0.00024243950610980392
Epoch:  349  	Training Loss: 0.0001576063223183155
Test Loss:  0.00015699266805313528
Valid Loss:  0.0002423983532935381
Epoch:  350  	Training Loss: 0.00015753587649669498
Test Loss:  0.00015709956642240286
Valid Loss:  0.00024236354511231184
Epoch:  351  	Training Loss: 0.0001574687921674922
Test Loss:  0.00015720800729468465
Valid Loss:  0.00024233585281763226
Epoch:  352  	Training Loss: 0.0001574040506966412
Test Loss:  0.00015602455823682249
Valid Loss:  0.00024186364316847175
Epoch:  353  	Training Loss: 0.00015663294470869005
Test Loss:  0.00015506141062360257
Valid Loss:  0.0002413935144431889
Epoch:  354  	Training Loss: 0.00015596904268022627
Test Loss:  0.0001543120015412569
Valid Loss:  0.0002409827138762921
Epoch:  355  	Training Loss: 0.00015544691996183246
Test Loss:  0.00015368859749287367
Valid Loss:  0.00024068093625828624
Epoch:  356  	Training Loss: 0.00015498342690989375
Test Loss:  0.00015310377057176083
Valid Loss:  0.00024037787807174027
Epoch:  357  	Training Loss: 0.00015455631364602596
Test Loss:  0.00015256850747391582
Valid Loss:  0.00024011966888792813
Epoch:  358  	Training Loss: 0.00015421872376464307
Test Loss:  0.0001521187659818679
Valid Loss:  0.00023974890063982457
Epoch:  359  	Training Loss: 0.0001539539371151477
Test Loss:  0.00015169927792157978
Valid Loss:  0.00023940825485624373
Epoch:  360  	Training Loss: 0.00015370204346254468
Test Loss:  0.00015129275561776012
Valid Loss:  0.0002390792651567608
Epoch:  361  	Training Loss: 0.00015345610154327005
Test Loss:  0.00015089685621205717
Valid Loss:  0.0002387585409451276
Epoch:  362  	Training Loss: 0.0001532157330075279
Test Loss:  0.00015103475016076118
Valid Loss:  0.000238703956711106
Epoch:  363  	Training Loss: 0.00015309439913835377
Test Loss:  0.00015117146540433168
Valid Loss:  0.0002386619453318417
Epoch:  364  	Training Loss: 0.0001529900764580816
Test Loss:  0.00015130636165849864
Valid Loss:  0.000238629465457052
Epoch:  365  	Training Loss: 0.0001529000437585637
Test Loss:  0.00015143811469897628
Valid Loss:  0.00023860458168201149
Epoch:  366  	Training Loss: 0.00015282208914868534
Test Loss:  0.00015156598237808794
Valid Loss:  0.00023858598433434963
Epoch:  367  	Training Loss: 0.00015275459736585617
Test Loss:  0.00015168949903454632
Valid Loss:  0.0002385724801570177
Epoch:  368  	Training Loss: 0.00015269560390152037
Test Loss:  0.00015180812624748796
Valid Loss:  0.00023856243933551013
Epoch:  369  	Training Loss: 0.00015264423564076424
Test Loss:  0.00015192216960713267
Valid Loss:  0.0002385554980719462
Epoch:  370  	Training Loss: 0.00015259873180184513
Test Loss:  0.0001520309306215495
Valid Loss:  0.00023855089966673404
Epoch:  371  	Training Loss: 0.00015255862672347575
Test Loss:  0.000152135020471178
Valid Loss:  0.0002385480620432645
Epoch:  372  	Training Loss: 0.000152523149154149
Test Loss:  0.0001525464467704296
Valid Loss:  0.00023869398864917457
Epoch:  373  	Training Loss: 0.00015231555153150111
Test Loss:  0.00015266233822330832
Valid Loss:  0.000238690510741435
Epoch:  374  	Training Loss: 0.0001521858648629859
Test Loss:  0.00015269554569385946
Valid Loss:  0.00023864046670496464
Epoch:  375  	Training Loss: 0.00015206399257294834
Test Loss:  0.0001527173153590411
Valid Loss:  0.00023858500935602933
Epoch:  376  	Training Loss: 0.00015194612205959857
Test Loss:  0.0001527274725958705
Valid Loss:  0.00023852252343203872
Epoch:  377  	Training Loss: 0.00015183129289653152
Test Loss:  0.00015274449833668768
Valid Loss:  0.0002384672116022557
Epoch:  378  	Training Loss: 0.00015171973791439086
Test Loss:  0.00015275544137693942
Valid Loss:  0.00023840840731281787
Epoch:  379  	Training Loss: 0.00015161077317316085
Test Loss:  0.00015276530757546425
Valid Loss:  0.00023835280444473028
Epoch:  380  	Training Loss: 0.00015150458784773946
Test Loss:  0.00015278553473763168
Valid Loss:  0.00023830517602618784
Epoch:  381  	Training Loss: 0.00015140080358833075
Test Loss:  0.00015279997023753822
Valid Loss:  0.00023825460812076926
Epoch:  382  	Training Loss: 0.00015129928942769766
Test Loss:  0.00015173926658462733
Valid Loss:  0.00023733594571240246
Epoch:  383  	Training Loss: 0.0001504912506788969
Test Loss:  0.00015097649884410203
Valid Loss:  0.0002368820714764297
Epoch:  384  	Training Loss: 0.00014974651276133955
Test Loss:  0.00015045766485854983
Valid Loss:  0.0002365835098316893
Epoch:  385  	Training Loss: 0.00014910286699887365
Test Loss:  0.0001500710059190169
Valid Loss:  0.0002363245585002005
Epoch:  386  	Training Loss: 0.0001485238317400217
Test Loss:  0.0001497789635322988
Valid Loss:  0.00023608643095940351
Epoch:  387  	Training Loss: 0.00014798920892644674
Test Loss:  0.00014955679944250733
Valid Loss:  0.00023586192401126027
Epoch:  388  	Training Loss: 0.00014748642570339143
Test Loss:  0.00014938710955902934
Valid Loss:  0.00023564585717394948
Epoch:  389  	Training Loss: 0.00014700856991112232
Test Loss:  0.00014925809227861464
Valid Loss:  0.000235437648370862
Epoch:  390  	Training Loss: 0.00014655559789389372
Test Loss:  0.00014915493375156075
Valid Loss:  0.00023523293202742934
Epoch:  391  	Training Loss: 0.00014611860387958586
Test Loss:  0.00014907609147485346
Valid Loss:  0.000235033716307953
Epoch:  392  	Training Loss: 0.0001456962781958282
Test Loss:  0.00014910462778061628
Valid Loss:  0.00023446093837264925
Epoch:  393  	Training Loss: 0.00014536702656187117
Test Loss:  0.00014930796169210225
Valid Loss:  0.00023418289492838085
Epoch:  394  	Training Loss: 0.00014513276983052492
Test Loss:  0.00014954805374145508
Valid Loss:  0.0002340138453291729
Epoch:  395  	Training Loss: 0.00014494027709588408
Test Loss:  0.0001497923512943089
Valid Loss:  0.00023390307615045458
Epoch:  396  	Training Loss: 0.0001447773538529873
Test Loss:  0.00015003075532149523
Valid Loss:  0.00023381647770293057
Epoch:  397  	Training Loss: 0.00014463855768553913
Test Loss:  0.0001502575760241598
Valid Loss:  0.00023374594456981868
Epoch:  398  	Training Loss: 0.00014451795141212642
Test Loss:  0.00015048336354084313
Valid Loss:  0.00023370192502625287
Epoch:  399  	Training Loss: 0.0001444107183488086
Test Loss:  0.00015070350491441786
Valid Loss:  0.00023367056564893574
Epoch:  400  	Training Loss: 0.0001443148939870298
Test Loss:  0.00015091599198058248
Valid Loss:  0.0002336469478905201
Epoch:  401  	Training Loss: 0.0001442315842723474
Test Loss:  0.00015109707601368427
Valid Loss:  0.0002336087345611304
Epoch:  402  	Training Loss: 0.0001441614149371162
Test Loss:  0.00015094203990884125
Valid Loss:  0.00023352159769274294
Epoch:  403  	Training Loss: 0.00014381887740455568
Test Loss:  0.00015073813847266138
Valid Loss:  0.00023341341875493526
Epoch:  404  	Training Loss: 0.00014350379933603108
Test Loss:  0.0001504974497947842
Valid Loss:  0.00023328737006522715
Epoch:  405  	Training Loss: 0.00014320574700832367
Test Loss:  0.00015023209562059492
Valid Loss:  0.00023314819554798305
Epoch:  406  	Training Loss: 0.00014291959814727306
Test Loss:  0.0001499524514656514
Valid Loss:   81%|████████▏ | 407/500 [04:53<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:53<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:59<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:59<01:15,  1.15it/s] 83%|████████▎ | 415/500 [04:59<00:54,  1.57it/s] 83%|████████▎ | 417/500 [05:00<00:39,  2.12it/s] 84%|████████▍ | 419/500 [05:00<00:28,  2.82it/s] 84%|████████▍ | 421/500 [05:06<01:35,  1.21s/it] 85%|████████▍ | 423/500 [05:06<01:07,  1.15it/s] 85%|████████▌ | 425/500 [05:07<00:47,  1.59it/s] 85%|████████▌ | 427/500 [05:07<00:33,  2.18it/s] 86%|████████▌ | 429/500 [05:07<00:24,  2.94it/s] 86%|████████▌ | 431/500 [05:13<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:13<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:13<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:14<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:14<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:20<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:20<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:20<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:20<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:20<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:27<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:27<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:27<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:27<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:27<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:33<00:45,  1.16s/it] 93%|█████████▎| 463/500 [05:34<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:34<00:21,  1.66it/s] 93%|█████████▎| 467/500 [05:34<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:34<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:40<00:34,  1.19s/it]0.0002330005809199065
Epoch:  407  	Training Loss: 0.0001426430681021884
Test Loss:  0.00014966324670240283
Valid Loss:  0.0002328471455257386
Epoch:  408  	Training Loss: 0.00014237468712963164
Test Loss:  0.00014937057858332992
Valid Loss:  0.00023269113444257528
Epoch:  409  	Training Loss: 0.0001421138149453327
Test Loss:  0.000149077910464257
Valid Loss:  0.0002325350505998358
Epoch:  410  	Training Loss: 0.00014186397311277688
Test Loss:  0.00014868404832668602
Valid Loss:  0.0002323787921341136
Epoch:  411  	Training Loss: 0.00014162043225951493
Test Loss:  0.0001482789230067283
Valid Loss:  0.0002321972860954702
Epoch:  412  	Training Loss: 0.00014138224651105702
Test Loss:  0.00014696533617097884
Valid Loss:  0.00023141794372349977
Epoch:  413  	Training Loss: 0.00014111508789937943
Test Loss:  0.00014635476691182703
Valid Loss:  0.00023110443726181984
Epoch:  414  	Training Loss: 0.00014099145482759923
Test Loss:  0.00014602477313019335
Valid Loss:  0.00023096485529094934
Epoch:  415  	Training Loss: 0.0001409075630363077
Test Loss:  0.00014582203584723175
Valid Loss:  0.0002308955736225471
Epoch:  416  	Training Loss: 0.00014084152644500136
Test Loss:  0.00014568271581083536
Valid Loss:  0.00023077231890056282
Epoch:  417  	Training Loss: 0.0001407860399922356
Test Loss:  0.00014557907707057893
Valid Loss:  0.0002306762180523947
Epoch:  418  	Training Loss: 0.00014073794591240585
Test Loss:  0.00014549828483723104
Valid Loss:  0.00023059535305947065
Epoch:  419  	Training Loss: 0.00014069471217226237
Test Loss:  0.0001454329612897709
Valid Loss:  0.0002305250527570024
Epoch:  420  	Training Loss: 0.0001406548690283671
Test Loss:  0.0001453807926736772
Valid Loss:  0.00023046511341817677
Epoch:  421  	Training Loss: 0.00014061777619645
Test Loss:  0.00014533907233271748
Valid Loss:  0.00023040951055008918
Epoch:  422  	Training Loss: 0.00014058224041946232
Test Loss:  0.0001453894074074924
Valid Loss:  0.0002304304507561028
Epoch:  423  	Training Loss: 0.00014052206824999303
Test Loss:  0.00014540948905050755
Valid Loss:  0.0002304210065631196
Epoch:  424  	Training Loss: 0.00014046678552404046
Test Loss:  0.0001454102311981842
Valid Loss:  0.00023039255756884813
Epoch:  425  	Training Loss: 0.00014041604299563915
Test Loss:  0.00014540262054651976
Valid Loss:  0.0002303556102560833
Epoch:  426  	Training Loss: 0.00014037330402061343
Test Loss:  0.0001453896111343056
Valid Loss:  0.00023031770251691341
Epoch:  427  	Training Loss: 0.00014033418847247958
Test Loss:  0.00014537377865053713
Valid Loss:  0.00023027980932965875
Epoch:  428  	Training Loss: 0.00014029620797373354
Test Loss:  0.00014535593800246716
Valid Loss:  0.00023024025722406805
Epoch:  429  	Training Loss: 0.00014025928976479918
Test Loss:  0.00014533716603182256
Valid Loss:  0.00023020003573037684
Epoch:  430  	Training Loss: 0.00014022341929376125
Test Loss:  0.00014531855413224548
Valid Loss:  0.00023016016348265111
Epoch:  431  	Training Loss: 0.00014018853835295886
Test Loss:  0.00014529976760968566
Valid Loss:  0.0002301205531693995
Epoch:  432  	Training Loss: 0.00014015486522112042
Test Loss:  0.00014481678954325616
Valid Loss:  0.00022945544333197176
Epoch:  433  	Training Loss: 0.0001396396546624601
Test Loss:  0.00014465853746514767
Valid Loss:  0.00022911552514415234
Epoch:  434  	Training Loss: 0.00013944816600997
Test Loss:  0.00014456521603278816
Valid Loss:  0.00022887397790327668
Epoch:  435  	Training Loss: 0.0001393116544932127
Test Loss:  0.000144506455399096
Valid Loss:  0.00022867400548420846
Epoch:  436  	Training Loss: 0.0001392060366924852
Test Loss:  0.0001444675144739449
Valid Loss:  0.0002285062801092863
Epoch:  437  	Training Loss: 0.00013912060239817947
Test Loss:  0.0001444407389499247
Valid Loss:  0.00022836441348772496
Epoch:  438  	Training Loss: 0.0001390486431773752
Test Loss:  0.00014442141400650144
Valid Loss:  0.0002282427012687549
Epoch:  439  	Training Loss: 0.00013898689940106124
Test Loss:  0.00014440581435337663
Valid Loss:  0.00022813765099272132
Epoch:  440  	Training Loss: 0.00013893232971895486
Test Loss:  0.00014439268852584064
Valid Loss:  0.00022804629406891763
Epoch:  441  	Training Loss: 0.00013888333342038095
Test Loss:  0.00014438072685152292
Valid Loss:  0.0002279665059177205
Epoch:  442  	Training Loss: 0.0001388384262099862
Test Loss:  0.00014245194324757904
Valid Loss:  0.00022622523829340935
Epoch:  443  	Training Loss: 0.00013823520566802472
Test Loss:  0.00014144679880701005
Valid Loss:  0.00022497196914628148
Epoch:  444  	Training Loss: 0.00013786423369310796
Test Loss:  0.0001408116950187832
Valid Loss:  0.0002241102047264576
Epoch:  445  	Training Loss: 0.00013757319538854063
Test Loss:  0.00014031879254616797
Valid Loss:  0.00022339896531775594
Epoch:  446  	Training Loss: 0.0001373372069792822
Test Loss:  0.00013994300388731062
Valid Loss:  0.00022280641132965684
Epoch:  447  	Training Loss: 0.00013712761574424803
Test Loss:  0.00013964790559839457
Valid Loss:  0.00022229726891964674
Epoch:  448  	Training Loss: 0.00013693135406356305
Test Loss:  0.0001393866550642997
Valid Loss:  0.00022181867097970098
Epoch:  449  	Training Loss: 0.00013674878573510796
Test Loss:  0.00013913981092628092
Valid Loss:  0.0002213563275290653
Epoch:  450  	Training Loss: 0.00013657858653459698
Test Loss:  0.0001389397366438061
Valid Loss:  0.0002209494123235345
Epoch:  451  	Training Loss: 0.00013641381519846618
Test Loss:  0.00013873848365619779
Valid Loss:  0.00022053913562558591
Epoch:  452  	Training Loss: 0.00013625802239403129
Test Loss:  0.00013824913185089827
Valid Loss:  0.00022025902580935508
Epoch:  453  	Training Loss: 0.00013584765838459134
Test Loss:  0.00013804319314658642
Valid Loss:  0.00022016846924088895
Epoch:  454  	Training Loss: 0.00013571222370956093
Test Loss:  0.00013794963888358325
Valid Loss:  0.00022013556736055762
Epoch:  455  	Training Loss: 0.0001356659340672195
Test Loss:  0.00013790391676593572
Valid Loss:  0.0002201198076363653
Epoch:  456  	Training Loss: 0.00013564876280725002
Test Loss:  0.0001378987799398601
Valid Loss:  0.00022010892280377448
Epoch:  457  	Training Loss: 0.00013564107939600945
Test Loss:  0.00013789816875942051
Valid Loss:  0.0002200984163209796
Epoch:  458  	Training Loss: 0.00013563636457547545
Test Loss:  0.0001378984161419794
Valid Loss:  0.00022008885571267456
Epoch:  459  	Training Loss: 0.00013563293032348156
Test Loss:  0.000137899027322419
Valid Loss:  0.0002200806193286553
Epoch:  460  	Training Loss: 0.00013562964159063995
Test Loss:  0.00013790004595648497
Valid Loss:  0.0002200733288191259
Epoch:  461  	Training Loss: 0.00013562671665567905
Test Loss:  0.00013790058437734842
Valid Loss:  0.00022006459766998887
Epoch:  462  	Training Loss: 0.00013562373351305723
Test Loss:  0.0001373989653075114
Valid Loss:  0.00021946193010080606
Epoch:  463  	Training Loss: 0.0001353841507807374
Test Loss:  0.00013708644837606698
Valid Loss:  0.00021903144079260528
Epoch:  464  	Training Loss: 0.0001351598766632378
Test Loss:  0.00013673205103259534
Valid Loss:  0.00021856665262021124
Epoch:  465  	Training Loss: 0.0001349424128420651
Test Loss:  0.0001364087947877124
Valid Loss:  0.0002181340241804719
Epoch:  466  	Training Loss: 0.000134733272716403
Test Loss:  0.0001360708411084488
Valid Loss:  0.00021769118029624224
Epoch:  467  	Training Loss: 0.0001345286436844617
Test Loss:  0.00013574009062722325
Valid Loss:  0.00021725674741901457
Epoch:  468  	Training Loss: 0.00013432942796498537
Test Loss:  0.00013542610395234078
Valid Loss:  0.00021683951490558684
Epoch:  469  	Training Loss: 0.00013413489796221256
Test Loss:  0.00013510743156075478
Valid Loss:  0.00021642129286192358
Epoch:  470  	Training Loss: 0.00013394438428804278
Test Loss:  0.00013479526387527585
Valid Loss:  0.00021601194748654962
Epoch:  471  	Training Loss: 0.0001337574649369344
Test Loss:  0.00013448840763885528
Valid Loss:  0.00021560912136919796
Epoch:  472  	Training Loss: 0.00013357444549910724
Test Loss:  0.00013323823804967105
Valid Loss:  0.0002140083524864167
Epoch:  473  	Training Loss: 0.00013322121230885386
Test Loss:  0.00013267627218738198
Valid Loss:  0.00021323848341125995 95%|█████████▍| 473/500 [05:40<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:41<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:41<00:10,  2.18it/s] 96%|█████████▌| 479/500 [05:41<00:07,  2.94it/s] 96%|█████████▌| 481/500 [05:47<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:47<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:47<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:48<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:48<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:54<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:54<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:54<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:55<00:01,  2.17it/s]100%|█████████▉| 499/500 [05:55<00:00,  2.87it/s]100%|██████████| 500/500 [05:55<00:00,  1.41it/s]

Epoch:  474  	Training Loss: 0.00013306357141118497
Test Loss:  0.00013237840903457254
Valid Loss:  0.00021279309294186532
Epoch:  475  	Training Loss: 0.00013295761891640723
Test Loss:  0.00013219023821875453
Valid Loss:  0.00021248099801596254
Epoch:  476  	Training Loss: 0.00013287838373798877
Test Loss:  0.00013205214054323733
Valid Loss:  0.0002122274599969387
Epoch:  477  	Training Loss: 0.00013281655265018344
Test Loss:  0.00013196069630794227
Valid Loss:  0.0002120272838510573
Epoch:  478  	Training Loss: 0.00013276665413286537
Test Loss:  0.00013187552394811064
Valid Loss:  0.00021183703211136162
Epoch:  479  	Training Loss: 0.00013272653450258076
Test Loss:  0.0001318358990829438
Valid Loss:  0.00021169842511881143
Epoch:  480  	Training Loss: 0.00013268913608044386
Test Loss:  0.00013180309906601906
Valid Loss:  0.00021157239098101854
Epoch:  481  	Training Loss: 0.0001326550991507247
Test Loss:  0.00013178671360947192
Valid Loss:  0.00021146878134459257
Epoch:  482  	Training Loss: 0.00013262216816656291
Test Loss:  0.00013206260337028652
Valid Loss:  0.00021156069124117494
Epoch:  483  	Training Loss: 0.00013239776308182627
Test Loss:  0.0001320888550253585
Valid Loss:  0.00021134658891241997
Epoch:  484  	Training Loss: 0.00013222247071098536
Test Loss:  0.0001320502778980881
Valid Loss:  0.0002110502973664552
Epoch:  485  	Training Loss: 0.00013205656432546675
Test Loss:  0.0001320038572885096
Valid Loss:  0.00021074092364870012
Epoch:  486  	Training Loss: 0.00013189671153668314
Test Loss:  0.0001319628208875656
Valid Loss:  0.00021043677406851202
Epoch:  487  	Training Loss: 0.00013174139894545078
Test Loss:  0.00013192971528042108
Valid Loss:  0.00021014083176851273
Epoch:  488  	Training Loss: 0.00013159029185771942
Test Loss:  0.00013190871686674654
Valid Loss:  0.00020985433366149664
Epoch:  489  	Training Loss: 0.00013144321565050632
Test Loss:  0.0001318947470281273
Valid Loss:  0.00020957525703124702
Epoch:  490  	Training Loss: 0.00013129989383742213
Test Loss:  0.00013188610319048166
Valid Loss:  0.00020930491155013442
Epoch:  491  	Training Loss: 0.00013116063200868666
Test Loss:  0.0001318828872172162
Valid Loss:  0.00020904073608107865
Epoch:  492  	Training Loss: 0.00013102454249747097
Test Loss:  0.0001317962014582008
Valid Loss:  0.0002088049368467182
Epoch:  493  	Training Loss: 0.00013097398914396763
Test Loss:  0.00013179930101614445
Valid Loss:  0.00020867717103101313
Epoch:  494  	Training Loss: 0.00013094430323690176
Test Loss:  0.00013185746502131224
Valid Loss:  0.00020861958910245448
Epoch:  495  	Training Loss: 0.00013092183507978916
Test Loss:  0.00013193096674513072
Valid Loss:  0.00020858699281234294
Epoch:  496  	Training Loss: 0.0001309021608904004
Test Loss:  0.00013199802197050303
Valid Loss:  0.00020855606999248266
Epoch:  497  	Training Loss: 0.0001308848732151091
Test Loss:  0.0001320733572356403
Valid Loss:  0.00020853878231719136
Epoch:  498  	Training Loss: 0.0001308694336330518
Test Loss:  0.00013215250510256737
Valid Loss:  0.00020852904708590358
Epoch:  499  	Training Loss: 0.00013085523096378893
Test Loss:  0.0001322313619311899
Valid Loss:  0.000208524230401963
Epoch:  500  	Training Loss: 0.00013084191596135497
Test Loss:  0.0001323101605521515
Valid Loss:  0.00020852190209552646
seed is  16
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:42, 11.71it/s]  1%|          | 4/500 [00:00<00:40, 12.33it/s]  1%|          | 6/500 [00:00<00:35, 13.86it/s]  2%|▏         | 8/500 [00:00<00:33, 14.77it/s]  2%|▏         | 10/500 [00:00<00:32, 15.21it/s]  2%|▏         | 12/500 [00:00<00:31, 15.44it/s]  3%|▎         | 14/500 [00:00<00:30, 15.70it/s]  3%|▎         | 16/500 [00:01<00:30, 15.91it/s]  4%|▎         | 18/500 [00:01<00:30, 16.06it/s]  4%|▍         | 20/500 [00:01<00:30, 15.84it/s]  4%|▍         | 22/500 [00:01<00:30, 15.44it/s]  5%|▍         | 24/500 [00:01<00:30, 15.76it/s]  5%|▌         | 26/500 [00:01<00:30, 15.47it/s]  6%|▌         | 28/500 [00:01<00:29, 15.75it/s]  6%|▌         | 30/500 [00:01<00:29, 16.02it/s]  6%|▋         | 32/500 [00:02<00:29, 15.72it/s]  7%|▋         | 34/500 [00:02<00:32, 14.54it/s]  7%|▋         | 36/500 [00:02<00:33, 14.06it/s]  8%|▊         | 38/500 [00:02<00:32, 14.32it/s]  8%|▊         | 40/500 [00:02<00:33, 13.65it/s]  8%|▊         | 42/500 [00:02<00:34, 13.36it/s]  9%|▉         | 44/500 [00:02<00:32, 14.00it/s]  9%|▉         | 46/500 [00:03<00:31, 14.52it/s] 10%|▉         | 48/500 [00:03<00:30, 14.97it/s] 10%|█         | 50/500 [00:03<00:29, 15.30it/s] 10%|█         | 52/500 [00:03<00:28, 15.61it/s] 11%|█         | 54/500 [00:03<00:28, 15.40it/s] 11%|█         | 56/500 [00:03<00:29, 15.23it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.61it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.51it/s] 12%|█▏        | 62/500 [00:04<00:28, 15.49it/s] 13%|█▎        | 64/500 [00:04<00:30, 14.19it/s] 13%|█▎        | 66/500 [00:04<00:32, 13.36it/s] 14%|█▎        | 68/500 [00:04<00:33, 13.02it/s] 14%|█▍        | 70/500 [00:04<00:33, 12.70it/s] 14%|█▍        | 72/500 [00:04<00:33, 12.61it/s] 15%|█▍        | 74/500 [00:05<00:34, 12.47it/s] 15%|█▌        | 76/500 [00:05<00:34, 12.43it/s] 16%|█▌        | 78/500 [00:05<00:33, 12.46it/s] 16%|█▌        | 80/500 [00:05<00:31, 13.27it/s] 16%|█▋        | 82/500 [00:05<00:30, 13.70it/s] 17%|█▋        | 84/500 [00:05<00:28, 14.41it/s] 17%|█▋        | 86/500 [00:05<00:27, 14.92it/s] 18%|█▊        | 88/500 [00:06<00:26, 15.31it/s] 18%|█▊        | 90/500 [00:06<00:26, 15.58it/s] 18%|█▊        | 92/500 [00:06<00:26, 15.55it/s] 19%|█▉        | 94/500 [00:06<00:25, 15.82it/s] 19%|█▉        | 96/500 [00:06<00:25, 16.01it/s] 20%|█▉        | 98/500 [00:06<00:25, 16.02it/s] 20%|██        | 100/500 [00:06<00:24, 16.12it/s] 20%|██        | 102/500 [00:06<00:25, 15.89it/s] 21%|██        | 104/500 [00:07<00:24, 16.06it/s] 21%|██        | 106/500 [00:07<00:24, 16.16it/s] 22%|██▏       | 108/500 [00:07<00:24, 16.25it/s] 22%|██▏       | 110/500 [00:07<00:23, 16.30it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.22it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.28it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.31it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.27it/s] 24%|██▍       | 120/500 [00:08<00:23, 16.34it/s] 24%|██▍       | 122/500 [00:08<00:22, 16.47it/s] 25%|██▍       | 124/500 [00:08<00:22, 16.46it/s]Epoch:  1  	Training Loss: 0.5441862344741821
Test Loss:  5601.6337890625
Valid Loss:  5612.912109375
Epoch:  2  	Training Loss: 5615.2900390625
Test Loss:  7.39376324775877e+18
Valid Loss:  7.341613411253354e+18
Epoch:  3  	Training Loss: 7.28919364464332e+18
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 15.91it/s] 26%|██▌       | 128/500 [00:08<00:24, 15.32it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.72it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.03it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.14it/s] 27%|██▋       | 136/500 [00:09<00:22, 15.99it/s] 28%|██▊       | 138/500 [00:09<00:23, 15.58it/s] 28%|██▊       | 140/500 [00:09<00:23, 15.48it/s] 28%|██▊       | 142/500 [00:09<00:22, 15.66it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.88it/s] 29%|██▉       | 146/500 [00:09<00:22, 16.09it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.23it/s] 30%|███       | 150/500 [00:09<00:21, 16.35it/s] 30%|███       | 152/500 [00:10<00:21, 16.39it/s] 31%|███       | 154/500 [00:10<00:21, 16.29it/s] 31%|███       | 156/500 [00:10<00:21, 16.26it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.28it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.21it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.18it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.17it/s] 33%|███▎      | 166/500 [00:10<00:22, 14.96it/s] 34%|███▎      | 168/500 [00:11<00:21, 15.31it/s] 34%|███▍      | 170/500 [00:11<00:21, 15.52it/s] 34%|███▍      | 172/500 [00:11<00:21, 15.48it/s] 35%|███▍      | 174/500 [00:11<00:20, 15.54it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.80it/s] 36%|███▌      | 178/500 [00:11<00:20, 16.03it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.14it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.16it/s] 37%|███▋      | 184/500 [00:12<00:19, 16.24it/s] 37%|███▋      | 186/500 [00:12<00:19, 16.01it/s] 38%|███▊      | 188/500 [00:12<00:19, 16.16it/s] 38%|███▊      | 190/500 [00:12<00:19, 15.84it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.95it/s] 39%|███▉      | 194/500 [00:12<00:19, 16.03it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.15it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.23it/s] 40%|████      | 200/500 [00:13<00:18, 15.98it/s] 40%|████      | 202/500 [00:13<00:18, 16.06it/s] 41%|████      | 204/500 [00:13<00:18, 15.73it/s] 41%|████      | 206/500 [00:13<00:18, 15.95it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.01it/s] 42%|████▏     | 210/500 [00:13<00:18, 16.01it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.75it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.02it/s] 43%|████▎     | 216/500 [00:14<00:17, 16.13it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.28it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.36it/s] 44%|████▍     | 222/500 [00:14<00:16, 16.37it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.30it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.30it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.35it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.39it/s] 46%|████▋     | 232/500 [00:15<00:16, 16.35it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.33it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.41it/s] 48%|████▊     | 238/500 [00:15<00:15, 16.42it/s] 48%|████▊     | 240/500 [00:15<00:15, 16.41it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.45it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.46it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.46it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.43it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.44it/s] 50%|█████     | 252/500 [00:16<00:15, 16.31it/s] 51%|█████     | 254/500 [00:16<00:15, 16.24it/s] 51%|█████     | 256/500 [00:16<00:14, 16.27it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.26it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.38it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.32it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.21it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.22it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.28it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.29it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.21it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.25it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.40it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.50it/s] 56%|█████▌    | 280/500 [00:17<00:13, 15.97it/s] 56%|█████▋    | 282/500 [00:18<00:14, 15.19it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.53it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.72it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.55it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.56it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.71it/s] 59%|█████▉    | 294/500 [00:18<00:12, 15.95it/s] 59%|█████▉    | 296/500 [00:19<00:12, 16.12it/s] 60%|█████▉    | 298/500 [00:19<00:12, 16.24it/s] 60%|██████    | 300/500 [00:19<00:12, 15.91it/s] 60%|██████    | 302/500 [00:19<00:12, 15.97it/s] 61%|██████    | 304/500 [00:19<00:12, 16.00it/s] 61%|██████    | 306/500 [00:19<00:12, 15.99it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.84it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.00it/s] 62%|██████▏   | 312/500 [00:20<00:11, 15.80it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.95it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.93it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.12it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.21it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.20it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.22it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.35it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.35it/s] 66%|██████▌   | 330/500 [00:21<00:10, 16.42it/s] 66%|██████▋   | 332/500 [00:21<00:10, 16.41it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.43it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.38it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.33it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.32it/s] 68%|██████▊   | 342/500 [00:21<00:10, 15.46it/s] 69%|██████▉   | 344/500 [00:21<00:09, 15.68it/s] 69%|██████▉   | 346/500 [00:22<00:09, 15.93it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.06it/s] 70%|███████   | 350/500 [00:22<00:09, 16.15it/s] 70%|███████   | 352/500 [00:22<00:09, 15.91it/s] 71%|███████   | 354/500 [00:22<00:09, 14.65it/s] 71%|███████   | 356/500 [00:22<00:09, 14.69it/s] 72%|███████▏  | 358/500 [00:22<00:09, 15.09it/s] 72%|███████▏  | 360/500 [00:23<00:09, 15.37it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.65it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.88it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.06it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.82it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.87it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.10it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.15it/s] 75%|███████▌  | 376/500 [00:24<00:07, 16.24it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.17it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.01it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.99it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.96it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.07it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.07it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.04it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.10it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.18it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.13it/s] 80%|███████▉  | 398/500 [00:25<00:06, 15.84it/s] 80%|████████  | 400/500 [00:25<00:06, 15.97it/s] 80%|████████  | 402/500 [00:25<00:06, 15.86it/s] 81%|████████  | 404/500 [00:25<00:06, 15.28it/s] 81%|████████  | 406/500 [00:25<00:06, 15.10it/s] 82%|████████▏ | 408/500 [00:26<00:05, 15.37it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.62it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.75it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.89it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.05it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.04it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.18it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.23it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.28it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.30it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.30it/s] 86%|████████▌ | 430/500 [00:27<00:04, 15.36it/s] 86%|████████▋ | 432/500 [00:27<00:04, 15.71it/s] 87%|████████▋ | 434/500 [00:27<00:04, 15.94it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.13it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.21it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.34it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.36it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.41it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.50it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.46it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.53it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.53it/s] 91%|█████████ | 454/500 [00:28<00:02, 15.33it/s] 91%|█████████ | 456/500 [00:29<00:02, 15.19it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.56it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.84it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.02it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.12it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.25it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.93it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.41it/s] 94%|█████████▍| 472/500 [00:30<00:01, 15.71it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.85it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.67it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.87it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.03it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.88it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.05it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.08it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.68it/s] 98%|█████████▊| 490/500 [00:31<00:00, 14.85it/s] 98%|█████████▊| 492/500 [00:31<00:00, 15.09it/s] 99%|█████████▉| 494/500 [00:31<00:00, 14.86it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.21it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.42it/s]100%|██████████| 500/500 [00:31<00:00, 15.61it/s]100%|██████████| 500/500 [00:31<00:00, 15.70it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  16
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:55,  6.24s/it]  1%|          | 3/500 [00:06<13:55,  1.68s/it]  1%|          | 5/500 [00:06<07:00,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:44,  2.15it/s]  4%|▍         | 19/500 [00:13<02:46,  2.90it/s]  4%|▍         | 21/500 [00:20<09:45,  1.22s/it]  5%|▍         | 23/500 [00:20<06:54,  1.15it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.96it/s]  6%|▌         | 31/500 [00:26<09:08,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:27<04:42,  1.65it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:33<08:55,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:34<03:21,  2.25it/s] 10%|▉         | 49/500 [00:34<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:47,  1.18s/it] 11%|█         | 53/500 [00:40<06:17,  1.19it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:47<08:43,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:29,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:47<02:25,  2.97it/s] 14%|█▍        | 71/500 [00:54<08:29,  1.19s/it] 15%|█▍        | 73/500 [00:54<06:04,  1.17it/s]Epoch:  1  	Training Loss: 0.5441862344741821
Test Loss:  172.94915771484375
Valid Loss:  170.74725341796875
Epoch:  2  	Training Loss: 168.19969177246094
Test Loss:  0.6546992659568787
Valid Loss:  0.6499119997024536
Epoch:  3  	Training Loss: 0.6272701025009155
Test Loss:  0.654685378074646
Valid Loss:  0.64990234375
Epoch:  4  	Training Loss: 0.6272562742233276
Test Loss:  0.6546714305877686
Valid Loss:  0.6498925685882568
Epoch:  5  	Training Loss: 0.6272424459457397
Test Loss:  0.6546573638916016
Valid Loss:  0.649882972240448
Epoch:  6  	Training Loss: 0.6272284984588623
Test Loss:  0.6546415090560913
Valid Loss:  0.6498729586601257
Epoch:  7  	Training Loss: 0.6272139549255371
Test Loss:  0.6546253561973572
Valid Loss:  0.6498627662658691
Epoch:  8  	Training Loss: 0.6271986961364746
Test Loss:  0.654609203338623
Valid Loss:  0.6498525738716125
Epoch:  9  	Training Loss: 0.6271833181381226
Test Loss:  0.6545929908752441
Valid Loss:  0.649842381477356
Epoch:  10  	Training Loss: 0.6271678805351257
Test Loss:  0.6545764207839966
Valid Loss:  0.6498318910598755
Epoch:  11  	Training Loss: 0.6271517872810364
Test Loss:  0.654559850692749
Valid Loss:  0.649821400642395
Epoch:  12  	Training Loss: 0.6271356344223022
Test Loss:  0.6545082926750183
Valid Loss:  0.6497820019721985
Epoch:  13  	Training Loss: 0.6270818710327148
Test Loss:  0.6544491052627563
Valid Loss:  0.649735689163208
Epoch:  14  	Training Loss: 0.6270267367362976
Test Loss:  0.6543889045715332
Valid Loss:  0.6496836543083191
Epoch:  15  	Training Loss: 0.6269711256027222
Test Loss:  0.6543254256248474
Valid Loss:  0.6496288776397705
Epoch:  16  	Training Loss: 0.6269103288650513
Test Loss:  0.6542599201202393
Valid Loss:  0.6495683193206787
Epoch:  17  	Training Loss: 0.6268460154533386
Test Loss:  0.6541830897331238
Valid Loss:  0.6494930982589722
Epoch:  18  	Training Loss: 0.6267739534378052
Test Loss:  0.6540976762771606
Valid Loss:  0.6494147181510925
Epoch:  19  	Training Loss: 0.6266989707946777
Test Loss:  0.6539989709854126
Valid Loss:  0.6493322849273682
Epoch:  20  	Training Loss: 0.6266193389892578
Test Loss:  0.6538892984390259
Valid Loss:  0.6492437124252319
Epoch:  21  	Training Loss: 0.6265337467193604
Test Loss:  0.6537722945213318
Valid Loss:  0.6491508483886719
Epoch:  22  	Training Loss: 0.6264407634735107
Test Loss:  0.6536769866943359
Valid Loss:  0.6490734219551086
Epoch:  23  	Training Loss: 0.6263630390167236
Test Loss:  0.6535733938217163
Valid Loss:  0.6489896774291992
Epoch:  24  	Training Loss: 0.6262831687927246
Test Loss:  0.6534655094146729
Valid Loss:  0.6489048004150391
Epoch:  25  	Training Loss: 0.6261996030807495
Test Loss:  0.6533512473106384
Valid Loss:  0.6488164663314819
Epoch:  26  	Training Loss: 0.6261106729507446
Test Loss:  0.6532317399978638
Valid Loss:  0.6487234830856323
Epoch:  27  	Training Loss: 0.6260164380073547
Test Loss:  0.6530996561050415
Valid Loss:  0.6486167311668396
Epoch:  28  	Training Loss: 0.6259133815765381
Test Loss:  0.6529499292373657
Valid Loss:  0.6484966278076172
Epoch:  29  	Training Loss: 0.6258029937744141
Test Loss:  0.6527887582778931
Valid Loss:  0.6483734250068665
Epoch:  30  	Training Loss: 0.6256856918334961
Test Loss:  0.6526115536689758
Valid Loss:  0.6482425928115845
Epoch:  31  	Training Loss: 0.6255545020103455
Test Loss:  0.6524257063865662
Valid Loss:  0.6481071710586548
Epoch:  32  	Training Loss: 0.625417947769165
Test Loss:  0.6522607207298279
Valid Loss:  0.6479746699333191
Epoch:  33  	Training Loss: 0.6252870559692383
Test Loss:  0.6520906686782837
Valid Loss:  0.6478281617164612
Epoch:  34  	Training Loss: 0.6251495480537415
Test Loss:  0.6519172787666321
Valid Loss:  0.6476761102676392
Epoch:  35  	Training Loss: 0.625004231929779
Test Loss:  0.6517369747161865
Valid Loss:  0.647505521774292
Epoch:  36  	Training Loss: 0.624847948551178
Test Loss:  0.6515514850616455
Valid Loss:  0.6473276019096375
Epoch:  37  	Training Loss: 0.6246829032897949
Test Loss:  0.6513562798500061
Valid Loss:  0.6471446752548218
Epoch:  38  	Training Loss: 0.6245090961456299
Test Loss:  0.6511521339416504
Valid Loss:  0.64695143699646
Epoch:  39  	Training Loss: 0.6243302822113037
Test Loss:  0.6509352922439575
Valid Loss:  0.6467406749725342
Epoch:  40  	Training Loss: 0.6241457462310791
Test Loss:  0.650712251663208
Valid Loss:  0.6465194225311279
Epoch:  41  	Training Loss: 0.623954713344574
Test Loss:  0.6504822969436646
Valid Loss:  0.646277904510498
Epoch:  42  	Training Loss: 0.6237589120864868
Test Loss:  0.6502085328102112
Valid Loss:  0.645988404750824
Epoch:  43  	Training Loss: 0.6235126852989197
Test Loss:  0.6498996615409851
Valid Loss:  0.6456739902496338
Epoch:  44  	Training Loss: 0.623254120349884
Test Loss:  0.6495833396911621
Valid Loss:  0.6453479528427124
Epoch:  45  	Training Loss: 0.6229860186576843
Test Loss:  0.6492459774017334
Valid Loss:  0.6450076699256897
Epoch:  46  	Training Loss: 0.6227055191993713
Test Loss:  0.6488922834396362
Valid Loss:  0.644648551940918
Epoch:  47  	Training Loss: 0.6224021911621094
Test Loss:  0.6485172510147095
Valid Loss:  0.6442692279815674
Epoch:  48  	Training Loss: 0.6220875978469849
Test Loss:  0.6481325030326843
Valid Loss:  0.6438801288604736
Epoch:  49  	Training Loss: 0.6217537522315979
Test Loss:  0.6477248072624207
Valid Loss:  0.6434733867645264
Epoch:  50  	Training Loss: 0.6213845014572144
Test Loss:  0.6472785472869873
Valid Loss:  0.6430466175079346
Epoch:  51  	Training Loss: 0.6209897994995117
Test Loss:  0.6468177437782288
Valid Loss:  0.6426089406013489
Epoch:  52  	Training Loss: 0.6205853223800659
Test Loss:  0.6463652849197388
Valid Loss:  0.642166018486023
Epoch:  53  	Training Loss: 0.6201882362365723
Test Loss:  0.6458697319030762
Valid Loss:  0.6416907906532288
Epoch:  54  	Training Loss: 0.619753360748291
Test Loss:  0.6453350186347961
Valid Loss:  0.6411855816841125
Epoch:  55  	Training Loss: 0.619275689125061
Test Loss:  0.6447612643241882
Valid Loss:  0.6406494379043579
Epoch:  56  	Training Loss: 0.6187430620193481
Test Loss:  0.6441513299942017
Valid Loss:  0.6400782465934753
Epoch:  57  	Training Loss: 0.6181718707084656
Test Loss:  0.643512487411499
Valid Loss:  0.6394819021224976
Epoch:  58  	Training Loss: 0.6175612807273865
Test Loss:  0.6428412199020386
Valid Loss:  0.6388109922409058
Epoch:  59  	Training Loss: 0.6169081926345825
Test Loss:  0.6421706080436707
Valid Loss:  0.6381405591964722
Epoch:  60  	Training Loss: 0.6162558794021606
Test Loss:  0.64150071144104
Valid Loss:  0.6374707818031311
Epoch:  61  	Training Loss: 0.6156042814254761
Test Loss:  0.6408315896987915
Valid Loss:  0.6368017196655273
Epoch:  62  	Training Loss: 0.614953339099884
Test Loss:  0.6400427222251892
Valid Loss:  0.6360088586807251
Epoch:  63  	Training Loss: 0.6141817569732666
Test Loss:  0.6392546892166138
Valid Loss:  0.6352170705795288
Epoch:  64  	Training Loss: 0.6134111881256104
Test Loss:  0.6384677290916443
Valid Loss:  0.6344262361526489
Epoch:  65  	Training Loss: 0.6126415729522705
Test Loss:  0.6376817226409912
Valid Loss:  0.6336364150047302
Epoch:  66  	Training Loss: 0.6118729710578918
Test Loss:  0.6368967890739441
Valid Loss:  0.6328475475311279
Epoch:  67  	Training Loss: 0.6111053228378296
Test Loss:  0.6361127495765686
Valid Loss:  0.6320598125457764
Epoch:  68  	Training Loss: 0.6103386878967285
Test Loss:  0.6353297233581543
Valid Loss:  0.6312729120254517
Epoch:  69  	Training Loss: 0.6095730066299438
Test Loss:  0.6345475912094116
Valid Loss:  0.6304870843887329
Epoch:  70  	Training Loss: 0.6088082790374756
Test Loss:  0.6337665915489197
Valid Loss:  0.6297022104263306
Epoch:  71  	Training Loss: 0.6080445051193237
Test Loss:  0.6329865455627441
Valid Loss:  0.6289184093475342
Epoch:  72  	Training Loss: 0.6072818040847778
Test Loss:  0.6323004961013794
Valid Loss:  0.6282315850257874
Epoch:  73  	Training Loss: 0.6066135168075562
Test Loss:  0.6316152811050415
Valid Loss:  0.6275455355644226
Epoch:  74  	Training Loss: 0.6059460639953613
Test Loss:  0.6309306621551514
Valid Loss:  0.6268601417541504
Epoch:  75  	Training Loss: 0.6052793264389038
Test Loss:  0.6302468776702881
Valid Loss:   15%|█▌        | 75/500 [00:54<04:24,  1.61it/s] 15%|█▌        | 77/500 [00:54<03:13,  2.19it/s] 16%|█▌        | 79/500 [00:54<02:25,  2.89it/s] 16%|█▌        | 81/500 [01:01<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:01<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:08<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:46,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:08<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:08<02:16,  2.94it/s] 20%|██        | 101/500 [01:14<07:51,  1.18s/it] 21%|██        | 103/500 [01:15<05:37,  1.18it/s] 21%|██        | 105/500 [01:15<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:15<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:15<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:21<07:43,  1.19s/it] 23%|██▎       | 113/500 [01:22<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:22<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:22<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:22<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:28<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:25,  1.21s/it] 27%|██▋       | 133/500 [01:35<05:17,  1.15it/s] 27%|██▋       | 135/500 [01:36<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:36<02:46,  2.18it/s] 28%|██▊       | 139/500 [01:36<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:42<07:04,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:02,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:43<01:59,  2.93it/s]0.626175582408905
Epoch:  76  	Training Loss: 0.6046132445335388
Test Loss:  0.6295638680458069
Valid Loss:  0.625491738319397
Epoch:  77  	Training Loss: 0.6039479970932007
Test Loss:  0.6288815140724182
Valid Loss:  0.6248086094856262
Epoch:  78  	Training Loss: 0.6032833456993103
Test Loss:  0.6281998753547668
Valid Loss:  0.6241261959075928
Epoch:  79  	Training Loss: 0.602619469165802
Test Loss:  0.6275190114974976
Valid Loss:  0.6234445571899414
Epoch:  80  	Training Loss: 0.601956307888031
Test Loss:  0.6268388032913208
Valid Loss:  0.6227636933326721
Epoch:  81  	Training Loss: 0.6012938022613525
Test Loss:  0.6261594295501709
Valid Loss:  0.6220834851264954
Epoch:  82  	Training Loss: 0.6006320714950562
Test Loss:  0.6255208253860474
Valid Loss:  0.6214457750320435
Epoch:  83  	Training Loss: 0.6000118255615234
Test Loss:  0.6248828768730164
Valid Loss:  0.6208087205886841
Epoch:  84  	Training Loss: 0.5993920564651489
Test Loss:  0.6242455244064331
Valid Loss:  0.6201722621917725
Epoch:  85  	Training Loss: 0.5987730026245117
Test Loss:  0.6236089468002319
Valid Loss:  0.6195364594459534
Epoch:  86  	Training Loss: 0.5981544852256775
Test Loss:  0.6229729056358337
Valid Loss:  0.6189013719558716
Epoch:  87  	Training Loss: 0.5975366830825806
Test Loss:  0.6223375201225281
Valid Loss:  0.6182669401168823
Epoch:  88  	Training Loss: 0.5969195365905762
Test Loss:  0.6217029094696045
Valid Loss:  0.6176331043243408
Epoch:  89  	Training Loss: 0.5963030457496643
Test Loss:  0.6210688352584839
Valid Loss:  0.6169999837875366
Epoch:  90  	Training Loss: 0.5956871509552002
Test Loss:  0.6204354763031006
Valid Loss:  0.6163674592971802
Epoch:  91  	Training Loss: 0.5950719118118286
Test Loss:  0.619802713394165
Valid Loss:  0.6157355904579163
Epoch:  92  	Training Loss: 0.5944573283195496
Test Loss:  0.6191918849945068
Valid Loss:  0.6151266098022461
Epoch:  93  	Training Loss: 0.5938649773597717
Test Loss:  0.6185815334320068
Valid Loss:  0.6145181655883789
Epoch:  94  	Training Loss: 0.5932732224464417
Test Loss:  0.6179717779159546
Valid Loss:  0.6139103174209595
Epoch:  95  	Training Loss: 0.5926820039749146
Test Loss:  0.6173627376556396
Valid Loss:  0.6133030652999878
Epoch:  96  	Training Loss: 0.5920913219451904
Test Loss:  0.6167541742324829
Valid Loss:  0.6126964688301086
Epoch:  97  	Training Loss: 0.5915012955665588
Test Loss:  0.6161462068557739
Valid Loss:  0.6120903491973877
Epoch:  98  	Training Loss: 0.5909118056297302
Test Loss:  0.6155388355255127
Valid Loss:  0.6114847660064697
Epoch:  99  	Training Loss: 0.5903229117393494
Test Loss:  0.6149320602416992
Valid Loss:  0.6108798980712891
Epoch:  100  	Training Loss: 0.5897345542907715
Test Loss:  0.6143258810043335
Valid Loss:  0.6102755069732666
Epoch:  101  	Training Loss: 0.5891467332839966
Test Loss:  0.613720178604126
Valid Loss:  0.6096717715263367
Epoch:  102  	Training Loss: 0.5885595083236694
Test Loss:  0.6131280064582825
Valid Loss:  0.6090819835662842
Epoch:  103  	Training Loss: 0.5879858732223511
Test Loss:  0.6125363707542419
Valid Loss:  0.6084928512573242
Epoch:  104  	Training Loss: 0.5874128937721252
Test Loss:  0.6119452714920044
Valid Loss:  0.6079041957855225
Epoch:  105  	Training Loss: 0.5868403911590576
Test Loss:  0.6113547682762146
Valid Loss:  0.6073161363601685
Epoch:  106  	Training Loss: 0.5862685441970825
Test Loss:  0.6107648611068726
Valid Loss:  0.6067286729812622
Epoch:  107  	Training Loss: 0.5856972336769104
Test Loss:  0.610175609588623
Valid Loss:  0.6061418652534485
Epoch:  108  	Training Loss: 0.5851264595985413
Test Loss:  0.6095868349075317
Valid Loss:  0.605555534362793
Epoch:  109  	Training Loss: 0.5845562219619751
Test Loss:  0.6089986562728882
Valid Loss:  0.60496985912323
Epoch:  110  	Training Loss: 0.5839866399765015
Test Loss:  0.6084110736846924
Valid Loss:  0.6043846607208252
Epoch:  111  	Training Loss: 0.583417534828186
Test Loss:  0.6078240871429443
Valid Loss:  0.6038001775741577
Epoch:  112  	Training Loss: 0.5828490853309631
Test Loss:  0.6072467565536499
Valid Loss:  0.603225588798523
Epoch:  113  	Training Loss: 0.5822902917861938
Test Loss:  0.6066699624061584
Valid Loss:  0.6026515960693359
Epoch:  114  	Training Loss: 0.5817321538925171
Test Loss:  0.6060937643051147
Valid Loss:  0.6020781993865967
Epoch:  115  	Training Loss: 0.5811746120452881
Test Loss:  0.605518102645874
Valid Loss:  0.6015053987503052
Epoch:  116  	Training Loss: 0.5806174278259277
Test Loss:  0.6049429178237915
Valid Loss:  0.6009330749511719
Epoch:  117  	Training Loss: 0.5800608992576599
Test Loss:  0.6043683886528015
Valid Loss:  0.6003612875938416
Epoch:  118  	Training Loss: 0.5795048475265503
Test Loss:  0.6037943363189697
Valid Loss:  0.5997899770736694
Epoch:  119  	Training Loss: 0.5789493322372437
Test Loss:  0.6032207608222961
Valid Loss:  0.5992192625999451
Epoch:  120  	Training Loss: 0.57839435338974
Test Loss:  0.6026477813720703
Valid Loss:  0.5986491441726685
Epoch:  121  	Training Loss: 0.5778398513793945
Test Loss:  0.6020753383636475
Valid Loss:  0.59807950258255
Epoch:  122  	Training Loss: 0.5772859454154968
Test Loss:  0.6015092134475708
Valid Loss:  0.5975162982940674
Epoch:  123  	Training Loss: 0.5767382979393005
Test Loss:  0.6009435653686523
Valid Loss:  0.5969537496566772
Epoch:  124  	Training Loss: 0.5761911869049072
Test Loss:  0.6003783941268921
Valid Loss:  0.5963916778564453
Epoch:  125  	Training Loss: 0.5756446719169617
Test Loss:  0.5998139381408691
Valid Loss:  0.5958302021026611
Epoch:  126  	Training Loss: 0.5750986337661743
Test Loss:  0.5992498993873596
Valid Loss:  0.5952692031860352
Epoch:  127  	Training Loss: 0.5745531320571899
Test Loss:  0.5986863970756531
Valid Loss:  0.5947087407112122
Epoch:  128  	Training Loss: 0.5740081667900085
Test Loss:  0.5981234908103943
Valid Loss:  0.5941488742828369
Epoch:  129  	Training Loss: 0.5734637379646301
Test Loss:  0.5975611209869385
Valid Loss:  0.5935894846916199
Epoch:  130  	Training Loss: 0.5729197859764099
Test Loss:  0.5969992876052856
Valid Loss:  0.5930307507514954
Epoch:  131  	Training Loss: 0.5723763704299927
Test Loss:  0.596437931060791
Valid Loss:  0.5924723744392395
Epoch:  132  	Training Loss: 0.5718334913253784
Test Loss:  0.5958819389343262
Valid Loss:  0.5919195413589478
Epoch:  133  	Training Loss: 0.5712959170341492
Test Loss:  0.5953263640403748
Valid Loss:  0.5913671851158142
Epoch:  134  	Training Loss: 0.5707588791847229
Test Loss:  0.5947713851928711
Valid Loss:  0.5908153057098389
Epoch:  135  	Training Loss: 0.5702222585678101
Test Loss:  0.5942168831825256
Valid Loss:  0.5902640223503113
Epoch:  136  	Training Loss: 0.5696861743927002
Test Loss:  0.5936628580093384
Valid Loss:  0.5897132158279419
Epoch:  137  	Training Loss: 0.5691506266593933
Test Loss:  0.5931094884872437
Valid Loss:  0.5891629457473755
Epoch:  138  	Training Loss: 0.5686155557632446
Test Loss:  0.5925565958023071
Valid Loss:  0.5886132717132568
Epoch:  139  	Training Loss: 0.5680810809135437
Test Loss:  0.5920042395591736
Valid Loss:  0.5880640149116516
Epoch:  140  	Training Loss: 0.5675470232963562
Test Loss:  0.5914523601531982
Valid Loss:  0.5875153541564941
Epoch:  141  	Training Loss: 0.5670135021209717
Test Loss:  0.5909010171890259
Valid Loss:  0.5869671702384949
Epoch:  142  	Training Loss: 0.5664804577827454
Test Loss:  0.590354323387146
Valid Loss:  0.5864236950874329
Epoch:  143  	Training Loss: 0.5659520626068115
Test Loss:  0.5898081064224243
Valid Loss:  0.5858807563781738
Epoch:  144  	Training Loss: 0.5654240846633911
Test Loss:  0.5892623662948608
Valid Loss:  0.5853382349014282
Epoch:  145  	Training Loss: 0.5648965835571289
Test Loss:  0.5887171030044556
Valid Loss:  0.5847963094711304
Epoch:  146  	Training Loss: 0.5643696784973145
Test Loss:  0.588172435760498
Valid Loss:  0.5842548608779907
Epoch:  147  	Training Loss: 0.5638431906700134
Test Loss:  0.5876282453536987
Valid Loss:  0.5837138891220093
Epoch:  148  	Training Loss: 0.5633171796798706
Test Loss:  0.5870844125747681
Valid Loss:  0.583173394203186
Epoch:  149  	Training Loss: 0.5627917051315308
Test Loss:  0.5865412950515747
Valid Loss:  0.5826334357261658
 30%|███       | 151/500 [01:49<07:04,  1.22s/it] 31%|███       | 153/500 [01:49<05:02,  1.15it/s] 31%|███       | 155/500 [01:49<03:37,  1.59it/s] 31%|███▏      | 157/500 [01:50<02:37,  2.17it/s] 32%|███▏      | 159/500 [01:50<01:56,  2.93it/s] 32%|███▏      | 161/500 [01:56<06:45,  1.20s/it] 33%|███▎      | 163/500 [01:56<04:49,  1.17it/s] 33%|███▎      | 165/500 [01:56<03:28,  1.61it/s] 33%|███▎      | 167/500 [01:57<02:33,  2.17it/s] 34%|███▍      | 169/500 [01:57<01:53,  2.91it/s] 34%|███▍      | 171/500 [02:03<06:34,  1.20s/it] 35%|███▍      | 173/500 [02:03<04:40,  1.16it/s] 35%|███▌      | 175/500 [02:03<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:03<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:04<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:10<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:10<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:10<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:10<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:11<01:47,  2.90it/s] 38%|███▊      | 191/500 [02:17<06:13,  1.21s/it] 39%|███▊      | 193/500 [02:17<04:26,  1.15it/s] 39%|███▉      | 195/500 [02:17<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:17<02:20,  2.16it/s] 40%|███▉      | 199/500 [02:18<01:43,  2.91it/s] 40%|████      | 201/500 [02:24<05:56,  1.19s/it] 41%|████      | 203/500 [02:24<04:13,  1.17it/s] 41%|████      | 205/500 [02:24<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:24<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:24<01:39,  2.91it/s] 42%|████▏     | 211/500 [02:31<05:39,  1.17s/it] 43%|████▎     | 213/500 [02:31<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:31<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:31<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:31<01:35,  2.93it/s] 44%|████▍     | 221/500 [02:38<05:30,  1.18s/it] 45%|████▍     | 223/500 [02:38<03:55,  1.18it/s]Epoch:  150  	Training Loss: 0.5622666478157043
Test Loss:  0.5859985947608948
Valid Loss:  0.5820940136909485
Epoch:  151  	Training Loss: 0.5617421865463257
Test Loss:  0.5854564309120178
Valid Loss:  0.5815550088882446
Epoch:  152  	Training Loss: 0.5612182021141052
Test Loss:  0.5849179029464722
Valid Loss:  0.5810198187828064
Epoch:  153  	Training Loss: 0.5606977939605713
Test Loss:  0.5843797922134399
Valid Loss:  0.5804850459098816
Epoch:  154  	Training Loss: 0.5601778626441956
Test Loss:  0.5838422179222107
Valid Loss:  0.5799508094787598
Epoch:  155  	Training Loss: 0.559658408164978
Test Loss:  0.5833051204681396
Valid Loss:  0.5794170498847961
Epoch:  156  	Training Loss: 0.5591393709182739
Test Loss:  0.5827685594558716
Valid Loss:  0.578883707523346
Epoch:  157  	Training Loss: 0.5586209297180176
Test Loss:  0.5822324156761169
Valid Loss:  0.5783509016036987
Epoch:  158  	Training Loss: 0.5581028461456299
Test Loss:  0.5816968083381653
Valid Loss:  0.5778186321258545
Epoch:  159  	Training Loss: 0.5575853586196899
Test Loss:  0.581161618232727
Valid Loss:  0.5772867202758789
Epoch:  160  	Training Loss: 0.5570682287216187
Test Loss:  0.5806270241737366
Valid Loss:  0.5767553448677063
Epoch:  161  	Training Loss: 0.5565516352653503
Test Loss:  0.5800927877426147
Valid Loss:  0.5762244462966919
Epoch:  162  	Training Loss: 0.5560355186462402
Test Loss:  0.5795605182647705
Valid Loss:  0.5756954550743103
Epoch:  163  	Training Loss: 0.5555211305618286
Test Loss:  0.5790287256240845
Valid Loss:  0.5751670002937317
Epoch:  164  	Training Loss: 0.5550073385238647
Test Loss:  0.5784974098205566
Valid Loss:  0.5746389627456665
Epoch:  165  	Training Loss: 0.5544940233230591
Test Loss:  0.577966570854187
Valid Loss:  0.5741115212440491
Epoch:  166  	Training Loss: 0.5539811849594116
Test Loss:  0.5774362087249756
Valid Loss:  0.5735846161842346
Epoch:  167  	Training Loss: 0.5534688830375671
Test Loss:  0.5769064426422119
Valid Loss:  0.5730580687522888
Epoch:  168  	Training Loss: 0.5529569983482361
Test Loss:  0.5763771533966064
Valid Loss:  0.5725321173667908
Epoch:  169  	Training Loss: 0.552445650100708
Test Loss:  0.575848400592804
Valid Loss:  0.5720066428184509
Epoch:  170  	Training Loss: 0.5519347786903381
Test Loss:  0.5753200054168701
Valid Loss:  0.5714817047119141
Epoch:  171  	Training Loss: 0.5514243841171265
Test Loss:  0.5747922658920288
Valid Loss:  0.5709571838378906
Epoch:  172  	Training Loss: 0.550914466381073
Test Loss:  0.5742663145065308
Valid Loss:  0.5704345703125
Epoch:  173  	Training Loss: 0.5504064559936523
Test Loss:  0.5737410187721252
Valid Loss:  0.5699125528335571
Epoch:  174  	Training Loss: 0.5498989224433899
Test Loss:  0.5732160806655884
Valid Loss:  0.5693910717964172
Epoch:  175  	Training Loss: 0.5493919253349304
Test Loss:  0.5726916790008545
Valid Loss:  0.568869948387146
Epoch:  176  	Training Loss: 0.5488853454589844
Test Loss:  0.5721677541732788
Valid Loss:  0.5683493614196777
Epoch:  177  	Training Loss: 0.5483792424201965
Test Loss:  0.5716443061828613
Valid Loss:  0.5678292512893677
Epoch:  178  	Training Loss: 0.5478734970092773
Test Loss:  0.5711212158203125
Valid Loss:  0.5673096179962158
Epoch:  179  	Training Loss: 0.5473682880401611
Test Loss:  0.5705987215042114
Valid Loss:  0.5667904615402222
Epoch:  180  	Training Loss: 0.5468636155128479
Test Loss:  0.5700767040252686
Valid Loss:  0.5662717223167419
Epoch:  181  	Training Loss: 0.5463593602180481
Test Loss:  0.5695551633834839
Valid Loss:  0.5657534599304199
Epoch:  182  	Training Loss: 0.5458555221557617
Test Loss:  0.5690349340438843
Valid Loss:  0.5652365684509277
Epoch:  183  	Training Loss: 0.5453530550003052
Test Loss:  0.5685151815414429
Valid Loss:  0.5647202134132385
Epoch:  184  	Training Loss: 0.5448510646820068
Test Loss:  0.5679959058761597
Valid Loss:  0.5642043352127075
Epoch:  185  	Training Loss: 0.5443495512008667
Test Loss:  0.5674771666526794
Valid Loss:  0.5636888742446899
Epoch:  186  	Training Loss: 0.54384845495224
Test Loss:  0.5669587850570679
Valid Loss:  0.5631738305091858
Epoch:  187  	Training Loss: 0.5433478355407715
Test Loss:  0.5664409399032593
Valid Loss:  0.5626593828201294
Epoch:  188  	Training Loss: 0.5428476333618164
Test Loss:  0.5659235715866089
Valid Loss:  0.5621453523635864
Epoch:  189  	Training Loss: 0.5423479676246643
Test Loss:  0.5654066801071167
Valid Loss:  0.5616317987442017
Epoch:  190  	Training Loss: 0.5418487787246704
Test Loss:  0.5648902654647827
Valid Loss:  0.5611187219619751
Epoch:  191  	Training Loss: 0.5413498878479004
Test Loss:  0.5643743276596069
Valid Loss:  0.5606061220169067
Epoch:  192  	Training Loss: 0.5408515930175781
Test Loss:  0.5638589262962341
Valid Loss:  0.5600940585136414
Epoch:  193  	Training Loss: 0.5403538942337036
Test Loss:  0.5633440017700195
Valid Loss:  0.5595825910568237
Epoch:  194  	Training Loss: 0.5398566126823425
Test Loss:  0.5628296136856079
Valid Loss:  0.5590714812278748
Epoch:  195  	Training Loss: 0.5393598079681396
Test Loss:  0.5623155832290649
Valid Loss:  0.558560848236084
Epoch:  196  	Training Loss: 0.5388634204864502
Test Loss:  0.5618021488189697
Valid Loss:  0.5580506920814514
Epoch:  197  	Training Loss: 0.538367509841919
Test Loss:  0.5612891316413879
Valid Loss:  0.5575410723686218
Epoch:  198  	Training Loss: 0.5378721356391907
Test Loss:  0.5607765913009644
Valid Loss:  0.5570319294929504
Epoch:  199  	Training Loss: 0.537377119064331
Test Loss:  0.5602645874023438
Valid Loss:  0.5565232038497925
Epoch:  200  	Training Loss: 0.5368826389312744
Test Loss:  0.5597530603408813
Valid Loss:  0.5560150146484375
Epoch:  201  	Training Loss: 0.536388635635376
Test Loss:  0.5592419505119324
Valid Loss:  0.5555073022842407
Epoch:  202  	Training Loss: 0.5358949899673462
Test Loss:  0.5587310791015625
Valid Loss:  0.554999828338623
Epoch:  203  	Training Loss: 0.5354017019271851
Test Loss:  0.5582207441329956
Valid Loss:  0.5544927716255188
Epoch:  204  	Training Loss: 0.5349088907241821
Test Loss:  0.5577108860015869
Valid Loss:  0.5539861917495728
Epoch:  205  	Training Loss: 0.5344164967536926
Test Loss:  0.5572013854980469
Valid Loss:  0.5534801483154297
Epoch:  206  	Training Loss: 0.5339245796203613
Test Loss:  0.556692361831665
Valid Loss:  0.5529744625091553
Epoch:  207  	Training Loss: 0.5334329605102539
Test Loss:  0.5561838746070862
Valid Loss:  0.5524693727493286
Epoch:  208  	Training Loss: 0.532941997051239
Test Loss:  0.5556758642196655
Valid Loss:  0.5519646406173706
Epoch:  209  	Training Loss: 0.5324513912200928
Test Loss:  0.5551682710647583
Valid Loss:  0.551460325717926
Epoch:  210  	Training Loss: 0.53196120262146
Test Loss:  0.5546610951423645
Valid Loss:  0.5509566068649292
Epoch:  211  	Training Loss: 0.5314715504646301
Test Loss:  0.5541544556617737
Valid Loss:  0.5504533052444458
Epoch:  212  	Training Loss: 0.530982255935669
Test Loss:  0.5536478161811829
Valid Loss:  0.5499500036239624
Epoch:  213  	Training Loss: 0.5304930806159973
Test Loss:  0.553141713142395
Valid Loss:  0.5494471788406372
Epoch:  214  	Training Loss: 0.5300043821334839
Test Loss:  0.5526360273361206
Valid Loss:  0.548944890499115
Epoch:  215  	Training Loss: 0.5295161008834839
Test Loss:  0.5521307587623596
Valid Loss:  0.548443078994751
Epoch:  216  	Training Loss: 0.5290282964706421
Test Loss:  0.5516260862350464
Valid Loss:  0.5479416847229004
Epoch:  217  	Training Loss: 0.5285409092903137
Test Loss:  0.5511218309402466
Valid Loss:  0.547440767288208
Epoch:  218  	Training Loss: 0.5280539989471436
Test Loss:  0.5506179928779602
Valid Loss:  0.5469403266906738
Epoch:  219  	Training Loss: 0.5275675654411316
Test Loss:  0.5501147508621216
Valid Loss:  0.5464403629302979
Epoch:  220  	Training Loss: 0.5270816087722778
Test Loss:  0.5496118664741516
Valid Loss:  0.5459407567977905
Epoch:  221  	Training Loss: 0.5265960693359375
Test Loss:  0.5491094589233398
Valid Loss:  0.545441746711731
Epoch:  222  	Training Loss: 0.5261108875274658
Test Loss:  0.5486066341400146
Valid Loss:  0.5449422597885132
Epoch:  223  	Training Loss: 0.5256254076957703
Test Loss:  0.5481042861938477
Valid Loss:  0.5444432497024536
 45%|████▌     | 225/500 [02:38<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:38<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:38<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:45<05:21,  1.20s/it] 47%|████▋     | 233/500 [02:45<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:45<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:45<01:59,  2.20it/s] 48%|████▊     | 239/500 [02:45<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:51<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:52<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:52<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:52<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:52<01:24,  2.98it/s] 50%|█████     | 251/500 [02:58<04:58,  1.20s/it] 51%|█████     | 253/500 [02:58<03:32,  1.16it/s] 51%|█████     | 255/500 [02:59<02:32,  1.61it/s] 51%|█████▏    | 257/500 [02:59<01:50,  2.20it/s] 52%|█████▏    | 259/500 [02:59<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:05<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:05<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:05<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:06<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:06<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:12<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:12<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:12<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:12<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:12<01:13,  3.03it/s] 56%|█████▌    | 281/500 [03:19<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:19<03:01,  1.20it/s] 57%|█████▋    | 285/500 [03:19<02:09,  1.65it/s] 57%|█████▋    | 287/500 [03:19<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:19<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:26<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:26<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:26<02:06,  1.62it/s]Epoch:  224  	Training Loss: 0.5251404047012329
Test Loss:  0.5476024150848389
Valid Loss:  0.5439447164535522
Epoch:  225  	Training Loss: 0.524655818939209
Test Loss:  0.5471009612083435
Valid Loss:  0.5434466600418091
Epoch:  226  	Training Loss: 0.5241717100143433
Test Loss:  0.5466000437736511
Valid Loss:  0.5429490804672241
Epoch:  227  	Training Loss: 0.5236880779266357
Test Loss:  0.5460995435714722
Valid Loss:  0.5424519777297974
Epoch:  228  	Training Loss: 0.5232048630714417
Test Loss:  0.5455995798110962
Valid Loss:  0.5419552326202393
Epoch:  229  	Training Loss: 0.5227221250534058
Test Loss:  0.5451000332832336
Valid Loss:  0.5414590835571289
Epoch:  230  	Training Loss: 0.5222398042678833
Test Loss:  0.5446009635925293
Valid Loss:  0.540963351726532
Epoch:  231  	Training Loss: 0.521757960319519
Test Loss:  0.5441023111343384
Valid Loss:  0.5404680967330933
Epoch:  232  	Training Loss: 0.5212765336036682
Test Loss:  0.543602705001831
Valid Loss:  0.5399717092514038
Epoch:  233  	Training Loss: 0.520794153213501
Test Loss:  0.5431034564971924
Valid Loss:  0.5394759178161621
Epoch:  234  	Training Loss: 0.5203121900558472
Test Loss:  0.5426048040390015
Valid Loss:  0.5389805436134338
Epoch:  235  	Training Loss: 0.5198307633399963
Test Loss:  0.5421064496040344
Valid Loss:  0.538485586643219
Epoch:  236  	Training Loss: 0.5193496942520142
Test Loss:  0.5416086316108704
Valid Loss:  0.5379911661148071
Epoch:  237  	Training Loss: 0.5188690423965454
Test Loss:  0.5411112904548645
Valid Loss:  0.5374971628189087
Epoch:  238  	Training Loss: 0.5183888673782349
Test Loss:  0.5406143665313721
Valid Loss:  0.5370035767555237
Epoch:  239  	Training Loss: 0.5179092288017273
Test Loss:  0.5401179790496826
Valid Loss:  0.5365104675292969
Epoch:  240  	Training Loss: 0.5174298882484436
Test Loss:  0.5396219491958618
Valid Loss:  0.5360178351402283
Epoch:  241  	Training Loss: 0.5169510841369629
Test Loss:  0.539126455783844
Valid Loss:  0.5355256199836731
Epoch:  242  	Training Loss: 0.5164726972579956
Test Loss:  0.5386302471160889
Valid Loss:  0.5350327491760254
Epoch:  243  	Training Loss: 0.5159937143325806
Test Loss:  0.5381344556808472
Valid Loss:  0.5345402956008911
Epoch:  244  	Training Loss: 0.5155150890350342
Test Loss:  0.5376392602920532
Valid Loss:  0.5340484380722046
Epoch:  245  	Training Loss: 0.5150370001792908
Test Loss:  0.5371444225311279
Valid Loss:  0.5335569381713867
Epoch:  246  	Training Loss: 0.514559268951416
Test Loss:  0.5366500616073608
Valid Loss:  0.533065915107727
Epoch:  247  	Training Loss: 0.5140820145606995
Test Loss:  0.5361560583114624
Valid Loss:  0.532575249671936
Epoch:  248  	Training Loss: 0.5136052370071411
Test Loss:  0.5356626510620117
Valid Loss:  0.5320851802825928
Epoch:  249  	Training Loss: 0.5131288766860962
Test Loss:  0.5351696610450745
Valid Loss:  0.5315954685211182
Epoch:  250  	Training Loss: 0.5126529932022095
Test Loss:  0.5346770882606506
Valid Loss:  0.5311062335968018
Epoch:  251  	Training Loss: 0.5121774673461914
Test Loss:  0.5341850519180298
Valid Loss:  0.5306174755096436
Epoch:  252  	Training Loss: 0.5117024183273315
Test Loss:  0.5336917042732239
Valid Loss:  0.5301275849342346
Epoch:  253  	Training Loss: 0.511226236820221
Test Loss:  0.533198893070221
Valid Loss:  0.5296380519866943
Epoch:  254  	Training Loss: 0.5107505321502686
Test Loss:  0.5327064990997314
Valid Loss:  0.5291489958763123
Epoch:  255  	Training Loss: 0.5102752447128296
Test Loss:  0.5322146415710449
Valid Loss:  0.5286604166030884
Epoch:  256  	Training Loss: 0.5098004341125488
Test Loss:  0.5317232012748718
Valid Loss:  0.5281723141670227
Epoch:  257  	Training Loss: 0.5093261003494263
Test Loss:  0.5312322378158569
Valid Loss:  0.5276846289634705
Epoch:  258  	Training Loss: 0.5088521242141724
Test Loss:  0.5307416915893555
Valid Loss:  0.5271974802017212
Epoch:  259  	Training Loss: 0.5083786249160767
Test Loss:  0.5302516222000122
Valid Loss:  0.5267106890678406
Epoch:  260  	Training Loss: 0.5079056024551392
Test Loss:  0.5297620296478271
Valid Loss:  0.5262243747711182
Epoch:  261  	Training Loss: 0.5074329376220703
Test Loss:  0.5292729139328003
Valid Loss:  0.525738537311554
Epoch:  262  	Training Loss: 0.5069608092308044
Test Loss:  0.5287827253341675
Valid Loss:  0.5252517461776733
Epoch:  263  	Training Loss: 0.5064876675605774
Test Loss:  0.5282930135726929
Valid Loss:  0.5247653126716614
Epoch:  264  	Training Loss: 0.5060149431228638
Test Loss:  0.5278037786483765
Valid Loss:  0.5242793560028076
Epoch:  265  	Training Loss: 0.5055427551269531
Test Loss:  0.5273149013519287
Valid Loss:  0.5237939357757568
Epoch:  266  	Training Loss: 0.5050709247589111
Test Loss:  0.5268265008926392
Valid Loss:  0.5233088731765747
Epoch:  267  	Training Loss: 0.5045995116233826
Test Loss:  0.5263386964797974
Valid Loss:  0.5228242874145508
Epoch:  268  	Training Loss: 0.5041285753250122
Test Loss:  0.5258512496948242
Valid Loss:  0.5223401784896851
Epoch:  269  	Training Loss: 0.5036580562591553
Test Loss:  0.5253642201423645
Valid Loss:  0.521856427192688
Epoch:  270  	Training Loss: 0.5031880140304565
Test Loss:  0.524877667427063
Valid Loss:  0.5213732123374939
Epoch:  271  	Training Loss: 0.5027183890342712
Test Loss:  0.5243915915489197
Valid Loss:  0.5208904147148132
Epoch:  272  	Training Loss: 0.5022492408752441
Test Loss:  0.5239039659500122
Valid Loss:  0.5204061269760132
Epoch:  273  	Training Loss: 0.5017785429954529
Test Loss:  0.5234167575836182
Valid Loss:  0.5199222564697266
Epoch:  274  	Training Loss: 0.5013083219528198
Test Loss:  0.5229300260543823
Valid Loss:  0.5194388628005981
Epoch:  275  	Training Loss: 0.500838577747345
Test Loss:  0.5224437713623047
Valid Loss:  0.5189558863639832
Epoch:  276  	Training Loss: 0.5003692507743835
Test Loss:  0.5219579935073853
Valid Loss:  0.5184733867645264
Epoch:  277  	Training Loss: 0.49990034103393555
Test Loss:  0.5214725732803345
Valid Loss:  0.5179913640022278
Epoch:  278  	Training Loss: 0.49943190813064575
Test Loss:  0.5209877490997314
Valid Loss:  0.5175098180770874
Epoch:  279  	Training Loss: 0.4989639222621918
Test Loss:  0.5205032825469971
Valid Loss:  0.5170285701751709
Epoch:  280  	Training Loss: 0.49849629402160645
Test Loss:  0.5200192928314209
Valid Loss:  0.5165479183197021
Epoch:  281  	Training Loss: 0.4980291724205017
Test Loss:  0.5195357203483582
Valid Loss:  0.5160676836967468
Epoch:  282  	Training Loss: 0.4975625276565552
Test Loss:  0.5190508365631104
Valid Loss:  0.5155860781669617
Epoch:  283  	Training Loss: 0.4970945119857788
Test Loss:  0.5185664296150208
Valid Loss:  0.5151050090789795
Epoch:  284  	Training Loss: 0.49662700295448303
Test Loss:  0.5180824995040894
Valid Loss:  0.5146243572235107
Epoch:  285  	Training Loss: 0.4961598813533783
Test Loss:  0.5175989866256714
Valid Loss:  0.5141440629959106
Epoch:  286  	Training Loss: 0.49569326639175415
Test Loss:  0.5171159505844116
Valid Loss:  0.5136643648147583
Epoch:  287  	Training Loss: 0.49522706866264343
Test Loss:  0.5166332721710205
Valid Loss:  0.5131850242614746
Epoch:  288  	Training Loss: 0.49476131796836853
Test Loss:  0.5161512494087219
Valid Loss:  0.5127062797546387
Epoch:  289  	Training Loss: 0.49429601430892944
Test Loss:  0.515669584274292
Valid Loss:  0.5122278928756714
Epoch:  290  	Training Loss: 0.49383118748664856
Test Loss:  0.5151883363723755
Valid Loss:  0.5117499232292175
Epoch:  291  	Training Loss: 0.4933667778968811
Test Loss:  0.5147075653076172
Valid Loss:  0.5112724304199219
Epoch:  292  	Training Loss: 0.4929027557373047
Test Loss:  0.5142253637313843
Valid Loss:  0.5107935667037964
Epoch:  293  	Training Loss: 0.4924374222755432
Test Loss:  0.5137436985969543
Valid Loss:  0.5103152394294739
Epoch:  294  	Training Loss: 0.49197256565093994
Test Loss:  0.5132625102996826
Valid Loss:  0.5098372101783752
Epoch:  295  	Training Loss: 0.4915081560611725
Test Loss:  0.5127817392349243
Valid Loss:  0.5093597173690796
Epoch:  296  	Training Loss: 0.49104416370391846
Test Loss:  0.5123013854026794
Valid Loss:  0.5088827013969421
Epoch:  297  	Training Loss: 0.49058061838150024
Test Loss:  0.5118215084075928
Valid Loss:   59%|█████▉    | 297/500 [03:26<01:32,  2.18it/s] 60%|█████▉    | 299/500 [03:26<01:08,  2.92it/s] 60%|██████    | 301/500 [03:32<03:53,  1.17s/it] 61%|██████    | 303/500 [03:33<02:45,  1.19it/s] 61%|██████    | 305/500 [03:33<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:33<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:33<01:04,  2.95it/s] 62%|██████▏   | 311/500 [03:39<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:39<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:39<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:40<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:40<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:46<03:35,  1.20s/it] 65%|██████▍   | 323/500 [03:46<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:47<01:50,  1.59it/s] 65%|██████▌   | 327/500 [03:47<01:20,  2.15it/s] 66%|██████▌   | 329/500 [03:47<00:59,  2.90it/s] 66%|██████▌   | 331/500 [03:53<03:25,  1.22s/it] 67%|██████▋   | 333/500 [03:53<02:26,  1.14it/s] 67%|██████▋   | 335/500 [03:54<01:45,  1.56it/s] 67%|██████▋   | 337/500 [03:54<01:16,  2.14it/s] 68%|██████▊   | 339/500 [03:54<00:55,  2.88it/s] 68%|██████▊   | 341/500 [04:00<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:00<02:14,  1.17it/s] 69%|██████▉   | 345/500 [04:01<01:36,  1.61it/s] 69%|██████▉   | 347/500 [04:01<01:09,  2.20it/s] 70%|██████▉   | 349/500 [04:01<00:50,  2.97it/s] 70%|███████   | 351/500 [04:07<02:56,  1.19s/it] 71%|███████   | 353/500 [04:07<02:05,  1.18it/s] 71%|███████   | 355/500 [04:07<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:08<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:08<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:14<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:14<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:14<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:14<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:14<00:43,  3.00it/s]0.5084061026573181
Epoch:  298  	Training Loss: 0.49011749029159546
Test Loss:  0.5113421082496643
Valid Loss:  0.5079300403594971
Epoch:  299  	Training Loss: 0.4896548390388489
Test Loss:  0.510863184928894
Valid Loss:  0.5074543356895447
Epoch:  300  	Training Loss: 0.4891926646232605
Test Loss:  0.5103846788406372
Valid Loss:  0.5069791078567505
Epoch:  301  	Training Loss: 0.48873090744018555
Test Loss:  0.5099066495895386
Valid Loss:  0.5065043568611145
Epoch:  302  	Training Loss: 0.488269567489624
Test Loss:  0.5094270706176758
Valid Loss:  0.5060280561447144
Epoch:  303  	Training Loss: 0.4878067970275879
Test Loss:  0.5089479684829712
Valid Loss:  0.5055522918701172
Epoch:  304  	Training Loss: 0.4873444437980652
Test Loss:  0.5084693431854248
Valid Loss:  0.5050768852233887
Epoch:  305  	Training Loss: 0.4868825078010559
Test Loss:  0.5079911351203918
Valid Loss:  0.5046018958091736
Epoch:  306  	Training Loss: 0.48642104864120483
Test Loss:  0.5075134038925171
Valid Loss:  0.5041275024414062
Epoch:  307  	Training Loss: 0.4859600067138672
Test Loss:  0.5070360898971558
Valid Loss:  0.5036534667015076
Epoch:  308  	Training Loss: 0.48549944162368774
Test Loss:  0.5065592527389526
Valid Loss:  0.5031799077987671
Epoch:  309  	Training Loss: 0.48503929376602173
Test Loss:  0.5060828924179077
Valid Loss:  0.50270676612854
Epoch:  310  	Training Loss: 0.48457959294319153
Test Loss:  0.5056069493293762
Valid Loss:  0.5022341012954712
Epoch:  311  	Training Loss: 0.48412036895751953
Test Loss:  0.5051314830780029
Valid Loss:  0.5017619132995605
Epoch:  312  	Training Loss: 0.4836615025997162
Test Loss:  0.504654049873352
Valid Loss:  0.5012876987457275
Epoch:  313  	Training Loss: 0.4832007884979248
Test Loss:  0.5041769742965698
Valid Loss:  0.5008139610290527
Epoch:  314  	Training Loss: 0.4827404320240021
Test Loss:  0.5037003755569458
Valid Loss:  0.5003407001495361
Epoch:  315  	Training Loss: 0.48228058218955994
Test Loss:  0.5032243132591248
Valid Loss:  0.4998677968978882
Epoch:  316  	Training Loss: 0.48182111978530884
Test Loss:  0.5027486681938171
Valid Loss:  0.4993954598903656
Epoch:  317  	Training Loss: 0.48136216402053833
Test Loss:  0.502273440361023
Valid Loss:  0.49892348051071167
Epoch:  318  	Training Loss: 0.48090359568595886
Test Loss:  0.5017987489700317
Valid Loss:  0.49845197796821594
Epoch:  319  	Training Loss: 0.4804455041885376
Test Loss:  0.5013244152069092
Valid Loss:  0.4979809522628784
Epoch:  320  	Training Loss: 0.4799878001213074
Test Loss:  0.5008505582809448
Valid Loss:  0.4975103735923767
Epoch:  321  	Training Loss: 0.47953060269355774
Test Loss:  0.5003771781921387
Valid Loss:  0.4970402121543884
Epoch:  322  	Training Loss: 0.47907376289367676
Test Loss:  0.4999024271965027
Valid Loss:  0.4965687394142151
Epoch:  323  	Training Loss: 0.4786156713962555
Test Loss:  0.4994280934333801
Valid Loss:  0.4960976839065552
Epoch:  324  	Training Loss: 0.47815802693367004
Test Loss:  0.49895423650741577
Valid Loss:  0.49562710523605347
Epoch:  325  	Training Loss: 0.477700799703598
Test Loss:  0.49848082661628723
Valid Loss:  0.4951569437980652
Epoch:  326  	Training Loss: 0.47724398970603943
Test Loss:  0.4980078637599945
Valid Loss:  0.4946872591972351
Epoch:  327  	Training Loss: 0.47678765654563904
Test Loss:  0.4975354075431824
Valid Loss:  0.49421802163124084
Epoch:  328  	Training Loss: 0.4763317406177521
Test Loss:  0.49706339836120605
Valid Loss:  0.4937492311000824
Epoch:  329  	Training Loss: 0.4758763015270233
Test Loss:  0.49659183621406555
Valid Loss:  0.49328094720840454
Epoch:  330  	Training Loss: 0.47542130947113037
Test Loss:  0.49612075090408325
Valid Loss:  0.4928130507469177
Epoch:  331  	Training Loss: 0.47496676445007324
Test Loss:  0.4956500828266144
Valid Loss:  0.4923456311225891
Epoch:  332  	Training Loss: 0.47451263666152954
Test Loss:  0.49517762660980225
Valid Loss:  0.491876482963562
Epoch:  333  	Training Loss: 0.47405678033828735
Test Loss:  0.4947056770324707
Valid Loss:  0.49140775203704834
Epoch:  334  	Training Loss: 0.4736013412475586
Test Loss:  0.4942341148853302
Valid Loss:  0.4909394383430481
Epoch:  335  	Training Loss: 0.4731464087963104
Test Loss:  0.4937629699707031
Valid Loss:  0.49047157168388367
Epoch:  336  	Training Loss: 0.4726918339729309
Test Loss:  0.49329230189323425
Valid Loss:  0.49000418186187744
Epoch:  337  	Training Loss: 0.4722377061843872
Test Loss:  0.49282214045524597
Valid Loss:  0.48953720927238464
Epoch:  338  	Training Loss: 0.4717840552330017
Test Loss:  0.49235236644744873
Valid Loss:  0.4890706539154053
Epoch:  339  	Training Loss: 0.47133079171180725
Test Loss:  0.4918830394744873
Valid Loss:  0.4886046051979065
Epoch:  340  	Training Loss: 0.4708779752254486
Test Loss:  0.4914141595363617
Valid Loss:  0.48813891410827637
Epoch:  341  	Training Loss: 0.470425546169281
Test Loss:  0.4909457564353943
Valid Loss:  0.4876737594604492
Epoch:  342  	Training Loss: 0.469973623752594
Test Loss:  0.49047550559043884
Valid Loss:  0.48720672726631165
Epoch:  343  	Training Loss: 0.4695199131965637
Test Loss:  0.4900056719779968
Valid Loss:  0.4867401123046875
Epoch:  344  	Training Loss: 0.4690666198730469
Test Loss:  0.489536315202713
Valid Loss:  0.48627403378486633
Epoch:  345  	Training Loss: 0.46861377358436584
Test Loss:  0.4890673756599426
Valid Loss:  0.4858083128929138
Epoch:  346  	Training Loss: 0.46816134452819824
Test Loss:  0.4885989725589752
Valid Loss:  0.4853431284427643
Epoch:  347  	Training Loss: 0.46770939230918884
Test Loss:  0.48813095688819885
Valid Loss:  0.4848783314228058
Epoch:  348  	Training Loss: 0.46725785732269287
Test Loss:  0.4876634478569031
Valid Loss:  0.4844140112400055
Epoch:  349  	Training Loss: 0.4668067693710327
Test Loss:  0.48719629645347595
Valid Loss:  0.483950138092041
Epoch:  350  	Training Loss: 0.466356098651886
Test Loss:  0.4867296814918518
Valid Loss:  0.48348674178123474
Epoch:  351  	Training Loss: 0.46590590476989746
Test Loss:  0.4862635135650635
Valid Loss:  0.4830237627029419
Epoch:  352  	Training Loss: 0.46545615792274475
Test Loss:  0.4857957363128662
Valid Loss:  0.4825592041015625
Epoch:  353  	Training Loss: 0.4650048613548279
Test Loss:  0.4853283762931824
Valid Loss:  0.48209503293037415
Epoch:  354  	Training Loss: 0.46455395221710205
Test Loss:  0.48486149311065674
Valid Loss:  0.48163145780563354
Epoch:  355  	Training Loss: 0.4641035795211792
Test Loss:  0.4843950867652893
Valid Loss:  0.4811682105064392
Epoch:  356  	Training Loss: 0.463653564453125
Test Loss:  0.4839291572570801
Valid Loss:  0.48070546984672546
Epoch:  357  	Training Loss: 0.463204026222229
Test Loss:  0.4834635853767395
Valid Loss:  0.48024314641952515
Epoch:  358  	Training Loss: 0.46275490522384644
Test Loss:  0.48299849033355713
Valid Loss:  0.47978127002716064
Epoch:  359  	Training Loss: 0.4623062014579773
Test Loss:  0.48253393173217773
Valid Loss:  0.47931984066963196
Epoch:  360  	Training Loss: 0.46185794472694397
Test Loss:  0.482069730758667
Valid Loss:  0.4788588881492615
Epoch:  361  	Training Loss: 0.46141016483306885
Test Loss:  0.48160600662231445
Valid Loss:  0.4783984124660492
Epoch:  362  	Training Loss: 0.46096277236938477
Test Loss:  0.481140673160553
Valid Loss:  0.4779362380504608
Epoch:  363  	Training Loss: 0.4605138301849365
Test Loss:  0.4806758165359497
Valid Loss:  0.4774746000766754
Epoch:  364  	Training Loss: 0.4600653648376465
Test Loss:  0.48021140694618225
Valid Loss:  0.47701340913772583
Epoch:  365  	Training Loss: 0.45961734652519226
Test Loss:  0.47974738478660583
Valid Loss:  0.4765526056289673
Epoch:  366  	Training Loss: 0.45916974544525146
Test Loss:  0.47928386926651
Valid Loss:  0.47609227895736694
Epoch:  367  	Training Loss: 0.4587225615978241
Test Loss:  0.4788208603858948
Valid Loss:  0.4756324291229248
Epoch:  368  	Training Loss: 0.45827585458755493
Test Loss:  0.4783582091331482
Valid Loss:  0.4751729965209961
Epoch:  369  	Training Loss: 0.4578295350074768
Test Loss:  0.4778960347175598
Valid Loss:  0.4747140407562256
Epoch:  370  	Training Loss: 0.4573837220668793
Test Loss:  0.477434366941452
Valid Loss:  0.4742555320262909
 74%|███████▍  | 371/500 [04:21<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:21<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:21<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:21<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:21<00:39,  3.03it/s] 76%|███████▌  | 381/500 [04:27<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:28<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:28<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:28<00:50,  2.26it/s] 78%|███████▊  | 389/500 [04:28<00:36,  3.03it/s] 78%|███████▊  | 391/500 [04:34<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:34<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:35<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:35<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:35<00:33,  3.01it/s] 80%|████████  | 401/500 [04:41<01:54,  1.15s/it] 81%|████████  | 403/500 [04:41<01:20,  1.21it/s] 81%|████████  | 405/500 [04:41<00:56,  1.67it/s] 81%|████████▏ | 407/500 [04:41<00:40,  2.28it/s] 82%|████████▏ | 409/500 [04:42<00:29,  3.06it/s] 82%|████████▏ | 411/500 [04:48<01:45,  1.19s/it] 83%|████████▎ | 413/500 [04:48<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:48<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:48<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:48<00:27,  2.98it/s] 84%|████████▍ | 421/500 [04:55<01:34,  1.19s/it] 85%|████████▍ | 423/500 [04:55<01:05,  1.17it/s] 85%|████████▌ | 425/500 [04:55<00:46,  1.62it/s] 85%|████████▌ | 427/500 [04:55<00:33,  2.21it/s] 86%|████████▌ | 429/500 [04:55<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:02<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:02<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:02<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:02<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:02<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:08<01:08,  1.16s/it] 89%|████████▊ | 443/500 [05:09<00:47,  1.20it/s]Epoch:  371  	Training Loss: 0.45693835616111755
Test Loss:  0.47697311639785767
Valid Loss:  0.47379744052886963
Epoch:  372  	Training Loss: 0.4564933776855469
Test Loss:  0.4765103757381439
Valid Loss:  0.47333791851997375
Epoch:  373  	Training Loss: 0.4560469686985016
Test Loss:  0.4760481119155884
Valid Loss:  0.4728788137435913
Epoch:  374  	Training Loss: 0.4556010067462921
Test Loss:  0.47558626532554626
Valid Loss:  0.47242018580436707
Epoch:  375  	Training Loss: 0.45515549182891846
Test Loss:  0.47512489557266235
Valid Loss:  0.471962034702301
Epoch:  376  	Training Loss: 0.4547104239463806
Test Loss:  0.47466397285461426
Valid Loss:  0.471504271030426
Epoch:  377  	Training Loss: 0.4542658030986786
Test Loss:  0.47420352697372437
Valid Loss:  0.47104698419570923
Epoch:  378  	Training Loss: 0.45382159948349
Test Loss:  0.4737434685230255
Valid Loss:  0.47059011459350586
Epoch:  379  	Training Loss: 0.4533778429031372
Test Loss:  0.47328388690948486
Valid Loss:  0.4701337218284607
Epoch:  380  	Training Loss: 0.45293450355529785
Test Loss:  0.47282475233078003
Valid Loss:  0.46967777609825134
Epoch:  381  	Training Loss: 0.4524916112422943
Test Loss:  0.4723660945892334
Valid Loss:  0.4692222476005554
Epoch:  382  	Training Loss: 0.4520491659641266
Test Loss:  0.4719056785106659
Valid Loss:  0.4687650203704834
Epoch:  383  	Training Loss: 0.45160505175590515
Test Loss:  0.4714456796646118
Valid Loss:  0.4683082401752472
Epoch:  384  	Training Loss: 0.45116132497787476
Test Loss:  0.47098612785339355
Valid Loss:  0.4678518772125244
Epoch:  385  	Training Loss: 0.4507180452346802
Test Loss:  0.47052711248397827
Valid Loss:  0.46739599108695984
Epoch:  386  	Training Loss: 0.4502752125263214
Test Loss:  0.47006848454475403
Valid Loss:  0.4669405221939087
Epoch:  387  	Training Loss: 0.4498327970504761
Test Loss:  0.469610333442688
Valid Loss:  0.46648553013801575
Epoch:  388  	Training Loss: 0.44939088821411133
Test Loss:  0.4691525995731354
Valid Loss:  0.46603095531463623
Epoch:  389  	Training Loss: 0.44894933700561523
Test Loss:  0.4686953127384186
Valid Loss:  0.46557682752609253
Epoch:  390  	Training Loss: 0.44850823283195496
Test Loss:  0.4682385325431824
Valid Loss:  0.4651232063770294
Epoch:  391  	Training Loss: 0.4480676054954529
Test Loss:  0.4677821397781372
Valid Loss:  0.46467000246047974
Epoch:  392  	Training Loss: 0.44762736558914185
Test Loss:  0.4673237204551697
Valid Loss:  0.4642147421836853
Epoch:  393  	Training Loss: 0.447185218334198
Test Loss:  0.4668657183647156
Valid Loss:  0.4637599289417267
Epoch:  394  	Training Loss: 0.4467434287071228
Test Loss:  0.4664081931114197
Valid Loss:  0.4633055627346039
Epoch:  395  	Training Loss: 0.4463021159172058
Test Loss:  0.465951144695282
Valid Loss:  0.4628516435623169
Epoch:  396  	Training Loss: 0.44586122035980225
Test Loss:  0.4654945433139801
Valid Loss:  0.4623981714248657
Epoch:  397  	Training Loss: 0.4454208016395569
Test Loss:  0.46503832936286926
Valid Loss:  0.46194517612457275
Epoch:  398  	Training Loss: 0.4449807405471802
Test Loss:  0.464582622051239
Valid Loss:  0.4614925980567932
Epoch:  399  	Training Loss: 0.44454115629196167
Test Loss:  0.4641273319721222
Valid Loss:  0.4610404372215271
Epoch:  400  	Training Loss: 0.444102019071579
Test Loss:  0.4636724889278412
Valid Loss:  0.46058881282806396
Epoch:  401  	Training Loss: 0.4436632990837097
Test Loss:  0.463218092918396
Valid Loss:  0.4601375460624695
Epoch:  402  	Training Loss: 0.44322502613067627
Test Loss:  0.46276241540908813
Valid Loss:  0.45968496799468994
Epoch:  403  	Training Loss: 0.44278550148010254
Test Loss:  0.4623071551322937
Valid Loss:  0.4592328667640686
Epoch:  404  	Training Loss: 0.44234636425971985
Test Loss:  0.4618523418903351
Valid Loss:  0.4587811827659607
Epoch:  405  	Training Loss: 0.44190770387649536
Test Loss:  0.46139800548553467
Valid Loss:  0.45833003520965576
Epoch:  406  	Training Loss: 0.4414694607257843
Test Loss:  0.46094411611557007
Valid Loss:  0.4578792452812195
Epoch:  407  	Training Loss: 0.44103169441223145
Test Loss:  0.4604906737804413
Valid Loss:  0.4574289321899414
Epoch:  408  	Training Loss: 0.44059431552886963
Test Loss:  0.4600377082824707
Valid Loss:  0.45697909593582153
Epoch:  409  	Training Loss: 0.440157413482666
Test Loss:  0.45958516001701355
Valid Loss:  0.4565296769142151
Epoch:  410  	Training Loss: 0.43972092866897583
Test Loss:  0.4591330885887146
Valid Loss:  0.45608073472976685
Epoch:  411  	Training Loss: 0.43928489089012146
Test Loss:  0.4586814343929291
Valid Loss:  0.45563220977783203
Epoch:  412  	Training Loss: 0.4388492703437805
Test Loss:  0.45822781324386597
Valid Loss:  0.45518171787261963
Epoch:  413  	Training Loss: 0.43841177225112915
Test Loss:  0.45777463912963867
Valid Loss:  0.45473170280456543
Epoch:  414  	Training Loss: 0.4379746615886688
Test Loss:  0.4573219418525696
Valid Loss:  0.45428210496902466
Epoch:  415  	Training Loss: 0.4375380277633667
Test Loss:  0.45686963200569153
Valid Loss:  0.4538329541683197
Epoch:  416  	Training Loss: 0.4371017813682556
Test Loss:  0.45641782879829407
Valid Loss:  0.45338428020477295
Epoch:  417  	Training Loss: 0.43666601181030273
Test Loss:  0.4559664726257324
Valid Loss:  0.4529360234737396
Epoch:  418  	Training Loss: 0.43623068928718567
Test Loss:  0.4555155038833618
Valid Loss:  0.4524881839752197
Epoch:  419  	Training Loss: 0.43579575419425964
Test Loss:  0.4550650715827942
Valid Loss:  0.4520408511161804
Epoch:  420  	Training Loss: 0.43536126613616943
Test Loss:  0.45461505651474
Valid Loss:  0.45159393548965454
Epoch:  421  	Training Loss: 0.4349272847175598
Test Loss:  0.45416539907455444
Valid Loss:  0.4511474668979645
Epoch:  422  	Training Loss: 0.43449366092681885
Test Loss:  0.4537142217159271
Valid Loss:  0.4506993889808655
Epoch:  423  	Training Loss: 0.4340584874153137
Test Loss:  0.4532634913921356
Valid Loss:  0.4502517580986023
Epoch:  424  	Training Loss: 0.4336237609386444
Test Loss:  0.45281317830085754
Valid Loss:  0.4498046040534973
Epoch:  425  	Training Loss: 0.4331894516944885
Test Loss:  0.4523633122444153
Valid Loss:  0.449357807636261
Epoch:  426  	Training Loss: 0.43275558948516846
Test Loss:  0.45191389322280884
Valid Loss:  0.44891154766082764
Epoch:  427  	Training Loss: 0.4323221445083618
Test Loss:  0.4514649510383606
Valid Loss:  0.4484656751155853
Epoch:  428  	Training Loss: 0.4318891763687134
Test Loss:  0.45101648569107056
Valid Loss:  0.4480202794075012
Epoch:  429  	Training Loss: 0.43145662546157837
Test Loss:  0.45056837797164917
Valid Loss:  0.44757530093193054
Epoch:  430  	Training Loss: 0.4310244917869568
Test Loss:  0.45012080669403076
Valid Loss:  0.44713079929351807
Epoch:  431  	Training Loss: 0.43059277534484863
Test Loss:  0.4496736228466034
Valid Loss:  0.4466867446899414
Epoch:  432  	Training Loss: 0.4301615357398987
Test Loss:  0.44922512769699097
Valid Loss:  0.4462413191795349
Epoch:  433  	Training Loss: 0.42972898483276367
Test Loss:  0.44877707958221436
Valid Loss:  0.4457963705062866
Epoch:  434  	Training Loss: 0.4292968809604645
Test Loss:  0.44832944869995117
Valid Loss:  0.44535183906555176
Epoch:  435  	Training Loss: 0.4288651943206787
Test Loss:  0.4478822946548462
Valid Loss:  0.4449077844619751
Epoch:  436  	Training Loss: 0.42843395471572876
Test Loss:  0.447435587644577
Valid Loss:  0.44446417689323425
Epoch:  437  	Training Loss: 0.4280031621456146
Test Loss:  0.44698935747146606
Valid Loss:  0.4440210163593292
Epoch:  438  	Training Loss: 0.4275727868080139
Test Loss:  0.4465435743331909
Valid Loss:  0.44357830286026
Epoch:  439  	Training Loss: 0.4271428883075714
Test Loss:  0.4460982084274292
Valid Loss:  0.4431360363960266
Epoch:  440  	Training Loss: 0.42671340703964233
Test Loss:  0.4456532895565033
Valid Loss:  0.44269418716430664
Epoch:  441  	Training Loss: 0.4262843132019043
Test Loss:  0.4452088475227356
Valid Loss:  0.44225284457206726
Epoch:  442  	Training Loss: 0.42585569620132446
Test Loss:  0.4447629451751709
Valid Loss:  0.4418100118637085
Epoch:  443  	Training Loss: 0.42542564868927
Test Loss:  0.44431746006011963
Valid Loss:  0.44136762619018555
 89%|████████▉ | 445/500 [05:09<00:33,  1.66it/s] 89%|████████▉ | 447/500 [05:09<00:23,  2.27it/s] 90%|████████▉ | 449/500 [05:09<00:16,  3.06it/s] 90%|█████████ | 451/500 [05:15<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:15<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:16<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:16<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:16<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:22<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:22<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:23<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:23<00:15,  2.19it/s] 94%|█████████▍| 469/500 [05:23<00:10,  2.95it/s] 94%|█████████▍| 471/500 [05:29<00:34,  1.21s/it] 95%|█████████▍| 473/500 [05:29<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:30<00:15,  1.60it/s] 95%|█████████▌| 477/500 [05:30<00:10,  2.19it/s] 96%|█████████▌| 479/500 [05:30<00:07,  2.90it/s] 96%|█████████▌| 481/500 [05:37<00:23,  1.23s/it] 97%|█████████▋| 483/500 [05:37<00:15,  1.12it/s] 97%|█████████▋| 485/500 [05:37<00:09,  1.54it/s] 97%|█████████▋| 487/500 [05:37<00:06,  2.09it/s] 98%|█████████▊| 489/500 [05:37<00:03,  2.81it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:44<00:06,  1.15it/s] 99%|█████████▉| 495/500 [05:44<00:03,  1.57it/s] 99%|█████████▉| 497/500 [05:44<00:01,  2.13it/s]100%|█████████▉| 499/500 [05:44<00:00,  2.82it/s]100%|██████████| 500/500 [05:44<00:00,  1.45it/s]
Epoch:  444  	Training Loss: 0.4249960780143738
Test Loss:  0.4438724219799042
Valid Loss:  0.440925657749176
Epoch:  445  	Training Loss: 0.4245668947696686
Test Loss:  0.4434278607368469
Valid Loss:  0.4404841661453247
Epoch:  446  	Training Loss: 0.4241381287574768
Test Loss:  0.4429836869239807
Valid Loss:  0.44004306197166443
Epoch:  447  	Training Loss: 0.42370980978012085
Test Loss:  0.4425399899482727
Valid Loss:  0.43960243463516235
Epoch:  448  	Training Loss: 0.4232819676399231
Test Loss:  0.4420967698097229
Valid Loss:  0.43916231393814087
Epoch:  449  	Training Loss: 0.42285454273223877
Test Loss:  0.4416539669036865
Valid Loss:  0.43872255086898804
Epoch:  450  	Training Loss: 0.4224275052547455
Test Loss:  0.44121164083480835
Valid Loss:  0.4382832646369934
Epoch:  451  	Training Loss: 0.4220009446144104
Test Loss:  0.44076967239379883
Valid Loss:  0.4378443956375122
Epoch:  452  	Training Loss: 0.42157480120658875
Test Loss:  0.4403263330459595
Valid Loss:  0.4374040961265564
Epoch:  453  	Training Loss: 0.4211472272872925
Test Loss:  0.43988344073295593
Valid Loss:  0.4369642734527588
Epoch:  454  	Training Loss: 0.4207201600074768
Test Loss:  0.4394410252571106
Valid Loss:  0.4365249276161194
Epoch:  455  	Training Loss: 0.42029350996017456
Test Loss:  0.4389989972114563
Valid Loss:  0.43608593940734863
Epoch:  456  	Training Loss: 0.41986727714538574
Test Loss:  0.4385574758052826
Valid Loss:  0.43564745783805847
Epoch:  457  	Training Loss: 0.41944149136543274
Test Loss:  0.4381163716316223
Valid Loss:  0.4352094233036041
Epoch:  458  	Training Loss: 0.41901618242263794
Test Loss:  0.4376757740974426
Valid Loss:  0.4347718358039856
Epoch:  459  	Training Loss: 0.4185912609100342
Test Loss:  0.43723559379577637
Valid Loss:  0.4343346953392029
Epoch:  460  	Training Loss: 0.41816678643226624
Test Loss:  0.43679583072662354
Valid Loss:  0.433898001909256
Epoch:  461  	Training Loss: 0.4177427589893341
Test Loss:  0.4363565444946289
Valid Loss:  0.4334617257118225
Epoch:  462  	Training Loss: 0.4173191487789154
Test Loss:  0.43591588735580444
Valid Loss:  0.43302416801452637
Epoch:  463  	Training Loss: 0.41689425706863403
Test Loss:  0.4354757070541382
Valid Loss:  0.43258702754974365
Epoch:  464  	Training Loss: 0.4164698123931885
Test Loss:  0.4350360035896301
Valid Loss:  0.43215036392211914
Epoch:  465  	Training Loss: 0.41604578495025635
Test Loss:  0.4345967173576355
Valid Loss:  0.4317140579223633
Epoch:  466  	Training Loss: 0.41562220454216003
Test Loss:  0.4341578781604767
Valid Loss:  0.4312782883644104
Epoch:  467  	Training Loss: 0.4151991009712219
Test Loss:  0.4337195158004761
Valid Loss:  0.43084293603897095
Epoch:  468  	Training Loss: 0.41477638483047485
Test Loss:  0.4332816004753113
Valid Loss:  0.4304080605506897
Epoch:  469  	Training Loss: 0.4143540859222412
Test Loss:  0.4328441023826599
Valid Loss:  0.4299736022949219
Epoch:  470  	Training Loss: 0.41393226385116577
Test Loss:  0.43240708112716675
Valid Loss:  0.42953959107398987
Epoch:  471  	Training Loss: 0.41351085901260376
Test Loss:  0.4319705367088318
Valid Loss:  0.42910605669021606
Epoch:  472  	Training Loss: 0.41308993101119995
Test Loss:  0.4315321445465088
Valid Loss:  0.4286707043647766
Epoch:  473  	Training Loss: 0.4126672148704529
Test Loss:  0.43109428882598877
Valid Loss:  0.42823588848114014
Epoch:  474  	Training Loss: 0.4122450053691864
Test Loss:  0.43065690994262695
Valid Loss:  0.4278014898300171
Epoch:  475  	Training Loss: 0.41182324290275574
Test Loss:  0.4302199184894562
Valid Loss:  0.42736753821372986
Epoch:  476  	Training Loss: 0.4114018976688385
Test Loss:  0.4297834038734436
Valid Loss:  0.42693406343460083
Epoch:  477  	Training Loss: 0.4109809994697571
Test Loss:  0.42934733629226685
Valid Loss:  0.42650097608566284
Epoch:  478  	Training Loss: 0.4105604887008667
Test Loss:  0.4289117157459259
Valid Loss:  0.42606836557388306
Epoch:  479  	Training Loss: 0.4101404845714569
Test Loss:  0.4284765422344208
Valid Loss:  0.4256362318992615
Epoch:  480  	Training Loss: 0.40972089767456055
Test Loss:  0.42804184556007385
Valid Loss:  0.4252045154571533
Epoch:  481  	Training Loss: 0.4093017578125
Test Loss:  0.42760753631591797
Valid Loss:  0.4247732162475586
Epoch:  482  	Training Loss: 0.4088830053806305
Test Loss:  0.4271719455718994
Valid Loss:  0.4243405759334564
Epoch:  483  	Training Loss: 0.4084629416465759
Test Loss:  0.4267366826534271
Valid Loss:  0.4239083528518677
Epoch:  484  	Training Loss: 0.4080433249473572
Test Loss:  0.42630189657211304
Valid Loss:  0.42347657680511475
Epoch:  485  	Training Loss: 0.40762409567832947
Test Loss:  0.42586755752563477
Valid Loss:  0.42304521799087524
Epoch:  486  	Training Loss: 0.4072053134441376
Test Loss:  0.4254336357116699
Valid Loss:  0.42261433601379395
Epoch:  487  	Training Loss: 0.4067869782447815
Test Loss:  0.4250001907348633
Valid Loss:  0.4221838712692261
Epoch:  488  	Training Loss: 0.40636906027793884
Test Loss:  0.42456719279289246
Valid Loss:  0.4217538833618164
Epoch:  489  	Training Loss: 0.4059515595436096
Test Loss:  0.42413464188575745
Valid Loss:  0.42132431268692017
Epoch:  490  	Training Loss: 0.4055345058441162
Test Loss:  0.42370250821113586
Valid Loss:  0.42089521884918213
Epoch:  491  	Training Loss: 0.4051178991794586
Test Loss:  0.4232708513736725
Valid Loss:  0.42046651244163513
Epoch:  492  	Training Loss: 0.40470167994499207
Test Loss:  0.42283791303634644
Valid Loss:  0.42003655433654785
Epoch:  493  	Training Loss: 0.4042842984199524
Test Loss:  0.42240551114082336
Valid Loss:  0.41960713267326355
Epoch:  494  	Training Loss: 0.40386736392974854
Test Loss:  0.42197346687316895
Valid Loss:  0.4191780686378479
Epoch:  495  	Training Loss: 0.4034508466720581
Test Loss:  0.4215419292449951
Valid Loss:  0.41874951124191284
Epoch:  496  	Training Loss: 0.4030347466468811
Test Loss:  0.4211108386516571
Valid Loss:  0.418321430683136
Epoch:  497  	Training Loss: 0.4026191234588623
Test Loss:  0.4206801950931549
Valid Loss:  0.4178937077522278
Epoch:  498  	Training Loss: 0.4022039473056793
Test Loss:  0.4202499985694885
Valid Loss:  0.41746652126312256
Epoch:  499  	Training Loss: 0.401789128780365
Test Loss:  0.41982024908065796
Valid Loss:  0.41703975200653076
Epoch:  500  	Training Loss: 0.40137481689453125
Test Loss:  0.4193909466266632
Valid Loss:  0.41661337018013
seed is  16
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:58,  6.25s/it]  1%|          | 3/500 [00:06<13:54,  1.68s/it]  1%|          | 5/500 [00:06<07:05,  1.16it/s]  1%|▏         | 7/500 [00:06<04:22,  1.88it/s]  2%|▏         | 9/500 [00:06<02:57,  2.76it/s]  2%|▏         | 11/500 [00:13<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.21it/s]  4%|▍         | 19/500 [00:13<02:40,  3.01it/s]  4%|▍         | 21/500 [00:19<09:29,  1.19s/it]  5%|▍         | 23/500 [00:20<06:44,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.24it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:06,  1.16s/it]  7%|▋         | 33/500 [00:26<06:29,  1.20it/s]  7%|▋         | 35/500 [00:26<04:40,  1.66it/s]  7%|▋         | 37/500 [00:27<03:24,  2.26it/s]  8%|▊         | 39/500 [00:27<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<08:56,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.03it/s] 10%|█         | 51/500 [00:40<08:46,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.25it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.02it/s] 12%|█▏        | 61/500 [00:46<08:34,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:24,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.02it/s] 14%|█▍        | 71/500 [00:53<08:24,  1.18s/it]Epoch:  1  	Training Loss: 0.5441862344741821
Test Loss:  13.96603012084961
Valid Loss:  13.738943099975586
Epoch:  2  	Training Loss: 13.689342498779297
Test Loss:  55.0875244140625
Valid Loss:  54.669708251953125
Epoch:  3  	Training Loss: 53.506568908691406
Test Loss:  2.1563310623168945
Valid Loss:  2.1334426403045654
Epoch:  4  	Training Loss: 2.1406197547912598
Test Loss:  2.1560258865356445
Valid Loss:  2.133131980895996
Epoch:  5  	Training Loss: 2.140307903289795
Test Loss:  2.1557369232177734
Valid Loss:  2.1328318119049072
Epoch:  6  	Training Loss: 2.140015125274658
Test Loss:  2.1554737091064453
Valid Loss:  2.132538080215454
Epoch:  7  	Training Loss: 2.1397364139556885
Test Loss:  2.1552236080169678
Valid Loss:  2.1322524547576904
Epoch:  8  	Training Loss: 2.1394643783569336
Test Loss:  2.154975175857544
Valid Loss:  2.131969451904297
Epoch:  9  	Training Loss: 2.1391987800598145
Test Loss:  2.1547436714172363
Valid Loss:  2.13169527053833
Epoch:  10  	Training Loss: 2.1389451026916504
Test Loss:  2.154541015625
Valid Loss:  2.131427764892578
Epoch:  11  	Training Loss: 2.13869571685791
Test Loss:  2.154343605041504
Valid Loss:  2.1311728954315186
Epoch:  12  	Training Loss: 2.1384592056274414
Test Loss:  2.877143383026123
Valid Loss:  2.8176708221435547
Epoch:  13  	Training Loss: 2.7739200592041016
Test Loss:  1.1217083930969238
Valid Loss:  1.1172174215316772
Epoch:  14  	Training Loss: 1.1617306470870972
Test Loss:  1.1199216842651367
Valid Loss:  1.1154136657714844
Epoch:  15  	Training Loss: 1.1599922180175781
Test Loss:  1.1181743144989014
Valid Loss:  1.1136174201965332
Epoch:  16  	Training Loss: 1.1582698822021484
Test Loss:  1.116438627243042
Valid Loss:  1.1118359565734863
Epoch:  17  	Training Loss: 1.1565744876861572
Test Loss:  1.1149036884307861
Valid Loss:  1.1102614402770996
Epoch:  18  	Training Loss: 1.1551716327667236
Test Loss:  1.1141448020935059
Valid Loss:  1.109436273574829
Epoch:  19  	Training Loss: 1.1544313430786133
Test Loss:  1.1135777235031128
Valid Loss:  1.1088734865188599
Epoch:  20  	Training Loss: 1.1538962125778198
Test Loss:  1.1131949424743652
Valid Loss:  1.1084351539611816
Epoch:  21  	Training Loss: 1.1534783840179443
Test Loss:  1.1128947734832764
Valid Loss:  1.1080536842346191
Epoch:  22  	Training Loss: 1.1531164646148682
Test Loss:  1.0210614204406738
Valid Loss:  1.0193469524383545
Epoch:  23  	Training Loss: 1.0654640197753906
Test Loss:  1.0210391283035278
Valid Loss:  1.0193010568618774
Epoch:  24  	Training Loss: 1.065420150756836
Test Loss:  1.021004557609558
Valid Loss:  1.0192482471466064
Epoch:  25  	Training Loss: 1.0653619766235352
Test Loss:  1.0209347009658813
Valid Loss:  1.019178867340088
Epoch:  26  	Training Loss: 1.0652825832366943
Test Loss:  1.020860195159912
Valid Loss:  1.0190792083740234
Epoch:  27  	Training Loss: 1.0651934146881104
Test Loss:  1.0207781791687012
Valid Loss:  1.018951654434204
Epoch:  28  	Training Loss: 1.065089225769043
Test Loss:  1.0206918716430664
Valid Loss:  1.0188018083572388
Epoch:  29  	Training Loss: 1.0649751424789429
Test Loss:  1.0206010341644287
Valid Loss:  1.0186445713043213
Epoch:  30  	Training Loss: 1.0648391246795654
Test Loss:  1.0204657316207886
Valid Loss:  1.0184553861618042
Epoch:  31  	Training Loss: 1.0646566152572632
Test Loss:  1.0202510356903076
Valid Loss:  1.0182299613952637
Epoch:  32  	Training Loss: 1.0643965005874634
Test Loss:  0.8635683655738831
Valid Loss:  0.866719126701355
Epoch:  33  	Training Loss: 0.9161582589149475
Test Loss:  0.8604274988174438
Valid Loss:  0.8554309010505676
Epoch:  34  	Training Loss: 0.9017339944839478
Test Loss:  0.8381698727607727
Valid Loss:  0.8131349086761475
Epoch:  35  	Training Loss: 0.8596959114074707
Test Loss:  0.7269086837768555
Valid Loss:  0.6989960074424744
Epoch:  36  	Training Loss: 0.7267965078353882
Test Loss:  0.5424212217330933
Valid Loss:  0.5239559412002563
Epoch:  37  	Training Loss: 0.5281392335891724
Test Loss:  0.31646260619163513
Valid Loss:  0.31701284646987915
Epoch:  38  	Training Loss: 0.31424903869628906
Test Loss:  0.15205715596675873
Valid Loss:  0.15215608477592468
Epoch:  39  	Training Loss: 0.15621966123580933
Test Loss:  0.06452122330665588
Valid Loss:  0.06570623070001602
Epoch:  40  	Training Loss: 0.06997741758823395
Test Loss:  0.025624293833971024
Valid Loss:  0.027383282780647278
Epoch:  41  	Training Loss: 0.030604800209403038
Test Loss:  0.010700814425945282
Valid Loss:  0.012578587979078293
Epoch:  42  	Training Loss: 0.014630207791924477
Test Loss:  0.00579455029219389
Valid Loss:  0.007835997268557549
Epoch:  43  	Training Loss: 0.009177571162581444
Test Loss:  0.004456119611859322
Valid Loss:  0.006363867782056332
Epoch:  44  	Training Loss: 0.007339812349528074
Test Loss:  0.003766373498365283
Valid Loss:  0.005479387007653713
Epoch:  45  	Training Loss: 0.006247160956263542
Test Loss:  0.003253570292145014
Valid Loss:  0.004773886874318123
Epoch:  46  	Training Loss: 0.005406918935477734
Test Loss:  0.0028306995518505573
Valid Loss:  0.00418400252237916
Epoch:  47  	Training Loss: 0.004718915559351444
Test Loss:  0.0024754777550697327
Valid Loss:  0.0036893943324685097
Epoch:  48  	Training Loss: 0.004144715610891581
Test Loss:  0.0021818876266479492
Valid Loss:  0.0032857602927833796
Epoch:  49  	Training Loss: 0.0036701280623674393
Test Loss:  0.00204444769769907
Valid Loss:  0.0030551599338650703
Epoch:  50  	Training Loss: 0.0033815428614616394
Test Loss:  0.00198097201064229
Valid Loss:  0.002937337150797248
Epoch:  51  	Training Loss: 0.0031906147487461567
Test Loss:  0.0019319116836413741
Valid Loss:  0.0028410330414772034
Epoch:  52  	Training Loss: 0.003044977318495512
Test Loss:  0.0020334660075604916
Valid Loss:  0.0027121289167553186
Epoch:  53  	Training Loss: 0.0025578783825039864
Test Loss:  0.0016257015522569418
Valid Loss:  0.0023692771792411804
Epoch:  54  	Training Loss: 0.0023991786874830723
Test Loss:  0.0016623055562376976
Valid Loss:  0.0023487918078899384
Epoch:  55  	Training Loss: 0.0023033996112644672
Test Loss:  0.0015745421405881643
Valid Loss:  0.0022476734593510628
Epoch:  56  	Training Loss: 0.0022176990751177073
Test Loss:  0.0015349481254816055
Valid Loss:  0.0021813209168612957
Epoch:  57  	Training Loss: 0.0021363338455557823
Test Loss:  0.0014834165340289474
Valid Loss:  0.0021088530775159597
Epoch:  58  	Training Loss: 0.002058653859421611
Test Loss:  0.0014391225995495915
Valid Loss:  0.0020419738721102476
Epoch:  59  	Training Loss: 0.0019811829552054405
Test Loss:  0.0013948220293968916
Valid Loss:  0.0019758320413529873
Epoch:  60  	Training Loss: 0.0019049926195293665
Test Loss:  0.0013530328869819641
Valid Loss:  0.0019134130561724305
Epoch:  61  	Training Loss: 0.0018323102267459035
Test Loss:  0.0013132647145539522
Valid Loss:  0.0018490756629034877
Epoch:  62  	Training Loss: 0.0017602876760065556
Test Loss:  0.0011981988791376352
Valid Loss:  0.0017218277789652348
Epoch:  63  	Training Loss: 0.0016570056322962046
Test Loss:  0.0011190602090209723
Valid Loss:  0.0016268030740320683
Epoch:  64  	Training Loss: 0.0015726364217698574
Test Loss:  0.0010580684756860137
Valid Loss:  0.001548777217976749
Epoch:  65  	Training Loss: 0.001498666126281023
Test Loss:  0.0010064851958304644
Valid Loss:  0.0014793886803090572
Epoch:  66  	Training Loss: 0.0014305105432868004
Test Loss:  0.0009547945810481906
Valid Loss:  0.001404479960910976
Epoch:  67  	Training Loss: 0.001355835353024304
Test Loss:  0.0009160393383353949
Valid Loss:  0.0013486873358488083
Epoch:  68  	Training Loss: 0.0013025853550061584
Test Loss:  0.0008825304685160518
Valid Loss:  0.0012988012749701738
Epoch:  69  	Training Loss: 0.0012539078015834093
Test Loss:  0.0008511446067132056
Valid Loss:  0.0012514939298853278
Epoch:  70  	Training Loss: 0.0012080925516784191
Test Loss:  0.000823517213575542
Valid Loss:  0.001208498957566917
Epoch:  71  	Training Loss: 0.0011660100426524878
Test Loss:  0.0007988610304892063
Valid Loss:  0.0011690636165440083
Epoch:  72  	Training Loss: 0.0011272018309682608
Test Loss:  0.0008059862884692848
Valid Loss:  0.0011722580529749393
 15%|█▍        | 73/500 [00:53<06:00,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:00<08:06,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:00<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.00it/s] 18%|█▊        | 91/500 [01:07<07:50,  1.15s/it] 19%|█▊        | 93/500 [01:07<05:35,  1.21it/s] 19%|█▉        | 95/500 [01:07<04:01,  1.68it/s] 19%|█▉        | 97/500 [01:07<02:56,  2.29it/s] 20%|█▉        | 99/500 [01:07<02:10,  3.08it/s] 20%|██        | 101/500 [01:14<07:47,  1.17s/it] 21%|██        | 103/500 [01:14<05:36,  1.18it/s] 21%|██        | 105/500 [01:14<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:14<03:00,  2.18it/s] 22%|██▏       | 109/500 [01:14<02:15,  2.88it/s] 22%|██▏       | 111/500 [01:27<13:54,  2.15s/it] 23%|██▎       | 113/500 [01:27<09:49,  1.52s/it] 23%|██▎       | 115/500 [01:27<06:58,  1.09s/it] 23%|██▎       | 117/500 [01:27<04:58,  1.28it/s] 24%|██▍       | 119/500 [01:27<03:35,  1.77it/s] 24%|██▍       | 121/500 [01:34<08:23,  1.33s/it] 25%|██▍       | 123/500 [01:34<05:58,  1.05it/s] 25%|██▌       | 125/500 [01:34<04:17,  1.46it/s] 25%|██▌       | 127/500 [01:34<03:06,  2.00it/s] 26%|██▌       | 129/500 [01:34<02:17,  2.70it/s] 26%|██▌       | 131/500 [01:40<07:19,  1.19s/it] 27%|██▋       | 133/500 [01:41<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:41<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:41<02:44,  2.21it/s] 28%|██▊       | 139/500 [01:41<02:03,  2.93it/s]Epoch:  73  	Training Loss: 0.001120546367019415
Test Loss:  0.0008144098683260381
Valid Loss:  0.001177649712190032
Epoch:  74  	Training Loss: 0.0011167936027050018
Test Loss:  0.0008219495066441596
Valid Loss:  0.0011826591799035668
Epoch:  75  	Training Loss: 0.0011141975410282612
Test Loss:  0.0008285895455628633
Valid Loss:  0.0011871859896928072
Epoch:  76  	Training Loss: 0.0011124040465801954
Test Loss:  0.0008343682857230306
Valid Loss:  0.0011912044137716293
Epoch:  77  	Training Loss: 0.001111163990572095
Test Loss:  0.0008393496973440051
Valid Loss:  0.0011947164312005043
Epoch:  78  	Training Loss: 0.0011103057768195868
Test Loss:  0.0008436121279373765
Valid Loss:  0.0011977565009146929
Epoch:  79  	Training Loss: 0.0011097131064161658
Test Loss:  0.0008472419576719403
Valid Loss:  0.0012003680458292365
Epoch:  80  	Training Loss: 0.0011093042558059096
Test Loss:  0.0008503203862346709
Valid Loss:  0.0012025970499962568
Epoch:  81  	Training Loss: 0.0011090205516666174
Test Loss:  0.0008529189508408308
Valid Loss:  0.0012044903123751283
Epoch:  82  	Training Loss: 0.0011088242754340172
Test Loss:  0.0006125755608081818
Valid Loss:  0.0008879353408701718
Epoch:  83  	Training Loss: 0.0009177729953080416
Test Loss:  0.0006931162206456065
Valid Loss:  0.0009115568827837706
Epoch:  84  	Training Loss: 0.0008211134700104594
Test Loss:  0.0005579969147220254
Valid Loss:  0.0007544943364337087
Epoch:  85  	Training Loss: 0.0007683670846745372
Test Loss:  0.0006400721613317728
Valid Loss:  0.0008093079086393118
Epoch:  86  	Training Loss: 0.0007380041643045843
Test Loss:  0.0005510157207027078
Valid Loss:  0.0007151140598580241
Epoch:  87  	Training Loss: 0.0007213959470391273
Test Loss:  0.0006192713044583797
Valid Loss:  0.0007686559110879898
Epoch:  88  	Training Loss: 0.0007116597844287753
Test Loss:  0.0005563179729506373
Valid Loss:  0.0007052660221233964
Epoch:  89  	Training Loss: 0.000705700134858489
Test Loss:  0.0006090684910304844
Valid Loss:  0.0007483125664293766
Epoch:  90  	Training Loss: 0.0007020274642854929
Test Loss:  0.0005632925312966108
Valid Loss:  0.0007034497102722526
Epoch:  91  	Training Loss: 0.0006996648153290153
Test Loss:  0.0006029470823705196
Valid Loss:  0.0007363838376477361
Epoch:  92  	Training Loss: 0.0006981322076171637
Test Loss:  0.0005704903742298484
Valid Loss:  0.0007011715788394213
Epoch:  93  	Training Loss: 0.0006919014267623425
Test Loss:  0.0005724129150621593
Valid Loss:  0.0007017832831479609
Epoch:  94  	Training Loss: 0.0006896171253174543
Test Loss:  0.0005712038837373257
Valid Loss:  0.0006987693486735225
Epoch:  95  	Training Loss: 0.0006878452259115875
Test Loss:  0.0005707105156034231
Valid Loss:  0.0006963626947253942
Epoch:  96  	Training Loss: 0.0006863828748464584
Test Loss:  0.0005706605734303594
Valid Loss:  0.0006942156469449401
Epoch:  97  	Training Loss: 0.0006851421785540879
Test Loss:  0.0005707790842279792
Valid Loss:  0.0006920616724528372
Epoch:  98  	Training Loss: 0.0006840181886218488
Test Loss:  0.0005710600526072085
Valid Loss:  0.0006900503649376333
Epoch:  99  	Training Loss: 0.0006829948979429901
Test Loss:  0.0005713229766115546
Valid Loss:  0.0006881000008434057
Epoch:  100  	Training Loss: 0.0006819652626290917
Test Loss:  0.0005709679098799825
Valid Loss:  0.0006852102233096957
Epoch:  101  	Training Loss: 0.0006807514000684023
Test Loss:  0.0005714257713407278
Valid Loss:  0.0006833281950093806
Epoch:  102  	Training Loss: 0.000679665245115757
Test Loss:  0.0005882278783246875
Valid Loss:  0.0006918032304383814
Epoch:  103  	Training Loss: 0.0006716067437082529
Test Loss:  0.0005581822479143739
Valid Loss:  0.0006630626739934087
Epoch:  104  	Training Loss: 0.0006654863245785236
Test Loss:  0.0005883031990379095
Valid Loss:  0.0006834570085629821
Epoch:  105  	Training Loss: 0.0006595738232135773
Test Loss:  0.0005432998877950013
Valid Loss:  0.0006442399462684989
Epoch:  106  	Training Loss: 0.0006584618822671473
Test Loss:  0.0006035467376932502
Valid Loss:  0.0006931022508069873
Epoch:  107  	Training Loss: 0.0006589232943952084
Test Loss:  0.0005293565336614847
Valid Loss:  0.000629825284704566
Epoch:  108  	Training Loss: 0.0006607318064197898
Test Loss:  0.0005600848817266524
Valid Loss:  0.0006551966071128845
Epoch:  109  	Training Loss: 0.0006531790713779628
Test Loss:  0.0005715488223358989
Valid Loss:  0.0006635960307903588
Epoch:  110  	Training Loss: 0.0006522693438455462
Test Loss:  0.0005559807759709656
Valid Loss:  0.000649204826913774
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.000651551759801805
Test Loss:  0.0005582810845226049
Valid Loss:  0.0006509391823783517
Epoch:  112  	Training Loss: 0.0006509168888442218
Test Loss:  0.0005584652535617352
Valid Loss:  0.000651130685582757
Epoch:  113  	Training Loss: 0.0006508686929009855
Test Loss:  0.0005586438928730786
Valid Loss:  0.0006513146217912436
Epoch:  114  	Training Loss: 0.00065082055516541
Test Loss:  0.0005588168278336525
Valid Loss:  0.000651494599878788
Epoch:  115  	Training Loss: 0.0006507741054520011
Test Loss:  0.0005589845823124051
Valid Loss:  0.0006516653811559081
Epoch:  116  	Training Loss: 0.0006507282378152013
Test Loss:  0.0005591475055553019
Valid Loss:  0.000651832262519747
Epoch:  117  	Training Loss: 0.000650682719424367
Test Loss:  0.0005593051319010556
Valid Loss:  0.0006519928574562073
Epoch:  118  	Training Loss: 0.0006506384816020727
Test Loss:  0.0005594567046500742
Valid Loss:  0.0006521482719108462
Epoch:  119  	Training Loss: 0.0006505942437797785
Test Loss:  0.0005596041446551681
Valid Loss:  0.0006522954208776355
Epoch:  120  	Training Loss: 0.0006505509372800589
Test Loss:  0.0005597463459707797
Valid Loss:  0.0006524409400299191
Epoch:  121  	Training Loss: 0.0006505090277642012
Test Loss:  0.0005598838906735182
Valid Loss:  0.0006525785429403186
Epoch:  122  	Training Loss: 0.0006504664197564125
Test Loss:  0.0005625421181321144
Valid Loss:  0.000655427691526711
Epoch:  123  	Training Loss: 0.0006503684562630951
Test Loss:  0.0005637656431645155
Valid Loss:  0.0006567225209437311
Epoch:  124  	Training Loss: 0.0006503479089587927
Test Loss:  0.0005643308977596462
Valid Loss:  0.0006573054706677794
Epoch:  125  	Training Loss: 0.0006503424956463277
Test Loss:  0.0005645995261147618
Valid Loss:  0.0006575676379725337
Epoch:  126  	Training Loss: 0.0006503399927169085
Test Loss:  0.000564735266380012
Valid Loss:  0.0006576860905624926
Epoch:  127  	Training Loss: 0.0006503395270556211
Test Loss:  0.0005648098886013031
Valid Loss:  0.0006577407475560904
Epoch:  128  	Training Loss: 0.0006503383629024029
Test Loss:  0.0005648575606755912
Valid Loss:  0.0006577669410035014
Epoch:  129  	Training Loss: 0.0006503377226181328
Test Loss:  0.0005648935330100358
Valid Loss:  0.000657779979519546
Epoch:  130  	Training Loss: 0.0006503368495032191
Test Loss:  0.000564922986086458
Valid Loss:  0.000657787371892482
Epoch:  131  	Training Loss: 0.0006503351032733917
Test Loss:  0.0005649501108564436
Valid Loss:  0.0006577923195436597
Epoch:  132  	Training Loss: 0.0006503353361040354
Test Loss:  0.0005635026027448475
Valid Loss:  0.000655385316349566
Epoch:  133  	Training Loss: 0.0006499700248241425
Test Loss:  0.0005619086441583931
Valid Loss:  0.000652686576358974
Epoch:  134  	Training Loss: 0.0006494952831417322
Test Loss:  0.0005604829639196396
Valid Loss:  0.0006502261385321617
Epoch:  135  	Training Loss: 0.0006490719388239086
Test Loss:  0.0005592079251073301
Valid Loss:  0.000647979904897511
Epoch:  136  	Training Loss: 0.0006486909696832299
Test Loss:  0.0005580645520240068
Valid Loss:  0.0006459224387072027
Epoch:  137  	Training Loss: 0.0006483442266471684
Test Loss:  0.0005570389330387115
Valid Loss:  0.0006440355209633708
Epoch:  138  	Training Loss: 0.0006480267620645463
Test Loss:  0.0005561191355809569
Valid Loss:  0.0006423023296520114
Epoch:  139  	Training Loss: 0.0006476716371253133
Test Loss:  0.0005550120258703828
Valid Loss:  0.0006402168655768037
Epoch:  140  	Training Loss: 0.0006472534732893109
Test Loss:   28%|██▊       | 141/500 [01:47<07:07,  1.19s/it] 29%|██▊       | 143/500 [01:47<05:04,  1.17it/s] 29%|██▉       | 145/500 [01:48<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:48<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:48<01:57,  2.98it/s] 30%|███       | 151/500 [01:54<06:52,  1.18s/it] 31%|███       | 153/500 [01:54<04:54,  1.18it/s] 31%|███       | 155/500 [01:54<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:55<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:55<01:54,  2.99it/s] 32%|███▏      | 161/500 [02:01<06:36,  1.17s/it] 33%|███▎      | 163/500 [02:01<04:44,  1.18it/s] 33%|███▎      | 165/500 [02:01<03:27,  1.62it/s] 33%|███▎      | 167/500 [02:01<02:32,  2.18it/s] 34%|███▍      | 169/500 [02:02<01:54,  2.89it/s] 34%|███▍      | 171/500 [02:08<06:35,  1.20s/it] 35%|███▍      | 173/500 [02:08<04:42,  1.16it/s] 35%|███▌      | 175/500 [02:08<03:22,  1.60it/s] 35%|███▌      | 177/500 [02:08<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:09<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:15<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:15<04:29,  1.18it/s] 37%|███▋      | 185/500 [02:15<03:13,  1.62it/s] 37%|███▋      | 187/500 [02:15<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:15<01:45,  2.94it/s] 38%|███▊      | 191/500 [02:22<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:22<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:22<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:22<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:22<01:40,  2.99it/s] 40%|████      | 201/500 [02:29<05:53,  1.18s/it] 41%|████      | 203/500 [02:29<04:13,  1.17it/s] 41%|████      | 205/500 [02:29<03:03,  1.61it/s] 41%|████▏     | 207/500 [02:29<02:13,  2.20it/s]0.0005540165002457798
Valid Loss:  0.0006382983410730958
Epoch:  141  	Training Loss: 0.000646863947622478
Test Loss:  0.0005531236529350281
Valid Loss:  0.0006365263252519071
Epoch:  142  	Training Loss: 0.0006464991602115333
Test Loss:  0.000554252415895462
Valid Loss:  0.000630389666184783
Epoch:  143  	Training Loss: 0.0006328710005618632
Test Loss:  0.0005536344833672047
Valid Loss:  0.0006241570808924735
Epoch:  144  	Training Loss: 0.0006277930806390941
Test Loss:  0.0005527128814719617
Valid Loss:  0.0006200267234817147
Epoch:  145  	Training Loss: 0.000624191015958786
Test Loss:  0.0005507915047928691
Valid Loss:  0.0006154560251161456
Epoch:  146  	Training Loss: 0.0006207937258295715
Test Loss:  0.00054838479263708
Valid Loss:  0.0006109046516939998
Epoch:  147  	Training Loss: 0.0006174908485263586
Test Loss:  0.0005457150982692838
Valid Loss:  0.0006065380293875933
Epoch:  148  	Training Loss: 0.0006141805206425488
Test Loss:  0.0005426534917205572
Valid Loss:  0.0006016135448589921
Epoch:  149  	Training Loss: 0.000610683171544224
Test Loss:  0.0005391361191868782
Valid Loss:  0.0005968469777144492
Epoch:  150  	Training Loss: 0.0006072416435927153
Test Loss:  0.0005372647428885102
Valid Loss:  0.0005930342013016343
Epoch:  151  	Training Loss: 0.0006038140272721648
Test Loss:  0.0005347438273020089
Valid Loss:  0.0005889484891667962
Epoch:  152  	Training Loss: 0.0006004299502819777
Test Loss:  0.0005297836032696068
Valid Loss:  0.0005826917476952076
Epoch:  153  	Training Loss: 0.0005994199309498072
Test Loss:  0.0005260352045297623
Valid Loss:  0.0005778420600108802
Epoch:  154  	Training Loss: 0.000598764163441956
Test Loss:  0.0005231826798990369
Valid Loss:  0.0005740397609770298
Epoch:  155  	Training Loss: 0.00059833301929757
Test Loss:  0.0005210053059272468
Valid Loss:  0.0005710418336093426
Epoch:  156  	Training Loss: 0.0005980426794849336
Test Loss:  0.0005193351535126567
Valid Loss:  0.0005686556687578559
Epoch:  157  	Training Loss: 0.0005978428525850177
Test Loss:  0.0005180528969503939
Valid Loss:  0.0005667421501129866
Epoch:  158  	Training Loss: 0.0005977003602311015
Test Loss:  0.0005170687800273299
Valid Loss:  0.000565194757655263
Epoch:  159  	Training Loss: 0.0005975939566269517
Test Loss:  0.0005163139430806041
Valid Loss:  0.0005639359005726874
Epoch:  160  	Training Loss: 0.0005975107196718454
Test Loss:  0.0005157364648766816
Valid Loss:  0.0005628983490169048
Epoch:  161  	Training Loss: 0.0005974431405775249
Test Loss:  0.0005152964149601758
Valid Loss:  0.0005620375741273165
Epoch:  162  	Training Loss: 0.0005973866209387779
Test Loss:  0.0005130221834406257
Valid Loss:  0.0005605051410384476
Epoch:  163  	Training Loss: 0.0005962586146779358
Test Loss:  0.0005111202481202781
Valid Loss:  0.0005592636880464852
Epoch:  164  	Training Loss: 0.0005953204818069935
Test Loss:  0.0005095589440315962
Valid Loss:  0.0005581961013376713
Epoch:  165  	Training Loss: 0.0005945079028606415
Test Loss:  0.000508395372889936
Valid Loss:  0.0005574057577177882
Epoch:  166  	Training Loss: 0.0005938910180702806
Test Loss:  0.0005073478678241372
Valid Loss:  0.0005566602339968085
Epoch:  167  	Training Loss: 0.0005932956119067967
Test Loss:  0.0005066035082563758
Valid Loss:  0.0005561836296692491
Epoch:  168  	Training Loss: 0.0005927615566179156
Test Loss:  0.0005058909300714731
Valid Loss:  0.000555808306671679
Epoch:  169  	Training Loss: 0.0005922586424276233
Test Loss:  0.0005053164204582572
Valid Loss:  0.0005554960225708783
Epoch:  170  	Training Loss: 0.0005918109090998769
Test Loss:  0.0005048680468462408
Valid Loss:  0.0005552398506551981
Epoch:  171  	Training Loss: 0.0005914071225561202
Test Loss:  0.0005044264253228903
Valid Loss:  0.0005549878114834428
Epoch:  172  	Training Loss: 0.0005910259205847979
Test Loss:  0.00049500452587381
Valid Loss:  0.0005453957128338516
Epoch:  173  	Training Loss: 0.0005744193913415074
Test Loss:  0.0004941412480548024
Valid Loss:  0.0005433302721939981
Epoch:  174  	Training Loss: 0.0005728758405894041
Test Loss:  0.0004940334474667907
Valid Loss:  0.0005432170582935214
Epoch:  175  	Training Loss: 0.0005728747928515077
Test Loss:  0.0004939432255923748
Valid Loss:  0.0005431243916973472
Epoch:  176  	Training Loss: 0.0005728728137910366
Test Loss:  0.0004938702331855893
Valid Loss:  0.0005430468590930104
Epoch:  177  	Training Loss: 0.0005728722317144275
Test Loss:  0.0004938087658956647
Valid Loss:  0.0005429813754744828
Epoch:  178  	Training Loss: 0.0005728718242608011
Test Loss:  0.0004937589401379228
Valid Loss:  0.0005429302109405398
Epoch:  179  	Training Loss: 0.0005728708347305655
Test Loss:  0.0004937174962833524
Valid Loss:  0.0005428866716101766
Epoch:  180  	Training Loss: 0.0005728701944462955
Test Loss:  0.0004936844343319535
Valid Loss:  0.0005428500007838011
Epoch:  181  	Training Loss: 0.0005728695541620255
Test Loss:  0.0004936562036164105
Valid Loss:  0.0005428206641227007
Epoch:  182  	Training Loss: 0.0005728691467083991
Test Loss:  0.000495329441037029
Valid Loss:  0.0005434873746708035
Epoch:  183  	Training Loss: 0.0005723303183913231
Test Loss:  0.0004966752021573484
Valid Loss:  0.0005438216030597687
Epoch:  184  	Training Loss: 0.000571870303247124
Test Loss:  0.0004977575736120343
Valid Loss:  0.0005439054220914841
Epoch:  185  	Training Loss: 0.0005714636063203216
Test Loss:  0.0004986322019249201
Valid Loss:  0.0005437908694148064
Epoch:  186  	Training Loss: 0.0005710960831493139
Test Loss:  0.0004993393667973578
Valid Loss:  0.0005435238126665354
Epoch:  187  	Training Loss: 0.0005707594100385904
Test Loss:  0.0004999163211323321
Valid Loss:  0.0005431486060842872
Epoch:  188  	Training Loss: 0.000570444914046675
Test Loss:  0.0005003924597986042
Valid Loss:  0.0005426892312243581
Epoch:  189  	Training Loss: 0.0005701499758288264
Test Loss:  0.0005007880972698331
Valid Loss:  0.0005421732203103602
Epoch:  190  	Training Loss: 0.00056987174320966
Test Loss:  0.0005011248867958784
Valid Loss:  0.000541616405826062
Epoch:  191  	Training Loss: 0.0005696065491065383
Test Loss:  0.0005014145863242447
Valid Loss:  0.000541031826287508
Epoch:  192  	Training Loss: 0.0005693549755960703
Test Loss:  0.0005017985822632909
Valid Loss:  0.0005410420708358288
Epoch:  193  	Training Loss: 0.0005683763884007931
Test Loss:  0.0005021679098717868
Valid Loss:  0.0005410256562754512
Epoch:  194  	Training Loss: 0.0005674000130966306
Test Loss:  0.0005025255959481001
Valid Loss:  0.000541002897080034
Epoch:  195  	Training Loss: 0.0005664349882863462
Test Loss:  0.000502870709169656
Valid Loss:  0.0005409435834735632
Epoch:  196  	Training Loss: 0.0005653651896864176
Test Loss:  0.0005031545297242701
Valid Loss:  0.0005408654687926173
Epoch:  197  	Training Loss: 0.0005642842734232545
Test Loss:  0.0005034034256823361
Valid Loss:  0.0005407521966844797
Epoch:  198  	Training Loss: 0.0005632113316096365
Test Loss:  0.0005034958012402058
Valid Loss:  0.0005406001582741737
Epoch:  199  	Training Loss: 0.000562147528398782
Test Loss:  0.0005034906789660454
Valid Loss:  0.000540437875315547
Epoch:  200  	Training Loss: 0.0005611070664599538
Test Loss:  0.0005034789792262018
Valid Loss:  0.000540254870429635
Epoch:  201  	Training Loss: 0.0005600373260676861
Test Loss:  0.0005034442292526364
Valid Loss:  0.0005400391528382897
Epoch:  202  	Training Loss: 0.0005589209031313658
Test Loss:  0.0005039044190198183
Valid Loss:  0.0005406678537838161
Epoch:  203  	Training Loss: 0.0005570254288613796
Test Loss:  0.0005030250176787376
Valid Loss:  0.0005395936314016581
Epoch:  204  	Training Loss: 0.0005552897928282619
Test Loss:  0.0005014009075239301
Valid Loss:  0.0005380908260121942
Epoch:  205  	Training Loss: 0.0005536579992622137
Test Loss:  0.000499633839353919
Valid Loss:  0.0005365158431231976
Epoch:  206  	Training Loss: 0.0005521095008589327
Test Loss:  0.0004979451186954975
Valid Loss:  0.0005349651910364628
Epoch:  207  	Training Loss: 0.0005506346351467073
Test Loss:  0.0004963396349921823
Valid Loss:  0.0005334517918527126
Epoch:  208  	Training Loss: 0.0005491144256666303
Test Loss:  0.0004940432263538241
Valid Loss:  0.0005310806445777416
 42%|████▏     | 209/500 [02:29<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:35<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:36<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:36<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:36<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:36<01:32,  3.03it/s] 44%|████▍     | 221/500 [02:42<05:25,  1.17s/it] 45%|████▍     | 223/500 [02:42<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:43<02:47,  1.65it/s] 45%|████▌     | 227/500 [02:43<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:43<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:49<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:49<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:49<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:49<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:50<01:26,  3.03it/s] 48%|████▊     | 241/500 [02:56<05:08,  1.19s/it] 49%|████▊     | 243/500 [02:56<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:56<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:56<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:56<01:24,  2.97it/s] 50%|█████     | 251/500 [03:03<04:53,  1.18s/it] 51%|█████     | 253/500 [03:03<03:29,  1.18it/s] 51%|█████     | 255/500 [03:03<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:03<01:49,  2.23it/s] 52%|█████▏    | 259/500 [03:03<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:10<04:38,  1.17s/it] 53%|█████▎    | 263/500 [03:10<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:10<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:10<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:10<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:16<04:25,  1.16s/it] 55%|█████▍    | 273/500 [03:16<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:17<02:15,  1.66it/s]Epoch:  209  	Training Loss: 0.000547452480532229
Test Loss:  0.0004922555526718497
Valid Loss:  0.0005292660789564252
Epoch:  210  	Training Loss: 0.0005458471132442355
Test Loss:  0.000490631558932364
Valid Loss:  0.0005276373121887445
Epoch:  211  	Training Loss: 0.0005442951805889606
Test Loss:  0.0004891041317023337
Valid Loss:  0.000526082469150424
Epoch:  212  	Training Loss: 0.0005427843425422907
Test Loss:  0.0004884084919467568
Valid Loss:  0.0005240294267423451
Epoch:  213  	Training Loss: 0.0005412530153989792
Test Loss:  0.00048760027857497334
Valid Loss:  0.0005218834266997874
Epoch:  214  	Training Loss: 0.0005396806518547237
Test Loss:  0.0004866601375397295
Valid Loss:  0.0005197536665946245
Epoch:  215  	Training Loss: 0.0005380420479923487
Test Loss:  0.00048552232328802347
Valid Loss:  0.000517629086971283
Epoch:  216  	Training Loss: 0.0005363143282011151
Test Loss:  0.0004843751958105713
Valid Loss:  0.0005155424005351961
Epoch:  217  	Training Loss: 0.0005346473772078753
Test Loss:  0.00048326162504963577
Valid Loss:  0.0005135336541570723
Epoch:  218  	Training Loss: 0.0005330056301318109
Test Loss:  0.00048214656999334693
Valid Loss:  0.0005115616368129849
Epoch:  219  	Training Loss: 0.0005313019501045346
Test Loss:  0.00048102898290380836
Valid Loss:  0.0005096259992569685
Epoch:  220  	Training Loss: 0.0005296566523611546
Test Loss:  0.0004799391026608646
Valid Loss:  0.0005077634705230594
Epoch:  221  	Training Loss: 0.0005280385375954211
Test Loss:  0.00047885096864774823
Valid Loss:  0.0005059352261014283
Epoch:  222  	Training Loss: 0.0005263536004349589
Test Loss:  0.0004777383292093873
Valid Loss:  0.000504104420542717
Epoch:  223  	Training Loss: 0.0005258247256278992
Test Loss:  0.0004773446707986295
Valid Loss:  0.0005029982421547174
Epoch:  224  	Training Loss: 0.0005253150011412799
Test Loss:  0.00047697927220724523
Valid Loss:  0.0005019368836656213
Epoch:  225  	Training Loss: 0.0005248202942311764
Test Loss:  0.0004766260681208223
Valid Loss:  0.0005009050946682692
Epoch:  226  	Training Loss: 0.0005243397317826748
Test Loss:  0.0004762838361784816
Valid Loss:  0.0004999019438400865
Epoch:  227  	Training Loss: 0.0005238737794570625
Test Loss:  0.0004759497242048383
Valid Loss:  0.0004989211447536945
Epoch:  228  	Training Loss: 0.0005234198179095984
Test Loss:  0.0004756260314024985
Valid Loss:  0.0004979688674211502
Epoch:  229  	Training Loss: 0.0005229788366705179
Test Loss:  0.0004753116809297353
Valid Loss:  0.0004970409790985286
Epoch:  230  	Training Loss: 0.000522549613378942
Test Loss:  0.00047500571236014366
Valid Loss:  0.000496135326102376
Epoch:  231  	Training Loss: 0.0005221316823735833
Test Loss:  0.00047470626304857433
Valid Loss:  0.0004952519666403532
Epoch:  232  	Training Loss: 0.0005217246362008154
Test Loss:  0.00047401522169820964
Valid Loss:  0.0004930180730298162
Epoch:  233  	Training Loss: 0.0005179591826163232
Test Loss:  0.0004677784163504839
Valid Loss:  0.00048427103320136666
Epoch:  234  	Training Loss: 0.0005091537022963166
Test Loss:  0.0004618374223355204
Valid Loss:  0.0004755319096148014
Epoch:  235  	Training Loss: 0.0005016390350647271
Test Loss:  0.0004589384188875556
Valid Loss:  0.00047223304864019156
Epoch:  236  	Training Loss: 0.000500070455018431
Test Loss:  0.00045650696847587824
Valid Loss:  0.0004693861701525748
Epoch:  237  	Training Loss: 0.0004984958795830607
Test Loss:  0.0004544247640296817
Valid Loss:  0.00046687753638252616
Epoch:  238  	Training Loss: 0.0004968818975612521
Test Loss:  0.00045261491322889924
Valid Loss:  0.00046465868945233524
Epoch:  239  	Training Loss: 0.0004953242023475468
Test Loss:  0.00045101740397512913
Valid Loss:  0.00046247110003605485
Epoch:  240  	Training Loss: 0.0004938134225085378
Test Loss:  0.000449588056653738
Valid Loss:  0.0004604148562066257
Epoch:  241  	Training Loss: 0.0004923419328406453
Test Loss:  0.00044829180114902556
Valid Loss:  0.00045851327013224363
Epoch:  242  	Training Loss: 0.0004908659029752016
Test Loss:  0.0004478099290281534
Valid Loss:  0.00045775662874802947
Epoch:  243  	Training Loss: 0.0004904530942440033
Test Loss:  0.0004473671433515847
Valid Loss:  0.0004570573219098151
Epoch:  244  	Training Loss: 0.0004900551866739988
Test Loss:  0.0004469606501515955
Valid Loss:  0.00045641008182428777
Epoch:  245  	Training Loss: 0.0004896711907349527
Test Loss:  0.0004465839883778244
Valid Loss:  0.00045580818550661206
Epoch:  246  	Training Loss: 0.0004893004661425948
Test Loss:  0.0004462371289264411
Valid Loss:  0.0004552461323328316
Epoch:  247  	Training Loss: 0.0004889429546892643
Test Loss:  0.000445910933194682
Valid Loss:  0.0004547199350781739
Epoch:  248  	Training Loss: 0.0004885966191068292
Test Loss:  0.00044560630340129137
Valid Loss:  0.0004542251117527485
Epoch:  249  	Training Loss: 0.0004882629436906427
Test Loss:  0.00044531672028824687
Valid Loss:  0.0004537577915471047
Epoch:  250  	Training Loss: 0.0004879381158389151
Test Loss:  0.00044504395918920636
Valid Loss:  0.000453315326012671
Epoch:  251  	Training Loss: 0.0004876251914538443
Test Loss:  0.0004447836254257709
Valid Loss:  0.00045289710396900773
Epoch:  252  	Training Loss: 0.0004873199504800141
Test Loss:  0.0004478437767829746
Valid Loss:  0.00045926147140562534
Epoch:  253  	Training Loss: 0.0004840815672650933
Test Loss:  0.0004483592347241938
Valid Loss:  0.00046200567157939076
Epoch:  254  	Training Loss: 0.0004818100715056062
Test Loss:  0.00044752872781828046
Valid Loss:  0.00046284374548122287
Epoch:  255  	Training Loss: 0.0004799238813575357
Test Loss:  0.0004461835487745702
Valid Loss:  0.00046283009578473866
Epoch:  256  	Training Loss: 0.0004783014883287251
Test Loss:  0.00044467291445471346
Valid Loss:  0.0004624046559911221
Epoch:  257  	Training Loss: 0.0004768510698340833
Test Loss:  0.00044316676212474704
Valid Loss:  0.00046186259714886546
Epoch:  258  	Training Loss: 0.0004755421541631222
Test Loss:  0.0004416774900164455
Valid Loss:  0.00046125007793307304
Epoch:  259  	Training Loss: 0.00047434004954993725
Test Loss:  0.0004402432532515377
Valid Loss:  0.00046062475303187966
Epoch:  260  	Training Loss: 0.0004732385277748108
Test Loss:  0.0004389458044897765
Valid Loss:  0.0004600383108481765
Epoch:  261  	Training Loss: 0.0004722313315141946
Test Loss:  0.00043771881610155106
Valid Loss:  0.0004594686324708164
Epoch:  262  	Training Loss: 0.000471292354632169
Test Loss:  0.0004394373099785298
Valid Loss:  0.0004584394337143749
Epoch:  263  	Training Loss: 0.00046718589146621525
Test Loss:  0.0004410920664668083
Valid Loss:  0.0004577293584588915
Epoch:  264  	Training Loss: 0.0004653397190850228
Test Loss:  0.0004423951613716781
Valid Loss:  0.00045740476343780756
Epoch:  265  	Training Loss: 0.0004643467837013304
Test Loss:  0.00044328568037599325
Valid Loss:  0.0004568483564071357
Epoch:  266  	Training Loss: 0.0004637116508092731
Test Loss:  0.0004432356799952686
Valid Loss:  0.00045590795343741775
Epoch:  267  	Training Loss: 0.0004633283824659884
Test Loss:  0.0004431029665283859
Valid Loss:  0.00045495753875002265
Epoch:  268  	Training Loss: 0.00046299624955281615
Test Loss:  0.0004426514497026801
Valid Loss:  0.0004539339570328593
Epoch:  269  	Training Loss: 0.0004627176094800234
Test Loss:  0.00044197580427862704
Valid Loss:  0.0004528850258793682
Epoch:  270  	Training Loss: 0.0004624709254130721
Test Loss:  0.00044140208046883345
Valid Loss:  0.0004519274807535112
Epoch:  271  	Training Loss: 0.0004622566048055887
Test Loss:  0.0004403935745358467
Valid Loss:  0.0004508925194386393
Epoch:  272  	Training Loss: 0.00046206917613744736
Test Loss:  0.0004225218144711107
Valid Loss:  0.00043199019273743033
Epoch:  273  	Training Loss: 0.00046110613038763404
Test Loss:  0.0004291542572900653
Valid Loss:  0.00043851364171132445
Epoch:  274  	Training Loss: 0.0004608540330082178
Test Loss:  0.0004261849680915475
Valid Loss:  0.00043506096699275076
Epoch:  275  	Training Loss: 0.00046072632540017366
Test Loss:  0.00042722123907878995
Valid Loss:  0.0004357837897259742
Epoch:  276  	Training Loss: 0.0004606245784088969
Test Loss:  0.00042663904605433345
Valid Loss:   55%|█████▌    | 277/500 [03:17<01:38,  2.27it/s] 56%|█████▌    | 279/500 [03:17<01:12,  3.04it/s] 56%|█████▌    | 281/500 [03:23<04:25,  1.21s/it] 57%|█████▋    | 283/500 [03:24<03:09,  1.14it/s] 57%|█████▋    | 285/500 [03:24<02:17,  1.57it/s] 57%|█████▋    | 287/500 [03:24<01:40,  2.12it/s] 58%|█████▊    | 289/500 [03:24<01:14,  2.83it/s] 58%|█████▊    | 291/500 [03:30<04:08,  1.19s/it] 59%|█████▊    | 293/500 [03:30<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:31<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:31<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:31<01:07,  2.97it/s] 60%|██████    | 301/500 [03:37<03:52,  1.17s/it] 61%|██████    | 303/500 [03:37<02:45,  1.19it/s] 61%|██████    | 305/500 [03:37<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:37<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:38<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:44<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:44<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:44<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:44<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:44<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:51<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:51<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:51<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:51<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:51<00:58,  2.92it/s] 66%|██████▌   | 331/500 [03:58<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:58<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:58<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:58<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:58<00:53,  3.01it/s] 68%|██████▊   | 341/500 [04:04<03:04,  1.16s/it] 69%|██████▊   | 343/500 [04:04<02:11,  1.19it/s]0.00043482991168275476
Epoch:  277  	Training Loss: 0.0004605314461514354
Test Loss:  0.00042672804556787014
Valid Loss:  0.0004345882043708116
Epoch:  278  	Training Loss: 0.000460443930933252
Test Loss:  0.0004265498137101531
Valid Loss:  0.0004340768209658563
Epoch:  279  	Training Loss: 0.0004603613051585853
Test Loss:  0.0004264888120815158
Valid Loss:  0.00043369774357415736
Epoch:  280  	Training Loss: 0.00046028359793126583
Test Loss:  0.00042638546437956393
Valid Loss:  0.0004332838288974017
Epoch:  281  	Training Loss: 0.0004602099070325494
Test Loss:  0.00042630545794963837
Valid Loss:  0.00043290213216096163
Epoch:  282  	Training Loss: 0.00046014104736968875
Test Loss:  0.00042591526289470494
Valid Loss:  0.0004314420511946082
Epoch:  283  	Training Loss: 0.0004589016316458583
Test Loss:  0.0004250141209922731
Valid Loss:  0.0004295023391023278
Epoch:  284  	Training Loss: 0.00045772173325531185
Test Loss:  0.00042428006418049335
Valid Loss:  0.0004277863190509379
Epoch:  285  	Training Loss: 0.0004565939598251134
Test Loss:  0.00042353657772764564
Valid Loss:  0.0004261092690285295
Epoch:  286  	Training Loss: 0.00045551624498330057
Test Loss:  0.0004228278121445328
Valid Loss:  0.00042451455374248326
Epoch:  287  	Training Loss: 0.00045448594028130174
Test Loss:  0.00042205018689855933
Valid Loss:  0.00042284143273718655
Epoch:  288  	Training Loss: 0.0004534998442977667
Test Loss:  0.00042116857366636395
Valid Loss:  0.00042116164695471525
Epoch:  289  	Training Loss: 0.0004525560070760548
Test Loss:  0.0004203183052595705
Valid Loss:  0.0004195176297798753
Epoch:  290  	Training Loss: 0.0004516098997555673
Test Loss:  0.00041945709381252527
Valid Loss:  0.0004176848742645234
Epoch:  291  	Training Loss: 0.00045056830276735127
Test Loss:  0.00041852128924801946
Valid Loss:  0.00041573256021365523
Epoch:  292  	Training Loss: 0.0004493982414714992
Test Loss:  0.00041484006214886904
Valid Loss:  0.0004123699036426842
Epoch:  293  	Training Loss: 0.0004482563235796988
Test Loss:  0.0004119588411413133
Valid Loss:  0.0004098303325008601
Epoch:  294  	Training Loss: 0.00044739898294210434
Test Loss:  0.00040969031397253275
Valid Loss:  0.0004079146892763674
Epoch:  295  	Training Loss: 0.00044673506636172533
Test Loss:  0.00040781698771752417
Valid Loss:  0.00040637835627421737
Epoch:  296  	Training Loss: 0.00044615284423343837
Test Loss:  0.00040632206946611404
Valid Loss:  0.0004051780852023512
Epoch:  297  	Training Loss: 0.0004456717288121581
Test Loss:  0.00040514173451811075
Valid Loss:  0.0004042864893563092
Epoch:  298  	Training Loss: 0.0004452875000424683
Test Loss:  0.0004041094216518104
Valid Loss:  0.0004035486199427396
Epoch:  299  	Training Loss: 0.000444919744040817
Test Loss:  0.00040328901377506554
Valid Loss:  0.00040295079816132784
Epoch:  300  	Training Loss: 0.00044458609772846103
Test Loss:  0.00040265481220558286
Valid Loss:  0.0004026010865345597
Epoch:  301  	Training Loss: 0.00044428405817598104
Test Loss:  0.0004020797787234187
Valid Loss:  0.000402345962356776
Epoch:  302  	Training Loss: 0.000444000877905637
Test Loss:  0.0004026110109407455
Valid Loss:  0.0004029463161714375
Epoch:  303  	Training Loss: 0.00044389528920874
Test Loss:  0.00040299625834450126
Valid Loss:  0.00040337792597711086
Epoch:  304  	Training Loss: 0.00044380052713677287
Test Loss:  0.00040327126043848693
Valid Loss:  0.0004036844475194812
Epoch:  305  	Training Loss: 0.00044371146941557527
Test Loss:  0.00040346436435356736
Valid Loss:  0.0004038946935907006
Epoch:  306  	Training Loss: 0.00044362578773871064
Test Loss:  0.0004035955644212663
Valid Loss:  0.00040403453749604523
Epoch:  307  	Training Loss: 0.00044354228884913027
Test Loss:  0.00040368136251345277
Valid Loss:  0.0004041218780912459
Epoch:  308  	Training Loss: 0.0004434592556208372
Test Loss:  0.0004037315375171602
Valid Loss:  0.00040416879346594214
Epoch:  309  	Training Loss: 0.00044337764848023653
Test Loss:  0.0004037566250190139
Valid Loss:  0.00040418741991743445
Epoch:  310  	Training Loss: 0.00044329577940516174
Test Loss:  0.0004037635517306626
Valid Loss:  0.00040418474236503243
Epoch:  311  	Training Loss: 0.00044321551104076207
Test Loss:  0.0004037561593577266
Valid Loss:  0.00040416576666757464
Epoch:  312  	Training Loss: 0.0004431339621078223
Test Loss:  0.00040383171290159225
Valid Loss:  0.00040430016815662384
Epoch:  313  	Training Loss: 0.00044312948011793196
Test Loss:  0.0004039040068164468
Valid Loss:  0.0004044233646709472
Epoch:  314  	Training Loss: 0.0004431251436471939
Test Loss:  0.000403970800107345
Valid Loss:  0.0004045395180583
Epoch:  315  	Training Loss: 0.0004431208362802863
Test Loss:  0.0004040320636704564
Valid Loss:  0.0004046466783620417
Epoch:  316  	Training Loss: 0.00044311757665127516
Test Loss:  0.0004040890489704907
Valid Loss:  0.0004047446418553591
Epoch:  317  	Training Loss: 0.0004431132401805371
Test Loss:  0.00040414134855382144
Valid Loss:  0.0004048374539706856
Epoch:  318  	Training Loss: 0.00044311012607067823
Test Loss:  0.0004041905631311238
Valid Loss:  0.0004049232229590416
Epoch:  319  	Training Loss: 0.00044310680823400617
Test Loss:  0.00040423544123768806
Valid Loss:  0.000405002007028088
Epoch:  320  	Training Loss: 0.0004431038396432996
Test Loss:  0.0004042771179229021
Valid Loss:  0.00040507520316168666
Epoch:  321  	Training Loss: 0.0004431002016644925
Test Loss:  0.00040431556408293545
Valid Loss:  0.0004051431023981422
Epoch:  322  	Training Loss: 0.00044309720396995544
Test Loss:  0.00041173817589879036
Valid Loss:  0.00041813362622633576
Epoch:  323  	Training Loss: 0.00043977273162454367
Test Loss:  0.00041516392957419157
Valid Loss:  0.00042436423245817423
Epoch:  324  	Training Loss: 0.00043869492947123945
Test Loss:  0.00041639278060756624
Valid Loss:  0.000427091057645157
Epoch:  325  	Training Loss: 0.0004381106118671596
Test Loss:  0.00041651944047771394
Valid Loss:  0.00042814415064640343
Epoch:  326  	Training Loss: 0.00043764011934399605
Test Loss:  0.00041620273259468377
Valid Loss:  0.00042847765143960714
Epoch:  327  	Training Loss: 0.0004372477123979479
Test Loss:  0.00041571754263713956
Valid Loss:  0.0004285020404495299
Epoch:  328  	Training Loss: 0.0004369134549051523
Test Loss:  0.0004151423927396536
Valid Loss:  0.00042836955981329083
Epoch:  329  	Training Loss: 0.0004365980566944927
Test Loss:  0.0004145477432757616
Valid Loss:  0.0004281763976905495
Epoch:  330  	Training Loss: 0.0004363000043667853
Test Loss:  0.00041395521839149296
Valid Loss:  0.00042796062189154327
Epoch:  331  	Training Loss: 0.00043603009544312954
Test Loss:  0.0004134143819101155
Valid Loss:  0.00042777141788974404
Epoch:  332  	Training Loss: 0.00043580294004641473
Test Loss:  0.0004091734590474516
Valid Loss:  0.00042315173777751625
Epoch:  333  	Training Loss: 0.0004350116942077875
Test Loss:  0.00040626508416607976
Valid Loss:  0.0004199264803901315
Epoch:  334  	Training Loss: 0.0004345508641563356
Test Loss:  0.00040420956793241203
Valid Loss:  0.0004176462534815073
Epoch:  335  	Training Loss: 0.00043425316107459366
Test Loss:  0.0004027257382404059
Valid Loss:  0.0004160059033893049
Epoch:  336  	Training Loss: 0.0004340431187301874
Test Loss:  0.00040164258098229766
Valid Loss:  0.00041481159860268235
Epoch:  337  	Training Loss: 0.00043387903133407235
Test Loss:  0.0004008400719612837
Valid Loss:  0.00041393371066078544
Epoch:  338  	Training Loss: 0.00043374099186621606
Test Loss:  0.00040023718611337245
Valid Loss:  0.00041328067891299725
Epoch:  339  	Training Loss: 0.0004336160491220653
Test Loss:  0.00039980155997909606
Valid Loss:  0.0004128097789362073
Epoch:  340  	Training Loss: 0.00043351069325581193
Test Loss:  0.00039946421748027205
Valid Loss:  0.0004124484839849174
Epoch:  341  	Training Loss: 0.00043339357944205403
Test Loss:  0.00039894419023767114
Valid Loss:  0.0004118571523576975
Epoch:  342  	Training Loss: 0.00043326138984411955
Test Loss:  0.000399440701585263
Valid Loss:  0.00041269807843491435
Epoch:  343  	Training Loss: 0.0004331496893428266
Test Loss:  0.0003999099717475474
Valid Loss:  0.0004134926130063832
 69%|██████▉   | 345/500 [04:05<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:05<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:05<00:50,  3.01it/s] 70%|███████   | 351/500 [04:11<02:54,  1.17s/it] 71%|███████   | 353/500 [04:11<02:03,  1.19it/s] 71%|███████   | 355/500 [04:11<01:29,  1.63it/s] 71%|███████▏  | 357/500 [04:12<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:12<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:18<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:18<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:18<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:18<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:19<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:25<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:25<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:25<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:25<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:25<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:32<02:22,  1.19s/it] 77%|███████▋  | 383/500 [04:32<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:32<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:32<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:39<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:39<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:39<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:39<00:46,  2.20it/s] 80%|███████▉  | 399/500 [04:39<00:34,  2.96it/s] 80%|████████  | 401/500 [04:46<01:57,  1.18s/it] 81%|████████  | 403/500 [04:46<01:22,  1.18it/s] 81%|████████  | 405/500 [04:46<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:46<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.99it/s]Epoch:  344  	Training Loss: 0.00043305271537974477
Test Loss:  0.00040035415440797806
Valid Loss:  0.00041424058144912124
Epoch:  345  	Training Loss: 0.00043296744115650654
Test Loss:  0.00040077388985082507
Valid Loss:  0.0004149428568780422
Epoch:  346  	Training Loss: 0.0004328920040279627
Test Loss:  0.0004011708660982549
Valid Loss:  0.00041560560930520296
Epoch:  347  	Training Loss: 0.00043282684055157006
Test Loss:  0.00040154458838514984
Valid Loss:  0.0004162280820310116
Epoch:  348  	Training Loss: 0.00043276927317492664
Test Loss:  0.00040189747232943773
Valid Loss:  0.0004168131563346833
Epoch:  349  	Training Loss: 0.0004327185160946101
Test Loss:  0.00040223062387667596
Valid Loss:  0.00041736243292689323
Epoch:  350  	Training Loss: 0.00043267427827231586
Test Loss:  0.0004025447415187955
Valid Loss:  0.0004178800736553967
Epoch:  351  	Training Loss: 0.000432634842582047
Test Loss:  0.00040284061105921865
Valid Loss:  0.0004183656710665673
Epoch:  352  	Training Loss: 0.00043260050006210804
Test Loss:  0.00040408672066405416
Valid Loss:  0.0004196778463665396
Epoch:  353  	Training Loss: 0.0004317474376875907
Test Loss:  0.000402600911911577
Valid Loss:  0.0004177169466856867
Epoch:  354  	Training Loss: 0.00043091821135021746
Test Loss:  0.0004021653439849615
Valid Loss:  0.00041704264003783464
Epoch:  355  	Training Loss: 0.000430099869845435
Test Loss:  0.0004013485449831933
Valid Loss:  0.00041592607158236206
Epoch:  356  	Training Loss: 0.00042929541086778045
Test Loss:  0.000400712713599205
Valid Loss:  0.0004150336317252368
Epoch:  357  	Training Loss: 0.0004285078030079603
Test Loss:  0.00040001689922064543
Valid Loss:  0.00041407454409636557
Epoch:  358  	Training Loss: 0.000427733437390998
Test Loss:  0.00039936829125508666
Valid Loss:  0.00041317183058708906
Epoch:  359  	Training Loss: 0.00042697059689089656
Test Loss:  0.0003987319942098111
Valid Loss:  0.00041228393092751503
Epoch:  360  	Training Loss: 0.0004262187867425382
Test Loss:  0.00039810972521081567
Valid Loss:  0.0004114198964089155
Epoch:  361  	Training Loss: 0.0004254792002029717
Test Loss:  0.00039750669384375215
Valid Loss:  0.0004105987027287483
Epoch:  362  	Training Loss: 0.0004247608594596386
Test Loss:  0.0003961186739616096
Valid Loss:  0.00040846323827281594
Epoch:  363  	Training Loss: 0.00042415098869241774
Test Loss:  0.0003948917146772146
Valid Loss:  0.00040654311305843294
Epoch:  364  	Training Loss: 0.00042359676444903016
Test Loss:  0.0003938105655834079
Valid Loss:  0.0004048155387863517
Epoch:  365  	Training Loss: 0.0004230838967487216
Test Loss:  0.0003928415826521814
Valid Loss:  0.0004032478900626302
Epoch:  366  	Training Loss: 0.00042260956251993775
Test Loss:  0.0003919699811376631
Valid Loss:  0.00040182058000937104
Epoch:  367  	Training Loss: 0.00042216514702886343
Test Loss:  0.0003911838575731963
Valid Loss:  0.00040051102405413985
Epoch:  368  	Training Loss: 0.0004217429377604276
Test Loss:  0.00039047468453645706
Valid Loss:  0.0003993120335508138
Epoch:  369  	Training Loss: 0.000421339413151145
Test Loss:  0.00038983189733698964
Valid Loss:  0.00039820128586143255
Epoch:  370  	Training Loss: 0.0004209553590044379
Test Loss:  0.00038924848195165396
Valid Loss:  0.00039717095205560327
Epoch:  371  	Training Loss: 0.00042059243423864245
Test Loss:  0.00038871594006195664
Valid Loss:  0.0003962079936172813
Epoch:  372  	Training Loss: 0.0004202438867650926
Test Loss:  0.0003904259647242725
Valid Loss:  0.00039853298221714795
Epoch:  373  	Training Loss: 0.0004198094247840345
Test Loss:  0.0003910742816515267
Valid Loss:  0.0003994746948592365
Epoch:  374  	Training Loss: 0.0004194597131572664
Test Loss:  0.00039115530671551824
Valid Loss:  0.00039962836308404803
Epoch:  375  	Training Loss: 0.00041914949542842805
Test Loss:  0.0003909396182280034
Valid Loss:  0.00039930944330990314
Epoch:  376  	Training Loss: 0.0004188495222479105
Test Loss:  0.0003909320221282542
Valid Loss:  0.0003993869759142399
Epoch:  377  	Training Loss: 0.00041854026494547725
Test Loss:  0.00039062154246494174
Valid Loss:  0.00039894779911264777
Epoch:  378  	Training Loss: 0.00041824381332844496
Test Loss:  0.00039056962123140693
Valid Loss:  0.00039897221722640097
Epoch:  379  	Training Loss: 0.00041794212302193046
Test Loss:  0.00039024383295327425
Valid Loss:  0.000398513424443081
Epoch:  380  	Training Loss: 0.00041764904744923115
Test Loss:  0.0003901869058609009
Valid Loss:  0.00039853333146311343
Epoch:  381  	Training Loss: 0.0004173542547505349
Test Loss:  0.00038986123399809003
Valid Loss:  0.0003980758192483336
Epoch:  382  	Training Loss: 0.00041706528281793
Test Loss:  0.00039111135993152857
Valid Loss:  0.0003985987859778106
Epoch:  383  	Training Loss: 0.0004128900181967765
Test Loss:  0.00039257685421034694
Valid Loss:  0.0003987365635111928
Epoch:  384  	Training Loss: 0.0004107884597033262
Test Loss:  0.00039308707346208394
Valid Loss:  0.00039815634954720736
Epoch:  385  	Training Loss: 0.00040960294427350163
Test Loss:  0.0003931691753678024
Valid Loss:  0.00039728396222926676
Epoch:  386  	Training Loss: 0.0004087120178155601
Test Loss:  0.00039309816202148795
Valid Loss:  0.0003964860225096345
Epoch:  387  	Training Loss: 0.0004079724894836545
Test Loss:  0.0003927779325749725
Valid Loss:  0.0003955352585762739
Epoch:  388  	Training Loss: 0.0004073167219758034
Test Loss:  0.00039241634658537805
Valid Loss:  0.0003946186334360391
Epoch:  389  	Training Loss: 0.0004067170084454119
Test Loss:  0.00039168045623227954
Valid Loss:  0.00039358242065645754
Epoch:  390  	Training Loss: 0.00040619331412017345
Test Loss:  0.00039113269303925335
Valid Loss:  0.00039269845001399517
Epoch:  391  	Training Loss: 0.0004056876350659877
Test Loss:  0.00039046374149620533
Valid Loss:  0.00039185554487630725
Epoch:  392  	Training Loss: 0.0004052105941809714
Test Loss:  0.00038540945388376713
Valid Loss:  0.0003857563133351505
Epoch:  393  	Training Loss: 0.0004039091872982681
Test Loss:  0.00038159984978847206
Valid Loss:  0.0003811140777543187
Epoch:  394  	Training Loss: 0.0004030799027532339
Test Loss:  0.000378699362045154
Valid Loss:  0.0003775557561311871
Epoch:  395  	Training Loss: 0.0004025499220006168
Test Loss:  0.0003764759749174118
Valid Loss:  0.0003748138260561973
Epoch:  396  	Training Loss: 0.00040221092058345675
Test Loss:  0.0003747579175978899
Valid Loss:  0.0003726919530890882
Epoch:  397  	Training Loss: 0.0004019933403469622
Test Loss:  0.0003734212077688426
Valid Loss:  0.00037104496732354164
Epoch:  398  	Training Loss: 0.00040185265243053436
Test Loss:  0.0003723767586052418
Valid Loss:  0.00036976224509999156
Epoch:  399  	Training Loss: 0.00040176050970330834
Test Loss:  0.00037155888276174664
Valid Loss:  0.000368765409803018
Epoch:  400  	Training Loss: 0.00040170075953938067
Test Loss:  0.000370914553059265
Valid Loss:  0.0003679877845570445
Epoch:  401  	Training Loss: 0.0004016608581878245
Test Loss:  0.00037040567258372903
Valid Loss:  0.00036738411290571094
Epoch:  402  	Training Loss: 0.00040163350058719516
Test Loss:  0.00038535764906555414
Valid Loss:  0.0003861098666675389
Epoch:  403  	Training Loss: 0.00039855489740148187
Test Loss:  0.0003705084091052413
Valid Loss:  0.00036856159567832947
Epoch:  404  	Training Loss: 0.00039582099998369813
Test Loss:  0.0003786393499467522
Valid Loss:  0.0003788149042520672
Epoch:  405  	Training Loss: 0.0003932751133106649
Test Loss:  0.0003693819453474134
Valid Loss:  0.00036774558247998357
Epoch:  406  	Training Loss: 0.00039069843478500843
Test Loss:  0.00037362868897616863
Valid Loss:  0.0003731346223503351
Epoch:  407  	Training Loss: 0.0003880861331708729
Test Loss:  0.0003665857366286218
Valid Loss:  0.0003653879975900054
Epoch:  408  	Training Loss: 0.0003852298832498491
Test Loss:  0.0003676451160572469
Valid Loss:  0.0003680468653328717
Epoch:  409  	Training Loss: 0.00038233265513554215
Test Loss:  0.0003623714728746563
Valid Loss:  0.00036216925946064293
Epoch:  410  	Training Loss: 0.0003795206139329821
Test Loss:  0.00036205811193212867
Valid Loss:  0.00036234111757948995
Epoch:  411  	Training Loss: 0.00037667754804715514
Test Loss:   82%|████████▏ | 411/500 [04:52<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:53<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:53<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:53<00:38,  2.18it/s] 84%|████████▍ | 419/500 [04:53<00:28,  2.88it/s] 84%|████████▍ | 421/500 [04:59<01:33,  1.18s/it] 85%|████████▍ | 423/500 [05:00<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:00<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:00<00:33,  2.17it/s] 86%|████████▌ | 429/500 [05:00<00:24,  2.87it/s] 86%|████████▌ | 431/500 [05:06<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:07<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:07<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:07<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:07<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:13<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:13<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:13<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:14<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:14<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:20<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:20<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:21<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:27<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:27<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:27<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:27<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:34<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:34<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:34<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.25it/s]0.00035811332054436207
Valid Loss:  0.0003574716974981129
Epoch:  412  	Training Loss: 0.00037373186205513775
Test Loss:  0.0003559471224434674
Valid Loss:  0.0003546311636455357
Epoch:  413  	Training Loss: 0.000373431365005672
Test Loss:  0.0003544358187355101
Valid Loss:  0.0003526157815940678
Epoch:  414  	Training Loss: 0.00037324923323467374
Test Loss:  0.0003533677663654089
Valid Loss:  0.000351166061591357
Epoch:  415  	Training Loss: 0.00037312775384634733
Test Loss:  0.00035260673030279577
Valid Loss:  0.0003501108440104872
Epoch:  416  	Training Loss: 0.00037303761928342283
Test Loss:  0.0003520559112075716
Valid Loss:  0.0003493335680104792
Epoch:  417  	Training Loss: 0.0003729647723957896
Test Loss:  0.00035165491863153875
Valid Loss:  0.00034875082201324403
Epoch:  418  	Training Loss: 0.000372899929061532
Test Loss:  0.0003513589035719633
Valid Loss:  0.00034830879303626716
Epoch:  419  	Training Loss: 0.00037284003337845206
Test Loss:  0.00035113596823066473
Valid Loss:  0.00034796493127942085
Epoch:  420  	Training Loss: 0.0003727825533133
Test Loss:  0.00035096699139103293
Valid Loss:  0.00034769391641020775
Epoch:  421  	Training Loss: 0.00037272664485499263
Test Loss:  0.0003508355584926903
Valid Loss:  0.00034747167956084013
Epoch:  422  	Training Loss: 0.00037267227889969945
Test Loss:  0.0003579905314836651
Valid Loss:  0.00036062346771359444
Epoch:  423  	Training Loss: 0.0003705662675201893
Test Loss:  0.0003502054023556411
Valid Loss:  0.00035235044197179377
Epoch:  424  	Training Loss: 0.00036892134812660515
Test Loss:  0.0003526294603943825
Valid Loss:  0.0003580358170438558
Epoch:  425  	Training Loss: 0.00036761589581146836
Test Loss:  0.00034900265745818615
Valid Loss:  0.00035481975646689534
Epoch:  426  	Training Loss: 0.00036653102142736316
Test Loss:  0.0003493731201160699
Valid Loss:  0.00035702373133972287
Epoch:  427  	Training Loss: 0.0003655679465737194
Test Loss:  0.0003474988043308258
Valid Loss:  0.00035579001996666193
Epoch:  428  	Training Loss: 0.00036474884836934507
Test Loss:  0.00034714999492280185
Valid Loss:  0.00035654514795169234
Epoch:  429  	Training Loss: 0.00036401316174305975
Test Loss:  0.0003458989958744496
Valid Loss:  0.000355906697222963
Epoch:  430  	Training Loss: 0.000363319821190089
Test Loss:  0.00034530338598415256
Valid Loss:  0.00035606883466243744
Epoch:  431  	Training Loss: 0.0003626800898928195
Test Loss:  0.00034433958353474736
Valid Loss:  0.0003556331212166697
Epoch:  432  	Training Loss: 0.0003620721399784088
Test Loss:  0.00034361975849606097
Valid Loss:  0.0003552798880264163
Epoch:  433  	Training Loss: 0.00036172260297462344
Test Loss:  0.00034309958573430777
Valid Loss:  0.00035517499782145023
Epoch:  434  	Training Loss: 0.0003613947192206979
Test Loss:  0.0003427229530643672
Valid Loss:  0.0003551859990693629
Epoch:  435  	Training Loss: 0.00036113205715082586
Test Loss:  0.0003423295565880835
Valid Loss:  0.0003551559057086706
Epoch:  436  	Training Loss: 0.0003608757979236543
Test Loss:  0.0003419379354454577
Valid Loss:  0.00035510928137227893
Epoch:  437  	Training Loss: 0.0003606242244131863
Test Loss:  0.00034154957393184304
Valid Loss:  0.00035505174309946597
Epoch:  438  	Training Loss: 0.0003603782970458269
Test Loss:  0.0003412204096093774
Valid Loss:  0.00035498535726219416
Epoch:  439  	Training Loss: 0.00036014526267535985
Test Loss:  0.0003409550990909338
Valid Loss:  0.00035494595067575574
Epoch:  440  	Training Loss: 0.0003599360352382064
Test Loss:  0.0003407139447517693
Valid Loss:  0.0003549280227161944
Epoch:  441  	Training Loss: 0.00035973137710243464
Test Loss:  0.00034047369263134897
Valid Loss:  0.0003549445536918938
Epoch:  442  	Training Loss: 0.0003595294547267258
Test Loss:  0.0003397787222638726
Valid Loss:  0.00035428671981208026
Epoch:  443  	Training Loss: 0.00035934464540332556
Test Loss:  0.000339288089890033
Valid Loss:  0.0003538619785103947
Epoch:  444  	Training Loss: 0.0003591922577470541
Test Loss:  0.00033890007762238383
Valid Loss:  0.0003535693685989827
Epoch:  445  	Training Loss: 0.0003590462147258222
Test Loss:  0.00033858115784823895
Valid Loss:  0.0003533657582011074
Epoch:  446  	Training Loss: 0.00035890439176000655
Test Loss:  0.0003383128787390888
Valid Loss:  0.00035322312032803893
Epoch:  447  	Training Loss: 0.00035876440233550966
Test Loss:  0.0003380965208634734
Valid Loss:  0.0003531191614456475
Epoch:  448  	Training Loss: 0.0003586342791095376
Test Loss:  0.0003379465779289603
Valid Loss:  0.0003530633985064924
Epoch:  449  	Training Loss: 0.000358516292180866
Test Loss:  0.0003378047258593142
Valid Loss:  0.00035301788011565804
Epoch:  450  	Training Loss: 0.00035839935299009085
Test Loss:  0.0003376705280970782
Valid Loss:  0.0003529799869284034
Epoch:  451  	Training Loss: 0.0003582843055482954
Test Loss:  0.000337541161570698
Valid Loss:  0.00035294739063829184
Epoch:  452  	Training Loss: 0.00035816984018310905
Test Loss:  0.00033712590811774135
Valid Loss:  0.0003525223000906408
Epoch:  453  	Training Loss: 0.0003580742341000587
Test Loss:  0.00033678262843750417
Valid Loss:  0.0003521895268931985
Epoch:  454  	Training Loss: 0.00035799009492620826
Test Loss:  0.00033640459878370166
Valid Loss:  0.00035178824327886105
Epoch:  455  	Training Loss: 0.0003579289768822491
Test Loss:  0.00033606626675464213
Valid Loss:  0.00035143306013196707
Epoch:  456  	Training Loss: 0.00035787327215075493
Test Loss:  0.0003357884124852717
Valid Loss:  0.0003511513350531459
Epoch:  457  	Training Loss: 0.00035782321356236935
Test Loss:  0.00033554411493241787
Valid Loss:  0.00035090005258098245
Epoch:  458  	Training Loss: 0.0003577863681130111
Test Loss:  0.00033534126123413444
Valid Loss:  0.000350700895069167
Epoch:  459  	Training Loss: 0.00035775062860921025
Test Loss:  0.0003351717023178935
Valid Loss:  0.00035054059117101133
Epoch:  460  	Training Loss: 0.0003577166353352368
Test Loss:  0.000335027405526489
Valid Loss:  0.0003504125343170017
Epoch:  461  	Training Loss: 0.0003576830495148897
Test Loss:  0.0003349031903780997
Valid Loss:  0.00035030802246183157
Epoch:  462  	Training Loss: 0.0003576513845473528
Test Loss:  0.000340368744218722
Valid Loss:  0.00035780726466327906
Epoch:  463  	Training Loss: 0.00035743816988542676
Test Loss:  0.0003375416563358158
Valid Loss:  0.0003540129982866347
Epoch:  464  	Training Loss: 0.0003573346184566617
Test Loss:  0.00033879303373396397
Valid Loss:  0.0003557436866685748
Epoch:  465  	Training Loss: 0.00035725621273741126
Test Loss:  0.0003380943671800196
Valid Loss:  0.000354826042894274
Epoch:  466  	Training Loss: 0.000357183744199574
Test Loss:  0.00033834250643849373
Valid Loss:  0.00035519502125680447
Epoch:  467  	Training Loss: 0.0003571131092030555
Test Loss:  0.0003381306305527687
Valid Loss:  0.000354939402313903
Epoch:  468  	Training Loss: 0.00035704392939805984
Test Loss:  0.0003381435526534915
Valid Loss:  0.00035499094519764185
Epoch:  469  	Training Loss: 0.00035697472048923373
Test Loss:  0.0003380489069968462
Valid Loss:  0.0003548961831256747
Epoch:  470  	Training Loss: 0.00035690583172254264
Test Loss:  0.0003380055713932961
Valid Loss:  0.00035487127024680376
Epoch:  471  	Training Loss: 0.00035683775786310434
Test Loss:  0.0003379392437636852
Valid Loss:  0.0003548148088157177
Epoch:  472  	Training Loss: 0.00035676907282322645
Test Loss:  0.0003375820233486593
Valid Loss:  0.0003526087384670973
Epoch:  473  	Training Loss: 0.00035293688415549695
Test Loss:  0.00033731971052475274
Valid Loss:  0.00035056902561336756
Epoch:  474  	Training Loss: 0.00035054353065788746
Test Loss:  0.00033686080132611096
Valid Loss:  0.0003483692998997867
Epoch:  475  	Training Loss: 0.00034875248093158007
Test Loss:  0.00033615913707762957
Valid Loss:  0.00034599448554217815
Epoch:  476  	Training Loss: 0.00034742284333333373
Test Loss:  0.00033530787914060056
Valid Loss:  0.0003436117840465158
Epoch:  477  	Training Loss: 0.0003463244065642357
Test Loss:  0.00033432868076488376
Valid Loss:  0.00034128883271478117
Epoch:  478  	Training Loss: 0.00034540591877885163
Test Loss:  0.00033315859036520123
Valid Loss:  0.00033904443262144923
 96%|█████████▌| 479/500 [05:34<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:41<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:41<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:41<00:06,  2.16it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.86it/s] 98%|█████████▊| 491/500 [05:48<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:48<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:48<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:48<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:48<00:00,  2.95it/s]100%|██████████| 500/500 [05:48<00:00,  1.43it/s]
Epoch:  479  	Training Loss: 0.0003447009949013591
Test Loss:  0.0003321317199151963
Valid Loss:  0.0003371014026924968
Epoch:  480  	Training Loss: 0.00034407636849209666
Test Loss:  0.00033130828524008393
Valid Loss:  0.0003353887004777789
Epoch:  481  	Training Loss: 0.00034353506634943187
Test Loss:  0.00033016936504282057
Valid Loss:  0.00033374119084328413
Epoch:  482  	Training Loss: 0.000343131716363132
Test Loss:  0.0003297337389085442
Valid Loss:  0.0003333107742946595
Epoch:  483  	Training Loss: 0.0003428905620239675
Test Loss:  0.00032936857314780354
Valid Loss:  0.0003329949686303735
Epoch:  484  	Training Loss: 0.0003426545881666243
Test Loss:  0.00032905564876273274
Valid Loss:  0.0003327599843032658
Epoch:  485  	Training Loss: 0.0003424231836106628
Test Loss:  0.00032877695048227906
Valid Loss:  0.0003325842844787985
Epoch:  486  	Training Loss: 0.00034219579538330436
Test Loss:  0.0003285265411250293
Valid Loss:  0.0003324493009131402
Epoch:  487  	Training Loss: 0.00034197227796539664
Test Loss:  0.00032829458359628916
Valid Loss:  0.0003323452256154269
Epoch:  488  	Training Loss: 0.00034175225300714374
Test Loss:  0.00032807717798277736
Valid Loss:  0.00033226367668248713
Epoch:  489  	Training Loss: 0.00034153542947024107
Test Loss:  0.0003278723161201924
Valid Loss:  0.0003321968833915889
Epoch:  490  	Training Loss: 0.0003413216909393668
Test Loss:  0.00032767467200756073
Valid Loss:  0.00033214158611372113
Epoch:  491  	Training Loss: 0.00034111092099919915
Test Loss:  0.00032748267403803766
Valid Loss:  0.0003320948453620076
Epoch:  492  	Training Loss: 0.00034090335248038173
Test Loss:  0.00032548385206609964
Valid Loss:  0.00032967625884339213
Epoch:  493  	Training Loss: 0.0003406949690543115
Test Loss:  0.0003248288994655013
Valid Loss:  0.00032901111990213394
Epoch:  494  	Training Loss: 0.00034056618460454047
Test Loss:  0.0003245837870053947
Valid Loss:  0.00032888242276385427
Epoch:  495  	Training Loss: 0.00034044700441882014
Test Loss:  0.0003244675463065505
Valid Loss:  0.00032892206218093634
Epoch:  496  	Training Loss: 0.00034033029805868864
Test Loss:  0.00032439272035844624
Valid Loss:  0.0003290139138698578
Epoch:  497  	Training Loss: 0.00034021600731648505
Test Loss:  0.0003243328828830272
Valid Loss:  0.00032912346068769693
Epoch:  498  	Training Loss: 0.00034010387025773525
Test Loss:  0.0003242779348511249
Valid Loss:  0.00032923725666478276
Epoch:  499  	Training Loss: 0.0003399939159862697
Test Loss:  0.00032422534422948956
Valid Loss:  0.00032935262424871325
Epoch:  500  	Training Loss: 0.0003398855624254793
Test Loss:  0.0003241737140342593
Valid Loss:  0.0003294655471108854
seed is  17
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.51it/s]  1%|          | 4/500 [00:00<00:30, 16.20it/s]  1%|          | 6/500 [00:00<00:30, 16.27it/s]  2%|▏         | 8/500 [00:00<00:30, 16.38it/s]  2%|▏         | 10/500 [00:00<00:29, 16.41it/s]  2%|▏         | 12/500 [00:00<00:29, 16.49it/s]  3%|▎         | 14/500 [00:00<00:29, 16.50it/s]  3%|▎         | 16/500 [00:00<00:29, 16.55it/s]  4%|▎         | 18/500 [00:01<00:29, 16.54it/s]  4%|▍         | 20/500 [00:01<00:29, 16.47it/s]  4%|▍         | 22/500 [00:01<00:29, 16.38it/s]  5%|▍         | 24/500 [00:01<00:29, 16.40it/s]  5%|▌         | 26/500 [00:01<00:28, 16.42it/s]  6%|▌         | 28/500 [00:01<00:28, 16.44it/s]  6%|▌         | 30/500 [00:01<00:28, 16.48it/s]  6%|▋         | 32/500 [00:01<00:28, 16.49it/s]  7%|▋         | 34/500 [00:02<00:28, 16.53it/s]  7%|▋         | 36/500 [00:02<00:28, 16.53it/s]  8%|▊         | 38/500 [00:02<00:28, 16.47it/s]  8%|▊         | 40/500 [00:02<00:28, 16.23it/s]  8%|▊         | 42/500 [00:02<00:28, 16.27it/s]  9%|▉         | 44/500 [00:02<00:28, 16.18it/s]  9%|▉         | 46/500 [00:02<00:27, 16.31it/s] 10%|▉         | 48/500 [00:02<00:27, 16.36it/s] 10%|█         | 50/500 [00:03<00:27, 16.39it/s] 10%|█         | 52/500 [00:03<00:27, 16.40it/s] 11%|█         | 54/500 [00:03<00:27, 16.51it/s] 11%|█         | 56/500 [00:03<00:26, 16.54it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.41it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.48it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.47it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.46it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.28it/s] 14%|█▎        | 68/500 [00:04<00:28, 15.08it/s] 14%|█▍        | 70/500 [00:04<00:30, 14.18it/s] 14%|█▍        | 72/500 [00:04<00:31, 13.59it/s] 15%|█▍        | 74/500 [00:04<00:30, 13.98it/s] 15%|█▌        | 76/500 [00:04<00:29, 14.43it/s] 16%|█▌        | 78/500 [00:04<00:30, 13.78it/s] 16%|█▌        | 80/500 [00:05<00:31, 13.29it/s] 16%|█▋        | 82/500 [00:05<00:30, 13.58it/s] 17%|█▋        | 84/500 [00:05<00:29, 14.32it/s] 17%|█▋        | 86/500 [00:05<00:27, 14.89it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.35it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.49it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.70it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.95it/s] 19%|█▉        | 96/500 [00:06<00:25, 16.10it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.16it/s] 20%|██        | 100/500 [00:06<00:24, 16.15it/s] 20%|██        | 102/500 [00:06<00:24, 16.24it/s] 21%|██        | 104/500 [00:06<00:24, 16.22it/s] 21%|██        | 106/500 [00:06<00:24, 16.30it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.41it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.43it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.42it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.42it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.46it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.49it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.49it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.50it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.53it/s]Epoch:  1  	Training Loss: 0.12434811890125275
Test Loss:  2134.944091796875
Valid Loss:  2137.723876953125
Epoch:  2  	Training Loss: 2135.57373046875
Test Loss:  175900922478592.0
Valid Loss:  174654291443712.0
Epoch:  3  	Training Loss: 173395379486720.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.37it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.36it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.44it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.42it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.27it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.64it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.88it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.05it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.17it/s] 29%|██▉       | 144/500 [00:09<00:22, 16.16it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.16it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.24it/s] 30%|███       | 150/500 [00:09<00:21, 16.30it/s] 30%|███       | 152/500 [00:09<00:21, 16.35it/s] 31%|███       | 154/500 [00:09<00:21, 16.20it/s] 31%|███       | 156/500 [00:09<00:21, 16.29it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.33it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.41it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.33it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.34it/s] 33%|███▎      | 166/500 [00:10<00:20, 15.97it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.04it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.17it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.27it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.14it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.20it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.30it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.37it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.41it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.36it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.28it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.34it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.39it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.33it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.27it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.30it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.37it/s] 40%|████      | 200/500 [00:12<00:18, 16.40it/s] 40%|████      | 202/500 [00:12<00:18, 16.43it/s] 41%|████      | 204/500 [00:12<00:18, 16.39it/s] 41%|████      | 206/500 [00:12<00:17, 16.40it/s] 42%|████▏     | 208/500 [00:12<00:18, 16.11it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.66it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.86it/s] 43%|████▎     | 214/500 [00:13<00:17, 15.96it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.10it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.24it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.35it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.40it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.42it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.39it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.27it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.29it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.34it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.37it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.41it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.49it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.47it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.45it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.40it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.23it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.23it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.26it/s] 50%|█████     | 252/500 [00:15<00:15, 16.25it/s] 51%|█████     | 254/500 [00:15<00:15, 16.37it/s] 51%|█████     | 256/500 [00:15<00:14, 16.39it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.38it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.39it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.48it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.33it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.38it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.41it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.45it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.35it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.39it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.41it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.42it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.45it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.50it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.52it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.50it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.48it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.49it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.33it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.31it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.36it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.37it/s] 60%|██████    | 300/500 [00:18<00:12, 16.40it/s] 60%|██████    | 302/500 [00:18<00:12, 16.43it/s] 61%|██████    | 304/500 [00:18<00:11, 16.45it/s] 61%|██████    | 306/500 [00:18<00:11, 16.45it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.45it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.37it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.35it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.42it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.43it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.36it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.39it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.27it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.35it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.44it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.44it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.45it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.32it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.26it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.18it/s] 68%|██████▊   | 338/500 [00:20<00:10, 15.99it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.11it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.22it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.29it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.08it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.22it/s] 70%|███████   | 350/500 [00:21<00:09, 16.15it/s] 70%|███████   | 352/500 [00:21<00:09, 16.16it/s] 71%|███████   | 354/500 [00:21<00:08, 16.22it/s] 71%|███████   | 356/500 [00:22<00:08, 16.28it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.30it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.29it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.17it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.24it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.32it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.24it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.28it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.35it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.42it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.38it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.34it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.40it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.46it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.33it/s] 77%|███████▋  | 386/500 [00:23<00:07, 16.28it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.42it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.46it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.21it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.28it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.35it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.39it/s] 80%|████████  | 400/500 [00:24<00:06, 16.14it/s] 80%|████████  | 402/500 [00:24<00:06, 14.71it/s] 81%|████████  | 404/500 [00:25<00:06, 13.97it/s] 81%|████████  | 406/500 [00:25<00:06, 14.61it/s] 82%|████████▏ | 408/500 [00:25<00:06, 15.13it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.52it/s] 82%|████████▏ | 412/500 [00:25<00:05, 15.84it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.02it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.17it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.27it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.30it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.27it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.31it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.29it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.41it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.43it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.44it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.47it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.44it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.34it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.25it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.29it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.35it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.36it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.38it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.37it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.37it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.12it/s] 91%|█████████ | 456/500 [00:28<00:02, 14.69it/s] 92%|█████████▏| 458/500 [00:28<00:03, 13.83it/s] 92%|█████████▏| 460/500 [00:28<00:03, 13.32it/s] 92%|█████████▏| 462/500 [00:28<00:02, 13.57it/s] 93%|█████████▎| 464/500 [00:28<00:02, 14.33it/s] 93%|█████████▎| 466/500 [00:28<00:02, 14.81it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.21it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.55it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.81it/s] 95%|█████████▍| 474/500 [00:29<00:01, 15.90it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.08it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.10it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.24it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.31it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.37it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.33it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.22it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.25it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.27it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.32it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.38it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.20it/s]100%|██████████| 500/500 [00:31<00:00, 15.87it/s]100%|██████████| 500/500 [00:31<00:00, 16.08it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  17
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:03,  6.26s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:40,  3.01it/s]  4%|▍         | 19/500 [00:26<02:40,  3.01it/s]  4%|▍         | 21/500 [00:26<17:21,  2.17s/it]  5%|▍         | 23/500 [00:26<12:10,  1.53s/it]  5%|▌         | 25/500 [00:32<15:56,  2.01s/it]  5%|▌         | 27/500 [00:32<11:14,  1.43s/it]  6%|▌         | 29/500 [00:32<07:58,  1.02s/it]  6%|▌         | 31/500 [00:45<20:06,  2.57s/it]  7%|▋         | 33/500 [00:45<14:09,  1.82s/it]  7%|▋         | 35/500 [00:51<17:10,  2.22s/it]  7%|▋         | 37/500 [00:51<12:07,  1.57s/it]  8%|▊         | 39/500 [00:51<08:36,  1.12s/it]  8%|▊         | 41/500 [01:04<20:28,  2.68s/it]  9%|▊         | 43/500 [01:04<14:25,  1.89s/it]  9%|▉         | 45/500 [01:10<17:11,  2.27s/it]  9%|▉         | 47/500 [01:11<12:08,  1.61s/it] 10%|▉         | 49/500 [01:11<08:36,  1.15s/it] 10%|█         | 51/500 [01:23<19:58,  2.67s/it] 11%|█         | 53/500 [01:23<14:04,  1.89s/it] 11%|█         | 55/500 [01:30<17:02,  2.30s/it] 11%|█▏        | 57/500 [01:30<12:04,  1.63s/it] 12%|█▏        | 59/500 [01:30<08:35,  1.17s/it] 12%|█▏        | 61/500 [01:43<19:47,  2.71s/it] 13%|█▎        | 63/500 [01:43<13:56,  1.91s/it]Epoch:  1  	Training Loss: 0.12434811890125275
Test Loss:  0.7184910178184509
Valid Loss:  0.7192379236221313
Epoch:  2  	Training Loss: 0.7321432828903198
Test Loss:  0.12055160105228424
Valid Loss:  0.12305139750242233
Epoch:  3  	Training Loss: 0.11566008627414703
Test Loss:  0.11830951273441315
Valid Loss:  0.12095296382904053
Epoch:  4  	Training Loss: 0.11373937129974365
Test Loss:  0.11830933392047882
Valid Loss:  0.12095294147729874
Epoch:  5  	Training Loss: 0.11373929679393768
Test Loss:  0.11830931901931763
Valid Loss:  0.12095293402671814
Epoch:  6  	Training Loss: 0.11373928934335709
Test Loss:  0.11830931901931763
Valid Loss:  0.12095292657613754
Epoch:  7  	Training Loss: 0.11373928934335709
Test Loss:  0.11830930411815643
Valid Loss:  0.12095292657613754
Epoch:  8  	Training Loss: 0.11373928189277649
Test Loss:  0.11830930411815643
Valid Loss:  0.12095291912555695
Epoch:  9  	Training Loss: 0.11373928189277649
Test Loss:  0.11830928921699524
Valid Loss:  0.12095291167497635
Epoch:  10  	Training Loss: 0.11373928189277649
Test Loss:  0.11830928921699524
Valid Loss:  0.12095289677381516
Epoch:  11  	Training Loss: 0.11373927444219589
Test Loss:  0.11830928921699524
Valid Loss:  0.12095289677381516
Epoch:  12  	Training Loss: 0.11373928189277649
Test Loss:  0.11830928176641464
Valid Loss:  0.12095288932323456
Epoch:  13  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  14  	Training Loss: 0.11373928189277649
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  15  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095289677381516
Epoch:  16  	Training Loss: 0.11373927444219589
Test Loss:  0.11830928176641464
Valid Loss:  0.12095288932323456
Epoch:  17  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  18  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095289677381516
Epoch:  19  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  20  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  22  	Training Loss: 0.11373928189277649
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  23  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  24  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  25  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  27  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  28  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  29  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  30  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  32  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  33  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  34  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  35  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  37  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  38  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  39  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  40  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  42  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  43  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  44  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  45  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  47  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  48  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  49  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  50  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  52  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  53  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  54  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  55  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  57  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  58  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  59  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  60  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  62  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  63  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
 13%|█▎        | 65/500 [01:49<16:30,  2.28s/it] 13%|█▎        | 67/500 [01:49<11:39,  1.61s/it] 14%|█▍        | 69/500 [01:49<08:15,  1.15s/it] 14%|█▍        | 71/500 [02:02<19:23,  2.71s/it] 15%|█▍        | 73/500 [02:02<13:42,  1.93s/it] 15%|█▌        | 75/500 [02:09<16:14,  2.29s/it] 15%|█▌        | 77/500 [02:09<11:27,  1.63s/it] 16%|█▌        | 79/500 [02:09<08:07,  1.16s/it] 16%|█▌        | 81/500 [02:21<18:38,  2.67s/it] 17%|█▋        | 83/500 [02:21<13:08,  1.89s/it] 17%|█▋        | 85/500 [02:28<15:38,  2.26s/it] 17%|█▋        | 87/500 [02:28<11:02,  1.60s/it] 18%|█▊        | 89/500 [02:28<07:49,  1.14s/it] 18%|█▊        | 91/500 [02:40<18:11,  2.67s/it] 19%|█▊        | 93/500 [02:40<12:48,  1.89s/it] 19%|█▉        | 95/500 [02:47<15:15,  2.26s/it] 19%|█▉        | 97/500 [02:47<10:46,  1.60s/it] 20%|█▉        | 99/500 [02:47<07:37,  1.14s/it] 20%|██        | 101/500 [02:59<17:39,  2.66s/it] 21%|██        | 103/500 [03:00<12:26,  1.88s/it] 21%|██        | 105/500 [03:06<14:49,  2.25s/it] 21%|██▏       | 107/500 [03:06<10:27,  1.60s/it] 22%|██▏       | 109/500 [03:06<07:24,  1.14s/it] 22%|██▏       | 111/500 [03:19<17:25,  2.69s/it] 23%|██▎       | 113/500 [03:19<12:16,  1.90s/it] 23%|██▎       | 115/500 [03:25<14:27,  2.25s/it] 23%|██▎       | 117/500 [03:25<10:12,  1.60s/it] 24%|██▍       | 119/500 [03:25<07:14,  1.14s/it] 24%|██▍       | 121/500 [03:32<11:09,  1.77s/it] 25%|██▍       | 123/500 [03:32<07:53,  1.26s/it]Epoch:  64  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  65  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  67  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  68  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  69  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  70  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  72  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  73  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  74  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  75  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  77  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  78  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  79  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  80  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  82  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  83  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  84  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  85  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  87  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  88  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  89  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  90  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  92  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  93  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  94  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  95  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  97  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  98  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  99  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  100  	Training Loss: 0.11373928189277649
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  102  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  103  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  104  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  105  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  107  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  108  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  109  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  110  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  112  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  113  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  114  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  115  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  117  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  118  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  119  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  120  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  121  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288187265396
Epoch:  122  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  123  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  124  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
 25%|██▌       | 125/500 [03:38<11:22,  1.82s/it] 25%|██▌       | 127/500 [03:38<08:03,  1.29s/it] 26%|██▌       | 129/500 [03:38<05:43,  1.08it/s] 26%|██▌       | 131/500 [03:51<15:31,  2.52s/it] 27%|██▋       | 133/500 [03:51<10:58,  1.79s/it] 27%|██▋       | 135/500 [03:57<13:29,  2.22s/it] 27%|██▋       | 137/500 [03:58<09:31,  1.57s/it] 28%|██▊       | 139/500 [03:58<06:44,  1.12s/it] 28%|██▊       | 141/500 [04:10<15:57,  2.67s/it] 29%|██▊       | 143/500 [04:10<11:13,  1.89s/it] 29%|██▉       | 145/500 [04:17<13:23,  2.26s/it] 29%|██▉       | 147/500 [04:17<09:26,  1.61s/it] 30%|██▉       | 149/500 [04:17<06:41,  1.14s/it] 30%|███       | 151/500 [04:29<15:30,  2.67s/it] 31%|███       | 153/500 [04:30<10:55,  1.89s/it] 31%|███       | 155/500 [04:36<13:01,  2.27s/it] 31%|███▏      | 157/500 [04:36<09:12,  1.61s/it] 32%|███▏      | 159/500 [04:36<06:32,  1.15s/it] 32%|███▏      | 161/500 [04:49<15:08,  2.68s/it] 33%|███▎      | 163/500 [04:49<10:38,  1.90s/it] 33%|███▎      | 165/500 [04:55<12:38,  2.26s/it] 33%|███▎      | 167/500 [04:55<08:54,  1.61s/it] 34%|███▍      | 169/500 [04:55<06:18,  1.14s/it] 34%|███▍      | 169/500 [05:06<06:18,  1.14s/it] 34%|███▍      | 171/500 [05:08<14:38,  2.67s/it] 35%|███▍      | 173/500 [05:08<10:18,  1.89s/it] 35%|███▌      | 175/500 [05:14<12:16,  2.27s/it] 35%|███▌      | 177/500 [05:14<08:39,  1.61s/it] 36%|███▌      | 179/500 [05:14<06:07,  1.14s/it] 36%|███▌      | 179/500 [05:26<06:07,  1.14s/it] 36%|███▌      | 181/500 [05:27<14:12,  2.67s/it] 37%|███▋      | 183/500 [05:27<09:59,  1.89s/it]Valid Loss:  0.12095289677381516
Epoch:  125  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  127  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  128  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  129  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  130  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  132  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  133  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  134  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  135  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  137  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  138  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  139  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  140  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  142  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  143  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  144  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  145  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288187265396
Epoch:  147  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  148  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  149  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  150  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  152  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  153  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095289677381516
Epoch:  154  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  155  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  157  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  158  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  159  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  160  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  162  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  163  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  164  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  165  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  167  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  168  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  169  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  170  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  172  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288187265396
Epoch:  173  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  174  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  175  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  177  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  178  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  179  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  180  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  182  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  183  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
 37%|███▋      | 185/500 [05:33<11:57,  2.28s/it] 37%|███▋      | 187/500 [05:34<08:27,  1.62s/it] 38%|███▊      | 189/500 [05:34<05:59,  1.16s/it] 38%|███▊      | 189/500 [05:46<05:59,  1.16s/it] 38%|███▊      | 191/500 [05:46<13:58,  2.71s/it] 39%|███▊      | 193/500 [05:47<09:49,  1.92s/it] 39%|███▉      | 195/500 [05:53<11:40,  2.30s/it] 39%|███▉      | 197/500 [05:53<08:13,  1.63s/it] 40%|███▉      | 199/500 [05:53<05:49,  1.16s/it] 40%|████      | 201/500 [06:06<13:14,  2.66s/it] 41%|████      | 203/500 [06:06<09:18,  1.88s/it] 41%|████      | 205/500 [06:12<11:04,  2.25s/it] 41%|████▏     | 207/500 [06:12<07:47,  1.60s/it] 42%|████▏     | 209/500 [06:12<05:31,  1.14s/it] 42%|████▏     | 211/500 [06:24<12:41,  2.64s/it] 43%|████▎     | 213/500 [06:25<08:55,  1.87s/it] 43%|████▎     | 215/500 [06:31<10:38,  2.24s/it] 43%|████▎     | 217/500 [06:31<07:31,  1.59s/it] 44%|████▍     | 219/500 [06:31<05:20,  1.14s/it] 44%|████▍     | 221/500 [06:44<12:22,  2.66s/it] 45%|████▍     | 223/500 [06:44<08:42,  1.89s/it] 45%|████▌     | 225/500 [06:50<10:21,  2.26s/it] 45%|████▌     | 227/500 [06:50<07:17,  1.60s/it] 46%|████▌     | 229/500 [06:50<05:09,  1.14s/it] 46%|████▌     | 231/500 [07:03<11:55,  2.66s/it] 47%|████▋     | 233/500 [07:03<08:23,  1.88s/it] 47%|████▋     | 235/500 [07:09<09:58,  2.26s/it] 47%|████▋     | 237/500 [07:09<07:01,  1.60s/it] 48%|████▊     | 239/500 [07:09<04:57,  1.14s/it] 48%|████▊     | 241/500 [07:22<11:32,  2.67s/it]Epoch:  184  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  185  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  187  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  188  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  189  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  190  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  192  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  193  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  194  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  195  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  197  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  198  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  199  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  200  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  202  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  203  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  204  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  205  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095289677381516
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  207  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  208  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  209  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  210  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  212  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  213  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  214  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  215  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  217  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095289677381516
Epoch:  218  	Training Loss: 0.11373928189277649
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288187265396
Epoch:  219  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  220  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  222  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  223  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  224  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  225  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  227  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  228  	Training Loss: 0.11373928189277649
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  229  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  230  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  232  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  233  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  234  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  235  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  237  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  238  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  239  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  240  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  242  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
 49%|████▊     | 243/500 [07:22<08:06,  1.89s/it] 49%|████▉     | 245/500 [07:28<09:40,  2.27s/it] 49%|████▉     | 247/500 [07:28<06:48,  1.61s/it] 50%|████▉     | 249/500 [07:29<04:48,  1.15s/it] 50%|█████     | 251/500 [07:41<11:06,  2.68s/it] 51%|█████     | 253/500 [07:41<07:47,  1.89s/it] 51%|█████     | 255/500 [07:48<09:18,  2.28s/it] 51%|█████▏    | 257/500 [07:48<06:33,  1.62s/it] 52%|█████▏    | 259/500 [07:48<04:37,  1.15s/it] 52%|█████▏    | 261/500 [08:00<10:33,  2.65s/it] 53%|█████▎    | 263/500 [08:00<07:24,  1.88s/it] 53%|█████▎    | 265/500 [08:07<08:50,  2.26s/it] 53%|█████▎    | 267/500 [08:07<06:13,  1.60s/it] 54%|█████▍    | 269/500 [08:07<04:23,  1.14s/it] 54%|█████▍    | 271/500 [08:19<10:07,  2.65s/it] 55%|█████▍    | 273/500 [08:19<07:06,  1.88s/it] 55%|█████▌    | 275/500 [08:26<08:25,  2.25s/it] 55%|█████▌    | 277/500 [08:26<05:55,  1.60s/it] 56%|█████▌    | 279/500 [08:26<04:11,  1.14s/it] 56%|█████▌    | 281/500 [08:38<09:44,  2.67s/it] 57%|█████▋    | 283/500 [08:39<06:50,  1.89s/it] 57%|█████▋    | 285/500 [08:45<08:07,  2.27s/it] 57%|█████▋    | 287/500 [08:45<05:44,  1.62s/it] 58%|█████▊    | 289/500 [08:45<04:03,  1.15s/it] 58%|█████▊    | 289/500 [08:56<04:03,  1.15s/it] 58%|█████▊    | 291/500 [08:58<09:21,  2.69s/it] 59%|█████▊    | 293/500 [08:58<06:33,  1.90s/it] 59%|█████▉    | 295/500 [09:04<07:45,  2.27s/it] 59%|█████▉    | 297/500 [09:04<05:26,  1.61s/it] 60%|█████▉    | 299/500 [09:04<03:50,  1.15s/it] 60%|█████▉    | 299/500 [09:16<03:50,  1.15s/it] 60%|██████    | 301/500 [09:17<08:54,  2.69s/it]Epoch:  243  	Training Loss: 0.11373928189277649
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  244  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  245  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  247  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  248  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  249  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  250  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  252  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  253  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  254  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  255  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  257  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  258  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  259  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  260  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  262  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  263  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  264  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  265  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095289677381516
Epoch:  267  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  268  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  269  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  270  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  272  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  273  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  274  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  275  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095289677381516
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  277  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  278  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  279  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  280  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  282  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  283  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  284  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  285  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  287  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  288  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  289  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  290  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  292  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  293  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  294  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095289677381516
Epoch:  295  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095289677381516
Epoch:  297  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  298  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  299  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  300  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  302  	Training Loss: 0.1137392669916153
 61%|██████    | 303/500 [09:17<06:14,  1.90s/it] 61%|██████    | 305/500 [09:23<07:24,  2.28s/it] 61%|██████▏   | 307/500 [09:24<05:13,  1.62s/it] 62%|██████▏   | 309/500 [09:24<03:41,  1.16s/it] 62%|██████▏   | 309/500 [09:36<03:41,  1.16s/it] 62%|██████▏   | 311/500 [09:36<08:27,  2.69s/it] 63%|██████▎   | 313/500 [09:36<05:56,  1.91s/it] 63%|██████▎   | 315/500 [09:43<07:06,  2.31s/it] 63%|██████▎   | 317/500 [09:43<04:59,  1.64s/it] 64%|██████▍   | 319/500 [09:43<03:30,  1.16s/it] 64%|██████▍   | 321/500 [09:55<07:57,  2.67s/it] 65%|██████▍   | 323/500 [09:56<05:33,  1.89s/it] 65%|██████▌   | 325/500 [10:02<06:38,  2.28s/it] 65%|██████▌   | 327/500 [10:02<04:39,  1.61s/it] 66%|██████▌   | 329/500 [10:02<03:16,  1.15s/it] 66%|██████▌   | 331/500 [10:15<07:28,  2.65s/it] 67%|██████▋   | 333/500 [10:15<05:13,  1.88s/it] 67%|██████▋   | 335/500 [10:21<06:13,  2.26s/it] 67%|██████▋   | 337/500 [10:21<04:22,  1.61s/it] 68%|██████▊   | 339/500 [10:21<03:05,  1.15s/it] 68%|██████▊   | 341/500 [10:34<07:06,  2.68s/it] 69%|██████▊   | 343/500 [10:34<04:58,  1.90s/it] 69%|██████▉   | 345/500 [10:40<05:52,  2.28s/it] 69%|██████▉   | 347/500 [10:40<04:06,  1.61s/it] 70%|██████▉   | 349/500 [10:41<02:53,  1.15s/it] 70%|███████   | 351/500 [10:53<06:37,  2.67s/it] 71%|███████   | 353/500 [10:53<04:37,  1.89s/it] 71%|███████   | 355/500 [10:59<05:28,  2.26s/it] 71%|███████▏  | 357/500 [11:00<03:49,  1.61s/it] 72%|███████▏  | 359/500 [11:00<02:41,  1.14s/it]Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  303  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  304  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  305  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095289677381516
Epoch:  307  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  308  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  309  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  310  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  312  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  313  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  314  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  315  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095289677381516
Epoch:  317  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  318  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  319  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  320  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  322  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  323  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  324  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  325  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  327  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  328  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  329  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  330  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  332  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  333  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  334  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095289677381516
Epoch:  335  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  337  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  338  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  339  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095289677381516
Epoch:  340  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  342  	Training Loss: 0.11373928189277649
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  343  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  344  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  345  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  347  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  348  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  349  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  350  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  352  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  353  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  354  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095289677381516
Epoch:  355  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  357  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  358  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  359  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  360  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:   72%|███████▏  | 361/500 [11:12<06:08,  2.65s/it] 73%|███████▎  | 363/500 [11:12<04:17,  1.88s/it] 73%|███████▎  | 365/500 [11:18<05:04,  2.25s/it] 73%|███████▎  | 367/500 [11:19<03:32,  1.60s/it] 74%|███████▍  | 369/500 [11:19<02:29,  1.14s/it] 74%|███████▍  | 371/500 [11:31<05:47,  2.69s/it] 75%|███████▍  | 373/500 [11:32<04:01,  1.91s/it] 75%|███████▌  | 375/500 [11:38<04:45,  2.28s/it] 75%|███████▌  | 377/500 [11:38<03:19,  1.62s/it] 76%|███████▌  | 379/500 [11:38<02:19,  1.15s/it] 76%|███████▌  | 381/500 [11:51<05:20,  2.70s/it] 77%|███████▋  | 383/500 [11:51<03:43,  1.91s/it] 77%|███████▋  | 385/500 [11:57<04:22,  2.29s/it] 77%|███████▋  | 387/500 [11:57<03:03,  1.62s/it] 78%|███████▊  | 389/500 [11:57<02:08,  1.15s/it] 78%|███████▊  | 391/500 [12:10<04:54,  2.70s/it] 79%|███████▊  | 393/500 [12:10<03:24,  1.91s/it] 79%|███████▉  | 395/500 [12:16<03:58,  2.27s/it] 79%|███████▉  | 397/500 [12:17<02:46,  1.61s/it] 80%|███████▉  | 399/500 [12:17<01:56,  1.15s/it] 80%|████████  | 401/500 [12:29<04:22,  2.65s/it] 81%|████████  | 403/500 [12:29<03:02,  1.88s/it] 81%|████████  | 405/500 [12:35<03:34,  2.26s/it] 81%|████████▏ | 407/500 [12:36<02:29,  1.60s/it] 82%|████████▏ | 409/500 [12:36<01:43,  1.14s/it] 82%|████████▏ | 409/500 [12:46<01:43,  1.14s/it] 82%|████████▏ | 411/500 [12:48<03:58,  2.68s/it] 83%|████████▎ | 413/500 [12:48<02:45,  1.90s/it] 83%|████████▎ | 415/500 [12:55<03:13,  2.28s/it] 83%|████████▎ | 417/500 [12:55<02:14,  1.62s/it] 84%|████████▍ | 419/500 [12:55<01:33,  1.16s/it]0.12095289677381516
Epoch:  362  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  363  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  364  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  365  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  367  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  368  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  369  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  370  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  372  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  373  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  374  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  375  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  377  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  378  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  379  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  380  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288187265396
Epoch:  382  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  383  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  384  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  385  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  387  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  388  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  389  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  390  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  392  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  393  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095289677381516
Epoch:  394  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  395  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  397  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  398  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  399  	Training Loss: 0.11373928189277649
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  400  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  402  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  403  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095289677381516
Epoch:  404  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  405  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  407  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  408  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  409  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  410  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  412  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  413  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  414  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  415  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095289677381516
Epoch:  417  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  418  	Training Loss: 0.11373928189277649
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  419  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  420  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
 84%|████████▍ | 419/500 [13:06<01:33,  1.16s/it] 84%|████████▍ | 421/500 [13:08<03:33,  2.70s/it] 85%|████████▍ | 423/500 [13:08<02:27,  1.91s/it] 85%|████████▌ | 425/500 [13:14<02:50,  2.28s/it] 85%|████████▌ | 427/500 [13:14<01:58,  1.62s/it] 86%|████████▌ | 429/500 [13:14<01:22,  1.16s/it] 86%|████████▌ | 429/500 [13:26<01:22,  1.16s/it] 86%|████████▌ | 431/500 [13:27<03:04,  2.68s/it] 87%|████████▋ | 433/500 [13:27<02:07,  1.90s/it] 87%|████████▋ | 435/500 [13:33<02:27,  2.27s/it] 87%|████████▋ | 437/500 [13:33<01:41,  1.61s/it] 88%|████████▊ | 439/500 [13:34<01:10,  1.15s/it] 88%|████████▊ | 439/500 [13:46<01:10,  1.15s/it] 88%|████████▊ | 441/500 [13:46<02:37,  2.67s/it] 89%|████████▊ | 443/500 [13:46<01:47,  1.89s/it] 89%|████████▉ | 445/500 [13:52<02:04,  2.26s/it] 89%|████████▉ | 447/500 [13:53<01:25,  1.60s/it] 90%|████████▉ | 449/500 [13:53<00:58,  1.14s/it] 90%|█████████ | 451/500 [14:05<02:10,  2.66s/it] 91%|█████████ | 453/500 [14:05<01:28,  1.89s/it] 91%|█████████ | 455/500 [14:12<01:43,  2.29s/it] 91%|█████████▏| 457/500 [14:12<01:10,  1.63s/it] 92%|█████████▏| 459/500 [14:12<00:47,  1.16s/it] 92%|█████████▏| 461/500 [14:25<01:44,  2.69s/it] 93%|█████████▎| 463/500 [14:25<01:10,  1.90s/it] 93%|█████████▎| 465/500 [14:31<01:20,  2.29s/it] 93%|█████████▎| 467/500 [14:31<00:53,  1.63s/it] 94%|█████████▍| 469/500 [14:31<00:35,  1.16s/it] 94%|█████████▍| 471/500 [14:44<01:18,  2.70s/it] 95%|█████████▍| 473/500 [14:44<00:51,  1.91s/it] 95%|█████████▌| 475/500 [14:50<00:57,  2.28s/it] 95%|█████████▌| 477/500 [14:51<00:37,  1.62s/it] 96%|█████████▌| 479/500 [14:51<00:24,  1.16s/it]Epoch:  421  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  422  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  423  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  424  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  425  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  427  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  428  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  429  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  430  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  432  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  433  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  434  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  435  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  437  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  438  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  439  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  440  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  442  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  443  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  444  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  445  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  447  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  448  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  449  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  450  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095289677381516
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  452  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  453  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  454  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  455  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  457  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  458  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  459  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  460  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  462  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  463  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  464  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  465  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  467  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288187265396
Epoch:  468  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  469  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  470  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  472  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  473  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  474  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  475  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.1137392669916153
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  477  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  478  	Training Loss: 0.11373927444219589
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  479  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  480  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
 96%|█████████▌| 481/500 [15:03<00:50,  2.67s/it] 97%|█████████▋| 483/500 [15:03<00:32,  1.89s/it] 97%|█████████▋| 485/500 [15:10<00:34,  2.27s/it] 97%|█████████▋| 487/500 [15:10<00:20,  1.61s/it] 98%|█████████▊| 489/500 [15:10<00:12,  1.15s/it] 98%|█████████▊| 491/500 [15:22<00:24,  2.67s/it] 99%|█████████▊| 493/500 [15:22<00:13,  1.89s/it] 99%|█████████▉| 495/500 [15:29<00:11,  2.26s/it] 99%|█████████▉| 497/500 [15:29<00:04,  1.60s/it]100%|█████████▉| 499/500 [15:29<00:01,  1.14s/it]100%|██████████| 500/500 [15:35<00:00,  1.87s/it]
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  482  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  483  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288187265396
Epoch:  484  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  485  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  487  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  488  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  489  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  490  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  492  	Training Loss: 0.11373927444219589
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  493  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  494  	Training Loss: 0.1137392669916153
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
Epoch:  495  	Training Loss: 0.1137392669916153
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  497  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288187265396
Epoch:  498  	Training Loss: 0.11373928189277649
Test Loss:  0.11830927431583405
Valid Loss:  0.12095288932323456
Epoch:  499  	Training Loss: 0.11373927444219589
Test Loss:  0.11830925941467285
Valid Loss:  0.12095288932323456
Epoch:  500  	Training Loss: 0.11373928189277649
Test Loss:  0.11830926686525345
Valid Loss:  0.12095288932323456
**************************************************learning rate decay**************************************************
seed is  17
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:06,  6.39s/it]  1%|          | 3/500 [00:06<14:08,  1.71s/it]  1%|          | 5/500 [00:06<07:07,  1.16it/s]  1%|▏         | 7/500 [00:06<04:20,  1.89it/s]  2%|▏         | 9/500 [00:06<02:57,  2.76it/s]  2%|▏         | 11/500 [00:13<11:08,  1.37s/it]  3%|▎         | 13/500 [00:13<07:36,  1.07it/s]  3%|▎         | 15/500 [00:13<05:18,  1.52it/s]  3%|▎         | 17/500 [00:13<03:46,  2.13it/s]  4%|▍         | 19/500 [00:13<02:45,  2.90it/s]  4%|▍         | 21/500 [00:20<09:49,  1.23s/it]  5%|▍         | 23/500 [00:20<06:58,  1.14it/s]  5%|▌         | 25/500 [00:20<04:59,  1.59it/s]  5%|▌         | 27/500 [00:20<03:37,  2.18it/s]  6%|▌         | 29/500 [00:20<02:41,  2.92it/s]  6%|▌         | 31/500 [00:27<09:27,  1.21s/it]  7%|▋         | 33/500 [00:27<06:45,  1.15it/s]  7%|▋         | 35/500 [00:27<04:54,  1.58it/s]  7%|▋         | 37/500 [00:27<03:35,  2.15it/s]  8%|▊         | 39/500 [00:28<02:39,  2.89it/s]  8%|▊         | 41/500 [00:34<09:00,  1.18s/it]  9%|▊         | 43/500 [00:34<06:26,  1.18it/s]  9%|▉         | 45/500 [00:34<04:38,  1.64it/s]  9%|▉         | 47/500 [00:34<03:22,  2.23it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:41<08:54,  1.19s/it] 11%|█         | 53/500 [00:41<06:21,  1.17it/s] 11%|█         | 55/500 [00:41<04:35,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:48<08:41,  1.19s/it] 13%|█▎        | 63/500 [00:48<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:15,  2.22it/s] 14%|█▍        | 69/500 [00:48<02:24,  2.98it/s]Epoch:  1  	Training Loss: 0.12434811890125275
Test Loss:  0.013715933077037334
Valid Loss:  0.018269885331392288
Epoch:  2  	Training Loss: 0.021673541516065598
Test Loss:  0.013239933177828789
Valid Loss:  0.015937890857458115
Epoch:  3  	Training Loss: 0.015399724245071411
Test Loss:  0.0073277922347188
Valid Loss:  0.010056937113404274
Epoch:  4  	Training Loss: 0.011880863457918167
Test Loss:  0.008236236870288849
Valid Loss:  0.009681887924671173
Epoch:  5  	Training Loss: 0.008668728172779083
Test Loss:  0.0037997267208993435
Valid Loss:  0.005694379098713398
Epoch:  6  	Training Loss: 0.006589011754840612
Test Loss:  0.004535308573395014
Valid Loss:  0.00560954213142395
Epoch:  7  	Training Loss: 0.004770810715854168
Test Loss:  0.0020933467894792557
Valid Loss:  0.00343737262301147
Epoch:  8  	Training Loss: 0.00374367693439126
Test Loss:  0.002612375421449542
Valid Loss:  0.003493370022624731
Epoch:  9  	Training Loss: 0.0029412689618766308
Test Loss:  0.0014843849930912256
Valid Loss:  0.0024711317382752895
Epoch:  10  	Training Loss: 0.0024550994858145714
Test Loss:  0.001711097895167768
Valid Loss:  0.002454630099236965
Epoch:  11  	Training Loss: 0.0021093846298754215
Test Loss:  0.0012564497301355004
Valid Loss:  0.0020175990648567677
Epoch:  12  	Training Loss: 0.0018698195926845074
Test Loss:  0.001280065393075347
Valid Loss:  0.0019083679653704166
Epoch:  13  	Training Loss: 0.0016670514596626163
Test Loss:  0.0011085690930485725
Valid Loss:  0.0017256294377148151
Epoch:  14  	Training Loss: 0.0015444135060533881
Test Loss:  0.0011084587313234806
Valid Loss:  0.0016557074850425124
Epoch:  15  	Training Loss: 0.001438615843653679
Test Loss:  0.0010204624850302935
Valid Loss:  0.0015651340363547206
Epoch:  16  	Training Loss: 0.0013721731957048178
Test Loss:  0.0010194525821134448
Valid Loss:  0.0015299543738365173
Epoch:  17  	Training Loss: 0.0013199837412685156
Test Loss:  0.0009761542314663529
Valid Loss:  0.0014801487559452653
Epoch:  18  	Training Loss: 0.0012812457280233502
Test Loss:  0.0009042734163813293
Valid Loss:  0.0014220245648175478
Epoch:  19  	Training Loss: 0.001255247974768281
Test Loss:  0.0009733181796036661
Valid Loss:  0.0014354328159242868
Epoch:  20  	Training Loss: 0.001218549907207489
Test Loss:  0.0008950624614953995
Valid Loss:  0.0013738753041252494
Epoch:  21  	Training Loss: 0.0011881687678396702
Test Loss:  0.0009180062916129827
Valid Loss:  0.0013695925008505583
Epoch:  22  	Training Loss: 0.0011624150210991502
Test Loss:  0.000825745752081275
Valid Loss:  0.001242147758603096
Epoch:  23  	Training Loss: 0.0010625324212014675
Test Loss:  0.0007817513542249799
Valid Loss:  0.0011820101644843817
Epoch:  24  	Training Loss: 0.001014974433928728
Test Loss:  0.0007612190674990416
Valid Loss:  0.0011440766975283623
Epoch:  25  	Training Loss: 0.00097685179207474
Test Loss:  0.0007189366733655334
Valid Loss:  0.0011030161986127496
Epoch:  26  	Training Loss: 0.0009435809915885329
Test Loss:  0.0007243533618748188
Valid Loss:  0.0010857186280190945
Epoch:  27  	Training Loss: 0.0009140705224126577
Test Loss:  0.0006593078142032027
Valid Loss:  0.0010396927827969193
Epoch:  28  	Training Loss: 0.0008894280763342977
Test Loss:  0.0007170196622610092
Valid Loss:  0.0010516883339732885
Epoch:  29  	Training Loss: 0.0008696498116478324
Test Loss:  0.0005942479474470019
Valid Loss:  0.0009890885557979345
Epoch:  30  	Training Loss: 0.0008550530183129013
Test Loss:  0.000748854479752481
Valid Loss:  0.0010496012400835752
Epoch:  31  	Training Loss: 0.000847661285661161
Test Loss:  0.0005245214561000466
Valid Loss:  0.0009582571219652891
Epoch:  32  	Training Loss: 0.0008521638810634613
Test Loss:  0.0006184304365888238
Valid Loss:  0.0009731160243973136
Epoch:  33  	Training Loss: 0.0008069472387433052
Test Loss:  0.0005945471348240972
Valid Loss:  0.0009568543173372746
Epoch:  34  	Training Loss: 0.0007955955807119608
Test Loss:  0.0005856491043232381
Valid Loss:  0.0009475949918851256
Epoch:  35  	Training Loss: 0.0007852505659684539
Test Loss:  0.0005757309845648706
Valid Loss:  0.0009383531869389117
Epoch:  36  	Training Loss: 0.0007756471168249846
Test Loss:  0.0005670053069479764
Valid Loss:  0.000929699745029211
Epoch:  37  	Training Loss: 0.0007666056044399738
Test Loss:  0.0005583466263487935
Valid Loss:  0.0009212422301061451
Epoch:  38  	Training Loss: 0.0007581298123113811
Test Loss:  0.0005513468640856445
Valid Loss:  0.0009135715081356466
Epoch:  39  	Training Loss: 0.0007502756780013442
Test Loss:  0.0005453888443298638
Valid Loss:  0.0009063364705070853
Epoch:  40  	Training Loss: 0.0007431324338540435
Test Loss:  0.0005387347191572189
Valid Loss:  0.0008989527123048902
Epoch:  41  	Training Loss: 0.0007364558987319469
Test Loss:  0.0005329210544005036
Valid Loss:  0.0008920502150431275
Epoch:  42  	Training Loss: 0.000730106548871845
Test Loss:  0.0005459252279251814
Valid Loss:  0.0008881084504537284
Epoch:  43  	Training Loss: 0.0007204035064205527
Test Loss:  0.000509060628246516
Valid Loss:  0.0008682766929268837
Epoch:  44  	Training Loss: 0.0007148296572268009
Test Loss:  0.0005311950808390975
Valid Loss:  0.0008736803429201245
Epoch:  45  	Training Loss: 0.0007094570901244879
Test Loss:  0.0005008024163544178
Valid Loss:  0.0008573072263970971
Epoch:  46  	Training Loss: 0.0007043741061352193
Test Loss:  0.0005198712460696697
Valid Loss:  0.0008618095889687538
Epoch:  47  	Training Loss: 0.0006995160947553813
Test Loss:  0.000493525352794677
Valid Loss:  0.0008476281655021012
Epoch:  48  	Training Loss: 0.0006947984220460057
Test Loss:  0.0005095727974548936
Valid Loss:  0.0008513970533385873
Epoch:  49  	Training Loss: 0.0006904485635459423
Test Loss:  0.0004874950391240418
Valid Loss:  0.0008392519084736705
Epoch:  50  	Training Loss: 0.0006861897418275476
Test Loss:  0.0005006543942727149
Valid Loss:  0.0008419502410106361
Epoch:  51  	Training Loss: 0.0006820863345637918
Test Loss:  0.0004810468526557088
Valid Loss:  0.0008310805424116552
Epoch:  52  	Training Loss: 0.0006781923002563417
Test Loss:  0.0004803675692528486
Valid Loss:  0.000818443950265646
Epoch:  53  	Training Loss: 0.0006625802488997579
Test Loss:  0.00046478884178213775
Valid Loss:  0.00080240482930094
Epoch:  54  	Training Loss: 0.0006500784656964242
Test Loss:  0.00045484458678402007
Valid Loss:  0.000790808058809489
Epoch:  55  	Training Loss: 0.0006424937164410949
Test Loss:  0.00045145495096221566
Valid Loss:  0.0007858215249143541
Epoch:  56  	Training Loss: 0.0006368989706970751
Test Loss:  0.000443101889686659
Valid Loss:  0.0007778821745887399
Epoch:  57  	Training Loss: 0.0006324168061837554
Test Loss:  0.0004437763709574938
Valid Loss:  0.0007756030536256731
Epoch:  58  	Training Loss: 0.000628555309958756
Test Loss:  0.00043762687710113823
Valid Loss:  0.0007694606902077794
Epoch:  59  	Training Loss: 0.0006250606966204941
Test Loss:  0.00043774174991995096
Valid Loss:  0.0007674170774407685
Epoch:  60  	Training Loss: 0.000621945655439049
Test Loss:  0.0004328726208768785
Valid Loss:  0.0007625948055647314
Epoch:  61  	Training Loss: 0.0006190734566189349
Test Loss:  0.0004336833953857422
Valid Loss:  0.0007615354843437672
Epoch:  62  	Training Loss: 0.0006164718070067465
Test Loss:  0.00042435521027073264
Valid Loss:  0.0007562354439869523
Epoch:  63  	Training Loss: 0.0006127207889221609
Test Loss:  0.00042495253728702664
Valid Loss:  0.0007551832241006196
Epoch:  64  	Training Loss: 0.000609530252404511
Test Loss:  0.00041966483695432544
Valid Loss:  0.0007515060715377331
Epoch:  65  	Training Loss: 0.0006064590415917337
Test Loss:  0.00041839730693027377
Valid Loss:  0.0007494294550269842
Epoch:  66  	Training Loss: 0.0006035667611286044
Test Loss:  0.0004155075876042247
Valid Loss:  0.0007465512026101351
Epoch:  67  	Training Loss: 0.000600866274908185
Test Loss:  0.0004132244212087244
Valid Loss:  0.000744072487577796
Epoch:  68  	Training Loss: 0.000598462182097137
Test Loss:  0.00041190674528479576
Valid Loss:  0.0007418683962896466
Epoch:  69  	Training Loss: 0.000596227531787008
Test Loss:  0.00041002099169418216
Valid Loss:  0.0007393372361548245
 14%|█▍        | 71/500 [00:54<08:24,  1.18s/it] 15%|█▍        | 73/500 [00:55<06:00,  1.18it/s] 15%|█▌        | 75/500 [00:55<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:55<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:55<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:01<08:19,  1.19s/it] 17%|█▋        | 83/500 [01:02<05:59,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:20,  1.59it/s] 17%|█▋        | 87/500 [01:02<03:12,  2.15it/s] 18%|█▊        | 89/500 [01:02<02:24,  2.84it/s] 18%|█▊        | 91/500 [01:09<08:21,  1.23s/it] 19%|█▊        | 93/500 [01:09<05:58,  1.14it/s] 19%|█▉        | 95/500 [01:09<04:17,  1.57it/s] 19%|█▉        | 97/500 [01:09<03:07,  2.15it/s] 20%|█▉        | 99/500 [01:09<02:18,  2.89it/s] 20%|██        | 101/500 [01:15<07:55,  1.19s/it] 21%|██        | 103/500 [01:16<05:41,  1.16it/s] 21%|██        | 105/500 [01:16<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:16<03:03,  2.14it/s] 22%|██▏       | 109/500 [01:16<02:17,  2.84it/s] 22%|██▏       | 111/500 [01:23<07:50,  1.21s/it] 23%|██▎       | 113/500 [01:23<05:36,  1.15it/s] 23%|██▎       | 115/500 [01:23<04:01,  1.59it/s] 23%|██▎       | 117/500 [01:23<02:55,  2.18it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.93it/s] 24%|██▍       | 121/500 [01:29<07:32,  1.19s/it] 25%|██▍       | 123/500 [01:30<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:30<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:30<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:30<02:05,  2.97it/s] 26%|██▌       | 131/500 [01:36<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:36<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:37<03:44,  1.63it/s]Epoch:  70  	Training Loss: 0.0005940470728091896
Test Loss:  0.0004083803214598447
Valid Loss:  0.0007369414088316262
Epoch:  71  	Training Loss: 0.000591930584050715
Test Loss:  0.0004068619746249169
Valid Loss:  0.0007345982594415545
Epoch:  72  	Training Loss: 0.0005898852250538766
Test Loss:  0.00040324387373402715
Valid Loss:  0.0007235600496642292
Epoch:  73  	Training Loss: 0.000575769750867039
Test Loss:  0.00038942875107750297
Valid Loss:  0.0007081794319674373
Epoch:  74  	Training Loss: 0.0005637573776766658
Test Loss:  0.0003828613553196192
Valid Loss:  0.0006943128537386656
Epoch:  75  	Training Loss: 0.000550035503692925
Test Loss:  0.0003713651094585657
Valid Loss:  0.0006782797863706946
Epoch:  76  	Training Loss: 0.0005361626390367746
Test Loss:  0.00036167880170978606
Valid Loss:  0.000664007558953017
Epoch:  77  	Training Loss: 0.0005225796485319734
Test Loss:  0.0003507311048451811
Valid Loss:  0.0006499617593362927
Epoch:  78  	Training Loss: 0.0005098860710859299
Test Loss:  0.00034062721533700824
Valid Loss:  0.0006368798203766346
Epoch:  79  	Training Loss: 0.0004982586833648384
Test Loss:  0.0003308667510282248
Valid Loss:  0.0006247250130400062
Epoch:  80  	Training Loss: 0.00048767816042527556
Test Loss:  0.00032192227081395686
Valid Loss:  0.000613753218203783
Epoch:  81  	Training Loss: 0.00047805672511458397
Test Loss:  0.00031385693000629544
Valid Loss:  0.0006035440601408482
Epoch:  82  	Training Loss: 0.0004693328228313476
Test Loss:  0.00030598868033848703
Valid Loss:  0.0005923181306570768
Epoch:  83  	Training Loss: 0.00046032274258323014
Test Loss:  0.00029627635376527905
Valid Loss:  0.0005819348734803498
Epoch:  84  	Training Loss: 0.00045225911890156567
Test Loss:  0.0002930534246843308
Valid Loss:  0.0005775360041297972
Epoch:  85  	Training Loss: 0.00044792285189032555
Test Loss:  0.0002908754686359316
Valid Loss:  0.0005741668283008039
Epoch:  86  	Training Loss: 0.00044427040847949684
Test Loss:  0.000287879491224885
Valid Loss:  0.0005704885697923601
Epoch:  87  	Training Loss: 0.00044089765287935734
Test Loss:  0.00028507737442851067
Valid Loss:  0.000567184470128268
Epoch:  88  	Training Loss: 0.0004378241137601435
Test Loss:  0.0002828050055541098
Valid Loss:  0.0005641064490191638
Epoch:  89  	Training Loss: 0.0004349168739281595
Test Loss:  0.0002806099073495716
Valid Loss:  0.0005611240630969405
Epoch:  90  	Training Loss: 0.00043217281927354634
Test Loss:  0.00027845927979797125
Valid Loss:  0.0005582229932770133
Epoch:  91  	Training Loss: 0.0004295706166885793
Test Loss:  0.0002763404627330601
Valid Loss:  0.00055553182028234
Epoch:  92  	Training Loss: 0.0004271637590136379
Test Loss:  0.0002749198174569756
Valid Loss:  0.0005528629408217967
Epoch:  93  	Training Loss: 0.00042447936721146107
Test Loss:  0.0002730945707298815
Valid Loss:  0.0005498905084095895
Epoch:  94  	Training Loss: 0.0004219211405143142
Test Loss:  0.0002713697322178632
Valid Loss:  0.0005469084717333317
Epoch:  95  	Training Loss: 0.00041940517257899046
Test Loss:  0.00026963610434904695
Valid Loss:  0.0005439156666398048
Epoch:  96  	Training Loss: 0.00041695794789120555
Test Loss:  0.00026802101638168097
Valid Loss:  0.0005409623263403773
Epoch:  97  	Training Loss: 0.00041453915764577687
Test Loss:  0.0002663777850102633
Valid Loss:  0.0005379946669563651
Epoch:  98  	Training Loss: 0.0004121573001611978
Test Loss:  0.00026455314946360886
Valid Loss:  0.0005350069259293377
Epoch:  99  	Training Loss: 0.0004098284989595413
Test Loss:  0.0002630555536597967
Valid Loss:  0.000532186240889132
Epoch:  100  	Training Loss: 0.0004075511242263019
Test Loss:  0.0002612102252896875
Valid Loss:  0.0005292609566822648
Epoch:  101  	Training Loss: 0.0004053096054121852
Test Loss:  0.0002598265709821135
Valid Loss:  0.0005265509244054556
Epoch:  102  	Training Loss: 0.0004031241696793586
Test Loss:  0.00025671609910205007
Valid Loss:  0.000522962654940784
Epoch:  103  	Training Loss: 0.0004005597438663244
Test Loss:  0.0002550026692915708
Valid Loss:  0.0005200684536248446
Epoch:  104  	Training Loss: 0.0003980422916356474
Test Loss:  0.0002530481433495879
Valid Loss:  0.0005170619115233421
Epoch:  105  	Training Loss: 0.0003955545253120363
Test Loss:  0.00025119082420133054
Valid Loss:  0.0005141206202097237
Epoch:  106  	Training Loss: 0.00039310273132286966
Test Loss:  0.00024925454636104405
Valid Loss:  0.0005111833452247083
Epoch:  107  	Training Loss: 0.0003906812344212085
Test Loss:  0.00024749920703470707
Valid Loss:  0.0005083530559204519
Epoch:  108  	Training Loss: 0.0003882972523570061
Test Loss:  0.00024574081180617213
Valid Loss:  0.0005055485526099801
Epoch:  109  	Training Loss: 0.0003859474672935903
Test Loss:  0.0002440183307044208
Valid Loss:  0.0005027723964303732
Epoch:  110  	Training Loss: 0.00038362405030056834
Test Loss:  0.0002423606492811814
Valid Loss:  0.000500051595736295
Epoch:  111  	Training Loss: 0.00038133159978315234
Test Loss:  0.00024072315136436373
Valid Loss:  0.0004973559989593923
Epoch:  112  	Training Loss: 0.00037906906800344586
Test Loss:  0.0002411029563518241
Valid Loss:  0.0004954925389029086
Epoch:  113  	Training Loss: 0.0003767634043470025
Test Loss:  0.00023842084920033813
Valid Loss:  0.0004922637599520385
Epoch:  114  	Training Loss: 0.00037471629912033677
Test Loss:  0.00023773554130457342
Valid Loss:  0.000490184873342514
Epoch:  115  	Training Loss: 0.0003728234441950917
Test Loss:  0.00023612345103174448
Valid Loss:  0.0004877022875007242
Epoch:  116  	Training Loss: 0.0003710393502842635
Test Loss:  0.00023529789177700877
Valid Loss:  0.00048567267367616296
Epoch:  117  	Training Loss: 0.0003692882019095123
Test Loss:  0.00023419634089805186
Valid Loss:  0.00048352719750255346
Epoch:  118  	Training Loss: 0.0003675736952573061
Test Loss:  0.00023340698680840433
Valid Loss:  0.000481534720165655
Epoch:  119  	Training Loss: 0.00036592106334865093
Test Loss:  0.00023223724565468729
Valid Loss:  0.00047947996063157916
Epoch:  120  	Training Loss: 0.00036436496884562075
Test Loss:  0.00023163482546806335
Valid Loss:  0.0004777081776410341
Epoch:  121  	Training Loss: 0.00036285683745518327
Test Loss:  0.00023066479479894042
Valid Loss:  0.00047577996156178415
Epoch:  122  	Training Loss: 0.00036138162249699235
Test Loss:  0.0002323360095033422
Valid Loss:  0.0004746530030388385
Epoch:  123  	Training Loss: 0.0003592651919461787
Test Loss:  0.00023104930005501956
Valid Loss:  0.00047229795018211007
Epoch:  124  	Training Loss: 0.0003573908470571041
Test Loss:  0.00022956162865739316
Valid Loss:  0.00046999927144497633
Epoch:  125  	Training Loss: 0.0003556140000000596
Test Loss:  0.00022822758182883263
Valid Loss:  0.00046784401638433337
Epoch:  126  	Training Loss: 0.0003539063036441803
Test Loss:  0.00022687329328618944
Valid Loss:  0.00046574402949772775
Epoch:  127  	Training Loss: 0.0003522547776810825
Test Loss:  0.00022566303960047662
Valid Loss:  0.0004637399688363075
Epoch:  128  	Training Loss: 0.00035065249539911747
Test Loss:  0.00022450291726272553
Valid Loss:  0.00046177743934094906
Epoch:  129  	Training Loss: 0.0003490756789688021
Test Loss:  0.0002233187115052715
Valid Loss:  0.0004598849918693304
Epoch:  130  	Training Loss: 0.00034753192448988557
Test Loss:  0.00022222174447961152
Valid Loss:  0.000458043155958876
Epoch:  131  	Training Loss: 0.00034602193045429885
Test Loss:  0.0002212019171565771
Valid Loss:  0.0004562338872347027
Epoch:  132  	Training Loss: 0.0003445346374064684
Test Loss:  0.0002127677871612832
Valid Loss:  0.00045018515083938837
Epoch:  133  	Training Loss: 0.00034210324520245194
Test Loss:  0.0002149371721316129
Valid Loss:  0.0004496134351938963
Epoch:  134  	Training Loss: 0.0003398801200091839
Test Loss:  0.0002114694070769474
Valid Loss:  0.00044621998677030206
Epoch:  135  	Training Loss: 0.0003377801040187478
Test Loss:  0.00021101321908645332
Valid Loss:  0.00044437055476009846
Epoch:  136  	Training Loss: 0.00033575191628187895
Test Loss:  0.00020912985200993717
Valid Loss:  0.00044181375415064394
Epoch:  137  	Training Loss: 0.00033378961961716413
Test Loss:  0.00020786531968042254
Valid Loss:  0.0004396057629492134 27%|██▋       | 137/500 [01:37<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:37<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:43<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:43<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:43<03:35,  1.64it/s] 29%|██▉       | 147/500 [01:43<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:44<01:56,  3.00it/s] 30%|███       | 151/500 [01:50<06:54,  1.19s/it] 31%|███       | 153/500 [01:50<04:55,  1.17it/s] 31%|███       | 155/500 [01:50<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:50<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:51<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:57<06:47,  1.20s/it] 33%|███▎      | 163/500 [01:57<04:50,  1.16it/s] 33%|███▎      | 165/500 [01:57<03:28,  1.60it/s] 33%|███▎      | 167/500 [01:57<02:31,  2.19it/s] 34%|███▍      | 169/500 [01:58<01:52,  2.95it/s] 34%|███▍      | 171/500 [02:04<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:04<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:04<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:04<02:27,  2.20it/s] 36%|███▌      | 179/500 [02:04<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:11<06:22,  1.20s/it] 37%|███▋      | 183/500 [02:11<04:32,  1.16it/s] 37%|███▋      | 185/500 [02:11<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:11<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:11<01:44,  2.96it/s] 38%|███▊      | 191/500 [02:18<06:09,  1.19s/it] 39%|███▊      | 193/500 [02:18<04:23,  1.17it/s] 39%|███▉      | 195/500 [02:18<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:18<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:18<01:41,  2.97it/s] 40%|████      | 201/500 [02:25<05:50,  1.17s/it] 41%|████      | 203/500 [02:25<04:09,  1.19it/s]
Epoch:  138  	Training Loss: 0.0003318754315841943
Test Loss:  0.0002062897547148168
Valid Loss:  0.0004373003321234137
Epoch:  139  	Training Loss: 0.00033002166310325265
Test Loss:  0.00020504207350313663
Valid Loss:  0.0004351538955233991
Epoch:  140  	Training Loss: 0.00032819187617860734
Test Loss:  0.00020370580023154616
Valid Loss:  0.00043298391392454505
Epoch:  141  	Training Loss: 0.00032639666460454464
Test Loss:  0.0002024884888669476
Valid Loss:  0.000430924235843122
Epoch:  142  	Training Loss: 0.0003246533451601863
Test Loss:  0.0002034376811934635
Valid Loss:  0.0004302463203202933
Epoch:  143  	Training Loss: 0.00032337658922187984
Test Loss:  0.00020277529256418347
Valid Loss:  0.00042879238026216626
Epoch:  144  	Training Loss: 0.0003221482620574534
Test Loss:  0.00020194172975607216
Valid Loss:  0.0004272646037861705
Epoch:  145  	Training Loss: 0.0003209277638234198
Test Loss:  0.00020110000332351774
Valid Loss:  0.0004257407272234559
Epoch:  146  	Training Loss: 0.0003197197220288217
Test Loss:  0.00020021677482873201
Valid Loss:  0.00042422034312039614
Epoch:  147  	Training Loss: 0.0003185307723470032
Test Loss:  0.00019932894792873412
Valid Loss:  0.0004227196332067251
Epoch:  148  	Training Loss: 0.00031735471566207707
Test Loss:  0.00019849013187922537
Valid Loss:  0.00042124639730900526
Epoch:  149  	Training Loss: 0.00031618605135008693
Test Loss:  0.0001976627390831709
Valid Loss:  0.00041978550143539906
Epoch:  150  	Training Loss: 0.0003150233533233404
Test Loss:  0.0001968471915461123
Valid Loss:  0.0004183382261544466
Epoch:  151  	Training Loss: 0.00031387165654450655
Test Loss:  0.00019604612316470593
Valid Loss:  0.00041691158548928797
Epoch:  152  	Training Loss: 0.00031272697378881276
Test Loss:  0.00019337642879690975
Valid Loss:  0.0004104198014829308
Epoch:  153  	Training Loss: 0.0003073001862503588
Test Loss:  0.00018812736379913986
Valid Loss:  0.00040381430881097913
Epoch:  154  	Training Loss: 0.00030278292251750827
Test Loss:  0.00018488355271983892
Valid Loss:  0.0003986548399552703
Epoch:  155  	Training Loss: 0.0002989554195664823
Test Loss:  0.00018166177324019372
Valid Loss:  0.00039406243013218045
Epoch:  156  	Training Loss: 0.0002957480610348284
Test Loss:  0.00017901702085509896
Valid Loss:  0.0003900685114786029
Epoch:  157  	Training Loss: 0.00029285706114023924
Test Loss:  0.00017650383233558387
Valid Loss:  0.00038644447340629995
Epoch:  158  	Training Loss: 0.0002901922562159598
Test Loss:  0.0001744164910633117
Valid Loss:  0.00038314779521897435
Epoch:  159  	Training Loss: 0.00028763836598955095
Test Loss:  0.00017236829444300383
Valid Loss:  0.00037998316111043096
Epoch:  160  	Training Loss: 0.00028521433705464005
Test Loss:  0.00017067010048776865
Valid Loss:  0.0003770480107050389
Epoch:  161  	Training Loss: 0.0002829399600159377
Test Loss:  0.0001690543140284717
Valid Loss:  0.00037418538704514503
Epoch:  162  	Training Loss: 0.000280753563856706
Test Loss:  0.00016983064415398985
Valid Loss:  0.0003734402125701308
Epoch:  163  	Training Loss: 0.00027927561313845217
Test Loss:  0.00016914395382627845
Valid Loss:  0.0003720568784046918
Epoch:  164  	Training Loss: 0.00027791608590632677
Test Loss:  0.00016839784802868962
Valid Loss:  0.00037061251350678504
Epoch:  165  	Training Loss: 0.0002766058314591646
Test Loss:  0.0001676366082392633
Valid Loss:  0.00036914460361003876
Epoch:  166  	Training Loss: 0.00027532779495231807
Test Loss:  0.00016688807227183133
Valid Loss:  0.0003676622873172164
Epoch:  167  	Training Loss: 0.00027407080051489174
Test Loss:  0.00016614039486739784
Valid Loss:  0.0003661693772301078
Epoch:  168  	Training Loss: 0.0002728301624301821
Test Loss:  0.00016539536591153592
Valid Loss:  0.0003646688419394195
Epoch:  169  	Training Loss: 0.00027160317404195666
Test Loss:  0.0001646534219617024
Valid Loss:  0.0003631650470197201
Epoch:  170  	Training Loss: 0.00027039082488045096
Test Loss:  0.00016391277313232422
Valid Loss:  0.0003616593894548714
Epoch:  171  	Training Loss: 0.00026918959338217974
Test Loss:  0.00016316986875608563
Valid Loss:  0.00036015664227306843
Epoch:  172  	Training Loss: 0.0002679985191207379
Test Loss:  0.00016037319437600672
Valid Loss:  0.0003563940117601305
Epoch:  173  	Training Loss: 0.0002659751917235553
Test Loss:  0.00015966649516485631
Valid Loss:  0.00035380173358134925
Epoch:  174  	Training Loss: 0.00026417634217068553
Test Loss:  0.00015775140491314232
Valid Loss:  0.0003510204260237515
Epoch:  175  	Training Loss: 0.0002624953631311655
Test Loss:  0.00015716798952780664
Valid Loss:  0.00034888461232185364
Epoch:  176  	Training Loss: 0.0002608803624752909
Test Loss:  0.00015573343262076378
Valid Loss:  0.0003465289482846856
Epoch:  177  	Training Loss: 0.0002593072422314435
Test Loss:  0.0001551384193589911
Valid Loss:  0.00034454106935299933
Epoch:  178  	Training Loss: 0.000257766165304929
Test Loss:  0.00015390865155495703
Valid Loss:  0.0003423919260967523
Epoch:  179  	Training Loss: 0.0002562562294770032
Test Loss:  0.00015328513109125197
Valid Loss:  0.00034050538670271635
Epoch:  180  	Training Loss: 0.0002547687035985291
Test Loss:  0.0001522064267192036
Valid Loss:  0.0003384929441381246
Epoch:  181  	Training Loss: 0.00025330408243462443
Test Loss:  0.00015155479195527732
Valid Loss:  0.0003366597229614854
Epoch:  182  	Training Loss: 0.0002518566616345197
Test Loss:  0.00014601543080061674
Valid Loss:  0.00033160351449623704
Epoch:  183  	Training Loss: 0.00024968775687739253
Test Loss:  0.0001482493244111538
Valid Loss:  0.00033171483664773405
Epoch:  184  	Training Loss: 0.0002485794830136001
Test Loss:  0.00014709008974023163
Valid Loss:  0.00033027984318323433
Epoch:  185  	Training Loss: 0.00024761888198554516
Test Loss:  0.00014680789900012314
Valid Loss:  0.00032925678533501923
Epoch:  186  	Training Loss: 0.0002466946025379002
Test Loss:  0.00014650283264927566
Valid Loss:  0.0003283231926616281
Epoch:  187  	Training Loss: 0.0002459028037264943
Test Loss:  0.0001462842628825456
Valid Loss:  0.0003276601782999933
Epoch:  188  	Training Loss: 0.0002452273038215935
Test Loss:  0.00014602752344217151
Valid Loss:  0.00032706939964555204
Epoch:  189  	Training Loss: 0.00024461737484671175
Test Loss:  0.00014585143071599305
Valid Loss:  0.0003265810664743185
Epoch:  190  	Training Loss: 0.00024406045849900693
Test Loss:  0.0001455724996048957
Valid Loss:  0.0003260471858084202
Epoch:  191  	Training Loss: 0.00024353933986276388
Test Loss:  0.00014543058932758868
Valid Loss:  0.00032561871921643615
Epoch:  192  	Training Loss: 0.0002430496970191598
Test Loss:  0.00014522696437779814
Valid Loss:  0.00032311477116309106
Epoch:  193  	Training Loss: 0.00024109383230097592
Test Loss:  0.00014359649503603578
Valid Loss:  0.0003205224056728184
Epoch:  194  	Training Loss: 0.00023975176736712456
Test Loss:  0.00014353041478898376
Valid Loss:  0.0003191318828612566
Epoch:  195  	Training Loss: 0.00023880433582235128
Test Loss:  0.00014270941028371453
Valid Loss:  0.0003176338504999876
Epoch:  196  	Training Loss: 0.0002379709912929684
Test Loss:  0.00014243039186112583
Valid Loss:  0.000316446996293962
Epoch:  197  	Training Loss: 0.00023718328156974167
Test Loss:  0.00014184610336087644
Valid Loss:  0.00031517731258645654
Epoch:  198  	Training Loss: 0.00023641716688871384
Test Loss:  0.00014148686022963375
Valid Loss:  0.00031402683816850185
Epoch:  199  	Training Loss: 0.00023566297022625804
Test Loss:  0.00014104240108281374
Valid Loss:  0.0003128815733361989
Epoch:  200  	Training Loss: 0.00023493607295677066
Test Loss:  0.0001406060764566064
Valid Loss:  0.00031175377080217004
Epoch:  201  	Training Loss: 0.00023423686798196286
Test Loss:  0.00014032810577191412
Valid Loss:  0.0003108235541731119
Epoch:  202  	Training Loss: 0.00023355954908765852
Test Loss:  0.00013743620365858078
Valid Loss:  0.0003079905000049621
Epoch:  203  	Training Loss: 0.00023177589173428714
Test Loss:  0.0001392093690810725
Valid Loss:  0.000306999369058758
Epoch:  204  	Training Loss: 0.00023008391144685447
Test Loss:  0.0001338617439614609
Valid Loss:  0.00030322285601869226
 41%|████      | 205/500 [02:25<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:25<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:25<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:38<10:08,  2.10s/it] 43%|████▎     | 213/500 [02:38<07:08,  1.49s/it] 43%|████▎     | 215/500 [02:38<05:08,  1.08s/it] 43%|████▎     | 217/500 [02:38<03:42,  1.27it/s] 44%|████▍     | 219/500 [02:38<02:40,  1.75it/s] 44%|████▍     | 221/500 [02:45<06:18,  1.36s/it] 45%|████▍     | 223/500 [02:45<04:29,  1.03it/s] 45%|████▌     | 225/500 [02:45<03:12,  1.43it/s] 45%|████▌     | 227/500 [02:45<02:20,  1.94it/s] 46%|████▌     | 229/500 [02:45<01:43,  2.61it/s] 46%|████▌     | 231/500 [02:52<05:35,  1.25s/it] 47%|████▋     | 233/500 [02:52<03:58,  1.12it/s] 47%|████▋     | 235/500 [02:52<02:51,  1.55it/s] 47%|████▋     | 237/500 [02:52<02:04,  2.12it/s] 48%|████▊     | 239/500 [02:52<01:32,  2.82it/s] 48%|████▊     | 241/500 [02:59<05:09,  1.19s/it] 49%|████▊     | 243/500 [02:59<03:40,  1.17it/s] 49%|████▉     | 245/500 [02:59<02:38,  1.61it/s] 49%|████▉     | 247/500 [02:59<01:55,  2.20it/s] 50%|████▉     | 249/500 [02:59<01:24,  2.96it/s] 50%|█████     | 251/500 [03:05<04:52,  1.18s/it] 51%|█████     | 253/500 [03:06<03:28,  1.18it/s] 51%|█████     | 255/500 [03:06<02:29,  1.63it/s] 51%|█████▏    | 257/500 [03:06<01:48,  2.23it/s] 52%|█████▏    | 259/500 [03:06<01:21,  2.97it/s] 52%|█████▏    | 261/500 [03:13<04:50,  1.21s/it] 53%|█████▎    | 263/500 [03:13<03:27,  1.14it/s] 53%|█████▎    | 265/500 [03:13<02:30,  1.57it/s] 53%|█████▎    | 267/500 [03:13<01:48,  2.14it/s] 54%|█████▍    | 269/500 [03:13<01:20,  2.87it/s]Epoch:  205  	Training Loss: 0.00022851326502859592
Test Loss:  0.00014012862811796367
Valid Loss:  0.0003042408498004079
Epoch:  206  	Training Loss: 0.00022714684018865228
Test Loss:  0.00012860044080298394
Valid Loss:  0.00029838489717803895
Epoch:  207  	Training Loss: 0.00022615541820414364
Test Loss:  0.00014679678133688867
Valid Loss:  0.00030481055728159845
Epoch:  208  	Training Loss: 0.00022608839208260179
Test Loss:  0.0001215958473039791
Valid Loss:  0.0002957545220851898
Epoch:  209  	Training Loss: 0.00022836023708805442
Test Loss:  0.0001751128729665652
Valid Loss:  0.0003204707463737577
Epoch:  210  	Training Loss: 0.00023634762328583747
Test Loss:  0.00012848153710365295
Valid Loss:  0.00031585065880790353
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.000259312626440078
Test Loss:  0.00011963193537667394
Valid Loss:  0.0002937481622211635
Epoch:  212  	Training Loss: 0.00022805437038186938
Test Loss:  0.00012839687406085432
Valid Loss:  0.0002900606777984649
Epoch:  213  	Training Loss: 0.00021748835570178926
Test Loss:  0.00013083982048556209
Valid Loss:  0.00029001684742979705
Epoch:  214  	Training Loss: 0.00021652266150340438
Test Loss:  0.00013095814210828394
Valid Loss:  0.00028936908347532153
Epoch:  215  	Training Loss: 0.000215903390198946
Test Loss:  0.00013070926070213318
Valid Loss:  0.0002886543807107955
Epoch:  216  	Training Loss: 0.00021532659593503922
Test Loss:  0.00013040672638453543
Valid Loss:  0.00028795169782824814
Epoch:  217  	Training Loss: 0.0002147880004486069
Test Loss:  0.00013011458213441074
Valid Loss:  0.00028725643642246723
Epoch:  218  	Training Loss: 0.00021425893646664917
Test Loss:  0.00012983317719772458
Valid Loss:  0.00028656842187047005
Epoch:  219  	Training Loss: 0.00021374050993472338
Test Loss:  0.00012954887642990798
Valid Loss:  0.00028588168788701296
Epoch:  220  	Training Loss: 0.0002132375375367701
Test Loss:  0.0001292830565944314
Valid Loss:  0.0002852041507139802
Epoch:  221  	Training Loss: 0.00021273866877891123
Test Loss:  0.00012901242007501423
Valid Loss:  0.0002845290000550449
Epoch:  222  	Training Loss: 0.00021224327792879194
Test Loss:  0.0001269702916033566
Valid Loss:  0.0002828195574693382
Epoch:  223  	Training Loss: 0.0002113158698193729
Test Loss:  0.00012630152923520654
Valid Loss:  0.0002817503409460187
Epoch:  224  	Training Loss: 0.00021062116138637066
Test Loss:  0.00012613553553819656
Valid Loss:  0.00028111206484027207
Epoch:  225  	Training Loss: 0.0002101673453580588
Test Loss:  0.0001259772398043424
Valid Loss:  0.0002805463154800236
Epoch:  226  	Training Loss: 0.00020977325038984418
Test Loss:  0.00012581715418491513
Valid Loss:  0.00028001173632219434
Epoch:  227  	Training Loss: 0.00020941153343301266
Test Loss:  0.0001256766845472157
Valid Loss:  0.0002795409527607262
Epoch:  228  	Training Loss: 0.00020907263387925923
Test Loss:  0.00012554950080811977
Valid Loss:  0.00027911088545806706
Epoch:  229  	Training Loss: 0.00020875879272352904
Test Loss:  0.0001254416274605319
Valid Loss:  0.00027872188366018236
Epoch:  230  	Training Loss: 0.0002084651932818815
Test Loss:  0.00012533881817944348
Valid Loss:  0.0002783414092846215
Epoch:  231  	Training Loss: 0.00020818127086386085
Test Loss:  0.00012523018813226372
Valid Loss:  0.0002779675996862352
Epoch:  232  	Training Loss: 0.0002079031546600163
Test Loss:  0.00012547860387712717
Valid Loss:  0.0002776226319838315
Epoch:  233  	Training Loss: 0.00020750290423166007
Test Loss:  0.00012544769560918212
Valid Loss:  0.0002771939034573734
Epoch:  234  	Training Loss: 0.00020711455726996064
Test Loss:  0.00012530479580163956
Valid Loss:  0.00027673188014887273
Epoch:  235  	Training Loss: 0.0002067294408334419
Test Loss:  0.00012511611566878855
Valid Loss:  0.00027625757502391934
Epoch:  236  	Training Loss: 0.00020634560496546328
Test Loss:  0.00012490811059251428
Valid Loss:  0.00027577742002904415
Epoch:  237  	Training Loss: 0.0002059627149719745
Test Loss:  0.00012469329521991313
Valid Loss:  0.00027529586805030704
Epoch:  238  	Training Loss: 0.0002055800287052989
Test Loss:  0.00012448092456907034
Valid Loss:  0.000274816615274176
Epoch:  239  	Training Loss: 0.00020519907411653548
Test Loss:  0.00012426979083102196
Valid Loss:  0.00027433776995167136
Epoch:  240  	Training Loss: 0.0002048199821729213
Test Loss:  0.00012406075256876647
Valid Loss:  0.00027386361034587026
Epoch:  241  	Training Loss: 0.000204443495022133
Test Loss:  0.0001238550612470135
Valid Loss:  0.0002733906148932874
Epoch:  242  	Training Loss: 0.0002040681429207325
Test Loss:  0.00012439338024705648
Valid Loss:  0.00027323339600116014
Epoch:  243  	Training Loss: 0.0002038821403402835
Test Loss:  0.00012479770521167666
Valid Loss:  0.0002730877895373851
Epoch:  244  	Training Loss: 0.0002037359809037298
Test Loss:  0.0001250960340257734
Valid Loss:  0.00027294582105241716
Epoch:  245  	Training Loss: 0.00020361339556984603
Test Loss:  0.0001253123627975583
Valid Loss:  0.00027280423091724515
Epoch:  246  	Training Loss: 0.00020350304839666933
Test Loss:  0.00012546464859042317
Valid Loss:  0.00027265993412584066
Epoch:  247  	Training Loss: 0.0002034005883615464
Test Loss:  0.00012556579895317554
Valid Loss:  0.0002725138620007783
Epoch:  248  	Training Loss: 0.0002033035270869732
Test Loss:  0.00012562716437969357
Valid Loss:  0.0002723674988374114
Epoch:  249  	Training Loss: 0.0002032095071626827
Test Loss:  0.0001256575487786904
Valid Loss:  0.0002722195931710303
Epoch:  250  	Training Loss: 0.00020311838306952268
Test Loss:  0.0001256661198567599
Valid Loss:  0.00027207157108932734
Epoch:  251  	Training Loss: 0.000203028874238953
Test Loss:  0.00012565727229230106
Valid Loss:  0.0002719241310842335
Epoch:  252  	Training Loss: 0.00020294000569265336
Test Loss:  0.00012423761654645205
Valid Loss:  0.00027106102788820863
Epoch:  253  	Training Loss: 0.00020260456949472427
Test Loss:  0.00012350099859759212
Valid Loss:  0.0002704689686652273
Epoch:  254  	Training Loss: 0.00020234825205989182
Test Loss:  0.00012306278222240508
Valid Loss:  0.0002699948672670871
Epoch:  255  	Training Loss: 0.00020211274386383593
Test Loss:  0.0001227665925398469
Valid Loss:  0.00026956922374665737
Epoch:  256  	Training Loss: 0.00020188592316117138
Test Loss:  0.0001225459564011544
Valid Loss:  0.0002691734116524458
Epoch:  257  	Training Loss: 0.000201664021005854
Test Loss:  0.00012236068141646683
Valid Loss:  0.00026879788492806256
Epoch:  258  	Training Loss: 0.0002014451747527346
Test Loss:  0.00012218879419378936
Valid Loss:  0.0002684322535060346
Epoch:  259  	Training Loss: 0.00020122804562561214
Test Loss:  0.00012202319339849055
Valid Loss:  0.0002680752077139914
Epoch:  260  	Training Loss: 0.000201013550395146
Test Loss:  0.0001218601391883567
Valid Loss:  0.0002677258162293583
Epoch:  261  	Training Loss: 0.00020080021931789815
Test Loss:  0.00012170158152002841
Valid Loss:  0.0002673821581993252
Epoch:  262  	Training Loss: 0.00020058915833942592
Test Loss:  0.00012196593161206692
Valid Loss:  0.00026714574778452516
Epoch:  263  	Training Loss: 0.00020027707796543837
Test Loss:  0.00012203836377011612
Valid Loss:  0.00026685211923904717
Epoch:  264  	Training Loss: 0.0001999770029215142
Test Loss:  0.00012199825869174674
Valid Loss:  0.00026652554515749216
Epoch:  265  	Training Loss: 0.00019968330161646008
Test Loss:  0.00012189931294415146
Valid Loss:  0.00026618223637342453
Epoch:  266  	Training Loss: 0.00019939325284212828
Test Loss:  0.00012176889867987484
Valid Loss:  0.0002658263547345996
Epoch:  267  	Training Loss: 0.00019910463015548885
Test Loss:  0.00012161344784544781
Valid Loss:  0.0002654658746905625
Epoch:  268  	Training Loss: 0.00019881816115230322
Test Loss:  0.00012145250366302207
Valid Loss:  0.00026510230964049697
Epoch:  269  	Training Loss: 0.0001985338458325714
Test Loss:  0.00012128870002925396
Valid Loss:  0.0002647379005793482
Epoch:  270  	Training Loss: 0.00019825148046948016
Test Loss:  0.00012112197873648256
Valid Loss:  0.00026437040651217103
 54%|█████▍    | 271/500 [03:19<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:20<03:11,  1.19it/s] 55%|█████▌    | 275/500 [03:20<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:20<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:20<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:26<04:21,  1.20s/it] 57%|█████▋    | 283/500 [03:26<03:06,  1.16it/s] 57%|█████▋    | 285/500 [03:27<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:27<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:27<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:33<04:11,  1.20s/it] 59%|█████▊    | 293/500 [03:33<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:34<02:07,  1.60it/s] 59%|█████▉    | 297/500 [03:34<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:34<01:08,  2.95it/s] 60%|██████    | 301/500 [03:40<03:55,  1.18s/it] 61%|██████    | 303/500 [03:40<02:47,  1.18it/s] 61%|██████    | 305/500 [03:40<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:41<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:41<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:47<03:46,  1.20s/it] 63%|██████▎   | 313/500 [03:47<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:47<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:48<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:48<01:01,  2.94it/s] 64%|██████▍   | 321/500 [03:54<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:54<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:54<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:54<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:55<00:57,  2.96it/s] 66%|██████▌   | 331/500 [04:01<03:19,  1.18s/it] 67%|██████▋   | 333/500 [04:01<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:01<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:01<01:13,  2.22it/s]Epoch:  271  	Training Loss: 0.00019797030836343765
Test Loss:  0.00012095406418666244
Valid Loss:  0.00026399962371215224
Epoch:  272  	Training Loss: 0.0001976911153178662
Test Loss:  0.00011967847967753187
Valid Loss:  0.00026296661235392094
Epoch:  273  	Training Loss: 0.0001969865697901696
Test Loss:  0.00011895375791937113
Valid Loss:  0.0002620047889649868
Epoch:  274  	Training Loss: 0.00019621122919488698
Test Loss:  0.00011831856681965292
Valid Loss:  0.0002609782386571169
Epoch:  275  	Training Loss: 0.0001953182218130678
Test Loss:  0.0001177613012259826
Valid Loss:  0.0002599322178866714
Epoch:  276  	Training Loss: 0.00019439999596215785
Test Loss:  0.00011731906124623492
Valid Loss:  0.00025891687255352736
Epoch:  277  	Training Loss: 0.00019353760580997914
Test Loss:  0.00011696643196046352
Valid Loss:  0.0002579995198175311
Epoch:  278  	Training Loss: 0.0001927774865180254
Test Loss:  0.00011667398212011904
Valid Loss:  0.0002571391232777387
Epoch:  279  	Training Loss: 0.00019208693993277848
Test Loss:  0.0001164602508652024
Valid Loss:  0.00025636976351961493
Epoch:  280  	Training Loss: 0.00019151068408973515
Test Loss:  0.00011633512622211128
Valid Loss:  0.00025575171457603574
Epoch:  281  	Training Loss: 0.00019104155944660306
Test Loss:  0.00011616850679274648
Valid Loss:  0.00025514798471704125
Epoch:  282  	Training Loss: 0.00019060175691265613
Test Loss:  0.00011608490603975952
Valid Loss:  0.00025487656239420176
Epoch:  283  	Training Loss: 0.00019024874200113118
Test Loss:  0.0001159868115792051
Valid Loss:  0.00025460447068326175
Epoch:  284  	Training Loss: 0.00018991652177646756
Test Loss:  0.00011588320921873674
Valid Loss:  0.00025434151757508516
Epoch:  285  	Training Loss: 0.0001896029571071267
Test Loss:  0.0001157861843239516
Valid Loss:  0.00025408982764929533
Epoch:  286  	Training Loss: 0.00018930522492155433
Test Loss:  0.00011568971967790276
Valid Loss:  0.00025384672335349023
Epoch:  287  	Training Loss: 0.0001890211133286357
Test Loss:  0.00011559809354366735
Valid Loss:  0.00025361101143062115
Epoch:  288  	Training Loss: 0.00018874782836064696
Test Loss:  0.0001155062418547459
Valid Loss:  0.0002533774822950363
Epoch:  289  	Training Loss: 0.00018848414765670896
Test Loss:  0.00011541284038685262
Valid Loss:  0.0002531454083509743
Epoch:  290  	Training Loss: 0.00018822851416189224
Test Loss:  0.00011532266944414005
Valid Loss:  0.0002529183984734118
Epoch:  291  	Training Loss: 0.0001879796909634024
Test Loss:  0.000115229791845195
Valid Loss:  0.00025269261095672846
Epoch:  292  	Training Loss: 0.0001877362374216318
Test Loss:  0.00011516496306285262
Valid Loss:  0.0002516270033083856
Epoch:  293  	Training Loss: 0.00018695829203352332
Test Loss:  0.00011459675442893058
Valid Loss:  0.0002504998992662877
Epoch:  294  	Training Loss: 0.00018625834491103888
Test Loss:  0.00011410456500016153
Valid Loss:  0.0002494824002496898
Epoch:  295  	Training Loss: 0.0001856170711107552
Test Loss:  0.00011367008846718818
Valid Loss:  0.0002485568984411657
Epoch:  296  	Training Loss: 0.00018501946760807186
Test Loss:  0.0001132736069848761
Valid Loss:  0.0002476773806847632
Epoch:  297  	Training Loss: 0.00018444500165060163
Test Loss:  0.00011288875975878909
Valid Loss:  0.0002468388411216438
Epoch:  298  	Training Loss: 0.00018389348406344652
Test Loss:  0.00011252445983700454
Valid Loss:  0.00024603569181635976
Epoch:  299  	Training Loss: 0.00018335756612941623
Test Loss:  0.00011217236169613898
Valid Loss:  0.0002452600747346878
Epoch:  300  	Training Loss: 0.00018283419194631279
Test Loss:  0.00011183130118297413
Valid Loss:  0.00024450579076074064
Epoch:  301  	Training Loss: 0.0001823203929234296
Test Loss:  0.0001115001505240798
Valid Loss:  0.00024377088993787766
Epoch:  302  	Training Loss: 0.00018181379709858447
Test Loss:  0.00011205853661522269
Valid Loss:  0.0002434058114886284
Epoch:  303  	Training Loss: 0.00018149556126445532
Test Loss:  0.0001122912872233428
Valid Loss:  0.00024302980455104262
Epoch:  304  	Training Loss: 0.0001812255650293082
Test Loss:  0.00011233908298891038
Valid Loss:  0.0002426458231639117
Epoch:  305  	Training Loss: 0.0001809720997698605
Test Loss:  0.00011228737275814638
Valid Loss:  0.0002422562101855874
Epoch:  306  	Training Loss: 0.00018072492093779147
Test Loss:  0.00011218275176361203
Valid Loss:  0.00024186537484638393
Epoch:  307  	Training Loss: 0.00018048097263090312
Test Loss:  0.00011205393093405291
Valid Loss:  0.00024147793010342866
Epoch:  308  	Training Loss: 0.00018023938173428178
Test Loss:  0.00011191154044354334
Valid Loss:  0.00024109306104946882
Epoch:  309  	Training Loss: 0.0001800004974938929
Test Loss:  0.00011175965482834727
Valid Loss:  0.00024071588995866477
Epoch:  310  	Training Loss: 0.00017976381059270352
Test Loss:  0.0001116104976972565
Valid Loss:  0.00024034356465563178
Epoch:  311  	Training Loss: 0.00017952831694856286
Test Loss:  0.00011146441102027893
Valid Loss:  0.00023997585230972618
Epoch:  312  	Training Loss: 0.0001792935945559293
Test Loss:  0.00011129326594527811
Valid Loss:  0.0002397497883066535
Epoch:  313  	Training Loss: 0.00017910175665747374
Test Loss:  0.00011115121014881879
Valid Loss:  0.00023953472555149347
Epoch:  314  	Training Loss: 0.0001789207453839481
Test Loss:  0.00011103264114353806
Valid Loss:  0.00023932629846967757
Epoch:  315  	Training Loss: 0.0001787467481335625
Test Loss:  0.0001109229342546314
Valid Loss:  0.0002391224988969043
Epoch:  316  	Training Loss: 0.00017858039063867182
Test Loss:  0.00011081944103352726
Valid Loss:  0.00023891947057563812
Epoch:  317  	Training Loss: 0.00017841928638517857
Test Loss:  0.00011072040069848299
Valid Loss:  0.0002387200074736029
Epoch:  318  	Training Loss: 0.0001782634062692523
Test Loss:  0.00011062500561820343
Valid Loss:  0.0002385204570600763
Epoch:  319  	Training Loss: 0.00017811183352023363
Test Loss:  0.00011053217167500407
Valid Loss:  0.0002383221435593441
Epoch:  320  	Training Loss: 0.00017796349129639566
Test Loss:  0.00011044220445910469
Valid Loss:  0.00023812650761101395
Epoch:  321  	Training Loss: 0.00017781872884370387
Test Loss:  0.0001103541799238883
Valid Loss:  0.00023792978026904166
Epoch:  322  	Training Loss: 0.0001776764402166009
Test Loss:  0.0001096997584681958
Valid Loss:  0.0002369807771174237
Epoch:  323  	Training Loss: 0.00017712543194647878
Test Loss:  0.00010936184844467789
Valid Loss:  0.00023616851831320673
Epoch:  324  	Training Loss: 0.00017661323363427073
Test Loss:  0.00010909544653259218
Valid Loss:  0.00023540371330454946
Epoch:  325  	Training Loss: 0.00017612027295399457
Test Loss:  0.00010884170478675514
Valid Loss:  0.00023466450511477888
Epoch:  326  	Training Loss: 0.00017563317669555545
Test Loss:  0.00010860675683943555
Valid Loss:  0.00023393769515678287
Epoch:  327  	Training Loss: 0.00017514439241494983
Test Loss:  0.00010833423584699631
Valid Loss:  0.00023318256717175245
Epoch:  328  	Training Loss: 0.0001746481575537473
Test Loss:  0.0001080357760656625
Valid Loss:  0.00023241285816766322
Epoch:  329  	Training Loss: 0.0001741448068059981
Test Loss:  0.00010773319809231907
Valid Loss:  0.00023165075981523842
Epoch:  330  	Training Loss: 0.0001736379344947636
Test Loss:  0.00010743048187578097
Valid Loss:  0.00023089299793355167
Epoch:  331  	Training Loss: 0.0001731281663523987
Test Loss:  0.00010713123629102483
Valid Loss:  0.00023014962789602578
Epoch:  332  	Training Loss: 0.00017262222536373883
Test Loss:  0.0001067232369678095
Valid Loss:  0.0002297006139997393
Epoch:  333  	Training Loss: 0.00017225256306119263
Test Loss:  0.00010649717296473682
Valid Loss:  0.00022930449631530792
Epoch:  334  	Training Loss: 0.00017189659411087632
Test Loss:  0.00010632287012413144
Valid Loss:  0.00022892144625075161
Epoch:  335  	Training Loss: 0.00017154973465949297
Test Loss:  0.00010616244253469631
Valid Loss:  0.00022854209237266332
Epoch:  336  	Training Loss: 0.00017121058772318065
Test Loss:  0.00010600723908282816
Valid Loss:  0.00022816583805251867
Epoch:  337  	Training Loss: 0.0001708784984657541
Test Loss:  0.00010584873234620318
Valid Loss:  0.00022778943821322173
 68%|██████▊   | 339/500 [04:01<00:53,  2.99it/s] 68%|██████▊   | 341/500 [04:08<03:08,  1.19s/it] 69%|██████▊   | 343/500 [04:08<02:13,  1.17it/s] 69%|██████▉   | 345/500 [04:08<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:08<01:08,  2.22it/s] 70%|██████▉   | 349/500 [04:08<00:50,  2.99it/s] 70%|███████   | 351/500 [04:15<02:55,  1.18s/it] 71%|███████   | 353/500 [04:15<02:04,  1.18it/s] 71%|███████   | 355/500 [04:15<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:15<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:15<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:22<02:49,  1.22s/it] 73%|███████▎  | 363/500 [04:22<01:59,  1.14it/s] 73%|███████▎  | 365/500 [04:22<01:25,  1.58it/s] 73%|███████▎  | 367/500 [04:22<01:01,  2.16it/s] 74%|███████▍  | 369/500 [04:22<00:45,  2.91it/s] 74%|███████▍  | 371/500 [04:29<02:34,  1.19s/it] 75%|███████▍  | 373/500 [04:29<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:29<01:18,  1.59it/s] 75%|███████▌  | 377/500 [04:29<00:57,  2.14it/s] 76%|███████▌  | 379/500 [04:29<00:42,  2.84it/s] 76%|███████▌  | 381/500 [04:36<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:36<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:36<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:36<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:36<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:42<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:43<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:43<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:43<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:43<00:33,  3.01it/s] 80%|████████  | 401/500 [04:49<01:57,  1.19s/it] 81%|████████  | 403/500 [04:49<01:22,  1.17it/s]Epoch:  338  	Training Loss: 0.00017055471835192293
Test Loss:  0.00010568380821496248
Valid Loss:  0.00022741763677913696
Epoch:  339  	Training Loss: 0.00017023851978592575
Test Loss:  0.00010550441947998479
Valid Loss:  0.0002270534314448014
Epoch:  340  	Training Loss: 0.00016993271128740162
Test Loss:  0.00010532886517466977
Valid Loss:  0.00022669238387607038
Epoch:  341  	Training Loss: 0.00016962508379947394
Test Loss:  0.00010516004840610549
Valid Loss:  0.00022632208128925413
Epoch:  342  	Training Loss: 0.00016931400750763714
Test Loss:  0.0001052159204846248
Valid Loss:  0.00022596053895540535
Epoch:  343  	Training Loss: 0.0001690796052571386
Test Loss:  0.00010519836359890178
Valid Loss:  0.00022560512297786772
Epoch:  344  	Training Loss: 0.00016885856166481972
Test Loss:  0.00010516253678360954
Valid Loss:  0.00022527537657879293
Epoch:  345  	Training Loss: 0.00016865061479620636
Test Loss:  0.00010511094296816736
Valid Loss:  0.00022495377925224602
Epoch:  346  	Training Loss: 0.00016844834317453206
Test Loss:  0.00010505829413887113
Valid Loss:  0.00022464200446847826
Epoch:  347  	Training Loss: 0.00016825133934617043
Test Loss:  0.00010500457574380562
Valid Loss:  0.0002243390044895932
Epoch:  348  	Training Loss: 0.00016805774066597223
Test Loss:  0.00010495181777514517
Valid Loss:  0.00022404240735340863
Epoch:  349  	Training Loss: 0.00016786772175692022
Test Loss:  0.00010490038403077051
Valid Loss:  0.00022375324624590576
Epoch:  350  	Training Loss: 0.0001676800602581352
Test Loss:  0.0001048488265951164
Valid Loss:  0.00022346741752699018
Epoch:  351  	Training Loss: 0.00016749463975429535
Test Loss:  0.00010479264165041968
Valid Loss:  0.00022318228730000556
Epoch:  352  	Training Loss: 0.00016731006326153874
Test Loss:  0.00010453847062308341
Valid Loss:  0.00022272809292189777
Epoch:  353  	Training Loss: 0.0001670047058723867
Test Loss:  0.00010432161070639268
Valid Loss:  0.0002222898037871346
Epoch:  354  	Training Loss: 0.0001667043543420732
Test Loss:  0.00010411936091259122
Valid Loss:  0.00022186522255651653
Epoch:  355  	Training Loss: 0.00016640734975226223
Test Loss:  0.00010392489639343694
Valid Loss:  0.00022144851391203701
Epoch:  356  	Training Loss: 0.00016611372120678425
Test Loss:  0.00010373016993980855
Valid Loss:  0.0002210367820225656
Epoch:  357  	Training Loss: 0.00016581962700001895
Test Loss:  0.00010354189726058394
Valid Loss:  0.0002206326462328434
Epoch:  358  	Training Loss: 0.00016552666784264147
Test Loss:  0.00010335606930311769
Valid Loss:  0.00022023319615982473
Epoch:  359  	Training Loss: 0.0001652357168495655
Test Loss:  0.0001031799110933207
Valid Loss:  0.00021983252372592688
Epoch:  360  	Training Loss: 0.00016494246665388346
Test Loss:  0.00010299711721017957
Valid Loss:  0.0002194347616750747
Epoch:  361  	Training Loss: 0.000164651675731875
Test Loss:  0.00010281459253747016
Valid Loss:  0.00021904203458689153
Epoch:  362  	Training Loss: 0.0001643625000724569
Test Loss:  0.00010281943832524121
Valid Loss:  0.0002187910577049479
Epoch:  363  	Training Loss: 0.00016414518177043647
Test Loss:  0.00010276434477418661
Valid Loss:  0.0002185265184380114
Epoch:  364  	Training Loss: 0.00016393206897191703
Test Loss:  0.00010268639744026586
Valid Loss:  0.0002182559692300856
Epoch:  365  	Training Loss: 0.00016372071695514023
Test Loss:  0.00010260660201311111
Valid Loss:  0.00021797968656755984
Epoch:  366  	Training Loss: 0.00016351033991668373
Test Loss:  0.00010251571802655235
Valid Loss:  0.0002176992711611092
Epoch:  367  	Training Loss: 0.00016330135986208916
Test Loss:  0.00010241956624668092
Valid Loss:  0.00021741670207120478
Epoch:  368  	Training Loss: 0.00016309405327774584
Test Loss:  0.0001023194199660793
Valid Loss:  0.0002171312808059156
Epoch:  369  	Training Loss: 0.0001628866739338264
Test Loss:  0.00010221823322353885
Valid Loss:  0.00021684564126189798
Epoch:  370  	Training Loss: 0.00016267935279756784
Test Loss:  0.0001021151983877644
Valid Loss:  0.00021655844466295093
Epoch:  371  	Training Loss: 0.00016247312305495143
Test Loss:  0.00010201228724326938
Valid Loss:  0.00021627117530442774
Epoch:  372  	Training Loss: 0.00016226802836172283
Test Loss:  0.00010197098890785128
Valid Loss:  0.000216030195588246
Epoch:  373  	Training Loss: 0.00016212041373364627
Test Loss:  0.00010191946057602763
Valid Loss:  0.00021579198073595762
Epoch:  374  	Training Loss: 0.00016197470540646464
Test Loss:  0.00010186480358242989
Valid Loss:  0.0002155561960535124
Epoch:  375  	Training Loss: 0.00016182796389330178
Test Loss:  0.00010180936806136742
Valid Loss:  0.00021531936363317072
Epoch:  376  	Training Loss: 0.0001616804802324623
Test Loss:  0.00010174881754210219
Valid Loss:  0.0002150858344975859
Epoch:  377  	Training Loss: 0.0001615346991457045
Test Loss:  0.00010168467997573316
Valid Loss:  0.0002148598723579198
Epoch:  378  	Training Loss: 0.00016139073704835027
Test Loss:  0.00010162108083022758
Valid Loss:  0.00021463894518092275
Epoch:  379  	Training Loss: 0.00016124924877658486
Test Loss:  0.00010155993368243799
Valid Loss:  0.0002144232130376622
Epoch:  380  	Training Loss: 0.00016110924480017275
Test Loss:  0.0001014989975374192
Valid Loss:  0.00021421100245788693
Epoch:  381  	Training Loss: 0.00016096796025522053
Test Loss:  0.00010144196858163923
Valid Loss:  0.00021400149853434414
Epoch:  382  	Training Loss: 0.0001608286111149937
Test Loss:  0.00010110627772519365
Valid Loss:  0.0002135521499440074
Epoch:  383  	Training Loss: 0.00016057040193118155
Test Loss:  0.00010101943917106837
Valid Loss:  0.00021317118080332875
Epoch:  384  	Training Loss: 0.0001603251730557531
Test Loss:  0.00010091610602103174
Valid Loss:  0.00021281189401634037
Epoch:  385  	Training Loss: 0.0001600874529685825
Test Loss:  0.00010081763321068138
Valid Loss:  0.00021246258984319866
Epoch:  386  	Training Loss: 0.00015985549543984234
Test Loss:  0.00010071722499560565
Valid Loss:  0.00021212213323451579
Epoch:  387  	Training Loss: 0.00015962644829414785
Test Loss:  0.00010062666842713952
Valid Loss:  0.00021177870803512633
Epoch:  388  	Training Loss: 0.00015939577133394778
Test Loss:  0.0001005275989882648
Valid Loss:  0.00021143366757314652
Epoch:  389  	Training Loss: 0.00015916742268018425
Test Loss:  0.00010042531357612461
Valid Loss:  0.00021109145018272102
Epoch:  390  	Training Loss: 0.0001589409075677395
Test Loss:  0.0001003273791866377
Valid Loss:  0.00021075300173833966
Epoch:  391  	Training Loss: 0.00015871573123149574
Test Loss:  0.00010022917558671907
Valid Loss:  0.0002104132727254182
Epoch:  392  	Training Loss: 0.0001584927085787058
Test Loss:  0.00010036768799182028
Valid Loss:  0.00021018835832364857
Epoch:  393  	Training Loss: 0.00015821710985619575
Test Loss:  0.00010037085303338245
Valid Loss:  0.0002099461416946724
Epoch:  394  	Training Loss: 0.00015796734078321606
Test Loss:  0.00010033265425590798
Valid Loss:  0.00020970444893464446
Epoch:  395  	Training Loss: 0.00015773580526001751
Test Loss:  0.00010028443648479879
Valid Loss:  0.0002094666997436434
Epoch:  396  	Training Loss: 0.00015751761384308338
Test Loss:  0.00010023031063610688
Valid Loss:  0.0002092348295263946
Epoch:  397  	Training Loss: 0.0001573119661770761
Test Loss:  0.0001001749697024934
Valid Loss:  0.00020900953677482903
Epoch:  398  	Training Loss: 0.0001571156462887302
Test Loss:  0.0001001218261080794
Valid Loss:  0.00020878792565781623
Epoch:  399  	Training Loss: 0.00015692386659793556
Test Loss:  0.00010005984222516418
Valid Loss:  0.00020857057825196534
Epoch:  400  	Training Loss: 0.00015673774760216475
Test Loss:  9.999606118071824e-05
Valid Loss:  0.00020835426403209567
Epoch:  401  	Training Loss: 0.0001565562270116061
Test Loss:  9.993261483032256e-05
Valid Loss:  0.00020813730952795595
Epoch:  402  	Training Loss: 0.00015637509932275862
Test Loss:  9.974617569241673e-05
Valid Loss:  0.0002073910436592996
Epoch:  403  	Training Loss: 0.00015590881230309606
Test Loss:  9.931628301274031e-05
Valid Loss:  0.00020666381169576198
Epoch:  404  	Training Loss: 0.0001554852060507983
Test Loss:  9.893378592096269e-05
Valid Loss:  0.0002060060651274398
 81%|████████  | 405/500 [04:50<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:50<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:50<00:30,  2.96it/s] 82%|████████▏ | 411/500 [04:56<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:56<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:57<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:57<00:38,  2.17it/s] 84%|████████▍ | 419/500 [04:57<00:27,  2.90it/s] 84%|████████▍ | 421/500 [05:03<01:33,  1.19s/it] 85%|████████▍ | 423/500 [05:03<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:03<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:04<00:33,  2.21it/s] 86%|████████▌ | 429/500 [05:04<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:10<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:10<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:10<00:40,  1.60it/s] 87%|████████▋ | 437/500 [05:11<00:29,  2.15it/s] 88%|████████▊ | 439/500 [05:11<00:21,  2.85it/s] 88%|████████▊ | 441/500 [05:17<01:11,  1.22s/it] 89%|████████▊ | 443/500 [05:17<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:17<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:18<00:24,  2.17it/s] 90%|████████▉ | 449/500 [05:18<00:17,  2.92it/s] 90%|█████████ | 451/500 [05:24<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:24<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:24<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:24<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:25<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:31<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:31<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:31<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:31<00:14,  2.20it/s] 94%|█████████▍| 469/500 [05:31<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:38<00:34,  1.18s/it]Epoch:  405  	Training Loss: 0.00015509399236179888
Test Loss:  9.860387945082039e-05
Valid Loss:  0.00020540077821351588
Epoch:  406  	Training Loss: 0.00015472123050130904
Test Loss:  9.829663031268865e-05
Valid Loss:  0.00020482663239818066
Epoch:  407  	Training Loss: 0.00015435926616191864
Test Loss:  9.80118929874152e-05
Valid Loss:  0.00020426814444363117
Epoch:  408  	Training Loss: 0.000154003850184381
Test Loss:  9.773715282790363e-05
Valid Loss:  0.00020371814025565982
Epoch:  409  	Training Loss: 0.00015365226136054844
Test Loss:  9.745913848746568e-05
Valid Loss:  0.00020317814778536558
Epoch:  410  	Training Loss: 0.00015330503811128438
Test Loss:  9.721505921334028e-05
Valid Loss:  0.00020264458726160228
Epoch:  411  	Training Loss: 0.00015295654884539545
Test Loss:  9.695757762528956e-05
Valid Loss:  0.00020211405353620648
Epoch:  412  	Training Loss: 0.00015260619693435729
Test Loss:  9.761778346728534e-05
Valid Loss:  0.0002018099039560184
Epoch:  413  	Training Loss: 0.00015228724805638194
Test Loss:  9.772242628969252e-05
Valid Loss:  0.0002014760102611035
Epoch:  414  	Training Loss: 0.00015200951020233333
Test Loss:  9.765791037352756e-05
Valid Loss:  0.00020112541096750647
Epoch:  415  	Training Loss: 0.00015173820429481566
Test Loss:  9.755033534020185e-05
Valid Loss:  0.00020077206136193126
Epoch:  416  	Training Loss: 0.00015146800433285534
Test Loss:  9.744078852236271e-05
Valid Loss:  0.00020041957031935453
Epoch:  417  	Training Loss: 0.00015120054013095796
Test Loss:  9.731299360282719e-05
Valid Loss:  0.00020006176782771945
Epoch:  418  	Training Loss: 0.00015093301772139966
Test Loss:  9.719025547383353e-05
Valid Loss:  0.00019970134599134326
Epoch:  419  	Training Loss: 0.0001506667904322967
Test Loss:  9.706746641313657e-05
Valid Loss:  0.00019933865405619144
Epoch:  420  	Training Loss: 0.00015040033031255007
Test Loss:  9.694624168332666e-05
Valid Loss:  0.000198972353246063
Epoch:  421  	Training Loss: 0.0001501318474765867
Test Loss:  9.681758092483506e-05
Valid Loss:  0.00019860289467033
Epoch:  422  	Training Loss: 0.0001498636556789279
Test Loss:  9.573012357577682e-05
Valid Loss:  0.00019803093164227903
Epoch:  423  	Training Loss: 0.00014961528358981013
Test Loss:  9.520322782918811e-05
Valid Loss:  0.00019761646399274468
Epoch:  424  	Training Loss: 0.00014940230175852776
Test Loss:  9.483562462264672e-05
Valid Loss:  0.00019723127479664981
Epoch:  425  	Training Loss: 0.00014918579836376011
Test Loss:  9.453599341213703e-05
Valid Loss:  0.0001968735596165061
Epoch:  426  	Training Loss: 0.00014897383516654372
Test Loss:  9.429669444216415e-05
Valid Loss:  0.00019653527124319226
Epoch:  427  	Training Loss: 0.00014876700879540294
Test Loss:  9.40979880397208e-05
Valid Loss:  0.00019623470143415034
Epoch:  428  	Training Loss: 0.00014856983034405857
Test Loss:  9.390931518282741e-05
Valid Loss:  0.00019594613695517182
Epoch:  429  	Training Loss: 0.00014837924391031265
Test Loss:  9.373803186463192e-05
Valid Loss:  0.00019567200797609985
Epoch:  430  	Training Loss: 0.00014820386422798038
Test Loss:  9.358069655718282e-05
Valid Loss:  0.0001954395993379876
Epoch:  431  	Training Loss: 0.00014804268721491098
Test Loss:  9.344338468508795e-05
Valid Loss:  0.0001952327584149316
Epoch:  432  	Training Loss: 0.0001478923950344324
Test Loss:  9.34986092033796e-05
Valid Loss:  0.00019494663865771145
Epoch:  433  	Training Loss: 0.00014766101958230138
Test Loss:  9.344879072159529e-05
Valid Loss:  0.00019464619981590658
Epoch:  434  	Training Loss: 0.00014743240899406374
Test Loss:  9.336319635622203e-05
Valid Loss:  0.00019434094429016113
Epoch:  435  	Training Loss: 0.00014720478793606162
Test Loss:  9.326122381025925e-05
Valid Loss:  0.00019403654732741416
Epoch:  436  	Training Loss: 0.00014697825827170163
Test Loss:  9.315140778198838e-05
Valid Loss:  0.00019373289251234382
Epoch:  437  	Training Loss: 0.00014675156853627414
Test Loss:  9.303844126407057e-05
Valid Loss:  0.00019343137682881206
Epoch:  438  	Training Loss: 0.00014652643585577607
Test Loss:  9.292056347476318e-05
Valid Loss:  0.00019313656957820058
Epoch:  439  	Training Loss: 0.0001463039661757648
Test Loss:  9.280988888349384e-05
Valid Loss:  0.00019284241716377437
Epoch:  440  	Training Loss: 0.0001460832281736657
Test Loss:  9.270120062865317e-05
Valid Loss:  0.00019254948711022735
Epoch:  441  	Training Loss: 0.00014586400357075036
Test Loss:  9.258721547666937e-05
Valid Loss:  0.00019225815776735544
Epoch:  442  	Training Loss: 0.0001456450845580548
Test Loss:  9.26141656236723e-05
Valid Loss:  0.0001919719361467287
Epoch:  443  	Training Loss: 0.00014545436715707183
Test Loss:  9.254410542780533e-05
Valid Loss:  0.00019168679136782885
Epoch:  444  	Training Loss: 0.00014526658924296498
Test Loss:  9.244961984222755e-05
Valid Loss:  0.00019139883806928992
Epoch:  445  	Training Loss: 0.00014507988817058504
Test Loss:  9.236055484507233e-05
Valid Loss:  0.00019111085566692054
Epoch:  446  	Training Loss: 0.00014489579189103097
Test Loss:  9.225845133187249e-05
Valid Loss:  0.0001908254052978009
Epoch:  447  	Training Loss: 0.00014471233589574695
Test Loss:  9.215399768436328e-05
Valid Loss:  0.00019054251606576145
Epoch:  448  	Training Loss: 0.0001445310772396624
Test Loss:  9.204624075209722e-05
Valid Loss:  0.00019026725203730166
Epoch:  449  	Training Loss: 0.00014435115735977888
Test Loss:  9.194718586513773e-05
Valid Loss:  0.00018999155145138502
Epoch:  450  	Training Loss: 0.0001441707427147776
Test Loss:  9.184678492601961e-05
Valid Loss:  0.00018971772806253284
Epoch:  451  	Training Loss: 0.00014399102656170726
Test Loss:  9.17472571018152e-05
Valid Loss:  0.0001894464367069304
Epoch:  452  	Training Loss: 0.00014381231449078768
Test Loss:  9.177299216389656e-05
Valid Loss:  0.0001892004074761644
Epoch:  453  	Training Loss: 0.00014362091314978898
Test Loss:  9.17295110411942e-05
Valid Loss:  0.00018894017557613552
Epoch:  454  	Training Loss: 0.0001434284495189786
Test Loss:  9.165095252683386e-05
Valid Loss:  0.00018867729522753507
Epoch:  455  	Training Loss: 0.00014323815412353724
Test Loss:  9.155960287898779e-05
Valid Loss:  0.0001884156372398138
Epoch:  456  	Training Loss: 0.00014304846990853548
Test Loss:  9.146332740783691e-05
Valid Loss:  0.00018815181101672351
Epoch:  457  	Training Loss: 0.00014285973156802356
Test Loss:  9.136463631875813e-05
Valid Loss:  0.00018788906163536012
Epoch:  458  	Training Loss: 0.00014267176447901875
Test Loss:  9.126278746407479e-05
Valid Loss:  0.0001876276364782825
Epoch:  459  	Training Loss: 0.00014248568913899362
Test Loss:  9.116170986089855e-05
Valid Loss:  0.00018736624042503536
Epoch:  460  	Training Loss: 0.00014229970111045986
Test Loss:  9.10577509785071e-05
Valid Loss:  0.00018710695439949632
Epoch:  461  	Training Loss: 0.0001421153574483469
Test Loss:  9.095652785617858e-05
Valid Loss:  0.00018684667884372175
Epoch:  462  	Training Loss: 0.0001419293985236436
Test Loss:  9.091373794944957e-05
Valid Loss:  0.00018673072918318212
Epoch:  463  	Training Loss: 0.0001418090978404507
Test Loss:  9.087250509764999e-05
Valid Loss:  0.00018662246293388307
Epoch:  464  	Training Loss: 0.00014169693167787045
Test Loss:  9.083209442906082e-05
Valid Loss:  0.00018652094877324998
Epoch:  465  	Training Loss: 0.00014159068814478815
Test Loss:  9.079449228011072e-05
Valid Loss:  0.0001864264195319265
Epoch:  466  	Training Loss: 0.00014149141497910023
Test Loss:  9.076097921933979e-05
Valid Loss:  0.00018633698346093297
Epoch:  467  	Training Loss: 0.0001413986028637737
Test Loss:  9.073082765098661e-05
Valid Loss:  0.00018625392112880945
Epoch:  468  	Training Loss: 0.0001413111895089969
Test Loss:  9.070338273886591e-05
Valid Loss:  0.00018617534078657627
Epoch:  469  	Training Loss: 0.00014122793800197542
Test Loss:  9.067861537914723e-05
Valid Loss:  0.00018610002007335424
Epoch:  470  	Training Loss: 0.0001411490811733529
Test Loss:  9.065667109098285e-05
Valid Loss:  0.00018602953059598804
Epoch:  471  	Training Loss: 0.0001410739350831136
Test Loss:  9.063635661732405e-05
Valid Loss:  0.0001859628682723269
Epoch:  472  	Training Loss: 0.0001410022669006139
Test Loss:  95%|█████████▍| 473/500 [05:38<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:38<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:38<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:38<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:45<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:45<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:45<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:45<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:45<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:51<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:52<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:52<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:52<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:52<00:00,  2.97it/s]100%|██████████| 500/500 [05:52<00:00,  1.42it/s]
 9.026919724419713e-05
Valid Loss:  0.00018575953436084092
Epoch:  473  	Training Loss: 0.00014091815683059394
Test Loss:  9.014364331960678e-05
Valid Loss:  0.00018559681484475732
Epoch:  474  	Training Loss: 0.00014083465794101357
Test Loss:  9.005274478113279e-05
Valid Loss:  0.00018541583267506212
Epoch:  475  	Training Loss: 0.00014073921192903072
Test Loss:  8.995288953883573e-05
Valid Loss:  0.00018521639867685735
Epoch:  476  	Training Loss: 0.00014063733397051692
Test Loss:  8.985061140265316e-05
Valid Loss:  0.00018500888836570084
Epoch:  477  	Training Loss: 0.00014052730693947524
Test Loss:  8.972093928605318e-05
Valid Loss:  0.00018478588026482612
Epoch:  478  	Training Loss: 0.00014040600217413157
Test Loss:  8.957443060353398e-05
Valid Loss:  0.0001845525694079697
Epoch:  479  	Training Loss: 0.00014026949065737426
Test Loss:  8.940839325077832e-05
Valid Loss:  0.00018430370255373418
Epoch:  480  	Training Loss: 0.00014012216706760228
Test Loss:  8.924822031985968e-05
Valid Loss:  0.00018405713490210474
Epoch:  481  	Training Loss: 0.0001399744360242039
Test Loss:  8.90924347913824e-05
Valid Loss:  0.0001838151947595179
Epoch:  482  	Training Loss: 0.0001398303429596126
Test Loss:  8.931689080782235e-05
Valid Loss:  0.00018367763550486416
Epoch:  483  	Training Loss: 0.00013968977145850658
Test Loss:  8.942116983234882e-05
Valid Loss:  0.00018353085033595562
Epoch:  484  	Training Loss: 0.00013955586473457515
Test Loss:  8.948224422056228e-05
Valid Loss:  0.00018337600340601057
Epoch:  485  	Training Loss: 0.00013942761870566756
Test Loss:  8.952476491685957e-05
Valid Loss:  0.0001832268899306655
Epoch:  486  	Training Loss: 0.00013931059220340103
Test Loss:  8.955231169238687e-05
Valid Loss:  0.00018307838763576
Epoch:  487  	Training Loss: 0.0001391943806083873
Test Loss:  8.95743869477883e-05
Valid Loss:  0.00018293369794264436
Epoch:  488  	Training Loss: 0.000139081064844504
Test Loss:  8.959522529039532e-05
Valid Loss:  0.00018279784126207232
Epoch:  489  	Training Loss: 0.0001389754470437765
Test Loss:  8.96127603482455e-05
Valid Loss:  0.00018266821280121803
Epoch:  490  	Training Loss: 0.00013887321983929724
Test Loss:  8.963319123722613e-05
Valid Loss:  0.00018254443421028554
Epoch:  491  	Training Loss: 0.00013877369929105043
Test Loss:  8.964742301031947e-05
Valid Loss:  0.00018242397345602512
Epoch:  492  	Training Loss: 0.00013867732195649296
Test Loss:  8.994671225082129e-05
Valid Loss:  0.0001821228943299502
Epoch:  493  	Training Loss: 0.00013845987268723547
Test Loss:  8.999588317237794e-05
Valid Loss:  0.00018187027308158576
Epoch:  494  	Training Loss: 0.00013828800001647323
Test Loss:  8.992271614260972e-05
Valid Loss:  0.00018163763161282986
Epoch:  495  	Training Loss: 0.00013813492842018604
Test Loss:  8.980404527392238e-05
Valid Loss:  0.00018140999600291252
Epoch:  496  	Training Loss: 0.0001379875757265836
Test Loss:  8.967405301518738e-05
Valid Loss:  0.00018118676962330937
Epoch:  497  	Training Loss: 0.00013784324983134866
Test Loss:  8.953428186941892e-05
Valid Loss:  0.00018096872372552752
Epoch:  498  	Training Loss: 0.00013770480290986598
Test Loss:  8.938753308029845e-05
Valid Loss:  0.00018075913249049336
Epoch:  499  	Training Loss: 0.00013757152191828936
Test Loss:  8.926341979531571e-05
Valid Loss:  0.00018055253894999623
Epoch:  500  	Training Loss: 0.00013743882300332189
Test Loss:  8.915261423680931e-05
Valid Loss:  0.00018034825916402042
seed is  18
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.56it/s]  1%|          | 4/500 [00:00<00:30, 16.04it/s]  1%|          | 6/500 [00:00<00:30, 16.26it/s]  2%|▏         | 8/500 [00:00<00:30, 16.29it/s]  2%|▏         | 10/500 [00:00<00:29, 16.34it/s]  2%|▏         | 12/500 [00:00<00:29, 16.38it/s]  3%|▎         | 14/500 [00:00<00:29, 16.40it/s]  3%|▎         | 16/500 [00:00<00:29, 16.42it/s]  4%|▎         | 18/500 [00:01<00:29, 16.13it/s]  4%|▍         | 20/500 [00:01<00:29, 16.14it/s]  4%|▍         | 22/500 [00:01<00:29, 16.29it/s]  5%|▍         | 24/500 [00:01<00:29, 16.34it/s]  5%|▌         | 26/500 [00:01<00:28, 16.40it/s]  6%|▌         | 28/500 [00:01<00:28, 16.41it/s]  6%|▌         | 30/500 [00:01<00:28, 16.36it/s]  6%|▋         | 32/500 [00:01<00:28, 16.29it/s]  7%|▋         | 34/500 [00:02<00:28, 16.39it/s]  7%|▋         | 36/500 [00:02<00:28, 16.38it/s]  8%|▊         | 38/500 [00:02<00:28, 16.39it/s]  8%|▊         | 40/500 [00:02<00:28, 16.39it/s]  8%|▊         | 42/500 [00:02<00:27, 16.40it/s]  9%|▉         | 44/500 [00:02<00:27, 16.38it/s]  9%|▉         | 46/500 [00:02<00:27, 16.40it/s] 10%|▉         | 48/500 [00:02<00:27, 16.45it/s] 10%|█         | 50/500 [00:03<00:27, 16.37it/s] 10%|█         | 52/500 [00:03<00:27, 16.32it/s] 11%|█         | 54/500 [00:03<00:27, 16.35it/s] 11%|█         | 56/500 [00:03<00:27, 16.37it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.29it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.34it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.36it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.26it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.27it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.34it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.29it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.33it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.37it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.28it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.37it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.34it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.36it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.29it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.24it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.12it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.17it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.20it/s] 19%|█▉        | 94/500 [00:05<00:25, 16.21it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.23it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.10it/s] 20%|██        | 100/500 [00:06<00:24, 16.19it/s] 20%|██        | 102/500 [00:06<00:24, 16.14it/s] 21%|██        | 104/500 [00:06<00:24, 16.28it/s] 21%|██        | 106/500 [00:06<00:24, 16.33it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.07it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.24it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.22it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.13it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.08it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.19it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.31it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.41it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.42it/s]Epoch:  1  	Training Loss: 0.5200355648994446
Test Loss:  11370.00390625
Valid Loss:  11396.56640625
Epoch:  2  	Training Loss: 11403.6015625
Test Loss:  3.765648236678868e+20
Valid Loss:  3.7390685546280806e+20
Epoch:  3  	Training Loss: 3.712418151989395e+20
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.41it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.43it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.42it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.41it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.30it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.24it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.31it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.40it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.42it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.48it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.49it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.34it/s] 30%|███       | 150/500 [00:09<00:24, 14.24it/s] 30%|███       | 152/500 [00:09<00:24, 13.96it/s] 31%|███       | 154/500 [00:09<00:23, 14.67it/s] 31%|███       | 156/500 [00:09<00:22, 15.06it/s] 32%|███▏      | 158/500 [00:09<00:22, 15.44it/s] 32%|███▏      | 160/500 [00:09<00:21, 15.82it/s] 32%|███▏      | 162/500 [00:10<00:21, 16.05it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.18it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.25it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.31it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.41it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.45it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.49it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.36it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.27it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.32it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.38it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.40it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.46it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.52it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.51it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.54it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.52it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.15it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.13it/s] 40%|████      | 200/500 [00:12<00:18, 16.20it/s] 40%|████      | 202/500 [00:12<00:18, 16.27it/s] 41%|████      | 204/500 [00:12<00:18, 16.31it/s] 41%|████      | 206/500 [00:12<00:17, 16.34it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.48it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.47it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.45it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.40it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.33it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.38it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.07it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.15it/s] 45%|████▍     | 224/500 [00:13<00:17, 16.22it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.15it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.15it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.21it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.28it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.36it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.38it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.46it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.39it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.36it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.20it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.12it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.12it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.17it/s] 50%|█████     | 252/500 [00:15<00:15, 16.25it/s] 51%|█████     | 254/500 [00:15<00:15, 16.33it/s] 51%|█████     | 256/500 [00:15<00:14, 16.40it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.41it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.44it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.45it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.43it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.32it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.20it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.14it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.23it/s] 55%|█████▍    | 274/500 [00:16<00:14, 15.33it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.42it/s] 56%|█████▌    | 278/500 [00:17<00:15, 14.56it/s] 56%|█████▌    | 280/500 [00:17<00:16, 13.65it/s] 56%|█████▋    | 282/500 [00:17<00:16, 13.22it/s] 57%|█████▋    | 284/500 [00:17<00:16, 12.92it/s] 57%|█████▋    | 286/500 [00:17<00:16, 12.74it/s] 58%|█████▊    | 288/500 [00:17<00:16, 13.05it/s] 58%|█████▊    | 290/500 [00:18<00:15, 13.96it/s] 58%|█████▊    | 292/500 [00:18<00:14, 14.57it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.00it/s] 59%|█████▉    | 296/500 [00:18<00:13, 15.33it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.65it/s] 60%|██████    | 300/500 [00:18<00:12, 15.80it/s] 60%|██████    | 302/500 [00:18<00:12, 16.03it/s] 61%|██████    | 304/500 [00:18<00:12, 16.16it/s] 61%|██████    | 306/500 [00:19<00:11, 16.29it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.36it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.45it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.46it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.35it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.38it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.43it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.43it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.34it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.43it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.45it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.52it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.56it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.59it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.60it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.60it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.46it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.38it/s] 68%|██████▊   | 342/500 [00:21<00:09, 15.97it/s] 69%|██████▉   | 344/500 [00:21<00:10, 15.43it/s] 69%|██████▉   | 346/500 [00:21<00:09, 15.48it/s] 70%|██████▉   | 348/500 [00:21<00:10, 14.39it/s] 70%|███████   | 350/500 [00:21<00:10, 13.86it/s] 70%|███████   | 352/500 [00:21<00:10, 14.59it/s] 71%|███████   | 354/500 [00:22<00:09, 15.04it/s] 71%|███████   | 356/500 [00:22<00:09, 15.36it/s] 72%|███████▏  | 358/500 [00:22<00:09, 15.56it/s] 72%|███████▏  | 360/500 [00:22<00:08, 15.80it/s] 72%|███████▏  | 362/500 [00:22<00:08, 15.96it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.09it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.18it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.26it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.26it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.28it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.35it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.37it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.41it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.37it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.28it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.14it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.17it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.26it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.27it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.36it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.40it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.44it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.50it/s] 80%|████████  | 400/500 [00:24<00:06, 16.45it/s] 80%|████████  | 402/500 [00:25<00:05, 16.40it/s] 81%|████████  | 404/500 [00:25<00:05, 16.37it/s] 81%|████████  | 406/500 [00:25<00:05, 16.39it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.26it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.74it/s] 82%|████████▏ | 412/500 [00:25<00:05, 15.86it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.01it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.11it/s] 84%|████████▎ | 418/500 [00:26<00:05, 15.75it/s] 84%|████████▍ | 420/500 [00:26<00:05, 14.36it/s] 84%|████████▍ | 422/500 [00:26<00:05, 13.69it/s] 85%|████████▍ | 424/500 [00:26<00:05, 13.24it/s] 85%|████████▌ | 426/500 [00:26<00:05, 12.90it/s] 86%|████████▌ | 428/500 [00:26<00:05, 12.75it/s] 86%|████████▌ | 430/500 [00:27<00:05, 12.65it/s] 86%|████████▋ | 432/500 [00:27<00:05, 12.57it/s] 87%|████████▋ | 434/500 [00:27<00:05, 12.51it/s] 87%|████████▋ | 436/500 [00:27<00:05, 12.48it/s] 88%|████████▊ | 438/500 [00:27<00:04, 12.45it/s] 88%|████████▊ | 440/500 [00:27<00:04, 12.39it/s] 88%|████████▊ | 442/500 [00:28<00:04, 12.40it/s] 89%|████████▉ | 444/500 [00:28<00:04, 12.30it/s] 89%|████████▉ | 446/500 [00:28<00:04, 12.30it/s] 90%|████████▉ | 448/500 [00:28<00:04, 12.94it/s] 90%|█████████ | 450/500 [00:28<00:03, 13.81it/s] 90%|█████████ | 452/500 [00:28<00:03, 14.32it/s] 91%|█████████ | 454/500 [00:28<00:03, 14.97it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.30it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.61it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.85it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.97it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.02it/s] 93%|█████████▎| 466/500 [00:29<00:02, 15.04it/s] 94%|█████████▎| 468/500 [00:29<00:02, 14.96it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.39it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.64it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.84it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.92it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.10it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.09it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.19it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.29it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.27it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.08it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.18it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.26it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.34it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.20it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 14.11it/s]100%|██████████| 500/500 [00:31<00:00, 13.89it/s]100%|██████████| 500/500 [00:31<00:00, 15.72it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  18
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:14,  6.40s/it]  1%|          | 3/500 [00:06<14:12,  1.71s/it]  1%|          | 5/500 [00:06<07:09,  1.15it/s]  1%|▏         | 7/500 [00:06<04:20,  1.90it/s]  2%|▏         | 9/500 [00:06<02:53,  2.84it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:25,  1.18s/it]  5%|▍         | 23/500 [00:20<06:41,  1.19it/s]  5%|▌         | 25/500 [00:20<04:48,  1.65it/s]  5%|▌         | 27/500 [00:20<03:29,  2.26it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:12,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.64it/s]  7%|▋         | 37/500 [00:27<03:28,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  2.99it/s]  8%|▊         | 41/500 [00:33<08:53,  1.16s/it]  9%|▊         | 43/500 [00:33<06:21,  1.20it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<09:03,  1.21s/it] 11%|█         | 53/500 [00:40<06:29,  1.15it/s] 11%|█         | 55/500 [00:40<04:40,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:23,  2.17it/s] 12%|█▏        | 59/500 [00:41<02:31,  2.92it/s] 12%|█▏        | 61/500 [00:47<08:42,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:14,  1.17it/s] 13%|█▎        | 65/500 [00:47<04:29,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.97it/s] 14%|█▍        | 71/500 [00:54<08:27,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:02,  1.18it/s]Epoch:  1  	Training Loss: 0.5200355648994446
Test Loss:  69.34207153320312
Valid Loss:  68.45314025878906
Epoch:  2  	Training Loss: 67.53313446044922
Test Loss:  0.511075496673584
Valid Loss:  0.5073657035827637
Epoch:  3  	Training Loss: 0.48701658844947815
Test Loss:  0.5104959011077881
Valid Loss:  0.5067940354347229
Epoch:  4  	Training Loss: 0.48646289110183716
Test Loss:  0.5099167823791504
Valid Loss:  0.5062228441238403
Epoch:  5  	Training Loss: 0.48590970039367676
Test Loss:  0.5093382596969604
Valid Loss:  0.5056523084640503
Epoch:  6  	Training Loss: 0.48535704612731934
Test Loss:  0.508760929107666
Valid Loss:  0.5050844550132751
Epoch:  7  	Training Loss: 0.4848065972328186
Test Loss:  0.508633553981781
Valid Loss:  0.5049638152122498
Epoch:  8  	Training Loss: 0.484688937664032
Test Loss:  0.5086310505867004
Valid Loss:  0.5049612522125244
Epoch:  9  	Training Loss: 0.4846864342689514
Test Loss:  0.5086284875869751
Valid Loss:  0.5049586892127991
Epoch:  10  	Training Loss: 0.4846839904785156
Test Loss:  0.5086259841918945
Valid Loss:  0.5049561262130737
Epoch:  11  	Training Loss: 0.48468145728111267
Test Loss:  0.508623480796814
Valid Loss:  0.5049535632133484
Epoch:  12  	Training Loss: 0.4846789836883545
Test Loss:  0.508622407913208
Valid Loss:  0.5049524903297424
Epoch:  13  	Training Loss: 0.4846779406070709
Test Loss:  0.508621335029602
Valid Loss:  0.5049513578414917
Epoch:  14  	Training Loss: 0.48467686772346497
Test Loss:  0.5086202025413513
Valid Loss:  0.5049502849578857
Epoch:  15  	Training Loss: 0.4846758246421814
Test Loss:  0.5086191892623901
Valid Loss:  0.5049492120742798
Epoch:  16  	Training Loss: 0.48467475175857544
Test Loss:  0.5086180567741394
Valid Loss:  0.5049481391906738
Epoch:  17  	Training Loss: 0.4846736788749695
Test Loss:  0.5086169242858887
Valid Loss:  0.5049470067024231
Epoch:  18  	Training Loss: 0.4846726059913635
Test Loss:  0.5086158514022827
Valid Loss:  0.5049459338188171
Epoch:  19  	Training Loss: 0.48467153310775757
Test Loss:  0.5086147785186768
Valid Loss:  0.5049448013305664
Epoch:  20  	Training Loss: 0.4846704304218292
Test Loss:  0.5086137056350708
Valid Loss:  0.5049436688423157
Epoch:  21  	Training Loss: 0.48466938734054565
Test Loss:  0.5086126327514648
Valid Loss:  0.5049426555633545
Epoch:  22  	Training Loss: 0.4846683144569397
Test Loss:  0.5086115598678589
Valid Loss:  0.504941463470459
Epoch:  23  	Training Loss: 0.48466724157333374
Test Loss:  0.5086103677749634
Valid Loss:  0.504940390586853
Epoch:  24  	Training Loss: 0.4846661686897278
Test Loss:  0.5086092948913574
Valid Loss:  0.5049391984939575
Epoch:  25  	Training Loss: 0.48466503620147705
Test Loss:  0.5086081624031067
Valid Loss:  0.5049381256103516
Epoch:  26  	Training Loss: 0.4846639633178711
Test Loss:  0.508607029914856
Valid Loss:  0.5049370527267456
Epoch:  27  	Training Loss: 0.48466289043426514
Test Loss:  0.50860595703125
Valid Loss:  0.5049358606338501
Epoch:  28  	Training Loss: 0.4846618175506592
Test Loss:  0.508604884147644
Valid Loss:  0.5049347877502441
Epoch:  29  	Training Loss: 0.48466071486473083
Test Loss:  0.5086037516593933
Valid Loss:  0.5049336552619934
Epoch:  30  	Training Loss: 0.4846596121788025
Test Loss:  0.5086026191711426
Valid Loss:  0.5049325227737427
Epoch:  31  	Training Loss: 0.48465853929519653
Test Loss:  0.5086015462875366
Valid Loss:  0.5049314498901367
Epoch:  32  	Training Loss: 0.4846574664115906
Test Loss:  0.5086004734039307
Valid Loss:  0.504930317401886
Epoch:  33  	Training Loss: 0.4846563935279846
Test Loss:  0.5085994005203247
Valid Loss:  0.5049291849136353
Epoch:  34  	Training Loss: 0.48465535044670105
Test Loss:  0.508598268032074
Valid Loss:  0.5049281716346741
Epoch:  35  	Training Loss: 0.4846543073654175
Test Loss:  0.508597195148468
Valid Loss:  0.5049270987510681
Epoch:  36  	Training Loss: 0.4846532344818115
Test Loss:  0.5085960626602173
Valid Loss:  0.5049259662628174
Epoch:  37  	Training Loss: 0.48465216159820557
Test Loss:  0.5085949897766113
Valid Loss:  0.5049248933792114
Epoch:  38  	Training Loss: 0.4846511483192444
Test Loss:  0.5085939764976501
Valid Loss:  0.5049238204956055
Epoch:  39  	Training Loss: 0.48465004563331604
Test Loss:  0.5085929036140442
Valid Loss:  0.5049227476119995
Epoch:  40  	Training Loss: 0.48464900255203247
Test Loss:  0.5085917711257935
Valid Loss:  0.5049216151237488
Epoch:  41  	Training Loss: 0.4846479296684265
Test Loss:  0.5085906982421875
Valid Loss:  0.5049205422401428
Epoch:  42  	Training Loss: 0.48464688658714294
Test Loss:  0.5085896849632263
Valid Loss:  0.5049194097518921
Epoch:  43  	Training Loss: 0.4846458435058594
Test Loss:  0.5085886120796204
Valid Loss:  0.5049183964729309
Epoch:  44  	Training Loss: 0.4846448302268982
Test Loss:  0.5085875391960144
Valid Loss:  0.504917323589325
Epoch:  45  	Training Loss: 0.48464375734329224
Test Loss:  0.5085865259170532
Valid Loss:  0.504916250705719
Epoch:  46  	Training Loss: 0.48464274406433105
Test Loss:  0.5085854530334473
Valid Loss:  0.5049152374267578
Epoch:  47  	Training Loss: 0.4846417009830475
Test Loss:  0.5085843801498413
Valid Loss:  0.5049141645431519
Epoch:  48  	Training Loss: 0.4846406579017639
Test Loss:  0.5085833668708801
Valid Loss:  0.5049130916595459
Epoch:  49  	Training Loss: 0.48463964462280273
Test Loss:  0.5085822343826294
Valid Loss:  0.5049120187759399
Epoch:  50  	Training Loss: 0.48463860154151917
Test Loss:  0.5085812211036682
Valid Loss:  0.504910945892334
Epoch:  51  	Training Loss: 0.484637588262558
Test Loss:  0.5085801482200623
Valid Loss:  0.504909873008728
Epoch:  52  	Training Loss: 0.4846365451812744
Test Loss:  0.5085790753364563
Valid Loss:  0.5049087405204773
Epoch:  53  	Training Loss: 0.48463547229766846
Test Loss:  0.5085779428482056
Valid Loss:  0.5049076080322266
Epoch:  54  	Training Loss: 0.4846343398094177
Test Loss:  0.5085768699645996
Valid Loss:  0.5049065351486206
Epoch:  55  	Training Loss: 0.48463329672813416
Test Loss:  0.5085756778717041
Valid Loss:  0.5049054622650146
Epoch:  56  	Training Loss: 0.4846322238445282
Test Loss:  0.5085746049880981
Valid Loss:  0.5049042701721191
Epoch:  57  	Training Loss: 0.48463112115859985
Test Loss:  0.5085735321044922
Valid Loss:  0.5049031972885132
Epoch:  58  	Training Loss: 0.4846300482749939
Test Loss:  0.5085724592208862
Valid Loss:  0.5049020648002625
Epoch:  59  	Training Loss: 0.4846290051937103
Test Loss:  0.5085713267326355
Valid Loss:  0.5049009323120117
Epoch:  60  	Training Loss: 0.484627902507782
Test Loss:  0.5085701942443848
Valid Loss:  0.5048998594284058
Epoch:  61  	Training Loss: 0.484626829624176
Test Loss:  0.5085691213607788
Valid Loss:  0.504898726940155
Epoch:  62  	Training Loss: 0.48462575674057007
Test Loss:  0.5085680484771729
Valid Loss:  0.5048976540565491
Epoch:  63  	Training Loss: 0.4846246838569641
Test Loss:  0.5085669755935669
Valid Loss:  0.5048965215682983
Epoch:  64  	Training Loss: 0.48462367057800293
Test Loss:  0.5085659027099609
Valid Loss:  0.5048955678939819
Epoch:  65  	Training Loss: 0.4846225678920746
Test Loss:  0.508564829826355
Valid Loss:  0.5048944354057312
Epoch:  66  	Training Loss: 0.484621524810791
Test Loss:  0.508563756942749
Valid Loss:  0.5048933625221252
Epoch:  67  	Training Loss: 0.48462051153182983
Test Loss:  0.5085626840591431
Valid Loss:  0.5048922300338745
Epoch:  68  	Training Loss: 0.4846194386482239
Test Loss:  0.5085616111755371
Valid Loss:  0.5048911571502686
Epoch:  69  	Training Loss: 0.4846183955669403
Test Loss:  0.5085604786872864
Valid Loss:  0.5048900842666626
Epoch:  70  	Training Loss: 0.48461732268333435
Test Loss:  0.5085594654083252
Valid Loss:  0.5048890113830566
Epoch:  71  	Training Loss: 0.4846162796020508
Test Loss:  0.5085583329200745
Valid Loss:  0.5048879384994507
Epoch:  72  	Training Loss: 0.4846152067184448
Test Loss:  0.5085573196411133
Valid Loss:  0.5048868656158447
Epoch:  73  	Training Loss: 0.48461419343948364
Test Loss:  0.5085562467575073
Valid Loss:  0.5048858523368835
Epoch:  74  	Training Loss: 0.48461320996284485
Test Loss:  0.5085552930831909
Valid Loss:  0.5048847794532776
Epoch:  75  	Training Loss: 0.4846121668815613
Test Loss:   15%|█▌        | 75/500 [00:54<04:20,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:01<08:08,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:07,  2.21it/s] 18%|█▊        | 89/500 [01:01<02:20,  2.92it/s] 18%|█▊        | 91/500 [01:08<08:07,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:08<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.97it/s] 20%|██        | 101/500 [01:14<07:52,  1.18s/it] 21%|██        | 103/500 [01:15<05:37,  1.18it/s] 21%|██        | 105/500 [01:15<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:15<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:15<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:21<07:34,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:26,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:22<02:55,  2.19it/s] 24%|██▍       | 119/500 [01:22<02:09,  2.94it/s] 24%|██▍       | 121/500 [01:28<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:28<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:28<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:35<07:24,  1.21s/it] 27%|██▋       | 133/500 [01:35<05:17,  1.16it/s] 27%|██▋       | 135/500 [01:35<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:36<02:45,  2.19it/s] 28%|██▊       | 139/500 [01:36<02:02,  2.94it/s] 28%|██▊       | 141/500 [01:42<07:05,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:03,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:38,  2.22it/s]0.508554220199585
Valid Loss:  0.5048837661743164
Epoch:  76  	Training Loss: 0.4846111834049225
Test Loss:  0.508553147315979
Valid Loss:  0.5048826932907104
Epoch:  77  	Training Loss: 0.4846101701259613
Test Loss:  0.5085521340370178
Valid Loss:  0.5048816800117493
Epoch:  78  	Training Loss: 0.48460912704467773
Test Loss:  0.5085511207580566
Valid Loss:  0.5048806667327881
Epoch:  79  	Training Loss: 0.48460814356803894
Test Loss:  0.5085500478744507
Valid Loss:  0.5048795938491821
Epoch:  80  	Training Loss: 0.48460710048675537
Test Loss:  0.5085490345954895
Valid Loss:  0.5048785209655762
Epoch:  81  	Training Loss: 0.4846061170101166
Test Loss:  0.5085480213165283
Valid Loss:  0.504877507686615
Epoch:  82  	Training Loss: 0.4846051335334778
Test Loss:  0.5085469484329224
Valid Loss:  0.5048763751983643
Epoch:  83  	Training Loss: 0.4846040606498718
Test Loss:  0.5085458755493164
Valid Loss:  0.5048753023147583
Epoch:  84  	Training Loss: 0.48460298776626587
Test Loss:  0.5085446834564209
Valid Loss:  0.5048741698265076
Epoch:  85  	Training Loss: 0.4846019148826599
Test Loss:  0.5085436105728149
Valid Loss:  0.5048730373382568
Epoch:  86  	Training Loss: 0.48460084199905396
Test Loss:  0.508542537689209
Valid Loss:  0.5048719644546509
Epoch:  87  	Training Loss: 0.4845997095108032
Test Loss:  0.5085414052009583
Valid Loss:  0.5048708915710449
Epoch:  88  	Training Loss: 0.48459869623184204
Test Loss:  0.5085402727127075
Valid Loss:  0.5048697590827942
Epoch:  89  	Training Loss: 0.4845975637435913
Test Loss:  0.5085391998291016
Valid Loss:  0.5048686265945435
Epoch:  90  	Training Loss: 0.48459652066230774
Test Loss:  0.5085381269454956
Valid Loss:  0.5048675537109375
Epoch:  91  	Training Loss: 0.4845954179763794
Test Loss:  0.5085369944572449
Valid Loss:  0.5048664212226868
Epoch:  92  	Training Loss: 0.48459431529045105
Test Loss:  0.5085358619689941
Valid Loss:  0.504865288734436
Epoch:  93  	Training Loss: 0.4845932722091675
Test Loss:  0.5085347890853882
Valid Loss:  0.5048642158508301
Epoch:  94  	Training Loss: 0.48459216952323914
Test Loss:  0.5085336565971375
Valid Loss:  0.5048630833625793
Epoch:  95  	Training Loss: 0.48459112644195557
Test Loss:  0.5085325241088867
Valid Loss:  0.5048619508743286
Epoch:  96  	Training Loss: 0.4845900535583496
Test Loss:  0.5085314512252808
Valid Loss:  0.5048608779907227
Epoch:  97  	Training Loss: 0.48458895087242126
Test Loss:  0.5085303783416748
Valid Loss:  0.5048598051071167
Epoch:  98  	Training Loss: 0.4845878481864929
Test Loss:  0.5085293054580688
Valid Loss:  0.5048587322235107
Epoch:  99  	Training Loss: 0.48458680510520935
Test Loss:  0.5085281729698181
Valid Loss:  0.5048575401306152
Epoch:  100  	Training Loss: 0.4845857620239258
Test Loss:  0.5085270404815674
Valid Loss:  0.5048564672470093
Epoch:  101  	Training Loss: 0.48458465933799744
Test Loss:  0.5085259675979614
Valid Loss:  0.5048553347587585
Epoch:  102  	Training Loss: 0.48458361625671387
Test Loss:  0.5085248947143555
Valid Loss:  0.5048543214797974
Epoch:  103  	Training Loss: 0.4845826029777527
Test Loss:  0.5085238814353943
Valid Loss:  0.5048532485961914
Epoch:  104  	Training Loss: 0.4845815896987915
Test Loss:  0.5085228681564331
Valid Loss:  0.5048522353172302
Epoch:  105  	Training Loss: 0.4845805764198303
Test Loss:  0.5085217952728271
Valid Loss:  0.5048511624336243
Epoch:  106  	Training Loss: 0.48457956314086914
Test Loss:  0.508520781993866
Valid Loss:  0.5048501491546631
Epoch:  107  	Training Loss: 0.48457854986190796
Test Loss:  0.50851970911026
Valid Loss:  0.5048490762710571
Epoch:  108  	Training Loss: 0.4845775365829468
Test Loss:  0.5085186958312988
Valid Loss:  0.5048481225967407
Epoch:  109  	Training Loss: 0.4845765233039856
Test Loss:  0.5085176825523376
Valid Loss:  0.5048470497131348
Epoch:  110  	Training Loss: 0.4845755100250244
Test Loss:  0.5085166692733765
Valid Loss:  0.5048459768295288
Epoch:  111  	Training Loss: 0.4845745265483856
Test Loss:  0.5085155963897705
Valid Loss:  0.5048449635505676
Epoch:  112  	Training Loss: 0.48457351326942444
Test Loss:  0.5085145831108093
Valid Loss:  0.5048438310623169
Epoch:  113  	Training Loss: 0.48457247018814087
Test Loss:  0.5085135102272034
Valid Loss:  0.5048428177833557
Epoch:  114  	Training Loss: 0.4845714569091797
Test Loss:  0.5085124373435974
Valid Loss:  0.5048417448997498
Epoch:  115  	Training Loss: 0.4845704138278961
Test Loss:  0.5085113644599915
Valid Loss:  0.5048407316207886
Epoch:  116  	Training Loss: 0.48456937074661255
Test Loss:  0.5085102915763855
Valid Loss:  0.5048395991325378
Epoch:  117  	Training Loss: 0.48456835746765137
Test Loss:  0.5085092782974243
Valid Loss:  0.5048385858535767
Epoch:  118  	Training Loss: 0.4845673143863678
Test Loss:  0.5085082054138184
Valid Loss:  0.5048375129699707
Epoch:  119  	Training Loss: 0.48456627130508423
Test Loss:  0.5085071325302124
Valid Loss:  0.5048364400863647
Epoch:  120  	Training Loss: 0.48456522822380066
Test Loss:  0.5085060596466064
Valid Loss:  0.5048353672027588
Epoch:  121  	Training Loss: 0.4845642149448395
Test Loss:  0.5085049867630005
Valid Loss:  0.5048342943191528
Epoch:  122  	Training Loss: 0.4845631718635559
Test Loss:  0.5085040330886841
Valid Loss:  0.5048332810401917
Epoch:  123  	Training Loss: 0.4845621883869171
Test Loss:  0.5085030198097229
Valid Loss:  0.5048322677612305
Epoch:  124  	Training Loss: 0.48456117510795593
Test Loss:  0.5085020065307617
Valid Loss:  0.5048312544822693
Epoch:  125  	Training Loss: 0.48456019163131714
Test Loss:  0.5085009336471558
Valid Loss:  0.5048302412033081
Epoch:  126  	Training Loss: 0.48455920815467834
Test Loss:  0.5084999799728394
Valid Loss:  0.5048291683197021
Epoch:  127  	Training Loss: 0.48455819487571716
Test Loss:  0.5084989070892334
Valid Loss:  0.504828155040741
Epoch:  128  	Training Loss: 0.48455721139907837
Test Loss:  0.5084978938102722
Valid Loss:  0.5048271417617798
Epoch:  129  	Training Loss: 0.48455625772476196
Test Loss:  0.508496880531311
Valid Loss:  0.5048261284828186
Epoch:  130  	Training Loss: 0.4845552444458008
Test Loss:  0.5084959268569946
Valid Loss:  0.5048251152038574
Epoch:  131  	Training Loss: 0.4845542311668396
Test Loss:  0.5084948539733887
Valid Loss:  0.5048241019248962
Epoch:  132  	Training Loss: 0.4845532476902008
Test Loss:  0.5084938406944275
Valid Loss:  0.5048230886459351
Epoch:  133  	Training Loss: 0.484552264213562
Test Loss:  0.5084927678108215
Valid Loss:  0.5048220157623291
Epoch:  134  	Training Loss: 0.48455125093460083
Test Loss:  0.5084917545318604
Valid Loss:  0.5048210024833679
Epoch:  135  	Training Loss: 0.48455026745796204
Test Loss:  0.5084907412528992
Valid Loss:  0.5048199892044067
Epoch:  136  	Training Loss: 0.48454925417900085
Test Loss:  0.508489727973938
Valid Loss:  0.5048189163208008
Epoch:  137  	Training Loss: 0.48454827070236206
Test Loss:  0.5084887146949768
Valid Loss:  0.5048179030418396
Epoch:  138  	Training Loss: 0.4845472574234009
Test Loss:  0.5084876418113708
Valid Loss:  0.5048168897628784
Epoch:  139  	Training Loss: 0.4845462739467621
Test Loss:  0.5084866285324097
Valid Loss:  0.5048158168792725
Epoch:  140  	Training Loss: 0.4845452606678009
Test Loss:  0.5084856152534485
Valid Loss:  0.504814863204956
Epoch:  141  	Training Loss: 0.4845442771911621
Test Loss:  0.5084846019744873
Valid Loss:  0.5048138499259949
Epoch:  142  	Training Loss: 0.4845432639122009
Test Loss:  0.5084835290908813
Valid Loss:  0.5048127174377441
Epoch:  143  	Training Loss: 0.48454219102859497
Test Loss:  0.5084824562072754
Valid Loss:  0.5048116445541382
Epoch:  144  	Training Loss: 0.4845411777496338
Test Loss:  0.5084813833236694
Valid Loss:  0.5048105716705322
Epoch:  145  	Training Loss: 0.48454010486602783
Test Loss:  0.5084802508354187
Valid Loss:  0.5048094987869263
Epoch:  146  	Training Loss: 0.48453906178474426
Test Loss:  0.5084792375564575
Valid Loss:  0.5048083662986755
Epoch:  147  	Training Loss: 0.4845380187034607
Test Loss:  0.5084781646728516
Valid Loss:  0.5048072934150696
Epoch:  148  	Training Loss: 0.48453694581985474
Test Loss:  0.5084770321846008
Valid Loss:  0.5048062205314636
 30%|██▉       | 149/500 [01:43<01:57,  2.99it/s] 30%|███       | 151/500 [01:49<06:45,  1.16s/it] 31%|███       | 153/500 [01:49<04:49,  1.20it/s] 31%|███       | 155/500 [01:49<03:28,  1.66it/s] 31%|███▏      | 157/500 [01:49<02:31,  2.27it/s] 32%|███▏      | 159/500 [01:49<01:51,  3.05it/s] 32%|███▏      | 161/500 [01:56<06:41,  1.18s/it] 33%|███▎      | 163/500 [01:56<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:56<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.22it/s] 34%|███▍      | 169/500 [01:56<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:02<06:24,  1.17s/it] 35%|███▍      | 173/500 [02:03<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:03<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:03<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:03<01:50,  2.91it/s] 36%|███▌      | 181/500 [02:09<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:10<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:10<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:10<02:22,  2.19it/s] 38%|███▊      | 189/500 [02:10<01:47,  2.90it/s] 38%|███▊      | 191/500 [02:16<06:12,  1.21s/it] 39%|███▊      | 193/500 [02:17<04:27,  1.15it/s] 39%|███▉      | 195/500 [02:17<03:13,  1.57it/s] 39%|███▉      | 197/500 [02:17<02:22,  2.13it/s] 40%|███▉      | 199/500 [02:17<01:45,  2.85it/s] 40%|████      | 201/500 [02:24<06:03,  1.22s/it] 41%|████      | 203/500 [02:24<04:19,  1.15it/s] 41%|████      | 205/500 [02:24<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:24<02:14,  2.17it/s] 42%|████▏     | 209/500 [02:24<01:39,  2.93it/s] 42%|████▏     | 211/500 [02:30<05:46,  1.20s/it] 43%|████▎     | 213/500 [02:31<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:31<02:57,  1.61it/s] 43%|████▎     | 217/500 [02:31<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:31<01:34,  2.96it/s] 44%|████▍     | 221/500 [02:37<05:29,  1.18s/it]Epoch:  149  	Training Loss: 0.48453590273857117
Test Loss:  0.5084759593009949
Valid Loss:  0.5048051476478577
Epoch:  150  	Training Loss: 0.4845348596572876
Test Loss:  0.5084748268127441
Valid Loss:  0.5048040151596069
Epoch:  151  	Training Loss: 0.48453378677368164
Test Loss:  0.508473813533783
Valid Loss:  0.504802942276001
Epoch:  152  	Training Loss: 0.4845327138900757
Test Loss:  0.508472740650177
Valid Loss:  0.504801869392395
Epoch:  153  	Training Loss: 0.4845317304134369
Test Loss:  0.5084717273712158
Valid Loss:  0.5048008561134338
Epoch:  154  	Training Loss: 0.4845306873321533
Test Loss:  0.5084706544876099
Valid Loss:  0.5047998428344727
Epoch:  155  	Training Loss: 0.48452967405319214
Test Loss:  0.5084696412086487
Valid Loss:  0.5047987699508667
Epoch:  156  	Training Loss: 0.48452866077423096
Test Loss:  0.508468508720398
Valid Loss:  0.5047976970672607
Epoch:  157  	Training Loss: 0.4845276474952698
Test Loss:  0.5084675550460815
Valid Loss:  0.5047966241836548
Epoch:  158  	Training Loss: 0.4845266342163086
Test Loss:  0.5084664821624756
Valid Loss:  0.5047956109046936
Epoch:  159  	Training Loss: 0.484525591135025
Test Loss:  0.5084654092788696
Valid Loss:  0.5047945380210876
Epoch:  160  	Training Loss: 0.48452457785606384
Test Loss:  0.5084643363952637
Valid Loss:  0.5047935247421265
Epoch:  161  	Training Loss: 0.4845235347747803
Test Loss:  0.5084633231163025
Valid Loss:  0.5047923922538757
Epoch:  162  	Training Loss: 0.4845225214958191
Test Loss:  0.5084621906280518
Valid Loss:  0.5047913789749146
Epoch:  163  	Training Loss: 0.48452144861221313
Test Loss:  0.5084611177444458
Valid Loss:  0.5047902464866638
Epoch:  164  	Training Loss: 0.48452043533325195
Test Loss:  0.5084600448608398
Valid Loss:  0.5047891139984131
Epoch:  165  	Training Loss: 0.4845193326473236
Test Loss:  0.5084589123725891
Valid Loss:  0.5047880411148071
Epoch:  166  	Training Loss: 0.48451828956604004
Test Loss:  0.5084578394889832
Valid Loss:  0.5047869682312012
Epoch:  167  	Training Loss: 0.4845171868801117
Test Loss:  0.5084567070007324
Valid Loss:  0.5047858357429504
Epoch:  168  	Training Loss: 0.4845161437988281
Test Loss:  0.5084556341171265
Valid Loss:  0.5047847628593445
Epoch:  169  	Training Loss: 0.48451507091522217
Test Loss:  0.5084545612335205
Valid Loss:  0.5047836303710938
Epoch:  170  	Training Loss: 0.4845140278339386
Test Loss:  0.5084534287452698
Valid Loss:  0.5047825574874878
Epoch:  171  	Training Loss: 0.48451292514801025
Test Loss:  0.5084523558616638
Valid Loss:  0.5047814846038818
Epoch:  172  	Training Loss: 0.4845118522644043
Test Loss:  0.5084512829780579
Valid Loss:  0.5047804117202759
Epoch:  173  	Training Loss: 0.4845108687877655
Test Loss:  0.5084502696990967
Valid Loss:  0.5047793388366699
Epoch:  174  	Training Loss: 0.48450982570648193
Test Loss:  0.5084491968154907
Valid Loss:  0.504778265953064
Epoch:  175  	Training Loss: 0.48450881242752075
Test Loss:  0.5084481239318848
Valid Loss:  0.5047772526741028
Epoch:  176  	Training Loss: 0.48450779914855957
Test Loss:  0.5084470510482788
Valid Loss:  0.5047761797904968
Epoch:  177  	Training Loss: 0.4845067858695984
Test Loss:  0.5084460973739624
Valid Loss:  0.5047751069068909
Epoch:  178  	Training Loss: 0.4845057725906372
Test Loss:  0.5084450244903564
Valid Loss:  0.5047740936279297
Epoch:  179  	Training Loss: 0.48450469970703125
Test Loss:  0.5084439516067505
Valid Loss:  0.5047730207443237
Epoch:  180  	Training Loss: 0.48450374603271484
Test Loss:  0.5084428787231445
Valid Loss:  0.5047719478607178
Epoch:  181  	Training Loss: 0.4845027029514313
Test Loss:  0.5084418654441833
Valid Loss:  0.5047709345817566
Epoch:  182  	Training Loss: 0.4845016896724701
Test Loss:  0.5084408521652222
Valid Loss:  0.5047698616981506
Epoch:  183  	Training Loss: 0.4845006465911865
Test Loss:  0.5084397792816162
Valid Loss:  0.5047688484191895
Epoch:  184  	Training Loss: 0.48449963331222534
Test Loss:  0.508438766002655
Valid Loss:  0.5047677755355835
Epoch:  185  	Training Loss: 0.48449862003326416
Test Loss:  0.5084376931190491
Valid Loss:  0.5047667622566223
Epoch:  186  	Training Loss: 0.484497606754303
Test Loss:  0.5084366798400879
Valid Loss:  0.5047657489776611
Epoch:  187  	Training Loss: 0.4844965934753418
Test Loss:  0.5084356069564819
Valid Loss:  0.5047646760940552
Epoch:  188  	Training Loss: 0.4844955801963806
Test Loss:  0.5084345936775208
Valid Loss:  0.5047636032104492
Epoch:  189  	Training Loss: 0.48449456691741943
Test Loss:  0.5084335803985596
Valid Loss:  0.504762589931488
Epoch:  190  	Training Loss: 0.48449355363845825
Test Loss:  0.5084325075149536
Valid Loss:  0.5047615766525269
Epoch:  191  	Training Loss: 0.48449254035949707
Test Loss:  0.5084314942359924
Valid Loss:  0.5047605037689209
Epoch:  192  	Training Loss: 0.4844915270805359
Test Loss:  0.5084303617477417
Valid Loss:  0.5047594904899597
Epoch:  193  	Training Loss: 0.4844905138015747
Test Loss:  0.5084294080734253
Valid Loss:  0.5047584176063538
Epoch:  194  	Training Loss: 0.4844895303249359
Test Loss:  0.5084283351898193
Valid Loss:  0.5047574043273926
Epoch:  195  	Training Loss: 0.4844885468482971
Test Loss:  0.5084273815155029
Valid Loss:  0.5047563910484314
Epoch:  196  	Training Loss: 0.4844875931739807
Test Loss:  0.508426308631897
Valid Loss:  0.5047553777694702
Epoch:  197  	Training Loss: 0.48448652029037476
Test Loss:  0.5084252953529358
Valid Loss:  0.504754364490509
Epoch:  198  	Training Loss: 0.48448556661605835
Test Loss:  0.5084242820739746
Valid Loss:  0.5047532916069031
Epoch:  199  	Training Loss: 0.48448455333709717
Test Loss:  0.5084233283996582
Valid Loss:  0.5047522783279419
Epoch:  200  	Training Loss: 0.4844835698604584
Test Loss:  0.5084222555160522
Valid Loss:  0.5047512650489807
Epoch:  201  	Training Loss: 0.4844825863838196
Test Loss:  0.5084211826324463
Valid Loss:  0.5047502517700195
Epoch:  202  	Training Loss: 0.4844815731048584
Test Loss:  0.5084201693534851
Valid Loss:  0.5047491788864136
Epoch:  203  	Training Loss: 0.4844805598258972
Test Loss:  0.5084191560745239
Valid Loss:  0.5047481060028076
Epoch:  204  	Training Loss: 0.4844795763492584
Test Loss:  0.5084181427955627
Valid Loss:  0.5047471523284912
Epoch:  205  	Training Loss: 0.48447856307029724
Test Loss:  0.5084171295166016
Valid Loss:  0.5047460794448853
Epoch:  206  	Training Loss: 0.48447757959365845
Test Loss:  0.5084160566329956
Valid Loss:  0.5047450661659241
Epoch:  207  	Training Loss: 0.48447656631469727
Test Loss:  0.5084149837493896
Valid Loss:  0.5047440528869629
Epoch:  208  	Training Loss: 0.4844755530357361
Test Loss:  0.5084139704704285
Valid Loss:  0.5047429800033569
Epoch:  209  	Training Loss: 0.4844745397567749
Test Loss:  0.5084129571914673
Valid Loss:  0.5047419667243958
Epoch:  210  	Training Loss: 0.4844735562801361
Test Loss:  0.5084118843078613
Valid Loss:  0.5047408938407898
Epoch:  211  	Training Loss: 0.48447251319885254
Test Loss:  0.5084109306335449
Valid Loss:  0.5047398805618286
Epoch:  212  	Training Loss: 0.48447152972221375
Test Loss:  0.508409857749939
Valid Loss:  0.5047388672828674
Epoch:  213  	Training Loss: 0.4844704866409302
Test Loss:  0.508408784866333
Valid Loss:  0.5047377943992615
Epoch:  214  	Training Loss: 0.4844695031642914
Test Loss:  0.5084077715873718
Valid Loss:  0.5047367811203003
Epoch:  215  	Training Loss: 0.4844685196876526
Test Loss:  0.5084067583084106
Valid Loss:  0.5047357082366943
Epoch:  216  	Training Loss: 0.4844675064086914
Test Loss:  0.5084056854248047
Valid Loss:  0.5047346353530884
Epoch:  217  	Training Loss: 0.48446643352508545
Test Loss:  0.5084046125411987
Valid Loss:  0.5047336220741272
Epoch:  218  	Training Loss: 0.48446545004844666
Test Loss:  0.5084036588668823
Valid Loss:  0.504732608795166
Epoch:  219  	Training Loss: 0.48446446657180786
Test Loss:  0.5084025859832764
Valid Loss:  0.5047315359115601
Epoch:  220  	Training Loss: 0.4844634234905243
Test Loss:  0.5084015130996704
Valid Loss:  0.5047304630279541
Epoch:  221  	Training Loss: 0.4844624102115631
Test Loss:  0.5084004998207092
Valid Loss:  0.5047295093536377
Epoch:  222  	Training Loss: 0.48446139693260193
Test Loss:   45%|████▍     | 223/500 [02:37<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:38<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:38<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:38<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:44<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:44<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:44<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:45<01:58,  2.23it/s] 48%|████▊     | 239/500 [02:45<01:27,  3.00it/s] 48%|████▊     | 241/500 [02:51<05:01,  1.16s/it] 49%|████▊     | 243/500 [02:51<03:34,  1.20it/s] 49%|████▉     | 245/500 [02:51<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:52<02:03,  2.06it/s] 50%|████▉     | 249/500 [02:52<01:38,  2.54it/s] 50%|█████     | 251/500 [02:58<05:05,  1.23s/it] 51%|█████     | 253/500 [02:58<03:37,  1.14it/s] 51%|█████     | 255/500 [02:59<02:45,  1.48it/s] 51%|█████▏    | 257/500 [02:59<02:07,  1.90it/s] 52%|█████▏    | 259/500 [02:59<01:34,  2.55it/s] 52%|█████▏    | 261/500 [03:06<04:52,  1.22s/it] 53%|█████▎    | 263/500 [03:06<03:27,  1.14it/s] 53%|█████▎    | 265/500 [03:06<02:28,  1.58it/s] 53%|█████▎    | 267/500 [03:06<01:47,  2.16it/s] 54%|█████▍    | 269/500 [03:06<01:19,  2.91it/s] 54%|█████▍    | 271/500 [03:13<04:33,  1.20s/it] 55%|█████▍    | 273/500 [03:13<03:14,  1.16it/s] 55%|█████▌    | 275/500 [03:13<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:13<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:13<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:19<04:19,  1.19s/it] 57%|█████▋    | 283/500 [03:20<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:20<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:20<01:46,  2.00it/s] 58%|█████▊    | 288/500 [03:20<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:21<01:22,  2.57it/s] 58%|█████▊    | 291/500 [03:27<04:55,  1.41s/it] 58%|█████▊    | 292/500 [03:27<04:07,  1.19s/it] 59%|█████▊    | 293/500 [03:27<03:19,  1.04it/s] 59%|█████▉    | 294/500 [03:28<02:38,  1.30it/s]0.5083993673324585
Valid Loss:  0.5047283172607422
Epoch:  223  	Training Loss: 0.48446035385131836
Test Loss:  0.5083982944488525
Valid Loss:  0.5047272443771362
Epoch:  224  	Training Loss: 0.4844593107700348
Test Loss:  0.5083972215652466
Valid Loss:  0.504726231098175
Epoch:  225  	Training Loss: 0.48445823788642883
Test Loss:  0.5083961486816406
Valid Loss:  0.5047250986099243
Epoch:  226  	Training Loss: 0.48445719480514526
Test Loss:  0.5083950161933899
Valid Loss:  0.5047240257263184
Epoch:  227  	Training Loss: 0.4844561517238617
Test Loss:  0.5083939433097839
Valid Loss:  0.5047229528427124
Epoch:  228  	Training Loss: 0.48445507884025574
Test Loss:  0.5083929300308228
Valid Loss:  0.5047218799591064
Epoch:  229  	Training Loss: 0.48445403575897217
Test Loss:  0.5083917379379272
Valid Loss:  0.5047207474708557
Epoch:  230  	Training Loss: 0.4844529628753662
Test Loss:  0.5083907246589661
Valid Loss:  0.5047196745872498
Epoch:  231  	Training Loss: 0.48445191979408264
Test Loss:  0.5083895921707153
Valid Loss:  0.504718542098999
Epoch:  232  	Training Loss: 0.4844508767127991
Test Loss:  0.5083885788917542
Valid Loss:  0.5047175884246826
Epoch:  233  	Training Loss: 0.4844498634338379
Test Loss:  0.508387565612793
Valid Loss:  0.5047165155410767
Epoch:  234  	Training Loss: 0.4844489097595215
Test Loss:  0.5083865523338318
Valid Loss:  0.5047155022621155
Epoch:  235  	Training Loss: 0.4844478964805603
Test Loss:  0.5083855390548706
Valid Loss:  0.5047144889831543
Epoch:  236  	Training Loss: 0.4844468832015991
Test Loss:  0.5083845257759094
Valid Loss:  0.5047134757041931
Epoch:  237  	Training Loss: 0.4844458997249603
Test Loss:  0.5083835124969482
Valid Loss:  0.5047124624252319
Epoch:  238  	Training Loss: 0.48444488644599915
Test Loss:  0.5083824992179871
Valid Loss:  0.5047114491462708
Epoch:  239  	Training Loss: 0.48444390296936035
Test Loss:  0.5083814859390259
Valid Loss:  0.5047103762626648
Epoch:  240  	Training Loss: 0.48444291949272156
Test Loss:  0.5083804130554199
Valid Loss:  0.5047093629837036
Epoch:  241  	Training Loss: 0.48444193601608276
Test Loss:  0.508379340171814
Valid Loss:  0.5047084093093872
Epoch:  242  	Training Loss: 0.4844409227371216
Test Loss:  0.5083783864974976
Valid Loss:  0.5047072768211365
Epoch:  243  	Training Loss: 0.4844399094581604
Test Loss:  0.5083773136138916
Valid Loss:  0.5047062635421753
Epoch:  244  	Training Loss: 0.484438955783844
Test Loss:  0.5083763003349304
Valid Loss:  0.5047052502632141
Epoch:  245  	Training Loss: 0.4844379127025604
Test Loss:  0.5083752870559692
Valid Loss:  0.5047042369842529
Epoch:  246  	Training Loss: 0.48443692922592163
Test Loss:  0.5083742141723633
Valid Loss:  0.504703164100647
Epoch:  247  	Training Loss: 0.48443591594696045
Test Loss:  0.5083732604980469
Valid Loss:  0.5047022104263306
Epoch:  248  	Training Loss: 0.48443493247032166
Test Loss:  0.5083721876144409
Valid Loss:  0.5047011375427246
Epoch:  249  	Training Loss: 0.4844339191913605
Test Loss:  0.5083711743354797
Valid Loss:  0.5047001242637634
Epoch:  250  	Training Loss: 0.4844329357147217
Test Loss:  0.5083701610565186
Valid Loss:  0.5046990513801575
Epoch:  251  	Training Loss: 0.4844319224357605
Test Loss:  0.5083690881729126
Valid Loss:  0.5046980381011963
Epoch:  252  	Training Loss: 0.4844309091567993
Test Loss:  0.5083680748939514
Valid Loss:  0.5046969652175903
Epoch:  253  	Training Loss: 0.4844299554824829
Test Loss:  0.5083670616149902
Valid Loss:  0.5046960115432739
Epoch:  254  	Training Loss: 0.48442894220352173
Test Loss:  0.508366048336029
Valid Loss:  0.5046949982643127
Epoch:  255  	Training Loss: 0.48442792892456055
Test Loss:  0.5083650350570679
Valid Loss:  0.5046939849853516
Epoch:  256  	Training Loss: 0.48442697525024414
Test Loss:  0.5083640217781067
Valid Loss:  0.5046929121017456
Epoch:  257  	Training Loss: 0.48442596197128296
Test Loss:  0.5083630084991455
Valid Loss:  0.5046918988227844
Epoch:  258  	Training Loss: 0.48442500829696655
Test Loss:  0.5083619952201843
Valid Loss:  0.5046908855438232
Epoch:  259  	Training Loss: 0.48442399501800537
Test Loss:  0.5083609819412231
Valid Loss:  0.5046898722648621
Epoch:  260  	Training Loss: 0.4844229817390442
Test Loss:  0.5083599090576172
Valid Loss:  0.5046888589859009
Epoch:  261  	Training Loss: 0.4844219982624054
Test Loss:  0.5083589553833008
Valid Loss:  0.5046878457069397
Epoch:  262  	Training Loss: 0.4844210147857666
Test Loss:  0.5083578824996948
Valid Loss:  0.5046868324279785
Epoch:  263  	Training Loss: 0.4844200015068054
Test Loss:  0.5083568096160889
Valid Loss:  0.5046857595443726
Epoch:  264  	Training Loss: 0.48441898822784424
Test Loss:  0.5083558559417725
Valid Loss:  0.5046846866607666
Epoch:  265  	Training Loss: 0.48441797494888306
Test Loss:  0.5083547830581665
Valid Loss:  0.5046836733818054
Epoch:  266  	Training Loss: 0.48441702127456665
Test Loss:  0.5083537697792053
Valid Loss:  0.5046826601028442
Epoch:  267  	Training Loss: 0.4844159483909607
Test Loss:  0.5083526968955994
Valid Loss:  0.5046815872192383
Epoch:  268  	Training Loss: 0.4844149649143219
Test Loss:  0.5083516836166382
Valid Loss:  0.5046805739402771
Epoch:  269  	Training Loss: 0.4844139814376831
Test Loss:  0.5083506107330322
Valid Loss:  0.5046795606613159
Epoch:  270  	Training Loss: 0.4844129681587219
Test Loss:  0.508349597454071
Valid Loss:  0.50467848777771
Epoch:  271  	Training Loss: 0.48441192507743835
Test Loss:  0.5083485841751099
Valid Loss:  0.504677414894104
Epoch:  272  	Training Loss: 0.48441094160079956
Test Loss:  0.5083475112915039
Valid Loss:  0.504676342010498
Epoch:  273  	Training Loss: 0.4844098687171936
Test Loss:  0.508346438407898
Valid Loss:  0.5046752691268921
Epoch:  274  	Training Loss: 0.4844088554382324
Test Loss:  0.508345365524292
Valid Loss:  0.5046741962432861
Epoch:  275  	Training Loss: 0.48440781235694885
Test Loss:  0.508344292640686
Valid Loss:  0.504673182964325
Epoch:  276  	Training Loss: 0.4844067692756653
Test Loss:  0.5083432197570801
Valid Loss:  0.504672110080719
Epoch:  277  	Training Loss: 0.4844057559967041
Test Loss:  0.5083421468734741
Valid Loss:  0.5046709775924683
Epoch:  278  	Training Loss: 0.48440471291542053
Test Loss:  0.5083410739898682
Valid Loss:  0.5046699643135071
Epoch:  279  	Training Loss: 0.48440366983413696
Test Loss:  0.508340060710907
Valid Loss:  0.5046689510345459
Epoch:  280  	Training Loss: 0.4844026267528534
Test Loss:  0.508338987827301
Valid Loss:  0.5046678185462952
Epoch:  281  	Training Loss: 0.4844015836715698
Test Loss:  0.5083378553390503
Valid Loss:  0.5046667456626892
Epoch:  282  	Training Loss: 0.48440054059028625
Test Loss:  0.5083368420600891
Valid Loss:  0.5046656727790833
Epoch:  283  	Training Loss: 0.48439955711364746
Test Loss:  0.5083358287811279
Valid Loss:  0.5046646595001221
Epoch:  284  	Training Loss: 0.4843984842300415
Test Loss:  0.508334755897522
Valid Loss:  0.5046635866165161
Epoch:  285  	Training Loss: 0.4843975007534027
Test Loss:  0.508333683013916
Valid Loss:  0.5046625137329102
Epoch:  286  	Training Loss: 0.48439645767211914
Test Loss:  0.5083326101303101
Valid Loss:  0.504661500453949
Epoch:  287  	Training Loss: 0.48439544439315796
Test Loss:  0.5083315968513489
Valid Loss:  0.5046603679656982
Epoch:  288  	Training Loss: 0.4843944013118744
Test Loss:  0.5083305239677429
Valid Loss:  0.5046593546867371
Epoch:  289  	Training Loss: 0.4843934178352356
Test Loss:  0.5083295106887817
Valid Loss:  0.5046583414077759
Epoch:  290  	Training Loss: 0.484392374753952
Test Loss:  0.5083284378051758
Valid Loss:  0.5046572685241699
Epoch:  291  	Training Loss: 0.48439133167266846
Test Loss:  0.5083274245262146
Valid Loss:  0.504656195640564
Epoch:  292  	Training Loss: 0.48439034819602966
Test Loss:  0.5083263516426086
Valid Loss:  0.5046551823616028
Epoch:  293  	Training Loss: 0.4843893051147461
Test Loss:  0.5083253383636475
Valid Loss:  0.5046541094779968
Epoch:  294  	Training Loss: 0.4843882918357849
Test Loss:  0.5083243250846863
Valid Loss:  0.5046530961990356
Epoch:  295  	Training Loss: 0.4843873381614685
Test Loss:  0.5083233118057251
Valid Loss:  0.5046520829200745
 59%|█████▉    | 296/500 [03:28<01:38,  2.07it/s] 60%|█████▉    | 298/500 [03:28<01:06,  3.02it/s] 60%|██████    | 300/500 [03:28<00:47,  4.18it/s] 60%|██████    | 302/500 [03:34<03:58,  1.20s/it] 61%|██████    | 304/500 [03:34<02:44,  1.19it/s] 61%|██████    | 306/500 [03:35<01:55,  1.68it/s] 62%|██████▏   | 308/500 [03:35<01:22,  2.32it/s] 62%|██████▏   | 310/500 [03:35<01:00,  3.13it/s] 62%|██████▏   | 312/500 [03:41<03:43,  1.19s/it] 63%|██████▎   | 314/500 [03:41<02:38,  1.18it/s] 63%|██████▎   | 316/500 [03:42<01:52,  1.63it/s] 64%|██████▎   | 318/500 [03:42<01:21,  2.23it/s] 64%|██████▍   | 320/500 [03:42<00:59,  3.01it/s] 64%|██████▍   | 322/500 [03:48<03:28,  1.17s/it] 65%|██████▍   | 324/500 [03:48<02:27,  1.19it/s] 65%|██████▌   | 326/500 [03:48<01:45,  1.65it/s] 66%|██████▌   | 328/500 [03:48<01:17,  2.22it/s] 66%|██████▌   | 330/500 [03:49<00:57,  2.95it/s] 66%|██████▋   | 332/500 [03:55<03:23,  1.21s/it] 67%|██████▋   | 334/500 [03:55<02:23,  1.16it/s] 67%|██████▋   | 336/500 [03:55<01:42,  1.60it/s] 68%|██████▊   | 338/500 [03:55<01:14,  2.19it/s] 68%|██████▊   | 340/500 [03:56<00:54,  2.95it/s] 68%|██████▊   | 342/500 [04:02<03:12,  1.22s/it] 69%|██████▉   | 344/500 [04:02<02:16,  1.15it/s] 69%|██████▉   | 346/500 [04:02<01:37,  1.59it/s] 70%|██████▉   | 348/500 [04:03<01:10,  2.17it/s] 70%|███████   | 350/500 [04:03<00:51,  2.93it/s] 70%|███████   | 352/500 [04:09<02:57,  1.20s/it] 71%|███████   | 354/500 [04:09<02:05,  1.16it/s] 71%|███████   | 356/500 [04:09<01:29,  1.60it/s] 72%|███████▏  | 358/500 [04:09<01:04,  2.19it/s] 72%|███████▏  | 360/500 [04:10<00:47,  2.95it/s] 72%|███████▏  | 362/500 [04:16<02:44,  1.19s/it] 73%|███████▎  | 364/500 [04:16<01:55,  1.17it/s] 73%|███████▎  | 366/500 [04:16<01:22,  1.62it/s] 74%|███████▎  | 368/500 [04:16<00:59,  2.22it/s]Epoch:  296  	Training Loss: 0.48438629508018494
Test Loss:  0.5083222389221191
Valid Loss:  0.5046510696411133
Epoch:  297  	Training Loss: 0.48438528180122375
Test Loss:  0.508321225643158
Valid Loss:  0.5046499967575073
Epoch:  298  	Training Loss: 0.48438429832458496
Test Loss:  0.5083202123641968
Valid Loss:  0.5046489834785461
Epoch:  299  	Training Loss: 0.4843832850456238
Test Loss:  0.5083191394805908
Valid Loss:  0.504647970199585
Epoch:  300  	Training Loss: 0.4843822717666626
Test Loss:  0.5083181262016296
Valid Loss:  0.504646897315979
Epoch:  301  	Training Loss: 0.4843812882900238
Test Loss:  0.5083170533180237
Valid Loss:  0.504645824432373
Epoch:  302  	Training Loss: 0.48438024520874023
Test Loss:  0.5083159804344177
Valid Loss:  0.5046447515487671
Epoch:  303  	Training Loss: 0.48437920212745667
Test Loss:  0.5083149671554565
Valid Loss:  0.5046436786651611
Epoch:  304  	Training Loss: 0.4843781888484955
Test Loss:  0.5083138942718506
Valid Loss:  0.5046426057815552
Epoch:  305  	Training Loss: 0.4843771457672119
Test Loss:  0.5083128213882446
Valid Loss:  0.504641592502594
Epoch:  306  	Training Loss: 0.48437613248825073
Test Loss:  0.5083117485046387
Valid Loss:  0.5046404600143433
Epoch:  307  	Training Loss: 0.4843750596046448
Test Loss:  0.5083106756210327
Valid Loss:  0.5046394467353821
Epoch:  308  	Training Loss: 0.4843740165233612
Test Loss:  0.5083096027374268
Valid Loss:  0.5046383142471313
Epoch:  309  	Training Loss: 0.4843730032444
Test Loss:  0.5083085298538208
Valid Loss:  0.5046372413635254
Epoch:  310  	Training Loss: 0.48437193036079407
Test Loss:  0.5083074569702148
Valid Loss:  0.5046361684799194
Epoch:  311  	Training Loss: 0.4843708872795105
Test Loss:  0.5083063840866089
Valid Loss:  0.5046350955963135
Epoch:  312  	Training Loss: 0.4843698740005493
Test Loss:  0.5083053708076477
Valid Loss:  0.5046341419219971
Epoch:  313  	Training Loss: 0.48436886072158813
Test Loss:  0.5083043575286865
Valid Loss:  0.5046330690383911
Epoch:  314  	Training Loss: 0.48436787724494934
Test Loss:  0.5083032846450806
Valid Loss:  0.5046321153640747
Epoch:  315  	Training Loss: 0.48436692357063293
Test Loss:  0.5083023309707642
Valid Loss:  0.5046311020851135
Epoch:  316  	Training Loss: 0.48436594009399414
Test Loss:  0.5083013772964478
Valid Loss:  0.5046300888061523
Epoch:  317  	Training Loss: 0.48436492681503296
Test Loss:  0.5083003044128418
Valid Loss:  0.5046290159225464
Epoch:  318  	Training Loss: 0.48436397314071655
Test Loss:  0.5082993507385254
Valid Loss:  0.50462806224823
Epoch:  319  	Training Loss: 0.48436298966407776
Test Loss:  0.5082982778549194
Valid Loss:  0.504626989364624
Epoch:  320  	Training Loss: 0.48436200618743896
Test Loss:  0.508297324180603
Valid Loss:  0.5046259760856628
Epoch:  321  	Training Loss: 0.48436102271080017
Test Loss:  0.5082962512969971
Valid Loss:  0.5046250224113464
Epoch:  322  	Training Loss: 0.4843600392341614
Test Loss:  0.5082952380180359
Valid Loss:  0.5046238899230957
Epoch:  323  	Training Loss: 0.4843589663505554
Test Loss:  0.5082941055297852
Valid Loss:  0.5046228170394897
Epoch:  324  	Training Loss: 0.48435795307159424
Test Loss:  0.5082931518554688
Valid Loss:  0.5046218037605286
Epoch:  325  	Training Loss: 0.4843568801879883
Test Loss:  0.5082920789718628
Valid Loss:  0.5046207308769226
Epoch:  326  	Training Loss: 0.4843558669090271
Test Loss:  0.5082909464836121
Valid Loss:  0.5046195983886719
Epoch:  327  	Training Loss: 0.48435482382774353
Test Loss:  0.5082899332046509
Valid Loss:  0.5046185255050659
Epoch:  328  	Training Loss: 0.48435381054878235
Test Loss:  0.5082888603210449
Valid Loss:  0.50461745262146
Epoch:  329  	Training Loss: 0.484352707862854
Test Loss:  0.508287787437439
Valid Loss:  0.504616379737854
Epoch:  330  	Training Loss: 0.4843516945838928
Test Loss:  0.508286714553833
Valid Loss:  0.5046153664588928
Epoch:  331  	Training Loss: 0.48435065150260925
Test Loss:  0.508285641670227
Valid Loss:  0.5046142935752869
Epoch:  332  	Training Loss: 0.4843496084213257
Test Loss:  0.5082845091819763
Valid Loss:  0.5046131610870361
Epoch:  333  	Training Loss: 0.48434850573539734
Test Loss:  0.5082833766937256
Valid Loss:  0.5046119689941406
Epoch:  334  	Training Loss: 0.484347403049469
Test Loss:  0.5082822442054749
Valid Loss:  0.5046108961105347
Epoch:  335  	Training Loss: 0.48434633016586304
Test Loss:  0.5082811117172241
Valid Loss:  0.5046098232269287
Epoch:  336  	Training Loss: 0.4843452274799347
Test Loss:  0.5082800388336182
Valid Loss:  0.504608690738678
Epoch:  337  	Training Loss: 0.48434412479400635
Test Loss:  0.5082789063453674
Valid Loss:  0.5046075582504272
Epoch:  338  	Training Loss: 0.48434311151504517
Test Loss:  0.5082777738571167
Valid Loss:  0.5046064257621765
Epoch:  339  	Training Loss: 0.48434197902679443
Test Loss:  0.5082767009735107
Valid Loss:  0.5046052932739258
Epoch:  340  	Training Loss: 0.4843409061431885
Test Loss:  0.50827556848526
Valid Loss:  0.504604160785675
Epoch:  341  	Training Loss: 0.4843398332595825
Test Loss:  0.5082744359970093
Valid Loss:  0.5046030282974243
Epoch:  342  	Training Loss: 0.4843387007713318
Test Loss:  0.5082733631134033
Valid Loss:  0.5046019554138184
Epoch:  343  	Training Loss: 0.4843376576900482
Test Loss:  0.5082722902297974
Valid Loss:  0.5046008825302124
Epoch:  344  	Training Loss: 0.48433658480644226
Test Loss:  0.5082712173461914
Valid Loss:  0.5045997500419617
Epoch:  345  	Training Loss: 0.4843355119228363
Test Loss:  0.5082700848579407
Valid Loss:  0.5045986175537109
Epoch:  346  	Training Loss: 0.48433443903923035
Test Loss:  0.5082690119743347
Valid Loss:  0.504597544670105
Epoch:  347  	Training Loss: 0.4843333959579468
Test Loss:  0.508267879486084
Valid Loss:  0.504596471786499
Epoch:  348  	Training Loss: 0.4843323230743408
Test Loss:  0.508266806602478
Valid Loss:  0.5045953392982483
Epoch:  349  	Training Loss: 0.4843312203884125
Test Loss:  0.5082657337188721
Valid Loss:  0.5045942664146423
Epoch:  350  	Training Loss: 0.4843301773071289
Test Loss:  0.5082645416259766
Valid Loss:  0.5045931339263916
Epoch:  351  	Training Loss: 0.48432910442352295
Test Loss:  0.5082635283470154
Valid Loss:  0.5045920610427856
Epoch:  352  	Training Loss: 0.484328031539917
Test Loss:  0.5082624554634094
Valid Loss:  0.5045909881591797
Epoch:  353  	Training Loss: 0.4843270182609558
Test Loss:  0.5082614421844482
Valid Loss:  0.5045899152755737
Epoch:  354  	Training Loss: 0.48432594537734985
Test Loss:  0.5082603693008423
Valid Loss:  0.5045888423919678
Epoch:  355  	Training Loss: 0.48432496190071106
Test Loss:  0.5082592964172363
Valid Loss:  0.5045878887176514
Epoch:  356  	Training Loss: 0.4843239486217499
Test Loss:  0.5082582235336304
Valid Loss:  0.5045868158340454
Epoch:  357  	Training Loss: 0.4843229055404663
Test Loss:  0.5082572102546692
Valid Loss:  0.5045857429504395
Epoch:  358  	Training Loss: 0.4843218922615051
Test Loss:  0.508256196975708
Valid Loss:  0.5045846700668335
Epoch:  359  	Training Loss: 0.48432087898254395
Test Loss:  0.508255124092102
Valid Loss:  0.5045835971832275
Epoch:  360  	Training Loss: 0.48431986570358276
Test Loss:  0.5082540512084961
Valid Loss:  0.5045825242996216
Epoch:  361  	Training Loss: 0.4843188524246216
Test Loss:  0.5082529783248901
Valid Loss:  0.5045815110206604
Epoch:  362  	Training Loss: 0.4843177795410156
Test Loss:  0.508251965045929
Valid Loss:  0.5045804381370544
Epoch:  363  	Training Loss: 0.48431676626205444
Test Loss:  0.5082508325576782
Valid Loss:  0.5045793652534485
Epoch:  364  	Training Loss: 0.4843156933784485
Test Loss:  0.5082497596740723
Valid Loss:  0.5045782327651978
Epoch:  365  	Training Loss: 0.48431462049484253
Test Loss:  0.5082486867904663
Valid Loss:  0.5045771598815918
Epoch:  366  	Training Loss: 0.48431357741355896
Test Loss:  0.5082476139068604
Valid Loss:  0.5045760869979858
Epoch:  367  	Training Loss: 0.4843125343322754
Test Loss:  0.5082465410232544
Valid Loss:  0.5045750141143799
Epoch:  368  	Training Loss: 0.48431146144866943
Test Loss:  0.5082454681396484
Valid Loss:  0.5045739412307739
Epoch:  369  	Training Loss: 0.48431044816970825
Test Loss:  0.5082443952560425
 74%|███████▍  | 370/500 [04:16<00:43,  2.99it/s] 74%|███████▍  | 372/500 [04:23<02:31,  1.19s/it] 75%|███████▍  | 374/500 [04:23<01:47,  1.18it/s] 75%|███████▌  | 376/500 [04:23<01:16,  1.63it/s] 76%|███████▌  | 378/500 [04:23<00:54,  2.23it/s] 76%|███████▌  | 380/500 [04:23<00:40,  2.99it/s] 76%|███████▋  | 382/500 [04:30<02:17,  1.17s/it] 77%|███████▋  | 384/500 [04:30<01:37,  1.20it/s] 77%|███████▋  | 386/500 [04:30<01:09,  1.65it/s] 78%|███████▊  | 388/500 [04:30<00:49,  2.25it/s] 78%|███████▊  | 390/500 [04:30<00:36,  2.98it/s] 78%|███████▊  | 392/500 [04:36<02:07,  1.18s/it] 79%|███████▉  | 394/500 [04:37<01:29,  1.18it/s] 79%|███████▉  | 396/500 [04:37<01:03,  1.64it/s] 80%|███████▉  | 398/500 [04:37<00:45,  2.23it/s] 80%|████████  | 400/500 [04:37<00:33,  2.99it/s] 80%|████████  | 402/500 [04:43<01:55,  1.18s/it] 81%|████████  | 404/500 [04:43<01:21,  1.18it/s] 81%|████████  | 406/500 [04:44<00:57,  1.63it/s] 82%|████████▏ | 408/500 [04:44<00:41,  2.23it/s] 82%|████████▏ | 410/500 [04:44<00:29,  3.00it/s] 82%|████████▏ | 412/500 [04:50<01:45,  1.20s/it] 83%|████████▎ | 414/500 [04:50<01:13,  1.16it/s] 83%|████████▎ | 416/500 [04:51<00:52,  1.61it/s] 84%|████████▎ | 418/500 [04:51<00:37,  2.20it/s] 84%|████████▍ | 420/500 [04:51<00:27,  2.96it/s] 84%|████████▍ | 422/500 [04:57<01:31,  1.18s/it] 85%|████████▍ | 424/500 [04:57<01:04,  1.19it/s] 85%|████████▌ | 426/500 [04:57<00:45,  1.64it/s] 86%|████████▌ | 428/500 [04:57<00:32,  2.24it/s] 86%|████████▌ | 430/500 [04:58<00:23,  3.01it/s] 86%|████████▋ | 432/500 [05:04<01:20,  1.18s/it] 87%|████████▋ | 434/500 [05:04<00:55,  1.18it/s] 87%|████████▋ | 436/500 [05:04<00:39,  1.64it/s] 88%|████████▊ | 438/500 [05:04<00:27,  2.23it/s] 88%|████████▊ | 440/500 [05:04<00:19,  3.00it/s] 88%|████████▊ | 442/500 [05:11<01:08,  1.19s/it]Valid Loss:  0.5045728087425232
Epoch:  370  	Training Loss: 0.4843093752861023
Test Loss:  0.5082433223724365
Valid Loss:  0.5045717358589172
Epoch:  371  	Training Loss: 0.48430830240249634
Test Loss:  0.5082421898841858
Valid Loss:  0.5045706629753113
Epoch:  372  	Training Loss: 0.4843072295188904
Test Loss:  0.5082411170005798
Valid Loss:  0.5045695304870605
Epoch:  373  	Training Loss: 0.4843061566352844
Test Loss:  0.5082399845123291
Valid Loss:  0.5045683979988098
Epoch:  374  	Training Loss: 0.48430508375167847
Test Loss:  0.5082389116287231
Valid Loss:  0.5045672655105591
Epoch:  375  	Training Loss: 0.4843039810657501
Test Loss:  0.5082377791404724
Valid Loss:  0.5045661926269531
Epoch:  376  	Training Loss: 0.48430293798446655
Test Loss:  0.5082366466522217
Valid Loss:  0.5045650601387024
Epoch:  377  	Training Loss: 0.4843018651008606
Test Loss:  0.5082355737686157
Valid Loss:  0.5045639276504517
Epoch:  378  	Training Loss: 0.48430073261260986
Test Loss:  0.5082345008850098
Valid Loss:  0.5045627951622009
Epoch:  379  	Training Loss: 0.4842996597290039
Test Loss:  0.508233368396759
Valid Loss:  0.504561722278595
Epoch:  380  	Training Loss: 0.48429858684539795
Test Loss:  0.5082322359085083
Valid Loss:  0.5045605897903442
Epoch:  381  	Training Loss: 0.484297513961792
Test Loss:  0.5082311630249023
Valid Loss:  0.5045594573020935
Epoch:  382  	Training Loss: 0.48429638147354126
Test Loss:  0.5082299709320068
Valid Loss:  0.5045583248138428
Epoch:  383  	Training Loss: 0.4842953085899353
Test Loss:  0.5082288384437561
Valid Loss:  0.504557192325592
Epoch:  384  	Training Loss: 0.48429417610168457
Test Loss:  0.5082277059555054
Valid Loss:  0.5045560002326965
Epoch:  385  	Training Loss: 0.48429301381111145
Test Loss:  0.5082265138626099
Valid Loss:  0.5045548677444458
Epoch:  386  	Training Loss: 0.4842919111251831
Test Loss:  0.5082253813743591
Valid Loss:  0.5045536756515503
Epoch:  387  	Training Loss: 0.4842907786369324
Test Loss:  0.5082242488861084
Valid Loss:  0.5045525431632996
Epoch:  388  	Training Loss: 0.48428964614868164
Test Loss:  0.5082230567932129
Valid Loss:  0.5045514106750488
Epoch:  389  	Training Loss: 0.4842885434627533
Test Loss:  0.5082219243049622
Valid Loss:  0.5045502185821533
Epoch:  390  	Training Loss: 0.48428744077682495
Test Loss:  0.5082207918167114
Valid Loss:  0.5045490860939026
Epoch:  391  	Training Loss: 0.4842863082885742
Test Loss:  0.5082196593284607
Valid Loss:  0.5045479536056519
Epoch:  392  	Training Loss: 0.4842851758003235
Test Loss:  0.50821852684021
Valid Loss:  0.5045467615127563
Epoch:  393  	Training Loss: 0.48428410291671753
Test Loss:  0.508217453956604
Valid Loss:  0.5045456886291504
Epoch:  394  	Training Loss: 0.4842830300331116
Test Loss:  0.508216381072998
Valid Loss:  0.5045446157455444
Epoch:  395  	Training Loss: 0.4842819571495056
Test Loss:  0.5082153081893921
Valid Loss:  0.5045435428619385
Epoch:  396  	Training Loss: 0.48428091406822205
Test Loss:  0.5082141757011414
Valid Loss:  0.5045424103736877
Epoch:  397  	Training Loss: 0.4842798411846161
Test Loss:  0.5082131028175354
Valid Loss:  0.504541277885437
Epoch:  398  	Training Loss: 0.48427876830101013
Test Loss:  0.5082119703292847
Valid Loss:  0.504540205001831
Epoch:  399  	Training Loss: 0.4842776656150818
Test Loss:  0.5082108974456787
Valid Loss:  0.5045391321182251
Epoch:  400  	Training Loss: 0.4842766523361206
Test Loss:  0.5082098245620728
Valid Loss:  0.5045379996299744
Epoch:  401  	Training Loss: 0.48427554965019226
Test Loss:  0.5082087516784668
Valid Loss:  0.5045368671417236
Epoch:  402  	Training Loss: 0.4842745065689087
Test Loss:  0.5082076191902161
Valid Loss:  0.5045357346534729
Epoch:  403  	Training Loss: 0.48427337408065796
Test Loss:  0.5082064270973206
Valid Loss:  0.5045346021652222
Epoch:  404  	Training Loss: 0.4842722713947296
Test Loss:  0.5082053542137146
Valid Loss:  0.5045334100723267
Epoch:  405  	Training Loss: 0.4842711389064789
Test Loss:  0.5082041621208191
Valid Loss:  0.5045323371887207
Epoch:  406  	Training Loss: 0.48427003622055054
Test Loss:  0.5082030296325684
Valid Loss:  0.5045311450958252
Epoch:  407  	Training Loss: 0.4842689335346222
Test Loss:  0.5082018375396729
Valid Loss:  0.5045300126075745
Epoch:  408  	Training Loss: 0.48426780104637146
Test Loss:  0.5082007646560669
Valid Loss:  0.5045288801193237
Epoch:  409  	Training Loss: 0.4842666983604431
Test Loss:  0.5081995725631714
Valid Loss:  0.504527747631073
Epoch:  410  	Training Loss: 0.4842655658721924
Test Loss:  0.5081984996795654
Valid Loss:  0.5045265555381775
Epoch:  411  	Training Loss: 0.48426446318626404
Test Loss:  0.5081973671913147
Valid Loss:  0.5045254230499268
Epoch:  412  	Training Loss: 0.4842633605003357
Test Loss:  0.508196234703064
Valid Loss:  0.5045243501663208
Epoch:  413  	Training Loss: 0.48426228761672974
Test Loss:  0.508195161819458
Valid Loss:  0.5045232772827148
Epoch:  414  	Training Loss: 0.48426124453544617
Test Loss:  0.508194088935852
Valid Loss:  0.5045222043991089
Epoch:  415  	Training Loss: 0.4842601418495178
Test Loss:  0.5081930160522461
Valid Loss:  0.5045210719108582
Epoch:  416  	Training Loss: 0.48425909876823425
Test Loss:  0.5081918835639954
Valid Loss:  0.5045199394226074
Epoch:  417  	Training Loss: 0.4842580556869507
Test Loss:  0.5081908106803894
Valid Loss:  0.5045188665390015
Epoch:  418  	Training Loss: 0.4842569828033447
Test Loss:  0.5081897377967834
Valid Loss:  0.5045177936553955
Epoch:  419  	Training Loss: 0.48425590991973877
Test Loss:  0.5081886649131775
Valid Loss:  0.5045166611671448
Epoch:  420  	Training Loss: 0.4842548370361328
Test Loss:  0.5081875324249268
Valid Loss:  0.504515528678894
Epoch:  421  	Training Loss: 0.48425379395484924
Test Loss:  0.5081864595413208
Valid Loss:  0.5045144557952881
Epoch:  422  	Training Loss: 0.4842527210712433
Test Loss:  0.5081853866577148
Valid Loss:  0.5045133829116821
Epoch:  423  	Training Loss: 0.48425161838531494
Test Loss:  0.5081842541694641
Valid Loss:  0.5045121908187866
Epoch:  424  	Training Loss: 0.4842505156993866
Test Loss:  0.5081831216812134
Valid Loss:  0.5045111179351807
Epoch:  425  	Training Loss: 0.48424941301345825
Test Loss:  0.5081819891929626
Valid Loss:  0.5045099258422852
Epoch:  426  	Training Loss: 0.4842483401298523
Test Loss:  0.5081808567047119
Valid Loss:  0.5045088529586792
Epoch:  427  	Training Loss: 0.48424720764160156
Test Loss:  0.5081797242164612
Valid Loss:  0.5045076608657837
Epoch:  428  	Training Loss: 0.4842461049556732
Test Loss:  0.5081785917282104
Valid Loss:  0.504506528377533
Epoch:  429  	Training Loss: 0.48424503207206726
Test Loss:  0.5081775188446045
Valid Loss:  0.5045053958892822
Epoch:  430  	Training Loss: 0.4842439293861389
Test Loss:  0.508176326751709
Valid Loss:  0.5045043230056763
Epoch:  431  	Training Loss: 0.4842427968978882
Test Loss:  0.508175253868103
Valid Loss:  0.5045031309127808
Epoch:  432  	Training Loss: 0.4842417240142822
Test Loss:  0.5081741213798523
Valid Loss:  0.5045020580291748
Epoch:  433  	Training Loss: 0.4842405915260315
Test Loss:  0.5081729888916016
Valid Loss:  0.5045008659362793
Epoch:  434  	Training Loss: 0.48423945903778076
Test Loss:  0.508171796798706
Valid Loss:  0.5044996738433838
Epoch:  435  	Training Loss: 0.48423832654953003
Test Loss:  0.5081706047058105
Valid Loss:  0.5044984817504883
Epoch:  436  	Training Loss: 0.4842372238636017
Test Loss:  0.5081695318222046
Valid Loss:  0.5044973492622375
Epoch:  437  	Training Loss: 0.48423612117767334
Test Loss:  0.5081683397293091
Valid Loss:  0.5044962167739868
Epoch:  438  	Training Loss: 0.48423492908477783
Test Loss:  0.5081671476364136
Valid Loss:  0.5044950246810913
Epoch:  439  	Training Loss: 0.4842338263988495
Test Loss:  0.5081660747528076
Valid Loss:  0.5044938921928406
Epoch:  440  	Training Loss: 0.48423269391059875
Test Loss:  0.5081648826599121
Valid Loss:  0.5044927597045898
Epoch:  441  	Training Loss: 0.484231561422348
Test Loss:  0.5081637501716614
Valid Loss:  0.5044915676116943
Epoch:  442  	Training Loss: 0.4842304587364197
Test Loss:  0.5081624984741211
Valid Loss:  0.5044903755187988
 89%|████████▉ | 444/500 [05:11<00:47,  1.18it/s] 89%|████████▉ | 446/500 [05:11<00:33,  1.63it/s] 90%|████████▉ | 448/500 [05:11<00:23,  2.22it/s] 90%|█████████ | 450/500 [05:11<00:16,  2.99it/s] 90%|█████████ | 452/500 [05:18<00:57,  1.21s/it] 91%|█████████ | 454/500 [05:18<00:39,  1.16it/s] 91%|█████████ | 456/500 [05:18<00:27,  1.60it/s] 92%|█████████▏| 458/500 [05:18<00:19,  2.19it/s] 92%|█████████▏| 460/500 [05:18<00:13,  2.95it/s] 92%|█████████▏| 462/500 [05:25<00:45,  1.19s/it] 93%|█████████▎| 464/500 [05:25<00:30,  1.17it/s] 93%|█████████▎| 466/500 [05:25<00:21,  1.62it/s] 94%|█████████▎| 468/500 [05:25<00:14,  2.21it/s] 94%|█████████▍| 470/500 [05:25<00:10,  2.98it/s] 94%|█████████▍| 472/500 [05:31<00:33,  1.18s/it] 95%|█████████▍| 474/500 [05:32<00:22,  1.18it/s] 95%|█████████▌| 476/500 [05:32<00:14,  1.63it/s] 96%|█████████▌| 478/500 [05:32<00:09,  2.23it/s] 96%|█████████▌| 480/500 [05:32<00:06,  2.99it/s] 96%|█████████▋| 482/500 [05:38<00:21,  1.18s/it] 97%|█████████▋| 484/500 [05:38<00:13,  1.18it/s] 97%|█████████▋| 486/500 [05:39<00:08,  1.64it/s] 98%|█████████▊| 488/500 [05:39<00:05,  2.24it/s] 98%|█████████▊| 490/500 [05:39<00:03,  3.00it/s] 98%|█████████▊| 492/500 [05:45<00:09,  1.19s/it] 99%|█████████▉| 494/500 [05:45<00:05,  1.17it/s] 99%|█████████▉| 496/500 [05:45<00:02,  1.62it/s]100%|█████████▉| 498/500 [05:46<00:00,  2.21it/s]100%|██████████| 500/500 [05:46<00:00,  2.97it/s]100%|██████████| 500/500 [05:46<00:00,  1.44it/s]
Epoch:  443  	Training Loss: 0.48422932624816895
Test Loss:  0.5081614255905151
Valid Loss:  0.5044891834259033
Epoch:  444  	Training Loss: 0.4842281937599182
Test Loss:  0.5081602334976196
Valid Loss:  0.5044880509376526
Epoch:  445  	Training Loss: 0.4842270016670227
Test Loss:  0.5081591010093689
Valid Loss:  0.5044868588447571
Epoch:  446  	Training Loss: 0.484225869178772
Test Loss:  0.5081579685211182
Valid Loss:  0.5044857263565063
Epoch:  447  	Training Loss: 0.48422476649284363
Test Loss:  0.5081567764282227
Valid Loss:  0.5044845342636108
Epoch:  448  	Training Loss: 0.4842236042022705
Test Loss:  0.5081555843353271
Valid Loss:  0.5044833421707153
Epoch:  449  	Training Loss: 0.4842224717140198
Test Loss:  0.5081544518470764
Valid Loss:  0.5044822096824646
Epoch:  450  	Training Loss: 0.48422136902809143
Test Loss:  0.5081533193588257
Valid Loss:  0.5044809579849243
Epoch:  451  	Training Loss: 0.4842202067375183
Test Loss:  0.5081521272659302
Valid Loss:  0.5044798851013184
Epoch:  452  	Training Loss: 0.4842190742492676
Test Loss:  0.5081510543823242
Valid Loss:  0.5044787526130676
Epoch:  453  	Training Loss: 0.4842180013656616
Test Loss:  0.5081499814987183
Valid Loss:  0.5044776201248169
Epoch:  454  	Training Loss: 0.4842168986797333
Test Loss:  0.5081488490104675
Valid Loss:  0.5044765472412109
Epoch:  455  	Training Loss: 0.4842158555984497
Test Loss:  0.5081477165222168
Valid Loss:  0.5044753551483154
Epoch:  456  	Training Loss: 0.48421478271484375
Test Loss:  0.5081466436386108
Valid Loss:  0.5044742822647095
Epoch:  457  	Training Loss: 0.4842137098312378
Test Loss:  0.5081455707550049
Valid Loss:  0.5044731497764587
Epoch:  458  	Training Loss: 0.48421257734298706
Test Loss:  0.5081443786621094
Valid Loss:  0.504472017288208
Epoch:  459  	Training Loss: 0.4842115044593811
Test Loss:  0.5081433653831482
Valid Loss:  0.504470944404602
Epoch:  460  	Training Loss: 0.48421043157577515
Test Loss:  0.5081422328948975
Valid Loss:  0.5044698119163513
Epoch:  461  	Training Loss: 0.4842093586921692
Test Loss:  0.5081411600112915
Valid Loss:  0.5044687986373901
Epoch:  462  	Training Loss: 0.4842083156108856
Test Loss:  0.508139967918396
Valid Loss:  0.5044675469398499
Epoch:  463  	Training Loss: 0.4842071533203125
Test Loss:  0.5081387758255005
Valid Loss:  0.5044664144515991
Epoch:  464  	Training Loss: 0.4842059910297394
Test Loss:  0.5081377029418945
Valid Loss:  0.5044652223587036
Epoch:  465  	Training Loss: 0.48420488834381104
Test Loss:  0.508136510848999
Valid Loss:  0.5044640302658081
Epoch:  466  	Training Loss: 0.4842037558555603
Test Loss:  0.5081353187561035
Valid Loss:  0.5044628381729126
Epoch:  467  	Training Loss: 0.4842025637626648
Test Loss:  0.5081341862678528
Valid Loss:  0.5044616460800171
Epoch:  468  	Training Loss: 0.48420143127441406
Test Loss:  0.508133053779602
Valid Loss:  0.5044605135917664
Epoch:  469  	Training Loss: 0.48420029878616333
Test Loss:  0.5081318616867065
Valid Loss:  0.5044593811035156
Epoch:  470  	Training Loss: 0.484199196100235
Test Loss:  0.508130669593811
Valid Loss:  0.5044581890106201
Epoch:  471  	Training Loss: 0.48419806361198425
Test Loss:  0.5081295967102051
Valid Loss:  0.5044570565223694
Epoch:  472  	Training Loss: 0.4841969609260559
Test Loss:  0.5081284046173096
Valid Loss:  0.5044558048248291
Epoch:  473  	Training Loss: 0.4841957688331604
Test Loss:  0.5081272125244141
Valid Loss:  0.5044546723365784
Epoch:  474  	Training Loss: 0.48419463634490967
Test Loss:  0.5081260204315186
Valid Loss:  0.5044534802436829
Epoch:  475  	Training Loss: 0.48419344425201416
Test Loss:  0.508124828338623
Valid Loss:  0.5044522285461426
Epoch:  476  	Training Loss: 0.4841923117637634
Test Loss:  0.5081236362457275
Valid Loss:  0.5044510960578918
Epoch:  477  	Training Loss: 0.4841911494731903
Test Loss:  0.508122444152832
Valid Loss:  0.5044498443603516
Epoch:  478  	Training Loss: 0.4841899573802948
Test Loss:  0.5081212520599365
Valid Loss:  0.504448652267456
Epoch:  479  	Training Loss: 0.48418882489204407
Test Loss:  0.508120059967041
Valid Loss:  0.5044474601745605
Epoch:  480  	Training Loss: 0.48418760299682617
Test Loss:  0.5081188678741455
Valid Loss:  0.504446268081665
Epoch:  481  	Training Loss: 0.48418647050857544
Test Loss:  0.5081177353858948
Valid Loss:  0.5044450759887695
Epoch:  482  	Training Loss: 0.4841853380203247
Test Loss:  0.5081165432929993
Valid Loss:  0.504443883895874
Epoch:  483  	Training Loss: 0.4841841757297516
Test Loss:  0.5081154108047485
Valid Loss:  0.5044427514076233
Epoch:  484  	Training Loss: 0.48418304324150085
Test Loss:  0.5081142783164978
Valid Loss:  0.5044416189193726
Epoch:  485  	Training Loss: 0.4841819107532501
Test Loss:  0.5081130862236023
Valid Loss:  0.504440426826477
Epoch:  486  	Training Loss: 0.4841807782649994
Test Loss:  0.5081119537353516
Valid Loss:  0.5044392347335815
Epoch:  487  	Training Loss: 0.48417964577674866
Test Loss:  0.5081108212471008
Valid Loss:  0.504438042640686
Epoch:  488  	Training Loss: 0.48417848348617554
Test Loss:  0.5081096291542053
Valid Loss:  0.5044369101524353
Epoch:  489  	Training Loss: 0.4841773509979248
Test Loss:  0.5081084966659546
Valid Loss:  0.5044357180595398
Epoch:  490  	Training Loss: 0.4841762185096741
Test Loss:  0.5081073045730591
Valid Loss:  0.5044345855712891
Epoch:  491  	Training Loss: 0.48417508602142334
Test Loss:  0.5081061720848083
Valid Loss:  0.5044333934783936
Epoch:  492  	Training Loss: 0.4841739535331726
Test Loss:  0.5081049203872681
Valid Loss:  0.504432201385498
Epoch:  493  	Training Loss: 0.4841727614402771
Test Loss:  0.5081037282943726
Valid Loss:  0.504430890083313
Epoch:  494  	Training Loss: 0.4841715693473816
Test Loss:  0.508102536201477
Valid Loss:  0.5044296979904175
Epoch:  495  	Training Loss: 0.4841703772544861
Test Loss:  0.5081013441085815
Valid Loss:  0.504428505897522
Epoch:  496  	Training Loss: 0.48416921496391296
Test Loss:  0.5081000924110413
Valid Loss:  0.5044273138046265
Epoch:  497  	Training Loss: 0.48416805267333984
Test Loss:  0.5080989003181458
Valid Loss:  0.5044260621070862
Epoch:  498  	Training Loss: 0.48416683077812195
Test Loss:  0.5080977082252502
Valid Loss:  0.5044248700141907
Epoch:  499  	Training Loss: 0.48416566848754883
Test Loss:  0.5080965161323547
Valid Loss:  0.5044236183166504
Epoch:  500  	Training Loss: 0.48416444659233093
Test Loss:  0.5080952644348145
Valid Loss:  0.5044223666191101
seed is  18
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:03,  6.14s/it]  1%|          | 3/500 [00:06<13:37,  1.64s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:45,  2.90it/s]  4%|▍         | 21/500 [00:20<09:49,  1.23s/it]  5%|▍         | 23/500 [00:20<06:58,  1.14it/s]  5%|▌         | 25/500 [00:20<04:59,  1.58it/s]  5%|▌         | 27/500 [00:20<03:37,  2.17it/s]  6%|▌         | 29/500 [00:20<02:40,  2.93it/s]  6%|▌         | 31/500 [00:27<09:32,  1.22s/it]  7%|▋         | 33/500 [00:27<06:47,  1.14it/s]  7%|▋         | 35/500 [00:27<04:53,  1.59it/s]  7%|▋         | 37/500 [00:27<03:33,  2.17it/s]  8%|▊         | 39/500 [00:27<02:37,  2.93it/s]  8%|▊         | 41/500 [00:34<09:19,  1.22s/it]  9%|▊         | 43/500 [00:34<06:40,  1.14it/s]  9%|▉         | 45/500 [00:34<04:47,  1.58it/s]  9%|▉         | 47/500 [00:34<03:29,  2.16it/s] 10%|▉         | 49/500 [00:34<02:35,  2.90it/s] 10%|█         | 51/500 [00:47<15:54,  2.13s/it] 11%|█         | 53/500 [00:47<11:15,  1.51s/it] 11%|█         | 55/500 [00:47<08:00,  1.08s/it] 11%|█▏        | 57/500 [00:47<05:43,  1.29it/s] 12%|█▏        | 59/500 [00:47<04:07,  1.78it/s] 12%|█▏        | 61/500 [00:54<09:50,  1.34s/it] 13%|█▎        | 63/500 [00:54<07:02,  1.03it/s] 13%|█▎        | 65/500 [00:54<05:04,  1.43it/s] 13%|█▎        | 67/500 [00:54<03:40,  1.96it/s] 14%|█▍        | 69/500 [00:54<02:42,  2.66it/s]Epoch:  1  	Training Loss: 0.5200355648994446
Test Loss:  2.8817853927612305
Valid Loss:  2.845694065093994
Epoch:  2  	Training Loss: 2.8480076789855957
Test Loss:  3.974356174468994
Valid Loss:  3.885557174682617
Epoch:  3  	Training Loss: 3.8278403282165527
Test Loss:  0.38762032985687256
Valid Loss:  0.39078444242477417
Epoch:  4  	Training Loss: 0.4107009172439575
Test Loss:  0.3790504038333893
Valid Loss:  0.38254934549331665
Epoch:  5  	Training Loss: 0.402824729681015
Test Loss:  0.3674278259277344
Valid Loss:  0.3714027404785156
Epoch:  6  	Training Loss: 0.39212766289711
Test Loss:  0.3564487397670746
Valid Loss:  0.3608950972557068
Epoch:  7  	Training Loss: 0.3820517063140869
Test Loss:  0.3460747301578522
Valid Loss:  0.35098758339881897
Epoch:  8  	Training Loss: 0.37255859375
Test Loss:  0.33626994490623474
Valid Loss:  0.34164372086524963
Epoch:  9  	Training Loss: 0.36361250281333923
Test Loss:  0.32700085639953613
Valid Loss:  0.3328295946121216
Epoch:  10  	Training Loss: 0.35518017411231995
Test Loss:  0.3182356655597687
Valid Loss:  0.32451286911964417
Epoch:  11  	Training Loss: 0.3472299575805664
Test Loss:  0.30994483828544617
Valid Loss:  0.3166639804840088
Epoch:  12  	Training Loss: 0.33973264694213867
Test Loss:  0.15247032046318054
Valid Loss:  0.17679071426391602
Epoch:  13  	Training Loss: 0.20945516228675842
Test Loss:  0.14334158599376678
Valid Loss:  0.16647964715957642
Epoch:  14  	Training Loss: 0.19733643531799316
Test Loss:  0.13835939764976501
Valid Loss:  0.16038069128990173
Epoch:  15  	Training Loss: 0.18994316458702087
Test Loss:  0.13318651914596558
Valid Loss:  0.1544112265110016
Epoch:  16  	Training Loss: 0.18286556005477905
Test Loss:  0.12813180685043335
Valid Loss:  0.148641437292099
Epoch:  17  	Training Loss: 0.1760546863079071
Test Loss:  0.1232537031173706
Valid Loss:  0.14308381080627441
Epoch:  18  	Training Loss: 0.1694992482662201
Test Loss:  0.11855770647525787
Valid Loss:  0.1377343237400055
Epoch:  19  	Training Loss: 0.1631896197795868
Test Loss:  0.11414561420679092
Valid Loss:  0.13269205391407013
Epoch:  20  	Training Loss: 0.15723979473114014
Test Loss:  0.10987761616706848
Valid Loss:  0.12782041728496552
Epoch:  21  	Training Loss: 0.1514865905046463
Test Loss:  0.10575931519269943
Valid Loss:  0.12312769889831543
Epoch:  22  	Training Loss: 0.14594820141792297
Test Loss:  0.07270347326993942
Valid Loss:  0.08656606078147888
Epoch:  23  	Training Loss: 0.094362273812294
Test Loss:  0.043367162346839905
Valid Loss:  0.05392831191420555
Epoch:  24  	Training Loss: 0.06387107074260712
Test Loss:  0.03605855256319046
Valid Loss:  0.04391859471797943
Epoch:  25  	Training Loss: 0.04854569584131241
Test Loss:  0.024490009993314743
Valid Loss:  0.031008359044790268
Epoch:  26  	Training Loss: 0.036473650485277176
Test Loss:  0.02049669250845909
Valid Loss:  0.025576060637831688
Epoch:  27  	Training Loss: 0.02823730558156967
Test Loss:  0.014752140268683434
Valid Loss:  0.019306369125843048
Epoch:  28  	Training Loss: 0.022298812866210938
Test Loss:  0.01291587483137846
Valid Loss:  0.016579031944274902
Epoch:  29  	Training Loss: 0.017933975905179977
Test Loss:  0.009631314314901829
Valid Loss:  0.012929627671837807
Epoch:  30  	Training Loss: 0.014607123099267483
Test Loss:  0.008617512881755829
Valid Loss:  0.011274266988039017
Epoch:  31  	Training Loss: 0.011990230530500412
Test Loss:  0.006554435472935438
Valid Loss:  0.008991814218461514
Epoch:  32  	Training Loss: 0.009923247620463371
Test Loss:  0.004318349063396454
Valid Loss:  0.006134742870926857
Epoch:  33  	Training Loss: 0.006898505613207817
Test Loss:  0.0035513374023139477
Valid Loss:  0.005191285163164139
Epoch:  34  	Training Loss: 0.0055652791634202
Test Loss:  0.0028353556990623474
Valid Loss:  0.0043221828527748585
Epoch:  35  	Training Loss: 0.004727383144199848
Test Loss:  0.002434261841699481
Valid Loss:  0.00382681330665946
Epoch:  36  	Training Loss: 0.004140062257647514
Test Loss:  0.002094774739816785
Valid Loss:  0.003390835365280509
Epoch:  37  	Training Loss: 0.0036765143740922213
Test Loss:  0.0018341722898185253
Valid Loss:  0.0030452078208327293
Epoch:  38  	Training Loss: 0.003296913579106331
Test Loss:  0.0016286311438307166
Valid Loss:  0.002774561755359173
Epoch:  39  	Training Loss: 0.0029903880786150694
Test Loss:  0.0014517101226374507
Valid Loss:  0.0025364384055137634
Epoch:  40  	Training Loss: 0.0027276964392513037
Test Loss:  0.0013080546632409096
Valid Loss:  0.002336641540750861
Epoch:  41  	Training Loss: 0.0025024833157658577
Test Loss:  0.0011879296507686377
Valid Loss:  0.002163985278457403
Epoch:  42  	Training Loss: 0.0023062978871166706
Test Loss:  0.0012197912437841296
Valid Loss:  0.001954243052750826
Epoch:  43  	Training Loss: 0.001839668140746653
Test Loss:  0.0008172887610271573
Valid Loss:  0.001490295398980379
Epoch:  44  	Training Loss: 0.0015507584903389215
Test Loss:  0.0011961976997554302
Valid Loss:  0.0016707433387637138
Epoch:  45  	Training Loss: 0.0014209980145096779
Test Loss:  0.0006966582732275128
Valid Loss:  0.0012452551163733006
Epoch:  46  	Training Loss: 0.001356589957140386
Test Loss:  0.0014486537547782063
Valid Loss:  0.0017593923257663846
Epoch:  47  	Training Loss: 0.0013904598308727145
Test Loss:  0.0008398164063692093
Valid Loss:  0.001327557722106576
Epoch:  48  	Training Loss: 0.0015310156159102917
Test Loss:  0.0022761509753763676
Valid Loss:  0.0024285975378006697
Epoch:  49  	Training Loss: 0.0018809717148542404
Test Loss:  0.0015674950554966927
Valid Loss:  0.0020398132037371397
Epoch:  50  	Training Loss: 0.0024266503751277924
Test Loss:  0.004396616946905851
Valid Loss:  0.0043238690122962
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.003480471670627594
Test Loss:  0.0005784646491520107
Valid Loss:  0.0011221367167308927
Epoch:  52  	Training Loss: 0.0012781406985595822
Test Loss:  0.0005319121992215514
Valid Loss:  0.0010241635609418154
Epoch:  53  	Training Loss: 0.0010987806599587202
Test Loss:  0.0005382202798500657
Valid Loss:  0.0010110825533047318
Epoch:  54  	Training Loss: 0.001052860519848764
Test Loss:  0.0005477419472299516
Valid Loss:  0.0010047507239505649
Epoch:  55  	Training Loss: 0.0010236846283078194
Test Loss:  0.0005571296205744147
Valid Loss:  0.0010005226358771324
Epoch:  56  	Training Loss: 0.0010040577035397291
Test Loss:  0.0005673998966813087
Valid Loss:  0.0009998332243412733
Epoch:  57  	Training Loss: 0.0009917332790791988
Test Loss:  0.0005764610250480473
Valid Loss:  0.0010001634946092963
Epoch:  58  	Training Loss: 0.0009828817564994097
Test Loss:  0.0005837982753291726
Valid Loss:  0.0010004036594182253
Epoch:  59  	Training Loss: 0.0009757533553056419
Test Loss:  0.0005885225837118924
Valid Loss:  0.0009990062098950148
Epoch:  60  	Training Loss: 0.0009696655906736851
Test Loss:  0.0005915714427828789
Valid Loss:  0.0009966217912733555
Epoch:  61  	Training Loss: 0.0009641777724027634
Test Loss:  0.0005930711049586535
Valid Loss:  0.0009932249085977674
Epoch:  62  	Training Loss: 0.0009589605615474284
Test Loss:  0.0006198268965817988
Valid Loss:  0.0009893279056996107
Epoch:  63  	Training Loss: 0.0009241201914846897
Test Loss:  0.0006109501700848341
Valid Loss:  0.0009646702092140913
Epoch:  64  	Training Loss: 0.0008982602739706635
Test Loss:  0.000599241117015481
Valid Loss:  0.0009395768865942955
Epoch:  65  	Training Loss: 0.0008747041574679315
Test Loss:  0.000587700866162777
Valid Loss:  0.000916000921279192
Epoch:  66  	Training Loss: 0.0008529021288268268
Test Loss:  0.0005759394261986017
Valid Loss:  0.0008933958015404642
Epoch:  67  	Training Loss: 0.0008323960355482996
Test Loss:  0.0005647388170473278
Valid Loss:  0.0008721245103515685
Epoch:  68  	Training Loss: 0.0008129919297061861
Test Loss:  0.0005541162099689245
Valid Loss:  0.000852098863106221
Epoch:  69  	Training Loss: 0.0007946060504764318
Test Loss:  0.0005435954662971199
Valid Loss:  0.0008328037802129984
Epoch:  70  	Training Loss: 0.0007770447991788387
Test Loss:  0.0005335673922672868
Valid Loss:   14%|█▍        | 71/500 [01:01<08:39,  1.21s/it] 15%|█▍        | 73/500 [01:01<06:11,  1.15it/s] 15%|█▌        | 75/500 [01:01<04:27,  1.59it/s] 15%|█▌        | 77/500 [01:01<03:14,  2.17it/s] 16%|█▌        | 79/500 [01:01<02:23,  2.93it/s] 16%|█▌        | 81/500 [01:08<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:08<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:08<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:08<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:08<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:14<08:00,  1.17s/it] 19%|█▊        | 93/500 [01:14<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:15<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:15<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:15<02:13,  2.99it/s] 20%|██        | 101/500 [01:21<07:55,  1.19s/it] 21%|██        | 103/500 [01:21<05:39,  1.17it/s] 21%|██        | 105/500 [01:22<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:22<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:22<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:28<07:33,  1.17s/it] 23%|██▎       | 113/500 [01:28<05:24,  1.19it/s] 23%|██▎       | 115/500 [01:28<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:28<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:29<02:05,  3.02it/s] 24%|██▍       | 121/500 [01:35<07:41,  1.22s/it] 25%|██▍       | 123/500 [01:35<05:29,  1.14it/s] 25%|██▌       | 125/500 [01:35<03:57,  1.58it/s] 25%|██▌       | 127/500 [01:36<02:52,  2.16it/s] 26%|██▌       | 129/500 [01:36<02:07,  2.90it/s] 26%|██▌       | 131/500 [01:42<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:42<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:42<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:42<02:42,  2.23it/s]0.0008145121391862631
Epoch:  71  	Training Loss: 0.000760353694204241
Test Loss:  0.0005239730235189199
Valid Loss:  0.0007970889564603567
Epoch:  72  	Training Loss: 0.0007442747009918094
Test Loss:  0.0005289771361276507
Valid Loss:  0.0007989073637872934
Epoch:  73  	Training Loss: 0.0007425216608680785
Test Loss:  0.0005322775105014443
Valid Loss:  0.000799866858869791
Epoch:  74  	Training Loss: 0.0007412094273604453
Test Loss:  0.0005344263045117259
Valid Loss:  0.0008002527756616473
Epoch:  75  	Training Loss: 0.0007400838658213615
Test Loss:  0.0005357412155717611
Valid Loss:  0.0008001337992027402
Epoch:  76  	Training Loss: 0.0007390611572191119
Test Loss:  0.0005365831311792135
Valid Loss:  0.0007997304783202708
Epoch:  77  	Training Loss: 0.0007381312316283584
Test Loss:  0.0005372733576223254
Valid Loss:  0.0007991553284227848
Epoch:  78  	Training Loss: 0.0007372882682830095
Test Loss:  0.0005377338966354728
Valid Loss:  0.0007984804688021541
Epoch:  79  	Training Loss: 0.0007364989724010229
Test Loss:  0.0005380103830248117
Valid Loss:  0.0007977730128914118
Epoch:  80  	Training Loss: 0.00073573540430516
Test Loss:  0.0005382878007367253
Valid Loss:  0.000797088781837374
Epoch:  81  	Training Loss: 0.0007350239902734756
Test Loss:  0.0005384897813200951
Valid Loss:  0.000796492793597281
Epoch:  82  	Training Loss: 0.0007343259057961404
Test Loss:  0.0005297953030094504
Valid Loss:  0.0007894588052295148
Epoch:  83  	Training Loss: 0.0007321193115785718
Test Loss:  0.0005258582532405853
Valid Loss:  0.0007855641888454556
Epoch:  84  	Training Loss: 0.0007302953163161874
Test Loss:  0.0005238065496087074
Valid Loss:  0.0007829274982213974
Epoch:  85  	Training Loss: 0.0007285660831257701
Test Loss:  0.0005225527565926313
Valid Loss:  0.0007808475056663156
Epoch:  86  	Training Loss: 0.0007268834160640836
Test Loss:  0.0005217025754973292
Valid Loss:  0.0007790942909196019
Epoch:  87  	Training Loss: 0.0007252233917824924
Test Loss:  0.0005209973314777017
Valid Loss:  0.000777500681579113
Epoch:  88  	Training Loss: 0.000723611912690103
Test Loss:  0.000520239002071321
Valid Loss:  0.0007758941501379013
Epoch:  89  	Training Loss: 0.0007219872204586864
Test Loss:  0.0005194857367314398
Valid Loss:  0.0007743136957287788
Epoch:  90  	Training Loss: 0.0007203749264590442
Test Loss:  0.0005187983624637127
Valid Loss:  0.000772795348893851
Epoch:  91  	Training Loss: 0.0007187835872173309
Test Loss:  0.0005180127918720245
Valid Loss:  0.0007712859660387039
Epoch:  92  	Training Loss: 0.0007172247860580683
Test Loss:  0.0005138152046129107
Valid Loss:  0.0007605848368257284
Epoch:  93  	Training Loss: 0.0007057502516545355
Test Loss:  0.0005058081587776542
Valid Loss:  0.0007480696076527238
Epoch:  94  	Training Loss: 0.0006947589572519064
Test Loss:  0.0004969281144440174
Valid Loss:  0.0007354558329097927
Epoch:  95  	Training Loss: 0.0006841993890702724
Test Loss:  0.0004885844537056983
Valid Loss:  0.0007235633675009012
Epoch:  96  	Training Loss: 0.0006740824319422245
Test Loss:  0.00048030485049821436
Valid Loss:  0.0007120658410713077
Epoch:  97  	Training Loss: 0.0006644652457907796
Test Loss:  0.00047309562796726823
Valid Loss:  0.0007013600552454591
Epoch:  98  	Training Loss: 0.000655020703561604
Test Loss:  0.000465192599222064
Valid Loss:  0.0006904565962031484
Epoch:  99  	Training Loss: 0.0006458526477217674
Test Loss:  0.0004586514551192522
Valid Loss:  0.0006806540186516941
Epoch:  100  	Training Loss: 0.0006369252223521471
Test Loss:  0.0004507778794504702
Valid Loss:  0.0006701654056087136
Epoch:  101  	Training Loss: 0.0006282191025093198
Test Loss:  0.0004445078084245324
Valid Loss:  0.0006606658571399748
Epoch:  102  	Training Loss: 0.0006196634494699538
Test Loss:  0.000440307951066643
Valid Loss:  0.0006511175306513906
Epoch:  103  	Training Loss: 0.0006112373084761202
Test Loss:  0.00043761407141573727
Valid Loss:  0.0006436726544052362
Epoch:  104  	Training Loss: 0.0006049498915672302
Test Loss:  0.0004354426055215299
Valid Loss:  0.0006372958887368441
Epoch:  105  	Training Loss: 0.0005995263927616179
Test Loss:  0.00043316392111591995
Valid Loss:  0.0006314106285572052
Epoch:  106  	Training Loss: 0.0005945940501987934
Test Loss:  0.0004307423369027674
Valid Loss:  0.0006259609945118427
Epoch:  107  	Training Loss: 0.000589956296607852
Test Loss:  0.0004281144356355071
Valid Loss:  0.0006206657271832228
Epoch:  108  	Training Loss: 0.0005854475311934948
Test Loss:  0.00042522780131548643
Valid Loss:  0.0006152440328150988
Epoch:  109  	Training Loss: 0.0005809330032207072
Test Loss:  0.0004223241121508181
Valid Loss:  0.0006099323509261012
Epoch:  110  	Training Loss: 0.0005763768567703664
Test Loss:  0.00041931821033358574
Valid Loss:  0.00060465675778687
Epoch:  111  	Training Loss: 0.0005718247266486287
Test Loss:  0.00041638320544734597
Valid Loss:  0.0005994992097839713
Epoch:  112  	Training Loss: 0.0005673591513186693
Test Loss:  0.00041243014857172966
Valid Loss:  0.000593070057220757
Epoch:  113  	Training Loss: 0.0005614656256511807
Test Loss:  0.00040813267696648836
Valid Loss:  0.0005864909617230296
Epoch:  114  	Training Loss: 0.0005556343821808696
Test Loss:  0.00040378241101279855
Valid Loss:  0.0005801110528409481
Epoch:  115  	Training Loss: 0.0005499530816450715
Test Loss:  0.00039954352541826665
Valid Loss:  0.0005738784093409777
Epoch:  116  	Training Loss: 0.0005444214912131429
Test Loss:  0.0003952769038733095
Valid Loss:  0.0005677846493199468
Epoch:  117  	Training Loss: 0.0005390301812440157
Test Loss:  0.0003910262603312731
Valid Loss:  0.0005618324503302574
Epoch:  118  	Training Loss: 0.0005336948670446873
Test Loss:  0.00038640378625132143
Valid Loss:  0.0005556312971748412
Epoch:  119  	Training Loss: 0.0005281957564875484
Test Loss:  0.0003819949633907527
Valid Loss:  0.0005496764788404107
Epoch:  120  	Training Loss: 0.0005228387308306992
Test Loss:  0.00037760750274173915
Valid Loss:  0.0005438628140836954
Epoch:  121  	Training Loss: 0.0005175958503969014
Test Loss:  0.00037292929482646286
Valid Loss:  0.0005378578207455575
Epoch:  122  	Training Loss: 0.0005121078575029969
Test Loss:  0.0003733570338226855
Valid Loss:  0.0005351161817088723
Epoch:  123  	Training Loss: 0.0005080319242551923
Test Loss:  0.00037095381412655115
Valid Loss:  0.0005308486288413405
Epoch:  124  	Training Loss: 0.0005040137912146747
Test Loss:  0.0003681917442008853
Valid Loss:  0.0005263941129669547
Epoch:  125  	Training Loss: 0.0004999066004529595
Test Loss:  0.0003654342144727707
Valid Loss:  0.0005220225430093706
Epoch:  126  	Training Loss: 0.0004958858480677009
Test Loss:  0.0003626965335570276
Valid Loss:  0.0005177377024665475
Epoch:  127  	Training Loss: 0.0004919416969642043
Test Loss:  0.00035993545316159725
Valid Loss:  0.0005134833045303822
Epoch:  128  	Training Loss: 0.0004879954212810844
Test Loss:  0.000357144046574831
Valid Loss:  0.0005092564970254898
Epoch:  129  	Training Loss: 0.0004840556939598173
Test Loss:  0.0003543412312865257
Valid Loss:  0.0005050605977885425
Epoch:  130  	Training Loss: 0.00048013185732997954
Test Loss:  0.0003515736316330731
Valid Loss:  0.0005009391461499035
Epoch:  131  	Training Loss: 0.00047626555897295475
Test Loss:  0.0003487952926661819
Valid Loss:  0.0004968432476744056
Epoch:  132  	Training Loss: 0.0004724028694909066
Test Loss:  0.0003271983878221363
Valid Loss:  0.0004813664418179542
Epoch:  133  	Training Loss: 0.0004633005301002413
Test Loss:  0.00031123554799705744
Valid Loss:  0.00046988518442958593
Epoch:  134  	Training Loss: 0.0004563912807498127
Test Loss:  0.00029902756796218455
Valid Loss:  0.0004609635507222265
Epoch:  135  	Training Loss: 0.0004508035199251026
Test Loss:  0.0002894419594667852
Valid Loss:  0.00045386055717244744
Epoch:  136  	Training Loss: 0.0004460342461243272
Test Loss:  0.0002816571795847267
Valid Loss:  0.00044792506378144026
Epoch:  137  	Training Loss: 0.00044177984818816185
Test Loss:  0.00027519260765984654
Valid Loss:  0.0004427791864145547
Epoch:  138  	Training Loss: 0.0004378835728857666
Test Loss:  0.0002696825540624559
Valid Loss:  0.000438287272118032
 28%|██▊       | 139/500 [01:42<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:49<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:49<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:49<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:49<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:49<01:58,  2.97it/s] 30%|███       | 151/500 [01:56<06:50,  1.18s/it] 31%|███       | 153/500 [01:56<04:53,  1.18it/s] 31%|███       | 155/500 [01:56<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:56<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:56<01:53,  3.01it/s] 32%|███▏      | 161/500 [02:03<06:49,  1.21s/it] 33%|███▎      | 163/500 [02:03<04:52,  1.15it/s] 33%|███▎      | 165/500 [02:03<03:31,  1.58it/s] 33%|███▎      | 167/500 [02:03<02:35,  2.14it/s] 34%|███▍      | 169/500 [02:03<01:56,  2.83it/s] 34%|███▍      | 171/500 [02:10<06:45,  1.23s/it] 35%|███▍      | 173/500 [02:10<04:49,  1.13it/s] 35%|███▌      | 175/500 [02:10<03:27,  1.57it/s] 35%|███▌      | 177/500 [02:10<02:30,  2.14it/s] 36%|███▌      | 179/500 [02:10<01:51,  2.89it/s] 36%|███▌      | 181/500 [02:17<06:22,  1.20s/it] 37%|███▋      | 183/500 [02:17<04:32,  1.16it/s] 37%|███▋      | 185/500 [02:17<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:17<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:17<01:46,  2.92it/s] 38%|███▊      | 191/500 [02:24<06:10,  1.20s/it] 39%|███▊      | 193/500 [02:24<04:24,  1.16it/s] 39%|███▉      | 195/500 [02:24<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:24<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:24<01:41,  2.96it/s] 40%|████      | 201/500 [02:31<05:52,  1.18s/it] 41%|████      | 203/500 [02:31<04:11,  1.18it/s] 41%|████      | 205/500 [02:31<03:00,  1.64it/s]Epoch:  139  	Training Loss: 0.0004342349711805582
Test Loss:  0.000264934467850253
Valid Loss:  0.00043419504072517157
Epoch:  140  	Training Loss: 0.0004308095667511225
Test Loss:  0.0002607810019981116
Valid Loss:  0.0004304363392293453
Epoch:  141  	Training Loss: 0.0004275554674677551
Test Loss:  0.0002570499200373888
Valid Loss:  0.00042690985719673336
Epoch:  142  	Training Loss: 0.00042442535050213337
Test Loss:  0.0002725999220274389
Valid Loss:  0.000422479584813118
Epoch:  143  	Training Loss: 0.00040750944754108787
Test Loss:  0.0002621507446747273
Valid Loss:  0.0004080899234395474
Epoch:  144  	Training Loss: 0.0003934809355996549
Test Loss:  0.00025877487496472895
Valid Loss:  0.0003982138296123594
Epoch:  145  	Training Loss: 0.00038117411895655096
Test Loss:  0.00025414087576791644
Valid Loss:  0.00038848863914608955
Epoch:  146  	Training Loss: 0.0003703076799865812
Test Loss:  0.0002505173033569008
Valid Loss:  0.0003798874095082283
Epoch:  147  	Training Loss: 0.00036063254810869694
Test Loss:  0.00024703648523427546
Valid Loss:  0.00037287408486008644
Epoch:  148  	Training Loss: 0.00035188859328627586
Test Loss:  0.00024376643705181777
Valid Loss:  0.00036687913234345615
Epoch:  149  	Training Loss: 0.00034396356204524636
Test Loss:  0.00024071038933470845
Valid Loss:  0.0003614682354964316
Epoch:  150  	Training Loss: 0.000336710421834141
Test Loss:  0.00023738887102808803
Valid Loss:  0.0003561208432074636
Epoch:  151  	Training Loss: 0.000329810893163085
Test Loss:  0.000234714534599334
Valid Loss:  0.0003512816329021007
Epoch:  152  	Training Loss: 0.0003234173054806888
Test Loss:  0.000232897320529446
Valid Loss:  0.0003449245705269277
Epoch:  153  	Training Loss: 0.0003157373866997659
Test Loss:  0.00023131877242121845
Valid Loss:  0.00033949920907616615
Epoch:  154  	Training Loss: 0.0003099394671153277
Test Loss:  0.0002287138340761885
Valid Loss:  0.0003343725693412125
Epoch:  155  	Training Loss: 0.0003052409738302231
Test Loss:  0.0002255425206385553
Valid Loss:  0.00032961188117042184
Epoch:  156  	Training Loss: 0.00030114347464405
Test Loss:  0.000222672606469132
Valid Loss:  0.00032541967811994255
Epoch:  157  	Training Loss: 0.00029734038980677724
Test Loss:  0.00021990391542203724
Valid Loss:  0.0003214001771993935
Epoch:  158  	Training Loss: 0.00029385415837168694
Test Loss:  0.00021684871171601117
Valid Loss:  0.0003175460151396692
Epoch:  159  	Training Loss: 0.0002906677545979619
Test Loss:  0.00021391670452430844
Valid Loss:  0.0003138890315312892
Epoch:  160  	Training Loss: 0.00028764083981513977
Test Loss:  0.00021113005641382188
Valid Loss:  0.0003104408679064363
Epoch:  161  	Training Loss: 0.0002848009462468326
Test Loss:  0.0002082431165035814
Valid Loss:  0.00030718272319063544
Epoch:  162  	Training Loss: 0.000282073684502393
Test Loss:  0.00020399480126798153
Valid Loss:  0.0003026958438567817
Epoch:  163  	Training Loss: 0.00027740088989958167
Test Loss:  0.00020164356101304293
Valid Loss:  0.00029930443270131946
Epoch:  164  	Training Loss: 0.0002730789128690958
Test Loss:  0.00019978506315965205
Valid Loss:  0.00029622126021422446
Epoch:  165  	Training Loss: 0.0002690456167329103
Test Loss:  0.0001985819253604859
Valid Loss:  0.00029353570425882936
Epoch:  166  	Training Loss: 0.00026532381889410317
Test Loss:  0.00019668771710712463
Valid Loss:  0.00029073236510157585
Epoch:  167  	Training Loss: 0.00026177577092312276
Test Loss:  0.00019526999676600099
Valid Loss:  0.0002881661057472229
Epoch:  168  	Training Loss: 0.000258374959230423
Test Loss:  0.00019454790162853897
Valid Loss:  0.00028589722933247685
Epoch:  169  	Training Loss: 0.0002552977530285716
Test Loss:  0.00019336113473400474
Valid Loss:  0.00028344697784632444
Epoch:  170  	Training Loss: 0.0002523860312066972
Test Loss:  0.0001927081757457927
Valid Loss:  0.0002813480095937848
Epoch:  171  	Training Loss: 0.0002497411333024502
Test Loss:  0.00019194040214642882
Valid Loss:  0.0002792323939502239
Epoch:  172  	Training Loss: 0.0002471859916113317
Test Loss:  0.00019904421060346067
Valid Loss:  0.0002769656712189317
Epoch:  173  	Training Loss: 0.00024064461467787623
Test Loss:  0.00019793954561464489
Valid Loss:  0.00027149030938744545
Epoch:  174  	Training Loss: 0.00023471898748539388
Test Loss:  0.00019582183449529111
Valid Loss:  0.0002659122401382774
Epoch:  175  	Training Loss: 0.0002288761461386457
Test Loss:  0.00019260446424596012
Valid Loss:  0.000259525200817734
Epoch:  176  	Training Loss: 0.0002227927907370031
Test Loss:  0.00018817436648532748
Valid Loss:  0.0002525098971091211
Epoch:  177  	Training Loss: 0.00021565755014307797
Test Loss:  0.0001829141256166622
Valid Loss:  0.00024407288583461195
Epoch:  178  	Training Loss: 0.00020792293071281165
Test Loss:  0.000177476424141787
Valid Loss:  0.00023562998103443533
Epoch:  179  	Training Loss: 0.00020032012253068388
Test Loss:  0.00017182181181851774
Valid Loss:  0.00022738547704648226
Epoch:  180  	Training Loss: 0.00019274854275863618
Test Loss:  0.00016616804350633174
Valid Loss:  0.00021950805967207998
Epoch:  181  	Training Loss: 0.0001854674774222076
Test Loss:  0.00016030123515520245
Valid Loss:  0.0002119162236340344
Epoch:  182  	Training Loss: 0.0001784111955203116
Test Loss:  0.00014883343828842044
Valid Loss:  0.0001998321822611615
Epoch:  183  	Training Loss: 0.0001681283174548298
Test Loss:  0.0001396244770148769
Valid Loss:  0.0001893298904178664
Epoch:  184  	Training Loss: 0.0001587400329299271
Test Loss:  0.0001315701229032129
Valid Loss:  0.00017988721083384007
Epoch:  185  	Training Loss: 0.00015018213889561594
Test Loss:  0.0001242510916199535
Valid Loss:  0.00017130297783296555
Epoch:  186  	Training Loss: 0.0001424257643520832
Test Loss:  0.00011751211422961205
Valid Loss:  0.00016349476936738938
Epoch:  187  	Training Loss: 0.0001353793777525425
Test Loss:  0.00011131211067549884
Valid Loss:  0.0001563495461596176
Epoch:  188  	Training Loss: 0.0001289608480874449
Test Loss:  0.00010564905824139714
Valid Loss:  0.00014988188922870904
Epoch:  189  	Training Loss: 0.00012314703781157732
Test Loss:  0.0001004720397759229
Valid Loss:  0.00014398018538486212
Epoch:  190  	Training Loss: 0.0001178631282527931
Test Loss:  9.577778109814972e-05
Valid Loss:  0.0001385762880090624
Epoch:  191  	Training Loss: 0.00011301663471385837
Test Loss:  9.157806198345497e-05
Valid Loss:  0.00013358770229388028
Epoch:  192  	Training Loss: 0.00010854626452783123
Test Loss:  9.14425982045941e-05
Valid Loss:  0.00012984794739168137
Epoch:  193  	Training Loss: 0.00010445740190334618
Test Loss:  8.860193338477984e-05
Valid Loss:  0.00012588556273840368
Epoch:  194  	Training Loss: 0.00010098920029122382
Test Loss:  8.544575393898413e-05
Valid Loss:  0.00012200284982100129
Epoch:  195  	Training Loss: 9.774246427696198e-05
Test Loss:  8.233525295509025e-05
Valid Loss:  0.00011836870544357225
Epoch:  196  	Training Loss: 9.470515215070918e-05
Test Loss:  7.936150359455496e-05
Valid Loss:  0.00011494891077745706
Epoch:  197  	Training Loss: 9.18510922929272e-05
Test Loss:  7.647456368431449e-05
Valid Loss:  0.00011174962855875492
Epoch:  198  	Training Loss: 8.924977737478912e-05
Test Loss:  7.373420521616936e-05
Valid Loss:  0.00010876392479985952
Epoch:  199  	Training Loss: 8.684818749316037e-05
Test Loss:  7.116624328773469e-05
Valid Loss:  0.00010595271305646747
Epoch:  200  	Training Loss: 8.462902042083442e-05
Test Loss:  6.874969403725117e-05
Valid Loss:  0.00010328761709388345
Epoch:  201  	Training Loss: 8.256486034952104e-05
Test Loss:  6.647709233220667e-05
Valid Loss:  0.00010079237108584493
Epoch:  202  	Training Loss: 8.061004336923361e-05
Test Loss:  5.929850885877386e-05
Valid Loss:  9.764995775185525e-05
Epoch:  203  	Training Loss: 7.84730218583718e-05
Test Loss:  5.8509220252744853e-05
Valid Loss:  9.627333201933652e-05
Epoch:  204  	Training Loss: 7.706387259531766e-05
Test Loss:  5.7233522966271266e-05
Valid Loss:  9.497917199041694e-05
Epoch:  205  	Training Loss: 7.586889842059463e-05
Test Loss:  5.66614544368349e-05
Valid Loss:  9.39624005695805e-05
Epoch:  206  	Training Loss: 7.481875945813954e-05
Test Loss:   41%|████▏     | 207/500 [02:31<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:31<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:37<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:38<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:38<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:38<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:38<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:44<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:44<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:44<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:45<02:03,  2.20it/s] 46%|████▌     | 229/500 [02:45<01:33,  2.91it/s] 46%|████▌     | 231/500 [02:51<05:24,  1.21s/it] 47%|████▋     | 233/500 [02:51<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:52<02:48,  1.57it/s] 47%|████▋     | 237/500 [02:52<02:03,  2.12it/s] 48%|████▊     | 239/500 [02:52<01:31,  2.87it/s] 48%|████▊     | 241/500 [02:58<05:16,  1.22s/it] 49%|████▊     | 243/500 [02:59<03:45,  1.14it/s] 49%|████▉     | 245/500 [02:59<02:41,  1.58it/s] 49%|████▉     | 247/500 [02:59<01:57,  2.16it/s] 50%|████▉     | 249/500 [02:59<01:26,  2.91it/s] 50%|█████     | 251/500 [03:05<04:50,  1.17s/it] 51%|█████     | 253/500 [03:05<03:27,  1.19it/s] 51%|█████     | 255/500 [03:05<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:06<01:48,  2.25it/s] 52%|█████▏    | 259/500 [03:06<01:19,  3.01it/s] 52%|█████▏    | 261/500 [03:12<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:12<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:12<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:12<01:44,  2.22it/s] 54%|█████▍    | 269/500 [03:13<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:19<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:19<03:11,  1.18it/s]5.5955981224542484e-05
Valid Loss:  9.301102545578033e-05
Epoch:  207  	Training Loss: 7.385881326626986e-05
Test Loss:  5.570398207055405e-05
Valid Loss:  9.227817645296454e-05
Epoch:  208  	Training Loss: 7.30392785044387e-05
Test Loss:  5.514412259799428e-05
Valid Loss:  9.14871197892353e-05
Epoch:  209  	Training Loss: 7.226642628666013e-05
Test Loss:  5.4862743127159774e-05
Valid Loss:  9.085692727239802e-05
Epoch:  210  	Training Loss: 7.153356273192912e-05
Test Loss:  5.438705193228088e-05
Valid Loss:  9.015067189466208e-05
Epoch:  211  	Training Loss: 7.083437230903655e-05
Test Loss:  5.4192722018342465e-05
Valid Loss:  8.958626131061465e-05
Epoch:  212  	Training Loss: 7.016527524683625e-05
Test Loss:  5.2053368563065305e-05
Valid Loss:  8.666711073601618e-05
Epoch:  213  	Training Loss: 6.779695104341954e-05
Test Loss:  5.000308738090098e-05
Valid Loss:  8.41007858980447e-05
Epoch:  214  	Training Loss: 6.57248601783067e-05
Test Loss:  4.80589151266031e-05
Valid Loss:  8.173799142241478e-05
Epoch:  215  	Training Loss: 6.383081927197054e-05
Test Loss:  4.6280023525469005e-05
Valid Loss:  7.960475340951234e-05
Epoch:  216  	Training Loss: 6.209546700119972e-05
Test Loss:  4.457516479305923e-05
Valid Loss:  7.763301255181432e-05
Epoch:  217  	Training Loss: 6.0491845943033695e-05
Test Loss:  4.300966247683391e-05
Valid Loss:  7.580929377581924e-05
Epoch:  218  	Training Loss: 5.901914119021967e-05
Test Loss:  4.155105125391856e-05
Valid Loss:  7.411198021145537e-05
Epoch:  219  	Training Loss: 5.7671913964441046e-05
Test Loss:  4.016652383143082e-05
Valid Loss:  7.253774674609303e-05
Epoch:  220  	Training Loss: 5.642908581648953e-05
Test Loss:  3.884236502926797e-05
Valid Loss:  7.104720862116665e-05
Epoch:  221  	Training Loss: 5.525298183783889e-05
Test Loss:  3.759087485377677e-05
Valid Loss:  6.96358474669978e-05
Epoch:  222  	Training Loss: 5.414422048488632e-05
Test Loss:  3.593784640543163e-05
Valid Loss:  6.836750981165096e-05
Epoch:  223  	Training Loss: 5.315740781952627e-05
Test Loss:  3.4709079045569524e-05
Valid Loss:  6.727696745656431e-05
Epoch:  224  	Training Loss: 5.231987597653642e-05
Test Loss:  3.37342826242093e-05
Valid Loss:  6.631728319916874e-05
Epoch:  225  	Training Loss: 5.1594077376648784e-05
Test Loss:  3.292215114925057e-05
Valid Loss:  6.54631876386702e-05
Epoch:  226  	Training Loss: 5.095422238809988e-05
Test Loss:  3.220953294658102e-05
Valid Loss:  6.468924402724952e-05
Epoch:  227  	Training Loss: 5.037666778662242e-05
Test Loss:  3.1559608032694086e-05
Valid Loss:  6.397889228537679e-05
Epoch:  228  	Training Loss: 4.984742554370314e-05
Test Loss:  3.099094465142116e-05
Valid Loss:  6.333219789667055e-05
Epoch:  229  	Training Loss: 4.9371250497642905e-05
Test Loss:  3.048389589821454e-05
Valid Loss:  6.274106272030622e-05
Epoch:  230  	Training Loss: 4.893812001682818e-05
Test Loss:  3.001462755491957e-05
Valid Loss:  6.219287752173841e-05
Epoch:  231  	Training Loss: 4.853333666687831e-05
Test Loss:  2.95783447654685e-05
Valid Loss:  6.167998071759939e-05
Epoch:  232  	Training Loss: 4.8152520321309566e-05
Test Loss:  3.12418160319794e-05
Valid Loss:  6.122647027950734e-05
Epoch:  233  	Training Loss: 4.7719397116452456e-05
Test Loss:  2.983269587275572e-05
Valid Loss:  6.0695969295920804e-05
Epoch:  234  	Training Loss: 4.733447713078931e-05
Test Loss:  2.996795046783518e-05
Valid Loss:  6.025355833116919e-05
Epoch:  235  	Training Loss: 4.69695296487771e-05
Test Loss:  2.9368971809162758e-05
Valid Loss:  5.980009154882282e-05
Epoch:  236  	Training Loss: 4.661808998207562e-05
Test Loss:  2.9154687581467442e-05
Valid Loss:  5.937752575846389e-05
Epoch:  237  	Training Loss: 4.6277560613816604e-05
Test Loss:  2.8771066354238428e-05
Valid Loss:  5.896330549148843e-05
Epoch:  238  	Training Loss: 4.594691199599765e-05
Test Loss:  2.84857778751757e-05
Valid Loss:  5.8566460211295635e-05
Epoch:  239  	Training Loss: 4.562571120914072e-05
Test Loss:  2.816609776346013e-05
Valid Loss:  5.8180630730930716e-05
Epoch:  240  	Training Loss: 4.531371087068692e-05
Test Loss:  2.787444282148499e-05
Valid Loss:  5.7808512792689726e-05
Epoch:  241  	Training Loss: 4.50098050350789e-05
Test Loss:  2.758365371846594e-05
Valid Loss:  5.7447665312793106e-05
Epoch:  242  	Training Loss: 4.471331340027973e-05
Test Loss:  2.6774177968036383e-05
Valid Loss:  5.700985639123246e-05
Epoch:  243  	Training Loss: 4.4391075789462775e-05
Test Loss:  2.6474175683688372e-05
Valid Loss:  5.660566966980696e-05
Epoch:  244  	Training Loss: 4.4089607399655506e-05
Test Loss:  2.615091943880543e-05
Valid Loss:  5.622027674689889e-05
Epoch:  245  	Training Loss: 4.3799824197776616e-05
Test Loss:  2.5845498385024257e-05
Valid Loss:  5.585253529716283e-05
Epoch:  246  	Training Loss: 4.352098039817065e-05
Test Loss:  2.5554538297001272e-05
Valid Loss:  5.549951674765907e-05
Epoch:  247  	Training Loss: 4.325257395976223e-05
Test Loss:  2.52743066084804e-05
Valid Loss:  5.5162057833513245e-05
Epoch:  248  	Training Loss: 4.2992895032512024e-05
Test Loss:  2.5004794224514626e-05
Valid Loss:  5.4837360949022695e-05
Epoch:  249  	Training Loss: 4.2741150537040085e-05
Test Loss:  2.474562279530801e-05
Valid Loss:  5.452421464724466e-05
Epoch:  250  	Training Loss: 4.2495812522247434e-05
Test Loss:  2.4489925635862164e-05
Valid Loss:  5.422034882940352e-05
Epoch:  251  	Training Loss: 4.2257001041434705e-05
Test Loss:  2.424934064038098e-05
Valid Loss:  5.3928921261103824e-05
Epoch:  252  	Training Loss: 4.202546551823616e-05
Test Loss:  2.4041361029958352e-05
Valid Loss:  5.387373312260024e-05
Epoch:  253  	Training Loss: 4.194661232759245e-05
Test Loss:  2.3994596631382592e-05
Valid Loss:  5.38260028406512e-05
Epoch:  254  	Training Loss: 4.187598460703157e-05
Test Loss:  2.3962864361237735e-05
Valid Loss:  5.377605702960864e-05
Epoch:  255  	Training Loss: 4.180744508630596e-05
Test Loss:  2.3939173843245953e-05
Valid Loss:  5.372763189370744e-05
Epoch:  256  	Training Loss: 4.1745093767531216e-05
Test Loss:  2.391396810708102e-05
Valid Loss:  5.367768608266488e-05
Epoch:  257  	Training Loss: 4.1684277675813064e-05
Test Loss:  2.3887459974503145e-05
Valid Loss:  5.3626012231688946e-05
Epoch:  258  	Training Loss: 4.162513141636737e-05
Test Loss:  2.3863463866291568e-05
Valid Loss:  5.3572824981529266e-05
Epoch:  259  	Training Loss: 4.156714567216113e-05
Test Loss:  2.38445518334629e-05
Valid Loss:  5.352234802558087e-05
Epoch:  260  	Training Loss: 4.151220491621643e-05
Test Loss:  2.382470847805962e-05
Valid Loss:  5.3477218898478895e-05
Epoch:  261  	Training Loss: 4.145825369050726e-05
Test Loss:  2.3803171643521637e-05
Valid Loss:  5.343368320609443e-05
Epoch:  262  	Training Loss: 4.1405663068871945e-05
Test Loss:  2.405317900411319e-05
Valid Loss:  5.337604306987487e-05
Epoch:  263  	Training Loss: 4.1362218325957656e-05
Test Loss:  2.3980896003195085e-05
Valid Loss:  5.333059743861668e-05
Epoch:  264  	Training Loss: 4.132183676119894e-05
Test Loss:  2.3941247491165996e-05
Valid Loss:  5.3285457397578284e-05
Epoch:  265  	Training Loss: 4.128213913645595e-05
Test Loss:  2.389972905803006e-05
Valid Loss:  5.32413469045423e-05
Epoch:  266  	Training Loss: 4.124258703086525e-05
Test Loss:  2.3858880012994632e-05
Valid Loss:  5.3198142268229276e-05
Epoch:  267  	Training Loss: 4.1203529690392315e-05
Test Loss:  2.381848571531009e-05
Valid Loss:  5.315611633704975e-05
Epoch:  268  	Training Loss: 4.1164690628647804e-05
Test Loss:  2.3779100956744514e-05
Valid Loss:  5.31141777173616e-05
Epoch:  269  	Training Loss: 4.112628084840253e-05
Test Loss:  2.3739965399727225e-05
Valid Loss:  5.307303217705339e-05
Epoch:  270  	Training Loss: 4.10885622841306e-05
Test Loss:  2.3701726604485884e-05
Valid Loss:  5.30326651642099e-05
Epoch:  271  	Training Loss: 4.1050821891985834e-05
Test Loss:  2.3664124455535784e-05
Valid Loss:  5.299047188600525e-05
Epoch:  272  	Training Loss: 4.101380909560248e-05
Test Loss:  2.3493135813623667e-05
Valid Loss:  5.281034827930853e-05
Epoch:  273  	Training Loss: 4.084085958311334e-05
Test Loss:  2.3349210096057504e-05
Valid Loss:  5.2630435675382614e-05
 55%|█████▌    | 275/500 [03:19<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:19<01:40,  2.23it/s] 56%|█████▌    | 279/500 [03:19<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:26<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:26<03:04,  1.17it/s] 57%|█████▋    | 285/500 [03:26<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:26<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:26<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:33<04:06,  1.18s/it] 59%|█████▊    | 293/500 [03:33<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:33<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:33<01:31,  2.23it/s] 60%|█████▉    | 299/500 [03:33<01:07,  3.00it/s] 60%|██████    | 301/500 [03:40<04:04,  1.23s/it] 61%|██████    | 303/500 [03:40<02:53,  1.14it/s] 61%|██████    | 305/500 [03:40<02:03,  1.58it/s] 61%|██████▏   | 307/500 [03:40<01:29,  2.15it/s] 62%|██████▏   | 309/500 [03:40<01:06,  2.86it/s] 62%|██████▏   | 311/500 [03:47<03:46,  1.20s/it] 63%|██████▎   | 313/500 [03:47<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:47<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:47<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:47<01:01,  2.95it/s] 64%|██████▍   | 321/500 [03:54<03:34,  1.20s/it] 65%|██████▍   | 323/500 [03:54<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:54<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:54<01:18,  2.19it/s] 66%|██████▌   | 329/500 [03:54<00:57,  2.96it/s] 66%|██████▌   | 331/500 [04:01<03:20,  1.19s/it] 67%|██████▋   | 333/500 [04:01<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:01<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:01<01:13,  2.22it/s] 68%|██████▊   | 339/500 [04:01<00:54,  2.98it/s]Epoch:  274  	Training Loss: 4.067075497005135e-05
Test Loss:  2.3206479454529472e-05
Valid Loss:  5.2451607189141214e-05
Epoch:  275  	Training Loss: 4.050330608151853e-05
Test Loss:  2.3064694687491283e-05
Valid Loss:  5.2273902838351205e-05
Epoch:  276  	Training Loss: 4.033855293528177e-05
Test Loss:  2.2922686184756458e-05
Valid Loss:  5.2097486332058907e-05
Epoch:  277  	Training Loss: 4.017619357910007e-05
Test Loss:  2.2780939616495743e-05
Valid Loss:  5.192177195567638e-05
Epoch:  278  	Training Loss: 4.001622073701583e-05
Test Loss:  2.2640724637312815e-05
Valid Loss:  5.174897160031833e-05
Epoch:  279  	Training Loss: 3.98582560592331e-05
Test Loss:  2.2500858904095367e-05
Valid Loss:  5.157630948815495e-05
Epoch:  280  	Training Loss: 3.970220132032409e-05
Test Loss:  2.236285581602715e-05
Valid Loss:  5.140536086400971e-05
Epoch:  281  	Training Loss: 3.954839485231787e-05
Test Loss:  2.2225449356483296e-05
Valid Loss:  5.12354527018033e-05
Epoch:  282  	Training Loss: 3.939627640647814e-05
Test Loss:  2.1442549041239545e-05
Valid Loss:  5.0793161790352315e-05
Epoch:  283  	Training Loss: 3.904840559698641e-05
Test Loss:  2.1125562852830626e-05
Valid Loss:  5.036563379690051e-05
Epoch:  284  	Training Loss: 3.8722057070117444e-05
Test Loss:  2.0831701476708986e-05
Valid Loss:  4.995601557311602e-05
Epoch:  285  	Training Loss: 3.840679710265249e-05
Test Loss:  2.0543800928862765e-05
Valid Loss:  4.956216798746027e-05
Epoch:  286  	Training Loss: 3.81011122954078e-05
Test Loss:  2.027252958214376e-05
Valid Loss:  4.918420017929748e-05
Epoch:  287  	Training Loss: 3.78056283807382e-05
Test Loss:  2.00130270968657e-05
Valid Loss:  4.8821253585629165e-05
Epoch:  288  	Training Loss: 3.7520178011618555e-05
Test Loss:  1.9765906472457573e-05
Valid Loss:  4.847192030865699e-05
Epoch:  289  	Training Loss: 3.724371345015243e-05
Test Loss:  1.9528199118212797e-05
Valid Loss:  4.813574196305126e-05
Epoch:  290  	Training Loss: 3.6975470720790327e-05
Test Loss:  1.930043799802661e-05
Valid Loss:  4.781235475093126e-05
Epoch:  291  	Training Loss: 3.6715398891828954e-05
Test Loss:  1.9081368009210564e-05
Valid Loss:  4.750086009153165e-05
Epoch:  292  	Training Loss: 3.646278491942212e-05
Test Loss:  1.770438757375814e-05
Valid Loss:  4.72137144242879e-05
Epoch:  293  	Training Loss: 3.599608317017555e-05
Test Loss:  1.7156398826045915e-05
Valid Loss:  4.7011661081342027e-05
Epoch:  294  	Training Loss: 3.569126783986576e-05
Test Loss:  1.6855397916515358e-05
Valid Loss:  4.681068458012305e-05
Epoch:  295  	Training Loss: 3.543314596754499e-05
Test Loss:  1.665996023803018e-05
Valid Loss:  4.660442937165499e-05
Epoch:  296  	Training Loss: 3.521288454066962e-05
Test Loss:  1.6533622329006903e-05
Valid Loss:  4.639519102056511e-05
Epoch:  297  	Training Loss: 3.5000248317373917e-05
Test Loss:  1.645489282964263e-05
Valid Loss:  4.618447201210074e-05
Epoch:  298  	Training Loss: 3.48050998582039e-05
Test Loss:  1.6367681382689625e-05
Valid Loss:  4.597914085024968e-05
Epoch:  299  	Training Loss: 3.4616012271726504e-05
Test Loss:  1.629073085496202e-05
Valid Loss:  4.57781643490307e-05
Epoch:  300  	Training Loss: 3.443395689828321e-05
Test Loss:  1.6222915292019024e-05
Valid Loss:  4.558412911137566e-05
Epoch:  301  	Training Loss: 3.4256201615789905e-05
Test Loss:  1.614617940504104e-05
Valid Loss:  4.5397289795801044e-05
Epoch:  302  	Training Loss: 3.408331758691929e-05
Test Loss:  1.834933937061578e-05
Valid Loss:  4.449888365343213e-05
Epoch:  303  	Training Loss: 3.35329859808553e-05
Test Loss:  1.7291487893089652e-05
Valid Loss:  4.429415275808424e-05
Epoch:  304  	Training Loss: 3.318099334137514e-05
Test Loss:  1.7325459339190274e-05
Valid Loss:  4.3936848669545725e-05
Epoch:  305  	Training Loss: 3.286336868768558e-05
Test Loss:  1.702741428744048e-05
Valid Loss:  4.3634543544612825e-05
Epoch:  306  	Training Loss: 3.2560506951995194e-05
Test Loss:  1.6834857888170518e-05
Valid Loss:  4.331615491537377e-05
Epoch:  307  	Training Loss: 3.2268781069433317e-05
Test Loss:  1.661254464124795e-05
Valid Loss:  4.300475484342314e-05
Epoch:  308  	Training Loss: 3.1987256079446524e-05
Test Loss:  1.6404303096351214e-05
Valid Loss:  4.2695966840256006e-05
Epoch:  309  	Training Loss: 3.1713047064840794e-05
Test Loss:  1.619180511625018e-05
Valid Loss:  4.2391598981339484e-05
Epoch:  310  	Training Loss: 3.144546280964278e-05
Test Loss:  1.5991141481208615e-05
Valid Loss:  4.209316466585733e-05
Epoch:  311  	Training Loss: 3.118583845207468e-05
Test Loss:  1.5793199054314755e-05
Valid Loss:  4.1800900362432e-05
Epoch:  312  	Training Loss: 3.093360646744259e-05
Test Loss:  1.5553159755654633e-05
Valid Loss:  4.1386476368643343e-05
Epoch:  313  	Training Loss: 3.0611437978222966e-05
Test Loss:  1.529218934592791e-05
Valid Loss:  4.1004637751029804e-05
Epoch:  314  	Training Loss: 3.031475716852583e-05
Test Loss:  1.5027089830255136e-05
Valid Loss:  4.0654347685631365e-05
Epoch:  315  	Training Loss: 3.0043971491977572e-05
Test Loss:  1.4775057934457436e-05
Valid Loss:  4.032513243146241e-05
Epoch:  316  	Training Loss: 2.9790535336360335e-05
Test Loss:  1.4538451068801805e-05
Valid Loss:  4.00154349335935e-05
Epoch:  317  	Training Loss: 2.9553568310802802e-05
Test Loss:  1.4317978639155626e-05
Valid Loss:  3.972068952862173e-05
Epoch:  318  	Training Loss: 2.933094401669223e-05
Test Loss:  1.4113809811533429e-05
Valid Loss:  3.943976480513811e-05
Epoch:  319  	Training Loss: 2.9121878469595686e-05
Test Loss:  1.3919625416747294e-05
Valid Loss:  3.9177997678052634e-05
Epoch:  320  	Training Loss: 2.8929987820447423e-05
Test Loss:  1.374214389215922e-05
Valid Loss:  3.892852691933513e-05
Epoch:  321  	Training Loss: 2.8748503609676845e-05
Test Loss:  1.357875680696452e-05
Valid Loss:  3.869002830469981e-05
Epoch:  322  	Training Loss: 2.857690014934633e-05
Test Loss:  1.3582227438746486e-05
Valid Loss:  3.853137604892254e-05
Epoch:  323  	Training Loss: 2.8508766263257712e-05
Test Loss:  1.353692732664058e-05
Valid Loss:  3.840751014649868e-05
Epoch:  324  	Training Loss: 2.8444768759072758e-05
Test Loss:  1.3475802916218527e-05
Valid Loss:  3.8300189771689475e-05
Epoch:  325  	Training Loss: 2.8383781682350673e-05
Test Loss:  1.3410738574748393e-05
Valid Loss:  3.820194615400396e-05
Epoch:  326  	Training Loss: 2.832481186487712e-05
Test Loss:  1.3346855666895863e-05
Valid Loss:  3.81098834623117e-05
Epoch:  327  	Training Loss: 2.8267866582609713e-05
Test Loss:  1.3285535715112928e-05
Valid Loss:  3.802256105700508e-05
Epoch:  328  	Training Loss: 2.8212274628458545e-05
Test Loss:  1.3227341696619987e-05
Valid Loss:  3.7938993045827374e-05
Epoch:  329  	Training Loss: 2.8158185159554705e-05
Test Loss:  1.3171818864066154e-05
Valid Loss:  3.785899389185943e-05
Epoch:  330  	Training Loss: 2.810512341966387e-05
Test Loss:  1.311870164499851e-05
Valid Loss:  3.7781366700073704e-05
Epoch:  331  	Training Loss: 2.8052843845216557e-05
Test Loss:  1.3067337931715883e-05
Valid Loss:  3.770655530388467e-05
Epoch:  332  	Training Loss: 2.8001220925943926e-05
Test Loss:  1.3195635801821481e-05
Valid Loss:  3.766254667425528e-05
Epoch:  333  	Training Loss: 2.7998972655041143e-05
Test Loss:  1.3216958905104548e-05
Valid Loss:  3.766053123399615e-05
Epoch:  334  	Training Loss: 2.799878711812198e-05
Test Loss:  1.3221516383055132e-05
Valid Loss:  3.766428562812507e-05
Epoch:  335  	Training Loss: 2.7998605219181627e-05
Test Loss:  1.3223737369116861e-05
Valid Loss:  3.76685056835413e-05
Epoch:  336  	Training Loss: 2.799803223751951e-05
Test Loss:  1.3225615475676022e-05
Valid Loss:  3.767268208321184e-05
Epoch:  337  	Training Loss: 2.799775029416196e-05
Test Loss:  1.3227161616669036e-05
Valid Loss:  3.767639282159507e-05
Epoch:  338  	Training Loss: 2.7997666620649397e-05
Test Loss:  1.322830757999327e-05
Valid Loss:  3.7680303648812696e-05
Epoch:  339  	Training Loss: 2.7997435608995147e-05
Test Loss:  1.3229976502771024e-05
Valid Loss:  3.7683283153455704e-05
Epoch:  340  	Training Loss: 2.79973610304296e-05
Test Loss:  1.3231517186795827e-05
Valid Loss:  3.76865646103397e-05
Epoch:  341  	Training Loss: 2.7997270080959424e-05
Test Loss:   68%|██████▊   | 341/500 [04:07<03:05,  1.17s/it] 69%|██████▊   | 343/500 [04:07<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:08<01:34,  1.65it/s] 69%|██████▉   | 347/500 [04:08<01:07,  2.25it/s] 70%|██████▉   | 349/500 [04:08<00:49,  3.03it/s] 70%|███████   | 351/500 [04:14<02:52,  1.16s/it] 71%|███████   | 353/500 [04:14<02:03,  1.19it/s] 71%|███████   | 355/500 [04:14<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:14<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:15<00:48,  2.91it/s] 72%|███████▏  | 361/500 [04:21<02:44,  1.19s/it] 73%|███████▎  | 363/500 [04:21<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:21<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:21<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:22<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:28<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:28<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:28<01:18,  1.60it/s] 75%|███████▌  | 377/500 [04:28<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:29<00:41,  2.93it/s] 76%|███████▌  | 381/500 [04:35<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:35<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:35<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:35<00:51,  2.22it/s] 78%|███████▊  | 389/500 [04:35<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:42<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:42<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:42<01:06,  1.59it/s] 79%|███████▉  | 397/500 [04:42<00:48,  2.14it/s] 80%|███████▉  | 399/500 [04:42<00:35,  2.84it/s] 80%|████████  | 401/500 [04:49<01:58,  1.19s/it] 81%|████████  | 403/500 [04:49<01:23,  1.17it/s] 81%|████████  | 405/500 [04:49<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:49<00:42,  2.21it/s]1.3232553101261146e-05
Valid Loss:  3.768993337871507e-05
Epoch:  342  	Training Loss: 2.79969499388244e-05
Test Loss:  1.3181859685573727e-05
Valid Loss:  3.768521128222346e-05
Epoch:  343  	Training Loss: 2.798988134600222e-05
Test Loss:  1.3173270417610183e-05
Valid Loss:  3.766848749364726e-05
Epoch:  344  	Training Loss: 2.7982696337858215e-05
Test Loss:  1.3162913091946393e-05
Valid Loss:  3.7653549952665344e-05
Epoch:  345  	Training Loss: 2.7975847842753865e-05
Test Loss:  1.3150141967344098e-05
Valid Loss:  3.763956556213088e-05
Epoch:  346  	Training Loss: 2.796934495563619e-05
Test Loss:  1.3140564988134429e-05
Valid Loss:  3.76260322809685e-05
Epoch:  347  	Training Loss: 2.7962672902503982e-05
Test Loss:  1.3129360013408586e-05
Valid Loss:  3.761261177714914e-05
Epoch:  348  	Training Loss: 2.7956291887676343e-05
Test Loss:  1.3119613868184388e-05
Valid Loss:  3.760005347430706e-05
Epoch:  349  	Training Loss: 2.7949668947258033e-05
Test Loss:  1.3110546206007712e-05
Valid Loss:  3.758788443519734e-05
Epoch:  350  	Training Loss: 2.7943446184508502e-05
Test Loss:  1.3098271665512584e-05
Valid Loss:  3.75768358935602e-05
Epoch:  351  	Training Loss: 2.793733074213378e-05
Test Loss:  1.3089269486954436e-05
Valid Loss:  3.756516525754705e-05
Epoch:  352  	Training Loss: 2.7931473596254364e-05
Test Loss:  1.2812884051527362e-05
Valid Loss:  3.742920671356842e-05
Epoch:  353  	Training Loss: 2.7774489353760146e-05
Test Loss:  1.2734899428323843e-05
Valid Loss:  3.72831491404213e-05
Epoch:  354  	Training Loss: 2.7689849957823753e-05
Test Loss:  1.2715141565422527e-05
Valid Loss:  3.715786442626268e-05
Epoch:  355  	Training Loss: 2.76217997452477e-05
Test Loss:  1.2698323189397343e-05
Valid Loss:  3.705368362716399e-05
Epoch:  356  	Training Loss: 2.7560976377571933e-05
Test Loss:  1.267204152100021e-05
Valid Loss:  3.696556086651981e-05
Epoch:  357  	Training Loss: 2.750330531853251e-05
Test Loss:  1.262749810848618e-05
Valid Loss:  3.688853757921606e-05
Epoch:  358  	Training Loss: 2.744683479249943e-05
Test Loss:  1.2578131645568646e-05
Valid Loss:  3.681641101138666e-05
Epoch:  359  	Training Loss: 2.7390982722863555e-05
Test Loss:  1.2528762454167008e-05
Valid Loss:  3.674812614917755e-05
Epoch:  360  	Training Loss: 2.733612564043142e-05
Test Loss:  1.2479756151151378e-05
Valid Loss:  3.668092540465295e-05
Epoch:  361  	Training Loss: 2.7282465453026816e-05
Test Loss:  1.2436541510396637e-05
Valid Loss:  3.6616853321902454e-05
Epoch:  362  	Training Loss: 2.7230777050135657e-05
Test Loss:  1.2530195817817003e-05
Valid Loss:  3.651168663054705e-05
Epoch:  363  	Training Loss: 2.7178928576176986e-05
Test Loss:  1.247899308509659e-05
Valid Loss:  3.6464203731156886e-05
Epoch:  364  	Training Loss: 2.712878631427884e-05
Test Loss:  1.244384839083068e-05
Valid Loss:  3.6411329347174615e-05
Epoch:  365  	Training Loss: 2.7079342544311658e-05
Test Loss:  1.2407095709932037e-05
Valid Loss:  3.635993925854564e-05
Epoch:  366  	Training Loss: 2.703032805584371e-05
Test Loss:  1.2371334378258325e-05
Valid Loss:  3.630829814937897e-05
Epoch:  367  	Training Loss: 2.6981846531271003e-05
Test Loss:  1.2336206054897048e-05
Valid Loss:  3.625767203629948e-05
Epoch:  368  	Training Loss: 2.6934292691294104e-05
Test Loss:  1.230215002578916e-05
Valid Loss:  3.620847564889118e-05
Epoch:  369  	Training Loss: 2.6888523279922083e-05
Test Loss:  1.2267966667423025e-05
Valid Loss:  3.615982859628275e-05
Epoch:  370  	Training Loss: 2.6843466912396252e-05
Test Loss:  1.2234125279064756e-05
Valid Loss:  3.6111399822402745e-05
Epoch:  371  	Training Loss: 2.679892713786103e-05
Test Loss:  1.2201917343190871e-05
Valid Loss:  3.606420796131715e-05
Epoch:  372  	Training Loss: 2.675645191629883e-05
Test Loss:  1.22339424706297e-05
Valid Loss:  3.601225034799427e-05
Epoch:  373  	Training Loss: 2.6704259653342888e-05
Test Loss:  1.2208865882712416e-05
Valid Loss:  3.597882459871471e-05
Epoch:  374  	Training Loss: 2.665572174009867e-05
Test Loss:  1.2176484233350493e-05
Valid Loss:  3.594191002775915e-05
Epoch:  375  	Training Loss: 2.6609652195475064e-05
Test Loss:  1.214865824294975e-05
Valid Loss:  3.590092819649726e-05
Epoch:  376  	Training Loss: 2.6565119696897455e-05
Test Loss:  1.2120380233682226e-05
Valid Loss:  3.58575998689048e-05
Epoch:  377  	Training Loss: 2.6521429390413687e-05
Test Loss:  1.2091886674170382e-05
Valid Loss:  3.581284545361996e-05
Epoch:  378  	Training Loss: 2.6478515792405233e-05
Test Loss:  1.2062613677699119e-05
Valid Loss:  3.576628296286799e-05
Epoch:  379  	Training Loss: 2.6435835025040433e-05
Test Loss:  1.2033374332531821e-05
Valid Loss:  3.571861452655867e-05
Epoch:  380  	Training Loss: 2.6393985535833053e-05
Test Loss:  1.1997771252936218e-05
Valid Loss:  3.567051680875011e-05
Epoch:  381  	Training Loss: 2.6352783606853336e-05
Test Loss:  1.1967504178755917e-05
Valid Loss:  3.561977428034879e-05
Epoch:  382  	Training Loss: 2.631226016092114e-05
Test Loss:  1.189367139886599e-05
Valid Loss:  3.5614732041722164e-05
Epoch:  383  	Training Loss: 2.6306228392058983e-05
Test Loss:  1.1835341865662485e-05
Valid Loss:  3.560814730008133e-05
Epoch:  384  	Training Loss: 2.6301520847482607e-05
Test Loss:  1.1790646567533258e-05
Valid Loss:  3.5601031413534656e-05
Epoch:  385  	Training Loss: 2.6297879230696708e-05
Test Loss:  1.1756481399061158e-05
Valid Loss:  3.5592202038969845e-05
Epoch:  386  	Training Loss: 2.6295163479517214e-05
Test Loss:  1.1730120604624972e-05
Valid Loss:  3.558352909749374e-05
Epoch:  387  	Training Loss: 2.629312984936405e-05
Test Loss:  1.1709778846125118e-05
Valid Loss:  3.55748925358057e-05
Epoch:  388  	Training Loss: 2.6291116228094324e-05
Test Loss:  1.169352799479384e-05
Valid Loss:  3.556599040166475e-05
Epoch:  389  	Training Loss: 2.6289766537956893e-05
Test Loss:  1.1681382602546364e-05
Valid Loss:  3.55566298821941e-05
Epoch:  390  	Training Loss: 2.6288373192073777e-05
Test Loss:  1.1671730135276448e-05
Valid Loss:  3.5548895539250225e-05
Epoch:  391  	Training Loss: 2.628708716656547e-05
Test Loss:  1.1663911209325306e-05
Valid Loss:  3.5540600947570056e-05
Epoch:  392  	Training Loss: 2.6286099455319345e-05
Test Loss:  1.1699996321112849e-05
Valid Loss:  3.533390554366633e-05
Epoch:  393  	Training Loss: 2.6162459107581526e-05
Test Loss:  1.1664966223179363e-05
Valid Loss:  3.5165758163202554e-05
Epoch:  394  	Training Loss: 2.604914152470883e-05
Test Loss:  1.1607598025875632e-05
Valid Loss:  3.501213723211549e-05
Epoch:  395  	Training Loss: 2.594354737084359e-05
Test Loss:  1.1545273082447238e-05
Valid Loss:  3.486551213427447e-05
Epoch:  396  	Training Loss: 2.5844517949735746e-05
Test Loss:  1.1484651622595266e-05
Valid Loss:  3.4724875149549916e-05
Epoch:  397  	Training Loss: 2.5751673092599958e-05
Test Loss:  1.1423306204960681e-05
Valid Loss:  3.4590706491144374e-05
Epoch:  398  	Training Loss: 2.566434704931453e-05
Test Loss:  1.1367610568413511e-05
Valid Loss:  3.4459309972589836e-05
Epoch:  399  	Training Loss: 2.5580589863238856e-05
Test Loss:  1.1315942174405791e-05
Valid Loss:  3.4332344512222335e-05
Epoch:  400  	Training Loss: 2.5500969059066847e-05
Test Loss:  1.1268253729213029e-05
Valid Loss:  3.421226574573666e-05
Epoch:  401  	Training Loss: 2.5424400519113988e-05
Test Loss:  1.1223499313928187e-05
Valid Loss:  3.409590499359183e-05
Epoch:  402  	Training Loss: 2.535137718950864e-05
Test Loss:  1.1202419045730494e-05
Valid Loss:  3.402957008802332e-05
Epoch:  403  	Training Loss: 2.530929668864701e-05
Test Loss:  1.116847215598682e-05
Valid Loss:  3.3973323297686875e-05
Epoch:  404  	Training Loss: 2.5268767785746604e-05
Test Loss:  1.1135040040244348e-05
Valid Loss:  3.391874270164408e-05
Epoch:  405  	Training Loss: 2.5228944650734775e-05
Test Loss:  1.110326593334321e-05
Valid Loss:  3.386607932043262e-05
Epoch:  406  	Training Loss: 2.518992914701812e-05
Test Loss:  1.1073344467149582e-05
Valid Loss:  3.381460555829108e-05
Epoch:  407  	Training Loss: 2.5152345187962055e-05
Test Loss:  1.1042925507354084e-05
Valid Loss:  3.3765834814403206e-05
Epoch:  408  	Training Loss: 2.5115321477642283e-05
Test Loss:  1.1013504263246432e-05
Valid Loss:   82%|████████▏ | 409/500 [04:49<00:30,  2.96it/s] 82%|████████▏ | 411/500 [04:56<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:56<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:56<00:52,  1.60it/s] 83%|████████▎ | 417/500 [04:56<00:38,  2.17it/s] 84%|████████▍ | 419/500 [04:56<00:28,  2.86it/s] 84%|████████▍ | 421/500 [05:03<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:03<01:06,  1.16it/s] 85%|████████▌ | 425/500 [05:03<00:47,  1.59it/s] 85%|████████▌ | 427/500 [05:03<00:34,  2.14it/s] 86%|████████▌ | 429/500 [05:03<00:25,  2.83it/s] 86%|████████▌ | 431/500 [05:10<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:10<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:10<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:10<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:10<00:20,  2.94it/s] 88%|████████▊ | 441/500 [05:17<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:17<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:17<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:17<00:23,  2.21it/s] 90%|████████▉ | 449/500 [05:17<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:23<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:24<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:24<00:28,  1.61it/s] 91%|█████████▏| 457/500 [05:24<00:19,  2.17it/s] 92%|█████████▏| 459/500 [05:24<00:14,  2.93it/s] 92%|█████████▏| 461/500 [05:30<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:31<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:31<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:31<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:31<00:10,  2.97it/s] 94%|█████████▍| 471/500 [05:37<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:37<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:37<00:15,  1.63it/s]3.3718362828949466e-05
Epoch:  409  	Training Loss: 2.5078716134885326e-05
Test Loss:  1.0984753316733986e-05
Valid Loss:  3.367222598171793e-05
Epoch:  410  	Training Loss: 2.504300937289372e-05
Test Loss:  1.0956913683912717e-05
Valid Loss:  3.362752613611519e-05
Epoch:  411  	Training Loss: 2.5007389922393486e-05
Test Loss:  1.0929759810096584e-05
Valid Loss:  3.3583553886273876e-05
Epoch:  412  	Training Loss: 2.49722579610534e-05
Test Loss:  1.0868119716178626e-05
Valid Loss:  3.353155989316292e-05
Epoch:  413  	Training Loss: 2.492350722604897e-05
Test Loss:  1.0829931852640584e-05
Valid Loss:  3.3470285416115075e-05
Epoch:  414  	Training Loss: 2.4875884264474735e-05
Test Loss:  1.0801808457472362e-05
Valid Loss:  3.340510374982841e-05
Epoch:  415  	Training Loss: 2.4829632820910774e-05
Test Loss:  1.0778412615763955e-05
Valid Loss:  3.3339903893647715e-05
Epoch:  416  	Training Loss: 2.478416354279034e-05
Test Loss:  1.075726504495833e-05
Valid Loss:  3.3275406167376786e-05
Epoch:  417  	Training Loss: 2.4739583750488237e-05
Test Loss:  1.0735904652392492e-05
Valid Loss:  3.321211988804862e-05
Epoch:  418  	Training Loss: 2.4696066247997805e-05
Test Loss:  1.0714935342548415e-05
Valid Loss:  3.314922651043162e-05
Epoch:  419  	Training Loss: 2.465322359057609e-05
Test Loss:  1.0695168384700082e-05
Valid Loss:  3.308828308945522e-05
Epoch:  420  	Training Loss: 2.461137955833692e-05
Test Loss:  1.0675680641725194e-05
Valid Loss:  3.302797267679125e-05
Epoch:  421  	Training Loss: 2.4570217647124082e-05
Test Loss:  1.065765718522016e-05
Valid Loss:  3.296915383543819e-05
Epoch:  422  	Training Loss: 2.4530221708118916e-05
Test Loss:  1.0678112630557735e-05
Valid Loss:  3.293681947980076e-05
Epoch:  423  	Training Loss: 2.4512286472599953e-05
Test Loss:  1.0685669622034766e-05
Valid Loss:  3.2910895242821425e-05
Epoch:  424  	Training Loss: 2.449475141474977e-05
Test Loss:  1.0688161637517624e-05
Valid Loss:  3.2888256100704893e-05
Epoch:  425  	Training Loss: 2.447746373945847e-05
Test Loss:  1.0688528163882438e-05
Valid Loss:  3.286616993136704e-05
Epoch:  426  	Training Loss: 2.4460645363433287e-05
Test Loss:  1.0687490430427715e-05
Valid Loss:  3.2844858651515096e-05
Epoch:  427  	Training Loss: 2.444404162815772e-05
Test Loss:  1.0686063433240633e-05
Valid Loss:  3.2823769288370386e-05
Epoch:  428  	Training Loss: 2.4427747121080756e-05
Test Loss:  1.0684630979085341e-05
Valid Loss:  3.2803305657580495e-05
Epoch:  429  	Training Loss: 2.441158903820906e-05
Test Loss:  1.0682892025215551e-05
Valid Loss:  3.278190706623718e-05
Epoch:  430  	Training Loss: 2.4395734726567753e-05
Test Loss:  1.0680770174076315e-05
Valid Loss:  3.2761687180027366e-05
Epoch:  431  	Training Loss: 2.4380078684771433e-05
Test Loss:  1.0676136298570782e-05
Valid Loss:  3.274070695624687e-05
Epoch:  432  	Training Loss: 2.4363776901736856e-05
Test Loss:  1.0635236321832053e-05
Valid Loss:  3.268975342507474e-05
Epoch:  433  	Training Loss: 2.4319268050021492e-05
Test Loss:  1.0598856533761136e-05
Valid Loss:  3.26382287312299e-05
Epoch:  434  	Training Loss: 2.4275579562527128e-05
Test Loss:  1.0565203410806134e-05
Valid Loss:  3.258752985857427e-05
Epoch:  435  	Training Loss: 2.4232645955635235e-05
Test Loss:  1.053468895406695e-05
Valid Loss:  3.253835529903881e-05
Epoch:  436  	Training Loss: 2.4191427655750886e-05
Test Loss:  1.0504380043130368e-05
Valid Loss:  3.249131623306312e-05
Epoch:  437  	Training Loss: 2.415049311821349e-05
Test Loss:  1.0474861483089626e-05
Valid Loss:  3.244511390221305e-05
Epoch:  438  	Training Loss: 2.411035166005604e-05
Test Loss:  1.044672080752207e-05
Valid Loss:  3.240063233533874e-05
Epoch:  439  	Training Loss: 2.407147258054465e-05
Test Loss:  1.0421330443932675e-05
Valid Loss:  3.235684198443778e-05
Epoch:  440  	Training Loss: 2.4032491637626663e-05
Test Loss:  1.039496055454947e-05
Valid Loss:  3.231476148357615e-05
Epoch:  441  	Training Loss: 2.399444201728329e-05
Test Loss:  1.0368947187089361e-05
Valid Loss:  3.2274612749461085e-05
Epoch:  442  	Training Loss: 2.395674709987361e-05
Test Loss:  1.0422776540508494e-05
Valid Loss:  3.2234482205240056e-05
Epoch:  443  	Training Loss: 2.3945216526044533e-05
Test Loss:  1.038879418047145e-05
Valid Loss:  3.224005922675133e-05
Epoch:  444  	Training Loss: 2.3933756892802194e-05
Test Loss:  1.0396535799372941e-05
Valid Loss:  3.222312079742551e-05
Epoch:  445  	Training Loss: 2.3922460968606174e-05
Test Loss:  1.038418213283876e-05
Valid Loss:  3.221666702302173e-05
Epoch:  446  	Training Loss: 2.3911416064947844e-05
Test Loss:  1.0382758773630485e-05
Valid Loss:  3.220493090339005e-05
Epoch:  447  	Training Loss: 2.3900243832031265e-05
Test Loss:  1.037478432408534e-05
Valid Loss:  3.2195566745940596e-05
Epoch:  448  	Training Loss: 2.38891807384789e-05
Test Loss:  1.036982393998187e-05
Valid Loss:  3.2185384043259546e-05
Epoch:  449  	Training Loss: 2.3878241336205974e-05
Test Loss:  1.0363670298829675e-05
Valid Loss:  3.217453195247799e-05
Epoch:  450  	Training Loss: 2.3867331037763506e-05
Test Loss:  1.0358172403357457e-05
Valid Loss:  3.216327968402766e-05
Epoch:  451  	Training Loss: 2.385644802416209e-05
Test Loss:  1.035212517308537e-05
Valid Loss:  3.215228207409382e-05
Epoch:  452  	Training Loss: 2.3845637770136818e-05
Test Loss:  1.0329811630072072e-05
Valid Loss:  3.2143943826667964e-05
Epoch:  453  	Training Loss: 2.383151149842888e-05
Test Loss:  1.0324359209334943e-05
Valid Loss:  3.212421870557591e-05
Epoch:  454  	Training Loss: 2.381686499575153e-05
Test Loss:  1.0321902664145455e-05
Valid Loss:  3.210305658285506e-05
Epoch:  455  	Training Loss: 2.380264413659461e-05
Test Loss:  1.0319441571482457e-05
Valid Loss:  3.208181806257926e-05
Epoch:  456  	Training Loss: 2.378843964834232e-05
Test Loss:  1.031754982250277e-05
Valid Loss:  3.206111068720929e-05
Epoch:  457  	Training Loss: 2.3774600776960142e-05
Test Loss:  1.0315276995243039e-05
Valid Loss:  3.204083623131737e-05
Epoch:  458  	Training Loss: 2.3761083866702393e-05
Test Loss:  1.0313909115211572e-05
Valid Loss:  3.2020390790421516e-05
Epoch:  459  	Training Loss: 2.3747490558889695e-05
Test Loss:  1.031231749948347e-05
Valid Loss:  3.2001142244553193e-05
Epoch:  460  	Training Loss: 2.3734113710816018e-05
Test Loss:  1.031081410474144e-05
Valid Loss:  3.198177000740543e-05
Epoch:  461  	Training Loss: 2.3721262550679967e-05
Test Loss:  1.0309453500667587e-05
Valid Loss:  3.196308534825221e-05
Epoch:  462  	Training Loss: 2.3708507796982303e-05
Test Loss:  1.0287832992617041e-05
Valid Loss:  3.190809366060421e-05
Epoch:  463  	Training Loss: 2.366379339946434e-05
Test Loss:  1.0264080628985539e-05
Valid Loss:  3.185667810612358e-05
Epoch:  464  	Training Loss: 2.361976839893032e-05
Test Loss:  1.024086304823868e-05
Valid Loss:  3.180607745889574e-05
Epoch:  465  	Training Loss: 2.357626181037631e-05
Test Loss:  1.0217818271485157e-05
Valid Loss:  3.175733581883833e-05
Epoch:  466  	Training Loss: 2.3533200874226168e-05
Test Loss:  1.0195421054959297e-05
Valid Loss:  3.1708794267615303e-05
Epoch:  467  	Training Loss: 2.3490676539950073e-05
Test Loss:  1.0173444024985656e-05
Valid Loss:  3.1661369575886056e-05
Epoch:  468  	Training Loss: 2.3448457795893773e-05
Test Loss:  1.01508439911413e-05
Valid Loss:  3.161450877087191e-05
Epoch:  469  	Training Loss: 2.340688297408633e-05
Test Loss:  1.012922075460665e-05
Valid Loss:  3.156793536618352e-05
Epoch:  470  	Training Loss: 2.3365773813566193e-05
Test Loss:  1.010805044643348e-05
Valid Loss:  3.15215511363931e-05
Epoch:  471  	Training Loss: 2.3325093934545293e-05
Test Loss:  1.0087580449180678e-05
Valid Loss:  3.1476254662266e-05
Epoch:  472  	Training Loss: 2.3284763301489875e-05
Test Loss:  1.007756327453535e-05
Valid Loss:  3.1456798751605675e-05
Epoch:  473  	Training Loss: 2.326321009604726e-05
Test Loss:  1.0072364602820016e-05
Valid Loss:  3.143256253679283e-05
Epoch:  474  	Training Loss: 2.3241758754011244e-05
Test Loss:  1.0068525625683833e-05
Valid Loss:  3.14072567562107e-05
Epoch:  475  	Training Loss: 2.3220731236506253e-05
Test Loss:  1.0064341040560976e-05
Valid Loss:  3.138111060252413e-05
 95%|█████████▌| 477/500 [05:38<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:38<00:07,  3.00it/s] 96%|█████████▌| 481/500 [05:44<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:44<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:44<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:45<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:45<00:03,  2.96it/s] 98%|█████████▊| 491/500 [05:51<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:51<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:51<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:51<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:51<00:00,  3.00it/s]100%|██████████| 500/500 [05:52<00:00,  1.42it/s]
Epoch:  476  	Training Loss: 2.319950726814568e-05
Test Loss:  1.0060292879643384e-05
Valid Loss:  3.135486622340977e-05
Epoch:  477  	Training Loss: 2.317906000826042e-05
Test Loss:  1.0056056453322526e-05
Valid Loss:  3.132914935122244e-05
Epoch:  478  	Training Loss: 2.3158238036558032e-05
Test Loss:  1.0052963261841796e-05
Valid Loss:  3.130286859232001e-05
Epoch:  479  	Training Loss: 2.3137959942687303e-05
Test Loss:  1.004891782940831e-05
Valid Loss:  3.12767006107606e-05
Epoch:  480  	Training Loss: 2.3117881937650964e-05
Test Loss:  1.0044988812296651e-05
Valid Loss:  3.1251725886249915e-05
Epoch:  481  	Training Loss: 2.309792398591526e-05
Test Loss:  1.0041128007287625e-05
Valid Loss:  3.122603447991423e-05
Epoch:  482  	Training Loss: 2.307818431290798e-05
Test Loss:  1.0037346328317653e-05
Valid Loss:  3.1213960028253496e-05
Epoch:  483  	Training Loss: 2.306727401446551e-05
Test Loss:  1.0036330422735773e-05
Valid Loss:  3.1200514058582485e-05
Epoch:  484  	Training Loss: 2.3056694772094488e-05
Test Loss:  1.0035400919150561e-05
Valid Loss:  3.118664972134866e-05
Epoch:  485  	Training Loss: 2.3046090063871816e-05
Test Loss:  1.0034592378360685e-05
Valid Loss:  3.1172854505712166e-05
Epoch:  486  	Training Loss: 2.3035654521663673e-05
Test Loss:  1.0033947546617128e-05
Valid Loss:  3.115903746220283e-05
Epoch:  487  	Training Loss: 2.302536813658662e-05
Test Loss:  1.003331271931529e-05
Valid Loss:  3.1145449611358345e-05
Epoch:  488  	Training Loss: 2.30149944400182e-05
Test Loss:  1.0032576028606854e-05
Valid Loss:  3.1131687137531117e-05
Epoch:  489  	Training Loss: 2.300462801940739e-05
Test Loss:  1.0032033969764598e-05
Valid Loss:  3.1117502658162266e-05
Epoch:  490  	Training Loss: 2.29946290346561e-05
Test Loss:  1.0031294550572056e-05
Valid Loss:  3.1104282243177295e-05
Epoch:  491  	Training Loss: 2.298461549798958e-05
Test Loss:  1.0030265912064351e-05
Valid Loss:  3.109141471213661e-05
Epoch:  492  	Training Loss: 2.2974569219513796e-05
Test Loss:  1.0075129466713406e-05
Valid Loss:  3.1070718250703067e-05
Epoch:  493  	Training Loss: 2.297186256328132e-05
Test Loss:  1.0055342499981634e-05
Valid Loss:  3.108857708866708e-05
Epoch:  494  	Training Loss: 2.2969370547798462e-05
Test Loss:  1.0062673936772626e-05
Valid Loss:  3.1088144169189036e-05
Epoch:  495  	Training Loss: 2.2966818505665287e-05
Test Loss:  1.0058496627607383e-05
Valid Loss:  3.109385215793736e-05
Epoch:  496  	Training Loss: 2.2964941308600828e-05
Test Loss:  1.0050047421827912e-05
Valid Loss:  3.109778117504902e-05
Epoch:  497  	Training Loss: 2.2962902221479453e-05
Test Loss:  1.0062631190521643e-05
Valid Loss:  3.1090570701053366e-05
Epoch:  498  	Training Loss: 2.2960815840633586e-05
Test Loss:  1.0056078281195369e-05
Valid Loss:  3.109441604465246e-05
Epoch:  499  	Training Loss: 2.2959096895647235e-05
Test Loss:  1.0057532563223504e-05
Valid Loss:  3.109284079982899e-05
Epoch:  500  	Training Loss: 2.295699596288614e-05
Test Loss:  1.005550984700676e-05
Valid Loss:  3.1093397410586476e-05
seed is  19
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.31it/s]  1%|          | 4/500 [00:00<00:30, 16.47it/s]  1%|          | 6/500 [00:00<00:30, 16.45it/s]  2%|▏         | 8/500 [00:00<00:29, 16.43it/s]  2%|▏         | 10/500 [00:00<00:29, 16.42it/s]  2%|▏         | 12/500 [00:00<00:29, 16.53it/s]  3%|▎         | 14/500 [00:00<00:29, 16.52it/s]  3%|▎         | 16/500 [00:00<00:29, 16.52it/s]  4%|▎         | 18/500 [00:01<00:29, 16.50it/s]  4%|▍         | 20/500 [00:01<00:29, 16.52it/s]  4%|▍         | 22/500 [00:01<00:29, 16.42it/s]  5%|▍         | 24/500 [00:01<00:29, 16.31it/s]  5%|▌         | 26/500 [00:01<00:29, 16.23it/s]  6%|▌         | 28/500 [00:01<00:29, 16.22it/s]  6%|▌         | 30/500 [00:01<00:29, 16.19it/s]  6%|▋         | 32/500 [00:01<00:28, 16.14it/s]  7%|▋         | 34/500 [00:02<00:28, 16.14it/s]  7%|▋         | 36/500 [00:02<00:28, 16.22it/s]  8%|▊         | 38/500 [00:02<00:29, 15.83it/s]  8%|▊         | 40/500 [00:02<00:31, 14.54it/s]  8%|▊         | 42/500 [00:02<00:33, 13.71it/s]  9%|▉         | 44/500 [00:02<00:33, 13.49it/s]  9%|▉         | 46/500 [00:02<00:34, 13.10it/s] 10%|▉         | 48/500 [00:03<00:35, 12.89it/s] 10%|█         | 50/500 [00:03<00:35, 12.65it/s] 10%|█         | 52/500 [00:03<00:35, 12.56it/s] 11%|█         | 54/500 [00:03<00:35, 12.50it/s] 11%|█         | 56/500 [00:03<00:36, 12.33it/s] 12%|█▏        | 58/500 [00:03<00:35, 12.31it/s] 12%|█▏        | 60/500 [00:04<00:35, 12.31it/s] 12%|█▏        | 62/500 [00:04<00:35, 12.22it/s] 13%|█▎        | 64/500 [00:04<00:33, 12.85it/s] 13%|█▎        | 66/500 [00:04<00:31, 13.71it/s] 14%|█▎        | 68/500 [00:04<00:29, 14.43it/s] 14%|█▍        | 70/500 [00:04<00:28, 14.89it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.36it/s] 15%|█▍        | 74/500 [00:05<00:27, 15.45it/s] 15%|█▌        | 76/500 [00:05<00:27, 15.70it/s] 16%|█▌        | 78/500 [00:05<00:26, 15.85it/s] 16%|█▌        | 80/500 [00:05<00:26, 16.03it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.22it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.33it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.40it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.44it/s] 18%|█▊        | 90/500 [00:06<00:25, 16.36it/s] 18%|█▊        | 92/500 [00:06<00:25, 16.09it/s] 19%|█▉        | 94/500 [00:06<00:25, 16.09it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.22it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.35it/s] 20%|██        | 100/500 [00:06<00:24, 16.41it/s] 20%|██        | 102/500 [00:06<00:24, 16.06it/s] 21%|██        | 104/500 [00:06<00:24, 16.23it/s] 21%|██        | 106/500 [00:07<00:24, 16.12it/s] 22%|██▏       | 108/500 [00:07<00:24, 16.24it/s] 22%|██▏       | 110/500 [00:07<00:23, 16.32it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.33it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.42it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.49it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.52it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.56it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.57it/s] 25%|██▍       | 124/500 [00:08<00:22, 16.56it/s]Epoch:  1  	Training Loss: 0.04605455324053764
Test Loss:  1123.412353515625
Valid Loss:  1123.099365234375
Epoch:  2  	Training Loss: 1119.2745361328125
Test Loss:  274731274076160.0
Valid Loss:  272802162671616.0
Epoch:  3  	Training Loss: 270922644717568.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:22, 16.48it/s] 26%|██▌       | 128/500 [00:08<00:22, 16.40it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.42it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.34it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.30it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.34it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.25it/s] 28%|██▊       | 140/500 [00:09<00:21, 16.40it/s] 28%|██▊       | 142/500 [00:09<00:21, 16.44it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.37it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.33it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.33it/s] 30%|███       | 150/500 [00:09<00:21, 16.23it/s] 30%|███       | 152/500 [00:09<00:21, 16.19it/s] 31%|███       | 154/500 [00:09<00:21, 15.97it/s] 31%|███       | 156/500 [00:10<00:21, 16.08it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.18it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.53it/s] 32%|███▏      | 162/500 [00:10<00:22, 14.89it/s] 33%|███▎      | 164/500 [00:10<00:22, 15.07it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.38it/s] 34%|███▎      | 168/500 [00:10<00:21, 15.59it/s] 34%|███▍      | 170/500 [00:10<00:20, 15.80it/s] 34%|███▍      | 172/500 [00:11<00:20, 15.92it/s] 35%|███▍      | 174/500 [00:11<00:20, 15.98it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.11it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.11it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.22it/s] 36%|███▋      | 182/500 [00:11<00:19, 15.95it/s] 37%|███▋      | 184/500 [00:11<00:21, 14.63it/s] 37%|███▋      | 186/500 [00:12<00:22, 13.87it/s] 38%|███▊      | 188/500 [00:12<00:22, 13.58it/s] 38%|███▊      | 190/500 [00:12<00:21, 14.38it/s] 38%|███▊      | 192/500 [00:12<00:20, 15.02it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.43it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.69it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.89it/s] 40%|████      | 200/500 [00:12<00:18, 16.00it/s] 40%|████      | 202/500 [00:13<00:18, 16.02it/s] 41%|████      | 204/500 [00:13<00:18, 16.13it/s] 41%|████      | 206/500 [00:13<00:18, 16.22it/s] 42%|████▏     | 208/500 [00:13<00:17, 16.28it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.26it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.31it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.41it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.44it/s] 44%|████▎     | 218/500 [00:14<00:17, 16.43it/s] 44%|████▍     | 220/500 [00:14<00:17, 16.43it/s] 44%|████▍     | 222/500 [00:14<00:16, 16.45it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.41it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.25it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.11it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.15it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.14it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.12it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.09it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.10it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.94it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.76it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.88it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.83it/s] 50%|████▉     | 248/500 [00:15<00:15, 15.96it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.14it/s] 50%|█████     | 252/500 [00:16<00:15, 16.18it/s] 51%|█████     | 254/500 [00:16<00:15, 16.15it/s] 51%|█████     | 256/500 [00:16<00:14, 16.27it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.36it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.38it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.45it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.35it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.39it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.40it/s] 54%|█████▍    | 270/500 [00:17<00:15, 15.01it/s] 54%|█████▍    | 272/500 [00:17<00:16, 14.24it/s] 55%|█████▍    | 274/500 [00:17<00:15, 14.85it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.10it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.33it/s] 56%|█████▌    | 280/500 [00:17<00:14, 15.66it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.90it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.07it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.20it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.29it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.37it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.38it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.40it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.42it/s] 60%|█████▉    | 298/500 [00:19<00:12, 16.45it/s] 60%|██████    | 300/500 [00:19<00:12, 16.43it/s] 60%|██████    | 302/500 [00:19<00:12, 16.46it/s] 61%|██████    | 304/500 [00:19<00:11, 16.48it/s] 61%|██████    | 306/500 [00:19<00:12, 15.46it/s] 62%|██████▏   | 308/500 [00:19<00:13, 14.43it/s] 62%|██████▏   | 310/500 [00:19<00:13, 13.75it/s] 62%|██████▏   | 312/500 [00:20<00:14, 13.31it/s] 63%|██████▎   | 314/500 [00:20<00:14, 13.02it/s] 63%|██████▎   | 316/500 [00:20<00:14, 12.82it/s] 64%|██████▎   | 318/500 [00:20<00:14, 12.65it/s] 64%|██████▍   | 320/500 [00:20<00:14, 12.57it/s] 64%|██████▍   | 322/500 [00:20<00:14, 12.69it/s] 65%|██████▍   | 324/500 [00:20<00:12, 13.60it/s] 65%|██████▌   | 326/500 [00:21<00:12, 14.25it/s] 66%|██████▌   | 328/500 [00:21<00:11, 14.76it/s] 66%|██████▌   | 330/500 [00:21<00:11, 15.30it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.64it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.86it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.04it/s] 68%|██████▊   | 338/500 [00:21<00:10, 16.17it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.28it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.35it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.37it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.27it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.15it/s] 70%|███████   | 350/500 [00:22<00:09, 16.13it/s] 70%|███████   | 352/500 [00:22<00:09, 16.12it/s] 71%|███████   | 354/500 [00:22<00:09, 16.15it/s] 71%|███████   | 356/500 [00:22<00:08, 16.25it/s] 72%|███████▏  | 358/500 [00:23<00:08, 16.30it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.36it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.34it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.22it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.24it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.99it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.99it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.06it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 16.10it/s] 75%|███████▌  | 376/500 [00:24<00:07, 16.13it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.11it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.13it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.25it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.34it/s] 77%|███████▋  | 386/500 [00:24<00:06, 16.48it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.54it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.50it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.47it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.52it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.50it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.29it/s] 80%|████████  | 400/500 [00:25<00:06, 16.37it/s] 80%|████████  | 402/500 [00:25<00:05, 16.40it/s] 81%|████████  | 404/500 [00:25<00:05, 16.42it/s] 81%|████████  | 406/500 [00:25<00:05, 16.48it/s] 82%|████████▏ | 408/500 [00:26<00:05, 16.35it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.48it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.53it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.44it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.47it/s] 84%|████████▎ | 418/500 [00:26<00:04, 16.47it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.47it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.39it/s] 85%|████████▍ | 424/500 [00:27<00:04, 16.45it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.51it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.51it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.48it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.49it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.48it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.44it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.32it/s] 88%|████████▊ | 440/500 [00:28<00:03, 16.22it/s] 88%|████████▊ | 442/500 [00:28<00:03, 15.84it/s] 89%|████████▉ | 444/500 [00:28<00:03, 14.51it/s] 89%|████████▉ | 446/500 [00:28<00:03, 13.68it/s] 90%|████████▉ | 448/500 [00:28<00:03, 14.00it/s] 90%|█████████ | 450/500 [00:28<00:03, 14.45it/s] 90%|█████████ | 452/500 [00:28<00:03, 13.85it/s] 91%|█████████ | 454/500 [00:29<00:03, 14.48it/s] 91%|█████████ | 456/500 [00:29<00:02, 14.93it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.35it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.70it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.78it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.84it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.02it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.14it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.95it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.15it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.01it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.01it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.13it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.88it/s] 96%|█████████▋| 482/500 [00:30<00:01, 14.58it/s] 97%|█████████▋| 484/500 [00:30<00:01, 13.73it/s] 97%|█████████▋| 486/500 [00:31<00:01, 13.26it/s] 98%|█████████▊| 488/500 [00:31<00:00, 13.12it/s] 98%|█████████▊| 490/500 [00:31<00:00, 13.96it/s] 98%|█████████▊| 492/500 [00:31<00:00, 14.63it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.14it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.56it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.87it/s]100%|██████████| 500/500 [00:32<00:00, 16.05it/s]100%|██████████| 500/500 [00:32<00:00, 15.61it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  19
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:03,  6.26s/it]  1%|          | 3/500 [00:06<13:53,  1.68s/it]  1%|          | 5/500 [00:06<07:05,  1.16it/s]  1%|▏         | 7/500 [00:06<04:22,  1.88it/s]  2%|▏         | 9/500 [00:06<02:58,  2.75it/s]  2%|▏         | 11/500 [00:13<10:57,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:34,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:37,  2.18it/s]  6%|▌         | 29/500 [00:20<02:43,  2.89it/s]  6%|▌         | 31/500 [00:27<09:21,  1.20s/it]  7%|▋         | 33/500 [00:27<06:40,  1.17it/s]  7%|▋         | 35/500 [00:27<04:48,  1.61it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:35,  2.97it/s]  8%|▊         | 41/500 [00:33<09:01,  1.18s/it]  9%|▊         | 43/500 [00:34<06:26,  1.18it/s]  9%|▉         | 45/500 [00:34<04:38,  1.63it/s]  9%|▉         | 47/500 [00:34<03:22,  2.23it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:55,  1.19s/it] 11%|█         | 53/500 [00:40<06:22,  1.17it/s] 11%|█         | 55/500 [00:41<04:37,  1.61it/s] 11%|█▏        | 57/500 [00:41<03:23,  2.18it/s] 12%|█▏        | 59/500 [00:41<02:30,  2.94it/s] 12%|█▏        | 61/500 [00:48<09:06,  1.24s/it] 13%|█▎        | 63/500 [00:48<06:30,  1.12it/s] 13%|█▎        | 65/500 [00:48<04:40,  1.55it/s] 13%|█▎        | 67/500 [00:48<03:24,  2.12it/s] 14%|█▍        | 69/500 [00:48<02:31,  2.85it/s] 14%|█▍        | 71/500 [00:54<08:32,  1.20s/it]Epoch:  1  	Training Loss: 0.04605455324053764
Test Loss:  72.98626708984375
Valid Loss:  72.34418487548828
Epoch:  2  	Training Loss: 71.22239685058594
Test Loss:  1323.9749755859375
Valid Loss:  1305.145263671875
Epoch:  3  	Training Loss: 1284.3863525390625
Test Loss:  0.0653315857052803
Valid Loss:  0.06711257994174957
Epoch:  4  	Training Loss: 0.062240682542324066
Test Loss:  0.06531433016061783
Valid Loss:  0.06709553301334381
Epoch:  5  	Training Loss: 0.062224678695201874
Test Loss:  0.06529707461595535
Valid Loss:  0.06707855314016342
Epoch:  6  	Training Loss: 0.06220877170562744
Test Loss:  0.06527996808290482
Valid Loss:  0.067061647772789
Epoch:  7  	Training Loss: 0.06219295412302017
Test Loss:  0.06526292860507965
Valid Loss:  0.06704482436180115
Epoch:  8  	Training Loss: 0.06217717379331589
Test Loss:  0.06524594128131866
Valid Loss:  0.06702811270952225
Epoch:  9  	Training Loss: 0.06216144934296608
Test Loss:  0.06522905826568604
Valid Loss:  0.06701146066188812
Epoch:  10  	Training Loss: 0.06214582547545433
Test Loss:  0.06521225720643997
Valid Loss:  0.06699483096599579
Epoch:  11  	Training Loss: 0.06213027983903885
Test Loss:  0.06519550830125809
Valid Loss:  0.0669783353805542
Epoch:  12  	Training Loss: 0.06211477890610695
Test Loss:  0.06515580415725708
Valid Loss:  0.06693962216377258
Epoch:  13  	Training Loss: 0.06207871437072754
Test Loss:  0.06511619687080383
Valid Loss:  0.06690093129873276
Epoch:  14  	Training Loss: 0.06204266846179962
Test Loss:  0.06507662683725357
Valid Loss:  0.06686227768659592
Epoch:  15  	Training Loss: 0.062006641179323196
Test Loss:  0.06503705680370331
Valid Loss:  0.06682366132736206
Epoch:  16  	Training Loss: 0.06197066605091095
Test Loss:  0.06499749422073364
Valid Loss:  0.06678501516580582
Epoch:  17  	Training Loss: 0.06193472445011139
Test Loss:  0.06495799124240875
Valid Loss:  0.06674642860889435
Epoch:  18  	Training Loss: 0.06189878657460213
Test Loss:  0.06491851806640625
Valid Loss:  0.06670793890953064
Epoch:  19  	Training Loss: 0.061862897127866745
Test Loss:  0.06487908959388733
Valid Loss:  0.06666940450668335
Epoch:  20  	Training Loss: 0.06182703375816345
Test Loss:  0.06483965367078781
Valid Loss:  0.06663095951080322
Epoch:  21  	Training Loss: 0.06179121881723404
Test Loss:  0.06480029225349426
Valid Loss:  0.0665925070643425
Epoch:  22  	Training Loss: 0.061755433678627014
Test Loss:  0.06475809961557388
Valid Loss:  0.06655135005712509
Epoch:  23  	Training Loss: 0.06171705946326256
Test Loss:  0.0647159218788147
Valid Loss:  0.06651018559932709
Epoch:  24  	Training Loss: 0.061678726226091385
Test Loss:  0.06467374414205551
Valid Loss:  0.06646904349327087
Epoch:  25  	Training Loss: 0.0616404190659523
Test Loss:  0.06463160365819931
Valid Loss:  0.06642790883779526
Epoch:  26  	Training Loss: 0.06160212680697441
Test Loss:  0.0645895004272461
Valid Loss:  0.06638677418231964
Epoch:  27  	Training Loss: 0.061563871800899506
Test Loss:  0.06454743444919586
Valid Loss:  0.06634573638439178
Epoch:  28  	Training Loss: 0.061525631695985794
Test Loss:  0.06450538337230682
Valid Loss:  0.06630472093820572
Epoch:  29  	Training Loss: 0.06148741394281387
Test Loss:  0.06446333974599838
Valid Loss:  0.06626369804143906
Epoch:  30  	Training Loss: 0.061449211090803146
Test Loss:  0.06442142277956009
Valid Loss:  0.06622277200222015
Epoch:  31  	Training Loss: 0.06141111999750137
Test Loss:  0.06437955796718597
Valid Loss:  0.06618184596300125
Epoch:  32  	Training Loss: 0.061373043805360794
Test Loss:  0.06434128433465958
Valid Loss:  0.06614456325769424
Epoch:  33  	Training Loss: 0.06133829429745674
Test Loss:  0.06430312991142273
Valid Loss:  0.06610728800296783
Epoch:  34  	Training Loss: 0.06130356341600418
Test Loss:  0.06426498293876648
Valid Loss:  0.06607003509998322
Epoch:  35  	Training Loss: 0.06126890331506729
Test Loss:  0.06422685086727142
Valid Loss:  0.06603282690048218
Epoch:  36  	Training Loss: 0.06123429164290428
Test Loss:  0.06418877094984055
Valid Loss:  0.06599566340446472
Epoch:  37  	Training Loss: 0.061199650168418884
Test Loss:  0.06415075063705444
Valid Loss:  0.06595851480960846
Epoch:  38  	Training Loss: 0.06116505712270737
Test Loss:  0.06411270797252655
Valid Loss:  0.06592140346765518
Epoch:  39  	Training Loss: 0.06113049387931824
Test Loss:  0.06407473981380463
Valid Loss:  0.0658843070268631
Epoch:  40  	Training Loss: 0.0610959529876709
Test Loss:  0.06403683125972748
Valid Loss:  0.06584727764129639
Epoch:  41  	Training Loss: 0.06106147915124893
Test Loss:  0.06399889290332794
Valid Loss:  0.06581024825572968
Epoch:  42  	Training Loss: 0.06102701276540756
Test Loss:  0.06395860016345978
Valid Loss:  0.06577091664075851
Epoch:  43  	Training Loss: 0.06099042668938637
Test Loss:  0.06391829252243042
Valid Loss:  0.06573161482810974
Epoch:  44  	Training Loss: 0.06095382571220398
Test Loss:  0.06387807428836823
Valid Loss:  0.06569238752126694
Epoch:  45  	Training Loss: 0.06091728061437607
Test Loss:  0.06383788585662842
Valid Loss:  0.06565310806035995
Epoch:  46  	Training Loss: 0.06088075786828995
Test Loss:  0.06379766762256622
Valid Loss:  0.06561392545700073
Epoch:  47  	Training Loss: 0.060844264924526215
Test Loss:  0.06375753879547119
Valid Loss:  0.06557473540306091
Epoch:  48  	Training Loss: 0.06080781668424606
Test Loss:  0.06371738761663437
Valid Loss:  0.06553559005260468
Epoch:  49  	Training Loss: 0.060771360993385315
Test Loss:  0.06367732584476471
Valid Loss:  0.06549646705389023
Epoch:  50  	Training Loss: 0.06073495000600815
Test Loss:  0.06363728642463684
Valid Loss:  0.06545736640691757
Epoch:  51  	Training Loss: 0.060698576271533966
Test Loss:  0.06359720230102539
Valid Loss:  0.06541833281517029
Epoch:  52  	Training Loss: 0.060662221163511276
Test Loss:  0.06355457007884979
Valid Loss:  0.06537672132253647
Epoch:  53  	Training Loss: 0.060623519122600555
Test Loss:  0.06351205706596375
Valid Loss:  0.0653352290391922
Epoch:  54  	Training Loss: 0.0605849027633667
Test Loss:  0.0634695440530777
Valid Loss:  0.06529378890991211
Epoch:  55  	Training Loss: 0.06054631993174553
Test Loss:  0.06342709064483643
Valid Loss:  0.06525233387947083
Epoch:  56  	Training Loss: 0.06050775200128555
Test Loss:  0.06338460743427277
Valid Loss:  0.06521090865135193
Epoch:  57  	Training Loss: 0.060469239950180054
Test Loss:  0.06334216147661209
Valid Loss:  0.0651695504784584
Epoch:  58  	Training Loss: 0.06043072044849396
Test Loss:  0.0632997453212738
Valid Loss:  0.06512817740440369
Epoch:  59  	Training Loss: 0.06039223074913025
Test Loss:  0.06325742602348328
Valid Loss:  0.06508688628673553
Epoch:  60  	Training Loss: 0.06035378575325012
Test Loss:  0.06321512162685394
Valid Loss:  0.0650455579161644
Epoch:  61  	Training Loss: 0.060315363109111786
Test Loss:  0.06317275762557983
Valid Loss:  0.06500428915023804
Epoch:  62  	Training Loss: 0.060276955366134644
Test Loss:  0.06313404440879822
Valid Loss:  0.06496652960777283
Epoch:  63  	Training Loss: 0.06024179607629776
Test Loss:  0.06309540569782257
Valid Loss:  0.06492878496646881
Epoch:  64  	Training Loss: 0.06020669639110565
Test Loss:  0.0630568116903305
Valid Loss:  0.06489109992980957
Epoch:  65  	Training Loss: 0.06017160415649414
Test Loss:  0.06301819533109665
Valid Loss:  0.06485342234373093
Epoch:  66  	Training Loss: 0.060136549174785614
Test Loss:  0.06297961622476578
Valid Loss:  0.06481578946113586
Epoch:  67  	Training Loss: 0.06010151654481888
Test Loss:  0.06294108927249908
Valid Loss:  0.06477819383144379
Epoch:  68  	Training Loss: 0.06006651371717453
Test Loss:  0.06290262937545776
Valid Loss:  0.06474064290523529
Epoch:  69  	Training Loss: 0.06003157049417496
Test Loss:  0.06286414712667465
Valid Loss:  0.0647030919790268
Epoch:  70  	Training Loss: 0.05999663844704628
Test Loss:  0.06282570958137512
Valid Loss:  0.06466557830572128
Epoch:  71  	Training Loss: 0.05996173247694969
Test Loss:  0.06278735399246216
Valid Loss:  0.06462808698415756
Epoch:  72  	Training Loss: 0.05992686003446579
Test Loss:  0.06274987757205963
Valid Loss:  0.06459154188632965
Epoch:  73  	Training Loss: 0.05989285558462143
Test Loss:   15%|█▍        | 73/500 [00:55<06:06,  1.17it/s] 15%|█▌        | 75/500 [00:55<04:24,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:12,  2.20it/s] 16%|█▌        | 79/500 [00:55<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:01<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:02<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:02<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:02<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:08<08:07,  1.19s/it] 19%|█▊        | 93/500 [01:08<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:09<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:09<02:15,  2.97it/s] 20%|██        | 101/500 [01:15<07:57,  1.20s/it] 21%|██        | 103/500 [01:15<05:43,  1.16it/s] 21%|██        | 105/500 [01:15<04:09,  1.58it/s] 21%|██▏       | 107/500 [01:16<03:02,  2.15it/s] 22%|██▏       | 109/500 [01:16<02:14,  2.90it/s] 22%|██▏       | 111/500 [01:22<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:22<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:23<02:56,  2.17it/s] 24%|██▍       | 119/500 [01:23<02:12,  2.87it/s] 24%|██▍       | 121/500 [01:29<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.22it/s] 26%|██▌       | 129/500 [01:30<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:36<07:18,  1.19s/it] 27%|██▋       | 133/500 [01:36<05:12,  1.17it/s] 27%|██▋       | 135/500 [01:36<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:36<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:36<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:43<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:43<05:03,  1.18it/s]0.06271249055862427
Valid Loss:  0.06455500423908234
Epoch:  74  	Training Loss: 0.05985884368419647
Test Loss:  0.06267502903938293
Valid Loss:  0.06451845169067383
Epoch:  75  	Training Loss: 0.059824831783771515
Test Loss:  0.06263761222362518
Valid Loss:  0.06448192894458771
Epoch:  76  	Training Loss: 0.05979085713624954
Test Loss:  0.06260023266077042
Valid Loss:  0.06444544345140457
Epoch:  77  	Training Loss: 0.05975689738988876
Test Loss:  0.06256290525197983
Valid Loss:  0.06440898776054382
Epoch:  78  	Training Loss: 0.059723008424043655
Test Loss:  0.06252558529376984
Valid Loss:  0.06437256187200546
Epoch:  79  	Training Loss: 0.05968910828232765
Test Loss:  0.06248833239078522
Valid Loss:  0.06433621793985367
Epoch:  80  	Training Loss: 0.05965526029467583
Test Loss:  0.0624510757625103
Valid Loss:  0.06429987400770187
Epoch:  81  	Training Loss: 0.05962143838405609
Test Loss:  0.06241387873888016
Valid Loss:  0.06426357477903366
Epoch:  82  	Training Loss: 0.05958765000104904
Test Loss:  0.062373846769332886
Valid Loss:  0.06422442197799683
Epoch:  83  	Training Loss: 0.05955128371715546
Test Loss:  0.06233378127217293
Valid Loss:  0.06418542563915253
Epoch:  84  	Training Loss: 0.059514954686164856
Test Loss:  0.06229378283023834
Valid Loss:  0.06414638459682465
Epoch:  85  	Training Loss: 0.05947864055633545
Test Loss:  0.062253788113594055
Valid Loss:  0.06410734355449677
Epoch:  86  	Training Loss: 0.059442367404699326
Test Loss:  0.06221383064985275
Valid Loss:  0.06406835466623306
Epoch:  87  	Training Loss: 0.059406109154224396
Test Loss:  0.06217386573553085
Valid Loss:  0.06402943283319473
Epoch:  88  	Training Loss: 0.05936989188194275
Test Loss:  0.06213401257991791
Valid Loss:  0.0639905035495758
Epoch:  89  	Training Loss: 0.059333685785532
Test Loss:  0.06209409236907959
Valid Loss:  0.06395156681537628
Epoch:  90  	Training Loss: 0.05929750204086304
Test Loss:  0.06205420568585396
Valid Loss:  0.06391274183988571
Epoch:  91  	Training Loss: 0.05926132947206497
Test Loss:  0.06201440095901489
Valid Loss:  0.06387387216091156
Epoch:  92  	Training Loss: 0.059225231409072876
Test Loss:  0.0619766004383564
Valid Loss:  0.06383699178695679
Epoch:  93  	Training Loss: 0.059190988540649414
Test Loss:  0.06193877011537552
Valid Loss:  0.06380011141300201
Epoch:  94  	Training Loss: 0.059156786650419235
Test Loss:  0.06190091744065285
Valid Loss:  0.06376324594020844
Epoch:  95  	Training Loss: 0.05912256985902786
Test Loss:  0.06186308711767197
Valid Loss:  0.06372639536857605
Epoch:  96  	Training Loss: 0.05908835679292679
Test Loss:  0.061825238168239594
Valid Loss:  0.06368952244520187
Epoch:  97  	Training Loss: 0.059054162353277206
Test Loss:  0.0617874376475811
Valid Loss:  0.0636526495218277
Epoch:  98  	Training Loss: 0.05901994928717613
Test Loss:  0.061749618500471115
Valid Loss:  0.06361580640077591
Epoch:  99  	Training Loss: 0.05898575484752655
Test Loss:  0.061711788177490234
Valid Loss:  0.06357896327972412
Epoch:  100  	Training Loss: 0.058951571583747864
Test Loss:  0.061673954129219055
Valid Loss:  0.06354207545518875
Epoch:  101  	Training Loss: 0.058917365968227386
Test Loss:  0.061636172235012054
Valid Loss:  0.06350526213645935
Epoch:  102  	Training Loss: 0.0588831827044487
Test Loss:  0.06159218028187752
Valid Loss:  0.06346240639686584
Epoch:  103  	Training Loss: 0.058843374252319336
Test Loss:  0.061548277735710144
Valid Loss:  0.06341958045959473
Epoch:  104  	Training Loss: 0.05880357325077057
Test Loss:  0.06150437891483307
Valid Loss:  0.06337679177522659
Epoch:  105  	Training Loss: 0.05876380205154419
Test Loss:  0.0614604651927948
Valid Loss:  0.06333400309085846
Epoch:  106  	Training Loss: 0.05872403830289841
Test Loss:  0.06141660735011101
Valid Loss:  0.06329122185707092
Epoch:  107  	Training Loss: 0.05868431180715561
Test Loss:  0.0613727793097496
Valid Loss:  0.06324850022792816
Epoch:  108  	Training Loss: 0.05864458158612251
Test Loss:  0.0613289400935173
Valid Loss:  0.06320581585168839
Epoch:  109  	Training Loss: 0.058604899793863297
Test Loss:  0.06128513440489769
Valid Loss:  0.06316305696964264
Epoch:  110  	Training Loss: 0.05856519192457199
Test Loss:  0.06124135106801987
Valid Loss:  0.06312037259340286
Epoch:  111  	Training Loss: 0.058525510132312775
Test Loss:  0.06119759380817413
Valid Loss:  0.06307767331600189
Epoch:  112  	Training Loss: 0.05848587304353714
Test Loss:  0.061155740171670914
Valid Loss:  0.06303691864013672
Epoch:  113  	Training Loss: 0.0584479495882988
Test Loss:  0.061113931238651276
Valid Loss:  0.06299612671136856
Epoch:  114  	Training Loss: 0.058410078287124634
Test Loss:  0.061072126030921936
Valid Loss:  0.0629553496837616
Epoch:  115  	Training Loss: 0.05837221443653107
Test Loss:  0.06103038787841797
Valid Loss:  0.0629146546125412
Epoch:  116  	Training Loss: 0.058334361761808395
Test Loss:  0.060988649725914
Valid Loss:  0.06287392973899841
Epoch:  117  	Training Loss: 0.058296553790569305
Test Loss:  0.06094690412282944
Valid Loss:  0.06283323466777802
Epoch:  118  	Training Loss: 0.05825872719287872
Test Loss:  0.06090525537729263
Valid Loss:  0.06279262155294418
Epoch:  119  	Training Loss: 0.058220963925123215
Test Loss:  0.060863591730594635
Valid Loss:  0.06275199353694916
Epoch:  120  	Training Loss: 0.0581832155585289
Test Loss:  0.060821957886219025
Valid Loss:  0.06271137297153473
Epoch:  121  	Training Loss: 0.058145470917224884
Test Loss:  0.06078031659126282
Valid Loss:  0.0626707673072815
Epoch:  122  	Training Loss: 0.05810776725411415
Test Loss:  0.060742683708667755
Valid Loss:  0.06263401359319687
Epoch:  123  	Training Loss: 0.05807357281446457
Test Loss:  0.060705021023750305
Valid Loss:  0.06259730458259583
Epoch:  124  	Training Loss: 0.05803941935300827
Test Loss:  0.06066740304231644
Valid Loss:  0.06256057322025299
Epoch:  125  	Training Loss: 0.058005303144454956
Test Loss:  0.06062981113791466
Valid Loss:  0.06252391636371613
Epoch:  126  	Training Loss: 0.05797119066119194
Test Loss:  0.060592249035835266
Valid Loss:  0.062487270683050156
Epoch:  127  	Training Loss: 0.05793711170554161
Test Loss:  0.06055479496717453
Valid Loss:  0.06245064735412598
Epoch:  128  	Training Loss: 0.05790310353040695
Test Loss:  0.060517288744449615
Valid Loss:  0.06241408362984657
Epoch:  129  	Training Loss: 0.0578690841794014
Test Loss:  0.060479890555143356
Valid Loss:  0.06237752363085747
Epoch:  130  	Training Loss: 0.057835131883621216
Test Loss:  0.06044243648648262
Valid Loss:  0.06234101578593254
Epoch:  131  	Training Loss: 0.057801175862550735
Test Loss:  0.06040508672595024
Valid Loss:  0.0623045489192009
Epoch:  132  	Training Loss: 0.05776726081967354
Test Loss:  0.060361288487911224
Valid Loss:  0.06226189061999321
Epoch:  133  	Training Loss: 0.0577276274561882
Test Loss:  0.060317542403936386
Valid Loss:  0.06221922114491463
Epoch:  134  	Training Loss: 0.057687997817993164
Test Loss:  0.06027381867170334
Valid Loss:  0.06217661872506142
Epoch:  135  	Training Loss: 0.05764840543270111
Test Loss:  0.06023009866476059
Valid Loss:  0.06213398277759552
Epoch:  136  	Training Loss: 0.05760879069566727
Test Loss:  0.06018642336130142
Valid Loss:  0.06209135055541992
Epoch:  137  	Training Loss: 0.057569246739149094
Test Loss:  0.06014274060726166
Valid Loss:  0.06204879283905029
Epoch:  138  	Training Loss: 0.05752968788146973
Test Loss:  0.060099102556705475
Valid Loss:  0.06200627237558365
Epoch:  139  	Training Loss: 0.057490140199661255
Test Loss:  0.0600554384291172
Valid Loss:  0.061963729560375214
Epoch:  140  	Training Loss: 0.057450637221336365
Test Loss:  0.0600118413567543
Valid Loss:  0.06192122399806976
Epoch:  141  	Training Loss: 0.057411156594753265
Test Loss:  0.05996827781200409
Valid Loss:  0.06187870353460312
Epoch:  142  	Training Loss: 0.057371675968170166
Test Loss:  0.05993117392063141
Valid Loss:  0.06184251978993416
Epoch:  143  	Training Loss: 0.05733804404735565
Test Loss:  0.05989409238100052
Valid Loss:  0.0618063285946846
Epoch:  144  	Training Loss: 0.05730442702770233
Test Loss:  0.059857044368982315
Valid Loss:  0.061770178377628326
 29%|██▉       | 145/500 [01:43<03:38,  1.63it/s] 29%|██▉       | 147/500 [01:43<02:38,  2.22it/s] 30%|██▉       | 149/500 [01:43<01:57,  2.98it/s] 30%|███       | 151/500 [01:50<06:58,  1.20s/it] 31%|███       | 153/500 [01:50<04:58,  1.16it/s] 31%|███       | 155/500 [01:50<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:50<02:35,  2.20it/s] 32%|███▏      | 159/500 [01:50<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:57<06:39,  1.18s/it] 33%|███▎      | 163/500 [01:57<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:57<03:28,  1.61it/s] 33%|███▎      | 167/500 [01:57<02:33,  2.17it/s] 34%|███▍      | 169/500 [01:57<01:55,  2.87it/s] 34%|███▍      | 171/500 [02:04<06:35,  1.20s/it] 35%|███▍      | 173/500 [02:04<04:41,  1.16it/s] 35%|███▌      | 175/500 [02:04<03:22,  1.60it/s] 35%|███▌      | 177/500 [02:04<02:27,  2.20it/s] 36%|███▌      | 179/500 [02:04<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:10<06:18,  1.19s/it] 36%|███▋      | 182/500 [02:11<05:16,  1.00it/s] 37%|███▋      | 184/500 [02:11<03:37,  1.45it/s] 37%|███▋      | 186/500 [02:11<02:34,  2.03it/s] 38%|███▊      | 188/500 [02:11<01:53,  2.75it/s] 38%|███▊      | 190/500 [02:11<01:25,  3.61it/s] 38%|███▊      | 192/500 [02:18<06:03,  1.18s/it] 39%|███▉      | 194/500 [02:18<04:16,  1.19it/s] 39%|███▉      | 196/500 [02:18<03:03,  1.66it/s] 40%|███▉      | 198/500 [02:18<02:13,  2.27it/s] 40%|████      | 200/500 [02:18<01:38,  3.05it/s] 40%|████      | 202/500 [02:24<05:51,  1.18s/it] 41%|████      | 204/500 [02:25<04:09,  1.18it/s] 41%|████      | 206/500 [02:25<02:59,  1.64it/s] 42%|████▏     | 208/500 [02:25<02:10,  2.23it/s] 42%|████▏     | 210/500 [02:25<01:36,  3.00it/s] 42%|████▏     | 212/500 [02:31<05:37,  1.17s/it] 43%|████▎     | 214/500 [02:31<04:01,  1.19it/s]Epoch:  145  	Training Loss: 0.057270824909210205
Test Loss:  0.05982004106044769
Valid Loss:  0.06173398345708847
Epoch:  146  	Training Loss: 0.057237230241298676
Test Loss:  0.059783004224300385
Valid Loss:  0.061697818338871
Epoch:  147  	Training Loss: 0.05720367282629013
Test Loss:  0.05974602699279785
Valid Loss:  0.06166175752878189
Epoch:  148  	Training Loss: 0.05717012658715248
Test Loss:  0.0597090870141983
Valid Loss:  0.0616256520152092
Epoch:  149  	Training Loss: 0.05713660269975662
Test Loss:  0.05967213958501816
Valid Loss:  0.061589568853378296
Epoch:  150  	Training Loss: 0.05710311233997345
Test Loss:  0.05963524430990219
Valid Loss:  0.06155349686741829
Epoch:  151  	Training Loss: 0.05706964433193207
Test Loss:  0.059598326683044434
Valid Loss:  0.06151749566197395
Epoch:  152  	Training Loss: 0.057036176323890686
Test Loss:  0.05956472083926201
Valid Loss:  0.06148470938205719
Epoch:  153  	Training Loss: 0.05700566619634628
Test Loss:  0.05953112244606018
Valid Loss:  0.06145191565155983
Epoch:  154  	Training Loss: 0.056975189596414566
Test Loss:  0.05949757248163223
Valid Loss:  0.06141914799809456
Epoch:  155  	Training Loss: 0.05694476142525673
Test Loss:  0.059464022517204285
Valid Loss:  0.061386432498693466
Epoch:  156  	Training Loss: 0.05691435933113098
Test Loss:  0.05943061038851738
Valid Loss:  0.06135375052690506
Epoch:  157  	Training Loss: 0.05688396096229553
Test Loss:  0.059397123754024506
Valid Loss:  0.061321064829826355
Epoch:  158  	Training Loss: 0.05685361847281456
Test Loss:  0.059363704174757004
Valid Loss:  0.06128844991326332
Epoch:  159  	Training Loss: 0.05682329833507538
Test Loss:  0.05933033302426338
Valid Loss:  0.061255864799022675
Epoch:  160  	Training Loss: 0.05679301172494888
Test Loss:  0.05929698795080185
Valid Loss:  0.061223287135362625
Epoch:  161  	Training Loss: 0.056762758642435074
Test Loss:  0.059263672679662704
Valid Loss:  0.06119074672460556
Epoch:  162  	Training Loss: 0.05673251301050186
Test Loss:  0.05922696366906166
Valid Loss:  0.06115494668483734
Epoch:  163  	Training Loss: 0.056699249893426895
Test Loss:  0.05919027328491211
Valid Loss:  0.06111915409564972
Epoch:  164  	Training Loss: 0.05666602402925491
Test Loss:  0.05915363132953644
Valid Loss:  0.06108339875936508
Epoch:  165  	Training Loss: 0.056632790714502335
Test Loss:  0.05911700055003166
Valid Loss:  0.061047669500112534
Epoch:  166  	Training Loss: 0.05659962445497513
Test Loss:  0.05908043310046196
Valid Loss:  0.06101192906498909
Epoch:  167  	Training Loss: 0.05656646564602852
Test Loss:  0.059043895453214645
Valid Loss:  0.06097627431154251
Epoch:  168  	Training Loss: 0.056533314287662506
Test Loss:  0.05900734290480614
Valid Loss:  0.06094060838222504
Epoch:  169  	Training Loss: 0.05650020390748978
Test Loss:  0.058970801532268524
Valid Loss:  0.060904987156391144
Epoch:  170  	Training Loss: 0.056467123329639435
Test Loss:  0.05893436074256897
Valid Loss:  0.060869406908750534
Epoch:  171  	Training Loss: 0.05643407255411148
Test Loss:  0.058897849172353745
Valid Loss:  0.060833826661109924
Epoch:  172  	Training Loss: 0.056401047855615616
Test Loss:  0.05886135995388031
Valid Loss:  0.060798197984695435
Epoch:  173  	Training Loss: 0.05636793375015259
Test Loss:  0.05882482975721359
Valid Loss:  0.06076255440711975
Epoch:  174  	Training Loss: 0.056334856897592545
Test Loss:  0.05878834426403046
Valid Loss:  0.06072697415947914
Epoch:  175  	Training Loss: 0.0563017874956131
Test Loss:  0.05875182896852493
Valid Loss:  0.06069140136241913
Epoch:  176  	Training Loss: 0.05626874789595604
Test Loss:  0.05871544033288956
Valid Loss:  0.06065582484006882
Epoch:  177  	Training Loss: 0.05623576045036316
Test Loss:  0.058679018169641495
Valid Loss:  0.06062029302120209
Epoch:  178  	Training Loss: 0.05620275437831879
Test Loss:  0.05864263325929642
Valid Loss:  0.06058478355407715
Epoch:  179  	Training Loss: 0.0561697855591774
Test Loss:  0.05860625579953194
Valid Loss:  0.0605493038892746
Epoch:  180  	Training Loss: 0.056136853992938995
Test Loss:  0.05856999009847641
Valid Loss:  0.06051384657621384
Epoch:  181  	Training Loss: 0.05610395222902298
Test Loss:  0.058533646166324615
Valid Loss:  0.060478441417217255
Epoch:  182  	Training Loss: 0.05607107654213905
Test Loss:  0.05849660560488701
Valid Loss:  0.06044228374958038
Epoch:  183  	Training Loss: 0.05603749677538872
Test Loss:  0.05845961719751358
Valid Loss:  0.060406189411878586
Epoch:  184  	Training Loss: 0.056003935635089874
Test Loss:  0.058422621339559555
Valid Loss:  0.060370072722435
Epoch:  185  	Training Loss: 0.05597042292356491
Test Loss:  0.05838563293218613
Valid Loss:  0.06033399701118469
Epoch:  186  	Training Loss: 0.05593693628907204
Test Loss:  0.05834873765707016
Valid Loss:  0.06029798835515976
Epoch:  187  	Training Loss: 0.05590348690748215
Test Loss:  0.05831185728311539
Valid Loss:  0.06026199460029602
Epoch:  188  	Training Loss: 0.05587005242705345
Test Loss:  0.05827496945858002
Valid Loss:  0.060226015746593475
Epoch:  189  	Training Loss: 0.05583663657307625
Test Loss:  0.058238107711076736
Valid Loss:  0.0601901113986969
Epoch:  190  	Training Loss: 0.05580328032374382
Test Loss:  0.05820136517286301
Valid Loss:  0.060154229402542114
Epoch:  191  	Training Loss: 0.055769942700862885
Test Loss:  0.05816461145877838
Valid Loss:  0.06011832132935524
Epoch:  192  	Training Loss: 0.055736660957336426
Test Loss:  0.05812608450651169
Valid Loss:  0.060080740600824356
Epoch:  193  	Training Loss: 0.05570176988840103
Test Loss:  0.0580875501036644
Valid Loss:  0.060043200850486755
Epoch:  194  	Training Loss: 0.05566692352294922
Test Loss:  0.05804909020662308
Valid Loss:  0.060005661100149155
Epoch:  195  	Training Loss: 0.05563207343220711
Test Loss:  0.058010563254356384
Valid Loss:  0.05996810644865036
Epoch:  196  	Training Loss: 0.05559724569320679
Test Loss:  0.05797211080789566
Valid Loss:  0.05993060767650604
Epoch:  197  	Training Loss: 0.05556245893239975
Test Loss:  0.05793367326259613
Valid Loss:  0.05989309400320053
Epoch:  198  	Training Loss: 0.055527687072753906
Test Loss:  0.05789526551961899
Valid Loss:  0.05985565483570099
Epoch:  199  	Training Loss: 0.05549293011426926
Test Loss:  0.05785680562257767
Valid Loss:  0.05981822311878204
Epoch:  200  	Training Loss: 0.055458176881074905
Test Loss:  0.057818420231342316
Valid Loss:  0.05978076532483101
Epoch:  201  	Training Loss: 0.05542343109846115
Test Loss:  0.05778009071946144
Valid Loss:  0.059743303805589676
Epoch:  202  	Training Loss: 0.05538873001933098
Test Loss:  0.05774719640612602
Valid Loss:  0.05971124768257141
Epoch:  203  	Training Loss: 0.055358923971652985
Test Loss:  0.05771433562040329
Valid Loss:  0.05967918038368225
Epoch:  204  	Training Loss: 0.055329158902168274
Test Loss:  0.057681530714035034
Valid Loss:  0.05964713543653488
Epoch:  205  	Training Loss: 0.05529942363500595
Test Loss:  0.05764876306056976
Valid Loss:  0.05961517244577408
Epoch:  206  	Training Loss: 0.055269695818424225
Test Loss:  0.0576159842312336
Valid Loss:  0.0595831498503685
Epoch:  207  	Training Loss: 0.05524002015590668
Test Loss:  0.057583242654800415
Valid Loss:  0.059551168233156204
Epoch:  208  	Training Loss: 0.055210359394550323
Test Loss:  0.0575505755841732
Valid Loss:  0.059519246220588684
Epoch:  209  	Training Loss: 0.05518070608377457
Test Loss:  0.05751786008477211
Valid Loss:  0.05948736146092415
Epoch:  210  	Training Loss: 0.05515110865235329
Test Loss:  0.05748520791530609
Valid Loss:  0.05945548415184021
Epoch:  211  	Training Loss: 0.0551215261220932
Test Loss:  0.057452596724033356
Valid Loss:  0.05942366272211075
Epoch:  212  	Training Loss: 0.055091965943574905
Test Loss:  0.057417407631874084
Valid Loss:  0.059389304369688034
Epoch:  213  	Training Loss: 0.055060118436813354
Test Loss:  0.05738220363855362
Valid Loss:  0.05935504287481308
Epoch:  214  	Training Loss: 0.055028293281793594
Test Loss:  0.05734711512923241
Valid Loss:  0.05932077765464783
Epoch:  215  	Training Loss: 0.05499648302793503
Test Loss:  0.05731193721294403
Valid Loss:  0.059286508709192276
Epoch:  216  	Training Loss: 0.05496469885110855 43%|████▎     | 216/500 [02:32<02:53,  1.64it/s] 44%|████▎     | 218/500 [02:32<02:05,  2.24it/s] 44%|████▍     | 220/500 [02:32<01:33,  3.01it/s] 44%|████▍     | 222/500 [02:38<05:29,  1.19s/it] 45%|████▍     | 224/500 [02:38<03:54,  1.18it/s] 45%|████▌     | 226/500 [02:38<02:48,  1.63it/s] 46%|████▌     | 228/500 [02:39<02:02,  2.22it/s] 46%|████▌     | 230/500 [02:39<01:30,  2.99it/s] 46%|████▋     | 232/500 [02:45<05:14,  1.17s/it] 47%|████▋     | 234/500 [02:45<03:43,  1.19it/s] 47%|████▋     | 236/500 [02:45<02:40,  1.64it/s] 48%|████▊     | 238/500 [02:45<01:57,  2.23it/s] 48%|████▊     | 240/500 [02:46<01:27,  2.98it/s] 48%|████▊     | 242/500 [02:52<05:08,  1.20s/it] 49%|████▉     | 244/500 [02:52<03:39,  1.17it/s] 49%|████▉     | 246/500 [02:52<02:37,  1.61it/s] 50%|████▉     | 248/500 [02:52<01:54,  2.20it/s] 50%|█████     | 250/500 [02:52<01:24,  2.96it/s] 50%|█████     | 252/500 [02:59<04:53,  1.18s/it] 51%|█████     | 254/500 [02:59<03:28,  1.18it/s] 51%|█████     | 256/500 [02:59<02:29,  1.63it/s] 52%|█████▏    | 258/500 [02:59<01:48,  2.23it/s] 52%|█████▏    | 260/500 [02:59<01:20,  3.00it/s] 52%|█████▏    | 262/500 [03:06<04:46,  1.20s/it] 53%|█████▎    | 264/500 [03:06<03:24,  1.15it/s] 53%|█████▎    | 266/500 [03:06<02:27,  1.59it/s] 54%|█████▎    | 268/500 [03:06<01:48,  2.14it/s] 54%|█████▍    | 270/500 [03:06<01:21,  2.84it/s] 54%|█████▍    | 272/500 [03:13<04:38,  1.22s/it] 55%|█████▍    | 274/500 [03:13<03:17,  1.14it/s] 55%|█████▌    | 276/500 [03:13<02:21,  1.58it/s] 56%|█████▌    | 278/500 [03:13<01:42,  2.16it/s] 56%|█████▌    | 280/500 [03:13<01:15,  2.91it/s] 56%|█████▋    | 282/500 [03:20<04:16,  1.18s/it] 57%|█████▋    | 284/500 [03:20<03:02,  1.19it/s] 57%|█████▋    | 286/500 [03:20<02:10,  1.64it/s]
Test Loss:  0.05727684497833252
Valid Loss:  0.05925227701663971
Epoch:  217  	Training Loss: 0.05493294820189476
Test Loss:  0.05724179744720459
Valid Loss:  0.05921804904937744
Epoch:  218  	Training Loss: 0.05490119755268097
Test Loss:  0.05720675364136696
Valid Loss:  0.05918389931321144
Epoch:  219  	Training Loss: 0.054869502782821655
Test Loss:  0.0571717694401741
Valid Loss:  0.05914974585175514
Epoch:  220  	Training Loss: 0.054837826639413834
Test Loss:  0.05713684856891632
Valid Loss:  0.059115614742040634
Epoch:  221  	Training Loss: 0.054806187748909
Test Loss:  0.05710192024707794
Valid Loss:  0.059081558138132095
Epoch:  222  	Training Loss: 0.054774560034275055
Test Loss:  0.05706411972641945
Valid Loss:  0.05904467776417732
Epoch:  223  	Training Loss: 0.05474040284752846
Test Loss:  0.05702634155750275
Valid Loss:  0.05900789052248001
Epoch:  224  	Training Loss: 0.05470622703433037
Test Loss:  0.056988611817359924
Valid Loss:  0.05897108465433121
Epoch:  225  	Training Loss: 0.05467209219932556
Test Loss:  0.0569508895277977
Valid Loss:  0.05893431603908539
Epoch:  226  	Training Loss: 0.054638005793094635
Test Loss:  0.05691320449113846
Valid Loss:  0.05889756232500076
Epoch:  227  	Training Loss: 0.054603926837444305
Test Loss:  0.056875549256801605
Valid Loss:  0.05886080861091614
Epoch:  228  	Training Loss: 0.05456986278295517
Test Loss:  0.056837908923625946
Valid Loss:  0.05882412940263748
Epoch:  229  	Training Loss: 0.05453583225607872
Test Loss:  0.05680029094219208
Valid Loss:  0.05878746509552002
Epoch:  230  	Training Loss: 0.05450180545449257
Test Loss:  0.056762684136629105
Valid Loss:  0.05875077471137047
Epoch:  231  	Training Loss: 0.054467834532260895
Test Loss:  0.05672513693571091
Valid Loss:  0.05871414393186569
Epoch:  232  	Training Loss: 0.054433852434158325
Test Loss:  0.05668928846716881
Valid Loss:  0.058679234236478806
Epoch:  233  	Training Loss: 0.0544014647603035
Test Loss:  0.05665352940559387
Valid Loss:  0.058644309639930725
Epoch:  234  	Training Loss: 0.05436909943819046
Test Loss:  0.05661781504750252
Valid Loss:  0.058609478175640106
Epoch:  235  	Training Loss: 0.05433676764369011
Test Loss:  0.05658211186528206
Valid Loss:  0.05857464671134949
Epoch:  236  	Training Loss: 0.05430450662970543
Test Loss:  0.056546468287706375
Valid Loss:  0.058539874851703644
Epoch:  237  	Training Loss: 0.05427221581339836
Test Loss:  0.05651088058948517
Valid Loss:  0.05850520730018616
Epoch:  238  	Training Loss: 0.054240092635154724
Test Loss:  0.05647537112236023
Valid Loss:  0.05847050994634628
Epoch:  239  	Training Loss: 0.0542079322040081
Test Loss:  0.056439828127622604
Valid Loss:  0.05843588337302208
Epoch:  240  	Training Loss: 0.054175809025764465
Test Loss:  0.056404344737529755
Valid Loss:  0.05840123072266579
Epoch:  241  	Training Loss: 0.05414370074868202
Test Loss:  0.05636882781982422
Valid Loss:  0.05836661905050278
Epoch:  242  	Training Loss: 0.054111629724502563
Test Loss:  0.05633321404457092
Valid Loss:  0.05833189934492111
Epoch:  243  	Training Loss: 0.05407937243580818
Test Loss:  0.056297607719898224
Valid Loss:  0.05829710513353348
Epoch:  244  	Training Loss: 0.05404715985059738
Test Loss:  0.056262023746967316
Valid Loss:  0.05826246365904808
Epoch:  245  	Training Loss: 0.054015014320611954
Test Loss:  0.056226447224617004
Valid Loss:  0.0582277774810791
Epoch:  246  	Training Loss: 0.05398282781243324
Test Loss:  0.05619092285633087
Valid Loss:  0.058193087577819824
Epoch:  247  	Training Loss: 0.05395069345831871
Test Loss:  0.056155405938625336
Valid Loss:  0.05815844610333443
Epoch:  248  	Training Loss: 0.053918592631816864
Test Loss:  0.0561198927462101
Valid Loss:  0.058123838156461716
Epoch:  249  	Training Loss: 0.05388648808002472
Test Loss:  0.05608445405960083
Valid Loss:  0.0580892488360405
Epoch:  250  	Training Loss: 0.053854409605264664
Test Loss:  0.05604899674654007
Valid Loss:  0.05805469676852226
Epoch:  251  	Training Loss: 0.053822390735149384
Test Loss:  0.0560135543346405
Valid Loss:  0.058020107448101044
Epoch:  252  	Training Loss: 0.05379033833742142
Test Loss:  0.05597986280918121
Valid Loss:  0.057987213134765625
Epoch:  253  	Training Loss: 0.05375983193516731
Test Loss:  0.05594613403081894
Valid Loss:  0.057954300194978714
Epoch:  254  	Training Loss: 0.0537293367087841
Test Loss:  0.05591243878006935
Valid Loss:  0.057921405881643295
Epoch:  255  	Training Loss: 0.05369886755943298
Test Loss:  0.055878739804029465
Valid Loss:  0.05788855627179146
Epoch:  256  	Training Loss: 0.05366839841008186
Test Loss:  0.055845100432634354
Valid Loss:  0.0578557550907135
Epoch:  257  	Training Loss: 0.05363796651363373
Test Loss:  0.05581144988536835
Valid Loss:  0.05782296136021614
Epoch:  258  	Training Loss: 0.053607575595378876
Test Loss:  0.055777907371520996
Valid Loss:  0.05779015272855759
Epoch:  259  	Training Loss: 0.053577177226543427
Test Loss:  0.05574428662657738
Valid Loss:  0.057757385075092316
Epoch:  260  	Training Loss: 0.05354681238532066
Test Loss:  0.05571071803569794
Valid Loss:  0.05772469565272331
Epoch:  261  	Training Loss: 0.05351646617054939
Test Loss:  0.0556771494448185
Valid Loss:  0.05769193917512894
Epoch:  262  	Training Loss: 0.05348613113164902
Test Loss:  0.05564238131046295
Valid Loss:  0.05765797570347786
Epoch:  263  	Training Loss: 0.053454674780368805
Test Loss:  0.055607639253139496
Valid Loss:  0.05762413144111633
Epoch:  264  	Training Loss: 0.05342324078083038
Test Loss:  0.05557286739349365
Valid Loss:  0.057590194046497345
Epoch:  265  	Training Loss: 0.05339181050658226
Test Loss:  0.05553813651204109
Valid Loss:  0.05755630135536194
Epoch:  266  	Training Loss: 0.05336041748523712
Test Loss:  0.05550346523523331
Valid Loss:  0.057522453367710114
Epoch:  267  	Training Loss: 0.053329065442085266
Test Loss:  0.05546879023313522
Valid Loss:  0.057488661259412766
Epoch:  268  	Training Loss: 0.0532977394759655
Test Loss:  0.05543411523103714
Valid Loss:  0.05745481699705124
Epoch:  269  	Training Loss: 0.05326642468571663
Test Loss:  0.055399566888809204
Valid Loss:  0.057421062141656876
Epoch:  270  	Training Loss: 0.05323511362075806
Test Loss:  0.0553649440407753
Valid Loss:  0.0573873408138752
Epoch:  271  	Training Loss: 0.05320383608341217
Test Loss:  0.055330391973257065
Valid Loss:  0.05735361576080322
Epoch:  272  	Training Loss: 0.05317261070013046
Test Loss:  0.05529503524303436
Valid Loss:  0.057319141924381256
Epoch:  273  	Training Loss: 0.05314064770936966
Test Loss:  0.05525963753461838
Valid Loss:  0.05728466063737869
Epoch:  274  	Training Loss: 0.05310870707035065
Test Loss:  0.05522433668375015
Valid Loss:  0.057250261306762695
Epoch:  275  	Training Loss: 0.05307678505778313
Test Loss:  0.05518904700875282
Valid Loss:  0.05721583217382431
Epoch:  276  	Training Loss: 0.05304491147398949
Test Loss:  0.05515377223491669
Valid Loss:  0.05718143284320831
Epoch:  277  	Training Loss: 0.05301305651664734
Test Loss:  0.05511856824159622
Valid Loss:  0.057147055864334106
Epoch:  278  	Training Loss: 0.05298120155930519
Test Loss:  0.055083319544792175
Valid Loss:  0.057112693786621094
Epoch:  279  	Training Loss: 0.052949368953704834
Test Loss:  0.055048126727342606
Valid Loss:  0.05707838758826256
Epoch:  280  	Training Loss: 0.05291758105158806
Test Loss:  0.05501294508576393
Valid Loss:  0.057044096291065216
Epoch:  281  	Training Loss: 0.052885811775922775
Test Loss:  0.054977789521217346
Valid Loss:  0.05700979009270668
Epoch:  282  	Training Loss: 0.05285406857728958
Test Loss:  0.054940566420555115
Valid Loss:  0.05697350203990936
Epoch:  283  	Training Loss: 0.05282041057944298
Test Loss:  0.05490332096815109
Valid Loss:  0.05693721026182175
Epoch:  284  	Training Loss: 0.05278678610920906
Test Loss:  0.05486612021923065
Valid Loss:  0.056900933384895325
Epoch:  285  	Training Loss: 0.052753206342458725
Test Loss:  0.0548289529979229
Valid Loss:  0.056864719837903976
Epoch:  286  	Training Loss: 0.05271962285041809
Test Loss:  0.05479176342487335
Valid Loss:  0.05682844668626785
Epoch:  287  	Training Loss: 0.052686095237731934
Test Loss:  0.05475464090704918
Valid Loss:   58%|█████▊    | 288/500 [03:20<01:34,  2.24it/s] 58%|█████▊    | 290/500 [03:20<01:09,  3.01it/s] 58%|█████▊    | 292/500 [03:26<04:01,  1.16s/it] 59%|█████▉    | 294/500 [03:27<02:52,  1.19it/s] 59%|█████▉    | 296/500 [03:27<02:04,  1.63it/s] 60%|█████▉    | 298/500 [03:27<01:30,  2.23it/s] 60%|██████    | 300/500 [03:27<01:06,  3.00it/s] 60%|██████    | 302/500 [03:33<03:51,  1.17s/it] 61%|██████    | 304/500 [03:33<02:44,  1.19it/s] 61%|██████    | 306/500 [03:34<01:57,  1.65it/s] 62%|██████▏   | 308/500 [03:34<01:25,  2.25it/s] 62%|██████▏   | 310/500 [03:34<01:02,  3.03it/s] 62%|██████▏   | 312/500 [03:40<03:39,  1.17s/it] 63%|██████▎   | 314/500 [03:40<02:35,  1.19it/s] 63%|██████▎   | 316/500 [03:40<01:52,  1.64it/s] 64%|██████▎   | 318/500 [03:40<01:21,  2.24it/s] 64%|██████▍   | 320/500 [03:41<00:59,  3.01it/s] 64%|██████▍   | 322/500 [03:47<03:30,  1.18s/it] 65%|██████▍   | 324/500 [03:47<02:29,  1.18it/s] 65%|██████▌   | 326/500 [03:47<01:46,  1.63it/s] 66%|██████▌   | 328/500 [03:47<01:17,  2.23it/s] 66%|██████▌   | 330/500 [03:47<00:56,  3.00it/s] 66%|██████▋   | 332/500 [03:54<03:18,  1.18s/it] 67%|██████▋   | 334/500 [03:54<02:20,  1.18it/s] 67%|██████▋   | 336/500 [03:54<01:40,  1.63it/s] 68%|██████▊   | 338/500 [03:54<01:13,  2.20it/s] 68%|██████▊   | 340/500 [03:54<00:54,  2.93it/s] 68%|██████▊   | 342/500 [04:01<03:07,  1.19s/it] 69%|██████▉   | 344/500 [04:01<02:12,  1.18it/s] 69%|██████▉   | 346/500 [04:01<01:34,  1.63it/s] 70%|██████▉   | 348/500 [04:01<01:08,  2.22it/s] 70%|███████   | 350/500 [04:01<00:50,  2.99it/s] 70%|███████   | 352/500 [04:07<02:53,  1.17s/it] 71%|███████   | 354/500 [04:08<02:02,  1.19it/s] 71%|███████   | 356/500 [04:08<01:27,  1.65it/s] 72%|███████▏  | 358/500 [04:08<01:03,  2.25it/s]0.056792281568050385
Epoch:  288  	Training Loss: 0.05265255272388458
Test Loss:  0.0547175407409668
Valid Loss:  0.056756068021059036
Epoch:  289  	Training Loss: 0.05261905491352081
Test Loss:  0.054680466651916504
Valid Loss:  0.056719936430454254
Epoch:  290  	Training Loss: 0.052585575729608536
Test Loss:  0.05464336276054382
Valid Loss:  0.05668378993868828
Epoch:  291  	Training Loss: 0.052552107721567154
Test Loss:  0.05460633337497711
Valid Loss:  0.05664769932627678
Epoch:  292  	Training Loss: 0.052518654614686966
Test Loss:  0.05456911027431488
Valid Loss:  0.056611426174640656
Epoch:  293  	Training Loss: 0.052485086023807526
Test Loss:  0.054531946778297424
Valid Loss:  0.05657513439655304
Epoch:  294  	Training Loss: 0.052451517432928085
Test Loss:  0.054494794458150864
Valid Loss:  0.05653894692659378
Epoch:  295  	Training Loss: 0.05241798236966133
Test Loss:  0.0544576421380043
Valid Loss:  0.05650273337960243
Epoch:  296  	Training Loss: 0.052384473383426666
Test Loss:  0.05442057177424431
Valid Loss:  0.05646650865674019
Epoch:  297  	Training Loss: 0.0523509681224823
Test Loss:  0.05438344180583954
Valid Loss:  0.05643041804432869
Epoch:  298  	Training Loss: 0.05231746658682823
Test Loss:  0.054346341639757156
Valid Loss:  0.05639418959617615
Epoch:  299  	Training Loss: 0.052284013479948044
Test Loss:  0.05430934205651283
Valid Loss:  0.05635814368724823
Epoch:  300  	Training Loss: 0.05225057154893875
Test Loss:  0.05427228659391403
Valid Loss:  0.056322015821933746
Epoch:  301  	Training Loss: 0.052217140793800354
Test Loss:  0.05423526093363762
Valid Loss:  0.05628591030836105
Epoch:  302  	Training Loss: 0.05218372493982315
Test Loss:  0.054208964109420776
Valid Loss:  0.05626021325588226
Epoch:  303  	Training Loss: 0.05215989053249359
Test Loss:  0.05418270826339722
Valid Loss:  0.05623451620340347
Epoch:  304  	Training Loss: 0.05213609337806702
Test Loss:  0.054156407713890076
Valid Loss:  0.05620891600847244
Epoch:  305  	Training Loss: 0.05211230367422104
Test Loss:  0.05413025990128517
Valid Loss:  0.0561833418905735
Epoch:  306  	Training Loss: 0.05208861082792282
Test Loss:  0.05410414934158325
Valid Loss:  0.05615776777267456
Epoch:  307  	Training Loss: 0.05206494778394699
Test Loss:  0.05407804250717163
Valid Loss:  0.05613228678703308
Epoch:  308  	Training Loss: 0.05204130709171295
Test Loss:  0.05405198782682419
Valid Loss:  0.056106775999069214
Epoch:  309  	Training Loss: 0.052017681300640106
Test Loss:  0.05402591452002525
Valid Loss:  0.056081373244524
Epoch:  310  	Training Loss: 0.05199410766363144
Test Loss:  0.0539998933672905
Valid Loss:  0.0560559444129467
Epoch:  311  	Training Loss: 0.051970548927783966
Test Loss:  0.05397391319274902
Valid Loss:  0.05603054165840149
Epoch:  312  	Training Loss: 0.051947012543678284
Test Loss:  0.053942449390888214
Valid Loss:  0.055999863892793655
Epoch:  313  	Training Loss: 0.05191858857870102
Test Loss:  0.05391105264425278
Valid Loss:  0.05596919357776642
Epoch:  314  	Training Loss: 0.05189017951488495
Test Loss:  0.053879618644714355
Valid Loss:  0.05593859776854515
Epoch:  315  	Training Loss: 0.051861830055713654
Test Loss:  0.0538482628762722
Valid Loss:  0.055907972157001495
Epoch:  316  	Training Loss: 0.051833465695381165
Test Loss:  0.05381692945957184
Valid Loss:  0.055877406150102615
Epoch:  317  	Training Loss: 0.05180513858795166
Test Loss:  0.05378558859229088
Valid Loss:  0.05584682524204254
Epoch:  318  	Training Loss: 0.051776837557554245
Test Loss:  0.05375426262617111
Valid Loss:  0.055816300213336945
Epoch:  319  	Training Loss: 0.051748573780059814
Test Loss:  0.053723033517599106
Valid Loss:  0.05578579381108284
Epoch:  320  	Training Loss: 0.051720328629016876
Test Loss:  0.0536918044090271
Valid Loss:  0.05575529485940933
Epoch:  321  	Training Loss: 0.05169210582971573
Test Loss:  0.053660571575164795
Valid Loss:  0.0557248517870903
Epoch:  322  	Training Loss: 0.05166390538215637
Test Loss:  0.053629472851753235
Valid Loss:  0.05569450184702873
Epoch:  323  	Training Loss: 0.05163579434156418
Test Loss:  0.05359839275479317
Valid Loss:  0.05566418915987015
Epoch:  324  	Training Loss: 0.05160772055387497
Test Loss:  0.05356733873486519
Valid Loss:  0.055633917450904846
Epoch:  325  	Training Loss: 0.05157965421676636
Test Loss:  0.05353635549545288
Valid Loss:  0.05560361593961716
Epoch:  326  	Training Loss: 0.05155162140727043
Test Loss:  0.0535053052008152
Valid Loss:  0.05557337775826454
Epoch:  327  	Training Loss: 0.05152361840009689
Test Loss:  0.0534743070602417
Valid Loss:  0.05554314702749252
Epoch:  328  	Training Loss: 0.051495615392923355
Test Loss:  0.05344333499670029
Valid Loss:  0.0555129237473011
Epoch:  329  	Training Loss: 0.051467638462781906
Test Loss:  0.053412407636642456
Valid Loss:  0.05548272654414177
Epoch:  330  	Training Loss: 0.05143969506025314
Test Loss:  0.05338148772716522
Valid Loss:  0.05545256286859512
Epoch:  331  	Training Loss: 0.05141177773475647
Test Loss:  0.053350623697042465
Valid Loss:  0.05542244017124176
Epoch:  332  	Training Loss: 0.05138389393687248
Test Loss:  0.053315091878175735
Valid Loss:  0.05538775026798248
Epoch:  333  	Training Loss: 0.05135180056095123
Test Loss:  0.05327950417995453
Valid Loss:  0.05535311624407768
Epoch:  334  	Training Loss: 0.05131973698735237
Test Loss:  0.0532439649105072
Valid Loss:  0.05531842261552811
Epoch:  335  	Training Loss: 0.05128766596317291
Test Loss:  0.053208447992801666
Valid Loss:  0.05528382584452629
Epoch:  336  	Training Loss: 0.05125565081834793
Test Loss:  0.05317295342683792
Valid Loss:  0.05524923652410507
Epoch:  337  	Training Loss: 0.05122361704707146
Test Loss:  0.05313742905855179
Valid Loss:  0.05521465092897415
Epoch:  338  	Training Loss: 0.05119160935282707
Test Loss:  0.05310199409723282
Valid Loss:  0.05518007650971413
Epoch:  339  	Training Loss: 0.05115964263677597
Test Loss:  0.05306650698184967
Valid Loss:  0.05514553189277649
Epoch:  340  	Training Loss: 0.05112766474485397
Test Loss:  0.05303110554814339
Valid Loss:  0.05511099472641945
Epoch:  341  	Training Loss: 0.051095716655254364
Test Loss:  0.05299568176269531
Valid Loss:  0.05507649853825569
Epoch:  342  	Training Loss: 0.05106379836797714
Test Loss:  0.05296102166175842
Valid Loss:  0.05504266917705536
Epoch:  343  	Training Loss: 0.05103253945708275
Test Loss:  0.05292632430791855
Valid Loss:  0.05500894784927368
Epoch:  344  	Training Loss: 0.05100128799676895
Test Loss:  0.05289169028401375
Valid Loss:  0.054975155740976334
Epoch:  345  	Training Loss: 0.05097004771232605
Test Loss:  0.052857063710689545
Valid Loss:  0.05494139716029167
Epoch:  346  	Training Loss: 0.050938818603754044
Test Loss:  0.052822455763816833
Valid Loss:  0.054907649755477905
Epoch:  347  	Training Loss: 0.050907619297504425
Test Loss:  0.052787937223911285
Valid Loss:  0.05487396568059921
Epoch:  348  	Training Loss: 0.05087645351886749
Test Loss:  0.05275334045290947
Valid Loss:  0.05484028905630112
Epoch:  349  	Training Loss: 0.05084531009197235
Test Loss:  0.0527188666164875
Valid Loss:  0.05480664595961571
Epoch:  350  	Training Loss: 0.050814177840948105
Test Loss:  0.05268436670303345
Valid Loss:  0.05477307736873627
Epoch:  351  	Training Loss: 0.05078309029340744
Test Loss:  0.05264994502067566
Valid Loss:  0.05473949387669563
Epoch:  352  	Training Loss: 0.05075203627347946
Test Loss:  0.052618663758039474
Valid Loss:  0.05470900237560272
Epoch:  353  	Training Loss: 0.05072379112243652
Test Loss:  0.05258738994598389
Valid Loss:  0.0546785406768322
Epoch:  354  	Training Loss: 0.05069557577371597
Test Loss:  0.052556153386831284
Valid Loss:  0.05464804172515869
Epoch:  355  	Training Loss: 0.05066738650202751
Test Loss:  0.052524976432323456
Valid Loss:  0.054617591202259064
Epoch:  356  	Training Loss: 0.050639234483242035
Test Loss:  0.05249377340078354
Valid Loss:  0.05458717420697212
Epoch:  357  	Training Loss: 0.05061108618974686
Test Loss:  0.0524626225233078
Valid Loss:  0.05455676466226578
Epoch:  358  	Training Loss: 0.05058295279741287
Test Loss:  0.05243147909641266
Valid Loss:  0.05452638864517212
 72%|███████▏  | 360/500 [04:08<00:46,  3.01it/s] 72%|███████▏  | 362/500 [04:14<02:41,  1.17s/it] 73%|███████▎  | 364/500 [04:14<01:53,  1.19it/s] 73%|███████▎  | 366/500 [04:14<01:21,  1.65it/s] 74%|███████▎  | 368/500 [04:15<00:58,  2.25it/s] 74%|███████▍  | 370/500 [04:15<00:42,  3.03it/s] 74%|███████▍  | 372/500 [04:21<02:30,  1.17s/it] 75%|███████▍  | 374/500 [04:21<01:45,  1.19it/s] 75%|███████▌  | 376/500 [04:21<01:15,  1.64it/s] 76%|███████▌  | 378/500 [04:21<00:55,  2.20it/s] 76%|███████▌  | 380/500 [04:22<00:40,  2.94it/s] 76%|███████▋  | 382/500 [04:28<02:20,  1.19s/it] 77%|███████▋  | 384/500 [04:28<01:38,  1.17it/s] 77%|███████▋  | 386/500 [04:28<01:10,  1.62it/s] 78%|███████▊  | 388/500 [04:28<00:50,  2.22it/s] 78%|███████▊  | 390/500 [04:28<00:36,  2.98it/s] 78%|███████▊  | 392/500 [04:35<02:05,  1.16s/it] 79%|███████▉  | 394/500 [04:35<01:28,  1.20it/s] 79%|███████▉  | 396/500 [04:35<01:02,  1.65it/s] 80%|███████▉  | 398/500 [04:35<00:45,  2.26it/s] 80%|████████  | 400/500 [04:35<00:33,  3.02it/s] 80%|████████  | 402/500 [04:41<01:53,  1.16s/it] 81%|████████  | 404/500 [04:42<01:19,  1.20it/s] 81%|████████  | 406/500 [04:42<00:56,  1.66it/s] 82%|████████▏ | 408/500 [04:42<00:40,  2.27it/s] 82%|████████▏ | 410/500 [04:42<00:29,  3.05it/s] 82%|████████▏ | 412/500 [04:48<01:44,  1.19s/it] 83%|████████▎ | 414/500 [04:48<01:13,  1.18it/s] 83%|████████▎ | 416/500 [04:49<00:51,  1.62it/s] 84%|████████▎ | 418/500 [04:49<00:37,  2.21it/s] 84%|████████▍ | 420/500 [04:49<00:26,  2.97it/s] 84%|████████▍ | 422/500 [04:55<01:31,  1.17s/it] 85%|████████▍ | 424/500 [04:55<01:03,  1.19it/s] 85%|████████▌ | 426/500 [04:55<00:45,  1.64it/s] 86%|████████▌ | 428/500 [04:55<00:32,  2.24it/s]Epoch:  359  	Training Loss: 0.05055485665798187
Test Loss:  0.05240039899945259
Valid Loss:  0.05449603870511055
Epoch:  360  	Training Loss: 0.050526753067970276
Test Loss:  0.052369289100170135
Valid Loss:  0.054465703666210175
Epoch:  361  	Training Loss: 0.05049867928028107
Test Loss:  0.05233822390437126
Valid Loss:  0.054435379803180695
Epoch:  362  	Training Loss: 0.05047064274549484
Test Loss:  0.05230732262134552
Valid Loss:  0.05440519005060196
Epoch:  363  	Training Loss: 0.050442710518836975
Test Loss:  0.05227635055780411
Valid Loss:  0.054375045001506805
Epoch:  364  	Training Loss: 0.050414834171533585
Test Loss:  0.05224546417593956
Valid Loss:  0.05434494465589523
Epoch:  365  	Training Loss: 0.0503869503736496
Test Loss:  0.052214615046978
Valid Loss:  0.05431484431028366
Epoch:  366  	Training Loss: 0.05035912245512009
Test Loss:  0.05218379199504852
Valid Loss:  0.05428479611873627
Epoch:  367  	Training Loss: 0.05033133178949356
Test Loss:  0.05215302109718323
Valid Loss:  0.05425478518009186
Epoch:  368  	Training Loss: 0.05030353367328644
Test Loss:  0.052122198045253754
Valid Loss:  0.05422475188970566
Epoch:  369  	Training Loss: 0.05027570575475693
Test Loss:  0.05209136754274368
Valid Loss:  0.05419465899467468
Epoch:  370  	Training Loss: 0.0502479188144207
Test Loss:  0.05206058546900749
Valid Loss:  0.054164592176675797
Epoch:  371  	Training Loss: 0.050220124423503876
Test Loss:  0.05202983319759369
Valid Loss:  0.05413462594151497
Epoch:  372  	Training Loss: 0.05019237846136093
Test Loss:  0.051999494433403015
Valid Loss:  0.054105013608932495
Epoch:  373  	Training Loss: 0.050164997577667236
Test Loss:  0.05196916684508324
Valid Loss:  0.054075468331575394
Epoch:  374  	Training Loss: 0.05013763904571533
Test Loss:  0.05193888396024704
Valid Loss:  0.05404585599899292
Epoch:  375  	Training Loss: 0.050110261887311935
Test Loss:  0.05190858989953995
Valid Loss:  0.054016366600990295
Epoch:  376  	Training Loss: 0.0500829815864563
Test Loss:  0.05187830328941345
Valid Loss:  0.05398686230182648
Epoch:  377  	Training Loss: 0.050055697560310364
Test Loss:  0.05184812843799591
Valid Loss:  0.05395737290382385
Epoch:  378  	Training Loss: 0.05002842843532562
Test Loss:  0.05181793123483658
Valid Loss:  0.053927913308143616
Epoch:  379  	Training Loss: 0.05000118538737297
Test Loss:  0.05178771913051605
Valid Loss:  0.05389852076768875
Epoch:  380  	Training Loss: 0.049973953515291214
Test Loss:  0.051757581532001495
Valid Loss:  0.0538690984249115
Epoch:  381  	Training Loss: 0.04994673281908035
Test Loss:  0.051727451384067535
Valid Loss:  0.05383967608213425
Epoch:  382  	Training Loss: 0.04991959035396576
Test Loss:  0.05169716849923134
Valid Loss:  0.053810134530067444
Epoch:  383  	Training Loss: 0.049892228096723557
Test Loss:  0.051666852086782455
Valid Loss:  0.053780630230903625
Epoch:  384  	Training Loss: 0.049864910542964935
Test Loss:  0.05163660645484924
Valid Loss:  0.05375111103057861
Epoch:  385  	Training Loss: 0.04983760789036751
Test Loss:  0.051606349647045135
Valid Loss:  0.053721580654382706
Epoch:  386  	Training Loss: 0.04981033131480217
Test Loss:  0.05157611891627312
Valid Loss:  0.05369212105870247
Epoch:  387  	Training Loss: 0.04978308826684952
Test Loss:  0.05154597759246826
Valid Loss:  0.05366269871592522
Epoch:  388  	Training Loss: 0.04975586384534836
Test Loss:  0.05151581019163132
Valid Loss:  0.05363322049379349
Epoch:  389  	Training Loss: 0.0497286431491375
Test Loss:  0.05148569121956825
Valid Loss:  0.05360386148095131
Epoch:  390  	Training Loss: 0.049701444804668427
Test Loss:  0.05145560950040817
Valid Loss:  0.053574442863464355
Epoch:  391  	Training Loss: 0.04967429116368294
Test Loss:  0.051425501704216
Valid Loss:  0.05354510247707367
Epoch:  392  	Training Loss: 0.049647144973278046
Test Loss:  0.05139479413628578
Valid Loss:  0.05351514369249344
Epoch:  393  	Training Loss: 0.04961946979165077
Test Loss:  0.05136410519480705
Valid Loss:  0.05348522961139679
Epoch:  394  	Training Loss: 0.04959180951118469
Test Loss:  0.05133349448442459
Valid Loss:  0.05345539748668671
Epoch:  395  	Training Loss: 0.0495641864836216
Test Loss:  0.05130289867520332
Valid Loss:  0.05342555791139603
Epoch:  396  	Training Loss: 0.0495365746319294
Test Loss:  0.051272351294755936
Valid Loss:  0.053395748138427734
Epoch:  397  	Training Loss: 0.04950900375843048
Test Loss:  0.05124179273843765
Valid Loss:  0.05336598679423332
Epoch:  398  	Training Loss: 0.04948149994015694
Test Loss:  0.051211290061473846
Valid Loss:  0.053336240351200104
Epoch:  399  	Training Loss: 0.0494539737701416
Test Loss:  0.051180820912122726
Valid Loss:  0.053306519985198975
Epoch:  400  	Training Loss: 0.049426496028900146
Test Loss:  0.05115031450986862
Valid Loss:  0.05327680706977844
Epoch:  401  	Training Loss: 0.04939904436469078
Test Loss:  0.05111997574567795
Valid Loss:  0.0532471165060997
Epoch:  402  	Training Loss: 0.0493716299533844
Test Loss:  0.051087670028209686
Valid Loss:  0.053215622901916504
Epoch:  403  	Training Loss: 0.04934250935912132
Test Loss:  0.05105537176132202
Valid Loss:  0.053184159100055695
Epoch:  404  	Training Loss: 0.04931342229247093
Test Loss:  0.05102311819791794
Valid Loss:  0.05315274000167847
Epoch:  405  	Training Loss: 0.04928434640169144
Test Loss:  0.05099085718393326
Valid Loss:  0.05312127619981766
Epoch:  406  	Training Loss: 0.049255311489105225
Test Loss:  0.05095864087343216
Valid Loss:  0.05308982729911804
Epoch:  407  	Training Loss: 0.04922626167535782
Test Loss:  0.05092644691467285
Valid Loss:  0.053058430552482605
Epoch:  408  	Training Loss: 0.049197278916835785
Test Loss:  0.05089423432946205
Valid Loss:  0.053027063608169556
Epoch:  409  	Training Loss: 0.04916828125715256
Test Loss:  0.05086204782128334
Valid Loss:  0.052995726466178894
Epoch:  410  	Training Loss: 0.04913928359746933
Test Loss:  0.050829894840717316
Valid Loss:  0.052964404225349426
Epoch:  411  	Training Loss: 0.04911034554243088
Test Loss:  0.05079781636595726
Valid Loss:  0.052933111786842346
Epoch:  412  	Training Loss: 0.04908140003681183
Test Loss:  0.050767604261636734
Valid Loss:  0.0529036745429039
Epoch:  413  	Training Loss: 0.04905419051647186
Test Loss:  0.05073746293783188
Valid Loss:  0.052874237298965454
Epoch:  414  	Training Loss: 0.04902700334787369
Test Loss:  0.05070727691054344
Valid Loss:  0.052844829857349396
Epoch:  415  	Training Loss: 0.0489998385310173
Test Loss:  0.05067715793848038
Valid Loss:  0.052815452218055725
Epoch:  416  	Training Loss: 0.04897269234061241
Test Loss:  0.05064701288938522
Valid Loss:  0.052786052227020264
Epoch:  417  	Training Loss: 0.04894554615020752
Test Loss:  0.05061696469783783
Valid Loss:  0.052756741642951965
Epoch:  418  	Training Loss: 0.0489184632897377
Test Loss:  0.05058689042925835
Valid Loss:  0.052727460861206055
Epoch:  419  	Training Loss: 0.04889136925339699
Test Loss:  0.05055685341358185
Valid Loss:  0.05269809067249298
Epoch:  420  	Training Loss: 0.048864297568798065
Test Loss:  0.05052681267261505
Valid Loss:  0.052668891847133636
Epoch:  421  	Training Loss: 0.04883725196123123
Test Loss:  0.05049683153629303
Valid Loss:  0.05263959988951683
Epoch:  422  	Training Loss: 0.048810239881277084
Test Loss:  0.05046530067920685
Valid Loss:  0.05260888487100601
Epoch:  423  	Training Loss: 0.04878179728984833
Test Loss:  0.05043375492095947
Valid Loss:  0.052578121423721313
Epoch:  424  	Training Loss: 0.048753418028354645
Test Loss:  0.05040222406387329
Valid Loss:  0.0525473952293396
Epoch:  425  	Training Loss: 0.04872503876686096
Test Loss:  0.05037075653672218
Valid Loss:  0.052516765892505646
Epoch:  426  	Training Loss: 0.04869670048356056
Test Loss:  0.05033932626247406
Valid Loss:  0.05248606577515602
Epoch:  427  	Training Loss: 0.04866836965084076
Test Loss:  0.05030791088938713
Valid Loss:  0.05245537310838699
Epoch:  428  	Training Loss: 0.04864005371928215
Test Loss:  0.05027647316455841
Valid Loss:  0.05242478847503662
Epoch:  429  	Training Loss: 0.04861178249120712
Test Loss:  0.050245076417922974
Valid Loss:  0.05239417031407356
Epoch:  430  	Training Loss: 0.04858352988958359
 86%|████████▌ | 430/500 [04:56<00:23,  3.02it/s] 86%|████████▋ | 432/500 [05:02<01:19,  1.16s/it] 87%|████████▋ | 434/500 [05:02<00:54,  1.20it/s] 87%|████████▋ | 436/500 [05:02<00:38,  1.66it/s] 88%|████████▊ | 438/500 [05:02<00:27,  2.27it/s] 88%|████████▊ | 440/500 [05:02<00:19,  3.05it/s] 88%|████████▊ | 442/500 [05:09<01:07,  1.16s/it] 89%|████████▉ | 444/500 [05:09<00:46,  1.20it/s] 89%|████████▉ | 446/500 [05:09<00:32,  1.65it/s] 90%|████████▉ | 448/500 [05:09<00:23,  2.22it/s] 90%|█████████ | 450/500 [05:09<00:17,  2.93it/s] 90%|█████████ | 452/500 [05:15<00:56,  1.19s/it] 91%|█████████ | 454/500 [05:16<00:39,  1.18it/s] 91%|█████████ | 456/500 [05:16<00:27,  1.62it/s] 92%|█████████▏| 458/500 [05:16<00:19,  2.19it/s] 92%|█████████▏| 460/500 [05:16<00:13,  2.89it/s] 92%|█████████▏| 462/500 [05:22<00:45,  1.19s/it] 93%|█████████▎| 464/500 [05:22<00:30,  1.18it/s] 93%|█████████▎| 466/500 [05:23<00:20,  1.63it/s] 94%|█████████▎| 468/500 [05:23<00:14,  2.23it/s] 94%|█████████▍| 470/500 [05:23<00:10,  3.00it/s] 94%|█████████▍| 472/500 [05:29<00:32,  1.17s/it] 95%|█████████▍| 474/500 [05:29<00:21,  1.18it/s] 95%|█████████▌| 476/500 [05:29<00:14,  1.64it/s] 96%|█████████▌| 478/500 [05:30<00:09,  2.24it/s] 96%|█████████▌| 480/500 [05:30<00:06,  3.00it/s] 96%|█████████▋| 482/500 [05:36<00:21,  1.19s/it] 97%|█████████▋| 484/500 [05:36<00:13,  1.17it/s] 97%|█████████▋| 486/500 [05:36<00:08,  1.62it/s] 98%|█████████▊| 488/500 [05:36<00:05,  2.21it/s] 98%|█████████▊| 490/500 [05:37<00:03,  2.98it/s] 98%|█████████▊| 492/500 [05:43<00:09,  1.16s/it] 99%|█████████▉| 494/500 [05:43<00:05,  1.20it/s] 99%|█████████▉| 496/500 [05:43<00:02,  1.65it/s]100%|█████████▉| 498/500 [05:43<00:00,  2.25it/s]100%|██████████| 500/500 [05:43<00:00,  3.02it/s]100%|██████████| 500/500 [05:43<00:00,  1.45it/s]
Test Loss:  0.05021373927593231
Valid Loss:  0.052363574504852295
Epoch:  431  	Training Loss: 0.04855525493621826
Test Loss:  0.050182342529296875
Valid Loss:  0.052332982420921326
Epoch:  432  	Training Loss: 0.048527032136917114
Test Loss:  0.05015574023127556
Valid Loss:  0.05230702459812164
Epoch:  433  	Training Loss: 0.04850301146507263
Test Loss:  0.05012911930680275
Valid Loss:  0.052281081676483154
Epoch:  434  	Training Loss: 0.04847899079322815
Test Loss:  0.05010257661342621
Valid Loss:  0.052255142480134964
Epoch:  435  	Training Loss: 0.04845503717660904
Test Loss:  0.05007607489824295
Valid Loss:  0.05222924426198006
Epoch:  436  	Training Loss: 0.04843108355998993
Test Loss:  0.050049543380737305
Valid Loss:  0.05220336094498634
Epoch:  437  	Training Loss: 0.04840715974569321
Test Loss:  0.05002305656671524
Valid Loss:  0.05217753350734711
Epoch:  438  	Training Loss: 0.04838327690958977
Test Loss:  0.049996618181467056
Valid Loss:  0.05215173959732056
Epoch:  439  	Training Loss: 0.04835940897464752
Test Loss:  0.049970220774412155
Valid Loss:  0.052125900983810425
Epoch:  440  	Training Loss: 0.04833555221557617
Test Loss:  0.04994380474090576
Valid Loss:  0.05210014432668686
Epoch:  441  	Training Loss: 0.048311762511730194
Test Loss:  0.049917496740818024
Valid Loss:  0.052074432373046875
Epoch:  442  	Training Loss: 0.04828794300556183
Test Loss:  0.0498838871717453
Valid Loss:  0.052041683346033096
Epoch:  443  	Training Loss: 0.0482577383518219
Test Loss:  0.04985029250383377
Valid Loss:  0.05200893431901932
Epoch:  444  	Training Loss: 0.04822755604982376
Test Loss:  0.04981667175889015
Valid Loss:  0.051976241171360016
Epoch:  445  	Training Loss: 0.048197343945503235
Test Loss:  0.04978320375084877
Valid Loss:  0.0519435778260231
Epoch:  446  	Training Loss: 0.048167191445827484
Test Loss:  0.04974966496229172
Valid Loss:  0.05191090703010559
Epoch:  447  	Training Loss: 0.048137035220861435
Test Loss:  0.04971613734960556
Valid Loss:  0.05187825486063957
Epoch:  448  	Training Loss: 0.048106901347637177
Test Loss:  0.04968266189098358
Valid Loss:  0.051845673471689224
Epoch:  449  	Training Loss: 0.048076801002025604
Test Loss:  0.04964924603700638
Valid Loss:  0.051813047379255295
Epoch:  450  	Training Loss: 0.04804670810699463
Test Loss:  0.049615804105997086
Valid Loss:  0.05178047716617584
Epoch:  451  	Training Loss: 0.04801665246486664
Test Loss:  0.049582406878471375
Valid Loss:  0.05174792930483818
Epoch:  452  	Training Loss: 0.04798659682273865
Test Loss:  0.04955514520406723
Valid Loss:  0.05172130838036537
Epoch:  453  	Training Loss: 0.04796203598380089
Test Loss:  0.04952787235379219
Valid Loss:  0.05169474706053734
Epoch:  454  	Training Loss: 0.04793747141957283
Test Loss:  0.04950069636106491
Valid Loss:  0.051668185740709305
Epoch:  455  	Training Loss: 0.04791295528411865
Test Loss:  0.04947349429130554
Valid Loss:  0.051641687750816345
Epoch:  456  	Training Loss: 0.04788845777511597
Test Loss:  0.04944629222154617
Valid Loss:  0.051615163683891296
Epoch:  457  	Training Loss: 0.04786399379372597
Test Loss:  0.049419157207012177
Valid Loss:  0.05158867686986923
Epoch:  458  	Training Loss: 0.04783952236175537
Test Loss:  0.049392081797122955
Valid Loss:  0.05156223848462105
Epoch:  459  	Training Loss: 0.04781509190797806
Test Loss:  0.049364976584911346
Valid Loss:  0.051535800099372864
Epoch:  460  	Training Loss: 0.047790683805942535
Test Loss:  0.04933788627386093
Valid Loss:  0.051509398967027664
Epoch:  461  	Training Loss: 0.04776627570390701
Test Loss:  0.04931078851222992
Valid Loss:  0.051482997834682465
Epoch:  462  	Training Loss: 0.047741927206516266
Test Loss:  0.04928378015756607
Valid Loss:  0.051456600427627563
Epoch:  463  	Training Loss: 0.04771753400564194
Test Loss:  0.04925672337412834
Valid Loss:  0.05143018811941147
Epoch:  464  	Training Loss: 0.0476931631565094
Test Loss:  0.0492297038435936
Valid Loss:  0.05140383541584015
Epoch:  465  	Training Loss: 0.04766882583498955
Test Loss:  0.049202777445316315
Valid Loss:  0.051377538591623306
Epoch:  466  	Training Loss: 0.0476444810628891
Test Loss:  0.049175672233104706
Valid Loss:  0.05135113000869751
Epoch:  467  	Training Loss: 0.04762010648846626
Test Loss:  0.049148641526699066
Valid Loss:  0.0513247475028038
Epoch:  468  	Training Loss: 0.04759575426578522
Test Loss:  0.04912159591913223
Valid Loss:  0.051298342645168304
Epoch:  469  	Training Loss: 0.04757139831781387
Test Loss:  0.04909464716911316
Valid Loss:  0.05127201974391937
Epoch:  470  	Training Loss: 0.04754708707332611
Test Loss:  0.0490676611661911
Valid Loss:  0.05124572664499283
Epoch:  471  	Training Loss: 0.04752279818058014
Test Loss:  0.04904070124030113
Valid Loss:  0.05121947079896927
Epoch:  472  	Training Loss: 0.04749853536486626
Test Loss:  0.049010392278432846
Valid Loss:  0.05118992552161217
Epoch:  473  	Training Loss: 0.04747123643755913
Test Loss:  0.04898010194301605
Valid Loss:  0.051160357892513275
Epoch:  474  	Training Loss: 0.0474439412355423
Test Loss:  0.04894975200295448
Valid Loss:  0.05113082379102707
Epoch:  475  	Training Loss: 0.047416724264621735
Test Loss:  0.04891955479979515
Valid Loss:  0.05110126733779907
Epoch:  476  	Training Loss: 0.04738949239253998
Test Loss:  0.04888926446437836
Valid Loss:  0.051071763038635254
Epoch:  477  	Training Loss: 0.047362279146909714
Test Loss:  0.04885900020599365
Valid Loss:  0.051042310893535614
Epoch:  478  	Training Loss: 0.04733505845069885
Test Loss:  0.048828817903995514
Valid Loss:  0.05101285129785538
Epoch:  479  	Training Loss: 0.047307878732681274
Test Loss:  0.048798561096191406
Valid Loss:  0.05098346620798111
Epoch:  480  	Training Loss: 0.047280702739953995
Test Loss:  0.04876845329999924
Valid Loss:  0.050954028964042664
Epoch:  481  	Training Loss: 0.0472535640001297
Test Loss:  0.0487382635474205
Valid Loss:  0.05092465505003929
Epoch:  482  	Training Loss: 0.04722645506262779
Test Loss:  0.048707015812397
Valid Loss:  0.05089414119720459
Epoch:  483  	Training Loss: 0.047198325395584106
Test Loss:  0.04867570474743843
Valid Loss:  0.05086369067430496
Epoch:  484  	Training Loss: 0.04717019945383072
Test Loss:  0.04864449426531792
Valid Loss:  0.05083321034908295
Epoch:  485  	Training Loss: 0.047142136842012405
Test Loss:  0.0486132949590683
Valid Loss:  0.050802797079086304
Epoch:  486  	Training Loss: 0.04711410030722618
Test Loss:  0.04858209937810898
Valid Loss:  0.05077246576547623
Epoch:  487  	Training Loss: 0.04708603769540787
Test Loss:  0.04855092614889145
Valid Loss:  0.05074207857251167
Epoch:  488  	Training Loss: 0.04705803096294403
Test Loss:  0.0485197976231575
Valid Loss:  0.05071176216006279
Epoch:  489  	Training Loss: 0.047030042856931686
Test Loss:  0.04848865419626236
Valid Loss:  0.050681427121162415
Epoch:  490  	Training Loss: 0.04700208827853203
Test Loss:  0.04845758527517319
Valid Loss:  0.0506511852145195
Epoch:  491  	Training Loss: 0.046974144876003265
Test Loss:  0.04842650145292282
Valid Loss:  0.05062080919742584
Epoch:  492  	Training Loss: 0.0469462051987648
Test Loss:  0.04840150475502014
Valid Loss:  0.05059646815061569
Epoch:  493  	Training Loss: 0.0469236895442009
Test Loss:  0.04837654531002045
Valid Loss:  0.05057206749916077
Epoch:  494  	Training Loss: 0.04690120741724968
Test Loss:  0.04835158586502075
Valid Loss:  0.05054771900177002
Epoch:  495  	Training Loss: 0.04687873646616936
Test Loss:  0.04832668602466583
Valid Loss:  0.050523463636636734
Epoch:  496  	Training Loss: 0.046856269240379333
Test Loss:  0.04830179363489151
Valid Loss:  0.050499141216278076
Epoch:  497  	Training Loss: 0.04683385789394379
Test Loss:  0.048276904970407486
Valid Loss:  0.0504748672246933
Epoch:  498  	Training Loss: 0.04681145399808884
Test Loss:  0.04825203865766525
Valid Loss:  0.050450608134269714
Epoch:  499  	Training Loss: 0.04678905010223389
Test Loss:  0.048227258026599884
Valid Loss:  0.05042634159326553
Epoch:  500  	Training Loss: 0.046766653656959534
Test Loss:  0.04820238798856735
Valid Loss:  0.050402164459228516
seed is  19
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:05,  6.38s/it]  1%|          | 3/500 [00:06<14:08,  1.71s/it]  1%|          | 5/500 [00:06<07:06,  1.16it/s]  1%|▏         | 7/500 [00:06<04:18,  1.91it/s]  2%|▏         | 9/500 [00:06<02:55,  2.81it/s]  2%|▏         | 11/500 [00:13<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:20<09:47,  1.23s/it]  5%|▍         | 23/500 [00:20<06:56,  1.14it/s]  5%|▌         | 25/500 [00:26<12:23,  1.57s/it]  5%|▌         | 27/500 [00:26<08:49,  1.12s/it]  6%|▌         | 29/500 [00:26<06:20,  1.24it/s]  6%|▌         | 31/500 [00:33<11:56,  1.53s/it]  7%|▋         | 33/500 [00:33<08:28,  1.09s/it]  7%|▋         | 35/500 [00:33<06:03,  1.28it/s]  7%|▋         | 37/500 [00:33<04:22,  1.76it/s]  8%|▊         | 39/500 [00:33<03:12,  2.40it/s]  8%|▊         | 41/500 [00:40<09:25,  1.23s/it]  9%|▊         | 43/500 [00:40<06:43,  1.13it/s]  9%|▉         | 45/500 [00:40<04:50,  1.57it/s]  9%|▉         | 47/500 [00:40<03:31,  2.14it/s] 10%|▉         | 49/500 [00:40<02:36,  2.88it/s] 10%|█         | 51/500 [00:46<08:52,  1.18s/it] 11%|█         | 53/500 [00:47<06:20,  1.18it/s] 11%|█         | 55/500 [00:47<04:33,  1.62it/s] 11%|█▏        | 57/500 [00:47<03:21,  2.19it/s] 12%|█▏        | 59/500 [00:47<02:32,  2.90it/s] 12%|█▏        | 61/500 [00:53<08:44,  1.19s/it] 13%|█▎        | 63/500 [00:54<06:14,  1.17it/s] 13%|█▎        | 65/500 [00:54<04:29,  1.62it/s] 13%|█▎        | 67/500 [00:54<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:54<02:24,  2.97it/s]Epoch:  1  	Training Loss: 0.04605455324053764
Test Loss:  6.419089317321777
Valid Loss:  6.3732123374938965
Epoch:  2  	Training Loss: 6.321584701538086
Test Loss:  38.10674285888672
Valid Loss:  38.548858642578125
Epoch:  3  	Training Loss: 37.76237487792969
Test Loss:  1.1729719638824463
Valid Loss:  1.3143869638442993
Epoch:  4  	Training Loss: 1.3550257682800293
Test Loss:  1.171278715133667
Valid Loss:  1.311528205871582
Epoch:  5  	Training Loss: 1.3526670932769775
Test Loss:  1.1696133613586426
Valid Loss:  1.308951497077942
Epoch:  6  	Training Loss: 1.3503425121307373
Test Loss:  1.1680727005004883
Valid Loss:  1.3064225912094116
Epoch:  7  	Training Loss: 1.348078966140747
Test Loss:  1.1666265726089478
Valid Loss:  1.303929090499878
Epoch:  8  	Training Loss: 1.3458882570266724
Test Loss:  1.165329933166504
Valid Loss:  1.3015481233596802
Epoch:  9  	Training Loss: 1.3438599109649658
Test Loss:  1.1640784740447998
Valid Loss:  1.2993258237838745
Epoch:  10  	Training Loss: 1.341895341873169
Test Loss:  1.1628475189208984
Valid Loss:  1.2972984313964844
Epoch:  11  	Training Loss: 1.34000563621521
Test Loss:  1.1616241931915283
Valid Loss:  1.2952858209609985
Epoch:  12  	Training Loss: 1.3381402492523193
Test Loss:  0.01587868295609951
Valid Loss:  0.06716965138912201
Epoch:  13  	Training Loss: 0.0802026093006134
Test Loss:  0.02853379026055336
Valid Loss:  0.058988697826862335
Epoch:  14  	Training Loss: 0.06388785690069199
Test Loss:  0.011219082400202751
Valid Loss:  0.04758021607995033
Epoch:  15  	Training Loss: 0.05560176819562912
Test Loss:  0.018942944705486298
Valid Loss:  0.04753021150827408
Epoch:  16  	Training Loss: 0.052796076983213425
Test Loss:  0.015793586149811745
Valid Loss:  0.04607658460736275
Epoch:  17  	Training Loss: 0.052039213478565216
Test Loss:  0.01627400517463684
Valid Loss:  0.045713845640420914
Epoch:  18  	Training Loss: 0.05145472288131714
Test Loss:  0.015848977491259575
Valid Loss:  0.04513419419527054
Epoch:  19  	Training Loss: 0.0509074330329895
Test Loss:  0.01568646728992462
Valid Loss:  0.04465354233980179
Epoch:  20  	Training Loss: 0.05040495842695236
Test Loss:  0.0154647845774889
Valid Loss:  0.04418998956680298
Epoch:  21  	Training Loss: 0.04993703216314316
Test Loss:  0.015284291468560696
Valid Loss:  0.043750934302806854
Epoch:  22  	Training Loss: 0.04949122667312622
Test Loss:  0.06302735209465027
Valid Loss:  0.06041485071182251
Epoch:  23  	Training Loss: 0.0561164990067482
Test Loss:  0.41951555013656616
Valid Loss:  0.4661174416542053
Epoch:  24  	Training Loss: 0.48124998807907104
Test Loss:  0.5650383234024048
Valid Loss:  0.5327674150466919
Epoch:  25  	Training Loss: 0.5077856779098511
Test Loss:  0.2922837734222412
Valid Loss:  0.28038477897644043
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.2645813822746277
Test Loss:  0.2597561180591583
Valid Loss:  0.24788933992385864
Epoch:  27  	Training Loss: 0.23314909636974335
Test Loss:  0.23216058313846588
Valid Loss:  0.22031189501285553
Epoch:  28  	Training Loss: 0.2065589725971222
Test Loss:  0.20793458819389343
Valid Loss:  0.1961069256067276
Epoch:  29  	Training Loss: 0.1833789199590683
Test Loss:  0.1859772801399231
Valid Loss:  0.17451047897338867
Epoch:  30  	Training Loss: 0.16250967979431152
Test Loss:  0.1638723760843277
Valid Loss:  0.1538897603750229
Epoch:  31  	Training Loss: 0.14173471927642822
Test Loss:  0.1316784918308258
Valid Loss:  0.1256413757801056
Epoch:  32  	Training Loss: 0.1148589551448822
Test Loss:  0.007226684596389532
Valid Loss:  0.01954621821641922
Epoch:  33  	Training Loss: 0.021628189831972122
Test Loss:  0.008053736761212349
Valid Loss:  0.01759110391139984
Epoch:  34  	Training Loss: 0.018321610987186432
Test Loss:  0.007293920032680035
Valid Loss:  0.015945032238960266
Epoch:  35  	Training Loss: 0.016557060182094574
Test Loss:  0.006694150157272816
Valid Loss:  0.01460236869752407
Epoch:  36  	Training Loss: 0.01506878063082695
Test Loss:  0.00618349201977253
Valid Loss:  0.01354994997382164
Epoch:  37  	Training Loss: 0.01382424309849739
Test Loss:  0.005756869912147522
Valid Loss:  0.012719026766717434
Epoch:  38  	Training Loss: 0.012828301638364792
Test Loss:  0.005456951446831226
Valid Loss:  0.012019103392958641
Epoch:  39  	Training Loss: 0.012011373415589333
Test Loss:  0.005204877816140652
Valid Loss:  0.011458382941782475
Epoch:  40  	Training Loss: 0.011376610025763512
Test Loss:  0.004993615671992302
Valid Loss:  0.010983417741954327
Epoch:  41  	Training Loss: 0.010875938460230827
Test Loss:  0.004814307205379009
Valid Loss:  0.010569998994469643
Epoch:  42  	Training Loss: 0.01046084612607956
Test Loss:  0.0030738336499780416
Valid Loss:  0.007825786247849464
Epoch:  43  	Training Loss: 0.00791129469871521
Test Loss:  0.002737130969762802
Valid Loss:  0.006635724566876888
Epoch:  44  	Training Loss: 0.006662257947027683
Test Loss:  0.0027833771891891956
Valid Loss:  0.006221007090061903
Epoch:  45  	Training Loss: 0.006232324056327343
Test Loss:  0.0028019144665449858
Valid Loss:  0.006025065667927265
Epoch:  46  	Training Loss: 0.006064167246222496
Test Loss:  0.0027765852864831686
Valid Loss:  0.0058918120339512825
Epoch:  47  	Training Loss: 0.005977954715490341
Test Loss:  0.0027344138361513615
Valid Loss:  0.005797390826046467
Epoch:  48  	Training Loss: 0.005927649326622486
Test Loss:  0.0027284189127385616
Valid Loss:  0.005734270438551903
Epoch:  49  	Training Loss: 0.005894387140870094
Test Loss:  0.002706221304833889
Valid Loss:  0.005688076838850975
Epoch:  50  	Training Loss: 0.005871802568435669
Test Loss:  0.0026933844201266766
Valid Loss:  0.005657119210809469
Epoch:  51  	Training Loss: 0.0058540538884699345
Test Loss:  0.0026863389648497105
Valid Loss:  0.005635014269500971
Epoch:  52  	Training Loss: 0.005840606056153774
Test Loss:  0.0025411006063222885
Valid Loss:  0.005348954815417528
Epoch:  53  	Training Loss: 0.0055666277185082436
Test Loss:  0.0024239555932581425
Valid Loss:  0.005137640982866287
Epoch:  54  	Training Loss: 0.005369012709707022
Test Loss:  0.002346200402826071
Valid Loss:  0.005004301201552153
Epoch:  55  	Training Loss: 0.005243280902504921
Test Loss:  0.0022997832857072353
Valid Loss:  0.0049189552664756775
Epoch:  56  	Training Loss: 0.00516780000180006
Test Loss:  0.0022745884489268064
Valid Loss:  0.004865250550210476
Epoch:  57  	Training Loss: 0.005110904108732939
Test Loss:  0.0022535473108291626
Valid Loss:  0.004826953634619713
Epoch:  58  	Training Loss: 0.0050698984414339066
Test Loss:  0.0022324365563690662
Valid Loss:  0.004794455133378506
Epoch:  59  	Training Loss: 0.005036558955907822
Test Loss:  0.0022118529304862022
Valid Loss:  0.004764876328408718
Epoch:  60  	Training Loss: 0.005008464679121971
Test Loss:  0.0021922076120972633
Valid Loss:  0.004739346913993359
Epoch:  61  	Training Loss: 0.004984148312360048
Test Loss:  0.002173091284930706
Valid Loss:  0.00471830228343606
Epoch:  62  	Training Loss: 0.004962285049259663
Test Loss:  0.002047131536528468
Valid Loss:  0.004597605671733618
Epoch:  63  	Training Loss: 0.004876310005784035
Test Loss:  0.0019239782122895122
Valid Loss:  0.004475950263440609
Epoch:  64  	Training Loss: 0.004786650650203228
Test Loss:  0.001823626458644867
Valid Loss:  0.004367408808320761
Epoch:  65  	Training Loss: 0.004702514503151178
Test Loss:  0.0017383369849994779
Valid Loss:  0.004267405718564987
Epoch:  66  	Training Loss: 0.0046212682500481606
Test Loss:  0.0016664797440171242
Valid Loss:  0.004175993613898754
Epoch:  67  	Training Loss: 0.00454466138035059
Test Loss:  0.0016085017705336213
Valid Loss:  0.004093288443982601
Epoch:  68  	Training Loss: 0.004473590757697821
Test Loss:  0.001563924946822226
Valid Loss:  0.00402016332373023
Epoch:  69  	Training Loss: 0.004409071058034897
Test Loss:  0.001529828878119588
Valid Loss:  0.003953515086323023
Epoch:  70  	Training Loss: 0.00434906966984272
Test Loss:  0.001505053834989667
Valid Loss:  0.0038955749478191137
Epoch:  71  	Training Loss: 0.004293675534427166
Test Loss:  0.0014937545638531446
Valid Loss:   14%|█▍        | 71/500 [01:00<08:28,  1.19s/it] 15%|█▍        | 73/500 [01:00<06:03,  1.18it/s] 15%|█▌        | 75/500 [01:01<04:21,  1.63it/s] 15%|█▌        | 77/500 [01:01<03:10,  2.22it/s] 16%|█▌        | 79/500 [01:01<02:21,  2.99it/s] 16%|█▌        | 81/500 [01:07<08:15,  1.18s/it] 17%|█▋        | 83/500 [01:07<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:07<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:08<03:05,  2.22it/s] 18%|█▊        | 89/500 [01:08<02:17,  2.99it/s] 18%|█▊        | 91/500 [01:14<08:21,  1.23s/it] 19%|█▊        | 93/500 [01:14<05:57,  1.14it/s] 19%|█▉        | 95/500 [01:15<04:17,  1.57it/s] 19%|█▉        | 97/500 [01:15<03:07,  2.15it/s] 20%|█▉        | 99/500 [01:15<02:18,  2.90it/s] 20%|██        | 101/500 [01:21<08:04,  1.21s/it] 21%|██        | 103/500 [01:21<05:46,  1.15it/s] 21%|██        | 105/500 [01:22<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:22<03:01,  2.17it/s] 22%|██▏       | 109/500 [01:22<02:13,  2.92it/s] 22%|██▏       | 111/500 [01:28<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:28<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:28<03:55,  1.64it/s] 23%|██▎       | 117/500 [01:29<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:29<02:10,  2.93it/s] 24%|██▍       | 121/500 [01:35<07:38,  1.21s/it] 25%|██▍       | 123/500 [01:35<05:27,  1.15it/s] 25%|██▌       | 125/500 [01:35<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:36<02:51,  2.18it/s] 26%|██▌       | 129/500 [01:36<02:06,  2.93it/s] 26%|██▌       | 131/500 [01:42<07:16,  1.18s/it] 27%|██▋       | 133/500 [01:42<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:42<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:42<02:46,  2.19it/s] 28%|██▊       | 139/500 [01:43<02:04,  2.89it/s]0.003848376916721463
Epoch:  72  	Training Loss: 0.004245229531079531
Test Loss:  0.0015568865928798914
Valid Loss:  0.0038474113680422306
Epoch:  73  	Training Loss: 0.0042190467938780785
Test Loss:  0.0016082716174423695
Valid Loss:  0.0038484432734549046
Epoch:  74  	Training Loss: 0.004201595671474934
Test Loss:  0.0016491529531776905
Valid Loss:  0.0038497415371239185
Epoch:  75  	Training Loss: 0.0041891708970069885
Test Loss:  0.001681236200965941
Valid Loss:  0.0038503161631524563
Epoch:  76  	Training Loss: 0.004178929608315229
Test Loss:  0.0017062037950381637
Valid Loss:  0.0038487061392515898
Epoch:  77  	Training Loss: 0.00416853092610836
Test Loss:  0.0017254992853850126
Valid Loss:  0.0038460444193333387
Epoch:  78  	Training Loss: 0.004159103147685528
Test Loss:  0.0017403948586434126
Valid Loss:  0.003842453006654978
Epoch:  79  	Training Loss: 0.004150258377194405
Test Loss:  0.0017519043758511543
Valid Loss:  0.003838092554360628
Epoch:  80  	Training Loss: 0.004141781013458967
Test Loss:  0.001760826911777258
Valid Loss:  0.003833132330328226
Epoch:  81  	Training Loss: 0.0041334014385938644
Test Loss:  0.0017677791183814406
Valid Loss:  0.0038272025994956493
Epoch:  82  	Training Loss: 0.004123958759009838
Test Loss:  0.001806753221899271
Valid Loss:  0.0033148929942399263
Epoch:  83  	Training Loss: 0.0034862919710576534
Test Loss:  0.0016552092274650931
Valid Loss:  0.0029704193584620953
Epoch:  84  	Training Loss: 0.003203009255230427
Test Loss:  0.0014764370862394571
Valid Loss:  0.002810064936056733
Epoch:  85  	Training Loss: 0.0031023798510432243
Test Loss:  0.0014330078847706318
Valid Loss:  0.002736672293394804
Epoch:  86  	Training Loss: 0.0030590593814849854
Test Loss:  0.0014092889614403248
Valid Loss:  0.0026908789295703173
Epoch:  87  	Training Loss: 0.0030325432308018208
Test Loss:  0.0013791406527161598
Valid Loss:  0.002661130391061306
Epoch:  88  	Training Loss: 0.003014698624610901
Test Loss:  0.0013755795080214739
Valid Loss:  0.0026393705047667027
Epoch:  89  	Training Loss: 0.002999207004904747
Test Loss:  0.0013565984554588795
Valid Loss:  0.0026214634999632835
Epoch:  90  	Training Loss: 0.0029844320379197598
Test Loss:  0.0013610541354864836
Valid Loss:  0.0026053180918097496
Epoch:  91  	Training Loss: 0.00296993600204587
Test Loss:  0.0013474670704454184
Valid Loss:  0.002589684445410967
Epoch:  92  	Training Loss: 0.002955834846943617
Test Loss:  0.0013355796691030264
Valid Loss:  0.0025818166323006153
Epoch:  93  	Training Loss: 0.0029441658407449722
Test Loss:  0.0013311387738212943
Valid Loss:  0.0025756494142115116
Epoch:  94  	Training Loss: 0.0029334593564271927
Test Loss:  0.0013283636653795838
Valid Loss:  0.002571159042418003
Epoch:  95  	Training Loss: 0.0029236767441034317
Test Loss:  0.0013329745270311832
Valid Loss:  0.0025669713504612446
Epoch:  96  	Training Loss: 0.0029150848276913166
Test Loss:  0.0013333866372704506
Valid Loss:  0.002562539419159293
Epoch:  97  	Training Loss: 0.0029067550785839558
Test Loss:  0.0013321414589881897
Valid Loss:  0.0025579766370356083
Epoch:  98  	Training Loss: 0.002898743376135826
Test Loss:  0.0013343114405870438
Valid Loss:  0.0025532920844852924
Epoch:  99  	Training Loss: 0.002891288371756673
Test Loss:  0.001333721331320703
Valid Loss:  0.002548415446653962
Epoch:  100  	Training Loss: 0.0028839590959250927
Test Loss:  0.001332014799118042
Valid Loss:  0.0025434987619519234
Epoch:  101  	Training Loss: 0.002876823768019676
Test Loss:  0.0013210033066570759
Valid Loss:  0.002537316409870982
Epoch:  102  	Training Loss: 0.0028697382658720016
Test Loss:  0.0013572281459346414
Valid Loss:  0.002532494720071554
Epoch:  103  	Training Loss: 0.002831691410392523
Test Loss:  0.0013774551916867495
Valid Loss:  0.002531757578253746
Epoch:  104  	Training Loss: 0.0028131769504398108
Test Loss:  0.0013861596817150712
Valid Loss:  0.002528095617890358
Epoch:  105  	Training Loss: 0.0027982615865767
Test Loss:  0.001388075528666377
Valid Loss:  0.0025157879572361708
Epoch:  106  	Training Loss: 0.0027837930247187614
Test Loss:  0.0013865098590031266
Valid Loss:  0.0024965787306427956
Epoch:  107  	Training Loss: 0.002769327722489834
Test Loss:  0.0013836356811225414
Valid Loss:  0.0024770591408014297
Epoch:  108  	Training Loss: 0.002754642628133297
Test Loss:  0.0013802202884107828
Valid Loss:  0.002457808703184128
Epoch:  109  	Training Loss: 0.002740168711170554
Test Loss:  0.0013765920884907246
Valid Loss:  0.002438952215015888
Epoch:  110  	Training Loss: 0.0027259024791419506
Test Loss:  0.0013728789053857327
Valid Loss:  0.0024205364752560854
Epoch:  111  	Training Loss: 0.0027116346172988415
Test Loss:  0.0013691287022083998
Valid Loss:  0.0024023717269301414
Epoch:  112  	Training Loss: 0.0026970640756189823
Test Loss:  0.0013672845670953393
Valid Loss:  0.002402456011623144
Epoch:  113  	Training Loss: 0.0026969651225954294
Test Loss:  0.001365924603305757
Valid Loss:  0.0024024872109293938
Epoch:  114  	Training Loss: 0.0026968750171363354
Test Loss:  0.0013649098109453917
Valid Loss:  0.0024024811573326588
Epoch:  115  	Training Loss: 0.002696789801120758
Test Loss:  0.0013641396071761847
Valid Loss:  0.0024024471640586853
Epoch:  116  	Training Loss: 0.0026967069134116173
Test Loss:  0.0013635416980832815
Valid Loss:  0.002402390819042921
Epoch:  117  	Training Loss: 0.0026966258883476257
Test Loss:  0.0013630796456709504
Valid Loss:  0.002402320969849825
Epoch:  118  	Training Loss: 0.0026965481229126453
Test Loss:  0.001362715382128954
Valid Loss:  0.002402243670076132
Epoch:  119  	Training Loss: 0.002696475014090538
Test Loss:  0.001362412702292204
Valid Loss:  0.002402158686891198
Epoch:  120  	Training Loss: 0.002696401672437787
Test Loss:  0.0013621565885841846
Valid Loss:  0.002402068581432104
Epoch:  121  	Training Loss: 0.0026963294949382544
Test Loss:  0.0013619312085211277
Valid Loss:  0.0024019735865294933
Epoch:  122  	Training Loss: 0.0026962561532855034
Test Loss:  0.0013037490425631404
Valid Loss:  0.0023754879366606474
Epoch:  123  	Training Loss: 0.00267606507986784
Test Loss:  0.0012653216253966093
Valid Loss:  0.0023566745221614838
Epoch:  124  	Training Loss: 0.00266026658937335
Test Loss:  0.0012391393538564444
Valid Loss:  0.002342074876651168
Epoch:  125  	Training Loss: 0.002646489068865776
Test Loss:  0.001220721285790205
Valid Loss:  0.0023298864252865314
Epoch:  126  	Training Loss: 0.0026335264556109905
Test Loss:  0.0012072501704096794
Valid Loss:  0.002318937797099352
Epoch:  127  	Training Loss: 0.0026205647736787796
Test Loss:  0.0011970065534114838
Valid Loss:  0.002308886032551527
Epoch:  128  	Training Loss: 0.002607895527034998
Test Loss:  0.001188896014355123
Valid Loss:  0.002299422398209572
Epoch:  129  	Training Loss: 0.002595420926809311
Test Loss:  0.0011821965454146266
Valid Loss:  0.002290355507284403
Epoch:  130  	Training Loss: 0.0025829393416643143
Test Loss:  0.001176387770101428
Valid Loss:  0.002281154738739133
Epoch:  131  	Training Loss: 0.0025701913982629776
Test Loss:  0.0011711780680343509
Valid Loss:  0.0022706491872668266
Epoch:  132  	Training Loss: 0.00255734589882195
Test Loss:  0.001220824895426631
Valid Loss:  0.0022835489362478256
Epoch:  133  	Training Loss: 0.0025590723380446434
Test Loss:  0.0011676419526338577
Valid Loss:  0.0022597850766032934
Epoch:  134  	Training Loss: 0.002575222635641694
Test Loss:  0.0012046870542690158
Valid Loss:  0.002247338183224201
Epoch:  135  	Training Loss: 0.002543102251365781
Test Loss:  0.0012191368732601404
Valid Loss:  0.0022497745230793953
Epoch:  136  	Training Loss: 0.0025290362536907196
Test Loss:  0.0011916020885109901
Valid Loss:  0.0022402885369956493
Epoch:  137  	Training Loss: 0.0025324909947812557
Test Loss:  0.0012130718678236008
Valid Loss:  0.0022411856334656477
Epoch:  138  	Training Loss: 0.002517307410016656
Test Loss:  0.0011917860247194767
Valid Loss:  0.0022326642647385597
Epoch:  139  	Training Loss: 0.0025191418826580048
Test Loss:  0.001213647541590035
Valid Loss:  0.002238074317574501
Epoch:  140  	Training Loss: 0.002508262638002634
Test Loss:  0.0011741012567654252
Valid Loss:  0.002226497745141387
 28%|██▊       | 141/500 [01:55<12:50,  2.15s/it] 29%|██▊       | 143/500 [01:55<09:03,  1.52s/it] 29%|██▉       | 145/500 [01:56<06:25,  1.09s/it] 29%|██▉       | 147/500 [01:56<04:35,  1.28it/s] 30%|██▉       | 149/500 [01:56<03:18,  1.77it/s] 30%|███       | 151/500 [02:02<07:48,  1.34s/it] 31%|███       | 153/500 [02:02<05:33,  1.04it/s] 31%|███       | 155/500 [02:02<04:00,  1.44it/s] 31%|███▏      | 157/500 [02:03<02:54,  1.96it/s] 32%|███▏      | 159/500 [02:03<02:07,  2.66it/s] 32%|███▏      | 161/500 [02:09<07:02,  1.25s/it] 33%|███▎      | 163/500 [02:09<05:01,  1.12it/s] 33%|███▎      | 165/500 [02:10<03:35,  1.55it/s] 33%|███▎      | 167/500 [02:10<02:36,  2.12it/s] 34%|███▍      | 169/500 [02:10<01:55,  2.86it/s] 34%|███▍      | 171/500 [02:16<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:16<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:16<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:17<02:25,  2.21it/s] 36%|███▌      | 179/500 [02:17<01:47,  2.98it/s] 36%|███▌      | 181/500 [02:23<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:23<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:23<03:16,  1.60it/s] 37%|███▋      | 187/500 [02:23<02:24,  2.16it/s] 38%|███▊      | 189/500 [02:24<01:48,  2.86it/s] 38%|███▊      | 191/500 [02:30<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:30<04:21,  1.17it/s] 39%|███▉      | 195/500 [02:30<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:30<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:30<01:40,  2.99it/s] 40%|████      | 201/500 [02:37<05:55,  1.19s/it] 41%|████      | 203/500 [02:37<04:15,  1.16it/s] 41%|████      | 205/500 [02:37<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:37<02:16,  2.15it/s]**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.002520717214792967
Test Loss:  0.0011711777187883854
Valid Loss:  0.002222185954451561
Epoch:  142  	Training Loss: 0.0025117769837379456
Test Loss:  0.0011508887400850654
Valid Loss:  0.0022079069167375565
Epoch:  143  	Training Loss: 0.0025014779530465603
Test Loss:  0.001136593404226005
Valid Loss:  0.0021948704961687326
Epoch:  144  	Training Loss: 0.0024919973220676184
Test Loss:  0.001125619513913989
Valid Loss:  0.002182441297918558
Epoch:  145  	Training Loss: 0.0024828845635056496
Test Loss:  0.0011173629900440574
Valid Loss:  0.002170574851334095
Epoch:  146  	Training Loss: 0.00247404957190156
Test Loss:  0.001110303564928472
Valid Loss:  0.002158988732844591
Epoch:  147  	Training Loss: 0.0024653577711433172
Test Loss:  0.001104789087548852
Valid Loss:  0.002147671766579151
Epoch:  148  	Training Loss: 0.0024568818043917418
Test Loss:  0.001099494518712163
Valid Loss:  0.002136607188731432
Epoch:  149  	Training Loss: 0.002448560204356909
Test Loss:  0.0010955880861729383
Valid Loss:  0.002126038074493408
Epoch:  150  	Training Loss: 0.002440451877191663
Test Loss:  0.0010921596549451351
Valid Loss:  0.0021155679132789373
Epoch:  151  	Training Loss: 0.0024324622936546803
Test Loss:  0.0010888694087043405
Valid Loss:  0.002105191582813859
Epoch:  152  	Training Loss: 0.002424599602818489
Test Loss:  0.0011179817374795675
Valid Loss:  0.0021015082020312548
Epoch:  153  	Training Loss: 0.0024105673655867577
Test Loss:  0.0011165565811097622
Valid Loss:  0.0020941190887242556
Epoch:  154  	Training Loss: 0.002398731652647257
Test Loss:  0.0011096876114606857
Valid Loss:  0.0020856482442468405
Epoch:  155  	Training Loss: 0.002387033775448799
Test Loss:  0.001102082314901054
Valid Loss:  0.0020769243128597736
Epoch:  156  	Training Loss: 0.0023755512665957212
Test Loss:  0.0010948034469038248
Valid Loss:  0.0020681305322796106
Epoch:  157  	Training Loss: 0.0023642892483621836
Test Loss:  0.0010874406434595585
Valid Loss:  0.0020592440851032734
Epoch:  158  	Training Loss: 0.0023531513288617134
Test Loss:  0.0010802343022078276
Valid Loss:  0.0020503129344433546
Epoch:  159  	Training Loss: 0.0023420536890625954
Test Loss:  0.0010731846559792757
Valid Loss:  0.0020412979647517204
Epoch:  160  	Training Loss: 0.002330970484763384
Test Loss:  0.0010665406007319689
Valid Loss:  0.0020323111675679684
Epoch:  161  	Training Loss: 0.002319997875019908
Test Loss:  0.0010599037632346153
Valid Loss:  0.0020233571995049715
Epoch:  162  	Training Loss: 0.0023091170005500317
Test Loss:  0.001055314438417554
Valid Loss:  0.0020198372658342123
Epoch:  163  	Training Loss: 0.0023053453769534826
Test Loss:  0.0010510529391467571
Valid Loss:  0.0020164167508482933
Epoch:  164  	Training Loss: 0.002301637316122651
Test Loss:  0.0010470643173903227
Valid Loss:  0.002013079822063446
Epoch:  165  	Training Loss: 0.0022979897912591696
Test Loss:  0.001043488155119121
Valid Loss:  0.002009811345487833
Epoch:  166  	Training Loss: 0.002294489648193121
Test Loss:  0.0010406197980046272
Valid Loss:  0.0020070967730134726
Epoch:  167  	Training Loss: 0.0022911555133759975
Test Loss:  0.0010377925354987383
Valid Loss:  0.0020043752156198025
Epoch:  168  	Training Loss: 0.0022878763265907764
Test Loss:  0.001035016612149775
Valid Loss:  0.0020016564521938562
Epoch:  169  	Training Loss: 0.0022846939973533154
Test Loss:  0.0010325993644073606
Valid Loss:  0.0019994459580630064
Epoch:  170  	Training Loss: 0.0022816623095422983
Test Loss:  0.001030430314131081
Valid Loss:  0.0019977071788161993
Epoch:  171  	Training Loss: 0.0022787859197705984
Test Loss:  0.0010284174932166934
Valid Loss:  0.001996399601921439
Epoch:  172  	Training Loss: 0.0022760345600545406
Test Loss:  0.0010066700633615255
Valid Loss:  0.001921277493238449
Epoch:  173  	Training Loss: 0.0021802394185215235
Test Loss:  0.0009817681275308132
Valid Loss:  0.0018513109534978867
Epoch:  174  	Training Loss: 0.0020892247557640076
Test Loss:  0.0009554301504977047
Valid Loss:  0.0017871363088488579
Epoch:  175  	Training Loss: 0.0020049503073096275
Test Loss:  0.0009304216364398599
Valid Loss:  0.0017300685867667198
Epoch:  176  	Training Loss: 0.001929414109326899
Test Loss:  0.0009072372922673821
Valid Loss:  0.0016794661059975624
Epoch:  177  	Training Loss: 0.001860500662587583
Test Loss:  0.0008852705941535532
Valid Loss:  0.001633546664379537
Epoch:  178  	Training Loss: 0.0017959909746423364
Test Loss:  0.000864849891513586
Valid Loss:  0.001590884756296873
Epoch:  179  	Training Loss: 0.0017341187922284007
Test Loss:  0.0008463012054562569
Valid Loss:  0.0015478674322366714
Epoch:  180  	Training Loss: 0.0016753885429352522
Test Loss:  0.0008295730222016573
Valid Loss:  0.0015085876220837235
Epoch:  181  	Training Loss: 0.001619886257685721
Test Loss:  0.0008132721995934844
Valid Loss:  0.0014734957367181778
Epoch:  182  	Training Loss: 0.0015693085733801126
Test Loss:  0.0007930751889944077
Valid Loss:  0.0014428782742470503
Epoch:  183  	Training Loss: 0.001525268191471696
Test Loss:  0.0007739412831142545
Valid Loss:  0.0014141278807073832
Epoch:  184  	Training Loss: 0.001484233420342207
Test Loss:  0.000755920191295445
Valid Loss:  0.0013875209260731936
Epoch:  185  	Training Loss: 0.001445991569198668
Test Loss:  0.0007389899110421538
Valid Loss:  0.0013628874439746141
Epoch:  186  	Training Loss: 0.0014103474095463753
Test Loss:  0.0007231378694996238
Valid Loss:  0.001340090180747211
Epoch:  187  	Training Loss: 0.0013771189842373133
Test Loss:  0.000708281178958714
Valid Loss:  0.0013189960736781359
Epoch:  188  	Training Loss: 0.001346138073131442
Test Loss:  0.0006944095366634429
Valid Loss:  0.0012994633289054036
Epoch:  189  	Training Loss: 0.001317247748374939
Test Loss:  0.0006813822546973825
Valid Loss:  0.0012813671492040157
Epoch:  190  	Training Loss: 0.0012902801390737295
Test Loss:  0.000669146713335067
Valid Loss:  0.0012645948445424438
Epoch:  191  	Training Loss: 0.0012651000870391726
Test Loss:  0.0006576802115887403
Valid Loss:  0.0012490353547036648
Epoch:  192  	Training Loss: 0.001241585472598672
Test Loss:  0.0006505116471089423
Valid Loss:  0.0012443270534276962
Epoch:  193  	Training Loss: 0.0012374611105769873
Test Loss:  0.0006447128835134208
Valid Loss:  0.0012402916327118874
Epoch:  194  	Training Loss: 0.0012337022926658392
Test Loss:  0.0006399289122782648
Valid Loss:  0.001236734795384109
Epoch:  195  	Training Loss: 0.0012302116956561804
Test Loss:  0.0006359081016853452
Valid Loss:  0.0012335210340097547
Epoch:  196  	Training Loss: 0.0012269285507500172
Test Loss:  0.0006324618589133024
Valid Loss:  0.0012305534910410643
Epoch:  197  	Training Loss: 0.00122384715359658
Test Loss:  0.0006300817476585507
Valid Loss:  0.00122823566198349
Epoch:  198  	Training Loss: 0.0012209591222926974
Test Loss:  0.0006278970977291465
Valid Loss:  0.001225973479449749
Epoch:  199  	Training Loss: 0.001218193443492055
Test Loss:  0.0006258640205487609
Valid Loss:  0.001223747618496418
Epoch:  200  	Training Loss: 0.0012155440635979176
Test Loss:  0.0006245909025892615
Valid Loss:  0.0012220238568261266
Epoch:  201  	Training Loss: 0.0012130551040172577
Test Loss:  0.0006232745945453644
Valid Loss:  0.0012202404905110598
Epoch:  202  	Training Loss: 0.001210661488585174
Test Loss:  0.0006217110203579068
Valid Loss:  0.0012160742189735174
Epoch:  203  	Training Loss: 0.0012003674637526274
Test Loss:  0.0006162161007523537
Valid Loss:  0.00121053378097713
Epoch:  204  	Training Loss: 0.0011915082577615976
Test Loss:  0.0006097140721976757
Valid Loss:  0.0012046913616359234
Epoch:  205  	Training Loss: 0.00118358398322016
Test Loss:  0.0006032289820723236
Valid Loss:  0.0011989276390522718
Epoch:  206  	Training Loss: 0.001176383811980486
Test Loss:  0.0005970507627353072
Valid Loss:  0.001193332951515913
Epoch:  207  	Training Loss: 0.001169747207313776
Test Loss:  0.0005912415217608213
Valid Loss:  0.0011879114899784327
Epoch:  208  	Training Loss: 0.0011635629925876856
Test Loss:  0.0005857809446752071
Valid Loss:   42%|████▏     | 209/500 [02:38<01:42,  2.85it/s] 42%|████▏     | 211/500 [02:44<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:44<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:44<02:57,  1.60it/s] 43%|████▎     | 217/500 [02:44<02:09,  2.19it/s] 44%|████▍     | 219/500 [02:44<01:35,  2.95it/s] 44%|████▍     | 221/500 [02:51<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:51<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:51<02:49,  1.63it/s] 45%|████▌     | 227/500 [02:51<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:52<01:41,  2.68it/s] 46%|████▌     | 231/500 [02:58<05:24,  1.21s/it] 47%|████▋     | 233/500 [02:58<03:50,  1.16it/s] 47%|████▋     | 235/500 [02:58<02:45,  1.60it/s] 47%|████▋     | 237/500 [02:58<02:00,  2.19it/s] 48%|████▊     | 239/500 [02:58<01:28,  2.95it/s] 48%|████▊     | 241/500 [03:05<05:05,  1.18s/it] 49%|████▊     | 243/500 [03:05<03:38,  1.18it/s] 49%|████▉     | 245/500 [03:05<02:38,  1.61it/s] 49%|████▉     | 247/500 [03:05<01:56,  2.17it/s] 50%|████▉     | 249/500 [03:05<01:27,  2.88it/s] 50%|█████     | 251/500 [03:12<04:56,  1.19s/it] 51%|█████     | 253/500 [03:12<03:31,  1.17it/s] 51%|█████     | 255/500 [03:12<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:12<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:12<01:23,  2.88it/s] 52%|█████▏    | 261/500 [03:19<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:19<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:19<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:19<01:47,  2.17it/s] 54%|█████▍    | 269/500 [03:19<01:19,  2.90it/s] 54%|█████▍    | 271/500 [03:25<04:31,  1.18s/it] 55%|█████▍    | 273/500 [03:26<03:14,  1.17it/s] 55%|█████▌    | 275/500 [03:26<02:20,  1.60it/s]0.0011826364789158106
Epoch:  209  	Training Loss: 0.0011577418772503734
Test Loss:  0.000580628402531147
Valid Loss:  0.001177481492049992
Epoch:  210  	Training Loss: 0.0011522165732458234
Test Loss:  0.0005757386097684503
Valid Loss:  0.0011724227806553245
Epoch:  211  	Training Loss: 0.0011469335295259953
Test Loss:  0.0005710728000849485
Valid Loss:  0.0011674391571432352
Epoch:  212  	Training Loss: 0.0011418532812967896
Test Loss:  0.0005758540937677026
Valid Loss:  0.0011670972453430295
Epoch:  213  	Training Loss: 0.0011377617483958602
Test Loss:  0.0005801097140647471
Valid Loss:  0.0011668731458485126
Epoch:  214  	Training Loss: 0.001134134246967733
Test Loss:  0.0005838299402967095
Valid Loss:  0.0011667078360915184
Epoch:  215  	Training Loss: 0.0011308753164485097
Test Loss:  0.0005870625609531999
Valid Loss:  0.0011665609199553728
Epoch:  216  	Training Loss: 0.001127901254221797
Test Loss:  0.0005898827221244574
Valid Loss:  0.0011664093472063541
Epoch:  217  	Training Loss: 0.0011251465184614062
Test Loss:  0.00059229985345155
Valid Loss:  0.0011662300676107407
Epoch:  218  	Training Loss: 0.0011225665220990777
Test Loss:  0.0005943733267486095
Valid Loss:  0.0011660155141726136
Epoch:  219  	Training Loss: 0.0011201263405382633
Test Loss:  0.0005961251445114613
Valid Loss:  0.001165756257250905
Epoch:  220  	Training Loss: 0.0011177975684404373
Test Loss:  0.0005976143293082714
Valid Loss:  0.0011654518311843276
Epoch:  221  	Training Loss: 0.001115595456212759
Test Loss:  0.0005988535704091191
Valid Loss:  0.0011651203967630863
Epoch:  222  	Training Loss: 0.00111350417137146
Test Loss:  0.0005708750104531646
Valid Loss:  0.0011472125770524144
Epoch:  223  	Training Loss: 0.0011063084239140153
Test Loss:  0.000555661041289568
Valid Loss:  0.0011365942191332579
Epoch:  224  	Training Loss: 0.001102061360143125
Test Loss:  0.000546879309695214
Valid Loss:  0.0011294595897197723
Epoch:  225  	Training Loss: 0.001098815817385912
Test Loss:  0.0005414908519014716
Valid Loss:  0.0011241452302783728
Epoch:  226  	Training Loss: 0.0010959848295897245
Test Loss:  0.0005379172507673502
Valid Loss:  0.0011198562569916248
Epoch:  227  	Training Loss: 0.0010933828307315707
Test Loss:  0.0005354044260457158
Valid Loss:  0.0011161662405356765
Epoch:  228  	Training Loss: 0.0010909468401223421
Test Loss:  0.0005334928282536566
Valid Loss:  0.001112892641685903
Epoch:  229  	Training Loss: 0.0010886373929679394
Test Loss:  0.000531946774572134
Valid Loss:  0.0011099205585196614
Epoch:  230  	Training Loss: 0.0010864370269700885
Test Loss:  0.0005306350067257881
Valid Loss:  0.0011071814224123955
Epoch:  231  	Training Loss: 0.0010843328200280666
Test Loss:  0.0005294788279570639
Valid Loss:  0.0011046273866668344
Epoch:  232  	Training Loss: 0.0010823148768395185
Test Loss:  0.0005356902256608009
Valid Loss:  0.0011050442699342966
Epoch:  233  	Training Loss: 0.0010746198240667582
Test Loss:  0.0005414923070929945
Valid Loss:  0.0011063013225793839
Epoch:  234  	Training Loss: 0.0010695300297811627
Test Loss:  0.0005465388530865312
Valid Loss:  0.0011077411472797394
Epoch:  235  	Training Loss: 0.001065978896804154
Test Loss:  0.0005507457535713911
Valid Loss:  0.0011090494226664305
Epoch:  236  	Training Loss: 0.001063337316736579
Test Loss:  0.0005541564314626157
Valid Loss:  0.0011100978590548038
Epoch:  237  	Training Loss: 0.0010612348560243845
Test Loss:  0.0005568653577938676
Valid Loss:  0.001110853161662817
Epoch:  238  	Training Loss: 0.001059452653862536
Test Loss:  0.0005589837674051523
Valid Loss:  0.0011113295331597328
Epoch:  239  	Training Loss: 0.0010578630026429892
Test Loss:  0.0005606160848401487
Valid Loss:  0.0011115592205896974
Epoch:  240  	Training Loss: 0.0010563904652372003
Test Loss:  0.0005618584109470248
Valid Loss:  0.0011115818051621318
Epoch:  241  	Training Loss: 0.001054988824762404
Test Loss:  0.000562789966352284
Valid Loss:  0.0011114366352558136
Epoch:  242  	Training Loss: 0.0010536338668316603
Test Loss:  0.0005029491730965674
Valid Loss:  0.0010599808301776648
Epoch:  243  	Training Loss: 0.0010176111245527864
Test Loss:  0.00048794838949106634
Valid Loss:  0.0010353662073612213
Epoch:  244  	Training Loss: 0.0009871850488707423
Test Loss:  0.0004753042012453079
Valid Loss:  0.0010131048038601875
Epoch:  245  	Training Loss: 0.0009580469341017306
Test Loss:  0.0004631023621186614
Valid Loss:  0.0009925465565174818
Epoch:  246  	Training Loss: 0.0009307042928412557
Test Loss:  0.00045150844380259514
Valid Loss:  0.0009733721963129938
Epoch:  247  	Training Loss: 0.0009049923392012715
Test Loss:  0.00044038501800969243
Valid Loss:  0.0009554280550219119
Epoch:  248  	Training Loss: 0.0008807881968095899
Test Loss:  0.0004297792329452932
Valid Loss:  0.0009368386818096042
Epoch:  249  	Training Loss: 0.0008579707355238497
Test Loss:  0.0004196742956992239
Valid Loss:  0.0009190784767270088
Epoch:  250  	Training Loss: 0.0008364364039152861
Test Loss:  0.0004100537043996155
Valid Loss:  0.0009022891754284501
Epoch:  251  	Training Loss: 0.0008160957368090749
Test Loss:  0.00040090098627842963
Valid Loss:  0.0008864038391038775
Epoch:  252  	Training Loss: 0.0007968634599819779
Test Loss:  0.00040075750439427793
Valid Loss:  0.0008851988241076469
Epoch:  253  	Training Loss: 0.0007959653157740831
Test Loss:  0.00040061521576717496
Valid Loss:  0.000884012202732265
Epoch:  254  	Training Loss: 0.0007950759027153254
Test Loss:  0.00040047414950095117
Valid Loss:  0.0008828443242236972
Epoch:  255  	Training Loss: 0.0007941949879750609
Test Loss:  0.0004003341600764543
Valid Loss:  0.0008816937333904207
Epoch:  256  	Training Loss: 0.0007933222223073244
Test Loss:  0.0004001960332971066
Valid Loss:  0.000880562118254602
Epoch:  257  	Training Loss: 0.0007924577221274376
Test Loss:  0.0004000586923211813
Valid Loss:  0.0008794486057013273
Epoch:  258  	Training Loss: 0.0007916010799817741
Test Loss:  0.00039992190431803465
Valid Loss:  0.0008783515077084303
Epoch:  259  	Training Loss: 0.0007907524704933167
Test Loss:  0.0003997873282060027
Valid Loss:  0.0008772722212597728
Epoch:  260  	Training Loss: 0.0007899123593233526
Test Loss:  0.0003996537998318672
Valid Loss:  0.0008762088255025446
Epoch:  261  	Training Loss: 0.0007890790002420545
Test Loss:  0.0003995200677309185
Valid Loss:  0.0008751637069508433
Epoch:  262  	Training Loss: 0.0007882537320256233
Test Loss:  0.0004035897145513445
Valid Loss:  0.0008761067874729633
Epoch:  263  	Training Loss: 0.0007875615265220404
Test Loss:  0.0004057816695421934
Valid Loss:  0.0008766658138483763
Epoch:  264  	Training Loss: 0.0007872699061408639
Test Loss:  0.00040678385994397104
Valid Loss:  0.0008769023697823286
Epoch:  265  	Training Loss: 0.0007870871340855956
Test Loss:  0.0004072117153555155
Valid Loss:  0.0008769709966145456
Epoch:  266  	Training Loss: 0.0007869283435866237
Test Loss:  0.0004073692252859473
Valid Loss:  0.0008769557462073863
Epoch:  267  	Training Loss: 0.0007867743261158466
Test Loss:  0.00040734559297561646
Valid Loss:  0.0008768823463469744
Epoch:  268  	Training Loss: 0.0007866158848628402
Test Loss:  0.00040723156416788697
Valid Loss:  0.0008767791441641748
Epoch:  269  	Training Loss: 0.0007864546496421099
Test Loss:  0.0004071280127391219
Valid Loss:  0.0008766785031184554
Epoch:  270  	Training Loss: 0.000786293763667345
Test Loss:  0.0004070294671691954
Valid Loss:  0.0008765797829255462
Epoch:  271  	Training Loss: 0.0007861311896704137
Test Loss:  0.0004070167487952858
Valid Loss:  0.0008765087695792317
Epoch:  272  	Training Loss: 0.0007859657634980977
Test Loss:  0.0004063592932652682
Valid Loss:  0.0008755414746701717
Epoch:  273  	Training Loss: 0.0007857560995034873
Test Loss:  0.00040578062180429697
Valid Loss:  0.00087461166549474
Epoch:  274  	Training Loss: 0.0007855551084503531
Test Loss:  0.00040526874363422394
Valid Loss:  0.0008737148600630462
Epoch:  275  	Training Loss: 0.0007853623246774077
Test Loss:  0.000404815305955708
Valid Loss:  0.0008728458778932691
Epoch:  276  	Training Loss: 0.0007851753034628928
Test Loss:  0.0004044122761115432
Valid Loss:  0.0008720040787011385
 55%|█████▌    | 277/500 [03:26<01:43,  2.16it/s] 56%|█████▌    | 279/500 [03:26<01:17,  2.86it/s] 56%|█████▌    | 281/500 [03:33<04:25,  1.21s/it] 57%|█████▋    | 283/500 [03:33<03:08,  1.15it/s] 57%|█████▋    | 285/500 [03:33<02:15,  1.59it/s] 57%|█████▋    | 287/500 [03:33<01:38,  2.17it/s] 58%|█████▊    | 289/500 [03:33<01:12,  2.93it/s] 58%|█████▊    | 291/500 [03:40<04:10,  1.20s/it] 59%|█████▊    | 293/500 [03:40<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:40<02:07,  1.61it/s] 59%|█████▉    | 297/500 [03:40<01:32,  2.20it/s] 60%|█████▉    | 299/500 [03:40<01:08,  2.95it/s] 60%|██████    | 301/500 [03:46<03:57,  1.20s/it] 61%|██████    | 303/500 [03:47<02:48,  1.17it/s] 61%|██████    | 305/500 [03:47<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:47<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:47<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:53<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:53<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:54<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:54<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:54<01:00,  3.01it/s] 64%|██████▍   | 321/500 [04:00<03:27,  1.16s/it] 65%|██████▍   | 323/500 [04:00<02:28,  1.19it/s] 65%|██████▌   | 325/500 [04:00<01:45,  1.65it/s] 65%|██████▌   | 327/500 [04:00<01:16,  2.26it/s] 66%|██████▌   | 329/500 [04:01<00:56,  3.03it/s] 66%|██████▌   | 331/500 [04:07<03:19,  1.18s/it] 67%|██████▋   | 333/500 [04:07<02:21,  1.18it/s] 67%|██████▋   | 335/500 [04:07<01:41,  1.63it/s] 67%|██████▋   | 337/500 [04:07<01:13,  2.21it/s] 68%|██████▊   | 339/500 [04:07<00:54,  2.98it/s] 68%|██████▊   | 341/500 [04:14<03:09,  1.19s/it] 69%|██████▊   | 343/500 [04:14<02:14,  1.17it/s]Epoch:  277  	Training Loss: 0.0007849935791455209
Test Loss:  0.0004040517087560147
Valid Loss:  0.0008711850387044251
Epoch:  278  	Training Loss: 0.0007848166860640049
Test Loss:  0.00040372897638008
Valid Loss:  0.0008703883504495025
Epoch:  279  	Training Loss: 0.0007846429944038391
Test Loss:  0.0004033890145365149
Valid Loss:  0.0008695926517248154
Epoch:  280  	Training Loss: 0.0007844716310501099
Test Loss:  0.00040308310417458415
Valid Loss:  0.0008688182570040226
Epoch:  281  	Training Loss: 0.0007843028870411217
Test Loss:  0.00040280623943544924
Valid Loss:  0.0008680618484504521
Epoch:  282  	Training Loss: 0.0007841371116228402
Test Loss:  0.00040355834062211215
Valid Loss:  0.0008679595775902271
Epoch:  283  	Training Loss: 0.0007833164418116212
Test Loss:  0.0004040306666865945
Valid Loss:  0.0008677832083776593
Epoch:  284  	Training Loss: 0.0007825389038771391
Test Loss:  0.00040429190266877413
Valid Loss:  0.0008675447897985578
Epoch:  285  	Training Loss: 0.000781786220613867
Test Loss:  0.00040439615258947015
Valid Loss:  0.0008672619587741792
Epoch:  286  	Training Loss: 0.000781049020588398
Test Loss:  0.00040438311407342553
Valid Loss:  0.0008669426315464079
Epoch:  287  	Training Loss: 0.0007803222397342324
Test Loss:  0.00040428503416478634
Valid Loss:  0.0008666277281008661
Epoch:  288  	Training Loss: 0.0007796028512530029
Test Loss:  0.0004041233332827687
Valid Loss:  0.0008663340122438967
Epoch:  289  	Training Loss: 0.0007788888760842383
Test Loss:  0.00040391687070950866
Valid Loss:  0.000866025104187429
Epoch:  290  	Training Loss: 0.0007781786262057722
Test Loss:  0.0004037311300635338
Valid Loss:  0.000865706242620945
Epoch:  291  	Training Loss: 0.0007774691330268979
Test Loss:  0.0004035310703329742
Valid Loss:  0.0008653787663206458
Epoch:  292  	Training Loss: 0.0007767616189084947
Test Loss:  0.0004055868776049465
Valid Loss:  0.0008660996099933982
Epoch:  293  	Training Loss: 0.0007742731831967831
Test Loss:  0.0004073665477335453
Valid Loss:  0.0008669048547744751
Epoch:  294  	Training Loss: 0.000772485975176096
Test Loss:  0.0004089052090421319
Valid Loss:  0.000867706083226949
Epoch:  295  	Training Loss: 0.0007711788639426231
Test Loss:  0.00041020946810021996
Valid Loss:  0.0008684469503350556
Epoch:  296  	Training Loss: 0.0007701959693804383
Test Loss:  0.0004113019967917353
Valid Loss:  0.0008690984104759991
Epoch:  297  	Training Loss: 0.0007694324012845755
Test Loss:  0.000412204914027825
Valid Loss:  0.0008696438162587583
Epoch:  298  	Training Loss: 0.0007688200566917658
Test Loss:  0.0004129456647206098
Valid Loss:  0.0008700901526026428
Epoch:  299  	Training Loss: 0.0007683094590902328
Test Loss:  0.00041354744462296367
Valid Loss:  0.0008704449282959104
Epoch:  300  	Training Loss: 0.0007678695837967098
Test Loss:  0.00041403266368433833
Valid Loss:  0.0008707166416570544
Epoch:  301  	Training Loss: 0.0007674777880311012
Test Loss:  0.0004144185804761946
Valid Loss:  0.0008709154790267348
Epoch:  302  	Training Loss: 0.000767117424402386
Test Loss:  0.0004061732906848192
Valid Loss:  0.0008589642238803208
Epoch:  303  	Training Loss: 0.0007534533506259322
Test Loss:  0.0003991043195128441
Valid Loss:  0.0008482768898829818
Epoch:  304  	Training Loss: 0.0007407860830426216
Test Loss:  0.00039284315425902605
Valid Loss:  0.0008385670371353626
Epoch:  305  	Training Loss: 0.0007289756322279572
Test Loss:  0.0003871904336847365
Valid Loss:  0.0008296557934954762
Epoch:  306  	Training Loss: 0.0007177529623731971
Test Loss:  0.0003820023266598582
Valid Loss:  0.000821227440610528
Epoch:  307  	Training Loss: 0.0007065543322823942
Test Loss:  0.0003772152995225042
Valid Loss:  0.0008133983938023448
Epoch:  308  	Training Loss: 0.0006960060563869774
Test Loss:  0.0003727305156644434
Valid Loss:  0.0008060748805291951
Epoch:  309  	Training Loss: 0.0006860470166429877
Test Loss:  0.000368509441614151
Valid Loss:  0.0007991966558620334
Epoch:  310  	Training Loss: 0.0006766298320144415
Test Loss:  0.00036452215863391757
Valid Loss:  0.0007927186088636518
Epoch:  311  	Training Loss: 0.0006674604373984039
Test Loss:  0.0003607537073548883
Valid Loss:  0.0007864784565754235
Epoch:  312  	Training Loss: 0.000658285163808614
Test Loss:  0.00034427258651703596
Valid Loss:  0.0007719689747318625
Epoch:  313  	Training Loss: 0.0006535826250910759
Test Loss:  0.0003366914461366832
Valid Loss:  0.0007651756168343127
Epoch:  314  	Training Loss: 0.0006515485001727939
Test Loss:  0.00033284371602348983
Valid Loss:  0.0007615486974827945
Epoch:  315  	Training Loss: 0.0006501837633550167
Test Loss:  0.000330684008076787
Valid Loss:  0.0007593357004225254
Epoch:  316  	Training Loss: 0.0006489988300018013
Test Loss:  0.0003293250920251012
Valid Loss:  0.0007577934884466231
Epoch:  317  	Training Loss: 0.0006478741415776312
Test Loss:  0.00032836059108376503
Valid Loss:  0.0007565821288153529
Epoch:  318  	Training Loss: 0.0006467793136835098
Test Loss:  0.00032759661553427577
Valid Loss:  0.0007555421907454729
Epoch:  319  	Training Loss: 0.0006457064882852137
Test Loss:  0.000326937937643379
Valid Loss:  0.0007545944536104798
Epoch:  320  	Training Loss: 0.000644654268398881
Test Loss:  0.00032633874798193574
Valid Loss:  0.0007537002675235271
Epoch:  321  	Training Loss: 0.000643620325718075
Test Loss:  0.00032577564707025886
Valid Loss:  0.000752841355279088
Epoch:  322  	Training Loss: 0.0006426111795008183
Test Loss:  0.00032660725992172956
Valid Loss:  0.0007525848923251033
Epoch:  323  	Training Loss: 0.0006410662899725139
Test Loss:  0.0003264269034843892
Valid Loss:  0.0007516525802202523
Epoch:  324  	Training Loss: 0.0006396375829353929
Test Loss:  0.00032572943018749356
Valid Loss:  0.0007503337692469358
Epoch:  325  	Training Loss: 0.000638294848613441
Test Loss:  0.0003247794811613858
Valid Loss:  0.000748836318962276
Epoch:  326  	Training Loss: 0.0006369845941662788
Test Loss:  0.0003237656783312559
Valid Loss:  0.0007472868310287595
Epoch:  327  	Training Loss: 0.000635684235021472
Test Loss:  0.0003226730623282492
Valid Loss:  0.000745694269426167
Epoch:  328  	Training Loss: 0.0006344234570860863
Test Loss:  0.00032156199449673295
Valid Loss:  0.0007441038615070283
Epoch:  329  	Training Loss: 0.0006331985350698233
Test Loss:  0.00032046192791312933
Valid Loss:  0.000742538133636117
Epoch:  330  	Training Loss: 0.0006320023676380515
Test Loss:  0.0003193860175088048
Valid Loss:  0.0007410055259242654
Epoch:  331  	Training Loss: 0.0006308337906375527
Test Loss:  0.00031834046239964664
Valid Loss:  0.0007395102875307202
Epoch:  332  	Training Loss: 0.0006296884967014194
Test Loss:  0.0003187243128195405
Valid Loss:  0.0007391719846054912
Epoch:  333  	Training Loss: 0.0006291496683843434
Test Loss:  0.0003190198913216591
Valid Loss:  0.0007388044614344835
Epoch:  334  	Training Loss: 0.0006286328425630927
Test Loss:  0.0003192269359715283
Valid Loss:  0.0007384062046185136
Epoch:  335  	Training Loss: 0.0006281398236751556
Test Loss:  0.00031937030144035816
Valid Loss:  0.0007379861199297011
Epoch:  336  	Training Loss: 0.0006276621716096997
Test Loss:  0.0003194499877281487
Valid Loss:  0.0007375447312369943
Epoch:  337  	Training Loss: 0.0006271988968364894
Test Loss:  0.0003194875316694379
Valid Loss:  0.0007370898383669555
Epoch:  338  	Training Loss: 0.0006267427816055715
Test Loss:  0.00031949148979038
Valid Loss:  0.0007366262143477798
Epoch:  339  	Training Loss: 0.0006262919632717967
Test Loss:  0.00031942204805091023
Valid Loss:  0.0007361263269558549
Epoch:  340  	Training Loss: 0.0006258419016376138
Test Loss:  0.0003193385782651603
Valid Loss:  0.0007356429705396295
Epoch:  341  	Training Loss: 0.0006253928877413273
Test Loss:  0.0003192048752680421
Valid Loss:  0.0007351491367444396
Epoch:  342  	Training Loss: 0.0006249467842280865
Test Loss:  0.0003183551016263664
Valid Loss:  0.0007339618750847876
Epoch:  343  	Training Loss: 0.0006236134213395417
Test Loss:  0.00031751603819429874
Valid Loss:  0.0007327951025217772
Epoch:  344  	Training Loss: 0.000622313586063683
Test Loss:  0.0003166902461089194
Valid Loss:  0.0007316482369787991
 69%|██████▉   | 345/500 [04:14<01:35,  1.62it/s] 69%|██████▉   | 347/500 [04:14<01:09,  2.21it/s] 70%|██████▉   | 349/500 [04:14<00:50,  2.98it/s] 70%|███████   | 351/500 [04:21<02:56,  1.18s/it] 71%|███████   | 353/500 [04:21<02:04,  1.18it/s] 71%|███████   | 355/500 [04:21<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:21<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:21<00:48,  2.92it/s] 72%|███████▏  | 361/500 [04:28<02:47,  1.20s/it] 73%|███████▎  | 363/500 [04:28<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:28<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:28<01:00,  2.19it/s] 74%|███████▍  | 369/500 [04:28<00:44,  2.95it/s] 74%|███████▍  | 371/500 [04:35<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:35<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:35<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:35<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:35<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:41<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:42<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:42<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:42<00:51,  2.21it/s] 78%|███████▊  | 389/500 [04:42<00:37,  2.94it/s] 78%|███████▊  | 391/500 [04:49<02:12,  1.22s/it] 79%|███████▊  | 393/500 [04:49<01:34,  1.14it/s] 79%|███████▉  | 395/500 [04:49<01:07,  1.57it/s] 79%|███████▉  | 397/500 [04:49<00:48,  2.11it/s] 80%|███████▉  | 399/500 [04:49<00:35,  2.81it/s] 80%|████████  | 401/500 [04:56<01:59,  1.20s/it] 81%|████████  | 403/500 [04:56<01:24,  1.15it/s] 81%|████████  | 405/500 [04:56<01:00,  1.57it/s] 81%|████████▏ | 407/500 [04:56<00:43,  2.14it/s] 82%|████████▏ | 409/500 [04:56<00:31,  2.89it/s] 82%|████████▏ | 411/500 [05:02<01:44,  1.17s/it]Epoch:  345  	Training Loss: 0.0006210459396243095
Test Loss:  0.0003158794716000557
Valid Loss:  0.0007305238395929337
Epoch:  346  	Training Loss: 0.000619816011749208
Test Loss:  0.0003150820848532021
Valid Loss:  0.000729420455172658
Epoch:  347  	Training Loss: 0.0006186269456520677
Test Loss:  0.0003143035573884845
Valid Loss:  0.0007283410523086786
Epoch:  348  	Training Loss: 0.000617467041593045
Test Loss:  0.00031354257953353226
Valid Loss:  0.00072728336090222
Epoch:  349  	Training Loss: 0.0006163354264572263
Test Loss:  0.00031279955874197185
Valid Loss:  0.0007262484286911786
Epoch:  350  	Training Loss: 0.0006152299465611577
Test Loss:  0.00031207373831421137
Valid Loss:  0.0007252370705828071
Epoch:  351  	Training Loss: 0.0006141504272818565
Test Loss:  0.0003113656130153686
Valid Loss:  0.0007242471911013126
Epoch:  352  	Training Loss: 0.0006130957626737654
Test Loss:  0.0003128661774098873
Valid Loss:  0.0007225578301586211
Epoch:  353  	Training Loss: 0.0006052402895875275
Test Loss:  0.00031420920277014375
Valid Loss:  0.0007212703349068761
Epoch:  354  	Training Loss: 0.0005983986193314195
Test Loss:  0.00031533141736872494
Valid Loss:  0.0007192173507064581
Epoch:  355  	Training Loss: 0.0005922509590163827
Test Loss:  0.0003162525244988501
Valid Loss:  0.0007162463152781129
Epoch:  356  	Training Loss: 0.0005862326361238956
Test Loss:  0.00031699042301625013
Valid Loss:  0.0007127368007786572
Epoch:  357  	Training Loss: 0.0005807745037600398
Test Loss:  0.00031757340184412897
Valid Loss:  0.0007093854364939034
Epoch:  358  	Training Loss: 0.0005757826729677618
Test Loss:  0.00031802739249542356
Valid Loss:  0.0007061765063554049
Epoch:  359  	Training Loss: 0.0005711863050237298
Test Loss:  0.0003183780063409358
Valid Loss:  0.0007030988344922662
Epoch:  360  	Training Loss: 0.000566722359508276
Test Loss:  0.0003186643007211387
Valid Loss:  0.0006999298348091543
Epoch:  361  	Training Loss: 0.0005621920572593808
Test Loss:  0.00031888874946162105
Valid Loss:  0.0006968945963308215
Epoch:  362  	Training Loss: 0.000557960825972259
Test Loss:  0.0002974055823870003
Valid Loss:  0.0006729852175340056
Epoch:  363  	Training Loss: 0.000547463889233768
Test Loss:  0.0002912270138040185
Valid Loss:  0.0006636995822191238
Epoch:  364  	Training Loss: 0.0005421729874797165
Test Loss:  0.00028861526516266167
Valid Loss:  0.0006579853361472487
Epoch:  365  	Training Loss: 0.0005377208581194282
Test Loss:  0.00028709074831567705
Valid Loss:  0.0006535016000270844
Epoch:  366  	Training Loss: 0.0005336824106052518
Test Loss:  0.0002859181258827448
Valid Loss:  0.0006495392299257219
Epoch:  367  	Training Loss: 0.0005300168413668871
Test Loss:  0.000284946640022099
Valid Loss:  0.0006459398427978158
Epoch:  368  	Training Loss: 0.0005266822408884764
Test Loss:  0.0002841212262865156
Valid Loss:  0.0006426358595490456
Epoch:  369  	Training Loss: 0.0005236432189121842
Test Loss:  0.00028341292636469007
Valid Loss:  0.0006395893869921565
Epoch:  370  	Training Loss: 0.000520867935847491
Test Loss:  0.00028280593687668443
Valid Loss:  0.0006367714377120137
Epoch:  371  	Training Loss: 0.0005183292087167501
Test Loss:  0.00028228602604940534
Valid Loss:  0.0006341583211906254
Epoch:  372  	Training Loss: 0.0005160019500181079
Test Loss:  0.0002829052973538637
Valid Loss:  0.0006327573792077601
Epoch:  373  	Training Loss: 0.0005138138658367097
Test Loss:  0.0002833559410646558
Valid Loss:  0.0006311350734904408
Epoch:  374  	Training Loss: 0.0005115658277645707
Test Loss:  0.0002836065541487187
Valid Loss:  0.0006294262129813433
Epoch:  375  	Training Loss: 0.0005095015512779355
Test Loss:  0.00028375477995723486
Valid Loss:  0.0006277066422626376
Epoch:  376  	Training Loss: 0.0005075717926956713
Test Loss:  0.0002837883366737515
Valid Loss:  0.0006259417859837413
Epoch:  377  	Training Loss: 0.0005057459929957986
Test Loss:  0.0002838323125615716
Valid Loss:  0.0006242587696760893
Epoch:  378  	Training Loss: 0.0005040279356762767
Test Loss:  0.00028388886130414903
Valid Loss:  0.0006226574187166989
Epoch:  379  	Training Loss: 0.0005024106940254569
Test Loss:  0.00028395518893375993
Valid Loss:  0.0006211342406459153
Epoch:  380  	Training Loss: 0.0005008879234082997
Test Loss:  0.0002840346423909068
Valid Loss:  0.0006196856265887618
Epoch:  381  	Training Loss: 0.000499454268720001
Test Loss:  0.0002841238456312567
Valid Loss:  0.0006183084333315492
Epoch:  382  	Training Loss: 0.0004981032107025385
Test Loss:  0.00028411555103957653
Valid Loss:  0.0006178540643304586
Epoch:  383  	Training Loss: 0.000496913562528789
Test Loss:  0.0002841225068550557
Valid Loss:  0.0006174290319904685
Epoch:  384  	Training Loss: 0.0004957890487276018
Test Loss:  0.00028414209373295307
Valid Loss:  0.0006170307751744986
Epoch:  385  	Training Loss: 0.0004947262350469828
Test Loss:  0.00028417358407750726
Valid Loss:  0.0006166560342535377
Epoch:  386  	Training Loss: 0.0004937192425131798
Test Loss:  0.00028421482420526445
Valid Loss:  0.0006163034704513848
Epoch:  387  	Training Loss: 0.0004927641130052507
Test Loss:  0.00028426400967873633
Valid Loss:  0.000615972385276109
Epoch:  388  	Training Loss: 0.0004918576451018453
Test Loss:  0.0002843198017217219
Valid Loss:  0.0006156580056995153
Epoch:  389  	Training Loss: 0.0004909959388896823
Test Loss:  0.0002843803376890719
Valid Loss:  0.0006153626018203795
Epoch:  390  	Training Loss: 0.0004901755601167679
Test Loss:  0.00028444567578844726
Valid Loss:  0.0006150814006105065
Epoch:  391  	Training Loss: 0.0004893936566077173
Test Loss:  0.00028451401158235967
Valid Loss:  0.0006148139946162701
Epoch:  392  	Training Loss: 0.0004886470851488411
Test Loss:  0.00028502801433205605
Valid Loss:  0.0006138704484328628
Epoch:  393  	Training Loss: 0.0004856273008044809
Test Loss:  0.00028539125923998654
Valid Loss:  0.0006129405228421092
Epoch:  394  	Training Loss: 0.0004831057449337095
Test Loss:  0.000285593094304204
Valid Loss:  0.0006119812605902553
Epoch:  395  	Training Loss: 0.0004809328238479793
Test Loss:  0.0002856428036466241
Valid Loss:  0.0006109846290200949
Epoch:  396  	Training Loss: 0.0004790092643816024
Test Loss:  0.00028555793687701225
Valid Loss:  0.0006099442252889276
Epoch:  397  	Training Loss: 0.0004772694665007293
Test Loss:  0.0002853577025234699
Valid Loss:  0.0006088679656386375
Epoch:  398  	Training Loss: 0.00047566735884174705
Test Loss:  0.0002850593882612884
Valid Loss:  0.000607759749982506
Epoch:  399  	Training Loss: 0.0004741703160107136
Test Loss:  0.0002846790011972189
Valid Loss:  0.0006066247005946934
Epoch:  400  	Training Loss: 0.00047275409451685846
Test Loss:  0.0002842311514541507
Valid Loss:  0.0006054694531485438
Epoch:  401  	Training Loss: 0.0004714017268270254
Test Loss:  0.0002837270440068096
Valid Loss:  0.0006043000612407923
Epoch:  402  	Training Loss: 0.00047010049456730485
Test Loss:  0.000279753643553704
Valid Loss:  0.0005983770824968815
Epoch:  403  	Training Loss: 0.00046673405449837446
Test Loss:  0.00027681136270985007
Valid Loss:  0.0005936003290116787
Epoch:  404  	Training Loss: 0.0004638301325030625
Test Loss:  0.0002745100937318057
Valid Loss:  0.0005895702634006739
Epoch:  405  	Training Loss: 0.0004612454795278609
Test Loss:  0.0002726393868215382
Valid Loss:  0.000586066278629005
Epoch:  406  	Training Loss: 0.0004589114396367222
Test Loss:  0.00027110541122965515
Valid Loss:  0.0005830041482113302
Epoch:  407  	Training Loss: 0.0004567441064864397
Test Loss:  0.0002697689924389124
Valid Loss:  0.0005802116938866675
Epoch:  408  	Training Loss: 0.00045476469676941633
Test Loss:  0.0002685985527932644
Valid Loss:  0.0005776513135060668
Epoch:  409  	Training Loss: 0.00045295071322470903
Test Loss:  0.00026756900479085743
Valid Loss:  0.0005752950673922896
Epoch:  410  	Training Loss: 0.00045128361671231687
Test Loss:  0.00026666189660318196
Valid Loss:  0.0005731177516281605
Epoch:  411  	Training Loss: 0.00044973386684432626
Test Loss:  0.00026588814216665924
Valid Loss:  0.0005711534759029746
Epoch:  412  	Training Loss: 0.00044827768579125404
Test Loss:  0.00026468036230653524
Valid Loss:  0.0005679603200405836
 83%|████████▎ | 413/500 [05:03<01:13,  1.19it/s] 83%|████████▎ | 415/500 [05:03<00:51,  1.64it/s] 83%|████████▎ | 417/500 [05:03<00:37,  2.24it/s] 84%|████████▍ | 419/500 [05:03<00:27,  3.00it/s] 84%|████████▍ | 421/500 [05:09<01:33,  1.19s/it] 85%|████████▍ | 423/500 [05:09<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:10<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:10<00:33,  2.17it/s] 86%|████████▌ | 429/500 [05:10<00:24,  2.87it/s] 86%|████████▌ | 431/500 [05:16<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:16<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:17<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:17<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:17<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:23<01:11,  1.22s/it] 89%|████████▊ | 443/500 [05:24<00:49,  1.14it/s] 89%|████████▉ | 445/500 [05:24<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:24<00:24,  2.16it/s] 90%|████████▉ | 449/500 [05:24<00:17,  2.91it/s] 90%|█████████ | 451/500 [05:30<00:58,  1.18s/it] 91%|█████████ | 453/500 [05:30<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:30<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:31<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:31<00:13,  2.99it/s] 92%|█████████▏| 461/500 [05:37<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:37<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:37<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:37<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:38<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:44<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:44<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:44<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:44<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:44<00:07,  2.99it/s]Epoch:  413  	Training Loss: 0.0004442239587660879
Test Loss:  0.00026325168437324464
Valid Loss:  0.0005646878853440285
Epoch:  414  	Training Loss: 0.00044057535706087947
Test Loss:  0.0002617933205328882
Valid Loss:  0.0005615232512354851
Epoch:  415  	Training Loss: 0.0004372314433567226
Test Loss:  0.00026035873452201486
Valid Loss:  0.000558505009394139
Epoch:  416  	Training Loss: 0.00043412644299678504
Test Loss:  0.00025895447470247746
Valid Loss:  0.0005556209944188595
Epoch:  417  	Training Loss: 0.00043120517511852086
Test Loss:  0.00025758170522749424
Valid Loss:  0.0005528724286705256
Epoch:  418  	Training Loss: 0.00042839080560952425
Test Loss:  0.00025619473308324814
Valid Loss:  0.0005501803243532777
Epoch:  419  	Training Loss: 0.000425694597652182
Test Loss:  0.0002548151824157685
Valid Loss:  0.0005475163925439119
Epoch:  420  	Training Loss: 0.00042309716809540987
Test Loss:  0.0002534518134780228
Valid Loss:  0.0005448394222185016
Epoch:  421  	Training Loss: 0.00042058515828102827
Test Loss:  0.00025195025955326855
Valid Loss:  0.0005422248505055904
Epoch:  422  	Training Loss: 0.00041812879499047995
Test Loss:  0.00025205756537616253
Valid Loss:  0.0005409743171185255
Epoch:  423  	Training Loss: 0.0004167476436123252
Test Loss:  0.00025212165201082826
Valid Loss:  0.0005397620843723416
Epoch:  424  	Training Loss: 0.0004154463531449437
Test Loss:  0.00025216402718797326
Valid Loss:  0.0005385872209444642
Epoch:  425  	Training Loss: 0.0004142174148000777
Test Loss:  0.00025218905648216605
Valid Loss:  0.0005374474567361176
Epoch:  426  	Training Loss: 0.0004130539018660784
Test Loss:  0.00025219927192665637
Valid Loss:  0.0005363426171243191
Epoch:  427  	Training Loss: 0.000411949644330889
Test Loss:  0.00025219906819984317
Valid Loss:  0.0005352707812562585
Epoch:  428  	Training Loss: 0.0004108924185857177
Test Loss:  0.00025216094218194485
Valid Loss:  0.0005341973155736923
Epoch:  429  	Training Loss: 0.00040977587923407555
Test Loss:  0.0002521369024179876
Valid Loss:  0.0005330310668796301
Epoch:  430  	Training Loss: 0.0004085359978489578
Test Loss:  0.000252114434260875
Valid Loss:  0.0005319055635482073
Epoch:  431  	Training Loss: 0.00040735240327194333
Test Loss:  0.0002520925481803715
Valid Loss:  0.0005308208055794239
Epoch:  432  	Training Loss: 0.0004062214575242251
Test Loss:  0.0002523033763282001
Valid Loss:  0.000530095596332103
Epoch:  433  	Training Loss: 0.0004052253207191825
Test Loss:  0.00025251053739339113
Valid Loss:  0.0005294145084917545
Epoch:  434  	Training Loss: 0.00040429813088849187
Test Loss:  0.0002527122269384563
Valid Loss:  0.000528775795828551
Epoch:  435  	Training Loss: 0.0004034343874081969
Test Loss:  0.00025290841585956514
Valid Loss:  0.0005281753255985677
Epoch:  436  	Training Loss: 0.00040263013215735555
Test Loss:  0.0002530993951950222
Valid Loss:  0.0005276089650578797
Epoch:  437  	Training Loss: 0.0004018799518235028
Test Loss:  0.00025328423362225294
Valid Loss:  0.000527076655998826
Epoch:  438  	Training Loss: 0.00040117991738952696
Test Loss:  0.00025346362963318825
Valid Loss:  0.0005265738582238555
Epoch:  439  	Training Loss: 0.0004005257214885205
Test Loss:  0.00025363595341332257
Valid Loss:  0.0005260990001261234
Epoch:  440  	Training Loss: 0.00039991410449147224
Test Loss:  0.00025380332954227924
Valid Loss:  0.0005256502190604806
Epoch:  441  	Training Loss: 0.00039934151573106647
Test Loss:  0.000253964273724705
Valid Loss:  0.0005252240225672722
Epoch:  442  	Training Loss: 0.00039880553958937526
Test Loss:  0.00025413098046556115
Valid Loss:  0.0005249740788713098
Epoch:  443  	Training Loss: 0.0003982874914072454
Test Loss:  0.00025431992253288627
Valid Loss:  0.0005247387452982366
Epoch:  444  	Training Loss: 0.00039785465924069285
Test Loss:  0.00025451998226344585
Valid Loss:  0.000524512492120266
Epoch:  445  	Training Loss: 0.00039748227572999895
Test Loss:  0.0002547224285081029
Valid Loss:  0.0005242918850854039
Epoch:  446  	Training Loss: 0.0003971534315496683
Test Loss:  0.0002549152122810483
Valid Loss:  0.0005240716272965074
Epoch:  447  	Training Loss: 0.000396857998566702
Test Loss:  0.00025511006242595613
Valid Loss:  0.0005238526500761509
Epoch:  448  	Training Loss: 0.0003965879150200635
Test Loss:  0.0002553048252593726
Valid Loss:  0.0005236355355009437
Epoch:  449  	Training Loss: 0.0003963382332585752
Test Loss:  0.0002554990933276713
Valid Loss:  0.0005234179552644491
Epoch:  450  	Training Loss: 0.00039610412204638124
Test Loss:  0.00025568989804014564
Valid Loss:  0.0005232018884271383
Epoch:  451  	Training Loss: 0.00039588456274941564
Test Loss:  0.00025587750133126974
Valid Loss:  0.0005229894304648042
Epoch:  452  	Training Loss: 0.00039567844942212105
Test Loss:  0.0002542107831686735
Valid Loss:  0.0005206000059843063
Epoch:  453  	Training Loss: 0.0003942640032619238
Test Loss:  0.0002528039622120559
Valid Loss:  0.0005185202462598681
Epoch:  454  	Training Loss: 0.0003929788654204458
Test Loss:  0.0002515841042622924
Valid Loss:  0.0005166592891328037
Epoch:  455  	Training Loss: 0.0003917827270925045
Test Loss:  0.0002505108714103699
Valid Loss:  0.0005149736534804106
Epoch:  456  	Training Loss: 0.0003906513738911599
Test Loss:  0.0002495429362170398
Valid Loss:  0.0005134223611094058
Epoch:  457  	Training Loss: 0.0003895654226653278
Test Loss:  0.0002486529992893338
Valid Loss:  0.000511973979882896
Epoch:  458  	Training Loss: 0.0003885134938172996
Test Loss:  0.0002478218520991504
Valid Loss:  0.0005106065655127168
Epoch:  459  	Training Loss: 0.0003874886315315962
Test Loss:  0.0002470355248078704
Valid Loss:  0.0005093032959848642
Epoch:  460  	Training Loss: 0.0003864853933919221
Test Loss:  0.0002462823467794806
Valid Loss:  0.000508048222400248
Epoch:  461  	Training Loss: 0.00038550083991140127
Test Loss:  0.00024555710842832923
Valid Loss:  0.0005068169557489455
Epoch:  462  	Training Loss: 0.0003845372120849788
Test Loss:  0.0002433905319776386
Valid Loss:  0.0005043114069849253
Epoch:  463  	Training Loss: 0.00038337919977493584
Test Loss:  0.00024150218814611435
Valid Loss:  0.0005021562101319432
Epoch:  464  	Training Loss: 0.00038234604289755225
Test Loss:  0.00023976623197086155
Valid Loss:  0.0005002456018701196
Epoch:  465  	Training Loss: 0.000381398422177881
Test Loss:  0.00023808916739653796
Valid Loss:  0.0004984935512766242
Epoch:  466  	Training Loss: 0.0003804777516052127
Test Loss:  0.00023643569147679955
Valid Loss:  0.0004968811990693212
Epoch:  467  	Training Loss: 0.0003795994562096894
Test Loss:  0.00023487326689064503
Valid Loss:  0.000495379907079041
Epoch:  468  	Training Loss: 0.000378769647795707
Test Loss:  0.00023339598556049168
Valid Loss:  0.0004939684877172112
Epoch:  469  	Training Loss: 0.0003779828839469701
Test Loss:  0.00023199401039164513
Valid Loss:  0.0004926343681290746
Epoch:  470  	Training Loss: 0.00037723645800724626
Test Loss:  0.0002306602691533044
Valid Loss:  0.0004913691082037985
Epoch:  471  	Training Loss: 0.00037652882747352123
Test Loss:  0.0002293903089594096
Valid Loss:  0.0004901658976450562
Epoch:  472  	Training Loss: 0.0003758561215363443
Test Loss:  0.000230433841352351
Valid Loss:  0.0004894109442830086
Epoch:  473  	Training Loss: 0.0003727070870809257
Test Loss:  0.00023161081480793655
Valid Loss:  0.0004890443524345756
Epoch:  474  	Training Loss: 0.000370411406038329
Test Loss:  0.00023278167645912617
Valid Loss:  0.0004888740368187428
Epoch:  475  	Training Loss: 0.0003686890995595604
Test Loss:  0.00023387352121062577
Valid Loss:  0.000488787773065269
Epoch:  476  	Training Loss: 0.00036735169123858213
Test Loss:  0.00023482136020902544
Valid Loss:  0.000488713791128248
Epoch:  477  	Training Loss: 0.0003662743547465652
Test Loss:  0.00023562886053696275
Valid Loss:  0.0004886207170784473
Epoch:  478  	Training Loss: 0.0003653772291727364
Test Loss:  0.0002363183011766523
Valid Loss:  0.0004884941736236215
Epoch:  479  	Training Loss: 0.0003646097029559314
Test Loss:  0.00023689953377470374
Valid Loss:  0.00048832967877388
Epoch:  480  	Training Loss: 0.0003639361239038408
Test Loss:  0.00023738396703265607
Valid Loss:   96%|█████████▌| 481/500 [05:51<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:51<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:51<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:51<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:51<00:03,  2.95it/s] 98%|█████████▊| 491/500 [05:58<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:58<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:58<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:58<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:58<00:00,  3.00it/s]100%|██████████| 500/500 [05:58<00:00,  1.39it/s]
0.0004885608213953674
Epoch:  481  	Training Loss: 0.00036334729520604014
Test Loss:  0.00023736988077871501
Valid Loss:  0.0004881824424955994
Epoch:  482  	Training Loss: 0.00036285698297433555
Test Loss:  0.00023492853506468236
Valid Loss:  0.0004856097511947155
Epoch:  483  	Training Loss: 0.00036141645978204906
Test Loss:  0.00023269388475455344
Valid Loss:  0.0004831032420042902
Epoch:  484  	Training Loss: 0.0003600924392230809
Test Loss:  0.0002306536480318755
Valid Loss:  0.00048077167593874037
Epoch:  485  	Training Loss: 0.0003588680410757661
Test Loss:  0.00022878151503391564
Valid Loss:  0.0004786115896422416
Epoch:  486  	Training Loss: 0.0003577278694137931
Test Loss:  0.0002270564145874232
Valid Loss:  0.00047659940901212394
Epoch:  487  	Training Loss: 0.0003566404338926077
Test Loss:  0.0002254061255371198
Valid Loss:  0.00047469549463130534
Epoch:  488  	Training Loss: 0.0003555021248757839
Test Loss:  0.00022385769989341497
Valid Loss:  0.00047287371126003563
Epoch:  489  	Training Loss: 0.0003544342762324959
Test Loss:  0.0002224055933766067
Valid Loss:  0.0004711368237622082
Epoch:  490  	Training Loss: 0.0003534263523761183
Test Loss:  0.00022104397066868842
Valid Loss:  0.00046948259114287794
Epoch:  491  	Training Loss: 0.00035246735205873847
Test Loss:  0.00021975688287056983
Valid Loss:  0.0004678479162976146
Epoch:  492  	Training Loss: 0.0003514921700116247
Test Loss:  0.00021321025269571692
Valid Loss:  0.00045913655776530504
Epoch:  493  	Training Loss: 0.0003488356014713645
Test Loss:  0.0002108146873069927
Valid Loss:  0.00045624346239492297
Epoch:  494  	Training Loss: 0.00034728689934127033
Test Loss:  0.0002084755979012698
Valid Loss:  0.00045338255586102605
Epoch:  495  	Training Loss: 0.0003458887804299593
Test Loss:  0.00020638341084122658
Valid Loss:  0.0004508091078605503
Epoch:  496  	Training Loss: 0.00034466086071915925
Test Loss:  0.00020436919294297695
Valid Loss:  0.000448473118012771
Epoch:  497  	Training Loss: 0.00034353084629401565
Test Loss:  0.00020248729560989887
Valid Loss:  0.0004463212681002915
Epoch:  498  	Training Loss: 0.00034249210148118436
Test Loss:  0.00020072501501999795
Valid Loss:  0.0004443358338903636
Epoch:  499  	Training Loss: 0.0003415251267142594
Test Loss:  0.00019907447858713567
Valid Loss:  0.0004424698418006301
Epoch:  500  	Training Loss: 0.00034063338534906507
Test Loss:  0.00019751010404434055
Valid Loss:  0.0004407446540426463
seed is  20
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.12it/s]  1%|          | 4/500 [00:00<00:31, 15.81it/s]  1%|          | 6/500 [00:00<00:30, 16.03it/s]  2%|▏         | 8/500 [00:00<00:30, 16.15it/s]  2%|▏         | 10/500 [00:00<00:30, 16.23it/s]  2%|▏         | 12/500 [00:00<00:30, 16.23it/s]  3%|▎         | 14/500 [00:00<00:29, 16.25it/s]  3%|▎         | 16/500 [00:00<00:29, 16.30it/s]  4%|▎         | 18/500 [00:01<00:29, 16.23it/s]  4%|▍         | 20/500 [00:01<00:30, 15.98it/s]  4%|▍         | 22/500 [00:01<00:32, 14.61it/s]  5%|▍         | 24/500 [00:01<00:34, 13.78it/s]  5%|▌         | 26/500 [00:01<00:35, 13.24it/s]  6%|▌         | 28/500 [00:01<00:35, 13.47it/s]  6%|▌         | 30/500 [00:02<00:33, 14.17it/s]  6%|▋         | 32/500 [00:02<00:31, 14.84it/s]  7%|▋         | 34/500 [00:02<00:30, 15.24it/s]  7%|▋         | 36/500 [00:02<00:29, 15.59it/s]  8%|▊         | 38/500 [00:02<00:29, 15.88it/s]  8%|▊         | 40/500 [00:02<00:29, 15.76it/s]  8%|▊         | 42/500 [00:02<00:29, 15.72it/s]  9%|▉         | 44/500 [00:02<00:28, 15.86it/s]  9%|▉         | 46/500 [00:03<00:29, 15.16it/s] 10%|▉         | 48/500 [00:03<00:31, 14.54it/s] 10%|█         | 50/500 [00:03<00:30, 14.55it/s] 10%|█         | 52/500 [00:03<00:29, 15.00it/s] 11%|█         | 54/500 [00:03<00:29, 15.10it/s] 11%|█         | 56/500 [00:03<00:29, 15.20it/s] 12%|█▏        | 58/500 [00:03<00:28, 15.42it/s] 12%|█▏        | 60/500 [00:03<00:28, 15.56it/s] 12%|█▏        | 62/500 [00:04<00:27, 15.77it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.62it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.36it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.69it/s] 14%|█▍        | 70/500 [00:04<00:26, 15.93it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.81it/s] 15%|█▍        | 74/500 [00:04<00:29, 14.58it/s] 15%|█▌        | 76/500 [00:04<00:28, 14.76it/s] 16%|█▌        | 78/500 [00:05<00:27, 15.17it/s] 16%|█▌        | 80/500 [00:05<00:27, 15.48it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.69it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.83it/s] 17%|█▋        | 86/500 [00:05<00:27, 15.32it/s] 18%|█▊        | 88/500 [00:05<00:28, 14.39it/s] 18%|█▊        | 90/500 [00:05<00:28, 14.48it/s] 18%|█▊        | 92/500 [00:06<00:28, 14.23it/s] 19%|█▉        | 94/500 [00:06<00:27, 14.65it/s] 19%|█▉        | 96/500 [00:06<00:26, 14.97it/s] 20%|█▉        | 98/500 [00:06<00:26, 15.03it/s] 20%|██        | 100/500 [00:06<00:26, 15.34it/s] 20%|██        | 102/500 [00:06<00:25, 15.60it/s] 21%|██        | 104/500 [00:06<00:24, 15.84it/s] 21%|██        | 106/500 [00:06<00:26, 14.90it/s] 22%|██▏       | 108/500 [00:07<00:25, 15.24it/s] 22%|██▏       | 110/500 [00:07<00:25, 15.56it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.76it/s] 23%|██▎       | 114/500 [00:07<00:25, 15.28it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.44it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.58it/s] 24%|██▍       | 120/500 [00:07<00:24, 15.77it/s] 24%|██▍       | 122/500 [00:07<00:24, 15.65it/s] 25%|██▍       | 124/500 [00:08<00:25, 14.64it/s]Epoch:  1  	Training Loss: 0.23076128959655762
Test Loss:  3800.177978515625
Valid Loss:  3799.30908203125
Epoch:  2  	Training Loss: 3800.9755859375
Test Loss:  204054768648192.0
Valid Loss:  202623403687936.0
Epoch:  3  	Training Loss: 201176435916800.0
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:24, 15.08it/s] 26%|██▌       | 128/500 [00:08<00:24, 15.31it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.58it/s] 26%|██▋       | 132/500 [00:08<00:24, 15.32it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.63it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.81it/s] 28%|██▊       | 138/500 [00:09<00:22, 16.00it/s] 28%|██▊       | 140/500 [00:09<00:22, 16.13it/s] 28%|██▊       | 142/500 [00:09<00:22, 16.21it/s] 29%|██▉       | 144/500 [00:09<00:21, 16.25it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.91it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.46it/s] 30%|███       | 150/500 [00:09<00:22, 15.61it/s] 30%|███       | 152/500 [00:09<00:22, 15.73it/s] 31%|███       | 154/500 [00:10<00:21, 15.81it/s] 31%|███       | 156/500 [00:10<00:22, 15.19it/s] 32%|███▏      | 158/500 [00:10<00:22, 15.53it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.68it/s] 32%|███▏      | 162/500 [00:10<00:22, 15.14it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.47it/s] 33%|███▎      | 166/500 [00:10<00:22, 14.99it/s] 34%|███▎      | 168/500 [00:10<00:22, 14.92it/s] 34%|███▍      | 170/500 [00:11<00:23, 14.16it/s] 34%|███▍      | 172/500 [00:11<00:24, 13.41it/s] 35%|███▍      | 174/500 [00:11<00:25, 12.67it/s] 35%|███▌      | 176/500 [00:11<00:24, 13.44it/s] 36%|███▌      | 178/500 [00:11<00:23, 13.79it/s] 36%|███▌      | 180/500 [00:11<00:22, 14.43it/s] 36%|███▋      | 182/500 [00:11<00:21, 14.88it/s] 37%|███▋      | 184/500 [00:12<00:20, 15.18it/s] 37%|███▋      | 186/500 [00:12<00:20, 15.21it/s] 38%|███▊      | 188/500 [00:12<00:20, 15.35it/s] 38%|███▊      | 190/500 [00:12<00:20, 15.43it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.63it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.69it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.79it/s] 40%|███▉      | 198/500 [00:13<00:20, 15.08it/s] 40%|████      | 200/500 [00:13<00:19, 15.24it/s] 40%|████      | 202/500 [00:13<00:20, 14.62it/s] 41%|████      | 204/500 [00:13<00:20, 14.66it/s] 41%|████      | 206/500 [00:13<00:19, 14.70it/s] 42%|████▏     | 208/500 [00:13<00:19, 15.00it/s] 42%|████▏     | 210/500 [00:13<00:19, 15.05it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.21it/s] 43%|████▎     | 214/500 [00:14<00:18, 15.37it/s] 43%|████▎     | 216/500 [00:14<00:18, 15.57it/s] 44%|████▎     | 218/500 [00:14<00:17, 15.68it/s] 44%|████▍     | 220/500 [00:14<00:17, 15.73it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.85it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.01it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.98it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.83it/s] 46%|████▌     | 230/500 [00:15<00:16, 15.91it/s] 46%|████▋     | 232/500 [00:15<00:16, 15.97it/s] 47%|████▋     | 234/500 [00:15<00:16, 15.93it/s] 47%|████▋     | 236/500 [00:15<00:16, 15.90it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.00it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.04it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.14it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.25it/s] 49%|████▉     | 246/500 [00:16<00:15, 16.21it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.27it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.37it/s] 50%|█████     | 252/500 [00:16<00:15, 16.43it/s] 51%|█████     | 254/500 [00:16<00:15, 16.30it/s] 51%|█████     | 256/500 [00:16<00:14, 16.35it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.34it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.14it/s] 52%|█████▏    | 262/500 [00:17<00:14, 16.05it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.11it/s] 53%|█████▎    | 266/500 [00:17<00:14, 16.17it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.23it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.32it/s] 54%|█████▍    | 272/500 [00:17<00:13, 16.32it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.21it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.22it/s] 56%|█████▌    | 278/500 [00:18<00:14, 14.92it/s] 56%|█████▌    | 280/500 [00:18<00:14, 15.21it/s] 56%|█████▋    | 282/500 [00:18<00:14, 15.39it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.51it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.55it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.83it/s] 58%|█████▊    | 290/500 [00:18<00:13, 16.06it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.24it/s] 59%|█████▉    | 294/500 [00:19<00:12, 16.33it/s] 59%|█████▉    | 296/500 [00:19<00:12, 16.37it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.94it/s] 60%|██████    | 300/500 [00:19<00:12, 16.05it/s] 60%|██████    | 302/500 [00:19<00:12, 15.97it/s] 61%|██████    | 304/500 [00:19<00:12, 15.90it/s] 61%|██████    | 306/500 [00:19<00:12, 15.95it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.03it/s] 62%|██████▏   | 310/500 [00:20<00:11, 15.98it/s] 62%|██████▏   | 312/500 [00:20<00:12, 15.66it/s] 63%|██████▎   | 314/500 [00:20<00:12, 14.89it/s] 63%|██████▎   | 316/500 [00:20<00:13, 14.05it/s] 64%|██████▎   | 318/500 [00:20<00:13, 13.59it/s] 64%|██████▍   | 320/500 [00:20<00:12, 14.27it/s] 64%|██████▍   | 322/500 [00:20<00:12, 14.81it/s] 65%|██████▍   | 324/500 [00:21<00:11, 15.24it/s] 65%|██████▌   | 326/500 [00:21<00:11, 15.60it/s] 66%|██████▌   | 328/500 [00:21<00:10, 15.81it/s] 66%|██████▌   | 330/500 [00:21<00:10, 15.91it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.96it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.67it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.86it/s] 68%|██████▊   | 338/500 [00:21<00:10, 14.76it/s] 68%|██████▊   | 340/500 [00:22<00:10, 15.23it/s] 68%|██████▊   | 342/500 [00:22<00:10, 15.25it/s] 69%|██████▉   | 344/500 [00:22<00:10, 14.21it/s] 69%|██████▉   | 346/500 [00:22<00:11, 13.68it/s] 70%|██████▉   | 348/500 [00:22<00:10, 14.38it/s] 70%|███████   | 350/500 [00:22<00:10, 14.60it/s] 70%|███████   | 352/500 [00:22<00:09, 14.99it/s] 71%|███████   | 354/500 [00:23<00:09, 15.23it/s] 71%|███████   | 356/500 [00:23<00:09, 15.60it/s] 72%|███████▏  | 358/500 [00:23<00:08, 15.84it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.03it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.20it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.22it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.17it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.20it/s] 74%|███████▍  | 370/500 [00:24<00:08, 16.09it/s] 74%|███████▍  | 372/500 [00:24<00:07, 16.14it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:07, 16.23it/s] 75%|███████▌  | 376/500 [00:24<00:07, 16.23it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.21it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.20it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.19it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.09it/s] 77%|███████▋  | 386/500 [00:25<00:07, 16.16it/s] 78%|███████▊  | 388/500 [00:25<00:06, 16.20it/s] 78%|███████▊  | 390/500 [00:25<00:06, 16.21it/s] 78%|███████▊  | 392/500 [00:25<00:06, 16.27it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.30it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.22it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.31it/s] 80%|████████  | 400/500 [00:25<00:06, 16.39it/s] 80%|████████  | 402/500 [00:25<00:06, 16.24it/s] 81%|████████  | 404/500 [00:26<00:05, 16.31it/s] 81%|████████  | 406/500 [00:26<00:06, 15.50it/s] 82%|████████▏ | 408/500 [00:26<00:06, 14.03it/s] 82%|████████▏ | 410/500 [00:26<00:06, 14.49it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.07it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.38it/s] 83%|████████▎ | 416/500 [00:26<00:05, 14.64it/s] 84%|████████▎ | 418/500 [00:27<00:05, 14.59it/s] 84%|████████▍ | 420/500 [00:27<00:05, 14.92it/s] 84%|████████▍ | 422/500 [00:27<00:05, 15.34it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.67it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.60it/s] 86%|████████▌ | 428/500 [00:27<00:04, 15.77it/s] 86%|████████▌ | 430/500 [00:27<00:04, 15.71it/s] 86%|████████▋ | 432/500 [00:27<00:04, 15.82it/s] 87%|████████▋ | 434/500 [00:28<00:04, 15.92it/s] 87%|████████▋ | 436/500 [00:28<00:04, 15.62it/s] 88%|████████▊ | 438/500 [00:28<00:03, 15.87it/s] 88%|████████▊ | 440/500 [00:28<00:03, 15.93it/s] 88%|████████▊ | 442/500 [00:28<00:03, 15.88it/s] 89%|████████▉ | 444/500 [00:28<00:03, 15.91it/s] 89%|████████▉ | 446/500 [00:28<00:03, 15.98it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.11it/s] 90%|█████████ | 450/500 [00:29<00:03, 15.98it/s] 90%|█████████ | 452/500 [00:29<00:03, 15.66it/s] 91%|█████████ | 454/500 [00:29<00:03, 15.07it/s] 91%|█████████ | 456/500 [00:29<00:02, 15.16it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.57it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.23it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.36it/s] 93%|█████████▎| 464/500 [00:30<00:02, 15.60it/s] 93%|█████████▎| 466/500 [00:30<00:02, 15.84it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.96it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.86it/s] 94%|█████████▍| 472/500 [00:30<00:01, 16.08it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.11it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.13it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.61it/s] 96%|█████████▌| 480/500 [00:31<00:01, 14.31it/s] 96%|█████████▋| 482/500 [00:31<00:01, 13.57it/s] 97%|█████████▋| 484/500 [00:31<00:01, 13.18it/s] 97%|█████████▋| 486/500 [00:31<00:01, 12.91it/s] 98%|█████████▊| 488/500 [00:31<00:00, 12.73it/s] 98%|█████████▊| 490/500 [00:31<00:00, 12.78it/s] 98%|█████████▊| 492/500 [00:31<00:00, 13.70it/s] 99%|█████████▉| 494/500 [00:32<00:00, 14.36it/s] 99%|█████████▉| 496/500 [00:32<00:00, 14.82it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 15.09it/s]100%|██████████| 500/500 [00:32<00:00, 14.96it/s]100%|██████████| 500/500 [00:32<00:00, 15.39it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  20
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<54:27,  6.55s/it]  1%|          | 3/500 [00:06<14:29,  1.75s/it]  1%|          | 5/500 [00:06<07:18,  1.13it/s]  1%|▏         | 7/500 [00:06<04:25,  1.86it/s]  2%|▏         | 9/500 [00:07<02:56,  2.78it/s]  2%|▏         | 11/500 [00:13<10:59,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:16,  1.53it/s]  3%|▎         | 17/500 [00:13<03:48,  2.11it/s]  4%|▍         | 19/500 [00:14<02:47,  2.87it/s]  4%|▍         | 21/500 [00:20<09:55,  1.24s/it]  5%|▍         | 23/500 [00:20<07:01,  1.13it/s]  5%|▌         | 25/500 [00:20<05:04,  1.56it/s]  5%|▌         | 27/500 [00:21<03:43,  2.11it/s]  6%|▌         | 29/500 [00:21<02:46,  2.84it/s]  6%|▌         | 31/500 [00:27<09:34,  1.22s/it]  7%|▋         | 33/500 [00:27<06:49,  1.14it/s]  7%|▋         | 35/500 [00:27<04:54,  1.58it/s]  7%|▋         | 37/500 [00:28<03:34,  2.16it/s]  8%|▊         | 39/500 [00:28<02:38,  2.92it/s]  8%|▊         | 41/500 [00:34<09:02,  1.18s/it]  9%|▊         | 43/500 [00:34<06:27,  1.18it/s]  9%|▉         | 45/500 [00:34<04:38,  1.63it/s]  9%|▉         | 47/500 [00:34<03:22,  2.24it/s] 10%|▉         | 49/500 [00:35<02:31,  2.98it/s] 10%|█         | 51/500 [00:41<08:49,  1.18s/it] 11%|█         | 53/500 [00:41<06:18,  1.18it/s] 11%|█         | 55/500 [00:41<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:19,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:54<15:20,  2.10s/it] 13%|█▎        | 63/500 [00:54<10:51,  1.49s/it] 13%|█▎        | 65/500 [01:00<14:31,  2.00s/it] 13%|█▎        | 67/500 [01:01<10:18,  1.43s/it] 14%|█▍        | 69/500 [01:01<07:21,  1.03s/it] 14%|█▍        | 71/500 [01:13<18:48,  2.63s/it]Epoch:  1  	Training Loss: 0.23076128959655762
Test Loss:  365.72332763671875
Valid Loss:  361.21124267578125
Epoch:  2  	Training Loss: 355.6732177734375
Test Loss:  2.325253963470459
Valid Loss:  2.2963335514068604
Epoch:  3  	Training Loss: 2.2362418174743652
Test Loss:  2.074957847595215
Valid Loss:  2.0488786697387695
Epoch:  4  	Training Loss: 1.9943279027938843
Test Loss:  1.8491474390029907
Valid Loss:  1.8256611824035645
Epoch:  5  	Training Loss: 1.7761763334274292
Test Loss:  1.6475828886032104
Valid Loss:  1.6264071464538574
Epoch:  6  	Training Loss: 1.5814731121063232
Test Loss:  1.4668796062469482
Valid Loss:  1.4478081464767456
Epoch:  7  	Training Loss: 1.4070119857788086
Test Loss:  1.3048561811447144
Valid Loss:  1.287689208984375
Epoch:  8  	Training Loss: 1.2506492137908936
Test Loss:  1.1597669124603271
Valid Loss:  1.144322156906128
Epoch:  9  	Training Loss: 1.1106902360916138
Test Loss:  1.0312206745147705
Valid Loss:  1.0189793109893799
Epoch:  10  	Training Loss: 0.9882203936576843
Test Loss:  0.9487975835800171
Valid Loss:  0.9373865723609924
Epoch:  11  	Training Loss: 0.9139546751976013
Test Loss:  0.9034521579742432
Valid Loss:  0.8968222141265869
Epoch:  12  	Training Loss: 0.8735003471374512
Test Loss:  0.8825477361679077
Valid Loss:  0.8767712116241455
Epoch:  13  	Training Loss: 0.852635383605957
Test Loss:  0.8656331300735474
Valid Loss:  0.8604589104652405
Epoch:  14  	Training Loss: 0.8350642919540405
Test Loss:  0.850986123085022
Valid Loss:  0.8459423780441284
Epoch:  15  	Training Loss: 0.8200615644454956
Test Loss:  0.8380219340324402
Valid Loss:  0.8331013917922974
Epoch:  16  	Training Loss: 0.806849479675293
Test Loss:  0.8267508745193481
Valid Loss:  0.8216260075569153
Epoch:  17  	Training Loss: 0.7954285144805908
Test Loss:  0.8165346384048462
Valid Loss:  0.8109264373779297
Epoch:  18  	Training Loss: 0.78502357006073
Test Loss:  0.8110620975494385
Valid Loss:  0.8049741387367249
Epoch:  19  	Training Loss: 0.7792309522628784
Test Loss:  0.8059821128845215
Valid Loss:  0.7995495796203613
Epoch:  20  	Training Loss: 0.7739136219024658
Test Loss:  0.801053524017334
Valid Loss:  0.7943904399871826
Epoch:  21  	Training Loss: 0.7688666582107544
Test Loss:  0.7961686849594116
Valid Loss:  0.7893130779266357
Epoch:  22  	Training Loss: 0.7638875246047974
Test Loss:  0.792451024055481
Valid Loss:  0.7855415344238281
Epoch:  23  	Training Loss: 0.7601546049118042
Test Loss:  0.7887561321258545
Valid Loss:  0.7818127274513245
Epoch:  24  	Training Loss: 0.7564749717712402
Test Loss:  0.7851017713546753
Valid Loss:  0.7781111001968384
Epoch:  25  	Training Loss: 0.7528364658355713
Test Loss:  0.7814690470695496
Valid Loss:  0.7744573354721069
Epoch:  26  	Training Loss: 0.7492520809173584
Test Loss:  0.7778542041778564
Valid Loss:  0.7708289623260498
Epoch:  27  	Training Loss: 0.7457102537155151
Test Loss:  0.774257242679596
Valid Loss:  0.7672234177589417
Epoch:  28  	Training Loss: 0.7421978712081909
Test Loss:  0.770677924156189
Valid Loss:  0.7636425495147705
Epoch:  29  	Training Loss: 0.7387145757675171
Test Loss:  0.7671162486076355
Valid Loss:  0.7600818276405334
Epoch:  30  	Training Loss: 0.7352511286735535
Test Loss:  0.763572096824646
Valid Loss:  0.7565386295318604
Epoch:  31  	Training Loss: 0.7318059206008911
Test Loss:  0.7600452899932861
Valid Loss:  0.7530203461647034
Epoch:  32  	Training Loss: 0.7283823490142822
Test Loss:  0.7506431341171265
Valid Loss:  0.7437309622764587
Epoch:  33  	Training Loss: 0.7197294235229492
Test Loss:  0.7476341724395752
Valid Loss:  0.7411525249481201
Epoch:  34  	Training Loss: 0.717242419719696
Test Loss:  0.7466093301773071
Valid Loss:  0.7402551770210266
Epoch:  35  	Training Loss: 0.7162213921546936
Test Loss:  0.7461376190185547
Valid Loss:  0.7398485541343689
Epoch:  36  	Training Loss: 0.7156468629837036
Test Loss:  0.7459011077880859
Valid Loss:  0.739619255065918
Epoch:  37  	Training Loss: 0.715330183506012
Test Loss:  0.7457261085510254
Valid Loss:  0.739436149597168
Epoch:  38  	Training Loss: 0.7151013016700745
Test Loss:  0.7456490993499756
Valid Loss:  0.7392893433570862
Epoch:  39  	Training Loss: 0.7149502038955688
Test Loss:  0.7455966472625732
Valid Loss:  0.739176869392395
Epoch:  40  	Training Loss: 0.7148463726043701
Test Loss:  0.7455750107765198
Valid Loss:  0.7391132116317749
Epoch:  41  	Training Loss: 0.7147809267044067
Test Loss:  0.7455692291259766
Valid Loss:  0.7390809059143066
Epoch:  42  	Training Loss: 0.7147461175918579
Test Loss:  0.7455655336380005
Valid Loss:  0.7390619516372681
Epoch:  43  	Training Loss: 0.7147239446640015
Test Loss:  0.7455621957778931
Valid Loss:  0.7390509843826294
Epoch:  44  	Training Loss: 0.7147064208984375
Test Loss:  0.7455592751502991
Valid Loss:  0.7390426397323608
Epoch:  45  	Training Loss: 0.7146927118301392
Test Loss:  0.7455585598945618
Valid Loss:  0.73903489112854
Epoch:  46  	Training Loss: 0.7146812677383423
Test Loss:  0.7455586194992065
Valid Loss:  0.7390305995941162
Epoch:  47  	Training Loss: 0.7146733999252319
Test Loss:  0.7455586194992065
Valid Loss:  0.7390271425247192
Epoch:  48  	Training Loss: 0.7146685719490051
Test Loss:  0.7455586194992065
Valid Loss:  0.7390244603157043
Epoch:  49  	Training Loss: 0.7146654725074768
Test Loss:  0.7455586194992065
Valid Loss:  0.7390223741531372
Epoch:  50  	Training Loss: 0.7146636247634888
Test Loss:  0.7455586194992065
Valid Loss:  0.739020824432373
Epoch:  51  	Training Loss: 0.7146624326705933
Test Loss:  0.7455586194992065
Valid Loss:  0.7390192747116089
Epoch:  52  	Training Loss: 0.7146613001823425
Test Loss:  0.7455586194992065
Valid Loss:  0.7390179634094238
Epoch:  53  	Training Loss: 0.7146604061126709
Test Loss:  0.7455586791038513
Valid Loss:  0.7390174865722656
Epoch:  54  	Training Loss: 0.7146601676940918
Test Loss:  0.7455586791038513
Valid Loss:  0.7390173077583313
Epoch:  55  	Training Loss: 0.7146601676940918
Test Loss:  0.7455586194992065
Valid Loss:  0.739017128944397
Epoch:  56  	Training Loss: 0.714660108089447
Test Loss:  0.7455586791038513
Valid Loss:  0.7390170097351074
Epoch:  57  	Training Loss: 0.7146600484848022
Test Loss:  0.7455586791038513
Valid Loss:  0.7390168309211731
Epoch:  58  	Training Loss: 0.7146600484848022
Test Loss:  0.7455586194992065
Valid Loss:  0.7390166521072388
Epoch:  59  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  60  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  62  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  63  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  64  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  65  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  67  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  68  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390164732933044
Epoch:  69  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  70  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  72  	Training Loss: 0.7146599292755127
 15%|█▍        | 73/500 [01:14<13:15,  1.86s/it] 15%|█▌        | 75/500 [01:20<15:56,  2.25s/it] 15%|█▌        | 77/500 [01:20<11:15,  1.60s/it] 16%|█▌        | 79/500 [01:20<07:58,  1.14s/it] 16%|█▌        | 81/500 [01:33<18:39,  2.67s/it] 17%|█▋        | 83/500 [01:33<13:08,  1.89s/it] 17%|█▋        | 85/500 [01:39<15:56,  2.30s/it] 17%|█▋        | 87/500 [01:39<11:14,  1.63s/it] 18%|█▊        | 89/500 [01:40<07:57,  1.16s/it] 18%|█▊        | 91/500 [01:52<18:15,  2.68s/it] 19%|█▊        | 93/500 [01:52<12:51,  1.89s/it] 19%|█▉        | 95/500 [01:58<15:18,  2.27s/it] 19%|█▉        | 97/500 [01:59<10:47,  1.61s/it] 20%|█▉        | 99/500 [01:59<07:38,  1.14s/it] 20%|██        | 101/500 [02:11<17:48,  2.68s/it] 21%|██        | 103/500 [02:11<12:32,  1.90s/it] 21%|██        | 105/500 [02:18<14:51,  2.26s/it] 21%|██▏       | 107/500 [02:18<10:28,  1.60s/it] 22%|██▏       | 109/500 [02:18<07:25,  1.14s/it] 22%|██▏       | 111/500 [02:30<17:19,  2.67s/it] 23%|██▎       | 113/500 [02:30<12:11,  1.89s/it] 23%|██▎       | 115/500 [02:37<14:32,  2.27s/it] 23%|██▎       | 117/500 [02:37<10:15,  1.61s/it] 24%|██▍       | 119/500 [02:37<07:16,  1.14s/it] 24%|██▍       | 121/500 [02:50<17:00,  2.69s/it] 25%|██▍       | 123/500 [02:50<11:58,  1.91s/it] 25%|██▌       | 125/500 [02:56<14:13,  2.28s/it] 25%|██▌       | 127/500 [02:56<10:01,  1.61s/it] 26%|██▌       | 129/500 [02:56<07:05,  1.15s/it] 26%|██▌       | 131/500 [03:09<16:23,  2.66s/it]Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  73  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  74  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  75  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  77  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390164732933044
Epoch:  78  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  79  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  80  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  82  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  83  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  84  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  85  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  87  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  88  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  89  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  90  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  92  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  93  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  94  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  95  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  97  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  98  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  99  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  100  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  102  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  103  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  104  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  105  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  107  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  108  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  109  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  110  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  112  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  113  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  114  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  115  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  117  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  118  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  119  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  120  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  122  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  123  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  124  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  125  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  127  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  128  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  129  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  130  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  132  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  133  	Training Loss: 0.7146598696708679
 27%|██▋       | 133/500 [03:09<11:31,  1.88s/it] 27%|██▋       | 135/500 [03:15<13:49,  2.27s/it] 27%|██▋       | 137/500 [03:15<09:44,  1.61s/it] 28%|██▊       | 139/500 [03:15<06:54,  1.15s/it] 28%|██▊       | 141/500 [03:28<16:07,  2.70s/it] 29%|██▊       | 143/500 [03:28<11:21,  1.91s/it] 29%|██▉       | 145/500 [03:35<13:36,  2.30s/it] 29%|██▉       | 147/500 [03:35<09:36,  1.63s/it] 30%|██▉       | 149/500 [03:35<06:48,  1.16s/it] 30%|███       | 151/500 [03:47<15:41,  2.70s/it] 31%|███       | 153/500 [03:48<11:02,  1.91s/it] 31%|███       | 155/500 [03:54<13:03,  2.27s/it] 31%|███▏      | 157/500 [03:54<09:12,  1.61s/it] 32%|███▏      | 159/500 [03:54<06:31,  1.15s/it] 32%|███▏      | 159/500 [04:04<06:31,  1.15s/it] 32%|███▏      | 161/500 [04:07<15:19,  2.71s/it] 33%|███▎      | 163/500 [04:07<10:46,  1.92s/it] 33%|███▎      | 165/500 [04:13<12:49,  2.30s/it] 33%|███▎      | 167/500 [04:13<09:02,  1.63s/it] 34%|███▍      | 169/500 [04:14<06:23,  1.16s/it] 34%|███▍      | 169/500 [04:24<06:23,  1.16s/it] 34%|███▍      | 171/500 [04:26<14:48,  2.70s/it] 35%|███▍      | 173/500 [04:26<10:24,  1.91s/it] 35%|███▌      | 175/500 [04:33<12:20,  2.28s/it] 35%|███▌      | 177/500 [04:33<08:41,  1.62s/it] 36%|███▌      | 179/500 [04:33<06:09,  1.15s/it] 36%|███▌      | 179/500 [04:44<06:09,  1.15s/it] 36%|███▌      | 181/500 [04:45<14:16,  2.69s/it] 37%|███▋      | 183/500 [04:46<10:03,  1.90s/it] 37%|███▋      | 185/500 [04:52<12:02,  2.29s/it] 37%|███▋      | 187/500 [04:52<08:29,  1.63s/it] 38%|███▊      | 189/500 [04:52<06:00,  1.16s/it] 38%|███▊      | 189/500 [05:04<06:00,  1.16s/it] 38%|███▊      | 191/500 [05:05<13:53,  2.70s/it] 39%|███▊      | 193/500 [05:05<09:45,  1.91s/it]Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  134  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  135  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.7146598696708679
Test Loss:  0.7455587387084961
Valid Loss:  0.7390165328979492
Epoch:  137  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  138  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390164732933044
Epoch:  139  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  140  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  142  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  143  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  144  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  145  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  147  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  148  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  149  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  150  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  152  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  153  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  154  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  155  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  157  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  158  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  159  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  160  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  162  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  163  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  164  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  165  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  167  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  168  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  169  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  170  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  172  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  173  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  174  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  175  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  177  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  178  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  179  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  180  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  182  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  183  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  184  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  185  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  187  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  188  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  189  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  190  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  192  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  193  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
 39%|███▉      | 195/500 [05:11<11:38,  2.29s/it] 39%|███▉      | 197/500 [05:11<08:12,  1.63s/it] 40%|███▉      | 199/500 [05:12<05:48,  1.16s/it] 40%|████      | 201/500 [05:24<13:20,  2.68s/it] 41%|████      | 203/500 [05:24<09:23,  1.90s/it] 41%|████      | 205/500 [05:31<11:11,  2.28s/it] 41%|████▏     | 207/500 [05:31<07:53,  1.62s/it] 42%|████▏     | 209/500 [05:31<05:34,  1.15s/it] 42%|████▏     | 211/500 [05:43<12:47,  2.66s/it] 43%|████▎     | 213/500 [05:43<09:01,  1.89s/it] 43%|████▎     | 215/500 [05:50<10:56,  2.30s/it] 43%|████▎     | 217/500 [05:50<07:42,  1.63s/it] 44%|████▍     | 219/500 [05:50<05:27,  1.16s/it] 44%|████▍     | 221/500 [06:03<12:34,  2.71s/it] 45%|████▍     | 223/500 [06:03<08:50,  1.92s/it] 45%|████▌     | 225/500 [06:09<10:27,  2.28s/it] 45%|████▌     | 227/500 [06:09<07:22,  1.62s/it] 46%|████▌     | 229/500 [06:09<05:12,  1.15s/it] 46%|████▌     | 231/500 [06:22<12:00,  2.68s/it] 47%|████▋     | 233/500 [06:22<08:25,  1.89s/it] 47%|████▋     | 235/500 [06:28<10:02,  2.27s/it] 47%|████▋     | 237/500 [06:29<07:03,  1.61s/it] 48%|████▊     | 239/500 [06:29<05:00,  1.15s/it] 48%|████▊     | 241/500 [06:41<11:39,  2.70s/it] 49%|████▊     | 243/500 [06:41<08:11,  1.91s/it] 49%|████▉     | 245/500 [06:48<09:44,  2.29s/it] 49%|████▉     | 247/500 [06:48<06:51,  1.63s/it] 50%|████▉     | 249/500 [06:48<04:50,  1.16s/it] 50%|█████     | 251/500 [07:01<11:14,  2.71s/it] 51%|█████     | 253/500 [07:01<07:53,  1.92s/it]Epoch:  194  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  195  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  197  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  198  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  199  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  200  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  202  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  203  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  204  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  205  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  207  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  208  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  209  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  210  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  212  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  213  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  214  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  215  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  217  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  218  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  219  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  220  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  222  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  223  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  224  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  225  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  227  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  228  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  229  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  230  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  232  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  233  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  234  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  235  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  237  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  238  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  239  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  240  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  242  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  243  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  244  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  245  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  247  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  248  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  249  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  250  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  252  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  253  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  254  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:   51%|█████     | 255/500 [07:07<09:28,  2.32s/it] 51%|█████▏    | 257/500 [07:08<06:40,  1.65s/it] 52%|█████▏    | 259/500 [07:08<04:42,  1.17s/it] 52%|█████▏    | 261/500 [07:20<10:48,  2.71s/it] 53%|█████▎    | 263/500 [07:20<07:35,  1.92s/it] 53%|█████▎    | 265/500 [07:27<08:59,  2.30s/it] 53%|█████▎    | 267/500 [07:27<06:19,  1.63s/it] 54%|█████▍    | 269/500 [07:27<04:28,  1.16s/it] 54%|█████▍    | 271/500 [07:40<10:14,  2.68s/it] 55%|█████▍    | 273/500 [07:40<07:11,  1.90s/it] 55%|█████▌    | 275/500 [07:46<08:34,  2.28s/it] 55%|█████▌    | 277/500 [07:46<06:01,  1.62s/it] 56%|█████▌    | 279/500 [07:46<04:15,  1.15s/it] 56%|█████▌    | 281/500 [07:59<09:53,  2.71s/it] 57%|█████▋    | 283/500 [07:59<06:56,  1.92s/it] 57%|█████▋    | 285/500 [08:06<08:15,  2.30s/it] 57%|█████▋    | 287/500 [08:06<05:47,  1.63s/it] 58%|█████▊    | 289/500 [08:06<04:05,  1.16s/it] 58%|█████▊    | 291/500 [08:19<09:30,  2.73s/it] 59%|█████▊    | 293/500 [08:19<06:39,  1.93s/it] 59%|█████▉    | 295/500 [08:25<07:53,  2.31s/it] 59%|█████▉    | 297/500 [08:25<05:32,  1.64s/it] 60%|█████▉    | 299/500 [08:25<03:54,  1.17s/it] 60%|██████    | 301/500 [08:38<08:57,  2.70s/it] 61%|██████    | 303/500 [08:38<06:16,  1.91s/it] 61%|██████    | 305/500 [08:45<07:31,  2.32s/it] 61%|██████▏   | 307/500 [08:45<05:17,  1.64s/it] 62%|██████▏   | 309/500 [08:45<03:43,  1.17s/it] 62%|██████▏   | 311/500 [08:58<08:34,  2.72s/it] 63%|██████▎   | 313/500 [08:58<06:00,  1.93s/it]0.7390165328979492
Epoch:  255  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  257  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  258  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  259  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  260  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  262  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  263  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  264  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  265  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  267  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  268  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  269  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  270  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  272  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  273  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  274  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  275  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  277  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  278  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  279  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  280  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  282  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  283  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  284  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  285  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390164732933044
Epoch:  287  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  288  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  289  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  290  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  292  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  293  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  294  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  295  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  297  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  298  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  299  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  300  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  302  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  303  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  304  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  305  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  307  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390164732933044
Epoch:  308  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  309  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  310  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  312  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  313  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  314  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  315  	Training Loss: 0.7146598696708679
Test Loss:   63%|██████▎   | 315/500 [09:04<07:12,  2.34s/it] 63%|██████▎   | 317/500 [09:04<05:03,  1.66s/it] 64%|██████▍   | 319/500 [09:05<03:34,  1.18s/it] 64%|██████▍   | 321/500 [09:17<08:13,  2.76s/it] 65%|██████▍   | 323/500 [09:18<05:45,  1.95s/it] 65%|██████▌   | 325/500 [09:18<04:02,  1.39s/it] 65%|██████▌   | 327/500 [09:18<02:51,  1.01it/s] 66%|██████▌   | 329/500 [09:18<02:01,  1.40it/s] 66%|██████▌   | 331/500 [09:31<06:46,  2.41s/it] 67%|██████▋   | 333/500 [09:31<04:44,  1.71s/it] 67%|██████▋   | 335/500 [09:37<05:55,  2.15s/it] 67%|██████▋   | 337/500 [09:37<04:09,  1.53s/it] 68%|██████▊   | 339/500 [09:38<02:55,  1.09s/it] 68%|██████▊   | 341/500 [09:50<07:07,  2.69s/it] 69%|██████▊   | 343/500 [09:51<04:59,  1.91s/it] 69%|██████▉   | 345/500 [09:51<03:30,  1.36s/it] 69%|██████▉   | 347/500 [09:51<02:29,  1.02it/s] 70%|██████▉   | 349/500 [09:51<01:46,  1.42it/s] 70%|███████   | 351/500 [10:04<05:55,  2.39s/it] 71%|███████   | 353/500 [10:04<04:08,  1.69s/it] 71%|███████   | 355/500 [10:10<05:09,  2.13s/it] 71%|███████   | 356/500 [10:10<04:15,  1.78s/it] 72%|███████▏  | 358/500 [10:10<02:50,  1.20s/it] 72%|███████▏  | 360/500 [10:17<04:15,  1.83s/it] 72%|███████▏  | 361/500 [10:23<06:09,  2.66s/it] 73%|███████▎  | 363/500 [10:23<04:00,  1.76s/it] 73%|███████▎  | 365/500 [10:29<05:02,  2.24s/it] 73%|███████▎  | 367/500 [10:30<03:25,  1.54s/it] 74%|███████▍  | 369/500 [10:30<02:20,  1.08s/it] 74%|███████▍  | 371/500 [10:42<05:45,  2.67s/it] 75%|███████▍  | 373/500 [10:42<03:58,  1.87s/it] 75%|███████▌  | 375/500 [10:49<04:43,  2.27s/it]0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  317  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  318  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  319  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  320  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  322  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  323  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  324  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  325  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  326  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  327  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  328  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  329  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  330  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  332  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  333  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  334  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  335  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  337  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  338  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  339  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  340  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  342  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  343  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  344  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  345  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  346  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  347  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  348  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390164732933044
Epoch:  349  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  350  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  352  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  353  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  354  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  355  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  357  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  358  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  359  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  360  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  362  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  363  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  364  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  365  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  367  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  368  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  369  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  370  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  372  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  373  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  374  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  375  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  377  	Training Loss: 0.7146598100662231
 75%|███████▌  | 377/500 [10:49<03:16,  1.60s/it] 76%|███████▌  | 379/500 [10:49<02:17,  1.14s/it] 76%|███████▌  | 381/500 [11:02<05:22,  2.71s/it] 77%|███████▋  | 383/500 [11:02<03:44,  1.92s/it] 77%|███████▋  | 385/500 [11:08<04:26,  2.32s/it] 77%|███████▋  | 387/500 [11:08<03:05,  1.64s/it] 78%|███████▊  | 389/500 [11:09<02:09,  1.17s/it] 78%|███████▊  | 391/500 [11:21<04:54,  2.70s/it] 79%|███████▊  | 393/500 [11:21<03:24,  1.91s/it] 79%|███████▉  | 395/500 [11:27<03:58,  2.27s/it] 79%|███████▉  | 397/500 [11:28<02:45,  1.61s/it] 80%|███████▉  | 399/500 [11:28<01:55,  1.15s/it] 80%|████████  | 401/500 [11:40<04:24,  2.67s/it] 81%|████████  | 403/500 [11:40<03:03,  1.89s/it] 81%|████████  | 405/500 [11:47<03:36,  2.28s/it] 81%|████████▏ | 407/500 [11:47<02:30,  1.62s/it] 82%|████████▏ | 409/500 [11:47<01:44,  1.15s/it] 82%|████████▏ | 411/500 [12:00<03:59,  2.69s/it] 83%|████████▎ | 413/500 [12:00<02:46,  1.91s/it] 83%|████████▎ | 415/500 [12:06<03:14,  2.29s/it] 83%|████████▎ | 417/500 [12:06<02:14,  1.62s/it] 84%|████████▍ | 419/500 [12:06<01:33,  1.16s/it] 84%|████████▍ | 421/500 [12:19<03:32,  2.69s/it] 85%|████████▍ | 423/500 [12:19<02:26,  1.90s/it] 85%|████████▌ | 425/500 [12:25<02:50,  2.27s/it] 85%|████████▌ | 427/500 [12:25<01:57,  1.62s/it] 86%|████████▌ | 429/500 [12:26<01:21,  1.15s/it] 86%|████████▌ | 431/500 [12:38<03:05,  2.68s/it] 87%|████████▋ | 433/500 [12:38<02:07,  1.90s/it] 87%|████████▋ | 435/500 [12:45<02:29,  2.30s/it] 87%|████████▋ | 437/500 [12:45<01:42,  1.63s/it]Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  378  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  379  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  380  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  382  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  383  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  384  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  385  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  387  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  388  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  389  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  390  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  392  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  393  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  394  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  395  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  397  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  398  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  399  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  400  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  402  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  403  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  404  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  405  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  407  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  408  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  409  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  410  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  412  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  413  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  414  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  415  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  417  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  418  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  419  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  420  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  422  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  423  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  424  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  425  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  427  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  428  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  429  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  430  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  432  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  433  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  434  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  435  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  437  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
 88%|████████▊ | 439/500 [12:45<01:10,  1.16s/it] 88%|████████▊ | 441/500 [12:57<02:38,  2.69s/it] 89%|████████▊ | 443/500 [12:58<01:48,  1.90s/it] 89%|████████▉ | 445/500 [13:04<02:04,  2.27s/it] 89%|████████▉ | 447/500 [13:04<01:25,  1.61s/it] 90%|████████▉ | 449/500 [13:04<00:58,  1.15s/it] 90%|████████▉ | 449/500 [13:14<00:58,  1.15s/it] 90%|█████████ | 451/500 [13:16<02:09,  2.65s/it] 91%|█████████ | 453/500 [13:17<01:28,  1.87s/it] 91%|█████████ | 455/500 [13:23<01:41,  2.25s/it] 91%|█████████▏| 457/500 [13:23<01:08,  1.60s/it] 92%|█████████▏| 459/500 [13:23<00:46,  1.14s/it] 92%|█████████▏| 461/500 [13:29<01:07,  1.74s/it] 93%|█████████▎| 463/500 [13:29<00:45,  1.24s/it] 93%|█████████▎| 465/500 [13:36<01:03,  1.80s/it] 93%|█████████▎| 467/500 [13:36<00:42,  1.29s/it] 94%|█████████▍| 469/500 [13:36<00:28,  1.09it/s] 94%|█████████▍| 471/500 [13:48<01:12,  2.51s/it] 95%|█████████▍| 473/500 [13:49<00:48,  1.78s/it] 95%|█████████▌| 475/500 [13:55<00:54,  2.16s/it] 95%|█████████▌| 477/500 [13:55<00:35,  1.54s/it] 96%|█████████▌| 479/500 [13:55<00:23,  1.10s/it] 96%|█████████▌| 481/500 [14:08<00:50,  2.66s/it] 97%|█████████▋| 483/500 [14:08<00:31,  1.88s/it] 97%|█████████▋| 485/500 [14:14<00:33,  2.25s/it] 97%|█████████▋| 487/500 [14:14<00:20,  1.60s/it] 98%|█████████▊| 489/500 [14:14<00:12,  1.14s/it] 98%|█████████▊| 489/500 [14:24<00:12,  1.14s/it] 98%|█████████▊| 491/500 [14:27<00:24,  2.69s/it] 99%|█████████▊| 493/500 [14:27<00:13,  1.90s/it] 99%|█████████▉| 495/500 [14:33<00:11,  2.29s/it] 99%|█████████▉| 497/500 [14:34<00:04,  1.63s/it]Epoch:  438  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  439  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  440  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  442  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  443  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  444  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  445  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  447  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  448  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  449  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  450  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  452  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  453  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  454  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  455  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  457  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  458  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  459  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  460  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  461  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  462  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  463  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  464  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  465  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  467  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  468  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  469  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  470  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  472  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  473  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  474  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  475  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  477  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  478  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  479  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  480  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  482  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  483  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  484  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  485  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  487  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  488  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  489  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390164732933044
Epoch:  490  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  492  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586791038513
Valid Loss:  0.7390165328979492
Epoch:  493  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  494  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  495  	Training Loss: 0.7146599292755127
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  497  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  498  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
Epoch:  499  	Training Loss: 0.7146598696708679
Test Loss:  0.7455586194992065
Valid Loss:  100%|█████████▉| 499/500 [14:34<00:01,  1.16s/it]100%|██████████| 500/500 [14:40<00:00,  1.76s/it]
0.7390165328979492
Epoch:  500  	Training Loss: 0.7146598100662231
Test Loss:  0.7455586194992065
Valid Loss:  0.7390165328979492
**************************************************learning rate decay**************************************************
seed is  20
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:08,  6.27s/it]  1%|          | 3/500 [00:06<13:56,  1.68s/it]  1%|          | 5/500 [00:06<07:03,  1.17it/s]  1%|▏         | 7/500 [00:06<04:17,  1.91it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<10:55,  1.34s/it]  3%|▎         | 13/500 [00:13<07:26,  1.09it/s]  3%|▎         | 15/500 [00:13<05:11,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.97it/s]  4%|▍         | 21/500 [00:20<09:34,  1.20s/it]  5%|▍         | 23/500 [00:20<06:50,  1.16it/s]  5%|▌         | 25/500 [00:20<04:57,  1.60it/s]  5%|▌         | 27/500 [00:20<03:38,  2.16it/s]  6%|▌         | 29/500 [00:20<02:44,  2.87it/s]  6%|▌         | 31/500 [00:27<09:21,  1.20s/it]  7%|▋         | 33/500 [00:27<06:40,  1.17it/s]  7%|▋         | 35/500 [00:27<04:48,  1.61it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:35,  2.97it/s]  8%|▊         | 39/500 [00:38<02:35,  2.97it/s]  8%|▊         | 41/500 [00:40<16:10,  2.12s/it]  9%|▊         | 43/500 [00:40<11:26,  1.50s/it]  9%|▉         | 45/500 [00:40<08:07,  1.07s/it]  9%|▉         | 47/500 [00:40<05:48,  1.30it/s] 10%|▉         | 49/500 [00:40<04:11,  1.79it/s] 10%|█         | 51/500 [00:53<16:54,  2.26s/it] 11%|█         | 53/500 [00:53<11:57,  1.61s/it] 11%|█         | 55/500 [00:53<08:32,  1.15s/it] 11%|█▏        | 57/500 [00:53<06:08,  1.20it/s] 12%|█▏        | 59/500 [00:53<04:28,  1.65it/s] 12%|█▏        | 61/500 [01:00<10:04,  1.38s/it] 13%|█▎        | 63/500 [01:00<07:10,  1.02it/s] 13%|█▎        | 65/500 [01:00<05:08,  1.41it/s] 13%|█▎        | 67/500 [01:00<03:43,  1.94it/s] 14%|█▍        | 69/500 [01:00<02:43,  2.63it/s]Epoch:  1  	Training Loss: 0.23076128959655762
Test Loss:  8.94984245300293
Valid Loss:  8.892338752746582
Epoch:  2  	Training Loss: 8.784073829650879
Test Loss:  40.14128112792969
Valid Loss:  39.27476501464844
Epoch:  3  	Training Loss: 39.20731735229492
Test Loss:  3.221388578414917
Valid Loss:  3.2122721672058105
Epoch:  4  	Training Loss: 3.202108860015869
Test Loss:  3.2067558765411377
Valid Loss:  3.2006888389587402
Epoch:  5  	Training Loss: 3.1896400451660156
Test Loss:  3.196326494216919
Valid Loss:  3.1920244693756104
Epoch:  6  	Training Loss: 3.1792826652526855
Test Loss:  3.185089111328125
Valid Loss:  3.1823477745056152
Epoch:  7  	Training Loss: 3.1680972576141357
Test Loss:  3.1747782230377197
Valid Loss:  3.1733274459838867
Epoch:  8  	Training Loss: 3.1581871509552
Test Loss:  3.1651363372802734
Valid Loss:  3.1644341945648193
Epoch:  9  	Training Loss: 3.1487882137298584
Test Loss:  3.1558427810668945
Valid Loss:  3.1556074619293213
Epoch:  10  	Training Loss: 3.1395182609558105
Test Loss:  3.1466970443725586
Valid Loss:  3.14686918258667
Epoch:  11  	Training Loss: 3.1303539276123047
Test Loss:  3.137655735015869
Valid Loss:  3.13830828666687
Epoch:  12  	Training Loss: 3.121377468109131
Test Loss:  46.10654830932617
Valid Loss:  45.051544189453125
Epoch:  13  	Training Loss: 44.941490173339844
Test Loss:  2.3632357120513916
Valid Loss:  2.3617472648620605
Epoch:  14  	Training Loss: 2.3664591312408447
Test Loss:  2.350153684616089
Valid Loss:  2.351707935333252
Epoch:  15  	Training Loss: 2.35689640045166
Test Loss:  2.3464884757995605
Valid Loss:  2.3489503860473633
Epoch:  16  	Training Loss: 2.353503704071045
Test Loss:  2.343973398208618
Valid Loss:  2.3469762802124023
Epoch:  17  	Training Loss: 2.350847005844116
Test Loss:  2.3419435024261475
Valid Loss:  2.345524787902832
Epoch:  18  	Training Loss: 2.3488779067993164
Test Loss:  2.3403563499450684
Valid Loss:  2.3443403244018555
Epoch:  19  	Training Loss: 2.347400665283203
Test Loss:  2.3390655517578125
Valid Loss:  2.3432343006134033
Epoch:  20  	Training Loss: 2.346102476119995
Test Loss:  2.3378469944000244
Valid Loss:  2.3421287536621094
Epoch:  21  	Training Loss: 2.344813346862793
Test Loss:  2.336672782897949
Valid Loss:  2.3411104679107666
Epoch:  22  	Training Loss: 2.3436009883880615
Test Loss:  1.3964742422103882
Valid Loss:  1.5027971267700195
Epoch:  23  	Training Loss: 1.5034019947052002
Test Loss:  0.548588752746582
Valid Loss:  0.5551444888114929
Epoch:  24  	Training Loss: 0.5744956731796265
Test Loss:  0.13395166397094727
Valid Loss:  0.1587236225605011
Epoch:  25  	Training Loss: 0.165703684091568
Test Loss:  0.05193660408258438
Valid Loss:  0.06407246738672256
Epoch:  26  	Training Loss: 0.07495181262493134
Test Loss:  0.029685024172067642
Valid Loss:  0.04101273790001869
Epoch:  27  	Training Loss: 0.04612930864095688
Test Loss:  0.01902814768254757
Valid Loss:  0.027606580406427383
Epoch:  28  	Training Loss: 0.03221704065799713
Test Loss:  0.014063211157917976
Valid Loss:  0.02110104262828827
Epoch:  29  	Training Loss: 0.023656560108065605
Test Loss:  0.010229700244963169
Valid Loss:  0.016038862988352776
Epoch:  30  	Training Loss: 0.017896397039294243
Test Loss:  0.008052928373217583
Valid Loss:  0.01289818063378334
Epoch:  31  	Training Loss: 0.013924354687333107
Test Loss:  0.006445165723562241
Valid Loss:  0.010581478476524353
Epoch:  32  	Training Loss: 0.011165767908096313
Test Loss:  0.005466993432492018
Valid Loss:  0.008926762267947197
Epoch:  33  	Training Loss: 0.009288020431995392
Test Loss:  0.005718299187719822
Valid Loss:  0.008732789196074009
Epoch:  34  	Training Loss: 0.008481909520924091
Test Loss:  0.0059526157565414906
Valid Loss:  0.008819721639156342
Epoch:  35  	Training Loss: 0.008384468033909798
Test Loss:  0.006128775887191296
Valid Loss:  0.008910801261663437
Epoch:  36  	Training Loss: 0.00842972844839096
Test Loss:  0.0062158540822565556
Valid Loss:  0.008941900916397572
Epoch:  37  	Training Loss: 0.008380049839615822
Test Loss:  0.006217483896762133
Valid Loss:  0.008927993476390839
Epoch:  38  	Training Loss: 0.00833052210509777
Test Loss:  0.00619457708671689
Valid Loss:  0.008902272209525108
Epoch:  39  	Training Loss: 0.008286353200674057
Test Loss:  0.006224486511200666
Valid Loss:  0.008926057256758213
Epoch:  40  	Training Loss: 0.008292672224342823
Test Loss:  0.006206853315234184
Valid Loss:  0.008921157568693161
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.008336417376995087
Test Loss:  0.0043353671208024025
Valid Loss:  0.007002290338277817
Epoch:  42  	Training Loss: 0.006744104437530041
Test Loss:  0.004041947424411774
Valid Loss:  0.0061768945306539536
Epoch:  43  	Training Loss: 0.0055570099502801895
Test Loss:  0.0031502321362495422
Valid Loss:  0.005227827932685614
Epoch:  44  	Training Loss: 0.005018893629312515
Test Loss:  0.0037707434967160225
Valid Loss:  0.005385188385844231
Epoch:  45  	Training Loss: 0.00468609482049942
Test Loss:  0.0025715220253914595
Valid Loss:  0.004535791929811239
Epoch:  46  	Training Loss: 0.004564795643091202
Test Loss:  0.004554294981062412
Valid Loss:  0.005764062516391277
Epoch:  47  	Training Loss: 0.004786673933267593
Test Loss:  0.002835525432601571
Valid Loss:  0.004911123774945736
Epoch:  48  	Training Loss: 0.005308236926794052
Test Loss:  0.007338052615523338
Valid Loss:  0.008206576108932495
Epoch:  49  	Training Loss: 0.0066283089108765125
Test Loss:  0.005141132511198521
Valid Loss:  0.007533317431807518
Epoch:  50  	Training Loss: 0.008537869900465012
Test Loss:  0.015070006251335144
Valid Loss:  0.01531822420656681
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.012656697072088718
Test Loss:  0.011631481349468231
Valid Loss:  0.011968150734901428
Epoch:  52  	Training Loss: 0.009732317179441452
Test Loss:  0.005879195407032967
Valid Loss:  0.0070689525455236435
Epoch:  53  	Training Loss: 0.005805621389299631
Test Loss:  0.0042812637984752655
Valid Loss:  0.005791215691715479
Epoch:  54  	Training Loss: 0.004924879875034094
Test Loss:  0.0036216722801327705
Valid Loss:  0.005282088182866573
Epoch:  55  	Training Loss: 0.004622435662895441
Test Loss:  0.003317654598504305
Valid Loss:  0.005040754098445177
Epoch:  56  	Training Loss: 0.004481013864278793
Test Loss:  0.0031464335042983294
Valid Loss:  0.004903223365545273
Epoch:  57  	Training Loss: 0.004417005926370621
Test Loss:  0.003086940385401249
Valid Loss:  0.0048570167273283005
Epoch:  58  	Training Loss: 0.004383178427815437
Test Loss:  0.003026227466762066
Valid Loss:  0.004793576430529356
Epoch:  59  	Training Loss: 0.004379435442388058
Test Loss:  0.0030321008525788784
Valid Loss:  0.004771308042109013
Epoch:  60  	Training Loss: 0.004320926498621702
Test Loss:  0.0029977005906403065
Valid Loss:  0.0047271098010241985
Epoch:  61  	Training Loss: 0.004328496754169464
Test Loss:  0.003014500020071864
Valid Loss:  0.004711817484349012
Epoch:  62  	Training Loss: 0.0042685894295573235
Test Loss:  0.0030113891698420048
Valid Loss:  0.0047062598168849945
Epoch:  63  	Training Loss: 0.004264163319021463
Test Loss:  0.00300868833437562
Valid Loss:  0.004700963385403156
Epoch:  64  	Training Loss: 0.004259818233549595
Test Loss:  0.003006325103342533
Valid Loss:  0.004695899784564972
Epoch:  65  	Training Loss: 0.004255546722561121
Test Loss:  0.0030042349826544523
Valid Loss:  0.0046910312958061695
Epoch:  66  	Training Loss: 0.004251348786056042
Test Loss:  0.003002369776368141
Valid Loss:  0.004686329513788223
Epoch:  67  	Training Loss: 0.004247218370437622
Test Loss:  0.0030006866436451674
Valid Loss:  0.004681773483753204
Epoch:  68  	Training Loss: 0.004243151284754276
Test Loss:  0.002999149262905121
Valid Loss:  0.0046773506328463554
Epoch:  69  	Training Loss: 0.004239145666360855
Test Loss:  0.00299773458391428
Valid Loss:  0.004673043265938759
Epoch:  70  	Training Loss: 0.004235203377902508
Test Loss:  0.0029964130371809006
Valid Loss:  0.004668833687901497
 14%|█▍        | 71/500 [01:06<08:37,  1.21s/it] 14%|█▍        | 72/500 [01:07<07:13,  1.01s/it] 15%|█▍        | 74/500 [01:07<04:58,  1.43it/s] 15%|█▌        | 76/500 [01:07<03:32,  1.99it/s] 16%|█▌        | 78/500 [01:07<02:36,  2.70it/s] 16%|█▌        | 80/500 [01:07<01:58,  3.55it/s] 16%|█▋        | 82/500 [01:13<08:03,  1.16s/it] 17%|█▋        | 84/500 [01:14<05:42,  1.22it/s] 17%|█▋        | 86/500 [01:14<04:05,  1.69it/s] 18%|█▊        | 88/500 [01:14<02:58,  2.31it/s] 18%|█▊        | 90/500 [01:14<02:11,  3.11it/s] 18%|█▊        | 92/500 [01:20<07:54,  1.16s/it] 19%|█▉        | 94/500 [01:20<05:40,  1.19it/s] 19%|█▉        | 96/500 [01:21<04:07,  1.64it/s] 20%|█▉        | 98/500 [01:21<03:01,  2.21it/s] 20%|██        | 100/500 [01:21<02:14,  2.98it/s] 20%|██        | 102/500 [01:27<07:54,  1.19s/it] 21%|██        | 104/500 [01:27<05:38,  1.17it/s] 21%|██        | 106/500 [01:27<04:04,  1.61it/s] 22%|██▏       | 108/500 [01:28<02:57,  2.21it/s] 22%|██▏       | 110/500 [01:28<02:11,  2.97it/s] 22%|██▏       | 112/500 [01:34<07:39,  1.18s/it] 23%|██▎       | 114/500 [01:34<05:27,  1.18it/s] 23%|██▎       | 116/500 [01:34<03:55,  1.63it/s] 24%|██▎       | 118/500 [01:34<02:51,  2.22it/s] 24%|██▍       | 120/500 [01:35<02:09,  2.93it/s] 24%|██▍       | 122/500 [01:41<07:24,  1.18s/it] 25%|██▍       | 124/500 [01:41<05:16,  1.19it/s] 25%|██▌       | 126/500 [01:41<03:47,  1.64it/s] 26%|██▌       | 128/500 [01:41<02:45,  2.24it/s] 26%|██▌       | 130/500 [01:41<02:02,  3.02it/s] 26%|██▋       | 132/500 [01:48<07:17,  1.19s/it] 27%|██▋       | 134/500 [01:48<05:14,  1.17it/s] 27%|██▋       | 136/500 [01:48<03:46,  1.60it/s] 28%|██▊       | 138/500 [01:48<02:45,  2.19it/s]Epoch:  71  	Training Loss: 0.004231317900121212
Test Loss:  0.0029950817115604877
Valid Loss:  0.004664719104766846
Epoch:  72  	Training Loss: 0.0042274887673556805
Test Loss:  0.0030880682170391083
Valid Loss:  0.004576073959469795
Epoch:  73  	Training Loss: 0.0041090999729931355
Test Loss:  0.0030063523445278406
Valid Loss:  0.004454056732356548
Epoch:  74  	Training Loss: 0.004021618980914354
Test Loss:  0.0029863237868994474
Valid Loss:  0.004376190714538097
Epoch:  75  	Training Loss: 0.003937721252441406
Test Loss:  0.0029234224930405617
Valid Loss:  0.004268079996109009
Epoch:  76  	Training Loss: 0.003851121524348855
Test Loss:  0.0029022765811532736
Valid Loss:  0.0042040287517011166
Epoch:  77  	Training Loss: 0.003767910413444042
Test Loss:  0.002812120132148266
Valid Loss:  0.004088916815817356
Epoch:  78  	Training Loss: 0.0036886301822960377
Test Loss:  0.0028030143585056067
Valid Loss:  0.004043807741254568
Epoch:  79  	Training Loss: 0.0036112810485064983
Test Loss:  0.0026981618721038103
Valid Loss:  0.003929340746253729
Epoch:  80  	Training Loss: 0.0035403019282966852
Test Loss:  0.0027223515789955854
Valid Loss:  0.003907253034412861
Epoch:  81  	Training Loss: 0.0034710378386080265
Test Loss:  0.0026028789579868317
Valid Loss:  0.0037900987081229687
Epoch:  82  	Training Loss: 0.0034118727780878544
Test Loss:  0.0026373998261988163
Valid Loss:  0.0038039875216782093
Epoch:  83  	Training Loss: 0.00339146563783288
Test Loss:  0.0026514767669141293
Valid Loss:  0.0038085156120359898
Epoch:  84  	Training Loss: 0.0033835778012871742
Test Loss:  0.002659226767718792
Valid Loss:  0.003809390589594841
Epoch:  85  	Training Loss: 0.003377168904989958
Test Loss:  0.002661370672285557
Valid Loss:  0.003806427586823702
Epoch:  86  	Training Loss: 0.00337136909365654
Test Loss:  0.002660715952515602
Valid Loss:  0.0038016117177903652
Epoch:  87  	Training Loss: 0.003365814685821533
Test Loss:  0.0026599958073347807
Valid Loss:  0.0037970959674566984
Epoch:  88  	Training Loss: 0.003360510803759098
Test Loss:  0.0026592016220092773
Valid Loss:  0.003792624920606613
Epoch:  89  	Training Loss: 0.003355354070663452
Test Loss:  0.0026578549295663834
Valid Loss:  0.0037877503782510757
Epoch:  90  	Training Loss: 0.0033502252772450447
Test Loss:  0.002657403703778982
Valid Loss:  0.003783648367971182
Epoch:  91  	Training Loss: 0.0033451237250119448
Test Loss:  0.002655607648193836
Valid Loss:  0.003778637619689107
Epoch:  92  	Training Loss: 0.0033400526735931635
Test Loss:  0.0025349599309265614
Valid Loss:  0.0036129713989794254
Epoch:  93  	Training Loss: 0.0032146372832357883
Test Loss:  0.0024734321050345898
Valid Loss:  0.0035506277345120907
Epoch:  94  	Training Loss: 0.003145510796457529
Test Loss:  0.002472891937941313
Valid Loss:  0.0035051186569035053
Epoch:  95  	Training Loss: 0.003092376980930567
Test Loss:  0.0023855739273130894
Valid Loss:  0.003432944416999817
Epoch:  96  	Training Loss: 0.0030416580848395824
Test Loss:  0.002383812330663204
Valid Loss:  0.003394175786525011
Epoch:  97  	Training Loss: 0.0029959522653371096
Test Loss:  0.0023077991791069508
Valid Loss:  0.0033333231694996357
Epoch:  98  	Training Loss: 0.0029517828952521086
Test Loss:  0.002306375652551651
Valid Loss:  0.0032984567806124687
Epoch:  99  	Training Loss: 0.002910248003900051
Test Loss:  0.0022390272933989763
Valid Loss:  0.003241701051592827
Epoch:  100  	Training Loss: 0.0028696327935904264
Test Loss:  0.0022362773306667805
Valid Loss:  0.003208156442269683
Epoch:  101  	Training Loss: 0.00283255847170949
Test Loss:  0.002176061039790511
Valid Loss:  0.0031571551226079464
Epoch:  102  	Training Loss: 0.0027973256073892117
Test Loss:  0.0020884620025753975
Valid Loss:  0.003107395488768816
Epoch:  103  	Training Loss: 0.002788133919239044
Test Loss:  0.0020606042817234993
Valid Loss:  0.003094425657764077
Epoch:  104  	Training Loss: 0.002783756935968995
Test Loss:  0.0020889013539999723
Valid Loss:  0.0031010673847049475
Epoch:  105  	Training Loss: 0.002779139205813408
Test Loss:  0.0020515418145805597
Valid Loss:  0.003083600662648678
Epoch:  106  	Training Loss: 0.002774197142571211
Test Loss:  0.0020738248713314533
Valid Loss:  0.0030884561128914356
Epoch:  107  	Training Loss: 0.002769219223409891
Test Loss:  0.0020524882711470127
Valid Loss:  0.0030766245909035206
Epoch:  108  	Training Loss: 0.0027646226808428764
Test Loss:  0.0020566158927977085
Valid Loss:  0.0030749787110835314
Epoch:  109  	Training Loss: 0.0027602221816778183
Test Loss:  0.0020498260855674744
Valid Loss:  0.0030689537525177
Epoch:  110  	Training Loss: 0.0027558570727705956
Test Loss:  0.0020462432876229286
Valid Loss:  0.003064399119466543
Epoch:  111  	Training Loss: 0.002751507330685854
Test Loss:  0.002043477026745677
Valid Loss:  0.003059911308810115
Epoch:  112  	Training Loss: 0.0027471641078591347
Test Loss:  0.002146766986697912
Valid Loss:  0.0030227513052523136
Epoch:  113  	Training Loss: 0.002665600273758173
Test Loss:  0.0019523079972714186
Valid Loss:  0.0029304996132850647
Epoch:  114  	Training Loss: 0.0026415821630507708
Test Loss:  0.002039936138316989
Valid Loss:  0.002953427378088236
Epoch:  115  	Training Loss: 0.0026207794435322285
Test Loss:  0.0019187110010534525
Valid Loss:  0.002897344995290041
Epoch:  116  	Training Loss: 0.002601888496428728
Test Loss:  0.0019652307964861393
Valid Loss:  0.0029054293408989906
Epoch:  117  	Training Loss: 0.002584114670753479
Test Loss:  0.0018939517904073
Valid Loss:  0.002867476548999548
Epoch:  118  	Training Loss: 0.0025676798541098833
Test Loss:  0.0019137412309646606
Valid Loss:  0.002864874666556716
Epoch:  119  	Training Loss: 0.002551950514316559
Test Loss:  0.0018687790725380182
Valid Loss:  0.002838949440047145
Epoch:  120  	Training Loss: 0.0025379483122378588
Test Loss:  0.001874745124951005
Valid Loss:  0.0028337137773633003
Epoch:  121  	Training Loss: 0.002526562660932541
Test Loss:  0.0018517813878133893
Valid Loss:  0.0028186531271785498
Epoch:  122  	Training Loss: 0.002517358399927616
Test Loss:  0.0015816311351954937
Valid Loss:  0.002601060550659895
Epoch:  123  	Training Loss: 0.0024006222374737263
Test Loss:  0.0016052054706960917
Valid Loss:  0.0025515882298350334
Epoch:  124  	Training Loss: 0.002310311421751976
Test Loss:  0.001545444829389453
Valid Loss:  0.0024635912850499153
Epoch:  125  	Training Loss: 0.002232086844742298
Test Loss:  0.0015207483666017652
Valid Loss:  0.002401415491476655
Epoch:  126  	Training Loss: 0.002162076300010085
Test Loss:  0.0014944560825824738
Valid Loss:  0.002344239968806505
Epoch:  127  	Training Loss: 0.0020992057397961617
Test Loss:  0.0014697464648634195
Valid Loss:  0.00229097087867558
Epoch:  128  	Training Loss: 0.0020407128613442183
Test Loss:  0.0014471036847680807
Valid Loss:  0.0022415188141167164
Epoch:  129  	Training Loss: 0.0019873594865202904
Test Loss:  0.0014304663054645061
Valid Loss:  0.002201212802901864
Epoch:  130  	Training Loss: 0.001939262612722814
Test Loss:  0.0014108950272202492
Valid Loss:  0.002161791082471609
Epoch:  131  	Training Loss: 0.001895018620416522
Test Loss:  0.0013990254374220967
Valid Loss:  0.0021330288145691156
Epoch:  132  	Training Loss: 0.0018566142534837127
Test Loss:  0.001484067877754569
Valid Loss:  0.0021526648197323084
Epoch:  133  	Training Loss: 0.0018223989754915237
Test Loss:  0.0014126210007816553
Valid Loss:  0.002091014292091131
Epoch:  134  	Training Loss: 0.0017959033139050007
Test Loss:  0.0014087476301938295
Valid Loss:  0.0020690751262009144
Epoch:  135  	Training Loss: 0.0017728290986269712
Test Loss:  0.0013799520675092936
Valid Loss:  0.0020372800063341856
Epoch:  136  	Training Loss: 0.0017530228942632675
Test Loss:  0.00136393285356462
Valid Loss:  0.0020147261675447226
Epoch:  137  	Training Loss: 0.0017358991317451
Test Loss:  0.0013438824098557234
Valid Loss:  0.0019917022436857224
Epoch:  138  	Training Loss: 0.0017202745657414198
Test Loss:  0.0013275800738483667
Valid Loss:  0.001971248537302017
Epoch:  139  	Training Loss: 0.0017051153117790818
Test Loss:  0.0013108855346217752
Valid Loss:  0.001951150712557137
 28%|██▊       | 140/500 [01:48<02:01,  2.95it/s] 28%|██▊       | 142/500 [01:55<07:03,  1.18s/it] 29%|██▉       | 144/500 [01:55<05:04,  1.17it/s] 29%|██▉       | 146/500 [01:55<03:40,  1.60it/s] 30%|██▉       | 148/500 [01:55<02:42,  2.16it/s] 30%|███       | 150/500 [01:55<02:02,  2.85it/s] 30%|███       | 152/500 [02:02<06:56,  1.20s/it] 31%|███       | 154/500 [02:02<04:58,  1.16it/s] 31%|███       | 156/500 [02:02<03:36,  1.59it/s] 32%|███▏      | 158/500 [02:02<02:39,  2.15it/s] 32%|███▏      | 160/500 [02:02<01:59,  2.84it/s] 32%|███▏      | 162/500 [02:09<06:45,  1.20s/it] 33%|███▎      | 164/500 [02:09<04:50,  1.16it/s] 33%|███▎      | 166/500 [02:09<03:30,  1.58it/s] 34%|███▎      | 168/500 [02:09<02:35,  2.14it/s] 34%|███▍      | 170/500 [02:09<01:56,  2.84it/s] 34%|███▍      | 172/500 [02:16<06:36,  1.21s/it] 35%|███▍      | 174/500 [02:16<04:41,  1.16it/s] 35%|███▌      | 176/500 [02:16<03:22,  1.60it/s] 36%|███▌      | 178/500 [02:16<02:27,  2.19it/s] 36%|███▌      | 180/500 [02:16<01:48,  2.95it/s] 36%|███▋      | 182/500 [02:23<06:22,  1.20s/it] 37%|███▋      | 184/500 [02:23<04:31,  1.16it/s] 37%|███▋      | 186/500 [02:23<03:15,  1.61it/s] 38%|███▊      | 188/500 [02:23<02:21,  2.20it/s] 38%|███▊      | 190/500 [02:23<01:44,  2.97it/s] 38%|███▊      | 192/500 [02:30<06:06,  1.19s/it] 39%|███▉      | 194/500 [02:30<04:20,  1.17it/s] 39%|███▉      | 196/500 [02:30<03:07,  1.63it/s] 40%|███▉      | 198/500 [02:30<02:15,  2.22it/s] 40%|████      | 200/500 [02:30<01:40,  2.99it/s] 40%|████      | 202/500 [02:37<05:53,  1.19s/it] 41%|████      | 204/500 [02:37<04:11,  1.18it/s] 41%|████      | 206/500 [02:37<03:00,  1.63it/s]Epoch:  140  	Training Loss: 0.0016904426738619804
Test Loss:  0.0012957375729456544
Valid Loss:  0.0019320560386404395
Epoch:  141  	Training Loss: 0.0016766637563705444
Test Loss:  0.0012809981126338243
Valid Loss:  0.00191362330224365
Epoch:  142  	Training Loss: 0.0016636537620797753
Test Loss:  0.0012053828686475754
Valid Loss:  0.0018435654928907752
Epoch:  143  	Training Loss: 0.0016100583598017693
Test Loss:  0.0011693270644173026
Valid Loss:  0.0018001252319663763
Epoch:  144  	Training Loss: 0.0015650796703994274
Test Loss:  0.0011371219297870994
Valid Loss:  0.0017600602004677057
Epoch:  145  	Training Loss: 0.0015243522357195616
Test Loss:  0.0011102557182312012
Valid Loss:  0.001724418019875884
Epoch:  146  	Training Loss: 0.0014875782653689384
Test Loss:  0.001088647055439651
Valid Loss:  0.0016916005406528711
Epoch:  147  	Training Loss: 0.0014546250458806753
Test Loss:  0.0010704847518354654
Valid Loss:  0.0016618482768535614
Epoch:  148  	Training Loss: 0.0014251659158617258
Test Loss:  0.0010548578575253487
Valid Loss:  0.0016377990832552314
Epoch:  149  	Training Loss: 0.0013988410355523229
Test Loss:  0.0010432847775518894
Valid Loss:  0.0016180858947336674
Epoch:  150  	Training Loss: 0.0013751242076978087
Test Loss:  0.001028499216772616
Valid Loss:  0.0015967295039445162
Epoch:  151  	Training Loss: 0.0013530158903449774
Test Loss:  0.0010190331377089024
Valid Loss:  0.0015798930544406176
Epoch:  152  	Training Loss: 0.0013346360065042973
Test Loss:  0.0010245644953101873
Valid Loss:  0.0015823907451704144
Epoch:  153  	Training Loss: 0.0013331776717677712
Test Loss:  0.0010289909550920129
Valid Loss:  0.0015843594446778297
Epoch:  154  	Training Loss: 0.0013319483259692788
Test Loss:  0.0010324963368475437
Valid Loss:  0.0015858756378293037
Epoch:  155  	Training Loss: 0.001330866478383541
Test Loss:  0.001035240013152361
Valid Loss:  0.0015870020724833012
Epoch:  156  	Training Loss: 0.001329881837591529
Test Loss:  0.0010373621480539441
Valid Loss:  0.0015878062695264816
Epoch:  157  	Training Loss: 0.001328983809798956
Test Loss:  0.0010390572715550661
Valid Loss:  0.0015883584273979068
Epoch:  158  	Training Loss: 0.0013281612191349268
Test Loss:  0.0010403827764093876
Valid Loss:  0.0015886921901255846
Epoch:  159  	Training Loss: 0.0013273665681481361
Test Loss:  0.001041376031935215
Valid Loss:  0.0015888464404270053
Epoch:  160  	Training Loss: 0.0013265954330563545
Test Loss:  0.001042105141095817
Valid Loss:  0.0015888770576566458
Epoch:  161  	Training Loss: 0.0013258878607302904
Test Loss:  0.0010426200460642576
Valid Loss:  0.001588786719366908
Epoch:  162  	Training Loss: 0.0013251898344606161
Test Loss:  0.0008821962401270866
Valid Loss:  0.0014379502972587943
Epoch:  163  	Training Loss: 0.0012685242109000683
Test Loss:  0.0010025098454207182
Valid Loss:  0.0014953464269638062
Epoch:  164  	Training Loss: 0.0012382767163217068
Test Loss:  0.0008584725437685847
Valid Loss:  0.0013883577194064856
Epoch:  165  	Training Loss: 0.001219327561557293
Test Loss:  0.00097974285017699
Valid Loss:  0.001457661739550531
Epoch:  166  	Training Loss: 0.00120303756557405
Test Loss:  0.0008480631513521075
Valid Loss:  0.001362442970275879
Epoch:  167  	Training Loss: 0.001190745271742344
Test Loss:  0.0009610573761165142
Valid Loss:  0.0014298558235168457
Epoch:  168  	Training Loss: 0.0011783416848629713
Test Loss:  0.0008423770195804536
Valid Loss:  0.0013435292057693005
Epoch:  169  	Training Loss: 0.0011682304320856929
Test Loss:  0.0009398034890182316
Valid Loss:  0.0014027004363015294
Epoch:  170  	Training Loss: 0.0011569639900699258
Test Loss:  0.0008378156344406307
Valid Loss:  0.0013287041801959276
Epoch:  171  	Training Loss: 0.0011480071116238832
Test Loss:  0.0009186097886413336
Valid Loss:  0.0013775171246379614
Epoch:  172  	Training Loss: 0.0011389271821826696
Test Loss:  0.0008852366008795798
Valid Loss:  0.001351678278297186
Epoch:  173  	Training Loss: 0.0011337983887642622
Test Loss:  0.0008950449409894645
Valid Loss:  0.0013600741513073444
Epoch:  174  	Training Loss: 0.0011309676337987185
Test Loss:  0.000884248991496861
Valid Loss:  0.0013498165644705296
Epoch:  175  	Training Loss: 0.001128385541960597
Test Loss:  0.0008878015214577317
Valid Loss:  0.0013520200736820698
Epoch:  176  	Training Loss: 0.0011261221952736378
Test Loss:  0.0008826589328236878
Valid Loss:  0.0013476868625730276
Epoch:  177  	Training Loss: 0.0011241049505770206
Test Loss:  0.0008789623389020562
Valid Loss:  0.0013457442400977015
Epoch:  178  	Training Loss: 0.001122279791161418
Test Loss:  0.0008808467537164688
Valid Loss:  0.0013448570389300585
Epoch:  179  	Training Loss: 0.001120548928156495
Test Loss:  0.0008773058652877808
Valid Loss:  0.0013422744814306498
Epoch:  180  	Training Loss: 0.0011188749922439456
Test Loss:  0.0008763278601691127
Valid Loss:  0.0013406097423285246
Epoch:  181  	Training Loss: 0.001117355888709426
Test Loss:  0.0008710805559530854
Valid Loss:  0.0013384371995925903
Epoch:  182  	Training Loss: 0.0011159884743392467
Test Loss:  0.0008603923488408327
Valid Loss:  0.001328738173469901
Epoch:  183  	Training Loss: 0.001100896275602281
Test Loss:  0.0008419530931860209
Valid Loss:  0.0013156778877601027
Epoch:  184  	Training Loss: 0.001092582126148045
Test Loss:  0.0008399203652516007
Valid Loss:  0.0013107636477798223
Epoch:  185  	Training Loss: 0.0010863423813134432
Test Loss:  0.0008329785778187215
Valid Loss:  0.0013033093418926
Epoch:  186  	Training Loss: 0.00108080985955894
Test Loss:  0.0008293095743283629
Valid Loss:  0.0012980061583220959
Epoch:  187  	Training Loss: 0.001076209475286305
Test Loss:  0.0008259137393906713
Valid Loss:  0.0012929727090522647
Epoch:  188  	Training Loss: 0.0010718711419031024
Test Loss:  0.0008231537067331374
Valid Loss:  0.0012885704636573792
Epoch:  189  	Training Loss: 0.001067773555405438
Test Loss:  0.0008215587586164474
Valid Loss:  0.0012849472695961595
Epoch:  190  	Training Loss: 0.001064000534825027
Test Loss:  0.0008191318484023213
Valid Loss:  0.0012810537591576576
Epoch:  191  	Training Loss: 0.0010606850264593959
Test Loss:  0.0008179224678315222
Valid Loss:  0.0012780039105564356
Epoch:  192  	Training Loss: 0.0010575904743745923
Test Loss:  0.0008211915264837444
Valid Loss:  0.0012796088121831417
Epoch:  193  	Training Loss: 0.0010569297010079026
Test Loss:  0.0008235754794441164
Valid Loss:  0.0012806197628378868
Epoch:  194  	Training Loss: 0.0010564292315393686
Test Loss:  0.0008252411498688161
Valid Loss:  0.0012811425840482116
Epoch:  195  	Training Loss: 0.0010560130467638373
Test Loss:  0.0008265742799267173
Valid Loss:  0.0012814480578526855
Epoch:  196  	Training Loss: 0.0010556236375123262
Test Loss:  0.000827606359962374
Valid Loss:  0.0012815757654607296
Epoch:  197  	Training Loss: 0.0010552583262324333
Test Loss:  0.000828410848043859
Valid Loss:  0.0012815704103559256
Epoch:  198  	Training Loss: 0.0010549137368798256
Test Loss:  0.0008287807577289641
Valid Loss:  0.001281294971704483
Epoch:  199  	Training Loss: 0.001054632244631648
Test Loss:  0.0008290837868116796
Valid Loss:  0.0012809920590370893
Epoch:  200  	Training Loss: 0.0010543784592300653
Test Loss:  0.0008293319260701537
Valid Loss:  0.001280652591958642
Epoch:  201  	Training Loss: 0.0010541270021349192
Test Loss:  0.0008295287843793631
Valid Loss:  0.001280284719541669
Epoch:  202  	Training Loss: 0.0010538767091929913
Test Loss:  0.0008223435143008828
Valid Loss:  0.0012716073542833328
Epoch:  203  	Training Loss: 0.0010509892599657178
Test Loss:  0.000821905501652509
Valid Loss:  0.0012668678537011147
Epoch:  204  	Training Loss: 0.00104853929951787
Test Loss:  0.0008164388709701598
Valid Loss:  0.0012617321917787194
Epoch:  205  	Training Loss: 0.0010466750245541334
Test Loss:  0.0008155035320669413
Valid Loss:  0.001258930773474276
Epoch:  206  	Training Loss: 0.0010448757093399763
Test Loss:  0.0008140273857861757
Valid Loss:  0.001256031566299498
Epoch:  207  	Training Loss: 0.001043106778524816
Test Loss:  0.0008126240572892129
Valid Loss:  0.001253283116966486
Epoch:  208  	Training Loss: 0.0010413577547296882
Test Loss:   42%|████▏     | 208/500 [02:37<02:11,  2.22it/s] 42%|████▏     | 210/500 [02:37<01:36,  2.99it/s] 42%|████▏     | 212/500 [02:43<05:38,  1.18s/it] 43%|████▎     | 214/500 [02:43<04:00,  1.19it/s] 43%|████▎     | 216/500 [02:44<02:52,  1.64it/s] 44%|████▎     | 218/500 [02:44<02:05,  2.24it/s] 44%|████▍     | 220/500 [02:44<01:33,  2.99it/s] 44%|████▍     | 222/500 [02:50<05:32,  1.20s/it] 45%|████▍     | 224/500 [02:50<03:56,  1.17it/s] 45%|████▌     | 226/500 [02:51<02:49,  1.62it/s] 46%|████▌     | 228/500 [02:51<02:03,  2.21it/s] 46%|████▌     | 230/500 [02:51<01:30,  2.98it/s] 46%|████▋     | 232/500 [02:57<05:22,  1.20s/it] 47%|████▋     | 234/500 [02:57<03:49,  1.16it/s] 47%|████▋     | 236/500 [02:57<02:44,  1.60it/s] 48%|████▊     | 238/500 [02:58<01:59,  2.19it/s] 48%|████▊     | 240/500 [02:58<01:28,  2.94it/s] 48%|████▊     | 242/500 [03:04<05:01,  1.17s/it] 49%|████▉     | 244/500 [03:04<03:34,  1.19it/s] 49%|████▉     | 246/500 [03:04<02:34,  1.65it/s] 50%|████▉     | 248/500 [03:04<01:51,  2.25it/s] 50%|█████     | 250/500 [03:04<01:22,  3.03it/s] 50%|█████     | 252/500 [03:11<04:48,  1.16s/it] 51%|█████     | 254/500 [03:11<03:24,  1.20it/s] 51%|█████     | 256/500 [03:11<02:27,  1.66it/s] 52%|█████▏    | 258/500 [03:11<01:46,  2.27it/s] 52%|█████▏    | 260/500 [03:11<01:18,  3.05it/s] 52%|█████▏    | 262/500 [03:18<04:41,  1.18s/it] 53%|█████▎    | 264/500 [03:18<03:20,  1.18it/s] 53%|█████▎    | 266/500 [03:18<02:23,  1.63it/s] 54%|█████▎    | 268/500 [03:18<01:43,  2.23it/s] 54%|█████▍    | 270/500 [03:18<01:16,  3.00it/s] 54%|█████▍    | 272/500 [03:24<04:30,  1.19s/it] 55%|█████▍    | 274/500 [03:25<03:12,  1.18it/s] 55%|█████▌    | 276/500 [03:25<02:17,  1.63it/s]0.0008112108916975558
Valid Loss:  0.0012506216298788786
Epoch:  209  	Training Loss: 0.0010396441211923957
Test Loss:  0.0008098630933091044
Valid Loss:  0.0012480819132179022
Epoch:  210  	Training Loss: 0.0010379872983321548
Test Loss:  0.0008085519657470286
Valid Loss:  0.001245685969479382
Epoch:  211  	Training Loss: 0.001036341185681522
Test Loss:  0.0008072726777754724
Valid Loss:  0.0012433279771357775
Epoch:  212  	Training Loss: 0.001034722663462162
Test Loss:  0.0007863173959776759
Valid Loss:  0.001228695153258741
Epoch:  213  	Training Loss: 0.0010315049439668655
Test Loss:  0.0007806512294337153
Valid Loss:  0.0012242950033396482
Epoch:  214  	Training Loss: 0.0010298574343323708
Test Loss:  0.0007776456186547875
Valid Loss:  0.0012216588947921991
Epoch:  215  	Training Loss: 0.0010283903684467077
Test Loss:  0.0007756265113130212
Valid Loss:  0.0012200881028547883
Epoch:  216  	Training Loss: 0.0010270997881889343
Test Loss:  0.0007766088820062578
Valid Loss:  0.0012203078949823976
Epoch:  217  	Training Loss: 0.0010260078124701977
Test Loss:  0.0007761915912851691
Valid Loss:  0.0012197105679661036
Epoch:  218  	Training Loss: 0.0010250266641378403
Test Loss:  0.0007780697196722031
Valid Loss:  0.0012204397935420275
Epoch:  219  	Training Loss: 0.0010242052376270294
Test Loss:  0.0007781363092362881
Valid Loss:  0.001220114529132843
Epoch:  220  	Training Loss: 0.0010234504006803036
Test Loss:  0.0007776867132633924
Valid Loss:  0.0012194809969514608
Epoch:  221  	Training Loss: 0.0010227363090962172
Test Loss:  0.0007770508527755737
Valid Loss:  0.0012188117252662778
Epoch:  222  	Training Loss: 0.0010220743715763092
Test Loss:  0.0007643825374543667
Valid Loss:  0.00120561383664608
Epoch:  223  	Training Loss: 0.001012651133351028
Test Loss:  0.0007562924874946475
Valid Loss:  0.001197829726152122
Epoch:  224  	Training Loss: 0.0010046514216810465
Test Loss:  0.000750448671169579
Valid Loss:  0.0011918132659047842
Epoch:  225  	Training Loss: 0.000997787807136774
Test Loss:  0.0007456706371158361
Valid Loss:  0.0011869586305692792
Epoch:  226  	Training Loss: 0.0009919492295011878
Test Loss:  0.0007409560494124889
Valid Loss:  0.0011823142413049936
Epoch:  227  	Training Loss: 0.000986694823950529
Test Loss:  0.0007364683551713824
Valid Loss:  0.0011779328342527151
Epoch:  228  	Training Loss: 0.0009819340193644166
Test Loss:  0.000732613611035049
Valid Loss:  0.0011738442117348313
Epoch:  229  	Training Loss: 0.0009776478400453925
Test Loss:  0.0007287269691005349
Valid Loss:  0.0011695288121700287
Epoch:  230  	Training Loss: 0.0009737411746755242
Test Loss:  0.000725651509128511
Valid Loss:  0.001166520407423377
Epoch:  231  	Training Loss: 0.0009703171672299504
Test Loss:  0.0007223197026178241
Valid Loss:  0.0011630977969616652
Epoch:  232  	Training Loss: 0.0009670634754002094
Test Loss:  0.0007238466059789062
Valid Loss:  0.0011638628784567118
Epoch:  233  	Training Loss: 0.0009669962455518544
Test Loss:  0.000725134159438312
Valid Loss:  0.0011645127087831497
Epoch:  234  	Training Loss: 0.0009669498540461063
Test Loss:  0.0007262316648848355
Valid Loss:  0.0011650687083601952
Epoch:  235  	Training Loss: 0.0009669153951108456
Test Loss:  0.0007271505310200155
Valid Loss:  0.0011655371636152267
Epoch:  236  	Training Loss: 0.0009668906568549573
Test Loss:  0.0007279313285835087
Valid Loss:  0.0011659364681690931
Epoch:  237  	Training Loss: 0.0009668719721958041
Test Loss:  0.0007285951869562268
Valid Loss:  0.0011662759352475405
Epoch:  238  	Training Loss: 0.0009668581187725067
Test Loss:  0.0007291601505130529
Valid Loss:  0.001166564878076315
Epoch:  239  	Training Loss: 0.0009668482234701514
Test Loss:  0.0007296388503164053
Valid Loss:  0.0011668085353448987
Epoch:  240  	Training Loss: 0.0009668407728895545
Test Loss:  0.0007300475845113397
Valid Loss:  0.0011670127278193831
Epoch:  241  	Training Loss: 0.0009668337879702449
Test Loss:  0.0007303939783014357
Valid Loss:  0.0011671851389110088
Epoch:  242  	Training Loss: 0.0009668289567343891
Test Loss:  0.0007332360255531967
Valid Loss:  0.0011685710633173585
Epoch:  243  	Training Loss: 0.000966728082858026
Test Loss:  0.000732234213501215
Valid Loss:  0.0011678915470838547
Epoch:  244  	Training Loss: 0.000966634601354599
Test Loss:  0.0007325391052290797
Valid Loss:  0.0011679136659950018
Epoch:  245  	Training Loss: 0.0009665428660809994
Test Loss:  0.0007323985919356346
Valid Loss:  0.0011677008587867022
Epoch:  246  	Training Loss: 0.0009664508979767561
Test Loss:  0.0007324148900806904
Valid Loss:  0.0011675700079649687
Epoch:  247  	Training Loss: 0.000966360792517662
Test Loss:  0.0007323749596253037
Valid Loss:  0.0011674099368974566
Epoch:  248  	Training Loss: 0.0009662688244134188
Test Loss:  0.0007323557510972023
Valid Loss:  0.0011672641849145293
Epoch:  249  	Training Loss: 0.0009661779040470719
Test Loss:  0.0007323280442506075
Valid Loss:  0.0011671101674437523
Epoch:  250  	Training Loss: 0.0009660880314186215
Test Loss:  0.0007323033642023802
Valid Loss:  0.0011669595260173082
Epoch:  251  	Training Loss: 0.0009659980423748493
Test Loss:  0.0007322788005694747
Valid Loss:  0.0011668121442198753
Epoch:  252  	Training Loss: 0.0009659138740971684
Test Loss:  0.0007300148135982454
Valid Loss:  0.001163957640528679
Epoch:  253  	Training Loss: 0.000963686965405941
Test Loss:  0.0007287387270480394
Valid Loss:  0.0011608590139076114
Epoch:  254  	Training Loss: 0.000959738390520215
Test Loss:  0.0007269956404343247
Valid Loss:  0.0011555703822523355
Epoch:  255  	Training Loss: 0.0009542873594909906
Test Loss:  0.0007237811223603785
Valid Loss:  0.001148495590314269
Epoch:  256  	Training Loss: 0.0009474512771703303
Test Loss:  0.00071833556285128
Valid Loss:  0.0011376335751265287
Epoch:  257  	Training Loss: 0.0009374971268698573
Test Loss:  0.0007110285805538297
Valid Loss:  0.0011255634017288685
Epoch:  258  	Training Loss: 0.0009263432584702969
Test Loss:  0.000702267570886761
Valid Loss:  0.001113158417865634
Epoch:  259  	Training Loss: 0.0009150166879408062
Test Loss:  0.0006931181997060776
Valid Loss:  0.0011008307337760925
Epoch:  260  	Training Loss: 0.0009041051380336285
Test Loss:  0.0006842039292678237
Valid Loss:  0.00108911725692451
Epoch:  261  	Training Loss: 0.0008940839907154441
Test Loss:  0.0006762341363355517
Valid Loss:  0.0010782218305394053
Epoch:  262  	Training Loss: 0.0008854491170495749
Test Loss:  0.0006651952862739563
Valid Loss:  0.0010693403892219067
Epoch:  263  	Training Loss: 0.0008819322101771832
Test Loss:  0.0006655657198280096
Valid Loss:  0.0010666778543964028
Epoch:  264  	Training Loss: 0.0008786990656517446
Test Loss:  0.0006611314602196217
Valid Loss:  0.0010616411454975605
Epoch:  265  	Training Loss: 0.0008757071336731315
Test Loss:  0.0006592092104256153
Valid Loss:  0.0010580525267869234
Epoch:  266  	Training Loss: 0.0008728331886231899
Test Loss:  0.000656501273624599
Valid Loss:  0.001054250169545412
Epoch:  267  	Training Loss: 0.000870063086040318
Test Loss:  0.0006547505035996437
Valid Loss:  0.00105094478931278
Epoch:  268  	Training Loss: 0.0008674472337588668
Test Loss:  0.000652695307508111
Valid Loss:  0.001047609024681151
Epoch:  269  	Training Loss: 0.0008649950032122433
Test Loss:  0.0006511183455586433
Valid Loss:  0.0010445938678458333
Epoch:  270  	Training Loss: 0.0008626512717455626
Test Loss:  0.0006491673411801457
Valid Loss:  0.001041530049405992
Epoch:  271  	Training Loss: 0.000860460102558136
Test Loss:  0.0006474495748989284
Valid Loss:  0.0010387442307546735
Epoch:  272  	Training Loss: 0.0008584044990129769
Test Loss:  0.0006542112678289413
Valid Loss:  0.0010429741814732552
Epoch:  273  	Training Loss: 0.0008568441262468696
Test Loss:  0.0006555910222232342
Valid Loss:  0.0010432818671688437
Epoch:  274  	Training Loss: 0.0008558247936889529
Test Loss:  0.0006555446889251471
Valid Loss:  0.0010426649823784828
Epoch:  275  	Training Loss: 0.0008548668702133
Test Loss:  0.0006550037651322782
Valid Loss:  0.0010416904697194695
Epoch:  276  	Training Loss: 0.0008539397967979312
Test Loss:  0.0006543084164150059
Valid Loss:  0.0010406008223071694
 56%|█████▌    | 278/500 [03:25<01:39,  2.22it/s] 56%|█████▌    | 280/500 [03:25<01:13,  2.99it/s] 56%|█████▋    | 282/500 [03:31<04:16,  1.18s/it] 57%|█████▋    | 284/500 [03:31<03:03,  1.18it/s] 57%|█████▋    | 286/500 [03:32<02:12,  1.61it/s] 58%|█████▊    | 288/500 [03:32<01:37,  2.17it/s] 58%|█████▊    | 290/500 [03:32<01:12,  2.88it/s] 58%|█████▊    | 292/500 [03:38<04:08,  1.20s/it] 59%|█████▉    | 294/500 [03:38<02:56,  1.17it/s] 59%|█████▉    | 296/500 [03:39<02:06,  1.61it/s] 60%|█████▉    | 298/500 [03:39<01:31,  2.20it/s] 60%|██████    | 300/500 [03:39<01:07,  2.96it/s] 60%|██████    | 302/500 [03:45<03:54,  1.19s/it] 61%|██████    | 304/500 [03:45<02:47,  1.17it/s] 61%|██████    | 306/500 [03:45<02:01,  1.60it/s] 62%|██████▏   | 308/500 [03:46<01:28,  2.16it/s] 62%|██████▏   | 310/500 [03:46<01:06,  2.88it/s] 62%|██████▏   | 312/500 [03:52<03:45,  1.20s/it] 63%|██████▎   | 314/500 [03:52<02:39,  1.16it/s] 63%|██████▎   | 316/500 [03:52<01:54,  1.61it/s] 64%|██████▎   | 318/500 [03:53<01:22,  2.20it/s] 64%|██████▍   | 320/500 [03:53<01:01,  2.95it/s] 64%|██████▍   | 322/500 [03:59<03:36,  1.22s/it] 65%|██████▍   | 324/500 [03:59<02:33,  1.15it/s] 65%|██████▌   | 326/500 [04:00<01:49,  1.59it/s] 66%|██████▌   | 328/500 [04:00<01:19,  2.17it/s] 66%|██████▌   | 330/500 [04:00<00:58,  2.92it/s] 66%|██████▋   | 332/500 [04:06<03:18,  1.18s/it] 67%|██████▋   | 334/500 [04:06<02:21,  1.17it/s] 67%|██████▋   | 336/500 [04:06<01:42,  1.60it/s] 68%|██████▊   | 338/500 [04:07<01:14,  2.17it/s] 68%|██████▊   | 340/500 [04:07<00:55,  2.87it/s] 68%|██████▊   | 342/500 [04:13<03:12,  1.22s/it] 69%|██████▉   | 344/500 [04:13<02:15,  1.15it/s]Epoch:  277  	Training Loss: 0.0008530409540981054
Test Loss:  0.0006537005538120866
Valid Loss:  0.0010397331789135933
Epoch:  278  	Training Loss: 0.0008521682466380298
Test Loss:  0.0006529075326398015
Valid Loss:  0.0010387154761701822
Epoch:  279  	Training Loss: 0.0008512934437021613
Test Loss:  0.000652165268547833
Valid Loss:  0.0010376418940722942
Epoch:  280  	Training Loss: 0.0008503901772201061
Test Loss:  0.0006513966945931315
Valid Loss:  0.0010365452617406845
Epoch:  281  	Training Loss: 0.0008495030924677849
Test Loss:  0.0006506439531221986
Valid Loss:  0.001035439781844616
Epoch:  282  	Training Loss: 0.0008486274164170027
Test Loss:  0.0006538503803312778
Valid Loss:  0.0010351906530559063
Epoch:  283  	Training Loss: 0.0008458821102976799
Test Loss:  0.0006563841016031802
Valid Loss:  0.0010350227821618319
Epoch:  284  	Training Loss: 0.0008441985119134188
Test Loss:  0.0006581140332855284
Valid Loss:  0.0010346375638619065
Epoch:  285  	Training Loss: 0.0008429089211858809
Test Loss:  0.0006589475087821484
Valid Loss:  0.001033961190842092
Epoch:  286  	Training Loss: 0.0008417803328484297
Test Loss:  0.0006590239936485887
Valid Loss:  0.0010330594377592206
Epoch:  287  	Training Loss: 0.0008407389395870268
Test Loss:  0.000658950419165194
Valid Loss:  0.0010320998262614012
Epoch:  288  	Training Loss: 0.0008397123892791569
Test Loss:  0.0006587564712390304
Valid Loss:  0.0010310994694009423
Epoch:  289  	Training Loss: 0.0008387001580558717
Test Loss:  0.0006584813818335533
Valid Loss:  0.001030073268339038
Epoch:  290  	Training Loss: 0.0008376985788345337
Test Loss:  0.0006578887696377933
Valid Loss:  0.001028971979394555
Epoch:  291  	Training Loss: 0.0008367107948288321
Test Loss:  0.0006575258448719978
Valid Loss:  0.0010279325069859624
Epoch:  292  	Training Loss: 0.0008357290062122047
Test Loss:  0.0005964552983641624
Valid Loss:  0.0009734210907481611
Epoch:  293  	Training Loss: 0.000814066908787936
Test Loss:  0.0006064678309485316
Valid Loss:  0.0009735319181345403
Epoch:  294  	Training Loss: 0.0008111951174214482
Test Loss:  0.0006078014266677201
Valid Loss:  0.0009716728236526251
Epoch:  295  	Training Loss: 0.0008094950462691486
Test Loss:  0.0006074106204323471
Valid Loss:  0.000969688524492085
Epoch:  296  	Training Loss: 0.0008079377585090697
Test Loss:  0.000606753455940634
Valid Loss:  0.00096806202782318
Epoch:  297  	Training Loss: 0.0008064184803515673
Test Loss:  0.0006056724232621491
Valid Loss:  0.0009662949596531689
Epoch:  298  	Training Loss: 0.0008049111347645521
Test Loss:  0.0006027750205248594
Valid Loss:  0.000964088540058583
Epoch:  299  	Training Loss: 0.000803436734713614
Test Loss:  0.0006032122182659805
Valid Loss:  0.0009629702544771135
Epoch:  300  	Training Loss: 0.000801958842203021
Test Loss:  0.0006004621391184628
Valid Loss:  0.0009607995161786675
Epoch:  301  	Training Loss: 0.0008004797855392098
Test Loss:  0.0005991614307276905
Valid Loss:  0.0009592198766767979
Epoch:  302  	Training Loss: 0.0007990149315446615
Test Loss:  0.0005973096122033894
Valid Loss:  0.0009513036347925663
Epoch:  303  	Training Loss: 0.0007747195195406675
Test Loss:  0.0005625677295029163
Valid Loss:  0.0009281839011237025
Epoch:  304  	Training Loss: 0.0007624651188962162
Test Loss:  0.0005667386576533318
Valid Loss:  0.0009277724893763661
Epoch:  305  	Training Loss: 0.0007553247851319611
Test Loss:  0.0005513504147529602
Valid Loss:  0.0009158351458609104
Epoch:  306  	Training Loss: 0.0007498789927922189
Test Loss:  0.000553019461221993
Valid Loss:  0.000913698342628777
Epoch:  307  	Training Loss: 0.0007452337886206806
Test Loss:  0.0005448387237265706
Valid Loss:  0.0009063285542652011
Epoch:  308  	Training Loss: 0.0007410391699522734
Test Loss:  0.000543497852049768
Valid Loss:  0.0009031048393808305
Epoch:  309  	Training Loss: 0.0007373452535830438
Test Loss:  0.0005392776802182198
Valid Loss:  0.0008983471198007464
Epoch:  310  	Training Loss: 0.0007337846327573061
Test Loss:  0.0005371483857743442
Valid Loss:  0.0008948158356361091
Epoch:  311  	Training Loss: 0.000730475876480341
Test Loss:  0.0005359735805541277
Valid Loss:  0.000891784904524684
Epoch:  312  	Training Loss: 0.0007273484952747822
Test Loss:  0.0005314521258696914
Valid Loss:  0.0008891626494005322
Epoch:  313  	Training Loss: 0.0007272453512996435
Test Loss:  0.0005306177772581577
Valid Loss:  0.00088863680139184
Epoch:  314  	Training Loss: 0.0007272285292856395
Test Loss:  0.0005304871592670679
Valid Loss:  0.0008885035058483481
Epoch:  315  	Training Loss: 0.0007272163638845086
Test Loss:  0.0005304912338033319
Valid Loss:  0.0008884547278285027
Epoch:  316  	Training Loss: 0.0007272067596204579
Test Loss:  0.000530521385371685
Valid Loss:  0.0008884216658771038
Epoch:  317  	Training Loss: 0.0007271974463947117
Test Loss:  0.0005305536324158311
Valid Loss:  0.0008883927366696298
Epoch:  318  	Training Loss: 0.0007271889480762184
Test Loss:  0.0005305839003995061
Valid Loss:  0.0008883657865226269
Epoch:  319  	Training Loss: 0.0007271812064573169
Test Loss:  0.0005306133534759283
Valid Loss:  0.0008883425034582615
Epoch:  320  	Training Loss: 0.00072717503644526
Test Loss:  0.0005306409439072013
Valid Loss:  0.0008883196278475225
Epoch:  321  	Training Loss: 0.0007271688664332032
Test Loss:  0.0005306665552780032
Valid Loss:  0.0008882962865754962
Epoch:  322  	Training Loss: 0.0007271638023667037
Test Loss:  0.0004913738230243325
Valid Loss:  0.0008498788229189813
Epoch:  323  	Training Loss: 0.0007102974341250956
Test Loss:  0.0005162141169421375
Valid Loss:  0.0008567864424549043
Epoch:  324  	Training Loss: 0.0007000510231591761
Test Loss:  0.000496886670589447
Valid Loss:  0.0008377298945561051
Epoch:  325  	Training Loss: 0.0006914522382430732
Test Loss:  0.0005007950821891427
Valid Loss:  0.0008339143823832273
Epoch:  326  	Training Loss: 0.0006837506662122905
Test Loss:  0.0004924897220917046
Valid Loss:  0.0008234202396124601
Epoch:  327  	Training Loss: 0.0006767042796127498
Test Loss:  0.0004905712557956576
Valid Loss:  0.000817638065200299
Epoch:  328  	Training Loss: 0.0006700276280753314
Test Loss:  0.00048435654025524855
Valid Loss:  0.0008094424265436828
Epoch:  329  	Training Loss: 0.0006636407924816012
Test Loss:  0.00048058314132504165
Valid Loss:  0.0008028530864976346
Epoch:  330  	Training Loss: 0.0006575502338819206
Test Loss:  0.0004761672462336719
Valid Loss:  0.0007960147340781987
Epoch:  331  	Training Loss: 0.0006516446592286229
Test Loss:  0.0004718956188298762
Valid Loss:  0.000789267010986805
Epoch:  332  	Training Loss: 0.000645959924440831
Test Loss:  0.00047529523726552725
Valid Loss:  0.0007891724235378206
Epoch:  333  	Training Loss: 0.0006410562782548368
Test Loss:  0.0004702935984823853
Valid Loss:  0.0007845979416742921
Epoch:  334  	Training Loss: 0.0006371363997459412
Test Loss:  0.00046574397129006684
Valid Loss:  0.000780101923737675
Epoch:  335  	Training Loss: 0.0006337236845865846
Test Loss:  0.0004622673150151968
Valid Loss:  0.0007762686582282186
Epoch:  336  	Training Loss: 0.0006306164432317019
Test Loss:  0.00045920151751488447
Valid Loss:  0.0007727450574748218
Epoch:  337  	Training Loss: 0.0006277099018916488
Test Loss:  0.00045658741146326065
Valid Loss:  0.0007693073130212724
Epoch:  338  	Training Loss: 0.0006249623838812113
Test Loss:  0.0004542964743450284
Valid Loss:  0.000766043143812567
Epoch:  339  	Training Loss: 0.0006223106756806374
Test Loss:  0.00045164048788137734
Valid Loss:  0.0007626529550179839
Epoch:  340  	Training Loss: 0.0006199311465024948
Test Loss:  0.00044961489038541913
Valid Loss:  0.0007595810457132757
Epoch:  341  	Training Loss: 0.000617608311586082
Test Loss:  0.00044737133430317044
Valid Loss:  0.000756586086936295
Epoch:  342  	Training Loss: 0.0006154647562652826
Test Loss:  0.0004522728850133717
Valid Loss:  0.0007553177420049906
Epoch:  343  	Training Loss: 0.0006132781272754073
Test Loss:  0.00044599513057619333
Valid Loss:  0.0007507148548029363
Epoch:  344  	Training Loss: 0.0006118905148468912
Test Loss:  0.00044727788190357387
Valid Loss:  0.0007495281752198935
Epoch:  345  	Training Loss: 0.0006107299122959375
 69%|██████▉   | 346/500 [04:13<01:36,  1.59it/s] 70%|██████▉   | 348/500 [04:14<01:09,  2.18it/s] 70%|███████   | 350/500 [04:14<00:51,  2.93it/s] 70%|███████   | 352/500 [04:20<02:55,  1.19s/it] 71%|███████   | 354/500 [04:20<02:04,  1.17it/s] 71%|███████   | 356/500 [04:20<01:28,  1.62it/s] 72%|███████▏  | 358/500 [04:20<01:03,  2.22it/s] 72%|███████▏  | 360/500 [04:21<00:46,  2.98it/s] 72%|███████▏  | 362/500 [04:27<02:45,  1.20s/it] 73%|███████▎  | 364/500 [04:27<01:56,  1.17it/s] 73%|███████▎  | 366/500 [04:27<01:23,  1.61it/s] 74%|███████▎  | 368/500 [04:27<00:59,  2.21it/s] 74%|███████▍  | 370/500 [04:28<00:43,  2.97it/s] 74%|███████▍  | 372/500 [04:34<02:31,  1.18s/it] 75%|███████▍  | 374/500 [04:34<01:46,  1.18it/s] 75%|███████▌  | 376/500 [04:34<01:15,  1.63it/s] 76%|███████▌  | 378/500 [04:34<00:54,  2.23it/s] 76%|███████▌  | 380/500 [04:34<00:39,  3.00it/s] 76%|███████▋  | 382/500 [04:41<02:17,  1.17s/it] 77%|███████▋  | 384/500 [04:41<01:37,  1.19it/s] 77%|███████▋  | 386/500 [04:41<01:09,  1.65it/s] 78%|███████▊  | 388/500 [04:41<00:49,  2.25it/s] 78%|███████▊  | 390/500 [04:41<00:36,  3.03it/s] 78%|███████▊  | 392/500 [04:48<02:08,  1.19s/it] 79%|███████▉  | 394/500 [04:48<01:30,  1.17it/s] 79%|███████▉  | 396/500 [04:54<02:38,  1.52s/it] 80%|███████▉  | 398/500 [04:54<01:50,  1.09s/it] 80%|████████  | 400/500 [04:54<01:18,  1.28it/s] 80%|████████  | 402/500 [05:00<02:25,  1.49s/it] 81%|████████  | 404/500 [05:01<01:41,  1.06s/it] 81%|████████  | 406/500 [05:01<01:11,  1.31it/s] 82%|████████▏ | 408/500 [05:01<00:50,  1.81it/s] 82%|████████▏ | 410/500 [05:01<00:36,  2.45it/s]Test Loss:  0.00044222857104614377
Valid Loss:  0.0007465078379027545
Epoch:  346  	Training Loss: 0.0006097936420701444
Test Loss:  0.00044368539238348603
Valid Loss:  0.0007459376938641071
Epoch:  347  	Training Loss: 0.0006089865346439183
Test Loss:  0.0004422368947416544
Valid Loss:  0.0007442267960868776
Epoch:  348  	Training Loss: 0.0006082835607230663
Test Loss:  0.00044160574907436967
Valid Loss:  0.0007430607220157981
Epoch:  349  	Training Loss: 0.0006076249992474914
Test Loss:  0.00044160039396956563
Valid Loss:  0.0007421947666443884
Epoch:  350  	Training Loss: 0.0006069941446185112
Test Loss:  0.0004414499271661043
Valid Loss:  0.0007412540726363659
Epoch:  351  	Training Loss: 0.000606454093940556
Test Loss:  0.00044163010898046196
Valid Loss:  0.0007404526695609093
Epoch:  352  	Training Loss: 0.0006059535080567002
Test Loss:  0.00043983448995277286
Valid Loss:  0.0007351003587245941
Epoch:  353  	Training Loss: 0.0006009862408973277
Test Loss:  0.00043602564255706966
Valid Loss:  0.0007302541052922606
Epoch:  354  	Training Loss: 0.0005969472695142031
Test Loss:  0.00043263082625344396
Valid Loss:  0.0007257662946358323
Epoch:  355  	Training Loss: 0.0005935765220783651
Test Loss:  0.0004299378488212824
Valid Loss:  0.0007221787818707526
Epoch:  356  	Training Loss: 0.0005907705053687096
Test Loss:  0.00042779702926054597
Valid Loss:  0.0007194117642939091
Epoch:  357  	Training Loss: 0.0005883760750293732
Test Loss:  0.00042779219802469015
Valid Loss:  0.0007178154774010181
Epoch:  358  	Training Loss: 0.0005866278079338372
Test Loss:  0.000426275102654472
Valid Loss:  0.0007164346752688289
Epoch:  359  	Training Loss: 0.0005853984039276838
Test Loss:  0.0004256591491866857
Valid Loss:  0.0007152475300244987
Epoch:  360  	Training Loss: 0.0005843630060553551
Test Loss:  0.0004246454336680472
Valid Loss:  0.0007140489760786295
Epoch:  361  	Training Loss: 0.0005835034535266459
Test Loss:  0.0004236629174556583
Valid Loss:  0.0007129479781724513
Epoch:  362  	Training Loss: 0.000582805136218667
Test Loss:  0.00041676941327750683
Valid Loss:  0.0007084158132784069
Epoch:  363  	Training Loss: 0.0005818821955472231
Test Loss:  0.0004169698222540319
Valid Loss:  0.0007076443871483207
Epoch:  364  	Training Loss: 0.0005811079172417521
Test Loss:  0.00041676685214042664
Valid Loss:  0.0007066794205456972
Epoch:  365  	Training Loss: 0.0005803429521620274
Test Loss:  0.0004165767168160528
Valid Loss:  0.0007057408220134676
Epoch:  366  	Training Loss: 0.0005796081386506557
Test Loss:  0.00041636195965111256
Valid Loss:  0.00070479343412444
Epoch:  367  	Training Loss: 0.000578918494284153
Test Loss:  0.000416246650274843
Valid Loss:  0.000703906815033406
Epoch:  368  	Training Loss: 0.0005782450316473842
Test Loss:  0.0004161533433943987
Valid Loss:  0.0007030613487586379
Epoch:  369  	Training Loss: 0.0005776066100224853
Test Loss:  0.00041603686986491084
Valid Loss:  0.0007023268262855709
Epoch:  370  	Training Loss: 0.000576975173316896
Test Loss:  0.0004159216769039631
Valid Loss:  0.0007016010349616408
Epoch:  371  	Training Loss: 0.0005763506633229554
Test Loss:  0.000415806716773659
Valid Loss:  0.0007008827524259686
Epoch:  372  	Training Loss: 0.000575731392018497
Test Loss:  0.00040770822670310736
Valid Loss:  0.0006934558041393757
Epoch:  373  	Training Loss: 0.0005706930533051491
Test Loss:  0.00040241109672933817
Valid Loss:  0.0006884551257826388
Epoch:  374  	Training Loss: 0.0005667119985446334
Test Loss:  0.00039805867709219456
Valid Loss:  0.0006841149879619479
Epoch:  375  	Training Loss: 0.0005631712265312672
Test Loss:  0.000394846050767228
Valid Loss:  0.0006803867872804403
Epoch:  376  	Training Loss: 0.0005600638687610626
Test Loss:  0.0003920727176591754
Valid Loss:  0.0006772920023649931
Epoch:  377  	Training Loss: 0.0005572043010033667
Test Loss:  0.00038935168413445354
Valid Loss:  0.00067439756821841
Epoch:  378  	Training Loss: 0.0005545725580304861
Test Loss:  0.0003870003274641931
Valid Loss:  0.000671711633913219
Epoch:  379  	Training Loss: 0.0005521258572116494
Test Loss:  0.0003847793850582093
Valid Loss:  0.0006692362949252129
Epoch:  380  	Training Loss: 0.0005498335231095552
Test Loss:  0.0003829967463389039
Valid Loss:  0.0006669906433671713
Epoch:  381  	Training Loss: 0.0005476829828694463
Test Loss:  0.000381307618226856
Valid Loss:  0.0006647920818068087
Epoch:  382  	Training Loss: 0.000545597868040204
Test Loss:  0.00039144587935879827
Valid Loss:  0.0006658685160800815
Epoch:  383  	Training Loss: 0.0005431824829429388
Test Loss:  0.0003976831794716418
Valid Loss:  0.0006668636342510581
Epoch:  384  	Training Loss: 0.0005424909759312868
Test Loss:  0.0004008038667961955
Valid Loss:  0.0006674099713563919
Epoch:  385  	Training Loss: 0.0005423142574727535
Test Loss:  0.00040256098145619035
Valid Loss:  0.000667693791911006
Epoch:  386  	Training Loss: 0.0005422580288723111
Test Loss:  0.0004034129960928112
Valid Loss:  0.000667800020892173
Epoch:  387  	Training Loss: 0.0005422405665740371
Test Loss:  0.00040386366890743375
Valid Loss:  0.0006678287172690034
Epoch:  388  	Training Loss: 0.0005422332906164229
Test Loss:  0.00040409492794424295
Valid Loss:  0.0006678206846117973
Epoch:  389  	Training Loss: 0.000542229856364429
Test Loss:  0.00040420901495963335
Valid Loss:  0.0006677965866401792
Epoch:  390  	Training Loss: 0.0005422283429652452
Test Loss:  0.00040425770566798747
Valid Loss:  0.0006677669007331133
Epoch:  391  	Training Loss: 0.0005422282265499234
Test Loss:  0.0004037535982206464
Valid Loss:  0.0006676496705040336
Epoch:  392  	Training Loss: 0.0005422284593805671
Test Loss:  0.000397785275708884
Valid Loss:  0.0006638584891334176
Epoch:  393  	Training Loss: 0.0005402272799983621
Test Loss:  0.0003927636134903878
Valid Loss:  0.0006606311653740704
Epoch:  394  	Training Loss: 0.0005384861724451184
Test Loss:  0.00038849879638291895
Valid Loss:  0.0006578639149665833
Epoch:  395  	Training Loss: 0.0005369199789129198
Test Loss:  0.00038485790719278157
Valid Loss:  0.000655435724183917
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.000535468861926347
Test Loss:  0.00037955731386318803
Valid Loss:  0.0006525540957227349
Epoch:  397  	Training Loss: 0.0005349144921638072
Test Loss:  0.00037730683106929064
Valid Loss:  0.0006512412801384926
Epoch:  398  	Training Loss: 0.0005345589015632868
Test Loss:  0.00037628112477250397
Valid Loss:  0.0006505391793325543
Epoch:  399  	Training Loss: 0.0005342433578334749
Test Loss:  0.0003757640370167792
Valid Loss:  0.0006500851595774293
Epoch:  400  	Training Loss: 0.0005339408526197076
Test Loss:  0.0003754621429834515
Valid Loss:  0.0006497310241684318
Epoch:  401  	Training Loss: 0.0005336472531780601
Test Loss:  0.0003752527409233153
Valid Loss:  0.0006494197878055274
Epoch:  402  	Training Loss: 0.0005333589506335557
Test Loss:  0.0003757949161808938
Valid Loss:  0.0006491555832326412
Epoch:  403  	Training Loss: 0.0005326743703335524
Test Loss:  0.00037586624966934323
Valid Loss:  0.0006486725178547204
Epoch:  404  	Training Loss: 0.0005320066120475531
Test Loss:  0.00037565361708402634
Valid Loss:  0.0006480594165623188
Epoch:  405  	Training Loss: 0.0005313559668138623
Test Loss:  0.000375324918422848
Valid Loss:  0.0006473856628872454
Epoch:  406  	Training Loss: 0.0005307085812091827
Test Loss:  0.0003749337629415095
Valid Loss:  0.0006466827471740544
Epoch:  407  	Training Loss: 0.0005300638731569052
Test Loss:  0.00037451437674462795
Valid Loss:  0.0006459618452936411
Epoch:  408  	Training Loss: 0.0005294212605804205
Test Loss:  0.0003740810207091272
Valid Loss:  0.0006452326197177172
Epoch:  409  	Training Loss: 0.000528792676050216
Test Loss:  0.00037354801315814257
Valid Loss:  0.000644486048258841
Epoch:  410  	Training Loss: 0.0005281795747578144
Test Loss:  0.0003730641328729689
Valid Loss:  0.000643754901830107
Epoch:  411  	Training Loss: 0.0005275684525258839
Test Loss:  0.00037261293618939817
Valid Loss:  0.0006430314970202744
Epoch:  412  	Training Loss: 0.0005269639077596366
Test Loss:   82%|████████▏ | 412/500 [05:07<01:49,  1.24s/it] 83%|████████▎ | 414/500 [05:07<01:17,  1.12it/s] 83%|████████▎ | 416/500 [05:08<00:54,  1.53it/s] 84%|████████▎ | 418/500 [05:08<00:39,  2.06it/s] 84%|████████▍ | 420/500 [05:08<00:29,  2.74it/s] 84%|████████▍ | 422/500 [05:14<01:34,  1.22s/it] 85%|████████▍ | 424/500 [05:15<01:06,  1.15it/s] 85%|████████▌ | 426/500 [05:15<00:46,  1.59it/s] 86%|████████▌ | 428/500 [05:15<00:33,  2.17it/s] 86%|████████▌ | 430/500 [05:15<00:23,  2.93it/s] 86%|████████▋ | 432/500 [05:21<01:19,  1.17s/it] 87%|████████▋ | 434/500 [05:21<00:55,  1.19it/s] 87%|████████▋ | 436/500 [05:21<00:38,  1.64it/s] 88%|████████▊ | 438/500 [05:22<00:27,  2.24it/s] 88%|████████▊ | 440/500 [05:22<00:19,  3.02it/s] 88%|████████▊ | 442/500 [05:28<01:09,  1.19s/it] 89%|████████▉ | 444/500 [05:28<00:47,  1.17it/s] 89%|████████▉ | 446/500 [05:28<00:33,  1.62it/s] 90%|████████▉ | 448/500 [05:28<00:23,  2.21it/s] 90%|█████████ | 450/500 [05:29<00:16,  2.97it/s] 90%|█████████ | 452/500 [05:35<00:56,  1.17s/it] 91%|█████████ | 454/500 [05:35<00:38,  1.19it/s] 91%|█████████ | 456/500 [05:35<00:26,  1.65it/s] 92%|█████████▏| 458/500 [05:35<00:18,  2.26it/s] 92%|█████████▏| 460/500 [05:35<00:13,  3.03it/s] 92%|█████████▏| 462/500 [05:42<00:44,  1.17s/it] 93%|█████████▎| 464/500 [05:42<00:30,  1.19it/s] 93%|█████████▎| 466/500 [05:42<00:20,  1.62it/s] 94%|█████████▎| 468/500 [05:42<00:14,  2.19it/s] 94%|█████████▍| 470/500 [05:42<00:10,  2.89it/s] 94%|█████████▍| 472/500 [05:49<00:33,  1.21s/it] 95%|█████████▍| 474/500 [05:49<00:22,  1.15it/s] 95%|█████████▌| 476/500 [05:49<00:15,  1.57it/s] 96%|█████████▌| 478/500 [05:49<00:10,  2.14it/s]0.00036306981928646564
Valid Loss:  0.0006361040286719799
Epoch:  413  	Training Loss: 0.0005242041079327464
Test Loss:  0.0003605156671255827
Valid Loss:  0.0006329638417810202
Epoch:  414  	Training Loss: 0.0005222269101068377
Test Loss:  0.00036009459290653467
Valid Loss:  0.0006309702876023948
Epoch:  415  	Training Loss: 0.000520703790243715
Test Loss:  0.0003602849901653826
Valid Loss:  0.0006295284256339073
Epoch:  416  	Training Loss: 0.0005194491823203862
Test Loss:  0.00036087591433897614
Valid Loss:  0.0006286263815127313
Epoch:  417  	Training Loss: 0.0005185425980016589
Test Loss:  0.00036096019903197885
Valid Loss:  0.0006275365594774485
Epoch:  418  	Training Loss: 0.0005177076673135161
Test Loss:  0.00036107454798184335
Valid Loss:  0.0006266073323786259
Epoch:  419  	Training Loss: 0.000517007487360388
Test Loss:  0.00036119396099820733
Valid Loss:  0.0006257916102185845
Epoch:  420  	Training Loss: 0.0005163715686649084
Test Loss:  0.00036134387482888997
Valid Loss:  0.000625058775767684
Epoch:  421  	Training Loss: 0.0005158031126484275
Test Loss:  0.0003613232111092657
Valid Loss:  0.0006242657545953989
Epoch:  422  	Training Loss: 0.0005152576486580074
Test Loss:  0.0003639848146121949
Valid Loss:  0.0006252367747947574
Epoch:  423  	Training Loss: 0.0005142143927514553
Test Loss:  0.0003654173342511058
Valid Loss:  0.0006256920751184225
Epoch:  424  	Training Loss: 0.000513410079292953
Test Loss:  0.00036603439366444945
Valid Loss:  0.000625774497166276
Epoch:  425  	Training Loss: 0.0005127199692651629
Test Loss:  0.0003661230148281902
Valid Loss:  0.000625604297965765
Epoch:  426  	Training Loss: 0.00051208829972893
Test Loss:  0.00036587915383279324
Valid Loss:  0.0006252692546695471
Epoch:  427  	Training Loss: 0.0005114910309202969
Test Loss:  0.00036543369060382247
Valid Loss:  0.0006248278659768403
Epoch:  428  	Training Loss: 0.0005109172197990119
Test Loss:  0.0003648690180853009
Valid Loss:  0.0006243225070647895
Epoch:  429  	Training Loss: 0.0005103613948449492
Test Loss:  0.00036424113204702735
Valid Loss:  0.0006237763445824385
Epoch:  430  	Training Loss: 0.0005098192486912012
Test Loss:  0.00036358178476803005
Valid Loss:  0.0006232091691344976
Epoch:  431  	Training Loss: 0.0005092888022772968
Test Loss:  0.0003629110869951546
Valid Loss:  0.0006226300029084086
Epoch:  432  	Training Loss: 0.0005087686004117131
Test Loss:  0.00036041904240846634
Valid Loss:  0.0006209765560925007
Epoch:  433  	Training Loss: 0.000507453631144017
Test Loss:  0.00035817729076370597
Valid Loss:  0.0006194676388986409
Epoch:  434  	Training Loss: 0.000506193027831614
Test Loss:  0.000356119591742754
Valid Loss:  0.0006180660566315055
Epoch:  435  	Training Loss: 0.0005049792816862464
Test Loss:  0.0003542050253599882
Valid Loss:  0.0006167456740513444
Epoch:  436  	Training Loss: 0.0005038178060203791
Test Loss:  0.0003525660722516477
Valid Loss:  0.0006155291921459138
Epoch:  437  	Training Loss: 0.0005027442239224911
Test Loss:  0.00035100727109238505
Valid Loss:  0.0006143641658127308
Epoch:  438  	Training Loss: 0.0005017064977437258
Test Loss:  0.0003495175624266267
Valid Loss:  0.0006132401758804917
Epoch:  439  	Training Loss: 0.0005007004365324974
Test Loss:  0.00034809097996912897
Valid Loss:  0.0006121577462181449
Epoch:  440  	Training Loss: 0.0004997270880267024
Test Loss:  0.0003467208007350564
Valid Loss:  0.000611109018791467
Epoch:  441  	Training Loss: 0.0004987797583453357
Test Loss:  0.0003454021643847227
Valid Loss:  0.0006100967875681818
Epoch:  442  	Training Loss: 0.0004978820215910673
Test Loss:  0.0003447812923695892
Valid Loss:  0.0006097704754211009
Epoch:  443  	Training Loss: 0.0004976552445441484
Test Loss:  0.0003443219175096601
Valid Loss:  0.0006095247226767242
Epoch:  444  	Training Loss: 0.0004974420298822224
Test Loss:  0.00034394755493849516
Valid Loss:  0.0006093108095228672
Epoch:  445  	Training Loss: 0.0004972465103492141
Test Loss:  0.0003436018596403301
Valid Loss:  0.00060910580214113
Epoch:  446  	Training Loss: 0.0004970597219653428
Test Loss:  0.0003432805242482573
Valid Loss:  0.0006089084781706333
Epoch:  447  	Training Loss: 0.000496879278216511
Test Loss:  0.00034297918318770826
Valid Loss:  0.0006087191868573427
Epoch:  448  	Training Loss: 0.0004967045970261097
Test Loss:  0.0003426873008720577
Valid Loss:  0.0006085332715883851
Epoch:  449  	Training Loss: 0.0004965353291481733
Test Loss:  0.00034241616958752275
Valid Loss:  0.0006083547486923635
Epoch:  450  	Training Loss: 0.0004963714745827019
Test Loss:  0.0003421666915528476
Valid Loss:  0.0006081870524212718
Epoch:  451  	Training Loss: 0.0004962186212651432
Test Loss:  0.0003419254207983613
Valid Loss:  0.0006080197053961456
Epoch:  452  	Training Loss: 0.0004960689693689346
Test Loss:  0.00034488405799493194
Valid Loss:  0.0006073705153539777
Epoch:  453  	Training Loss: 0.0004943843232467771
Test Loss:  0.00034668968874029815
Valid Loss:  0.0006065980414859951
Epoch:  454  	Training Loss: 0.0004931125440634787
Test Loss:  0.0003478271537460387
Valid Loss:  0.0006057205609977245
Epoch:  455  	Training Loss: 0.0004920251085422933
Test Loss:  0.0003486104542389512
Valid Loss:  0.0006047702627256513
Epoch:  456  	Training Loss: 0.0004910895368084311
Test Loss:  0.0003488092334009707
Valid Loss:  0.0006037543062120676
Epoch:  457  	Training Loss: 0.000490260892547667
Test Loss:  0.0003487828653305769
Valid Loss:  0.0006027224590070546
Epoch:  458  	Training Loss: 0.0004894740413874388
Test Loss:  0.0003485966008156538
Valid Loss:  0.0006016907282173634
Epoch:  459  	Training Loss: 0.0004887205432169139
Test Loss:  0.00034811272053048015
Valid Loss:  0.0006006438634358346
Epoch:  460  	Training Loss: 0.00048802816309034824
Test Loss:  0.00034759874688461423
Valid Loss:  0.0005996247055009007
Epoch:  461  	Training Loss: 0.00048734768643043935
Test Loss:  0.0003470648662187159
Valid Loss:  0.0005986298201605678
Epoch:  462  	Training Loss: 0.00048667675582692027
Test Loss:  0.0003430672222748399
Valid Loss:  0.0005963745061308146
Epoch:  463  	Training Loss: 0.0004862264031544328
Test Loss:  0.0003411617944948375
Valid Loss:  0.000595181598328054
Epoch:  464  	Training Loss: 0.00048590515507385135
Test Loss:  0.0003402031143195927
Valid Loss:  0.00059445173246786
Epoch:  465  	Training Loss: 0.00048561394214630127
Test Loss:  0.0003396818065084517
Valid Loss:  0.0005939329857937992
Epoch:  466  	Training Loss: 0.00048533239169046283
Test Loss:  0.0003393666702322662
Valid Loss:  0.0005935104563832283
Epoch:  467  	Training Loss: 0.00048505596350878477
Test Loss:  0.00033914949744939804
Valid Loss:  0.0005931335035711527
Epoch:  468  	Training Loss: 0.000484783056890592
Test Loss:  0.00033898395486176014
Valid Loss:  0.0005927787278778851
Epoch:  469  	Training Loss: 0.0004845131770707667
Test Loss:  0.00033884510048665106
Valid Loss:  0.0005924372235313058
Epoch:  470  	Training Loss: 0.0004842460621148348
Test Loss:  0.00033871899358928204
Valid Loss:  0.0005920992698520422
Epoch:  471  	Training Loss: 0.00048398220678791404
Test Loss:  0.00033860476105473936
Valid Loss:  0.0005917673697695136
Epoch:  472  	Training Loss: 0.0004837205051444471
Test Loss:  0.0003386739990673959
Valid Loss:  0.00059125991538167
Epoch:  473  	Training Loss: 0.00048186792992055416
Test Loss:  0.0003389125340618193
Valid Loss:  0.0005908471066504717
Epoch:  474  	Training Loss: 0.0004803107294719666
Test Loss:  0.00033904489828273654
Valid Loss:  0.0005904046702198684
Epoch:  475  	Training Loss: 0.0004789781814906746
Test Loss:  0.00033905572490766644
Valid Loss:  0.000589938776101917
Epoch:  476  	Training Loss: 0.00047777785221114755
Test Loss:  0.00033893651561811566
Valid Loss:  0.000589432311244309
Epoch:  477  	Training Loss: 0.00047672545770183206
Test Loss:  0.0003387595934327692
Valid Loss:  0.0005889033200219274
Epoch:  478  	Training Loss: 0.0004757689603138715
Test Loss:  0.00033848627936095
Valid Loss:  0.0005883294506929815
Epoch:  479  	Training Loss: 0.0004748860083054751
Test Loss:  0.0003381835122127086
Valid Loss:  0.0005877332878299057
Epoch:  480  	Training Loss: 0.0004740416188724339
Test Loss:   96%|█████████▌| 480/500 [05:49<00:06,  2.87it/s] 96%|█████████▋| 482/500 [05:56<00:21,  1.18s/it] 97%|█████████▋| 484/500 [05:56<00:13,  1.19it/s] 97%|█████████▋| 486/500 [05:56<00:08,  1.64it/s] 98%|█████████▊| 488/500 [05:56<00:05,  2.24it/s] 98%|█████████▊| 490/500 [05:56<00:03,  3.00it/s] 98%|█████████▊| 492/500 [06:02<00:09,  1.17s/it] 99%|█████████▉| 494/500 [06:03<00:05,  1.18it/s] 99%|█████████▉| 496/500 [06:03<00:02,  1.61it/s]100%|█████████▉| 498/500 [06:03<00:00,  2.18it/s]100%|██████████| 500/500 [06:03<00:00,  2.92it/s]100%|██████████| 500/500 [06:03<00:00,  1.38it/s]
0.00033785804407671094
Valid Loss:  0.0005871198372915387
Epoch:  481  	Training Loss: 0.00047323270700871944
Test Loss:  0.0003374651132617146
Valid Loss:  0.000586463138461113
Epoch:  482  	Training Loss: 0.00047247615293599665
Test Loss:  0.0003222874365746975
Valid Loss:  0.0005771135329268873
Epoch:  483  	Training Loss: 0.00047029508277773857
Test Loss:  0.0003243464161641896
Valid Loss:  0.0005762488581240177
Epoch:  484  	Training Loss: 0.00046881966409273446
Test Loss:  0.00032308613299392164
Valid Loss:  0.0005740610649809241
Epoch:  485  	Training Loss: 0.0004675917443819344
Test Loss:  0.0003227952402085066
Valid Loss:  0.0005724430084228516
Epoch:  486  	Training Loss: 0.00046647421550005674
Test Loss:  0.00032235594699159265
Valid Loss:  0.0005708827520720661
Epoch:  487  	Training Loss: 0.0004654410295188427
Test Loss:  0.0003219814971089363
Valid Loss:  0.0005694564897567034
Epoch:  488  	Training Loss: 0.00046447437489405274
Test Loss:  0.000321609724778682
Valid Loss:  0.0005681189359165728
Epoch:  489  	Training Loss: 0.0004635658988263458
Test Loss:  0.0003209515707567334
Valid Loss:  0.0005668182857334614
Epoch:  490  	Training Loss: 0.0004627757880371064
Test Loss:  0.00032061769161373377
Valid Loss:  0.0005657161236740649
Epoch:  491  	Training Loss: 0.0004620087565854192
Test Loss:  0.00032021570950746536
Valid Loss:  0.0005646287463605404
Epoch:  492  	Training Loss: 0.00046126043889671564
Test Loss:  0.0003204341046512127
Valid Loss:  0.0005645925411954522
Epoch:  493  	Training Loss: 0.00046098013990558684
Test Loss:  0.0003203580272383988
Valid Loss:  0.0005644139018841088
Epoch:  494  	Training Loss: 0.0004607090668287128
Test Loss:  0.0003201563376933336
Valid Loss:  0.0005641706520691514
Epoch:  495  	Training Loss: 0.0004604458808898926
Test Loss:  0.0003199042985215783
Valid Loss:  0.000563901208806783
Epoch:  496  	Training Loss: 0.0004601878463290632
Test Loss:  0.0003196356992702931
Valid Loss:  0.0005636202986352146
Epoch:  497  	Training Loss: 0.0004599338280968368
Test Loss:  0.00031936337472870946
Valid Loss:  0.0005633358377963305
Epoch:  498  	Training Loss: 0.0004596842627506703
Test Loss:  0.0003190977149643004
Valid Loss:  0.0005630517844110727
Epoch:  499  	Training Loss: 0.0004594380734488368
Test Loss:  0.0003188361879438162
Valid Loss:  0.0005627680802717805
Epoch:  500  	Training Loss: 0.00045919453259557486
Test Loss:  0.0003185831883456558
Valid Loss:  0.0005624864716082811
