train data shape torch.Size([256, 2])
train label shape torch.Size([256, 1])
torch.Size([256, 3])
train_data shape torch.Size([3])
seed is  1
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]/home/yuyi/Documents/ModifiedNGD/utils/readData.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
  0%|          | 1/500 [00:00<03:24,  2.44it/s]  1%|          | 3/500 [00:00<01:15,  6.55it/s]  1%|          | 5/500 [00:00<00:52,  9.48it/s]  1%|▏         | 7/500 [00:00<00:42, 11.52it/s]  2%|▏         | 9/500 [00:00<00:37, 13.01it/s]  2%|▏         | 11/500 [00:01<00:35, 13.83it/s]  3%|▎         | 13/500 [00:01<00:34, 14.01it/s]  3%|▎         | 15/500 [00:01<00:33, 14.29it/s]  3%|▎         | 17/500 [00:01<00:32, 14.92it/s]  4%|▍         | 19/500 [00:01<00:31, 15.40it/s]  4%|▍         | 21/500 [00:01<00:31, 15.45it/s]  5%|▍         | 23/500 [00:01<00:30, 15.72it/s]  5%|▌         | 25/500 [00:01<00:30, 15.83it/s]  5%|▌         | 27/500 [00:02<00:30, 15.67it/s]  6%|▌         | 29/500 [00:02<00:29, 15.79it/s]  6%|▌         | 31/500 [00:02<00:29, 15.98it/s]  7%|▋         | 33/500 [00:02<00:29, 15.90it/s]  7%|▋         | 35/500 [00:02<00:29, 15.73it/s]  7%|▋         | 37/500 [00:02<00:29, 15.56it/s]  8%|▊         | 39/500 [00:02<00:29, 15.74it/s]  8%|▊         | 41/500 [00:02<00:28, 15.89it/s]  9%|▊         | 43/500 [00:03<00:28, 15.99it/s]  9%|▉         | 45/500 [00:03<00:28, 16.06it/s]  9%|▉         | 47/500 [00:03<00:28, 16.11it/s] 10%|▉         | 49/500 [00:03<00:28, 16.08it/s] 10%|█         | 51/500 [00:03<00:27, 16.14it/s] 11%|█         | 53/500 [00:03<00:27, 16.12it/s] 11%|█         | 55/500 [00:03<00:27, 16.09it/s] 11%|█▏        | 57/500 [00:03<00:27, 16.07it/s] 12%|█▏        | 59/500 [00:04<00:27, 16.15it/s] 12%|█▏        | 61/500 [00:04<00:27, 16.14it/s] 13%|█▎        | 63/500 [00:04<00:26, 16.19it/s] 13%|█▎        | 65/500 [00:04<00:26, 16.15it/s] 13%|█▎        | 67/500 [00:04<00:26, 16.25it/s] 14%|█▍        | 69/500 [00:04<00:26, 16.27it/s] 14%|█▍        | 71/500 [00:04<00:26, 16.30it/s] 15%|█▍        | 73/500 [00:04<00:26, 16.40it/s] 15%|█▌        | 75/500 [00:05<00:25, 16.46it/s] 15%|█▌        | 77/500 [00:05<00:25, 16.39it/s] 16%|█▌        | 79/500 [00:05<00:25, 16.42it/s] 16%|█▌        | 81/500 [00:05<00:25, 16.40it/s] 17%|█▋        | 83/500 [00:05<00:25, 16.31it/s] 17%|█▋        | 85/500 [00:05<00:25, 16.03it/s] 17%|█▋        | 87/500 [00:05<00:25, 16.09it/s] 18%|█▊        | 89/500 [00:05<00:25, 15.81it/s] 18%|█▊        | 91/500 [00:06<00:25, 15.96it/s] 19%|█▊        | 93/500 [00:06<00:25, 16.00it/s] 19%|█▉        | 95/500 [00:06<00:25, 16.11it/s] 19%|█▉        | 97/500 [00:06<00:24, 16.19it/s] 20%|█▉        | 99/500 [00:06<00:24, 16.15it/s] 20%|██        | 101/500 [00:06<00:25, 15.69it/s] 21%|██        | 103/500 [00:06<00:25, 15.82it/s] 21%|██        | 105/500 [00:06<00:24, 15.97it/s] 21%|██▏       | 107/500 [00:07<00:24, 16.05it/s] 22%|██▏       | 109/500 [00:07<00:24, 15.98it/s] 22%|██▏       | 111/500 [00:07<00:24, 16.08it/s] 23%|██▎       | 113/500 [00:07<00:24, 16.07it/s] 23%|██▎       | 115/500 [00:07<00:23, 16.12it/s] 23%|██▎       | 117/500 [00:07<00:23, 16.15it/s] 24%|██▍       | 119/500 [00:07<00:23, 16.19it/s] 24%|██▍       | 121/500 [00:07<00:23, 16.25it/s] 25%|██▍       | 123/500 [00:08<00:23, 16.29it/s]Epoch:  1  	Training Loss: 0.023777710273861885
Test Loss:  1.4305262565612793
Valid Loss:  1.4499030113220215
Epoch:  2  	Training Loss: 1.432321310043335
Test Loss:  58211.5625
Valid Loss:  58036.8125
Epoch:  3  	Training Loss: 58054.3046875
Test Loss:  1.7037251417467497e+25
Valid Loss:  1.6889676311956316e+25
Epoch:  4  	Training Loss: 1.6925661297958105e+25
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
 25%|██▌       | 125/500 [00:08<00:23, 16.29it/s] 25%|██▌       | 127/500 [00:08<00:22, 16.31it/s] 26%|██▌       | 129/500 [00:08<00:22, 16.37it/s] 26%|██▌       | 131/500 [00:08<00:22, 16.36it/s] 27%|██▋       | 133/500 [00:08<00:22, 16.28it/s] 27%|██▋       | 135/500 [00:08<00:22, 16.25it/s] 27%|██▋       | 137/500 [00:08<00:22, 16.25it/s] 28%|██▊       | 139/500 [00:08<00:22, 16.32it/s] 28%|██▊       | 141/500 [00:09<00:22, 16.28it/s] 29%|██▊       | 143/500 [00:09<00:22, 16.19it/s] 29%|██▉       | 145/500 [00:09<00:21, 16.19it/s] 29%|██▉       | 147/500 [00:09<00:21, 16.21it/s] 30%|██▉       | 149/500 [00:09<00:21, 15.99it/s] 30%|███       | 151/500 [00:09<00:23, 14.80it/s] 31%|███       | 153/500 [00:09<00:24, 13.92it/s] 31%|███       | 155/500 [00:10<00:25, 13.39it/s] 31%|███▏      | 157/500 [00:10<00:26, 12.97it/s] 32%|███▏      | 159/500 [00:10<00:26, 12.81it/s] 32%|███▏      | 161/500 [00:10<00:26, 12.64it/s] 33%|███▎      | 163/500 [00:10<00:26, 12.50it/s] 33%|███▎      | 165/500 [00:10<00:27, 12.40it/s] 33%|███▎      | 167/500 [00:11<00:27, 12.32it/s] 34%|███▍      | 169/500 [00:11<00:25, 12.85it/s] 34%|███▍      | 171/500 [00:11<00:24, 13.65it/s] 35%|███▍      | 173/500 [00:11<00:22, 14.34it/s] 35%|███▌      | 175/500 [00:11<00:21, 14.92it/s] 35%|███▌      | 177/500 [00:11<00:21, 15.33it/s] 36%|███▌      | 179/500 [00:11<00:20, 15.61it/s] 36%|███▌      | 181/500 [00:11<00:20, 15.65it/s] 37%|███▋      | 183/500 [00:12<00:19, 15.86it/s] 37%|███▋      | 185/500 [00:12<00:19, 15.85it/s] 37%|███▋      | 187/500 [00:12<00:19, 15.87it/s] 38%|███▊      | 189/500 [00:12<00:19, 15.68it/s] 38%|███▊      | 191/500 [00:12<00:19, 15.79it/s] 39%|███▊      | 193/500 [00:12<00:19, 15.62it/s] 39%|███▉      | 195/500 [00:12<00:19, 15.87it/s] 39%|███▉      | 197/500 [00:12<00:18, 15.97it/s] 40%|███▉      | 199/500 [00:13<00:18, 16.07it/s] 40%|████      | 201/500 [00:13<00:18, 16.09it/s] 41%|████      | 203/500 [00:13<00:18, 15.68it/s] 41%|████      | 205/500 [00:13<00:18, 15.69it/s] 41%|████▏     | 207/500 [00:13<00:18, 15.86it/s] 42%|████▏     | 209/500 [00:13<00:18, 15.91it/s] 42%|████▏     | 211/500 [00:13<00:17, 16.06it/s] 43%|████▎     | 213/500 [00:13<00:17, 16.11it/s] 43%|████▎     | 215/500 [00:14<00:17, 16.14it/s] 43%|████▎     | 217/500 [00:14<00:17, 16.18it/s] 44%|████▍     | 219/500 [00:14<00:17, 16.24it/s] 44%|████▍     | 221/500 [00:14<00:17, 16.19it/s] 45%|████▍     | 223/500 [00:14<00:17, 16.04it/s] 45%|████▌     | 225/500 [00:14<00:17, 16.10it/s] 45%|████▌     | 227/500 [00:14<00:16, 16.14it/s] 46%|████▌     | 229/500 [00:14<00:16, 16.17it/s] 46%|████▌     | 231/500 [00:15<00:16, 16.22it/s] 47%|████▋     | 233/500 [00:15<00:16, 16.13it/s] 47%|████▋     | 235/500 [00:15<00:16, 16.03it/s] 47%|████▋     | 237/500 [00:15<00:16, 16.10it/s] 48%|████▊     | 239/500 [00:15<00:16, 15.96it/s] 48%|████▊     | 241/500 [00:15<00:16, 16.01it/s] 49%|████▊     | 243/500 [00:15<00:16, 15.83it/s] 49%|████▉     | 245/500 [00:15<00:16, 15.93it/s] 49%|████▉     | 247/500 [00:16<00:15, 16.00it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
 50%|████▉     | 249/500 [00:16<00:15, 15.73it/s] 50%|█████     | 251/500 [00:16<00:15, 15.85it/s] 51%|█████     | 253/500 [00:16<00:15, 15.91it/s] 51%|█████     | 255/500 [00:16<00:15, 15.74it/s] 51%|█████▏    | 257/500 [00:16<00:15, 15.60it/s] 52%|█████▏    | 259/500 [00:16<00:15, 15.68it/s] 52%|█████▏    | 261/500 [00:16<00:14, 15.94it/s] 53%|█████▎    | 263/500 [00:17<00:14, 16.09it/s] 53%|█████▎    | 265/500 [00:17<00:14, 16.15it/s] 53%|█████▎    | 267/500 [00:17<00:14, 16.30it/s] 54%|█████▍    | 269/500 [00:17<00:14, 16.28it/s] 54%|█████▍    | 271/500 [00:17<00:14, 16.01it/s] 55%|█████▍    | 273/500 [00:17<00:14, 15.53it/s] 55%|█████▌    | 275/500 [00:17<00:14, 15.71it/s] 55%|█████▌    | 277/500 [00:17<00:14, 15.93it/s] 56%|█████▌    | 279/500 [00:18<00:13, 16.01it/s] 56%|█████▌    | 281/500 [00:18<00:13, 15.84it/s] 57%|█████▋    | 283/500 [00:18<00:13, 15.83it/s] 57%|█████▋    | 285/500 [00:18<00:13, 15.81it/s] 57%|█████▋    | 287/500 [00:18<00:13, 15.97it/s] 58%|█████▊    | 289/500 [00:18<00:13, 16.07it/s] 58%|█████▊    | 291/500 [00:18<00:17, 11.99it/s] 59%|█████▊    | 293/500 [00:19<00:15, 13.04it/s] 59%|█████▉    | 295/500 [00:19<00:15, 13.27it/s] 59%|█████▉    | 297/500 [00:19<00:15, 12.87it/s] 60%|█████▉    | 299/500 [00:19<00:15, 12.71it/s] 60%|██████    | 301/500 [00:19<00:15, 12.55it/s] 61%|██████    | 303/500 [00:19<00:15, 12.51it/s] 61%|██████    | 305/500 [00:20<00:15, 12.48it/s] 61%|██████▏   | 307/500 [00:20<00:14, 13.20it/s] 62%|██████▏   | 309/500 [00:20<00:13, 13.94it/s] 62%|██████▏   | 311/500 [00:20<00:12, 14.56it/s] 63%|██████▎   | 313/500 [00:20<00:12, 14.94it/s] 63%|██████▎   | 315/500 [00:20<00:12, 15.13it/s] 63%|██████▎   | 317/500 [00:20<00:11, 15.48it/s] 64%|██████▍   | 319/500 [00:20<00:11, 15.73it/s] 64%|██████▍   | 321/500 [00:21<00:11, 15.87it/s] 65%|██████▍   | 323/500 [00:21<00:11, 15.71it/s] 65%|██████▌   | 325/500 [00:21<00:12, 14.38it/s] 65%|██████▌   | 327/500 [00:21<00:12, 13.71it/s] 66%|██████▌   | 329/500 [00:21<00:12, 13.25it/s] 66%|██████▌   | 331/500 [00:21<00:13, 12.95it/s] 67%|██████▋   | 333/500 [00:22<00:13, 12.74it/s] 67%|██████▋   | 335/500 [00:22<00:13, 12.57it/s] 67%|██████▋   | 337/500 [00:22<00:13, 12.51it/s] 68%|██████▊   | 339/500 [00:22<00:12, 12.42it/s] 68%|██████▊   | 341/500 [00:22<00:12, 12.39it/s] 69%|██████▊   | 343/500 [00:22<00:12, 12.40it/s] 69%|██████▉   | 345/500 [00:22<00:11, 13.32it/s] 69%|██████▉   | 347/500 [00:23<00:10, 14.15it/s] 70%|██████▉   | 349/500 [00:23<00:10, 14.56it/s] 70%|███████   | 351/500 [00:23<00:10, 14.77it/s] 71%|███████   | 353/500 [00:23<00:09, 15.18it/s] 71%|███████   | 355/500 [00:23<00:09, 15.53it/s] 71%|███████▏  | 357/500 [00:23<00:09, 15.08it/s] 72%|███████▏  | 359/500 [00:23<00:09, 14.38it/s] 72%|███████▏  | 361/500 [00:24<00:09, 14.48it/s] 73%|███████▎  | 363/500 [00:24<00:09, 15.00it/s] 73%|███████▎  | 365/500 [00:24<00:08, 15.35it/s] 73%|███████▎  | 367/500 [00:24<00:08, 15.55it/s] 74%|███████▍  | 369/500 [00:24<00:08, 15.53it/s] 74%|███████▍  | 371/500 [00:24<00:08, 15.36it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
 75%|███████▍  | 373/500 [00:24<00:08, 15.61it/s] 75%|███████▌  | 375/500 [00:24<00:08, 15.58it/s] 75%|███████▌  | 377/500 [00:25<00:07, 15.76it/s] 76%|███████▌  | 379/500 [00:25<00:07, 15.77it/s] 76%|███████▌  | 381/500 [00:25<00:07, 15.86it/s] 77%|███████▋  | 383/500 [00:25<00:07, 16.05it/s] 77%|███████▋  | 385/500 [00:25<00:07, 16.08it/s] 77%|███████▋  | 387/500 [00:25<00:06, 16.22it/s] 78%|███████▊  | 389/500 [00:25<00:06, 16.30it/s] 78%|███████▊  | 391/500 [00:25<00:06, 16.29it/s] 79%|███████▊  | 393/500 [00:26<00:06, 15.68it/s] 79%|███████▉  | 395/500 [00:26<00:06, 15.66it/s] 79%|███████▉  | 397/500 [00:26<00:06, 15.60it/s] 80%|███████▉  | 399/500 [00:26<00:06, 15.35it/s] 80%|████████  | 401/500 [00:26<00:06, 15.46it/s] 81%|████████  | 403/500 [00:26<00:06, 15.67it/s] 81%|████████  | 405/500 [00:26<00:05, 15.87it/s] 81%|████████▏ | 407/500 [00:26<00:05, 15.89it/s] 82%|████████▏ | 409/500 [00:27<00:05, 15.83it/s] 82%|████████▏ | 411/500 [00:27<00:05, 15.81it/s] 83%|████████▎ | 413/500 [00:27<00:05, 15.71it/s] 83%|████████▎ | 415/500 [00:27<00:05, 15.69it/s] 83%|████████▎ | 417/500 [00:27<00:05, 15.63it/s] 84%|████████▍ | 419/500 [00:27<00:05, 15.47it/s] 84%|████████▍ | 421/500 [00:27<00:05, 14.67it/s] 85%|████████▍ | 423/500 [00:28<00:05, 13.86it/s] 85%|████████▌ | 425/500 [00:28<00:05, 14.52it/s] 85%|████████▌ | 427/500 [00:28<00:04, 14.98it/s] 86%|████████▌ | 429/500 [00:28<00:04, 15.40it/s] 86%|████████▌ | 431/500 [00:28<00:04, 15.62it/s] 87%|████████▋ | 433/500 [00:28<00:04, 15.84it/s] 87%|████████▋ | 435/500 [00:28<00:04, 16.00it/s] 87%|████████▋ | 437/500 [00:28<00:03, 15.99it/s] 88%|████████▊ | 439/500 [00:28<00:03, 16.15it/s] 88%|████████▊ | 441/500 [00:29<00:03, 16.19it/s] 89%|████████▊ | 443/500 [00:29<00:03, 16.22it/s] 89%|████████▉ | 445/500 [00:29<00:03, 16.25it/s] 89%|████████▉ | 447/500 [00:29<00:03, 16.28it/s] 90%|████████▉ | 449/500 [00:29<00:03, 16.11it/s] 90%|█████████ | 451/500 [00:29<00:03, 16.14it/s] 91%|█████████ | 453/500 [00:29<00:02, 16.24it/s] 91%|█████████ | 455/500 [00:29<00:02, 16.31it/s] 91%|█████████▏| 457/500 [00:30<00:02, 16.25it/s] 92%|█████████▏| 459/500 [00:30<00:02, 16.24it/s] 92%|█████████▏| 461/500 [00:30<00:02, 16.20it/s] 93%|█████████▎| 463/500 [00:30<00:02, 16.25it/s] 93%|█████████▎| 465/500 [00:30<00:02, 16.25it/s] 93%|█████████▎| 467/500 [00:30<00:02, 16.30it/s] 94%|█████████▍| 469/500 [00:30<00:01, 16.27it/s] 94%|█████████▍| 471/500 [00:30<00:01, 16.20it/s] 95%|█████████▍| 473/500 [00:31<00:01, 16.26it/s] 95%|█████████▌| 475/500 [00:31<00:01, 16.26it/s] 95%|█████████▌| 477/500 [00:31<00:01, 15.69it/s] 96%|█████████▌| 479/500 [00:31<00:01, 15.19it/s] 96%|█████████▌| 481/500 [00:31<00:01, 15.33it/s] 97%|█████████▋| 483/500 [00:31<00:01, 14.61it/s] 97%|█████████▋| 485/500 [00:31<00:01, 13.83it/s] 97%|█████████▋| 487/500 [00:32<00:00, 14.46it/s] 98%|█████████▊| 489/500 [00:32<00:00, 14.95it/s] 98%|█████████▊| 491/500 [00:32<00:00, 15.29it/s] 99%|█████████▊| 493/500 [00:32<00:00, 15.52it/s] 99%|█████████▉| 495/500 [00:32<00:00, 15.77it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
 99%|█████████▉| 497/500 [00:32<00:00, 15.91it/s]100%|█████████▉| 499/500 [00:32<00:00, 15.93it/s]100%|██████████| 500/500 [00:32<00:00, 15.22it/s]
/home/yuyi/anaconda3/envs/ng/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/autograd/engine.cpp:1151.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  1
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:36,  6.45s/it]  1%|          | 3/500 [00:06<14:15,  1.72s/it]  1%|          | 5/500 [00:06<07:10,  1.15it/s]  1%|▏         | 7/500 [00:06<04:20,  1.89it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.99it/s]  4%|▍         | 21/500 [00:20<09:31,  1.19s/it]  5%|▍         | 23/500 [00:20<06:45,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.24it/s]  6%|▌         | 29/500 [00:20<02:35,  3.02it/s]  6%|▌         | 31/500 [00:27<09:25,  1.21s/it]  7%|▋         | 33/500 [00:27<06:43,  1.16it/s]  7%|▋         | 35/500 [00:27<04:50,  1.60it/s]  7%|▋         | 37/500 [00:27<03:31,  2.19it/s]  8%|▊         | 39/500 [00:27<02:36,  2.95it/s]  8%|▊         | 41/500 [00:34<09:16,  1.21s/it]  9%|▊         | 43/500 [00:34<06:36,  1.15it/s]  9%|▉         | 45/500 [00:34<04:45,  1.59it/s]  9%|▉         | 47/500 [00:34<03:27,  2.18it/s] 10%|▉         | 49/500 [00:34<02:33,  2.94it/s] 10%|█         | 51/500 [00:41<09:06,  1.22s/it] 11%|█         | 53/500 [00:41<06:30,  1.14it/s] 11%|█         | 55/500 [00:41<04:40,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:24,  2.17it/s] 12%|█▏        | 59/500 [00:41<02:30,  2.92it/s] 12%|█▏        | 61/500 [00:47<08:41,  1.19s/it] 13%|█▎        | 63/500 [00:48<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.95it/s] 14%|█▍        | 71/500 [00:54<08:27,  1.18s/it]Epoch:  1  	Training Loss: 0.023777708411216736
Test Loss:  0.06404690444469452
Valid Loss:  0.0726214200258255
Epoch:  2  	Training Loss: 0.07407228648662567
Test Loss:  1.4247889518737793
Valid Loss:  1.3587684631347656
Epoch:  3  	Training Loss: 1.3678028583526611
Test Loss:  0.027305759489536285
Valid Loss:  0.03342064842581749
Epoch:  4  	Training Loss: 0.030287297442555428
Test Loss:  0.027181796729564667
Valid Loss:  0.0332832969725132
Epoch:  5  	Training Loss: 0.03016173280775547
Test Loss:  0.02705155313014984
Valid Loss:  0.033138006925582886
Epoch:  6  	Training Loss: 0.0300293006002903
Test Loss:  0.026933982968330383
Valid Loss:  0.03300364688038826
Epoch:  7  	Training Loss: 0.029906798154115677
Test Loss:  0.026850625872612
Valid Loss:  0.0329107865691185
Epoch:  8  	Training Loss: 0.029822062700986862
Test Loss:  0.026768028736114502
Valid Loss:  0.032818686217069626
Epoch:  9  	Training Loss: 0.02973812073469162
Test Loss:  0.026686154305934906
Valid Loss:  0.03272733464837074
Epoch:  10  	Training Loss: 0.029654929414391518
Test Loss:  0.026605023071169853
Valid Loss:  0.032636746764183044
Epoch:  11  	Training Loss: 0.029572460800409317
Test Loss:  0.026524577289819717
Valid Loss:  0.032546862959861755
Epoch:  12  	Training Loss: 0.029490657150745392
Test Loss:  0.026431532576680183
Valid Loss:  0.03244040533900261
Epoch:  13  	Training Loss: 0.02939300611615181
Test Loss:  0.02633998543024063
Valid Loss:  0.0323343425989151
Epoch:  14  	Training Loss: 0.029296202585101128
Test Loss:  0.026249870657920837
Valid Loss:  0.032229430973529816
Epoch:  15  	Training Loss: 0.02920081466436386
Test Loss:  0.026159923523664474
Valid Loss:  0.03212542459368706
Epoch:  16  	Training Loss: 0.029106132686138153
Test Loss:  0.02607078105211258
Valid Loss:  0.03202183544635773
Epoch:  17  	Training Loss: 0.02901185117661953
Test Loss:  0.02598278596997261
Valid Loss:  0.0319189727306366
Epoch:  18  	Training Loss: 0.028918836265802383
Test Loss:  0.025913497433066368
Valid Loss:  0.03184031695127487
Epoch:  19  	Training Loss: 0.028846152126789093
Test Loss:  0.025859259068965912
Valid Loss:  0.03177923709154129
Epoch:  20  	Training Loss: 0.02879117988049984
Test Loss:  0.025812653824687004
Valid Loss:  0.031729742884635925
Epoch:  21  	Training Loss: 0.028744637966156006
Test Loss:  0.025780372321605682
Valid Loss:  0.03169480711221695
Epoch:  22  	Training Loss: 0.02871159091591835
Test Loss:  0.02576112002134323
Valid Loss:  0.03167359158396721
Epoch:  23  	Training Loss: 0.0286918506026268
Test Loss:  0.025744447484612465
Valid Loss:  0.0316549688577652
Epoch:  24  	Training Loss: 0.028674282133579254
Test Loss:  0.025731593370437622
Valid Loss:  0.031640417873859406
Epoch:  25  	Training Loss: 0.02866034395992756
Test Loss:  0.025719819590449333
Valid Loss:  0.0316261351108551
Epoch:  26  	Training Loss: 0.028646815568208694
Test Loss:  0.02570844441652298
Valid Loss:  0.03161201626062393
Epoch:  27  	Training Loss: 0.028633587062358856
Test Loss:  0.02569754421710968
Valid Loss:  0.03159797191619873
Epoch:  28  	Training Loss: 0.028620606288313866
Test Loss:  0.025686651468276978
Valid Loss:  0.0315842479467392
Epoch:  29  	Training Loss: 0.028607845306396484
Test Loss:  0.025675902143120766
Valid Loss:  0.031570613384246826
Epoch:  30  	Training Loss: 0.02859519049525261
Test Loss:  0.02566519007086754
Valid Loss:  0.03155708312988281
Epoch:  31  	Training Loss: 0.028582628816366196
Test Loss:  0.0256545078009367
Valid Loss:  0.03154366463422775
Epoch:  32  	Training Loss: 0.028570163995027542
Test Loss:  0.02564188651740551
Valid Loss:  0.031532254070043564
Epoch:  33  	Training Loss: 0.028558408841490746
Test Loss:  0.025630390271544456
Valid Loss:  0.03152068704366684
Epoch:  34  	Training Loss: 0.02854696474969387
Test Loss:  0.025618888437747955
Valid Loss:  0.031509172171354294
Epoch:  35  	Training Loss: 0.02853555977344513
Test Loss:  0.025607382878661156
Valid Loss:  0.03149772062897682
Epoch:  36  	Training Loss: 0.028524233028292656
Test Loss:  0.02559659443795681
Valid Loss:  0.031486235558986664
Epoch:  37  	Training Loss: 0.028513092547655106
Test Loss:  0.025586767122149467
Valid Loss:  0.03147462010383606
Epoch:  38  	Training Loss: 0.028502076864242554
Test Loss:  0.025576988235116005
Valid Loss:  0.03146308660507202
Epoch:  39  	Training Loss: 0.028491120785474777
Test Loss:  0.025567254051566124
Valid Loss:  0.031451623886823654
Epoch:  40  	Training Loss: 0.028480224311351776
Test Loss:  0.025557518005371094
Valid Loss:  0.03144022822380066
Epoch:  41  	Training Loss: 0.028469379991292953
Test Loss:  0.025547785684466362
Valid Loss:  0.031428903341293335
Epoch:  42  	Training Loss: 0.02845858596265316
Test Loss:  0.02553824707865715
Valid Loss:  0.03141748905181885
Epoch:  43  	Training Loss: 0.028447754681110382
Test Loss:  0.025528712198138237
Valid Loss:  0.03140617161989212
Epoch:  44  	Training Loss: 0.028436986729502678
Test Loss:  0.025519169867038727
Valid Loss:  0.031394924968481064
Epoch:  45  	Training Loss: 0.028426282107830048
Test Loss:  0.025509677827358246
Valid Loss:  0.03138375282287598
Epoch:  46  	Training Loss: 0.028415657579898834
Test Loss:  0.0255003422498703
Valid Loss:  0.03137262910604477
Epoch:  47  	Training Loss: 0.02840510755777359
Test Loss:  0.025491081178188324
Valid Loss:  0.03136155754327774
Epoch:  48  	Training Loss: 0.02839461714029312
Test Loss:  0.025481829419732094
Valid Loss:  0.03135056793689728
Epoch:  49  	Training Loss: 0.028384197503328323
Test Loss:  0.025472596287727356
Valid Loss:  0.031339652836322784
Epoch:  50  	Training Loss: 0.028373852372169495
Test Loss:  0.02546374686062336
Valid Loss:  0.03132873773574829
Epoch:  51  	Training Loss: 0.028363579884171486
Test Loss:  0.02545490302145481
Valid Loss:  0.03131788969039917
Epoch:  52  	Training Loss: 0.02835337445139885
Test Loss:  0.02544613555073738
Valid Loss:  0.031307097524404526
Epoch:  53  	Training Loss: 0.028343211859464645
Test Loss:  0.0254373736679554
Valid Loss:  0.03129638731479645
Epoch:  54  	Training Loss: 0.028333116322755814
Test Loss:  0.025428637862205505
Valid Loss:  0.03128574788570404
Epoch:  55  	Training Loss: 0.028323084115982056
Test Loss:  0.025419924408197403
Valid Loss:  0.0312751829624176
Epoch:  56  	Training Loss: 0.02831311523914337
Test Loss:  0.025411320850253105
Valid Loss:  0.03126467764377594
Epoch:  57  	Training Loss: 0.02830321155488491
Test Loss:  0.025402717292308807
Valid Loss:  0.03125424683094025
Epoch:  58  	Training Loss: 0.028293371200561523
Test Loss:  0.025394100695848465
Valid Loss:  0.031243888661265373
Epoch:  59  	Training Loss: 0.028283586725592613
Test Loss:  0.025385532528162003
Valid Loss:  0.031233595684170723
Epoch:  60  	Training Loss: 0.028273863717913628
Test Loss:  0.02537696808576584
Valid Loss:  0.031223364174365997
Epoch:  61  	Training Loss: 0.028264198452234268
Test Loss:  0.02536841668188572
Valid Loss:  0.03121320903301239
Epoch:  62  	Training Loss: 0.028254585340619087
Test Loss:  0.025359950959682465
Valid Loss:  0.031203145161271095
Epoch:  63  	Training Loss: 0.02824505791068077
Test Loss:  0.025351490825414658
Valid Loss:  0.031193146482110023
Epoch:  64  	Training Loss: 0.028235584497451782
Test Loss:  0.02534305304288864
Valid Loss:  0.03118322417140007
Epoch:  65  	Training Loss: 0.028226178139448166
Test Loss:  0.025334620848298073
Valid Loss:  0.03117336519062519
Epoch:  66  	Training Loss: 0.02821682021021843
Test Loss:  0.0253261961042881
Valid Loss:  0.031163565814495087
Epoch:  67  	Training Loss: 0.02820751816034317
Test Loss:  0.025317776948213577
Valid Loss:  0.031153837218880653
Epoch:  68  	Training Loss: 0.02819826826453209
Test Loss:  0.025309376418590546
Valid Loss:  0.031144171953201294
Epoch:  69  	Training Loss: 0.028189076110720634
Test Loss:  0.02530098333954811
Valid Loss:  0.03113456629216671
Epoch:  70  	Training Loss: 0.02817992866039276
Test Loss:  0.02529260143637657
Valid Loss:  0.03112502582371235
Epoch:  71  	Training Loss: 0.028170837089419365
Test Loss:  0.02528422698378563
Valid Loss:  0.031115535646677017
Epoch:  72  	Training Loss: 0.02816178649663925
Test Loss:  0.02527584135532379
 15%|█▍        | 73/500 [00:55<06:04,  1.17it/s] 15%|█▌        | 75/500 [00:55<04:25,  1.60it/s] 15%|█▌        | 77/500 [00:55<03:15,  2.16it/s] 16%|█▌        | 79/500 [00:55<02:26,  2.87it/s] 16%|█▌        | 81/500 [01:01<08:24,  1.20s/it] 17%|█▋        | 83/500 [01:02<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:02<03:08,  2.19it/s] 18%|█▊        | 89/500 [01:02<02:19,  2.95it/s] 18%|█▊        | 91/500 [01:08<08:00,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:43,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:09<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:09<02:13,  3.01it/s] 20%|██        | 101/500 [01:15<08:03,  1.21s/it] 21%|██        | 103/500 [01:15<05:46,  1.15it/s] 21%|██        | 105/500 [01:16<04:08,  1.59it/s] 21%|██▏       | 107/500 [01:16<03:00,  2.17it/s] 22%|██▏       | 109/500 [01:16<02:13,  2.93it/s] 22%|██▏       | 111/500 [01:22<07:40,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:23<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:29<07:35,  1.20s/it] 25%|██▍       | 123/500 [01:29<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:29<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:30<02:50,  2.19it/s] 26%|██▌       | 129/500 [01:30<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:36<07:18,  1.19s/it] 27%|██▋       | 133/500 [01:36<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:36<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:36<02:46,  2.18it/s] 28%|██▊       | 139/500 [01:37<02:03,  2.93it/s] 28%|██▊       | 141/500 [01:43<07:15,  1.21s/it]Valid Loss:  0.031105851754546165
Epoch:  73  	Training Loss: 0.028152573853731155
Test Loss:  0.0252674650400877
Valid Loss:  0.03109622187912464
Epoch:  74  	Training Loss: 0.02814340591430664
Test Loss:  0.025259125977754593
Valid Loss:  0.031086646020412445
Epoch:  75  	Training Loss: 0.028134290128946304
Test Loss:  0.025250811129808426
Valid Loss:  0.031077129766345024
Epoch:  76  	Training Loss: 0.02812521532177925
Test Loss:  0.025242602452635765
Valid Loss:  0.031067661941051483
Epoch:  77  	Training Loss: 0.02811618521809578
Test Loss:  0.025234438478946686
Valid Loss:  0.03105825185775757
Epoch:  78  	Training Loss: 0.02810719981789589
Test Loss:  0.025226294994354248
Valid Loss:  0.031048890203237534
Epoch:  79  	Training Loss: 0.02809826098382473
Test Loss:  0.02521819993853569
Valid Loss:  0.031039582565426826
Epoch:  80  	Training Loss: 0.028089381754398346
Test Loss:  0.02521013468503952
Valid Loss:  0.03103032521903515
Epoch:  81  	Training Loss: 0.028080549091100693
Test Loss:  0.025202110409736633
Valid Loss:  0.031021125614643097
Epoch:  82  	Training Loss: 0.02807176485657692
Test Loss:  0.02519404888153076
Valid Loss:  0.031011685729026794
Epoch:  83  	Training Loss: 0.02806279808282852
Test Loss:  0.02518600970506668
Valid Loss:  0.03100232407450676
Epoch:  84  	Training Loss: 0.02805388532578945
Test Loss:  0.025177985429763794
Valid Loss:  0.030993010848760605
Epoch:  85  	Training Loss: 0.02804502472281456
Test Loss:  0.0251699760556221
Valid Loss:  0.030983759090304375
Epoch:  86  	Training Loss: 0.0280362069606781
Test Loss:  0.02516198717057705
Valid Loss:  0.030974557623267174
Epoch:  87  	Training Loss: 0.02802743762731552
Test Loss:  0.025154009461402893
Valid Loss:  0.0309654138982296
Epoch:  88  	Training Loss: 0.028018716722726822
Test Loss:  0.02514604479074478
Valid Loss:  0.030956322327256203
Epoch:  89  	Training Loss: 0.028010033071041107
Test Loss:  0.025138098746538162
Valid Loss:  0.030947286635637283
Epoch:  90  	Training Loss: 0.02800140343606472
Test Loss:  0.025130167603492737
Valid Loss:  0.030938301235437393
Epoch:  91  	Training Loss: 0.02799280919134617
Test Loss:  0.025122247636318207
Valid Loss:  0.030929362401366234
Epoch:  92  	Training Loss: 0.027984270825982094
Test Loss:  0.0251145139336586
Valid Loss:  0.030920298770070076
Epoch:  93  	Training Loss: 0.027975717559456825
Test Loss:  0.025107041001319885
Valid Loss:  0.030911250039935112
Epoch:  94  	Training Loss: 0.02796722762286663
Test Loss:  0.02509959600865841
Valid Loss:  0.030902262777090073
Epoch:  95  	Training Loss: 0.027958787977695465
Test Loss:  0.025092165917158127
Valid Loss:  0.03089332953095436
Epoch:  96  	Training Loss: 0.027950404211878777
Test Loss:  0.025084758177399635
Valid Loss:  0.030884457752108574
Epoch:  97  	Training Loss: 0.02794206514954567
Test Loss:  0.025077370926737785
Valid Loss:  0.030875636264681816
Epoch:  98  	Training Loss: 0.02793378010392189
Test Loss:  0.025070009753108025
Valid Loss:  0.030866870656609535
Epoch:  99  	Training Loss: 0.027925537899136543
Test Loss:  0.02506265789270401
Valid Loss:  0.030858155339956284
Epoch:  100  	Training Loss: 0.027917344123125076
Test Loss:  0.02505532279610634
Valid Loss:  0.030849486589431763
Epoch:  101  	Training Loss: 0.02790919505059719
Test Loss:  0.025048013776540756
Valid Loss:  0.03084087371826172
Epoch:  102  	Training Loss: 0.027901088818907738
Test Loss:  0.02504069358110428
Valid Loss:  0.030832121148705482
Epoch:  103  	Training Loss: 0.027892878279089928
Test Loss:  0.02503339946269989
Valid Loss:  0.03082343563437462
Epoch:  104  	Training Loss: 0.027884725481271744
Test Loss:  0.02502613142132759
Valid Loss:  0.030814802274107933
Epoch:  105  	Training Loss: 0.02787661924958229
Test Loss:  0.025018882006406784
Valid Loss:  0.030806228518486023
Epoch:  106  	Training Loss: 0.027868561446666718
Test Loss:  0.02501165121793747
Valid Loss:  0.030797701328992844
Epoch:  107  	Training Loss: 0.027860566973686218
Test Loss:  0.025004614144563675
Valid Loss:  0.03078920766711235
Epoch:  108  	Training Loss: 0.027852622792124748
Test Loss:  0.02499760314822197
Valid Loss:  0.030780769884586334
Epoch:  109  	Training Loss: 0.027844734489917755
Test Loss:  0.024990614503622055
Valid Loss:  0.03077237866818905
Epoch:  110  	Training Loss: 0.027836907655000687
Test Loss:  0.024983694776892662
Valid Loss:  0.03076406754553318
Epoch:  111  	Training Loss: 0.027829144150018692
Test Loss:  0.02497680112719536
Valid Loss:  0.030755814164876938
Epoch:  112  	Training Loss: 0.027821436524391174
Test Loss:  0.02496994659304619
Valid Loss:  0.030747409909963608
Epoch:  113  	Training Loss: 0.027813605964183807
Test Loss:  0.024963121861219406
Valid Loss:  0.030739063397049904
Epoch:  114  	Training Loss: 0.027805838733911514
Test Loss:  0.024956315755844116
Valid Loss:  0.030730772763490677
Epoch:  115  	Training Loss: 0.0277981236577034
Test Loss:  0.024949532002210617
Valid Loss:  0.03072252869606018
Epoch:  116  	Training Loss: 0.027790451422333717
Test Loss:  0.02494277060031891
Valid Loss:  0.03071434795856476
Epoch:  117  	Training Loss: 0.02778283692896366
Test Loss:  0.024936024099588394
Valid Loss:  0.030706217512488365
Epoch:  118  	Training Loss: 0.027775272727012634
Test Loss:  0.024929333478212357
Valid Loss:  0.030698155984282494
Epoch:  119  	Training Loss: 0.027767769992351532
Test Loss:  0.024922683835029602
Valid Loss:  0.030690152198076248
Epoch:  120  	Training Loss: 0.027760324999690056
Test Loss:  0.02491605468094349
Valid Loss:  0.03068220615386963
Epoch:  121  	Training Loss: 0.02775292657315731
Test Loss:  0.02490944042801857
Valid Loss:  0.030674297362565994
Epoch:  122  	Training Loss: 0.027745569124817848
Test Loss:  0.024902960285544395
Valid Loss:  0.030666373670101166
Epoch:  123  	Training Loss: 0.027738220989704132
Test Loss:  0.024896539747714996
Valid Loss:  0.03065851330757141
Epoch:  124  	Training Loss: 0.02773093432188034
Test Loss:  0.024890225380659103
Valid Loss:  0.030650753527879715
Epoch:  125  	Training Loss: 0.027723709121346474
Test Loss:  0.024883929640054703
Valid Loss:  0.0306430421769619
Epoch:  126  	Training Loss: 0.027716536074876785
Test Loss:  0.024877652525901794
Valid Loss:  0.03063538856804371
Epoch:  127  	Training Loss: 0.027709411457180977
Test Loss:  0.02487139031291008
Valid Loss:  0.0306277833878994
Epoch:  128  	Training Loss: 0.027702337130904198
Test Loss:  0.024865150451660156
Valid Loss:  0.030620232224464417
Epoch:  129  	Training Loss: 0.027695313096046448
Test Loss:  0.024858921766281128
Valid Loss:  0.030612733215093613
Epoch:  130  	Training Loss: 0.02768833562731743
Test Loss:  0.02485271356999874
Valid Loss:  0.030605275183916092
Epoch:  131  	Training Loss: 0.02768140286207199
Test Loss:  0.024846520274877548
Valid Loss:  0.030597861856222153
Epoch:  132  	Training Loss: 0.027674516662955284
Test Loss:  0.024840431287884712
Valid Loss:  0.030590545386075974
Epoch:  133  	Training Loss: 0.027667731046676636
Test Loss:  0.02483435906469822
Valid Loss:  0.030583273619413376
Epoch:  134  	Training Loss: 0.02766098454594612
Test Loss:  0.024828296154737473
Valid Loss:  0.030576050281524658
Epoch:  135  	Training Loss: 0.02765427902340889
Test Loss:  0.02482224814593792
Valid Loss:  0.030568862333893776
Epoch:  136  	Training Loss: 0.02764761447906494
Test Loss:  0.02481621317565441
Valid Loss:  0.030561722815036774
Epoch:  137  	Training Loss: 0.027640989050269127
Test Loss:  0.024810194969177246
Valid Loss:  0.030554616823792458
Epoch:  138  	Training Loss: 0.027634408324956894
Test Loss:  0.024804256856441498
Valid Loss:  0.03054758906364441
Epoch:  139  	Training Loss: 0.02762787416577339
Test Loss:  0.024798324331641197
Valid Loss:  0.030540600419044495
Epoch:  140  	Training Loss: 0.027621375396847725
Test Loss:  0.024792402982711792
Valid Loss:  0.030533649027347565
Epoch:  141  	Training Loss: 0.027614910155534744
Test Loss:  0.024786490947008133
Valid Loss:  0.030526738613843918
Epoch:  142  	Training Loss: 0.0276084803044796
Test Loss:  0.024780655279755592
Valid Loss:  0.030519817024469376
Epoch:  143  	Training Loss: 0.027602065354585648
Test Loss:   29%|██▊       | 143/500 [01:43<05:10,  1.15it/s] 29%|██▉       | 145/500 [01:43<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:43<02:42,  2.18it/s] 30%|██▉       | 149/500 [01:44<01:59,  2.93it/s] 30%|███       | 151/500 [01:50<06:58,  1.20s/it] 31%|███       | 153/500 [01:50<04:58,  1.16it/s] 31%|███       | 155/500 [01:50<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:50<02:35,  2.20it/s] 32%|███▏      | 159/500 [01:51<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:57<06:40,  1.18s/it] 33%|███▎      | 163/500 [01:57<04:45,  1.18it/s] 33%|███▎      | 165/500 [01:57<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:57<02:30,  2.22it/s] 34%|███▍      | 169/500 [01:57<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:04<06:39,  1.21s/it] 35%|███▍      | 173/500 [02:04<04:45,  1.15it/s] 35%|███▌      | 175/500 [02:04<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:04<02:28,  2.17it/s] 36%|███▌      | 179/500 [02:04<01:49,  2.93it/s] 36%|███▌      | 181/500 [02:11<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:11<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:16,  1.60it/s] 37%|███▋      | 187/500 [02:11<02:24,  2.16it/s] 38%|███▊      | 189/500 [02:11<01:48,  2.86it/s] 38%|███▊      | 191/500 [02:18<06:21,  1.23s/it] 39%|███▊      | 193/500 [02:18<04:32,  1.13it/s] 39%|███▉      | 195/500 [02:18<03:15,  1.56it/s] 39%|███▉      | 197/500 [02:18<02:21,  2.14it/s] 40%|███▉      | 199/500 [02:19<01:44,  2.89it/s] 40%|████      | 201/500 [02:25<06:08,  1.23s/it] 41%|████      | 203/500 [02:25<04:22,  1.13it/s] 41%|████      | 205/500 [02:25<03:08,  1.57it/s] 41%|████▏     | 207/500 [02:26<02:16,  2.14it/s] 42%|████▏     | 209/500 [02:26<01:40,  2.89it/s] 42%|████▏     | 211/500 [02:32<05:45,  1.20s/it] 43%|████▎     | 213/500 [02:32<04:06,  1.16it/s]0.024774834513664246
Valid Loss:  0.030512943863868713
Epoch:  144  	Training Loss: 0.027595696970820427
Test Loss:  0.024769023060798645
Valid Loss:  0.030506102368235588
Epoch:  145  	Training Loss: 0.027589362114667892
Test Loss:  0.02476322464644909
Valid Loss:  0.030499311164021492
Epoch:  146  	Training Loss: 0.027583064511418343
Test Loss:  0.02475743554532528
Valid Loss:  0.030492542311549187
Epoch:  147  	Training Loss: 0.027576804161071777
Test Loss:  0.024751652032136917
Valid Loss:  0.030485814437270164
Epoch:  148  	Training Loss: 0.0275705736130476
Test Loss:  0.024745885282754898
Valid Loss:  0.030479127541184425
Epoch:  149  	Training Loss: 0.027564382180571556
Test Loss:  0.024740152060985565
Valid Loss:  0.030472466722130775
Epoch:  150  	Training Loss: 0.02755821868777275
Test Loss:  0.024734439328312874
Valid Loss:  0.03046584129333496
Epoch:  151  	Training Loss: 0.02755209431052208
Test Loss:  0.02472873218357563
Valid Loss:  0.030459245666861534
Epoch:  152  	Training Loss: 0.027545996010303497
Test Loss:  0.02472313679754734
Valid Loss:  0.030452661216259003
Epoch:  153  	Training Loss: 0.027539927512407303
Test Loss:  0.024717604741454124
Valid Loss:  0.030446114018559456
Epoch:  154  	Training Loss: 0.027533896267414093
Test Loss:  0.02471209317445755
Valid Loss:  0.030439594760537148
Epoch:  155  	Training Loss: 0.027527891099452972
Test Loss:  0.02470659650862217
Valid Loss:  0.030433112755417824
Epoch:  156  	Training Loss: 0.027521923184394836
Test Loss:  0.02470111846923828
Valid Loss:  0.03042665868997574
Epoch:  157  	Training Loss: 0.02751598134636879
Test Loss:  0.02469564974308014
Valid Loss:  0.03042023442685604
Epoch:  158  	Training Loss: 0.02751006744801998
Test Loss:  0.024690214544534683
Valid Loss:  0.03041383996605873
Epoch:  159  	Training Loss: 0.02750418521463871
Test Loss:  0.0246848426759243
Valid Loss:  0.030407514423131943
Epoch:  160  	Training Loss: 0.02749835141003132
Test Loss:  0.0246795192360878
Valid Loss:  0.03040127083659172
Epoch:  161  	Training Loss: 0.027492549270391464
Test Loss:  0.024674303829669952
Valid Loss:  0.03039506822824478
Epoch:  162  	Training Loss: 0.027486780658364296
Test Loss:  0.024669233709573746
Valid Loss:  0.030388984829187393
Epoch:  163  	Training Loss: 0.02748114801943302
Test Loss:  0.02466418780386448
Valid Loss:  0.030382933095097542
Epoch:  164  	Training Loss: 0.027475545182824135
Test Loss:  0.02465914562344551
Valid Loss:  0.030376911163330078
Epoch:  165  	Training Loss: 0.027469968423247337
Test Loss:  0.02465413138270378
Valid Loss:  0.030370907858014107
Epoch:  166  	Training Loss: 0.02746441587805748
Test Loss:  0.024649133905768394
Valid Loss:  0.03036494553089142
Epoch:  167  	Training Loss: 0.02745889499783516
Test Loss:  0.024644147604703903
Valid Loss:  0.030358998104929924
Epoch:  168  	Training Loss: 0.027453400194644928
Test Loss:  0.024639185518026352
Valid Loss:  0.030353084206581116
Epoch:  169  	Training Loss: 0.027447933331131935
Test Loss:  0.024634230881929398
Valid Loss:  0.03034718707203865
Epoch:  170  	Training Loss: 0.027442488819360733
Test Loss:  0.024629291146993637
Valid Loss:  0.030341312289237976
Epoch:  171  	Training Loss: 0.02743706852197647
Test Loss:  0.024624381214380264
Valid Loss:  0.03033548593521118
Epoch:  172  	Training Loss: 0.027431678026914597
Test Loss:  0.02461947128176689
Valid Loss:  0.030329642817378044
Epoch:  173  	Training Loss: 0.027426252141594887
Test Loss:  0.02461457997560501
Valid Loss:  0.030323827639222145
Epoch:  174  	Training Loss: 0.027420859783887863
Test Loss:  0.024609709158539772
Valid Loss:  0.030318036675453186
Epoch:  175  	Training Loss: 0.027415497228503227
Test Loss:  0.02460489794611931
Valid Loss:  0.030312275514006615
Epoch:  176  	Training Loss: 0.027410190552473068
Test Loss:  0.024600112810730934
Valid Loss:  0.030306536704301834
Epoch:  177  	Training Loss: 0.027404911816120148
Test Loss:  0.024595336988568306
Valid Loss:  0.030300820246338844
Epoch:  178  	Training Loss: 0.027399662882089615
Test Loss:  0.02459058351814747
Valid Loss:  0.03029513545334339
Epoch:  179  	Training Loss: 0.02739444002509117
Test Loss:  0.024585843086242676
Valid Loss:  0.03028947114944458
Epoch:  180  	Training Loss: 0.027389243245124817
Test Loss:  0.02458111196756363
Valid Loss:  0.03028382733464241
Epoch:  181  	Training Loss: 0.02738407999277115
Test Loss:  0.0245764572173357
Valid Loss:  0.030278218910098076
Epoch:  182  	Training Loss: 0.027378957718610764
Test Loss:  0.024571869522333145
Valid Loss:  0.03027268312871456
Epoch:  183  	Training Loss: 0.027373913675546646
Test Loss:  0.02456730045378208
Valid Loss:  0.030267171561717987
Epoch:  184  	Training Loss: 0.027368895709514618
Test Loss:  0.024562781676650047
Valid Loss:  0.030261743813753128
Epoch:  185  	Training Loss: 0.027363914996385574
Test Loss:  0.024558283388614655
Valid Loss:  0.030256351456046104
Epoch:  186  	Training Loss: 0.02735895663499832
Test Loss:  0.024553800001740456
Valid Loss:  0.03025098517537117
Epoch:  187  	Training Loss: 0.027354035526514053
Test Loss:  0.02454933524131775
Valid Loss:  0.03024563565850258
Epoch:  188  	Training Loss: 0.027349140495061874
Test Loss:  0.024544885382056236
Valid Loss:  0.03024032711982727
Epoch:  189  	Training Loss: 0.02734427899122238
Test Loss:  0.024540450423955917
Valid Loss:  0.03023502789437771
Epoch:  190  	Training Loss: 0.02733943797647953
Test Loss:  0.024536041542887688
Valid Loss:  0.030229758471250534
Epoch:  191  	Training Loss: 0.027334626764059067
Test Loss:  0.024531640112400055
Valid Loss:  0.030224516987800598
Epoch:  192  	Training Loss: 0.02732984349131584
Test Loss:  0.02452729269862175
Valid Loss:  0.03021932952105999
Epoch:  193  	Training Loss: 0.027325116097927094
Test Loss:  0.02452296018600464
Valid Loss:  0.030214156955480576
Epoch:  194  	Training Loss: 0.027320414781570435
Test Loss:  0.024518638849258423
Valid Loss:  0.030209006741642952
Epoch:  195  	Training Loss: 0.02731573022902012
Test Loss:  0.024514324963092804
Valid Loss:  0.030203871428966522
Epoch:  196  	Training Loss: 0.027311068028211594
Test Loss:  0.02451002225279808
Valid Loss:  0.030198752880096436
Epoch:  197  	Training Loss: 0.02730643004179001
Test Loss:  0.02450573444366455
Valid Loss:  0.03019365482032299
Epoch:  198  	Training Loss: 0.027301806956529617
Test Loss:  0.02450144849717617
Valid Loss:  0.030188575387001038
Epoch:  199  	Training Loss: 0.027297204360365868
Test Loss:  0.024497173726558685
Valid Loss:  0.03018350899219513
Epoch:  200  	Training Loss: 0.02729262225329876
Test Loss:  0.024492910131812096
Valid Loss:  0.030178453773260117
Epoch:  201  	Training Loss: 0.027288056910037994
Test Loss:  0.024488653987646103
Valid Loss:  0.030173415318131447
Epoch:  202  	Training Loss: 0.027283508330583572
Test Loss:  0.024484451860189438
Valid Loss:  0.030168425291776657
Epoch:  203  	Training Loss: 0.02727900631725788
Test Loss:  0.024480247870087624
Valid Loss:  0.030163444578647614
Epoch:  204  	Training Loss: 0.027274517342448235
Test Loss:  0.0244760625064373
Valid Loss:  0.03015848435461521
Epoch:  205  	Training Loss: 0.02727004699409008
Test Loss:  0.024471886456012726
Valid Loss:  0.030153539031744003
Epoch:  206  	Training Loss: 0.027265604585409164
Test Loss:  0.0244677122682333
Valid Loss:  0.03014860488474369
Epoch:  207  	Training Loss: 0.027261171489953995
Test Loss:  0.02446354739367962
Valid Loss:  0.030143683776259422
Epoch:  208  	Training Loss: 0.02725675329566002
Test Loss:  0.024459391832351685
Valid Loss:  0.0301387757062912
Epoch:  209  	Training Loss: 0.027252351865172386
Test Loss:  0.024455241858959198
Valid Loss:  0.030133886262774467
Epoch:  210  	Training Loss: 0.027247967198491096
Test Loss:  0.02445109933614731
Valid Loss:  0.030129002407193184
Epoch:  211  	Training Loss: 0.027243593707680702
Test Loss:  0.024446964263916016
Valid Loss:  0.030124135315418243
Epoch:  212  	Training Loss: 0.02723923698067665
Test Loss:  0.024442989379167557
Valid Loss:  0.030119426548480988
Epoch:  213  	Training Loss: 0.027235031127929688
Test Loss:  0.024439021944999695
Valid Loss:  0.030114728957414627
 43%|████▎     | 215/500 [02:32<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:32<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:33<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:39<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:39<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:39<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:39<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:40<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:46<05:20,  1.19s/it] 47%|████▋     | 233/500 [02:46<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:46<02:46,  1.59it/s] 47%|████▋     | 237/500 [02:46<02:02,  2.15it/s] 48%|████▊     | 239/500 [02:47<01:31,  2.86it/s] 48%|████▊     | 241/500 [02:53<05:14,  1.22s/it] 49%|████▊     | 243/500 [02:53<03:43,  1.15it/s] 49%|████▉     | 245/500 [02:53<02:40,  1.59it/s] 49%|████▉     | 247/500 [02:53<01:56,  2.18it/s] 50%|████▉     | 249/500 [02:54<01:25,  2.94it/s] 50%|█████     | 251/500 [03:00<04:55,  1.19s/it] 51%|█████     | 253/500 [03:00<03:30,  1.17it/s] 51%|█████     | 255/500 [03:00<02:31,  1.62it/s] 51%|█████▏    | 257/500 [03:00<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:00<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:07<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:07<03:21,  1.17it/s] 53%|█████▎    | 265/500 [03:07<02:24,  1.62it/s] 53%|█████▎    | 267/500 [03:07<01:45,  2.22it/s] 54%|█████▍    | 269/500 [03:07<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:14<04:34,  1.20s/it] 55%|█████▍    | 273/500 [03:14<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:14<02:20,  1.61it/s] 55%|█████▌    | 277/500 [03:14<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:14<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:21<04:26,  1.22s/it] 57%|█████▋    | 283/500 [03:21<03:09,  1.14it/s]Epoch:  214  	Training Loss: 0.027230840176343918
Test Loss:  0.02443506196141243
Valid Loss:  0.030110036954283714
Epoch:  215  	Training Loss: 0.027226660400629044
Test Loss:  0.024431105703115463
Valid Loss:  0.030105359852313995
Epoch:  216  	Training Loss: 0.027222497388720512
Test Loss:  0.024427153170108795
Valid Loss:  0.03010069951415062
Epoch:  217  	Training Loss: 0.027218345552682877
Test Loss:  0.02442321367561817
Valid Loss:  0.03009604476392269
Epoch:  218  	Training Loss: 0.027214206755161285
Test Loss:  0.024419274181127548
Valid Loss:  0.03009140118956566
Epoch:  219  	Training Loss: 0.02721007913351059
Test Loss:  0.024415340274572372
Valid Loss:  0.030086763203144073
Epoch:  220  	Training Loss: 0.027205966413021088
Test Loss:  0.024411413818597794
Valid Loss:  0.030082140117883682
Epoch:  221  	Training Loss: 0.027201859280467033
Test Loss:  0.024407483637332916
Valid Loss:  0.030077524483203888
Epoch:  222  	Training Loss: 0.027197767049074173
Test Loss:  0.024403776973485947
Valid Loss:  0.030073121190071106
Epoch:  223  	Training Loss: 0.02719387784600258
Test Loss:  0.024400081485509872
Valid Loss:  0.030068738386034966
Epoch:  224  	Training Loss: 0.02719000354409218
Test Loss:  0.024396423250436783
Valid Loss:  0.0300644151866436
Epoch:  225  	Training Loss: 0.027186159044504166
Test Loss:  0.02439277619123459
Valid Loss:  0.030060116201639175
Epoch:  226  	Training Loss: 0.027182329446077347
Test Loss:  0.02438913658261299
Valid Loss:  0.030055822804570198
Epoch:  227  	Training Loss: 0.027178512886166573
Test Loss:  0.02438550814986229
Valid Loss:  0.030051544308662415
Epoch:  228  	Training Loss: 0.027174707502126694
Test Loss:  0.024381885305047035
Valid Loss:  0.030047280713915825
Epoch:  229  	Training Loss: 0.02717091515660286
Test Loss:  0.024378269910812378
Valid Loss:  0.030043022707104683
Epoch:  230  	Training Loss: 0.02716713398694992
Test Loss:  0.024374661967158318
Valid Loss:  0.030038785189390182
Epoch:  231  	Training Loss: 0.027163371443748474
Test Loss:  0.024371059611439705
Valid Loss:  0.030034542083740234
Epoch:  232  	Training Loss: 0.027159612625837326
Test Loss:  0.02436765655875206
Valid Loss:  0.030030474066734314
Epoch:  233  	Training Loss: 0.027156013995409012
Test Loss:  0.02436426281929016
Valid Loss:  0.03002641350030899
Epoch:  234  	Training Loss: 0.027152422815561295
Test Loss:  0.024360869079828262
Valid Loss:  0.030022356659173965
Epoch:  235  	Training Loss: 0.02714885212481022
Test Loss:  0.02435748651623726
Valid Loss:  0.030018314719200134
Epoch:  236  	Training Loss: 0.027145283296704292
Test Loss:  0.024354100227355957
Valid Loss:  0.0300142839550972
Epoch:  237  	Training Loss: 0.02714172564446926
Test Loss:  0.024350721389055252
Valid Loss:  0.030010249465703964
Epoch:  238  	Training Loss: 0.027138173580169678
Test Loss:  0.024347353726625443
Valid Loss:  0.030006226152181625
Epoch:  239  	Training Loss: 0.02713463455438614
Test Loss:  0.02434398978948593
Valid Loss:  0.030002210289239883
Epoch:  240  	Training Loss: 0.027131102979183197
Test Loss:  0.024340618401765823
Valid Loss:  0.029998192563652992
Epoch:  241  	Training Loss: 0.027127575129270554
Test Loss:  0.02433726005256176
Valid Loss:  0.029994191601872444
Epoch:  242  	Training Loss: 0.027124058455228806
Test Loss:  0.024334043264389038
Valid Loss:  0.029990321025252342
Epoch:  243  	Training Loss: 0.027120674028992653
Test Loss:  0.024330828338861465
Valid Loss:  0.029986463487148285
Epoch:  244  	Training Loss: 0.027117295190691948
Test Loss:  0.024327624589204788
Valid Loss:  0.029982611536979675
Epoch:  245  	Training Loss: 0.02711392380297184
Test Loss:  0.02432441897690296
Valid Loss:  0.029978767037391663
Epoch:  246  	Training Loss: 0.027110561728477478
Test Loss:  0.024321213364601135
Valid Loss:  0.029974913224577904
Epoch:  247  	Training Loss: 0.027107207104563713
Test Loss:  0.024318039417266846
Valid Loss:  0.02997114136815071
Epoch:  248  	Training Loss: 0.027103876695036888
Test Loss:  0.024314869195222855
Valid Loss:  0.029967375099658966
Epoch:  249  	Training Loss: 0.02710055187344551
Test Loss:  0.024311695247888565
Valid Loss:  0.029963606968522072
Epoch:  250  	Training Loss: 0.027097228914499283
Test Loss:  0.02430853806436062
Valid Loss:  0.029959846287965775
Epoch:  251  	Training Loss: 0.02709391713142395
Test Loss:  0.024305377155542374
Valid Loss:  0.029956091195344925
Epoch:  252  	Training Loss: 0.027090609073638916
Test Loss:  0.02430238574743271
Valid Loss:  0.029952511191368103
Epoch:  253  	Training Loss: 0.027087464928627014
Test Loss:  0.024299416691064835
Valid Loss:  0.02994893118739128
Epoch:  254  	Training Loss: 0.027084320783615112
Test Loss:  0.024296460673213005
Valid Loss:  0.029945366084575653
Epoch:  255  	Training Loss: 0.027081184089183807
Test Loss:  0.024293512105941772
Valid Loss:  0.029941821470856667
Epoch:  256  	Training Loss: 0.02707805670797825
Test Loss:  0.024290570989251137
Valid Loss:  0.029938288033008575
Epoch:  257  	Training Loss: 0.02707492932677269
Test Loss:  0.024287626147270203
Valid Loss:  0.02993476577103138
Epoch:  258  	Training Loss: 0.027071820572018623
Test Loss:  0.024284694343805313
Valid Loss:  0.029931247234344482
Epoch:  259  	Training Loss: 0.027068709954619408
Test Loss:  0.024281764402985573
Valid Loss:  0.02992773987352848
Epoch:  260  	Training Loss: 0.02706560678780079
Test Loss:  0.024278836324810982
Valid Loss:  0.029924262315034866
Epoch:  261  	Training Loss: 0.027062509208917618
Test Loss:  0.02427590638399124
Valid Loss:  0.029920794069767
Epoch:  262  	Training Loss: 0.027059417217969894
Test Loss:  0.024273131042718887
Valid Loss:  0.02991747297346592
Epoch:  263  	Training Loss: 0.027056461200118065
Test Loss:  0.024270348250865936
Valid Loss:  0.029914148151874542
Epoch:  264  	Training Loss: 0.027053505182266235
Test Loss:  0.02426758036017418
Valid Loss:  0.02991083636879921
Epoch:  265  	Training Loss: 0.027050558477640152
Test Loss:  0.024264808744192123
Valid Loss:  0.02990752086043358
Epoch:  266  	Training Loss: 0.027047613635659218
Test Loss:  0.024262048304080963
Valid Loss:  0.02990422211587429
Epoch:  267  	Training Loss: 0.02704467996954918
Test Loss:  0.02425932139158249
Valid Loss:  0.02990092895925045
Epoch:  268  	Training Loss: 0.027041753754019737
Test Loss:  0.024256598204374313
Valid Loss:  0.02989763393998146
Epoch:  269  	Training Loss: 0.027038829401135445
Test Loss:  0.024253886193037033
Valid Loss:  0.029894376173615456
Epoch:  270  	Training Loss: 0.027035923674702644
Test Loss:  0.024251174181699753
Valid Loss:  0.029891133308410645
Epoch:  271  	Training Loss: 0.02703303098678589
Test Loss:  0.024248464033007622
Valid Loss:  0.029887892305850983
Epoch:  272  	Training Loss: 0.02703014574944973
Test Loss:  0.02424582839012146
Valid Loss:  0.029884710907936096
Epoch:  273  	Training Loss: 0.02702731266617775
Test Loss:  0.0242431852966547
Valid Loss:  0.029881538823246956
Epoch:  274  	Training Loss: 0.027024488896131516
Test Loss:  0.02424054965376854
Valid Loss:  0.029878370463848114
Epoch:  275  	Training Loss: 0.02702166885137558
Test Loss:  0.024237921461462975
Valid Loss:  0.02987521141767502
Epoch:  276  	Training Loss: 0.02701885625720024
Test Loss:  0.024235282093286514
Valid Loss:  0.029872067272663116
Epoch:  277  	Training Loss: 0.0270160511136055
Test Loss:  0.02423265390098095
Valid Loss:  0.029868941754102707
Epoch:  278  	Training Loss: 0.027013255283236504
Test Loss:  0.024230023846030235
Valid Loss:  0.029865819960832596
Epoch:  279  	Training Loss: 0.027010465040802956
Test Loss:  0.024227403104305267
Valid Loss:  0.02986270561814308
Epoch:  280  	Training Loss: 0.027007680386304855
Test Loss:  0.024224791675806046
Valid Loss:  0.02985960617661476
Epoch:  281  	Training Loss: 0.0270049050450325
Test Loss:  0.024222170934081078
Valid Loss:  0.029856503009796143
Epoch:  282  	Training Loss: 0.027002131566405296
Test Loss:  0.024219665676355362
Valid Loss:  0.029853511601686478
Epoch:  283  	Training Loss: 0.026999466121196747
Test Loss:  0.024217158555984497
Valid Loss:  0.029850546270608902
Epoch:  284  	Training Loss: 0.026996804401278496
Test Loss:   57%|█████▋    | 285/500 [03:21<02:15,  1.58it/s] 57%|█████▋    | 287/500 [03:21<01:38,  2.16it/s] 58%|█████▊    | 289/500 [03:21<01:13,  2.86it/s] 58%|█████▊    | 291/500 [03:28<04:16,  1.23s/it] 59%|█████▊    | 293/500 [03:28<03:03,  1.13it/s] 59%|█████▉    | 295/500 [03:28<02:12,  1.55it/s] 59%|█████▉    | 297/500 [03:28<01:36,  2.10it/s] 60%|█████▉    | 299/500 [03:29<01:11,  2.82it/s] 60%|██████    | 301/500 [03:35<04:06,  1.24s/it] 61%|██████    | 303/500 [03:35<02:55,  1.12it/s] 61%|██████    | 305/500 [03:35<02:05,  1.56it/s] 61%|██████▏   | 307/500 [03:36<01:30,  2.13it/s] 62%|██████▏   | 309/500 [03:36<01:06,  2.87it/s] 62%|██████▏   | 311/500 [03:42<03:54,  1.24s/it] 63%|██████▎   | 313/500 [03:43<02:46,  1.12it/s] 63%|██████▎   | 315/500 [03:43<01:58,  1.56it/s] 63%|██████▎   | 317/500 [03:43<01:26,  2.11it/s] 64%|██████▍   | 319/500 [03:43<01:03,  2.85it/s] 64%|██████▍   | 321/500 [03:50<03:41,  1.23s/it] 65%|██████▍   | 323/500 [03:50<02:37,  1.12it/s] 65%|██████▌   | 325/500 [03:50<01:53,  1.54it/s] 65%|██████▌   | 327/500 [03:50<01:23,  2.08it/s] 66%|██████▌   | 329/500 [03:50<01:01,  2.77it/s] 66%|██████▌   | 331/500 [03:57<03:31,  1.25s/it] 67%|██████▋   | 333/500 [03:57<02:29,  1.11it/s] 67%|██████▋   | 335/500 [03:57<01:47,  1.54it/s] 67%|██████▋   | 337/500 [03:57<01:17,  2.11it/s] 68%|██████▊   | 339/500 [03:57<00:56,  2.83it/s] 68%|██████▊   | 341/500 [04:04<03:16,  1.24s/it] 69%|██████▊   | 343/500 [04:04<02:19,  1.12it/s] 69%|██████▉   | 345/500 [04:04<01:39,  1.55it/s] 69%|██████▉   | 347/500 [04:04<01:12,  2.12it/s] 70%|██████▉   | 349/500 [04:05<00:52,  2.86it/s] 70%|███████   | 351/500 [04:11<03:03,  1.23s/it] 71%|███████   | 353/500 [04:11<02:09,  1.13it/s]0.024214651435613632
Valid Loss:  0.029847603291273117
Epoch:  285  	Training Loss: 0.02699415013194084
Test Loss:  0.024212149903178215
Valid Loss:  0.029844654724001884
Epoch:  286  	Training Loss: 0.026991501450538635
Test Loss:  0.024209655821323395
Valid Loss:  0.029841719195246696
Epoch:  287  	Training Loss: 0.026988860219717026
Test Loss:  0.024207156151533127
Valid Loss:  0.029838787391781807
Epoch:  288  	Training Loss: 0.026986222714185715
Test Loss:  0.024204671382904053
Valid Loss:  0.029835859313607216
Epoch:  289  	Training Loss: 0.026983592659235
Test Loss:  0.02420218102633953
Valid Loss:  0.029832933098077774
Epoch:  290  	Training Loss: 0.026980966329574585
Test Loss:  0.024199701845645905
Valid Loss:  0.029830019921064377
Epoch:  291  	Training Loss: 0.026978345587849617
Test Loss:  0.024197224527597427
Valid Loss:  0.02982710301876068
Epoch:  292  	Training Loss: 0.026975730434060097
Test Loss:  0.02419479563832283
Valid Loss:  0.029824240133166313
Epoch:  293  	Training Loss: 0.026973169296979904
Test Loss:  0.02419237419962883
Valid Loss:  0.02982138842344284
Epoch:  294  	Training Loss: 0.02697061374783516
Test Loss:  0.024189960211515427
Valid Loss:  0.029818540439009666
Epoch:  295  	Training Loss: 0.026968061923980713
Test Loss:  0.024187540635466576
Valid Loss:  0.029815692454576492
Epoch:  296  	Training Loss: 0.026965511962771416
Test Loss:  0.02418512850999832
Valid Loss:  0.029812853783369064
Epoch:  297  	Training Loss: 0.026962971314787865
Test Loss:  0.024182721972465515
Valid Loss:  0.029810016974806786
Epoch:  298  	Training Loss: 0.026960434392094612
Test Loss:  0.024180321022868156
Valid Loss:  0.029807187616825104
Epoch:  299  	Training Loss: 0.026957903057336807
Test Loss:  0.02417791076004505
Valid Loss:  0.029804347082972527
Epoch:  300  	Training Loss: 0.02695537358522415
Test Loss:  0.02417551353573799
Valid Loss:  0.02980152703821659
Epoch:  301  	Training Loss: 0.026952853426337242
Test Loss:  0.024173110723495483
Valid Loss:  0.029798705130815506
Epoch:  302  	Training Loss: 0.026950333267450333
Test Loss:  0.024170730262994766
Valid Loss:  0.029795892536640167
Epoch:  303  	Training Loss: 0.02694782055914402
Test Loss:  0.02416834607720375
Valid Loss:  0.02979307807981968
Epoch:  304  	Training Loss: 0.026945313438773155
Test Loss:  0.024165965616703033
Valid Loss:  0.02979026734828949
Epoch:  305  	Training Loss: 0.026942811906337738
Test Loss:  0.024163588881492615
Valid Loss:  0.02978745847940445
Epoch:  306  	Training Loss: 0.02694031223654747
Test Loss:  0.024161210283637047
Valid Loss:  0.029784657061100006
Epoch:  307  	Training Loss: 0.0269378162920475
Test Loss:  0.024158835411071777
Valid Loss:  0.02978186309337616
Epoch:  308  	Training Loss: 0.02693532407283783
Test Loss:  0.024156467989087105
Valid Loss:  0.029779061675071716
Epoch:  309  	Training Loss: 0.026932839304208755
Test Loss:  0.024154100567102432
Valid Loss:  0.029776273295283318
Epoch:  310  	Training Loss: 0.02693035453557968
Test Loss:  0.02415173500776291
Valid Loss:  0.02977347932755947
Epoch:  311  	Training Loss: 0.026927873492240906
Test Loss:  0.024149369448423386
Valid Loss:  0.02977069653570652
Epoch:  312  	Training Loss: 0.026925401762127876
Test Loss:  0.02414705976843834
Valid Loss:  0.02976793795824051
Epoch:  313  	Training Loss: 0.026922956109046936
Test Loss:  0.02414475753903389
Valid Loss:  0.029765181243419647
Epoch:  314  	Training Loss: 0.02692052163183689
Test Loss:  0.024142449721693993
Valid Loss:  0.02976243570446968
Epoch:  315  	Training Loss: 0.026918087154626846
Test Loss:  0.02414015494287014
Valid Loss:  0.02975970320403576
Epoch:  316  	Training Loss: 0.02691565826535225
Test Loss:  0.02413785457611084
Valid Loss:  0.029757004231214523
Epoch:  317  	Training Loss: 0.026913238689303398
Test Loss:  0.024135559797286987
Valid Loss:  0.029754307121038437
Epoch:  318  	Training Loss: 0.026910820975899696
Test Loss:  0.024133265018463135
Valid Loss:  0.02975161373615265
Epoch:  319  	Training Loss: 0.026908408850431442
Test Loss:  0.02413097396492958
Valid Loss:  0.02974892593920231
Epoch:  320  	Training Loss: 0.026906002312898636
Test Loss:  0.024128688499331474
Valid Loss:  0.029746245592832565
Epoch:  321  	Training Loss: 0.026903601363301277
Test Loss:  0.024126403033733368
Valid Loss:  0.029743563383817673
Epoch:  322  	Training Loss: 0.026901204138994217
Test Loss:  0.024124182760715485
Valid Loss:  0.029740946367383003
Epoch:  323  	Training Loss: 0.026898864656686783
Test Loss:  0.0241219662129879
Valid Loss:  0.02973833866417408
Epoch:  324  	Training Loss: 0.026896536350250244
Test Loss:  0.024119745939970016
Valid Loss:  0.029735736548900604
Epoch:  325  	Training Loss: 0.026894202455878258
Test Loss:  0.02411753311753273
Valid Loss:  0.029733125120401382
Epoch:  326  	Training Loss: 0.02689187601208687
Test Loss:  0.024115320295095444
Valid Loss:  0.029730524867773056
Epoch:  327  	Training Loss: 0.02688954770565033
Test Loss:  0.024113107472658157
Valid Loss:  0.02972792275249958
Epoch:  328  	Training Loss: 0.026887230575084686
Test Loss:  0.02411089837551117
Valid Loss:  0.0297253280878067
Epoch:  329  	Training Loss: 0.026884915307164192
Test Loss:  0.02410868927836418
Valid Loss:  0.029722733423113823
Epoch:  330  	Training Loss: 0.026882601901888847
Test Loss:  0.024106483906507492
Valid Loss:  0.02972014620900154
Epoch:  331  	Training Loss: 0.02688029035925865
Test Loss:  0.02410428412258625
Valid Loss:  0.02971755899488926
Epoch:  332  	Training Loss: 0.026877988129854202
Test Loss:  0.024102110415697098
Valid Loss:  0.029715003445744514
Epoch:  333  	Training Loss: 0.026875706389546394
Test Loss:  0.02409994602203369
Valid Loss:  0.029712460935115814
Epoch:  334  	Training Loss: 0.026873435825109482
Test Loss:  0.024097777903079987
Valid Loss:  0.02970992587506771
Epoch:  335  	Training Loss: 0.02687116339802742
Test Loss:  0.02409561164677143
Valid Loss:  0.029707394540309906
Epoch:  336  	Training Loss: 0.026868894696235657
Test Loss:  0.024093445390462875
Valid Loss:  0.029704870656132698
Epoch:  337  	Training Loss: 0.02686663344502449
Test Loss:  0.024091292172670364
Valid Loss:  0.029702359810471535
Epoch:  338  	Training Loss: 0.02686438150703907
Test Loss:  0.024089137092232704
Valid Loss:  0.02969985641539097
Epoch:  339  	Training Loss: 0.02686212956905365
Test Loss:  0.024086985737085342
Valid Loss:  0.029697351157665253
Epoch:  340  	Training Loss: 0.026859883219003677
Test Loss:  0.02408483624458313
Valid Loss:  0.029694851487874985
Epoch:  341  	Training Loss: 0.026857640594244003
Test Loss:  0.024082686752080917
Valid Loss:  0.029692353680729866
Epoch:  342  	Training Loss: 0.02685539983212948
Test Loss:  0.024080537259578705
Valid Loss:  0.02968985214829445
Epoch:  343  	Training Loss: 0.026853155344724655
Test Loss:  0.024078384041786194
Valid Loss:  0.02968735434114933
Epoch:  344  	Training Loss: 0.02685091644525528
Test Loss:  0.02407623641192913
Valid Loss:  0.02968486025929451
Epoch:  345  	Training Loss: 0.026848675683140755
Test Loss:  0.024074092507362366
Valid Loss:  0.02968236431479454
Epoch:  346  	Training Loss: 0.026846444234251976
Test Loss:  0.024071941152215004
Valid Loss:  0.029679875820875168
Epoch:  347  	Training Loss: 0.0268442090600729
Test Loss:  0.024069804698228836
Valid Loss:  0.029677394777536392
Epoch:  348  	Training Loss: 0.02684197947382927
Test Loss:  0.02406766265630722
Valid Loss:  0.02967490628361702
Epoch:  349  	Training Loss: 0.026839755475521088
Test Loss:  0.024065518751740456
Valid Loss:  0.029672425240278244
Epoch:  350  	Training Loss: 0.026837525889277458
Test Loss:  0.02406337670981884
Valid Loss:  0.02966994233429432
Epoch:  351  	Training Loss: 0.026835303753614426
Test Loss:  0.024061236530542374
Valid Loss:  0.029667465016245842
Epoch:  352  	Training Loss: 0.026833083480596542
Test Loss:  0.024059079587459564
Valid Loss:  0.029664963483810425
Epoch:  353  	Training Loss: 0.026830844581127167
Test Loss:  0.02405693382024765
Valid Loss:  0.029662471264600754
Epoch:  354  	Training Loss: 0.02682860568165779
Test Loss:  0.024054784327745438
Valid Loss:  0.029659977182745934
 71%|███████   | 355/500 [04:11<01:32,  1.57it/s] 71%|███████▏  | 357/500 [04:12<01:06,  2.14it/s] 72%|███████▏  | 359/500 [04:12<00:48,  2.89it/s] 72%|███████▏  | 361/500 [04:18<02:50,  1.23s/it] 73%|███████▎  | 363/500 [04:18<02:00,  1.14it/s] 73%|███████▎  | 365/500 [04:19<01:25,  1.58it/s] 73%|███████▎  | 367/500 [04:19<01:01,  2.16it/s] 74%|███████▍  | 369/500 [04:19<00:45,  2.91it/s] 74%|███████▍  | 371/500 [04:26<02:40,  1.24s/it] 75%|███████▍  | 373/500 [04:26<01:53,  1.12it/s] 75%|███████▌  | 375/500 [04:26<01:20,  1.55it/s] 75%|███████▌  | 377/500 [04:26<00:57,  2.12it/s] 76%|███████▌  | 379/500 [04:26<00:42,  2.86it/s] 76%|███████▌  | 381/500 [04:33<02:25,  1.22s/it] 77%|███████▋  | 383/500 [04:33<01:42,  1.14it/s] 77%|███████▋  | 385/500 [04:33<01:12,  1.58it/s] 77%|███████▋  | 387/500 [04:33<00:52,  2.16it/s] 78%|███████▊  | 389/500 [04:33<00:38,  2.90it/s] 78%|███████▊  | 391/500 [04:40<02:10,  1.20s/it] 79%|███████▊  | 393/500 [04:40<01:32,  1.16it/s] 79%|███████▉  | 395/500 [04:40<01:05,  1.60it/s] 79%|███████▉  | 397/500 [04:40<00:47,  2.19it/s] 80%|███████▉  | 399/500 [04:40<00:34,  2.94it/s] 80%|████████  | 401/500 [04:47<02:00,  1.22s/it] 81%|████████  | 403/500 [04:47<01:24,  1.14it/s] 81%|████████  | 405/500 [04:47<00:59,  1.58it/s] 81%|████████▏ | 407/500 [04:47<00:42,  2.17it/s] 82%|████████▏ | 409/500 [04:47<00:31,  2.92it/s] 82%|████████▏ | 411/500 [04:54<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:54<01:16,  1.14it/s] 83%|████████▎ | 415/500 [04:54<00:53,  1.58it/s] 83%|████████▎ | 417/500 [04:54<00:38,  2.16it/s] 84%|████████▍ | 419/500 [04:54<00:27,  2.91it/s] 84%|████████▍ | 421/500 [05:01<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:01<01:05,  1.17it/s]Epoch:  355  	Training Loss: 0.026826372370123863
Test Loss:  0.024052636697888374
Valid Loss:  0.029657483100891113
Epoch:  356  	Training Loss: 0.026824135333299637
Test Loss:  0.02405048906803131
Valid Loss:  0.029654989019036293
Epoch:  357  	Training Loss: 0.02682190015912056
Test Loss:  0.0240483395755291
Valid Loss:  0.02965252473950386
Epoch:  358  	Training Loss: 0.026819678023457527
Test Loss:  0.024046197533607483
Valid Loss:  0.029650036245584488
Epoch:  359  	Training Loss: 0.026817454025149345
Test Loss:  0.024044044315814972
Valid Loss:  0.02964755892753601
Epoch:  360  	Training Loss: 0.026815230026841164
Test Loss:  0.024041902273893356
Valid Loss:  0.02964508906006813
Epoch:  361  	Training Loss: 0.02681300789117813
Test Loss:  0.024039750918745995
Valid Loss:  0.0296426210552454
Epoch:  362  	Training Loss: 0.026810791343450546
Test Loss:  0.024037647992372513
Valid Loss:  0.029640179127454758
Epoch:  363  	Training Loss: 0.02680860459804535
Test Loss:  0.024035539478063583
Valid Loss:  0.029637765139341354
Epoch:  364  	Training Loss: 0.02680642530322075
Test Loss:  0.02403344213962555
Valid Loss:  0.0296353530138731
Epoch:  365  	Training Loss: 0.026804253458976746
Test Loss:  0.024031341075897217
Valid Loss:  0.029632925987243652
Epoch:  366  	Training Loss: 0.02680208347737789
Test Loss:  0.024029241874814034
Valid Loss:  0.02963051199913025
Epoch:  367  	Training Loss: 0.026799913495779037
Test Loss:  0.0240271408110857
Valid Loss:  0.029628101736307144
Epoch:  368  	Training Loss: 0.02679774910211563
Test Loss:  0.024025045335292816
Valid Loss:  0.02962569147348404
Epoch:  369  	Training Loss: 0.026795584708452225
Test Loss:  0.024022947996854782
Valid Loss:  0.029623284935951233
Epoch:  370  	Training Loss: 0.02679342031478882
Test Loss:  0.024020856246352196
Valid Loss:  0.029620880261063576
Epoch:  371  	Training Loss: 0.02679126337170601
Test Loss:  0.02401876635849476
Valid Loss:  0.02961847372353077
Epoch:  372  	Training Loss: 0.02678910829126835
Test Loss:  0.024016709998250008
Valid Loss:  0.029616111889481544
Epoch:  373  	Training Loss: 0.026786990463733673
Test Loss:  0.024014659225940704
Valid Loss:  0.029613759368658066
Epoch:  374  	Training Loss: 0.026784878224134445
Test Loss:  0.024012606590986252
Valid Loss:  0.029611406847834587
Epoch:  375  	Training Loss: 0.02678276225924492
Test Loss:  0.024010557681322098
Valid Loss:  0.02960905432701111
Epoch:  376  	Training Loss: 0.02678065001964569
Test Loss:  0.02400851622223854
Valid Loss:  0.02960670366883278
Epoch:  377  	Training Loss: 0.02677854895591736
Test Loss:  0.024006474763154984
Valid Loss:  0.029604358598589897
Epoch:  378  	Training Loss: 0.026776447892189026
Test Loss:  0.02400442771613598
Valid Loss:  0.029602017253637314
Epoch:  379  	Training Loss: 0.026774344965815544
Test Loss:  0.02400238998234272
Valid Loss:  0.02959967777132988
Epoch:  380  	Training Loss: 0.02677224762737751
Test Loss:  0.024000348523259163
Valid Loss:  0.029597334563732147
Epoch:  381  	Training Loss: 0.026770152151584625
Test Loss:  0.023998312652111053
Valid Loss:  0.02959500066936016
Epoch:  382  	Training Loss: 0.02676805481314659
Test Loss:  0.023996269330382347
Valid Loss:  0.02959265746176243
Epoch:  383  	Training Loss: 0.02676595374941826
Test Loss:  0.02399422600865364
Valid Loss:  0.029590314254164696
Epoch:  384  	Training Loss: 0.026763856410980225
Test Loss:  0.023992188274860382
Valid Loss:  0.029587967321276665
Epoch:  385  	Training Loss: 0.026761755347251892
Test Loss:  0.023990143090486526
Valid Loss:  0.029585624113678932
Epoch:  386  	Training Loss: 0.026759658008813858
Test Loss:  0.023988105356693268
Valid Loss:  0.029583288356661797
Epoch:  387  	Training Loss: 0.026757560670375824
Test Loss:  0.02398606762290001
Valid Loss:  0.029580947011709213
Epoch:  388  	Training Loss: 0.02675546705722809
Test Loss:  0.023984026163816452
Valid Loss:  0.02957860752940178
Epoch:  389  	Training Loss: 0.026753373444080353
Test Loss:  0.023981988430023193
Valid Loss:  0.029576271772384644
Epoch:  390  	Training Loss: 0.026751281693577766
Test Loss:  0.023979946970939636
Valid Loss:  0.029573937878012657
Epoch:  391  	Training Loss: 0.02674918808043003
Test Loss:  0.02397790551185608
Valid Loss:  0.02957160398364067
Epoch:  392  	Training Loss: 0.026747100055217743
Test Loss:  0.023975901305675507
Valid Loss:  0.029569298028945923
Epoch:  393  	Training Loss: 0.026745041832327843
Test Loss:  0.023973898962140083
Valid Loss:  0.029566999524831772
Epoch:  394  	Training Loss: 0.026742985472083092
Test Loss:  0.02397189661860466
Valid Loss:  0.029564708471298218
Epoch:  395  	Training Loss: 0.02674093097448349
Test Loss:  0.023969898000359535
Valid Loss:  0.029562408104538918
Epoch:  396  	Training Loss: 0.026738876476883888
Test Loss:  0.023967891931533813
Valid Loss:  0.029560111463069916
Epoch:  397  	Training Loss: 0.026736821979284286
Test Loss:  0.02396589145064354
Valid Loss:  0.02955782413482666
Epoch:  398  	Training Loss: 0.026734771206974983
Test Loss:  0.023963890969753265
Valid Loss:  0.02955552190542221
Epoch:  399  	Training Loss: 0.02673271670937538
Test Loss:  0.023961897939443588
Valid Loss:  0.029553234577178955
Epoch:  400  	Training Loss: 0.026730675250291824
Test Loss:  0.023959893733263016
Valid Loss:  0.0295509435236454
Epoch:  401  	Training Loss: 0.02672862634062767
Test Loss:  0.02395789697766304
Valid Loss:  0.029548661783337593
Epoch:  402  	Training Loss: 0.026726581156253815
Test Loss:  0.02395590767264366
Valid Loss:  0.029546372592449188
Epoch:  403  	Training Loss: 0.02672453783452511
Test Loss:  0.023953916504979134
Valid Loss:  0.02954409085214138
Epoch:  404  	Training Loss: 0.0267224982380867
Test Loss:  0.023951927199959755
Valid Loss:  0.02954181097447872
Epoch:  405  	Training Loss: 0.02672046236693859
Test Loss:  0.023949939757585526
Valid Loss:  0.029539532959461212
Epoch:  406  	Training Loss: 0.026718422770500183
Test Loss:  0.023947948589920998
Valid Loss:  0.029537251219153404
Epoch:  407  	Training Loss: 0.026716385036706924
Test Loss:  0.023945964872837067
Valid Loss:  0.029534969478845596
Epoch:  408  	Training Loss: 0.026714351028203964
Test Loss:  0.02394397184252739
Valid Loss:  0.029532693326473236
Epoch:  409  	Training Loss: 0.026712309569120407
Test Loss:  0.02394198626279831
Valid Loss:  0.029530413448810577
Epoch:  410  	Training Loss: 0.026710275560617447
Test Loss:  0.02393999509513378
Valid Loss:  0.02952813357114792
Epoch:  411  	Training Loss: 0.026708241552114487
Test Loss:  0.023938007652759552
Valid Loss:  0.02952585741877556
Epoch:  412  	Training Loss: 0.026706207543611526
Test Loss:  0.023936033248901367
Valid Loss:  0.029523596167564392
Epoch:  413  	Training Loss: 0.02670418471097946
Test Loss:  0.02393406070768833
Valid Loss:  0.029521331191062927
Epoch:  414  	Training Loss: 0.026702165603637695
Test Loss:  0.023932086303830147
Valid Loss:  0.029519066214561462
Epoch:  415  	Training Loss: 0.02670014277100563
Test Loss:  0.02393011748790741
Valid Loss:  0.029516804963350296
Epoch:  416  	Training Loss: 0.026698123663663864
Test Loss:  0.023928141221404076
Valid Loss:  0.02951454371213913
Epoch:  417  	Training Loss: 0.026696104556322098
Test Loss:  0.02392616868019104
Valid Loss:  0.029512284323573112
Epoch:  418  	Training Loss: 0.02669408544898033
Test Loss:  0.0239242035895586
Valid Loss:  0.029510023072361946
Epoch:  419  	Training Loss: 0.026692066341638565
Test Loss:  0.023922231048345566
Valid Loss:  0.029507765546441078
Epoch:  420  	Training Loss: 0.0266900472342968
Test Loss:  0.02392026223242283
Valid Loss:  0.02950550802052021
Epoch:  421  	Training Loss: 0.02668803557753563
Test Loss:  0.023918289691209793
Valid Loss:  0.029503248631954193
Epoch:  422  	Training Loss: 0.02668602019548416
Test Loss:  0.023916322737932205
Valid Loss:  0.02950100041925907
Epoch:  423  	Training Loss: 0.026684006676077843
Test Loss:  0.023914359509944916
Valid Loss:  0.029498739168047905
Epoch:  424  	Training Loss: 0.026681996881961823
Test Loss:  0.023912396281957626
Valid Loss:  0.029496490955352783
Epoch:  425  	Training Loss: 0.02667998895049095
Test Loss:  0.023910434916615486
 85%|████████▌ | 425/500 [05:01<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:01<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:01<00:24,  2.90it/s] 86%|████████▌ | 431/500 [05:08<01:24,  1.23s/it] 87%|████████▋ | 433/500 [05:08<00:59,  1.13it/s] 87%|████████▋ | 435/500 [05:08<00:41,  1.57it/s] 87%|████████▋ | 437/500 [05:08<00:29,  2.15it/s] 88%|████████▊ | 439/500 [05:08<00:21,  2.89it/s] 88%|████████▊ | 441/500 [05:15<01:11,  1.22s/it] 89%|████████▊ | 443/500 [05:15<00:50,  1.14it/s] 89%|████████▉ | 445/500 [05:15<00:34,  1.57it/s] 89%|████████▉ | 447/500 [05:15<00:24,  2.15it/s] 90%|████████▉ | 449/500 [05:15<00:17,  2.90it/s] 90%|█████████ | 451/500 [05:22<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:22<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:22<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:22<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:22<00:13,  2.94it/s] 92%|█████████▏| 461/500 [05:29<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:29<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:29<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:29<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:29<00:10,  2.96it/s] 94%|█████████▍| 471/500 [05:36<00:35,  1.21s/it] 95%|█████████▍| 473/500 [05:36<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:36<00:15,  1.59it/s] 95%|█████████▌| 477/500 [05:36<00:10,  2.18it/s] 96%|█████████▌| 479/500 [05:36<00:07,  2.93it/s] 96%|█████████▌| 481/500 [05:43<00:23,  1.23s/it] 97%|█████████▋| 483/500 [05:43<00:14,  1.14it/s] 97%|█████████▋| 485/500 [05:43<00:09,  1.57it/s] 97%|█████████▋| 487/500 [05:43<00:06,  2.15it/s] 98%|█████████▊| 489/500 [05:43<00:03,  2.88it/s] 98%|█████████▊| 491/500 [05:50<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:50<00:06,  1.17it/s] 99%|█████████▉| 495/500 [05:50<00:03,  1.61it/s]Valid Loss:  0.029494239017367363
Epoch:  426  	Training Loss: 0.026677977293729782
Test Loss:  0.023908467963337898
Valid Loss:  0.02949199080467224
Epoch:  427  	Training Loss: 0.02667596936225891
Test Loss:  0.023906514048576355
Valid Loss:  0.02948974445462227
Epoch:  428  	Training Loss: 0.026673968881368637
Test Loss:  0.023904547095298767
Valid Loss:  0.02948751673102379
Epoch:  429  	Training Loss: 0.026671966537833214
Test Loss:  0.023902587592601776
Valid Loss:  0.02948528528213501
Epoch:  430  	Training Loss: 0.026669969782233238
Test Loss:  0.023900624364614487
Valid Loss:  0.02948305755853653
Epoch:  431  	Training Loss: 0.026667967438697815
Test Loss:  0.023898649960756302
Valid Loss:  0.029480833560228348
Epoch:  432  	Training Loss: 0.02666596695780754
Test Loss:  0.023896727710962296
Valid Loss:  0.02947864681482315
Epoch:  433  	Training Loss: 0.0266640093177557
Test Loss:  0.02389480546116829
Valid Loss:  0.029476460069417953
Epoch:  434  	Training Loss: 0.026662051677703857
Test Loss:  0.023892879486083984
Valid Loss:  0.029474275186657906
Epoch:  435  	Training Loss: 0.026660092175006866
Test Loss:  0.023890960961580276
Valid Loss:  0.02947208657860756
Epoch:  436  	Training Loss: 0.026658136397600174
Test Loss:  0.02388903684914112
Valid Loss:  0.02946990728378296
Epoch:  437  	Training Loss: 0.02665618062019348
Test Loss:  0.023887109011411667
Valid Loss:  0.02946772426366806
Epoch:  438  	Training Loss: 0.02665422111749649
Test Loss:  0.02388518862426281
Valid Loss:  0.029465539380908012
Epoch:  439  	Training Loss: 0.026652267202734947
Test Loss:  0.023883268237113953
Valid Loss:  0.029463358223438263
Epoch:  440  	Training Loss: 0.026650309562683105
Test Loss:  0.023881344124674797
Valid Loss:  0.02946118451654911
Epoch:  441  	Training Loss: 0.02664836123585701
Test Loss:  0.02387942187488079
Valid Loss:  0.02945900335907936
Epoch:  442  	Training Loss: 0.026646409183740616
Test Loss:  0.023877542465925217
Valid Loss:  0.02945687249302864
Epoch:  443  	Training Loss: 0.026644494384527206
Test Loss:  0.023875657469034195
Valid Loss:  0.02945472113788128
Epoch:  444  	Training Loss: 0.026642581447958946
Test Loss:  0.02387377992272377
Valid Loss:  0.029452593997120857
Epoch:  445  	Training Loss: 0.026640668511390686
Test Loss:  0.0238718930631876
Valid Loss:  0.02945045754313469
Epoch:  446  	Training Loss: 0.026638757437467575
Test Loss:  0.023870013654232025
Valid Loss:  0.029448319226503372
Epoch:  447  	Training Loss: 0.026636850088834763
Test Loss:  0.02386813424527645
Valid Loss:  0.029446188360452652
Epoch:  448  	Training Loss: 0.02663493901491165
Test Loss:  0.023866254836320877
Valid Loss:  0.02944406121969223
Epoch:  449  	Training Loss: 0.02663303166627884
Test Loss:  0.023864375427365303
Valid Loss:  0.029441922903060913
Epoch:  450  	Training Loss: 0.026631124317646027
Test Loss:  0.023862499743700027
Valid Loss:  0.029439792037010193
Epoch:  451  	Training Loss: 0.026629220694303513
Test Loss:  0.023860622197389603
Valid Loss:  0.02943766675889492
Epoch:  452  	Training Loss: 0.026627318933606148
Test Loss:  0.023858703672885895
Valid Loss:  0.02943549118936062
Epoch:  453  	Training Loss: 0.02662537805736065
Test Loss:  0.023856811225414276
Valid Loss:  0.029433317482471466
Epoch:  454  	Training Loss: 0.026623444631695747
Test Loss:  0.02385491505265236
Valid Loss:  0.02943115122616291
Epoch:  455  	Training Loss: 0.026621507480740547
Test Loss:  0.02385302074253559
Valid Loss:  0.029428988695144653
Epoch:  456  	Training Loss: 0.026619572192430496
Test Loss:  0.023851126432418823
Valid Loss:  0.029426811262965202
Epoch:  457  	Training Loss: 0.026617642492055893
Test Loss:  0.023849233984947205
Valid Loss:  0.029424648731946945
Epoch:  458  	Training Loss: 0.02661571092903614
Test Loss:  0.023847337812185287
Valid Loss:  0.02942248433828354
Epoch:  459  	Training Loss: 0.026613783091306686
Test Loss:  0.023845447227358818
Valid Loss:  0.02942032366991043
Epoch:  460  	Training Loss: 0.026611853390932083
Test Loss:  0.02384355664253235
Valid Loss:  0.029418159276247025
Epoch:  461  	Training Loss: 0.02660992741584778
Test Loss:  0.02384166419506073
Valid Loss:  0.029416000470519066
Epoch:  462  	Training Loss: 0.026607999578118324
Test Loss:  0.023839741945266724
Valid Loss:  0.029413795098662376
Epoch:  463  	Training Loss: 0.026606038212776184
Test Loss:  0.02383781597018242
Valid Loss:  0.029411597177386284
Epoch:  464  	Training Loss: 0.026604076847434044
Test Loss:  0.02383589558303356
Valid Loss:  0.02940939925611019
Epoch:  465  	Training Loss: 0.0266021229326725
Test Loss:  0.023833975195884705
Valid Loss:  0.029407205060124397
Epoch:  466  	Training Loss: 0.02660016342997551
Test Loss:  0.0238320492208004
Valid Loss:  0.029405003413558006
Epoch:  467  	Training Loss: 0.026598207652568817
Test Loss:  0.02383013442158699
Valid Loss:  0.02940281294286251
Epoch:  468  	Training Loss: 0.026596251875162125
Test Loss:  0.023828215897083282
Valid Loss:  0.029400616884231567
Epoch:  469  	Training Loss: 0.026594296097755432
Test Loss:  0.023826293647289276
Valid Loss:  0.029398424550890923
Epoch:  470  	Training Loss: 0.02659233845770359
Test Loss:  0.023824375122785568
Valid Loss:  0.02939622849225998
Epoch:  471  	Training Loss: 0.026590386405587196
Test Loss:  0.023822464048862457
Valid Loss:  0.02939404360949993
Epoch:  472  	Training Loss: 0.02658843621611595
Test Loss:  0.02382061816751957
Valid Loss:  0.029391929507255554
Epoch:  473  	Training Loss: 0.026586562395095825
Test Loss:  0.02381877973675728
Valid Loss:  0.029389826580882072
Epoch:  474  	Training Loss: 0.0265846885740757
Test Loss:  0.02381693758070469
Valid Loss:  0.029387719929218292
Epoch:  475  	Training Loss: 0.026582814753055573
Test Loss:  0.02381509728729725
Valid Loss:  0.029385613277554512
Epoch:  476  	Training Loss: 0.026580942794680595
Test Loss:  0.023813262581825256
Valid Loss:  0.02938351035118103
Epoch:  477  	Training Loss: 0.026579074561595917
Test Loss:  0.023811426013708115
Valid Loss:  0.02938140369951725
Epoch:  478  	Training Loss: 0.02657720446586609
Test Loss:  0.023809587582945824
Valid Loss:  0.029379304498434067
Epoch:  479  	Training Loss: 0.02657533437013626
Test Loss:  0.02380775474011898
Valid Loss:  0.029377203434705734
Epoch:  480  	Training Loss: 0.026573466137051582
Test Loss:  0.02380591630935669
Valid Loss:  0.02937510423362255
Epoch:  481  	Training Loss: 0.026571601629257202
Test Loss:  0.023804085329174995
Valid Loss:  0.029373012483119965
Epoch:  482  	Training Loss: 0.02656973898410797
Test Loss:  0.023802276700735092
Valid Loss:  0.029370930045843124
Epoch:  483  	Training Loss: 0.026567893102765083
Test Loss:  0.023800456896424294
Valid Loss:  0.029368851333856583
Epoch:  484  	Training Loss: 0.026566043496131897
Test Loss:  0.023798644542694092
Valid Loss:  0.02936677075922489
Epoch:  485  	Training Loss: 0.02656419575214386
Test Loss:  0.02379683405160904
Valid Loss:  0.02936469204723835
Epoch:  486  	Training Loss: 0.02656235173344612
Test Loss:  0.023795023560523987
Valid Loss:  0.029362617060542107
Epoch:  487  	Training Loss: 0.026560509577393532
Test Loss:  0.023793209344148636
Valid Loss:  0.029360540211200714
Epoch:  488  	Training Loss: 0.02655866928398609
Test Loss:  0.023791396990418434
Valid Loss:  0.02935846894979477
Epoch:  489  	Training Loss: 0.026556827127933502
Test Loss:  0.02378958836197853
Valid Loss:  0.029356397688388824
Epoch:  490  	Training Loss: 0.026554984971880913
Test Loss:  0.023787785321474075
Valid Loss:  0.02935432642698288
Epoch:  491  	Training Loss: 0.026553146541118622
Test Loss:  0.023785969242453575
Valid Loss:  0.029352251440286636
Epoch:  492  	Training Loss: 0.02655130624771118
Test Loss:  0.023784149438142776
Valid Loss:  0.0293501615524292
Epoch:  493  	Training Loss: 0.026549452915787697
Test Loss:  0.02378232404589653
Valid Loss:  0.029348069801926613
Epoch:  494  	Training Loss: 0.026547595858573914
Test Loss:  0.023780498653650284
Valid Loss:  0.029345978051424026
Epoch:  495  	Training Loss: 0.02654573693871498
Test Loss:  0.023778671398758888
Valid Loss:  0.02934389002621174
Epoch:  496  	Training Loss: 0.026543879881501198
 99%|█████████▉| 497/500 [05:50<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:50<00:00,  2.95it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
Test Loss:  0.023776846006512642
Valid Loss:  0.029341796413064003
Epoch:  497  	Training Loss: 0.026542024686932564
Test Loss:  0.023775022476911545
Valid Loss:  0.029339730739593506
Epoch:  498  	Training Loss: 0.026540173217654228
Test Loss:  0.0237731970846653
Valid Loss:  0.029337657615542412
Epoch:  499  	Training Loss: 0.026538323611021042
Test Loss:  0.023771367967128754
Valid Loss:  0.029335588216781616
Epoch:  500  	Training Loss: 0.026536472141742706
Test Loss:  0.02376953884959221
Valid Loss:  0.02933352254331112
seed is  1
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:37,  6.45s/it]  1%|          | 3/500 [00:06<14:22,  1.74s/it]  1%|          | 5/500 [00:06<07:16,  1.13it/s]  1%|▏         | 7/500 [00:06<04:24,  1.86it/s]  2%|▏         | 9/500 [00:07<03:01,  2.71it/s]  2%|▏         | 11/500 [00:13<11:25,  1.40s/it]  3%|▎         | 13/500 [00:13<07:48,  1.04it/s]  3%|▎         | 15/500 [00:14<05:28,  1.48it/s]  3%|▎         | 17/500 [00:14<03:57,  2.04it/s]  4%|▍         | 19/500 [00:14<02:55,  2.74it/s]  4%|▍         | 21/500 [00:27<17:47,  2.23s/it]  5%|▍         | 23/500 [00:27<12:29,  1.57s/it]  5%|▌         | 25/500 [00:27<08:48,  1.11s/it]  5%|▌         | 27/500 [00:27<06:17,  1.25it/s]  6%|▌         | 29/500 [00:27<04:32,  1.73it/s]  6%|▌         | 31/500 [00:34<10:47,  1.38s/it]  6%|▋         | 32/500 [00:34<09:01,  1.16s/it]  7%|▋         | 34/500 [00:34<06:08,  1.26it/s]  7%|▋         | 36/500 [00:34<04:19,  1.79it/s]  8%|▊         | 38/500 [00:34<03:06,  2.47it/s]  8%|▊         | 40/500 [00:34<02:17,  3.35it/s]  8%|▊         | 42/500 [00:41<09:01,  1.18s/it]  9%|▉         | 44/500 [00:41<06:23,  1.19it/s]  9%|▉         | 46/500 [00:41<04:34,  1.65it/s] 10%|▉         | 48/500 [00:41<03:20,  2.26it/s] 10%|█         | 50/500 [00:41<02:27,  3.04it/s] 10%|█         | 52/500 [00:48<08:58,  1.20s/it] 11%|█         | 54/500 [00:48<06:24,  1.16it/s] 11%|█         | 56/500 [00:48<04:36,  1.61it/s] 12%|█▏        | 58/500 [00:48<03:21,  2.20it/s] 12%|█▏        | 60/500 [00:48<02:29,  2.95it/s] 12%|█▏        | 62/500 [00:55<09:04,  1.24s/it] 13%|█▎        | 64/500 [00:55<06:30,  1.12it/s] 13%|█▎        | 66/500 [00:55<04:40,  1.55it/s] 14%|█▎        | 68/500 [00:55<03:24,  2.12it/s]Epoch:  1  	Training Loss: 0.023777708411216736
Test Loss:  0.007308665197342634
Valid Loss:  0.008836114779114723
Epoch:  2  	Training Loss: 0.008195148780941963
Test Loss:  0.002833221573382616
Valid Loss:  0.0024743780959397554
Epoch:  3  	Training Loss: 0.0027396995574235916
Test Loss:  0.01746208965778351
Valid Loss:  0.01949922740459442
Epoch:  4  	Training Loss: 0.018810175359249115
Test Loss:  0.02001824975013733
Valid Loss:  0.01758822239935398
Epoch:  5  	Training Loss: 0.018439870327711105
Test Loss:  0.008314077742397785
Valid Loss:  0.010203223675489426
Epoch:  6  	Training Loss: 0.009319312870502472
Test Loss:  0.008139073848724365
Valid Loss:  0.010015701875090599
Epoch:  7  	Training Loss: 0.009144941344857216
Test Loss:  0.007922733202576637
Valid Loss:  0.00978410616517067
Epoch:  8  	Training Loss: 0.00893328245729208
Test Loss:  0.007726581301540136
Valid Loss:  0.009575130417943
Epoch:  9  	Training Loss: 0.00873967818915844
Test Loss:  0.00754636200144887
Valid Loss:  0.00938442163169384
Epoch:  10  	Training Loss: 0.008562270551919937
Test Loss:  0.007381527218967676
Valid Loss:  0.00921607855707407
Epoch:  11  	Training Loss: 0.008401595987379551
Test Loss:  0.007211846765130758
Valid Loss:  0.009041409939527512
Epoch:  12  	Training Loss: 0.008238115347921848
Test Loss:  0.011374078691005707
Valid Loss:  0.010125312954187393
Epoch:  13  	Training Loss: 0.010774261318147182
Test Loss:  0.015609079971909523
Valid Loss:  0.01856662891805172
Epoch:  14  	Training Loss: 0.017149165272712708
Test Loss:  0.004891898483037949
Valid Loss:  0.006168884690850973
Epoch:  15  	Training Loss: 0.005749736446887255
Test Loss:  0.004233360290527344
Valid Loss:  0.0046780286356806755
Epoch:  16  	Training Loss: 0.004735779482871294
Test Loss:  0.0036537223495543003
Valid Loss:  0.00472645740956068
Epoch:  17  	Training Loss: 0.004496708046644926
Test Loss:  0.004281369969248772
Valid Loss:  0.004301666282117367
Epoch:  18  	Training Loss: 0.004545480944216251
Test Loss:  0.0038725235499441624
Valid Loss:  0.005130920559167862
Epoch:  19  	Training Loss: 0.004858188796788454
Test Loss:  0.0052755363285541534
Valid Loss:  0.004829850047826767
Epoch:  20  	Training Loss: 0.005247343331575394
Test Loss:  0.005224624183028936
Valid Loss:  0.006844252347946167
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.006402601487934589
Test Loss:  0.0042328923009335995
Valid Loss:  0.005555994808673859
Epoch:  22  	Training Loss: 0.005196818150579929
Test Loss:  0.003198171965777874
Valid Loss:  0.0037479852326214314
Epoch:  23  	Training Loss: 0.0037150250282138586
Test Loss:  0.0030351157765835524
Valid Loss:  0.0035548778250813484
Epoch:  24  	Training Loss: 0.0035445578396320343
Test Loss:  0.0028791609220206738
Valid Loss:  0.003371211001649499
Epoch:  25  	Training Loss: 0.0033812522888183594
Test Loss:  0.0027741894591599703
Valid Loss:  0.0032379936892539263
Epoch:  26  	Training Loss: 0.0032669929787516594
Test Loss:  0.0027014859952032566
Valid Loss:  0.003131062490865588
Epoch:  27  	Training Loss: 0.0031809452921152115
Test Loss:  0.002628682879731059
Valid Loss:  0.0030423435382544994
Epoch:  28  	Training Loss: 0.003105616196990013
Test Loss:  0.0025660281535238028
Valid Loss:  0.002960466779768467
Epoch:  29  	Training Loss: 0.003038543974980712
Test Loss:  0.0025054265279322863
Valid Loss:  0.0028896951116621494
Epoch:  30  	Training Loss: 0.0029789619147777557
Test Loss:  0.002452746033668518
Valid Loss:  0.0028250960167497396
Epoch:  31  	Training Loss: 0.0029258951544761658
Test Loss:  0.002403849270194769
Valid Loss:  0.0027677416801452637
Epoch:  32  	Training Loss: 0.0028783995658159256
Test Loss:  0.0023177526891231537
Valid Loss:  0.002713254652917385
Epoch:  33  	Training Loss: 0.002818851266056299
Test Loss:  0.0022766883485019207
Valid Loss:  0.002678035292774439
Epoch:  34  	Training Loss: 0.0027882331050932407
Test Loss:  0.00224249972961843
Valid Loss:  0.0026476902421563864
Epoch:  35  	Training Loss: 0.002761972602456808
Test Loss:  0.0022148420102894306
Valid Loss:  0.0026190727949142456
Epoch:  36  	Training Loss: 0.0027386900037527084
Test Loss:  0.002191337291151285
Valid Loss:  0.0025921971537172794
Epoch:  37  	Training Loss: 0.002717633731663227
Test Loss:  0.0021707327105104923
Valid Loss:  0.002567123156040907
Epoch:  38  	Training Loss: 0.002698456170037389
Test Loss:  0.002152336062863469
Valid Loss:  0.002543845446780324
Epoch:  39  	Training Loss: 0.0026809510309249163
Test Loss:  0.002135717775672674
Valid Loss:  0.002522300696000457
Epoch:  40  	Training Loss: 0.0026649499777704477
Test Loss:  0.0021205893717706203
Valid Loss:  0.002502383664250374
Epoch:  41  	Training Loss: 0.002650305163115263
Test Loss:  0.0021067606285214424
Valid Loss:  0.0024839872494339943
Epoch:  42  	Training Loss: 0.00263813603669405
Test Loss:  0.0018673388985916972
Valid Loss:  0.002273562829941511
Epoch:  43  	Training Loss: 0.0024154712446033955
Test Loss:  0.0017775263404473662
Valid Loss:  0.002200624905526638
Epoch:  44  	Training Loss: 0.002330717397853732
Test Loss:  0.0017579621635377407
Valid Loss:  0.0021548685617744923
Epoch:  45  	Training Loss: 0.00228491285815835
Test Loss:  0.0017067895969375968
Valid Loss:  0.0021336963400244713
Epoch:  46  	Training Loss: 0.0022473607677966356
Test Loss:  0.0017003270331770182
Valid Loss:  0.0020968709141016006
Epoch:  47  	Training Loss: 0.0022141204681247473
Test Loss:  0.0016540482174605131
Valid Loss:  0.0020758516620844603
Epoch:  48  	Training Loss: 0.0021809805184602737
Test Loss:  0.001651344122365117
Valid Loss:  0.0020314683206379414
Epoch:  49  	Training Loss: 0.002145681530237198
Test Loss:  0.0016076908214017749
Valid Loss:  0.002011070493608713
Epoch:  50  	Training Loss: 0.0021148656960576773
Test Loss:  0.001602150034159422
Valid Loss:  0.0019766364712268114
Epoch:  51  	Training Loss: 0.0020865139085799456
Test Loss:  0.0015599485486745834
Valid Loss:  0.0019581543747335672
Epoch:  52  	Training Loss: 0.0020590564236044884
Test Loss:  0.0014907500008121133
Valid Loss:  0.001848857500590384
Epoch:  53  	Training Loss: 0.0019499228801578283
Test Loss:  0.0014237051364034414
Valid Loss:  0.0017874797340482473
Epoch:  54  	Training Loss: 0.0018823383143171668
Test Loss:  0.0013746076729148626
Valid Loss:  0.0017419288633391261
Epoch:  55  	Training Loss: 0.0018334472551941872
Test Loss:  0.00133613683283329
Valid Loss:  0.0017051675822585821
Epoch:  56  	Training Loss: 0.0017947207670658827
Test Loss:  0.0013066304381936789
Valid Loss:  0.0016731212381273508
Epoch:  57  	Training Loss: 0.0017624637112021446
Test Loss:  0.0012811850756406784
Valid Loss:  0.0016460795886814594
Epoch:  58  	Training Loss: 0.0017366308020427823
Test Loss:  0.001260228455066681
Valid Loss:  0.0016227025771513581
Epoch:  59  	Training Loss: 0.0017167599871754646
Test Loss:  0.0012451830552890897
Valid Loss:  0.0016077205073088408
Epoch:  60  	Training Loss: 0.0017051135655492544
Test Loss:  0.0012327940203249454
Valid Loss:  0.0015974990092217922
Epoch:  61  	Training Loss: 0.0016958472551777959
Test Loss:  0.0012230079155415297
Valid Loss:  0.0015880170976743102
Epoch:  62  	Training Loss: 0.0016871680272743106
Test Loss:  0.0012455217074602842
Valid Loss:  0.0015512157697230577
Epoch:  63  	Training Loss: 0.0016657453961670399
Test Loss:  0.0012397600803524256
Valid Loss:  0.0015399607364088297
Epoch:  64  	Training Loss: 0.00165827595628798
Test Loss:  0.0012349362950772047
Valid Loss:  0.001530492678284645
Epoch:  65  	Training Loss: 0.001652362523600459
Test Loss:  0.0012294637272134423
Valid Loss:  0.0015222019283100963
Epoch:  66  	Training Loss: 0.001647184370085597
Test Loss:  0.0012243316741660237
Valid Loss:  0.0015146222431212664
Epoch:  67  	Training Loss: 0.0016425775829702616
Test Loss:  0.0012192267458885908
Valid Loss:  0.0015077651478350163
Epoch:  68  	Training Loss: 0.0016384071204811335
Test Loss:  0.0012145463842898607
Valid Loss:  0.001501468475908041
Epoch:  69  	Training Loss: 0.00163469894323498
Test Loss:  0.0012101909378543496
Valid Loss:   14%|█▍        | 70/500 [00:56<02:31,  2.84it/s] 14%|█▍        | 72/500 [01:02<08:42,  1.22s/it] 15%|█▍        | 74/500 [01:02<06:12,  1.14it/s] 15%|█▌        | 76/500 [01:02<04:27,  1.58it/s] 16%|█▌        | 78/500 [01:03<03:15,  2.16it/s] 16%|█▌        | 80/500 [01:03<02:24,  2.92it/s] 16%|█▋        | 82/500 [01:09<08:24,  1.21s/it] 17%|█▋        | 84/500 [01:09<06:00,  1.16it/s] 17%|█▋        | 86/500 [01:09<04:18,  1.60it/s] 18%|█▊        | 88/500 [01:09<03:08,  2.19it/s] 18%|█▊        | 90/500 [01:10<02:19,  2.94it/s] 18%|█▊        | 92/500 [01:16<08:08,  1.20s/it] 19%|█▉        | 94/500 [01:16<05:50,  1.16it/s] 19%|█▉        | 96/500 [01:16<04:14,  1.59it/s] 20%|█▉        | 98/500 [01:17<03:07,  2.15it/s] 20%|██        | 100/500 [01:17<02:18,  2.89it/s] 20%|██        | 102/500 [01:23<08:05,  1.22s/it] 21%|██        | 104/500 [01:23<05:46,  1.14it/s] 21%|██        | 106/500 [01:23<04:08,  1.58it/s] 22%|██▏       | 108/500 [01:24<03:01,  2.16it/s] 22%|██▏       | 110/500 [01:24<02:14,  2.91it/s] 22%|██▏       | 112/500 [01:30<07:45,  1.20s/it] 23%|██▎       | 114/500 [01:30<05:31,  1.16it/s] 23%|██▎       | 116/500 [01:30<03:58,  1.61it/s] 24%|██▎       | 118/500 [01:30<02:53,  2.20it/s] 24%|██▍       | 120/500 [01:31<02:08,  2.96it/s] 24%|██▍       | 122/500 [01:37<07:25,  1.18s/it] 25%|██▍       | 124/500 [01:37<05:18,  1.18it/s] 25%|██▌       | 126/500 [01:43<09:41,  1.55s/it] 26%|██▌       | 128/500 [01:44<06:52,  1.11s/it] 26%|██▌       | 130/500 [01:44<04:54,  1.26it/s] 26%|██▋       | 132/500 [01:50<09:12,  1.50s/it] 27%|██▋       | 134/500 [01:50<06:31,  1.07s/it] 27%|██▋       | 136/500 [01:50<04:39,  1.30it/s]0.0014956851955503225
Epoch:  70  	Training Loss: 0.0016313852975144982
Test Loss:  0.0012063083704560995
Valid Loss:  0.0014903605915606022
Epoch:  71  	Training Loss: 0.0016284552402794361
Test Loss:  0.0012028103228658438
Valid Loss:  0.0014855435583740473
Epoch:  72  	Training Loss: 0.0016258759424090385
Test Loss:  0.0011468876618891954
Valid Loss:  0.001465172739699483
Epoch:  73  	Training Loss: 0.0016034950967878103
Test Loss:  0.001150966389104724
Valid Loss:  0.0014553475193679333
Epoch:  74  	Training Loss: 0.0015952521935105324
Test Loss:  0.0011307939421385527
Valid Loss:  0.0014525209553539753
Epoch:  75  	Training Loss: 0.0015884931199252605
Test Loss:  0.0011428170837461948
Valid Loss:  0.001442678039893508
Epoch:  76  	Training Loss: 0.0015828284667804837
Test Loss:  0.0011200932785868645
Valid Loss:  0.0014413574244827032
Epoch:  77  	Training Loss: 0.0015770196914672852
Test Loss:  0.001137913204729557
Valid Loss:  0.0014326778473332524
Epoch:  78  	Training Loss: 0.0015736768255010247
Test Loss:  0.0011108616599813104
Valid Loss:  0.0014324858784675598
Epoch:  79  	Training Loss: 0.0015682796947658062
Test Loss:  0.0011289980029687285
Valid Loss:  0.0014233740512281656
Epoch:  80  	Training Loss: 0.0015642717480659485
Test Loss:  0.0011059617390856147
Valid Loss:  0.001423134934157133
Epoch:  81  	Training Loss: 0.0015597727615386248
Test Loss:  0.0011275289580225945
Valid Loss:  0.0014195977710187435
Epoch:  82  	Training Loss: 0.0015607138630002737
Test Loss:  0.0011049947934225202
Valid Loss:  0.0013775033876299858
Epoch:  83  	Training Loss: 0.0015252875164151192
Test Loss:  0.0010800185846164823
Valid Loss:  0.0013609302695840597
Epoch:  84  	Training Loss: 0.0015063664177432656
Test Loss:  0.0010799726005643606
Valid Loss:  0.001347486861050129
Epoch:  85  	Training Loss: 0.0014961750712245703
Test Loss:  0.001069379854016006
Valid Loss:  0.0013423056807368994
Epoch:  86  	Training Loss: 0.0014899689704179764
Test Loss:  0.0010662388522177935
Valid Loss:  0.0013359962031245232
Epoch:  87  	Training Loss: 0.0014850865118205547
Test Loss:  0.0010627317242324352
Valid Loss:  0.0013309487840160728
Epoch:  88  	Training Loss: 0.0014810143038630486
Test Loss:  0.001059863017871976
Valid Loss:  0.0013266586465761065
Epoch:  89  	Training Loss: 0.0014776804018765688
Test Loss:  0.0010598056251183152
Valid Loss:  0.0013218780513852835
Epoch:  90  	Training Loss: 0.0014746913220733404
Test Loss:  0.0010567164281383157
Valid Loss:  0.0013190717436373234
Epoch:  91  	Training Loss: 0.0014719926984980702
Test Loss:  0.0010571873281151056
Valid Loss:  0.0013155294582247734
Epoch:  92  	Training Loss: 0.0014695532154291868
Test Loss:  0.0010463916696608067
Valid Loss:  0.0012959509622305632
Epoch:  93  	Training Loss: 0.0014521937118843198
Test Loss:  0.0010447563836351037
Valid Loss:  0.0012868717312812805
Epoch:  94  	Training Loss: 0.0014437097124755383
Test Loss:  0.0010405334178358316
Valid Loss:  0.0012813996290788054
Epoch:  95  	Training Loss: 0.0014378554187715054
Test Loss:  0.0010398556478321552
Valid Loss:  0.0012753751361742616
Epoch:  96  	Training Loss: 0.0014327361714094877
Test Loss:  0.0010349629446864128
Valid Loss:  0.001270275330170989
Epoch:  97  	Training Loss: 0.0014278831658884883
Test Loss:  0.0010329133365303278
Valid Loss:  0.0012647530529648066
Epoch:  98  	Training Loss: 0.001423110719770193
Test Loss:  0.0010282008443027735
Valid Loss:  0.001259873970411718
Epoch:  99  	Training Loss: 0.0014184111496433616
Test Loss:  0.0010264767333865166
Valid Loss:  0.00125447241589427
Epoch:  100  	Training Loss: 0.0014137926045805216
Test Loss:  0.0010222001001238823
Valid Loss:  0.0012496542185544968
Epoch:  101  	Training Loss: 0.0014092839555814862
Test Loss:  0.001019689254462719
Valid Loss:  0.0012446925975382328
Epoch:  102  	Training Loss: 0.001404986483976245
Test Loss:  0.0009951898828148842
Valid Loss:  0.0012324093841016293
Epoch:  103  	Training Loss: 0.0013908399268984795
Test Loss:  0.0010153886396437883
Valid Loss:  0.0012255660258233547
Epoch:  104  	Training Loss: 0.0013893673894926906
Test Loss:  0.001000298885628581
Valid Loss:  0.0012266593985259533
Epoch:  105  	Training Loss: 0.0013884261716157198
Test Loss:  0.0010077501647174358
Valid Loss:  0.0012235508766025305
Epoch:  106  	Training Loss: 0.0013877303572371602
Test Loss:  0.0010025202063843608
Valid Loss:  0.0012231218861415982
Epoch:  107  	Training Loss: 0.001387283205986023
Test Loss:  0.0010052337311208248
Valid Loss:  0.001221214421093464
Epoch:  108  	Training Loss: 0.0013868643436580896
Test Loss:  0.0010011292761191726
Valid Loss:  0.0012207968393340707
Epoch:  109  	Training Loss: 0.0013865088112652302
Test Loss:  0.0010033268481492996
Valid Loss:  0.001219289842993021
Epoch:  110  	Training Loss: 0.0013861635234206915
Test Loss:  0.0010003270581364632
Valid Loss:  0.0012188402470201254
Epoch:  111  	Training Loss: 0.0013858368620276451
Test Loss:  0.0010015147272497416
Valid Loss:  0.0012177032185718417
Epoch:  112  	Training Loss: 0.001385554438456893
Test Loss:  0.0009853075025603175
Valid Loss:  0.0012171955313533545
Epoch:  113  	Training Loss: 0.0013820595340803266
Test Loss:  0.0009970596292987466
Valid Loss:  0.0012144489446654916
Epoch:  114  	Training Loss: 0.0013812194811180234
Test Loss:  0.0009953085100278258
Valid Loss:  0.0012143406784161925
Epoch:  115  	Training Loss: 0.0013811163371428847
Test Loss:  0.0009965416975319386
Valid Loss:  0.0012136718723922968
Epoch:  116  	Training Loss: 0.001381043577566743
Test Loss:  0.0009962556650862098
Valid Loss:  0.001213236479088664
Epoch:  117  	Training Loss: 0.0013810013188049197
Test Loss:  0.0009951632237061858
Valid Loss:  0.0012131077237427235
Epoch:  118  	Training Loss: 0.0013809769880026579
Test Loss:  0.00099587207660079
Valid Loss:  0.0012126484652981162
Epoch:  119  	Training Loss: 0.001380939967930317
Test Loss:  0.0009953173575922847
Valid Loss:  0.0012124332133680582
Epoch:  120  	Training Loss: 0.0013809322845190763
Test Loss:  0.0009938438888639212
Valid Loss:  0.0012126180808991194
Epoch:  121  	Training Loss: 0.0013809346128255129
Test Loss:  0.000995525741018355
Valid Loss:  0.0012121177278459072
Epoch:  122  	Training Loss: 0.001380904228426516
Test Loss:  0.0009903176687657833
Valid Loss:  0.0012115280842408538
Epoch:  123  	Training Loss: 0.0013792059617117047
Test Loss:  0.0009896999690681696
Valid Loss:  0.0012101249303668737
Epoch:  124  	Training Loss: 0.0013777324929833412
Test Loss:  0.0009893296519294381
Valid Loss:  0.0012087688082829118
Epoch:  125  	Training Loss: 0.0013764360919594765
Test Loss:  0.0009894173126667738
Valid Loss:  0.0012073284015059471
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.0013752835802733898
Test Loss:  0.000969127519056201
Valid Loss:  0.001176283461973071
Epoch:  127  	Training Loss: 0.0013467196840792894
Test Loss:  0.0009529778035357594
Valid Loss:  0.0011558806290850043
Epoch:  128  	Training Loss: 0.001328362850472331
Test Loss:  0.0009388725738972425
Valid Loss:  0.0011404033284634352
Epoch:  129  	Training Loss: 0.0013145327102392912
Test Loss:  0.0009263724205084145
Valid Loss:  0.0011282823979854584
Epoch:  130  	Training Loss: 0.0013034987496212125
Test Loss:  0.0009159501641988754
Valid Loss:  0.0011183454189449549
Epoch:  131  	Training Loss: 0.0012943196343258023
Test Loss:  0.0009068002691492438
Valid Loss:  0.0011096689850091934
Epoch:  132  	Training Loss: 0.0012861470459029078
Test Loss:  0.0008787500555627048
Valid Loss:  0.0010862324852496386
Epoch:  133  	Training Loss: 0.0012633020523935556
Test Loss:  0.0008582151494920254
Valid Loss:  0.0010625889990478754
Epoch:  134  	Training Loss: 0.0012411025818437338
Test Loss:  0.0008415746269747615
Valid Loss:  0.0010408563539385796
Epoch:  135  	Training Loss: 0.001221769955009222
Test Loss:  0.0008299441542476416
Valid Loss:  0.0010252436622977257
Epoch:  136  	Training Loss: 0.0012068429496139288
Test Loss:  0.0008214610861614347
Valid Loss:  0.0010159839875996113
Epoch:  137  	Training Loss: 0.0011966181918978691
Test Loss:   28%|██▊       | 138/500 [01:50<03:22,  1.79it/s] 28%|██▊       | 140/500 [01:51<02:27,  2.43it/s] 28%|██▊       | 142/500 [01:57<07:36,  1.27s/it] 29%|██▉       | 144/500 [01:57<05:26,  1.09it/s] 29%|██▉       | 146/500 [01:57<03:56,  1.50it/s] 30%|██▉       | 148/500 [01:58<02:53,  2.03it/s] 30%|███       | 150/500 [01:58<02:09,  2.70it/s] 30%|███       | 152/500 [02:04<07:11,  1.24s/it] 31%|███       | 154/500 [02:04<05:06,  1.13it/s] 31%|███       | 156/500 [02:05<03:40,  1.56it/s] 32%|███▏      | 158/500 [02:05<02:39,  2.14it/s] 32%|███▏      | 160/500 [02:05<01:57,  2.88it/s] 32%|███▏      | 162/500 [02:11<06:46,  1.20s/it] 33%|███▎      | 164/500 [02:11<04:49,  1.16it/s] 33%|███▎      | 166/500 [02:12<03:27,  1.61it/s] 34%|███▎      | 168/500 [02:12<02:30,  2.20it/s] 34%|███▍      | 170/500 [02:12<01:51,  2.96it/s] 34%|███▍      | 172/500 [02:18<06:25,  1.17s/it] 35%|███▍      | 174/500 [02:18<04:34,  1.19it/s] 35%|███▌      | 176/500 [02:18<03:17,  1.64it/s] 36%|███▌      | 178/500 [02:18<02:23,  2.24it/s] 36%|███▌      | 180/500 [02:19<01:46,  3.02it/s] 36%|███▋      | 182/500 [02:25<06:19,  1.19s/it] 37%|███▋      | 184/500 [02:25<04:29,  1.17it/s] 37%|███▋      | 186/500 [02:25<03:13,  1.62it/s] 38%|███▊      | 188/500 [02:25<02:20,  2.21it/s] 38%|███▊      | 190/500 [02:25<01:44,  2.98it/s] 38%|███▊      | 192/500 [02:32<06:06,  1.19s/it] 39%|███▉      | 194/500 [02:32<04:20,  1.17it/s] 39%|███▉      | 196/500 [02:32<03:09,  1.61it/s] 40%|███▉      | 198/500 [02:32<02:19,  2.17it/s] 40%|████      | 200/500 [02:32<01:43,  2.89it/s] 40%|████      | 202/500 [02:39<06:05,  1.23s/it] 41%|████      | 204/500 [02:39<04:20,  1.14it/s]0.0008145030005834997
Valid Loss:  0.0010108118876814842
Epoch:  138  	Training Loss: 0.0011883379193022847
Test Loss:  0.0008087880560196936
Valid Loss:  0.0010074772872030735
Epoch:  139  	Training Loss: 0.001181866624392569
Test Loss:  0.0008041772525757551
Valid Loss:  0.0010050891432911158
Epoch:  140  	Training Loss: 0.0011773009318858385
Test Loss:  0.0008004985866136849
Valid Loss:  0.0010033103171736002
Epoch:  141  	Training Loss: 0.0011735399020835757
Test Loss:  0.000795687607023865
Valid Loss:  0.001001373864710331
Epoch:  142  	Training Loss: 0.0011702502379193902
Test Loss:  0.0007906173123046756
Valid Loss:  0.0009996098233386874
Epoch:  143  	Training Loss: 0.0011660808231681585
Test Loss:  0.0007878248579800129
Valid Loss:  0.0009985493961721659
Epoch:  144  	Training Loss: 0.0011630285298451781
Test Loss:  0.0007866129744797945
Valid Loss:  0.0009980171453207731
Epoch:  145  	Training Loss: 0.0011609159409999847
Test Loss:  0.0007861009216867387
Valid Loss:  0.0009979644091799855
Epoch:  146  	Training Loss: 0.001159423729404807
Test Loss:  0.0007862356724217534
Valid Loss:  0.0009980439208447933
Epoch:  147  	Training Loss: 0.0011583443265408278
Test Loss:  0.0007863964419811964
Valid Loss:  0.0009982227347791195
Epoch:  148  	Training Loss: 0.0011574719101190567
Test Loss:  0.0007866119267418981
Valid Loss:  0.000998463830910623
Epoch:  149  	Training Loss: 0.0011567746987566352
Test Loss:  0.0007870107656344771
Valid Loss:  0.0009987149387598038
Epoch:  150  	Training Loss: 0.0011562536237761378
Test Loss:  0.0007875062292441726
Valid Loss:  0.0009989558020606637
Epoch:  151  	Training Loss: 0.0011558386031538248
Test Loss:  0.0007878656033426523
Valid Loss:  0.0009992023697122931
Epoch:  152  	Training Loss: 0.001155485981144011
Test Loss:  0.0007859899778850377
Valid Loss:  0.0009978350717574358
Epoch:  153  	Training Loss: 0.0011538815451785922
Test Loss:  0.000784609466791153
Valid Loss:  0.000996519229374826
Epoch:  154  	Training Loss: 0.0011523643042892218
Test Loss:  0.0007835036376491189
Valid Loss:  0.0009952427353709936
Epoch:  155  	Training Loss: 0.0011509149335324764
Test Loss:  0.0007827569497749209
Valid Loss:  0.000994002679362893
Epoch:  156  	Training Loss: 0.0011495251674205065
Test Loss:  0.0007821778999641538
Valid Loss:  0.0009928494691848755
Epoch:  157  	Training Loss: 0.001148222596384585
Test Loss:  0.0007817447185516357
Valid Loss:  0.0009918801952153444
Epoch:  158  	Training Loss: 0.001147018512710929
Test Loss:  0.0007813869742676616
Valid Loss:  0.0009909423533827066
Epoch:  159  	Training Loss: 0.0011458629742264748
Test Loss:  0.0007810985553078353
Valid Loss:  0.0009900256991386414
Epoch:  160  	Training Loss: 0.0011447465512901545
Test Loss:  0.0007808632217347622
Valid Loss:  0.0009891295339912176
Epoch:  161  	Training Loss: 0.001143686124123633
Test Loss:  0.0007806966314092278
Valid Loss:  0.0009882880840450525
Epoch:  162  	Training Loss: 0.0011427069548517466
Test Loss:  0.0007797535508871078
Valid Loss:  0.0009877309203147888
Epoch:  163  	Training Loss: 0.0011417075293138623
Test Loss:  0.000779214664362371
Valid Loss:  0.000987167120911181
Epoch:  164  	Training Loss: 0.0011407681740820408
Test Loss:  0.0007781708845868707
Valid Loss:  0.0009865264873951674
Epoch:  165  	Training Loss: 0.001139923231676221
Test Loss:  0.000778262154199183
Valid Loss:  0.0009859127458184958
Epoch:  166  	Training Loss: 0.0011390555882826447
Test Loss:  0.0007772092940285802
Valid Loss:  0.0009852310176938772
Epoch:  167  	Training Loss: 0.0011382994707673788
Test Loss:  0.0007777172140777111
Valid Loss:  0.0009845718741416931
Epoch:  168  	Training Loss: 0.0011374936439096928
Test Loss:  0.0007780557498335838
Valid Loss:  0.0009840085403993726
Epoch:  169  	Training Loss: 0.0011367584811523557
Test Loss:  0.0007771840319037437
Valid Loss:  0.0009833734948188066
Epoch:  170  	Training Loss: 0.001136119943112135
Test Loss:  0.000777744222432375
Valid Loss:  0.0009827713947743177
Epoch:  171  	Training Loss: 0.0011354107409715652
Test Loss:  0.0007780814194120467
Valid Loss:  0.0009822174906730652
Epoch:  172  	Training Loss: 0.001134728197939694
Test Loss:  0.000768221216276288
Valid Loss:  0.0009556743898428977
Epoch:  173  	Training Loss: 0.0011114160297438502
Test Loss:  0.0007620247779414058
Valid Loss:  0.0009457858395762742
Epoch:  174  	Training Loss: 0.0011028097942471504
Test Loss:  0.0007553728064522147
Valid Loss:  0.0009391759522259235
Epoch:  175  	Training Loss: 0.0010968610877171159
Test Loss:  0.0007499525672756135
Valid Loss:  0.0009340314427390695
Epoch:  176  	Training Loss: 0.0010920172790065408
Test Loss:  0.0007446029921993613
Valid Loss:  0.0009295460768043995
Epoch:  177  	Training Loss: 0.0010875276057049632
Test Loss:  0.0007394879357889295
Valid Loss:  0.0009253537282347679
Epoch:  178  	Training Loss: 0.0010831811232492328
Test Loss:  0.0007347282953560352
Valid Loss:  0.0009213369921781123
Epoch:  179  	Training Loss: 0.0010789294028654695
Test Loss:  0.000730396481230855
Valid Loss:  0.0009174358565360308
Epoch:  180  	Training Loss: 0.0010747464839369059
Test Loss:  0.0007264517480507493
Valid Loss:  0.0009136282606050372
Epoch:  181  	Training Loss: 0.0010706305038183928
Test Loss:  0.0007228110916912556
Valid Loss:  0.0009098929585888982
Epoch:  182  	Training Loss: 0.0010666265152394772
Test Loss:  0.0007134727784432471
Valid Loss:  0.000906649453099817
Epoch:  183  	Training Loss: 0.001062365248799324
Test Loss:  0.000707488099578768
Valid Loss:  0.0009037000127136707
Epoch:  184  	Training Loss: 0.0010588672012090683
Test Loss:  0.0007027751998975873
Valid Loss:  0.0009011115762405097
Epoch:  185  	Training Loss: 0.0010557896457612514
Test Loss:  0.0006989489193074405
Valid Loss:  0.0008986085886135697
Epoch:  186  	Training Loss: 0.0010528785642236471
Test Loss:  0.0006956135621294379
Valid Loss:  0.0008962155552580953
Epoch:  187  	Training Loss: 0.0010501643409952521
Test Loss:  0.000692501082085073
Valid Loss:  0.000894082710146904
Epoch:  188  	Training Loss: 0.0010476151946932077
Test Loss:  0.0006896776612848043
Valid Loss:  0.0008920181426219642
Epoch:  189  	Training Loss: 0.0010451814159750938
Test Loss:  0.0006870900397188962
Valid Loss:  0.000890105206053704
Epoch:  190  	Training Loss: 0.0010428593959659338
Test Loss:  0.0006847132463008165
Valid Loss:  0.0008882252150215209
Epoch:  191  	Training Loss: 0.0010405720677226782
Test Loss:  0.0006824809242971241
Valid Loss:  0.000886378635186702
Epoch:  192  	Training Loss: 0.0010383155895397067
Test Loss:  0.0006714320625178516
Valid Loss:  0.000875057652592659
Epoch:  193  	Training Loss: 0.0010248132748529315
Test Loss:  0.0006645754911005497
Valid Loss:  0.0008656381396576762
Epoch:  194  	Training Loss: 0.0010141487000510097
Test Loss:  0.0006584413931705058
Valid Loss:  0.0008569925557821989
Epoch:  195  	Training Loss: 0.0010044872760772705
Test Loss:  0.0006522588082589209
Valid Loss:  0.0008491015760228038
Epoch:  196  	Training Loss: 0.0009955496061593294
Test Loss:  0.0006464158650487661
Valid Loss:  0.0008417705539613962
Epoch:  197  	Training Loss: 0.0009871333604678512
Test Loss:  0.0006408464396372437
Valid Loss:  0.0008346777176484466
Epoch:  198  	Training Loss: 0.0009790263138711452
Test Loss:  0.0006353885401040316
Valid Loss:  0.0008276841253973544
Epoch:  199  	Training Loss: 0.0009711385355331004
Test Loss:  0.0006298762746155262
Valid Loss:  0.0008207801729440689
Epoch:  200  	Training Loss: 0.0009634258458390832
Test Loss:  0.0006245874683372676
Valid Loss:  0.0008139899000525475
Epoch:  201  	Training Loss: 0.0009559258469380438
Test Loss:  0.0006194603629410267
Valid Loss:  0.0008073423523455858
Epoch:  202  	Training Loss: 0.0009487166535109282
Test Loss:  0.0006107774097472429
Valid Loss:  0.0008058201055973768
Epoch:  203  	Training Loss: 0.0009452430531382561
Test Loss:  0.000607901019975543
Valid Loss:  0.0008041094406507909
Epoch:  204  	Training Loss: 0.0009427779586985707
Test Loss:  0.0006057972786948085
Valid Loss:  0.0008024403359740973
Epoch:  205  	Training Loss: 0.0009405874297954142
Test Loss:  0.000605423585511744
Valid Loss:  0.0008005837444216013
 41%|████      | 206/500 [02:39<03:06,  1.57it/s] 42%|████▏     | 208/500 [02:39<02:15,  2.15it/s] 42%|████▏     | 210/500 [02:40<01:39,  2.90it/s] 42%|████▏     | 212/500 [02:46<05:49,  1.21s/it] 43%|████▎     | 214/500 [02:46<04:09,  1.15it/s] 43%|████▎     | 216/500 [02:46<02:59,  1.58it/s] 44%|████▎     | 218/500 [02:46<02:10,  2.17it/s] 44%|████▍     | 220/500 [02:47<01:35,  2.92it/s] 44%|████▍     | 222/500 [02:53<05:43,  1.24s/it] 45%|████▍     | 224/500 [02:53<04:04,  1.13it/s] 45%|████▌     | 226/500 [02:53<02:55,  1.56it/s] 46%|████▌     | 228/500 [02:54<02:07,  2.14it/s] 46%|████▌     | 230/500 [02:54<01:33,  2.88it/s] 46%|████▋     | 232/500 [03:00<05:23,  1.21s/it] 47%|████▋     | 234/500 [03:00<03:50,  1.16it/s] 47%|████▋     | 236/500 [03:00<02:44,  1.60it/s] 48%|████▊     | 238/500 [03:01<01:59,  2.19it/s] 48%|████▊     | 240/500 [03:01<01:28,  2.95it/s] 48%|████▊     | 242/500 [03:07<05:15,  1.22s/it] 49%|████▉     | 244/500 [03:07<03:45,  1.14it/s] 49%|████▉     | 246/500 [03:08<02:43,  1.56it/s] 50%|████▉     | 248/500 [03:08<01:59,  2.10it/s] 50%|█████     | 250/500 [03:08<01:29,  2.79it/s] 50%|█████     | 252/500 [03:14<05:01,  1.22s/it] 51%|█████     | 254/500 [03:15<03:34,  1.15it/s] 51%|█████     | 256/500 [03:15<02:33,  1.59it/s] 52%|█████▏    | 258/500 [03:15<01:51,  2.17it/s] 52%|█████▏    | 260/500 [03:15<01:22,  2.92it/s] 52%|█████▏    | 262/500 [03:21<04:43,  1.19s/it] 53%|█████▎    | 264/500 [03:21<03:22,  1.17it/s] 53%|█████▎    | 266/500 [03:22<02:26,  1.60it/s] 54%|█████▎    | 268/500 [03:22<01:46,  2.17it/s] 54%|█████▍    | 270/500 [03:22<01:18,  2.92it/s] 54%|█████▍    | 272/500 [03:28<04:36,  1.21s/it]Epoch:  206  	Training Loss: 0.0009386099991388619
Test Loss:  0.0006047568749636412
Valid Loss:  0.0007988172583281994
Epoch:  207  	Training Loss: 0.0009366664453409612
Test Loss:  0.0006039392901584506
Valid Loss:  0.0007970972801558673
Epoch:  208  	Training Loss: 0.0009347491431981325
Test Loss:  0.00060306052910164
Valid Loss:  0.0007954057073220611
Epoch:  209  	Training Loss: 0.0009328546584583819
Test Loss:  0.0006021731533110142
Valid Loss:  0.0007937360787764192
Epoch:  210  	Training Loss: 0.0009310016757808626
Test Loss:  0.0006014003301970661
Valid Loss:  0.0007921169162727892
Epoch:  211  	Training Loss: 0.0009292078902944922
Test Loss:  0.0006006197072565556
Valid Loss:  0.0007905157981440425
Epoch:  212  	Training Loss: 0.0009274326730519533
Test Loss:  0.0006010618526488543
Valid Loss:  0.0007901702192611992
Epoch:  213  	Training Loss: 0.0009267067653127015
Test Loss:  0.0006013657548464835
Valid Loss:  0.0007898580515757203
Epoch:  214  	Training Loss: 0.0009260265505872667
Test Loss:  0.0006015753606334329
Valid Loss:  0.0007895866292528808
Epoch:  215  	Training Loss: 0.0009253970929421484
Test Loss:  0.0006017199484631419
Valid Loss:  0.0007893397123552859
Epoch:  216  	Training Loss: 0.0009248046553693712
Test Loss:  0.0006018299609422684
Valid Loss:  0.0007891079294495285
Epoch:  217  	Training Loss: 0.0009242337546311319
Test Loss:  0.0006019129068590701
Valid Loss:  0.0007888874970376492
Epoch:  218  	Training Loss: 0.0009236835758201778
Test Loss:  0.0006019872380420566
Valid Loss:  0.0007886824896559119
Epoch:  219  	Training Loss: 0.0009231551666744053
Test Loss:  0.0006020516739226878
Valid Loss:  0.0007885153172537684
Epoch:  220  	Training Loss: 0.0009226547554135323
Test Loss:  0.0006021014996804297
Valid Loss:  0.0007883556536398828
Epoch:  221  	Training Loss: 0.0009221701184287667
Test Loss:  0.0006021432345733047
Valid Loss:  0.000788204837590456
Epoch:  222  	Training Loss: 0.0009217052720487118
Test Loss:  0.0006001876899972558
Valid Loss:  0.0007843227940611541
Epoch:  223  	Training Loss: 0.0009180658962577581
Test Loss:  0.0005981047288514674
Valid Loss:  0.0007810863316990435
Epoch:  224  	Training Loss: 0.0009150558616966009
Test Loss:  0.0005959355039522052
Valid Loss:  0.0007783101173117757
Epoch:  225  	Training Loss: 0.0009123490890488029
Test Loss:  0.0005938513204455376
Valid Loss:  0.0007757472922094166
Epoch:  226  	Training Loss: 0.000909774040337652
Test Loss:  0.0005921219126321375
Valid Loss:  0.0007734225364401937
Epoch:  227  	Training Loss: 0.0009073668625205755
Test Loss:  0.0005903808632865548
Valid Loss:  0.0007713690865784883
Epoch:  228  	Training Loss: 0.0009051894303411245
Test Loss:  0.000588851748034358
Valid Loss:  0.00076961365994066
Epoch:  229  	Training Loss: 0.0009032743400894105
Test Loss:  0.0005873813643120229
Valid Loss:  0.0007681665010750294
Epoch:  230  	Training Loss: 0.0009016302647069097
Test Loss:  0.000586023845244199
Valid Loss:  0.0007668915204703808
Epoch:  231  	Training Loss: 0.0009001473081298172
Test Loss:  0.0005850184243172407
Valid Loss:  0.0007656312081962824
Epoch:  232  	Training Loss: 0.0008987301262095571
Test Loss:  0.0005820877267979085
Valid Loss:  0.0007582508842460811
Epoch:  233  	Training Loss: 0.0008910647011362016
Test Loss:  0.0005766096874140203
Valid Loss:  0.0007520723156630993
Epoch:  234  	Training Loss: 0.0008844156982377172
Test Loss:  0.000571314012631774
Valid Loss:  0.0007466728566214442
Epoch:  235  	Training Loss: 0.0008784899255260825
Test Loss:  0.0005665420321747661
Valid Loss:  0.0007416270091198385
Epoch:  236  	Training Loss: 0.0008728259708732367
Test Loss:  0.0005620944430120289
Valid Loss:  0.0007367789512500167
Epoch:  237  	Training Loss: 0.0008673593401908875
Test Loss:  0.0005578231066465378
Valid Loss:  0.0007320670993067324
Epoch:  238  	Training Loss: 0.0008620881708338857
Test Loss:  0.000553652411326766
Valid Loss:  0.0007276451215147972
Epoch:  239  	Training Loss: 0.0008570136269554496
Test Loss:  0.0005498271202668548
Valid Loss:  0.0007233156356960535
Epoch:  240  	Training Loss: 0.0008520608535036445
Test Loss:  0.0005460310494527221
Valid Loss:  0.0007194011704996228
Epoch:  241  	Training Loss: 0.0008473789785057306
Test Loss:  0.0005413764738477767
Valid Loss:  0.0007149280281737447
Epoch:  242  	Training Loss: 0.0008427290013059974
Test Loss:  0.0005360518116503954
Valid Loss:  0.0007135358173400164
Epoch:  243  	Training Loss: 0.0008404696709476411
Test Loss:  0.000533715239726007
Valid Loss:  0.0007125079282559454
Epoch:  244  	Training Loss: 0.0008388588321395218
Test Loss:  0.0005324874073266983
Valid Loss:  0.0007115864427760243
Epoch:  245  	Training Loss: 0.0008374545723199844
Test Loss:  0.0005317113827914
Valid Loss:  0.000710726308170706
Epoch:  246  	Training Loss: 0.0008361469954252243
Test Loss:  0.000531274126842618
Valid Loss:  0.0007100171642377973
Epoch:  247  	Training Loss: 0.0008350160205736756
Test Loss:  0.0005310619599185884
Valid Loss:  0.0007093884632922709
Epoch:  248  	Training Loss: 0.0008339849882759154
Test Loss:  0.0005307953106239438
Valid Loss:  0.0007088367128744721
Epoch:  249  	Training Loss: 0.0008330267737619579
Test Loss:  0.0005307098617777228
Valid Loss:  0.0007083225063979626
Epoch:  250  	Training Loss: 0.0008321609348058701
Test Loss:  0.0005307123064994812
Valid Loss:  0.00070784060517326
Epoch:  251  	Training Loss: 0.0008313496946357191
Test Loss:  0.0005306396633386612
Valid Loss:  0.0007073947926983237
Epoch:  252  	Training Loss: 0.0008305947412736714
Test Loss:  0.0005331154679879546
Valid Loss:  0.0007067923434078693
Epoch:  253  	Training Loss: 0.0008288479875773191
Test Loss:  0.0005336918402463198
Valid Loss:  0.0007066680118441582
Epoch:  254  	Training Loss: 0.0008276384323835373
Test Loss:  0.0005339026683941483
Valid Loss:  0.0007066740654408932
Epoch:  255  	Training Loss: 0.0008266351651400328
Test Loss:  0.0005339730996638536
Valid Loss:  0.0007067942642606795
Epoch:  256  	Training Loss: 0.0008258434245362878
Test Loss:  0.0005340788047760725
Valid Loss:  0.0007069743587635458
Epoch:  257  	Training Loss: 0.000825179333332926
Test Loss:  0.0005342314834706485
Valid Loss:  0.0007071693544276059
Epoch:  258  	Training Loss: 0.0008246013894677162
Test Loss:  0.0005344223463907838
Valid Loss:  0.000707385828718543
Epoch:  259  	Training Loss: 0.0008240945171564817
Test Loss:  0.000534622638951987
Valid Loss:  0.0007076088804751635
Epoch:  260  	Training Loss: 0.0008236513240262866
Test Loss:  0.0005348140839487314
Valid Loss:  0.0007078305352479219
Epoch:  261  	Training Loss: 0.0008232663967646658
Test Loss:  0.0005350129795260727
Valid Loss:  0.0007080453797243536
Epoch:  262  	Training Loss: 0.0008229295490309596
Test Loss:  0.0005333927692845464
Valid Loss:  0.0007001013145782053
Epoch:  263  	Training Loss: 0.0008163831662386656
Test Loss:  0.0005274006398394704
Valid Loss:  0.0006946335197426379
Epoch:  264  	Training Loss: 0.000811296864412725
Test Loss:  0.0005219662562012672
Valid Loss:  0.0006898854626342654
Epoch:  265  	Training Loss: 0.000806770462077111
Test Loss:  0.0005172932287678123
Valid Loss:  0.0006858592387288809
Epoch:  266  	Training Loss: 0.0008026240393519402
Test Loss:  0.0005133189843036234
Valid Loss:  0.0006821226561442018
Epoch:  267  	Training Loss: 0.0007987190037965775
Test Loss:  0.0005096938693895936
Valid Loss:  0.0006786327576264739
Epoch:  268  	Training Loss: 0.0007950280560180545
Test Loss:  0.0005064306315034628
Valid Loss:  0.0006753536872565746
Epoch:  269  	Training Loss: 0.0007915091118775308
Test Loss:  0.0005033849738538265
Valid Loss:  0.0006722297985106707
Epoch:  270  	Training Loss: 0.0007881563506089151
Test Loss:  0.0005004951963201165
Valid Loss:  0.0006693057948723435
Epoch:  271  	Training Loss: 0.0007849666872061789
Test Loss:  0.000497842556796968
Valid Loss:  0.0006664820248261094
Epoch:  272  	Training Loss: 0.0007818695157766342
Test Loss:  0.0004952565650455654
Valid Loss:  0.0006659855134785175
Epoch:  273  	Training Loss: 0.00078050815500319
Test Loss:  0.000493308063596487
Valid Loss:  0.0006654969183728099
Epoch:  274  	Training Loss: 0.000779329682700336
 55%|█████▍    | 274/500 [03:28<03:16,  1.15it/s] 55%|█████▌    | 276/500 [03:29<02:20,  1.59it/s] 56%|█████▌    | 278/500 [03:29<01:42,  2.18it/s] 56%|█████▌    | 280/500 [03:29<01:15,  2.93it/s] 56%|█████▋    | 282/500 [03:35<04:19,  1.19s/it] 57%|█████▋    | 284/500 [03:35<03:03,  1.17it/s] 57%|█████▋    | 286/500 [03:35<02:11,  1.63it/s] 58%|█████▊    | 288/500 [03:36<01:35,  2.22it/s] 58%|█████▊    | 290/500 [03:36<01:10,  2.99it/s] 58%|█████▊    | 292/500 [03:42<04:06,  1.19s/it] 59%|█████▉    | 294/500 [03:42<02:55,  1.18it/s] 59%|█████▉    | 296/500 [03:42<02:05,  1.63it/s] 60%|█████▉    | 298/500 [03:42<01:30,  2.22it/s] 60%|██████    | 300/500 [03:43<01:06,  2.99it/s] 60%|██████    | 302/500 [03:49<04:01,  1.22s/it] 61%|██████    | 304/500 [03:49<02:51,  1.14it/s] 61%|██████    | 306/500 [03:49<02:02,  1.58it/s] 62%|██████▏   | 308/500 [03:50<01:28,  2.16it/s] 62%|██████▏   | 310/500 [03:50<01:05,  2.91it/s] 62%|██████▏   | 312/500 [03:56<03:46,  1.20s/it] 63%|██████▎   | 314/500 [03:56<02:40,  1.16it/s] 63%|██████▎   | 316/500 [03:56<01:54,  1.60it/s] 64%|██████▎   | 318/500 [03:57<01:22,  2.19it/s] 64%|██████▍   | 320/500 [03:57<01:00,  2.95it/s] 64%|██████▍   | 322/500 [04:03<03:29,  1.18s/it] 65%|██████▍   | 324/500 [04:03<02:28,  1.18it/s] 65%|██████▌   | 326/500 [04:03<01:46,  1.63it/s] 66%|██████▌   | 328/500 [04:03<01:18,  2.20it/s] 66%|██████▌   | 330/500 [04:04<00:58,  2.91it/s] 66%|██████▋   | 332/500 [04:10<03:22,  1.21s/it] 67%|██████▋   | 334/500 [04:10<02:23,  1.16it/s] 67%|██████▋   | 336/500 [04:10<01:42,  1.60it/s] 68%|██████▊   | 338/500 [04:10<01:13,  2.19it/s] 68%|██████▊   | 340/500 [04:11<00:54,  2.93it/s]Test Loss:  0.0004934066091664135
Valid Loss:  0.0006650822469964623
Epoch:  275  	Training Loss: 0.0007781866588629782
Test Loss:  0.0004911519936285913
Valid Loss:  0.000664589402731508
Epoch:  276  	Training Loss: 0.0007772052194923162
Test Loss:  0.0004921512445434928
Valid Loss:  0.0006640058709308505
Epoch:  277  	Training Loss: 0.000776090775616467
Test Loss:  0.0004919302300550044
Valid Loss:  0.0006637650658376515
Epoch:  278  	Training Loss: 0.0007751521188765764
Test Loss:  0.0004897171747870743
Valid Loss:  0.0006633208831772208
Epoch:  279  	Training Loss: 0.0007742828456684947
Test Loss:  0.0004907557740807533
Valid Loss:  0.0006628038245253265
Epoch:  280  	Training Loss: 0.0007732948288321495
Test Loss:  0.0004906467511318624
Valid Loss:  0.0006626560352742672
Epoch:  281  	Training Loss: 0.0007724590832367539
Test Loss:  0.0004885997623205185
Valid Loss:  0.00066230574157089
Epoch:  282  	Training Loss: 0.000771674676798284
Test Loss:  0.0004871378478128463
Valid Loss:  0.0006585413939319551
Epoch:  283  	Training Loss: 0.0007684198790229857
Test Loss:  0.0004849611723329872
Valid Loss:  0.0006551134865731001
Epoch:  284  	Training Loss: 0.0007653150823898613
Test Loss:  0.0004825288779102266
Valid Loss:  0.0006518989102914929
Epoch:  285  	Training Loss: 0.0007623026613146067
Test Loss:  0.00048001809045672417
Valid Loss:  0.0006487761274911463
Epoch:  286  	Training Loss: 0.0007593505433760583
Test Loss:  0.00047753454418852925
Valid Loss:  0.0006457351264543831
Epoch:  287  	Training Loss: 0.0007564635016024113
Test Loss:  0.0004750902589876205
Valid Loss:  0.0006427521584555507
Epoch:  288  	Training Loss: 0.0007536200573667884
Test Loss:  0.00047270592767745256
Valid Loss:  0.000639832578599453
Epoch:  289  	Training Loss: 0.000750840874388814
Test Loss:  0.0004703652230091393
Valid Loss:  0.0006369599141180515
Epoch:  290  	Training Loss: 0.0007480978965759277
Test Loss:  0.00046807058970443904
Valid Loss:  0.0006341304397210479
Epoch:  291  	Training Loss: 0.000745388853829354
Test Loss:  0.0004658206889871508
Valid Loss:  0.0006313400808721781
Epoch:  292  	Training Loss: 0.0007427181117236614
Test Loss:  0.0004664905136451125
Valid Loss:  0.0006300964159891009
Epoch:  293  	Training Loss: 0.0007413647836074233
Test Loss:  0.00046643076348118484
Valid Loss:  0.0006290794699452817
Epoch:  294  	Training Loss: 0.0007401277543976903
Test Loss:  0.00046606932301074266
Valid Loss:  0.0006281309179030359
Epoch:  295  	Training Loss: 0.0007389138918370008
Test Loss:  0.00046558171743527055
Valid Loss:  0.0006272486643865705
Epoch:  296  	Training Loss: 0.0007377113215625286
Test Loss:  0.00046504143392667174
Valid Loss:  0.0006264210096560419
Epoch:  297  	Training Loss: 0.0007365327328443527
Test Loss:  0.00046446971828117967
Valid Loss:  0.0006256308406591415
Epoch:  298  	Training Loss: 0.0007353625842370093
Test Loss:  0.000463890319224447
Valid Loss:  0.0006248540594242513
Epoch:  299  	Training Loss: 0.0007342099561356008
Test Loss:  0.00046332553029060364
Valid Loss:  0.0006240917718969285
Epoch:  300  	Training Loss: 0.0007330827647820115
Test Loss:  0.00046269508311524987
Valid Loss:  0.0006233615567907691
Epoch:  301  	Training Loss: 0.0007319780415855348
Test Loss:  0.0004621177213266492
Valid Loss:  0.0006226396653801203
Epoch:  302  	Training Loss: 0.0007308993954211473
Test Loss:  0.0004619095998350531
Valid Loss:  0.0006219468195922673
Epoch:  303  	Training Loss: 0.0007298795972019434
Test Loss:  0.00046159891644492745
Valid Loss:  0.0006212783046066761
Epoch:  304  	Training Loss: 0.0007288774359039962
Test Loss:  0.00046124105574563146
Valid Loss:  0.0006206179969012737
Epoch:  305  	Training Loss: 0.0007278838311322033
Test Loss:  0.0004608670133166015
Valid Loss:  0.000619961298070848
Epoch:  306  	Training Loss: 0.0007269096677191556
Test Loss:  0.00046048976946622133
Valid Loss:  0.0006193236913532019
Epoch:  307  	Training Loss: 0.0007259661215357482
Test Loss:  0.0004601176187861711
Valid Loss:  0.0006186985410749912
Epoch:  308  	Training Loss: 0.0007250409689731896
Test Loss:  0.00045975431567057967
Valid Loss:  0.0006180757191032171
Epoch:  309  	Training Loss: 0.0007241212297230959
Test Loss:  0.00045940285781398416
Valid Loss:  0.000617454235907644
Epoch:  310  	Training Loss: 0.0007232059724628925
Test Loss:  0.0004590566677507013
Valid Loss:  0.0006168533000163734
Epoch:  311  	Training Loss: 0.0007223032880574465
Test Loss:  0.0004587146104313433
Valid Loss:  0.0006162763456813991
Epoch:  312  	Training Loss: 0.0007214169017970562
Test Loss:  0.0004555644700303674
Valid Loss:  0.0006153097492642701
Epoch:  313  	Training Loss: 0.0007191261975094676
Test Loss:  0.0004543543327599764
Valid Loss:  0.000614533550105989
Epoch:  314  	Training Loss: 0.0007173025514930487
Test Loss:  0.00045367720304057
Valid Loss:  0.0006139369215816259
Epoch:  315  	Training Loss: 0.000715730944648385
Test Loss:  0.00045323686208575964
Valid Loss:  0.0006134246941655874
Epoch:  316  	Training Loss: 0.0007142795366235077
Test Loss:  0.00045294585288502276
Valid Loss:  0.0006129874964244664
Epoch:  317  	Training Loss: 0.0007129613077268004
Test Loss:  0.00045268068788573146
Valid Loss:  0.0006126706721261144
Epoch:  318  	Training Loss: 0.0007117915665730834
Test Loss:  0.00045249934191815555
Valid Loss:  0.0006124074570834637
Epoch:  319  	Training Loss: 0.0007107351557351649
Test Loss:  0.0004523739335127175
Valid Loss:  0.0006124484352767467
Epoch:  320  	Training Loss: 0.0007099176291376352
Test Loss:  0.0004514726169873029
Valid Loss:  0.000611956580542028
Epoch:  321  	Training Loss: 0.0007091022562235594
Test Loss:  0.0004519759677350521
Valid Loss:  0.000611961935646832
Epoch:  322  	Training Loss: 0.0007083835080265999
Test Loss:  0.00044915638864040375
Valid Loss:  0.0006064999615773559
Epoch:  323  	Training Loss: 0.0007026100065559149
Test Loss:  0.0004456471069715917
Valid Loss:  0.0006024597678333521
Epoch:  324  	Training Loss: 0.0006985618965700269
Test Loss:  0.0004421332268975675
Valid Loss:  0.0005990057252347469
Epoch:  325  	Training Loss: 0.000694985268637538
Test Loss:  0.0004391530528664589
Valid Loss:  0.0005959182744845748
Epoch:  326  	Training Loss: 0.000691684428602457
Test Loss:  0.0004364260530564934
Valid Loss:  0.0005931221530772746
Epoch:  327  	Training Loss: 0.0006886604242026806
Test Loss:  0.00043406954500824213
Valid Loss:  0.0005905358702875674
Epoch:  328  	Training Loss: 0.0006858367123641074
Test Loss:  0.00043189318967051804
Valid Loss:  0.0005880569224245846
Epoch:  329  	Training Loss: 0.0006831215578131378
Test Loss:  0.00042982626473531127
Valid Loss:  0.00058571039699018
Epoch:  330  	Training Loss: 0.0006804707809351385
Test Loss:  0.0004278299165889621
Valid Loss:  0.0005834918702021241
Epoch:  331  	Training Loss: 0.0006778883980587125
Test Loss:  0.00042595542618073523
Valid Loss:  0.0005813913885504007
Epoch:  332  	Training Loss: 0.0006753982743248343
Test Loss:  0.00042359932558611035
Valid Loss:  0.0005801583174616098
Epoch:  333  	Training Loss: 0.0006736378418281674
Test Loss:  0.0004229822661727667
Valid Loss:  0.0005791619187220931
Epoch:  334  	Training Loss: 0.0006721234531141818
Test Loss:  0.0004223184078000486
Valid Loss:  0.0005781844956800342
Epoch:  335  	Training Loss: 0.000670652836561203
Test Loss:  0.00042165513150393963
Valid Loss:  0.0005772404256276786
Epoch:  336  	Training Loss: 0.0006692539318464696
Test Loss:  0.00042098737321794033
Valid Loss:  0.0005763485096395016
Epoch:  337  	Training Loss: 0.0006679217331111431
Test Loss:  0.00042031865450553596
Valid Loss:  0.0005754688754677773
Epoch:  338  	Training Loss: 0.0006666306289844215
Test Loss:  0.0004196260997559875
Valid Loss:  0.0005745997186750174
Epoch:  339  	Training Loss: 0.0006653806194663048
Test Loss:  0.00041894230525940657
Valid Loss:  0.0005737504689022899
Epoch:  340  	Training Loss: 0.0006641654763370752
Test Loss:  0.0004183381097391248
Valid Loss:  0.0005729092517867684
Epoch:  341  	Training Loss: 0.000662987120449543
Test Loss:  0.0004177137743681669
Valid Loss:  0.0005721071502193809
Epoch:  342  	Training Loss: 0.0006618741317652166
Test Loss:   68%|██████▊   | 342/500 [04:17<03:09,  1.20s/it] 69%|██████▉   | 344/500 [04:17<02:14,  1.16it/s] 69%|██████▉   | 346/500 [04:17<01:35,  1.60it/s] 70%|██████▉   | 348/500 [04:17<01:09,  2.19it/s] 70%|███████   | 350/500 [04:17<00:51,  2.90it/s] 70%|███████   | 352/500 [04:24<03:01,  1.23s/it] 71%|███████   | 354/500 [04:24<02:09,  1.13it/s] 71%|███████   | 356/500 [04:24<01:32,  1.56it/s] 72%|███████▏  | 358/500 [04:25<01:06,  2.14it/s] 72%|███████▏  | 360/500 [04:25<00:48,  2.89it/s] 72%|███████▏  | 362/500 [04:31<02:47,  1.21s/it] 73%|███████▎  | 364/500 [04:31<01:57,  1.15it/s] 73%|███████▎  | 366/500 [04:31<01:24,  1.59it/s] 74%|███████▎  | 368/500 [04:32<01:01,  2.15it/s] 74%|███████▍  | 370/500 [04:32<00:45,  2.86it/s] 74%|███████▍  | 372/500 [04:38<02:34,  1.21s/it] 75%|███████▍  | 374/500 [04:38<01:49,  1.15it/s] 75%|███████▌  | 376/500 [04:38<01:18,  1.57it/s] 76%|███████▌  | 378/500 [04:39<00:57,  2.12it/s] 76%|███████▌  | 380/500 [04:39<00:42,  2.81it/s] 76%|███████▋  | 382/500 [04:45<02:27,  1.25s/it] 77%|███████▋  | 384/500 [04:46<01:43,  1.12it/s] 77%|███████▋  | 386/500 [04:46<01:13,  1.55it/s] 78%|███████▊  | 388/500 [04:46<00:52,  2.11it/s] 78%|███████▊  | 390/500 [04:46<00:38,  2.85it/s] 78%|███████▊  | 392/500 [04:53<02:12,  1.23s/it] 79%|███████▉  | 394/500 [04:53<01:33,  1.13it/s] 79%|███████▉  | 396/500 [04:53<01:06,  1.55it/s] 80%|███████▉  | 398/500 [04:53<00:48,  2.10it/s] 80%|████████  | 400/500 [04:53<00:35,  2.79it/s] 80%|████████  | 402/500 [05:00<02:00,  1.23s/it] 81%|████████  | 404/500 [05:00<01:24,  1.14it/s] 81%|████████  | 406/500 [05:00<00:59,  1.57it/s] 82%|████████▏ | 408/500 [05:00<00:42,  2.15it/s]0.00041545528802089393
Valid Loss:  0.0005709542892873287
Epoch:  343  	Training Loss: 0.0006604247028008103
Test Loss:  0.000414064183132723
Valid Loss:  0.000569865689612925
Epoch:  344  	Training Loss: 0.0006590949487872422
Test Loss:  0.0004130768938921392
Valid Loss:  0.0005688084638677537
Epoch:  345  	Training Loss: 0.0006578300381079316
Test Loss:  0.0004122998798266053
Valid Loss:  0.0005677812732756138
Epoch:  346  	Training Loss: 0.0006566156516782939
Test Loss:  0.0004116403579246253
Valid Loss:  0.0005667842924594879
Epoch:  347  	Training Loss: 0.0006554463761858642
Test Loss:  0.00041105085983872414
Valid Loss:  0.0005658179288730025
Epoch:  348  	Training Loss: 0.0006543199415318668
Test Loss:  0.00041050929576158524
Valid Loss:  0.0005648811929859221
Epoch:  349  	Training Loss: 0.0006532333791255951
Test Loss:  0.00041000329656526446
Valid Loss:  0.0005639728624373674
Epoch:  350  	Training Loss: 0.0006521902978420258
Test Loss:  0.0004095343465451151
Valid Loss:  0.0005631030071526766
Epoch:  351  	Training Loss: 0.0006511968676932156
Test Loss:  0.0004090841975994408
Valid Loss:  0.0005622596945613623
Epoch:  352  	Training Loss: 0.0006502381293103099
Test Loss:  0.00040963239734992385
Valid Loss:  0.0005608777864836156
Epoch:  353  	Training Loss: 0.0006480637239292264
Test Loss:  0.0004092826275154948
Valid Loss:  0.0005595404654741287
Epoch:  354  	Training Loss: 0.0006461515440605581
Test Loss:  0.00040868460200726986
Valid Loss:  0.0005582661251537502
Epoch:  355  	Training Loss: 0.0006444248137995601
Test Loss:  0.0004080217913724482
Valid Loss:  0.0005570446373894811
Epoch:  356  	Training Loss: 0.000642849481664598
Test Loss:  0.00040740202530287206
Valid Loss:  0.0005559098208323121
Epoch:  357  	Training Loss: 0.0006414352683350444
Test Loss:  0.00040680920938029885
Valid Loss:  0.000554855854716152
Epoch:  358  	Training Loss: 0.0006401337450370193
Test Loss:  0.0004062409861944616
Valid Loss:  0.0005538382101804018
Epoch:  359  	Training Loss: 0.0006389250047504902
Test Loss:  0.00040572319994680583
Valid Loss:  0.0005528628826141357
Epoch:  360  	Training Loss: 0.0006378015968948603
Test Loss:  0.0004052279982715845
Valid Loss:  0.0005519178230315447
Epoch:  361  	Training Loss: 0.0006367484456859529
Test Loss:  0.00040475482819601893
Valid Loss:  0.0005510266637429595
Epoch:  362  	Training Loss: 0.0006357597885653377
Test Loss:  0.0004040277563035488
Valid Loss:  0.0005451496690511703
Epoch:  363  	Training Loss: 0.0006308407755568624
Test Loss:  0.00040028151124715805
Valid Loss:  0.0005406853160820901
Epoch:  364  	Training Loss: 0.0006271718302741647
Test Loss:  0.0003970531979575753
Valid Loss:  0.0005370466969907284
Epoch:  365  	Training Loss: 0.0006239977665245533
Test Loss:  0.0003943347546737641
Valid Loss:  0.0005339570925571024
Epoch:  366  	Training Loss: 0.0006211132276803255
Test Loss:  0.0003919677692465484
Valid Loss:  0.0005312347784638405
Epoch:  367  	Training Loss: 0.0006184019148349762
Test Loss:  0.00038984508137218654
Valid Loss:  0.0005287652602419257
Epoch:  368  	Training Loss: 0.0006158044561743736
Test Loss:  0.0003878684074152261
Valid Loss:  0.0005264806095510721
Epoch:  369  	Training Loss: 0.0006132804555818439
Test Loss:  0.0003860399010591209
Valid Loss:  0.0005243195337243378
Epoch:  370  	Training Loss: 0.0006108005181886256
Test Loss:  0.00038430170388892293
Valid Loss:  0.0005222483887337148
Epoch:  371  	Training Loss: 0.0006083522457629442
Test Loss:  0.00038263018359430134
Valid Loss:  0.000520244357176125
Epoch:  372  	Training Loss: 0.0006059299339540303
Test Loss:  0.0003806925087701529
Valid Loss:  0.0005197469145059586
Epoch:  373  	Training Loss: 0.0006046977359801531
Test Loss:  0.00037951674312353134
Valid Loss:  0.0005193472607061267
Epoch:  374  	Training Loss: 0.0006037430721335113
Test Loss:  0.0003793989308178425
Valid Loss:  0.0005191998789086938
Epoch:  375  	Training Loss: 0.0006028930656611919
Test Loss:  0.00037891778629273176
Valid Loss:  0.0005189599469304085
Epoch:  376  	Training Loss: 0.0006021619192324579
Test Loss:  0.0003790777991525829
Valid Loss:  0.0005189471994526684
Epoch:  377  	Training Loss: 0.0006014961982145905
Test Loss:  0.0003785444423556328
Valid Loss:  0.0005186755442991853
Epoch:  378  	Training Loss: 0.0006008984055370092
Test Loss:  0.0003788985777646303
Valid Loss:  0.0005186368944123387
Epoch:  379  	Training Loss: 0.0006003236630931497
Test Loss:  0.0003790209302678704
Valid Loss:  0.000518632703460753
Epoch:  380  	Training Loss: 0.0005998315755277872
Test Loss:  0.00037867261562496424
Valid Loss:  0.0005184479523450136
Epoch:  381  	Training Loss: 0.0005993773811496794
Test Loss:  0.0003789119655266404
Valid Loss:  0.0005184190813452005
Epoch:  382  	Training Loss: 0.0005989468190819025
Test Loss:  0.0003778364625759423
Valid Loss:  0.0005149960634298623
Epoch:  383  	Training Loss: 0.0005958122783340514
Test Loss:  0.0003754977078642696
Valid Loss:  0.0005122621078044176
Epoch:  384  	Training Loss: 0.0005931338528171182
Test Loss:  0.00037328305188566446
Valid Loss:  0.0005098764086142182
Epoch:  385  	Training Loss: 0.0005906964652240276
Test Loss:  0.00037131307180970907
Valid Loss:  0.0005077383830212057
Epoch:  386  	Training Loss: 0.0005885164719074965
Test Loss:  0.0003695175109896809
Valid Loss:  0.0005057626985944808
Epoch:  387  	Training Loss: 0.0005864516133442521
Test Loss:  0.000367891596397385
Valid Loss:  0.0005039103562012315
Epoch:  388  	Training Loss: 0.0005844680708833039
Test Loss:  0.0003663948446046561
Valid Loss:  0.000502138223964721
Epoch:  389  	Training Loss: 0.0005825270782224834
Test Loss:  0.00036494972300715744
Valid Loss:  0.0005004400154575706
Epoch:  390  	Training Loss: 0.0005806208355352283
Test Loss:  0.00036362107493914664
Valid Loss:  0.0004987595020793378
Epoch:  391  	Training Loss: 0.0005787286208942533
Test Loss:  0.00036234233994036913
Valid Loss:  0.0004971009911969304
Epoch:  392  	Training Loss: 0.000576855381950736
Test Loss:  0.0003602169454097748
Valid Loss:  0.0004951271694153547
Epoch:  393  	Training Loss: 0.0005745962262153625
Test Loss:  0.00035905325785279274
Valid Loss:  0.0004938133060932159
Epoch:  394  	Training Loss: 0.0005727674579247832
Test Loss:  0.0003581793571356684
Valid Loss:  0.0004929087590426207
Epoch:  395  	Training Loss: 0.0005711071426048875
Test Loss:  0.0003574989386834204
Valid Loss:  0.0004922148073092103
Epoch:  396  	Training Loss: 0.0005696406587958336
Test Loss:  0.0003571192210074514
Valid Loss:  0.0004916376783512533
Epoch:  397  	Training Loss: 0.0005684364587068558
Test Loss:  0.00035678897984325886
Valid Loss:  0.0004911206779070199
Epoch:  398  	Training Loss: 0.0005673635751008987
Test Loss:  0.0003564605722203851
Valid Loss:  0.0004906428512185812
Epoch:  399  	Training Loss: 0.0005663850461132824
Test Loss:  0.00035612977808341384
Valid Loss:  0.0004901852225884795
Epoch:  400  	Training Loss: 0.0005654500564560294
Test Loss:  0.00035579176619648933
Valid Loss:  0.0004897536127828062
Epoch:  401  	Training Loss: 0.0005645569181069732
Test Loss:  0.0003554468275979161
Valid Loss:  0.000489349418785423
Epoch:  402  	Training Loss: 0.0005637104623019695
Test Loss:  0.00035559438401833177
Valid Loss:  0.00048675149446353316
Epoch:  403  	Training Loss: 0.0005610187654383481
Test Loss:  0.0003544441715348512
Valid Loss:  0.0004844175127800554
Epoch:  404  	Training Loss: 0.0005586320767179132
Test Loss:  0.00035289250081405044
Valid Loss:  0.0004822108894586563
Epoch:  405  	Training Loss: 0.0005563374143093824
Test Loss:  0.0003513003175612539
Valid Loss:  0.0004801151517312974
Epoch:  406  	Training Loss: 0.0005540938582271338
Test Loss:  0.00034971704008057714
Valid Loss:  0.00047809831448830664
Epoch:  407  	Training Loss: 0.0005518833640962839
Test Loss:  0.00034817427513189614
Valid Loss:  0.00047614489449188113
Epoch:  408  	Training Loss: 0.0005496988305822015
Test Loss:  0.0003466767957434058
Valid Loss:  0.0004742440360132605
Epoch:  409  	Training Loss: 0.0005475356010720134
Test Loss:  0.0003452154924161732
Valid Loss:  0.0004723850579466671
Epoch:  410  	Training Loss: 0.0005453905905596912
Test Loss:   82%|████████▏ | 410/500 [05:00<00:31,  2.90it/s] 82%|████████▏ | 412/500 [05:07<01:46,  1.21s/it] 83%|████████▎ | 414/500 [05:07<01:14,  1.15it/s] 83%|████████▎ | 416/500 [05:07<00:52,  1.59it/s] 84%|████████▎ | 418/500 [05:07<00:38,  2.15it/s] 84%|████████▍ | 420/500 [05:07<00:28,  2.84it/s] 84%|████████▍ | 422/500 [05:14<01:32,  1.19s/it] 85%|████████▍ | 424/500 [05:14<01:04,  1.17it/s] 85%|████████▌ | 426/500 [05:14<00:46,  1.60it/s] 86%|████████▌ | 428/500 [05:14<00:33,  2.16it/s] 86%|████████▌ | 430/500 [05:14<00:24,  2.86it/s] 86%|████████▋ | 432/500 [05:21<01:22,  1.21s/it] 87%|████████▋ | 434/500 [05:21<00:57,  1.16it/s] 87%|████████▋ | 436/500 [05:21<00:40,  1.60it/s] 88%|████████▊ | 438/500 [05:21<00:28,  2.19it/s] 88%|████████▊ | 440/500 [05:21<00:20,  2.95it/s] 88%|████████▊ | 442/500 [05:28<01:10,  1.21s/it] 89%|████████▉ | 444/500 [05:28<00:48,  1.16it/s] 89%|████████▉ | 446/500 [05:28<00:33,  1.60it/s] 90%|████████▉ | 448/500 [05:28<00:23,  2.18it/s] 90%|█████████ | 450/500 [05:28<00:17,  2.94it/s] 90%|█████████ | 452/500 [05:35<00:58,  1.21s/it] 91%|█████████ | 454/500 [05:35<00:39,  1.15it/s] 91%|█████████ | 456/500 [05:35<00:27,  1.59it/s] 92%|█████████▏| 458/500 [05:35<00:19,  2.18it/s] 92%|█████████▏| 460/500 [05:35<00:13,  2.93it/s] 92%|█████████▏| 462/500 [05:42<00:45,  1.20s/it] 93%|█████████▎| 464/500 [05:42<00:30,  1.16it/s] 93%|█████████▎| 466/500 [05:42<00:21,  1.61it/s] 94%|█████████▎| 468/500 [05:42<00:14,  2.20it/s] 94%|█████████▍| 470/500 [05:42<00:10,  2.96it/s] 94%|█████████▍| 472/500 [05:49<00:33,  1.20s/it] 95%|█████████▍| 474/500 [05:49<00:22,  1.16it/s] 95%|█████████▌| 476/500 [05:49<00:14,  1.61it/s]0.0003437904524616897
Valid Loss:  0.00047056065523065627
Epoch:  411  	Training Loss: 0.0005432621110230684
Test Loss:  0.00034236686769872904
Valid Loss:  0.000468757760245353
Epoch:  412  	Training Loss: 0.000541148183401674
Test Loss:  0.0003385569725651294
Valid Loss:  0.00046670978190377355
Epoch:  413  	Training Loss: 0.0005387533456087112
Test Loss:  0.00033685044036246836
Valid Loss:  0.00046495874994434416
Epoch:  414  	Training Loss: 0.0005366214318200946
Test Loss:  0.000335585733409971
Valid Loss:  0.0004632592899724841
Epoch:  415  	Training Loss: 0.0005345597746782005
Test Loss:  0.0003344258002471179
Valid Loss:  0.0004615891957655549
Epoch:  416  	Training Loss: 0.0005325492238625884
Test Loss:  0.00033330213045701385
Valid Loss:  0.0004599547537509352
Epoch:  417  	Training Loss: 0.0005305831436999142
Test Loss:  0.000332186056766659
Valid Loss:  0.0004583574482239783
Epoch:  418  	Training Loss: 0.0005286644445732236
Test Loss:  0.0003310682950541377
Valid Loss:  0.0004568207950796932
Epoch:  419  	Training Loss: 0.0005268325912766159
Test Loss:  0.00033003228600136936
Valid Loss:  0.00045531417708843946
Epoch:  420  	Training Loss: 0.0005250507383607328
Test Loss:  0.00032903748797252774
Valid Loss:  0.0004538154462352395
Epoch:  421  	Training Loss: 0.0005233011906966567
Test Loss:  0.00032808605465106666
Valid Loss:  0.00045233918353915215
Epoch:  422  	Training Loss: 0.000521584355738014
Test Loss:  0.00032703415490686893
Valid Loss:  0.00044898714986629784
Epoch:  423  	Training Loss: 0.0005186436465010047
Test Loss:  0.0003247188578825444
Valid Loss:  0.0004461950738914311
Epoch:  424  	Training Loss: 0.0005161083536222577
Test Loss:  0.0003224471875000745
Valid Loss:  0.0004436550661921501
Epoch:  425  	Training Loss: 0.000513724866323173
Test Loss:  0.00032037083292379975
Valid Loss:  0.0004412953567225486
Epoch:  426  	Training Loss: 0.0005114430096000433
Test Loss:  0.0003184853121638298
Valid Loss:  0.00043907936196774244
Epoch:  427  	Training Loss: 0.0005092419451102614
Test Loss:  0.0003167459217365831
Valid Loss:  0.0004369714006315917
Epoch:  428  	Training Loss: 0.0005070967599749565
Test Loss:  0.0003151204145979136
Valid Loss:  0.00043494795681908727
Epoch:  429  	Training Loss: 0.0005049905739724636
Test Loss:  0.0003135742445010692
Valid Loss:  0.0004329853691160679
Epoch:  430  	Training Loss: 0.0005029125604778528
Test Loss:  0.00031209306325763464
Valid Loss:  0.00043107219971716404
Epoch:  431  	Training Loss: 0.0005008596926927567
Test Loss:  0.00031067983945831656
Valid Loss:  0.0004292078083381057
Epoch:  432  	Training Loss: 0.0004988281289115548
Test Loss:  0.00030953658279031515
Valid Loss:  0.00042817473877221346
Epoch:  433  	Training Loss: 0.0004969693254679441
Test Loss:  0.00030885793967172503
Valid Loss:  0.00042732618749141693
Epoch:  434  	Training Loss: 0.0004953223979100585
Test Loss:  0.0003083758056163788
Valid Loss:  0.00042659672908484936
Epoch:  435  	Training Loss: 0.0004938537604175508
Test Loss:  0.0003080014721490443
Valid Loss:  0.0004259562701918185
Epoch:  436  	Training Loss: 0.0004925389075651765
Test Loss:  0.0003076998400501907
Valid Loss:  0.00042542812298052013
Epoch:  437  	Training Loss: 0.0004913770244456828
Test Loss:  0.00030714855529367924
Valid Loss:  0.00042478617979213595
Epoch:  438  	Training Loss: 0.0004903459339402616
Test Loss:  0.0003068288788199425
Valid Loss:  0.0004242460709065199
Epoch:  439  	Training Loss: 0.0004894193261861801
Test Loss:  0.0003068915684707463
Valid Loss:  0.00042391367605887353
Epoch:  440  	Training Loss: 0.0004885587841272354
Test Loss:  0.00030634846189059317
Valid Loss:  0.0004233021754771471
Epoch:  441  	Training Loss: 0.0004877699539065361
Test Loss:  0.00030651051201857626
Valid Loss:  0.00042298686457797885
Epoch:  442  	Training Loss: 0.00048701948253437877
Test Loss:  0.00030683609656989574
Valid Loss:  0.00042242405470460653
Epoch:  443  	Training Loss: 0.00048584103933535516
Test Loss:  0.00030636880546808243
Valid Loss:  0.00042183627374470234
Epoch:  444  	Training Loss: 0.0004847916425205767
Test Loss:  0.00030589086236432195
Valid Loss:  0.00042125722393393517
Epoch:  445  	Training Loss: 0.0004837962915189564
Test Loss:  0.00030549883376806974
Valid Loss:  0.00042071175994351506
Epoch:  446  	Training Loss: 0.00048285574303008616
Test Loss:  0.00030518556013703346
Valid Loss:  0.00042020820546895266
Epoch:  447  	Training Loss: 0.0004819865571334958
Test Loss:  0.0003048153594136238
Valid Loss:  0.0004197817179374397
Epoch:  448  	Training Loss: 0.0004811747057829052
Test Loss:  0.00030456320382654667
Valid Loss:  0.00041937740752473474
Epoch:  449  	Training Loss: 0.00048043299466371536
Test Loss:  0.00030435065855272114
Valid Loss:  0.00041905278339982033
Epoch:  450  	Training Loss: 0.0004798053705599159
Test Loss:  0.0003041813615709543
Valid Loss:  0.00041878671618178487
Epoch:  451  	Training Loss: 0.0004792632535099983
Test Loss:  0.00030407909071072936
Valid Loss:  0.0004185422440059483
Epoch:  452  	Training Loss: 0.000478780159028247
Test Loss:  0.000303199834888801
Valid Loss:  0.00041497230995446444
Epoch:  453  	Training Loss: 0.0004754475667141378
Test Loss:  0.00030154900741763413
Valid Loss:  0.0004120226949453354
Epoch:  454  	Training Loss: 0.0004726763581857085
Test Loss:  0.0002996230323333293
Valid Loss:  0.00040938088204711676
Epoch:  455  	Training Loss: 0.00047014933079481125
Test Loss:  0.0002976682735607028
Valid Loss:  0.00040695659117773175
Epoch:  456  	Training Loss: 0.0004677843244280666
Test Loss:  0.00029583799187093973
Valid Loss:  0.00040469467057846487
Epoch:  457  	Training Loss: 0.00046552359708584845
Test Loss:  0.0002941075072158128
Valid Loss:  0.0004025418311357498
Epoch:  458  	Training Loss: 0.00046334147918969393
Test Loss:  0.0002924791187979281
Valid Loss:  0.00040049522067420185
Epoch:  459  	Training Loss: 0.00046122755156829953
Test Loss:  0.0002909489849116653
Valid Loss:  0.0003985451185144484
Epoch:  460  	Training Loss: 0.0004591800388880074
Test Loss:  0.0002895174839068204
Valid Loss:  0.00039666853263042867
Epoch:  461  	Training Loss: 0.0004571887257043272
Test Loss:  0.00028816238045692444
Valid Loss:  0.00039485920569859445
Epoch:  462  	Training Loss: 0.0004552569007501006
Test Loss:  0.0002877356600947678
Valid Loss:  0.0003940893802791834
Epoch:  463  	Training Loss: 0.0004545945266727358
Test Loss:  0.0002878708764910698
Valid Loss:  0.00039362444658763707
Epoch:  464  	Training Loss: 0.00045403518015518785
Test Loss:  0.00028776651015505195
Valid Loss:  0.0003932202234864235
Epoch:  465  	Training Loss: 0.0004535327898338437
Test Loss:  0.0002875417994800955
Valid Loss:  0.00039285345701500773
Epoch:  466  	Training Loss: 0.00045305880485102534
Test Loss:  0.0002872658078558743
Valid Loss:  0.0003925190831068903
Epoch:  467  	Training Loss: 0.000452601962024346
Test Loss:  0.0002869735471904278
Valid Loss:  0.0003922116884496063
Epoch:  468  	Training Loss: 0.00045215716818347573
Test Loss:  0.00028668332379311323
Valid Loss:  0.00039192914846353233
Epoch:  469  	Training Loss: 0.0004517222987487912
Test Loss:  0.0002864055859390646
Valid Loss:  0.00039166631177067757
Epoch:  470  	Training Loss: 0.00045129581121727824
Test Loss:  0.00028614193433895707
Valid Loss:  0.00039142160676419735
Epoch:  471  	Training Loss: 0.00045087578473612666
Test Loss:  0.00028589359135366976
Valid Loss:  0.00039119445136748254
Epoch:  472  	Training Loss: 0.0004504626849666238
Test Loss:  0.00028404020122252405
Valid Loss:  0.0003899925504811108
Epoch:  473  	Training Loss: 0.00044913258170709014
Test Loss:  0.0002828832366503775
Valid Loss:  0.0003889140207320452
Epoch:  474  	Training Loss: 0.0004478654882404953
Test Loss:  0.00028199341613799334
Valid Loss:  0.0003878732386510819
Epoch:  475  	Training Loss: 0.0004466143436729908
Test Loss:  0.00028121116338297725
Valid Loss:  0.00038684916216880083
Epoch:  476  	Training Loss: 0.0004453707952052355
Test Loss:  0.0002804724790621549
Valid Loss:  0.0003858327982015908
Epoch:  477  	Training Loss: 0.00044413350406102836
Test Loss:  0.0002797521301545203
Valid Loss:  0.0003848214983008802
 96%|█████████▌| 478/500 [05:49<00:10,  2.19it/s] 96%|█████████▌| 480/500 [05:49<00:06,  2.94it/s] 96%|█████████▋| 482/500 [05:56<00:21,  1.21s/it] 97%|█████████▋| 484/500 [05:56<00:13,  1.16it/s] 97%|█████████▋| 486/500 [05:56<00:08,  1.60it/s] 98%|█████████▊| 488/500 [05:56<00:05,  2.19it/s] 98%|█████████▊| 490/500 [05:56<00:03,  2.95it/s] 98%|█████████▊| 492/500 [06:03<00:09,  1.19s/it] 99%|█████████▉| 494/500 [06:03<00:05,  1.16it/s] 99%|█████████▉| 496/500 [06:03<00:02,  1.59it/s]100%|█████████▉| 498/500 [06:03<00:00,  2.15it/s]100%|██████████| 500/500 [06:03<00:00,  2.84it/s]100%|██████████| 500/500 [06:03<00:00,  1.37it/s]
Epoch:  478  	Training Loss: 0.0004429020918905735
Test Loss:  0.0002790404832921922
Valid Loss:  0.00038381380727514625
Epoch:  479  	Training Loss: 0.0004416757437866181
Test Loss:  0.0002783348027151078
Valid Loss:  0.00038281167508102953
Epoch:  480  	Training Loss: 0.0004404557403177023
Test Loss:  0.0002776331384666264
Valid Loss:  0.00038181361742317677
Epoch:  481  	Training Loss: 0.0004392415867187083
Test Loss:  0.0002769373531918973
Valid Loss:  0.00038082082755863667
Epoch:  482  	Training Loss: 0.00043803415610454977
Test Loss:  0.0002762750955298543
Valid Loss:  0.0003801521670538932
Epoch:  483  	Training Loss: 0.000436869275290519
Test Loss:  0.0002757262554951012
Valid Loss:  0.0003795581578742713
Epoch:  484  	Training Loss: 0.00043580326018854976
Test Loss:  0.0002752594300545752
Valid Loss:  0.0003790240443777293
Epoch:  485  	Training Loss: 0.00043482519686222076
Test Loss:  0.000274855294264853
Valid Loss:  0.00037853969843126833
Epoch:  486  	Training Loss: 0.0004339260049164295
Test Loss:  0.00027450069319456816
Valid Loss:  0.00037809630157426
Epoch:  487  	Training Loss: 0.0004330980882514268
Test Loss:  0.0002741871285252273
Valid Loss:  0.0003776879166252911
Epoch:  488  	Training Loss: 0.0004323349567130208
Test Loss:  0.00027390915784053504
Valid Loss:  0.00037731078919023275
Epoch:  489  	Training Loss: 0.00043163105146959424
Test Loss:  0.0002736594760790467
Valid Loss:  0.00037695825449191034
Epoch:  490  	Training Loss: 0.00043097956222482026
Test Loss:  0.0002734351437538862
Valid Loss:  0.0003766273439396173
Epoch:  491  	Training Loss: 0.00043037172872573137
Test Loss:  0.00027322309324517846
Valid Loss:  0.00037630769656971097
Epoch:  492  	Training Loss: 0.0004297965788282454
Test Loss:  0.00027366101858206093
Valid Loss:  0.00037457660073414445
Epoch:  493  	Training Loss: 0.00042777039925567806
Test Loss:  0.0002724941587075591
Valid Loss:  0.0003727611037902534
Epoch:  494  	Training Loss: 0.00042592833051458
Test Loss:  0.000271246419288218
Valid Loss:  0.00037104455986991525
Epoch:  495  	Training Loss: 0.00042414607014507055
Test Loss:  0.00027008363394998014
Valid Loss:  0.00036942679435014725
Epoch:  496  	Training Loss: 0.00042240656330250204
Test Loss:  0.0002689897664822638
Valid Loss:  0.00036788865691050887
Epoch:  497  	Training Loss: 0.0004207002930343151
Test Loss:  0.00026794575387611985
Valid Loss:  0.0003664092218969017
Epoch:  498  	Training Loss: 0.00041902007069438696
Test Loss:  0.0002669424284249544
Valid Loss:  0.0003649760037660599
Epoch:  499  	Training Loss: 0.0004173603665549308
Test Loss:  0.0002659703604876995
Valid Loss:  0.00036358326906338334
Epoch:  500  	Training Loss: 0.00041572062764316797
Test Loss:  0.00026502710534259677
Valid Loss:  0.00036222278140485287
seed is  2
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:42, 11.71it/s]  1%|          | 4/500 [00:00<00:41, 12.03it/s]  1%|          | 6/500 [00:00<00:40, 12.25it/s]  2%|▏         | 8/500 [00:00<00:36, 13.45it/s]  2%|▏         | 10/500 [00:00<00:34, 14.21it/s]  2%|▏         | 12/500 [00:00<00:34, 14.23it/s]  3%|▎         | 14/500 [00:01<00:32, 14.78it/s]  3%|▎         | 16/500 [00:01<00:31, 15.27it/s]  4%|▎         | 18/500 [00:01<00:30, 15.57it/s]  4%|▍         | 20/500 [00:01<00:30, 15.84it/s]  4%|▍         | 22/500 [00:01<00:29, 16.00it/s]  5%|▍         | 24/500 [00:01<00:29, 16.10it/s]  5%|▌         | 26/500 [00:01<00:29, 16.24it/s]  6%|▌         | 28/500 [00:01<00:29, 15.91it/s]  6%|▌         | 30/500 [00:01<00:29, 15.94it/s]  6%|▋         | 32/500 [00:02<00:30, 15.42it/s]  7%|▋         | 34/500 [00:02<00:32, 14.39it/s]  7%|▋         | 36/500 [00:02<00:34, 13.40it/s]  8%|▊         | 38/500 [00:02<00:35, 13.08it/s]  8%|▊         | 40/500 [00:02<00:35, 12.87it/s]  8%|▊         | 42/500 [00:02<00:36, 12.71it/s]  9%|▉         | 44/500 [00:03<00:34, 13.29it/s]  9%|▉         | 46/500 [00:03<00:32, 13.82it/s] 10%|▉         | 48/500 [00:03<00:31, 14.44it/s] 10%|█         | 50/500 [00:03<00:30, 15.00it/s] 10%|█         | 52/500 [00:03<00:29, 15.38it/s] 11%|█         | 54/500 [00:03<00:28, 15.70it/s] 11%|█         | 56/500 [00:03<00:28, 15.71it/s] 12%|█▏        | 58/500 [00:03<00:27, 15.86it/s] 12%|█▏        | 60/500 [00:04<00:28, 15.60it/s] 12%|█▏        | 62/500 [00:04<00:28, 15.55it/s] 13%|█▎        | 64/500 [00:04<00:28, 15.48it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.67it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.89it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.01it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.15it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.21it/s] 15%|█▌        | 76/500 [00:05<00:25, 16.31it/s] 16%|█▌        | 78/500 [00:05<00:25, 16.34it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.35it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.38it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.35it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.12it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.29it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.73it/s] 18%|█▊        | 92/500 [00:06<00:25, 15.86it/s] 19%|█▉        | 94/500 [00:06<00:25, 16.01it/s] 19%|█▉        | 96/500 [00:06<00:25, 16.10it/s] 20%|█▉        | 98/500 [00:06<00:25, 16.03it/s] 20%|██        | 100/500 [00:06<00:24, 16.14it/s] 20%|██        | 102/500 [00:06<00:25, 15.78it/s] 21%|██        | 104/500 [00:06<00:25, 15.58it/s] 21%|██        | 106/500 [00:06<00:25, 15.62it/s] 22%|██▏       | 108/500 [00:07<00:25, 15.67it/s] 22%|██▏       | 110/500 [00:07<00:24, 15.91it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.82it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.99it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.15it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.22it/s] 24%|██▍       | 120/500 [00:07<00:23, 15.85it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.04it/s]Epoch:  1  	Training Loss: 0.03792910277843475
Test Loss:  0.09493377804756165
Valid Loss:  0.11666446924209595
Epoch:  2  	Training Loss: 0.11754895746707916
Test Loss:  6493.208984375
Valid Loss:  6466.4208984375
Epoch:  3  	Training Loss: 6473.8564453125
Test Loss:  8958597404819456.0
Valid Loss:  8883838667194368.0
Epoch:  4  	Training Loss: 8899850842144768.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  5  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
 25%|██▍       | 124/500 [00:08<00:23, 16.17it/s] 25%|██▌       | 126/500 [00:08<00:23, 16.23it/s] 26%|██▌       | 128/500 [00:08<00:23, 16.11it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.64it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.87it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.71it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.95it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.09it/s] 28%|██▊       | 140/500 [00:09<00:22, 16.10it/s] 28%|██▊       | 142/500 [00:09<00:22, 15.71it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.90it/s] 29%|██▉       | 146/500 [00:09<00:22, 16.01it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.09it/s] 30%|███       | 150/500 [00:09<00:23, 14.62it/s] 30%|███       | 152/500 [00:09<00:24, 14.35it/s] 31%|███       | 154/500 [00:10<00:25, 13.81it/s] 31%|███       | 156/500 [00:10<00:25, 13.29it/s] 32%|███▏      | 158/500 [00:10<00:26, 12.98it/s] 32%|███▏      | 160/500 [00:10<00:26, 12.75it/s] 32%|███▏      | 162/500 [00:10<00:26, 12.63it/s] 33%|███▎      | 164/500 [00:10<00:27, 12.30it/s] 33%|███▎      | 166/500 [00:11<00:27, 12.33it/s] 34%|███▎      | 168/500 [00:11<00:26, 12.31it/s] 34%|███▍      | 170/500 [00:11<00:26, 12.24it/s] 34%|███▍      | 172/500 [00:11<00:26, 12.28it/s] 35%|███▍      | 174/500 [00:11<00:26, 12.28it/s] 35%|███▌      | 176/500 [00:11<00:26, 12.31it/s] 36%|███▌      | 178/500 [00:12<00:26, 12.33it/s] 36%|███▌      | 180/500 [00:12<00:25, 12.32it/s] 36%|███▋      | 182/500 [00:12<00:24, 13.06it/s] 37%|███▋      | 184/500 [00:12<00:22, 13.90it/s] 37%|███▋      | 186/500 [00:12<00:21, 14.56it/s] 38%|███▊      | 188/500 [00:12<00:20, 15.08it/s] 38%|███▊      | 190/500 [00:12<00:20, 15.47it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.68it/s] 39%|███▉      | 194/500 [00:13<00:19, 15.88it/s] 39%|███▉      | 196/500 [00:13<00:19, 15.95it/s] 40%|███▉      | 198/500 [00:13<00:18, 16.12it/s] 40%|████      | 200/500 [00:13<00:18, 15.99it/s] 40%|████      | 202/500 [00:13<00:18, 16.06it/s] 41%|████      | 204/500 [00:13<00:18, 15.85it/s] 41%|████      | 206/500 [00:13<00:19, 14.72it/s] 42%|████▏     | 208/500 [00:13<00:20, 13.91it/s] 42%|████▏     | 210/500 [00:14<00:21, 13.39it/s] 42%|████▏     | 212/500 [00:14<00:22, 13.05it/s] 43%|████▎     | 214/500 [00:14<00:22, 12.84it/s] 43%|████▎     | 216/500 [00:14<00:22, 12.54it/s] 44%|████▎     | 218/500 [00:14<00:22, 12.38it/s] 44%|████▍     | 220/500 [00:14<00:22, 12.38it/s] 44%|████▍     | 222/500 [00:15<00:22, 12.38it/s] 45%|████▍     | 224/500 [00:15<00:23, 11.93it/s] 45%|████▌     | 226/500 [00:15<00:22, 12.04it/s] 46%|████▌     | 228/500 [00:15<00:22, 12.12it/s] 46%|████▌     | 230/500 [00:15<00:22, 12.05it/s] 46%|████▋     | 232/500 [00:15<00:22, 12.14it/s] 47%|████▋     | 234/500 [00:16<00:21, 12.26it/s] 47%|████▋     | 236/500 [00:16<00:19, 13.26it/s] 48%|████▊     | 238/500 [00:16<00:18, 14.10it/s] 48%|████▊     | 240/500 [00:16<00:17, 14.75it/s] 48%|████▊     | 242/500 [00:16<00:16, 15.21it/s] 49%|████▉     | 244/500 [00:16<00:16, 15.54it/s] 49%|████▉     | 246/500 [00:16<00:16, 15.81it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
 50%|████▉     | 248/500 [00:16<00:15, 15.96it/s] 50%|█████     | 250/500 [00:17<00:15, 16.09it/s] 50%|█████     | 252/500 [00:17<00:15, 16.13it/s] 51%|█████     | 254/500 [00:17<00:15, 16.26it/s] 51%|█████     | 256/500 [00:17<00:15, 16.19it/s] 52%|█████▏    | 258/500 [00:17<00:14, 16.22it/s] 52%|█████▏    | 260/500 [00:17<00:14, 16.27it/s] 52%|█████▏    | 262/500 [00:17<00:14, 16.35it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.40it/s] 53%|█████▎    | 266/500 [00:18<00:14, 16.28it/s] 54%|█████▎    | 268/500 [00:18<00:14, 16.31it/s] 54%|█████▍    | 270/500 [00:18<00:14, 16.38it/s] 54%|█████▍    | 272/500 [00:18<00:13, 16.42it/s] 55%|█████▍    | 274/500 [00:18<00:14, 15.24it/s] 55%|█████▌    | 276/500 [00:18<00:15, 14.24it/s] 56%|█████▌    | 278/500 [00:18<00:16, 13.61it/s] 56%|█████▌    | 280/500 [00:19<00:16, 13.21it/s] 56%|█████▋    | 282/500 [00:19<00:16, 12.94it/s] 57%|█████▋    | 284/500 [00:19<00:16, 12.76it/s] 57%|█████▋    | 286/500 [00:19<00:16, 12.63it/s] 58%|█████▊    | 288/500 [00:19<00:16, 12.53it/s] 58%|█████▊    | 290/500 [00:19<00:16, 12.42it/s] 58%|█████▊    | 292/500 [00:20<00:16, 12.30it/s] 59%|█████▉    | 294/500 [00:20<00:16, 12.24it/s] 59%|█████▉    | 296/500 [00:20<00:16, 12.26it/s] 60%|█████▉    | 298/500 [00:20<00:16, 12.24it/s] 60%|██████    | 300/500 [00:20<00:16, 12.26it/s] 60%|██████    | 302/500 [00:20<00:16, 12.30it/s] 61%|██████    | 304/500 [00:21<00:15, 12.72it/s] 61%|██████    | 306/500 [00:21<00:15, 12.48it/s] 62%|██████▏   | 308/500 [00:21<00:15, 12.33it/s] 62%|██████▏   | 310/500 [00:21<00:15, 12.32it/s] 62%|██████▏   | 312/500 [00:21<00:14, 12.61it/s] 63%|██████▎   | 314/500 [00:21<00:13, 13.51it/s] 63%|██████▎   | 316/500 [00:21<00:13, 13.44it/s] 64%|██████▎   | 318/500 [00:22<00:14, 12.99it/s] 64%|██████▍   | 320/500 [00:22<00:13, 12.99it/s] 64%|██████▍   | 322/500 [00:22<00:13, 13.69it/s] 65%|██████▍   | 324/500 [00:22<00:12, 14.39it/s] 65%|██████▌   | 326/500 [00:22<00:11, 14.61it/s] 66%|██████▌   | 328/500 [00:22<00:11, 15.05it/s] 66%|██████▌   | 330/500 [00:22<00:11, 15.33it/s] 66%|██████▋   | 332/500 [00:23<00:10, 15.46it/s] 67%|██████▋   | 334/500 [00:23<00:10, 15.68it/s] 67%|██████▋   | 336/500 [00:23<00:10, 15.86it/s] 68%|██████▊   | 338/500 [00:23<00:10, 16.03it/s] 68%|██████▊   | 340/500 [00:23<00:09, 16.11it/s] 68%|██████▊   | 342/500 [00:23<00:09, 16.18it/s] 69%|██████▉   | 344/500 [00:23<00:09, 16.27it/s] 69%|██████▉   | 346/500 [00:23<00:09, 16.30it/s] 70%|██████▉   | 348/500 [00:24<00:09, 16.38it/s] 70%|███████   | 350/500 [00:24<00:09, 16.41it/s] 70%|███████   | 352/500 [00:24<00:09, 16.37it/s] 71%|███████   | 354/500 [00:24<00:08, 16.36it/s] 71%|███████   | 356/500 [00:24<00:08, 16.35it/s] 72%|███████▏  | 358/500 [00:24<00:08, 16.35it/s] 72%|███████▏  | 360/500 [00:24<00:08, 16.43it/s] 72%|███████▏  | 362/500 [00:24<00:08, 16.38it/s] 73%|███████▎  | 364/500 [00:24<00:08, 16.34it/s] 73%|███████▎  | 366/500 [00:25<00:08, 16.40it/s] 74%|███████▎  | 368/500 [00:25<00:08, 16.39it/s] 74%|███████▍  | 370/500 [00:25<00:08, 16.25it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
 74%|███████▍  | 372/500 [00:25<00:07, 16.18it/s] 75%|███████▍  | 374/500 [00:25<00:07, 16.25it/s] 75%|███████▌  | 376/500 [00:25<00:07, 16.27it/s] 76%|███████▌  | 378/500 [00:25<00:07, 16.29it/s] 76%|███████▌  | 380/500 [00:25<00:07, 16.28it/s] 76%|███████▋  | 382/500 [00:26<00:07, 16.29it/s] 77%|███████▋  | 384/500 [00:26<00:07, 16.18it/s] 77%|███████▋  | 386/500 [00:26<00:07, 15.97it/s] 78%|███████▊  | 388/500 [00:26<00:07, 15.62it/s] 78%|███████▊  | 390/500 [00:26<00:07, 14.72it/s] 78%|███████▊  | 392/500 [00:26<00:07, 13.82it/s] 79%|███████▉  | 394/500 [00:26<00:07, 14.12it/s] 79%|███████▉  | 396/500 [00:27<00:07, 14.67it/s] 80%|███████▉  | 398/500 [00:27<00:06, 15.15it/s] 80%|████████  | 400/500 [00:27<00:06, 15.22it/s] 80%|████████  | 402/500 [00:27<00:06, 15.43it/s] 81%|████████  | 404/500 [00:27<00:06, 15.59it/s] 81%|████████  | 406/500 [00:27<00:06, 15.52it/s] 82%|████████▏ | 408/500 [00:27<00:05, 15.82it/s] 82%|████████▏ | 410/500 [00:27<00:05, 15.61it/s] 82%|████████▏ | 412/500 [00:28<00:06, 14.40it/s] 83%|████████▎ | 414/500 [00:28<00:06, 13.74it/s] 83%|████████▎ | 416/500 [00:28<00:06, 13.34it/s] 84%|████████▎ | 418/500 [00:28<00:06, 12.80it/s] 84%|████████▍ | 420/500 [00:28<00:06, 13.11it/s] 84%|████████▍ | 422/500 [00:28<00:05, 13.79it/s] 85%|████████▍ | 424/500 [00:28<00:05, 14.38it/s] 85%|████████▌ | 426/500 [00:29<00:05, 14.80it/s] 86%|████████▌ | 428/500 [00:29<00:04, 15.24it/s] 86%|████████▌ | 430/500 [00:29<00:04, 15.58it/s] 86%|████████▋ | 432/500 [00:29<00:04, 15.31it/s] 87%|████████▋ | 434/500 [00:29<00:04, 15.53it/s] 87%|████████▋ | 436/500 [00:29<00:04, 15.40it/s] 88%|████████▊ | 438/500 [00:29<00:03, 15.66it/s] 88%|████████▊ | 440/500 [00:30<00:04, 14.29it/s] 88%|████████▊ | 442/500 [00:30<00:03, 14.76it/s] 89%|████████▉ | 444/500 [00:30<00:03, 15.20it/s] 89%|████████▉ | 446/500 [00:30<00:03, 15.54it/s] 90%|████████▉ | 448/500 [00:30<00:03, 15.78it/s] 90%|█████████ | 450/500 [00:30<00:03, 15.97it/s] 90%|█████████ | 452/500 [00:30<00:02, 16.09it/s] 91%|█████████ | 454/500 [00:30<00:02, 16.23it/s] 91%|█████████ | 456/500 [00:31<00:02, 16.30it/s] 92%|█████████▏| 458/500 [00:31<00:02, 16.40it/s] 92%|█████████▏| 460/500 [00:31<00:02, 16.39it/s] 92%|█████████▏| 462/500 [00:31<00:02, 16.42it/s] 93%|█████████▎| 464/500 [00:31<00:02, 16.49it/s] 93%|█████████▎| 466/500 [00:31<00:02, 16.24it/s] 94%|█████████▎| 468/500 [00:31<00:01, 16.37it/s] 94%|█████████▍| 470/500 [00:31<00:01, 16.37it/s] 94%|█████████▍| 472/500 [00:32<00:01, 16.40it/s] 95%|█████████▍| 474/500 [00:32<00:01, 16.42it/s] 95%|█████████▌| 476/500 [00:32<00:01, 16.43it/s] 96%|█████████▌| 478/500 [00:32<00:01, 16.41it/s] 96%|█████████▌| 480/500 [00:32<00:01, 16.33it/s] 96%|█████████▋| 482/500 [00:32<00:01, 16.12it/s] 97%|█████████▋| 484/500 [00:32<00:01, 15.81it/s] 97%|█████████▋| 486/500 [00:32<00:00, 15.56it/s] 98%|█████████▊| 488/500 [00:33<00:00, 14.42it/s] 98%|█████████▊| 490/500 [00:33<00:00, 13.76it/s] 98%|█████████▊| 492/500 [00:33<00:00, 14.16it/s] 99%|█████████▉| 494/500 [00:33<00:00, 14.58it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
 99%|█████████▉| 496/500 [00:33<00:00, 14.82it/s]100%|█████████▉| 498/500 [00:33<00:00, 15.18it/s]100%|██████████| 500/500 [00:33<00:00, 15.48it/s]100%|██████████| 500/500 [00:33<00:00, 14.77it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  2
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:47,  6.35s/it]  1%|          | 3/500 [00:06<14:05,  1.70s/it]  1%|          | 5/500 [00:06<07:05,  1.16it/s]  1%|▏         | 7/500 [00:06<04:17,  1.91it/s]  2%|▏         | 9/500 [00:06<02:52,  2.84it/s]  2%|▏         | 11/500 [00:13<10:58,  1.35s/it]  3%|▎         | 13/500 [00:13<07:28,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.17it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:42,  1.22s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.20it/s]  6%|▌         | 29/500 [00:20<02:41,  2.91it/s]  6%|▌         | 31/500 [00:27<09:26,  1.21s/it]  7%|▋         | 33/500 [00:27<06:45,  1.15it/s]  7%|▋         | 35/500 [00:27<04:51,  1.60it/s]  7%|▋         | 37/500 [00:27<03:32,  2.18it/s]  8%|▊         | 39/500 [00:27<02:36,  2.94it/s]  8%|▊         | 41/500 [00:34<09:10,  1.20s/it]  9%|▊         | 43/500 [00:34<06:33,  1.16it/s]  9%|▉         | 45/500 [00:34<04:42,  1.61it/s]  9%|▉         | 47/500 [00:34<03:26,  2.20it/s] 10%|▉         | 49/500 [00:34<02:32,  2.96it/s] 10%|█         | 51/500 [00:41<08:55,  1.19s/it] 11%|█         | 53/500 [00:41<06:22,  1.17it/s] 11%|█         | 55/500 [00:41<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:41<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:43,  1.19s/it] 13%|█▎        | 63/500 [00:48<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:48<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:16,  2.21it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.96it/s] 14%|█▍        | 71/500 [00:54<08:35,  1.20s/it]Epoch:  1  	Training Loss: 0.03792910650372505
Test Loss:  0.10974043607711792
Valid Loss:  0.13856211304664612
Epoch:  2  	Training Loss: 0.1377776712179184
Test Loss:  1.474692940711975
Valid Loss:  1.4664275646209717
Epoch:  3  	Training Loss: 1.4881855249404907
Test Loss:  0.027077585458755493
Valid Loss:  0.03339052200317383
Epoch:  4  	Training Loss: 0.03041469119489193
Test Loss:  0.026585005223751068
Valid Loss:  0.03280971199274063
Epoch:  5  	Training Loss: 0.029894161969423294
Test Loss:  0.02611631155014038
Valid Loss:  0.03225359320640564
Epoch:  6  	Training Loss: 0.02939586341381073
Test Loss:  0.02566877007484436
Valid Loss:  0.03171950578689575
Epoch:  7  	Training Loss: 0.02891729585826397
Test Loss:  0.025240043178200722
Valid Loss:  0.031205162405967712
Epoch:  8  	Training Loss: 0.028456339612603188
Test Loss:  0.024828128516674042
Valid Loss:  0.030708620324730873
Epoch:  9  	Training Loss: 0.028011184185743332
Test Loss:  0.02443130686879158
Valid Loss:  0.03022819757461548
Epoch:  10  	Training Loss: 0.027580268681049347
Test Loss:  0.024048084393143654
Valid Loss:  0.029762424528598785
Epoch:  11  	Training Loss: 0.02716226875782013
Test Loss:  0.023677192628383636
Valid Loss:  0.029310069978237152
Epoch:  12  	Training Loss: 0.02675604447722435
Test Loss:  0.0219015683978796
Valid Loss:  0.02712881565093994
Epoch:  13  	Training Loss: 0.024821549654006958
Test Loss:  0.020714707672595978
Valid Loss:  0.025697320699691772
Epoch:  14  	Training Loss: 0.023530399426817894
Test Loss:  0.019860485568642616
Valid Loss:  0.02465714141726494
Epoch:  15  	Training Loss: 0.022520776838064194
Test Loss:  0.019085485488176346
Valid Loss:  0.02370205521583557
Epoch:  16  	Training Loss: 0.02162674441933632
Test Loss:  0.01842016540467739
Valid Loss:  0.02289791963994503
Epoch:  17  	Training Loss: 0.020863819867372513
Test Loss:  0.017949409782886505
Valid Loss:  0.02232268452644348
Epoch:  18  	Training Loss: 0.020316628739237785
Test Loss:  0.0175539068877697
Valid Loss:  0.021838219836354256
Epoch:  19  	Training Loss: 0.019861962646245956
Test Loss:  0.0172093715518713
Valid Loss:  0.021432630717754364
Epoch:  20  	Training Loss: 0.019482573494315147
Test Loss:  0.016943495720624924
Valid Loss:  0.021104756742715836
Epoch:  21  	Training Loss: 0.019168175756931305
Test Loss:  0.016692059114575386
Valid Loss:  0.020820852369070053
Epoch:  22  	Training Loss: 0.01890403777360916
Test Loss:  0.016509465873241425
Valid Loss:  0.020613189786672592
Epoch:  23  	Training Loss: 0.018708225339651108
Test Loss:  0.01633923128247261
Valid Loss:  0.020426549017429352
Epoch:  24  	Training Loss: 0.01853531412780285
Test Loss:  0.01616816781461239
Valid Loss:  0.020251579582691193
Epoch:  25  	Training Loss: 0.018375946208834648
Test Loss:  0.015997186303138733
Valid Loss:  0.02008640766143799
Epoch:  26  	Training Loss: 0.018229130655527115
Test Loss:  0.015858592465519905
Valid Loss:  0.019946368411183357
Epoch:  27  	Training Loss: 0.018101606518030167
Test Loss:  0.015740569680929184
Valid Loss:  0.019823608919978142
Epoch:  28  	Training Loss: 0.017986897379159927
Test Loss:  0.015626024454832077
Valid Loss:  0.019719427451491356
Epoch:  29  	Training Loss: 0.017882617190480232
Test Loss:  0.015532281249761581
Valid Loss:  0.01962920092046261
Epoch:  30  	Training Loss: 0.01779082417488098
Test Loss:  0.015440871939063072
Valid Loss:  0.01955210417509079
Epoch:  31  	Training Loss: 0.01770729012787342
Test Loss:  0.015348061919212341
Valid Loss:  0.01948484405875206
Epoch:  32  	Training Loss: 0.0176289901137352
Test Loss:  0.015255147591233253
Valid Loss:  0.01942477375268936
Epoch:  33  	Training Loss: 0.0175562035292387
Test Loss:  0.015170750208199024
Valid Loss:  0.01936696097254753
Epoch:  34  	Training Loss: 0.017488747835159302
Test Loss:  0.015085859224200249
Valid Loss:  0.019314303994178772
Epoch:  35  	Training Loss: 0.01742440089583397
Test Loss:  0.015007752925157547
Valid Loss:  0.019263798370957375
Epoch:  36  	Training Loss: 0.01736525073647499
Test Loss:  0.014942091889679432
Valid Loss:  0.019214428961277008
Epoch:  37  	Training Loss: 0.01731276325881481
Test Loss:  0.014878083020448685
Valid Loss:  0.019169360399246216
Epoch:  38  	Training Loss: 0.017264308407902718
Test Loss:  0.014812377281486988
Valid Loss:  0.019128430634737015
Epoch:  39  	Training Loss: 0.017218679189682007
Test Loss:  0.01476089097559452
Valid Loss:  0.019088687375187874
Epoch:  40  	Training Loss: 0.01717825047671795
Test Loss:  0.014717384241521358
Valid Loss:  0.019051793962717056
Epoch:  41  	Training Loss: 0.017141858115792274
Test Loss:  0.014673597179353237
Valid Loss:  0.01901846192777157
Epoch:  42  	Training Loss: 0.017108015716075897
Test Loss:  0.01463126577436924
Valid Loss:  0.018982745707035065
Epoch:  43  	Training Loss: 0.01707322522997856
Test Loss:  0.014590206556022167
Valid Loss:  0.01895059272646904
Epoch:  44  	Training Loss: 0.01704113557934761
Test Loss:  0.014548763632774353
Valid Loss:  0.01892094686627388
Epoch:  45  	Training Loss: 0.017010778188705444
Test Loss:  0.014507330022752285
Valid Loss:  0.018893102183938026
Epoch:  46  	Training Loss: 0.01698172092437744
Test Loss:  0.014468357898294926
Valid Loss:  0.01886666566133499
Epoch:  47  	Training Loss: 0.01695377007126808
Test Loss:  0.014431888237595558
Valid Loss:  0.018841415643692017
Epoch:  48  	Training Loss: 0.01692681945860386
Test Loss:  0.014396438375115395
Valid Loss:  0.018817178905010223
Epoch:  49  	Training Loss: 0.016900792717933655
Test Loss:  0.014363080263137817
Valid Loss:  0.018793871626257896
Epoch:  50  	Training Loss: 0.0168764665722847
Test Loss:  0.014335732907056808
Valid Loss:  0.01877160370349884
Epoch:  51  	Training Loss: 0.016854792833328247
Test Loss:  0.014309361577033997
Valid Loss:  0.018750663846731186
Epoch:  52  	Training Loss: 0.016834907233715057
Test Loss:  0.014285925775766373
Valid Loss:  0.018731288611888885
Epoch:  53  	Training Loss: 0.01681685447692871
Test Loss:  0.014263110235333443
Valid Loss:  0.01871304400265217
Epoch:  54  	Training Loss: 0.01679982990026474
Test Loss:  0.01424169261008501
Valid Loss:  0.018695641309022903
Epoch:  55  	Training Loss: 0.016783516854047775
Test Loss:  0.014222988858819008
Valid Loss:  0.018678920343518257
Epoch:  56  	Training Loss: 0.016767796128988266
Test Loss:  0.014206238090991974
Valid Loss:  0.018662787973880768
Epoch:  57  	Training Loss: 0.016752606257796288
Test Loss:  0.014190277084708214
Valid Loss:  0.01864718273282051
Epoch:  58  	Training Loss: 0.01673852652311325
Test Loss:  0.01417513471096754
Valid Loss:  0.018632985651493073
Epoch:  59  	Training Loss: 0.01672595739364624
Test Loss:  0.014160861261188984
Valid Loss:  0.01861962303519249
Epoch:  60  	Training Loss: 0.01671433635056019
Test Loss:  0.01414724625647068
Valid Loss:  0.018606772646307945
Epoch:  61  	Training Loss: 0.01670326292514801
Test Loss:  0.014134133234620094
Valid Loss:  0.018594326451420784
Epoch:  62  	Training Loss: 0.01669261045753956
Test Loss:  0.01412137970328331
Valid Loss:  0.018582168966531754
Epoch:  63  	Training Loss: 0.01668226160109043
Test Loss:  0.014109009876847267
Valid Loss:  0.018570350483059883
Epoch:  64  	Training Loss: 0.016672242432832718
Test Loss:  0.014097001403570175
Valid Loss:  0.018558867275714874
Epoch:  65  	Training Loss: 0.016662541776895523
Test Loss:  0.014085324481129646
Valid Loss:  0.018547695130109787
Epoch:  66  	Training Loss: 0.016653137281537056
Test Loss:  0.014073965139687061
Valid Loss:  0.018536832183599472
Epoch:  67  	Training Loss: 0.01664401963353157
Test Loss:  0.014062917791306973
Valid Loss:  0.01852627657353878
Epoch:  68  	Training Loss: 0.016635186970233917
Test Loss:  0.014052161946892738
Valid Loss:  0.018516018986701965
Epoch:  69  	Training Loss: 0.01662692055106163
Test Loss:  0.014041881076991558
Valid Loss:  0.018506599590182304
Epoch:  70  	Training Loss: 0.016619283705949783
Test Loss:  0.014031993225216866
Valid Loss:  0.018497545272111893
Epoch:  71  	Training Loss: 0.016612010076642036
Test Loss:  0.014022430405020714
Valid Loss:  0.01848871260881424
Epoch:  72  	Training Loss: 0.016604993492364883
 15%|█▍        | 73/500 [00:55<06:08,  1.16it/s] 15%|█▌        | 75/500 [00:55<04:24,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:13,  2.18it/s] 16%|█▌        | 79/500 [00:55<02:23,  2.93it/s] 16%|█▌        | 81/500 [01:01<08:21,  1.20s/it] 17%|█▋        | 83/500 [01:02<05:58,  1.16it/s] 17%|█▋        | 85/500 [01:02<04:18,  1.60it/s] 17%|█▋        | 87/500 [01:02<03:10,  2.16it/s] 18%|█▊        | 89/500 [01:02<02:23,  2.86it/s] 18%|█▊        | 91/500 [01:08<08:13,  1.21s/it] 19%|█▊        | 93/500 [01:09<05:52,  1.16it/s] 19%|█▉        | 95/500 [01:09<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:09<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:09<02:16,  2.93it/s] 20%|██        | 101/500 [01:15<07:54,  1.19s/it] 21%|██        | 103/500 [01:15<05:40,  1.16it/s] 21%|██        | 105/500 [01:16<04:07,  1.60it/s] 21%|██▏       | 107/500 [01:16<03:02,  2.16it/s] 22%|██▏       | 109/500 [01:16<02:16,  2.86it/s] 22%|██▏       | 111/500 [01:22<07:50,  1.21s/it] 23%|██▎       | 113/500 [01:23<05:35,  1.15it/s] 23%|██▎       | 115/500 [01:23<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:23<02:55,  2.19it/s] 24%|██▍       | 119/500 [01:23<02:09,  2.95it/s] 24%|██▍       | 121/500 [01:29<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:29<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:29<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:30<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:30<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:36<07:26,  1.21s/it] 27%|██▋       | 133/500 [01:36<05:18,  1.15it/s] 27%|██▋       | 135/500 [01:37<03:48,  1.60it/s] 27%|██▋       | 137/500 [01:37<02:46,  2.18it/s] 28%|██▊       | 139/500 [01:37<02:03,  2.93it/s] 28%|██▊       | 141/500 [01:43<07:10,  1.20s/it]Test Loss:  0.014013126492500305
Valid Loss:  0.01848004385828972
Epoch:  73  	Training Loss: 0.0165981687605381
Test Loss:  0.014004074037075043
Valid Loss:  0.01847158372402191
Epoch:  74  	Training Loss: 0.01659167930483818
Test Loss:  0.013995465822517872
Valid Loss:  0.01846393570303917
Epoch:  75  	Training Loss: 0.016585776582360268
Test Loss:  0.013987205922603607
Valid Loss:  0.018456581979990005
Epoch:  76  	Training Loss: 0.016580183058977127
Test Loss:  0.013979209586977959
Valid Loss:  0.018449364230036736
Epoch:  77  	Training Loss: 0.01657484471797943
Test Loss:  0.013971731998026371
Valid Loss:  0.018443074077367783
Epoch:  78  	Training Loss: 0.01657015085220337
Test Loss:  0.013964895159006119
Valid Loss:  0.0184377059340477
Epoch:  79  	Training Loss: 0.01656590960919857
Test Loss:  0.013958347961306572
Valid Loss:  0.018432311713695526
Epoch:  80  	Training Loss: 0.016561992466449738
Test Loss:  0.01395199541002512
Valid Loss:  0.01842690259218216
Epoch:  81  	Training Loss: 0.016558276489377022
Test Loss:  0.013945801183581352
Valid Loss:  0.018421495333313942
Epoch:  82  	Training Loss: 0.016554709523916245
Test Loss:  0.013939743861556053
Valid Loss:  0.01841612718999386
Epoch:  83  	Training Loss: 0.016551390290260315
Test Loss:  0.013934287242591381
Valid Loss:  0.018411803990602493
Epoch:  84  	Training Loss: 0.016548387706279755
Test Loss:  0.013928957283496857
Valid Loss:  0.018407396972179413
Epoch:  85  	Training Loss: 0.016545552760362625
Test Loss:  0.013923737220466137
Valid Loss:  0.01840294525027275
Epoch:  86  	Training Loss: 0.016542837023735046
Test Loss:  0.013918617740273476
Valid Loss:  0.01839848794043064
Epoch:  87  	Training Loss: 0.01654021069407463
Test Loss:  0.01391381211578846
Valid Loss:  0.01839406043291092
Epoch:  88  	Training Loss: 0.01653767004609108
Test Loss:  0.013909656554460526
Valid Loss:  0.01838967576622963
Epoch:  89  	Training Loss: 0.01653520204126835
Test Loss:  0.013905610889196396
Valid Loss:  0.01838536374270916
Epoch:  90  	Training Loss: 0.016532812267541885
Test Loss:  0.013901667669415474
Valid Loss:  0.01838112249970436
Epoch:  91  	Training Loss: 0.016530487686395645
Test Loss:  0.013897813856601715
Valid Loss:  0.01837695762515068
Epoch:  92  	Training Loss: 0.01652822643518448
Test Loss:  0.013894032686948776
Valid Loss:  0.01837283931672573
Epoch:  93  	Training Loss: 0.016526008024811745
Test Loss:  0.013890468515455723
Valid Loss:  0.018368808552622795
Epoch:  94  	Training Loss: 0.016523895785212517
Test Loss:  0.013886967673897743
Valid Loss:  0.018365267664194107
Epoch:  95  	Training Loss: 0.016521863639354706
Test Loss:  0.013884056359529495
Valid Loss:  0.01836172118782997
Epoch:  96  	Training Loss: 0.016520163044333458
Test Loss:  0.01388054620474577
Valid Loss:  0.018359839916229248
Epoch:  97  	Training Loss: 0.016518566757440567
Test Loss:  0.013877613469958305
Valid Loss:  0.018357455730438232
Epoch:  98  	Training Loss: 0.016517136245965958
Test Loss:  0.01387488842010498
Valid Loss:  0.01835513859987259
Epoch:  99  	Training Loss: 0.016515811905264854
Test Loss:  0.01387239433825016
Valid Loss:  0.018352674320340157
Epoch:  100  	Training Loss: 0.016514554619789124
Test Loss:  0.013870070688426495
Valid Loss:  0.01835012622177601
Epoch:  101  	Training Loss: 0.01651335321366787
Test Loss:  0.013867868110537529
Valid Loss:  0.01834753155708313
Epoch:  102  	Training Loss: 0.016512194648385048
Test Loss:  0.013865703716874123
Valid Loss:  0.01834515854716301
Epoch:  103  	Training Loss: 0.016511166468262672
Test Loss:  0.013863387517631054
Valid Loss:  0.018343649804592133
Epoch:  104  	Training Loss: 0.01651023142039776
Test Loss:  0.013861316256225109
Valid Loss:  0.018341921269893646
Epoch:  105  	Training Loss: 0.016509369015693665
Test Loss:  0.013859407044947147
Valid Loss:  0.01834005117416382
Epoch:  106  	Training Loss: 0.016508549451828003
Test Loss:  0.013857612386345863
Valid Loss:  0.018338091671466827
Epoch:  107  	Training Loss: 0.016507763415575027
Test Loss:  0.013855907134711742
Valid Loss:  0.018336083739995956
Epoch:  108  	Training Loss: 0.01650700345635414
Test Loss:  0.013854265213012695
Valid Loss:  0.018334049731492996
Epoch:  109  	Training Loss: 0.01650630496442318
Test Loss:  0.013852421194314957
Valid Loss:  0.01833321526646614
Epoch:  110  	Training Loss: 0.016505688428878784
Test Loss:  0.013850786723196507
Valid Loss:  0.018332114443182945
Epoch:  111  	Training Loss: 0.016505133360624313
Test Loss:  0.013849294744431973
Valid Loss:  0.018330831080675125
Epoch:  112  	Training Loss: 0.016504617407917976
Test Loss:  0.013847907073795795
Valid Loss:  0.018329430371522903
Epoch:  113  	Training Loss: 0.01650412753224373
Test Loss:  0.01384658645838499
Valid Loss:  0.01832795888185501
Epoch:  114  	Training Loss: 0.016503656283020973
Test Loss:  0.013845317997038364
Valid Loss:  0.018326446413993835
Epoch:  115  	Training Loss: 0.016503196209669113
Test Loss:  0.013844096101820469
Valid Loss:  0.018324915319681168
Epoch:  116  	Training Loss: 0.016502756625413895
Test Loss:  0.01384290587157011
Valid Loss:  0.0183233805000782
Epoch:  117  	Training Loss: 0.016502322629094124
Test Loss:  0.013841751031577587
Valid Loss:  0.018321851268410683
Epoch:  118  	Training Loss: 0.016501903533935547
Test Loss:  0.013840618543326855
Valid Loss:  0.01832033321261406
Epoch:  119  	Training Loss: 0.016501493752002716
Test Loss:  0.013839512132108212
Valid Loss:  0.01831883192062378
Epoch:  120  	Training Loss: 0.01650109514594078
Test Loss:  0.013838429935276508
Valid Loss:  0.01831735111773014
Epoch:  121  	Training Loss: 0.01650070771574974
Test Loss:  0.01383737102150917
Valid Loss:  0.018315894529223442
Epoch:  122  	Training Loss: 0.016500335186719894
Test Loss:  0.013836326077580452
Valid Loss:  0.018314454704523087
Epoch:  123  	Training Loss: 0.016499968245625496
Test Loss:  0.013835297897458076
Valid Loss:  0.01831303909420967
Epoch:  124  	Training Loss: 0.016499608755111694
Test Loss:  0.013834290206432343
Valid Loss:  0.018311642110347748
Epoch:  125  	Training Loss: 0.016499260440468788
Test Loss:  0.01383330300450325
Valid Loss:  0.018310273066163063
Epoch:  126  	Training Loss: 0.016498921439051628
Test Loss:  0.013832330703735352
Valid Loss:  0.01830892264842987
Epoch:  127  	Training Loss: 0.016498591750860214
Test Loss:  0.01383137796074152
Valid Loss:  0.018307596445083618
Epoch:  128  	Training Loss: 0.016498269513249397
Test Loss:  0.013830438256263733
Valid Loss:  0.018306292593479156
Epoch:  129  	Training Loss: 0.016497954726219177
Test Loss:  0.013829519972205162
Valid Loss:  0.018305012956261635
Epoch:  130  	Training Loss: 0.016497649252414703
Test Loss:  0.013828612864017487
Valid Loss:  0.018303751945495605
Epoch:  131  	Training Loss: 0.016497354954481125
Test Loss:  0.01382772158831358
Valid Loss:  0.018302511423826218
Epoch:  132  	Training Loss: 0.016497064381837845
Test Loss:  0.013826850801706314
Valid Loss:  0.01830129511654377
Epoch:  133  	Training Loss: 0.01649678498506546
Test Loss:  0.013825994916260242
Valid Loss:  0.018300101161003113
Epoch:  134  	Training Loss: 0.016496513038873672
Test Loss:  0.013825148344039917
Valid Loss:  0.0182989239692688
Epoch:  135  	Training Loss: 0.016496244817972183
Test Loss:  0.013824323192238808
Valid Loss:  0.018297769129276276
Epoch:  136  	Training Loss: 0.01649598963558674
Test Loss:  0.01382350828498602
Valid Loss:  0.018296632915735245
Epoch:  137  	Training Loss: 0.016495738178491592
Test Loss:  0.013822709210216999
Valid Loss:  0.018295517191290855
Epoch:  138  	Training Loss: 0.016495496034622192
Test Loss:  0.013821922242641449
Valid Loss:  0.01829441823065281
Epoch:  139  	Training Loss: 0.01649525575339794
Test Loss:  0.013821149244904518
Valid Loss:  0.018293339759111404
Epoch:  140  	Training Loss: 0.016495024785399437
Test Loss:  0.013820392079651356
Valid Loss:  0.018292278051376343
Epoch:  141  	Training Loss: 0.01649479940533638
Test Loss:  0.01381964422762394
Valid Loss:  0.018291236832737923
Epoch:  142  	Training Loss: 0.01649458333849907
Test Loss:  0.013818911276757717
Valid Loss:  0.018290208652615547
 29%|██▊       | 143/500 [01:43<05:07,  1.16it/s] 29%|██▉       | 145/500 [01:43<03:41,  1.61it/s] 29%|██▉       | 147/500 [01:44<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:44<01:59,  2.95it/s] 30%|███       | 151/500 [01:50<06:53,  1.19s/it] 31%|███       | 153/500 [01:50<04:55,  1.17it/s] 31%|███       | 155/500 [01:50<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:50<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:51<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:57<06:49,  1.21s/it] 33%|███▎      | 163/500 [01:57<04:52,  1.15it/s] 33%|███▎      | 165/500 [01:57<03:29,  1.60it/s] 33%|███▎      | 167/500 [01:57<02:33,  2.18it/s] 34%|███▍      | 169/500 [01:58<01:52,  2.93it/s] 34%|███▍      | 171/500 [02:04<06:42,  1.22s/it] 35%|███▍      | 173/500 [02:04<04:47,  1.14it/s] 35%|███▌      | 175/500 [02:04<03:26,  1.58it/s] 35%|███▌      | 177/500 [02:05<02:29,  2.16it/s] 36%|███▌      | 179/500 [02:05<01:52,  2.86it/s] 36%|███▌      | 181/500 [02:11<06:21,  1.20s/it] 37%|███▋      | 183/500 [02:11<04:32,  1.16it/s] 37%|███▋      | 185/500 [02:11<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:12<02:22,  2.20it/s] 38%|███▊      | 189/500 [02:12<01:44,  2.96it/s] 38%|███▊      | 191/500 [02:18<06:06,  1.18s/it] 39%|███▊      | 193/500 [02:18<04:21,  1.18it/s] 39%|███▉      | 195/500 [02:18<03:07,  1.62it/s] 39%|███▉      | 197/500 [02:18<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:19<01:40,  2.99it/s] 40%|████      | 201/500 [02:25<05:55,  1.19s/it] 41%|████      | 203/500 [02:25<04:15,  1.16it/s] 41%|████      | 205/500 [02:25<03:05,  1.59it/s] 41%|████▏     | 207/500 [02:25<02:16,  2.15it/s] 42%|████▏     | 209/500 [02:26<01:42,  2.85it/s] 42%|████▏     | 211/500 [02:32<05:47,  1.20s/it]Epoch:  143  	Training Loss: 0.016494370996952057
Test Loss:  0.01381818950176239
Valid Loss:  0.018289199098944664
Epoch:  144  	Training Loss: 0.016494160518050194
Test Loss:  0.013817481696605682
Valid Loss:  0.018288202583789825
Epoch:  145  	Training Loss: 0.016493957489728928
Test Loss:  0.013816781342029572
Valid Loss:  0.01828722655773163
Epoch:  146  	Training Loss: 0.01649376191198826
Test Loss:  0.01381609681993723
Valid Loss:  0.018286269158124924
Epoch:  147  	Training Loss: 0.016493570059537888
Test Loss:  0.013815420679748058
Valid Loss:  0.018285321071743965
Epoch:  148  	Training Loss: 0.016493383795022964
Test Loss:  0.013814757578074932
Valid Loss:  0.018284393474459648
Epoch:  149  	Training Loss: 0.01649320125579834
Test Loss:  0.013814106583595276
Valid Loss:  0.018283477053046227
Epoch:  150  	Training Loss: 0.016493026167154312
Test Loss:  0.013813466764986515
Valid Loss:  0.018282581120729446
Epoch:  151  	Training Loss: 0.016492854803800583
Test Loss:  0.0138128362596035
Valid Loss:  0.018281694501638412
Epoch:  152  	Training Loss: 0.016492687165737152
Test Loss:  0.013812216930091381
Valid Loss:  0.01828082464635372
Epoch:  153  	Training Loss: 0.01649252325296402
Test Loss:  0.01381160318851471
Valid Loss:  0.018279965966939926
Epoch:  154  	Training Loss: 0.016492359340190887
Test Loss:  0.01381099782884121
Valid Loss:  0.018279118463397026
Epoch:  155  	Training Loss: 0.016492201015353203
Test Loss:  0.013810405507683754
Valid Loss:  0.01827828399837017
Epoch:  156  	Training Loss: 0.016492046415805817
Test Loss:  0.013809820637106895
Valid Loss:  0.018277466297149658
Epoch:  157  	Training Loss: 0.016491897404193878
Test Loss:  0.013809246942400932
Valid Loss:  0.01827665977180004
Epoch:  158  	Training Loss: 0.01649175025522709
Test Loss:  0.013808625750243664
Valid Loss:  0.01827607862651348
Epoch:  159  	Training Loss: 0.016491614282131195
Test Loss:  0.013808096759021282
Valid Loss:  0.018275244161486626
Epoch:  160  	Training Loss: 0.016491476446390152
Test Loss:  0.013807514682412148
Valid Loss:  0.01827465184032917
Epoch:  161  	Training Loss: 0.016491346061229706
Test Loss:  0.013807014562189579
Valid Loss:  0.018273813650012016
Epoch:  162  	Training Loss: 0.01649121567606926
Test Loss:  0.013806460425257683
Valid Loss:  0.018273230642080307
Epoch:  163  	Training Loss: 0.01649109460413456
Test Loss:  0.013805985450744629
Valid Loss:  0.018272409215569496
Epoch:  164  	Training Loss: 0.016490977257490158
Test Loss:  0.013805449940264225
Valid Loss:  0.01827184110879898
Epoch:  165  	Training Loss: 0.016490858048200607
Test Loss:  0.013804994523525238
Valid Loss:  0.018271038308739662
Epoch:  166  	Training Loss: 0.016490746289491653
Test Loss:  0.013804478570818901
Valid Loss:  0.01827048510313034
Epoch:  167  	Training Loss: 0.0164906345307827
Test Loss:  0.013804039917886257
Valid Loss:  0.018269699066877365
Epoch:  168  	Training Loss: 0.016490532085299492
Test Loss:  0.013803539797663689
Valid Loss:  0.018269170075654984
Epoch:  169  	Training Loss: 0.016490422189235687
Test Loss:  0.013803061097860336
Valid Loss:  0.018268615007400513
Epoch:  170  	Training Loss: 0.016490325331687927
Test Loss:  0.013802656903862953
Valid Loss:  0.018267840147018433
Epoch:  171  	Training Loss: 0.01649022474884987
Test Loss:  0.013802186585962772
Valid Loss:  0.018267320469021797
Epoch:  172  	Training Loss: 0.016490131616592407
Test Loss:  0.01380179077386856
Valid Loss:  0.018266573548316956
Epoch:  173  	Training Loss: 0.016490032896399498
Test Loss:  0.013801325112581253
Valid Loss:  0.018266083672642708
Epoch:  174  	Training Loss: 0.016489943489432335
Test Loss:  0.01380094327032566
Valid Loss:  0.018265360966324806
Epoch:  175  	Training Loss: 0.01648985594511032
Test Loss:  0.013800268992781639
Valid Loss:  0.018265709280967712
Epoch:  176  	Training Loss: 0.016489800065755844
Test Loss:  0.013799998909235
Valid Loss:  0.01826479099690914
Epoch:  177  	Training Loss: 0.016489725559949875
Test Loss:  0.013799414038658142
Valid Loss:  0.0182650163769722
Epoch:  178  	Training Loss: 0.0164896659553051
Test Loss:  0.013799147680401802
Valid Loss:  0.018264222890138626
Epoch:  179  	Training Loss: 0.01648961752653122
Test Loss:  0.01379869133234024
Valid Loss:  0.018264135345816612
Epoch:  180  	Training Loss: 0.016489561647176743
Test Loss:  0.013798238709568977
Valid Loss:  0.0182641614228487
Epoch:  181  	Training Loss: 0.016489513218402863
Test Loss:  0.013797853142023087
Valid Loss:  0.01826406829059124
Epoch:  182  	Training Loss: 0.01648947224020958
Test Loss:  0.013797516003251076
Valid Loss:  0.01826389506459236
Epoch:  183  	Training Loss: 0.016489438712596893
Test Loss:  0.013797208666801453
Valid Loss:  0.018263671547174454
Epoch:  184  	Training Loss: 0.016489407047629356
Test Loss:  0.01379692368209362
Valid Loss:  0.018263408914208412
Epoch:  185  	Training Loss: 0.01648937352001667
Test Loss:  0.013796656392514706
Valid Loss:  0.01826312579214573
Epoch:  186  	Training Loss: 0.016489345580339432
Test Loss:  0.013796401210129261
Valid Loss:  0.018262825906276703
Epoch:  187  	Training Loss: 0.016489315778017044
Test Loss:  0.013796155340969563
Valid Loss:  0.01826252043247223
Epoch:  188  	Training Loss: 0.016489289700984955
Test Loss:  0.013795914128422737
Valid Loss:  0.018262211233377457
Epoch:  189  	Training Loss: 0.016489263623952866
Test Loss:  0.013795680366456509
Valid Loss:  0.018261902034282684
Epoch:  190  	Training Loss: 0.016489237546920776
Test Loss:  0.013795451261103153
Valid Loss:  0.018261589109897614
Epoch:  191  	Training Loss: 0.016489211469888687
Test Loss:  0.013795226812362671
Valid Loss:  0.01826128363609314
Epoch:  192  	Training Loss: 0.016489187255501747
Test Loss:  0.013795005157589912
Valid Loss:  0.018260974436998367
Epoch:  193  	Training Loss: 0.016489163041114807
Test Loss:  0.013794789090752602
Valid Loss:  0.018260672688484192
Epoch:  194  	Training Loss: 0.016489138826727867
Test Loss:  0.01379457488656044
Valid Loss:  0.018260372802615166
Epoch:  195  	Training Loss: 0.016489114612340927
Test Loss:  0.013794363476336002
Valid Loss:  0.018260076642036438
Epoch:  196  	Training Loss: 0.016489090397953987
Test Loss:  0.013794154860079288
Valid Loss:  0.01825978420674801
Epoch:  197  	Training Loss: 0.016489066183567047
Test Loss:  0.013793950900435448
Valid Loss:  0.01825949363410473
Epoch:  198  	Training Loss: 0.016489043831825256
Test Loss:  0.013793750666081905
Valid Loss:  0.018259208649396896
Epoch:  199  	Training Loss: 0.016489021480083466
Test Loss:  0.013793550431728363
Valid Loss:  0.01825892925262451
Epoch:  200  	Training Loss: 0.016488999128341675
Test Loss:  0.013793352991342545
Valid Loss:  0.018258651718497276
Epoch:  201  	Training Loss: 0.016488976776599884
Test Loss:  0.013793161138892174
Valid Loss:  0.01825837790966034
Epoch:  202  	Training Loss: 0.01648895815014839
Test Loss:  0.013792971149086952
Valid Loss:  0.0182581078261137
Epoch:  203  	Training Loss: 0.0164889395236969
Test Loss:  0.01379278302192688
Valid Loss:  0.01825784519314766
Epoch:  204  	Training Loss: 0.016488920897245407
Test Loss:  0.01379259955137968
Valid Loss:  0.01825758069753647
Epoch:  205  	Training Loss: 0.016488904133439064
Test Loss:  0.01379241794347763
Valid Loss:  0.018257325515151024
Epoch:  206  	Training Loss: 0.016488883644342422
Test Loss:  0.013792240060865879
Valid Loss:  0.018257075920701027
Epoch:  207  	Training Loss: 0.01648886688053608
Test Loss:  0.013792064972221851
Valid Loss:  0.01825682446360588
Epoch:  208  	Training Loss: 0.016488850116729736
Test Loss:  0.013791888952255249
Valid Loss:  0.018256578594446182
Epoch:  209  	Training Loss: 0.016488835215568542
Test Loss:  0.013791719451546669
Valid Loss:  0.018256336450576782
Epoch:  210  	Training Loss: 0.0164888184517622
Test Loss:  0.01379154808819294
Valid Loss:  0.018256094306707382
Epoch:  211  	Training Loss: 0.016488803550601006
Test Loss:  0.013791382312774658
Valid Loss:  0.018255863338708878
Epoch:  212  	Training Loss: 0.01648878864943981
Test Loss:  0.01379122119396925
Valid Loss:  0.018255628645420074
Epoch:  213  	Training Loss: 0.016488773748278618
Test Loss:   43%|████▎     | 213/500 [02:32<04:09,  1.15it/s] 43%|████▎     | 215/500 [02:32<03:00,  1.58it/s] 43%|████▎     | 217/500 [02:32<02:12,  2.14it/s] 44%|████▍     | 219/500 [02:33<01:39,  2.83it/s] 44%|████▍     | 221/500 [02:39<05:36,  1.21s/it] 45%|████▍     | 223/500 [02:39<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:39<02:52,  1.60it/s] 45%|████▌     | 227/500 [02:39<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:40<01:32,  2.91it/s] 46%|████▌     | 231/500 [02:46<05:27,  1.22s/it] 47%|████▋     | 233/500 [02:46<03:52,  1.15it/s] 47%|████▋     | 235/500 [02:46<02:47,  1.59it/s] 47%|████▋     | 237/500 [02:46<02:01,  2.17it/s] 48%|████▊     | 239/500 [02:47<01:29,  2.91it/s] 48%|████▊     | 241/500 [02:53<05:10,  1.20s/it] 49%|████▊     | 243/500 [02:53<03:42,  1.16it/s] 49%|████▉     | 245/500 [02:53<02:41,  1.58it/s] 49%|████▉     | 247/500 [02:54<01:58,  2.13it/s] 50%|████▉     | 249/500 [02:54<01:28,  2.83it/s] 50%|█████     | 251/500 [03:00<04:58,  1.20s/it] 51%|█████     | 253/500 [03:00<03:32,  1.16it/s] 51%|█████     | 255/500 [03:00<02:32,  1.61it/s] 51%|█████▏    | 257/500 [03:00<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:01<01:21,  2.95it/s] 52%|█████▏    | 261/500 [03:07<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:07<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:07<02:23,  1.63it/s] 53%|█████▎    | 267/500 [03:07<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:07<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:14<04:33,  1.19s/it] 55%|█████▍    | 273/500 [03:14<03:15,  1.16it/s] 55%|█████▌    | 275/500 [03:14<02:21,  1.59it/s] 55%|█████▌    | 277/500 [03:14<01:44,  2.14it/s] 56%|█████▌    | 279/500 [03:14<01:17,  2.84it/s] 56%|█████▌    | 281/500 [03:21<04:22,  1.20s/it] 57%|█████▋    | 283/500 [03:21<03:06,  1.16it/s]0.013791061006486416
Valid Loss:  0.01825539954006672
Epoch:  214  	Training Loss: 0.016488760709762573
Test Loss:  0.013790899887681007
Valid Loss:  0.018255174160003662
Epoch:  215  	Training Loss: 0.01648874767124653
Test Loss:  0.013790743425488472
Valid Loss:  0.018254954367876053
Epoch:  216  	Training Loss: 0.016488736495375633
Test Loss:  0.013790592551231384
Valid Loss:  0.018254734575748444
Epoch:  217  	Training Loss: 0.01648872345685959
Test Loss:  0.013790438883006573
Valid Loss:  0.01825452223420143
Epoch:  218  	Training Loss: 0.016488712280988693
Test Loss:  0.013790290802717209
Valid Loss:  0.01825430989265442
Epoch:  219  	Training Loss: 0.016488701105117798
Test Loss:  0.01379014365375042
Valid Loss:  0.018254097551107407
Epoch:  220  	Training Loss: 0.016488689929246902
Test Loss:  0.013789995573461056
Valid Loss:  0.018253890797495842
Epoch:  221  	Training Loss: 0.016488678753376007
Test Loss:  0.013789854012429714
Valid Loss:  0.018253687769174576
Epoch:  222  	Training Loss: 0.01648866944015026
Test Loss:  0.013789714314043522
Valid Loss:  0.018253490328788757
Epoch:  223  	Training Loss: 0.016488660126924515
Test Loss:  0.013789583928883076
Valid Loss:  0.01825329288840294
Epoch:  224  	Training Loss: 0.016488652676343918
Test Loss:  0.013789458200335503
Valid Loss:  0.01825309917330742
Epoch:  225  	Training Loss: 0.01648864522576332
Test Loss:  0.013789333403110504
Valid Loss:  0.018252907320857048
Epoch:  226  	Training Loss: 0.016488637775182724
Test Loss:  0.013789207674562931
Valid Loss:  0.018252722918987274
Epoch:  227  	Training Loss: 0.016488630324602127
Test Loss:  0.013789089396595955
Valid Loss:  0.01825253665447235
Epoch:  228  	Training Loss: 0.01648862473666668
Test Loss:  0.013788968324661255
Valid Loss:  0.018252354115247726
Epoch:  229  	Training Loss: 0.016488617286086082
Test Loss:  0.013788847252726555
Valid Loss:  0.0182521753013134
Epoch:  230  	Training Loss: 0.016488611698150635
Test Loss:  0.013788731768727303
Valid Loss:  0.018251996487379074
Epoch:  231  	Training Loss: 0.016488604247570038
Test Loss:  0.01378861628472805
Valid Loss:  0.018251817673444748
Epoch:  232  	Training Loss: 0.01648859679698944
Test Loss:  0.013788500800728798
Valid Loss:  0.01825164444744587
Epoch:  233  	Training Loss: 0.016488589346408844
Test Loss:  0.013788387179374695
Valid Loss:  0.01825147308409214
Epoch:  234  	Training Loss: 0.016488581895828247
Test Loss:  0.013788275420665741
Valid Loss:  0.01825130358338356
Epoch:  235  	Training Loss: 0.01648857444524765
Test Loss:  0.013788165524601936
Valid Loss:  0.01825113222002983
Epoch:  236  	Training Loss: 0.016488565132021904
Test Loss:  0.013788055628538132
Valid Loss:  0.0182509683072567
Epoch:  237  	Training Loss: 0.016488555818796158
Test Loss:  0.013787944801151752
Valid Loss:  0.018250808119773865
Epoch:  238  	Training Loss: 0.01648855023086071
Test Loss:  0.013787839561700821
Valid Loss:  0.018250644207000732
Epoch:  239  	Training Loss: 0.016488542780280113
Test Loss:  0.01378773432224989
Valid Loss:  0.0182504802942276
Epoch:  240  	Training Loss: 0.016488533467054367
Test Loss:  0.013787629082798958
Valid Loss:  0.018250327557325363
Epoch:  241  	Training Loss: 0.01648852787911892
Test Loss:  0.013787530362606049
Valid Loss:  0.01825016923248768
Epoch:  242  	Training Loss: 0.016488518565893173
Test Loss:  0.013787454925477505
Valid Loss:  0.01825001835823059
Epoch:  243  	Training Loss: 0.016488512977957726
Test Loss:  0.01378738321363926
Valid Loss:  0.018249869346618652
Epoch:  244  	Training Loss: 0.016488507390022278
Test Loss:  0.013787307776510715
Valid Loss:  0.018249718472361565
Epoch:  245  	Training Loss: 0.01648849993944168
Test Loss:  0.013787235133349895
Valid Loss:  0.018249573186039925
Epoch:  246  	Training Loss: 0.016488494351506233
Test Loss:  0.0137871652841568
Valid Loss:  0.018249429762363434
Epoch:  247  	Training Loss: 0.016488488763570786
Test Loss:  0.013787094503641129
Valid Loss:  0.018249288201332092
Epoch:  248  	Training Loss: 0.016488483175635338
Test Loss:  0.013787025585770607
Valid Loss:  0.01824914664030075
Epoch:  249  	Training Loss: 0.01648847758769989
Test Loss:  0.013786956667900085
Valid Loss:  0.018249008804559708
Epoch:  250  	Training Loss: 0.01648847386240959
Test Loss:  0.013786889612674713
Valid Loss:  0.018248870968818665
Epoch:  251  	Training Loss: 0.016488466411828995
Test Loss:  0.01378682255744934
Valid Loss:  0.01824873872101307
Epoch:  252  	Training Loss: 0.016488462686538696
Test Loss:  0.013786758296191692
Valid Loss:  0.018248604610562325
Epoch:  253  	Training Loss: 0.016488458961248398
Test Loss:  0.013786694034934044
Valid Loss:  0.01824847422540188
Epoch:  254  	Training Loss: 0.0164884552359581
Test Loss:  0.01378663070499897
Valid Loss:  0.01824834756553173
Epoch:  255  	Training Loss: 0.0164884515106678
Test Loss:  0.013786567375063896
Valid Loss:  0.018248219043016434
Epoch:  256  	Training Loss: 0.016488444060087204
Test Loss:  0.013786504045128822
Valid Loss:  0.018248094245791435
Epoch:  257  	Training Loss: 0.016488440334796906
Test Loss:  0.013786444440484047
Valid Loss:  0.018247971311211586
Epoch:  258  	Training Loss: 0.016488434746861458
Test Loss:  0.013786383904516697
Valid Loss:  0.018247850239276886
Epoch:  259  	Training Loss: 0.01648843288421631
Test Loss:  0.013786325231194496
Valid Loss:  0.018247731029987335
Epoch:  260  	Training Loss: 0.01648842915892601
Test Loss:  0.01378626748919487
Valid Loss:  0.018247613683342934
Epoch:  261  	Training Loss: 0.01648842543363571
Test Loss:  0.013786211609840393
Valid Loss:  0.018247496336698532
Epoch:  262  	Training Loss: 0.01648842543363571
Test Loss:  0.013786155730485916
Valid Loss:  0.01824738085269928
Epoch:  263  	Training Loss: 0.016488421708345413
Test Loss:  0.01378609798848629
Valid Loss:  0.018247267231345177
Epoch:  264  	Training Loss: 0.016488414257764816
Test Loss:  0.013786042109131813
Valid Loss:  0.018247157335281372
Epoch:  265  	Training Loss: 0.016488410532474518
Test Loss:  0.013785986229777336
Valid Loss:  0.018247045576572418
Epoch:  266  	Training Loss: 0.01648840866982937
Test Loss:  0.013785934075713158
Valid Loss:  0.018246935680508614
Epoch:  267  	Training Loss: 0.01648840494453907
Test Loss:  0.01378588005900383
Valid Loss:  0.018246827647089958
Epoch:  268  	Training Loss: 0.01648840308189392
Test Loss:  0.013785827904939651
Valid Loss:  0.018246721476316452
Epoch:  269  	Training Loss: 0.016488399356603622
Test Loss:  0.013785775750875473
Valid Loss:  0.018246617168188095
Epoch:  270  	Training Loss: 0.016488399356603622
Test Loss:  0.013785725459456444
Valid Loss:  0.018246512860059738
Epoch:  271  	Training Loss: 0.016488395631313324
Test Loss:  0.013785677030682564
Valid Loss:  0.01824641041457653
Epoch:  272  	Training Loss: 0.016488391906023026
Test Loss:  0.013785628601908684
Valid Loss:  0.01824631169438362
Epoch:  273  	Training Loss: 0.016488388180732727
Test Loss:  0.013785578310489655
Valid Loss:  0.018246211111545563
Epoch:  274  	Training Loss: 0.01648838445544243
Test Loss:  0.013785529881715775
Valid Loss:  0.018246114253997803
Epoch:  275  	Training Loss: 0.01648838259279728
Test Loss:  0.013785483315587044
Valid Loss:  0.018246013671159744
Epoch:  276  	Training Loss: 0.01648838073015213
Test Loss:  0.013785436749458313
Valid Loss:  0.018245920538902283
Epoch:  277  	Training Loss: 0.01648837700486183
Test Loss:  0.013785390183329582
Valid Loss:  0.01824582740664482
Epoch:  278  	Training Loss: 0.016488375142216682
Test Loss:  0.013785343617200851
Valid Loss:  0.01824573241174221
Epoch:  279  	Training Loss: 0.016488371416926384
Test Loss:  0.013785299845039845
Valid Loss:  0.018245641142129898
Epoch:  280  	Training Loss: 0.016488369554281235
Test Loss:  0.013785254210233688
Valid Loss:  0.018245551735162735
Epoch:  281  	Training Loss: 0.016488367691636086
Test Loss:  0.013785210438072681
Valid Loss:  0.01824546605348587
Epoch:  282  	Training Loss: 0.016488365828990936
Test Loss:  0.013785166665911674
Valid Loss:  0.018245376646518707
Epoch:  283  	Training Loss: 0.016488362103700638
Test Loss:  0.013785125687718391
Valid Loss:  0.018245289102196693
 57%|█████▋    | 285/500 [03:27<05:34,  1.55s/it] 57%|█████▋    | 287/500 [03:27<03:56,  1.11s/it] 58%|█████▊    | 289/500 [03:28<02:48,  1.26it/s] 58%|█████▊    | 289/500 [03:40<02:48,  1.26it/s] 58%|█████▊    | 291/500 [03:40<08:34,  2.46s/it] 59%|█████▊    | 293/500 [03:40<06:01,  1.75s/it] 59%|█████▉    | 295/500 [03:47<07:22,  2.16s/it] 59%|█████▉    | 297/500 [03:47<05:11,  1.53s/it] 60%|█████▉    | 299/500 [03:47<03:39,  1.09s/it] 60%|██████    | 301/500 [03:59<08:40,  2.62s/it] 61%|██████    | 303/500 [03:59<06:04,  1.85s/it] 61%|██████    | 305/500 [04:06<07:15,  2.23s/it] 61%|██████▏   | 307/500 [04:06<05:05,  1.59s/it] 62%|██████▏   | 309/500 [04:06<03:35,  1.13s/it] 62%|██████▏   | 311/500 [04:19<08:33,  2.72s/it] 63%|██████▎   | 313/500 [04:19<06:00,  1.93s/it] 63%|██████▎   | 315/500 [04:26<07:13,  2.34s/it] 63%|██████▎   | 317/500 [04:26<05:04,  1.66s/it] 64%|██████▍   | 319/500 [04:26<03:34,  1.18s/it] 64%|██████▍   | 321/500 [04:39<08:08,  2.73s/it] 65%|██████▍   | 323/500 [04:39<05:42,  1.93s/it] 65%|██████▌   | 325/500 [04:45<06:43,  2.30s/it] 65%|██████▌   | 327/500 [04:45<04:43,  1.64s/it] 66%|██████▌   | 329/500 [04:45<03:19,  1.17s/it] 66%|██████▌   | 331/500 [04:58<07:44,  2.75s/it] 67%|██████▋   | 333/500 [04:58<05:25,  1.95s/it] 67%|██████▋   | 335/500 [05:05<06:18,  2.30s/it] 67%|██████▋   | 337/500 [05:05<04:26,  1.63s/it] 68%|██████▊   | 339/500 [05:05<03:08,  1.17s/it] 68%|██████▊   | 341/500 [05:18<07:15,  2.74s/it]Epoch:  284  	Training Loss: 0.01648835837841034
Test Loss:  0.013785081915557384
Valid Loss:  0.01824520155787468
Epoch:  285  	Training Loss: 0.01648835837841034
Test Loss:  0.013785040006041527
Valid Loss:  0.018245119601488113
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.01648835465312004
Test Loss:  0.01378502044826746
Valid Loss:  0.01824507862329483
Epoch:  287  	Training Loss: 0.01648835465312004
Test Loss:  0.013784999959170818
Valid Loss:  0.018245037645101547
Epoch:  288  	Training Loss: 0.01648835465312004
Test Loss:  0.013784980401396751
Valid Loss:  0.018244996666908264
Epoch:  289  	Training Loss: 0.016488350927829742
Test Loss:  0.01378495991230011
Valid Loss:  0.01824495568871498
Epoch:  290  	Training Loss: 0.016488350927829742
Test Loss:  0.013784939423203468
Valid Loss:  0.018244914710521698
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.016488350927829742
Test Loss:  0.013784929178655148
Valid Loss:  0.018244896084070206
Epoch:  292  	Training Loss: 0.016488350927829742
Test Loss:  0.013784919865429401
Valid Loss:  0.018244875594973564
Epoch:  293  	Training Loss: 0.016488349065184593
Test Loss:  0.01378490962088108
Valid Loss:  0.018244855105876923
Epoch:  294  	Training Loss: 0.016488347202539444
Test Loss:  0.013784898445010185
Valid Loss:  0.01824483461678028
Epoch:  295  	Training Loss: 0.016488349065184593
Test Loss:  0.013784889131784439
Valid Loss:  0.01824481599032879
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.016488349065184593
Test Loss:  0.01378488540649414
Valid Loss:  0.018244806677103043
Epoch:  297  	Training Loss: 0.016488347202539444
Test Loss:  0.013784879818558693
Valid Loss:  0.018244797363877296
Epoch:  298  	Training Loss: 0.016488347202539444
Test Loss:  0.013784874230623245
Valid Loss:  0.018244784325361252
Epoch:  299  	Training Loss: 0.016488347202539444
Test Loss:  0.013784869574010372
Valid Loss:  0.018244776874780655
Epoch:  300  	Training Loss: 0.016488347202539444
Test Loss:  0.013784864917397499
Valid Loss:  0.01824476569890976
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.016488347202539444
Test Loss:  0.01378486305475235
Valid Loss:  0.01824476197361946
Epoch:  302  	Training Loss: 0.016488347202539444
Test Loss:  0.0137848611921072
Valid Loss:  0.018244756385684013
Epoch:  303  	Training Loss: 0.016488347202539444
Test Loss:  0.013784857466816902
Valid Loss:  0.018244750797748566
Epoch:  304  	Training Loss: 0.016488343477249146
Test Loss:  0.013784855604171753
Valid Loss:  0.018244747072458267
Epoch:  305  	Training Loss: 0.016488345339894295
Test Loss:  0.013784853741526604
Valid Loss:  0.01824474148452282
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.016488343477249146
Test Loss:  0.013784851878881454
Valid Loss:  0.01824473962187767
Epoch:  307  	Training Loss: 0.016488345339894295
Test Loss:  0.013784851878881454
Valid Loss:  0.01824473775923252
Epoch:  308  	Training Loss: 0.016488343477249146
Test Loss:  0.013784850016236305
Valid Loss:  0.018244735896587372
Epoch:  309  	Training Loss: 0.016488343477249146
Test Loss:  0.013784848153591156
Valid Loss:  0.018244732171297073
Epoch:  310  	Training Loss: 0.016488343477249146
Test Loss:  0.013784847222268581
Valid Loss:  0.018244730308651924
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.016488345339894295
Test Loss:  0.013784846290946007
Valid Loss:  0.018244728446006775
Epoch:  312  	Training Loss: 0.016488345339894295
Test Loss:  0.013784847222268581
Valid Loss:  0.018244728446006775
Epoch:  313  	Training Loss: 0.016488343477249146
Test Loss:  0.013784845359623432
Valid Loss:  0.018244726583361626
Epoch:  314  	Training Loss: 0.016488345339894295
Test Loss:  0.013784844428300858
Valid Loss:  0.018244724720716476
Epoch:  315  	Training Loss: 0.016488345339894295
Test Loss:  0.013784844428300858
Valid Loss:  0.018244722858071327
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.016488345339894295
Test Loss:  0.013784844428300858
Valid Loss:  0.018244720995426178
Epoch:  317  	Training Loss: 0.016488345339894295
Test Loss:  0.013784844428300858
Valid Loss:  0.018244720995426178
Epoch:  318  	Training Loss: 0.016488343477249146
Test Loss:  0.013784843496978283
Valid Loss:  0.018244720995426178
Epoch:  319  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.018244720995426178
Epoch:  320  	Training Loss: 0.016488343477249146
Test Loss:  0.013784844428300858
Valid Loss:  0.018244720995426178
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.018244720995426178
Epoch:  322  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.018244720995426178
Epoch:  323  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.018244720995426178
Epoch:  324  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.018244720995426178
Epoch:  325  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471913278103
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  327  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471913278103
Epoch:  328  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471913278103
Epoch:  329  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471913278103
Epoch:  330  	Training Loss: 0.016488345339894295
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471913278103
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  332  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  333  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  334  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  335  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  337  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  338  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471913278103
Epoch:  339  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  340  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
 69%|██████▊   | 343/500 [05:18<05:04,  1.94s/it] 69%|██████▉   | 345/500 [05:24<05:56,  2.30s/it] 69%|██████▉   | 347/500 [05:24<04:09,  1.63s/it] 70%|██████▉   | 349/500 [05:24<02:55,  1.16s/it] 70%|███████   | 351/500 [05:37<06:41,  2.69s/it] 71%|███████   | 353/500 [05:37<04:40,  1.91s/it] 71%|███████   | 355/500 [05:44<05:31,  2.28s/it] 71%|███████▏  | 357/500 [05:44<03:52,  1.63s/it] 72%|███████▏  | 359/500 [05:44<02:44,  1.16s/it] 72%|███████▏  | 361/500 [05:57<06:19,  2.73s/it] 73%|███████▎  | 363/500 [05:57<04:24,  1.93s/it] 73%|███████▎  | 365/500 [06:03<05:15,  2.34s/it] 73%|███████▎  | 367/500 [06:03<03:41,  1.66s/it] 74%|███████▍  | 369/500 [06:04<02:35,  1.19s/it] 74%|███████▍  | 370/500 [06:10<04:31,  2.09s/it] 74%|███████▍  | 371/500 [06:16<06:18,  2.93s/it] 75%|███████▍  | 373/500 [06:16<03:59,  1.89s/it] 75%|███████▌  | 375/500 [06:23<04:52,  2.34s/it] 75%|███████▌  | 377/500 [06:23<03:16,  1.59s/it] 76%|███████▌  | 379/500 [06:23<02:13,  1.11s/it] 76%|███████▌  | 381/500 [06:35<05:22,  2.71s/it] 77%|███████▋  | 383/500 [06:36<03:41,  1.89s/it] 77%|███████▋  | 385/500 [06:42<04:24,  2.30s/it] 77%|███████▋  | 387/500 [06:42<03:03,  1.62s/it] 78%|███████▊  | 389/500 [06:42<02:08,  1.16s/it] 78%|███████▊  | 390/500 [06:49<03:48,  2.08s/it] 78%|███████▊  | 391/500 [06:55<05:19,  2.93s/it] 79%|███████▊  | 393/500 [06:55<03:21,  1.88s/it] 79%|███████▉  | 395/500 [07:01<04:03,  2.32s/it] 79%|███████▉  | 397/500 [07:02<02:43,  1.58s/it] 80%|███████▉  | 399/500 [07:02<01:50,  1.10s/it]Epoch:  342  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  343  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  344  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  345  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  347  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  348  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  349  	Training Loss: 0.016488343477249146
Test Loss:  0.013784843496978283
Valid Loss:  0.01824471913278103
Epoch:  350  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  352  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  353  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  354  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  355  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  357  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  358  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  359  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  360  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  362  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  363  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  364  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  365  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  367  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  368  	Training Loss: 0.016488343477249146
Test Loss:  0.013784840703010559
Valid Loss:  0.01824471727013588
Epoch:  369  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  370  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  372  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  373  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  374  	Training Loss: 0.016488343477249146
Test Loss:  0.013784840703010559
Valid Loss:  0.01824471540749073
Epoch:  375  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  377  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  378  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  379  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  380  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  382  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  383  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  384  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  385  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  387  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  388  	Training Loss: 0.016488345339894295
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  389  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  390  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  392  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  393  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  394  	Training Loss: 0.016488345339894295
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471913278103
Epoch:  395  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  397  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  398  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  399  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  400  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
 80%|████████  | 401/500 [07:14<04:29,  2.72s/it] 81%|████████  | 403/500 [07:14<03:04,  1.90s/it] 81%|████████  | 405/500 [07:21<03:39,  2.31s/it] 81%|████████▏ | 407/500 [07:21<02:31,  1.63s/it] 82%|████████▏ | 409/500 [07:21<01:44,  1.15s/it] 82%|████████▏ | 411/500 [07:34<04:00,  2.71s/it] 83%|████████▎ | 413/500 [07:34<02:46,  1.92s/it] 83%|████████▎ | 415/500 [07:41<03:18,  2.34s/it] 83%|████████▎ | 417/500 [07:41<02:17,  1.65s/it] 84%|████████▍ | 419/500 [07:41<01:35,  1.18s/it] 84%|████████▍ | 421/500 [07:54<03:36,  2.73s/it] 85%|████████▍ | 423/500 [07:54<02:29,  1.94s/it] 85%|████████▌ | 425/500 [08:00<02:54,  2.33s/it] 85%|████████▌ | 427/500 [08:00<02:00,  1.65s/it] 86%|████████▌ | 429/500 [08:01<01:23,  1.18s/it] 86%|████████▌ | 431/500 [08:14<03:12,  2.79s/it] 87%|████████▋ | 433/500 [08:14<02:11,  1.97s/it] 87%|████████▋ | 435/500 [08:20<02:31,  2.33s/it] 87%|████████▋ | 437/500 [08:20<01:44,  1.66s/it] 88%|████████▊ | 439/500 [08:20<01:11,  1.18s/it] 88%|████████▊ | 441/500 [08:33<02:40,  2.72s/it] 89%|████████▊ | 443/500 [08:33<01:49,  1.93s/it] 89%|████████▉ | 445/500 [08:39<02:05,  2.29s/it] 89%|████████▉ | 447/500 [08:40<01:26,  1.63s/it] 90%|████████▉ | 449/500 [08:40<00:59,  1.17s/it] 90%|████████▉ | 449/500 [08:50<00:59,  1.17s/it] 90%|█████████ | 451/500 [08:53<02:13,  2.73s/it] 91%|█████████ | 453/500 [08:53<01:30,  1.93s/it] 91%|█████████ | 455/500 [08:59<01:44,  2.31s/it] 91%|█████████▏| 457/500 [08:59<01:10,  1.64s/it]**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  402  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  403  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  404  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  405  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  407  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  408  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  409  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  410  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  412  	Training Loss: 0.016488345339894295
Test Loss:  0.013784840703010559
Valid Loss:  0.01824471727013588
Epoch:  413  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  414  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  415  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  417  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  418  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  419  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  420  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  422  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  423  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  424  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  425  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  427  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  428  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  429  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  430  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  432  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  433  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  434  	Training Loss: 0.016488343477249146
Test Loss:  0.013784843496978283
Valid Loss:  0.01824471727013588
Epoch:  435  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  437  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  438  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  439  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  440  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  442  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  443  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  444  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  445  	Training Loss: 0.016488345339894295
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.016488343477249146
Test Loss:  0.013784840703010559
Valid Loss:  0.01824471727013588
Epoch:  447  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  448  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  449  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  450  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  452  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  453  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  454  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  455  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  457  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  458  	Training Loss: 0.016488345339894295
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
 92%|█████████▏| 459/500 [08:59<00:48,  1.17s/it] 92%|█████████▏| 459/500 [09:10<00:48,  1.17s/it] 92%|█████████▏| 461/500 [09:12<01:47,  2.75s/it] 93%|█████████▎| 463/500 [09:12<01:12,  1.95s/it] 93%|█████████▎| 465/500 [09:19<01:21,  2.33s/it] 93%|█████████▎| 467/500 [09:19<00:54,  1.66s/it] 94%|█████████▍| 469/500 [09:19<00:36,  1.19s/it] 94%|█████████▍| 470/500 [09:26<01:03,  2.10s/it] 94%|█████████▍| 471/500 [09:32<01:26,  2.97s/it] 95%|█████████▍| 473/500 [09:32<00:51,  1.92s/it] 95%|█████████▌| 475/500 [09:39<00:59,  2.39s/it] 95%|█████████▌| 477/500 [09:39<00:37,  1.63s/it] 96%|█████████▌| 479/500 [09:39<00:23,  1.14s/it] 96%|█████████▌| 480/500 [09:45<00:42,  2.10s/it] 96%|█████████▌| 481/500 [09:52<00:57,  3.02s/it] 97%|█████████▋| 483/500 [09:52<00:32,  1.92s/it] 97%|█████████▋| 485/500 [09:59<00:35,  2.39s/it] 97%|█████████▋| 486/500 [09:59<00:27,  1.93s/it] 98%|█████████▊| 488/500 [09:59<00:15,  1.26s/it] 98%|█████████▊| 490/500 [10:05<00:19,  1.94s/it] 98%|█████████▊| 491/500 [10:12<00:25,  2.78s/it] 99%|█████████▊| 493/500 [10:12<00:12,  1.81s/it] 99%|█████████▉| 495/500 [10:18<00:11,  2.28s/it] 99%|█████████▉| 497/500 [10:18<00:04,  1.56s/it]100%|█████████▉| 499/500 [10:18<00:01,  1.09s/it]100%|██████████| 500/500 [10:25<00:00,  2.06s/it]100%|██████████| 500/500 [10:25<00:00,  1.25s/it]
Epoch:  459  	Training Loss: 0.016488343477249146
Test Loss:  0.013784840703010559
Valid Loss:  0.01824471727013588
Epoch:  460  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  462  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  463  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  464  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  465  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  467  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  468  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  469  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  470  	Training Loss: 0.016488345339894295
Test Loss:  0.013784840703010559
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  472  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  473  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  474  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  475  	Training Loss: 0.016488343477249146
Test Loss:  0.013784843496978283
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  477  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  478  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  479  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  480  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  482  	Training Loss: 0.016488343477249146
Test Loss:  0.013784840703010559
Valid Loss:  0.01824471727013588
Epoch:  483  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  484  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  485  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  487  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  488  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  489  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  490  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  492  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  493  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  494  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  495  	Training Loss: 0.016488345339894295
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  497  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
Epoch:  498  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471913278103
Epoch:  499  	Training Loss: 0.016488343477249146
Test Loss:  0.013784841634333134
Valid Loss:  0.01824471727013588
Epoch:  500  	Training Loss: 0.016488343477249146
Test Loss:  0.013784842565655708
Valid Loss:  0.01824471727013588
**************************************************learning rate decay**************************************************
seed is  2
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:58,  6.37s/it]  1%|          | 3/500 [00:06<14:06,  1.70s/it]  1%|          | 5/500 [00:06<07:07,  1.16it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:55,  2.79it/s]  2%|▏         | 11/500 [00:13<10:56,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.95it/s]  4%|▍         | 21/500 [00:20<09:34,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  3.00it/s]  6%|▌         | 31/500 [00:27<09:21,  1.20s/it]  7%|▋         | 33/500 [00:27<06:40,  1.17it/s]  7%|▋         | 35/500 [00:33<11:54,  1.54s/it]  7%|▋         | 37/500 [00:33<08:27,  1.10s/it]  8%|▊         | 39/500 [00:33<06:02,  1.27it/s]  8%|▊         | 41/500 [00:40<11:38,  1.52s/it]  9%|▊         | 43/500 [00:40<08:17,  1.09s/it]  9%|▉         | 45/500 [00:40<05:55,  1.28it/s]  9%|▉         | 47/500 [00:40<04:16,  1.76it/s] 10%|▉         | 49/500 [00:40<03:07,  2.40it/s] 10%|█         | 51/500 [00:46<09:10,  1.23s/it] 11%|█         | 53/500 [00:47<06:32,  1.14it/s] 11%|█         | 55/500 [00:47<04:42,  1.58it/s] 11%|█▏        | 57/500 [00:47<03:25,  2.16it/s] 12%|█▏        | 59/500 [00:47<02:31,  2.91it/s] 12%|█▏        | 61/500 [00:53<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:53<06:12,  1.17it/s] 13%|█▎        | 65/500 [00:54<04:27,  1.62it/s] 13%|█▎        | 67/500 [00:54<03:15,  2.21it/s]Epoch:  1  	Training Loss: 0.03792910650372505
Test Loss:  0.018300313502550125
Valid Loss:  0.015546232461929321
Epoch:  2  	Training Loss: 0.01663842797279358
Test Loss:  0.6091827154159546
Valid Loss:  0.6180791854858398
Epoch:  3  	Training Loss: 0.6165328025817871
Test Loss:  0.4798583388328552
Valid Loss:  0.4745200574398041
Epoch:  4  	Training Loss: 0.48318588733673096
Test Loss:  0.01831423118710518
Valid Loss:  0.018607255071401596
Epoch:  5  	Training Loss: 0.018831050023436546
Test Loss:  0.01502351462841034
Valid Loss:  0.016241809353232384
Epoch:  6  	Training Loss: 0.015962138772010803
Test Loss:  0.014477615244686604
Valid Loss:  0.01584823802113533
Epoch:  7  	Training Loss: 0.01556079275906086
Test Loss:  0.01426437497138977
Valid Loss:  0.015700459480285645
Epoch:  8  	Training Loss: 0.015403348952531815
Test Loss:  0.01414930447936058
Valid Loss:  0.015623838640749454
Epoch:  9  	Training Loss: 0.015316878445446491
Test Loss:  0.014073645696043968
Valid Loss:  0.015567095018923283
Epoch:  10  	Training Loss: 0.015251824632287025
Test Loss:  0.014023815281689167
Valid Loss:  0.015527397394180298
Epoch:  11  	Training Loss: 0.01520097628235817
Test Loss:  0.013982350938022137
Valid Loss:  0.015494585037231445
Epoch:  12  	Training Loss: 0.015162279829382896
Test Loss:  0.03420837223529816
Valid Loss:  0.03590277582406998
Epoch:  13  	Training Loss: 0.03416761755943298
Test Loss:  0.046515509486198425
Valid Loss:  0.04146195948123932
Epoch:  14  	Training Loss: 0.043142110109329224
Test Loss:  0.015533627942204475
Valid Loss:  0.018367372453212738
Epoch:  15  	Training Loss: 0.016651209443807602
Test Loss:  0.00864499993622303
Valid Loss:  0.009740637615323067
Epoch:  16  	Training Loss: 0.0088933315128088
Test Loss:  0.0023806090466678143
Valid Loss:  0.0029200841672718525
Epoch:  17  	Training Loss: 0.0026311809197068214
Test Loss:  0.0011365138925611973
Valid Loss:  0.0013825579080730677
Epoch:  18  	Training Loss: 0.0012308706063777208
Test Loss:  0.0007579540833830833
Valid Loss:  0.0009540903847664595
Epoch:  19  	Training Loss: 0.0008337895851582289
Test Loss:  0.0005786016117781401
Valid Loss:  0.000733170541934669
Epoch:  20  	Training Loss: 0.000639748468529433
Test Loss:  0.00046041046152822673
Valid Loss:  0.0005957773537375033
Epoch:  21  	Training Loss: 0.000521856069099158
Test Loss:  0.0003856912662740797
Valid Loss:  0.0005058631068095565
Epoch:  22  	Training Loss: 0.00044760946184396744
Test Loss:  0.0003018983989022672
Valid Loss:  0.0004308205971028656
Epoch:  23  	Training Loss: 0.00038257663254626095
Test Loss:  0.00029649518546648324
Valid Loss:  0.00038164170109666884
Epoch:  24  	Training Loss: 0.0003447141498327255
Test Loss:  0.0002453139459248632
Valid Loss:  0.0003448164206929505
Epoch:  25  	Training Loss: 0.00031738393590785563
Test Loss:  0.0002446044818498194
Valid Loss:  0.00031055763247422874
Epoch:  26  	Training Loss: 0.00028890592511743307
Test Loss:  0.00018047586490865797
Valid Loss:  0.0002514577645342797
Epoch:  27  	Training Loss: 0.00024201208725571632
Test Loss:  0.00016497413162142038
Valid Loss:  0.00020409045100677758
Epoch:  28  	Training Loss: 0.00020110142941121012
Test Loss:  0.00011734014697140083
Valid Loss:  0.00016608054284006357
Epoch:  29  	Training Loss: 0.0001760401646606624
Test Loss:  0.00013625847350340337
Valid Loss:  0.00015848237671889365
Epoch:  30  	Training Loss: 0.00016817684809211642
Test Loss:  0.00010864606883842498
Valid Loss:  0.00015575815632473677
Epoch:  31  	Training Loss: 0.0001723470923025161
Test Loss:  0.00016557678463868797
Valid Loss:  0.00017801218200474977
Epoch:  32  	Training Loss: 0.00018535839626565576
Test Loss:  0.00013176281936466694
Valid Loss:  0.00014949546311981976
Epoch:  33  	Training Loss: 0.00016475690063089132
Test Loss:  0.00012152724957559258
Valid Loss:  0.0001413707941537723
Epoch:  34  	Training Loss: 0.00015860996791161597
Test Loss:  0.0001144636917160824
Valid Loss:  0.0001352620020043105
Epoch:  35  	Training Loss: 0.0001537749485578388
Test Loss:  0.00010780474985949695
Valid Loss:  0.00012964176130481064
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.00014880584785714746
Test Loss:  9.929129737429321e-05
Valid Loss:  0.00012380177213344723
Epoch:  37  	Training Loss: 0.00014210352674126625
Test Loss:  9.577600576449186e-05
Valid Loss:  0.0001212337811011821
Epoch:  38  	Training Loss: 0.00013781143934465945
Test Loss:  9.384725126437843e-05
Valid Loss:  0.00011978876864304766
Epoch:  39  	Training Loss: 0.00013462288188748062
Test Loss:  9.271514136344194e-05
Valid Loss:  0.00011888172593899071
Epoch:  40  	Training Loss: 0.0001322285970672965
Test Loss:  9.192101424559951e-05
Valid Loss:  0.00011819050996564329
Epoch:  41  	Training Loss: 0.00013038030010648072
Test Loss:  9.134388528764248e-05
Valid Loss:  0.0001176080695586279
Epoch:  42  	Training Loss: 0.00012887899356428534
Test Loss:  8.628032810520381e-05
Valid Loss:  0.00011362158693373203
Epoch:  43  	Training Loss: 0.00012504475307650864
Test Loss:  8.36570980027318e-05
Valid Loss:  0.00011061701661674306
Epoch:  44  	Training Loss: 0.00012181794591015205
Test Loss:  8.13637234386988e-05
Valid Loss:  0.0001078384811989963
Epoch:  45  	Training Loss: 0.00011893264309037477
Test Loss:  7.940012437757105e-05
Valid Loss:  0.00010551052400842309
Epoch:  46  	Training Loss: 0.0001164281929959543
Test Loss:  7.77590976213105e-05
Valid Loss:  0.00010356493294239044
Epoch:  47  	Training Loss: 0.00011422681563999504
Test Loss:  7.62811687309295e-05
Valid Loss:  0.0001018719922285527
Epoch:  48  	Training Loss: 0.00011225906200706959
Test Loss:  7.51150437281467e-05
Valid Loss:  0.00010047211253549904
Epoch:  49  	Training Loss: 0.00011053211346734315
Test Loss:  7.408108649542555e-05
Valid Loss:  9.92542045423761e-05
Epoch:  50  	Training Loss: 0.00010898784239543602
Test Loss:  7.328892388613895e-05
Valid Loss:  9.825531742535532e-05
Epoch:  51  	Training Loss: 0.0001076114276656881
Test Loss:  7.273696246556938e-05
Valid Loss:  9.743226110003889e-05
Epoch:  52  	Training Loss: 0.00010641368862707168
Test Loss:  7.314846152439713e-05
Valid Loss:  9.777639934327453e-05
Epoch:  53  	Training Loss: 0.00010588212171569467
Test Loss:  7.345675840042531e-05
Valid Loss:  9.805608715396374e-05
Epoch:  54  	Training Loss: 0.00010546413250267506
Test Loss:  7.368644583038986e-05
Valid Loss:  9.827323810895905e-05
Epoch:  55  	Training Loss: 0.00010512115113670006
Test Loss:  7.386814104393125e-05
Valid Loss:  9.843547741184011e-05
Epoch:  56  	Training Loss: 0.00010482767538633198
Test Loss:  7.398224261123687e-05
Valid Loss:  9.854834934230894e-05
Epoch:  57  	Training Loss: 0.00010456528252689168
Test Loss:  7.405014184769243e-05
Valid Loss:  9.861841681413352e-05
Epoch:  58  	Training Loss: 0.00010432488488731906
Test Loss:  7.410109537886456e-05
Valid Loss:  9.865270840236917e-05
Epoch:  59  	Training Loss: 0.00010410044342279434
Test Loss:  7.410795660689473e-05
Valid Loss:  9.865442552836612e-05
Epoch:  60  	Training Loss: 0.00010388954251538962
Test Loss:  7.408263627439737e-05
Valid Loss:  9.862842125585303e-05
Epoch:  61  	Training Loss: 0.00010368658695369959
Test Loss:  7.403620111290365e-05
Valid Loss:  9.858210978563875e-05
Epoch:  62  	Training Loss: 0.00010349490185035393
Test Loss:  7.204341818578541e-05
Valid Loss:  9.689325088402256e-05
Epoch:  63  	Training Loss: 0.00010278666013618931
Test Loss:  7.155216007959098e-05
Valid Loss:  9.653133747633547e-05
Epoch:  64  	Training Loss: 0.00010256233508698642
Test Loss:  7.141726382542402e-05
Valid Loss:  9.647139813750982e-05
Epoch:  65  	Training Loss: 0.00010239555558655411
Test Loss:  7.1379603468813e-05
Valid Loss:  9.648658306105062e-05
Epoch:  66  	Training Loss: 0.00010224836296401918
Test Loss:  7.137525244615972e-05
Valid Loss:  9.652326116338372e-05
Epoch:  67  	Training Loss: 0.00010211375774815679
Test Loss:  7.135859050322324e-05
Valid Loss:  9.654682071413845e-05
Epoch:  68  	Training Loss: 0.000101980593171902
Test Loss:  7.13383051333949e-05
Valid Loss:  9.656119800638407e-05
 14%|█▍        | 69/500 [00:54<02:25,  2.96it/s] 14%|█▍        | 71/500 [01:00<08:34,  1.20s/it] 15%|█▍        | 73/500 [01:00<06:06,  1.17it/s] 15%|█▌        | 75/500 [01:00<04:23,  1.61it/s] 15%|█▌        | 77/500 [01:01<03:11,  2.21it/s] 16%|█▌        | 79/500 [01:01<02:22,  2.96it/s] 16%|█▌        | 81/500 [01:07<08:25,  1.21s/it] 17%|█▋        | 83/500 [01:07<06:00,  1.16it/s] 17%|█▋        | 85/500 [01:07<04:19,  1.60it/s] 17%|█▋        | 87/500 [01:08<03:09,  2.17it/s] 18%|█▊        | 89/500 [01:08<02:20,  2.93it/s] 18%|█▊        | 91/500 [01:14<08:17,  1.22s/it] 19%|█▊        | 93/500 [01:14<05:55,  1.15it/s] 19%|█▉        | 95/500 [01:15<04:15,  1.59it/s] 19%|█▉        | 97/500 [01:15<03:05,  2.17it/s] 20%|█▉        | 99/500 [01:15<02:17,  2.92it/s] 20%|██        | 101/500 [01:21<07:57,  1.20s/it] 21%|██        | 103/500 [01:21<05:43,  1.16it/s] 21%|██        | 105/500 [01:22<04:09,  1.58it/s] 21%|██▏       | 107/500 [01:22<03:04,  2.13it/s] 22%|██▏       | 109/500 [01:22<02:18,  2.83it/s] 22%|██▏       | 111/500 [01:29<08:04,  1.25s/it] 23%|██▎       | 113/500 [01:29<05:45,  1.12it/s] 23%|██▎       | 115/500 [01:29<04:08,  1.55it/s] 23%|██▎       | 117/500 [01:29<03:00,  2.12it/s] 24%|██▍       | 119/500 [01:29<02:13,  2.86it/s] 24%|██▍       | 121/500 [01:35<07:34,  1.20s/it] 25%|██▍       | 123/500 [01:36<05:24,  1.16it/s] 25%|██▌       | 125/500 [01:36<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:36<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:36<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:42<07:23,  1.20s/it] 27%|██▋       | 133/500 [01:43<05:16,  1.16it/s] 27%|██▋       | 135/500 [01:43<03:47,  1.60it/s]Epoch:  69  	Training Loss: 0.00010185433347942308
Test Loss:  7.13145564077422e-05
Valid Loss:  9.65733706834726e-05
Epoch:  70  	Training Loss: 0.00010173658665735275
Test Loss:  7.128616562113166e-05
Valid Loss:  9.658010094426572e-05
Epoch:  71  	Training Loss: 0.00010162795661017299
Test Loss:  7.12714099790901e-05
Valid Loss:  9.659436909714714e-05
Epoch:  72  	Training Loss: 0.00010152455070056021
Test Loss:  7.186396396718919e-05
Valid Loss:  9.678808419266716e-05
Epoch:  73  	Training Loss: 0.00010102727537741885
Test Loss:  7.17851216904819e-05
Valid Loss:  9.664984827395529e-05
Epoch:  74  	Training Loss: 0.00010070838470710441
Test Loss:  7.169177115429193e-05
Valid Loss:  9.65170911513269e-05
Epoch:  75  	Training Loss: 0.00010041393397841603
Test Loss:  7.161981193348765e-05
Valid Loss:  9.64016217039898e-05
Epoch:  76  	Training Loss: 0.00010013561404775828
Test Loss:  7.154469494707882e-05
Valid Loss:  9.630252316128463e-05
Epoch:  77  	Training Loss: 9.987447992898524e-05
Test Loss:  7.146334974095225e-05
Valid Loss:  9.621815115679055e-05
Epoch:  78  	Training Loss: 9.963117190636694e-05
Test Loss:  7.13972985977307e-05
Valid Loss:  9.614289592718706e-05
Epoch:  79  	Training Loss: 9.939793380908668e-05
Test Loss:  7.133166218409315e-05
Valid Loss:  9.606555249774829e-05
Epoch:  80  	Training Loss: 9.917275747284293e-05
Test Loss:  7.126473065000027e-05
Valid Loss:  9.59847093326971e-05
Epoch:  81  	Training Loss: 9.895527909975499e-05
Test Loss:  7.118940993677825e-05
Valid Loss:  9.589947148924693e-05
Epoch:  82  	Training Loss: 9.874947863863781e-05
Test Loss:  7.102842209860682e-05
Valid Loss:  9.533558477414772e-05
Epoch:  83  	Training Loss: 9.805744048207998e-05
Test Loss:  7.086042023729533e-05
Valid Loss:  9.48917877394706e-05
Epoch:  84  	Training Loss: 9.758806845638901e-05
Test Loss:  7.067102706059813e-05
Valid Loss:  9.450549259781837e-05
Epoch:  85  	Training Loss: 9.722265531308949e-05
Test Loss:  7.049073610687628e-05
Valid Loss:  9.416705870535225e-05
Epoch:  86  	Training Loss: 9.692421008367091e-05
Test Loss:  7.031490531517193e-05
Valid Loss:  9.388394391862676e-05
Epoch:  87  	Training Loss: 9.668774146120995e-05
Test Loss:  7.01626850059256e-05
Valid Loss:  9.364211291540414e-05
Epoch:  88  	Training Loss: 9.648111881688237e-05
Test Loss:  7.003846258157864e-05
Valid Loss:  9.34539275476709e-05
Epoch:  89  	Training Loss: 9.629601117921993e-05
Test Loss:  6.995406874921173e-05
Valid Loss:  9.3296286650002e-05
Epoch:  90  	Training Loss: 9.613704605726525e-05
Test Loss:  6.987588130868971e-05
Valid Loss:  9.316833165939897e-05
Epoch:  91  	Training Loss: 9.600560588296503e-05
Test Loss:  6.980491889407858e-05
Valid Loss:  9.306675929110497e-05
Epoch:  92  	Training Loss: 9.58955570240505e-05
Test Loss:  6.844710151199251e-05
Valid Loss:  9.186554234474897e-05
Epoch:  93  	Training Loss: 9.549353853799403e-05
Test Loss:  6.832057260908186e-05
Valid Loss:  9.169091936200857e-05
Epoch:  94  	Training Loss: 9.532031253911555e-05
Test Loss:  6.821902934461832e-05
Valid Loss:  9.153824066743255e-05
Epoch:  95  	Training Loss: 9.515472629573196e-05
Test Loss:  6.813083018641919e-05
Valid Loss:  9.13989933906123e-05
Epoch:  96  	Training Loss: 9.499519364908338e-05
Test Loss:  6.804733129683882e-05
Valid Loss:  9.126528311753646e-05
Epoch:  97  	Training Loss: 9.483857866143808e-05
Test Loss:  6.796685920562595e-05
Valid Loss:  9.113513806369156e-05
Epoch:  98  	Training Loss: 9.468368807574734e-05
Test Loss:  6.787673191865906e-05
Valid Loss:  9.099493036046624e-05
Epoch:  99  	Training Loss: 9.453170787310228e-05
Test Loss:  6.780207331757993e-05
Valid Loss:  9.086810314329341e-05
Epoch:  100  	Training Loss: 9.438447887077928e-05
Test Loss:  6.773149652872235e-05
Valid Loss:  9.074897388927639e-05
Epoch:  101  	Training Loss: 9.424067684449255e-05
Test Loss:  6.766609294572845e-05
Valid Loss:  9.063344623427838e-05
Epoch:  102  	Training Loss: 9.410028724232689e-05
Test Loss:  6.755321373930201e-05
Valid Loss:  9.040042641572654e-05
Epoch:  103  	Training Loss: 9.383684664499015e-05
Test Loss:  6.743299309164286e-05
Valid Loss:  9.017834963742644e-05
Epoch:  104  	Training Loss: 9.358135866932571e-05
Test Loss:  6.734624912496656e-05
Valid Loss:  8.998909470392391e-05
Epoch:  105  	Training Loss: 9.33296832954511e-05
Test Loss:  6.725572166033089e-05
Valid Loss:  8.980192069429904e-05
Epoch:  106  	Training Loss: 9.308205335400999e-05
Test Loss:  6.717501673847437e-05
Valid Loss:  8.962703577708453e-05
Epoch:  107  	Training Loss: 9.283957479055971e-05
Test Loss:  6.710257002850994e-05
Valid Loss:  8.947167225414887e-05
Epoch:  108  	Training Loss: 9.26030334085226e-05
Test Loss:  6.70283188810572e-05
Valid Loss:  8.932792115956545e-05
Epoch:  109  	Training Loss: 9.237196354661137e-05
Test Loss:  6.696787022519857e-05
Valid Loss:  8.919525134842843e-05
Epoch:  110  	Training Loss: 9.214428428094834e-05
Test Loss:  6.690066948067397e-05
Valid Loss:  8.905718277674168e-05
Epoch:  111  	Training Loss: 9.192003926727921e-05
Test Loss:  6.683617539238185e-05
Valid Loss:  8.892331970855594e-05
Epoch:  112  	Training Loss: 9.169912664219737e-05
Test Loss:  6.663407839369029e-05
Valid Loss:  8.838782378006727e-05
Epoch:  113  	Training Loss: 9.141201735474169e-05
Test Loss:  6.633564044022933e-05
Valid Loss:  8.78575665410608e-05
Epoch:  114  	Training Loss: 9.118029993260279e-05
Test Loss:  6.608007242903113e-05
Valid Loss:  8.739916665945202e-05
Epoch:  115  	Training Loss: 9.097943984670565e-05
Test Loss:  6.584851507795975e-05
Valid Loss:  8.698475721757859e-05
Epoch:  116  	Training Loss: 9.079903247766197e-05
Test Loss:  6.566257070517167e-05
Valid Loss:  8.663627522764727e-05
Epoch:  117  	Training Loss: 9.06428977032192e-05
Test Loss:  6.552081322297454e-05
Valid Loss:  8.633185643702745e-05
Epoch:  118  	Training Loss: 9.049968502949923e-05
Test Loss:  6.539990135934204e-05
Valid Loss:  8.606219489593059e-05
Epoch:  119  	Training Loss: 9.0365982032381e-05
Test Loss:  6.529531674459577e-05
Valid Loss:  8.582129521528259e-05
Epoch:  120  	Training Loss: 9.024013706948608e-05
Test Loss:  6.520393071696162e-05
Valid Loss:  8.560469723306596e-05
Epoch:  121  	Training Loss: 9.012104419525713e-05
Test Loss:  6.511977699119598e-05
Valid Loss:  8.541508577764034e-05
Epoch:  122  	Training Loss: 9.001060971058905e-05
Test Loss:  6.469225627370179e-05
Valid Loss:  8.504999277647585e-05
Epoch:  123  	Training Loss: 8.987689216155559e-05
Test Loss:  6.460140866693109e-05
Valid Loss:  8.499145042151213e-05
Epoch:  124  	Training Loss: 8.977102697826922e-05
Test Loss:  6.455311086028814e-05
Valid Loss:  8.49730713525787e-05
Epoch:  125  	Training Loss: 8.966629684437066e-05
Test Loss:  6.451392255257815e-05
Valid Loss:  8.495869406033307e-05
Epoch:  126  	Training Loss: 8.955775410868227e-05
Test Loss:  6.446529732784256e-05
Valid Loss:  8.493307541357353e-05
Epoch:  127  	Training Loss: 8.94541444722563e-05
Test Loss:  6.44203246338293e-05
Valid Loss:  8.491121116094291e-05
Epoch:  128  	Training Loss: 8.935421647038311e-05
Test Loss:  6.437771662604064e-05
Valid Loss:  8.488979801768437e-05
Epoch:  129  	Training Loss: 8.925784641178325e-05
Test Loss:  6.434087845264003e-05
Valid Loss:  8.487218292430043e-05
Epoch:  130  	Training Loss: 8.91643576323986e-05
Test Loss:  6.4309366280213e-05
Valid Loss:  8.485918078804389e-05
Epoch:  131  	Training Loss: 8.907345909392461e-05
Test Loss:  6.427998596336693e-05
Valid Loss:  8.484715363010764e-05
Epoch:  132  	Training Loss: 8.898510714061558e-05
Test Loss:  6.504752673208714e-05
Valid Loss:  8.55869147926569e-05
Epoch:  133  	Training Loss: 8.867239375831559e-05
Test Loss:  6.53250390314497e-05
Valid Loss:  8.590221841586754e-05
Epoch:  134  	Training Loss: 8.847593562677503e-05
Test Loss:  6.546858639921993e-05
Valid Loss:  8.607439667684957e-05
Epoch:  135  	Training Loss: 8.831646118778735e-05
Test Loss:  6.554591527674347e-05
Valid Loss:  8.616849663667381e-05
Epoch:  136  	Training Loss: 8.81701271282509e-05
Test Loss:  6.55986659694463e-05
Valid Loss:  8.622500172350556e-05
Epoch:  137  	Training Loss: 8.803332457318902e-05
Test Loss:  6.563388160429895e-05
 27%|██▋       | 137/500 [01:43<02:47,  2.17it/s] 28%|██▊       | 139/500 [01:43<02:05,  2.87it/s] 28%|██▊       | 141/500 [01:49<07:13,  1.21s/it] 29%|██▊       | 143/500 [01:50<05:09,  1.15it/s] 29%|██▉       | 145/500 [01:50<03:44,  1.58it/s] 29%|██▉       | 147/500 [01:50<02:45,  2.14it/s] 30%|██▉       | 149/500 [01:50<02:03,  2.85it/s] 30%|███       | 151/500 [01:56<06:58,  1.20s/it] 31%|███       | 153/500 [01:57<04:57,  1.17it/s] 31%|███       | 155/500 [01:57<03:33,  1.61it/s] 31%|███▏      | 157/500 [01:57<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:57<01:54,  2.97it/s] 32%|███▏      | 161/500 [02:03<06:48,  1.21s/it] 33%|███▎      | 163/500 [02:04<04:51,  1.16it/s] 33%|███▎      | 165/500 [02:04<03:29,  1.60it/s] 33%|███▎      | 167/500 [02:04<02:31,  2.19it/s] 34%|███▍      | 169/500 [02:04<01:52,  2.95it/s] 34%|███▍      | 171/500 [02:10<06:33,  1.20s/it] 35%|███▍      | 173/500 [02:10<04:40,  1.16it/s] 35%|███▌      | 175/500 [02:11<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:11<02:26,  2.20it/s] 36%|███▌      | 179/500 [02:11<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:17<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:17<04:33,  1.16it/s] 37%|███▋      | 185/500 [02:18<03:17,  1.59it/s] 37%|███▋      | 187/500 [02:18<02:25,  2.15it/s] 38%|███▊      | 189/500 [02:18<01:49,  2.85it/s] 38%|███▊      | 191/500 [02:24<06:12,  1.20s/it] 39%|███▊      | 193/500 [02:24<04:24,  1.16it/s] 39%|███▉      | 195/500 [02:25<03:10,  1.61it/s] 39%|███▉      | 197/500 [02:25<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:25<01:41,  2.96it/s] 40%|████      | 201/500 [02:31<05:58,  1.20s/it] 41%|████      | 203/500 [02:31<04:15,  1.16it/s] 41%|████      | 205/500 [02:31<03:03,  1.61it/s]Valid Loss:  8.625244663562626e-05
Epoch:  138  	Training Loss: 8.79022991284728e-05
Test Loss:  6.566357478732243e-05
Valid Loss:  8.625911868875846e-05
Epoch:  139  	Training Loss: 8.7770153186284e-05
Test Loss:  6.566530646523461e-05
Valid Loss:  8.623737085144967e-05
Epoch:  140  	Training Loss: 8.764097583480179e-05
Test Loss:  6.565824151039124e-05
Valid Loss:  8.620417793281376e-05
Epoch:  141  	Training Loss: 8.751398127060384e-05
Test Loss:  6.562174530699849e-05
Valid Loss:  8.614672697149217e-05
Epoch:  142  	Training Loss: 8.738552423892543e-05
Test Loss:  6.549288082169369e-05
Valid Loss:  8.578492270316929e-05
Epoch:  143  	Training Loss: 8.712739509064704e-05
Test Loss:  6.511266838060692e-05
Valid Loss:  8.531588537152857e-05
Epoch:  144  	Training Loss: 8.688537491252646e-05
Test Loss:  6.492304964922369e-05
Valid Loss:  8.49935895530507e-05
Epoch:  145  	Training Loss: 8.664806955493987e-05
Test Loss:  6.475269765360281e-05
Valid Loss:  8.467849693261087e-05
Epoch:  146  	Training Loss: 8.639397856313735e-05
Test Loss:  6.453230162151158e-05
Valid Loss:  8.435747440671548e-05
Epoch:  147  	Training Loss: 8.615286787971854e-05
Test Loss:  6.437720003305003e-05
Valid Loss:  8.40931897982955e-05
Epoch:  148  	Training Loss: 8.59216961544007e-05
Test Loss:  6.422638398362324e-05
Valid Loss:  8.384670945815742e-05
Epoch:  149  	Training Loss: 8.569820784032345e-05
Test Loss:  6.410056812455878e-05
Valid Loss:  8.362642984138802e-05
Epoch:  150  	Training Loss: 8.548111509298906e-05
Test Loss:  6.398643017746508e-05
Valid Loss:  8.342275395989418e-05
Epoch:  151  	Training Loss: 8.526963938493282e-05
Test Loss:  6.388327165041119e-05
Valid Loss:  8.323109068442136e-05
Epoch:  152  	Training Loss: 8.506413723807782e-05
Test Loss:  6.398538243956864e-05
Valid Loss:  8.327368414029479e-05
Epoch:  153  	Training Loss: 8.485402213409543e-05
Test Loss:  6.393635703716427e-05
Valid Loss:  8.32114601507783e-05
Epoch:  154  	Training Loss: 8.46521434141323e-05
Test Loss:  6.386986933648586e-05
Valid Loss:  8.313673606608063e-05
Epoch:  155  	Training Loss: 8.445618732366711e-05
Test Loss:  6.379182013915852e-05
Valid Loss:  8.304760558530688e-05
Epoch:  156  	Training Loss: 8.426541171502322e-05
Test Loss:  6.37071134406142e-05
Valid Loss:  8.294852159451693e-05
Epoch:  157  	Training Loss: 8.407916175201535e-05
Test Loss:  6.361794658005238e-05
Valid Loss:  8.284297655336559e-05
Epoch:  158  	Training Loss: 8.3897277363576e-05
Test Loss:  6.3526546000503e-05
Valid Loss:  8.273387356894091e-05
Epoch:  159  	Training Loss: 8.371983130928129e-05
Test Loss:  6.343301356537268e-05
Valid Loss:  8.262148185167462e-05
Epoch:  160  	Training Loss: 8.353737939614803e-05
Test Loss:  6.336277874652296e-05
Valid Loss:  8.249900565715507e-05
Epoch:  161  	Training Loss: 8.334115409525111e-05
Test Loss:  6.32178271189332e-05
Valid Loss:  8.232380059780553e-05
Epoch:  162  	Training Loss: 8.315013838000596e-05
Test Loss:  6.336867227219045e-05
Valid Loss:  8.224841440096498e-05
Epoch:  163  	Training Loss: 8.300373156089336e-05
Test Loss:  6.332045450108126e-05
Valid Loss:  8.21473659016192e-05
Epoch:  164  	Training Loss: 8.289235120173544e-05
Test Loss:  6.326315633486956e-05
Valid Loss:  8.205998892663047e-05
Epoch:  165  	Training Loss: 8.278443419840187e-05
Test Loss:  6.32065421086736e-05
Valid Loss:  8.19921915535815e-05
Epoch:  166  	Training Loss: 8.268252713605762e-05
Test Loss:  6.3177605625242e-05
Valid Loss:  8.193797839339823e-05
Epoch:  167  	Training Loss: 8.258614980150014e-05
Test Loss:  6.314222991932184e-05
Valid Loss:  8.188508218154311e-05
Epoch:  168  	Training Loss: 8.249198435805738e-05
Test Loss:  6.31241564406082e-05
Valid Loss:  8.188822539523244e-05
Epoch:  169  	Training Loss: 8.244816854130477e-05
Test Loss:  6.118723831605166e-05
Valid Loss:  7.991872553247958e-05
Epoch:  170  	Training Loss: 8.277289452962577e-05
Test Loss:  6.190663407323882e-05
Valid Loss:  8.049156167544425e-05
Epoch:  171  	Training Loss: 8.250765677075833e-05
Test Loss:  6.222707452252507e-05
Valid Loss:  8.08298573247157e-05
Epoch:  172  	Training Loss: 8.235932909883559e-05
Test Loss:  6.182835204526782e-05
Valid Loss:  8.054971840465441e-05
Epoch:  173  	Training Loss: 8.217523281928152e-05
Test Loss:  6.187787221278995e-05
Valid Loss:  8.064978464972228e-05
Epoch:  174  	Training Loss: 8.203386096283793e-05
Test Loss:  6.193813896970823e-05
Valid Loss:  8.075503865256906e-05
Epoch:  175  	Training Loss: 8.190730295609683e-05
Test Loss:  6.199332710821182e-05
Valid Loss:  8.085193985607475e-05
Epoch:  176  	Training Loss: 8.179289579857141e-05
Test Loss:  6.204421515576541e-05
Valid Loss:  8.093914220808074e-05
Epoch:  177  	Training Loss: 8.168831118382514e-05
Test Loss:  6.209082494024187e-05
Valid Loss:  8.101807907223701e-05
Epoch:  178  	Training Loss: 8.159162098309025e-05
Test Loss:  6.213147571543232e-05
Valid Loss:  8.108514884952456e-05
Epoch:  179  	Training Loss: 8.150243229465559e-05
Test Loss:  6.217470217961818e-05
Valid Loss:  8.114957017824054e-05
Epoch:  180  	Training Loss: 8.14181548776105e-05
Test Loss:  6.221384683158249e-05
Valid Loss:  8.120461279759184e-05
Epoch:  181  	Training Loss: 8.133870142046362e-05
Test Loss:  6.225344259291887e-05
Valid Loss:  8.125560270855203e-05
Epoch:  182  	Training Loss: 8.126567263389006e-05
Test Loss:  6.257191125769168e-05
Valid Loss:  8.142850856529549e-05
Epoch:  183  	Training Loss: 8.111557690426707e-05
Test Loss:  6.277923239395022e-05
Valid Loss:  8.154247188940644e-05
Epoch:  184  	Training Loss: 8.103250002022833e-05
Test Loss:  6.29042333457619e-05
Valid Loss:  8.160708239302039e-05
Epoch:  185  	Training Loss: 8.097745740087703e-05
Test Loss:  6.297375512076542e-05
Valid Loss:  8.16361716715619e-05
Epoch:  186  	Training Loss: 8.093315409496427e-05
Test Loss:  6.300865061348304e-05
Valid Loss:  8.164210885297507e-05
Epoch:  187  	Training Loss: 8.089440234471112e-05
Test Loss:  6.301964458543807e-05
Valid Loss:  8.163347956724465e-05
Epoch:  188  	Training Loss: 8.085782610578462e-05
Test Loss:  6.301590474322438e-05
Valid Loss:  8.161530422512442e-05
Epoch:  189  	Training Loss: 8.082141721388325e-05
Test Loss:  6.300317909335718e-05
Valid Loss:  8.159134449670091e-05
Epoch:  190  	Training Loss: 8.078515384113416e-05
Test Loss:  6.298498919932172e-05
Valid Loss:  8.156455442076549e-05
Epoch:  191  	Training Loss: 8.074907964328304e-05
Test Loss:  6.296367064351216e-05
Valid Loss:  8.153638918884099e-05
Epoch:  192  	Training Loss: 8.071305637713522e-05
Test Loss:  6.214806489879265e-05
Valid Loss:  8.080633415374905e-05
Epoch:  193  	Training Loss: 8.052055636653677e-05
Test Loss:  6.198041955940425e-05
Valid Loss:  8.062169217737392e-05
Epoch:  194  	Training Loss: 8.040028478717431e-05
Test Loss:  6.191404827404767e-05
Valid Loss:  8.053235796978697e-05
Epoch:  195  	Training Loss: 8.028661250136793e-05
Test Loss:  6.186749669723213e-05
Valid Loss:  8.047448500292376e-05
Epoch:  196  	Training Loss: 8.017809886951e-05
Test Loss:  6.183664663694799e-05
Valid Loss:  8.043218986131251e-05
Epoch:  197  	Training Loss: 8.00746347522363e-05
Test Loss:  6.18091580690816e-05
Valid Loss:  8.039847307372838e-05
Epoch:  198  	Training Loss: 7.997640932444483e-05
Test Loss:  6.17869955021888e-05
Valid Loss:  8.037857332965359e-05
Epoch:  199  	Training Loss: 7.988549623405561e-05
Test Loss:  6.177050818223506e-05
Valid Loss:  8.037072257138789e-05
Epoch:  200  	Training Loss: 7.979889051057398e-05
Test Loss:  6.177415343699977e-05
Valid Loss:  8.037639054236934e-05
Epoch:  201  	Training Loss: 7.971467130118981e-05
Test Loss:  6.17746336502023e-05
Valid Loss:  8.037680527195334e-05
Epoch:  202  	Training Loss: 7.963244570419192e-05
Test Loss:  6.169924745336175e-05
Valid Loss:  7.984269177541137e-05
Epoch:  203  	Training Loss: 7.920268399175256e-05
Test Loss:  6.1012920923531055e-05
Valid Loss:  7.897283649072051e-05
Epoch:  204  	Training Loss: 7.884282240411267e-05
Test Loss:  6.0800080973422155e-05
Valid Loss:  7.8506265708711e-05
Epoch:  205  	Training Loss: 7.852201088098809e-05
Test Loss:  6.04731758357957e-05
Valid Loss:  7.801874016877264e-05
 41%|████▏     | 207/500 [02:32<02:12,  2.20it/s] 42%|████▏     | 209/500 [02:32<01:38,  2.97it/s] 42%|████▏     | 211/500 [02:38<05:40,  1.18s/it] 43%|████▎     | 213/500 [02:38<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:38<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:38<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:39<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:45<05:33,  1.20s/it] 45%|████▍     | 223/500 [02:45<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:45<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:45<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:46<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:52<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:52<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:52<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:52<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:52<01:26,  3.00it/s] 48%|████▊     | 241/500 [02:59<05:16,  1.22s/it] 49%|████▊     | 243/500 [02:59<03:45,  1.14it/s] 49%|████▉     | 245/500 [02:59<02:41,  1.58it/s] 49%|████▉     | 247/500 [02:59<01:57,  2.16it/s] 50%|████▉     | 249/500 [02:59<01:26,  2.91it/s] 50%|█████     | 251/500 [03:06<05:02,  1.21s/it] 51%|█████     | 253/500 [03:06<03:35,  1.15it/s] 51%|█████     | 255/500 [03:06<02:34,  1.58it/s] 51%|█████▏    | 257/500 [03:06<01:52,  2.17it/s] 52%|█████▏    | 259/500 [03:06<01:22,  2.92it/s] 52%|█████▏    | 261/500 [03:13<04:45,  1.19s/it] 53%|█████▎    | 263/500 [03:13<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:13<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:13<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:13<01:17,  2.96it/s] 54%|█████▍    | 271/500 [03:20<04:35,  1.20s/it] 55%|█████▍    | 273/500 [03:20<03:15,  1.16it/s]Epoch:  206  	Training Loss: 7.823036139598116e-05
Test Loss:  6.027540803188458e-05
Valid Loss:  7.766934140818194e-05
Epoch:  207  	Training Loss: 7.795842248015106e-05
Test Loss:  6.006819603499025e-05
Valid Loss:  7.734986138530076e-05
Epoch:  208  	Training Loss: 7.769766671117395e-05
Test Loss:  5.9910478739766404e-05
Valid Loss:  7.708125485805795e-05
Epoch:  209  	Training Loss: 7.744276081211865e-05
Test Loss:  5.9748585044872016e-05
Valid Loss:  7.684163574595004e-05
Epoch:  210  	Training Loss: 7.719182030996308e-05
Test Loss:  5.9658232203219086e-05
Valid Loss:  7.663673750357702e-05
Epoch:  211  	Training Loss: 7.691833889111876e-05
Test Loss:  5.9432095440570265e-05
Valid Loss:  7.635544898221269e-05
Epoch:  212  	Training Loss: 7.665332668693736e-05
Test Loss:  5.962122304481454e-05
Valid Loss:  7.648804603377357e-05
Epoch:  213  	Training Loss: 7.65245349612087e-05
Test Loss:  5.972789949737489e-05
Valid Loss:  7.6567885116674e-05
Epoch:  214  	Training Loss: 7.641038246219978e-05
Test Loss:  5.979376146569848e-05
Valid Loss:  7.661263225600123e-05
Epoch:  215  	Training Loss: 7.630202162545174e-05
Test Loss:  5.983559458400123e-05
Valid Loss:  7.663659926038235e-05
Epoch:  216  	Training Loss: 7.61981718824245e-05
Test Loss:  5.985885945847258e-05
Valid Loss:  7.664283475605771e-05
Epoch:  217  	Training Loss: 7.609797467011958e-05
Test Loss:  5.987096665194258e-05
Valid Loss:  7.663661381229758e-05
Epoch:  218  	Training Loss: 7.600149547215551e-05
Test Loss:  5.987784606986679e-05
Valid Loss:  7.662455755053088e-05
Epoch:  219  	Training Loss: 7.590680615976453e-05
Test Loss:  5.988127668388188e-05
Valid Loss:  7.66084049246274e-05
Epoch:  220  	Training Loss: 7.5813994044438e-05
Test Loss:  5.988253542454913e-05
Valid Loss:  7.658832328161225e-05
Epoch:  221  	Training Loss: 7.572281901957467e-05
Test Loss:  5.987997064949013e-05
Valid Loss:  7.656309753656387e-05
Epoch:  222  	Training Loss: 7.563440885860473e-05
Test Loss:  5.9437199524836615e-05
Valid Loss:  7.622990233357996e-05
Epoch:  223  	Training Loss: 7.553762407042086e-05
Test Loss:  5.9201905969530344e-05
Valid Loss:  7.606093276990578e-05
Epoch:  224  	Training Loss: 7.548459689132869e-05
Test Loss:  5.9070349379908293e-05
Valid Loss:  7.597084913868457e-05
Epoch:  225  	Training Loss: 7.544536492787302e-05
Test Loss:  5.8992554841097444e-05
Valid Loss:  7.592046313220635e-05
Epoch:  226  	Training Loss: 7.541030208813027e-05
Test Loss:  5.8942867326550186e-05
Valid Loss:  7.589056622236967e-05
Epoch:  227  	Training Loss: 7.53767671994865e-05
Test Loss:  5.890894681215286e-05
Valid Loss:  7.587198342662305e-05
Epoch:  228  	Training Loss: 7.534404721809551e-05
Test Loss:  5.888335726922378e-05
Valid Loss:  7.585894491057843e-05
Epoch:  229  	Training Loss: 7.531173469033092e-05
Test Loss:  5.8862322475761175e-05
Valid Loss:  7.584880222566426e-05
Epoch:  230  	Training Loss: 7.527960406150669e-05
Test Loss:  5.884421989321709e-05
Valid Loss:  7.584018021589145e-05
Epoch:  231  	Training Loss: 7.52479099901393e-05
Test Loss:  5.882767800358124e-05
Valid Loss:  7.583196565974504e-05
Epoch:  232  	Training Loss: 7.52163614379242e-05
Test Loss:  5.948497710051015e-05
Valid Loss:  7.644559082109481e-05
Epoch:  233  	Training Loss: 7.503193046431988e-05
Test Loss:  5.935919762123376e-05
Valid Loss:  7.63840289437212e-05
Epoch:  234  	Training Loss: 7.488286792067811e-05
Test Loss:  5.9480978961801156e-05
Valid Loss:  7.650865882169455e-05
Epoch:  235  	Training Loss: 7.474725134670734e-05
Test Loss:  5.9510253777261823e-05
Valid Loss:  7.65409495215863e-05
Epoch:  236  	Training Loss: 7.462073699571192e-05
Test Loss:  5.955449159955606e-05
Valid Loss:  7.657401147298515e-05
Epoch:  237  	Training Loss: 7.450024713762105e-05
Test Loss:  5.95839592278935e-05
Valid Loss:  7.658997492399067e-05
Epoch:  238  	Training Loss: 7.438595639541745e-05
Test Loss:  5.8992816775571555e-05
Valid Loss:  7.599231321364641e-05
Epoch:  239  	Training Loss: 7.43179552955553e-05
Test Loss:  5.976515240035951e-05
Valid Loss:  7.664720033062622e-05
Epoch:  240  	Training Loss: 7.417807501042262e-05
Test Loss:  5.953303480055183e-05
Valid Loss:  7.643869321327657e-05
Epoch:  241  	Training Loss: 7.406796794384718e-05
Test Loss:  5.964652154943906e-05
Valid Loss:  7.652242493350059e-05
Epoch:  242  	Training Loss: 7.396511500701308e-05
Test Loss:  5.958618930890225e-05
Valid Loss:  7.649351027794182e-05
Epoch:  243  	Training Loss: 7.393422856694087e-05
Test Loss:  5.959295231150463e-05
Valid Loss:  7.652495696675032e-05
Epoch:  244  	Training Loss: 7.390700920950621e-05
Test Loss:  5.961849819868803e-05
Valid Loss:  7.657194510102272e-05
Epoch:  245  	Training Loss: 7.388229278149083e-05
Test Loss:  5.964743104414083e-05
Valid Loss:  7.662276766495779e-05
Epoch:  246  	Training Loss: 7.385940261883661e-05
Test Loss:  5.967972901999019e-05
Valid Loss:  7.667483441764489e-05
Epoch:  247  	Training Loss: 7.383807678706944e-05
Test Loss:  5.9711484936997294e-05
Valid Loss:  7.672488573007286e-05
Epoch:  248  	Training Loss: 7.381819887086749e-05
Test Loss:  5.9741731092799455e-05
Valid Loss:  7.677143003093079e-05
Epoch:  249  	Training Loss: 7.379961607512087e-05
Test Loss:  5.9769197832793e-05
Valid Loss:  7.681675197090954e-05
Epoch:  250  	Training Loss: 7.378200098173693e-05
Test Loss:  5.980012065265328e-05
Valid Loss:  7.686155004194006e-05
Epoch:  251  	Training Loss: 7.37656737328507e-05
Test Loss:  5.9824240452144295e-05
Valid Loss:  7.690093480050564e-05
Epoch:  252  	Training Loss: 7.375011045951396e-05
Test Loss:  6.0171591030666605e-05
Valid Loss:  7.652947533642873e-05
Epoch:  253  	Training Loss: 7.317394920391962e-05
Test Loss:  5.9348771173972636e-05
Valid Loss:  7.60285765863955e-05
Epoch:  254  	Training Loss: 7.257524703163654e-05
Test Loss:  5.845536361448467e-05
Valid Loss:  7.508727867389098e-05
Epoch:  255  	Training Loss: 7.16278882464394e-05
Test Loss:  5.753795267082751e-05
Valid Loss:  7.377548899967223e-05
Epoch:  256  	Training Loss: 7.058772462187335e-05
Test Loss:  5.6345772463828325e-05
Valid Loss:  7.227850437629968e-05
Epoch:  257  	Training Loss: 6.9439884100575e-05
Test Loss:  5.510311166290194e-05
Valid Loss:  7.074530003592372e-05
Epoch:  258  	Training Loss: 6.82155805407092e-05
Test Loss:  5.4085183364804834e-05
Valid Loss:  6.96062998031266e-05
Epoch:  259  	Training Loss: 6.723980186507106e-05
Test Loss:  5.333766239346005e-05
Valid Loss:  6.885231414344162e-05
Epoch:  260  	Training Loss: 6.656663026660681e-05
Test Loss:  5.3041017963550985e-05
Valid Loss:  6.840714195277542e-05
Epoch:  261  	Training Loss: 6.613578443648294e-05
Test Loss:  5.28468081029132e-05
Valid Loss:  6.813756044721231e-05
Epoch:  262  	Training Loss: 6.583039066754282e-05
Test Loss:  5.3054325690027326e-05
Valid Loss:  6.839347770437598e-05
Epoch:  263  	Training Loss: 6.57248601783067e-05
Test Loss:  5.313943620421924e-05
Valid Loss:  6.854526873212308e-05
Epoch:  264  	Training Loss: 6.563751958310604e-05
Test Loss:  5.320227501215413e-05
Valid Loss:  6.867099727969617e-05
Epoch:  265  	Training Loss: 6.556262815138325e-05
Test Loss:  5.325618258211762e-05
Valid Loss:  6.87828433001414e-05
Epoch:  266  	Training Loss: 6.54974501230754e-05
Test Loss:  5.330972635420039e-05
Valid Loss:  6.888654024805874e-05
Epoch:  267  	Training Loss: 6.544019561260939e-05
Test Loss:  5.33607708348427e-05
Valid Loss:  6.897958519402891e-05
Epoch:  268  	Training Loss: 6.538914749398828e-05
Test Loss:  5.340364441508427e-05
Valid Loss:  6.906180351506919e-05
Epoch:  269  	Training Loss: 6.534275598824024e-05
Test Loss:  5.344625242287293e-05
Valid Loss:  6.913772813277319e-05
Epoch:  270  	Training Loss: 6.530026439577341e-05
Test Loss:  5.348555714590475e-05
Valid Loss:  6.920547457411885e-05
Epoch:  271  	Training Loss: 6.526068318635225e-05
Test Loss:  5.3521136578638107e-05
Valid Loss:  6.92658795742318e-05
Epoch:  272  	Training Loss: 6.522362673422322e-05
Test Loss:  5.364140452002175e-05
Valid Loss:  6.927746289875358e-05
Epoch:  273  	Training Loss: 6.507615762529895e-05
Test Loss:  5.331200372893363e-05
Valid Loss:  6.905235204612836e-05
 55%|█████▌    | 275/500 [03:20<02:20,  1.61it/s] 55%|█████▌    | 277/500 [03:20<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:20<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:27<04:19,  1.18s/it] 57%|█████▋    | 283/500 [03:27<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:27<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:27<01:36,  2.20it/s] 58%|█████▊    | 289/500 [03:27<01:11,  2.96it/s] 58%|█████▊    | 291/500 [03:34<04:09,  1.19s/it] 59%|█████▊    | 293/500 [03:34<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:34<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:34<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:34<01:07,  2.98it/s] 60%|██████    | 301/500 [03:40<03:54,  1.18s/it] 61%|██████    | 303/500 [03:41<02:47,  1.18it/s] 61%|██████    | 305/500 [03:41<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:41<01:29,  2.17it/s] 62%|██████▏   | 309/500 [03:41<01:06,  2.87it/s] 62%|██████▏   | 311/500 [03:54<06:48,  2.16s/it] 63%|██████▎   | 313/500 [03:54<04:46,  1.53s/it] 63%|██████▎   | 315/500 [03:54<03:22,  1.09s/it] 63%|██████▎   | 317/500 [03:54<02:23,  1.28it/s] 64%|██████▍   | 319/500 [03:54<01:42,  1.76it/s] 64%|██████▍   | 321/500 [04:01<04:07,  1.38s/it] 65%|██████▍   | 323/500 [04:01<02:54,  1.01it/s] 65%|██████▌   | 325/500 [04:01<02:04,  1.41it/s] 65%|██████▌   | 327/500 [04:01<01:29,  1.93it/s] 66%|██████▌   | 329/500 [04:02<01:05,  2.62it/s] 66%|██████▌   | 331/500 [04:08<03:29,  1.24s/it] 67%|██████▋   | 333/500 [04:08<02:28,  1.12it/s] 67%|██████▋   | 335/500 [04:08<01:46,  1.56it/s] 67%|██████▋   | 337/500 [04:08<01:17,  2.12it/s] 68%|██████▊   | 339/500 [04:09<00:56,  2.86it/s]Epoch:  274  	Training Loss: 6.497403228422627e-05
Test Loss:  5.310020060278475e-05
Valid Loss:  6.890604709042236e-05
Epoch:  275  	Training Loss: 6.48786299279891e-05
Test Loss:  5.289537148200907e-05
Valid Loss:  6.877198757138103e-05
Epoch:  276  	Training Loss: 6.478770228568465e-05
Test Loss:  5.271674308460206e-05
Valid Loss:  6.865758768981323e-05
Epoch:  277  	Training Loss: 6.470069638453424e-05
Test Loss:  5.254976713331416e-05
Valid Loss:  6.855262472527102e-05
Epoch:  278  	Training Loss: 6.461574230343103e-05
Test Loss:  5.239703386905603e-05
Valid Loss:  6.84589467709884e-05
Epoch:  279  	Training Loss: 6.453305832110345e-05
Test Loss:  5.2256153139751405e-05
Valid Loss:  6.837418914074078e-05
Epoch:  280  	Training Loss: 6.445220060413703e-05
Test Loss:  5.2125109505141154e-05
Valid Loss:  6.829667836427689e-05
Epoch:  281  	Training Loss: 6.437271076720208e-05
Test Loss:  5.2001494623254985e-05
Valid Loss:  6.822364957770333e-05
Epoch:  282  	Training Loss: 6.429426139220595e-05
Test Loss:  5.1717128371819854e-05
Valid Loss:  6.801406561862677e-05
Epoch:  283  	Training Loss: 6.418946577468887e-05
Test Loss:  5.1514616643544286e-05
Valid Loss:  6.786199082853273e-05
Epoch:  284  	Training Loss: 6.408945773728192e-05
Test Loss:  5.132990190759301e-05
Valid Loss:  6.772617052774876e-05
Epoch:  285  	Training Loss: 6.399225821951404e-05
Test Loss:  5.115680687595159e-05
Valid Loss:  6.760108954040334e-05
Epoch:  286  	Training Loss: 6.389764894265682e-05
Test Loss:  5.099320333101787e-05
Valid Loss:  6.748505984432995e-05
Epoch:  287  	Training Loss: 6.38054043520242e-05
Test Loss:  5.083601354272105e-05
Valid Loss:  6.737680814694613e-05
Epoch:  288  	Training Loss: 6.371371273417026e-05
Test Loss:  5.0706763431662694e-05
Valid Loss:  6.727483560098335e-05
Epoch:  289  	Training Loss: 6.360802944982424e-05
Test Loss:  5.052572669228539e-05
Valid Loss:  6.7145076172892e-05
Epoch:  290  	Training Loss: 6.350573676172644e-05
Test Loss:  5.03529590787366e-05
Valid Loss:  6.70236986479722e-05
Epoch:  291  	Training Loss: 6.340631080092862e-05
Test Loss:  5.018919910071418e-05
Valid Loss:  6.69110959279351e-05
Epoch:  292  	Training Loss: 6.330900941975415e-05
Test Loss:  5.016830255044624e-05
Valid Loss:  6.698744255118072e-05
Epoch:  293  	Training Loss: 6.321826367639005e-05
Test Loss:  5.0223687139805406e-05
Valid Loss:  6.711659079883248e-05
Epoch:  294  	Training Loss: 6.314192432910204e-05
Test Loss:  5.028613668400794e-05
Valid Loss:  6.72425449010916e-05
Epoch:  295  	Training Loss: 6.307709554675967e-05
Test Loss:  5.0339222070761025e-05
Valid Loss:  6.735764327459037e-05
Epoch:  296  	Training Loss: 6.30216090939939e-05
Test Loss:  5.0393784476909786e-05
Valid Loss:  6.746778672095388e-05
Epoch:  297  	Training Loss: 6.297403160715476e-05
Test Loss:  5.0445400120224804e-05
Valid Loss:  6.757042137905955e-05
Epoch:  298  	Training Loss: 6.293302431004122e-05
Test Loss:  5.049102765042335e-05
Valid Loss:  6.766549631720409e-05
Epoch:  299  	Training Loss: 6.289783050306141e-05
Test Loss:  5.0537651986815035e-05
Valid Loss:  6.775623478461057e-05
Epoch:  300  	Training Loss: 6.286733696470037e-05
Test Loss:  5.0581133109517395e-05
Valid Loss:  6.784005381632596e-05
Epoch:  301  	Training Loss: 6.284065602812916e-05
Test Loss:  5.06218675582204e-05
Valid Loss:  6.79166623740457e-05
Epoch:  302  	Training Loss: 6.281737296376377e-05
Test Loss:  5.066694939159788e-05
Valid Loss:  6.788260361645371e-05
Epoch:  303  	Training Loss: 6.274615589063615e-05
Test Loss:  4.959500802215189e-05
Valid Loss:  6.670666334684938e-05
Epoch:  304  	Training Loss: 6.276400381466374e-05
Test Loss:  5.021618562750518e-05
Valid Loss:  6.710161687806249e-05
Epoch:  305  	Training Loss: 6.263697287067771e-05
Test Loss:  5.01957765663974e-05
Valid Loss:  6.708400178467855e-05
Epoch:  306  	Training Loss: 6.255564221646637e-05
Test Loss:  5.019588570576161e-05
Valid Loss:  6.70781300868839e-05
Epoch:  307  	Training Loss: 6.247622513910756e-05
Test Loss:  5.022375626140274e-05
Valid Loss:  6.718838994856924e-05
Epoch:  308  	Training Loss: 6.248702993616462e-05
Test Loss:  4.893330333288759e-05
Valid Loss:  6.583313370356336e-05
Epoch:  309  	Training Loss: 6.262421084102243e-05
Test Loss:  4.9843940360005945e-05
Valid Loss:  6.650368595728651e-05
Epoch:  310  	Training Loss: 6.244324322324246e-05
Test Loss:  4.987433203496039e-05
Valid Loss:  6.6587861510925e-05
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 6.235578621271998e-05
Test Loss:  4.990375236957334e-05
Valid Loss:  6.658161873929203e-05
Epoch:  312  	Training Loss: 6.231584120541811e-05
Test Loss:  4.990323577658273e-05
Valid Loss:  6.658936035819352e-05
Epoch:  313  	Training Loss: 6.225692050065845e-05
Test Loss:  4.986865315004252e-05
Valid Loss:  6.655995093751699e-05
Epoch:  314  	Training Loss: 6.220024079084396e-05
Test Loss:  4.981805614079349e-05
Valid Loss:  6.658396159764379e-05
Epoch:  315  	Training Loss: 6.218754424480721e-05
Test Loss:  4.92196086270269e-05
Valid Loss:  6.594067963305861e-05
Epoch:  316  	Training Loss: 6.218113412614912e-05
Test Loss:  4.9323742132401094e-05
Valid Loss:  6.600657798117027e-05
Epoch:  317  	Training Loss: 6.211460276972502e-05
Test Loss:  4.935681863571517e-05
Valid Loss:  6.602888606721535e-05
Epoch:  318  	Training Loss: 6.205633690115064e-05
Test Loss:  4.935300239594653e-05
Valid Loss:  6.609386036871001e-05
Epoch:  319  	Training Loss: 6.203992961673066e-05
Test Loss:  4.884729423793033e-05
Valid Loss:  6.555292929988354e-05
Epoch:  320  	Training Loss: 6.203961675055325e-05
Test Loss:  4.896428799838759e-05
Valid Loss:  6.563743227161467e-05
Epoch:  321  	Training Loss: 6.197261245688424e-05
Test Loss:  4.901167631032877e-05
Valid Loss:  6.571582343894988e-05
Epoch:  322  	Training Loss: 6.193342414917424e-05
Test Loss:  4.879308835370466e-05
Valid Loss:  6.557074084412307e-05
Epoch:  323  	Training Loss: 6.190497515490279e-05
Test Loss:  4.867089228355326e-05
Valid Loss:  6.548337114509195e-05
Epoch:  324  	Training Loss: 6.188555562403053e-05
Test Loss:  4.8593654355499893e-05
Valid Loss:  6.542247137986124e-05
Epoch:  325  	Training Loss: 6.18685080553405e-05
Test Loss:  4.8536960093770176e-05
Valid Loss:  6.537421722896397e-05
Epoch:  326  	Training Loss: 6.185215897858143e-05
Test Loss:  4.8490390327060595e-05
Valid Loss:  6.53319584671408e-05
Epoch:  327  	Training Loss: 6.18360354565084e-05
Test Loss:  4.844913200940937e-05
Valid Loss:  6.529340316774324e-05
Epoch:  328  	Training Loss: 6.182012293720618e-05
Test Loss:  4.8410634917672724e-05
Valid Loss:  6.525700882775709e-05
Epoch:  329  	Training Loss: 6.180441414471716e-05
Test Loss:  4.8373858589911833e-05
Valid Loss:  6.522194598801434e-05
Epoch:  330  	Training Loss: 6.178887269925326e-05
Test Loss:  4.833910134038888e-05
Valid Loss:  6.518856389448047e-05
Epoch:  331  	Training Loss: 6.177370232762769e-05
Test Loss:  4.830455873161554e-05
Valid Loss:  6.515556015074253e-05
Epoch:  332  	Training Loss: 6.175872113090008e-05
Test Loss:  4.851560515817255e-05
Valid Loss:  6.524823402287439e-05
Epoch:  333  	Training Loss: 6.168395339045674e-05
Test Loss:  4.865129085374065e-05
Valid Loss:  6.532284896820784e-05
Epoch:  334  	Training Loss: 6.16324323345907e-05
Test Loss:  4.873996658716351e-05
Valid Loss:  6.537881563417614e-05
Epoch:  335  	Training Loss: 6.158836913527921e-05
Test Loss:  4.879681364400312e-05
Valid Loss:  6.542018672917038e-05
Epoch:  336  	Training Loss: 6.154729635454714e-05
Test Loss:  4.88350196974352e-05
Valid Loss:  6.545117503264919e-05
Epoch:  337  	Training Loss: 6.150760600576177e-05
Test Loss:  4.886117676505819e-05
Valid Loss:  6.547453813254833e-05
Epoch:  338  	Training Loss: 6.146890518721193e-05
Test Loss:  4.8879119276534766e-05
Valid Loss:  6.549152749357745e-05
Epoch:  339  	Training Loss: 6.143099744804204e-05
Test Loss:  4.889123374596238e-05
Valid Loss:  6.550367106683552e-05
Epoch:  340  	Training Loss: 6.139336619526148e-05
Test Loss:  4.889882984571159e-05
Valid Loss:  6.551158730871975e-05
 68%|██████▊   | 341/500 [04:15<03:08,  1.19s/it] 69%|██████▊   | 343/500 [04:15<02:13,  1.17it/s] 69%|██████▉   | 345/500 [04:15<01:35,  1.62it/s] 69%|██████▉   | 347/500 [04:15<01:09,  2.22it/s] 70%|██████▉   | 349/500 [04:15<00:50,  2.98it/s] 70%|███████   | 351/500 [04:22<02:59,  1.20s/it] 71%|███████   | 353/500 [04:22<02:06,  1.16it/s] 71%|███████   | 355/500 [04:22<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:22<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:22<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:29<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:29<01:57,  1.16it/s] 73%|███████▎  | 365/500 [04:29<01:23,  1.61it/s] 73%|███████▎  | 367/500 [04:29<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:29<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:36<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:36<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:36<01:18,  1.60it/s] 75%|███████▌  | 377/500 [04:36<00:57,  2.16it/s] 76%|███████▌  | 379/500 [04:36<00:42,  2.86it/s] 76%|███████▌  | 381/500 [04:43<02:26,  1.23s/it] 77%|███████▋  | 383/500 [04:43<01:43,  1.13it/s] 77%|███████▋  | 385/500 [04:43<01:14,  1.55it/s] 77%|███████▋  | 387/500 [04:43<00:53,  2.10it/s] 78%|███████▊  | 389/500 [04:44<00:39,  2.79it/s] 78%|███████▊  | 391/500 [04:50<02:13,  1.23s/it] 79%|███████▊  | 393/500 [04:50<01:34,  1.14it/s] 79%|███████▉  | 395/500 [04:50<01:06,  1.57it/s] 79%|███████▉  | 397/500 [04:51<00:47,  2.15it/s] 80%|███████▉  | 399/500 [04:51<00:34,  2.90it/s] 80%|████████  | 401/500 [04:57<01:59,  1.21s/it] 81%|████████  | 403/500 [04:57<01:23,  1.16it/s] 81%|████████  | 405/500 [04:57<00:59,  1.60it/s] 81%|████████▏ | 407/500 [04:57<00:42,  2.19it/s]Epoch:  341  	Training Loss: 6.135631701909006e-05
Test Loss:  4.890285345027223e-05
Valid Loss:  6.551630212925375e-05
Epoch:  342  	Training Loss: 6.131967529654503e-05
Test Loss:  4.8939662519842386e-05
Valid Loss:  6.557288725161925e-05
Epoch:  343  	Training Loss: 6.129207758931443e-05
Test Loss:  4.8970148782245815e-05
Valid Loss:  6.56243646517396e-05
Epoch:  344  	Training Loss: 6.126610969658941e-05
Test Loss:  4.8997429985320196e-05
Valid Loss:  6.567138188984245e-05
Epoch:  345  	Training Loss: 6.124182255007327e-05
Test Loss:  4.902019281871617e-05
Valid Loss:  6.571436824742705e-05
Epoch:  346  	Training Loss: 6.121862679719925e-05
Test Loss:  4.904005618300289e-05
Valid Loss:  6.575375300599262e-05
Epoch:  347  	Training Loss: 6.119667523307726e-05
Test Loss:  4.905663809040561e-05
Valid Loss:  6.578897591680288e-05
Epoch:  348  	Training Loss: 6.117553857620806e-05
Test Loss:  4.907017864752561e-05
Valid Loss:  6.582175410585478e-05
Epoch:  349  	Training Loss: 6.115520955063403e-05
Test Loss:  4.9080841563409194e-05
Valid Loss:  6.585169467143714e-05
Epoch:  350  	Training Loss: 6.113568815635517e-05
Test Loss:  4.908909977530129e-05
Valid Loss:  6.587900134036317e-05
Epoch:  351  	Training Loss: 6.111688708188012e-05
Test Loss:  4.909526614937931e-05
Valid Loss:  6.590422708541155e-05
Epoch:  352  	Training Loss: 6.109855894465e-05
Test Loss:  4.893104778602719e-05
Valid Loss:  6.580373155884445e-05
Epoch:  353  	Training Loss: 6.104970088927075e-05
Test Loss:  4.884263762505725e-05
Valid Loss:  6.576425221282989e-05
Epoch:  354  	Training Loss: 6.100866085034795e-05
Test Loss:  4.8797686758916825e-05
Valid Loss:  6.575915176654235e-05
Epoch:  355  	Training Loss: 6.097173900343478e-05
Test Loss:  4.8778048949316144e-05
Valid Loss:  6.577368912985548e-05
Epoch:  356  	Training Loss: 6.093747651902959e-05
Test Loss:  4.877338506048545e-05
Valid Loss:  6.579894397873431e-05
Epoch:  357  	Training Loss: 6.090544047765434e-05
Test Loss:  4.8777059419080615e-05
Valid Loss:  6.582996866200119e-05
Epoch:  358  	Training Loss: 6.0875070630572736e-05
Test Loss:  4.8785401304485276e-05
Valid Loss:  6.586378731299192e-05
Epoch:  359  	Training Loss: 6.084623237256892e-05
Test Loss:  4.8796311602927744e-05
Valid Loss:  6.589877011720091e-05
Epoch:  360  	Training Loss: 6.081892570364289e-05
Test Loss:  4.880889900960028e-05
Valid Loss:  6.59337529214099e-05
Epoch:  361  	Training Loss: 6.079277954995632e-05
Test Loss:  4.882171924691647e-05
Valid Loss:  6.596814637305215e-05
Epoch:  362  	Training Loss: 6.076771387597546e-05
Test Loss:  4.8801739467307925e-05
Valid Loss:  6.590386328753084e-05
Epoch:  363  	Training Loss: 6.070649760658853e-05
Test Loss:  4.8716141463955864e-05
Valid Loss:  6.580358603969216e-05
Epoch:  364  	Training Loss: 6.065041816327721e-05
Test Loss:  4.861466004513204e-05
Valid Loss:  6.569678953383118e-05
Epoch:  365  	Training Loss: 6.059681618353352e-05
Test Loss:  4.851322592003271e-05
Valid Loss:  6.559295434271917e-05
Epoch:  366  	Training Loss: 6.054521509213373e-05
Test Loss:  4.8415473429486156e-05
Valid Loss:  6.549384124809876e-05
Epoch:  367  	Training Loss: 6.049525472917594e-05
Test Loss:  4.832298873225227e-05
Valid Loss:  6.540171307278797e-05
Epoch:  368  	Training Loss: 6.044648034730926e-05
Test Loss:  4.8236819566227496e-05
Valid Loss:  6.531649705721065e-05
Epoch:  369  	Training Loss: 6.039854633854702e-05
Test Loss:  4.8154099204111844e-05
Valid Loss:  6.523548654513434e-05
Epoch:  370  	Training Loss: 6.0352031141519547e-05
Test Loss:  4.807486038771458e-05
Valid Loss:  6.515895074699074e-05
Epoch:  371  	Training Loss: 6.0306512750685215e-05
Test Loss:  4.7998924856074154e-05
Valid Loss:  6.508570368168876e-05
Epoch:  372  	Training Loss: 6.026196206221357e-05
Test Loss:  4.8107951442943886e-05
Valid Loss:  6.511021638289094e-05
Epoch:  373  	Training Loss: 6.021330045768991e-05
Test Loss:  4.814679778064601e-05
Valid Loss:  6.511210813187063e-05
Epoch:  374  	Training Loss: 6.017481427988969e-05
Test Loss:  4.8150857764994726e-05
Valid Loss:  6.510013190563768e-05
Epoch:  375  	Training Loss: 6.013831080053933e-05
Test Loss:  4.813839404960163e-05
Valid Loss:  6.508160731755197e-05
Epoch:  376  	Training Loss: 6.010249489918351e-05
Test Loss:  4.811800317838788e-05
Valid Loss:  6.5059561165981e-05
Epoch:  377  	Training Loss: 6.006676994729787e-05
Test Loss:  4.8094480007421225e-05
Valid Loss:  6.503558688564226e-05
Epoch:  378  	Training Loss: 6.003149610478431e-05
Test Loss:  4.8068897740449756e-05
Valid Loss:  6.5010623075068e-05
Epoch:  379  	Training Loss: 5.999638233333826e-05
Test Loss:  4.8042245907709e-05
Valid Loss:  6.498547736555338e-05
Epoch:  380  	Training Loss: 5.9961526858387515e-05
Test Loss:  4.8015273932833225e-05
Valid Loss:  6.495976413134485e-05
Epoch:  381  	Training Loss: 5.992691149003804e-05
Test Loss:  4.7987541620386764e-05
Valid Loss:  6.493372347904369e-05
Epoch:  382  	Training Loss: 5.989251076243818e-05
Test Loss:  4.743456156575121e-05
Valid Loss:  6.448770000133663e-05
Epoch:  383  	Training Loss: 5.9770813095383346e-05
Test Loss:  4.7413115680683404e-05
Valid Loss:  6.444918108172715e-05
Epoch:  384  	Training Loss: 5.97155412833672e-05
Test Loss:  4.735568290925585e-05
Valid Loss:  6.43904713797383e-05
Epoch:  385  	Training Loss: 5.9661411796696484e-05
Test Loss:  4.729047941509634e-05
Valid Loss:  6.432784721255302e-05
Epoch:  386  	Training Loss: 5.960785347269848e-05
Test Loss:  4.7224304580595344e-05
Valid Loss:  6.426557229133323e-05
Epoch:  387  	Training Loss: 5.955486631137319e-05
Test Loss:  4.715970135293901e-05
Valid Loss:  6.420501449611038e-05
Epoch:  388  	Training Loss: 5.950245031272061e-05
Test Loss:  4.709618224296719e-05
Valid Loss:  6.414568633772433e-05
Epoch:  389  	Training Loss: 5.945051088929176e-05
Test Loss:  4.703386366600171e-05
Valid Loss:  6.408795161405578e-05
Epoch:  390  	Training Loss: 5.9399120800662786e-05
Test Loss:  4.697300755651668e-05
Valid Loss:  6.403149745892733e-05
Epoch:  391  	Training Loss: 5.934806540608406e-05
Test Loss:  4.691337380791083e-05
Valid Loss:  6.397629476850852e-05
Epoch:  392  	Training Loss: 5.92974029132165e-05
Test Loss:  4.68769867438823e-05
Valid Loss:  6.393007060978562e-05
Epoch:  393  	Training Loss: 5.924935976509005e-05
Test Loss:  4.6848672354826704e-05
Valid Loss:  6.389150075847283e-05
Epoch:  394  	Training Loss: 5.920238982071169e-05
Test Loss:  4.682280996348709e-05
Valid Loss:  6.385927554219961e-05
Epoch:  395  	Training Loss: 5.9157209761906415e-05
Test Loss:  4.680143320001662e-05
Valid Loss:  6.383157597156242e-05
Epoch:  396  	Training Loss: 5.911246262257919e-05
Test Loss:  4.678266850532964e-05
Valid Loss:  6.380691775120795e-05
Epoch:  397  	Training Loss: 5.906826481805183e-05
Test Loss:  4.676558819483034e-05
Valid Loss:  6.378449324984103e-05
Epoch:  398  	Training Loss: 5.902464181417599e-05
Test Loss:  4.674948286265135e-05
Valid Loss:  6.37635966995731e-05
Epoch:  399  	Training Loss: 5.89816554565914e-05
Test Loss:  4.673333023674786e-05
Valid Loss:  6.374408258125186e-05
Epoch:  400  	Training Loss: 5.89391820540186e-05
Test Loss:  4.671828355640173e-05
Valid Loss:  6.37261473457329e-05
Epoch:  401  	Training Loss: 5.889727981411852e-05
Test Loss:  4.6703717089258134e-05
Valid Loss:  6.371020572260022e-05
Epoch:  402  	Training Loss: 5.885583959752694e-05
Test Loss:  4.6489563828799874e-05
Valid Loss:  6.335702346405014e-05
Epoch:  403  	Training Loss: 5.8798075770027936e-05
Test Loss:  4.6696961362613365e-05
Valid Loss:  6.34777607046999e-05
Epoch:  404  	Training Loss: 5.871733446838334e-05
Test Loss:  4.668818655773066e-05
Valid Loss:  6.34674506727606e-05
Epoch:  405  	Training Loss: 5.864347986062057e-05
Test Loss:  4.6671742893522605e-05
Valid Loss:  6.348246097331867e-05
Epoch:  406  	Training Loss: 5.8589503169059753e-05
Test Loss:  4.627100861398503e-05
Valid Loss:  6.305790157057345e-05
Epoch:  407  	Training Loss: 5.8543770137475803e-05
Test Loss:  4.649705078918487e-05
Valid Loss:  6.321165710687637e-05
Epoch:  408  	Training Loss: 5.846508429385722e-05
Test Loss:  4.6504799684043974e-05
Valid Loss:  6.322857370832935e-05
 82%|████████▏ | 409/500 [04:58<00:30,  2.95it/s] 82%|████████▏ | 411/500 [05:04<01:45,  1.19s/it] 83%|████████▎ | 413/500 [05:04<01:14,  1.16it/s] 83%|████████▎ | 415/500 [05:04<00:53,  1.60it/s] 83%|████████▎ | 417/500 [05:04<00:37,  2.18it/s] 84%|████████▍ | 419/500 [05:05<00:27,  2.94it/s] 84%|████████▍ | 421/500 [05:11<01:37,  1.24s/it] 85%|████████▍ | 423/500 [05:11<01:08,  1.12it/s] 85%|████████▌ | 425/500 [05:12<00:48,  1.54it/s] 85%|████████▌ | 427/500 [05:12<00:35,  2.08it/s] 86%|████████▌ | 429/500 [05:12<00:25,  2.77it/s] 86%|████████▌ | 431/500 [05:18<01:23,  1.21s/it] 87%|████████▋ | 433/500 [05:18<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:19<00:41,  1.58it/s] 87%|████████▋ | 437/500 [05:19<00:29,  2.13it/s] 88%|████████▊ | 439/500 [05:19<00:21,  2.83it/s] 88%|████████▊ | 441/500 [05:25<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:25<00:49,  1.15it/s] 89%|████████▉ | 445/500 [05:26<00:34,  1.59it/s] 89%|████████▉ | 447/500 [05:26<00:24,  2.18it/s] 90%|████████▉ | 449/500 [05:26<00:17,  2.89it/s] 90%|█████████ | 451/500 [05:33<01:01,  1.25s/it] 91%|█████████ | 453/500 [05:33<00:42,  1.11it/s] 91%|█████████ | 455/500 [05:33<00:29,  1.54it/s] 91%|█████████▏| 457/500 [05:33<00:20,  2.11it/s] 92%|█████████▏| 459/500 [05:33<00:14,  2.85it/s] 92%|█████████▏| 461/500 [05:40<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:40<00:32,  1.16it/s] 93%|█████████▎| 465/500 [05:40<00:22,  1.58it/s] 93%|█████████▎| 467/500 [05:40<00:15,  2.16it/s] 94%|█████████▍| 469/500 [05:40<00:10,  2.91it/s] 94%|█████████▍| 471/500 [05:46<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:47<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:47<00:15,  1.61it/s]Epoch:  409  	Training Loss: 5.839427103637718e-05
Test Loss:  4.649824040825479e-05
Valid Loss:  6.326606671791524e-05
Epoch:  410  	Training Loss: 5.8344950957689434e-05
Test Loss:  4.610866744769737e-05
Valid Loss:  6.286014831857756e-05
Epoch:  411  	Training Loss: 5.8302932302467525e-05
Test Loss:  4.634210199583322e-05
Valid Loss:  6.30242720944807e-05
Epoch:  412  	Training Loss: 5.822655657539144e-05
Test Loss:  4.6280700189527124e-05
Valid Loss:  6.298234802670777e-05
Epoch:  413  	Training Loss: 5.8200796047458425e-05
Test Loss:  4.6224682591855526e-05
Valid Loss:  6.294446211541072e-05
Epoch:  414  	Training Loss: 5.817606870550662e-05
Test Loss:  4.61733179690782e-05
Valid Loss:  6.291014142334461e-05
Epoch:  415  	Training Loss: 5.815188342239708e-05
Test Loss:  4.6126111556077376e-05
Valid Loss:  6.287859287112951e-05
Epoch:  416  	Training Loss: 5.812829112983309e-05
Test Loss:  4.60823648609221e-05
Valid Loss:  6.284904520725831e-05
Epoch:  417  	Training Loss: 5.810499715153128e-05
Test Loss:  4.6041826863074675e-05
Valid Loss:  6.282226968323812e-05
Epoch:  418  	Training Loss: 5.8082361647393554e-05
Test Loss:  4.600384272634983e-05
Valid Loss:  6.279702938627452e-05
Epoch:  419  	Training Loss: 5.805990076623857e-05
Test Loss:  4.596847065840848e-05
Valid Loss:  6.277360080275685e-05
Epoch:  420  	Training Loss: 5.8038167480845004e-05
Test Loss:  4.593355697579682e-05
Valid Loss:  6.27515692031011e-05
Epoch:  421  	Training Loss: 5.801681982120499e-05
Test Loss:  4.590130993165076e-05
Valid Loss:  6.273097824305296e-05
Epoch:  422  	Training Loss: 5.79956904402934e-05
Test Loss:  4.603227353072725e-05
Valid Loss:  6.28730995231308e-05
Epoch:  423  	Training Loss: 5.796309415018186e-05
Test Loss:  4.612287011696026e-05
Valid Loss:  6.298109656199813e-05
Epoch:  424  	Training Loss: 5.7935205404646695e-05
Test Loss:  4.618649836629629e-05
Valid Loss:  6.306580326054245e-05
Epoch:  425  	Training Loss: 5.791041985503398e-05
Test Loss:  4.623243512469344e-05
Valid Loss:  6.31346192676574e-05
Epoch:  426  	Training Loss: 5.7887682487489656e-05
Test Loss:  4.6266337449196726e-05
Valid Loss:  6.319256499409676e-05
Epoch:  427  	Training Loss: 5.786675319541246e-05
Test Loss:  4.629252725862898e-05
Valid Loss:  6.324287824099883e-05
Epoch:  428  	Training Loss: 5.784732638858259e-05
Test Loss:  4.6314049541251734e-05
Valid Loss:  6.328778545139357e-05
Epoch:  429  	Training Loss: 5.7829201978165656e-05
Test Loss:  4.633177013602108e-05
Valid Loss:  6.332874181680381e-05
Epoch:  430  	Training Loss: 5.7812190789263695e-05
Test Loss:  4.6347333409357816e-05
Valid Loss:  6.336660590022802e-05
Epoch:  431  	Training Loss: 5.7796354667516425e-05
Test Loss:  4.6360983105842024e-05
Valid Loss:  6.340189429465681e-05
Epoch:  432  	Training Loss: 5.778139893664047e-05
Test Loss:  4.6066907088970765e-05
Valid Loss:  6.31027141935192e-05
Epoch:  433  	Training Loss: 5.771628275397234e-05
Test Loss:  4.5912009227322415e-05
Valid Loss:  6.289839802775532e-05
Epoch:  434  	Training Loss: 5.7659595768200234e-05
Test Loss:  4.574829654302448e-05
Valid Loss:  6.270280573517084e-05
Epoch:  435  	Training Loss: 5.760897329309955e-05
Test Loss:  4.560758679872379e-05
Valid Loss:  6.253206811379641e-05
Epoch:  436  	Training Loss: 5.756300379289314e-05
Test Loss:  4.547833668766543e-05
Valid Loss:  6.237879279069602e-05
Epoch:  437  	Training Loss: 5.752103606937453e-05
Test Loss:  4.536331834970042e-05
Valid Loss:  6.224258686415851e-05
Epoch:  438  	Training Loss: 5.748199328081682e-05
Test Loss:  4.525832264334895e-05
Valid Loss:  6.211978325154632e-05
Epoch:  439  	Training Loss: 5.744511872762814e-05
Test Loss:  4.51626765425317e-05
Valid Loss:  6.20086066192016e-05
Epoch:  440  	Training Loss: 5.741021959693171e-05
Test Loss:  4.507380799623206e-05
Valid Loss:  6.190798740135506e-05
Epoch:  441  	Training Loss: 5.737677565775812e-05
Test Loss:  4.4994110794505104e-05
Valid Loss:  6.18171616224572e-05
Epoch:  442  	Training Loss: 5.734463775297627e-05
Test Loss:  4.5188651711214334e-05
Valid Loss:  6.19751590420492e-05
Epoch:  443  	Training Loss: 5.7289576943730935e-05
Test Loss:  4.5302946091396734e-05
Valid Loss:  6.207318801898509e-05
Epoch:  444  	Training Loss: 5.7242570619564503e-05
Test Loss:  4.537076165433973e-05
Valid Loss:  6.213570304680616e-05
Epoch:  445  	Training Loss: 5.719864202546887e-05
Test Loss:  4.541216912912205e-05
Valid Loss:  6.217666668817401e-05
Epoch:  446  	Training Loss: 5.7156383263645694e-05
Test Loss:  4.543862451100722e-05
Valid Loss:  6.220526847755536e-05
Epoch:  447  	Training Loss: 5.7115714298561215e-05
Test Loss:  4.545329284155741e-05
Valid Loss:  6.222856609383598e-05
Epoch:  448  	Training Loss: 5.7077435485552996e-05
Test Loss:  4.5464650611393154e-05
Valid Loss:  6.224746903171763e-05
Epoch:  449  	Training Loss: 5.704016803065315e-05
Test Loss:  4.547414937405847e-05
Valid Loss:  6.226279947441071e-05
Epoch:  450  	Training Loss: 5.700360270566307e-05
Test Loss:  4.548208380583674e-05
Valid Loss:  6.227580888662487e-05
Epoch:  451  	Training Loss: 5.696780135622248e-05
Test Loss:  4.5488886826206e-05
Valid Loss:  6.22864899924025e-05
Epoch:  452  	Training Loss: 5.693268030881882e-05
Test Loss:  4.546398122329265e-05
Valid Loss:  6.224844401003793e-05
Epoch:  453  	Training Loss: 5.6901135394582525e-05
Test Loss:  4.544652620097622e-05
Valid Loss:  6.221805233508348e-05
Epoch:  454  	Training Loss: 5.687041630153544e-05
Test Loss:  4.5433800551109016e-05
Valid Loss:  6.219308124855161e-05
Epoch:  455  	Training Loss: 5.684018833562732e-05
Test Loss:  4.542418901110068e-05
Valid Loss:  6.217238114913926e-05
Epoch:  456  	Training Loss: 5.681046241079457e-05
Test Loss:  4.54169676231686e-05
Valid Loss:  6.215496978256851e-05
Epoch:  457  	Training Loss: 5.678124580299482e-05
Test Loss:  4.541152520687319e-05
Valid Loss:  6.21398285147734e-05
Epoch:  458  	Training Loss: 5.675237480318174e-05
Test Loss:  4.540734153124504e-05
Valid Loss:  6.212681182660162e-05
Epoch:  459  	Training Loss: 5.672395491274074e-05
Test Loss:  4.540442751022056e-05
Valid Loss:  6.211577419890091e-05
Epoch:  460  	Training Loss: 5.669590609613806e-05
Test Loss:  4.540228837868199e-05
Valid Loss:  6.210609717527404e-05
Epoch:  461  	Training Loss: 5.666823562933132e-05
Test Loss:  4.5399552618619055e-05
Valid Loss:  6.209759158082306e-05
Epoch:  462  	Training Loss: 5.664105265168473e-05
Test Loss:  4.530401201918721e-05
Valid Loss:  6.200179632287472e-05
Epoch:  463  	Training Loss: 5.6621945986989886e-05
Test Loss:  4.523655297816731e-05
Valid Loss:  6.1923754401505e-05
Epoch:  464  	Training Loss: 5.660509486915544e-05
Test Loss:  4.5184686314314604e-05
Valid Loss:  6.185740494402125e-05
Epoch:  465  	Training Loss: 5.658955342369154e-05
Test Loss:  4.5141627197153866e-05
Valid Loss:  6.179943011375144e-05
Epoch:  466  	Training Loss: 5.657518340740353e-05
Test Loss:  4.5105527533451095e-05
Valid Loss:  6.174848385853693e-05
Epoch:  467  	Training Loss: 5.6561577366665006e-05
Test Loss:  4.507272387854755e-05
Valid Loss:  6.170364940771833e-05
Epoch:  468  	Training Loss: 5.6549208238720894e-05
Test Loss:  4.504382377490401e-05
Valid Loss:  6.166383536765352e-05
Epoch:  469  	Training Loss: 5.653742118738592e-05
Test Loss:  4.501879448071122e-05
Valid Loss:  6.162836507428437e-05
Epoch:  470  	Training Loss: 5.652596883010119e-05
Test Loss:  4.499604256125167e-05
Valid Loss:  6.159667100291699e-05
Epoch:  471  	Training Loss: 5.6515007599955425e-05
Test Loss:  4.497610279941e-05
Valid Loss:  6.156819290481508e-05
Epoch:  472  	Training Loss: 5.6504337408114225e-05
Test Loss:  4.497084592003375e-05
Valid Loss:  6.15753888268955e-05
Epoch:  473  	Training Loss: 5.649403465213254e-05
Test Loss:  4.496745896176435e-05
Valid Loss:  6.158404721645638e-05
Epoch:  474  	Training Loss: 5.648412843584083e-05
Test Loss:  4.496488327276893e-05
Valid Loss:  6.159376789582893e-05
Epoch:  475  	Training Loss: 5.647440048051067e-05
Test Loss:  4.496388282859698e-05
Valid Loss:  6.160439079394564e-05
Epoch:  476  	Training Loss: 5.64647234568838e-05
Test Loss:  4.496406108955853e-05
Valid Loss:  6.161583587527275e-05
 95%|█████████▌| 477/500 [05:47<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:47<00:07,  2.97it/s] 96%|█████████▌| 481/500 [05:53<00:22,  1.19s/it] 96%|█████████▋| 482/500 [05:54<00:18,  1.00s/it] 97%|█████████▋| 484/500 [05:54<00:11,  1.44it/s] 97%|█████████▋| 486/500 [05:54<00:06,  2.01it/s] 98%|█████████▊| 488/500 [05:54<00:04,  2.73it/s] 98%|█████████▊| 490/500 [05:54<00:02,  3.58it/s] 98%|█████████▊| 492/500 [06:01<00:09,  1.19s/it] 99%|█████████▉| 494/500 [06:01<00:05,  1.18it/s] 99%|█████████▉| 496/500 [06:01<00:02,  1.64it/s]100%|█████████▉| 498/500 [06:01<00:00,  2.25it/s]100%|██████████| 500/500 [06:01<00:00,  3.02it/s]100%|██████████| 500/500 [06:01<00:00,  1.38it/s]
Epoch:  477  	Training Loss: 5.6455588492099196e-05
Test Loss:  4.49652798124589e-05
Valid Loss:  6.162788486108184e-05
Epoch:  478  	Training Loss: 5.6446457165293396e-05
Test Loss:  4.4967378926230595e-05
Valid Loss:  6.164027581689879e-05
Epoch:  479  	Training Loss: 5.643749682349153e-05
Test Loss:  4.4969856389798224e-05
Valid Loss:  6.165263039292768e-05
Epoch:  480  	Training Loss: 5.6428718380630016e-05
Test Loss:  4.497261033975519e-05
Valid Loss:  6.16654651821591e-05
Epoch:  481  	Training Loss: 5.641997995553538e-05
Test Loss:  4.497588815866038e-05
Valid Loss:  6.16782417637296e-05
Epoch:  482  	Training Loss: 5.6411568948533386e-05
Test Loss:  4.50795741926413e-05
Valid Loss:  6.178513285703957e-05
Epoch:  483  	Training Loss: 5.6386226788163185e-05
Test Loss:  4.5168948417995125e-05
Valid Loss:  6.187800318002701e-05
Epoch:  484  	Training Loss: 5.6365650380030274e-05
Test Loss:  4.5245091314427555e-05
Valid Loss:  6.195856985868886e-05
Epoch:  485  	Training Loss: 5.63487847102806e-05
Test Loss:  4.530967999016866e-05
Valid Loss:  6.202791701070964e-05
Epoch:  486  	Training Loss: 5.63345747650601e-05
Test Loss:  4.5363853132585064e-05
Valid Loss:  6.208692502696067e-05
Epoch:  487  	Training Loss: 5.63223147764802e-05
Test Loss:  4.5409022277453914e-05
Valid Loss:  6.21374201728031e-05
Epoch:  488  	Training Loss: 5.631176463793963e-05
Test Loss:  4.544614421320148e-05
Valid Loss:  6.218047928996384e-05
Epoch:  489  	Training Loss: 5.6302302255062386e-05
Test Loss:  4.547617572825402e-05
Valid Loss:  6.221639341674745e-05
Epoch:  490  	Training Loss: 5.629374572890811e-05
Test Loss:  4.5500200940296054e-05
Valid Loss:  6.224655953701586e-05
Epoch:  491  	Training Loss: 5.62857385375537e-05
Test Loss:  4.551894016913138e-05
Valid Loss:  6.227170524653047e-05
Epoch:  492  	Training Loss: 5.627834616461769e-05
Test Loss:  4.538000939646736e-05
Valid Loss:  6.21714279986918e-05
Epoch:  493  	Training Loss: 5.6255183153552935e-05
Test Loss:  4.527859346126206e-05
Valid Loss:  6.20922728558071e-05
Epoch:  494  	Training Loss: 5.6236633099615574e-05
Test Loss:  4.520435686572455e-05
Valid Loss:  6.203005614224821e-05
Epoch:  495  	Training Loss: 5.622041499009356e-05
Test Loss:  4.5148295612307265e-05
Valid Loss:  6.197935726959258e-05
Epoch:  496  	Training Loss: 5.6205495639005676e-05
Test Loss:  4.5105050958227366e-05
Valid Loss:  6.193715671543032e-05
Epoch:  497  	Training Loss: 5.619120929623023e-05
Test Loss:  4.5070992200635374e-05
Valid Loss:  6.190093699842691e-05
Epoch:  498  	Training Loss: 5.6177403166657314e-05
Test Loss:  4.504276148509234e-05
Valid Loss:  6.186985410749912e-05
Epoch:  499  	Training Loss: 5.616406997432932e-05
Test Loss:  4.501933653955348e-05
Valid Loss:  6.184211088111624e-05
Epoch:  500  	Training Loss: 5.615102418232709e-05
Test Loss:  4.499910573940724e-05
Valid Loss:  6.181760545587167e-05
seed is  3
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.44it/s]  1%|          | 4/500 [00:00<00:30, 16.13it/s]  1%|          | 6/500 [00:00<00:30, 16.23it/s]  2%|▏         | 8/500 [00:00<00:30, 16.26it/s]  2%|▏         | 10/500 [00:00<00:30, 16.32it/s]  2%|▏         | 12/500 [00:00<00:30, 16.26it/s]  3%|▎         | 14/500 [00:00<00:30, 16.02it/s]  3%|▎         | 16/500 [00:01<00:30, 15.64it/s]  4%|▎         | 18/500 [00:01<00:30, 15.55it/s]  4%|▍         | 20/500 [00:01<00:30, 15.59it/s]  4%|▍         | 22/500 [00:01<00:30, 15.86it/s]  5%|▍         | 24/500 [00:01<00:29, 16.04it/s]  5%|▌         | 26/500 [00:01<00:29, 16.11it/s]  6%|▌         | 28/500 [00:01<00:28, 16.29it/s]  6%|▌         | 30/500 [00:01<00:28, 16.36it/s]  6%|▋         | 32/500 [00:01<00:28, 16.41it/s]  7%|▋         | 34/500 [00:02<00:28, 16.32it/s]  7%|▋         | 36/500 [00:02<00:28, 16.16it/s]  8%|▊         | 38/500 [00:02<00:28, 16.22it/s]  8%|▊         | 40/500 [00:02<00:28, 16.19it/s]  8%|▊         | 42/500 [00:02<00:28, 16.13it/s]  9%|▉         | 44/500 [00:02<00:28, 15.97it/s]  9%|▉         | 46/500 [00:02<00:28, 16.03it/s] 10%|▉         | 48/500 [00:03<00:30, 14.73it/s] 10%|█         | 50/500 [00:03<00:30, 14.52it/s] 10%|█         | 52/500 [00:03<00:33, 13.36it/s] 11%|█         | 54/500 [00:03<00:34, 13.06it/s] 11%|█         | 56/500 [00:03<00:34, 12.86it/s] 12%|█▏        | 58/500 [00:03<00:34, 12.74it/s] 12%|█▏        | 60/500 [00:03<00:34, 12.65it/s] 12%|█▏        | 62/500 [00:04<00:34, 12.71it/s] 13%|█▎        | 64/500 [00:04<00:34, 12.62it/s] 13%|█▎        | 66/500 [00:04<00:34, 12.50it/s] 14%|█▎        | 68/500 [00:04<00:34, 12.45it/s] 14%|█▍        | 70/500 [00:04<00:34, 12.41it/s] 14%|█▍        | 72/500 [00:04<00:34, 12.45it/s] 15%|█▍        | 74/500 [00:05<00:34, 12.45it/s] 15%|█▌        | 76/500 [00:05<00:33, 12.63it/s] 16%|█▌        | 78/500 [00:05<00:31, 13.59it/s] 16%|█▌        | 80/500 [00:05<00:29, 14.35it/s] 16%|█▋        | 82/500 [00:05<00:28, 14.93it/s] 17%|█▋        | 84/500 [00:05<00:27, 15.38it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.67it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.95it/s] 18%|█▊        | 90/500 [00:06<00:25, 16.11it/s] 18%|█▊        | 92/500 [00:06<00:25, 15.78it/s] 19%|█▉        | 94/500 [00:06<00:25, 15.67it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.87it/s] 20%|█▉        | 98/500 [00:06<00:25, 16.05it/s] 20%|██        | 100/500 [00:06<00:24, 16.20it/s] 20%|██        | 102/500 [00:06<00:24, 16.27it/s] 21%|██        | 104/500 [00:06<00:24, 16.31it/s] 21%|██        | 106/500 [00:07<00:24, 16.32it/s] 22%|██▏       | 108/500 [00:07<00:23, 16.34it/s] 22%|██▏       | 110/500 [00:07<00:23, 16.34it/s] 22%|██▏       | 112/500 [00:07<00:24, 16.00it/s] 23%|██▎       | 114/500 [00:07<00:24, 16.07it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.75it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.66it/s] 24%|██▍       | 120/500 [00:07<00:24, 15.74it/s] 24%|██▍       | 122/500 [00:08<00:24, 15.67it/s] 25%|██▍       | 124/500 [00:08<00:23, 15.88it/s]Epoch:  1  	Training Loss: 0.11694976687431335
Test Loss:  2563.65576171875
Valid Loss:  2561.56298828125
Epoch:  2  	Training Loss: 2563.1337890625
Test Loss:  74249616228352.0
Valid Loss:  73634454437888.0
Epoch:  3  	Training Loss: 73781984886784.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 16.08it/s] 26%|██▌       | 128/500 [00:08<00:23, 16.08it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.84it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.78it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.70it/s] 27%|██▋       | 136/500 [00:09<00:23, 15.51it/s] 28%|██▊       | 138/500 [00:09<00:25, 14.26it/s] 28%|██▊       | 140/500 [00:09<00:25, 14.01it/s] 28%|██▊       | 142/500 [00:09<00:27, 13.25it/s] 29%|██▉       | 144/500 [00:09<00:27, 13.06it/s] 29%|██▉       | 146/500 [00:09<00:25, 13.69it/s] 30%|██▉       | 148/500 [00:09<00:24, 14.31it/s] 30%|███       | 150/500 [00:10<00:24, 14.48it/s] 30%|███       | 152/500 [00:10<00:23, 14.51it/s] 31%|███       | 154/500 [00:10<00:24, 14.38it/s] 31%|███       | 156/500 [00:10<00:23, 14.83it/s] 32%|███▏      | 158/500 [00:10<00:22, 15.21it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.56it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.85it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.97it/s] 33%|███▎      | 166/500 [00:11<00:22, 15.09it/s] 34%|███▎      | 168/500 [00:11<00:23, 14.15it/s] 34%|███▍      | 170/500 [00:11<00:24, 13.73it/s] 34%|███▍      | 172/500 [00:11<00:24, 13.41it/s] 35%|███▍      | 174/500 [00:11<00:24, 13.06it/s] 35%|███▌      | 176/500 [00:11<00:24, 13.09it/s] 36%|███▌      | 178/500 [00:12<00:25, 12.79it/s] 36%|███▌      | 180/500 [00:12<00:25, 12.67it/s] 36%|███▋      | 182/500 [00:12<00:23, 13.25it/s] 37%|███▋      | 184/500 [00:12<00:22, 13.90it/s] 37%|███▋      | 186/500 [00:12<00:21, 14.59it/s] 38%|███▊      | 188/500 [00:12<00:20, 14.92it/s] 38%|███▊      | 190/500 [00:12<00:21, 14.18it/s] 38%|███▊      | 192/500 [00:12<00:20, 14.79it/s] 39%|███▉      | 194/500 [00:13<00:21, 14.45it/s] 39%|███▉      | 196/500 [00:13<00:22, 13.68it/s] 40%|███▉      | 198/500 [00:13<00:22, 13.26it/s] 40%|████      | 200/500 [00:13<00:23, 12.99it/s] 40%|████      | 202/500 [00:13<00:23, 12.82it/s] 41%|████      | 204/500 [00:13<00:23, 12.71it/s] 41%|████      | 206/500 [00:14<00:23, 12.60it/s] 42%|████▏     | 208/500 [00:14<00:23, 12.45it/s] 42%|████▏     | 210/500 [00:14<00:23, 12.35it/s] 42%|████▏     | 212/500 [00:14<00:23, 12.29it/s] 43%|████▎     | 214/500 [00:14<00:22, 12.75it/s] 43%|████▎     | 216/500 [00:14<00:22, 12.60it/s] 44%|████▎     | 218/500 [00:15<00:22, 12.54it/s] 44%|████▍     | 220/500 [00:15<00:21, 13.08it/s] 44%|████▍     | 222/500 [00:15<00:20, 13.73it/s] 45%|████▍     | 224/500 [00:15<00:20, 13.39it/s] 45%|████▌     | 226/500 [00:15<00:21, 12.99it/s] 46%|████▌     | 228/500 [00:15<00:21, 12.81it/s] 46%|████▌     | 230/500 [00:15<00:21, 12.66it/s] 46%|████▋     | 232/500 [00:16<00:21, 12.51it/s] 47%|████▋     | 234/500 [00:16<00:21, 12.37it/s] 47%|████▋     | 236/500 [00:16<00:21, 12.35it/s] 48%|████▊     | 238/500 [00:16<00:21, 12.39it/s] 48%|████▊     | 240/500 [00:16<00:20, 12.40it/s] 48%|████▊     | 242/500 [00:16<00:20, 12.36it/s] 49%|████▉     | 244/500 [00:17<00:20, 12.33it/s] 49%|████▉     | 246/500 [00:17<00:20, 12.31it/s] 50%|████▉     | 248/500 [00:17<00:20, 12.31it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:17<00:20, 12.35it/s] 50%|█████     | 252/500 [00:17<00:20, 12.37it/s] 51%|█████     | 254/500 [00:17<00:19, 12.37it/s] 51%|█████     | 256/500 [00:18<00:19, 12.35it/s] 52%|█████▏    | 258/500 [00:18<00:19, 12.27it/s] 52%|█████▏    | 260/500 [00:18<00:19, 12.33it/s] 52%|█████▏    | 262/500 [00:18<00:19, 12.34it/s] 53%|█████▎    | 264/500 [00:18<00:19, 12.35it/s] 53%|█████▎    | 266/500 [00:18<00:19, 11.97it/s] 54%|█████▎    | 268/500 [00:19<00:19, 12.12it/s] 54%|█████▍    | 270/500 [00:19<00:18, 12.19it/s] 54%|█████▍    | 272/500 [00:19<00:18, 12.23it/s] 55%|█████▍    | 274/500 [00:19<00:17, 12.96it/s] 55%|█████▌    | 276/500 [00:19<00:16, 13.72it/s] 56%|█████▌    | 278/500 [00:19<00:15, 14.29it/s] 56%|█████▌    | 280/500 [00:19<00:14, 14.73it/s] 56%|█████▋    | 282/500 [00:20<00:14, 14.91it/s] 57%|█████▋    | 284/500 [00:20<00:14, 14.89it/s] 57%|█████▋    | 286/500 [00:20<00:14, 14.73it/s] 58%|█████▊    | 288/500 [00:20<00:15, 13.95it/s] 58%|█████▊    | 290/500 [00:20<00:15, 13.45it/s] 58%|█████▊    | 292/500 [00:20<00:15, 13.14it/s] 59%|█████▉    | 294/500 [00:20<00:15, 12.93it/s] 59%|█████▉    | 296/500 [00:21<00:16, 12.73it/s] 60%|█████▉    | 298/500 [00:21<00:16, 12.58it/s] 60%|██████    | 300/500 [00:21<00:16, 12.41it/s] 60%|██████    | 302/500 [00:21<00:16, 12.29it/s] 61%|██████    | 304/500 [00:21<00:16, 12.03it/s] 61%|██████    | 306/500 [00:21<00:16, 12.08it/s] 62%|██████▏   | 308/500 [00:22<00:15, 12.12it/s] 62%|██████▏   | 310/500 [00:22<00:15, 12.21it/s] 62%|██████▏   | 312/500 [00:22<00:15, 12.28it/s] 63%|██████▎   | 314/500 [00:22<00:15, 12.31it/s] 63%|██████▎   | 316/500 [00:22<00:14, 12.85it/s] 64%|██████▎   | 318/500 [00:22<00:13, 13.42it/s] 64%|██████▍   | 320/500 [00:23<00:13, 13.09it/s] 64%|██████▍   | 322/500 [00:23<00:13, 12.89it/s] 65%|██████▍   | 324/500 [00:23<00:13, 12.97it/s] 65%|██████▌   | 326/500 [00:23<00:12, 13.47it/s] 66%|██████▌   | 328/500 [00:23<00:12, 13.99it/s] 66%|██████▌   | 330/500 [00:23<00:11, 14.64it/s] 66%|██████▋   | 332/500 [00:23<00:11, 15.16it/s] 67%|██████▋   | 334/500 [00:23<00:10, 15.41it/s] 67%|██████▋   | 336/500 [00:24<00:10, 15.62it/s] 68%|██████▊   | 338/500 [00:24<00:10, 15.85it/s] 68%|██████▊   | 340/500 [00:24<00:09, 16.01it/s] 68%|██████▊   | 342/500 [00:24<00:09, 16.17it/s] 69%|██████▉   | 344/500 [00:24<00:09, 16.28it/s] 69%|██████▉   | 346/500 [00:24<00:09, 16.36it/s] 70%|██████▉   | 348/500 [00:24<00:09, 16.44it/s] 70%|███████   | 350/500 [00:24<00:09, 16.44it/s] 70%|███████   | 352/500 [00:25<00:08, 16.45it/s] 71%|███████   | 354/500 [00:25<00:08, 16.41it/s] 71%|███████   | 356/500 [00:25<00:08, 16.37it/s] 72%|███████▏  | 358/500 [00:25<00:08, 16.42it/s] 72%|███████▏  | 360/500 [00:25<00:08, 16.44it/s] 72%|███████▏  | 362/500 [00:25<00:08, 16.42it/s] 73%|███████▎  | 364/500 [00:25<00:08, 15.99it/s] 73%|███████▎  | 366/500 [00:25<00:08, 16.12it/s] 74%|███████▎  | 368/500 [00:26<00:08, 16.20it/s] 74%|███████▍  | 370/500 [00:26<00:07, 16.26it/s] 74%|███████▍  | 372/500 [00:26<00:07, 16.37it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:26<00:08, 15.39it/s] 75%|███████▌  | 376/500 [00:26<00:08, 14.31it/s] 76%|███████▌  | 378/500 [00:26<00:09, 13.45it/s] 76%|███████▌  | 380/500 [00:26<00:08, 13.90it/s] 76%|███████▋  | 382/500 [00:27<00:08, 14.57it/s] 77%|███████▋  | 384/500 [00:27<00:07, 15.10it/s] 77%|███████▋  | 386/500 [00:27<00:07, 15.13it/s] 78%|███████▊  | 388/500 [00:27<00:07, 15.38it/s] 78%|███████▊  | 390/500 [00:27<00:07, 15.68it/s] 78%|███████▊  | 392/500 [00:27<00:06, 15.89it/s] 79%|███████▉  | 394/500 [00:27<00:06, 16.03it/s] 79%|███████▉  | 396/500 [00:27<00:06, 16.11it/s] 80%|███████▉  | 398/500 [00:28<00:06, 16.14it/s] 80%|████████  | 400/500 [00:28<00:06, 16.18it/s] 80%|████████  | 402/500 [00:28<00:06, 16.06it/s] 81%|████████  | 404/500 [00:28<00:06, 15.98it/s] 81%|████████  | 406/500 [00:28<00:05, 15.91it/s] 82%|████████▏ | 408/500 [00:28<00:05, 15.74it/s] 82%|████████▏ | 410/500 [00:28<00:05, 15.82it/s] 82%|████████▏ | 412/500 [00:28<00:05, 16.03it/s] 83%|████████▎ | 414/500 [00:29<00:05, 15.71it/s] 83%|████████▎ | 416/500 [00:29<00:05, 15.59it/s] 84%|████████▎ | 418/500 [00:29<00:05, 14.84it/s] 84%|████████▍ | 420/500 [00:29<00:05, 14.62it/s] 84%|████████▍ | 422/500 [00:29<00:05, 15.07it/s] 85%|████████▍ | 424/500 [00:29<00:04, 15.31it/s] 85%|████████▌ | 426/500 [00:29<00:04, 15.33it/s] 86%|████████▌ | 428/500 [00:29<00:04, 15.18it/s] 86%|████████▌ | 430/500 [00:30<00:04, 15.21it/s] 86%|████████▋ | 432/500 [00:30<00:04, 14.09it/s] 87%|████████▋ | 434/500 [00:30<00:04, 13.75it/s] 87%|████████▋ | 436/500 [00:30<00:04, 14.33it/s] 88%|████████▊ | 438/500 [00:30<00:04, 14.90it/s] 88%|████████▊ | 440/500 [00:30<00:03, 15.23it/s] 88%|████████▊ | 442/500 [00:30<00:03, 15.56it/s] 89%|████████▉ | 444/500 [00:31<00:03, 15.72it/s] 89%|████████▉ | 446/500 [00:31<00:03, 15.88it/s] 90%|████████▉ | 448/500 [00:31<00:03, 16.07it/s] 90%|█████████ | 450/500 [00:31<00:03, 16.16it/s] 90%|█████████ | 452/500 [00:31<00:02, 16.22it/s] 91%|█████████ | 454/500 [00:31<00:02, 16.34it/s] 91%|█████████ | 456/500 [00:31<00:02, 15.86it/s] 92%|█████████▏| 458/500 [00:31<00:02, 15.54it/s] 92%|█████████▏| 460/500 [00:32<00:02, 15.75it/s] 92%|█████████▏| 462/500 [00:32<00:02, 14.59it/s] 93%|█████████▎| 464/500 [00:32<00:02, 13.85it/s] 93%|█████████▎| 466/500 [00:32<00:02, 14.01it/s] 94%|█████████▎| 468/500 [00:32<00:02, 14.71it/s] 94%|█████████▍| 470/500 [00:32<00:01, 15.19it/s] 94%|█████████▍| 472/500 [00:32<00:01, 15.58it/s] 95%|█████████▍| 474/500 [00:32<00:01, 15.86it/s] 95%|█████████▌| 476/500 [00:33<00:01, 16.03it/s] 96%|█████████▌| 478/500 [00:33<00:01, 16.10it/s] 96%|█████████▌| 480/500 [00:33<00:01, 16.15it/s] 96%|█████████▋| 482/500 [00:33<00:01, 16.25it/s] 97%|█████████▋| 484/500 [00:33<00:00, 16.28it/s] 97%|█████████▋| 486/500 [00:33<00:00, 16.30it/s] 98%|█████████▊| 488/500 [00:33<00:00, 16.34it/s] 98%|█████████▊| 490/500 [00:33<00:00, 16.38it/s] 98%|█████████▊| 492/500 [00:34<00:00, 16.39it/s] 99%|█████████▉| 494/500 [00:34<00:00, 15.74it/s] 99%|█████████▉| 496/500 [00:34<00:00, 15.80it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:34<00:00, 15.93it/s]100%|██████████| 500/500 [00:34<00:00, 16.06it/s]100%|██████████| 500/500 [00:34<00:00, 14.45it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  3
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<53:17,  6.41s/it]  1%|          | 3/500 [00:06<14:11,  1.71s/it]  1%|          | 5/500 [00:06<07:08,  1.16it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:53,  2.84it/s]  2%|▏         | 11/500 [00:13<11:14,  1.38s/it]  3%|▎         | 13/500 [00:13<07:39,  1.06it/s]  3%|▎         | 15/500 [00:13<05:20,  1.52it/s]  3%|▎         | 17/500 [00:13<03:49,  2.11it/s]  4%|▍         | 19/500 [00:14<02:50,  2.82it/s]  4%|▍         | 21/500 [00:20<09:52,  1.24s/it]  5%|▍         | 23/500 [00:20<07:00,  1.14it/s]  5%|▌         | 25/500 [00:20<05:00,  1.58it/s]  5%|▌         | 27/500 [00:20<03:37,  2.17it/s]  6%|▌         | 29/500 [00:21<02:40,  2.93it/s]  6%|▌         | 31/500 [00:33<16:43,  2.14s/it]  7%|▋         | 33/500 [00:33<11:48,  1.52s/it]  7%|▋         | 35/500 [00:40<15:32,  2.01s/it]  7%|▋         | 37/500 [00:40<10:59,  1.42s/it]  8%|▊         | 39/500 [00:40<07:48,  1.02s/it]  8%|▊         | 41/500 [00:52<19:51,  2.60s/it]  9%|▊         | 43/500 [00:53<14:02,  1.84s/it]  9%|▉         | 45/500 [00:59<17:17,  2.28s/it]  9%|▉         | 47/500 [00:59<12:13,  1.62s/it] 10%|▉         | 49/500 [01:00<08:39,  1.15s/it] 10%|█         | 51/500 [01:12<20:27,  2.73s/it] 11%|█         | 53/500 [01:13<14:24,  1.93s/it] 11%|█         | 55/500 [01:19<17:03,  2.30s/it] 11%|█▏        | 57/500 [01:19<12:05,  1.64s/it] 12%|█▏        | 59/500 [01:19<08:35,  1.17s/it] 12%|█▏        | 61/500 [01:32<19:49,  2.71s/it] 13%|█▎        | 63/500 [01:32<13:59,  1.92s/it]Epoch:  1  	Training Loss: 0.11694976687431335
Test Loss:  208.64810180664062
Valid Loss:  205.87269592285156
Epoch:  2  	Training Loss: 206.95791625976562
Test Loss:  0.9892471432685852
Valid Loss:  0.9856164455413818
Epoch:  3  	Training Loss: 0.9990866184234619
Test Loss:  0.9172033071517944
Valid Loss:  0.9137066006660461
Epoch:  4  	Training Loss: 0.9263269901275635
Test Loss:  0.8504143357276917
Valid Loss:  0.8470476865768433
Epoch:  5  	Training Loss: 0.8588739633560181
Test Loss:  0.7884984016418457
Valid Loss:  0.7852580547332764
Epoch:  6  	Training Loss: 0.7963420748710632
Test Loss:  0.7311015725135803
Valid Loss:  0.727983832359314
Epoch:  7  	Training Loss: 0.7383739948272705
Test Loss:  0.6778953671455383
Valid Loss:  0.6748968362808228
Epoch:  8  	Training Loss: 0.6846378445625305
Test Loss:  0.6285748481750488
Valid Loss:  0.6256919503211975
Epoch:  9  	Training Loss: 0.6348260641098022
Test Loss:  0.5828574299812317
Valid Loss:  0.5800867080688477
Epoch:  10  	Training Loss: 0.588653028011322
Test Loss:  0.5404806137084961
Valid Loss:  0.537818968296051
Epoch:  11  	Training Loss: 0.5458539128303528
Test Loss:  0.5012011528015137
Valid Loss:  0.4986453652381897
Epoch:  12  	Training Loss: 0.5061829090118408
Test Loss:  0.471868634223938
Valid Loss:  0.4695504307746887
Epoch:  13  	Training Loss: 0.4767206907272339
Test Loss:  0.44430339336395264
Valid Loss:  0.442208468914032
Epoch:  14  	Training Loss: 0.44902923703193665
Test Loss:  0.41839706897735596
Valid Loss:  0.41651177406311035
Epoch:  15  	Training Loss: 0.42300012707710266
Test Loss:  0.39404797554016113
Valid Loss:  0.3923596143722534
Epoch:  16  	Training Loss: 0.3985317051410675
Test Loss:  0.3711608946323395
Valid Loss:  0.3696575164794922
Epoch:  17  	Training Loss: 0.37552860379219055
Test Loss:  0.34964650869369507
Valid Loss:  0.34831690788269043
Epoch:  18  	Training Loss: 0.3539014756679535
Test Loss:  0.3294210731983185
Valid Loss:  0.3282548189163208
Epoch:  19  	Training Loss: 0.3335665762424469
Test Loss:  0.3104061782360077
Valid Loss:  0.30939334630966187
Epoch:  20  	Training Loss: 0.3144453167915344
Test Loss:  0.2925281226634979
Valid Loss:  0.29165953397750854
Epoch:  21  	Training Loss: 0.2964639663696289
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  22  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  23  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  24  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  25  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  26  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  27  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  28  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  29  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  30  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  32  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  33  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  34  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  35  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  37  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  38  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  39  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  40  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  42  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  43  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  44  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  45  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  47  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  48  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  49  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  50  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  52  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  53  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  54  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  55  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  57  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  58  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  59  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  60  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  62  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  63  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  64  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  65  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
 13%|█▎        | 65/500 [01:38<16:35,  2.29s/it] 13%|█▎        | 67/500 [01:38<11:42,  1.62s/it] 14%|█▍        | 69/500 [01:38<08:18,  1.16s/it] 14%|█▍        | 71/500 [01:51<19:35,  2.74s/it] 15%|█▍        | 73/500 [01:51<13:47,  1.94s/it] 15%|█▌        | 75/500 [01:58<16:15,  2.30s/it] 15%|█▌        | 77/500 [01:58<11:28,  1.63s/it] 16%|█▌        | 79/500 [01:58<08:11,  1.17s/it] 16%|█▌        | 81/500 [02:11<18:50,  2.70s/it] 17%|█▋        | 83/500 [02:11<13:16,  1.91s/it] 17%|█▋        | 85/500 [02:17<15:49,  2.29s/it] 17%|█▋        | 87/500 [02:17<11:10,  1.62s/it] 18%|█▊        | 89/500 [02:17<07:55,  1.16s/it] 18%|█▊        | 91/500 [02:30<18:23,  2.70s/it] 19%|█▊        | 93/500 [02:30<12:57,  1.91s/it] 19%|█▉        | 95/500 [02:36<15:23,  2.28s/it] 19%|█▉        | 97/500 [02:37<10:51,  1.62s/it] 20%|█▉        | 99/500 [02:37<07:41,  1.15s/it] 20%|██        | 101/500 [02:49<18:05,  2.72s/it] 21%|██        | 103/500 [02:50<12:44,  1.93s/it] 21%|██        | 105/500 [02:56<15:05,  2.29s/it] 21%|██▏       | 107/500 [02:56<10:39,  1.63s/it] 22%|██▏       | 109/500 [02:56<07:32,  1.16s/it] 22%|██▏       | 111/500 [03:09<17:25,  2.69s/it] 23%|██▎       | 113/500 [03:09<12:15,  1.90s/it] 23%|██▎       | 115/500 [03:15<14:45,  2.30s/it] 23%|██▎       | 117/500 [03:15<10:24,  1.63s/it] 24%|██▍       | 119/500 [03:16<07:22,  1.16s/it] 24%|██▍       | 119/500 [03:26<07:22,  1.16s/it] 24%|██▍       | 121/500 [03:28<16:58,  2.69s/it] 25%|██▍       | 123/500 [03:28<11:56,  1.90s/it]**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  67  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  68  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  69  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  70  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  72  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  73  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  74  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  75  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  77  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  78  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  79  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  80  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  82  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  83  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  84  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  85  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  87  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  88  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  89  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  90  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  92  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  93  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  94  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  95  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  97  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  98  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  99  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  100  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  102  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  103  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  104  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  105  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  107  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  108  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  109  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  110  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  112  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  113  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  114  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  115  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  117  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  118  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  119  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  120  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  122  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  123  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  124  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  125  	Training Loss: 0.29374176263809204
Test Loss:  25%|██▌       | 125/500 [03:34<14:16,  2.29s/it] 25%|██▌       | 127/500 [03:35<10:04,  1.62s/it] 26%|██▌       | 129/500 [03:35<07:08,  1.15s/it] 26%|██▌       | 129/500 [03:46<07:08,  1.15s/it] 26%|██▌       | 131/500 [03:47<16:32,  2.69s/it] 27%|██▋       | 133/500 [03:47<11:38,  1.90s/it] 27%|██▋       | 135/500 [03:54<14:07,  2.32s/it] 27%|██▋       | 137/500 [03:54<09:58,  1.65s/it] 28%|██▊       | 139/500 [03:54<07:03,  1.17s/it] 28%|██▊       | 139/500 [04:06<07:03,  1.17s/it] 28%|██▊       | 141/500 [04:07<16:11,  2.71s/it] 29%|██▊       | 143/500 [04:07<11:23,  1.91s/it] 29%|██▉       | 145/500 [04:13<13:34,  2.29s/it] 29%|██▉       | 147/500 [04:14<09:34,  1.63s/it] 30%|██▉       | 149/500 [04:14<06:46,  1.16s/it] 30%|██▉       | 149/500 [04:26<06:46,  1.16s/it] 30%|███       | 151/500 [04:27<15:57,  2.74s/it] 31%|███       | 153/500 [04:27<11:13,  1.94s/it] 31%|███       | 155/500 [04:33<13:13,  2.30s/it] 31%|███▏      | 157/500 [04:33<09:20,  1.64s/it] 32%|███▏      | 159/500 [04:33<06:38,  1.17s/it] 32%|███▏      | 159/500 [04:46<06:38,  1.17s/it] 32%|███▏      | 161/500 [04:46<15:24,  2.73s/it] 33%|███▎      | 163/500 [04:46<10:51,  1.93s/it] 33%|███▎      | 165/500 [04:53<13:04,  2.34s/it] 33%|███▎      | 167/500 [04:53<09:12,  1.66s/it] 34%|███▍      | 169/500 [04:53<06:31,  1.18s/it] 34%|███▍      | 171/500 [05:06<14:48,  2.70s/it] 35%|███▍      | 173/500 [05:06<10:27,  1.92s/it] 35%|███▌      | 175/500 [05:12<12:29,  2.31s/it] 35%|███▌      | 177/500 [05:12<08:48,  1.64s/it] 36%|███▌      | 179/500 [05:12<06:13,  1.16s/it] 36%|███▌      | 181/500 [05:25<14:36,  2.75s/it] 37%|███▋      | 183/500 [05:25<10:16,  1.94s/it] 0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  127  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  128  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  129  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  130  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  132  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  133  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  134  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  135  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  137  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  138  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  139  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  140  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  142  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  143  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  144  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  145  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  147  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  148  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  149  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  150  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  152  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  153  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  154  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  155  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  157  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  158  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  159  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  160  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  162  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  163  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  164  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  165  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  167  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  168  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  169  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  170  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  172  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  173  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  174  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  175  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  177  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  178  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  179  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  180  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  182  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  183  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  184  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
 37%|███▋      | 185/500 [05:32<12:04,  2.30s/it] 37%|███▋      | 187/500 [05:32<08:30,  1.63s/it] 38%|███▊      | 189/500 [05:32<06:01,  1.16s/it] 38%|███▊      | 191/500 [05:44<13:51,  2.69s/it] 39%|███▊      | 193/500 [05:45<09:45,  1.91s/it] 39%|███▉      | 195/500 [05:51<11:43,  2.31s/it] 39%|███▉      | 197/500 [05:51<08:15,  1.64s/it] 40%|███▉      | 199/500 [05:51<05:50,  1.16s/it] 40%|████      | 201/500 [06:04<13:36,  2.73s/it] 41%|████      | 203/500 [06:04<09:34,  1.93s/it] 41%|████      | 205/500 [06:11<11:18,  2.30s/it] 41%|████▏     | 207/500 [06:11<07:57,  1.63s/it] 42%|████▏     | 209/500 [06:11<05:37,  1.16s/it] 42%|████▏     | 211/500 [06:23<12:58,  2.69s/it] 43%|████▎     | 213/500 [06:24<09:07,  1.91s/it] 43%|████▎     | 215/500 [06:30<10:56,  2.30s/it] 43%|████▎     | 217/500 [06:30<07:42,  1.64s/it] 44%|████▍     | 219/500 [06:30<05:27,  1.17s/it] 44%|████▍     | 221/500 [06:43<12:42,  2.73s/it] 45%|████▍     | 223/500 [06:43<08:57,  1.94s/it] 45%|████▌     | 225/500 [06:50<10:40,  2.33s/it] 45%|████▌     | 227/500 [06:50<07:31,  1.65s/it] 46%|████▌     | 229/500 [06:50<05:19,  1.18s/it] 46%|████▌     | 231/500 [07:03<12:31,  2.79s/it] 47%|████▋     | 233/500 [07:03<08:47,  1.98s/it] 47%|████▋     | 235/500 [07:10<10:22,  2.35s/it] 47%|████▋     | 237/500 [07:10<07:18,  1.67s/it] 48%|████▊     | 239/500 [07:10<05:10,  1.19s/it] 48%|████▊     | 241/500 [07:23<11:56,  2.77s/it]Valid Loss:  0.28896892070770264
Epoch:  185  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  187  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  188  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  189  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  190  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  192  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  193  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  194  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  195  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  197  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  198  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  199  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  200  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  202  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  203  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  204  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  205  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  207  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  208  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  209  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  210  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  212  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  213  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  214  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  215  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  217  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  218  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  219  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  220  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  222  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  223  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  224  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  225  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  227  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  228  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  229  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  230  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  232  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  233  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  234  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  235  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  237  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  238  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  239  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  240  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  242  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  243  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:   49%|████▊     | 243/500 [07:23<08:23,  1.96s/it] 49%|████▉     | 245/500 [07:30<09:57,  2.35s/it] 49%|████▉     | 247/500 [07:30<07:01,  1.66s/it] 50%|████▉     | 249/500 [07:30<04:57,  1.18s/it] 50%|█████     | 251/500 [07:43<11:24,  2.75s/it] 51%|█████     | 253/500 [07:43<08:00,  1.95s/it] 51%|█████     | 255/500 [07:49<09:28,  2.32s/it] 51%|█████▏    | 257/500 [07:49<06:40,  1.65s/it] 52%|█████▏    | 259/500 [07:49<04:42,  1.17s/it] 52%|█████▏    | 261/500 [08:02<10:48,  2.71s/it] 53%|█████▎    | 263/500 [08:02<07:35,  1.92s/it] 53%|█████▎    | 265/500 [08:09<09:09,  2.34s/it] 53%|█████▎    | 267/500 [08:09<06:27,  1.66s/it] 54%|█████▍    | 269/500 [08:09<04:35,  1.19s/it] 54%|█████▍    | 270/500 [08:15<08:00,  2.09s/it] 54%|█████▍    | 271/500 [08:22<11:12,  2.94s/it] 55%|█████▍    | 273/500 [08:22<07:09,  1.89s/it] 55%|█████▌    | 275/500 [08:28<08:43,  2.33s/it] 55%|█████▌    | 276/500 [08:28<07:03,  1.89s/it] 56%|█████▌    | 278/500 [08:29<04:34,  1.23s/it] 56%|█████▌    | 280/500 [08:35<06:54,  1.89s/it] 56%|█████▌    | 281/500 [08:41<09:59,  2.74s/it] 57%|█████▋    | 283/500 [08:41<06:26,  1.78s/it] 57%|█████▋    | 285/500 [08:47<08:02,  2.24s/it] 57%|█████▋    | 287/500 [08:48<05:26,  1.53s/it] 58%|█████▊    | 289/500 [08:48<03:45,  1.07s/it] 58%|█████▊    | 291/500 [09:00<09:20,  2.68s/it] 59%|█████▊    | 293/500 [09:00<06:28,  1.88s/it] 59%|█████▉    | 295/500 [09:07<07:42,  2.26s/it] 59%|█████▉    | 297/500 [09:07<05:23,  1.59s/it] 60%|█████▉    | 299/500 [09:07<03:47,  1.13s/it] 60%|██████    | 301/500 [09:19<08:50,  2.66s/it]0.28896892070770264
Epoch:  244  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  245  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  247  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  248  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  249  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  250  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  252  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  253  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  254  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  255  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  257  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  258  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  259  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  260  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  262  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  263  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  264  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  265  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  267  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  268  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  269  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  270  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  272  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  273  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  274  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  275  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  277  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  278  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  279  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  280  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  282  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  283  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  284  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  285  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  287  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  288  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  289  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  290  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  292  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  293  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  294  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  295  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  297  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  298  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  299  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  300  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  302  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
 61%|██████    | 303/500 [09:19<06:10,  1.88s/it] 61%|██████    | 305/500 [09:26<07:21,  2.26s/it] 61%|██████▏   | 307/500 [09:26<05:09,  1.60s/it] 62%|██████▏   | 309/500 [09:26<03:38,  1.14s/it] 62%|██████▏   | 309/500 [09:36<03:38,  1.14s/it] 62%|██████▏   | 311/500 [09:39<08:26,  2.68s/it] 63%|██████▎   | 313/500 [09:39<05:54,  1.90s/it] 63%|██████▎   | 315/500 [09:45<07:02,  2.29s/it] 63%|██████▎   | 317/500 [09:45<04:56,  1.62s/it] 64%|██████▍   | 319/500 [09:45<03:29,  1.16s/it] 64%|██████▍   | 319/500 [09:56<03:29,  1.16s/it] 64%|██████▍   | 321/500 [09:58<08:02,  2.70s/it] 65%|██████▍   | 323/500 [09:58<05:38,  1.91s/it] 65%|██████▌   | 325/500 [10:04<06:39,  2.28s/it] 65%|██████▌   | 327/500 [10:05<04:40,  1.62s/it] 66%|██████▌   | 329/500 [10:05<03:17,  1.15s/it] 66%|██████▌   | 329/500 [10:16<03:17,  1.15s/it] 66%|██████▌   | 331/500 [10:17<07:37,  2.71s/it] 67%|██████▋   | 333/500 [10:17<05:19,  1.92s/it] 67%|██████▋   | 335/500 [10:24<06:19,  2.30s/it] 67%|██████▋   | 337/500 [10:24<04:27,  1.64s/it] 68%|██████▊   | 339/500 [10:24<03:07,  1.17s/it] 68%|██████▊   | 339/500 [10:36<03:07,  1.17s/it] 68%|██████▊   | 341/500 [10:37<07:12,  2.72s/it] 69%|██████▊   | 343/500 [10:37<05:02,  1.92s/it] 69%|██████▉   | 345/500 [10:43<05:59,  2.32s/it] 69%|██████▉   | 347/500 [10:44<04:11,  1.65s/it] 70%|██████▉   | 349/500 [10:44<02:56,  1.17s/it] 70%|██████▉   | 349/500 [10:56<02:56,  1.17s/it] 70%|███████   | 351/500 [10:56<06:44,  2.71s/it] 71%|███████   | 353/500 [10:57<04:42,  1.92s/it] 71%|███████   | 355/500 [11:03<05:33,  2.30s/it] 71%|███████▏  | 357/500 [11:03<03:53,  1.63s/it] 72%|███████▏  | 359/500 [11:03<02:43,  1.16s/it] 72%|███████▏  | 361/500 [11:16<06:14,  2.70s/it]Epoch:  303  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  304  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  305  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  307  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  308  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  309  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  310  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  312  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  313  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  314  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  315  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  317  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  318  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  319  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  320  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  322  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  323  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  324  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  325  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  327  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  328  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  329  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  330  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  332  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  333  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  334  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  335  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  337  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  338  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  339  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  340  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  342  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  343  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  344  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  345  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  347  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  348  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  349  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  350  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  352  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  353  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  354  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  355  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  357  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  358  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  359  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  360  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896889090538025
 73%|███████▎  | 363/500 [11:16<04:21,  1.91s/it] 73%|███████▎  | 365/500 [11:22<05:08,  2.29s/it] 73%|███████▎  | 367/500 [11:22<03:35,  1.62s/it] 74%|███████▍  | 369/500 [11:22<02:31,  1.15s/it] 74%|███████▍  | 371/500 [11:35<05:52,  2.73s/it] 75%|███████▍  | 373/500 [11:35<04:05,  1.94s/it] 75%|███████▌  | 375/500 [11:42<04:49,  2.31s/it] 75%|███████▌  | 377/500 [11:42<03:21,  1.64s/it] 76%|███████▌  | 379/500 [11:42<02:21,  1.17s/it] 76%|███████▌  | 381/500 [11:55<05:22,  2.71s/it] 77%|███████▋  | 383/500 [11:55<03:44,  1.92s/it] 77%|███████▋  | 385/500 [12:01<04:22,  2.28s/it] 77%|███████▋  | 387/500 [12:01<03:02,  1.62s/it] 78%|███████▊  | 389/500 [12:01<02:07,  1.15s/it] 78%|███████▊  | 391/500 [12:14<04:51,  2.67s/it] 79%|███████▊  | 393/500 [12:14<03:22,  1.90s/it] 79%|███████▉  | 395/500 [12:20<04:00,  2.29s/it] 79%|███████▉  | 397/500 [12:21<02:47,  1.62s/it] 80%|███████▉  | 399/500 [12:21<01:56,  1.16s/it] 80%|████████  | 401/500 [12:33<04:28,  2.71s/it] 81%|████████  | 403/500 [12:34<03:06,  1.92s/it] 81%|████████  | 405/500 [12:40<03:37,  2.29s/it] 81%|████████▏ | 407/500 [12:40<02:31,  1.63s/it] 82%|████████▏ | 409/500 [12:40<01:45,  1.16s/it] 82%|████████▏ | 411/500 [12:53<03:58,  2.68s/it] 83%|████████▎ | 413/500 [12:53<02:45,  1.90s/it] 83%|████████▎ | 415/500 [12:59<03:12,  2.26s/it] 83%|████████▎ | 417/500 [12:59<02:13,  1.61s/it] 84%|████████▍ | 419/500 [12:59<01:32,  1.14s/it]Epoch:  362  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  363  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  364  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  365  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  367  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  368  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  369  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  370  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  372  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  373  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  374  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  375  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  377  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  378  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  379  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  380  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  382  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  383  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  384  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  385  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  387  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  388  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  389  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  390  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  392  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  393  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  394  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  395  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  397  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  398  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  399  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  400  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  402  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  403  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  404  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  405  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  407  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  408  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  409  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  410  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  412  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  413  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  414  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  415  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  417  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  418  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  419  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  420  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
 84%|████████▍ | 421/500 [13:12<03:33,  2.70s/it] 85%|████████▍ | 423/500 [13:12<02:27,  1.92s/it] 85%|████████▌ | 425/500 [13:18<02:52,  2.29s/it] 85%|████████▌ | 427/500 [13:19<01:58,  1.63s/it] 86%|████████▌ | 429/500 [13:19<01:22,  1.16s/it] 86%|████████▌ | 431/500 [13:31<03:06,  2.71s/it] 87%|████████▋ | 433/500 [13:32<02:08,  1.92s/it] 87%|████████▋ | 435/500 [13:38<02:28,  2.28s/it] 87%|████████▋ | 437/500 [13:38<01:42,  1.62s/it] 88%|████████▊ | 439/500 [13:38<01:10,  1.16s/it] 88%|████████▊ | 441/500 [13:51<02:37,  2.67s/it] 89%|████████▊ | 443/500 [13:51<01:47,  1.89s/it] 89%|████████▉ | 445/500 [13:57<02:05,  2.28s/it] 89%|████████▉ | 447/500 [13:57<01:25,  1.62s/it] 90%|████████▉ | 449/500 [13:57<00:58,  1.15s/it] 90%|█████████ | 451/500 [14:10<02:11,  2.68s/it] 91%|█████████ | 453/500 [14:10<01:29,  1.90s/it] 91%|█████████ | 455/500 [14:16<01:43,  2.29s/it] 91%|█████████▏| 457/500 [14:17<01:09,  1.62s/it] 92%|█████████▏| 459/500 [14:17<00:47,  1.16s/it] 92%|█████████▏| 461/500 [14:29<01:45,  2.71s/it] 93%|█████████▎| 463/500 [14:29<01:10,  1.92s/it] 93%|█████████▎| 465/500 [14:36<01:20,  2.30s/it] 93%|█████████▎| 467/500 [14:36<00:53,  1.63s/it] 94%|█████████▍| 469/500 [14:36<00:36,  1.16s/it] 94%|█████████▍| 469/500 [14:46<00:36,  1.16s/it] 94%|█████████▍| 471/500 [14:48<01:17,  2.67s/it] 95%|█████████▍| 473/500 [14:49<00:50,  1.89s/it] 95%|█████████▌| 475/500 [14:55<00:56,  2.26s/it] 95%|█████████▌| 477/500 [14:55<00:36,  1.60s/it] 96%|█████████▌| 479/500 [14:55<00:23,  1.14s/it]Epoch:  421  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  422  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  423  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  424  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  425  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  427  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  428  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  429  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  430  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  432  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  433  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  434  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  435  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  437  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  438  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  439  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  440  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  442  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  443  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  444  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  445  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  447  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  448  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  449  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  450  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  452  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  453  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  454  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  455  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  457  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  458  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  459  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  460  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  462  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  463  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  464  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  465  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  467  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  468  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  469  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  470  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  472  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  473  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  474  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  475  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  477  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  478  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  479  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  480  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
 96%|█████████▌| 479/500 [15:06<00:23,  1.14s/it] 96%|█████████▌| 481/500 [15:08<00:51,  2.72s/it] 97%|█████████▋| 483/500 [15:08<00:32,  1.93s/it] 97%|█████████▋| 485/500 [15:14<00:34,  2.30s/it] 97%|█████████▋| 487/500 [15:15<00:21,  1.63s/it] 98%|█████████▊| 489/500 [15:15<00:12,  1.16s/it] 98%|█████████▊| 489/500 [15:26<00:12,  1.16s/it] 98%|█████████▊| 491/500 [15:27<00:24,  2.70s/it] 99%|█████████▊| 493/500 [15:27<00:13,  1.91s/it] 99%|█████████▉| 495/500 [15:34<00:11,  2.28s/it] 99%|█████████▉| 497/500 [15:34<00:04,  1.61s/it]100%|█████████▉| 499/500 [15:34<00:01,  1.15s/it]100%|██████████| 500/500 [15:40<00:00,  1.88s/it]
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  482  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  483  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  484  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  485  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  487  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  488  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  489  	Training Loss: 0.29374173283576965
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  490  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.29374173283576965
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  492  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  493  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  494  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896889090538025
Epoch:  495  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  497  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  498  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
Epoch:  499  	Training Loss: 0.29374176263809204
Test Loss:  0.28986021876335144
Valid Loss:  0.28896892070770264
Epoch:  500  	Training Loss: 0.29374176263809204
Test Loss:  0.28986018896102905
Valid Loss:  0.28896892070770264
**************************************************learning rate decay**************************************************
seed is  3
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:38,  6.21s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.09it/s]  3%|▎         | 15/500 [00:19<13:17,  1.64s/it]  3%|▎         | 17/500 [00:19<09:14,  1.15s/it]  4%|▍         | 19/500 [00:19<06:30,  1.23it/s]  4%|▍         | 21/500 [00:26<12:09,  1.52s/it]  5%|▍         | 23/500 [00:26<08:35,  1.08s/it]  5%|▌         | 25/500 [00:32<13:28,  1.70s/it]  5%|▌         | 27/500 [00:32<09:31,  1.21s/it]  6%|▌         | 29/500 [00:32<06:46,  1.16it/s]  6%|▌         | 31/500 [00:45<19:21,  2.48s/it]  7%|▋         | 33/500 [00:45<13:38,  1.75s/it]  7%|▋         | 35/500 [00:45<09:39,  1.25s/it]  7%|▋         | 37/500 [00:45<06:53,  1.12it/s]  8%|▊         | 39/500 [00:45<04:56,  1.55it/s]  8%|▊         | 41/500 [00:58<17:42,  2.32s/it]  9%|▊         | 43/500 [00:58<12:29,  1.64s/it]  9%|▉         | 45/500 [00:58<08:51,  1.17s/it]  9%|▉         | 47/500 [00:58<06:19,  1.19it/s] 10%|▉         | 49/500 [00:58<04:35,  1.64it/s] 10%|█         | 51/500 [01:05<10:14,  1.37s/it] 11%|█         | 53/500 [01:05<07:17,  1.02it/s] 11%|█         | 55/500 [01:05<05:14,  1.41it/s] 11%|█▏        | 57/500 [01:05<03:48,  1.94it/s] 12%|█▏        | 59/500 [01:05<02:48,  2.62it/s] 12%|█▏        | 61/500 [01:11<08:50,  1.21s/it] 13%|█▎        | 63/500 [01:11<06:18,  1.16it/s] 13%|█▎        | 65/500 [01:12<04:32,  1.60it/s] 13%|█▎        | 67/500 [01:12<03:18,  2.18it/s]Epoch:  1  	Training Loss: 0.11694976687431335
Test Loss:  19.230144500732422
Valid Loss:  19.08190155029297
Epoch:  2  	Training Loss: 19.18641471862793
Test Loss:  0.30904293060302734
Valid Loss:  0.28875821828842163
Epoch:  3  	Training Loss: 0.2931097745895386
Test Loss:  0.07066074013710022
Valid Loss:  0.08983147144317627
Epoch:  4  	Training Loss: 0.08459588885307312
Test Loss:  0.06511588394641876
Valid Loss:  0.08730410039424896
Epoch:  5  	Training Loss: 0.08143071830272675
Test Loss:  0.06393517553806305
Valid Loss:  0.08699431270360947
Epoch:  6  	Training Loss: 0.08095098286867142
Test Loss:  0.06354837119579315
Valid Loss:  0.08701014518737793
Epoch:  7  	Training Loss: 0.08087259531021118
Test Loss:  0.0633782371878624
Valid Loss:  0.08701559901237488
Epoch:  8  	Training Loss: 0.08084622025489807
Test Loss:  0.06331213563680649
Valid Loss:  0.08699913322925568
Epoch:  9  	Training Loss: 0.08082596212625504
Test Loss:  0.06327162683010101
Valid Loss:  0.0869763195514679
Epoch:  10  	Training Loss: 0.08080658316612244
Test Loss:  0.06323573738336563
Valid Loss:  0.08695267140865326
Epoch:  11  	Training Loss: 0.08078749477863312
Test Loss:  0.06321290880441666
Valid Loss:  0.08692507445812225
Epoch:  12  	Training Loss: 0.08076846599578857
Test Loss:  0.06444457173347473
Valid Loss:  0.08703132718801498
Epoch:  13  	Training Loss: 0.08095564693212509
Test Loss:  0.06235891953110695
Valid Loss:  0.09177489578723907
Epoch:  14  	Training Loss: 0.08437475562095642
Test Loss:  0.0804273933172226
Valid Loss:  0.09698621928691864
Epoch:  15  	Training Loss: 0.09198375046253204
Test Loss:  0.0619102418422699
Valid Loss:  0.09130042791366577
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.08414770662784576
Test Loss:  0.09918463230133057
Valid Loss:  0.10617482662200928
Epoch:  17  	Training Loss: 0.10396554321050644
Test Loss:  0.09206963330507278
Valid Loss:  0.13442887365818024
Epoch:  18  	Training Loss: 0.12386216968297958
Test Loss:  0.07965506613254547
Valid Loss:  0.09342639148235321
Epoch:  19  	Training Loss: 0.08990718424320221
Test Loss:  0.06209498643875122
Valid Loss:  0.08928953111171722
Epoch:  20  	Training Loss: 0.08264146000146866
Test Loss:  0.06487416476011276
Valid Loss:  0.08644384145736694
Epoch:  21  	Training Loss: 0.08113469183444977
Test Loss:  0.06291458755731583
Valid Loss:  0.08677636086940765
Epoch:  22  	Training Loss: 0.08091741800308228
Test Loss:  0.06654803454875946
Valid Loss:  0.08706213533878326
Epoch:  23  	Training Loss: 0.08184856176376343
Test Loss:  0.06227598711848259
Valid Loss:  0.09067600220441818
Epoch:  24  	Training Loss: 0.08360810577869415
Test Loss:  0.08117032051086426
Valid Loss:  0.09486894309520721
Epoch:  25  	Training Loss: 0.09108386188745499
Test Loss:  0.08075252920389175
Valid Loss:  0.11989478766918182
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.11019892245531082
Test Loss:  0.18301214277744293
Valid Loss:  0.17357788980007172
Epoch:  27  	Training Loss: 0.17442500591278076
Test Loss:  0.21430759131908417
Valid Loss:  0.274334192276001
Epoch:  28  	Training Loss: 0.25792643427848816
Test Loss:  0.35429054498672485
Valid Loss:  0.3211943805217743
Epoch:  29  	Training Loss: 0.32623225450515747
Test Loss:  0.236033096909523
Valid Loss:  0.29807478189468384
Epoch:  30  	Training Loss: 0.28092971444129944
Test Loss:  0.3461998701095581
Valid Loss:  0.31128665804862976
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.32011285424232483
Test Loss:  0.13677716255187988
Valid Loss:  0.14011791348457336
Epoch:  32  	Training Loss: 0.1397223025560379
Test Loss:  0.08742241561412811
Valid Loss:  0.1097046285867691
Epoch:  33  	Training Loss: 0.10457338392734528
Test Loss:  0.0831093043088913
Valid Loss:  0.10913357883691788
Epoch:  34  	Training Loss: 0.10309501737356186
Test Loss:  0.08225779980421066
Valid Loss:  0.10916325449943542
Epoch:  35  	Training Loss: 0.1028747409582138
Test Loss:  0.08190221339464188
Valid Loss:  0.10902862250804901
Epoch:  36  	Training Loss: 0.1026679277420044
Test Loss:  0.08179250359535217
Valid Loss:  0.10891720652580261
Epoch:  37  	Training Loss: 0.10256116092205048
Test Loss:  0.08165188878774643
Valid Loss:  0.10900698602199554
Epoch:  38  	Training Loss: 0.10258027911186218
Test Loss:  0.08169888705015182
Valid Loss:  0.10888881981372833
Epoch:  39  	Training Loss: 0.1025078296661377
Test Loss:  0.08160857111215591
Valid Loss:  0.10900065302848816
Epoch:  40  	Training Loss: 0.1025562733411789
Test Loss:  0.08162982761859894
Valid Loss:  0.10883180797100067
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.10243509709835052
Test Loss:  0.07858186215162277
Valid Loss:  0.10448625683784485
Epoch:  42  	Training Loss: 0.09875147044658661
Test Loss:  0.07851319015026093
Valid Loss:  0.10445382446050644
Epoch:  43  	Training Loss: 0.09867456555366516
Test Loss:  0.07847954332828522
Valid Loss:  0.1044444590806961
Epoch:  44  	Training Loss: 0.09865488111972809
Test Loss:  0.07844866812229156
Valid Loss:  0.10444071143865585
Epoch:  45  	Training Loss: 0.09863872826099396
Test Loss:  0.07842008769512177
Valid Loss:  0.10444013774394989
Epoch:  46  	Training Loss: 0.09862450510263443
Test Loss:  0.07839488983154297
Valid Loss:  0.10443944483995438
Epoch:  47  	Training Loss: 0.09861116111278534
Test Loss:  0.07837198674678802
Valid Loss:  0.10443858057260513
Epoch:  48  	Training Loss: 0.09859880059957504
Test Loss:  0.07835016399621964
Valid Loss:  0.1044381782412529
Epoch:  49  	Training Loss: 0.0985885038971901
Test Loss:  0.07833006232976913
Valid Loss:  0.10443761944770813
Epoch:  50  	Training Loss: 0.09857931733131409
Test Loss:  0.07831089198589325
Valid Loss:  0.1044372022151947
Epoch:  51  	Training Loss: 0.09857060760259628
Test Loss:  0.07829324901103973
Valid Loss:  0.10443652421236038
Epoch:  52  	Training Loss: 0.09856237471103668
Test Loss:  0.07707592099905014
Valid Loss:  0.10278867930173874
Epoch:  53  	Training Loss: 0.0971403419971466
Test Loss:  0.07582907378673553
Valid Loss:  0.10115925222635269
Epoch:  54  	Training Loss: 0.09574747085571289
Test Loss:  0.07456792891025543
Valid Loss:  0.0995546206831932
Epoch:  55  	Training Loss: 0.09437009692192078
Test Loss:  0.07329195737838745
Valid Loss:  0.09796904027462006
Epoch:  56  	Training Loss: 0.09297985583543777
Test Loss:  0.07203616201877594
Valid Loss:  0.09643106907606125
Epoch:  57  	Training Loss: 0.09161853045225143
Test Loss:  0.07079104334115982
Valid Loss:  0.09487580507993698
Epoch:  58  	Training Loss: 0.09026500582695007
Test Loss:  0.06954850256443024
Valid Loss:  0.09330011904239655
Epoch:  59  	Training Loss: 0.08890022337436676
Test Loss:  0.06833502650260925
Valid Loss:  0.09172259271144867
Epoch:  60  	Training Loss: 0.0875672996044159
Test Loss:  0.06713845580816269
Valid Loss:  0.0901617705821991
Epoch:  61  	Training Loss: 0.08624371141195297
Test Loss:  0.06596416234970093
Valid Loss:  0.08863215148448944
Epoch:  62  	Training Loss: 0.08493828028440475
Test Loss:  0.06400984525680542
Valid Loss:  0.08734862506389618
Epoch:  63  	Training Loss: 0.08352889120578766
Test Loss:  0.06313808262348175
Valid Loss:  0.08589284121990204
Epoch:  64  	Training Loss: 0.0823579654097557
Test Loss:  0.062190406024456024
Valid Loss:  0.08452558517456055
Epoch:  65  	Training Loss: 0.08122199773788452
Test Loss:  0.061221785843372345
Valid Loss:  0.08319393545389175
Epoch:  66  	Training Loss: 0.08009742200374603
Test Loss:  0.060256436467170715
Valid Loss:  0.0818866491317749
Epoch:  67  	Training Loss: 0.07898063212633133
Test Loss:  0.059310831129550934
Valid Loss:  0.08061212301254272
Epoch:  68  	Training Loss: 0.07789003849029541
Test Loss:  0.05837872624397278
Valid Loss:  0.07935548573732376
Epoch:  69  	Training Loss: 0.07680481672286987
Test Loss:   14%|█▍        | 69/500 [01:12<02:26,  2.94it/s] 14%|█▍        | 71/500 [01:18<08:29,  1.19s/it] 15%|█▍        | 73/500 [01:18<06:04,  1.17it/s] 15%|█▌        | 75/500 [01:19<04:22,  1.62it/s] 15%|█▌        | 77/500 [01:19<03:10,  2.22it/s] 16%|█▌        | 79/500 [01:19<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:25<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:25<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:25<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:26<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:26<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:32<08:00,  1.18s/it] 19%|█▊        | 93/500 [01:32<05:43,  1.19it/s] 19%|█▉        | 95/500 [01:32<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:32<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:32<02:13,  3.00it/s] 20%|██        | 101/500 [01:39<07:49,  1.18s/it] 21%|██        | 103/500 [01:39<05:34,  1.19it/s] 21%|██        | 105/500 [01:39<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:39<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:39<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:46<07:42,  1.19s/it] 23%|██▎       | 113/500 [01:46<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:46<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:46<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:46<02:08,  2.98it/s] 24%|██▍       | 121/500 [01:52<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:53<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:53<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:53<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:53<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:59<07:14,  1.18s/it] 27%|██▋       | 133/500 [01:59<05:10,  1.18it/s] 27%|██▋       | 135/500 [02:00<03:43,  1.64it/s] 27%|██▋       | 137/500 [02:00<02:42,  2.23it/s] 28%|██▊       | 139/500 [02:00<02:00,  3.01it/s]0.057461805641651154
Valid Loss:  0.07811511307954788
Epoch:  70  	Training Loss: 0.07572382688522339
Test Loss:  0.05656835809350014
Valid Loss:  0.07690201699733734
Epoch:  71  	Training Loss: 0.07466335594654083
Test Loss:  0.055689021944999695
Valid Loss:  0.07570382207632065
Epoch:  72  	Training Loss: 0.07360897958278656
Test Loss:  0.05462266132235527
Valid Loss:  0.07442149519920349
Epoch:  73  	Training Loss: 0.07242348790168762
Test Loss:  0.053726062178611755
Valid Loss:  0.07328741252422333
Epoch:  74  	Training Loss: 0.07137929648160934
Test Loss:  0.052843086421489716
Valid Loss:  0.07216312736272812
Epoch:  75  	Training Loss: 0.070307157933712
Test Loss:  0.05191493034362793
Valid Loss:  0.07088319212198257
Epoch:  76  	Training Loss: 0.06904054433107376
Test Loss:  0.05091172084212303
Valid Loss:  0.06928230822086334
Epoch:  77  	Training Loss: 0.0675661563873291
Test Loss:  0.04975792020559311
Valid Loss:  0.0673968642950058
Epoch:  78  	Training Loss: 0.06605677306652069
Test Loss:  0.048576973378658295
Valid Loss:  0.06551312655210495
Epoch:  79  	Training Loss: 0.06446433067321777
Test Loss:  0.04725366830825806
Valid Loss:  0.06351946294307709
Epoch:  80  	Training Loss: 0.06270204484462738
Test Loss:  0.04593078792095184
Valid Loss:  0.061568569391965866
Epoch:  81  	Training Loss: 0.060992635786533356
Test Loss:  0.044674865901470184
Valid Loss:  0.05974189192056656
Epoch:  82  	Training Loss: 0.05940885841846466
Test Loss:  0.04415760934352875
Valid Loss:  0.05887511372566223
Epoch:  83  	Training Loss: 0.05864677578210831
Test Loss:  0.0436260923743248
Valid Loss:  0.05803569406270981
Epoch:  84  	Training Loss: 0.057902611792087555
Test Loss:  0.043093107640743256
Valid Loss:  0.05723065137863159
Epoch:  85  	Training Loss: 0.0571783110499382
Test Loss:  0.04256347194314003
Valid Loss:  0.05644577369093895
Epoch:  86  	Training Loss: 0.05646843463182449
Test Loss:  0.042047031223773956
Valid Loss:  0.055681996047496796
Epoch:  87  	Training Loss: 0.05577497556805611
Test Loss:  0.041549041867256165
Valid Loss:  0.054927341639995575
Epoch:  88  	Training Loss: 0.05508905276656151
Test Loss:  0.041051268577575684
Valid Loss:  0.05418775975704193
Epoch:  89  	Training Loss: 0.054414935410022736
Test Loss:  0.04055812954902649
Valid Loss:  0.053462132811546326
Epoch:  90  	Training Loss: 0.05375237762928009
Test Loss:  0.04007060080766678
Valid Loss:  0.05274977162480354
Epoch:  91  	Training Loss: 0.05310109630227089
Test Loss:  0.03960922732949257
Valid Loss:  0.052050065249204636
Epoch:  92  	Training Loss: 0.0524597130715847
Test Loss:  0.03882945328950882
Valid Loss:  0.051023293286561966
Epoch:  93  	Training Loss: 0.051532767713069916
Test Loss:  0.03807229921221733
Valid Loss:  0.050035301595926285
Epoch:  94  	Training Loss: 0.05063449591398239
Test Loss:  0.037355825304985046
Valid Loss:  0.049070969223976135
Epoch:  95  	Training Loss: 0.04975667595863342
Test Loss:  0.0366649255156517
Valid Loss:  0.04812217131257057
Epoch:  96  	Training Loss: 0.0488925464451313
Test Loss:  0.03600086271762848
Valid Loss:  0.04719911515712738
Epoch:  97  	Training Loss: 0.04805196821689606
Test Loss:  0.035360705107450485
Valid Loss:  0.04630156606435776
Epoch:  98  	Training Loss: 0.04723421484231949
Test Loss:  0.034742288291454315
Valid Loss:  0.04542902484536171
Epoch:  99  	Training Loss: 0.04643857851624489
Test Loss:  0.03414290398359299
Valid Loss:  0.04458247497677803
Epoch:  100  	Training Loss: 0.045663539320230484
Test Loss:  0.033558931201696396
Valid Loss:  0.04375172778964043
Epoch:  101  	Training Loss: 0.044889338314533234
Test Loss:  0.032990962266922
Valid Loss:  0.04293564707040787
Epoch:  102  	Training Loss: 0.04412754997611046
Test Loss:  0.032583560794591904
Valid Loss:  0.04218175634741783
Epoch:  103  	Training Loss: 0.043458230793476105
Test Loss:  0.03217499703168869
Valid Loss:  0.04145780950784683
Epoch:  104  	Training Loss: 0.04281158000230789
Test Loss:  0.031770117580890656
Valid Loss:  0.040762074291706085
Epoch:  105  	Training Loss: 0.0421864278614521
Test Loss:  0.031377505511045456
Valid Loss:  0.0400930717587471
Epoch:  106  	Training Loss: 0.041581686586141586
Test Loss:  0.03099653869867325
Valid Loss:  0.03943170979619026
Epoch:  107  	Training Loss: 0.04099632054567337
Test Loss:  0.030626922845840454
Valid Loss:  0.0387858971953392
Epoch:  108  	Training Loss: 0.040429383516311646
Test Loss:  0.030268147587776184
Valid Loss:  0.03816138952970505
Epoch:  109  	Training Loss: 0.039880067110061646
Test Loss:  0.029919862747192383
Valid Loss:  0.0375572070479393
Epoch:  110  	Training Loss: 0.039347611367702484
Test Loss:  0.02958168089389801
Valid Loss:  0.03697235882282257
Epoch:  111  	Training Loss: 0.03882833570241928
Test Loss:  0.02924990840256214
Valid Loss:  0.036384373903274536
Epoch:  112  	Training Loss: 0.038315825164318085
Test Loss:  0.028494369238615036
Valid Loss:  0.03538136184215546
Epoch:  113  	Training Loss: 0.03740072250366211
Test Loss:  0.0277769286185503
Valid Loss:  0.03445250540971756
Epoch:  114  	Training Loss: 0.036540884524583817
Test Loss:  0.027103964239358902
Valid Loss:  0.03359740972518921
Epoch:  115  	Training Loss: 0.035741209983825684
Test Loss:  0.026465337723493576
Valid Loss:  0.03278917819261551
Epoch:  116  	Training Loss: 0.034979552030563354
Test Loss:  0.025851011276245117
Valid Loss:  0.03201228752732277
Epoch:  117  	Training Loss: 0.034248050302267075
Test Loss:  0.02525613270699978
Valid Loss:  0.031263403594493866
Epoch:  118  	Training Loss: 0.033545829355716705
Test Loss:  0.024682998657226562
Valid Loss:  0.030551662668585777
Epoch:  119  	Training Loss: 0.03288017213344574
Test Loss:  0.02413981407880783
Valid Loss:  0.029881551861763
Epoch:  120  	Training Loss: 0.0322425551712513
Test Loss:  0.02361990697681904
Valid Loss:  0.02925863303244114
Epoch:  121  	Training Loss: 0.031637147068977356
Test Loss:  0.023117145523428917
Valid Loss:  0.0286529753357172
Epoch:  122  	Training Loss: 0.031048400327563286
Test Loss:  0.02281055599451065
Valid Loss:  0.028149310499429703
Epoch:  123  	Training Loss: 0.0306005347520113
Test Loss:  0.02252228930592537
Valid Loss:  0.027658823877573013
Epoch:  124  	Training Loss: 0.030161801725625992
Test Loss:  0.022245602682232857
Valid Loss:  0.02718469128012657
Epoch:  125  	Training Loss: 0.029736217111349106
Test Loss:  0.021962005645036697
Valid Loss:  0.026724087074398994
Epoch:  126  	Training Loss: 0.02932196483016014
Test Loss:  0.021679498255252838
Valid Loss:  0.026277439668774605
Epoch:  127  	Training Loss: 0.028917944058775902
Test Loss:  0.02140570431947708
Valid Loss:  0.025839440524578094
Epoch:  128  	Training Loss: 0.028524909168481827
Test Loss:  0.021137623116374016
Valid Loss:  0.025411024689674377
Epoch:  129  	Training Loss: 0.028141211718320847
Test Loss:  0.02087339758872986
Valid Loss:  0.02499280497431755
Epoch:  130  	Training Loss: 0.027766387909650803
Test Loss:  0.02061738818883896
Valid Loss:  0.02458229474723339
Epoch:  131  	Training Loss: 0.027400188148021698
Test Loss:  0.02036561258137226
Valid Loss:  0.0241809394210577
Epoch:  132  	Training Loss: 0.02704208344221115
Test Loss:  0.020225059241056442
Valid Loss:  0.02401675656437874
Epoch:  133  	Training Loss: 0.026865489780902863
Test Loss:  0.020083468407392502
Valid Loss:  0.02387261390686035
Epoch:  134  	Training Loss: 0.02670622617006302
Test Loss:  0.019937116652727127
Valid Loss:  0.023743266239762306
Epoch:  135  	Training Loss: 0.026560023427009583
Test Loss:  0.019788840785622597
Valid Loss:  0.023625005036592484
Epoch:  136  	Training Loss: 0.02642296999692917
Test Loss:  0.019646214321255684
Valid Loss:  0.023514049127697945
Epoch:  137  	Training Loss: 0.026296526193618774
Test Loss:  0.01951022632420063
Valid Loss:  0.023411227390170097
Epoch:  138  	Training Loss: 0.02617831900715828
Test Loss:  0.019380906596779823
Valid Loss:  0.02331436425447464
Epoch:  139  	Training Loss: 0.026064125820994377
Test Loss:  0.01925837993621826
Valid Loss:  0.023225437849760056
Epoch:  140  	Training Loss: 0.02595784142613411
Test Loss:  0.0191425122320652
Valid Loss:  0.023143477737903595
 28%|██▊       | 141/500 [02:06<07:00,  1.17s/it] 29%|██▊       | 143/500 [02:06<05:00,  1.19it/s] 29%|██▉       | 145/500 [02:06<03:36,  1.64it/s] 29%|██▉       | 147/500 [02:06<02:37,  2.24it/s] 30%|██▉       | 149/500 [02:07<01:56,  3.01it/s] 30%|███       | 151/500 [02:13<06:50,  1.18s/it] 31%|███       | 153/500 [02:13<04:53,  1.18it/s] 31%|███       | 155/500 [02:13<03:30,  1.64it/s] 31%|███▏      | 157/500 [02:13<02:33,  2.24it/s] 32%|███▏      | 159/500 [02:13<01:53,  3.00it/s] 32%|███▏      | 161/500 [02:20<06:42,  1.19s/it] 33%|███▎      | 163/500 [02:20<04:46,  1.18it/s] 33%|███▎      | 165/500 [02:20<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:20<02:29,  2.22it/s] 34%|███▍      | 169/500 [02:20<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:27<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:27<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:27<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:27<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:27<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:33<06:11,  1.16s/it] 37%|███▋      | 183/500 [02:33<04:24,  1.20it/s] 37%|███▋      | 185/500 [02:34<03:09,  1.66it/s] 37%|███▋      | 187/500 [02:34<02:18,  2.26it/s] 38%|███▊      | 189/500 [02:34<01:42,  3.04it/s] 38%|███▊      | 191/500 [02:40<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:40<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:40<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:41<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:41<01:39,  3.01it/s] 40%|████      | 201/500 [02:47<05:57,  1.19s/it] 41%|████      | 203/500 [02:47<04:14,  1.17it/s] 41%|████      | 205/500 [02:47<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:48<02:15,  2.16it/s] 42%|████▏     | 209/500 [02:48<01:39,  2.92it/s]Epoch:  141  	Training Loss: 0.0258584376424551
Test Loss:  0.01903289556503296
Valid Loss:  0.023066354915499687
Epoch:  142  	Training Loss: 0.025763582438230515
Test Loss:  0.018526853993535042
Valid Loss:  0.022359363734722137
Epoch:  143  	Training Loss: 0.02512453868985176
Test Loss:  0.01804398000240326
Valid Loss:  0.021677903831005096
Epoch:  144  	Training Loss: 0.024508217349648476
Test Loss:  0.017573758959770203
Valid Loss:  0.021014299243688583
Epoch:  145  	Training Loss: 0.02391079254448414
Test Loss:  0.017121246084570885
Valid Loss:  0.02037418633699417
Epoch:  146  	Training Loss: 0.023336250334978104
Test Loss:  0.016687901690602303
Valid Loss:  0.019756363704800606
Epoch:  147  	Training Loss: 0.02278205007314682
Test Loss:  0.01627233251929283
Valid Loss:  0.019157633185386658
Epoch:  148  	Training Loss: 0.022246209904551506
Test Loss:  0.015871573239564896
Valid Loss:  0.018575958907604218
Epoch:  149  	Training Loss: 0.02172168530523777
Test Loss:  0.015480035915970802
Valid Loss:  0.018015539273619652
Epoch:  150  	Training Loss: 0.021213877946138382
Test Loss:  0.015097396448254585
Valid Loss:  0.017474183812737465
Epoch:  151  	Training Loss: 0.020721953362226486
Test Loss:  0.014728257432579994
Valid Loss:  0.01695273257791996
Epoch:  152  	Training Loss: 0.020246721804142
Test Loss:  0.014633525162935257
Valid Loss:  0.01693744584918022
Epoch:  153  	Training Loss: 0.02020719088613987
Test Loss:  0.014560474082827568
Valid Loss:  0.016929851844906807
Epoch:  154  	Training Loss: 0.020176265388727188
Test Loss:  0.014503682032227516
Valid Loss:  0.016927169635891914
Epoch:  155  	Training Loss: 0.02015095204114914
Test Loss:  0.014460781589150429
Valid Loss:  0.016924181953072548
Epoch:  156  	Training Loss: 0.020131537690758705
Test Loss:  0.014429210685193539
Valid Loss:  0.01692059077322483
Epoch:  157  	Training Loss: 0.02011643722653389
Test Loss:  0.014405254274606705
Valid Loss:  0.016916554421186447
Epoch:  158  	Training Loss: 0.020103830844163895
Test Loss:  0.014384707435965538
Valid Loss:  0.016912147402763367
Epoch:  159  	Training Loss: 0.02009228989481926
Test Loss:  0.014367463067173958
Valid Loss:  0.016907483339309692
Epoch:  160  	Training Loss: 0.020081643015146255
Test Loss:  0.01435232162475586
Valid Loss:  0.016902701929211617
Epoch:  161  	Training Loss: 0.020071549341082573
Test Loss:  0.014338863082230091
Valid Loss:  0.016898028552532196
Epoch:  162  	Training Loss: 0.02006206475198269
Test Loss:  0.014223916456103325
Valid Loss:  0.016737155616283417
Epoch:  163  	Training Loss: 0.01991293951869011
Test Loss:  0.014107180759310722
Valid Loss:  0.01658688858151436
Epoch:  164  	Training Loss: 0.01977068930864334
Test Loss:  0.013990305364131927
Valid Loss:  0.016445232555270195
Epoch:  165  	Training Loss: 0.019635334610939026
Test Loss:  0.013873898424208164
Valid Loss:  0.01631266251206398
Epoch:  166  	Training Loss: 0.019507789984345436
Test Loss:  0.013762272894382477
Valid Loss:  0.01618659496307373
Epoch:  167  	Training Loss: 0.01938667520880699
Test Loss:  0.013656885363161564
Valid Loss:  0.016068121418356895
Epoch:  168  	Training Loss: 0.019272685050964355
Test Loss:  0.013555395416915417
Valid Loss:  0.015953730791807175
Epoch:  169  	Training Loss: 0.01916388049721718
Test Loss:  0.013458200730383396
Valid Loss:  0.015843255445361137
Epoch:  170  	Training Loss: 0.01905924081802368
Test Loss:  0.013365143910050392
Valid Loss:  0.01573704183101654
Epoch:  171  	Training Loss: 0.018958522006869316
Test Loss:  0.013275821693241596
Valid Loss:  0.015634559094905853
Epoch:  172  	Training Loss: 0.018861595541238785
Test Loss:  0.013221390545368195
Valid Loss:  0.015543628484010696
Epoch:  173  	Training Loss: 0.018778841942548752
Test Loss:  0.013166438788175583
Valid Loss:  0.015459519810974598
Epoch:  174  	Training Loss: 0.018700476735830307
Test Loss:  0.013111475855112076
Valid Loss:  0.015381093136966228
Epoch:  175  	Training Loss: 0.018625307828187943
Test Loss:  0.013056863099336624
Valid Loss:  0.015307565219700336
Epoch:  176  	Training Loss: 0.018553143367171288
Test Loss:  0.012997282668948174
Valid Loss:  0.015238304622471333
Epoch:  177  	Training Loss: 0.01848306879401207
Test Loss:  0.012935146689414978
Valid Loss:  0.015172820538282394
Epoch:  178  	Training Loss: 0.018414342775940895
Test Loss:  0.01287394855171442
Valid Loss:  0.015109498985111713
Epoch:  179  	Training Loss: 0.018345775082707405
Test Loss:  0.01281272154301405
Valid Loss:  0.01504819467663765
Epoch:  180  	Training Loss: 0.01827772706747055
Test Loss:  0.012750154361128807
Valid Loss:  0.014991121366620064
Epoch:  181  	Training Loss: 0.01821371540427208
Test Loss:  0.012689953669905663
Valid Loss:  0.014937883242964745
Epoch:  182  	Training Loss: 0.018153434619307518
Test Loss:  0.012658532708883286
Valid Loss:  0.014941215515136719
Epoch:  183  	Training Loss: 0.01814643293619156
Test Loss:  0.012630213052034378
Valid Loss:  0.014944885857403278
Epoch:  184  	Training Loss: 0.01813904568552971
Test Loss:  0.012608671560883522
Valid Loss:  0.01494801789522171
Epoch:  185  	Training Loss: 0.01813293620944023
Test Loss:  0.012592043727636337
Valid Loss:  0.014950525015592575
Epoch:  186  	Training Loss: 0.01812763512134552
Test Loss:  0.012579000554978848
Valid Loss:  0.014952609315514565
Epoch:  187  	Training Loss: 0.018122872337698936
Test Loss:  0.012568606063723564
Valid Loss:  0.014954237267374992
Epoch:  188  	Training Loss: 0.018118418753147125
Test Loss:  0.012556001543998718
Valid Loss:  0.014956582337617874
Epoch:  189  	Training Loss: 0.018111368641257286
Test Loss:  0.012545907869935036
Valid Loss:  0.014958532527089119
Epoch:  190  	Training Loss: 0.018104705959558487
Test Loss:  0.012537695467472076
Valid Loss:  0.014960113912820816
Epoch:  191  	Training Loss: 0.01809835620224476
Test Loss:  0.012530934065580368
Valid Loss:  0.014961459673941135
Epoch:  192  	Training Loss: 0.018092267215251923
Test Loss:  0.012422790750861168
Valid Loss:  0.014769610948860645
Epoch:  193  	Training Loss: 0.017928309738636017
Test Loss:  0.012314647436141968
Valid Loss:  0.01458018645644188
Epoch:  194  	Training Loss: 0.017764801159501076
Test Loss:  0.012206877581775188
Valid Loss:  0.014392825774848461
Epoch:  195  	Training Loss: 0.01760387234389782
Test Loss:  0.01209948305040598
Valid Loss:  0.014207929372787476
Epoch:  196  	Training Loss: 0.01744450256228447
Test Loss:  0.01199263334274292
Valid Loss:  0.01402689516544342
Epoch:  197  	Training Loss: 0.01728907972574234
Test Loss:  0.01188819482922554
Valid Loss:  0.013852443546056747
Epoch:  198  	Training Loss: 0.017139703035354614
Test Loss:  0.011784505099058151
Valid Loss:  0.013681192882359028
Epoch:  199  	Training Loss: 0.016991248354315758
Test Loss:  0.011681433767080307
Valid Loss:  0.013510972261428833
Epoch:  200  	Training Loss: 0.016843419522047043
Test Loss:  0.011579172685742378
Valid Loss:  0.013343911617994308
Epoch:  201  	Training Loss: 0.016697676852345467
Test Loss:  0.011477747932076454
Valid Loss:  0.013179829344153404
Epoch:  202  	Training Loss: 0.01655394770205021
Test Loss:  0.011366529390215874
Valid Loss:  0.012976158410310745
Epoch:  203  	Training Loss: 0.016369901597499847
Test Loss:  0.011255275458097458
Valid Loss:  0.012779587879776955
Epoch:  204  	Training Loss: 0.01619132235646248
Test Loss:  0.0111440010368824
Valid Loss:  0.012589037418365479
Epoch:  205  	Training Loss: 0.01601664163172245
Test Loss:  0.01103207841515541
Valid Loss:  0.012401813641190529
Epoch:  206  	Training Loss: 0.015842292457818985
Test Loss:  0.010921254754066467
Valid Loss:  0.012218471616506577
Epoch:  207  	Training Loss: 0.015670139342546463
Test Loss:  0.010821428149938583
Valid Loss:  0.01203952543437481
Epoch:  208  	Training Loss: 0.015500684268772602
Test Loss:  0.01072131097316742
Valid Loss:  0.011863739229738712
Epoch:  209  	Training Loss: 0.015333105809986591
Test Loss:  0.010621357709169388
Valid Loss:  0.01170191541314125
Epoch:  210  	Training Loss: 0.015167748555541039
Test Loss:  0.010519948787987232
Valid Loss:  0.011549543589353561
Epoch:  211  	Training Loss: 0.015004117973148823
Test Loss:   42%|████▏     | 211/500 [02:54<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:54<04:07,  1.16it/s] 43%|████▎     | 215/500 [02:54<02:57,  1.61it/s] 43%|████▎     | 217/500 [02:54<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:55<01:35,  2.96it/s] 44%|████▍     | 221/500 [03:01<05:30,  1.18s/it] 45%|████▍     | 223/500 [03:01<03:55,  1.18it/s] 45%|████▌     | 225/500 [03:01<02:48,  1.63it/s] 45%|████▌     | 227/500 [03:01<02:02,  2.22it/s] 46%|████▌     | 229/500 [03:01<01:30,  3.00it/s] 46%|████▌     | 231/500 [03:08<05:17,  1.18s/it] 47%|████▋     | 233/500 [03:08<03:46,  1.18it/s] 47%|████▋     | 235/500 [03:08<02:42,  1.63it/s] 47%|████▋     | 237/500 [03:08<01:58,  2.22it/s] 48%|████▊     | 239/500 [03:08<01:27,  2.99it/s] 48%|████▊     | 241/500 [03:15<05:07,  1.19s/it] 49%|████▊     | 243/500 [03:15<03:40,  1.17it/s] 49%|████▉     | 245/500 [03:15<02:38,  1.61it/s] 49%|████▉     | 247/500 [03:15<01:54,  2.20it/s] 50%|████▉     | 249/500 [03:15<01:24,  2.96it/s] 50%|█████     | 251/500 [03:22<04:57,  1.19s/it] 51%|█████     | 253/500 [03:22<03:31,  1.17it/s] 51%|█████     | 255/500 [03:22<02:31,  1.61it/s] 51%|█████▏    | 257/500 [03:22<01:50,  2.20it/s] 52%|█████▏    | 259/500 [03:22<01:21,  2.96it/s] 52%|█████▏    | 261/500 [03:28<04:41,  1.18s/it] 53%|█████▎    | 263/500 [03:29<03:20,  1.18it/s] 53%|█████▎    | 265/500 [03:29<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:29<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:29<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:35<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:35<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:35<02:16,  1.64it/s] 55%|█████▌    | 277/500 [03:36<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:36<01:13,  3.02it/s]0.010414551943540573
Valid Loss:  0.011400092393159866
Epoch:  212  	Training Loss: 0.014843136072158813
Test Loss:  0.010308800265192986
Valid Loss:  0.011356202885508537
Epoch:  213  	Training Loss: 0.014778325334191322
Test Loss:  0.010221780277788639
Valid Loss:  0.011315291747450829
Epoch:  214  	Training Loss: 0.01472014281898737
Test Loss:  0.010145861655473709
Valid Loss:  0.011272566393017769
Epoch:  215  	Training Loss: 0.01466478779911995
Test Loss:  0.010078102350234985
Valid Loss:  0.011230897158384323
Epoch:  216  	Training Loss: 0.014612607657909393
Test Loss:  0.010017519816756248
Valid Loss:  0.011191120371222496
Epoch:  217  	Training Loss: 0.014562916941940784
Test Loss:  0.009961121715605259
Valid Loss:  0.011152531951665878
Epoch:  218  	Training Loss: 0.014514838345348835
Test Loss:  0.009908750653266907
Valid Loss:  0.01111433282494545
Epoch:  219  	Training Loss: 0.014467177912592888
Test Loss:  0.009859814308583736
Valid Loss:  0.011076908558607101
Epoch:  220  	Training Loss: 0.01442011073231697
Test Loss:  0.009813372045755386
Valid Loss:  0.011040978133678436
Epoch:  221  	Training Loss: 0.014374284073710442
Test Loss:  0.009768752381205559
Valid Loss:  0.011005450040102005
Epoch:  222  	Training Loss: 0.014329265803098679
Test Loss:  0.009757458232343197
Valid Loss:  0.011000026017427444
Epoch:  223  	Training Loss: 0.014322447590529919
Test Loss:  0.00974659901112318
Valid Loss:  0.010994776152074337
Epoch:  224  	Training Loss: 0.01431591622531414
Test Loss:  0.009736113250255585
Valid Loss:  0.010989787988364697
Epoch:  225  	Training Loss: 0.01430932991206646
Test Loss:  0.009725883603096008
Valid Loss:  0.01098446361720562
Epoch:  226  	Training Loss: 0.014302405528724194
Test Loss:  0.009715965017676353
Valid Loss:  0.01097937859594822
Epoch:  227  	Training Loss: 0.014295751228928566
Test Loss:  0.009706318378448486
Valid Loss:  0.010974494740366936
Epoch:  228  	Training Loss: 0.014288969337940216
Test Loss:  0.009696890600025654
Valid Loss:  0.010969368740916252
Epoch:  229  	Training Loss: 0.014281809329986572
Test Loss:  0.009687591344118118
Valid Loss:  0.010964049026370049
Epoch:  230  	Training Loss: 0.014274083077907562
Test Loss:  0.00967847928404808
Valid Loss:  0.01095898263156414
Epoch:  231  	Training Loss: 0.014266634359955788
Test Loss:  0.009669594466686249
Valid Loss:  0.010954132303595543
Epoch:  232  	Training Loss: 0.01425945945084095
Test Loss:  0.009564870968461037
Valid Loss:  0.010830100625753403
Epoch:  233  	Training Loss: 0.014134962111711502
Test Loss:  0.009470346383750439
Valid Loss:  0.010717128403484821
Epoch:  234  	Training Loss: 0.014020942151546478
Test Loss:  0.009385451674461365
Valid Loss:  0.010613522492349148
Epoch:  235  	Training Loss: 0.013916518539190292
Test Loss:  0.00930789764970541
Valid Loss:  0.010517820715904236
Epoch:  236  	Training Loss: 0.013819647021591663
Test Loss:  0.00923591386526823
Valid Loss:  0.010429268702864647
Epoch:  237  	Training Loss: 0.01372942142188549
Test Loss:  0.009169133380055428
Valid Loss:  0.010347063653171062
Epoch:  238  	Training Loss: 0.013645129278302193
Test Loss:  0.009106788784265518
Valid Loss:  0.010269176214933395
Epoch:  239  	Training Loss: 0.013565871864557266
Test Loss:  0.009048189967870712
Valid Loss:  0.010195272043347359
Epoch:  240  	Training Loss: 0.013490617275238037
Test Loss:  0.008992514573037624
Valid Loss:  0.01012507639825344
Epoch:  241  	Training Loss: 0.013418877497315407
Test Loss:  0.00892057828605175
Valid Loss:  0.010050751268863678
Epoch:  242  	Training Loss: 0.013336693868041039
Test Loss:  0.008718112483620644
Valid Loss:  0.009772220626473427
Epoch:  243  	Training Loss: 0.013060247525572777
Test Loss:  0.00852029025554657
Valid Loss:  0.009501399472355843
Epoch:  244  	Training Loss: 0.012790663167834282
Test Loss:  0.00832531787455082
Valid Loss:  0.009239299222826958
Epoch:  245  	Training Loss: 0.012522531673312187
Test Loss:  0.008133331313729286
Valid Loss:  0.008984614163637161
Epoch:  246  	Training Loss: 0.012259213253855705
Test Loss:  0.007948729209601879
Valid Loss:  0.008740332908928394
Epoch:  247  	Training Loss: 0.01200495008379221
Test Loss:  0.007771871518343687
Valid Loss:  0.008503071032464504
Epoch:  248  	Training Loss: 0.01175720151513815
Test Loss:  0.007599930744618177
Valid Loss:  0.008265255019068718
Epoch:  249  	Training Loss: 0.011504638940095901
Test Loss:  0.007429805584251881
Valid Loss:  0.00803285650908947
Epoch:  250  	Training Loss: 0.011260511353611946
Test Loss:  0.0072647808119654655
Valid Loss:  0.007809937931597233
Epoch:  251  	Training Loss: 0.01102364994585514
Test Loss:  0.007102825678884983
Valid Loss:  0.007594977505505085
Epoch:  252  	Training Loss: 0.010792236775159836
Test Loss:  0.007020589895546436
Valid Loss:  0.007494194433093071
Epoch:  253  	Training Loss: 0.010673275217413902
Test Loss:  0.006957135163247585
Valid Loss:  0.007408100180327892
Epoch:  254  	Training Loss: 0.010573331266641617
Test Loss:  0.006898428779095411
Valid Loss:  0.007325286511331797
Epoch:  255  	Training Loss: 0.010477800853550434
Test Loss:  0.006842634174972773
Valid Loss:  0.007245132699608803
Epoch:  256  	Training Loss: 0.010384812951087952
Test Loss:  0.006788639351725578
Valid Loss:  0.007166918367147446
Epoch:  257  	Training Loss: 0.01029389351606369
Test Loss:  0.006736091338098049
Valid Loss:  0.007090120576322079
Epoch:  258  	Training Loss: 0.010204412043094635
Test Loss:  0.006684585008770227
Valid Loss:  0.0070145996287465096
Epoch:  259  	Training Loss: 0.01011613942682743
Test Loss:  0.006634006276726723
Valid Loss:  0.006940259598195553
Epoch:  260  	Training Loss: 0.01002909243106842
Test Loss:  0.006584238260984421
Valid Loss:  0.006867118179798126
Epoch:  261  	Training Loss: 0.00994336698204279
Test Loss:  0.006535377819091082
Valid Loss:  0.0068056620657444
Epoch:  262  	Training Loss: 0.009858802892267704
Test Loss:  0.006396126002073288
Valid Loss:  0.0066026728600263596
Epoch:  263  	Training Loss: 0.009622029960155487
Test Loss:  0.006260142661631107
Valid Loss:  0.006408456712961197
Epoch:  264  	Training Loss: 0.009393838234245777
Test Loss:  0.0061269644647836685
Valid Loss:  0.006221204996109009
Epoch:  265  	Training Loss: 0.00917058251798153
Test Loss:  0.005996888969093561
Valid Loss:  0.006040626205503941
Epoch:  266  	Training Loss: 0.008953927084803581
Test Loss:  0.005869971588253975
Valid Loss:  0.00586161483079195
Epoch:  267  	Training Loss: 0.008743597194552422
Test Loss:  0.005744951777160168
Valid Loss:  0.005689315963536501
Epoch:  268  	Training Loss: 0.008540397509932518
Test Loss:  0.005620511248707771
Valid Loss:  0.00552352936938405
Epoch:  269  	Training Loss: 0.008342467248439789
Test Loss:  0.00549835991114378
Valid Loss:  0.005361909046769142
Epoch:  270  	Training Loss: 0.008148154243826866
Test Loss:  0.00537845678627491
Valid Loss:  0.005206278990954161
Epoch:  271  	Training Loss: 0.00795908086001873
Test Loss:  0.00525734992697835
Valid Loss:  0.005053341388702393
Epoch:  272  	Training Loss: 0.007772878743708134
Test Loss:  0.005170437972992659
Valid Loss:  0.004935399163514376
Epoch:  273  	Training Loss: 0.007631758227944374
Test Loss:  0.005086303222924471
Valid Loss:  0.004822145216166973
Epoch:  274  	Training Loss: 0.007497047074139118
Test Loss:  0.005006532184779644
Valid Loss:  0.00471536535769701
Epoch:  275  	Training Loss: 0.007370871026068926
Test Loss:  0.0049291690811514854
Valid Loss:  0.004612707067281008
Epoch:  276  	Training Loss: 0.007248621433973312
Test Loss:  0.004854197613894939
Valid Loss:  0.004513990134000778
Epoch:  277  	Training Loss: 0.007130141369998455
Test Loss:  0.004781483672559261
Valid Loss:  0.004419099073857069
Epoch:  278  	Training Loss: 0.0070153456181287766
Test Loss:  0.004710992332547903
Valid Loss:  0.00432790070772171
Epoch:  279  	Training Loss: 0.006904088892042637
Test Loss:  0.004642651416361332
Valid Loss:  0.004240233451128006
Epoch:  280  	Training Loss: 0.006796277593821287
Test Loss:  0.004576370120048523
Valid Loss:  0.004156011622399092
Epoch:  281  	Training Loss: 0.006691794376820326
Test Loss:  0.004512109328061342
Valid Loss:   56%|█████▌    | 281/500 [03:42<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:42<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:42<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:42<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:43<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:49<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:49<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:49<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:49<01:31,  2.23it/s] 60%|█████▉    | 299/500 [03:49<01:07,  3.00it/s] 60%|██████    | 301/500 [03:56<03:54,  1.18s/it] 61%|██████    | 303/500 [03:56<02:46,  1.18it/s] 61%|██████    | 305/500 [03:56<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:56<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:56<01:03,  3.01it/s] 62%|██████▏   | 311/500 [04:02<03:40,  1.17s/it] 63%|██████▎   | 313/500 [04:03<02:36,  1.19it/s] 63%|██████▎   | 315/500 [04:03<01:52,  1.65it/s] 63%|██████▎   | 317/500 [04:03<01:21,  2.25it/s] 64%|██████▍   | 319/500 [04:03<00:59,  3.03it/s] 64%|██████▍   | 321/500 [04:09<03:27,  1.16s/it] 65%|██████▍   | 323/500 [04:09<02:26,  1.20it/s] 65%|██████▌   | 325/500 [04:09<01:45,  1.67it/s] 65%|██████▌   | 327/500 [04:10<01:16,  2.27it/s] 66%|██████▌   | 329/500 [04:10<00:55,  3.06it/s] 66%|██████▌   | 331/500 [04:16<03:19,  1.18s/it] 67%|██████▋   | 333/500 [04:16<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:16<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:16<01:13,  2.21it/s] 68%|██████▊   | 339/500 [04:17<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:23<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:23<02:12,  1.18it/s] 69%|██████▉   | 345/500 [04:23<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:23<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:23<00:50,  3.01it/s]0.004083351232111454
Epoch:  282  	Training Loss: 0.006590535864233971
Test Loss:  0.004426832310855389
Valid Loss:  0.003982309252023697
Epoch:  283  	Training Loss: 0.0064519052393734455
Test Loss:  0.004342083353549242
Valid Loss:  0.0038841725327074528
Epoch:  284  	Training Loss: 0.006315060891211033
Test Loss:  0.00425773486495018
Valid Loss:  0.0037892917171120644
Epoch:  285  	Training Loss: 0.006181955803185701
Test Loss:  0.004175518173724413
Valid Loss:  0.0036979885771870613
Epoch:  286  	Training Loss: 0.006053091958165169
Test Loss:  0.004095364362001419
Valid Loss:  0.003610038897022605
Epoch:  287  	Training Loss: 0.005927866790443659
Test Loss:  0.004017005208879709
Valid Loss:  0.00352485291659832
Epoch:  288  	Training Loss: 0.005805294495075941
Test Loss:  0.003940192516893148
Valid Loss:  0.0034419316798448563
Epoch:  289  	Training Loss: 0.005684562027454376
Test Loss:  0.003865411737933755
Valid Loss:  0.0033597098663449287
Epoch:  290  	Training Loss: 0.005567321088165045
Test Loss:  0.0037921657785773277
Valid Loss:  0.003279514145106077
Epoch:  291  	Training Loss: 0.0054514287039637566
Test Loss:  0.003720683977007866
Valid Loss:  0.003201780840754509
Epoch:  292  	Training Loss: 0.005337387323379517
Test Loss:  0.0036258192267268896
Valid Loss:  0.003140064189210534
Epoch:  293  	Training Loss: 0.005266521591693163
Test Loss:  0.0035625752061605453
Valid Loss:  0.003092404454946518
Epoch:  294  	Training Loss: 0.005209023132920265
Test Loss:  0.003515256568789482
Valid Loss:  0.0030509321950376034
Epoch:  295  	Training Loss: 0.005157467443495989
Test Loss:  0.003476227167993784
Valid Loss:  0.0030123672913759947
Epoch:  296  	Training Loss: 0.005108591169118881
Test Loss:  0.003442327491939068
Valid Loss:  0.0029755113646388054
Epoch:  297  	Training Loss: 0.005061393603682518
Test Loss:  0.003411495126783848
Valid Loss:  0.002939839381724596
Epoch:  298  	Training Loss: 0.005015203729271889
Test Loss:  0.0033824387937784195
Valid Loss:  0.002905153203755617
Epoch:  299  	Training Loss: 0.004969812463968992
Test Loss:  0.003354650689288974
Valid Loss:  0.0028713869396597147
Epoch:  300  	Training Loss: 0.004925151355564594
Test Loss:  0.003327957820147276
Valid Loss:  0.002838517539203167
Epoch:  301  	Training Loss: 0.004881206899881363
Test Loss:  0.0033020460978150368
Valid Loss:  0.0028065964579582214
Epoch:  302  	Training Loss: 0.004837945569306612
Test Loss:  0.003261453937739134
Valid Loss:  0.0027591718826442957
Epoch:  303  	Training Loss: 0.004756514448672533
Test Loss:  0.0032175290398299694
Valid Loss:  0.0027137049473822117
Epoch:  304  	Training Loss: 0.00467894971370697
Test Loss:  0.003174020443111658
Valid Loss:  0.0026710196398198605
Epoch:  305  	Training Loss: 0.004606487229466438
Test Loss:  0.003127333475276828
Valid Loss:  0.00262995227240026
Epoch:  306  	Training Loss: 0.004535782150924206
Test Loss:  0.003081734525039792
Valid Loss:  0.0025908027309924364
Epoch:  307  	Training Loss: 0.004467331804335117
Test Loss:  0.003037488553673029
Valid Loss:  0.0025534380692988634
Epoch:  308  	Training Loss: 0.004400943405926228
Test Loss:  0.002994098234921694
Valid Loss:  0.002517515793442726
Epoch:  309  	Training Loss: 0.004336338024586439
Test Loss:  0.0029518092051148415
Valid Loss:  0.0024820524267852306
Epoch:  310  	Training Loss: 0.004273131489753723
Test Loss:  0.0029107294976711273
Valid Loss:  0.0024461133871227503
Epoch:  311  	Training Loss: 0.0042122709564864635
Test Loss:  0.0028710737824440002
Valid Loss:  0.002412316622212529
Epoch:  312  	Training Loss: 0.004156230483204126
Test Loss:  0.0028269346803426743
Valid Loss:  0.002370061818510294
Epoch:  313  	Training Loss: 0.0040912930853664875
Test Loss:  0.0027837385423481464
Valid Loss:  0.0023290349636226892
Epoch:  314  	Training Loss: 0.0040273345075547695
Test Loss:  0.0027415971271693707
Valid Loss:  0.002289368072524667
Epoch:  315  	Training Loss: 0.003964536357671022
Test Loss:  0.002700403332710266
Valid Loss:  0.0022527347318828106
Epoch:  316  	Training Loss: 0.003902856493368745
Test Loss:  0.0026602516882121563
Valid Loss:  0.0022212606854736805
Epoch:  317  	Training Loss: 0.0038434118032455444
Test Loss:  0.002622359897941351
Valid Loss:  0.002190851606428623
Epoch:  318  	Training Loss: 0.003786932211369276
Test Loss:  0.0025853095576167107
Valid Loss:  0.0021613258868455887
Epoch:  319  	Training Loss: 0.0037313008215278387
Test Loss:  0.0025492296554148197
Valid Loss:  0.002132787834852934
Epoch:  320  	Training Loss: 0.0036768452264368534
Test Loss:  0.002513954183086753
Valid Loss:  0.0021051098592579365
Epoch:  321  	Training Loss: 0.003623038763180375
Test Loss:  0.0024796014185994864
Valid Loss:  0.002078387187793851
Epoch:  322  	Training Loss: 0.0035703948233276606
Test Loss:  0.002468290738761425
Valid Loss:  0.002064298838376999
Epoch:  323  	Training Loss: 0.003542227204889059
Test Loss:  0.002455819630995393
Valid Loss:  0.002050897805020213
Epoch:  324  	Training Loss: 0.0035137669183313847
Test Loss:  0.002443327335640788
Valid Loss:  0.0020375950261950493
Epoch:  325  	Training Loss: 0.003485381370410323
Test Loss:  0.0024307863786816597
Valid Loss:  0.002022449392825365
Epoch:  326  	Training Loss: 0.0034574742894619703
Test Loss:  0.002417186973616481
Valid Loss:  0.0020067072473466396
Epoch:  327  	Training Loss: 0.0034303166903555393
Test Loss:  0.0024036415852606297
Valid Loss:  0.00199146568775177
Epoch:  328  	Training Loss: 0.003403734415769577
Test Loss:  0.002390292240306735
Valid Loss:  0.0019767777994275093
Epoch:  329  	Training Loss: 0.003378053428605199
Test Loss:  0.0023771277628839016
Valid Loss:  0.001961402827873826
Epoch:  330  	Training Loss: 0.0033531873486936092
Test Loss:  0.002364023122936487
Valid Loss:  0.0019463724456727505
Epoch:  331  	Training Loss: 0.003328489838168025
Test Loss:  0.0023510935716331005
Valid Loss:  0.0019318272825330496
Epoch:  332  	Training Loss: 0.0033045243471860886
Test Loss:  0.0023272824473679066
Valid Loss:  0.0019238158129155636
Epoch:  333  	Training Loss: 0.0032924883998930454
Test Loss:  0.0023098583333194256
Valid Loss:  0.0019195758504793048
Epoch:  334  	Training Loss: 0.003282724879682064
Test Loss:  0.0022959806956350803
Valid Loss:  0.0019172198371961713
Epoch:  335  	Training Loss: 0.0032738903537392616
Test Loss:  0.002284151501953602
Valid Loss:  0.0019158318173140287
Epoch:  336  	Training Loss: 0.00326547771692276
Test Loss:  0.0022735532838851213
Valid Loss:  0.001914977328851819
Epoch:  337  	Training Loss: 0.003257255768403411
Test Loss:  0.0022637348156422377
Valid Loss:  0.0019144313409924507
Epoch:  338  	Training Loss: 0.0032489169389009476
Test Loss:  0.002253638580441475
Valid Loss:  0.001913902466185391
Epoch:  339  	Training Loss: 0.003240365767851472
Test Loss:  0.002244033385068178
Valid Loss:  0.0019135557813569903
Epoch:  340  	Training Loss: 0.003231882583349943
Test Loss:  0.0022347650956362486
Valid Loss:  0.0019132870947942138
Epoch:  341  	Training Loss: 0.0032244150061160326
Test Loss:  0.002226955723017454
Valid Loss:  0.0019131001317873597
Epoch:  342  	Training Loss: 0.0032183355651795864
Test Loss:  0.002202811185270548
Valid Loss:  0.0018850979395210743
Epoch:  343  	Training Loss: 0.003175424411892891
Test Loss:  0.00217916420660913
Valid Loss:  0.0018579436000436544
Epoch:  344  	Training Loss: 0.0031333116348832846
Test Loss:  0.002155933529138565
Valid Loss:  0.00183174479752779
Epoch:  345  	Training Loss: 0.0030919788405299187
Test Loss:  0.002133206697180867
Valid Loss:  0.0018065557815134525
Epoch:  346  	Training Loss: 0.0030515212565660477
Test Loss:  0.0021109709050506353
Valid Loss:  0.0017821777146309614
Epoch:  347  	Training Loss: 0.003011840395629406
Test Loss:  0.0020892515312880278
Valid Loss:  0.0017585880123078823
Epoch:  348  	Training Loss: 0.002972728107124567
Test Loss:  0.0020683337934315205
Valid Loss:  0.0017357633914798498
Epoch:  349  	Training Loss: 0.0029344516806304455
Test Loss:  0.002048034919425845
Valid Loss:  0.0017138153780251741
Epoch:  350  	Training Loss: 0.0028970541898161173
Test Loss:  0.0020262820180505514
Valid Loss:  0.0016926543321460485
 70%|███████   | 351/500 [04:30<02:55,  1.18s/it] 71%|███████   | 353/500 [04:30<02:04,  1.18it/s] 71%|███████   | 355/500 [04:30<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:30<01:03,  2.23it/s] 72%|███████▏  | 359/500 [04:30<00:47,  2.94it/s] 72%|███████▏  | 361/500 [04:37<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:37<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:37<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:37<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:37<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:43<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:44<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:44<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:44<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:44<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:50<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:50<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:50<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:51<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:51<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:57<02:10,  1.19s/it] 79%|███████▊  | 393/500 [04:57<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:57<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:58<00:46,  2.20it/s] 80%|███████▉  | 399/500 [04:58<00:34,  2.96it/s] 80%|████████  | 401/500 [05:04<01:55,  1.17s/it] 81%|████████  | 403/500 [05:04<01:21,  1.19it/s] 81%|████████  | 405/500 [05:04<00:57,  1.65it/s] 81%|████████▏ | 407/500 [05:04<00:41,  2.23it/s] 82%|████████▏ | 409/500 [05:04<00:30,  2.97it/s] 82%|████████▏ | 411/500 [05:11<01:44,  1.18s/it] 83%|████████▎ | 413/500 [05:11<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:11<00:52,  1.63it/s] 83%|████████▎ | 417/500 [05:11<00:37,  2.23it/s]Epoch:  351  	Training Loss: 0.0028604604303836823
Test Loss:  0.0020039803348481655
Valid Loss:  0.0016721616266295314
Epoch:  352  	Training Loss: 0.0028245202265679836
Test Loss:  0.0019845147617161274
Valid Loss:  0.0016571502201259136
Epoch:  353  	Training Loss: 0.0027995838318020105
Test Loss:  0.001966024748980999
Valid Loss:  0.001642976189032197
Epoch:  354  	Training Loss: 0.0027752448804676533
Test Loss:  0.001948336255736649
Valid Loss:  0.00162955978885293
Epoch:  355  	Training Loss: 0.0027514505200088024
Test Loss:  0.0019313509110361338
Valid Loss:  0.001616824185475707
Epoch:  356  	Training Loss: 0.0027281534858047962
Test Loss:  0.0019149701111018658
Valid Loss:  0.0016047203680500388
Epoch:  357  	Training Loss: 0.0027053281664848328
Test Loss:  0.0018991590477526188
Valid Loss:  0.0015931951347738504
Epoch:  358  	Training Loss: 0.002682944294065237
Test Loss:  0.0018838249379768968
Valid Loss:  0.0015801528934389353
Epoch:  359  	Training Loss: 0.0026609806809574366
Test Loss:  0.0018689215648919344
Valid Loss:  0.001567254075780511
Epoch:  360  	Training Loss: 0.0026394270826131105
Test Loss:  0.0018544249469414353
Valid Loss:  0.0015547925140708685
Epoch:  361  	Training Loss: 0.0026182655710726976
Test Loss:  0.0018402899149805307
Valid Loss:  0.0015427384059876204
Epoch:  362  	Training Loss: 0.0025974877644330263
Test Loss:  0.0018366517033427954
Valid Loss:  0.0015379562973976135
Epoch:  363  	Training Loss: 0.0025864453054964542
Test Loss:  0.0018329445738345385
Valid Loss:  0.0015327574219554663
Epoch:  364  	Training Loss: 0.0025757860857993364
Test Loss:  0.0018291965825483203
Valid Loss:  0.0015275717014446855
Epoch:  365  	Training Loss: 0.002565455622971058
Test Loss:  0.0018253989983350039
Valid Loss:  0.0015224865637719631
Epoch:  366  	Training Loss: 0.0025552986189723015
Test Loss:  0.0018215116579085588
Valid Loss:  0.0015174413565546274
Epoch:  367  	Training Loss: 0.0025452710688114166
Test Loss:  0.001817606040276587
Valid Loss:  0.0015124991768971086
Epoch:  368  	Training Loss: 0.0025355080142617226
Test Loss:  0.0018136948347091675
Valid Loss:  0.0015076542040333152
Epoch:  369  	Training Loss: 0.0025259829126298428
Test Loss:  0.0018097697757184505
Valid Loss:  0.0015029089991003275
Epoch:  370  	Training Loss: 0.0025166927371174097
Test Loss:  0.0018058589193969965
Valid Loss:  0.0014982615830376744
Epoch:  371  	Training Loss: 0.0025074961595237255
Test Loss:  0.0018019264098256826
Valid Loss:  0.0014931962359696627
Epoch:  372  	Training Loss: 0.0024983668699860573
Test Loss:  0.0017692616675049067
Valid Loss:  0.0014626603806391358
Epoch:  373  	Training Loss: 0.0024455497041344643
Test Loss:  0.001737438840791583
Valid Loss:  0.0014313827268779278
Epoch:  374  	Training Loss: 0.00239410693757236
Test Loss:  0.0017053356859833002
Valid Loss:  0.001400895300321281
Epoch:  375  	Training Loss: 0.002344556152820587
Test Loss:  0.0016735004028305411
Valid Loss:  0.001371690072119236
Epoch:  376  	Training Loss: 0.002296632155776024
Test Loss:  0.0016425217036157846
Valid Loss:  0.0013434796128422022
Epoch:  377  	Training Loss: 0.002250001300126314
Test Loss:  0.001612548134289682
Valid Loss:  0.00131648825481534
Epoch:  378  	Training Loss: 0.002204974414780736
Test Loss:  0.0015834611840546131
Valid Loss:  0.0012905399780720472
Epoch:  379  	Training Loss: 0.0021614106371998787
Test Loss:  0.0015552109107375145
Valid Loss:  0.001265629194676876
Epoch:  380  	Training Loss: 0.0021192142739892006
Test Loss:  0.0015277130296453834
Valid Loss:  0.0012415717355906963
Epoch:  381  	Training Loss: 0.002078099176287651
Test Loss:  0.0015009953640401363
Valid Loss:  0.0012186177773401141
Epoch:  382  	Training Loss: 0.0020384080708026886
Test Loss:  0.0014870675513520837
Valid Loss:  0.0012080706655979156
Epoch:  383  	Training Loss: 0.002021385356783867
Test Loss:  0.0014737856108695269
Valid Loss:  0.0011981548741459846
Epoch:  384  	Training Loss: 0.002004841575399041
Test Loss:  0.0014610810903832316
Valid Loss:  0.0011888056760653853
Epoch:  385  	Training Loss: 0.001988726668059826
Test Loss:  0.0014488891465589404
Valid Loss:  0.0011799747589975595
Epoch:  386  	Training Loss: 0.001973026664927602
Test Loss:  0.0014371222350746393
Valid Loss:  0.0011716055450960994
Epoch:  387  	Training Loss: 0.0019577029161155224
Test Loss:  0.0014257682487368584
Valid Loss:  0.0011636626441031694
Epoch:  388  	Training Loss: 0.0019427303923293948
Test Loss:  0.0014147660695016384
Valid Loss:  0.0011561124119907618
Epoch:  389  	Training Loss: 0.001928099780343473
Test Loss:  0.0014040970709174871
Valid Loss:  0.0011489354074001312
Epoch:  390  	Training Loss: 0.001913791405968368
Test Loss:  0.001393742742948234
Valid Loss:  0.0011421078816056252
Epoch:  391  	Training Loss: 0.0018997977022081614
Test Loss:  0.0013836591970175505
Valid Loss:  0.0011355830356478691
Epoch:  392  	Training Loss: 0.0018860965501517057
Test Loss:  0.0013804552145302296
Valid Loss:  0.0011316027957946062
Epoch:  393  	Training Loss: 0.0018794676288962364
Test Loss:  0.00137725577224046
Valid Loss:  0.0011276272125542164
Epoch:  394  	Training Loss: 0.0018729731673374772
Test Loss:  0.0013740614522248507
Valid Loss:  0.0011235191486775875
Epoch:  395  	Training Loss: 0.001866606529802084
Test Loss:  0.001370863988995552
Valid Loss:  0.0011193131795153022
Epoch:  396  	Training Loss: 0.0018603666685521603
Test Loss:  0.0013676814269274473
Valid Loss:  0.0011151405051350594
Epoch:  397  	Training Loss: 0.0018542357720434666
Test Loss:  0.001364503288641572
Valid Loss:  0.0011110110208392143
Epoch:  398  	Training Loss: 0.0018482159357517958
Test Loss:  0.0013613228220492601
Valid Loss:  0.001106903306208551
Epoch:  399  	Training Loss: 0.001842307043261826
Test Loss:  0.0013581616804003716
Valid Loss:  0.0011028377339243889
Epoch:  400  	Training Loss: 0.001836481736972928
Test Loss:  0.00135499844327569
Valid Loss:  0.0010987838031724095
Epoch:  401  	Training Loss: 0.0018306871643289924
Test Loss:  0.0013518088962882757
Valid Loss:  0.0010947207920253277
Epoch:  402  	Training Loss: 0.001824856735765934
Test Loss:  0.001340995542705059
Valid Loss:  0.0010877292370423675
Epoch:  403  	Training Loss: 0.001811299822293222
Test Loss:  0.001330636558122933
Valid Loss:  0.0010812157997861505
Epoch:  404  	Training Loss: 0.0017980618868023157
Test Loss:  0.0013206570874899626
Valid Loss:  0.0010751038789749146
Epoch:  405  	Training Loss: 0.001785124884918332
Test Loss:  0.0013110042782500386
Valid Loss:  0.0010693423682823777
Epoch:  406  	Training Loss: 0.0017724792705848813
Test Loss:  0.0013016416924074292
Valid Loss:  0.001063911709934473
Epoch:  407  	Training Loss: 0.0017601045547053218
Test Loss:  0.0012925431365147233
Valid Loss:  0.0010587696451693773
Epoch:  408  	Training Loss: 0.0017479868838563561
Test Loss:  0.0012836577370762825
Valid Loss:  0.0010538966162130237
Epoch:  409  	Training Loss: 0.0017361260252073407
Test Loss:  0.0012749973684549332
Valid Loss:  0.0010492687579244375
Epoch:  410  	Training Loss: 0.001724514295347035
Test Loss:  0.0012665345566347241
Valid Loss:  0.0010448776884004474
Epoch:  411  	Training Loss: 0.001713140052743256
Test Loss:  0.0012582553317770362
Valid Loss:  0.001040708040818572
Epoch:  412  	Training Loss: 0.001701995963230729
Test Loss:  0.0012532495893537998
Valid Loss:  0.0010407151421532035
Epoch:  413  	Training Loss: 0.0016983982641249895
Test Loss:  0.0012483036844059825
Valid Loss:  0.0010407778900116682
Epoch:  414  	Training Loss: 0.0016950605204328895
Test Loss:  0.0012433584779500961
Valid Loss:  0.0010408801026642323
Epoch:  415  	Training Loss: 0.0016919468762353063
Test Loss:  0.0012385454028844833
Valid Loss:  0.0010411207331344485
Epoch:  416  	Training Loss: 0.0016888142563402653
Test Loss:  0.0012340153334662318
Valid Loss:  0.0010413939598947763
Epoch:  417  	Training Loss: 0.0016858894377946854
Test Loss:  0.0012297432404011488
Valid Loss:  0.0010416805744171143
Epoch:  418  	Training Loss: 0.0016831522807478905
Test Loss:  0.0012256952468305826
Valid Loss:  0.001041986746713519
Epoch:  419  	Training Loss: 0.0016804831102490425
Test Loss:  0.00122174434363842
 84%|████████▍ | 419/500 [05:11<00:26,  3.00it/s] 84%|████████▍ | 421/500 [05:18<01:33,  1.18s/it] 85%|████████▍ | 423/500 [05:18<01:05,  1.18it/s] 85%|████████▌ | 425/500 [05:18<00:45,  1.63it/s] 85%|████████▌ | 427/500 [05:18<00:32,  2.23it/s] 86%|████████▌ | 429/500 [05:18<00:23,  3.00it/s] 86%|████████▌ | 431/500 [05:24<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:25<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:25<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:25<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:25<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:31<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:31<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:32<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:32<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:32<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:38<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:38<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:38<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:39<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:39<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:45<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:45<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:45<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:46<00:15,  2.17it/s] 94%|█████████▍| 469/500 [05:46<00:10,  2.93it/s] 94%|█████████▍| 471/500 [05:52<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:52<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:52<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:52<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:53<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:59<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:59<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:59<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:59<00:05,  2.24it/s]Valid Loss:  0.0010424226056784391
Epoch:  420  	Training Loss: 0.0016777412965893745
Test Loss:  0.0012177706230431795
Valid Loss:  0.0010427255183458328
Epoch:  421  	Training Loss: 0.0016749761998653412
Test Loss:  0.0012138874735683203
Valid Loss:  0.0010431752307340503
Epoch:  422  	Training Loss: 0.0016721810679882765
Test Loss:  0.001211800379678607
Valid Loss:  0.001041728537529707
Epoch:  423  	Training Loss: 0.001671260572038591
Test Loss:  0.0012102812761440873
Valid Loss:  0.0010407501831650734
Epoch:  424  	Training Loss: 0.0016704361187294126
Test Loss:  0.0012091286480426788
Valid Loss:  0.0010400747414678335
Epoch:  425  	Training Loss: 0.0016696453094482422
Test Loss:  0.0012081977911293507
Valid Loss:  0.0010395990684628487
Epoch:  426  	Training Loss: 0.0016688811592757702
Test Loss:  0.0012074244441464543
Valid Loss:  0.0010392565745860338
Epoch:  427  	Training Loss: 0.0016681281849741936
Test Loss:  0.001206749933771789
Valid Loss:  0.0010389939416199923
Epoch:  428  	Training Loss: 0.0016673810314387083
Test Loss:  0.0012061367742717266
Valid Loss:  0.0010387906804680824
Epoch:  429  	Training Loss: 0.0016666400479152799
Test Loss:  0.0012055679690092802
Valid Loss:  0.0010386237408965826
Epoch:  430  	Training Loss: 0.0016659037210047245
Test Loss:  0.0012050240766257048
Valid Loss:  0.0010384945198893547
Epoch:  431  	Training Loss: 0.0016651699552312493
Test Loss:  0.001204508589580655
Valid Loss:  0.0010383770568296313
Epoch:  432  	Training Loss: 0.0016644379356876016
Test Loss:  0.0011954604415223002
Valid Loss:  0.0010318688582628965
Epoch:  433  	Training Loss: 0.0016480435151606798
Test Loss:  0.001186216832138598
Valid Loss:  0.0010251272469758987
Epoch:  434  	Training Loss: 0.001631999621167779
Test Loss:  0.0011767586693167686
Valid Loss:  0.0010183068225160241
Epoch:  435  	Training Loss: 0.0016162593383342028
Test Loss:  0.0011672567343339324
Valid Loss:  0.001011490123346448
Epoch:  436  	Training Loss: 0.0016008112579584122
Test Loss:  0.001157756894826889
Valid Loss:  0.001004706835374236
Epoch:  437  	Training Loss: 0.0015855844831094146
Test Loss:  0.00114829046651721
Valid Loss:  0.0009977691806852818
Epoch:  438  	Training Loss: 0.0015706007834523916
Test Loss:  0.0011389029677957296
Valid Loss:  0.000989537569694221
Epoch:  439  	Training Loss: 0.0015558729646727443
Test Loss:  0.001129603711888194
Valid Loss:  0.0009814236545935273
Epoch:  440  	Training Loss: 0.0015413900837302208
Test Loss:  0.0011204072507098317
Valid Loss:  0.0009734280174598098
Epoch:  441  	Training Loss: 0.0015271424781531096
Test Loss:  0.0011113284854218364
Valid Loss:  0.0009655579342506826
Epoch:  442  	Training Loss: 0.001513110939413309
Test Loss:  0.0011030372697860003
Valid Loss:  0.0009631571010686457
Epoch:  443  	Training Loss: 0.0015031800139695406
Test Loss:  0.001094980863854289
Valid Loss:  0.0009606906678527594
Epoch:  444  	Training Loss: 0.0014936206862330437
Test Loss:  0.0010871366830542684
Valid Loss:  0.0009581837221048772
Epoch:  445  	Training Loss: 0.0014843929093331099
Test Loss:  0.0010795154375955462
Valid Loss:  0.0009556569857522845
Epoch:  446  	Training Loss: 0.0014754647854715586
Test Loss:  0.001072111539542675
Valid Loss:  0.0009531372343190014
Epoch:  447  	Training Loss: 0.0014668188523501158
Test Loss:  0.0010649303440004587
Valid Loss:  0.0009506308706477284
Epoch:  448  	Training Loss: 0.0014584194868803024
Test Loss:  0.0010579482186585665
Valid Loss:  0.0009481488959863782
Epoch:  449  	Training Loss: 0.0014502545818686485
Test Loss:  0.0010511615546420217
Valid Loss:  0.0009456931729800999
Epoch:  450  	Training Loss: 0.001442302018404007
Test Loss:  0.0010445723310112953
Valid Loss:  0.0009431479265913367
Epoch:  451  	Training Loss: 0.001434526639059186
Test Loss:  0.001038089394569397
Valid Loss:  0.0009407139150425792
Epoch:  452  	Training Loss: 0.0014268594095483422
Test Loss:  0.0010354099795222282
Valid Loss:  0.0009399631526321173
Epoch:  453  	Training Loss: 0.0014245015336200595
Test Loss:  0.001032822416163981
Valid Loss:  0.0009392722276970744
Epoch:  454  	Training Loss: 0.0014221642632037401
Test Loss:  0.0010302980663254857
Valid Loss:  0.0009386322344653308
Epoch:  455  	Training Loss: 0.00141983013600111
Test Loss:  0.0010278293630108237
Valid Loss:  0.0009380356059409678
Epoch:  456  	Training Loss: 0.0014175174292176962
Test Loss:  0.0010253930231556296
Valid Loss:  0.0009374720975756645
Epoch:  457  	Training Loss: 0.001415211008861661
Test Loss:  0.0010230019688606262
Valid Loss:  0.0009369271574541926
Epoch:  458  	Training Loss: 0.0014129127375781536
Test Loss:  0.0010206340812146664
Valid Loss:  0.0009364110883325338
Epoch:  459  	Training Loss: 0.0014106308808550239
Test Loss:  0.0010182906407862902
Valid Loss:  0.0009359104442410171
Epoch:  460  	Training Loss: 0.0014083539135754108
Test Loss:  0.0010159735102206469
Valid Loss:  0.0009354221983812749
Epoch:  461  	Training Loss: 0.0014060861431062222
Test Loss:  0.0010136798955500126
Valid Loss:  0.0009349354077130556
Epoch:  462  	Training Loss: 0.0014038264052942395
Test Loss:  0.0010107953567057848
Valid Loss:  0.000933274975977838
Epoch:  463  	Training Loss: 0.0014016410568729043
Test Loss:  0.0010080826468765736
Valid Loss:  0.0009316852083429694
Epoch:  464  	Training Loss: 0.0013996148481965065
Test Loss:  0.0010055890306830406
Valid Loss:  0.0009301779209636152
Epoch:  465  	Training Loss: 0.0013977396301925182
Test Loss:  0.0010033301077783108
Valid Loss:  0.0009288128931075335
Epoch:  466  	Training Loss: 0.0013960942160338163
Test Loss:  0.0010014530271291733
Valid Loss:  0.0009275955962948501
Epoch:  467  	Training Loss: 0.0013947791885584593
Test Loss:  0.0009997382294386625
Valid Loss:  0.0009265294065698981
Epoch:  468  	Training Loss: 0.00139359082095325
Test Loss:  0.0009983442723751068
Valid Loss:  0.0009254614124074578
Epoch:  469  	Training Loss: 0.001392676611430943
Test Loss:  0.0009970881510525942
Valid Loss:  0.000924447551369667
Epoch:  470  	Training Loss: 0.0013919093180447817
Test Loss:  0.0009958974551409483
Valid Loss:  0.0009234610479325056
Epoch:  471  	Training Loss: 0.0013912178110331297
Test Loss:  0.00099479709751904
Valid Loss:  0.0009225117391906679
Epoch:  472  	Training Loss: 0.0013906083768233657
Test Loss:  0.0009859850397333503
Valid Loss:  0.0009184060618281364
Epoch:  473  	Training Loss: 0.001381112146191299
Test Loss:  0.0009775091893970966
Valid Loss:  0.0009145409567281604
Epoch:  474  	Training Loss: 0.0013718516565859318
Test Loss:  0.0009693524334579706
Valid Loss:  0.0009109539678320289
Epoch:  475  	Training Loss: 0.0013628201559185982
Test Loss:  0.0009614571463316679
Valid Loss:  0.0009075597627088428
Epoch:  476  	Training Loss: 0.0013539831852540374
Test Loss:  0.0009537952719256282
Valid Loss:  0.0009043255704455078
Epoch:  477  	Training Loss: 0.0013453286373987794
Test Loss:  0.0009463428286835551
Valid Loss:  0.0009012431255541742
Epoch:  478  	Training Loss: 0.0013368515064939857
Test Loss:  0.0009390991763211787
Valid Loss:  0.0008982771541923285
Epoch:  479  	Training Loss: 0.0013285430613905191
Test Loss:  0.0009320371900685132
Valid Loss:  0.0008954433724284172
Epoch:  480  	Training Loss: 0.0013203909620642662
Test Loss:  0.0009251412702724338
Valid Loss:  0.0008927159360609949
Epoch:  481  	Training Loss: 0.001312363427132368
Test Loss:  0.0009183091460727155
Valid Loss:  0.0008900143438950181
Epoch:  482  	Training Loss: 0.0013044069055467844
Test Loss:  0.0009118324378505349
Valid Loss:  0.0008844350231811404
Epoch:  483  	Training Loss: 0.0012933267280459404
Test Loss:  0.0009053705143742263
Valid Loss:  0.000878848135471344
Epoch:  484  	Training Loss: 0.001282461453229189
Test Loss:  0.0008989167399704456
Valid Loss:  0.0008732728310860693
Epoch:  485  	Training Loss: 0.0012717786012217402
Test Loss:  0.0008925065631046891
Valid Loss:  0.000867722206749022
Epoch:  486  	Training Loss: 0.0012612675782293081
Test Loss:  0.0008861487731337547
Valid Loss:  0.0008622310124337673
Epoch:  487  	Training Loss: 0.0012509406078606844
Test Loss:  0.0008798468625172973
Valid Loss:  0.0008567961631342769
 98%|█████████▊| 489/500 [05:59<00:03,  3.02it/s] 98%|█████████▊| 491/500 [06:06<00:10,  1.20s/it] 99%|█████████▊| 493/500 [06:06<00:06,  1.16it/s] 99%|█████████▉| 495/500 [06:06<00:03,  1.61it/s] 99%|█████████▉| 497/500 [06:06<00:01,  2.20it/s]100%|█████████▉| 499/500 [06:06<00:00,  2.95it/s]100%|██████████| 500/500 [06:06<00:00,  1.36it/s]
Epoch:  488  	Training Loss: 0.0012407670728862286
Test Loss:  0.0008736022282391787
Valid Loss:  0.0008514310466125607
Epoch:  489  	Training Loss: 0.0012307525612413883
Test Loss:  0.000867420865688473
Valid Loss:  0.0008461409015581012
Epoch:  490  	Training Loss: 0.0012208913685753942
Test Loss:  0.0008613236714154482
Valid Loss:  0.0008409550646319985
Epoch:  491  	Training Loss: 0.00121118884999305
Test Loss:  0.0008552896324545145
Valid Loss:  0.0008358491468243301
Epoch:  492  	Training Loss: 0.0012016274267807603
Test Loss:  0.0008543833391740918
Valid Loss:  0.0008358914637938142
Epoch:  493  	Training Loss: 0.0011997177498415112
Test Loss:  0.0008534283842891455
Valid Loss:  0.0008359018247574568
Epoch:  494  	Training Loss: 0.0011978496331721544
Test Loss:  0.0008524212171323597
Valid Loss:  0.0008358875056728721
Epoch:  495  	Training Loss: 0.0011960135307163
Test Loss:  0.0008513585780747235
Valid Loss:  0.000835837097838521
Epoch:  496  	Training Loss: 0.0011942207347601652
Test Loss:  0.0008502538548782468
Valid Loss:  0.0008357625920325518
Epoch:  497  	Training Loss: 0.0011924458667635918
Test Loss:  0.0008491248008795083
Valid Loss:  0.0008356742328032851
Epoch:  498  	Training Loss: 0.0011906945146620274
Test Loss:  0.0008479569805786014
Valid Loss:  0.0008355671889148653
Epoch:  499  	Training Loss: 0.0011889610905200243
Test Loss:  0.0008467709412798285
Valid Loss:  0.0008354416349902749
Epoch:  500  	Training Loss: 0.0011872481554746628
Test Loss:  0.0008455603383481503
Valid Loss:  0.0008353074663318694
seed is  4
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.31it/s]  1%|          | 4/500 [00:00<00:31, 15.96it/s]  1%|          | 6/500 [00:00<00:30, 16.11it/s]  2%|▏         | 8/500 [00:00<00:30, 16.08it/s]  2%|▏         | 10/500 [00:00<00:30, 15.87it/s]  2%|▏         | 12/500 [00:00<00:30, 15.95it/s]  3%|▎         | 14/500 [00:00<00:30, 15.89it/s]  3%|▎         | 16/500 [00:01<00:30, 16.05it/s]  4%|▎         | 18/500 [00:01<00:29, 16.14it/s]  4%|▍         | 20/500 [00:01<00:29, 16.24it/s]  4%|▍         | 22/500 [00:01<00:29, 16.35it/s]  5%|▍         | 24/500 [00:01<00:29, 16.35it/s]  5%|▌         | 26/500 [00:01<00:29, 16.22it/s]  6%|▌         | 28/500 [00:01<00:29, 15.86it/s]  6%|▌         | 30/500 [00:01<00:29, 15.99it/s]  6%|▋         | 32/500 [00:01<00:29, 15.92it/s]  7%|▋         | 34/500 [00:02<00:29, 15.54it/s]  7%|▋         | 36/500 [00:02<00:30, 15.39it/s]  8%|▊         | 38/500 [00:02<00:29, 15.58it/s]  8%|▊         | 40/500 [00:02<00:29, 15.49it/s]  8%|▊         | 42/500 [00:02<00:29, 15.72it/s]  9%|▉         | 44/500 [00:02<00:28, 15.74it/s]  9%|▉         | 46/500 [00:02<00:28, 15.83it/s] 10%|▉         | 48/500 [00:03<00:28, 15.76it/s] 10%|█         | 50/500 [00:03<00:28, 15.90it/s] 10%|█         | 52/500 [00:03<00:28, 15.94it/s] 11%|█         | 54/500 [00:03<00:28, 15.80it/s] 11%|█         | 56/500 [00:03<00:27, 15.88it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.06it/s] 12%|█▏        | 60/500 [00:03<00:27, 15.92it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.05it/s] 13%|█▎        | 64/500 [00:04<00:27, 16.14it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.23it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.29it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.35it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.35it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.36it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.36it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.36it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.33it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.44it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.46it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.45it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.41it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.40it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.41it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.44it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.46it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.35it/s] 20%|██        | 100/500 [00:06<00:24, 16.40it/s] 20%|██        | 102/500 [00:06<00:24, 16.38it/s] 21%|██        | 104/500 [00:06<00:24, 16.38it/s] 21%|██        | 106/500 [00:06<00:24, 16.38it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.26it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.32it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.21it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.30it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.15it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.05it/s] 24%|██▍       | 120/500 [00:07<00:24, 15.63it/s] 24%|██▍       | 122/500 [00:07<00:24, 15.40it/s] 25%|██▍       | 124/500 [00:07<00:24, 15.28it/s]Epoch:  1  	Training Loss: 0.08961300551891327
Test Loss:  2716.386474609375
Valid Loss:  2706.438232421875
Epoch:  2  	Training Loss: 2711.1181640625
Test Loss:  4602958327054336.0
Valid Loss:  4563421005611008.0
Epoch:  3  	Training Loss: 4573286545489920.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:24, 15.58it/s] 26%|██▌       | 128/500 [00:07<00:23, 15.76it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.92it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.11it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.17it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.24it/s] 28%|██▊       | 138/500 [00:08<00:24, 14.51it/s] 28%|██▊       | 140/500 [00:08<00:26, 13.76it/s] 28%|██▊       | 142/500 [00:08<00:25, 14.10it/s] 29%|██▉       | 144/500 [00:09<00:24, 14.61it/s] 29%|██▉       | 146/500 [00:09<00:24, 14.56it/s] 30%|██▉       | 148/500 [00:09<00:25, 13.82it/s] 30%|███       | 150/500 [00:09<00:25, 13.49it/s] 30%|███       | 152/500 [00:09<00:24, 14.24it/s] 31%|███       | 154/500 [00:09<00:24, 14.37it/s] 31%|███       | 156/500 [00:09<00:24, 13.90it/s] 32%|███▏      | 158/500 [00:10<00:23, 14.51it/s] 32%|███▏      | 160/500 [00:10<00:22, 15.00it/s] 32%|███▏      | 162/500 [00:10<00:22, 15.34it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.64it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.77it/s] 34%|███▎      | 168/500 [00:10<00:20, 15.81it/s] 34%|███▍      | 170/500 [00:10<00:20, 15.96it/s] 34%|███▍      | 172/500 [00:10<00:22, 14.85it/s] 35%|███▍      | 174/500 [00:11<00:21, 15.26it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.54it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.81it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.72it/s] 36%|███▋      | 182/500 [00:11<00:20, 15.88it/s] 37%|███▋      | 184/500 [00:11<00:19, 15.95it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.05it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.14it/s] 38%|███▊      | 190/500 [00:12<00:19, 16.12it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.04it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.87it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.79it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.83it/s] 40%|████      | 200/500 [00:12<00:18, 15.97it/s] 40%|████      | 202/500 [00:12<00:18, 16.07it/s] 41%|████      | 204/500 [00:12<00:18, 16.13it/s] 41%|████      | 206/500 [00:13<00:18, 16.14it/s] 42%|████▏     | 208/500 [00:13<00:17, 16.25it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.97it/s] 42%|████▏     | 212/500 [00:13<00:19, 14.88it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.24it/s] 43%|████▎     | 216/500 [00:13<00:18, 15.51it/s] 44%|████▎     | 218/500 [00:13<00:18, 15.48it/s] 44%|████▍     | 220/500 [00:13<00:18, 15.45it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.48it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.54it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.46it/s] 46%|████▌     | 228/500 [00:14<00:18, 14.85it/s] 46%|████▌     | 230/500 [00:14<00:18, 14.88it/s] 46%|████▋     | 232/500 [00:14<00:17, 15.20it/s] 47%|████▋     | 234/500 [00:14<00:17, 15.29it/s] 47%|████▋     | 236/500 [00:15<00:17, 15.48it/s] 48%|████▊     | 238/500 [00:15<00:16, 15.44it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.66it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.82it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.45it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.26it/s] 50%|████▉     | 248/500 [00:15<00:16, 15.23it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:16, 15.28it/s] 50%|█████     | 252/500 [00:16<00:16, 15.49it/s] 51%|█████     | 254/500 [00:16<00:15, 15.45it/s] 51%|█████     | 256/500 [00:16<00:15, 15.68it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.77it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.95it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.06it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.00it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.09it/s] 54%|█████▎    | 268/500 [00:17<00:14, 16.09it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.94it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.07it/s] 55%|█████▍    | 274/500 [00:17<00:14, 16.13it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.23it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.28it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.25it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.30it/s] 57%|█████▋    | 284/500 [00:18<00:13, 16.29it/s] 57%|█████▋    | 286/500 [00:18<00:13, 16.34it/s] 58%|█████▊    | 288/500 [00:18<00:12, 16.35it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.32it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.36it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.34it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.31it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.32it/s] 60%|██████    | 300/500 [00:19<00:12, 16.33it/s] 60%|██████    | 302/500 [00:19<00:12, 16.38it/s] 61%|██████    | 304/500 [00:19<00:11, 16.42it/s] 61%|██████    | 306/500 [00:19<00:11, 16.42it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.44it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.39it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.36it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.35it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.38it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.32it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.25it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.31it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.32it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.31it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.34it/s] 66%|██████▌   | 330/500 [00:20<00:10, 15.89it/s] 66%|██████▋   | 332/500 [00:20<00:10, 15.71it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.63it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.73it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.90it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.97it/s] 68%|██████▊   | 342/500 [00:21<00:09, 15.92it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.07it/s] 69%|██████▉   | 346/500 [00:21<00:10, 15.08it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.44it/s] 70%|███████   | 350/500 [00:22<00:10, 14.88it/s] 70%|███████   | 352/500 [00:22<00:10, 13.78it/s] 71%|███████   | 354/500 [00:22<00:11, 13.13it/s] 71%|███████   | 356/500 [00:22<00:11, 12.98it/s] 72%|███████▏  | 358/500 [00:22<00:10, 13.49it/s] 72%|███████▏  | 360/500 [00:22<00:09, 14.20it/s] 72%|███████▏  | 362/500 [00:23<00:09, 14.60it/s] 73%|███████▎  | 364/500 [00:23<00:09, 15.00it/s] 73%|███████▎  | 366/500 [00:23<00:08, 14.95it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.32it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.46it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.67it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:08, 15.70it/s] 75%|███████▌  | 376/500 [00:23<00:07, 15.91it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.06it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.09it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.03it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.10it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.09it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.03it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.12it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.18it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.96it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.10it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.21it/s] 80%|████████  | 400/500 [00:25<00:06, 16.34it/s] 80%|████████  | 402/500 [00:25<00:05, 16.34it/s] 81%|████████  | 404/500 [00:25<00:05, 16.39it/s] 81%|████████  | 406/500 [00:25<00:05, 16.48it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.49it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.47it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.47it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.49it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.49it/s] 84%|████████▎ | 418/500 [00:26<00:04, 16.43it/s] 84%|████████▍ | 420/500 [00:26<00:05, 15.53it/s] 84%|████████▍ | 422/500 [00:26<00:05, 15.21it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.52it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.78it/s] 86%|████████▌ | 428/500 [00:27<00:04, 15.96it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.08it/s] 86%|████████▋ | 432/500 [00:27<00:04, 15.78it/s] 87%|████████▋ | 434/500 [00:27<00:04, 15.81it/s] 87%|████████▋ | 436/500 [00:27<00:04, 15.69it/s] 88%|████████▊ | 438/500 [00:27<00:03, 15.65it/s] 88%|████████▊ | 440/500 [00:27<00:03, 15.82it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.00it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.08it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.17it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.21it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.20it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.11it/s] 91%|█████████ | 454/500 [00:28<00:03, 15.01it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.14it/s] 92%|█████████▏| 458/500 [00:29<00:02, 15.30it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.46it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.54it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.80it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.02it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.95it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.74it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.78it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.87it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.97it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.82it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.92it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.89it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.87it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.05it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.96it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.08it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.18it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.25it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.28it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.14it/s]100%|██████████| 500/500 [00:31<00:00, 16.19it/s]100%|██████████| 500/500 [00:31<00:00, 15.78it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  4
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:05,  6.26s/it]  1%|          | 3/500 [00:06<13:52,  1.68s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:53,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.97it/s]  4%|▍         | 21/500 [00:20<09:43,  1.22s/it]  5%|▍         | 23/500 [00:20<06:54,  1.15it/s]  5%|▌         | 25/500 [00:20<04:56,  1.60it/s]  5%|▌         | 27/500 [00:20<03:35,  2.19it/s]  6%|▌         | 29/500 [00:20<02:39,  2.95it/s]  6%|▌         | 31/500 [00:26<09:20,  1.20s/it]  7%|▋         | 33/500 [00:27<06:40,  1.17it/s]  7%|▋         | 35/500 [00:27<04:48,  1.61it/s]  7%|▋         | 37/500 [00:27<03:30,  2.20it/s]  8%|▊         | 39/500 [00:27<02:35,  2.97it/s]  8%|▊         | 41/500 [00:33<09:05,  1.19s/it]  9%|▊         | 43/500 [00:34<06:30,  1.17it/s]  9%|▉         | 45/500 [00:34<04:41,  1.62it/s]  9%|▉         | 47/500 [00:34<03:25,  2.21it/s] 10%|▉         | 49/500 [00:34<02:31,  2.97it/s] 10%|█         | 51/500 [00:40<09:02,  1.21s/it] 11%|█         | 53/500 [00:41<06:28,  1.15it/s] 11%|█         | 55/500 [00:41<04:39,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:23,  2.17it/s] 12%|█▏        | 59/500 [00:41<02:31,  2.92it/s] 12%|█▏        | 61/500 [00:47<08:47,  1.20s/it] 13%|█▎        | 63/500 [00:48<06:17,  1.16it/s] 13%|█▎        | 65/500 [00:48<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:48<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:48<02:26,  2.95it/s] 14%|█▍        | 71/500 [00:54<08:36,  1.20s/it] 15%|█▍        | 73/500 [00:55<06:09,  1.16it/s]Epoch:  1  	Training Loss: 0.08961300551891327
Test Loss:  169.0166473388672
Valid Loss:  167.33428955078125
Epoch:  2  	Training Loss: 168.35565185546875
Test Loss:  0.16929280757904053
Valid Loss:  0.17022722959518433
Epoch:  3  	Training Loss: 0.17342016100883484
Test Loss:  0.16900624334812164
Valid Loss:  0.16992957890033722
Epoch:  4  	Training Loss: 0.1731204092502594
Test Loss:  0.1687575876712799
Valid Loss:  0.16968458890914917
Epoch:  5  	Training Loss: 0.17287074029445648
Test Loss:  0.1685093343257904
Valid Loss:  0.16944000124931335
Epoch:  6  	Training Loss: 0.172621488571167
Test Loss:  0.16826149821281433
Valid Loss:  0.16919583082199097
Epoch:  7  	Training Loss: 0.17237263917922974
Test Loss:  0.16801407933235168
Valid Loss:  0.16895204782485962
Epoch:  8  	Training Loss: 0.1721242070198059
Test Loss:  0.16776707768440247
Valid Loss:  0.1687086522579193
Epoch:  9  	Training Loss: 0.17187616229057312
Test Loss:  0.1675204634666443
Valid Loss:  0.16846568882465363
Epoch:  10  	Training Loss: 0.17162856459617615
Test Loss:  0.16727428138256073
Valid Loss:  0.16822311282157898
Epoch:  11  	Training Loss: 0.17138135433197021
Test Loss:  0.1670284867286682
Valid Loss:  0.16798096895217896
Epoch:  12  	Training Loss: 0.17113454639911652
Test Loss:  0.16680480539798737
Valid Loss:  0.1677597165107727
Epoch:  13  	Training Loss: 0.17090916633605957
Test Loss:  0.16658136248588562
Valid Loss:  0.16753873229026794
Epoch:  14  	Training Loss: 0.17068400979042053
Test Loss:  0.16635820269584656
Valid Loss:  0.16731801629066467
Epoch:  15  	Training Loss: 0.17045916616916656
Test Loss:  0.16613531112670898
Valid Loss:  0.1670975387096405
Epoch:  16  	Training Loss: 0.1702345460653305
Test Loss:  0.1659126579761505
Valid Loss:  0.16687734425067902
Epoch:  17  	Training Loss: 0.17001019418239594
Test Loss:  0.16569028794765472
Valid Loss:  0.16665738821029663
Epoch:  18  	Training Loss: 0.16978611052036285
Test Loss:  0.16546815633773804
Valid Loss:  0.16643768548965454
Epoch:  19  	Training Loss: 0.16956228017807007
Test Loss:  0.16524627804756165
Valid Loss:  0.16621825098991394
Epoch:  20  	Training Loss: 0.16933871805667877
Test Loss:  0.16502468287944794
Valid Loss:  0.16599906980991364
Epoch:  21  	Training Loss: 0.16911542415618896
Test Loss:  0.16480334103107452
Valid Loss:  0.16578015685081482
Epoch:  22  	Training Loss: 0.16889238357543945
Test Loss:  0.1645830124616623
Valid Loss:  0.1655622273683548
Epoch:  23  	Training Loss: 0.16867032647132874
Test Loss:  0.16436243057250977
Valid Loss:  0.16534405946731567
Epoch:  24  	Training Loss: 0.1684480607509613
Test Loss:  0.16414162516593933
Valid Loss:  0.16512566804885864
Epoch:  25  	Training Loss: 0.16822554171085358
Test Loss:  0.1639205813407898
Valid Loss:  0.1649070382118225
Epoch:  26  	Training Loss: 0.16800278425216675
Test Loss:  0.16369931399822235
Valid Loss:  0.16468818485736847
Epoch:  27  	Training Loss: 0.16777978837490082
Test Loss:  0.1634777933359146
Valid Loss:  0.16446909308433533
Epoch:  28  	Training Loss: 0.1675565540790558
Test Loss:  0.16325606405735016
Valid Loss:  0.16424977779388428
Epoch:  29  	Training Loss: 0.16733308136463165
Test Loss:  0.1630340963602066
Valid Loss:  0.16403023898601532
Epoch:  30  	Training Loss: 0.1671094000339508
Test Loss:  0.16281190514564514
Valid Loss:  0.16381046175956726
Epoch:  31  	Training Loss: 0.16688546538352966
Test Loss:  0.16258949041366577
Valid Loss:  0.1635904610157013
Epoch:  32  	Training Loss: 0.1666613221168518
Test Loss:  0.1623682677745819
Valid Loss:  0.16337168216705322
Epoch:  33  	Training Loss: 0.16643837094306946
Test Loss:  0.16214750707149506
Valid Loss:  0.16315330564975739
Epoch:  34  	Training Loss: 0.16621586680412292
Test Loss:  0.16192719340324402
Valid Loss:  0.16293537616729736
Epoch:  35  	Training Loss: 0.1659938246011734
Test Loss:  0.1617073118686676
Valid Loss:  0.16271789371967316
Epoch:  36  	Training Loss: 0.1657722294330597
Test Loss:  0.161487877368927
Valid Loss:  0.16250085830688477
Epoch:  37  	Training Loss: 0.1655510663986206
Test Loss:  0.1612689048051834
Valid Loss:  0.1622842252254486
Epoch:  38  	Training Loss: 0.16533035039901733
Test Loss:  0.16105034947395325
Valid Loss:  0.16206803917884827
Epoch:  39  	Training Loss: 0.16511008143424988
Test Loss:  0.1608322262763977
Valid Loss:  0.16185230016708374
Epoch:  40  	Training Loss: 0.16489022970199585
Test Loss:  0.16061456501483917
Valid Loss:  0.16163699328899384
Epoch:  41  	Training Loss: 0.16467085480690002
Test Loss:  0.16039732098579407
Valid Loss:  0.16142210364341736
Epoch:  42  	Training Loss: 0.16445188224315643
Test Loss:  0.16018031537532806
Valid Loss:  0.1612074375152588
Epoch:  43  	Training Loss: 0.16423314809799194
Test Loss:  0.15996365249156952
Valid Loss:  0.16099314391613007
Epoch:  44  	Training Loss: 0.1640147715806961
Test Loss:  0.15974734723567963
Valid Loss:  0.1607791930437088
Epoch:  45  	Training Loss: 0.16379675269126892
Test Loss:  0.1595313996076584
Valid Loss:  0.160565584897995
Epoch:  46  	Training Loss: 0.1635790765285492
Test Loss:  0.159315824508667
Valid Loss:  0.16035233438014984
Epoch:  47  	Training Loss: 0.1633617877960205
Test Loss:  0.15910059213638306
Valid Loss:  0.16013945639133453
Epoch:  48  	Training Loss: 0.16314482688903809
Test Loss:  0.15888571739196777
Valid Loss:  0.1599268913269043
Epoch:  49  	Training Loss: 0.1629282385110855
Test Loss:  0.15867117047309875
Valid Loss:  0.1597146987915039
Epoch:  50  	Training Loss: 0.1627120077610016
Test Loss:  0.15845701098442078
Valid Loss:  0.15950286388397217
Epoch:  51  	Training Loss: 0.16249613463878632
Test Loss:  0.15824319422245026
Valid Loss:  0.1592913717031479
Epoch:  52  	Training Loss: 0.1622806191444397
Test Loss:  0.15802884101867676
Valid Loss:  0.15907934308052063
Epoch:  53  	Training Loss: 0.16206452250480652
Test Loss:  0.15781481564044952
Valid Loss:  0.15886761248111725
Epoch:  54  	Training Loss: 0.1618487685918808
Test Loss:  0.15760107338428497
Valid Loss:  0.15865619480609894
Epoch:  55  	Training Loss: 0.16163332760334015
Test Loss:  0.15738767385482788
Valid Loss:  0.1584450900554657
Epoch:  56  	Training Loss: 0.16141816973686218
Test Loss:  0.15717455744743347
Valid Loss:  0.15823426842689514
Epoch:  57  	Training Loss: 0.16120335459709167
Test Loss:  0.15696175396442413
Valid Loss:  0.15802377462387085
Epoch:  58  	Training Loss: 0.16098883748054504
Test Loss:  0.15674926340579987
Valid Loss:  0.15781357884407043
Epoch:  59  	Training Loss: 0.1607746183872223
Test Loss:  0.15653708577156067
Valid Loss:  0.15760371088981628
Epoch:  60  	Training Loss: 0.1605607271194458
Test Loss:  0.15632522106170654
Valid Loss:  0.15739411115646362
Epoch:  61  	Training Loss: 0.1603471338748932
Test Loss:  0.1561136543750763
Valid Loss:  0.15718485414981842
Epoch:  62  	Training Loss: 0.16013386845588684
Test Loss:  0.1559031903743744
Valid Loss:  0.15697667002677917
Epoch:  63  	Training Loss: 0.15992167592048645
Test Loss:  0.15569287538528442
Valid Loss:  0.15676864981651306
Epoch:  64  	Training Loss: 0.15970967710018158
Test Loss:  0.15548273921012878
Valid Loss:  0.1565607786178589
Epoch:  65  	Training Loss: 0.15949782729148865
Test Loss:  0.1552727371454239
Valid Loss:  0.15635308623313904
Epoch:  66  	Training Loss: 0.15928614139556885
Test Loss:  0.15506291389465332
Valid Loss:  0.15614554286003113
Epoch:  67  	Training Loss: 0.15907461941242218
Test Loss:  0.1548532396554947
Valid Loss:  0.15593814849853516
Epoch:  68  	Training Loss: 0.15886324644088745
Test Loss:  0.15464374423027039
Valid Loss:  0.15573091804981232
Epoch:  69  	Training Loss: 0.15865203738212585
Test Loss:  0.1544344127178192
Valid Loss:  0.1555238664150238
Epoch:  70  	Training Loss: 0.1584409922361374
Test Loss:  0.15422523021697998
Valid Loss:  0.15531694889068604
Epoch:  71  	Training Loss: 0.15823011100292206
Test Loss:  0.15401619672775269
Valid Loss:  0.1551102101802826
Epoch:  72  	Training Loss: 0.15801939368247986
Test Loss:  0.15380807220935822
Valid Loss:  0.154904305934906
Epoch:  73  	Training Loss: 0.1578095406293869
Test Loss:  0.1536003202199936
Valid Loss:  0.15469878911972046
 15%|█▌        | 75/500 [00:55<04:25,  1.60it/s] 15%|█▌        | 77/500 [00:55<03:13,  2.19it/s] 16%|█▌        | 79/500 [00:55<02:22,  2.95it/s] 16%|█▌        | 81/500 [01:01<08:27,  1.21s/it] 17%|█▋        | 83/500 [01:02<06:02,  1.15it/s] 17%|█▋        | 85/500 [01:02<04:20,  1.59it/s] 17%|█▋        | 87/500 [01:02<03:10,  2.17it/s] 18%|█▊        | 89/500 [01:02<02:20,  2.92it/s] 18%|█▊        | 91/500 [01:08<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:09<03:01,  2.23it/s] 20%|█▉        | 99/500 [01:09<02:13,  3.00it/s] 20%|██        | 101/500 [01:15<07:53,  1.19s/it] 21%|██        | 103/500 [01:15<05:38,  1.17it/s] 21%|██        | 105/500 [01:15<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:16<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:16<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:22<07:41,  1.19s/it] 23%|██▎       | 113/500 [01:22<05:29,  1.17it/s] 23%|██▎       | 115/500 [01:22<03:56,  1.62it/s] 23%|██▎       | 117/500 [01:22<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:23<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:29<07:30,  1.19s/it] 25%|██▍       | 123/500 [01:29<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:29<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:29<02:48,  2.21it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.97it/s] 26%|██▌       | 131/500 [01:36<07:14,  1.18s/it] 27%|██▋       | 133/500 [01:36<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:36<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:36<02:42,  2.24it/s] 28%|██▊       | 139/500 [01:36<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:43<07:07,  1.19s/it] 29%|██▊       | 143/500 [01:43<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:43<03:40,  1.61it/s]Epoch:  74  	Training Loss: 0.15760008990764618
Test Loss:  0.1533930003643036
Valid Loss:  0.15449368953704834
Epoch:  75  	Training Loss: 0.1573910117149353
Test Loss:  0.15318603813648224
Valid Loss:  0.15428894758224487
Epoch:  76  	Training Loss: 0.15718235075473785
Test Loss:  0.15297946333885193
Valid Loss:  0.15408462285995483
Epoch:  77  	Training Loss: 0.15697407722473145
Test Loss:  0.15277329087257385
Valid Loss:  0.15388065576553345
Epoch:  78  	Training Loss: 0.15676617622375488
Test Loss:  0.152567520737648
Valid Loss:  0.1536770910024643
Epoch:  79  	Training Loss: 0.15655870735645294
Test Loss:  0.1523621380329132
Valid Loss:  0.153473898768425
Epoch:  80  	Training Loss: 0.15635159611701965
Test Loss:  0.15215712785720825
Valid Loss:  0.15327110886573792
Epoch:  81  	Training Loss: 0.1561448872089386
Test Loss:  0.15195250511169434
Valid Loss:  0.1530686616897583
Epoch:  82  	Training Loss: 0.1559385508298874
Test Loss:  0.15174783766269684
Valid Loss:  0.1528662145137787
Epoch:  83  	Training Loss: 0.1557321846485138
Test Loss:  0.15154337882995605
Valid Loss:  0.1526639759540558
Epoch:  84  	Training Loss: 0.1555260419845581
Test Loss:  0.15133914351463318
Valid Loss:  0.1524619162082672
Epoch:  85  	Training Loss: 0.15532007813453674
Test Loss:  0.15113508701324463
Valid Loss:  0.15226009488105774
Epoch:  86  	Training Loss: 0.1551143378019333
Test Loss:  0.15093126893043518
Valid Loss:  0.1520584523677826
Epoch:  87  	Training Loss: 0.15490880608558655
Test Loss:  0.15072764456272125
Valid Loss:  0.15185701847076416
Epoch:  88  	Training Loss: 0.15470348298549652
Test Loss:  0.15052422881126404
Valid Loss:  0.15165579319000244
Epoch:  89  	Training Loss: 0.1544983685016632
Test Loss:  0.15032102167606354
Valid Loss:  0.15145479142665863
Epoch:  90  	Training Loss: 0.15429344773292542
Test Loss:  0.15011802315711975
Valid Loss:  0.15125399827957153
Epoch:  91  	Training Loss: 0.15408876538276672
Test Loss:  0.14991521835327148
Valid Loss:  0.15105336904525757
Epoch:  92  	Training Loss: 0.15388426184654236
Test Loss:  0.14971262216567993
Valid Loss:  0.15085293352603912
Epoch:  93  	Training Loss: 0.15367992222309113
Test Loss:  0.14951029419898987
Valid Loss:  0.15065275132656097
Epoch:  94  	Training Loss: 0.15347588062286377
Test Loss:  0.1493082046508789
Valid Loss:  0.1504528522491455
Epoch:  95  	Training Loss: 0.1532720923423767
Test Loss:  0.1491064429283142
Valid Loss:  0.15025323629379272
Epoch:  96  	Training Loss: 0.15306860208511353
Test Loss:  0.1489049196243286
Valid Loss:  0.15005388855934143
Epoch:  97  	Training Loss: 0.15286538004875183
Test Loss:  0.1487036943435669
Valid Loss:  0.14985480904579163
Epoch:  98  	Training Loss: 0.15266242623329163
Test Loss:  0.14850273728370667
Valid Loss:  0.1496559977531433
Epoch:  99  	Training Loss: 0.1524597555398941
Test Loss:  0.14830204844474792
Valid Loss:  0.14945745468139648
Epoch:  100  	Training Loss: 0.15225735306739807
Test Loss:  0.14810164272785187
Valid Loss:  0.14925917983055115
Epoch:  101  	Training Loss: 0.15205523371696472
Test Loss:  0.1479015052318573
Valid Loss:  0.1490612030029297
Epoch:  102  	Training Loss: 0.15185338258743286
Test Loss:  0.14770346879959106
Valid Loss:  0.14886526763439178
Epoch:  103  	Training Loss: 0.15165366232395172
Test Loss:  0.1475057452917099
Valid Loss:  0.14866966009140015
Epoch:  104  	Training Loss: 0.15145422518253326
Test Loss:  0.147308349609375
Valid Loss:  0.14847436547279358
Epoch:  105  	Training Loss: 0.15125513076782227
Test Loss:  0.14711128175258636
Valid Loss:  0.14827938377857208
Epoch:  106  	Training Loss: 0.15105634927749634
Test Loss:  0.146914541721344
Valid Loss:  0.14808470010757446
Epoch:  107  	Training Loss: 0.15085789561271667
Test Loss:  0.1467180997133255
Valid Loss:  0.1478903889656067
Epoch:  108  	Training Loss: 0.15065976977348328
Test Loss:  0.14652197062969208
Valid Loss:  0.1476963460445404
Epoch:  109  	Training Loss: 0.15046194195747375
Test Loss:  0.1463261842727661
Valid Loss:  0.14750263094902039
Epoch:  110  	Training Loss: 0.1502644568681717
Test Loss:  0.14613071084022522
Valid Loss:  0.14730924367904663
Epoch:  111  	Training Loss: 0.1500672996044159
Test Loss:  0.1459355652332306
Valid Loss:  0.14711615443229675
Epoch:  112  	Training Loss: 0.14987044036388397
Test Loss:  0.14574097096920013
Valid Loss:  0.14692364633083344
Epoch:  113  	Training Loss: 0.1496741622686386
Test Loss:  0.14554673433303833
Valid Loss:  0.14673146605491638
Epoch:  114  	Training Loss: 0.1494782269001007
Test Loss:  0.14535287022590637
Valid Loss:  0.14653965830802917
Epoch:  115  	Training Loss: 0.14928266406059265
Test Loss:  0.14515933394432068
Valid Loss:  0.14634819328784943
Epoch:  116  	Training Loss: 0.14908744394779205
Test Loss:  0.14496615529060364
Valid Loss:  0.14615705609321594
Epoch:  117  	Training Loss: 0.1488925814628601
Test Loss:  0.14477333426475525
Valid Loss:  0.1459662914276123
Epoch:  118  	Training Loss: 0.14869807660579681
Test Loss:  0.14458085596561432
Valid Loss:  0.14577583968639374
Epoch:  119  	Training Loss: 0.14850389957427979
Test Loss:  0.14438873529434204
Valid Loss:  0.14558574557304382
Epoch:  120  	Training Loss: 0.1483100801706314
Test Loss:  0.14419695734977722
Valid Loss:  0.14539599418640137
Epoch:  121  	Training Loss: 0.14811661839485168
Test Loss:  0.14400547742843628
Valid Loss:  0.14520657062530518
Epoch:  122  	Training Loss: 0.14792348444461823
Test Loss:  0.14381229877471924
Valid Loss:  0.1450154185295105
Epoch:  123  	Training Loss: 0.1477285772562027
Test Loss:  0.1436193883419037
Valid Loss:  0.1448245644569397
Epoch:  124  	Training Loss: 0.14753396809101105
Test Loss:  0.1434268057346344
Valid Loss:  0.14463400840759277
Epoch:  125  	Training Loss: 0.14733967185020447
Test Loss:  0.1432345062494278
Valid Loss:  0.14444375038146973
Epoch:  126  	Training Loss: 0.14714567363262177
Test Loss:  0.14304247498512268
Valid Loss:  0.14425379037857056
Epoch:  127  	Training Loss: 0.14695195853710175
Test Loss:  0.14285077154636383
Valid Loss:  0.14406408369541168
Epoch:  128  	Training Loss: 0.1467585563659668
Test Loss:  0.14265936613082886
Valid Loss:  0.14387468993663788
Epoch:  129  	Training Loss: 0.14656543731689453
Test Loss:  0.14246824383735657
Valid Loss:  0.14368560910224915
Epoch:  130  	Training Loss: 0.14637261629104614
Test Loss:  0.14227741956710815
Valid Loss:  0.1434968113899231
Epoch:  131  	Training Loss: 0.14618010818958282
Test Loss:  0.14208686351776123
Valid Loss:  0.14330828189849854
Epoch:  132  	Training Loss: 0.145987868309021
Test Loss:  0.141896054148674
Valid Loss:  0.14311948418617249
Epoch:  133  	Training Loss: 0.14579534530639648
Test Loss:  0.1417054831981659
Valid Loss:  0.14293090999126434
Epoch:  134  	Training Loss: 0.14560306072235107
Test Loss:  0.14151515066623688
Valid Loss:  0.1427425742149353
Epoch:  135  	Training Loss: 0.14541101455688477
Test Loss:  0.14132507145404816
Valid Loss:  0.14255450665950775
Epoch:  136  	Training Loss: 0.14521922171115875
Test Loss:  0.14113526046276093
Valid Loss:  0.1423666626214981
Epoch:  137  	Training Loss: 0.14502768218517303
Test Loss:  0.1409456729888916
Valid Loss:  0.14217908680438995
Epoch:  138  	Training Loss: 0.1448363959789276
Test Loss:  0.14075633883476257
Valid Loss:  0.1419917643070221
Epoch:  139  	Training Loss: 0.14464536309242249
Test Loss:  0.14056727290153503
Valid Loss:  0.14180466532707214
Epoch:  140  	Training Loss: 0.14445456862449646
Test Loss:  0.1403784453868866
Valid Loss:  0.14161783456802368
Epoch:  141  	Training Loss: 0.14426401257514954
Test Loss:  0.14018985629081726
Valid Loss:  0.14143122732639313
Epoch:  142  	Training Loss: 0.1440737396478653
Test Loss:  0.14000283181667328
Valid Loss:  0.14124619960784912
Epoch:  143  	Training Loss: 0.1438850313425064
Test Loss:  0.1398160755634308
Valid Loss:  0.1410614252090454
Epoch:  144  	Training Loss: 0.143696591258049
Test Loss:  0.1396295726299286
Valid Loss:  0.1408768743276596
Epoch:  145  	Training Loss: 0.1435084044933319
Test Loss:  0.13944333791732788
Valid Loss:  0.14069262146949768
Epoch:  146  	Training Loss: 0.1433204710483551
Test Loss:  0.13925734162330627
 29%|██▉       | 147/500 [01:43<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:43<01:58,  2.97it/s] 30%|███       | 151/500 [01:50<06:56,  1.19s/it] 31%|███       | 153/500 [01:50<04:57,  1.17it/s] 31%|███       | 155/500 [01:50<03:33,  1.61it/s] 31%|███▏      | 157/500 [01:50<02:35,  2.20it/s] 32%|███▏      | 159/500 [01:50<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:56<06:40,  1.18s/it] 33%|███▎      | 163/500 [01:57<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:57<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:57<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:57<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:03<06:30,  1.19s/it] 35%|███▍      | 173/500 [02:03<04:38,  1.17it/s] 35%|███▌      | 175/500 [02:04<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:04<02:25,  2.21it/s] 36%|███▌      | 179/500 [02:04<01:48,  2.96it/s] 36%|███▌      | 181/500 [02:10<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:10<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:11<03:15,  1.61it/s] 37%|███▋      | 187/500 [02:11<02:21,  2.20it/s] 38%|███▊      | 189/500 [02:11<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:17<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:17<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:17<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:17<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:18<01:40,  3.00it/s] 40%|████      | 201/500 [02:24<05:58,  1.20s/it] 41%|████      | 203/500 [02:24<04:15,  1.16it/s] 41%|████      | 205/500 [02:24<03:03,  1.61it/s] 41%|████▏     | 207/500 [02:24<02:13,  2.19it/s] 42%|████▏     | 209/500 [02:25<01:38,  2.94it/s] 42%|████▏     | 211/500 [02:31<05:45,  1.20s/it] 43%|████▎     | 213/500 [02:31<04:06,  1.16it/s] 43%|████▎     | 215/500 [02:31<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:31<02:08,  2.20it/s]Valid Loss:  0.14050857722759247
Epoch:  147  	Training Loss: 0.14313280582427979
Test Loss:  0.13907158374786377
Valid Loss:  0.14032478630542755
Epoch:  148  	Training Loss: 0.14294536411762238
Test Loss:  0.13888609409332275
Valid Loss:  0.14014124870300293
Epoch:  149  	Training Loss: 0.14275819063186646
Test Loss:  0.13870081305503845
Valid Loss:  0.1399579495191574
Epoch:  150  	Training Loss: 0.14257124066352844
Test Loss:  0.13851580023765564
Valid Loss:  0.13977491855621338
Epoch:  151  	Training Loss: 0.14238454401493073
Test Loss:  0.13833102583885193
Valid Loss:  0.13959208130836487
Epoch:  152  	Training Loss: 0.1421981006860733
Test Loss:  0.1381450891494751
Valid Loss:  0.13940811157226562
Epoch:  153  	Training Loss: 0.14201048016548157
Test Loss:  0.13795940577983856
Valid Loss:  0.13922438025474548
Epoch:  154  	Training Loss: 0.14182309806346893
Test Loss:  0.13777397572994232
Valid Loss:  0.13904091715812683
Epoch:  155  	Training Loss: 0.1416359841823578
Test Loss:  0.13758878409862518
Valid Loss:  0.13885772228240967
Epoch:  156  	Training Loss: 0.14144913852214813
Test Loss:  0.13740387558937073
Valid Loss:  0.1386747658252716
Epoch:  157  	Training Loss: 0.14126254618167877
Test Loss:  0.13721925020217896
Valid Loss:  0.13849209249019623
Epoch:  158  	Training Loss: 0.1410762369632721
Test Loss:  0.1370348483324051
Valid Loss:  0.13830965757369995
Epoch:  159  	Training Loss: 0.14089015126228333
Test Loss:  0.1368507295846939
Valid Loss:  0.13812750577926636
Epoch:  160  	Training Loss: 0.14070436358451843
Test Loss:  0.13666686415672302
Valid Loss:  0.13794557750225067
Epoch:  161  	Training Loss: 0.14051881432533264
Test Loss:  0.13648325204849243
Valid Loss:  0.13776391744613647
Epoch:  162  	Training Loss: 0.14033353328704834
Test Loss:  0.13630053400993347
Valid Loss:  0.13758313655853271
Epoch:  163  	Training Loss: 0.14014914631843567
Test Loss:  0.136118084192276
Valid Loss:  0.13740262389183044
Epoch:  164  	Training Loss: 0.1399650275707245
Test Loss:  0.1359359472990036
Valid Loss:  0.13722240924835205
Epoch:  165  	Training Loss: 0.13978122174739838
Test Loss:  0.1357540786266327
Valid Loss:  0.13704244792461395
Epoch:  166  	Training Loss: 0.13959766924381256
Test Loss:  0.13557246327400208
Valid Loss:  0.13686278462409973
Epoch:  167  	Training Loss: 0.13941439986228943
Test Loss:  0.13539111614227295
Valid Loss:  0.1366833746433258
Epoch:  168  	Training Loss: 0.13923139870166779
Test Loss:  0.1352100670337677
Valid Loss:  0.13650423288345337
Epoch:  169  	Training Loss: 0.13904869556427002
Test Loss:  0.13502928614616394
Valid Loss:  0.13632537424564362
Epoch:  170  	Training Loss: 0.13886623084545135
Test Loss:  0.13484878838062286
Valid Loss:  0.13614675402641296
Epoch:  171  	Training Loss: 0.13868406414985657
Test Loss:  0.13466855883598328
Valid Loss:  0.13596847653388977
Epoch:  172  	Training Loss: 0.13850218057632446
Test Loss:  0.13448941707611084
Valid Loss:  0.13579122722148895
Epoch:  173  	Training Loss: 0.13832136988639832
Test Loss:  0.13431058824062347
Valid Loss:  0.13561426103115082
Epoch:  174  	Training Loss: 0.13814087212085724
Test Loss:  0.1341319978237152
Valid Loss:  0.13543756306171417
Epoch:  175  	Training Loss: 0.13796064257621765
Test Loss:  0.13395366072654724
Valid Loss:  0.13526111841201782
Epoch:  176  	Training Loss: 0.13778065145015717
Test Loss:  0.13377563655376434
Valid Loss:  0.13508495688438416
Epoch:  177  	Training Loss: 0.13760094344615936
Test Loss:  0.13359785079956055
Valid Loss:  0.13490906357765198
Epoch:  178  	Training Loss: 0.13742151856422424
Test Loss:  0.13342034816741943
Valid Loss:  0.1347334086894989
Epoch:  179  	Training Loss: 0.13724234700202942
Test Loss:  0.13324308395385742
Valid Loss:  0.1345580369234085
Epoch:  180  	Training Loss: 0.13706344366073608
Test Loss:  0.1330661177635193
Valid Loss:  0.1343829333782196
Epoch:  181  	Training Loss: 0.13688482344150543
Test Loss:  0.13288941979408264
Valid Loss:  0.1342080980539322
Epoch:  182  	Training Loss: 0.13670645654201508
Test Loss:  0.1327143907546997
Valid Loss:  0.1340349316596985
Epoch:  183  	Training Loss: 0.136529803276062
Test Loss:  0.13253962993621826
Valid Loss:  0.13386200368404388
Epoch:  184  	Training Loss: 0.13635340332984924
Test Loss:  0.1323651671409607
Valid Loss:  0.13368937373161316
Epoch:  185  	Training Loss: 0.13617731630802155
Test Loss:  0.132191002368927
Valid Loss:  0.13351702690124512
Epoch:  186  	Training Loss: 0.13600148260593414
Test Loss:  0.1320170760154724
Valid Loss:  0.13334494829177856
Epoch:  187  	Training Loss: 0.13582594692707062
Test Loss:  0.1318434476852417
Valid Loss:  0.1331731677055359
Epoch:  188  	Training Loss: 0.13565067946910858
Test Loss:  0.13167011737823486
Valid Loss:  0.1330016553401947
Epoch:  189  	Training Loss: 0.13547572493553162
Test Loss:  0.13149704039096832
Valid Loss:  0.132830411195755
Epoch:  190  	Training Loss: 0.13530100882053375
Test Loss:  0.13132426142692566
Valid Loss:  0.132659450173378
Epoch:  191  	Training Loss: 0.13512659072875977
Test Loss:  0.13115175068378448
Valid Loss:  0.13248875737190247
Epoch:  192  	Training Loss: 0.13495245575904846
Test Loss:  0.13097929954528809
Valid Loss:  0.13231812417507172
Epoch:  193  	Training Loss: 0.13477838039398193
Test Loss:  0.13080710172653198
Valid Loss:  0.13214772939682007
Epoch:  194  	Training Loss: 0.1346045434474945
Test Loss:  0.13063518702983856
Valid Loss:  0.1319776177406311
Epoch:  195  	Training Loss: 0.13443097472190857
Test Loss:  0.13046349585056305
Valid Loss:  0.13180774450302124
Epoch:  196  	Training Loss: 0.13425767421722412
Test Loss:  0.13029205799102783
Valid Loss:  0.1316380798816681
Epoch:  197  	Training Loss: 0.13408459722995758
Test Loss:  0.13012085855007172
Valid Loss:  0.13146871328353882
Epoch:  198  	Training Loss: 0.13391177356243134
Test Loss:  0.12994995713233948
Valid Loss:  0.13129960000514984
Epoch:  199  	Training Loss: 0.13373923301696777
Test Loss:  0.12977930903434753
Valid Loss:  0.13113072514533997
Epoch:  200  	Training Loss: 0.1335669457912445
Test Loss:  0.1296088844537735
Valid Loss:  0.13096211850643158
Epoch:  201  	Training Loss: 0.13339491188526154
Test Loss:  0.12943872809410095
Valid Loss:  0.1307937502861023
Epoch:  202  	Training Loss: 0.13322311639785767
Test Loss:  0.12926721572875977
Valid Loss:  0.13062404096126556
Epoch:  203  	Training Loss: 0.13304996490478516
Test Loss:  0.12909594178199768
Valid Loss:  0.13045458495616913
Epoch:  204  	Training Loss: 0.13287706673145294
Test Loss:  0.12892493605613708
Valid Loss:  0.1302853673696518
Epoch:  205  	Training Loss: 0.13270443677902222
Test Loss:  0.12875419855117798
Valid Loss:  0.13011643290519714
Epoch:  206  	Training Loss: 0.1325320303440094
Test Loss:  0.12858371436595917
Valid Loss:  0.1299477219581604
Epoch:  207  	Training Loss: 0.13235992193222046
Test Loss:  0.12841346859931946
Valid Loss:  0.12977929413318634
Epoch:  208  	Training Loss: 0.13218805193901062
Test Loss:  0.12824349105358124
Valid Loss:  0.1296110898256302
Epoch:  209  	Training Loss: 0.13201643526554108
Test Loss:  0.12807375192642212
Valid Loss:  0.12944313883781433
Epoch:  210  	Training Loss: 0.13184508681297302
Test Loss:  0.1279042661190033
Valid Loss:  0.12927547097206116
Epoch:  211  	Training Loss: 0.13167397677898407
Test Loss:  0.12773504853248596
Valid Loss:  0.1291080266237259
Epoch:  212  	Training Loss: 0.1315031200647354
Test Loss:  0.12756593525409698
Valid Loss:  0.1289406716823578
Epoch:  213  	Training Loss: 0.1313323676586151
Test Loss:  0.1273970752954483
Valid Loss:  0.12877361476421356
Epoch:  214  	Training Loss: 0.1311618983745575
Test Loss:  0.1272284984588623
Valid Loss:  0.12860679626464844
Epoch:  215  	Training Loss: 0.13099166750907898
Test Loss:  0.1270601749420166
Valid Loss:  0.128440260887146
Epoch:  216  	Training Loss: 0.13082173466682434
Test Loss:  0.1268921196460724
Valid Loss:  0.12827396392822266
Epoch:  217  	Training Loss: 0.1306520402431488
Test Loss:  0.12672434747219086
Valid Loss:  0.1281079649925232
Epoch:  218  	Training Loss: 0.13048264384269714
Test Loss:  0.12655682861804962
Valid Loss:  0.12794220447540283
 44%|████▍     | 219/500 [02:32<01:34,  2.96it/s] 44%|████▍     | 221/500 [02:38<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:38<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:38<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:38<02:03,  2.20it/s] 46%|████▌     | 229/500 [02:38<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:45<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:45<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:45<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:45<01:57,  2.25it/s] 48%|████▊     | 239/500 [02:45<01:27,  3.00it/s] 48%|████▊     | 241/500 [02:51<05:02,  1.17s/it] 49%|████▊     | 243/500 [02:52<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:52<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:52<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:52<01:23,  3.02it/s] 50%|█████     | 251/500 [02:58<04:53,  1.18s/it] 51%|█████     | 253/500 [02:58<03:28,  1.18it/s] 51%|█████     | 255/500 [02:59<02:29,  1.63it/s] 51%|█████▏    | 257/500 [02:59<01:49,  2.21it/s] 52%|█████▏    | 259/500 [02:59<01:22,  2.93it/s] 52%|█████▏    | 261/500 [03:05<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:05<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:05<02:22,  1.64it/s] 53%|█████▎    | 267/500 [03:05<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:06<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:12<04:31,  1.18s/it] 55%|█████▍    | 273/500 [03:12<03:13,  1.18it/s] 55%|█████▌    | 275/500 [03:12<02:18,  1.63it/s] 55%|█████▌    | 277/500 [03:12<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:13<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:19<04:22,  1.20s/it] 57%|█████▋    | 283/500 [03:19<03:06,  1.16it/s] 57%|█████▋    | 285/500 [03:19<02:13,  1.61it/s] 57%|█████▋    | 287/500 [03:19<01:37,  2.18it/s] 58%|█████▊    | 289/500 [03:19<01:12,  2.93it/s]Epoch:  219  	Training Loss: 0.13031351566314697
Test Loss:  0.12638956308364868
Valid Loss:  0.12777669727802277
Epoch:  220  	Training Loss: 0.1301446259021759
Test Loss:  0.12622259557247162
Valid Loss:  0.12761148810386658
Epoch:  221  	Training Loss: 0.1299760341644287
Test Loss:  0.12605588138103485
Valid Loss:  0.12744653224945068
Epoch:  222  	Training Loss: 0.12980769574642181
Test Loss:  0.12588953971862793
Valid Loss:  0.12728193402290344
Epoch:  223  	Training Loss: 0.12963971495628357
Test Loss:  0.12572342157363892
Valid Loss:  0.12711754441261292
Epoch:  224  	Training Loss: 0.12947197258472443
Test Loss:  0.12555748224258423
Valid Loss:  0.1269533783197403
Epoch:  225  	Training Loss: 0.1293044239282608
Test Loss:  0.12539179623126984
Valid Loss:  0.1267894208431244
Epoch:  226  	Training Loss: 0.12913711369037628
Test Loss:  0.12522634863853455
Valid Loss:  0.1266256868839264
Epoch:  227  	Training Loss: 0.12897002696990967
Test Loss:  0.1250610649585724
Valid Loss:  0.1264621615409851
Epoch:  228  	Training Loss: 0.12880313396453857
Test Loss:  0.12489602714776993
Valid Loss:  0.12629882991313934
Epoch:  229  	Training Loss: 0.1286364644765854
Test Loss:  0.12473118305206299
Valid Loss:  0.1261357069015503
Epoch:  230  	Training Loss: 0.12847000360488892
Test Loss:  0.12456658482551575
Valid Loss:  0.12597283720970154
Epoch:  231  	Training Loss: 0.12830378115177155
Test Loss:  0.12440219521522522
Valid Loss:  0.1258101761341095
Epoch:  232  	Training Loss: 0.1281377673149109
Test Loss:  0.12423592805862427
Valid Loss:  0.12564565241336823
Epoch:  233  	Training Loss: 0.1279698610305786
Test Loss:  0.12406988441944122
Valid Loss:  0.12548135221004486
Epoch:  234  	Training Loss: 0.12780219316482544
Test Loss:  0.12390408664941788
Valid Loss:  0.12531733512878418
Epoch:  235  	Training Loss: 0.12763479351997375
Test Loss:  0.12373850494623184
Valid Loss:  0.12515351176261902
Epoch:  236  	Training Loss: 0.1274675726890564
Test Loss:  0.1235731840133667
Valid Loss:  0.12498990446329117
Epoch:  237  	Training Loss: 0.12730062007904053
Test Loss:  0.12340805679559708
Valid Loss:  0.12482654303312302
Epoch:  238  	Training Loss: 0.12713387608528137
Test Loss:  0.12324320524930954
Valid Loss:  0.12466342002153397
Epoch:  239  	Training Loss: 0.1269674003124237
Test Loss:  0.12307858467102051
Valid Loss:  0.12450054287910461
Epoch:  240  	Training Loss: 0.12680116295814514
Test Loss:  0.12291418015956879
Valid Loss:  0.12433789670467377
Epoch:  241  	Training Loss: 0.12663516402244568
Test Loss:  0.12275001406669617
Valid Loss:  0.12417545914649963
Epoch:  242  	Training Loss: 0.12646937370300293
Test Loss:  0.12258847802877426
Valid Loss:  0.12401559948921204
Epoch:  243  	Training Loss: 0.1263062059879303
Test Loss:  0.12242715060710907
Valid Loss:  0.12385596334934235
Epoch:  244  	Training Loss: 0.12614327669143677
Test Loss:  0.12226602435112
Valid Loss:  0.12369650602340698
Epoch:  245  	Training Loss: 0.12598052620887756
Test Loss:  0.12210511416196823
Valid Loss:  0.12353727966547012
Epoch:  246  	Training Loss: 0.12581799924373627
Test Loss:  0.1219443827867508
Valid Loss:  0.12337825447320938
Epoch:  247  	Training Loss: 0.12565568089485168
Test Loss:  0.12178387492895126
Valid Loss:  0.12321943044662476
Epoch:  248  	Training Loss: 0.12549355626106262
Test Loss:  0.12162356823682785
Valid Loss:  0.12306079268455505
Epoch:  249  	Training Loss: 0.12533165514469147
Test Loss:  0.12146346271038055
Valid Loss:  0.12290236353874207
Epoch:  250  	Training Loss: 0.12516994774341583
Test Loss:  0.12130355089902878
Valid Loss:  0.12274414300918579
Epoch:  251  	Training Loss: 0.12500843405723572
Test Loss:  0.12114385515451431
Valid Loss:  0.12258612364530563
Epoch:  252  	Training Loss: 0.12484714388847351
Test Loss:  0.12099175155162811
Valid Loss:  0.12243558466434479
Epoch:  253  	Training Loss: 0.12469348311424255
Test Loss:  0.12083994597196579
Valid Loss:  0.12228534370660782
Epoch:  254  	Training Loss: 0.12454012781381607
Test Loss:  0.12068840116262436
Valid Loss:  0.12213534861803055
Epoch:  255  	Training Loss: 0.12438704073429108
Test Loss:  0.12053714692592621
Valid Loss:  0.12198568880558014
Epoch:  256  	Training Loss: 0.12423424422740936
Test Loss:  0.12038616836071014
Valid Loss:  0.12183627486228943
Epoch:  257  	Training Loss: 0.12408173084259033
Test Loss:  0.12023548036813736
Valid Loss:  0.12168712913990021
Epoch:  258  	Training Loss: 0.12392950057983398
Test Loss:  0.12008504569530487
Valid Loss:  0.12153825163841248
Epoch:  259  	Training Loss: 0.12377753853797913
Test Loss:  0.11993492394685745
Valid Loss:  0.12138968706130981
Epoch:  260  	Training Loss: 0.12362588942050934
Test Loss:  0.11978505551815033
Valid Loss:  0.12124137580394745
Epoch:  261  	Training Loss: 0.12347448617219925
Test Loss:  0.11963547766208649
Valid Loss:  0.12109334766864777
Epoch:  262  	Training Loss: 0.12332338094711304
Test Loss:  0.1194785088300705
Valid Loss:  0.12093799561262131
Epoch:  263  	Training Loss: 0.12316478788852692
Test Loss:  0.11932176351547241
Valid Loss:  0.12078288197517395
Epoch:  264  	Training Loss: 0.12300644814968109
Test Loss:  0.11916527152061462
Valid Loss:  0.12062801420688629
Epoch:  265  	Training Loss: 0.12284836173057556
Test Loss:  0.11900900304317474
Valid Loss:  0.12047336995601654
Epoch:  266  	Training Loss: 0.12269049882888794
Test Loss:  0.11885298788547516
Valid Loss:  0.12031897902488708
Epoch:  267  	Training Loss: 0.12253288179636002
Test Loss:  0.11869721114635468
Valid Loss:  0.12016479671001434
Epoch:  268  	Training Loss: 0.1223755031824112
Test Loss:  0.1185416430234909
Valid Loss:  0.1200108602643013
Epoch:  269  	Training Loss: 0.12221834063529968
Test Loss:  0.11838632822036743
Valid Loss:  0.11985716968774796
Epoch:  270  	Training Loss: 0.12206143885850906
Test Loss:  0.11823125183582306
Valid Loss:  0.11970369517803192
Epoch:  271  	Training Loss: 0.12190476059913635
Test Loss:  0.1180763989686966
Valid Loss:  0.11955046653747559
Epoch:  272  	Training Loss: 0.12174830585718155
Test Loss:  0.11792314052581787
Valid Loss:  0.11939879506826401
Epoch:  273  	Training Loss: 0.12159348279237747
Test Loss:  0.11777009814977646
Valid Loss:  0.11924734711647034
Epoch:  274  	Training Loss: 0.1214388832449913
Test Loss:  0.11761726438999176
Valid Loss:  0.11909613013267517
Epoch:  275  	Training Loss: 0.12128449976444244
Test Loss:  0.11746469140052795
Valid Loss:  0.1189451515674591
Epoch:  276  	Training Loss: 0.12113034725189209
Test Loss:  0.11731229722499847
Valid Loss:  0.11879438906908035
Epoch:  277  	Training Loss: 0.12097641080617905
Test Loss:  0.1171601265668869
Valid Loss:  0.11864378303289413
Epoch:  278  	Training Loss: 0.12082267552614212
Test Loss:  0.11700816452503204
Valid Loss:  0.11849343776702881
Epoch:  279  	Training Loss: 0.1206691563129425
Test Loss:  0.11685644090175629
Valid Loss:  0.1183432936668396
Epoch:  280  	Training Loss: 0.1205158680677414
Test Loss:  0.11670490354299545
Valid Loss:  0.11819333583116531
Epoch:  281  	Training Loss: 0.1203627735376358
Test Loss:  0.11655359715223312
Valid Loss:  0.11804363131523132
Epoch:  282  	Training Loss: 0.12020990252494812
Test Loss:  0.1164017766714096
Valid Loss:  0.11789338290691376
Epoch:  283  	Training Loss: 0.12005650997161865
Test Loss:  0.11625014245510101
Valid Loss:  0.1177433431148529
Epoch:  284  	Training Loss: 0.1199033111333847
Test Loss:  0.11609872430562973
Valid Loss:  0.11759350448846817
Epoch:  285  	Training Loss: 0.11975034326314926
Test Loss:  0.11594753712415695
Valid Loss:  0.11744388192892075
Epoch:  286  	Training Loss: 0.11959756165742874
Test Loss:  0.1157965213060379
Valid Loss:  0.11729444563388824
Epoch:  287  	Training Loss: 0.11944497376680374
Test Loss:  0.11564569175243378
Valid Loss:  0.11714521050453186
Epoch:  288  	Training Loss: 0.11929258704185486
Test Loss:  0.11549508571624756
Valid Loss:  0.1169961541891098
Epoch:  289  	Training Loss: 0.11914040893316269
Test Loss:  0.11534465849399567
Valid Loss:  0.11684732139110565
Epoch:  290  	Training Loss: 0.11898842453956604
Test Loss:  0.11519445478916168
Valid Loss:  0.11669865995645523
 58%|█████▊    | 291/500 [03:26<04:12,  1.21s/it] 59%|█████▊    | 293/500 [03:26<02:59,  1.15it/s] 59%|█████▉    | 295/500 [03:26<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:26<01:33,  2.18it/s] 60%|█████▉    | 299/500 [03:26<01:08,  2.93it/s] 60%|██████    | 301/500 [03:33<03:59,  1.20s/it] 61%|██████    | 303/500 [03:33<02:50,  1.16it/s] 61%|██████    | 305/500 [03:33<02:01,  1.60it/s] 61%|██████▏   | 307/500 [03:33<01:28,  2.19it/s] 62%|██████▏   | 309/500 [03:33<01:04,  2.94it/s] 62%|██████▏   | 311/500 [03:40<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:40<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:40<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:40<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:40<01:01,  2.94it/s] 64%|██████▍   | 321/500 [03:47<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:47<02:30,  1.17it/s] 65%|██████▌   | 325/500 [03:47<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:47<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:47<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:54<03:22,  1.20s/it] 67%|██████▋   | 333/500 [03:54<02:23,  1.16it/s] 67%|██████▋   | 335/500 [03:54<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:54<01:14,  2.20it/s] 68%|██████▊   | 339/500 [03:54<00:54,  2.96it/s] 68%|██████▊   | 341/500 [04:01<03:12,  1.21s/it] 69%|██████▊   | 343/500 [04:01<02:16,  1.15it/s] 69%|██████▉   | 345/500 [04:01<01:37,  1.59it/s] 69%|██████▉   | 347/500 [04:01<01:10,  2.16it/s] 70%|██████▉   | 349/500 [04:01<00:51,  2.91it/s] 70%|███████   | 351/500 [04:08<02:58,  1.20s/it] 71%|███████   | 353/500 [04:08<02:06,  1.16it/s] 71%|███████   | 355/500 [04:08<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:08<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:08<00:47,  2.95it/s] 72%|███████▏  | 361/500 [04:15<02:47,  1.21s/it]Epoch:  291  	Training Loss: 0.1188366487622261
Test Loss:  0.11504444479942322
Valid Loss:  0.11655022203922272
Epoch:  292  	Training Loss: 0.11868506669998169
Test Loss:  0.1148940920829773
Valid Loss:  0.11640143394470215
Epoch:  293  	Training Loss: 0.11853315681219101
Test Loss:  0.11474393308162689
Valid Loss:  0.11625286936759949
Epoch:  294  	Training Loss: 0.11838144063949585
Test Loss:  0.11459401994943619
Valid Loss:  0.11610452830791473
Epoch:  295  	Training Loss: 0.1182299554347992
Test Loss:  0.11444428563117981
Valid Loss:  0.1159563735127449
Epoch:  296  	Training Loss: 0.11807868629693985
Test Loss:  0.11429481208324432
Valid Loss:  0.11580844223499298
Epoch:  297  	Training Loss: 0.11792763322591782
Test Loss:  0.11414552479982376
Valid Loss:  0.11566074192523956
Epoch:  298  	Training Loss: 0.1177767962217331
Test Loss:  0.1139964610338211
Valid Loss:  0.11551323533058167
Epoch:  299  	Training Loss: 0.11762619018554688
Test Loss:  0.11384762823581696
Valid Loss:  0.11536594480276108
Epoch:  300  	Training Loss: 0.11747577786445618
Test Loss:  0.11369897425174713
Valid Loss:  0.1152188703417778
Epoch:  301  	Training Loss: 0.11732558161020279
Test Loss:  0.11355054378509521
Valid Loss:  0.11507201194763184
Epoch:  302  	Training Loss: 0.1171756163239479
Test Loss:  0.11340314149856567
Valid Loss:  0.11492615193128586
Epoch:  303  	Training Loss: 0.1170266643166542
Test Loss:  0.11325597018003464
Valid Loss:  0.11478050798177719
Epoch:  304  	Training Loss: 0.11687793582677841
Test Loss:  0.11310901492834091
Valid Loss:  0.11463508009910583
Epoch:  305  	Training Loss: 0.11672942340373993
Test Loss:  0.11296229064464569
Valid Loss:  0.11448989808559418
Epoch:  306  	Training Loss: 0.11658114939928055
Test Loss:  0.11281578242778778
Valid Loss:  0.11434493213891983
Epoch:  307  	Training Loss: 0.11643309891223907
Test Loss:  0.11266949772834778
Valid Loss:  0.1142001524567604
Epoch:  308  	Training Loss: 0.11628526449203491
Test Loss:  0.11252342164516449
Valid Loss:  0.11405561864376068
Epoch:  309  	Training Loss: 0.11613764613866806
Test Loss:  0.11237756907939911
Valid Loss:  0.11391128599643707
Epoch:  310  	Training Loss: 0.11599025130271912
Test Loss:  0.11223195493221283
Valid Loss:  0.11376715451478958
Epoch:  311  	Training Loss: 0.11584307998418808
Test Loss:  0.11208652704954147
Valid Loss:  0.11362326890230179
Epoch:  312  	Training Loss: 0.11569612473249435
Test Loss:  0.11194919049739838
Valid Loss:  0.1134873554110527
Epoch:  313  	Training Loss: 0.11555731296539307
Test Loss:  0.11181211471557617
Valid Loss:  0.11335167288780212
Epoch:  314  	Training Loss: 0.11541874706745148
Test Loss:  0.11167526990175247
Valid Loss:  0.11321626603603363
Epoch:  315  	Training Loss: 0.11528044939041138
Test Loss:  0.11153867840766907
Valid Loss:  0.11308109760284424
Epoch:  316  	Training Loss: 0.11514240503311157
Test Loss:  0.11140235513448715
Valid Loss:  0.11294616013765335
Epoch:  317  	Training Loss: 0.11500461399555206
Test Loss:  0.11126628518104553
Valid Loss:  0.11281147599220276
Epoch:  318  	Training Loss: 0.11486706137657166
Test Loss:  0.11113045364618301
Valid Loss:  0.11267708241939545
Epoch:  319  	Training Loss: 0.11472978442907333
Test Loss:  0.11099490523338318
Valid Loss:  0.11254292726516724
Epoch:  320  	Training Loss: 0.1145927757024765
Test Loss:  0.11085958778858185
Valid Loss:  0.11240901798009872
Epoch:  321  	Training Loss: 0.11445600539445877
Test Loss:  0.11072453111410141
Valid Loss:  0.11227533221244812
Epoch:  322  	Training Loss: 0.11431948840618134
Test Loss:  0.11058196425437927
Valid Loss:  0.11213424801826477
Epoch:  323  	Training Loss: 0.11417537927627563
Test Loss:  0.11043959110975266
Valid Loss:  0.11199335753917694
Epoch:  324  	Training Loss: 0.11403148621320724
Test Loss:  0.11029744148254395
Valid Loss:  0.11185269802808762
Epoch:  325  	Training Loss: 0.11388780176639557
Test Loss:  0.11015550792217255
Valid Loss:  0.11171223223209381
Epoch:  326  	Training Loss: 0.1137443482875824
Test Loss:  0.11001378297805786
Valid Loss:  0.11157198250293732
Epoch:  327  	Training Loss: 0.11360109597444534
Test Loss:  0.10987228155136108
Valid Loss:  0.11143195629119873
Epoch:  328  	Training Loss: 0.113458052277565
Test Loss:  0.10973098874092102
Valid Loss:  0.11129213124513626
Epoch:  329  	Training Loss: 0.11331523954868317
Test Loss:  0.10958992689847946
Valid Loss:  0.1111525297164917
Epoch:  330  	Training Loss: 0.11317265033721924
Test Loss:  0.10944905877113342
Valid Loss:  0.11101313680410385
Epoch:  331  	Training Loss: 0.11303026974201202
Test Loss:  0.10930842161178589
Valid Loss:  0.11087395250797272
Epoch:  332  	Training Loss: 0.11288809776306152
Test Loss:  0.10916794836521149
Valid Loss:  0.1107349619269371
Epoch:  333  	Training Loss: 0.11274611949920654
Test Loss:  0.10902771353721619
Valid Loss:  0.1105962023139
Epoch:  334  	Training Loss: 0.11260436475276947
Test Loss:  0.1088877022266388
Valid Loss:  0.11045762151479721
Epoch:  335  	Training Loss: 0.1124628409743309
Test Loss:  0.10874787718057632
Valid Loss:  0.11031925678253174
Epoch:  336  	Training Loss: 0.11232151836156845
Test Loss:  0.10860831290483475
Valid Loss:  0.11018114537000656
Epoch:  337  	Training Loss: 0.11218041181564331
Test Loss:  0.10846894979476929
Valid Loss:  0.1100432425737381
Epoch:  338  	Training Loss: 0.11203955113887787
Test Loss:  0.10832979530096054
Valid Loss:  0.10990555584430695
Epoch:  339  	Training Loss: 0.11189889907836914
Test Loss:  0.10819089412689209
Valid Loss:  0.1097680926322937
Epoch:  340  	Training Loss: 0.11175847798585892
Test Loss:  0.10805220901966095
Valid Loss:  0.10963085293769836
Epoch:  341  	Training Loss: 0.1116182878613472
Test Loss:  0.10791370272636414
Valid Loss:  0.10949379205703735
Epoch:  342  	Training Loss: 0.11147826910018921
Test Loss:  0.10777249932289124
Valid Loss:  0.10935407876968384
Epoch:  343  	Training Loss: 0.11133554577827454
Test Loss:  0.10763150453567505
Valid Loss:  0.10921454429626465
Epoch:  344  	Training Loss: 0.11119300127029419
Test Loss:  0.10749071836471558
Valid Loss:  0.10907521843910217
Epoch:  345  	Training Loss: 0.11105066537857056
Test Loss:  0.10735011100769043
Valid Loss:  0.10893607139587402
Epoch:  346  	Training Loss: 0.11090852320194244
Test Loss:  0.10720968246459961
Valid Loss:  0.1087971180677414
Epoch:  347  	Training Loss: 0.11076656728982925
Test Loss:  0.1070694774389267
Valid Loss:  0.10865837335586548
Epoch:  348  	Training Loss: 0.11062481999397278
Test Loss:  0.1069294661283493
Valid Loss:  0.10851980745792389
Epoch:  349  	Training Loss: 0.11048326641321182
Test Loss:  0.10678963363170624
Valid Loss:  0.10838142037391663
Epoch:  350  	Training Loss: 0.11034189164638519
Test Loss:  0.1066499799489975
Valid Loss:  0.10824324190616608
Epoch:  351  	Training Loss: 0.11020071804523468
Test Loss:  0.10651053488254547
Valid Loss:  0.10810525715351105
Epoch:  352  	Training Loss: 0.11005975306034088
Test Loss:  0.10638222843408585
Valid Loss:  0.10797825455665588
Epoch:  353  	Training Loss: 0.10993001610040665
Test Loss:  0.1062542051076889
Valid Loss:  0.1078515350818634
Epoch:  354  	Training Loss: 0.1098005473613739
Test Loss:  0.10612640529870987
Valid Loss:  0.10772505402565002
Epoch:  355  	Training Loss: 0.10967131704092026
Test Loss:  0.10599882900714874
Valid Loss:  0.10759879648685455
Epoch:  356  	Training Loss: 0.10954233258962631
Test Loss:  0.1058715283870697
Valid Loss:  0.10747277736663818
Epoch:  357  	Training Loss: 0.10941358655691147
Test Loss:  0.10574444383382797
Valid Loss:  0.1073470190167427
Epoch:  358  	Training Loss: 0.10928510129451752
Test Loss:  0.10561761260032654
Valid Loss:  0.10722149163484573
Epoch:  359  	Training Loss: 0.10915684700012207
Test Loss:  0.1054910197854042
Valid Loss:  0.10709618777036667
Epoch:  360  	Training Loss: 0.10902883112430573
Test Loss:  0.10536465048789978
Valid Loss:  0.10697111487388611
Epoch:  361  	Training Loss: 0.10890103131532669
Test Loss:  0.10523851215839386
Valid Loss:  0.10684625804424286
Epoch:  362  	Training Loss: 0.10877348482608795
Test Loss:  0.10510359704494476
Valid Loss:  0.10671274363994598
 73%|███████▎  | 363/500 [04:15<01:58,  1.16it/s] 73%|███████▎  | 365/500 [04:15<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:15<01:00,  2.19it/s] 74%|███████▍  | 369/500 [04:15<00:44,  2.94it/s] 74%|███████▍  | 371/500 [04:22<02:35,  1.21s/it] 75%|███████▍  | 373/500 [04:22<01:49,  1.15it/s] 75%|███████▌  | 375/500 [04:22<01:18,  1.60it/s] 75%|███████▌  | 377/500 [04:22<00:56,  2.18it/s] 76%|███████▌  | 379/500 [04:22<00:41,  2.94it/s] 76%|███████▌  | 381/500 [04:28<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:29<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:29<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:29<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:29<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:35<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:35<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:36<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:36<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:36<00:33,  3.00it/s] 80%|████████  | 401/500 [04:42<01:56,  1.18s/it] 81%|████████  | 403/500 [04:42<01:22,  1.18it/s] 81%|████████  | 405/500 [04:42<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:43<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:43<00:30,  2.95it/s] 82%|████████▏ | 411/500 [04:49<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:49<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:49<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:49<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:50<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:56<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:56<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:56<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:56<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:56<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:03<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:03<00:57,  1.17it/s]Epoch:  363  	Training Loss: 0.10863707214593887
Test Loss:  0.10496887564659119
Valid Loss:  0.10657942295074463
Epoch:  364  	Training Loss: 0.10850084573030472
Test Loss:  0.10483435541391373
Valid Loss:  0.1064462885260582
Epoch:  365  	Training Loss: 0.10836482048034668
Test Loss:  0.10470003634691238
Valid Loss:  0.10631336271762848
Epoch:  366  	Training Loss: 0.10822900384664536
Test Loss:  0.10456590354442596
Valid Loss:  0.10618061572313309
Epoch:  367  	Training Loss: 0.10809336602687836
Test Loss:  0.10443197190761566
Valid Loss:  0.10604807734489441
Epoch:  368  	Training Loss: 0.10795794427394867
Test Loss:  0.10429824143648148
Valid Loss:  0.10591572523117065
Epoch:  369  	Training Loss: 0.1078227162361145
Test Loss:  0.104164719581604
Valid Loss:  0.10578356683254242
Epoch:  370  	Training Loss: 0.10768768191337585
Test Loss:  0.10403138399124146
Valid Loss:  0.1056516170501709
Epoch:  371  	Training Loss: 0.10755284130573273
Test Loss:  0.10389824211597443
Valid Loss:  0.1055198609828949
Epoch:  372  	Training Loss: 0.10741822421550751
Test Loss:  0.1037636399269104
Valid Loss:  0.10538666695356369
Epoch:  373  	Training Loss: 0.10728210210800171
Test Loss:  0.10362924635410309
Valid Loss:  0.105253666639328
Epoch:  374  	Training Loss: 0.10714621841907501
Test Loss:  0.1034950539469719
Valid Loss:  0.10512086749076843
Epoch:  375  	Training Loss: 0.10701051354408264
Test Loss:  0.10336104780435562
Valid Loss:  0.10498824715614319
Epoch:  376  	Training Loss: 0.1068749949336052
Test Loss:  0.10322721302509308
Valid Loss:  0.10485582053661346
Epoch:  377  	Training Loss: 0.10673966258764267
Test Loss:  0.10309357941150665
Valid Loss:  0.10472357273101807
Epoch:  378  	Training Loss: 0.10660452395677567
Test Loss:  0.10296012461185455
Valid Loss:  0.10459151864051819
Epoch:  379  	Training Loss: 0.10646955668926239
Test Loss:  0.10282687097787857
Valid Loss:  0.10445964336395264
Epoch:  380  	Training Loss: 0.10633480548858643
Test Loss:  0.10269378125667572
Valid Loss:  0.10432794690132141
Epoch:  381  	Training Loss: 0.10620023310184479
Test Loss:  0.10256089270114899
Valid Loss:  0.10419643670320511
Epoch:  382  	Training Loss: 0.10606583952903748
Test Loss:  0.10243483632802963
Valid Loss:  0.10407167673110962
Epoch:  383  	Training Loss: 0.10593834519386292
Test Loss:  0.10230894386768341
Valid Loss:  0.10394707322120667
Epoch:  384  	Training Loss: 0.10581102222204208
Test Loss:  0.1021832674741745
Valid Loss:  0.10382269322872162
Epoch:  385  	Training Loss: 0.10568390786647797
Test Loss:  0.10205778479576111
Valid Loss:  0.1036984920501709
Epoch:  386  	Training Loss: 0.10555699467658997
Test Loss:  0.10193251818418503
Valid Loss:  0.10357451438903809
Epoch:  387  	Training Loss: 0.10543029010295868
Test Loss:  0.10180743783712387
Valid Loss:  0.1034507155418396
Epoch:  388  	Training Loss: 0.10530377924442291
Test Loss:  0.10168256610631943
Valid Loss:  0.10332713276147842
Epoch:  389  	Training Loss: 0.10517746955156326
Test Loss:  0.1015578880906105
Valid Loss:  0.10320372879505157
Epoch:  390  	Training Loss: 0.10505136102437973
Test Loss:  0.1014334112405777
Valid Loss:  0.10308052599430084
Epoch:  391  	Training Loss: 0.10492543876171112
Test Loss:  0.10130913555622101
Valid Loss:  0.10295753926038742
Epoch:  392  	Training Loss: 0.10479974746704102
Test Loss:  0.10118578374385834
Valid Loss:  0.10283541679382324
Epoch:  393  	Training Loss: 0.10467496514320374
Test Loss:  0.10106261074542999
Valid Loss:  0.10271354019641876
Epoch:  394  	Training Loss: 0.10455039143562317
Test Loss:  0.10093966126441956
Valid Loss:  0.1025918573141098
Epoch:  395  	Training Loss: 0.10442601144313812
Test Loss:  0.10081689804792404
Valid Loss:  0.10247035324573517
Epoch:  396  	Training Loss: 0.10430184006690979
Test Loss:  0.10069435834884644
Valid Loss:  0.10234905779361725
Epoch:  397  	Training Loss: 0.10417787730693817
Test Loss:  0.10057200491428375
Valid Loss:  0.10222797095775604
Epoch:  398  	Training Loss: 0.10405412316322327
Test Loss:  0.10044987499713898
Valid Loss:  0.10210707783699036
Epoch:  399  	Training Loss: 0.10393056273460388
Test Loss:  0.10032792389392853
Valid Loss:  0.10198637843132019
Epoch:  400  	Training Loss: 0.10380721092224121
Test Loss:  0.10020621120929718
Valid Loss:  0.10186591744422913
Epoch:  401  	Training Loss: 0.10368408262729645
Test Loss:  0.10008466243743896
Valid Loss:  0.10174563527107239
Epoch:  402  	Training Loss: 0.1035611554980278
Test Loss:  0.0999554842710495
Valid Loss:  0.10161777585744858
Epoch:  403  	Training Loss: 0.10343046486377716
Test Loss:  0.09982645511627197
Valid Loss:  0.1014900952577591
Epoch:  404  	Training Loss: 0.10329996049404144
Test Loss:  0.09969762712717056
Valid Loss:  0.10136259347200394
Epoch:  405  	Training Loss: 0.10316962003707886
Test Loss:  0.09956894814968109
Valid Loss:  0.1012352705001831
Epoch:  406  	Training Loss: 0.10303948819637299
Test Loss:  0.09944047778844833
Valid Loss:  0.10110810399055481
Epoch:  407  	Training Loss: 0.10290953516960144
Test Loss:  0.09931221604347229
Valid Loss:  0.10098115354776382
Epoch:  408  	Training Loss: 0.10277976095676422
Test Loss:  0.0991840809583664
Valid Loss:  0.10085436701774597
Epoch:  409  	Training Loss: 0.10265015810728073
Test Loss:  0.09905616194009781
Valid Loss:  0.10072776675224304
Epoch:  410  	Training Loss: 0.10252074897289276
Test Loss:  0.09892840683460236
Valid Loss:  0.10060135275125504
Epoch:  411  	Training Loss: 0.10239153355360031
Test Loss:  0.09880087524652481
Valid Loss:  0.10047513246536255
Epoch:  412  	Training Loss: 0.10226251184940338
Test Loss:  0.09868238121271133
Valid Loss:  0.10035786032676697
Epoch:  413  	Training Loss: 0.10214263200759888
Test Loss:  0.09856410324573517
Valid Loss:  0.1002407893538475
Epoch:  414  	Training Loss: 0.10202295333147049
Test Loss:  0.09844601154327393
Valid Loss:  0.10012391209602356
Epoch:  415  	Training Loss: 0.10190349072217941
Test Loss:  0.0983281135559082
Valid Loss:  0.10000722110271454
Epoch:  416  	Training Loss: 0.10178422927856445
Test Loss:  0.09821044653654099
Valid Loss:  0.09989075362682343
Epoch:  417  	Training Loss: 0.10166515409946442
Test Loss:  0.0980929583311081
Valid Loss:  0.09977445751428604
Epoch:  418  	Training Loss: 0.1015462875366211
Test Loss:  0.09797566384077072
Valid Loss:  0.09965838491916656
Epoch:  419  	Training Loss: 0.10142761468887329
Test Loss:  0.09785858541727066
Valid Loss:  0.09954247623682022
Epoch:  420  	Training Loss: 0.1013091504573822
Test Loss:  0.09774167835712433
Valid Loss:  0.09942679107189178
Epoch:  421  	Training Loss: 0.10119087249040604
Test Loss:  0.09762498736381531
Valid Loss:  0.09931129217147827
Epoch:  422  	Training Loss: 0.10107279568910599
Test Loss:  0.097493015229702
Valid Loss:  0.09918069839477539
Epoch:  423  	Training Loss: 0.10093928873538971
Test Loss:  0.09736122190952301
Valid Loss:  0.09905026853084564
Epoch:  424  	Training Loss: 0.10080596804618835
Test Loss:  0.09722957015037537
Valid Loss:  0.09892001748085022
Epoch:  425  	Training Loss: 0.10067279636859894
Test Loss:  0.09709811210632324
Valid Loss:  0.09878991544246674
Epoch:  426  	Training Loss: 0.10053978860378265
Test Loss:  0.09696680307388306
Valid Loss:  0.09865998476743698
Epoch:  427  	Training Loss: 0.1004069447517395
Test Loss:  0.0968356728553772
Valid Loss:  0.09853023290634155
Epoch:  428  	Training Loss: 0.10027427971363068
Test Loss:  0.09670470654964447
Valid Loss:  0.09840063750743866
Epoch:  429  	Training Loss: 0.10014177858829498
Test Loss:  0.09657390415668488
Valid Loss:  0.0982711911201477
Epoch:  430  	Training Loss: 0.10000945627689362
Test Loss:  0.0964432805776596
Valid Loss:  0.09814193844795227
Epoch:  431  	Training Loss: 0.09987729787826538
Test Loss:  0.09631282091140747
Valid Loss:  0.09801282733678818
Epoch:  432  	Training Loss: 0.09974530339241028
Test Loss:  0.0961894690990448
Valid Loss:  0.09789073467254639
Epoch:  433  	Training Loss: 0.09962047636508942
Test Loss:  0.09606628865003586
Valid Loss:  0.09776883572340012
Epoch:  434  	Training Loss: 0.09949582815170288
Test Loss:  0.09594325721263885
Valid Loss:  0.09764710068702698
 87%|████████▋ | 435/500 [05:03<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:03<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:03<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:10<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:10<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:10<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:10<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:10<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:16<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:17<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:17<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:17<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:17<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:23<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:23<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:24<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:24<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:24<00:10,  2.99it/s] 94%|█████████▍| 471/500 [05:30<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:30<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:30<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:31<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:37<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:37<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:37<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:38<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:44<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:44<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:44<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:44<00:00,  3.00it/s]100%|██████████| 500/500 [05:44<00:00,  1.45it/s]
Epoch:  435  	Training Loss: 0.09937138110399246
Test Loss:  0.09582048654556274
Valid Loss:  0.09752558171749115
Epoch:  436  	Training Loss: 0.09924712777137756
Test Loss:  0.09569787979125977
Valid Loss:  0.09740421175956726
Epoch:  437  	Training Loss: 0.0991230458021164
Test Loss:  0.09557542949914932
Valid Loss:  0.09728304296731949
Epoch:  438  	Training Loss: 0.09899914264678955
Test Loss:  0.0954531580209732
Valid Loss:  0.09716203808784485
Epoch:  439  	Training Loss: 0.09887543320655823
Test Loss:  0.09533105790615082
Valid Loss:  0.09704120457172394
Epoch:  440  	Training Loss: 0.09875188022851944
Test Loss:  0.09520914405584335
Valid Loss:  0.09692054241895676
Epoch:  441  	Training Loss: 0.09862850606441498
Test Loss:  0.09508740156888962
Valid Loss:  0.0968000590801239
Epoch:  442  	Training Loss: 0.09850530326366425
Test Loss:  0.0949699655175209
Valid Loss:  0.0966838076710701
Epoch:  443  	Training Loss: 0.09838645160198212
Test Loss:  0.09485267102718353
Valid Loss:  0.09656774997711182
Epoch:  444  	Training Loss: 0.09826776385307312
Test Loss:  0.09473558515310287
Valid Loss:  0.09645184874534607
Epoch:  445  	Training Loss: 0.09814925491809845
Test Loss:  0.09461864829063416
Valid Loss:  0.09633612632751465
Epoch:  446  	Training Loss: 0.09803091734647751
Test Loss:  0.09450192004442215
Valid Loss:  0.09622053802013397
Epoch:  447  	Training Loss: 0.0979127585887909
Test Loss:  0.09438533335924149
Valid Loss:  0.09610515832901001
Epoch:  448  	Training Loss: 0.09779477119445801
Test Loss:  0.09426892548799515
Valid Loss:  0.09598994255065918
Epoch:  449  	Training Loss: 0.09767694771289825
Test Loss:  0.09415269643068314
Valid Loss:  0.09587489068508148
Epoch:  450  	Training Loss: 0.09755931049585342
Test Loss:  0.09403666108846664
Valid Loss:  0.0957600325345993
Epoch:  451  	Training Loss: 0.09744186699390411
Test Loss:  0.0939207673072815
Valid Loss:  0.09564535319805145
Epoch:  452  	Training Loss: 0.09732457995414734
Test Loss:  0.09380199015140533
Valid Loss:  0.095527783036232
Epoch:  453  	Training Loss: 0.09720437228679657
Test Loss:  0.0936834067106247
Valid Loss:  0.09541040658950806
Epoch:  454  	Training Loss: 0.09708435088396072
Test Loss:  0.0935649573802948
Valid Loss:  0.09529321640729904
Epoch:  455  	Training Loss: 0.09696448594331741
Test Loss:  0.09344672411680222
Valid Loss:  0.09517620503902435
Epoch:  456  	Training Loss: 0.09684482216835022
Test Loss:  0.09332862496376038
Valid Loss:  0.095059335231781
Epoch:  457  	Training Loss: 0.09672532230615616
Test Loss:  0.09321070462465286
Valid Loss:  0.09494264423847198
Epoch:  458  	Training Loss: 0.09660598635673523
Test Loss:  0.09309300780296326
Valid Loss:  0.09482613205909729
Epoch:  459  	Training Loss: 0.09648683667182922
Test Loss:  0.09297545254230499
Valid Loss:  0.09470981359481812
Epoch:  460  	Training Loss: 0.09636788815259933
Test Loss:  0.09285809844732285
Valid Loss:  0.09459365904331207
Epoch:  461  	Training Loss: 0.09624909609556198
Test Loss:  0.09274090826511383
Valid Loss:  0.09447767585515976
Epoch:  462  	Training Loss: 0.09613049030303955
Test Loss:  0.09262506663799286
Valid Loss:  0.0943630188703537
Epoch:  463  	Training Loss: 0.09601321816444397
Test Loss:  0.09250935912132263
Valid Loss:  0.09424854069948196
Epoch:  464  	Training Loss: 0.09589613229036331
Test Loss:  0.09239383786916733
Valid Loss:  0.09413421899080276
Epoch:  465  	Training Loss: 0.09577921032905579
Test Loss:  0.09227852523326874
Valid Loss:  0.0940200537443161
Epoch:  466  	Training Loss: 0.09566245973110199
Test Loss:  0.09216334670782089
Valid Loss:  0.09390608221292496
Epoch:  467  	Training Loss: 0.09554589539766312
Test Loss:  0.09204833954572678
Valid Loss:  0.09379228204488754
Epoch:  468  	Training Loss: 0.09542949497699738
Test Loss:  0.09193352609872818
Valid Loss:  0.09367863833904266
Epoch:  469  	Training Loss: 0.09531327337026596
Test Loss:  0.09181887656450272
Valid Loss:  0.09356515854597092
Epoch:  470  	Training Loss: 0.09519722312688828
Test Loss:  0.09170439094305038
Valid Loss:  0.0934518575668335
Epoch:  471  	Training Loss: 0.09508133679628372
Test Loss:  0.09159009158611298
Valid Loss:  0.0933387354016304
Epoch:  472  	Training Loss: 0.09496563673019409
Test Loss:  0.09147709608078003
Valid Loss:  0.09322690218687057
Epoch:  473  	Training Loss: 0.09485127031803131
Test Loss:  0.0913643017411232
Valid Loss:  0.09311525523662567
Epoch:  474  	Training Loss: 0.09473705291748047
Test Loss:  0.09125165641307831
Valid Loss:  0.09300374984741211
Epoch:  475  	Training Loss: 0.09462301433086395
Test Loss:  0.09113918244838715
Valid Loss:  0.09289245307445526
Epoch:  476  	Training Loss: 0.09450915455818176
Test Loss:  0.09102688729763031
Valid Loss:  0.09278126806020737
Epoch:  477  	Training Loss: 0.0943954735994339
Test Loss:  0.09091474115848541
Valid Loss:  0.09267029166221619
Epoch:  478  	Training Loss: 0.09428194165229797
Test Loss:  0.09080278128385544
Valid Loss:  0.09255946427583694
Epoch:  479  	Training Loss: 0.09416860342025757
Test Loss:  0.09069100022315979
Valid Loss:  0.09244882315397263
Epoch:  480  	Training Loss: 0.0940554291009903
Test Loss:  0.09057936072349548
Valid Loss:  0.09233833849430084
Epoch:  481  	Training Loss: 0.09394240379333496
Test Loss:  0.09046787768602371
Valid Loss:  0.09222802519798279
Epoch:  482  	Training Loss: 0.09382957220077515
Test Loss:  0.0903518944978714
Valid Loss:  0.09211321175098419
Epoch:  483  	Training Loss: 0.09371215105056763
Test Loss:  0.09023603051900864
Valid Loss:  0.09199857711791992
Epoch:  484  	Training Loss: 0.09359486401081085
Test Loss:  0.0901203602552414
Valid Loss:  0.09188412129878998
Epoch:  485  	Training Loss: 0.0934777706861496
Test Loss:  0.09000484645366669
Valid Loss:  0.09176981449127197
Epoch:  486  	Training Loss: 0.09336084872484207
Test Loss:  0.0898895114660263
Valid Loss:  0.0916556864976883
Epoch:  487  	Training Loss: 0.09324410557746887
Test Loss:  0.08977434039115906
Valid Loss:  0.09154171496629715
Epoch:  488  	Training Loss: 0.09312750399112701
Test Loss:  0.08965933322906494
Valid Loss:  0.09142790734767914
Epoch:  489  	Training Loss: 0.09301108866930008
Test Loss:  0.08954447507858276
Valid Loss:  0.09131424129009247
Epoch:  490  	Training Loss: 0.09289483726024628
Test Loss:  0.08942978084087372
Valid Loss:  0.09120076149702072
Epoch:  491  	Training Loss: 0.09277871996164322
Test Loss:  0.089315265417099
Valid Loss:  0.09108741581439972
Epoch:  492  	Training Loss: 0.09266279637813568
Test Loss:  0.08920083940029144
Valid Loss:  0.09097419679164886
Epoch:  493  	Training Loss: 0.09254695475101471
Test Loss:  0.08908657729625702
Valid Loss:  0.09086109697818756
Epoch:  494  	Training Loss: 0.09243126213550568
Test Loss:  0.08897246420383453
Valid Loss:  0.09074816107749939
Epoch:  495  	Training Loss: 0.09231570363044739
Test Loss:  0.08885850012302399
Valid Loss:  0.09063539654016495
Epoch:  496  	Training Loss: 0.09220033884048462
Test Loss:  0.08874469995498657
Valid Loss:  0.09052275121212006
Epoch:  497  	Training Loss: 0.09208511561155319
Test Loss:  0.0886310413479805
Valid Loss:  0.09041029214859009
Epoch:  498  	Training Loss: 0.0919700562953949
Test Loss:  0.08851756900548935
Valid Loss:  0.09029796719551086
Epoch:  499  	Training Loss: 0.09185515344142914
Test Loss:  0.08840425312519073
Valid Loss:  0.09018580615520477
Epoch:  500  	Training Loss: 0.09174041450023651
Test Loss:  0.08829104900360107
Valid Loss:  0.09007379412651062
seed is  4
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:36,  6.33s/it]  1%|          | 3/500 [00:06<13:59,  1.69s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.93it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:57,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:34,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:26<12:19,  1.56s/it]  5%|▌         | 27/500 [00:26<08:43,  1.11s/it]  6%|▌         | 29/500 [00:26<06:13,  1.26it/s]  6%|▌         | 31/500 [00:33<11:47,  1.51s/it]  7%|▋         | 33/500 [00:33<08:21,  1.07s/it]  7%|▋         | 35/500 [00:33<05:58,  1.30it/s]  7%|▋         | 37/500 [00:33<04:18,  1.79it/s]  8%|▊         | 39/500 [00:33<03:09,  2.44it/s]  8%|▊         | 41/500 [00:40<09:29,  1.24s/it]  9%|▊         | 43/500 [00:40<06:46,  1.12it/s]  9%|▉         | 45/500 [00:40<04:52,  1.56it/s]  9%|▉         | 47/500 [00:40<03:32,  2.13it/s] 10%|▉         | 49/500 [00:40<02:36,  2.87it/s] 10%|█         | 51/500 [00:46<08:59,  1.20s/it] 11%|█         | 53/500 [00:47<06:25,  1.16it/s] 11%|█         | 55/500 [00:47<04:37,  1.60it/s] 11%|█▏        | 57/500 [00:47<03:22,  2.19it/s] 12%|█▏        | 59/500 [00:47<02:30,  2.94it/s] 12%|█▏        | 61/500 [00:53<08:49,  1.21s/it] 13%|█▎        | 63/500 [00:54<06:18,  1.16it/s] 13%|█▎        | 65/500 [00:54<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:54<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:54<02:26,  2.93it/s]Epoch:  1  	Training Loss: 0.08961300551891327
Test Loss:  7.622038841247559
Valid Loss:  7.7256269454956055
Epoch:  2  	Training Loss: 7.791842460632324
Test Loss:  109.8427963256836
Valid Loss:  107.800048828125
Epoch:  3  	Training Loss: 108.38026428222656
Test Loss:  1.2836568355560303
Valid Loss:  1.2816691398620605
Epoch:  4  	Training Loss: 1.2814013957977295
Test Loss:  1.28335702419281
Valid Loss:  1.2813643217086792
Epoch:  5  	Training Loss: 1.2811042070388794
Test Loss:  1.2830586433410645
Valid Loss:  1.2810649871826172
Epoch:  6  	Training Loss: 1.2808094024658203
Test Loss:  1.2827632427215576
Valid Loss:  1.2807676792144775
Epoch:  7  	Training Loss: 1.280517339706421
Test Loss:  1.2824695110321045
Valid Loss:  1.280470609664917
Epoch:  8  	Training Loss: 1.2802271842956543
Test Loss:  1.2821776866912842
Valid Loss:  1.2801752090454102
Epoch:  9  	Training Loss: 1.2799382209777832
Test Loss:  1.2818841934204102
Valid Loss:  1.2798793315887451
Epoch:  10  	Training Loss: 1.2796469926834106
Test Loss:  1.2815923690795898
Valid Loss:  1.2795861959457397
Epoch:  11  	Training Loss: 1.2793563604354858
Test Loss:  1.2812997102737427
Valid Loss:  1.2792916297912598
Epoch:  12  	Training Loss: 1.2790648937225342
Test Loss:  0.0018528716173022985
Valid Loss:  0.0020192014053463936
Epoch:  13  	Training Loss: 0.0024014245718717575
Test Loss:  0.0015633529983460903
Valid Loss:  0.0015778972301632166
Epoch:  14  	Training Loss: 0.001925668679177761
Test Loss:  0.0013068367261439562
Valid Loss:  0.0011793612502515316
Epoch:  15  	Training Loss: 0.0015652822330594063
Test Loss:  0.001138070016168058
Valid Loss:  0.0010132177267223597
Epoch:  16  	Training Loss: 0.0013912622816860676
Test Loss:  0.0010149783920496702
Valid Loss:  0.0009414344094693661
Epoch:  17  	Training Loss: 0.0013011717237532139
Test Loss:  0.0009298636578023434
Valid Loss:  0.0009068038780242205
Epoch:  18  	Training Loss: 0.0012507745996117592
Test Loss:  0.0008771285065449774
Valid Loss:  0.0008904676651582122
Epoch:  19  	Training Loss: 0.001222016173414886
Test Loss:  0.0008462087716907263
Valid Loss:  0.0008817313355393708
Epoch:  20  	Training Loss: 0.0012059046421200037
Test Loss:  0.000825021299533546
Valid Loss:  0.0008783055236563087
Epoch:  21  	Training Loss: 0.0011952222557738423
Test Loss:  0.0008114965166896582
Valid Loss:  0.0008752868743613362
Epoch:  22  	Training Loss: 0.001187613233923912
Test Loss:  0.0009751979378052056
Valid Loss:  0.0009749235468916595
Epoch:  23  	Training Loss: 0.0013051293790340424
Test Loss:  0.009807165712118149
Valid Loss:  0.009175028651952744
Epoch:  24  	Training Loss: 0.009418582543730736
Test Loss:  0.019680770114064217
Valid Loss:  0.020641297101974487
Epoch:  25  	Training Loss: 0.021216927096247673
Test Loss:  0.012009898200631142
Valid Loss:  0.01132582500576973
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0116724306717515
Test Loss:  0.040547069162130356
Valid Loss:  0.04000585153698921
Epoch:  27  	Training Loss: 0.04048388451337814
Test Loss:  0.048121899366378784
Valid Loss:  0.045421093702316284
Epoch:  28  	Training Loss: 0.046415217220783234
Test Loss:  0.0012047199998050928
Valid Loss:  0.0009221045766025782
Epoch:  29  	Training Loss: 0.001212729373946786
Test Loss:  0.0010568633442744613
Valid Loss:  0.0008136408869177103
Epoch:  30  	Training Loss: 0.0011019229423254728
Test Loss:  0.001016270718537271
Valid Loss:  0.0007860639598220587
Epoch:  31  	Training Loss: 0.0010697586694732308
Test Loss:  0.0009794632205739617
Valid Loss:  0.000764150288887322
Epoch:  32  	Training Loss: 0.0010433539282530546
Test Loss:  0.0009485546033829451
Valid Loss:  0.0007469416595995426
Epoch:  33  	Training Loss: 0.0010249328333884478
Test Loss:  0.000925107509829104
Valid Loss:  0.0007347745122388005
Epoch:  34  	Training Loss: 0.0010114316828548908
Test Loss:  0.0009054380934685469
Valid Loss:  0.0007259362027980387
Epoch:  35  	Training Loss: 0.0010015045991167426
Test Loss:  0.0008898214437067509
Valid Loss:  0.0007196442456915975
Epoch:  36  	Training Loss: 0.0009941889438778162
Test Loss:  0.0008767967810854316
Valid Loss:  0.0007151045138016343
Epoch:  37  	Training Loss: 0.0009887533960863948
Test Loss:  0.0008661827887408435
Valid Loss:  0.0007117659552022815
Epoch:  38  	Training Loss: 0.0009846296161413193
Test Loss:  0.0008573590312153101
Valid Loss:  0.0007093889871612191
Epoch:  39  	Training Loss: 0.0009814960649237037
Test Loss:  0.0008501404663547873
Valid Loss:  0.0007077368209138513
Epoch:  40  	Training Loss: 0.0009791840566322207
Test Loss:  0.0008441865211352706
Valid Loss:  0.000706556485965848
Epoch:  41  	Training Loss: 0.000977464602328837
Test Loss:  0.0008392500458285213
Valid Loss:  0.0007056420436128974
Epoch:  42  	Training Loss: 0.0009761758265085518
Test Loss:  0.0008326546521857381
Valid Loss:  0.0007036681054159999
Epoch:  43  	Training Loss: 0.0009729752782732248
Test Loss:  0.000827482552267611
Valid Loss:  0.0007018653559498489
Epoch:  44  	Training Loss: 0.0009702002862468362
Test Loss:  0.0008228805381804705
Valid Loss:  0.0007001215126365423
Epoch:  45  	Training Loss: 0.0009672861779108644
Test Loss:  0.0008187203202396631
Valid Loss:  0.0006984563660807908
Epoch:  46  	Training Loss: 0.0009644485544413328
Test Loss:  0.0008148510241881013
Valid Loss:  0.0006968359812162817
Epoch:  47  	Training Loss: 0.0009616668685339391
Test Loss:  0.0008111756760627031
Valid Loss:  0.0006952514522708952
Epoch:  48  	Training Loss: 0.0009589148103259504
Test Loss:  0.0008074776269495487
Valid Loss:  0.0006936853751540184
Epoch:  49  	Training Loss: 0.0009561922634020448
Test Loss:  0.0008035437203943729
Valid Loss:  0.0006921336753293872
Epoch:  50  	Training Loss: 0.0009534967830404639
Test Loss:  0.0007997159264050424
Valid Loss:  0.0006906046764925122
Epoch:  51  	Training Loss: 0.0009508501971140504
Test Loss:  0.0007959845243021846
Valid Loss:  0.0006891113589517772
Epoch:  52  	Training Loss: 0.0009482464520260692
Test Loss:  0.0007962816744111478
Valid Loss:  0.0006890610093250871
Epoch:  53  	Training Loss: 0.0009473984246142209
Test Loss:  0.0007939941715449095
Valid Loss:  0.0006886261398904026
Epoch:  54  	Training Loss: 0.0009466143674217165
Test Loss:  0.0007935920730233192
Valid Loss:  0.0006884930189698935
Epoch:  55  	Training Loss: 0.0009458708809688687
Test Loss:  0.000792068662121892
Valid Loss:  0.0006881909212097526
Epoch:  56  	Training Loss: 0.0009451546939089894
Test Loss:  0.0007913999143056571
Valid Loss:  0.0006880133296363056
Epoch:  57  	Training Loss: 0.0009444623719900846
Test Loss:  0.0007902659708634019
Valid Loss:  0.0006877677515149117
Epoch:  58  	Training Loss: 0.0009437879198230803
Test Loss:  0.0007895339513197541
Valid Loss:  0.0006875740946270525
Epoch:  59  	Training Loss: 0.0009431203943677247
Test Loss:  0.000788618519436568
Valid Loss:  0.0006873548845760524
Epoch:  60  	Training Loss: 0.0009424632880836725
Test Loss:  0.0007878982578404248
Valid Loss:  0.0006871566292829812
Epoch:  61  	Training Loss: 0.0009418186964467168
Test Loss:  0.0007871162379160523
Valid Loss:  0.0006869486533105373
Epoch:  62  	Training Loss: 0.0009411843493580818
Test Loss:  0.0007860757177695632
Valid Loss:  0.0006867599440738559
Epoch:  63  	Training Loss: 0.0009405383025296032
Test Loss:  0.0007853013230487704
Valid Loss:  0.0006865938194096088
Epoch:  64  	Training Loss: 0.0009399103000760078
Test Loss:  0.0007846883381716907
Valid Loss:  0.0006864466122351587
Epoch:  65  	Training Loss: 0.0009392970241606236
Test Loss:  0.0007841670885682106
Valid Loss:  0.000686309183947742
Epoch:  66  	Training Loss: 0.000938696030061692
Test Loss:  0.0007837127195671201
Valid Loss:  0.0006861808360554278
Epoch:  67  	Training Loss: 0.0009381154086440802
Test Loss:  0.0007832917617633939
Valid Loss:  0.0006860512075945735
Epoch:  68  	Training Loss: 0.000937542412430048
Test Loss:  0.0007828976958990097
Valid Loss:  0.0006859221030026674
Epoch:  69  	Training Loss: 0.0009369798353873193
Test Loss:  0.0007825218490324914
Valid Loss:  0.0006857940461486578
 14%|█▍        | 71/500 [01:00<08:27,  1.18s/it] 15%|█▍        | 73/500 [01:00<06:01,  1.18it/s] 15%|█▌        | 75/500 [01:01<04:20,  1.63it/s] 15%|█▌        | 77/500 [01:01<03:09,  2.23it/s] 16%|█▌        | 79/500 [01:01<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:07<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:07<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:07<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:08<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:08<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:14<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:14<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:14<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:14<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:15<02:13,  3.00it/s] 20%|██        | 101/500 [01:21<07:55,  1.19s/it] 21%|██        | 103/500 [01:21<05:39,  1.17it/s] 21%|██        | 105/500 [01:21<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:21<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:28<07:43,  1.19s/it] 23%|██▎       | 113/500 [01:28<05:29,  1.17it/s] 23%|██▎       | 115/500 [01:28<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:28<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:28<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:35<07:33,  1.20s/it] 25%|██▍       | 123/500 [01:35<05:23,  1.17it/s] 25%|██▌       | 125/500 [01:35<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:35<02:49,  2.19it/s] 26%|██▌       | 129/500 [01:35<02:06,  2.93it/s] 26%|██▌       | 131/500 [01:42<07:26,  1.21s/it] 27%|██▋       | 133/500 [01:42<05:18,  1.15it/s] 27%|██▋       | 135/500 [01:42<03:49,  1.59it/s] 27%|██▋       | 137/500 [01:42<02:46,  2.18it/s]Epoch:  70  	Training Loss: 0.0009364282013848424
Test Loss:  0.0007821630570106208
Valid Loss:  0.0006856662221252918
Epoch:  71  	Training Loss: 0.0009358868119306862
Test Loss:  0.0007818229496479034
Valid Loss:  0.0006855385145172477
Epoch:  72  	Training Loss: 0.0009353570640087128
Test Loss:  0.0007126062409952283
Valid Loss:  0.0006672246381640434
Epoch:  73  	Training Loss: 0.0008846845012158155
Test Loss:  0.0006677235360257328
Valid Loss:  0.0006612876895815134
Epoch:  74  	Training Loss: 0.0008555654203519225
Test Loss:  0.0006397966644726694
Valid Loss:  0.0006601298227906227
Epoch:  75  	Training Loss: 0.0008376985206268728
Test Loss:  0.0006190118147060275
Valid Loss:  0.0006610651616938412
Epoch:  76  	Training Loss: 0.0008248373633250594
Test Loss:  0.0006049663061276078
Valid Loss:  0.0006617452600039542
Epoch:  77  	Training Loss: 0.0008146885083988309
Test Loss:  0.0005921180127188563
Valid Loss:  0.0006611414137296379
Epoch:  78  	Training Loss: 0.0008056613150984049
Test Loss:  0.0005822930834256113
Valid Loss:  0.000658073928207159
Epoch:  79  	Training Loss: 0.0007977294735610485
Test Loss:  0.0005737288156524301
Valid Loss:  0.0006549583631567657
Epoch:  80  	Training Loss: 0.0007903946097940207
Test Loss:  0.0005648978403769433
Valid Loss:  0.0006521932082250714
Epoch:  81  	Training Loss: 0.0007829340174794197
Test Loss:  0.0005563278100453317
Valid Loss:  0.0006496607093140483
Epoch:  82  	Training Loss: 0.0007752373930998147
Test Loss:  0.0005479718092828989
Valid Loss:  0.000644270854536444
Epoch:  83  	Training Loss: 0.00077058095484972
Test Loss:  0.0005480680847540498
Valid Loss:  0.0006379697006195784
Epoch:  84  	Training Loss: 0.0007676325039938092
Test Loss:  0.0005456191138364375
Valid Loss:  0.000634270953014493
Epoch:  85  	Training Loss: 0.0007654493092559278
Test Loss:  0.0005450442549772561
Valid Loss:  0.0006303450209088624
Epoch:  86  	Training Loss: 0.0007635847432538867
Test Loss:  0.000543907517567277
Valid Loss:  0.0006271576276049018
Epoch:  87  	Training Loss: 0.0007619573152624071
Test Loss:  0.0005434151389636099
Valid Loss:  0.0006241562659852207
Epoch:  88  	Training Loss: 0.0007605332066304982
Test Loss:  0.0005428307922556996
Valid Loss:  0.0006215318571776152
Epoch:  89  	Training Loss: 0.0007592733018100262
Test Loss:  0.00054240005556494
Valid Loss:  0.0006191284628584981
Epoch:  90  	Training Loss: 0.0007581833051517606
Test Loss:  0.0005420182133093476
Valid Loss:  0.0006171545828692615
Epoch:  91  	Training Loss: 0.0007573241600766778
Test Loss:  0.0005416797939687967
Valid Loss:  0.0006154442671686411
Epoch:  92  	Training Loss: 0.0007565927226096392
Test Loss:  0.0005415849154815078
Valid Loss:  0.0006135956500656903
Epoch:  93  	Training Loss: 0.0007556088967248797
Test Loss:  0.0005413072067312896
Valid Loss:  0.0006119711324572563
Epoch:  94  	Training Loss: 0.0007546869455836713
Test Loss:  0.0005411807796917856
Valid Loss:  0.0006103960913605988
Epoch:  95  	Training Loss: 0.0007538375211879611
Test Loss:  0.0005410105804912746
Valid Loss:  0.0006090520182624459
Epoch:  96  	Training Loss: 0.0007530846633017063
Test Loss:  0.0005409115110523999
Valid Loss:  0.0006078605074435472
Epoch:  97  	Training Loss: 0.0007523868698626757
Test Loss:  0.0005408006254583597
Valid Loss:  0.0006067439098842442
Epoch:  98  	Training Loss: 0.0007517172489315271
Test Loss:  0.0005407168064266443
Valid Loss:  0.0006056781276129186
Epoch:  99  	Training Loss: 0.0007510712603107095
Test Loss:  0.0005406316486187279
Valid Loss:  0.0006046683993190527
Epoch:  100  	Training Loss: 0.000750448671169579
Test Loss:  0.0005405672127380967
Valid Loss:  0.0006037093698978424
Epoch:  101  	Training Loss: 0.0007498547784052789
Test Loss:  0.0005405054544098675
Valid Loss:  0.0006028012139722705
Epoch:  102  	Training Loss: 0.0007492828881368041
Test Loss:  0.0005403556860983372
Valid Loss:  0.0005995371611788869
Epoch:  103  	Training Loss: 0.0007458727341145277
Test Loss:  0.0005401991656981409
Valid Loss:  0.0005968732875771821
Epoch:  104  	Training Loss: 0.0007430354598909616
Test Loss:  0.0005399725632742047
Valid Loss:  0.000594634679146111
Epoch:  105  	Training Loss: 0.0007406029617413878
Test Loss:  0.0005396481137722731
Valid Loss:  0.0005927971797063947
Epoch:  106  	Training Loss: 0.000738476519472897
Test Loss:  0.0005391992162913084
Valid Loss:  0.0005911766784265637
Epoch:  107  	Training Loss: 0.0007365472847595811
Test Loss:  0.0005386247066780925
Valid Loss:  0.000589713454246521
Epoch:  108  	Training Loss: 0.000734760717023164
Test Loss:  0.0005379358190111816
Valid Loss:  0.0005882458062842488
Epoch:  109  	Training Loss: 0.0007330492371693254
Test Loss:  0.0005370190483517945
Valid Loss:  0.0005866644205525517
Epoch:  110  	Training Loss: 0.0007313003297895193
Test Loss:  0.0005360132781788707
Valid Loss:  0.0005851632449775934
Epoch:  111  	Training Loss: 0.000729613471776247
Test Loss:  0.0005349301500245929
Valid Loss:  0.000583728076890111
Epoch:  112  	Training Loss: 0.0007279727142304182
Test Loss:  0.0005351074505597353
Valid Loss:  0.0005828817375004292
Epoch:  113  	Training Loss: 0.0007271312060765922
Test Loss:  0.0005352111184038222
Valid Loss:  0.0005820803344249725
Epoch:  114  	Training Loss: 0.0007263415609486401
Test Loss:  0.0005352555890567601
Valid Loss:  0.0005813115858472884
Epoch:  115  	Training Loss: 0.0007256002863869071
Test Loss:  0.0005352344596758485
Valid Loss:  0.0005805590189993382
Epoch:  116  	Training Loss: 0.0007248806650750339
Test Loss:  0.0005351564032025635
Valid Loss:  0.000579842715524137
Epoch:  117  	Training Loss: 0.0007241838029585779
Test Loss:  0.0005350233986973763
Valid Loss:  0.0005791292060166597
Epoch:  118  	Training Loss: 0.0007235120865516365
Test Loss:  0.0005348584381863475
Valid Loss:  0.0005784304812550545
Epoch:  119  	Training Loss: 0.0007228574249893427
Test Loss:  0.0005346561083570123
Valid Loss:  0.0005777430487796664
Epoch:  120  	Training Loss: 0.0007222126005217433
Test Loss:  0.0005344172823242843
Valid Loss:  0.000577062601223588
Epoch:  121  	Training Loss: 0.000721581163816154
Test Loss:  0.0005341577343642712
Valid Loss:  0.0005764149245806038
Epoch:  122  	Training Loss: 0.0007209691102616489
Test Loss:  0.0005194525001570582
Valid Loss:  0.0005744603695347905
Epoch:  123  	Training Loss: 0.0007138637593016028
Test Loss:  0.0005173361278139055
Valid Loss:  0.0005723104113712907
Epoch:  124  	Training Loss: 0.0007115832413546741
Test Loss:  0.0005147510673850775
Valid Loss:  0.0005703852511942387
Epoch:  125  	Training Loss: 0.0007092191372066736
Test Loss:  0.0005119362031109631
Valid Loss:  0.0005685095675289631
Epoch:  126  	Training Loss: 0.0007068843115121126
Test Loss:  0.0005089734913781285
Valid Loss:  0.0005666007054969668
Epoch:  127  	Training Loss: 0.0007044357480481267
Test Loss:  0.0005060692201368511
Valid Loss:  0.0005647476064041257
Epoch:  128  	Training Loss: 0.0007020452758297324
Test Loss:  0.0005032423650845885
Valid Loss:  0.0005629349034279585
Epoch:  129  	Training Loss: 0.0006996996817179024
Test Loss:  0.000500496244058013
Valid Loss:  0.000561154680326581
Epoch:  130  	Training Loss: 0.0006973871495574713
Test Loss:  0.0004978014621883631
Valid Loss:  0.0005594076355919242
Epoch:  131  	Training Loss: 0.0006951286923140287
Test Loss:  0.0004952216986566782
Valid Loss:  0.0005577379488386214
Epoch:  132  	Training Loss: 0.0006929414812475443
Test Loss:  0.0004988092114217579
Valid Loss:  0.0005553507944568992
Epoch:  133  	Training Loss: 0.0006906002527102828
Test Loss:  0.0005013503832742572
Valid Loss:  0.0005540625425055623
Epoch:  134  	Training Loss: 0.0006891485536471009
Test Loss:  0.0005031067412346601
Valid Loss:  0.000553266960196197
Epoch:  135  	Training Loss: 0.0006880575092509389
Test Loss:  0.0005043352139182389
Valid Loss:  0.0005527109606191516
Epoch:  136  	Training Loss: 0.0006871420191600919
Test Loss:  0.0005052420892752707
Valid Loss:  0.0005523093277588487
Epoch:  137  	Training Loss: 0.0006863460876047611
Test Loss:  0.0005059392424300313
Valid Loss:  0.0005520001286640763
Epoch:  138  	Training Loss: 0.0006856172112748027
Test Loss:   28%|██▊       | 139/500 [01:42<02:03,  2.92it/s] 28%|██▊       | 141/500 [01:49<07:14,  1.21s/it] 29%|██▊       | 143/500 [01:49<05:09,  1.15it/s] 29%|██▉       | 145/500 [01:49<03:42,  1.59it/s] 29%|██▉       | 147/500 [01:49<02:42,  2.18it/s] 30%|██▉       | 149/500 [01:49<01:59,  2.93it/s] 30%|███       | 151/500 [01:56<06:55,  1.19s/it] 31%|███       | 153/500 [01:56<04:56,  1.17it/s] 31%|███       | 155/500 [01:56<03:33,  1.62it/s] 31%|███▏      | 157/500 [01:56<02:35,  2.20it/s] 32%|███▏      | 159/500 [01:56<01:55,  2.96it/s] 32%|███▏      | 161/500 [02:03<06:39,  1.18s/it] 33%|███▎      | 163/500 [02:03<04:45,  1.18it/s] 33%|███▎      | 165/500 [02:03<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:03<02:29,  2.22it/s] 34%|███▍      | 169/500 [02:03<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:09<06:33,  1.20s/it] 35%|███▍      | 173/500 [02:10<04:40,  1.16it/s] 35%|███▌      | 175/500 [02:10<03:22,  1.61it/s] 35%|███▌      | 177/500 [02:10<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:10<01:48,  2.95it/s] 36%|███▌      | 181/500 [02:16<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:16<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:17<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:17<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:17<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:23<06:11,  1.20s/it] 39%|███▊      | 193/500 [02:23<04:25,  1.16it/s] 39%|███▉      | 195/500 [02:24<03:10,  1.60it/s] 39%|███▉      | 197/500 [02:24<02:18,  2.18it/s] 40%|███▉      | 199/500 [02:24<01:42,  2.94it/s] 40%|████      | 201/500 [02:30<05:53,  1.18s/it] 41%|████      | 203/500 [02:30<04:11,  1.18it/s] 41%|████      | 205/500 [02:30<03:00,  1.63it/s]0.0005065112491138279
Valid Loss:  0.0005517571116797626
Epoch:  139  	Training Loss: 0.0006849450874142349
Test Loss:  0.0005070162005722523
Valid Loss:  0.0005515663069672883
Epoch:  140  	Training Loss: 0.0006843238370493054
Test Loss:  0.0005074837827123702
Valid Loss:  0.0005514159565791488
Epoch:  141  	Training Loss: 0.0006837480468675494
Test Loss:  0.000507930526509881
Valid Loss:  0.0005513041978701949
Epoch:  142  	Training Loss: 0.0006832179496996105
Test Loss:  0.0005041367840021849
Valid Loss:  0.0005501594278030097
Epoch:  143  	Training Loss: 0.0006810908089391887
Test Loss:  0.0005012707551941276
Valid Loss:  0.000548941025044769
Epoch:  144  	Training Loss: 0.0006791935884393752
Test Loss:  0.0004988050204701722
Valid Loss:  0.0005476527730934322
Epoch:  145  	Training Loss: 0.0006773659260943532
Test Loss:  0.0004965338739566505
Valid Loss:  0.0005463364068418741
Epoch:  146  	Training Loss: 0.000675499439239502
Test Loss:  0.000494218897074461
Valid Loss:  0.0005449246964417398
Epoch:  147  	Training Loss: 0.0006735479109920561
Test Loss:  0.0004919648636132479
Valid Loss:  0.000543533475138247
Epoch:  148  	Training Loss: 0.0006716257776133716
Test Loss:  0.0004897586768493056
Valid Loss:  0.0005421676905825734
Epoch:  149  	Training Loss: 0.0006697318749502301
Test Loss:  0.0004875963495578617
Valid Loss:  0.0005408263532444835
Epoch:  150  	Training Loss: 0.0006678642239421606
Test Loss:  0.0004854729922953993
Valid Loss:  0.0005395126645453274
Epoch:  151  	Training Loss: 0.0006660270737484097
Test Loss:  0.00048338682972826064
Valid Loss:  0.0005382256931625307
Epoch:  152  	Training Loss: 0.0006642142543569207
Test Loss:  0.0004830034449696541
Valid Loss:  0.0005385865224525332
Epoch:  153  	Training Loss: 0.0006632978329434991
Test Loss:  0.00048329459968954325
Valid Loss:  0.0005386744742281735
Epoch:  154  	Training Loss: 0.0006624654633924365
Test Loss:  0.0004836631705984473
Valid Loss:  0.0005387234268710017
Epoch:  155  	Training Loss: 0.0006617075996473432
Test Loss:  0.0004840429173782468
Valid Loss:  0.0005387709243223071
Epoch:  156  	Training Loss: 0.000661128549836576
Test Loss:  0.00048443087143823504
Valid Loss:  0.0005388163845054805
Epoch:  157  	Training Loss: 0.0006605772068724036
Test Loss:  0.00048481806879863143
Valid Loss:  0.0005388637073338032
Epoch:  158  	Training Loss: 0.0006600308697670698
Test Loss:  0.0004852042766287923
Valid Loss:  0.0005389137659221888
Epoch:  159  	Training Loss: 0.0006594893056899309
Test Loss:  0.00048558611888438463
Valid Loss:  0.00053896673489362
Epoch:  160  	Training Loss: 0.0006589674158021808
Test Loss:  0.0004859620821662247
Valid Loss:  0.000539023894816637
Epoch:  161  	Training Loss: 0.0006584675866179168
Test Loss:  0.00048633915139362216
Valid Loss:  0.0005390837322920561
Epoch:  162  	Training Loss: 0.0006579894688911736
Test Loss:  0.00045516627142205834
Valid Loss:  0.0005228702793829143
Epoch:  163  	Training Loss: 0.0006362267304211855
Test Loss:  0.0004275067476555705
Valid Loss:  0.0005137234693393111
Epoch:  164  	Training Loss: 0.000620897626504302
Test Loss:  0.00041000969940796494
Valid Loss:  0.0005070884362794459
Epoch:  165  	Training Loss: 0.0006096810102462769
Test Loss:  0.0003965127980336547
Valid Loss:  0.000503103481605649
Epoch:  166  	Training Loss: 0.0006008092896081507
Test Loss:  0.00038692046655341983
Valid Loss:  0.0004984615370631218
Epoch:  167  	Training Loss: 0.0005931969499215484
Test Loss:  0.0003782261919695884
Valid Loss:  0.0004946456756442785
Epoch:  168  	Training Loss: 0.0005862449761480093
Test Loss:  0.000370953930541873
Valid Loss:  0.0004912405856885016
Epoch:  169  	Training Loss: 0.0005800693761557341
Test Loss:  0.0003650822618510574
Valid Loss:  0.0004879885818809271
Epoch:  170  	Training Loss: 0.0005743430810980499
Test Loss:  0.00036008417373523116
Valid Loss:  0.00048484804574400187
Epoch:  171  	Training Loss: 0.0005689169629476964
Test Loss:  0.0003557082964107394
Valid Loss:  0.00048179220175370574
Epoch:  172  	Training Loss: 0.0005637183785438538
Test Loss:  0.000355206779204309
Valid Loss:  0.00047459136112593114
Epoch:  173  	Training Loss: 0.0005548709305003285
Test Loss:  0.00035464338725432754
Valid Loss:  0.00046960386680439115
Epoch:  174  	Training Loss: 0.0005480148829519749
Test Loss:  0.0003553649003151804
Valid Loss:  0.0004658355610445142
Epoch:  175  	Training Loss: 0.0005426896968856454
Test Loss:  0.00035603134892880917
Valid Loss:  0.00046330064651556313
Epoch:  176  	Training Loss: 0.0005385424010455608
Test Loss:  0.0003572653513401747
Valid Loss:  0.0004614554054569453
Epoch:  177  	Training Loss: 0.0005353018641471863
Test Loss:  0.0003584161459002644
Valid Loss:  0.0004602869739755988
Epoch:  178  	Training Loss: 0.0005327610415406525
Test Loss:  0.00035977992229163647
Valid Loss:  0.00045949933701194823
Epoch:  179  	Training Loss: 0.0005307578248903155
Test Loss:  0.0003610424464568496
Valid Loss:  0.0004590732278302312
Epoch:  180  	Training Loss: 0.0005291708512231708
Test Loss:  0.00036234623985365033
Valid Loss:  0.00045885000145062804
Epoch:  181  	Training Loss: 0.0005279048345983028
Test Loss:  0.00036354450276121497
Valid Loss:  0.00045881286496296525
Epoch:  182  	Training Loss: 0.00052688765572384
Test Loss:  0.0003627431869972497
Valid Loss:  0.0004567712312564254
Epoch:  183  	Training Loss: 0.0005245601641945541
Test Loss:  0.00036080763675272465
Valid Loss:  0.0004550471203401685
Epoch:  184  	Training Loss: 0.0005221798201091588
Test Loss:  0.0003590812557376921
Valid Loss:  0.0004529010329861194
Epoch:  185  	Training Loss: 0.0005198817234486341
Test Loss:  0.0003572962596081197
Valid Loss:  0.00045080104609951377
Epoch:  186  	Training Loss: 0.000517658656463027
Test Loss:  0.0003555254661478102
Valid Loss:  0.00044875324238091707
Epoch:  187  	Training Loss: 0.0005154838436283171
Test Loss:  0.00035361904883757234
Valid Loss:  0.00044661451829597354
Epoch:  188  	Training Loss: 0.0005131709622219205
Test Loss:  0.0003516922879498452
Valid Loss:  0.00044454779708757997
Epoch:  189  	Training Loss: 0.0005109206540510058
Test Loss:  0.0003497967845760286
Valid Loss:  0.0004425325896590948
Epoch:  190  	Training Loss: 0.0005087302415631711
Test Loss:  0.0003479194128885865
Valid Loss:  0.0004405702056828886
Epoch:  191  	Training Loss: 0.0005065960576757789
Test Loss:  0.0003460685256868601
Valid Loss:  0.0004386607324704528
Epoch:  192  	Training Loss: 0.0005045152502134442
Test Loss:  0.000328670721501112
Valid Loss:  0.00041864917147904634
Epoch:  193  	Training Loss: 0.0004896759055554867
Test Loss:  0.00032289070077240467
Valid Loss:  0.00041234534000977874
Epoch:  194  	Training Loss: 0.0004852802667301148
Test Loss:  0.00031907708034850657
Valid Loss:  0.0004090214497409761
Epoch:  195  	Training Loss: 0.00048275775043293834
Test Loss:  0.0003156758612021804
Valid Loss:  0.0004063173255417496
Epoch:  196  	Training Loss: 0.0004805914359167218
Test Loss:  0.000312637013848871
Valid Loss:  0.0004039451596327126
Epoch:  197  	Training Loss: 0.0004786976787727326
Test Loss:  0.00030998513102531433
Valid Loss:  0.0004020162741653621
Epoch:  198  	Training Loss: 0.00047711541992612183
Test Loss:  0.0003075875574722886
Valid Loss:  0.00040041928878054023
Epoch:  199  	Training Loss: 0.00047578790690749884
Test Loss:  0.0003053968830499798
Valid Loss:  0.0003987497475463897
Epoch:  200  	Training Loss: 0.0004746143822558224
Test Loss:  0.0003031621454283595
Valid Loss:  0.00039722866495139897
Epoch:  201  	Training Loss: 0.0004735659749712795
Test Loss:  0.0003011029039043933
Valid Loss:  0.0003958502202294767
Epoch:  202  	Training Loss: 0.00047263209125958383
Test Loss:  0.0003006441402249038
Valid Loss:  0.0003952374099753797
Epoch:  203  	Training Loss: 0.0004716234398074448
Test Loss:  0.00030026963213458657
Valid Loss:  0.0003946697397623211
Epoch:  204  	Training Loss: 0.00047066155821084976
Test Loss:  0.0002999625285156071
Valid Loss:  0.00039413804188370705
Epoch:  205  	Training Loss: 0.0004697409167420119
Test Loss:  0.00029971374897286296
Valid Loss:  0.0003936404245905578
Epoch:  206  	Training Loss: 0.00046885781921446323
Test Loss:   41%|████▏     | 207/500 [02:31<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:31<01:37,  3.00it/s] 42%|████▏     | 211/500 [02:37<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:37<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:37<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:37<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:37<01:34,  2.99it/s] 44%|████▍     | 221/500 [02:44<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:44<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:44<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:44<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:44<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:51<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:51<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:51<02:43,  1.63it/s] 47%|████▋     | 237/500 [02:51<01:58,  2.21it/s] 48%|████▊     | 239/500 [02:51<01:27,  2.97it/s] 48%|████▊     | 241/500 [02:58<05:08,  1.19s/it] 49%|████▊     | 243/500 [02:58<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:58<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:58<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:58<01:24,  2.97it/s] 50%|█████     | 251/500 [03:05<04:58,  1.20s/it] 51%|█████     | 253/500 [03:05<03:32,  1.16it/s] 51%|█████     | 255/500 [03:05<02:33,  1.60it/s] 51%|█████▏    | 257/500 [03:05<01:51,  2.18it/s] 52%|█████▏    | 259/500 [03:05<01:21,  2.94it/s] 52%|█████▏    | 261/500 [03:12<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:12<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:12<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:12<01:46,  2.19it/s] 54%|█████▍    | 269/500 [03:12<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:18<04:32,  1.19s/it] 55%|█████▍    | 273/500 [03:19<03:14,  1.17it/s]0.00029951095348224044
Valid Loss:  0.00039317423943430185
Epoch:  207  	Training Loss: 0.0004680108104366809
Test Loss:  0.0002993480011355132
Valid Loss:  0.0003927356447093189
Epoch:  208  	Training Loss: 0.0004671970382332802
Test Loss:  0.00029921825625933707
Valid Loss:  0.00039232580456882715
Epoch:  209  	Training Loss: 0.00046641399967484176
Test Loss:  0.0002991169167216867
Valid Loss:  0.00039194239070639014
Epoch:  210  	Training Loss: 0.00046566128730773926
Test Loss:  0.00029904223629273474
Valid Loss:  0.0003915840061381459
Epoch:  211  	Training Loss: 0.0004649360489565879
Test Loss:  0.000298987579299137
Valid Loss:  0.00039124858449213207
Epoch:  212  	Training Loss: 0.0004642377025447786
Test Loss:  0.0002944295993074775
Valid Loss:  0.0003888747887685895
Epoch:  213  	Training Loss: 0.0004618444945663214
Test Loss:  0.00029207541956566274
Valid Loss:  0.00038669537752866745
Epoch:  214  	Training Loss: 0.00046010984806343913
Test Loss:  0.00029048367287032306
Valid Loss:  0.0003845250466838479
Epoch:  215  	Training Loss: 0.0004585079732351005
Test Loss:  0.00028909993125125766
Valid Loss:  0.0003821866703219712
Epoch:  216  	Training Loss: 0.00045685184886679053
Test Loss:  0.00028782026492990553
Valid Loss:  0.0003798904363065958
Epoch:  217  	Training Loss: 0.00045523757580667734
Test Loss:  0.00028659796225838363
Valid Loss:  0.00037764228181913495
Epoch:  218  	Training Loss: 0.0004536636406555772
Test Loss:  0.0002854175691027194
Valid Loss:  0.0003753880155272782
Epoch:  219  	Training Loss: 0.00045212876284494996
Test Loss:  0.00028427192592062056
Valid Loss:  0.00037295708898454905
Epoch:  220  	Training Loss: 0.0004506314289756119
Test Loss:  0.0002831634774338454
Valid Loss:  0.0003705797716975212
Epoch:  221  	Training Loss: 0.00044916951446793973
Test Loss:  0.00028208113508298993
Valid Loss:  0.0003682608949020505
Epoch:  222  	Training Loss: 0.00044774083653464913
Test Loss:  0.00028047157684341073
Valid Loss:  0.00036584126064553857
Epoch:  223  	Training Loss: 0.0004457492323126644
Test Loss:  0.00027973001124337316
Valid Loss:  0.00036335457116365433
Epoch:  224  	Training Loss: 0.0004438416217453778
Test Loss:  0.00027873669750988483
Valid Loss:  0.0003609703271649778
Epoch:  225  	Training Loss: 0.0004419392498675734
Test Loss:  0.0002777691406663507
Valid Loss:  0.0003584471414797008
Epoch:  226  	Training Loss: 0.00044002244248986244
Test Loss:  0.00027675722958520055
Valid Loss:  0.0003559955512173474
Epoch:  227  	Training Loss: 0.0004381680046208203
Test Loss:  0.00027577404398471117
Valid Loss:  0.0003536100557539612
Epoch:  228  	Training Loss: 0.00043637159978970885
Test Loss:  0.0002748008701018989
Valid Loss:  0.00035128724994137883
Epoch:  229  	Training Loss: 0.0004346318310126662
Test Loss:  0.0002738440234679729
Valid Loss:  0.0003490162780508399
Epoch:  230  	Training Loss: 0.00043293609633110464
Test Loss:  0.0002728307154029608
Valid Loss:  0.00034662586404010653
Epoch:  231  	Training Loss: 0.0004311456286814064
Test Loss:  0.0002717910101637244
Valid Loss:  0.0003442957531660795
Epoch:  232  	Training Loss: 0.00042940484127029777
Test Loss:  0.00026974378852173686
Valid Loss:  0.00033292087027803063
Epoch:  233  	Training Loss: 0.00042216849396936595
Test Loss:  0.00026639108546078205
Valid Loss:  0.00032761989859864116
Epoch:  234  	Training Loss: 0.0004186847363598645
Test Loss:  0.0002632665273267776
Valid Loss:  0.00032382371136918664
Epoch:  235  	Training Loss: 0.00041571923065930605
Test Loss:  0.00026090105529874563
Valid Loss:  0.0003202510706614703
Epoch:  236  	Training Loss: 0.00041283463360741735
Test Loss:  0.00025877292500808835
Valid Loss:  0.0003171202843077481
Epoch:  237  	Training Loss: 0.0004101154045201838
Test Loss:  0.0002569782664068043
Valid Loss:  0.000314228527713567
Epoch:  238  	Training Loss: 0.00040749635081738234
Test Loss:  0.000255303893936798
Valid Loss:  0.00031149317510426044
Epoch:  239  	Training Loss: 0.0004049585259053856
Test Loss:  0.0002535080420784652
Valid Loss:  0.00030887650791555643
Epoch:  240  	Training Loss: 0.0004024238442070782
Test Loss:  0.0002517743851058185
Valid Loss:  0.00030609354143962264
Epoch:  241  	Training Loss: 0.00039962519076652825
Test Loss:  0.0002499153488315642
Valid Loss:  0.0003030372899957001
Epoch:  242  	Training Loss: 0.0003966836375184357
Test Loss:  0.00024828797904774547
Valid Loss:  0.00030099318246357143
Epoch:  243  	Training Loss: 0.000394859176594764
Test Loss:  0.0002468600869178772
Valid Loss:  0.0002990609500557184
Epoch:  244  	Training Loss: 0.0003930733655579388
Test Loss:  0.00024554014089517295
Valid Loss:  0.0002971272624563426
Epoch:  245  	Training Loss: 0.0003912434622179717
Test Loss:  0.0002443202247377485
Valid Loss:  0.00029527273727580905
Epoch:  246  	Training Loss: 0.0003894622204825282
Test Loss:  0.00024317647330462933
Valid Loss:  0.00029348302632570267
Epoch:  247  	Training Loss: 0.000387677107937634
Test Loss:  0.00024205510271713138
Valid Loss:  0.00029166473541408777
Epoch:  248  	Training Loss: 0.0003858505515381694
Test Loss:  0.00024097580171655864
Valid Loss:  0.000289901508949697
Epoch:  249  	Training Loss: 0.0003840664867311716
Test Loss:  0.00023993196373339742
Valid Loss:  0.0002881898544728756
Epoch:  250  	Training Loss: 0.00038232459337450564
Test Loss:  0.00023892542230896652
Valid Loss:  0.0002865309943445027
Epoch:  251  	Training Loss: 0.0003806237946264446
Test Loss:  0.00023794881417416036
Valid Loss:  0.00028491634293459356
Epoch:  252  	Training Loss: 0.00037896077265031636
Test Loss:  0.00023820919159334153
Valid Loss:  0.0002832022146321833
Epoch:  253  	Training Loss: 0.0003765572910197079
Test Loss:  0.0002375616750214249
Valid Loss:  0.00028140447102487087
Epoch:  254  	Training Loss: 0.000374354247469455
Test Loss:  0.00023641438747290522
Valid Loss:  0.0002795987529680133
Epoch:  255  	Training Loss: 0.0003722567344084382
Test Loss:  0.0002351975708734244
Valid Loss:  0.0002778522903099656
Epoch:  256  	Training Loss: 0.0003702648973558098
Test Loss:  0.00023397098993882537
Valid Loss:  0.0002761675277724862
Epoch:  257  	Training Loss: 0.0003683555405586958
Test Loss:  0.00023270444944500923
Valid Loss:  0.0002744586090557277
Epoch:  258  	Training Loss: 0.0003663612878881395
Test Loss:  0.0002313820441486314
Valid Loss:  0.00027271604631096125
Epoch:  259  	Training Loss: 0.0003643066738732159
Test Loss:  0.00023005844559520483
Valid Loss:  0.00027101513114757836
Epoch:  260  	Training Loss: 0.0003623156517278403
Test Loss:  0.00022875628201290965
Valid Loss:  0.0002693668648134917
Epoch:  261  	Training Loss: 0.00036038365215063095
Test Loss:  0.00022749218624085188
Valid Loss:  0.0002677692682482302
Epoch:  262  	Training Loss: 0.0003585093072615564
Test Loss:  0.00022033073764760047
Valid Loss:  0.00026121249538846314
Epoch:  263  	Training Loss: 0.0003519185702316463
Test Loss:  0.00021461074356921017
Valid Loss:  0.0002563139423727989
Epoch:  264  	Training Loss: 0.0003470839001238346
Test Loss:  0.00021068147907499224
Valid Loss:  0.00025269004981964827
Epoch:  265  	Training Loss: 0.00034313261858187616
Test Loss:  0.0002079322439385578
Valid Loss:  0.00024969936930574477
Epoch:  266  	Training Loss: 0.00033932493533939123
Test Loss:  0.00020518673409242183
Valid Loss:  0.0002468912280164659
Epoch:  267  	Training Loss: 0.0003360073023941368
Test Loss:  0.00020320208568591624
Valid Loss:  0.000244508235482499
Epoch:  268  	Training Loss: 0.0003329640021547675
Test Loss:  0.00020147992472629994
Valid Loss:  0.00024229174596257508
Epoch:  269  	Training Loss: 0.0003300919197499752
Test Loss:  0.0002000037202378735
Valid Loss:  0.00024022074649110436
Epoch:  270  	Training Loss: 0.0003273382317274809
Test Loss:  0.00019868028175551444
Valid Loss:  0.00023824772506486624
Epoch:  271  	Training Loss: 0.0003246764244977385
Test Loss:  0.0001974765327759087
Valid Loss:  0.00023635881370864809
Epoch:  272  	Training Loss: 0.0003220915677957237
Test Loss:  0.00019578702631406486
Valid Loss:  0.00023321800108533353
Epoch:  273  	Training Loss: 0.0003176567261107266
Test Loss:  0.00019535914179868996
Valid Loss:  0.00023124634753912687
 55%|█████▌    | 275/500 [03:19<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:19<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:19<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:25<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:25<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:26<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:26<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:26<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:32<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:32<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:32<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:32<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:33<01:06,  3.01it/s] 60%|██████    | 301/500 [03:39<03:55,  1.18s/it] 61%|██████    | 303/500 [03:39<02:46,  1.18it/s] 61%|██████    | 305/500 [03:39<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:39<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:39<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:46<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:46<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:46<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:46<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:46<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:53<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:53<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:53<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:53<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:53<00:56,  3.01it/s] 66%|██████▌   | 331/500 [04:00<03:26,  1.22s/it] 67%|██████▋   | 333/500 [04:00<02:26,  1.14it/s] 67%|██████▋   | 335/500 [04:00<01:44,  1.58it/s] 67%|██████▋   | 337/500 [04:00<01:15,  2.16it/s] 68%|██████▊   | 339/500 [04:00<00:55,  2.91it/s]Epoch:  274  	Training Loss: 0.0003141718916594982
Test Loss:  0.00019497860921546817
Valid Loss:  0.0002297277533216402
Epoch:  275  	Training Loss: 0.0003114133724011481
Test Loss:  0.00019498070469126105
Valid Loss:  0.0002287123934365809
Epoch:  276  	Training Loss: 0.0003092125116381794
Test Loss:  0.00019509147386997938
Valid Loss:  0.0002279921609442681
Epoch:  277  	Training Loss: 0.0003074405249208212
Test Loss:  0.000195333210285753
Valid Loss:  0.00022751634242013097
Epoch:  278  	Training Loss: 0.00030603271443396807
Test Loss:  0.00019563190289773047
Valid Loss:  0.00022720597917214036
Epoch:  279  	Training Loss: 0.0003048850048799068
Test Loss:  0.00019596831407397985
Valid Loss:  0.0002270172262797132
Epoch:  280  	Training Loss: 0.00030393750057555735
Test Loss:  0.00019631869508884847
Valid Loss:  0.0002269145188620314
Epoch:  281  	Training Loss: 0.00030314610921777785
Test Loss:  0.00019667026936076581
Valid Loss:  0.000226872245548293
Epoch:  282  	Training Loss: 0.00030247712857089937
Test Loss:  0.00019737878756131977
Valid Loss:  0.00022700827685184777
Epoch:  283  	Training Loss: 0.00030178914312273264
Test Loss:  0.00019779003923758864
Valid Loss:  0.00022706881281919777
Epoch:  284  	Training Loss: 0.00030125927878543735
Test Loss:  0.0001983738038688898
Valid Loss:  0.0002272742276545614
Epoch:  285  	Training Loss: 0.0003008407074958086
Test Loss:  0.00019873630662914366
Valid Loss:  0.0002274001599289477
Epoch:  286  	Training Loss: 0.0003005009493790567
Test Loss:  0.00019918716861866415
Valid Loss:  0.00022759637795388699
Epoch:  287  	Training Loss: 0.00030021904967725277
Test Loss:  0.00019948113185819238
Valid Loss:  0.00022772536613047123
Epoch:  288  	Training Loss: 0.00029997684760019183
Test Loss:  0.00019981968216598034
Valid Loss:  0.00022788871137890965
Epoch:  289  	Training Loss: 0.00029976406949572265
Test Loss:  0.00020004596444778144
Valid Loss:  0.0002279973414260894
Epoch:  290  	Training Loss: 0.00029957201331853867
Test Loss:  0.00020029459847137332
Valid Loss:  0.0002281210763612762
Epoch:  291  	Training Loss: 0.00029939651722088456
Test Loss:  0.000200465670786798
Valid Loss:  0.00022820690355729312
Epoch:  292  	Training Loss: 0.0002992326335515827
Test Loss:  0.00020038007642142475
Valid Loss:  0.00022811314556747675
Epoch:  293  	Training Loss: 0.0002989560307469219
Test Loss:  0.00020030149607919157
Valid Loss:  0.00022802964667789638
Epoch:  294  	Training Loss: 0.0002986991312354803
Test Loss:  0.00020023285469505936
Valid Loss:  0.00022795949189458042
Epoch:  295  	Training Loss: 0.0002984580351039767
Test Loss:  0.00020017134374938905
Valid Loss:  0.00022790055663790554
Epoch:  296  	Training Loss: 0.00029822043143212795
Test Loss:  0.00020011657034046948
Valid Loss:  0.000227852986427024
Epoch:  297  	Training Loss: 0.0002980013960041106
Test Loss:  0.0002000702079385519
Valid Loss:  0.00022781438019592315
Epoch:  298  	Training Loss: 0.000297796941595152
Test Loss:  0.0002000324020627886
Valid Loss:  0.00022778281709179282
Epoch:  299  	Training Loss: 0.0002976058458443731
Test Loss:  0.00020000117365270853
Valid Loss:  0.0002277593594044447
Epoch:  300  	Training Loss: 0.00029742642072960734
Test Loss:  0.00019997541676275432
Valid Loss:  0.00022774151875637472
Epoch:  301  	Training Loss: 0.0002972573565784842
Test Loss:  0.00019995540787931532
Valid Loss:  0.0002277278690598905
Epoch:  302  	Training Loss: 0.0002970981877297163
Test Loss:  0.0001998821971938014
Valid Loss:  0.00022767586051486433
Epoch:  303  	Training Loss: 0.000297009275527671
Test Loss:  0.00019995460752397776
Valid Loss:  0.00022770567738916725
Epoch:  304  	Training Loss: 0.0002969233610201627
Test Loss:  0.0001999961823457852
Valid Loss:  0.00022771809017285705
Epoch:  305  	Training Loss: 0.0002968397457152605
Test Loss:  0.00020004171528853476
Valid Loss:  0.00022773296223022044
Epoch:  306  	Training Loss: 0.0002967574109788984
Test Loss:  0.00020008443971164525
Valid Loss:  0.00022774640819989145
Epoch:  307  	Training Loss: 0.00029667606577277184
Test Loss:  0.0002001261163968593
Valid Loss:  0.00022776128025725484
Epoch:  308  	Training Loss: 0.00029659748543053865
Test Loss:  0.00020016657072119415
Valid Loss:  0.0002277760358992964
Epoch:  309  	Training Loss: 0.00029652059311047196
Test Loss:  0.00020020514784846455
Valid Loss:  0.00022779138816986233
Epoch:  310  	Training Loss: 0.0002964463201351464
Test Loss:  0.00020024337572976947
Valid Loss:  0.00022780569270253181
Epoch:  311  	Training Loss: 0.0002963725128211081
Test Loss:  0.0002002803230425343
Valid Loss:  0.00022781960433349013
Epoch:  312  	Training Loss: 0.00029630062635987997
Test Loss:  0.0002003850240726024
Valid Loss:  0.00022787810303270817
Epoch:  313  	Training Loss: 0.00029626485775224864
Test Loss:  0.0002004557172767818
Valid Loss:  0.00022791647643316537
Epoch:  314  	Training Loss: 0.00029623060254380107
Test Loss:  0.0002005058340728283
Valid Loss:  0.0002279450709465891
Epoch:  315  	Training Loss: 0.0002961978898383677
Test Loss:  0.00020054327615071088
Valid Loss:  0.00022796695702709258
Epoch:  316  	Training Loss: 0.00029616570100188255
Test Loss:  0.0002005741116590798
Valid Loss:  0.00022798411373514682
Epoch:  317  	Training Loss: 0.0002961339196190238
Test Loss:  0.0002005989954341203
Valid Loss:  0.00022799981525167823
Epoch:  318  	Training Loss: 0.0002961039135698229
Test Loss:  0.0002006203430937603
Valid Loss:  0.00022801132581662387
Epoch:  319  	Training Loss: 0.0002960727724712342
Test Loss:  0.00020063867850694805
Valid Loss:  0.00022802388411946595
Epoch:  320  	Training Loss: 0.00029603647999465466
Test Loss:  0.00020065324497409165
Valid Loss:  0.0002280338085256517
Epoch:  321  	Training Loss: 0.0002960010606329888
Test Loss:  0.0002006673312280327
Valid Loss:  0.00022804306354373693
Epoch:  322  	Training Loss: 0.00029596564127132297
Test Loss:  0.00019951723515987396
Valid Loss:  0.00022646092111244798
Epoch:  323  	Training Loss: 0.0002939286641776562
Test Loss:  0.00019774018437601626
Valid Loss:  0.0002245627110823989
Epoch:  324  	Training Loss: 0.00029194896342232823
Test Loss:  0.0001966432319022715
Valid Loss:  0.00022310440544970334
Epoch:  325  	Training Loss: 0.00029008713318035007
Test Loss:  0.00019535158935468644
Valid Loss:  0.00022157405328471214
Epoch:  326  	Training Loss: 0.00028831776580773294
Test Loss:  0.00019436815637163818
Valid Loss:  0.00022025470389053226
Epoch:  327  	Training Loss: 0.0002866282593458891
Test Loss:  0.00019334282842464745
Valid Loss:  0.00021894653036724776
Epoch:  328  	Training Loss: 0.0002850097371265292
Test Loss:  0.0001924727257573977
Valid Loss:  0.00021775717323180288
Epoch:  329  	Training Loss: 0.00028345425380393863
Test Loss:  0.0001916067412821576
Valid Loss:  0.00021660234779119492
Epoch:  330  	Training Loss: 0.0002818889915943146
Test Loss:  0.00019077009346801788
Valid Loss:  0.00021545894560404122
Epoch:  331  	Training Loss: 0.00028027142980135977
Test Loss:  0.00018994083802681416
Valid Loss:  0.00021434493828564882
Epoch:  332  	Training Loss: 0.0002787105040624738
Test Loss:  0.0001899171620607376
Valid Loss:  0.00021429397747851908
Epoch:  333  	Training Loss: 0.0002785050019156188
Test Loss:  0.0001898951450129971
Valid Loss:  0.00021425298473332077
Epoch:  334  	Training Loss: 0.0002783159143291414
Test Loss:  0.00018988241208717227
Valid Loss:  0.00021423716680146754
Epoch:  335  	Training Loss: 0.0002781554067041725
Test Loss:  0.00018988328520208597
Valid Loss:  0.00021423419821076095
Epoch:  336  	Training Loss: 0.0002780210052151233
Test Loss:  0.00018990188254974782
Valid Loss:  0.0002142458106391132
Epoch:  337  	Training Loss: 0.00027789571322500706
Test Loss:  0.00018993686535395682
Valid Loss:  0.00021427366300486028
Epoch:  338  	Training Loss: 0.00027778095682151616
Test Loss:  0.0001899825583677739
Valid Loss:  0.00021430944616440684
Epoch:  339  	Training Loss: 0.00027766404673457146
Test Loss:  0.00019003194756805897
Valid Loss:  0.00021434934751596302
Epoch:  340  	Training Loss: 0.0002775617758743465
Test Loss:  0.00019008565868716687
Valid Loss:  0.00021439143165480345
 68%|██████▊   | 341/500 [04:07<03:08,  1.19s/it] 69%|██████▊   | 343/500 [04:07<02:13,  1.17it/s] 69%|██████▉   | 345/500 [04:07<01:35,  1.62it/s] 69%|██████▉   | 347/500 [04:07<01:08,  2.22it/s] 70%|██████▉   | 349/500 [04:07<00:50,  2.96it/s] 70%|███████   | 351/500 [04:13<02:55,  1.18s/it] 71%|███████   | 353/500 [04:14<02:04,  1.18it/s] 71%|███████   | 355/500 [04:14<01:29,  1.63it/s] 71%|███████▏  | 357/500 [04:14<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:14<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:20<02:46,  1.20s/it] 73%|███████▎  | 363/500 [04:20<01:57,  1.16it/s] 73%|███████▎  | 365/500 [04:21<01:24,  1.61it/s] 73%|███████▎  | 367/500 [04:21<01:00,  2.20it/s] 74%|███████▍  | 369/500 [04:21<00:44,  2.96it/s] 74%|███████▍  | 371/500 [04:27<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:27<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:27<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:28<00:55,  2.24it/s] 76%|███████▌  | 379/500 [04:28<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:34<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:34<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:34<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:34<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:34<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:41<02:06,  1.17s/it] 79%|███████▊  | 393/500 [04:41<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:41<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:41<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:41<00:33,  3.02it/s] 80%|████████  | 401/500 [04:48<01:56,  1.18s/it] 81%|████████  | 403/500 [04:48<01:22,  1.18it/s] 81%|████████  | 405/500 [04:48<00:58,  1.64it/s] 81%|████████▏ | 407/500 [04:48<00:41,  2.23it/s]Epoch:  341  	Training Loss: 0.00027746829437091947
Test Loss:  0.00019014222198165953
Valid Loss:  0.00021443779405672103
Epoch:  342  	Training Loss: 0.00027738077915273607
Test Loss:  0.00019050939590670168
Valid Loss:  0.00021462602308019996
Epoch:  343  	Training Loss: 0.00027724774554371834
Test Loss:  0.00019069106201641262
Valid Loss:  0.00021470374485943466
Epoch:  344  	Training Loss: 0.00027713197050616145
Test Loss:  0.00019085389794781804
Valid Loss:  0.00021477742120623589
Epoch:  345  	Training Loss: 0.0002770281571429223
Test Loss:  0.00019100421923212707
Valid Loss:  0.00021484763419721276
Epoch:  346  	Training Loss: 0.00027693447191268206
Test Loss:  0.00019114278256893158
Valid Loss:  0.00021491528605110943
Epoch:  347  	Training Loss: 0.0002768496051430702
Test Loss:  0.00019127177074551582
Valid Loss:  0.00021497916895896196
Epoch:  348  	Training Loss: 0.000276770704658702
Test Loss:  0.00019138741481583565
Valid Loss:  0.0002150383807020262
Epoch:  349  	Training Loss: 0.00027669849805533886
Test Loss:  0.0001914934255182743
Valid Loss:  0.00021509396901819855
Epoch:  350  	Training Loss: 0.00027663022046908736
Test Loss:  0.00019159007933922112
Valid Loss:  0.0002151450316887349
Epoch:  351  	Training Loss: 0.00027656726888380945
Test Loss:  0.00019167971913702786
Valid Loss:  0.00021519375150091946
Epoch:  352  	Training Loss: 0.000276506703812629
Test Loss:  0.00018766397261060774
Valid Loss:  0.0002078379038721323
Epoch:  353  	Training Loss: 0.0002664366620592773
Test Loss:  0.00017760130867827684
Valid Loss:  0.00019821510068140924
Epoch:  354  	Training Loss: 0.00026050431188195944
Test Loss:  0.00017706355720292777
Valid Loss:  0.00019730112398974597
Epoch:  355  	Training Loss: 0.00025658245431259274
Test Loss:  0.0001710276847006753
Valid Loss:  0.0001912684238050133
Epoch:  356  	Training Loss: 0.00025321703287772834
Test Loss:  0.00017119364929385483
Valid Loss:  0.00019205492571927607
Epoch:  357  	Training Loss: 0.0002503682626411319
Test Loss:  0.00016645182040520012
Valid Loss:  0.0001870756532298401
Epoch:  358  	Training Loss: 0.00024799781385809183
Test Loss:  0.0001675326784607023
Valid Loss:  0.00018851160712074488
Epoch:  359  	Training Loss: 0.0002458523667883128
Test Loss:  0.000163600459927693
Valid Loss:  0.00018412750796414912
Epoch:  360  	Training Loss: 0.00024368232698179781
Test Loss:  0.00016481001512147486
Valid Loss:  0.00018554420967120677
Epoch:  361  	Training Loss: 0.00024164572823792696
Test Loss:  0.00016141828382387757
Valid Loss:  0.00018152831762563437
Epoch:  362  	Training Loss: 0.00023970118490979075
Test Loss:  0.0001635090447962284
Valid Loss:  0.00018217484466731548
Epoch:  363  	Training Loss: 0.00023630709620192647
Test Loss:  0.00016169852460734546
Valid Loss:  0.00017954051145352423
Epoch:  364  	Training Loss: 0.00023396158940158784
Test Loss:  0.00016225047875195742
Valid Loss:  0.0001792792754713446
Epoch:  365  	Training Loss: 0.0002322074433322996
Test Loss:  0.00016207198495976627
Valid Loss:  0.00017847775598056614
Epoch:  366  	Training Loss: 0.00023086302098818123
Test Loss:  0.00016240445256698877
Valid Loss:  0.00017827733245212585
Epoch:  367  	Training Loss: 0.00022982574591878802
Test Loss:  0.0001626245357329026
Valid Loss:  0.00017805797688197345
Epoch:  368  	Training Loss: 0.00022902256750967354
Test Loss:  0.00016295973910018802
Valid Loss:  0.0001780239399522543
Epoch:  369  	Training Loss: 0.0002283991634612903
Test Loss:  0.0001632748026167974
Valid Loss:  0.00017803075024858117
Epoch:  370  	Training Loss: 0.0002279143373016268
Test Loss:  0.0001636068627703935
Valid Loss:  0.00017810225836001337
Epoch:  371  	Training Loss: 0.00022753566736355424
Test Loss:  0.0001639246620470658
Valid Loss:  0.00017819736967794597
Epoch:  372  	Training Loss: 0.00022723989968653768
Test Loss:  0.0001622439594939351
Valid Loss:  0.00017725865473039448
Epoch:  373  	Training Loss: 0.00022244408319238573
Test Loss:  0.00015957109280861914
Valid Loss:  0.00017469147860538214
Epoch:  374  	Training Loss: 0.00022028645616956055
Test Loss:  0.00015825788432266563
Valid Loss:  0.0001733752724248916
Epoch:  375  	Training Loss: 0.0002185846824431792
Test Loss:  0.00015726216952316463
Valid Loss:  0.00017226103227585554
Epoch:  376  	Training Loss: 0.00021699906210415065
Test Loss:  0.00015658581105526537
Valid Loss:  0.00017145101446658373
Epoch:  377  	Training Loss: 0.00021542575268540531
Test Loss:  0.00015585134678985924
Valid Loss:  0.00017050151654984802
Epoch:  378  	Training Loss: 0.000213933817576617
Test Loss:  0.00015527085633948445
Valid Loss:  0.00016968048294074833
Epoch:  379  	Training Loss: 0.00021249230485409498
Test Loss:  0.00015475467080250382
Valid Loss:  0.0001689028285909444
Epoch:  380  	Training Loss: 0.00021109057706780732
Test Loss:  0.0001542901445645839
Valid Loss:  0.0001681681169429794
Epoch:  381  	Training Loss: 0.00020972464699298143
Test Loss:  0.00015386503946501762
Valid Loss:  0.00016746579785831273
Epoch:  382  	Training Loss: 0.00020839196804445237
Test Loss:  0.0001528473076177761
Valid Loss:  0.00016624995623715222
Epoch:  383  	Training Loss: 0.00020769756520166993
Test Loss:  0.00015231416909955442
Valid Loss:  0.00016557020717300475
Epoch:  384  	Training Loss: 0.00020725744252558798
Test Loss:  0.00015201716450974345
Valid Loss:  0.00016515888273715973
Epoch:  385  	Training Loss: 0.00020691748068202287
Test Loss:  0.00015184204676188529
Valid Loss:  0.00016489322297275066
Epoch:  386  	Training Loss: 0.0002066205779556185
Test Loss:  0.00015173559950198978
Valid Loss:  0.00016470972332172096
Epoch:  387  	Training Loss: 0.00020634534303098917
Test Loss:  0.00015166839875746518
Valid Loss:  0.00016457500169053674
Epoch:  388  	Training Loss: 0.00020608353952411562
Test Loss:  0.00015162464114837348
Valid Loss:  0.00016447016969323158
Epoch:  389  	Training Loss: 0.00020583176228683442
Test Loss:  0.00015159683243837208
Valid Loss:  0.00016438501188531518
Epoch:  390  	Training Loss: 0.00020558926917146891
Test Loss:  0.0001515801704954356
Valid Loss:  0.00016431466792710125
Epoch:  391  	Training Loss: 0.00020535412477329373
Test Loss:  0.00015156957670114934
Valid Loss:  0.00016425314242951572
Epoch:  392  	Training Loss: 0.0002051270566880703
Test Loss:  0.00015170537517406046
Valid Loss:  0.000164249082445167
Epoch:  393  	Training Loss: 0.0002047022571787238
Test Loss:  0.0001517936761956662
Valid Loss:  0.0001641953713260591
Epoch:  394  	Training Loss: 0.00020431497250683606
Test Loss:  0.00015187203825917095
Valid Loss:  0.00016413677076343447
Epoch:  395  	Training Loss: 0.00020395946921780705
Test Loss:  0.00015195258310995996
Valid Loss:  0.00016408675583079457
Epoch:  396  	Training Loss: 0.00020363146904855967
Test Loss:  0.0001520370424259454
Valid Loss:  0.00016404976486228406
Epoch:  397  	Training Loss: 0.00020332870190031826
Test Loss:  0.00015212946163956076
Valid Loss:  0.00016403134213760495
Epoch:  398  	Training Loss: 0.00020304220379330218
Test Loss:  0.00015222432557493448
Valid Loss:  0.00016402036999352276
Epoch:  399  	Training Loss: 0.00020277604926377535
Test Loss:  0.00015232307487167418
Valid Loss:  0.00016402122855652124
Epoch:  400  	Training Loss: 0.00020252828835509717
Test Loss:  0.00015242397785186768
Valid Loss:  0.0001640305999899283
Epoch:  401  	Training Loss: 0.00020229897927492857
Test Loss:  0.00015252850425895303
Valid Loss:  0.0001640480331843719
Epoch:  402  	Training Loss: 0.00020208448404446244
Test Loss:  0.00015355547657236457
Valid Loss:  0.0001649936311878264
Epoch:  403  	Training Loss: 0.00020160962594673038
Test Loss:  0.0001538359501864761
Valid Loss:  0.0001651688653510064
Epoch:  404  	Training Loss: 0.00020134670194238424
Test Loss:  0.00015397413517348468
Valid Loss:  0.00016520296048838645
Epoch:  405  	Training Loss: 0.00020111401681788266
Test Loss:  0.00015409255865961313
Valid Loss:  0.00016523044905625284
Epoch:  406  	Training Loss: 0.00020089338067919016
Test Loss:  0.0001542079698992893
Valid Loss:  0.0001652603386901319
Epoch:  407  	Training Loss: 0.0002006928261835128
Test Loss:  0.00015432504005730152
Valid Loss:  0.00016529750428162515
 82%|████████▏ | 409/500 [04:48<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:54<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:55<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:55<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:55<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:55<00:27,  2.99it/s] 84%|████████▍ | 421/500 [05:01<01:32,  1.17s/it] 85%|████████▍ | 423/500 [05:01<01:04,  1.20it/s] 85%|████████▌ | 425/500 [05:01<00:45,  1.65it/s] 85%|████████▌ | 427/500 [05:02<00:32,  2.26it/s] 86%|████████▌ | 429/500 [05:02<00:23,  3.04it/s] 86%|████████▌ | 431/500 [05:08<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:08<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:08<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:08<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:09<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:15<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:15<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:15<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:15<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:16<00:17,  2.95it/s] 90%|█████████ | 451/500 [05:22<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:22<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:22<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:22<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:22<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:29<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:29<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:29<00:21,  1.59it/s] 93%|█████████▎| 467/500 [05:29<00:15,  2.18it/s] 94%|█████████▍| 469/500 [05:29<00:10,  2.93it/s] 94%|█████████▍| 471/500 [05:36<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:36<00:23,  1.16it/s]Epoch:  408  	Training Loss: 0.00020051040337421
Test Loss:  0.00015444232849404216
Valid Loss:  0.0001653405633987859
Epoch:  409  	Training Loss: 0.00020034326007589698
Test Loss:  0.00015455950051546097
Valid Loss:  0.00016538926865905523
Epoch:  410  	Training Loss: 0.00020019066869281232
Test Loss:  0.00015467664343304932
Valid Loss:  0.0001654422376304865
Epoch:  411  	Training Loss: 0.00020004995167255402
Test Loss:  0.00015479202556889504
Valid Loss:  0.00016549813153687865
Epoch:  412  	Training Loss: 0.00019992070156149566
Test Loss:  0.00015249094576574862
Valid Loss:  0.0001639324618736282
Epoch:  413  	Training Loss: 0.00019580620573833585
Test Loss:  0.00014948192983865738
Valid Loss:  0.00016052288992796093
Epoch:  414  	Training Loss: 0.0001933906605700031
Test Loss:  0.00014751029084436595
Valid Loss:  0.0001588728919159621
Epoch:  415  	Training Loss: 0.00019171090389136225
Test Loss:  0.00014601985458284616
Valid Loss:  0.00015743663243483752
Epoch:  416  	Training Loss: 0.00019042975327465683
Test Loss:  0.00014494826609734446
Valid Loss:  0.000156423106091097
Epoch:  417  	Training Loss: 0.00018937376444227993
Test Loss:  0.00014410357107408345
Valid Loss:  0.00015557280858047307
Epoch:  418  	Training Loss: 0.0001884492376120761
Test Loss:  0.00014342712529469281
Valid Loss:  0.00015486640040762722
Epoch:  419  	Training Loss: 0.0001876048045232892
Test Loss:  0.00014285957149695605
Valid Loss:  0.00015424333105329424
Epoch:  420  	Training Loss: 0.00018681157962419093
Test Loss:  0.00014236883725970984
Valid Loss:  0.00015368386812042445
Epoch:  421  	Training Loss: 0.00018605284276418388
Test Loss:  0.0001419351319782436
Valid Loss:  0.00015316979261115193
Epoch:  422  	Training Loss: 0.00018531811656430364
Test Loss:  0.000141096199513413
Valid Loss:  0.0001519302313681692
Epoch:  423  	Training Loss: 0.0001845326041802764
Test Loss:  0.00014088893658481538
Valid Loss:  0.0001519807701697573
Epoch:  424  	Training Loss: 0.0001837535237427801
Test Loss:  0.00014021541574038565
Valid Loss:  0.00015101776807568967
Epoch:  425  	Training Loss: 0.00018294504843652248
Test Loss:  0.0001399760803906247
Valid Loss:  0.00015089058433659375
Epoch:  426  	Training Loss: 0.00018217971955891699
Test Loss:  0.00013945397222414613
Valid Loss:  0.00015007122419774532
Epoch:  427  	Training Loss: 0.00018144104979000986
Test Loss:  0.0001392888225382194
Valid Loss:  0.00014997755351942033
Epoch:  428  	Training Loss: 0.0001807246881071478
Test Loss:  0.00013884941290598363
Valid Loss:  0.0001492475566919893
Epoch:  429  	Training Loss: 0.0001800243917386979
Test Loss:  0.00013871827104594558
Valid Loss:  0.00014915931387804449
Epoch:  430  	Training Loss: 0.00017934024799615145
Test Loss:  0.000138331379275769
Valid Loss:  0.00014849507715553045
Epoch:  431  	Training Loss: 0.00017866987036541104
Test Loss:  0.00013821700122207403
Valid Loss:  0.00014840376388747245
Epoch:  432  	Training Loss: 0.0001780125021468848
Test Loss:  0.00013892007700633258
Valid Loss:  0.00014901401300448924
Epoch:  433  	Training Loss: 0.0001759197621140629
Test Loss:  0.00013835978461429477
Valid Loss:  0.00014785880921408534
Epoch:  434  	Training Loss: 0.00017450540326535702
Test Loss:  0.00013843367923982441
Valid Loss:  0.00014761392958462238
Epoch:  435  	Training Loss: 0.00017346159438602626
Test Loss:  0.00013849535025656223
Valid Loss:  0.0001473771408200264
Epoch:  436  	Training Loss: 0.0001726822811178863
Test Loss:  0.0001386569783790037
Valid Loss:  0.00014731218107044697
Epoch:  437  	Training Loss: 0.0001720992149785161
Test Loss:  0.00013884625514037907
Valid Loss:  0.00014731258852407336
Epoch:  438  	Training Loss: 0.00017166190082207322
Test Loss:  0.00013905411469750106
Valid Loss:  0.00014736998127773404
Epoch:  439  	Training Loss: 0.00017133416258729994
Test Loss:  0.00013926572864875197
Valid Loss:  0.00014745673979632556
Epoch:  440  	Training Loss: 0.00017108663450926542
Test Loss:  0.00013947136176284403
Valid Loss:  0.00014755922893527895
Epoch:  441  	Training Loss: 0.00017089858010876924
Test Loss:  0.00013966660480946302
Valid Loss:  0.0001476688776165247
Epoch:  442  	Training Loss: 0.00017075530195143074
Test Loss:  0.0001396248408127576
Valid Loss:  0.00014737906167283654
Epoch:  443  	Training Loss: 0.0001705404429230839
Test Loss:  0.00013994456094224006
Valid Loss:  0.000147818005643785
Epoch:  444  	Training Loss: 0.0001703478628769517
Test Loss:  0.0001399629982188344
Valid Loss:  0.00014767301036044955
Epoch:  445  	Training Loss: 0.00017017438949551433
Test Loss:  0.00014015888154972345
Valid Loss:  0.00014799338532611728
Epoch:  446  	Training Loss: 0.00017001783999148756
Test Loss:  0.0001401750632794574
Valid Loss:  0.00014793986338190734
Epoch:  447  	Training Loss: 0.00016987640992738307
Test Loss:  0.00014032736362423748
Valid Loss:  0.00014818235649727285
Epoch:  448  	Training Loss: 0.00016974791651591659
Test Loss:  0.00014036710490472615
Valid Loss:  0.0001481833023717627
Epoch:  449  	Training Loss: 0.0001696315739536658
Test Loss:  0.00014048957382328808
Valid Loss:  0.00014837417984381318
Epoch:  450  	Training Loss: 0.00016952501027844846
Test Loss:  0.00014054171333555132
Valid Loss:  0.00014840741641819477
Epoch:  451  	Training Loss: 0.00016942861839197576
Test Loss:  0.00014064554125070572
Valid Loss:  0.00014856166671961546
Epoch:  452  	Training Loss: 0.0001693403028184548
Test Loss:  0.00014078046660870314
Valid Loss:  0.0001487377448938787
Epoch:  453  	Training Loss: 0.00016930831770878285
Test Loss:  0.00014086131704971194
Valid Loss:  0.0001488338748458773
Epoch:  454  	Training Loss: 0.00016928190598264337
Test Loss:  0.00014091470802668482
Valid Loss:  0.00014888864825479686
Epoch:  455  	Training Loss: 0.00016925792442634702
Test Loss:  0.00014095213555265218
Valid Loss:  0.0001489229907747358
Epoch:  456  	Training Loss: 0.0001692353980615735
Test Loss:  0.000140983538585715
Valid Loss:  0.00014894736523274332
Epoch:  457  	Training Loss: 0.0001692132354946807
Test Loss:  0.0001410090335411951
Valid Loss:  0.0001489659189246595
Epoch:  458  	Training Loss: 0.00016919094196055084
Test Loss:  0.0001410334079992026
Valid Loss:  0.00014898154768161476
Epoch:  459  	Training Loss: 0.00016917033644858748
Test Loss:  0.00014105593436397612
Valid Loss:  0.00014899467350915074
Epoch:  460  	Training Loss: 0.0001691502402536571
Test Loss:  0.00014107712195254862
Valid Loss:  0.00014900846872478724
Epoch:  461  	Training Loss: 0.00016913027502596378
Test Loss:  0.00014109844050835818
Valid Loss:  0.00014901996473781765
Epoch:  462  	Training Loss: 0.00016911100829020143
Test Loss:  0.00013864852371625602
Valid Loss:  0.0001478425838286057
Epoch:  463  	Training Loss: 0.00016622508701402694
Test Loss:  0.00013555181794799864
Valid Loss:  0.00014383898815140128
Epoch:  464  	Training Loss: 0.00016455941658932716
Test Loss:  0.0001339466980425641
Valid Loss:  0.00014469370944425464
Epoch:  465  	Training Loss: 0.00016320310533046722
Test Loss:  0.00013208876771386713
Valid Loss:  0.00014189828652888536
Epoch:  466  	Training Loss: 0.00016214721836149693
Test Loss:  0.00013145999400876462
Valid Loss:  0.000142707081977278
Epoch:  467  	Training Loss: 0.00016123347450047731
Test Loss:  0.00013022267376072705
Valid Loss:  0.0001405677176080644
Epoch:  468  	Training Loss: 0.00016039663751143962
Test Loss:  0.00012989412061870098
Valid Loss:  0.00014117686077952385
Epoch:  469  	Training Loss: 0.00015958488802425563
Test Loss:  0.00012879390851594508
Valid Loss:  0.00013946244143880904
Epoch:  470  	Training Loss: 0.00015872527728788555
Test Loss:  0.00012845583842135966
Valid Loss:  0.00013977661728858948
Epoch:  471  	Training Loss: 0.00015788470045663416
Test Loss:  0.0001274848764296621
Valid Loss:  0.00013841246254742146
Epoch:  472  	Training Loss: 0.00015699303185101599
Test Loss:  0.00012717457138933241
Valid Loss:  0.0001382983464282006
Epoch:  473  	Training Loss: 0.00015631367568857968
Test Loss:  0.00012679575593210757
Valid Loss:  0.00013804069021716714
Epoch:  474  	Training Loss: 0.00015569842071272433
Test Loss:  0.00012645567767322063
Valid Loss:  0.00013785946066491306
 95%|█████████▌| 475/500 [05:36<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:36<00:10,  2.20it/s] 96%|█████████▌| 479/500 [05:36<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:43<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:43<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:43<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:43<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:43<00:03,  2.99it/s] 98%|█████████▊| 491/500 [05:50<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:50<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:50<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:50<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:50<00:00,  2.98it/s]100%|██████████| 500/500 [05:50<00:00,  1.43it/s]
Epoch:  475  	Training Loss: 0.00015513537800870836
Test Loss:  0.00012612203136086464
Valid Loss:  0.00013769266661256552
Epoch:  476  	Training Loss: 0.00015461689326912165
Test Loss:  0.00012580279144458473
Valid Loss:  0.00013754924293607473
Epoch:  477  	Training Loss: 0.00015413590881507844
Test Loss:  0.0001254904200322926
Valid Loss:  0.00013742194278165698
Epoch:  478  	Training Loss: 0.0001536874915473163
Test Loss:  0.0001251863723155111
Valid Loss:  0.00013730769569519907
Epoch:  479  	Training Loss: 0.00015326685388572514
Test Loss:  0.00012489064829424024
Valid Loss:  0.00013720574497710913
Epoch:  480  	Training Loss: 0.00015287185669876635
Test Loss:  0.00012460141442716122
Valid Loss:  0.00013711242354474962
Epoch:  481  	Training Loss: 0.00015249880379997194
Test Loss:  0.0001243195147253573
Valid Loss:  0.00013702706201002002
Epoch:  482  	Training Loss: 0.00015214567247312516
Test Loss:  0.00012422524741850793
Valid Loss:  0.00013695252710022032
Epoch:  483  	Training Loss: 0.00015206506941467524
Test Loss:  0.0001241511490661651
Valid Loss:  0.0001369213277939707
Epoch:  484  	Training Loss: 0.00015199134941212833
Test Loss:  0.0001240925776073709
Valid Loss:  0.0001369123929180205
Epoch:  485  	Training Loss: 0.0001519220240879804
Test Loss:  0.000124043581308797
Valid Loss:  0.00013691731146536767
Epoch:  486  	Training Loss: 0.00015185674419626594
Test Loss:  0.00012400203559082001
Valid Loss:  0.00013692956417798996
Epoch:  487  	Training Loss: 0.00015179379261098802
Test Loss:  0.00012396583042573184
Valid Loss:  0.0001369464152958244
Epoch:  488  	Training Loss: 0.00015173343126662076
Test Loss:  0.00012391981726977974
Valid Loss:  0.00013697655231226236
Epoch:  489  	Training Loss: 0.00015166078810580075
Test Loss:  0.00012387811148073524
Valid Loss:  0.0001370053505524993
Epoch:  490  	Training Loss: 0.0001515920739620924
Test Loss:  0.00012384072761051357
Valid Loss:  0.00013703334843739867
Epoch:  491  	Training Loss: 0.0001515270851086825
Test Loss:  0.000123807301861234
Valid Loss:  0.00013704237062484026
Epoch:  492  	Training Loss: 0.00015146493387874216
Test Loss:  0.00012483248428907245
Valid Loss:  0.0001384694769512862
Epoch:  493  	Training Loss: 0.000151174288475886
Test Loss:  0.00012483441969379783
Valid Loss:  0.0001384330098517239
Epoch:  494  	Training Loss: 0.0001510865258751437
Test Loss:  0.00012486439663916826
Valid Loss:  0.00013843842316418886
Epoch:  495  	Training Loss: 0.00015100667951628566
Test Loss:  0.000124895348562859
Valid Loss:  0.000138446397613734
Epoch:  496  	Training Loss: 0.00015093495312612504
Test Loss:  0.0001249279303010553
Valid Loss:  0.00013845766079612076
Epoch:  497  	Training Loss: 0.0001508706627646461
Test Loss:  0.00012496227282099426
Valid Loss:  0.00013847020454704762
Epoch:  498  	Training Loss: 0.00015081262972671539
Test Loss:  0.0001249961496796459
Valid Loss:  0.00013848554226569831
Epoch:  499  	Training Loss: 0.0001507596898591146
Test Loss:  0.00012502988101914525
Valid Loss:  0.0001385023642797023
Epoch:  500  	Training Loss: 0.00015071165398694575
Test Loss:  0.0001250640780199319
Valid Loss:  0.00013851976837031543
seed is  5
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:35, 14.11it/s]  1%|          | 4/500 [00:00<00:34, 14.56it/s]  1%|          | 6/500 [00:00<00:32, 15.10it/s]  2%|▏         | 8/500 [00:00<00:33, 14.75it/s]  2%|▏         | 10/500 [00:00<00:32, 15.25it/s]  2%|▏         | 12/500 [00:00<00:31, 15.67it/s]  3%|▎         | 14/500 [00:00<00:30, 15.83it/s]  3%|▎         | 16/500 [00:01<00:31, 15.36it/s]  4%|▎         | 18/500 [00:01<00:30, 15.65it/s]  4%|▍         | 20/500 [00:01<00:30, 15.86it/s]  4%|▍         | 22/500 [00:01<00:29, 16.06it/s]  5%|▍         | 24/500 [00:01<00:29, 16.19it/s]  5%|▌         | 26/500 [00:01<00:29, 16.29it/s]  6%|▌         | 28/500 [00:01<00:29, 16.18it/s]  6%|▌         | 30/500 [00:01<00:28, 16.22it/s]  6%|▋         | 32/500 [00:02<00:28, 16.20it/s]  7%|▋         | 34/500 [00:02<00:28, 16.27it/s]  7%|▋         | 36/500 [00:02<00:28, 16.19it/s]  8%|▊         | 38/500 [00:02<00:28, 16.22it/s]  8%|▊         | 40/500 [00:02<00:28, 16.27it/s]  8%|▊         | 42/500 [00:02<00:28, 16.32it/s]  9%|▉         | 44/500 [00:02<00:27, 16.36it/s]  9%|▉         | 46/500 [00:02<00:27, 16.37it/s] 10%|▉         | 48/500 [00:03<00:27, 16.37it/s] 10%|█         | 50/500 [00:03<00:27, 16.41it/s] 10%|█         | 52/500 [00:03<00:27, 16.41it/s] 11%|█         | 54/500 [00:03<00:27, 16.33it/s] 11%|█         | 56/500 [00:03<00:27, 16.12it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.15it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.21it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.22it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.25it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.27it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.31it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.34it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.34it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.31it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.32it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.38it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.38it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.26it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.32it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.25it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.28it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.22it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.88it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.78it/s] 19%|█▉        | 96/500 [00:05<00:25, 15.94it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.91it/s] 20%|██        | 100/500 [00:06<00:25, 15.92it/s] 20%|██        | 102/500 [00:06<00:24, 16.04it/s] 21%|██        | 104/500 [00:06<00:24, 16.13it/s] 21%|██        | 106/500 [00:06<00:24, 16.18it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.13it/s] 22%|██▏       | 110/500 [00:06<00:24, 15.90it/s] 22%|██▏       | 112/500 [00:06<00:24, 15.89it/s] 23%|██▎       | 114/500 [00:07<00:24, 16.03it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.04it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.37it/s] 24%|██▍       | 120/500 [00:07<00:26, 14.17it/s] 24%|██▍       | 122/500 [00:07<00:25, 14.63it/s] 25%|██▍       | 124/500 [00:07<00:25, 14.96it/s]Epoch:  1  	Training Loss: 0.21564969420433044
Test Loss:  5135.55908203125
Valid Loss:  5137.7080078125
Epoch:  2  	Training Loss: 5138.73828125
Test Loss:  1.8171455155575194e+17
Valid Loss:  1.801528155475804e+17
Epoch:  3  	Training Loss: 1.805409775119237e+17
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:24, 15.32it/s] 26%|██▌       | 128/500 [00:08<00:23, 15.51it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.63it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.74it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.62it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.64it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.83it/s] 28%|██▊       | 140/500 [00:08<00:22, 15.87it/s] 28%|██▊       | 142/500 [00:08<00:25, 14.26it/s] 29%|██▉       | 144/500 [00:09<00:24, 14.66it/s] 29%|██▉       | 146/500 [00:09<00:23, 15.15it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.57it/s] 30%|███       | 150/500 [00:09<00:22, 15.84it/s] 30%|███       | 152/500 [00:09<00:21, 16.03it/s] 31%|███       | 154/500 [00:09<00:21, 16.13it/s] 31%|███       | 156/500 [00:09<00:21, 16.26it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.39it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.48it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.46it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.40it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.43it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.42it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.43it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.42it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.41it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.41it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.34it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.35it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.33it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.38it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.36it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.31it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.22it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.12it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.98it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.10it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.12it/s] 40%|████      | 200/500 [00:12<00:18, 16.17it/s] 40%|████      | 202/500 [00:12<00:18, 16.19it/s] 41%|████      | 204/500 [00:12<00:18, 16.02it/s] 41%|████      | 206/500 [00:12<00:18, 15.97it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.07it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.14it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.81it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.88it/s] 43%|████▎     | 216/500 [00:13<00:18, 15.69it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.84it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.01it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.00it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.97it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.95it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.97it/s] 46%|████▌     | 230/500 [00:14<00:16, 15.97it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.79it/s] 47%|████▋     | 234/500 [00:14<00:17, 14.94it/s] 47%|████▋     | 236/500 [00:14<00:18, 13.91it/s] 48%|████▊     | 238/500 [00:14<00:18, 13.97it/s] 48%|████▊     | 240/500 [00:15<00:18, 14.18it/s] 48%|████▊     | 242/500 [00:15<00:17, 14.64it/s] 49%|████▉     | 244/500 [00:15<00:17, 14.91it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.16it/s] 50%|████▉     | 248/500 [00:15<00:16, 15.08it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:16, 15.46it/s] 50%|█████     | 252/500 [00:15<00:15, 15.75it/s] 51%|█████     | 254/500 [00:16<00:15, 15.90it/s] 51%|█████     | 256/500 [00:16<00:15, 16.05it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.16it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.17it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.11it/s] 53%|█████▎    | 264/500 [00:16<00:15, 15.25it/s] 53%|█████▎    | 266/500 [00:16<00:15, 15.58it/s] 54%|█████▎    | 268/500 [00:16<00:14, 15.80it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.95it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.04it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.20it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.23it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.32it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.36it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.29it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.32it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.37it/s] 58%|█████▊    | 288/500 [00:18<00:12, 16.32it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.23it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.28it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.18it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.73it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.79it/s] 60%|██████    | 300/500 [00:18<00:12, 15.67it/s] 60%|██████    | 302/500 [00:18<00:12, 15.90it/s] 61%|██████    | 304/500 [00:19<00:12, 15.98it/s] 61%|██████    | 306/500 [00:19<00:11, 16.19it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.29it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.18it/s] 62%|██████▏   | 312/500 [00:19<00:11, 15.89it/s] 63%|██████▎   | 314/500 [00:19<00:11, 15.98it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.01it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.99it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.04it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.90it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.85it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.02it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.18it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.27it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.29it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.19it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.10it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.63it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.77it/s] 68%|██████▊   | 342/500 [00:21<00:10, 15.15it/s] 69%|██████▉   | 344/500 [00:21<00:10, 15.36it/s] 69%|██████▉   | 346/500 [00:21<00:09, 15.55it/s] 70%|██████▉   | 348/500 [00:21<00:09, 15.53it/s] 70%|███████   | 350/500 [00:22<00:09, 15.55it/s] 70%|███████   | 352/500 [00:22<00:09, 15.72it/s] 71%|███████   | 354/500 [00:22<00:09, 15.33it/s] 71%|███████   | 356/500 [00:22<00:09, 15.30it/s] 72%|███████▏  | 358/500 [00:22<00:09, 15.35it/s] 72%|███████▏  | 360/500 [00:22<00:09, 15.34it/s] 72%|███████▏  | 362/500 [00:22<00:08, 15.59it/s] 73%|███████▎  | 364/500 [00:22<00:08, 15.77it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.81it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.94it/s] 74%|███████▍  | 370/500 [00:23<00:08, 16.06it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.15it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.24it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.26it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.34it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.32it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.35it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.39it/s] 77%|███████▋  | 386/500 [00:24<00:06, 16.38it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.38it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.40it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.39it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.34it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.36it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.38it/s] 80%|████████  | 400/500 [00:25<00:06, 16.38it/s] 80%|████████  | 402/500 [00:25<00:05, 16.41it/s] 81%|████████  | 404/500 [00:25<00:05, 16.25it/s] 81%|████████  | 406/500 [00:25<00:05, 15.69it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.68it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.89it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.03it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.99it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.07it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.20it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.25it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.26it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.28it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.13it/s] 86%|████████▌ | 428/500 [00:26<00:04, 15.91it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.05it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.06it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.04it/s] 87%|████████▋ | 436/500 [00:27<00:04, 15.77it/s] 88%|████████▊ | 438/500 [00:27<00:03, 15.99it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.13it/s] 88%|████████▊ | 442/500 [00:27<00:03, 15.88it/s] 89%|████████▉ | 444/500 [00:27<00:03, 15.95it/s] 89%|████████▉ | 446/500 [00:27<00:03, 15.91it/s] 90%|████████▉ | 448/500 [00:28<00:03, 15.73it/s] 90%|█████████ | 450/500 [00:28<00:03, 15.88it/s] 90%|█████████ | 452/500 [00:28<00:03, 15.97it/s] 91%|█████████ | 454/500 [00:28<00:02, 15.98it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.90it/s] 92%|█████████▏| 458/500 [00:28<00:02, 15.78it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.02it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.14it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.01it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.02it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.65it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.71it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.60it/s] 95%|█████████▍| 474/500 [00:29<00:01, 15.70it/s] 95%|█████████▌| 476/500 [00:29<00:01, 15.96it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.03it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.37it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.01it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.38it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.52it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.60it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.83it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.98it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.13it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.80it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.76it/s]100%|██████████| 500/500 [00:31<00:00, 15.90it/s]100%|██████████| 500/500 [00:31<00:00, 15.91it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  5
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:50,  6.23s/it]  1%|          | 3/500 [00:06<13:48,  1.67s/it]  1%|          | 5/500 [00:06<06:57,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.95it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:43,  1.32s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:54,  1.61it/s]  5%|▌         | 27/500 [00:20<03:33,  2.21it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:07,  1.17s/it]  7%|▋         | 33/500 [00:26<06:31,  1.19it/s]  7%|▋         | 35/500 [00:26<04:41,  1.65it/s]  7%|▋         | 37/500 [00:27<03:25,  2.26it/s]  8%|▊         | 39/500 [00:27<02:31,  3.03it/s]  8%|▊         | 41/500 [00:33<08:55,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:48,  1.18s/it] 11%|█         | 53/500 [00:40<06:18,  1.18it/s] 11%|█         | 55/500 [00:40<04:32,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.00it/s] 12%|█▏        | 61/500 [00:47<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:24,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.02it/s]Epoch:  1  	Training Loss: 0.21564969420433044
Test Loss:  0.016333306208252907
Valid Loss:  0.020057065412402153
Epoch:  2  	Training Loss: 0.018269438296556473
Test Loss:  0.013009070418775082
Valid Loss:  0.01598692126572132
Epoch:  3  	Training Loss: 0.014752942137420177
Test Loss:  0.011075234040617943
Valid Loss:  0.013600065372884274
Epoch:  4  	Training Loss: 0.012523915618658066
Test Loss:  0.00945570319890976
Valid Loss:  0.011579236015677452
Epoch:  5  	Training Loss: 0.010678190737962723
Test Loss:  0.008117208257317543
Valid Loss:  0.009915858507156372
Epoch:  6  	Training Loss: 0.009156210348010063
Test Loss:  0.007016654126346111
Valid Loss:  0.008544854819774628
Epoch:  7  	Training Loss: 0.007908886298537254
Test Loss:  0.006105985026806593
Valid Loss:  0.007410930469632149
Epoch:  8  	Training Loss: 0.006881934590637684
Test Loss:  0.005350717343389988
Valid Loss:  0.00647171214222908
Epoch:  9  	Training Loss: 0.006034709978848696
Test Loss:  0.004724370781332254
Valid Loss:  0.0056930044665932655
Epoch:  10  	Training Loss: 0.005335797555744648
Test Loss:  0.0042043752036988735
Valid Loss:  0.005047245882451534
Epoch:  11  	Training Loss: 0.004759112372994423
Test Loss:  0.0037723397836089134
Valid Loss:  0.00451103737577796
Epoch:  12  	Training Loss: 0.004283285699784756
Test Loss:  0.0034138523042201996
Valid Loss:  0.004066395573318005
Epoch:  13  	Training Loss: 0.003891193540766835
Test Loss:  0.0031147808767855167
Valid Loss:  0.0036966432817280293
Epoch:  14  	Training Loss: 0.003567187115550041
Test Loss:  0.0028673186898231506
Valid Loss:  0.0033912514336407185
Epoch:  15  	Training Loss: 0.003302512224763632
Test Loss:  0.002661962527781725
Valid Loss:  0.0031392774544656277
Epoch:  16  	Training Loss: 0.0030861448030918837
Test Loss:  0.002489726059138775
Valid Loss:  0.0029312502592802048
Epoch:  17  	Training Loss: 0.0029072940815240145
Test Loss:  0.002347387373447418
Valid Loss:  0.00275542214512825
Epoch:  18  	Training Loss: 0.0027586552314460278
Test Loss:  0.0022272146306931973
Valid Loss:  0.002607903443276882
Epoch:  19  	Training Loss: 0.0026349963154643774
Test Loss:  0.0021260189823806286
Valid Loss:  0.002483714371919632
Epoch:  20  	Training Loss: 0.002532037440687418
Test Loss:  0.002040646970272064
Valid Loss:  0.002379001583904028
Epoch:  21  	Training Loss: 0.002446217928081751
Test Loss:  0.001968629425391555
Valid Loss:  0.0022906148806214333
Epoch:  22  	Training Loss: 0.002374619245529175
Test Loss:  0.0019076494500041008
Valid Loss:  0.002216177526861429
Epoch:  23  	Training Loss: 0.0023147938773036003
Test Loss:  0.001855918439105153
Valid Loss:  0.0021532117389142513
Epoch:  24  	Training Loss: 0.002264737617224455
Test Loss:  0.0018119750311598182
Valid Loss:  0.0020999801345169544
Epoch:  25  	Training Loss: 0.002222868148237467
Test Loss:  0.0017751045525074005
Valid Loss:  0.002054419834166765
Epoch:  26  	Training Loss: 0.002187946578487754
Test Loss:  0.001744341105222702
Valid Loss:  0.00201529823243618
Epoch:  27  	Training Loss: 0.0021587717346847057
Test Loss:  0.0017168589401990175
Valid Loss:  0.001982643734663725
Epoch:  28  	Training Loss: 0.002134374575689435
Test Loss:  0.0016942364163696766
Valid Loss:  0.00195431150496006
Epoch:  29  	Training Loss: 0.002114057308062911
Test Loss:  0.0016741971485316753
Valid Loss:  0.0019304669694975019
Epoch:  30  	Training Loss: 0.0020970762707293034
Test Loss:  0.0016574581386521459
Valid Loss:  0.001909805228933692
Epoch:  31  	Training Loss: 0.0020828857086598873
Test Loss:  0.0016424842178821564
Valid Loss:  0.001892383792437613
Epoch:  32  	Training Loss: 0.0020709934178739786
Test Loss:  0.0016294866800308228
Valid Loss:  0.0018773596966639161
Epoch:  33  	Training Loss: 0.002060946775600314
Test Loss:  0.0016179837984964252
Valid Loss:  0.0018646914977580309
Epoch:  34  	Training Loss: 0.002052591647952795
Test Loss:  0.001609164522960782
Valid Loss:  0.0018531822133809328
Epoch:  35  	Training Loss: 0.002045559696853161
Test Loss:  0.0016006281366571784
Valid Loss:  0.001843570964410901
Epoch:  36  	Training Loss: 0.002039628569036722
Test Loss:  0.0015932597452774644
Valid Loss:  0.0018352266633883119
Epoch:  37  	Training Loss: 0.0020346143282949924
Test Loss:  0.0015867780894041061
Valid Loss:  0.001827998086810112
Epoch:  38  	Training Loss: 0.0020303630735725164
Test Loss:  0.0015810532495379448
Valid Loss:  0.0018217137549072504
Epoch:  39  	Training Loss: 0.0020267427898943424
Test Loss:  0.0015759889502078295
Valid Loss:  0.0018162315245717764
Epoch:  40  	Training Loss: 0.00202367315068841
Test Loss:  0.001572355511598289
Valid Loss:  0.0018110478995367885
Epoch:  41  	Training Loss: 0.0020210726652294397
Test Loss:  0.0015683500096201897
Valid Loss:  0.001806778833270073
Epoch:  42  	Training Loss: 0.002018850762397051
Test Loss:  0.0015648846747353673
Valid Loss:  0.001803011167794466
Epoch:  43  	Training Loss: 0.002016967162489891
Test Loss:  0.001561575336381793
Valid Loss:  0.0017998151015490294
Epoch:  44  	Training Loss: 0.002015366218984127
Test Loss:  0.0015586675144731998
Valid Loss:  0.0017970235785469413
Epoch:  45  	Training Loss: 0.002013982040807605
Test Loss:  0.0015564730856567621
Valid Loss:  0.0017943636048585176
Epoch:  46  	Training Loss: 0.0020127648022025824
Test Loss:  0.0015540787717327476
Valid Loss:  0.0017921951366588473
Epoch:  47  	Training Loss: 0.002011694014072418
Test Loss:  0.0015524793416261673
Valid Loss:  0.0017900702077895403
Epoch:  48  	Training Loss: 0.0020107526797801256
Test Loss:  0.0015507922507822514
Valid Loss:  0.0017882739193737507
Epoch:  49  	Training Loss: 0.002009928459301591
Test Loss:  0.0015494306571781635
Valid Loss:  0.0017865864792838693
Epoch:  50  	Training Loss: 0.0020091934129595757
Test Loss:  0.0015480451984331012
Valid Loss:  0.0017851205775514245
Epoch:  51  	Training Loss: 0.002008529845625162
Test Loss:  0.0015468241181224585
Valid Loss:  0.0017838027561083436
Epoch:  52  	Training Loss: 0.002007944043725729
Test Loss:  0.0015459740534424782
Valid Loss:  0.0017825034447014332
Epoch:  53  	Training Loss: 0.002007444389164448
Test Loss:  0.001545457635074854
Valid Loss:  0.00178117910400033
Epoch:  54  	Training Loss: 0.00200702715665102
Test Loss:  0.001544453902170062
Valid Loss:  0.001780156628228724
Epoch:  55  	Training Loss: 0.0020066590514034033
Test Loss:  0.0015439988346770406
Valid Loss:  0.0017790336860343814
Epoch:  56  	Training Loss: 0.002006330993026495
Test Loss:  0.0015434441156685352
Valid Loss:  0.001778020872734487
Epoch:  57  	Training Loss: 0.002006044378504157
Test Loss:  0.001542343059554696
Valid Loss:  0.001777345547452569
Epoch:  58  	Training Loss: 0.002005784772336483
Test Loss:  0.001542005455121398
Valid Loss:  0.0017764741787686944
Epoch:  59  	Training Loss: 0.00200555007904768
Test Loss:  0.001541010569781065
Valid Loss:  0.0017759432084858418
Epoch:  60  	Training Loss: 0.002005327492952347
Test Loss:  0.0015407900791615248
Valid Loss:  0.0017751984996721148
Epoch:  61  	Training Loss: 0.0020051239989697933
Test Loss:  0.0015398828545585275
Valid Loss:  0.0017747797537595034
Epoch:  62  	Training Loss: 0.0020049314480274916
Test Loss:  0.001540167722851038
Valid Loss:  0.001773948548361659
Epoch:  63  	Training Loss: 0.0020047505386173725
Test Loss:  0.0015391733031719923
Valid Loss:  0.0017736256122589111
Epoch:  64  	Training Loss: 0.0020045717246830463
Test Loss:  0.0015384841244667768
Valid Loss:  0.0017732944106683135
Epoch:  65  	Training Loss: 0.002004409907385707
Test Loss:  0.0015388723695650697
Valid Loss:  0.0017725774087011814
Epoch:  66  	Training Loss: 0.002004246460273862
Test Loss:  0.0015380035620182753
Valid Loss:  0.0017723513301461935
Epoch:  67  	Training Loss: 0.0020040972158312798
Test Loss:  0.001538122771307826
Valid Loss:  0.0017718021990731359
Epoch:  68  	Training Loss: 0.0020039547234773636
Test Loss:  0.001537754200398922
Valid Loss:  0.0017714524874463677
Epoch:  69  	Training Loss: 0.002003830624744296
Test Loss:  0.0015367299783974886
Valid Loss:  0.0017714285058900714
Epoch:  70  	Training Loss: 0.0020037093199789524
Test Loss:  0.001537297386676073
Valid Loss:   14%|█▍        | 71/500 [00:53<08:18,  1.16s/it] 15%|█▍        | 73/500 [00:53<05:56,  1.20it/s] 15%|█▌        | 75/500 [00:54<04:16,  1.66it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.26it/s] 16%|█▌        | 79/500 [00:54<02:18,  3.04it/s] 16%|█▌        | 81/500 [01:00<08:04,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:46,  1.21it/s] 17%|█▋        | 85/500 [01:00<04:09,  1.67it/s] 17%|█▋        | 87/500 [01:00<03:01,  2.27it/s] 18%|█▊        | 89/500 [01:01<02:14,  3.05it/s] 18%|█▊        | 91/500 [01:07<07:51,  1.15s/it] 19%|█▊        | 93/500 [01:07<05:37,  1.21it/s] 19%|█▉        | 95/500 [01:07<04:03,  1.67it/s] 19%|█▉        | 97/500 [01:07<02:57,  2.28it/s] 20%|█▉        | 99/500 [01:07<02:11,  3.05it/s] 20%|██        | 101/500 [01:13<07:42,  1.16s/it] 21%|██        | 103/500 [01:14<05:30,  1.20it/s] 21%|██        | 105/500 [01:14<03:58,  1.66it/s] 21%|██▏       | 107/500 [01:14<02:53,  2.27it/s] 22%|██▏       | 109/500 [01:14<02:08,  3.04it/s] 22%|██▏       | 111/500 [01:20<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:20<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:21<03:55,  1.63it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:21<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:27<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:27<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:27<03:52,  1.61it/s] 25%|██▌       | 127/500 [01:28<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:28<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:34<07:13,  1.17s/it] 27%|██▋       | 133/500 [01:34<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:34<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:34<02:42,  2.24it/s]0.0017708472441881895
Epoch:  71  	Training Loss: 0.0020035896450281143
Test Loss:  0.0015369367320090532
Valid Loss:  0.0017705789068713784
Epoch:  72  	Training Loss: 0.002003477420657873
Test Loss:  0.0015362798003479838
Valid Loss:  0.0017704773927107453
Epoch:  73  	Training Loss: 0.0020033656619489193
Test Loss:  0.001536515774205327
Valid Loss:  0.0017700758762657642
Epoch:  74  	Training Loss: 0.0020032550673931837
Test Loss:  0.0015362279955297709
Valid Loss:  0.0017698563169687986
Epoch:  75  	Training Loss: 0.002003150060772896
Test Loss:  0.0015360319521278143
Valid Loss:  0.0017696302384138107
Epoch:  76  	Training Loss: 0.002003048313781619
Test Loss:  0.0015351164620369673
Valid Loss:  0.001769723603501916
Epoch:  77  	Training Loss: 0.0020029523875564337
Test Loss:  0.0015357774682343006
Valid Loss:  0.0017692497931420803
Epoch:  78  	Training Loss: 0.0020028501749038696
Test Loss:  0.001535506802611053
Valid Loss:  0.0017690829699859023
Epoch:  79  	Training Loss: 0.0020027505233883858
Test Loss:  0.0015353423077613115
Valid Loss:  0.0017688946099951863
Epoch:  80  	Training Loss: 0.002002654829993844
Test Loss:  0.0015351781621575356
Valid Loss:  0.0017687217332422733
Epoch:  81  	Training Loss: 0.002002560067921877
Test Loss:  0.0015350208850577474
Valid Loss:  0.001768553163856268
Epoch:  82  	Training Loss: 0.002002465073019266
Test Loss:  0.001534871058538556
Valid Loss:  0.0017683947226032615
Epoch:  83  	Training Loss: 0.0020023700781166553
Test Loss:  0.0015347228618338704
Valid Loss:  0.0017682446632534266
Epoch:  84  	Training Loss: 0.0020022776443511248
Test Loss:  0.001534434501081705
Valid Loss:  0.001768160262145102
Epoch:  85  	Training Loss: 0.0020021849777549505
Test Loss:  0.0015342290280386806
Valid Loss:  0.001768065500073135
Epoch:  86  	Training Loss: 0.002002095803618431
Test Loss:  0.001534380717203021
Valid Loss:  0.0017678410513326526
Epoch:  87  	Training Loss: 0.0020020059309899807
Test Loss:  0.0015342296101152897
Valid Loss:  0.0017677175346761942
Epoch:  88  	Training Loss: 0.0020019186194986105
Test Loss:  0.0015341087710112333
Valid Loss:  0.0017675881972536445
Epoch:  89  	Training Loss: 0.0020018317736685276
Test Loss:  0.0015339847886934876
Valid Loss:  0.001767470152117312
Epoch:  90  	Training Loss: 0.002001742832362652
Test Loss:  0.0015338819939643145
Valid Loss:  0.0017673518741503358
Epoch:  91  	Training Loss: 0.0020016576163470745
Test Loss:  0.0015337689546868205
Valid Loss:  0.0017672410467639565
Epoch:  92  	Training Loss: 0.002001570537686348
Test Loss:  0.001533658360131085
Valid Loss:  0.0017671303357928991
Epoch:  93  	Training Loss: 0.002001482527703047
Test Loss:  0.0015335544012486935
Valid Loss:  0.0017670212546363473
Epoch:  94  	Training Loss: 0.0020013987086713314
Test Loss:  0.0015334573108702898
Valid Loss:  0.0017669179942458868
Epoch:  95  	Training Loss: 0.0020013146568089724
Test Loss:  0.0015333628980442882
Valid Loss:  0.0017668138025328517
Epoch:  96  	Training Loss: 0.0020012285094708204
Test Loss:  0.0015332745388150215
Valid Loss:  0.0017667149659246206
Epoch:  97  	Training Loss: 0.002001146087422967
Test Loss:  0.0015331837348639965
Valid Loss:  0.001766613801009953
Epoch:  98  	Training Loss: 0.0020010615698993206
Test Loss:  0.0015330964233726263
Valid Loss:  0.001766519621014595
Epoch:  99  	Training Loss: 0.002000977285206318
Test Loss:  0.00153301190584898
Valid Loss:  0.0017664257902652025
Epoch:  100  	Training Loss: 0.00200089393183589
Test Loss:  0.0015329259913414717
Valid Loss:  0.0017663323087617755
Epoch:  101  	Training Loss: 0.0020008098799735308
Test Loss:  0.0015328393783420324
Valid Loss:  0.0017662395257502794
Epoch:  102  	Training Loss: 0.0020007258281111717
Test Loss:  0.0015327604487538338
Valid Loss:  0.0017661477904766798
Epoch:  103  	Training Loss: 0.0020006427075713873
Test Loss:  0.0015326791908591986
Valid Loss:  0.001766060944646597
Epoch:  104  	Training Loss: 0.0020005605183541775
Test Loss:  0.0015326007269322872
Valid Loss:  0.0017659706063568592
Epoch:  105  	Training Loss: 0.002000477397814393
Test Loss:  0.0015325220301747322
Valid Loss:  0.0017658844590187073
Epoch:  106  	Training Loss: 0.0020003945101052523
Test Loss:  0.0015324435662478209
Valid Loss:  0.0017657976131886244
Epoch:  107  	Training Loss: 0.0020003109239041805
Test Loss:  0.0015323678962886333
Valid Loss:  0.001765709719620645
Epoch:  108  	Training Loss: 0.0020002301316708326
Test Loss:  0.001532294787466526
Valid Loss:  0.0017656271811574697
Epoch:  109  	Training Loss: 0.002000149106606841
Test Loss:  0.001532216789200902
Valid Loss:  0.0017655439442023635
Epoch:  110  	Training Loss: 0.002000068547204137
Test Loss:  0.0015321418177336454
Valid Loss:  0.001765458844602108
Epoch:  111  	Training Loss: 0.001999987056478858
Test Loss:  0.001532064750790596
Valid Loss:  0.0017653778195381165
Epoch:  112  	Training Loss: 0.00199990626424551
Test Loss:  0.0015319924568757415
Valid Loss:  0.0017652970273047686
Epoch:  113  	Training Loss: 0.001999826170504093
Test Loss:  0.001531922840513289
Valid Loss:  0.0017652134411036968
Epoch:  114  	Training Loss: 0.001999747473746538
Test Loss:  0.0015318486839532852
Valid Loss:  0.0017651331145316362
Epoch:  115  	Training Loss: 0.0019996678456664085
Test Loss:  0.0015317762736231089
Valid Loss:  0.0017650527879595757
Epoch:  116  	Training Loss: 0.0019995870534330606
Test Loss:  0.001531706191599369
Valid Loss:  0.0017649747896939516
Epoch:  117  	Training Loss: 0.0019995078910142183
Test Loss:  0.0015316316857933998
Valid Loss:  0.001764896558597684
Epoch:  118  	Training Loss: 0.001999426167458296
Test Loss:  0.0015315631171688437
Valid Loss:  0.001764814369380474
Epoch:  119  	Training Loss: 0.0019993484020233154
Test Loss:  0.001531489659100771
Valid Loss:  0.0017647361382842064
Epoch:  120  	Training Loss: 0.0019992683082818985
Test Loss:  0.0015314188785851002
Valid Loss:  0.0017646559281274676
Epoch:  121  	Training Loss: 0.001999189145863056
Test Loss:  0.0015313494950532913
Valid Loss:  0.001764578395523131
Epoch:  122  	Training Loss: 0.001999108586460352
Test Loss:  0.0015312866307795048
Valid Loss:  0.0017645014449954033
Epoch:  123  	Training Loss: 0.001999028492718935
Test Loss:  0.0015312160830944777
Valid Loss:  0.0017644253093749285
Epoch:  124  	Training Loss: 0.001998949097469449
Test Loss:  0.001531150657683611
Valid Loss:  0.0017643463797867298
Epoch:  125  	Training Loss: 0.001998871099203825
Test Loss:  0.001531088026240468
Valid Loss:  0.0017642679158598185
Epoch:  126  	Training Loss: 0.0019987900741398335
Test Loss:  0.0015310205053538084
Valid Loss:  0.0017641924787312746
Epoch:  127  	Training Loss: 0.001998713007196784
Test Loss:  0.0015309553127735853
Valid Loss:  0.0017641172744333744
Epoch:  128  	Training Loss: 0.0019986324477940798
Test Loss:  0.0015308924484997988
Valid Loss:  0.001764041604474187
Epoch:  129  	Training Loss: 0.0019985518883913755
Test Loss:  0.0015308267902582884
Valid Loss:  0.0017639698926359415
Epoch:  130  	Training Loss: 0.001998473424464464
Test Loss:  0.0015307639259845018
Valid Loss:  0.0017638958524912596
Epoch:  131  	Training Loss: 0.0019983951933681965
Test Loss:  0.0015307031571865082
Valid Loss:  0.001763824955560267
Epoch:  132  	Training Loss: 0.001998315565288067
Test Loss:  0.0015306402929127216
Valid Loss:  0.0017637514974921942
Epoch:  133  	Training Loss: 0.0019982405938208103
Test Loss:  0.0015305784763768315
Valid Loss:  0.001763677690178156
Epoch:  134  	Training Loss: 0.0019981637597084045
Test Loss:  0.0015305178239941597
Valid Loss:  0.0017636066768318415
Epoch:  135  	Training Loss: 0.0019980892539024353
Test Loss:  0.0015304535627365112
Valid Loss:  0.0017635385738685727
Epoch:  136  	Training Loss: 0.001998013351112604
Test Loss:  0.001530391164124012
Valid Loss:  0.0017634669784456491
Epoch:  137  	Training Loss: 0.001997937448322773
Test Loss:  0.0015303303953260183
Valid Loss:  0.0017633943352848291
Epoch:  138  	Training Loss: 0.0019978603813797235
Test Loss:  0.0015302668325603008
Valid Loss:  0.0017633233219385147
Epoch:  139  	Training Loss: 0.001997786108404398
Test Loss:  0.0015302050160244107
Valid Loss:   28%|██▊       | 139/500 [01:35<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:41<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:41<05:06,  1.17it/s] 29%|██▉       | 145/500 [01:41<03:40,  1.61it/s] 29%|██▉       | 147/500 [01:41<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:42<01:59,  2.94it/s] 30%|███       | 151/500 [01:48<06:55,  1.19s/it] 31%|███       | 153/500 [01:48<04:57,  1.17it/s] 31%|███       | 155/500 [01:48<03:34,  1.61it/s] 31%|███▏      | 157/500 [01:48<02:36,  2.20it/s] 32%|███▏      | 159/500 [01:48<01:55,  2.96it/s] 32%|███▏      | 161/500 [01:55<06:41,  1.18s/it] 33%|███▎      | 163/500 [01:55<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:55<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:55<02:29,  2.22it/s] 34%|███▍      | 169/500 [01:55<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:02<06:38,  1.21s/it] 35%|███▍      | 173/500 [02:02<04:44,  1.15it/s] 35%|███▌      | 175/500 [02:02<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:02<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:02<01:49,  2.93it/s] 36%|███▌      | 181/500 [02:09<06:17,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:09<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:09<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:09<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:16<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:16<04:23,  1.17it/s] 39%|███▉      | 195/500 [02:16<03:08,  1.61it/s] 39%|███▉      | 197/500 [02:16<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:16<01:41,  2.97it/s] 40%|████      | 201/500 [02:23<05:59,  1.20s/it] 41%|████      | 203/500 [02:23<04:16,  1.16it/s] 41%|████      | 205/500 [02:23<03:04,  1.60it/s] 41%|████▏     | 207/500 [02:23<02:13,  2.19it/s]0.001763251842930913
Epoch:  140  	Training Loss: 0.001997709507122636
Test Loss:  0.0015301464591175318
Valid Loss:  0.0017631814116612077
Epoch:  141  	Training Loss: 0.0019976350013166666
Test Loss:  0.0015300827799364924
Valid Loss:  0.0017631109803915024
Epoch:  142  	Training Loss: 0.001997559331357479
Test Loss:  0.0015300228260457516
Valid Loss:  0.0017630427610129118
Epoch:  143  	Training Loss: 0.0019974850583821535
Test Loss:  0.0015299635706469417
Valid Loss:  0.001762972678989172
Epoch:  144  	Training Loss: 0.0019974112510681152
Test Loss:  0.0015299010556191206
Valid Loss:  0.0017629049252718687
Epoch:  145  	Training Loss: 0.0019973358139395714
Test Loss:  0.0015298423822969198
Valid Loss:  0.0017628364730626345
Epoch:  146  	Training Loss: 0.0019972622394561768
Test Loss:  0.0015297848731279373
Valid Loss:  0.001762766158208251
Epoch:  147  	Training Loss: 0.0019971898291260004
Test Loss:  0.0015297244535759091
Valid Loss:  0.0017626986373215914
Epoch:  148  	Training Loss: 0.001997116021811962
Test Loss:  0.0015296631027013063
Valid Loss:  0.0017626285552978516
Epoch:  149  	Training Loss: 0.00199704198166728
Test Loss:  0.0015296009369194508
Valid Loss:  0.0017625615000724792
Epoch:  150  	Training Loss: 0.00199696933850646
Test Loss:  0.0015295404009521008
Valid Loss:  0.0017624926986172795
Epoch:  151  	Training Loss: 0.0019968971610069275
Test Loss:  0.0015294819604605436
Valid Loss:  0.0017624261090531945
Epoch:  152  	Training Loss: 0.001996823353692889
Test Loss:  0.0015294216573238373
Valid Loss:  0.001762359170243144
Epoch:  153  	Training Loss: 0.001996750244870782
Test Loss:  0.0015293604228645563
Valid Loss:  0.0017622914165258408
Epoch:  154  	Training Loss: 0.0019966785330325365
Test Loss:  0.0015293037286028266
Valid Loss:  0.0017622229643166065
Epoch:  155  	Training Loss: 0.00199660612270236
Test Loss:  0.0015292419120669365
Valid Loss:  0.0017621571896597743
Epoch:  156  	Training Loss: 0.001996534178033471
Test Loss:  0.0015291831223294139
Valid Loss:  0.0017620893195271492
Epoch:  157  	Training Loss: 0.001996461534872651
Test Loss:  0.0015291261952370405
Valid Loss:  0.0017620220314711332
Epoch:  158  	Training Loss: 0.0019963886588811874
Test Loss:  0.0015290636802092195
Valid Loss:  0.0017619568388909101
Epoch:  159  	Training Loss: 0.0019963178783655167
Test Loss:  0.0015290044248104095
Valid Loss:  0.0017618873389437795
Epoch:  160  	Training Loss: 0.0019962447695434093
Test Loss:  0.0015289473813027143
Valid Loss:  0.001761819003149867
Epoch:  161  	Training Loss: 0.0019961721263825893
Test Loss:  0.001528885681182146
Valid Loss:  0.0017617560224607587
Epoch:  162  	Training Loss: 0.0019960985518991947
Test Loss:  0.001528826542198658
Valid Loss:  0.0017616874538362026
Epoch:  163  	Training Loss: 0.001996029168367386
Test Loss:  0.0015287684509530663
Valid Loss:  0.0017616198165342212
Epoch:  164  	Training Loss: 0.001995956990867853
Test Loss:  0.0015287052374333143
Valid Loss:  0.0017615545075386763
Epoch:  165  	Training Loss: 0.0019958834163844585
Test Loss:  0.0015286505222320557
Valid Loss:  0.001761487452313304
Epoch:  166  	Training Loss: 0.001995813101530075
Test Loss:  0.0015285914996638894
Valid Loss:  0.001761424238793552
Epoch:  167  	Training Loss: 0.0019957413896918297
Test Loss:  0.0015285320114344358
Valid Loss:  0.0017613583477213979
Epoch:  168  	Training Loss: 0.001995669910684228
Test Loss:  0.0015284762484952807
Valid Loss:  0.0017612919909879565
Epoch:  169  	Training Loss: 0.001995599828660488
Test Loss:  0.0015284145483747125
Valid Loss:  0.0017612252850085497
Epoch:  170  	Training Loss: 0.0019955269526690245
Test Loss:  0.0015283569227904081
Valid Loss:  0.0017611600924283266
Epoch:  171  	Training Loss: 0.00199545593932271
Test Loss:  0.001528300577774644
Valid Loss:  0.001761090476065874
Epoch:  172  	Training Loss: 0.0019953851588070393
Test Loss:  0.0015282408567145467
Valid Loss:  0.0017610294744372368
Epoch:  173  	Training Loss: 0.001995314843952656
Test Loss:  0.0015281845116987824
Valid Loss:  0.0017609638161957264
Epoch:  174  	Training Loss: 0.001995244063436985
Test Loss:  0.001528126304037869
Valid Loss:  0.0017608983907848597
Epoch:  175  	Training Loss: 0.001995174679905176
Test Loss:  0.001528067048639059
Valid Loss:  0.0017608359921723604
Epoch:  176  	Training Loss: 0.001995106227695942
Test Loss:  0.0015280095394700766
Valid Loss:  0.0017607698682695627
Epoch:  177  	Training Loss: 0.0019950345158576965
Test Loss:  0.0015279515646398067
Valid Loss:  0.001760705141350627
Epoch:  178  	Training Loss: 0.0019949651323258877
Test Loss:  0.001527892192825675
Valid Loss:  0.0017606406472623348
Epoch:  179  	Training Loss: 0.0019948952831327915
Test Loss:  0.0015278339851647615
Valid Loss:  0.00176057661883533
Epoch:  180  	Training Loss: 0.0019948254339396954
Test Loss:  0.0015277777565643191
Valid Loss:  0.0017605130560696125
Epoch:  181  	Training Loss: 0.00199475628323853
Test Loss:  0.0015277187339961529
Valid Loss:  0.0017604471649974585
Epoch:  182  	Training Loss: 0.001994685735553503
Test Loss:  0.001527660759165883
Valid Loss:  0.001760386978276074
Epoch:  183  	Training Loss: 0.001994616352021694
Test Loss:  0.0015276032499969006
Valid Loss:  0.0017603188753128052
Epoch:  184  	Training Loss: 0.0019945476669818163
Test Loss:  0.0015275466721504927
Valid Loss:  0.001760257175192237
Epoch:  185  	Training Loss: 0.001994478050619364
Test Loss:  0.0015274917241185904
Valid Loss:  0.0017601937288418412
Epoch:  186  	Training Loss: 0.0019944102969020605
Test Loss:  0.001527430023998022
Valid Loss:  0.0017601300496608019
Epoch:  187  	Training Loss: 0.0019943409133702517
Test Loss:  0.0015273748431354761
Valid Loss:  0.0017600683495402336
Epoch:  188  	Training Loss: 0.0019942717626690865
Test Loss:  0.00152731838170439
Valid Loss:  0.001760002807714045
Epoch:  189  	Training Loss: 0.0019942037761211395
Test Loss:  0.0015272584278136492
Valid Loss:  0.0017599421553313732
Epoch:  190  	Training Loss: 0.0019941346254199743
Test Loss:  0.0015272017335519195
Valid Loss:  0.0017598782433196902
Epoch:  191  	Training Loss: 0.001994065009057522
Test Loss:  0.001527146901935339
Valid Loss:  0.001759813167154789
Epoch:  192  	Training Loss: 0.001993997022509575
Test Loss:  0.0015270864823833108
Valid Loss:  0.0017597540281713009
Epoch:  193  	Training Loss: 0.0019939292687922716
Test Loss:  0.0015270336298272014
Valid Loss:  0.0017596904654055834
Epoch:  194  	Training Loss: 0.0019938605837523937
Test Loss:  0.001526976702734828
Valid Loss:  0.0017596256220713258
Epoch:  195  	Training Loss: 0.001993792597204447
Test Loss:  0.0015269163995981216
Valid Loss:  0.0017595653189346194
Epoch:  196  	Training Loss: 0.001993724377825856
Test Loss:  0.0015268655261024833
Valid Loss:  0.001759504433721304
Epoch:  197  	Training Loss: 0.0019936554599553347
Test Loss:  0.0015268046408891678
Valid Loss:  0.0017594404052942991
Epoch:  198  	Training Loss: 0.0019935877062380314
Test Loss:  0.0015267487615346909
Valid Loss:  0.0017593788215890527
Epoch:  199  	Training Loss: 0.0019935201853513718
Test Loss:  0.0015266956761479378
Valid Loss:  0.0017593159573152661
Epoch:  200  	Training Loss: 0.001993452664464712
Test Loss:  0.0015266345581039786
Valid Loss:  0.0017592554213479161
Epoch:  201  	Training Loss: 0.0019933844450861216
Test Loss:  0.00152658112347126
Valid Loss:  0.0017591905780136585
Epoch:  202  	Training Loss: 0.00199331808835268
Test Loss:  0.001526528038084507
Valid Loss:  0.0017591309733688831
Epoch:  203  	Training Loss: 0.0019932491704821587
Test Loss:  0.0015264679677784443
Valid Loss:  0.0017590681090950966
Epoch:  204  	Training Loss: 0.0019931825809180737
Test Loss:  0.0015264118555933237
Valid Loss:  0.00175900524482131
Epoch:  205  	Training Loss: 0.0019931148272007704
Test Loss:  0.0015263555105775595
Valid Loss:  0.00175894342828542
Epoch:  206  	Training Loss: 0.0019930489361286163
Test Loss:  0.0015262982342392206
Valid Loss:  0.0017588830087333918
Epoch:  207  	Training Loss: 0.001992981182411313
Test Loss:  0.0015262457309290767
Valid Loss:  0.0017588199116289616
Epoch:  208  	Training Loss: 0.0019929143600165844
Test Loss:   42%|████▏     | 209/500 [02:23<01:38,  2.94it/s] 42%|████▏     | 211/500 [02:29<05:39,  1.18s/it] 43%|████▎     | 213/500 [02:29<04:02,  1.18it/s] 43%|████▎     | 215/500 [02:30<02:54,  1.64it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.23it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:36<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:36<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:36<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:37<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:37<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:43<05:19,  1.19s/it] 47%|████▋     | 233/500 [02:43<03:47,  1.17it/s] 47%|████▋     | 235/500 [02:43<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:43<01:59,  2.21it/s] 48%|████▊     | 239/500 [02:44<01:28,  2.96it/s] 48%|████▊     | 241/500 [02:50<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:50<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:50<01:24,  2.98it/s] 50%|█████     | 251/500 [02:57<04:53,  1.18s/it] 51%|█████     | 253/500 [02:57<03:29,  1.18it/s] 51%|█████     | 255/500 [02:57<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:57<01:49,  2.22it/s] 52%|█████▏    | 259/500 [02:57<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:04<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:04<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:04<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:04<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:04<01:17,  2.96it/s] 54%|█████▍    | 271/500 [03:11<04:28,  1.17s/it] 55%|█████▍    | 273/500 [03:11<03:11,  1.19it/s] 55%|█████▌    | 275/500 [03:11<02:17,  1.64it/s]0.0015261867083609104
Valid Loss:  0.0017587615875527263
Epoch:  209  	Training Loss: 0.0019928468391299248
Test Loss:  0.0015261308290064335
Valid Loss:  0.001758699188940227
Epoch:  210  	Training Loss: 0.001992779318243265
Test Loss:  0.0015260754153132439
Valid Loss:  0.0017586369067430496
Epoch:  211  	Training Loss: 0.00199271272867918
Test Loss:  0.0015260179061442614
Valid Loss:  0.0017585764871910214
Epoch:  212  	Training Loss: 0.001992644742131233
Test Loss:  0.0015259619103744626
Valid Loss:  0.0017585154855623841
Epoch:  213  	Training Loss: 0.00199257698841393
Test Loss:  0.0015259090578183532
Valid Loss:  0.0017584532033652067
Epoch:  214  	Training Loss: 0.001992511563003063
Test Loss:  0.0015258523635566235
Valid Loss:  0.0017583947628736496
Epoch:  215  	Training Loss: 0.001992445206269622
Test Loss:  0.0015257963677868247
Valid Loss:  0.0017583321314305067
Epoch:  216  	Training Loss: 0.001992379315197468
Test Loss:  0.0015257378108799458
Valid Loss:  0.001758271362632513
Epoch:  217  	Training Loss: 0.0019923108629882336
Test Loss:  0.0015256849583238363
Valid Loss:  0.0017582103610038757
Epoch:  218  	Training Loss: 0.001992245204746723
Test Loss:  0.0015256297774612904
Valid Loss:  0.001758151687681675
Epoch:  219  	Training Loss: 0.001992178615182638
Test Loss:  0.0015255706384778023
Valid Loss:  0.0017580916173756123
Epoch:  220  	Training Loss: 0.0019921106286346912
Test Loss:  0.0015255147591233253
Valid Loss:  0.0017580320127308369
Epoch:  221  	Training Loss: 0.0019920445047318935
Test Loss:  0.0015254626050591469
Valid Loss:  0.0017579685663804412
Epoch:  222  	Training Loss: 0.0019919774495065212
Test Loss:  0.0015254049794748425
Valid Loss:  0.001757909543812275
Epoch:  223  	Training Loss: 0.001991912489756942
Test Loss:  0.0015253503806889057
Valid Loss:  0.001757850288413465
Epoch:  224  	Training Loss: 0.001991845900192857
Test Loss:  0.0015252998564392328
Valid Loss:  0.0017577891703695059
Epoch:  225  	Training Loss: 0.001991779776290059
Test Loss:  0.0015252412995323539
Valid Loss:  0.0017577288672327995
Epoch:  226  	Training Loss: 0.0019917150493711233
Test Loss:  0.0015251899603754282
Valid Loss:  0.0017576704267412424
Epoch:  227  	Training Loss: 0.0019916484598070383
Test Loss:  0.0015251338481903076
Valid Loss:  0.0017576124519109726
Epoch:  228  	Training Loss: 0.0019915837328881025
Test Loss:  0.001525078434497118
Valid Loss:  0.001757552265189588
Epoch:  229  	Training Loss: 0.0019915197044610977
Test Loss:  0.0015250265132635832
Valid Loss:  0.0017574912635609508
Epoch:  230  	Training Loss: 0.0019914531148970127
Test Loss:  0.0015249683056026697
Valid Loss:  0.0017574331723153591
Epoch:  231  	Training Loss: 0.0019913867581635714
Test Loss:  0.0015249140560626984
Valid Loss:  0.0017573739169165492
Epoch:  232  	Training Loss: 0.001991321798413992
Test Loss:  0.0015248634153977036
Valid Loss:  0.0017573116347193718
Epoch:  233  	Training Loss: 0.0019912573043257
Test Loss:  0.001524806604720652
Valid Loss:  0.0017572547076269984
Epoch:  234  	Training Loss: 0.0019911909475922585
Test Loss:  0.0015247534029185772
Valid Loss:  0.0017571956850588322
Epoch:  235  	Training Loss: 0.001991125289350748
Test Loss:  0.0015246989205479622
Valid Loss:  0.0017571370117366314
Epoch:  236  	Training Loss: 0.0019910610280930996
Test Loss:  0.0015246430411934853
Valid Loss:  0.0017570756608620286
Epoch:  237  	Training Loss: 0.001990996766835451
Test Loss:  0.0015245925169438124
Valid Loss:  0.001757018151693046
Epoch:  238  	Training Loss: 0.0019909320399165154
Test Loss:  0.0015245359390974045
Valid Loss:  0.0017569586634635925
Epoch:  239  	Training Loss: 0.0019908668473362923
Test Loss:  0.0015244821552187204
Valid Loss:  0.0017569009214639664
Epoch:  240  	Training Loss: 0.0019908021204173565
Test Loss:  0.0015244295354932547
Valid Loss:  0.001756842015311122
Epoch:  241  	Training Loss: 0.0019907369278371334
Test Loss:  0.0015243727248162031
Valid Loss:  0.0017567819450050592
Epoch:  242  	Training Loss: 0.001990671269595623
Test Loss:  0.0015243177767843008
Valid Loss:  0.0017567238537594676
Epoch:  243  	Training Loss: 0.001990607241168618
Test Loss:  0.001524266554042697
Valid Loss:  0.0017566676251590252
Epoch:  244  	Training Loss: 0.001990542747080326
Test Loss:  0.0015242118388414383
Valid Loss:  0.0017566048773005605
Epoch:  245  	Training Loss: 0.0019904773216694593
Test Loss:  0.001524156890809536
Valid Loss:  0.0017565492307767272
Epoch:  246  	Training Loss: 0.001990413758903742
Test Loss:  0.0015241054352372885
Valid Loss:  0.0017564897425472736
Epoch:  247  	Training Loss: 0.0019903485663235188
Test Loss:  0.0015240495558828115
Valid Loss:  0.0017564304871484637
Epoch:  248  	Training Loss: 0.001990285236388445
Test Loss:  0.0015239971689879894
Valid Loss:  0.0017563716974109411
Epoch:  249  	Training Loss: 0.0019902207423001528
Test Loss:  0.0015239394269883633
Valid Loss:  0.0017563131405040622
Epoch:  250  	Training Loss: 0.0019901562482118607
Test Loss:  0.001523887855000794
Valid Loss:  0.0017562577268108726
Epoch:  251  	Training Loss: 0.0019900917541235685
Test Loss:  0.0015238330233842134
Valid Loss:  0.001756196841597557
Epoch:  252  	Training Loss: 0.001990026794373989
Test Loss:  0.0015237809857353568
Valid Loss:  0.0017561388667672873
Epoch:  253  	Training Loss: 0.001989962998777628
Test Loss:  0.0015237284824252129
Valid Loss:  0.001756081823259592
Epoch:  254  	Training Loss: 0.001989897107705474
Test Loss:  0.0015236769104376435
Valid Loss:  0.0017560218693688512
Epoch:  255  	Training Loss: 0.0019898354075849056
Test Loss:  0.0015236211474984884
Valid Loss:  0.001755966804921627
Epoch:  256  	Training Loss: 0.001989771146327257
Test Loss:  0.0015235719038173556
Valid Loss:  0.001755906268954277
Epoch:  257  	Training Loss: 0.0019897071179002523
Test Loss:  0.0015235149767249823
Valid Loss:  0.0017558492254465818
Epoch:  258  	Training Loss: 0.0019896426238119602
Test Loss:  0.001523462706245482
Valid Loss:  0.0017557896208018064
Epoch:  259  	Training Loss: 0.001989578828215599
Test Loss:  0.0015234119491651654
Valid Loss:  0.0017557346727699041
Epoch:  260  	Training Loss: 0.001989515731111169
Test Loss:  0.001523354323580861
Valid Loss:  0.0017556753009557724
Epoch:  261  	Training Loss: 0.001989453099668026
Test Loss:  0.0015233028680086136
Valid Loss:  0.0017556181410327554
Epoch:  262  	Training Loss: 0.001989387907087803
Test Loss:  0.0015232500154525042
Valid Loss:  0.001755559933371842
Epoch:  263  	Training Loss: 0.001989324577152729
Test Loss:  0.0015231959987431765
Valid Loss:  0.0017555016092956066
Epoch:  264  	Training Loss: 0.0019892617128789425
Test Loss:  0.001523144543170929
Valid Loss:  0.0017554438672959805
Epoch:  265  	Training Loss: 0.0019891972187906504
Test Loss:  0.0015230902936309576
Valid Loss:  0.0017553846118971705
Epoch:  266  	Training Loss: 0.0019891345873475075
Test Loss:  0.0015230383723974228
Valid Loss:  0.0017553283832967281
Epoch:  267  	Training Loss: 0.0019890707917511463
Test Loss:  0.0015229887794703245
Valid Loss:  0.0017552709905430675
Epoch:  268  	Training Loss: 0.0019890079274773598
Test Loss:  0.001522931968793273
Valid Loss:  0.0017552160425111651
Epoch:  269  	Training Loss: 0.0019889436662197113
Test Loss:  0.0015228796983137727
Valid Loss:  0.0017551558557897806
Epoch:  270  	Training Loss: 0.0019888808019459248
Test Loss:  0.0015228257980197668
Valid Loss:  0.0017550989286974072
Epoch:  271  	Training Loss: 0.00198881677351892
Test Loss:  0.0015227722469717264
Valid Loss:  0.0017550429329276085
Epoch:  272  	Training Loss: 0.0019887546077370644
Test Loss:  0.00152272277045995
Valid Loss:  0.001754984725266695
Epoch:  273  	Training Loss: 0.001988692209124565
Test Loss:  0.0015226693358272314
Valid Loss:  0.0017549300100654364
Epoch:  274  	Training Loss: 0.0019886286463588476
Test Loss:  0.001522614387795329
Valid Loss:  0.0017548701725900173
Epoch:  275  	Training Loss: 0.001988566480576992
Test Loss:  0.001522565959021449
Valid Loss:  0.0017548131290823221
Epoch:  276  	Training Loss: 0.001988504081964493
Test Loss:  0.0015225143870338798
Valid Loss:  0.0017547577153891325
 55%|█████▌    | 277/500 [03:11<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:11<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:17<04:19,  1.18s/it] 57%|█████▋    | 283/500 [03:18<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:18<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:18<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:18<01:11,  2.97it/s] 58%|█████▊    | 291/500 [03:24<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:24<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:25<02:06,  1.63it/s] 59%|█████▉    | 297/500 [03:25<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:25<01:07,  2.98it/s] 60%|██████    | 301/500 [03:31<03:54,  1.18s/it] 61%|██████    | 303/500 [03:31<02:46,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:32<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:38<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:38<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:38<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:38<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:39<01:00,  2.97it/s] 64%|██████▍   | 321/500 [03:45<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:45<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:45<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:45<01:19,  2.19it/s] 66%|██████▌   | 329/500 [03:45<00:58,  2.94it/s] 66%|██████▌   | 331/500 [03:52<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:52<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:52<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:52<01:14,  2.20it/s] 68%|██████▊   | 339/500 [03:52<00:54,  2.96it/s] 68%|██████▊   | 341/500 [03:59<03:12,  1.21s/it] 69%|██████▊   | 343/500 [03:59<02:16,  1.15it/s]Epoch:  277  	Training Loss: 0.0019884409848600626
Test Loss:  0.0015224609524011612
Valid Loss:  0.0017547026509419084
Epoch:  278  	Training Loss: 0.001988379517570138
Test Loss:  0.0015224084490910172
Valid Loss:  0.0017546460730955005
Epoch:  279  	Training Loss: 0.001988315721973777
Test Loss:  0.0015223559457808733
Valid Loss:  0.0017545879818499088
Epoch:  280  	Training Loss: 0.001988254487514496
Test Loss:  0.0015223069349303842
Valid Loss:  0.0017545311711728573
Epoch:  281  	Training Loss: 0.001988191157579422
Test Loss:  0.001522253965958953
Valid Loss:  0.0017544743604958057
Epoch:  282  	Training Loss: 0.00198812922462821
Test Loss:  0.0015222004149109125
Valid Loss:  0.0017544192960485816
Epoch:  283  	Training Loss: 0.001988066593185067
Test Loss:  0.0015221521025523543
Valid Loss:  0.0017543603898957372
Epoch:  284  	Training Loss: 0.001988004893064499
Test Loss:  0.0015220972709357738
Valid Loss:  0.0017543032299727201
Epoch:  285  	Training Loss: 0.001987941563129425
Test Loss:  0.0015220465138554573
Valid Loss:  0.0017542471177875996
Epoch:  286  	Training Loss: 0.0019878798630088568
Test Loss:  0.0015219936612993479
Valid Loss:  0.0017541927518323064
Epoch:  287  	Training Loss: 0.001987817231565714
Test Loss:  0.0015219412744045258
Valid Loss:  0.001754135126248002
Epoch:  288  	Training Loss: 0.001987755298614502
Test Loss:  0.001521890633739531
Valid Loss:  0.0017540780827403069
Epoch:  289  	Training Loss: 0.00198769336566329
Test Loss:  0.0015218367334455252
Valid Loss:  0.0017540245316922665
Epoch:  290  	Training Loss: 0.001987631432712078
Test Loss:  0.001521785045042634
Valid Loss:  0.0017539691179990768
Epoch:  291  	Training Loss: 0.001987567637115717
Test Loss:  0.0015217338223010302
Valid Loss:  0.001753909164108336
Epoch:  292  	Training Loss: 0.001987506402656436
Test Loss:  0.0015216825995594263
Valid Loss:  0.0017538516549393535
Epoch:  293  	Training Loss: 0.001987444469705224
Test Loss:  0.0015216342872008681
Valid Loss:  0.0017537979874759912
Epoch:  294  	Training Loss: 0.001987383235245943
Test Loss:  0.0015215810853987932
Valid Loss:  0.0017537435051053762
Epoch:  295  	Training Loss: 0.001987320836633444
Test Loss:  0.0015215282328426838
Valid Loss:  0.0017536835512146354
Epoch:  296  	Training Loss: 0.0019872598350048065
Test Loss:  0.0015214798040688038
Valid Loss:  0.001753630000166595
Epoch:  297  	Training Loss: 0.001987199066206813
Test Loss:  0.001521427882835269
Valid Loss:  0.001753574120812118
Epoch:  298  	Training Loss: 0.0019871355034410954
Test Loss:  0.0015213778242468834
Valid Loss:  0.0017535171937197447
Epoch:  299  	Training Loss: 0.0019870735704898834
Test Loss:  0.0015213224105536938
Valid Loss:  0.0017534627113491297
Epoch:  300  	Training Loss: 0.001987012103199959
Test Loss:  0.001521269790828228
Valid Loss:  0.0017534043872728944
Epoch:  301  	Training Loss: 0.001986950635910034
Test Loss:  0.0015212222933769226
Valid Loss:  0.0017533485079184175
Epoch:  302  	Training Loss: 0.001986889634281397
Test Loss:  0.001521167578175664
Valid Loss:  0.0017532951897010207
Epoch:  303  	Training Loss: 0.0019868279341608286
Test Loss:  0.0015211185673251748
Valid Loss:  0.0017532382626086473
Epoch:  304  	Training Loss: 0.001986767165362835
Test Loss:  0.0015210676938295364
Valid Loss:  0.0017531823832541704
Epoch:  305  	Training Loss: 0.001986705232411623
Test Loss:  0.0015210160054266453
Valid Loss:  0.0017531272023916245
Epoch:  306  	Training Loss: 0.001986643997952342
Test Loss:  0.001520965714007616
Valid Loss:  0.0017530726036056876
Epoch:  307  	Training Loss: 0.0019865829963237047
Test Loss:  0.00152091053314507
Valid Loss:  0.0017530170734971762
Epoch:  308  	Training Loss: 0.001986522227525711
Test Loss:  0.0015208607073873281
Valid Loss:  0.0017529625911265612
Epoch:  309  	Training Loss: 0.001986460294574499
Test Loss:  0.0015208108816295862
Valid Loss:  0.0017529046162962914
Epoch:  310  	Training Loss: 0.001986399060115218
Test Loss:  0.0015207600081339478
Valid Loss:  0.0017528482712805271
Epoch:  311  	Training Loss: 0.00198633735999465
Test Loss:  0.0015207105316221714
Valid Loss:  0.0017527927411720157
Epoch:  312  	Training Loss: 0.0019862791523337364
Test Loss:  0.0015206579118967056
Valid Loss:  0.0017527395393699408
Epoch:  313  	Training Loss: 0.00198621628805995
Test Loss:  0.0015206083189696074
Valid Loss:  0.0017526858719065785
Epoch:  314  	Training Loss: 0.0019861566834151745
Test Loss:  0.00152055942453444
Valid Loss:  0.0017526282463222742
Epoch:  315  	Training Loss: 0.001986094983294606
Test Loss:  0.0015205064555630088
Valid Loss:  0.0017525739967823029
Epoch:  316  	Training Loss: 0.0019860346801579
Test Loss:  0.001520455814898014
Valid Loss:  0.0017525191651657224
Epoch:  317  	Training Loss: 0.00198597414419055
Test Loss:  0.001520406687632203
Valid Loss:  0.0017524647992104292
Epoch:  318  	Training Loss: 0.0019859126769006252
Test Loss:  0.0015203540679067373
Valid Loss:  0.0017524093855172396
Epoch:  319  	Training Loss: 0.001985852839425206
Test Loss:  0.0015203066868707538
Valid Loss:  0.0017523542046546936
Epoch:  320  	Training Loss: 0.001985791604965925
Test Loss:  0.0015202517388388515
Valid Loss:  0.0017523010028526187
Epoch:  321  	Training Loss: 0.001985731068998575
Test Loss:  0.0015202026115730405
Valid Loss:  0.001752244308590889
Epoch:  322  	Training Loss: 0.0019856682047247887
Test Loss:  0.0015201536007225513
Valid Loss:  0.0017521863337606192
Epoch:  323  	Training Loss: 0.001985610695555806
Test Loss:  0.0015201021451503038
Valid Loss:  0.0017521341796964407
Epoch:  324  	Training Loss: 0.0019855487626045942
Test Loss:  0.0015200533671304584
Valid Loss:  0.0017520802794024348
Epoch:  325  	Training Loss: 0.0019854893907904625
Test Loss:  0.0015200027264654636
Valid Loss:  0.0017520261462777853
Epoch:  326  	Training Loss: 0.0019854293204844
Test Loss:  0.001519951969385147
Valid Loss:  0.0017519717803224921
Epoch:  327  	Training Loss: 0.001985368551686406
Test Loss:  0.0015199027257040143
Valid Loss:  0.0017519148532301188
Epoch:  328  	Training Loss: 0.0019853082485497
Test Loss:  0.001519850455224514
Valid Loss:  0.0017518645618110895
Epoch:  329  	Training Loss: 0.0019852477125823498
Test Loss:  0.001519802026450634
Valid Loss:  0.0017518072854727507
Epoch:  330  	Training Loss: 0.0019851867109537125
Test Loss:  0.0015197497559711337
Valid Loss:  0.0017517509404569864
Epoch:  331  	Training Loss: 0.0019851268734782934
Test Loss:  0.0015196993481367826
Valid Loss:  0.0017516977386549115
Epoch:  332  	Training Loss: 0.0019850670360028744
Test Loss:  0.0015196509193629026
Valid Loss:  0.0017516433726996183
Epoch:  333  	Training Loss: 0.0019850069656968117
Test Loss:  0.001519600278697908
Valid Loss:  0.0017515893559902906
Epoch:  334  	Training Loss: 0.001984948292374611
Test Loss:  0.0015195516170933843
Valid Loss:  0.0017515352228656411
Epoch:  335  	Training Loss: 0.0019848879892379045
Test Loss:  0.0015194994630292058
Valid Loss:  0.0017514796927571297
Epoch:  336  	Training Loss: 0.001984827686101198
Test Loss:  0.0015194498701021075
Valid Loss:  0.0017514257924631238
Epoch:  337  	Training Loss: 0.0019847669173032045
Test Loss:  0.0015194021398201585
Valid Loss:  0.0017513723578304052
Epoch:  338  	Training Loss: 0.001984706846997142
Test Loss:  0.0015193498693406582
Valid Loss:  0.0017513188067823648
Epoch:  339  	Training Loss: 0.001984648173674941
Test Loss:  0.0015193030703812838
Valid Loss:  0.0017512638587504625
Epoch:  340  	Training Loss: 0.0019845878705382347
Test Loss:  0.0015192496357485652
Valid Loss:  0.0017512106569483876
Epoch:  341  	Training Loss: 0.0019845282658934593
Test Loss:  0.0015192035352811217
Valid Loss:  0.0017511544283479452
Epoch:  342  	Training Loss: 0.0019844677299261093
Test Loss:  0.0015191552229225636
Valid Loss:  0.0017511029727756977
Epoch:  343  	Training Loss: 0.001984409522265196
Test Loss:  0.0015191012062132359
Valid Loss:  0.001751049654558301
Epoch:  344  	Training Loss: 0.001984349684789777
Test Loss:  0.0015190518461167812
Valid Loss:  0.0017509934259578586
Epoch:  345  	Training Loss: 0.0019842905458062887
Test Loss:  0.0015190031845122576
Valid Loss:   69%|██████▉   | 345/500 [03:59<01:37,  1.60it/s] 69%|██████▉   | 347/500 [03:59<01:10,  2.18it/s] 70%|██████▉   | 349/500 [03:59<00:51,  2.93it/s] 70%|███████   | 351/500 [04:06<03:00,  1.21s/it] 71%|███████   | 353/500 [04:06<02:07,  1.15it/s] 71%|███████   | 355/500 [04:06<01:31,  1.59it/s] 71%|███████▏  | 357/500 [04:06<01:05,  2.18it/s] 72%|███████▏  | 359/500 [04:06<00:48,  2.91it/s] 72%|███████▏  | 361/500 [04:13<02:48,  1.21s/it] 73%|███████▎  | 363/500 [04:13<01:59,  1.15it/s] 73%|███████▎  | 365/500 [04:13<01:24,  1.59it/s] 73%|███████▎  | 367/500 [04:13<01:01,  2.17it/s] 74%|███████▍  | 369/500 [04:13<00:44,  2.93it/s] 74%|███████▍  | 371/500 [04:20<02:35,  1.20s/it] 75%|███████▍  | 373/500 [04:20<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:20<01:17,  1.60it/s] 75%|███████▌  | 377/500 [04:20<00:56,  2.19it/s] 76%|███████▌  | 379/500 [04:20<00:41,  2.95it/s] 76%|███████▌  | 381/500 [04:27<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:27<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:27<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:27<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:27<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:34<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:34<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:34<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:34<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:34<00:33,  2.98it/s] 80%|████████  | 401/500 [04:41<01:58,  1.20s/it] 81%|████████  | 403/500 [04:41<01:23,  1.17it/s] 81%|████████  | 405/500 [04:41<00:58,  1.61it/s] 81%|████████▏ | 407/500 [04:41<00:42,  2.20it/s] 82%|████████▏ | 409/500 [04:41<00:30,  2.97it/s] 82%|████████▏ | 411/500 [04:48<01:47,  1.21s/it] 83%|████████▎ | 413/500 [04:48<01:15,  1.15it/s]0.0017509391764178872
Epoch:  346  	Training Loss: 0.0019842307083308697
Test Loss:  0.0015189528930932283
Valid Loss:  0.0017508865566924214
Epoch:  347  	Training Loss: 0.0019841715693473816
Test Loss:  0.0015189062105491757
Valid Loss:  0.0017508327728137374
Epoch:  348  	Training Loss: 0.001984112896025181
Test Loss:  0.001518850913271308
Valid Loss:  0.0017507791053503752
Epoch:  349  	Training Loss: 0.001984052825719118
Test Loss:  0.0015188023680821061
Valid Loss:  0.0017507256707176566
Epoch:  350  	Training Loss: 0.001983994385227561
Test Loss:  0.001518754754215479
Valid Loss:  0.001750670257024467
Epoch:  351  	Training Loss: 0.0019839343149214983
Test Loss:  0.0015187032986432314
Valid Loss:  0.0017506163567304611
Epoch:  352  	Training Loss: 0.001983874710276723
Test Loss:  0.0015186592936515808
Valid Loss:  0.001750562689267099
Epoch:  353  	Training Loss: 0.001983815338462591
Test Loss:  0.001518607372418046
Valid Loss:  0.0017505098367109895
Epoch:  354  	Training Loss: 0.0019837564323097467
Test Loss:  0.0015185587108135223
Valid Loss:  0.0017504545394331217
Epoch:  355  	Training Loss: 0.001983697060495615
Test Loss:  0.0015185102820396423
Valid Loss:  0.0017504028510302305
Epoch:  356  	Training Loss: 0.001983639318495989
Test Loss:  0.0015184568474069238
Valid Loss:  0.001750349998474121
Epoch:  357  	Training Loss: 0.001983579946681857
Test Loss:  0.001518413657322526
Valid Loss:  0.0017502943519502878
Epoch:  358  	Training Loss: 0.0019835203420370817
Test Loss:  0.0015183608047664165
Valid Loss:  0.0017502439441159368
Epoch:  359  	Training Loss: 0.0019834614358842373
Test Loss:  0.0015183119103312492
Valid Loss:  0.0017501902766525745
Epoch:  360  	Training Loss: 0.00198340299539268
Test Loss:  0.001518263597972691
Valid Loss:  0.0017501359106972814
Epoch:  361  	Training Loss: 0.0019833440892398357
Test Loss:  0.0015182149363681674
Valid Loss:  0.0017500813119113445
Epoch:  362  	Training Loss: 0.0019832835532724857
Test Loss:  0.0015181666240096092
Valid Loss:  0.001750028459355235
Epoch:  363  	Training Loss: 0.001983226742595434
Test Loss:  0.001518115634098649
Valid Loss:  0.0017499772366136312
Epoch:  364  	Training Loss: 0.001983167137950659
Test Loss:  0.0015180668560788035
Valid Loss:  0.0017499233363196254
Epoch:  365  	Training Loss: 0.001983108464628458
Test Loss:  0.00151801947504282
Valid Loss:  0.0017498719971626997
Epoch:  366  	Training Loss: 0.0019830502569675446
Test Loss:  0.0015179682523012161
Valid Loss:  0.0017498168163001537
Epoch:  367  	Training Loss: 0.001982990885153413
Test Loss:  0.001517921220511198
Valid Loss:  0.0017497625667601824
Epoch:  368  	Training Loss: 0.001982932910323143
Test Loss:  0.0015178699977695942
Valid Loss:  0.0017497085500508547
Epoch:  369  	Training Loss: 0.0019828733056783676
Test Loss:  0.0015178207540884614
Valid Loss:  0.0017496581422165036
Epoch:  370  	Training Loss: 0.001982814632356167
Test Loss:  0.0015177754685282707
Valid Loss:  0.0017496035434305668
Epoch:  371  	Training Loss: 0.0019827568903565407
Test Loss:  0.001517722848802805
Valid Loss:  0.0017495510401204228
Epoch:  372  	Training Loss: 0.001982698682695627
Test Loss:  0.0015176767483353615
Valid Loss:  0.0017494959756731987
Epoch:  373  	Training Loss: 0.001982639776542783
Test Loss:  0.0015176271554082632
Valid Loss:  0.001749446615576744
Epoch:  374  	Training Loss: 0.001982581103220582
Test Loss:  0.001517577562481165
Valid Loss:  0.0017493917839601636
Epoch:  375  	Training Loss: 0.001982523128390312
Test Loss:  0.0015175289008766413
Valid Loss:  0.0017493388149887323
Epoch:  376  	Training Loss: 0.0019824665505439043
Test Loss:  0.0015174828004091978
Valid Loss:  0.0017492870101705194
Epoch:  377  	Training Loss: 0.0019824067130684853
Test Loss:  0.0015174357686191797
Valid Loss:  0.0017492346232756972
Epoch:  378  	Training Loss: 0.00198234966956079
Test Loss:  0.001517385826446116
Valid Loss:  0.0017491825856268406
Epoch:  379  	Training Loss: 0.0019822902977466583
Test Loss:  0.0015173351857811213
Valid Loss:  0.0017491290345788002
Epoch:  380  	Training Loss: 0.001982232090085745
Test Loss:  0.0015172886196523905
Valid Loss:  0.0017490768805146217
Epoch:  381  	Training Loss: 0.0019821738824248314
Test Loss:  0.0015172407729551196
Valid Loss:  0.001749023562297225
Epoch:  382  	Training Loss: 0.001982116838917136
Test Loss:  0.0015171916456893086
Valid Loss:  0.0017489707097411156
Epoch:  383  	Training Loss: 0.001982057234272361
Test Loss:  0.0015171419363468885
Valid Loss:  0.0017489207675680518
Epoch:  384  	Training Loss: 0.001981999259442091
Test Loss:  0.0015170923434197903
Valid Loss:  0.0017488625599071383
Epoch:  385  	Training Loss: 0.0019819429144263268
Test Loss:  0.0015170457772910595
Valid Loss:  0.0017488138983026147
Epoch:  386  	Training Loss: 0.0019818837754428387
Test Loss:  0.001516998279839754
Valid Loss:  0.0017487592995166779
Epoch:  387  	Training Loss: 0.001981827663257718
Test Loss:  0.0015169518301263452
Valid Loss:  0.001748708775267005
Epoch:  388  	Training Loss: 0.00198176852427423
Test Loss:  0.001516900840215385
Valid Loss:  0.0017486556898802519
Epoch:  389  	Training Loss: 0.001981709385290742
Test Loss:  0.0015168518293648958
Valid Loss:  0.0017486043507233262
Epoch:  390  	Training Loss: 0.0019816539715975523
Test Loss:  0.0015168063109740615
Valid Loss:  0.0017485503340139985
Epoch:  391  	Training Loss: 0.0019815952982753515
Test Loss:  0.0015167571837082505
Valid Loss:  0.0017484996933490038
Epoch:  392  	Training Loss: 0.0019815366249531507
Test Loss:  0.001516711083240807
Valid Loss:  0.001748445676639676
Epoch:  393  	Training Loss: 0.001981480047106743
Test Loss:  0.0015166590455919504
Valid Loss:  0.0017483953852206469
Epoch:  394  	Training Loss: 0.001981422770768404
Test Loss:  0.001516613643616438
Valid Loss:  0.0017483425326645374
Epoch:  395  	Training Loss: 0.0019813659600913525
Test Loss:  0.0015165641671046615
Valid Loss:  0.0017482922412455082
Epoch:  396  	Training Loss: 0.001981307752430439
Test Loss:  0.001516518066637218
Valid Loss:  0.0017482393886893988
Epoch:  397  	Training Loss: 0.0019812502432614565
Test Loss:  0.0015164710348472
Valid Loss:  0.0017481877002865076
Epoch:  398  	Training Loss: 0.0019811922684311867
Test Loss:  0.0015164220239967108
Valid Loss:  0.0017481344984844327
Epoch:  399  	Training Loss: 0.001981134992092848
Test Loss:  0.0015163756906986237
Valid Loss:  0.0017480812966823578
Epoch:  400  	Training Loss: 0.0019810788799077272
Test Loss:  0.0015163266798481345
Valid Loss:  0.001748031354509294
Epoch:  401  	Training Loss: 0.00198102043941617
Test Loss:  0.0015162767376750708
Valid Loss:  0.0017479776870459318
Epoch:  402  	Training Loss: 0.0019809636287391186
Test Loss:  0.0015162306372076273
Valid Loss:  0.001747926464304328
Epoch:  403  	Training Loss: 0.0019809058867394924
Test Loss:  0.0015161845367401838
Valid Loss:  0.0017478729132562876
Epoch:  404  	Training Loss: 0.001980849541723728
Test Loss:  0.0015161364572122693
Valid Loss:  0.0017478230874985456
Epoch:  405  	Training Loss: 0.0019807913340628147
Test Loss:  0.0015160880284383893
Valid Loss:  0.001747773727402091
Epoch:  406  	Training Loss: 0.001980733359232545
Test Loss:  0.001516043092124164
Valid Loss:  0.001747719245031476
Epoch:  407  	Training Loss: 0.0019806777127087116
Test Loss:  0.0015159936156123877
Valid Loss:  0.0017476696521043777
Epoch:  408  	Training Loss: 0.0019806199707090855
Test Loss:  0.001515945652499795
Valid Loss:  0.0017476179637014866
Epoch:  409  	Training Loss: 0.0019805640913546085
Test Loss:  0.0015158997848629951
Valid Loss:  0.00174756592605263
Epoch:  410  	Training Loss: 0.0019805061165243387
Test Loss:  0.0015158485621213913
Valid Loss:  0.001747515401802957
Epoch:  411  	Training Loss: 0.001980448607355356
Test Loss:  0.0015158038586378098
Valid Loss:  0.0017474619671702385
Epoch:  412  	Training Loss: 0.00198039086535573
Test Loss:  0.0015157577581703663
Valid Loss:  0.0017474107444286346
Epoch:  413  	Training Loss: 0.001980336382985115
Test Loss:  0.0015157109592109919
Valid Loss:  0.0017473604530096054
Epoch:  414  	Training Loss: 0.0019802777096629143
Test Loss:  0.00151566241402179
 83%|████████▎ | 415/500 [04:48<00:53,  1.60it/s] 83%|████████▎ | 417/500 [04:48<00:38,  2.18it/s] 84%|████████▍ | 419/500 [04:48<00:27,  2.94it/s] 84%|████████▍ | 421/500 [04:54<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:55<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:55<00:45,  1.63it/s] 85%|████████▌ | 427/500 [04:55<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:55<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:01<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:01<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:02<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:02<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:02<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:08<01:11,  1.21s/it] 89%|████████▊ | 443/500 [05:08<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:09<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:09<00:24,  2.18it/s] 90%|████████▉ | 449/500 [05:09<00:17,  2.93it/s] 90%|█████████ | 451/500 [05:15<00:58,  1.20s/it] 91%|█████████ | 453/500 [05:15<00:40,  1.16it/s] 91%|█████████ | 455/500 [05:16<00:28,  1.60it/s] 91%|█████████▏| 457/500 [05:16<00:19,  2.19it/s] 92%|█████████▏| 459/500 [05:16<00:13,  2.94it/s] 92%|█████████▏| 461/500 [05:22<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:22<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:23<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:23<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:29<00:35,  1.22s/it] 95%|█████████▍| 473/500 [05:29<00:23,  1.14it/s] 95%|█████████▌| 475/500 [05:30<00:15,  1.58it/s] 95%|█████████▌| 477/500 [05:30<00:10,  2.16it/s] 96%|█████████▌| 479/500 [05:30<00:07,  2.91it/s] 96%|█████████▌| 481/500 [05:36<00:22,  1.19s/it]Valid Loss:  0.0017473094630986452
Epoch:  415  	Training Loss: 0.0019802208989858627
Test Loss:  0.0015156148001551628
Valid Loss:  0.0017472575418651104
Epoch:  416  	Training Loss: 0.0019801657181233168
Test Loss:  0.0015155666042119265
Valid Loss:  0.0017472058534622192
Epoch:  417  	Training Loss: 0.001980107743293047
Test Loss:  0.0015155206201598048
Valid Loss:  0.00174715556204319
Epoch:  418  	Training Loss: 0.001980049768462777
Test Loss:  0.0015154742868617177
Valid Loss:  0.0017471034079790115
Epoch:  419  	Training Loss: 0.001979995518922806
Test Loss:  0.0015154286520555615
Valid Loss:  0.0017470527673140168
Epoch:  420  	Training Loss: 0.0019799373112618923
Test Loss:  0.0015153794083744287
Valid Loss:  0.001747002126649022
Epoch:  421  	Training Loss: 0.0019798821303993464
Test Loss:  0.0015153330750763416
Valid Loss:  0.0017469499725848436
Epoch:  422  	Training Loss: 0.0019798241555690765
Test Loss:  0.001515284413471818
Valid Loss:  0.0017468970036134124
Epoch:  423  	Training Loss: 0.0019797668792307377
Test Loss:  0.001515239360742271
Valid Loss:  0.0017468456644564867
Epoch:  424  	Training Loss: 0.0019797119311988354
Test Loss:  0.0015151919797062874
Valid Loss:  0.0017467954894527793
Epoch:  425  	Training Loss: 0.001979655120521784
Test Loss:  0.0015151440165936947
Valid Loss:  0.0017467456636950374
Epoch:  426  	Training Loss: 0.0019795987755060196
Test Loss:  0.0015150988474488258
Valid Loss:  0.0017466938588768244
Epoch:  427  	Training Loss: 0.0019795417319983244
Test Loss:  0.0015150501858443022
Valid Loss:  0.001746641704812646
Epoch:  428  	Training Loss: 0.0019794844556599855
Test Loss:  0.0015150036197155714
Valid Loss:  0.001746593858115375
Epoch:  429  	Training Loss: 0.0019794281106442213
Test Loss:  0.0015149562386795878
Valid Loss:  0.0017465394921600819
Epoch:  430  	Training Loss: 0.0019793726969510317
Test Loss:  0.0015149086248129606
Valid Loss:  0.0017464871052652597
Epoch:  431  	Training Loss: 0.001979315187782049
Test Loss:  0.001514865318313241
Valid Loss:  0.001746437163092196
Epoch:  432  	Training Loss: 0.0019792590755969286
Test Loss:  0.001514813513495028
Valid Loss:  0.001746386638842523
Epoch:  433  	Training Loss: 0.001979202264919877
Test Loss:  0.0015147640369832516
Valid Loss:  0.0017463352996855974
Epoch:  434  	Training Loss: 0.0019791461527347565
Test Loss:  0.001514721428975463
Valid Loss:  0.0017462846590206027
Epoch:  435  	Training Loss: 0.0019790902733802795
Test Loss:  0.0015146726509556174
Valid Loss:  0.001746232621371746
Epoch:  436  	Training Loss: 0.001979034161195159
Test Loss:  0.001514625851996243
Valid Loss:  0.001746182213537395
Epoch:  437  	Training Loss: 0.0019789778161793947
Test Loss:  0.0015145777724683285
Valid Loss:  0.0017461333191022277
Epoch:  438  	Training Loss: 0.0019789221696555614
Test Loss:  0.001514533068984747
Valid Loss:  0.0017460811650380492
Epoch:  439  	Training Loss: 0.00197886535897851
Test Loss:  0.001514484523795545
Valid Loss:  0.0017460295930504799
Epoch:  440  	Training Loss: 0.0019788106437772512
Test Loss:  0.0015144378412514925
Valid Loss:  0.001745979767292738
Epoch:  441  	Training Loss: 0.0019787533674389124
Test Loss:  0.00151439371984452
Valid Loss:  0.0017459264490753412
Epoch:  442  	Training Loss: 0.001978697720915079
Test Loss:  0.0015143451746553183
Valid Loss:  0.0017458779038861394
Epoch:  443  	Training Loss: 0.001978641375899315
Test Loss:  0.001514301635324955
Valid Loss:  0.0017458264483138919
Epoch:  444  	Training Loss: 0.0019785859622061253
Test Loss:  0.001514252508059144
Valid Loss:  0.0017457767389714718
Epoch:  445  	Training Loss: 0.0019785300828516483
Test Loss:  0.0015142079209908843
Valid Loss:  0.001745726098306477
Epoch:  446  	Training Loss: 0.0019784749019891024
Test Loss:  0.0015141600742936134
Valid Loss:  0.0017456761561334133
Epoch:  447  	Training Loss: 0.00197841739282012
Test Loss:  0.0015141121111810207
Valid Loss:  0.0017456253990530968
Epoch:  448  	Training Loss: 0.001978361513465643
Test Loss:  0.001514070201665163
Valid Loss:  0.0017455744091421366
Epoch:  449  	Training Loss: 0.0019783060997724533
Test Loss:  0.0015140196774154902
Valid Loss:  0.0017455262131989002
Epoch:  450  	Training Loss: 0.0019782506860792637
Test Loss:  0.001513973344117403
Valid Loss:  0.0017454733606427908
Epoch:  451  	Training Loss: 0.0019781943410634995
Test Loss:  0.0015139288734644651
Valid Loss:  0.0017454245826229453
Epoch:  452  	Training Loss: 0.0019781384617090225
Test Loss:  0.0015138807939365506
Valid Loss:  0.0017453746404498816
Epoch:  453  	Training Loss: 0.0019780825823545456
Test Loss:  0.0015138378366827965
Valid Loss:  0.0017453206237405539
Epoch:  454  	Training Loss: 0.0019780280999839306
Test Loss:  0.0015137882437556982
Valid Loss:  0.0017452717293053865
Epoch:  455  	Training Loss: 0.00197797198779881
Test Loss:  0.0015137430746108294
Valid Loss:  0.0017452227184548974
Epoch:  456  	Training Loss: 0.001977915409952402
Test Loss:  0.001513695577159524
Valid Loss:  0.0017451730091124773
Epoch:  457  	Training Loss: 0.0019778618589043617
Test Loss:  0.0015136476140469313
Valid Loss:  0.001745122019201517
Epoch:  458  	Training Loss: 0.00197780504822731
Test Loss:  0.0015136031433939934
Valid Loss:  0.0017450728919357061
Epoch:  459  	Training Loss: 0.001977750100195408
Test Loss:  0.0015135561116039753
Valid Loss:  0.0017450217856094241
Epoch:  460  	Training Loss: 0.0019776932895183563
Test Loss:  0.0015135137364268303
Valid Loss:  0.0017449703300371766
Epoch:  461  	Training Loss: 0.0019776374101638794
Test Loss:  0.001513464143499732
Valid Loss:  0.0017449207371100783
Epoch:  462  	Training Loss: 0.0019775829277932644
Test Loss:  0.0015134189743548632
Valid Loss:  0.0017448707949370146
Epoch:  463  	Training Loss: 0.001977526815608144
Test Loss:  0.0015133734559640288
Valid Loss:  0.0017448232974857092
Epoch:  464  	Training Loss: 0.001977473497390747
Test Loss:  0.001513326889835298
Valid Loss:  0.0017447733553126454
Epoch:  465  	Training Loss: 0.001977418316528201
Test Loss:  0.0015132820699363947
Valid Loss:  0.0017447194550186396
Epoch:  466  	Training Loss: 0.001977363135665655
Test Loss:  0.0015132344560697675
Valid Loss:  0.0017446724232286215
Epoch:  467  	Training Loss: 0.0019773070234805346
Test Loss:  0.0015131888212636113
Valid Loss:  0.0017446198035031557
Epoch:  468  	Training Loss: 0.001977252308279276
Test Loss:  0.0015131402760744095
Valid Loss:  0.0017445719568058848
Epoch:  469  	Training Loss: 0.001977197825908661
Test Loss:  0.0015130992978811264
Valid Loss:  0.0017445211997255683
Epoch:  470  	Training Loss: 0.001977140549570322
Test Loss:  0.0015130529645830393
Valid Loss:  0.0017444720724597573
Epoch:  471  	Training Loss: 0.0019770865328609943
Test Loss:  0.0015130056999623775
Valid Loss:  0.0017444220138713717
Epoch:  472  	Training Loss: 0.0019770306535065174
Test Loss:  0.0015129600651562214
Valid Loss:  0.0017443728866055608
Epoch:  473  	Training Loss: 0.001976976403966546
Test Loss:  0.001512911869212985
Valid Loss:  0.0017443234100937843
Epoch:  474  	Training Loss: 0.0019769221544265747
Test Loss:  0.0015128699596971273
Valid Loss:  0.0017442733515053988
Epoch:  475  	Training Loss: 0.0019768665079027414
Test Loss:  0.0015128205996006727
Valid Loss:  0.0017442243406549096
Epoch:  476  	Training Loss: 0.0019768117927014828
Test Loss:  0.0015127734513953328
Valid Loss:  0.001744173583574593
Epoch:  477  	Training Loss: 0.0019767580088227987
Test Loss:  0.0015127313090488315
Valid Loss:  0.0017441241070628166
Epoch:  478  	Training Loss: 0.0019767028279602528
Test Loss:  0.0015126840444281697
Valid Loss:  0.0017440755618736148
Epoch:  479  	Training Loss: 0.0019766478799283504
Test Loss:  0.0015126389916986227
Valid Loss:  0.0017440262017771602
Epoch:  480  	Training Loss: 0.001976592233404517
Test Loss:  0.0015125942882150412
Valid Loss:  0.0017439770745113492
Epoch:  481  	Training Loss: 0.001976538449525833
Test Loss:  0.0015125484205782413
Valid Loss:  0.0017439264338463545
Epoch:  482  	Training Loss: 0.0019764830358326435
Test Loss:  0.0015125058125704527
Valid Loss:  0.0017438773065805435
Epoch:  483  	Training Loss: 0.001976429019123316
 97%|█████████▋| 483/500 [05:36<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:36<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:37<00:05,  2.20it/s] 98%|█████████▊| 489/500 [05:37<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:43<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:43<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:43<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:43<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:44<00:00,  2.95it/s]100%|██████████| 500/500 [05:44<00:00,  1.45it/s]
Test Loss:  0.0015124579658731818
Valid Loss:  0.0017438281793147326
Epoch:  484  	Training Loss: 0.0019763759337365627
Test Loss:  0.0015124117489904165
Valid Loss:  0.0017437791684642434
Epoch:  485  	Training Loss: 0.001976318657398224
Test Loss:  0.0015123661141842604
Valid Loss:  0.0017437294591218233
Epoch:  486  	Training Loss: 0.001976266037672758
Test Loss:  0.0015123216435313225
Valid Loss:  0.0017436810303479433
Epoch:  487  	Training Loss: 0.001976211089640856
Test Loss:  0.0015122740296646953
Valid Loss:  0.0017436306225135922
Epoch:  488  	Training Loss: 0.001976156607270241
Test Loss:  0.0015122307231649756
Valid Loss:  0.0017435813788324594
Epoch:  489  	Training Loss: 0.001976101892068982
Test Loss:  0.0015121859032660723
Valid Loss:  0.001743533881381154
Epoch:  490  	Training Loss: 0.0019760457798838615
Test Loss:  0.0015121387550607324
Valid Loss:  0.0017434835899621248
Epoch:  491  	Training Loss: 0.0019759931601583958
Test Loss:  0.0015120955649763346
Valid Loss:  0.0017434335313737392
Epoch:  492  	Training Loss: 0.0019759382121264935
Test Loss:  0.0015120496973395348
Valid Loss:  0.0017433840548619628
Epoch:  493  	Training Loss: 0.001975883264094591
Test Loss:  0.0015120063908398151
Valid Loss:  0.0017433351604267955
Epoch:  494  	Training Loss: 0.0019758278504014015
Test Loss:  0.0015119570307433605
Valid Loss:  0.0017432859167456627
Epoch:  495  	Training Loss: 0.001975774532184005
Test Loss:  0.0015119122108444571
Valid Loss:  0.0017432353924959898
Epoch:  496  	Training Loss: 0.0019757188856601715
Test Loss:  0.0015118701849132776
Valid Loss:  0.0017431885935366154
Epoch:  497  	Training Loss: 0.001975664868950844
Test Loss:  0.001511820824816823
Valid Loss:  0.0017431415617465973
Epoch:  498  	Training Loss: 0.0019756110850721598
Test Loss:  0.0015117796137928963
Valid Loss:  0.0017430897569283843
Epoch:  499  	Training Loss: 0.001975557766854763
Test Loss:  0.00151173141784966
Valid Loss:  0.0017430407460778952
Epoch:  500  	Training Loss: 0.001975501887500286
Test Loss:  0.0015116867143660784
Valid Loss:  0.0017429912695661187
seed is  5
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:56,  6.25s/it]  1%|          | 3/500 [00:06<13:49,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<11:00,  1.35s/it]  3%|▎         | 13/500 [00:13<07:29,  1.08it/s]  3%|▎         | 15/500 [00:13<05:13,  1.55it/s]  3%|▎         | 17/500 [00:13<03:43,  2.16it/s]  4%|▍         | 19/500 [00:13<02:43,  2.95it/s]  4%|▍         | 21/500 [00:20<09:41,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.20it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:27<09:34,  1.23s/it]  7%|▋         | 33/500 [00:27<06:49,  1.14it/s]  7%|▋         | 35/500 [00:27<04:54,  1.58it/s]  7%|▋         | 37/500 [00:27<03:34,  2.16it/s]  8%|▊         | 39/500 [00:27<02:38,  2.91it/s]  8%|▊         | 41/500 [00:34<09:03,  1.18s/it]  9%|▊         | 43/500 [00:34<06:28,  1.18it/s]  9%|▉         | 45/500 [00:34<04:39,  1.63it/s]  9%|▉         | 47/500 [00:34<03:23,  2.22it/s] 10%|▉         | 49/500 [00:34<02:30,  2.99it/s] 10%|█         | 51/500 [00:40<08:51,  1.18s/it] 11%|█         | 53/500 [00:41<06:19,  1.18it/s] 11%|█         | 55/500 [00:41<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:41<02:27,  3.00it/s] 12%|█▏        | 61/500 [00:47<08:35,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:08,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:48<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:48<02:23,  3.01it/s]Epoch:  1  	Training Loss: 0.21564969420433044
Test Loss:  0.10744792222976685
Valid Loss:  0.1091029942035675
Epoch:  2  	Training Loss: 0.1110517829656601
Test Loss:  0.06849963963031769
Valid Loss:  0.07102783024311066
Epoch:  3  	Training Loss: 0.07200546562671661
Test Loss:  0.0493379682302475
Valid Loss:  0.052253928035497665
Epoch:  4  	Training Loss: 0.05265633016824722
Test Loss:  0.03722495585680008
Valid Loss:  0.04036295413970947
Epoch:  5  	Training Loss: 0.040336549282073975
Test Loss:  0.029456738382577896
Valid Loss:  0.03271038830280304
Epoch:  6  	Training Loss: 0.03236498311161995
Test Loss:  0.024410828948020935
Valid Loss:  0.027712276205420494
Epoch:  7  	Training Loss: 0.027129795402288437
Test Loss:  0.02106502465903759
Valid Loss:  0.02437194250524044
Epoch:  8  	Training Loss: 0.023615382611751556
Test Loss:  0.01879725605249405
Valid Loss:  0.02207067608833313
Epoch:  9  	Training Loss: 0.021193094551563263
Test Loss:  0.017213771119713783
Valid Loss:  0.020428813993930817
Epoch:  10  	Training Loss: 0.019468609243631363
Test Loss:  0.016060585156083107
Valid Loss:  0.019207945093512535
Epoch:  11  	Training Loss: 0.018194884061813354
Test Loss:  0.015184851363301277
Valid Loss:  0.01826190948486328
Epoch:  12  	Training Loss: 0.017215702682733536
Test Loss:  0.013338923454284668
Valid Loss:  0.016118144616484642
Epoch:  13  	Training Loss: 0.015140987932682037
Test Loss:  0.01209261454641819
Valid Loss:  0.014556227251887321
Epoch:  14  	Training Loss: 0.013710785657167435
Test Loss:  0.011412685737013817
Valid Loss:  0.013659583404660225
Epoch:  15  	Training Loss: 0.012916676700115204
Test Loss:  0.010805523954331875
Valid Loss:  0.012960338965058327
Epoch:  16  	Training Loss: 0.012231485918164253
Test Loss:  0.010246602818369865
Valid Loss:  0.01229964941740036
Epoch:  17  	Training Loss: 0.01159470435231924
Test Loss:  0.009725209325551987
Valid Loss:  0.011677039787173271
Epoch:  18  	Training Loss: 0.010999382473528385
Test Loss:  0.009237105026841164
Valid Loss:  0.011089464649558067
Epoch:  19  	Training Loss: 0.010441018268465996
Test Loss:  0.008779549039900303
Valid Loss:  0.01053537055850029
Epoch:  20  	Training Loss: 0.009917095303535461
Test Loss:  0.008347546681761742
Valid Loss:  0.01001952774822712
Epoch:  21  	Training Loss: 0.009425302967429161
Test Loss:  0.007942029275000095
Valid Loss:  0.009532371535897255
Epoch:  22  	Training Loss: 0.00896287802606821
Test Loss:  0.007539892569184303
Valid Loss:  0.009046988561749458
Epoch:  23  	Training Loss: 0.008499467745423317
Test Loss:  0.007199409417808056
Valid Loss:  0.008682876825332642
Epoch:  24  	Training Loss: 0.008125459775328636
Test Loss:  0.006913849152624607
Valid Loss:  0.008364472538232803
Epoch:  25  	Training Loss: 0.007806818000972271
Test Loss:  0.00666168425232172
Valid Loss:  0.008075622841715813
Epoch:  26  	Training Loss: 0.00752340629696846
Test Loss:  0.006432115100324154
Valid Loss:  0.0078079309314489365
Epoch:  27  	Training Loss: 0.007264557294547558
Test Loss:  0.006218370050191879
Valid Loss:  0.007553900592029095
Epoch:  28  	Training Loss: 0.007022621110081673
Test Loss:  0.0060165803879499435
Valid Loss:  0.007310919929295778
Epoch:  29  	Training Loss: 0.006793770473450422
Test Loss:  0.005824735853821039
Valid Loss:  0.007077550515532494
Epoch:  30  	Training Loss: 0.006575881503522396
Test Loss:  0.005641511641442776
Valid Loss:  0.006853227037936449
Epoch:  31  	Training Loss: 0.006367937661707401
Test Loss:  0.005471515469253063
Valid Loss:  0.0066455574706196785
Epoch:  32  	Training Loss: 0.006177115254104137
Test Loss:  0.005252472124993801
Valid Loss:  0.006339740473777056
Epoch:  33  	Training Loss: 0.005915477406233549
Test Loss:  0.00507760513573885
Valid Loss:  0.006126387044787407
Epoch:  34  	Training Loss: 0.005717214196920395
Test Loss:  0.0049171303398907185
Valid Loss:  0.005928133614361286
Epoch:  35  	Training Loss: 0.005538563244044781
Test Loss:  0.0047795940190553665
Valid Loss:  0.0057532889768481255
Epoch:  36  	Training Loss: 0.00538286566734314
Test Loss:  0.004653820767998695
Valid Loss:  0.005592588800936937
Epoch:  37  	Training Loss: 0.005238038953393698
Test Loss:  0.004535318352282047
Valid Loss:  0.005442321766167879
Epoch:  38  	Training Loss: 0.0051014479249715805
Test Loss:  0.004421214573085308
Valid Loss:  0.0052992356941103935
Epoch:  39  	Training Loss: 0.004970734007656574
Test Loss:  0.004311635624617338
Valid Loss:  0.005163542460650206
Epoch:  40  	Training Loss: 0.004845550283789635
Test Loss:  0.004206836223602295
Valid Loss:  0.005035185720771551
Epoch:  41  	Training Loss: 0.004727037623524666
Test Loss:  0.0041053397580981255
Valid Loss:  0.00490749254822731
Epoch:  42  	Training Loss: 0.004611033946275711
Test Loss:  0.003859744407236576
Valid Loss:  0.004550081677734852
Epoch:  43  	Training Loss: 0.004314253572374582
Test Loss:  0.0036025068257004023
Valid Loss:  0.004186189733445644
Epoch:  44  	Training Loss: 0.004008030518889427
Test Loss:  0.003323705866932869
Valid Loss:  0.0038429650012403727
Epoch:  45  	Training Loss: 0.0037003580946475267
Test Loss:  0.003059829119592905
Valid Loss:  0.003534122835844755
Epoch:  46  	Training Loss: 0.0034146574325859547
Test Loss:  0.0028343377634882927
Valid Loss:  0.0032773532439023256
Epoch:  47  	Training Loss: 0.0031747620087116957
Test Loss:  0.0026585771702229977
Valid Loss:  0.0030725314281880856
Epoch:  48  	Training Loss: 0.0029818816110491753
Test Loss:  0.002524629235267639
Valid Loss:  0.002913318108767271
Epoch:  49  	Training Loss: 0.0028300033882260323
Test Loss:  0.002416229574009776
Valid Loss:  0.002784683834761381
Epoch:  50  	Training Loss: 0.002709121908992529
Test Loss:  0.002324536442756653
Valid Loss:  0.0026743649505078793
Epoch:  51  	Training Loss: 0.0026073039043694735
Test Loss:  0.002243475988507271
Valid Loss:  0.002580022206529975
Epoch:  52  	Training Loss: 0.0025199283845722675
Test Loss:  0.0021373513154685497
Valid Loss:  0.002485953737050295
Epoch:  53  	Training Loss: 0.0024110537488013506
Test Loss:  0.002039002487435937
Valid Loss:  0.0023843112867325544
Epoch:  54  	Training Loss: 0.0023040766827762127
Test Loss:  0.0019408409716561437
Valid Loss:  0.002282028552144766
Epoch:  55  	Training Loss: 0.002198473084717989
Test Loss:  0.0018497765995562077
Valid Loss:  0.002183714881539345
Epoch:  56  	Training Loss: 0.0020980755798518658
Test Loss:  0.0017689471133053303
Valid Loss:  0.0020970143377780914
Epoch:  57  	Training Loss: 0.0020110865589231253
Test Loss:  0.001702368026599288
Valid Loss:  0.0020237299613654613
Epoch:  58  	Training Loss: 0.0019396001007407904
Test Loss:  0.0016512658912688494
Valid Loss:  0.0019627478905022144
Epoch:  59  	Training Loss: 0.001880376017652452
Test Loss:  0.0016090527642518282
Valid Loss:  0.0019128283020108938
Epoch:  60  	Training Loss: 0.0018314754124730825
Test Loss:  0.0015725663397461176
Valid Loss:  0.001870109816081822
Epoch:  61  	Training Loss: 0.0017901184037327766
Test Loss:  0.0015387814491987228
Valid Loss:  0.0018307400168851018
Epoch:  62  	Training Loss: 0.0017522575799375772
Test Loss:  0.0015000614803284407
Valid Loss:  0.0017716573784127831
Epoch:  63  	Training Loss: 0.001703133573755622
Test Loss:  0.0014635521220043302
Valid Loss:  0.0017212822567671537
Epoch:  64  	Training Loss: 0.0016595704946666956
Test Loss:  0.001429024268873036
Valid Loss:  0.00167606002651155
Epoch:  65  	Training Loss: 0.0016194237396121025
Test Loss:  0.0013959750067442656
Valid Loss:  0.001634719897992909
Epoch:  66  	Training Loss: 0.0015820213593542576
Test Loss:  0.001364127965644002
Valid Loss:  0.0015961143653839827
Epoch:  67  	Training Loss: 0.0015467195771634579
Test Loss:  0.0013335925759747624
Valid Loss:  0.0015594305004924536
Epoch:  68  	Training Loss: 0.0015130480751395226
Test Loss:  0.0013041188940405846
Valid Loss:  0.0015245482791215181
Epoch:  69  	Training Loss: 0.0014808487612754107
Test Loss:  0.0012759128585457802
Valid Loss:  0.0014911327743902802
Epoch:  70  	Training Loss: 0.001450083334930241
Test Loss:  0.001248791697435081
Valid Loss:  0.0014592912048101425
Epoch:  71  	Training Loss: 0.0014205689076334238
 14%|█▍        | 71/500 [00:54<08:24,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:00,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:55<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:01<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:01<02:17,  2.98it/s] 18%|█▊        | 91/500 [01:08<08:13,  1.21s/it] 19%|█▊        | 93/500 [01:08<05:52,  1.16it/s] 19%|█▉        | 95/500 [01:08<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:08<03:04,  2.19it/s] 20%|█▉        | 99/500 [01:08<02:16,  2.94it/s] 20%|██        | 101/500 [01:15<07:55,  1.19s/it] 21%|██        | 103/500 [01:15<05:39,  1.17it/s] 21%|██        | 105/500 [01:15<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:15<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:15<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:22<07:47,  1.20s/it] 23%|██▎       | 113/500 [01:22<05:34,  1.16it/s] 23%|██▎       | 115/500 [01:22<04:00,  1.60it/s] 23%|██▎       | 117/500 [01:22<02:55,  2.19it/s] 24%|██▍       | 119/500 [01:22<02:09,  2.94it/s] 24%|██▍       | 121/500 [01:29<07:28,  1.18s/it] 25%|██▍       | 123/500 [01:29<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:29<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:29<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:29<02:04,  2.99it/s] 26%|██▌       | 131/500 [01:36<07:20,  1.19s/it] 27%|██▋       | 133/500 [01:36<05:14,  1.17it/s] 27%|██▋       | 135/500 [01:36<03:46,  1.61it/s] 27%|██▋       | 137/500 [01:36<02:44,  2.20it/s] 28%|██▊       | 139/500 [01:36<02:02,  2.96it/s]Test Loss:  0.0012226838152855635
Valid Loss:  0.001428896328434348
Epoch:  72  	Training Loss: 0.0013921759091317654
Test Loss:  0.0011757907923310995
Valid Loss:  0.0013809534721076488
Epoch:  73  	Training Loss: 0.0013454509899020195
Test Loss:  0.001134598976932466
Valid Loss:  0.0013362907338887453
Epoch:  74  	Training Loss: 0.0013031137641519308
Test Loss:  0.0010972011368721724
Valid Loss:  0.0012948650401085615
Epoch:  75  	Training Loss: 0.0012639848282560706
Test Loss:  0.0010628064628690481
Valid Loss:  0.0012565252836793661
Epoch:  76  	Training Loss: 0.0012274805922061205
Test Loss:  0.001031016930937767
Valid Loss:  0.001220304169692099
Epoch:  77  	Training Loss: 0.001193310134112835
Test Loss:  0.0010014338186010718
Valid Loss:  0.0011872355826199055
Epoch:  78  	Training Loss: 0.0011615253752097487
Test Loss:  0.00097413151524961
Valid Loss:  0.001156124286353588
Epoch:  79  	Training Loss: 0.0011320345802232623
Test Loss:  0.0009486164199188352
Valid Loss:  0.0011270636459812522
Epoch:  80  	Training Loss: 0.001104382099583745
Test Loss:  0.000924695807043463
Valid Loss:  0.0010997657664120197
Epoch:  81  	Training Loss: 0.0010783837642520666
Test Loss:  0.0009022562298923731
Valid Loss:  0.0010741442674770951
Epoch:  82  	Training Loss: 0.001054279855452478
Test Loss:  0.000889167538844049
Valid Loss:  0.0010566117707639933
Epoch:  83  	Training Loss: 0.0010388605296611786
Test Loss:  0.0008761646458879113
Valid Loss:  0.0010400873143225908
Epoch:  84  	Training Loss: 0.0010240250267088413
Test Loss:  0.0008632969693280756
Valid Loss:  0.0010243554133921862
Epoch:  85  	Training Loss: 0.0010096724145114422
Test Loss:  0.0008506170124746859
Valid Loss:  0.001009270898066461
Epoch:  86  	Training Loss: 0.000995744252577424
Test Loss:  0.0008381133084185421
Valid Loss:  0.000994781032204628
Epoch:  87  	Training Loss: 0.0009822282008826733
Test Loss:  0.0008260146132670343
Valid Loss:  0.0009806944290176034
Epoch:  88  	Training Loss: 0.0009691505692899227
Test Loss:  0.0008141156286001205
Valid Loss:  0.0009670956642366946
Epoch:  89  	Training Loss: 0.0009564299834892154
Test Loss:  0.0008025038405321538
Valid Loss:  0.0009539257152937353
Epoch:  90  	Training Loss: 0.0009440570720471442
Test Loss:  0.000791373080573976
Valid Loss:  0.0009410884813405573
Epoch:  91  	Training Loss: 0.0009320920798927546
Test Loss:  0.0007806095527485013
Valid Loss:  0.0009285809937864542
Epoch:  92  	Training Loss: 0.0009204922243952751
Test Loss:  0.0007754256366752088
Valid Loss:  0.0009187730611301959
Epoch:  93  	Training Loss: 0.0009134534047916532
Test Loss:  0.0007701294962316751
Valid Loss:  0.0009092016262002289
Epoch:  94  	Training Loss: 0.000905666034668684
Test Loss:  0.0007644262514077127
Valid Loss:  0.0009001791477203369
Epoch:  95  	Training Loss: 0.0008975488017313182
Test Loss:  0.0007624421268701553
Valid Loss:  0.0008947852766141295
Epoch:  96  	Training Loss: 0.0008927442831918597
Test Loss:  0.0007538329809904099
Valid Loss:  0.0008864756091497838
Epoch:  97  	Training Loss: 0.0008856142521835864
Test Loss:  0.0007513257442042232
Valid Loss:  0.0008810344734229147
Epoch:  98  	Training Loss: 0.0008804359240457416
Test Loss:  0.000743845768738538
Valid Loss:  0.0008739300537854433
Epoch:  99  	Training Loss: 0.0008744685910642147
Test Loss:  0.0007409435929730535
Valid Loss:  0.0008684845524840057
Epoch:  100  	Training Loss: 0.0008692018454894423
Test Loss:  0.0007348160725086927
Valid Loss:  0.0008625948685221374
Epoch:  101  	Training Loss: 0.0008645401103422046
Test Loss:  0.0007300228462554514
Valid Loss:  0.0008562215371057391
Epoch:  102  	Training Loss: 0.0008582925656810403
Test Loss:  0.00071071891579777
Valid Loss:  0.0008368856506422162
Epoch:  103  	Training Loss: 0.0008392707677558064
Test Loss:  0.0006891890079714358
Valid Loss:  0.0008213272085413337
Epoch:  104  	Training Loss: 0.0008225722704082727
Test Loss:  0.0006715056370012462
Valid Loss:  0.0008072403725236654
Epoch:  105  	Training Loss: 0.0008081264095380902
Test Loss:  0.0006577008753083646
Valid Loss:  0.0007926312973722816
Epoch:  106  	Training Loss: 0.0007944540120661259
Test Loss:  0.0006450794171541929
Valid Loss:  0.0007787271752022207
Epoch:  107  	Training Loss: 0.0007816589204594493
Test Loss:  0.0006335474899969995
Valid Loss:  0.000766060664318502
Epoch:  108  	Training Loss: 0.0007700209971517324
Test Loss:  0.0006203589146025479
Valid Loss:  0.0007549388101324439
Epoch:  109  	Training Loss: 0.0007591060129925609
Test Loss:  0.0006105429492890835
Valid Loss:  0.0007428529788739979
Epoch:  110  	Training Loss: 0.0007481704233214259
Test Loss:  0.0006002695299685001
Valid Loss:  0.000731569598428905
Epoch:  111  	Training Loss: 0.0007376829162240028
Test Loss:  0.0005903124692849815
Valid Loss:  0.0007207092130556703
Epoch:  112  	Training Loss: 0.0007276367396116257
Test Loss:  0.000583209446631372
Valid Loss:  0.0007142014219425619
Epoch:  113  	Training Loss: 0.000721505144611001
Test Loss:  0.000578453007619828
Valid Loss:  0.0007071960717439651
Epoch:  114  	Training Loss: 0.0007156764040701091
Test Loss:  0.0005715470761060715
Valid Loss:  0.0007010242552496493
Epoch:  115  	Training Loss: 0.0007098271744325757
Test Loss:  0.0005667374352924526
Valid Loss:  0.0006946764187887311
Epoch:  116  	Training Loss: 0.000704469159245491
Test Loss:  0.0005605747574009001
Valid Loss:  0.0006891251541674137
Epoch:  117  	Training Loss: 0.0006991968839429319
Test Loss:  0.0005565427709370852
Valid Loss:  0.000682960613630712
Epoch:  118  	Training Loss: 0.0006942263571545482
Test Loss:  0.0005506518064066768
Valid Loss:  0.0006779044051654637
Epoch:  119  	Training Loss: 0.0006893822574056685
Test Loss:  0.0005467276205308735
Valid Loss:  0.0006722889374941587
Epoch:  120  	Training Loss: 0.0006847967160865664
Test Loss:  0.0005414746701717377
Valid Loss:  0.0006676019402220845
Epoch:  121  	Training Loss: 0.0006804054137319326
Test Loss:  0.0005380329675972462
Valid Loss:  0.0006623038789257407
Epoch:  122  	Training Loss: 0.0006761481054127216
Test Loss:  0.0005360491340979934
Valid Loss:  0.0006562471389770508
Epoch:  123  	Training Loss: 0.0006712687900289893
Test Loss:  0.0005344090168364346
Valid Loss:  0.0006517094443552196
Epoch:  124  	Training Loss: 0.0006675028707832098
Test Loss:  0.0005329923587851226
Valid Loss:  0.0006479931762441993
Epoch:  125  	Training Loss: 0.0006643420783802867
Test Loss:  0.0005316983442753553
Valid Loss:  0.0006450725486502051
Epoch:  126  	Training Loss: 0.0006617011968046427
Test Loss:  0.000530279881786555
Valid Loss:  0.0006426351610571146
Epoch:  127  	Training Loss: 0.0006593601428903639
Test Loss:  0.0005288950633257627
Valid Loss:  0.0006404112791642547
Epoch:  128  	Training Loss: 0.0006572236306965351
Test Loss:  0.0005274917930364609
Valid Loss:  0.0006383684230968356
Epoch:  129  	Training Loss: 0.0006552105187438428
Test Loss:  0.0005260694306343794
Valid Loss:  0.0006365166045725346
Epoch:  130  	Training Loss: 0.0006533372215926647
Test Loss:  0.0005247268127277493
Valid Loss:  0.0006348391179926693
Epoch:  131  	Training Loss: 0.000651634531095624
Test Loss:  0.0005234634736552835
Valid Loss:  0.000633208779618144
Epoch:  132  	Training Loss: 0.0006500203162431717
Test Loss:  0.0005172612145543098
Valid Loss:  0.000630614347755909
Epoch:  133  	Training Loss: 0.0006470656953752041
Test Loss:  0.000514326966367662
Valid Loss:  0.0006272143218666315
Epoch:  134  	Training Loss: 0.0006441978039219975
Test Loss:  0.0005112334620207548
Valid Loss:  0.0006240527727641165
Epoch:  135  	Training Loss: 0.000641531078144908
Test Loss:  0.0005077674286440015
Valid Loss:  0.0006212573498487473
Epoch:  136  	Training Loss: 0.0006389922928065062
Test Loss:  0.0005051922053098679
Valid Loss:  0.0006183057557791471
Epoch:  137  	Training Loss: 0.0006366011220961809
Test Loss:  0.0005021212855353951
Valid Loss:  0.0006157424068078399
Epoch:  138  	Training Loss: 0.000634336844086647
Test Loss:  0.0004999516531825066
Valid Loss:  0.0006128809181973338
Epoch:  139  	Training Loss: 0.000632087467238307
Test Loss:  0.0004973349859938025
Valid Loss:  0.0006102931220084429
 28%|██▊       | 141/500 [01:42<07:07,  1.19s/it] 29%|██▊       | 143/500 [01:43<05:05,  1.17it/s] 29%|██▉       | 145/500 [01:43<03:39,  1.62it/s] 29%|██▉       | 147/500 [01:43<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:43<01:58,  2.97it/s] 30%|███       | 151/500 [01:49<06:54,  1.19s/it] 31%|███       | 153/500 [01:50<04:55,  1.17it/s] 31%|███       | 155/500 [01:50<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:50<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:50<01:54,  2.99it/s] 32%|███▏      | 161/500 [01:56<06:44,  1.19s/it] 33%|███▎      | 163/500 [01:56<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:57<03:27,  1.61it/s] 33%|███▎      | 167/500 [01:57<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:57<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:03<06:36,  1.20s/it] 35%|███▍      | 173/500 [02:03<04:43,  1.16it/s] 35%|███▌      | 175/500 [02:04<03:23,  1.60it/s] 35%|███▌      | 177/500 [02:04<02:27,  2.19it/s] 36%|███▌      | 179/500 [02:04<01:49,  2.93it/s] 36%|███▌      | 181/500 [02:10<06:14,  1.17s/it] 37%|███▋      | 183/500 [02:10<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:10<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:10<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:11<01:43,  3.02it/s] 38%|███▊      | 191/500 [02:17<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:17<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:17<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:17<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:17<01:39,  3.03it/s] 40%|████      | 201/500 [02:24<05:53,  1.18s/it] 41%|████      | 203/500 [02:24<04:12,  1.18it/s] 41%|████      | 205/500 [02:24<03:00,  1.63it/s]Epoch:  140  	Training Loss: 0.0006299144588410854
Test Loss:  0.0004951294977217913
Valid Loss:  0.0006076728459447622
Epoch:  141  	Training Loss: 0.0006278443615883589
Test Loss:  0.0004929685383103788
Valid Loss:  0.0006051959935575724
Epoch:  142  	Training Loss: 0.0006258644862100482
Test Loss:  0.00048761279322206974
Valid Loss:  0.0006010755896568298
Epoch:  143  	Training Loss: 0.0006221323274075985
Test Loss:  0.0004832026897929609
Valid Loss:  0.0005971427308395505
Epoch:  144  	Training Loss: 0.0006187487160786986
Test Loss:  0.0004793226544279605
Valid Loss:  0.0005933815846219659
Epoch:  145  	Training Loss: 0.0006156465969979763
Test Loss:  0.00047580880345776677
Valid Loss:  0.000590065959841013
Epoch:  146  	Training Loss: 0.0006128669483587146
Test Loss:  0.0004732116940431297
Valid Loss:  0.000587156624533236
Epoch:  147  	Training Loss: 0.0006104593630880117
Test Loss:  0.00047088551218621433
Valid Loss:  0.0005846695858053863
Epoch:  148  	Training Loss: 0.0006083004409447312
Test Loss:  0.00046904096961952746
Valid Loss:  0.0005823366809636354
Epoch:  149  	Training Loss: 0.0006062295869924128
Test Loss:  0.00046717352233827114
Valid Loss:  0.0005800588405691087
Epoch:  150  	Training Loss: 0.0006041839951649308
Test Loss:  0.00046536626177839935
Valid Loss:  0.0005778440972790122
Epoch:  151  	Training Loss: 0.0006022003944963217
Test Loss:  0.00046375079546123743
Valid Loss:  0.0005756258615292609
Epoch:  152  	Training Loss: 0.0006003069574944675
Test Loss:  0.0004625614092219621
Valid Loss:  0.0005747023969888687
Epoch:  153  	Training Loss: 0.0005997847765684128
Test Loss:  0.00046178774209693074
Valid Loss:  0.0005737245082855225
Epoch:  154  	Training Loss: 0.0005993087543174624
Test Loss:  0.00046091940021142364
Valid Loss:  0.0005729190306738019
Epoch:  155  	Training Loss: 0.0005988689372316003
Test Loss:  0.0004603819688782096
Valid Loss:  0.0005720526678487659
Epoch:  156  	Training Loss: 0.0005984709714539349
Test Loss:  0.00045966310426592827
Valid Loss:  0.0005713675636798143
Epoch:  157  	Training Loss: 0.0005981031572446227
Test Loss:  0.00045904243597760797
Valid Loss:  0.0005707156378775835
Epoch:  158  	Training Loss: 0.0005977591499686241
Test Loss:  0.0004587084404192865
Valid Loss:  0.0005699906614609063
Epoch:  159  	Training Loss: 0.0005974384257569909
Test Loss:  0.0004581616376526654
Valid Loss:  0.0005694162682630122
Epoch:  160  	Training Loss: 0.0005971344071440399
Test Loss:  0.0004576522042043507
Valid Loss:  0.0005688905366696417
Epoch:  161  	Training Loss: 0.0005968496552668512
Test Loss:  0.0004573912010528147
Valid Loss:  0.000568284944165498
Epoch:  162  	Training Loss: 0.0005965803284198046
Test Loss:  0.0004491491708904505
Valid Loss:  0.0005605666665360332
Epoch:  163  	Training Loss: 0.0005880568060092628
Test Loss:  0.00044131206232123077
Valid Loss:  0.0005530602647922933
Epoch:  164  	Training Loss: 0.0005799097125418484
Test Loss:  0.000434152374509722
Valid Loss:  0.0005457410588860512
Epoch:  165  	Training Loss: 0.0005720822373405099
Test Loss:  0.00042746675899252295
Valid Loss:  0.0005387263372540474
Epoch:  166  	Training Loss: 0.0005646530189551413
Test Loss:  0.0004211479099467397
Valid Loss:  0.0005320085911080241
Epoch:  167  	Training Loss: 0.0005575762479566038
Test Loss:  0.000415005226386711
Valid Loss:  0.0005255876458249986
Epoch:  168  	Training Loss: 0.000550844706594944
Test Loss:  0.0004091078299097717
Valid Loss:  0.0005193710094317794
Epoch:  169  	Training Loss: 0.0005443695699796081
Test Loss:  0.00040333165088668466
Valid Loss:  0.0005133722443133593
Epoch:  170  	Training Loss: 0.0005381926894187927
Test Loss:  0.00039798085344955325
Valid Loss:  0.0005075996741652489
Epoch:  171  	Training Loss: 0.0005323038785718381
Test Loss:  0.000392679066862911
Valid Loss:  0.000502085720654577
Epoch:  172  	Training Loss: 0.0005266893422231078
Test Loss:  0.00038866500835865736
Valid Loss:  0.0004979802179150283
Epoch:  173  	Training Loss: 0.000522628310136497
Test Loss:  0.0003847865154966712
Valid Loss:  0.0004939305363222957
Epoch:  174  	Training Loss: 0.0005186673952266574
Test Loss:  0.0003810318885371089
Valid Loss:  0.0004899429040960968
Epoch:  175  	Training Loss: 0.0005147692281752825
Test Loss:  0.0003773344215005636
Valid Loss:  0.0004860121989622712
Epoch:  176  	Training Loss: 0.0005109334597364068
Test Loss:  0.0003737210063263774
Valid Loss:  0.00048219342716038227
Epoch:  177  	Training Loss: 0.0005071585183031857
Test Loss:  0.00037027132930234075
Valid Loss:  0.00047846417874097824
Epoch:  178  	Training Loss: 0.0005034838104620576
Test Loss:  0.0003668723802547902
Valid Loss:  0.00047479712520726025
Epoch:  179  	Training Loss: 0.0004998662043362856
Test Loss:  0.00036350463051348925
Valid Loss:  0.00047118865768425167
Epoch:  180  	Training Loss: 0.0004963065148331225
Test Loss:  0.00036029552575200796
Valid Loss:  0.000467633712105453
Epoch:  181  	Training Loss: 0.000492806313559413
Test Loss:  0.00035720295272767544
Valid Loss:  0.00046413380187004805
Epoch:  182  	Training Loss: 0.0004893631557933986
Test Loss:  0.00035877234768122435
Valid Loss:  0.00046145886881276965
Epoch:  183  	Training Loss: 0.00048747705295681953
Test Loss:  0.00035833255969919264
Valid Loss:  0.0004597357474267483
Epoch:  184  	Training Loss: 0.00048600888112559915
Test Loss:  0.0003574257716536522
Valid Loss:  0.0004582035471685231
Epoch:  185  	Training Loss: 0.0004846412339247763
Test Loss:  0.0003562390629667789
Valid Loss:  0.0004567803698591888
Epoch:  186  	Training Loss: 0.00048331054858863354
Test Loss:  0.0003549954271875322
Valid Loss:  0.000455407309345901
Epoch:  187  	Training Loss: 0.0004820080357603729
Test Loss:  0.00035373965511098504
Valid Loss:  0.00045407016295939684
Epoch:  188  	Training Loss: 0.00048075802624225616
Test Loss:  0.00035264602047391236
Valid Loss:  0.0004527286801021546
Epoch:  189  	Training Loss: 0.00047954617184586823
Test Loss:  0.0003514513373374939
Valid Loss:  0.00045142672024667263
Epoch:  190  	Training Loss: 0.0004783499171026051
Test Loss:  0.00035026008845306933
Valid Loss:  0.00045015322393737733
Epoch:  191  	Training Loss: 0.000477171823149547
Test Loss:  0.0003490539384074509
Valid Loss:  0.0004489092971198261
Epoch:  192  	Training Loss: 0.0004760117153637111
Test Loss:  0.0003430732758715749
Valid Loss:  0.0004456905007828027
Epoch:  193  	Training Loss: 0.0004728458006866276
Test Loss:  0.00033937592525035143
Valid Loss:  0.00044204568257555366
Epoch:  194  	Training Loss: 0.0004691506619565189
Test Loss:  0.00033596233697608113
Valid Loss:  0.0004384791827760637
Epoch:  195  	Training Loss: 0.00046557674068026245
Test Loss:  0.0003328162420075387
Valid Loss:  0.00043497991282492876
Epoch:  196  	Training Loss: 0.00046212022425606847
Test Loss:  0.00032988691236823797
Valid Loss:  0.00043153599835932255
Epoch:  197  	Training Loss: 0.00045876920921728015
Test Loss:  0.0003269874141551554
Valid Loss:  0.00042821100214496255
Epoch:  198  	Training Loss: 0.00045557148405350745
Test Loss:  0.0003242094535380602
Valid Loss:  0.00042498373659327626
Epoch:  199  	Training Loss: 0.000452489941380918
Test Loss:  0.0003215461038053036
Valid Loss:  0.0004218278336338699
Epoch:  200  	Training Loss: 0.00044948450522497296
Test Loss:  0.0003188933478668332
Valid Loss:  0.00041874591261148453
Epoch:  201  	Training Loss: 0.00044654402881860733
Test Loss:  0.0003161743516102433
Valid Loss:  0.0004157428629696369
Epoch:  202  	Training Loss: 0.0004436589661054313
Test Loss:  0.00031581675284542143
Valid Loss:  0.00041500586667098105
Epoch:  203  	Training Loss: 0.0004429914988577366
Test Loss:  0.0003154704172629863
Valid Loss:  0.00041429558768868446
Epoch:  204  	Training Loss: 0.0004423574428074062
Test Loss:  0.00031510688131675124
Valid Loss:  0.00041360416798852384
Epoch:  205  	Training Loss: 0.00044174681534059346
Test Loss:  0.00031471651163883507
Valid Loss:  0.0004129282315261662
Epoch:  206  	Training Loss: 0.0004411535046529025
Test Loss:  0.0003143041976727545
Valid Loss:  0.0004122665850445628
Epoch:  207  	Training Loss: 0.0004405798972584307
Test Loss:  0.00031387689523398876
Valid Loss:   41%|████▏     | 207/500 [02:24<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:24<01:37,  3.00it/s] 42%|████▏     | 211/500 [02:31<05:43,  1.19s/it] 43%|████▎     | 213/500 [02:31<04:05,  1.17it/s] 43%|████▎     | 215/500 [02:31<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:31<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:31<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:38<05:35,  1.20s/it] 45%|████▍     | 223/500 [02:38<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:38<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:38<02:04,  2.19it/s] 46%|████▌     | 229/500 [02:38<01:31,  2.95it/s] 46%|████▌     | 231/500 [02:44<05:13,  1.17s/it] 47%|████▋     | 233/500 [02:44<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:45<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:45<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:45<01:26,  3.03it/s] 48%|████▊     | 241/500 [02:51<05:08,  1.19s/it] 49%|████▊     | 243/500 [02:51<03:39,  1.17it/s] 49%|████▉     | 245/500 [02:51<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:52<01:54,  2.21it/s] 50%|████▉     | 249/500 [02:52<01:24,  2.98it/s] 50%|█████     | 251/500 [02:58<04:52,  1.17s/it] 51%|█████     | 253/500 [02:58<03:28,  1.19it/s] 51%|█████     | 255/500 [02:58<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:58<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:59<01:19,  3.01it/s] 52%|█████▏    | 261/500 [03:05<04:42,  1.18s/it] 53%|█████▎    | 263/500 [03:05<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:05<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:05<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:05<01:17,  2.99it/s] 54%|█████▍    | 271/500 [03:12<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:12<03:11,  1.18it/s]0.0004116195486858487
Epoch:  208  	Training Loss: 0.0004400250327307731
Test Loss:  0.0003134248545393348
Valid Loss:  0.0004109763540327549
Epoch:  209  	Training Loss: 0.00043947662925347686
Test Loss:  0.00031296699307858944
Valid Loss:  0.0004103734390810132
Epoch:  210  	Training Loss: 0.00043894757982343435
Test Loss:  0.0003125026705674827
Valid Loss:  0.00040978618199005723
Epoch:  211  	Training Loss: 0.0004384336934890598
Test Loss:  0.00031202801619656384
Valid Loss:  0.0004092130984645337
Epoch:  212  	Training Loss: 0.0004379225429147482
Test Loss:  0.00030946903279982507
Valid Loss:  0.0004071457078680396
Epoch:  213  	Training Loss: 0.0004357332654763013
Test Loss:  0.0003075147687923163
Valid Loss:  0.0004050382412970066
Epoch:  214  	Training Loss: 0.00043361439020372927
Test Loss:  0.0003058577422052622
Valid Loss:  0.0004029081901535392
Epoch:  215  	Training Loss: 0.00043155986350029707
Test Loss:  0.00030388840241357684
Valid Loss:  0.00040092255221679807
Epoch:  216  	Training Loss: 0.00042959299753420055
Test Loss:  0.0003020239237230271
Valid Loss:  0.0003989680844824761
Epoch:  217  	Training Loss: 0.0004276664403732866
Test Loss:  0.00030034035444259644
Valid Loss:  0.0003970173420384526
Epoch:  218  	Training Loss: 0.00042578839929774404
Test Loss:  0.00029854531749151647
Valid Loss:  0.0003952114493586123
Epoch:  219  	Training Loss: 0.0004239740374032408
Test Loss:  0.000297058024443686
Valid Loss:  0.0003933781699743122
Epoch:  220  	Training Loss: 0.00042222056072205305
Test Loss:  0.00029527919832617044
Valid Loss:  0.0003916692512575537
Epoch:  221  	Training Loss: 0.0004205286968499422
Test Loss:  0.0002936040982604027
Valid Loss:  0.00038997933734208345
Epoch:  222  	Training Loss: 0.00041887833504006267
Test Loss:  0.0002913247444666922
Valid Loss:  0.0003884322941303253
Epoch:  223  	Training Loss: 0.00041731493547558784
Test Loss:  0.00028929964173585176
Valid Loss:  0.00038695160765200853
Epoch:  224  	Training Loss: 0.00041582767153158784
Test Loss:  0.0002874896745197475
Valid Loss:  0.0003855245013255626
Epoch:  225  	Training Loss: 0.0004143991391174495
Test Loss:  0.0002858226071111858
Valid Loss:  0.0003841454454232007
Epoch:  226  	Training Loss: 0.00041302473982796073
Test Loss:  0.00028428889345377684
Valid Loss:  0.00038281234446913004
Epoch:  227  	Training Loss: 0.0004117076750844717
Test Loss:  0.0002828655706252903
Valid Loss:  0.00038151926128193736
Epoch:  228  	Training Loss: 0.00041044066892936826
Test Loss:  0.00028146631666459143
Valid Loss:  0.0003802645078394562
Epoch:  229  	Training Loss: 0.00040922113112173975
Test Loss:  0.00028018190641887486
Valid Loss:  0.00037906746729277074
Epoch:  230  	Training Loss: 0.00040806829929351807
Test Loss:  0.00027902491274289787
Valid Loss:  0.0003778974642045796
Epoch:  231  	Training Loss: 0.0004069497808814049
Test Loss:  0.0002779530477710068
Valid Loss:  0.00037676270585507154
Epoch:  232  	Training Loss: 0.0004058730264659971
Test Loss:  0.00027713895542547107
Valid Loss:  0.0003754760546144098
Epoch:  233  	Training Loss: 0.0004047140828333795
Test Loss:  0.0002762799267657101
Valid Loss:  0.00037421309389173985
Epoch:  234  	Training Loss: 0.00040357362013310194
Test Loss:  0.0002753877197392285
Valid Loss:  0.00037297222297638655
Epoch:  235  	Training Loss: 0.0004024603986181319
Test Loss:  0.0002744907105807215
Valid Loss:  0.0003717647341545671
Epoch:  236  	Training Loss: 0.00040137884207069874
Test Loss:  0.00027358316583558917
Valid Loss:  0.0003705897834151983
Epoch:  237  	Training Loss: 0.00040032394463196397
Test Loss:  0.0002726829261519015
Valid Loss:  0.000369440414942801
Epoch:  238  	Training Loss: 0.0003992948913946748
Test Loss:  0.0002717804745770991
Valid Loss:  0.00036830734461545944
Epoch:  239  	Training Loss: 0.00039828201988711953
Test Loss:  0.0002709855907596648
Valid Loss:  0.0003671552985906601
Epoch:  240  	Training Loss: 0.0003972912672907114
Test Loss:  0.00027017798856832087
Valid Loss:  0.00036603701300919056
Epoch:  241  	Training Loss: 0.00039632836706005037
Test Loss:  0.00026935848291032016
Valid Loss:  0.00036496302345767617
Epoch:  242  	Training Loss: 0.00039538589771836996
Test Loss:  0.00026848289417102933
Valid Loss:  0.0003635183093138039
Epoch:  243  	Training Loss: 0.00039408006705343723
Test Loss:  0.0002675795112736523
Valid Loss:  0.0003621264477260411
Epoch:  244  	Training Loss: 0.00039281396311707795
Test Loss:  0.00026665738550946116
Valid Loss:  0.0003607688413467258
Epoch:  245  	Training Loss: 0.0003915808629244566
Test Loss:  0.0002657244331203401
Valid Loss:  0.0003594389418140054
Epoch:  246  	Training Loss: 0.0003903722681570798
Test Loss:  0.0002647856017574668
Valid Loss:  0.00035816209856420755
Epoch:  247  	Training Loss: 0.00038920133374631405
Test Loss:  0.0002639048616401851
Valid Loss:  0.0003569080727174878
Epoch:  248  	Training Loss: 0.0003880644799210131
Test Loss:  0.0002630087547004223
Valid Loss:  0.0003556781739462167
Epoch:  249  	Training Loss: 0.00038694386603310704
Test Loss:  0.00026210176292806864
Valid Loss:  0.0003544824430719018
Epoch:  250  	Training Loss: 0.0003858458949252963
Test Loss:  0.0002611824602354318
Valid Loss:  0.00035331377875991166
Epoch:  251  	Training Loss: 0.0003847726038657129
Test Loss:  0.00026027485728263855
Valid Loss:  0.0003521719772834331
Epoch:  252  	Training Loss: 0.00038371572736650705
Test Loss:  0.00025978207122534513
Valid Loss:  0.000349751440808177
Epoch:  253  	Training Loss: 0.0003817974356934428
Test Loss:  0.0002585099427960813
Valid Loss:  0.0003477533464320004
Epoch:  254  	Training Loss: 0.00038010120624676347
Test Loss:  0.00025730422930791974
Valid Loss:  0.00034590368159115314
Epoch:  255  	Training Loss: 0.0003785304434131831
Test Loss:  0.0002559382119216025
Valid Loss:  0.0003442014567553997
Epoch:  256  	Training Loss: 0.0003770451294258237
Test Loss:  0.00025455193826928735
Valid Loss:  0.00034258345840498805
Epoch:  257  	Training Loss: 0.00037560725468210876
Test Loss:  0.0002532126964069903
Valid Loss:  0.00034102730569429696
Epoch:  258  	Training Loss: 0.00037421489832922816
Test Loss:  0.00025189953157678246
Valid Loss:  0.00033953486126847565
Epoch:  259  	Training Loss: 0.0003728608717210591
Test Loss:  0.00025062242639251053
Valid Loss:  0.0003380927664693445
Epoch:  260  	Training Loss: 0.0003715410130098462
Test Loss:  0.00024938699789345264
Valid Loss:  0.0003366987220942974
Epoch:  261  	Training Loss: 0.0003702538087964058
Test Loss:  0.0002481983683537692
Valid Loss:  0.0003353425126988441
Epoch:  262  	Training Loss: 0.00036900219856761396
Test Loss:  0.0002467645681463182
Valid Loss:  0.0003343696007505059
Epoch:  263  	Training Loss: 0.00036801554961130023
Test Loss:  0.0002454912755638361
Valid Loss:  0.00033344613621011376
Epoch:  264  	Training Loss: 0.0003670901642180979
Test Loss:  0.00024433969520032406
Valid Loss:  0.00033255413291044533
Epoch:  265  	Training Loss: 0.00036619941238313913
Test Loss:  0.00024329821462742984
Valid Loss:  0.0003316850052215159
Epoch:  266  	Training Loss: 0.0003653349995147437
Test Loss:  0.00024233471776824445
Valid Loss:  0.00033083706512115896
Epoch:  267  	Training Loss: 0.0003645014949142933
Test Loss:  0.00024144565395545214
Valid Loss:  0.000330036913510412
Epoch:  268  	Training Loss: 0.00036369875306263566
Test Loss:  0.0002406179264653474
Valid Loss:  0.000329262315062806
Epoch:  269  	Training Loss: 0.00036292464938014746
Test Loss:  0.00023983389837667346
Valid Loss:  0.0003284995327703655
Epoch:  270  	Training Loss: 0.0003621659125201404
Test Loss:  0.0002390909503446892
Valid Loss:  0.00032775208819657564
Epoch:  271  	Training Loss: 0.000361423910362646
Test Loss:  0.00023838141351006925
Valid Loss:  0.0003270162269473076
Epoch:  272  	Training Loss: 0.0003606964601203799
Test Loss:  0.0002385778643656522
Valid Loss:  0.00032553644268773496
Epoch:  273  	Training Loss: 0.0003595121670514345
Test Loss:  0.0002383269602432847
Valid Loss:  0.0003243296523578465
Epoch:  274  	Training Loss: 0.0003584994119592011
Test Loss:  0.00023780213086865842
Valid Loss:  0.0003232347662560642
 55%|█████▌    | 275/500 [03:12<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:12<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:12<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:19<04:19,  1.18s/it] 57%|█████▋    | 283/500 [03:19<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:19<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:19<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:19<01:10,  2.97it/s] 58%|█████▊    | 291/500 [03:25<04:07,  1.19s/it] 59%|█████▊    | 293/500 [03:26<02:56,  1.17it/s] 59%|█████▉    | 295/500 [03:26<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:26<01:31,  2.22it/s] 60%|█████▉    | 299/500 [03:26<01:07,  2.98it/s] 60%|██████    | 301/500 [03:32<03:53,  1.17s/it] 61%|██████    | 303/500 [03:32<02:46,  1.19it/s] 61%|██████    | 305/500 [03:33<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:33<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:33<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:39<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:39<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:39<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:39<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:40<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:46<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:46<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:46<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:46<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:46<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:53<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:53<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:53<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:53<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:53<00:54,  2.98it/s] 68%|██████▊   | 341/500 [04:00<03:08,  1.18s/it]Epoch:  275  	Training Loss: 0.0003575439041014761
Test Loss:  0.00023714511189609766
Valid Loss:  0.00032220687717199326
Epoch:  276  	Training Loss: 0.00035662457230500877
Test Loss:  0.00023640353174414486
Valid Loss:  0.0003212162118870765
Epoch:  277  	Training Loss: 0.00035572919296100736
Test Loss:  0.00023568086908198893
Valid Loss:  0.0003202492371201515
Epoch:  278  	Training Loss: 0.00035487074637785554
Test Loss:  0.0002349771384615451
Valid Loss:  0.0003193246084265411
Epoch:  279  	Training Loss: 0.0003540425677783787
Test Loss:  0.0002342327788937837
Valid Loss:  0.00031844881596043706
Epoch:  280  	Training Loss: 0.0003532321425154805
Test Loss:  0.0002334812597837299
Valid Loss:  0.00031758350087329745
Epoch:  281  	Training Loss: 0.00035243353340774775
Test Loss:  0.00023273492115549743
Valid Loss:  0.00031673727789893746
Epoch:  282  	Training Loss: 0.000351649709045887
Test Loss:  0.00023096735822036862
Valid Loss:  0.00031532609136775136
Epoch:  283  	Training Loss: 0.00035024905810132623
Test Loss:  0.0002293047436978668
Valid Loss:  0.00031402212334796786
Epoch:  284  	Training Loss: 0.00034893411793746054
Test Loss:  0.00022775235993321985
Valid Loss:  0.0003128020907752216
Epoch:  285  	Training Loss: 0.00034770439378917217
Test Loss:  0.0002262970374431461
Valid Loss:  0.00031164009124040604
Epoch:  286  	Training Loss: 0.0003465310437604785
Test Loss:  0.0002249189419671893
Valid Loss:  0.0003105355426669121
Epoch:  287  	Training Loss: 0.00034541316563263535
Test Loss:  0.00022361264564096928
Valid Loss:  0.0003094835265073925
Epoch:  288  	Training Loss: 0.00034434758708812296
Test Loss:  0.00022237517987377942
Valid Loss:  0.0003084912896156311
Epoch:  289  	Training Loss: 0.00034333160147070885
Test Loss:  0.00022121536312624812
Valid Loss:  0.0003075579006690532
Epoch:  290  	Training Loss: 0.0003423668968025595
Test Loss:  0.00022011484543327242
Valid Loss:  0.0003066678182221949
Epoch:  291  	Training Loss: 0.0003414441889617592
Test Loss:  0.00021907477639615536
Valid Loss:  0.00030581801547668874
Epoch:  292  	Training Loss: 0.0003405634197406471
Test Loss:  0.00021879082487430423
Valid Loss:  0.00030505273025482893
Epoch:  293  	Training Loss: 0.0003397529071662575
Test Loss:  0.0002184311451856047
Valid Loss:  0.00030431742197833955
Epoch:  294  	Training Loss: 0.00033896992681548
Test Loss:  0.00021803104027640074
Valid Loss:  0.00030359969241544604
Epoch:  295  	Training Loss: 0.0003382056311238557
Test Loss:  0.0002176041016355157
Valid Loss:  0.0003028995997738093
Epoch:  296  	Training Loss: 0.00033745920518413186
Test Loss:  0.00021715719776693732
Valid Loss:  0.00030221097404137254
Epoch:  297  	Training Loss: 0.0003367330355104059
Test Loss:  0.00021661391656380147
Valid Loss:  0.00030156440334394574
Epoch:  298  	Training Loss: 0.0003360362316016108
Test Loss:  0.00021615851437672973
Valid Loss:  0.000300908024655655
Epoch:  299  	Training Loss: 0.0003353533975314349
Test Loss:  0.0002155909314751625
Valid Loss:  0.00030029326444491744
Epoch:  300  	Training Loss: 0.0003346905286889523
Test Loss:  0.00021527093485929072
Valid Loss:  0.00029963499400764704
Epoch:  301  	Training Loss: 0.00033403257839381695
Test Loss:  0.00021476171968970448
Valid Loss:  0.00029903746326453984
Epoch:  302  	Training Loss: 0.0003333990753162652
Test Loss:  0.00021503839525394142
Valid Loss:  0.00029892486054450274
Epoch:  303  	Training Loss: 0.0003333027707412839
Test Loss:  0.0002152731758542359
Valid Loss:  0.000298824452329427
Epoch:  304  	Training Loss: 0.00033322046510875225
Test Loss:  0.00021547202777583152
Valid Loss:  0.00029873516177758574
Epoch:  305  	Training Loss: 0.0003331515472382307
Test Loss:  0.00021563803602475673
Valid Loss:  0.00029865297256037593
Epoch:  306  	Training Loss: 0.00033309159334748983
Test Loss:  0.00021577712323050946
Valid Loss:  0.00029857608024030924
Epoch:  307  	Training Loss: 0.00033303958480246365
Test Loss:  0.00021588924573734403
Valid Loss:  0.0002985061437357217
Epoch:  308  	Training Loss: 0.0003329934843350202
Test Loss:  0.0002159835130441934
Valid Loss:  0.0002984362654387951
Epoch:  309  	Training Loss: 0.00033294991590082645
Test Loss:  0.0002160567237297073
Valid Loss:  0.00029837392503395677
Epoch:  310  	Training Loss: 0.00033291138242930174
Test Loss:  0.00021611565898638219
Valid Loss:  0.0002983129525091499
Epoch:  311  	Training Loss: 0.0003328732564114034
Test Loss:  0.00021615982404910028
Valid Loss:  0.0002982556470669806
Epoch:  312  	Training Loss: 0.00033283757511526346
Test Loss:  0.00021578707674052566
Valid Loss:  0.0002971587819047272
Epoch:  313  	Training Loss: 0.0003319421084597707
Test Loss:  0.00021533871768042445
Valid Loss:  0.0002961372083518654
Epoch:  314  	Training Loss: 0.00033110787626355886
Test Loss:  0.00021483947057276964
Valid Loss:  0.00029517675284296274
Epoch:  315  	Training Loss: 0.0003303204430267215
Test Loss:  0.00021430582273751497
Valid Loss:  0.0002942598657682538
Epoch:  316  	Training Loss: 0.0003295605129096657
Test Loss:  0.00021377035591285676
Valid Loss:  0.00029337662272155285
Epoch:  317  	Training Loss: 0.00032882491359487176
Test Loss:  0.00021321802341844887
Valid Loss:  0.00029253147658891976
Epoch:  318  	Training Loss: 0.00032811288838274777
Test Loss:  0.0002126540057361126
Valid Loss:  0.0002917208184953779
Epoch:  319  	Training Loss: 0.0003274208283983171
Test Loss:  0.00021210584964137524
Valid Loss:  0.0002909405156970024
Epoch:  320  	Training Loss: 0.00032674739486537874
Test Loss:  0.00021156115690246224
Valid Loss:  0.0002901795378420502
Epoch:  321  	Training Loss: 0.00032608353649266064
Test Loss:  0.00021101493621245027
Valid Loss:  0.00028943840879946947
Epoch:  322  	Training Loss: 0.0003254325420130044
Test Loss:  0.0002096006355714053
Valid Loss:  0.0002883223060052842
Epoch:  323  	Training Loss: 0.0003243141691200435
Test Loss:  0.0002084123552776873
Valid Loss:  0.00028722151182591915
Epoch:  324  	Training Loss: 0.00032322865445166826
Test Loss:  0.00020740216132253408
Valid Loss:  0.000286135240457952
Epoch:  325  	Training Loss: 0.0003221929364372045
Test Loss:  0.00020642901654355228
Valid Loss:  0.00028506945818662643
Epoch:  326  	Training Loss: 0.00032117648515850306
Test Loss:  0.0002055054355878383
Valid Loss:  0.0002840220113284886
Epoch:  327  	Training Loss: 0.00032017537159845233
Test Loss:  0.00020463374676182866
Valid Loss:  0.0002829937147907913
Epoch:  328  	Training Loss: 0.00031919096363708377
Test Loss:  0.00020378227054607123
Valid Loss:  0.00028198279323987663
Epoch:  329  	Training Loss: 0.0003182201471645385
Test Loss:  0.0002029475144809112
Valid Loss:  0.0002809865400195122
Epoch:  330  	Training Loss: 0.00031726155430078506
Test Loss:  0.0002021380205405876
Valid Loss:  0.00028000527527183294
Epoch:  331  	Training Loss: 0.0003163194051012397
Test Loss:  0.00020141369896009564
Valid Loss:  0.0002790400758385658
Epoch:  332  	Training Loss: 0.0003154027508571744
Test Loss:  0.00020029247389174998
Valid Loss:  0.00027837298694066703
Epoch:  333  	Training Loss: 0.00031456194119527936
Test Loss:  0.00019937493198085576
Valid Loss:  0.0002777501358650625
Epoch:  334  	Training Loss: 0.000313782220473513
Test Loss:  0.00019861501641571522
Valid Loss:  0.00027716511976905167
Epoch:  335  	Training Loss: 0.00031306821620091796
Test Loss:  0.00019796972628682852
Valid Loss:  0.00027660836349241436
Epoch:  336  	Training Loss: 0.00031240409589372575
Test Loss:  0.00019743725715670735
Valid Loss:  0.00027608306845650077
Epoch:  337  	Training Loss: 0.0003117815940640867
Test Loss:  0.00019695874652825296
Valid Loss:  0.00027557561406865716
Epoch:  338  	Training Loss: 0.0003111852565780282
Test Loss:  0.0001965139526873827
Valid Loss:  0.000275088706985116
Epoch:  339  	Training Loss: 0.0003106107469648123
Test Loss:  0.00019610133313108236
Valid Loss:  0.00027460994897410274
Epoch:  340  	Training Loss: 0.0003100569301750511
Test Loss:  0.000195712098502554
Valid Loss:  0.00027414297801442444
Epoch:  341  	Training Loss: 0.0003095170250162482
Test Loss:  0.0001953535247594118
Valid Loss:  0.0002736822352744639
 69%|██████▊   | 343/500 [04:00<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:00<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:00<01:08,  2.22it/s] 70%|██████▉   | 349/500 [04:00<00:50,  2.99it/s] 70%|███████   | 351/500 [04:06<02:54,  1.17s/it] 71%|███████   | 353/500 [04:07<02:03,  1.19it/s] 71%|███████   | 355/500 [04:07<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:07<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:07<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:13<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:13<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:14<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:14<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:14<00:43,  3.00it/s] 74%|███████▍  | 371/500 [04:20<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:20<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:20<01:16,  1.62it/s] 75%|███████▌  | 377/500 [04:21<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:21<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:27<02:21,  1.18s/it] 77%|███████▋  | 383/500 [04:27<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:27<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:27<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:28<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:34<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:34<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:34<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:34<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:34<00:33,  2.98it/s] 80%|████████  | 401/500 [04:41<01:58,  1.20s/it] 81%|████████  | 403/500 [04:41<01:23,  1.16it/s] 81%|████████  | 405/500 [04:41<00:59,  1.61it/s] 81%|████████▏ | 407/500 [04:41<00:42,  2.20it/s]Epoch:  342  	Training Loss: 0.0003089917008765042
Test Loss:  0.00019609686569310725
Valid Loss:  0.0002731402055360377
Epoch:  343  	Training Loss: 0.00030856774537824094
Test Loss:  0.0001965105620911345
Valid Loss:  0.00027279939968138933
Epoch:  344  	Training Loss: 0.00030830607283860445
Test Loss:  0.0001966976560652256
Valid Loss:  0.0002725485246628523
Epoch:  345  	Training Loss: 0.00030811273609288037
Test Loss:  0.0001967423886526376
Valid Loss:  0.000272346253041178
Epoch:  346  	Training Loss: 0.00030794780468568206
Test Loss:  0.00019670733308885247
Valid Loss:  0.0002721732307691127
Epoch:  347  	Training Loss: 0.0003077976871281862
Test Loss:  0.00019662745762616396
Valid Loss:  0.000272019999101758
Epoch:  348  	Training Loss: 0.0003076567081734538
Test Loss:  0.0001965266710612923
Valid Loss:  0.0002718853356782347
Epoch:  349  	Training Loss: 0.0003075245185755193
Test Loss:  0.00019641505787149072
Valid Loss:  0.00027176737785339355
Epoch:  350  	Training Loss: 0.00030739972135052085
Test Loss:  0.00019630313909146935
Valid Loss:  0.00027166056679561734
Epoch:  351  	Training Loss: 0.0003072803665418178
Test Loss:  0.00019619532395154238
Valid Loss:  0.000271565280854702
Epoch:  352  	Training Loss: 0.0003071650571655482
Test Loss:  0.00019531961879692972
Valid Loss:  0.000270565680693835
Epoch:  353  	Training Loss: 0.00030618481105193496
Test Loss:  0.00019448657985776663
Valid Loss:  0.0002695797011256218
Epoch:  354  	Training Loss: 0.00030521961161866784
Test Loss:  0.00019368756329640746
Valid Loss:  0.0002686041407287121
Epoch:  355  	Training Loss: 0.00030426596640609205
Test Loss:  0.00019291616627015173
Valid Loss:  0.00026763934874907136
Epoch:  356  	Training Loss: 0.0003033248067367822
Test Loss:  0.00019216432701796293
Valid Loss:  0.0002666882355697453
Epoch:  357  	Training Loss: 0.0003023936878889799
Test Loss:  0.00019143900135532022
Valid Loss:  0.00026575138326734304
Epoch:  358  	Training Loss: 0.0003014756366610527
Test Loss:  0.00019072851864621043
Valid Loss:  0.00026482553221285343
Epoch:  359  	Training Loss: 0.00030057114781811833
Test Loss:  0.0001900299685075879
Valid Loss:  0.0002639082376845181
Epoch:  360  	Training Loss: 0.0002996750408783555
Test Loss:  0.0001893433218356222
Valid Loss:  0.0002630024391692132
Epoch:  361  	Training Loss: 0.0002987871994264424
Test Loss:  0.0001886656100396067
Valid Loss:  0.0002621037419885397
Epoch:  362  	Training Loss: 0.00029791006818413734
Test Loss:  0.00018789565365295857
Valid Loss:  0.00026189329219050705
Epoch:  363  	Training Loss: 0.0002976001997012645
Test Loss:  0.00018743326654657722
Valid Loss:  0.00026171960053034127
Epoch:  364  	Training Loss: 0.00029732746770605445
Test Loss:  0.00018713301687967032
Valid Loss:  0.0002615590929053724
Epoch:  365  	Training Loss: 0.0002970689092762768
Test Loss:  0.00018691920558921993
Valid Loss:  0.00026140460977330804
Epoch:  366  	Training Loss: 0.0002968170156236738
Test Loss:  0.00018675532191991806
Valid Loss:  0.0002612528041936457
Epoch:  367  	Training Loss: 0.0002965716412290931
Test Loss:  0.0001866193488240242
Valid Loss:  0.00026110245380550623
Epoch:  368  	Training Loss: 0.0002963283332064748
Test Loss:  0.00018649737467058003
Valid Loss:  0.00026095338398590684
Epoch:  369  	Training Loss: 0.0002960912825074047
Test Loss:  0.00018638728943187743
Valid Loss:  0.00026080492534674704
Epoch:  370  	Training Loss: 0.00029585903394035995
Test Loss:  0.00018628124962560833
Valid Loss:  0.00026065806741826236
Epoch:  371  	Training Loss: 0.0002956296084448695
Test Loss:  0.00018617924069985747
Valid Loss:  0.0002605124609544873
Epoch:  372  	Training Loss: 0.0002954048686660826
Test Loss:  0.0001863898942247033
Valid Loss:  0.0002601912128739059
Epoch:  373  	Training Loss: 0.0002950115595012903
Test Loss:  0.0001863956858869642
Valid Loss:  0.0002598981373012066
Epoch:  374  	Training Loss: 0.000294656929327175
Test Loss:  0.0001862815406639129
Valid Loss:  0.000259618042036891
Epoch:  375  	Training Loss: 0.0002943133586086333
Test Loss:  0.0001861186174210161
Valid Loss:  0.00025934705627150834
Epoch:  376  	Training Loss: 0.0002939768019132316
Test Loss:  0.00018594012362882495
Valid Loss:  0.0002590794756542891
Epoch:  377  	Training Loss: 0.00029365107184275985
Test Loss:  0.00018575400463305414
Valid Loss:  0.00025882074260152876
Epoch:  378  	Training Loss: 0.0002933318610303104
Test Loss:  0.0001855641312431544
Valid Loss:  0.0002585691399872303
Epoch:  379  	Training Loss: 0.0002930220798589289
Test Loss:  0.00018536746210884303
Valid Loss:  0.0002583215828053653
Epoch:  380  	Training Loss: 0.00029271680978126824
Test Loss:  0.0001851701963460073
Valid Loss:  0.0002580828149802983
Epoch:  381  	Training Loss: 0.0002924147411249578
Test Loss:  0.0001849722466431558
Valid Loss:  0.0002578468411229551
Epoch:  382  	Training Loss: 0.0002921134582720697
Test Loss:  0.00018437467224430293
Valid Loss:  0.0002572778321336955
Epoch:  383  	Training Loss: 0.00029153976356610656
Test Loss:  0.0001838158641476184
Valid Loss:  0.0002567200572229922
Epoch:  384  	Training Loss: 0.0002909779141191393
Test Loss:  0.00018329423619434237
Valid Loss:  0.0002561720903031528
Epoch:  385  	Training Loss: 0.00029042462119832635
Test Loss:  0.00018280204676557332
Valid Loss:  0.00025563040981069207
Epoch:  386  	Training Loss: 0.0002898811944760382
Test Loss:  0.00018233709852211177
Valid Loss:  0.0002550975186750293
Epoch:  387  	Training Loss: 0.00028934606234543025
Test Loss:  0.0001818899909267202
Valid Loss:  0.0002545695169828832
Epoch:  388  	Training Loss: 0.0002888171002268791
Test Loss:  0.00018145929789170623
Valid Loss:  0.00025404879124835134
Epoch:  389  	Training Loss: 0.00028829468647018075
Test Loss:  0.00018104306946042925
Valid Loss:  0.00025353155797347426
Epoch:  390  	Training Loss: 0.0002877769584301859
Test Loss:  0.0001806388609111309
Valid Loss:  0.00025302075664512813
Epoch:  391  	Training Loss: 0.00028726476011797786
Test Loss:  0.00018024542077910155
Valid Loss:  0.0002525125746615231
Epoch:  392  	Training Loss: 0.0002867565490305424
Test Loss:  0.00018033874221146107
Valid Loss:  0.0002521656861063093
Epoch:  393  	Training Loss: 0.0002864605630747974
Test Loss:  0.00018037212430499494
Valid Loss:  0.00025185360573232174
Epoch:  394  	Training Loss: 0.0002861926332116127
Test Loss:  0.00018035761604551226
Valid Loss:  0.0002515678061172366
Epoch:  395  	Training Loss: 0.00028594222385436296
Test Loss:  0.0001803002814995125
Valid Loss:  0.00025129926507361233
Epoch:  396  	Training Loss: 0.0002857028739526868
Test Loss:  0.0001802116457838565
Valid Loss:  0.00025104539236053824
Epoch:  397  	Training Loss: 0.0002854716731235385
Test Loss:  0.00018009726773016155
Valid Loss:  0.00025079818442463875
Epoch:  398  	Training Loss: 0.0002852452453225851
Test Loss:  0.0001799631427275017
Valid Loss:  0.0002505597658455372
Epoch:  399  	Training Loss: 0.00028502268833108246
Test Loss:  0.000179815455339849
Valid Loss:  0.00025032603298313916
Epoch:  400  	Training Loss: 0.00028480347828008235
Test Loss:  0.00017965541337616742
Valid Loss:  0.00025009887758642435
Epoch:  401  	Training Loss: 0.00028458688757382333
Test Loss:  0.00017948757158592343
Valid Loss:  0.0002498790272511542
Epoch:  402  	Training Loss: 0.00028437303262762725
Test Loss:  0.00017900412785820663
Valid Loss:  0.00024930672952905297
Epoch:  403  	Training Loss: 0.00028376339469105005
Test Loss:  0.0001785378553904593
Valid Loss:  0.0002487442397978157
Epoch:  404  	Training Loss: 0.00028316749376244843
Test Loss:  0.0001780907914508134
Valid Loss:  0.0002481909468770027
Epoch:  405  	Training Loss: 0.0002825865230988711
Test Loss:  0.00017765889060683548
Valid Loss:  0.00024764364934526384
Epoch:  406  	Training Loss: 0.0002820153604261577
Test Loss:  0.00017724011559039354
Valid Loss:  0.0002471072075422853
Epoch:  407  	Training Loss: 0.0002814567997120321
Test Loss:  0.00017683347687125206
Valid Loss:  0.0002465786528773606
Epoch:  408  	Training Loss: 0.0002809066791087389
Test Loss:  0.00017643434694036841
Valid Loss:  0.00024605856742709875
Epoch:  409  	Training Loss: 0.0002803645911626518
Test Loss:  82%|████████▏ | 409/500 [04:41<00:30,  2.96it/s] 82%|████████▏ | 411/500 [04:48<01:46,  1.19s/it] 83%|████████▎ | 413/500 [04:48<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:48<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:48<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:48<00:27,  2.97it/s] 84%|████████▍ | 421/500 [04:55<01:34,  1.20s/it] 85%|████████▍ | 423/500 [04:55<01:06,  1.16it/s] 85%|████████▌ | 425/500 [04:55<00:46,  1.61it/s] 85%|████████▌ | 427/500 [04:55<00:33,  2.20it/s] 86%|████████▌ | 429/500 [04:55<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:02<01:22,  1.20s/it] 87%|████████▋ | 433/500 [05:02<00:57,  1.16it/s] 87%|████████▋ | 435/500 [05:02<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:02<00:28,  2.19it/s] 88%|████████▊ | 439/500 [05:02<00:20,  2.95it/s] 88%|████████▊ | 441/500 [05:09<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:09<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:09<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:09<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:09<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:15<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:16<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:16<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:16<00:19,  2.20it/s] 92%|█████████▏| 459/500 [05:16<00:13,  2.96it/s] 92%|█████████▏| 461/500 [05:22<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:23<00:31,  1.16it/s] 93%|█████████▎| 465/500 [05:23<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:23<00:15,  2.20it/s] 94%|█████████▍| 469/500 [05:23<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:29<00:35,  1.21s/it] 95%|█████████▍| 473/500 [05:30<00:23,  1.15it/s] 95%|█████████▌| 475/500 [05:30<00:15,  1.60it/s] 0.00017605029279366136
Valid Loss:  0.0002455427311360836
Epoch:  410  	Training Loss: 0.0002798301284201443
Test Loss:  0.00017567699251230806
Valid Loss:  0.00024503213353455067
Epoch:  411  	Training Loss: 0.0002793016319628805
Test Loss:  0.0001753117103362456
Valid Loss:  0.00024452668731100857
Epoch:  412  	Training Loss: 0.0002787811099551618
Test Loss:  0.0001743831526255235
Valid Loss:  0.0002438596566207707
Epoch:  413  	Training Loss: 0.0002780695795081556
Test Loss:  0.00017365241365041584
Valid Loss:  0.0002432335022604093
Epoch:  414  	Training Loss: 0.00027739483630284667
Test Loss:  0.000173047577845864
Valid Loss:  0.00024263272644020617
Epoch:  415  	Training Loss: 0.00027674183365888894
Test Loss:  0.00017252092948183417
Valid Loss:  0.00024204293731600046
Epoch:  416  	Training Loss: 0.00027610192773863673
Test Loss:  0.00017204563482664526
Valid Loss:  0.0002414664631942287
Epoch:  417  	Training Loss: 0.000275473459623754
Test Loss:  0.00017160293646156788
Valid Loss:  0.00024089738144539297
Epoch:  418  	Training Loss: 0.00027485634200274944
Test Loss:  0.0001711828663246706
Valid Loss:  0.00024033323279581964
Epoch:  419  	Training Loss: 0.0002742468495853245
Test Loss:  0.00017077915254049003
Valid Loss:  0.00023977397358976305
Epoch:  420  	Training Loss: 0.00027364460402168334
Test Loss:  0.0001703848975012079
Valid Loss:  0.00023921974934637547
Epoch:  421  	Training Loss: 0.00027305001276545227
Test Loss:  0.00016999791841953993
Valid Loss:  0.00023867089475970715
Epoch:  422  	Training Loss: 0.0002724637452047318
Test Loss:  0.00016974491882137954
Valid Loss:  0.00023830616555642337
Epoch:  423  	Training Loss: 0.00027211240376345813
Test Loss:  0.0001694897364359349
Valid Loss:  0.0002379428769927472
Epoch:  424  	Training Loss: 0.00027176307048648596
Test Loss:  0.000169234728673473
Valid Loss:  0.00023758140741847456
Epoch:  425  	Training Loss: 0.00027141644386574626
Test Loss:  0.00016897637397050858
Valid Loss:  0.0002372239250689745
Epoch:  426  	Training Loss: 0.0002710712724365294
Test Loss:  0.00016871708794496953
Valid Loss:  0.00023686772328801453
Epoch:  427  	Training Loss: 0.00027072877855971456
Test Loss:  0.0001684585731709376
Valid Loss:  0.0002365156979067251
Epoch:  428  	Training Loss: 0.00027038733242079616
Test Loss:  0.00016820052405819297
Valid Loss:  0.0002361652732361108
Epoch:  429  	Training Loss: 0.00027004757430404425
Test Loss:  0.00016794196562841535
Valid Loss:  0.00023581681307405233
Epoch:  430  	Training Loss: 0.00026971157058142126
Test Loss:  0.00016768614295870066
Valid Loss:  0.00023546992451883852
Epoch:  431  	Training Loss: 0.0002693786518648267
Test Loss:  0.00016743196465540677
Valid Loss:  0.00023512729967478663
Epoch:  432  	Training Loss: 0.00026904611149802804
Test Loss:  0.00016747666813898832
Valid Loss:  0.00023494710330851376
Epoch:  433  	Training Loss: 0.0002688503882382065
Test Loss:  0.0001674949162406847
Valid Loss:  0.0002347698900848627
Epoch:  434  	Training Loss: 0.00026866153348237276
Test Loss:  0.00016748433699831367
Valid Loss:  0.00023459989461116493
Epoch:  435  	Training Loss: 0.0002684778592083603
Test Loss:  0.00016745712491683662
Valid Loss:  0.0002344316162634641
Epoch:  436  	Training Loss: 0.00026829791022464633
Test Loss:  0.00016740948194637895
Valid Loss:  0.00023426531697623432
Epoch:  437  	Training Loss: 0.0002681218320503831
Test Loss:  0.00016735185636207461
Valid Loss:  0.00023410134599544108
Epoch:  438  	Training Loss: 0.0002679472090676427
Test Loss:  0.00016727906768210232
Valid Loss:  0.00023393752053380013
Epoch:  439  	Training Loss: 0.0002677743323147297
Test Loss:  0.00016719725681468844
Valid Loss:  0.00023377645993605256
Epoch:  440  	Training Loss: 0.00026760293985717
Test Loss:  0.00016710965428501368
Valid Loss:  0.00023361686908174306
Epoch:  441  	Training Loss: 0.00026743198395706713
Test Loss:  0.00016701285494491458
Valid Loss:  0.00023345793306361884
Epoch:  442  	Training Loss: 0.00026726193027570844
Test Loss:  0.0001667397445999086
Valid Loss:  0.00023335058358497918
Epoch:  443  	Training Loss: 0.00026712415274232626
Test Loss:  0.00016653550846967846
Valid Loss:  0.00023325429356191307
Epoch:  444  	Training Loss: 0.0002669907989911735
Test Loss:  0.00016637571388855577
Valid Loss:  0.00023316257284022868
Epoch:  445  	Training Loss: 0.00026686047203838825
Test Loss:  0.00016624826821498573
Valid Loss:  0.00023307526134885848
Epoch:  446  	Training Loss: 0.0002667322114575654
Test Loss:  0.00016613706247881055
Valid Loss:  0.00023299148597288877
Epoch:  447  	Training Loss: 0.00026660511502996087
Test Loss:  0.00016604046686552465
Valid Loss:  0.00023290816170629114
Epoch:  448  	Training Loss: 0.00026647915365174413
Test Loss:  0.00016595347551628947
Valid Loss:  0.0002328281698282808
Epoch:  449  	Training Loss: 0.000266354123596102
Test Loss:  0.00016587291611358523
Valid Loss:  0.00023275027342606336
Epoch:  450  	Training Loss: 0.00026623051962815225
Test Loss:  0.00016579549992457032
Valid Loss:  0.00023267266806215048
Epoch:  451  	Training Loss: 0.00026610714849084616
Test Loss:  0.00016572246386203915
Valid Loss:  0.00023259635781869292
Epoch:  452  	Training Loss: 0.0002659859601408243
Test Loss:  0.0001650599588174373
Valid Loss:  0.00023205255274660885
Epoch:  453  	Training Loss: 0.00026543281273916364
Test Loss:  0.00016451638657599688
Valid Loss:  0.000231527432333678
Epoch:  454  	Training Loss: 0.0002648961963132024
Test Loss:  0.00016405028873123229
Valid Loss:  0.00023101332772057503
Epoch:  455  	Training Loss: 0.00026436959160491824
Test Loss:  0.00016363407485187054
Valid Loss:  0.00023050674644764513
Epoch:  456  	Training Loss: 0.00026385008823126554
Test Loss:  0.00016324964235536754
Valid Loss:  0.0002300047781318426
Epoch:  457  	Training Loss: 0.000263336201896891
Test Loss:  0.0001628850877750665
Valid Loss:  0.00022950662241782993
Epoch:  458  	Training Loss: 0.0002628281945362687
Test Loss:  0.00016253592912107706
Valid Loss:  0.0002290166448801756
Epoch:  459  	Training Loss: 0.0002623294712975621
Test Loss:  0.0001621984993107617
Valid Loss:  0.00022853119298815727
Epoch:  460  	Training Loss: 0.0002618360158521682
Test Loss:  0.0001618661335669458
Valid Loss:  0.00022804949549026787
Epoch:  461  	Training Loss: 0.000261347449850291
Test Loss:  0.0001615423389011994
Valid Loss:  0.00022757388069294393
Epoch:  462  	Training Loss: 0.00026086746947839856
Test Loss:  0.00016157831123564392
Valid Loss:  0.00022706962772645056
Epoch:  463  	Training Loss: 0.0002603539323899895
Test Loss:  0.00016145751578733325
Valid Loss:  0.00022659896058030427
Epoch:  464  	Training Loss: 0.0002598773571662605
Test Loss:  0.00016123821842484176
Valid Loss:  0.0002261442132294178
Epoch:  465  	Training Loss: 0.0002594160323496908
Test Loss:  0.0001609663595445454
Valid Loss:  0.00022570003056898713
Epoch:  466  	Training Loss: 0.00025896128499880433
Test Loss:  0.00016066670650616288
Valid Loss:  0.00022526236716657877
Epoch:  467  	Training Loss: 0.00025851267855614424
Test Loss:  0.0001603548153070733
Valid Loss:  0.00022483227076008916
Epoch:  468  	Training Loss: 0.0002580690197646618
Test Loss:  0.0001600388204678893
Valid Loss:  0.00022441116743721068
Epoch:  469  	Training Loss: 0.00025762920267879963
Test Loss:  0.00015972372784744948
Valid Loss:  0.00022399789304472506
Epoch:  470  	Training Loss: 0.00025719424593262374
Test Loss:  0.0001594117929926142
Valid Loss:  0.00022358937712851912
Epoch:  471  	Training Loss: 0.0002567628980614245
Test Loss:  0.00015910323418211192
Valid Loss:  0.0002231871330877766
Epoch:  472  	Training Loss: 0.00025633309269323945
Test Loss:  0.00015852627984713763
Valid Loss:  0.00022277298558037728
Epoch:  473  	Training Loss: 0.0002558493288233876
Test Loss:  0.000158108479809016
Valid Loss:  0.00022238685050979257
Epoch:  474  	Training Loss: 0.00025538401678204536
Test Loss:  0.00015777433873154223
Valid Loss:  0.0002220118185505271
Epoch:  475  	Training Loss: 0.0002549277269281447
Test Loss:  0.00015748277655802667
Valid Loss:  0.00022164374240674078
Epoch:  476  	Training Loss: 0.0002544787130318582
Test Loss:  0.00015721548697911203
 95%|█████████▌| 477/500 [05:30<00:10,  2.19it/s] 96%|█████████▌| 479/500 [05:30<00:07,  2.94it/s] 96%|█████████▌| 481/500 [05:36<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:37<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:37<00:05,  2.19it/s] 98%|█████████▊| 489/500 [05:37<00:03,  2.95it/s] 98%|█████████▊| 491/500 [05:43<00:10,  1.21s/it] 99%|█████████▊| 493/500 [05:43<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:44<00:03,  1.59it/s] 99%|█████████▉| 497/500 [05:44<00:01,  2.17it/s]100%|█████████▉| 499/500 [05:44<00:00,  2.93it/s]100%|██████████| 500/500 [05:44<00:00,  1.45it/s]
Valid Loss:  0.0002212794788647443
Epoch:  477  	Training Loss: 0.00025403540348634124
Test Loss:  0.00015695893671363592
Valid Loss:  0.0002209175145253539
Epoch:  478  	Training Loss: 0.0002535972453188151
Test Loss:  0.00015671318396925926
Valid Loss:  0.00022055617591831833
Epoch:  479  	Training Loss: 0.0002531636564526707
Test Loss:  0.00015646935207769275
Valid Loss:  0.00022019713651388884
Epoch:  480  	Training Loss: 0.00025273364735767245
Test Loss:  0.0001562271500006318
Valid Loss:  0.00021983819897286594
Epoch:  481  	Training Loss: 0.00025230777100659907
Test Loss:  0.0001559850643388927
Valid Loss:  0.00021948009089101106
Epoch:  482  	Training Loss: 0.000251885736361146
Test Loss:  0.00015626591630280018
Valid Loss:  0.0002191356907133013
Epoch:  483  	Training Loss: 0.00025152837042696774
Test Loss:  0.0001564586127642542
Valid Loss:  0.00021886311878915876
Epoch:  484  	Training Loss: 0.00025124719832092524
Test Loss:  0.0001565763377584517
Valid Loss:  0.00021862867288291454
Epoch:  485  	Training Loss: 0.0002510067424736917
Test Loss:  0.00015662805526517332
Valid Loss:  0.00021841585112269968
Epoch:  486  	Training Loss: 0.00025079178158193827
Test Loss:  0.00015663108206354082
Valid Loss:  0.00021821937116328627
Epoch:  487  	Training Loss: 0.0002505909651517868
Test Loss:  0.00015659703058190644
Valid Loss:  0.00021803121489938349
Epoch:  488  	Training Loss: 0.0002503986470401287
Test Loss:  0.00015653290029149503
Valid Loss:  0.00021785017452202737
Epoch:  489  	Training Loss: 0.00025021153851412237
Test Loss:  0.00015645098756067455
Valid Loss:  0.00021767542057204992
Epoch:  490  	Training Loss: 0.0002500285336282104
Test Loss:  0.00015635332965757698
Valid Loss:  0.00021750379528384656
Epoch:  491  	Training Loss: 0.0002498470130376518
Test Loss:  0.00015624804655089974
Valid Loss:  0.00021733599714934826
Epoch:  492  	Training Loss: 0.000249668606556952
Test Loss:  0.00015528259973507375
Valid Loss:  0.0002168449864257127
Epoch:  493  	Training Loss: 0.00024920227588154376
Test Loss:  0.00015450423234142363
Valid Loss:  0.00021643273066729307
Epoch:  494  	Training Loss: 0.0002488108875695616
Test Loss:  0.00015386792074423283
Valid Loss:  0.00021607193048112094
Epoch:  495  	Training Loss: 0.00024847060558386147
Test Loss:  0.00015334105410147458
Valid Loss:  0.00021574643324129283
Epoch:  496  	Training Loss: 0.0002481658011674881
Test Loss:  0.00015289954899344593
Valid Loss:  0.00021544829360209405
Epoch:  497  	Training Loss: 0.00024788593873381615
Test Loss:  0.00015252336743287742
Valid Loss:  0.00021517014829441905
Epoch:  498  	Training Loss: 0.0002476238878443837
Test Loss:  0.00015220169734675437
Valid Loss:  0.00021490581275429577
Epoch:  499  	Training Loss: 0.00024737571948207915
Test Loss:  0.00015191957936622202
Valid Loss:  0.00021465163445100188
Epoch:  500  	Training Loss: 0.00024713610764592886
Test Loss:  0.00015167190576903522
Valid Loss:  0.00021440496493596584
seed is  6
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.17it/s]  1%|          | 4/500 [00:00<00:30, 16.45it/s]  1%|          | 6/500 [00:00<00:29, 16.51it/s]  2%|▏         | 8/500 [00:00<00:29, 16.52it/s]  2%|▏         | 10/500 [00:00<00:29, 16.49it/s]  2%|▏         | 12/500 [00:00<00:29, 16.52it/s]  3%|▎         | 14/500 [00:00<00:29, 16.55it/s]  3%|▎         | 16/500 [00:00<00:29, 16.47it/s]  4%|▎         | 18/500 [00:01<00:29, 16.41it/s]  4%|▍         | 20/500 [00:01<00:29, 16.31it/s]  4%|▍         | 22/500 [00:01<00:29, 16.04it/s]  5%|▍         | 24/500 [00:01<00:29, 15.99it/s]  5%|▌         | 26/500 [00:01<00:29, 16.04it/s]  6%|▌         | 28/500 [00:01<00:29, 16.18it/s]  6%|▌         | 30/500 [00:01<00:28, 16.24it/s]  6%|▋         | 32/500 [00:01<00:28, 16.36it/s]  7%|▋         | 34/500 [00:02<00:28, 16.40it/s]  7%|▋         | 36/500 [00:02<00:28, 16.42it/s]  8%|▊         | 38/500 [00:02<00:28, 16.40it/s]  8%|▊         | 40/500 [00:02<00:28, 16.29it/s]  8%|▊         | 42/500 [00:02<00:28, 16.30it/s]  9%|▉         | 44/500 [00:02<00:28, 16.20it/s]  9%|▉         | 46/500 [00:02<00:28, 16.20it/s] 10%|▉         | 48/500 [00:02<00:27, 16.26it/s] 10%|█         | 50/500 [00:03<00:27, 16.27it/s] 10%|█         | 52/500 [00:03<00:27, 16.32it/s] 11%|█         | 54/500 [00:03<00:27, 16.35it/s] 11%|█         | 56/500 [00:03<00:27, 16.15it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.18it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.12it/s] 12%|█▏        | 62/500 [00:03<00:28, 15.14it/s] 13%|█▎        | 64/500 [00:03<00:28, 15.46it/s] 13%|█▎        | 66/500 [00:04<00:28, 15.30it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.61it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.76it/s] 14%|█▍        | 72/500 [00:04<00:29, 14.69it/s] 15%|█▍        | 74/500 [00:04<00:28, 14.99it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.42it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.73it/s] 16%|█▌        | 80/500 [00:04<00:26, 15.89it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.15it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.21it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.28it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.22it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.34it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.48it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.57it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.62it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.45it/s] 20%|██        | 100/500 [00:06<00:24, 16.45it/s] 20%|██        | 102/500 [00:06<00:24, 16.51it/s] 21%|██        | 104/500 [00:06<00:23, 16.61it/s] 21%|██        | 106/500 [00:06<00:23, 16.63it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.61it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.58it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.59it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.61it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.61it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.58it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.59it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.66it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.33it/s]Epoch:  1  	Training Loss: 0.023397840559482574
Test Loss:  125.54142761230469
Valid Loss:  125.90763092041016
Epoch:  2  	Training Loss: 125.97348022460938
Test Loss:  103999889408.0
Valid Loss:  103100620800.0
Epoch:  3  	Training Loss: 103259832320.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.36it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.34it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.40it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.41it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.27it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.18it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.28it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.39it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.47it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.48it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.49it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.48it/s] 30%|███       | 150/500 [00:09<00:21, 16.45it/s] 30%|███       | 152/500 [00:09<00:21, 16.30it/s] 31%|███       | 154/500 [00:09<00:21, 16.21it/s] 31%|███       | 156/500 [00:09<00:21, 16.30it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.35it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.37it/s] 32%|███▏      | 162/500 [00:09<00:21, 15.73it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.50it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.26it/s] 34%|███▎      | 168/500 [00:10<00:21, 15.17it/s] 34%|███▍      | 170/500 [00:10<00:22, 14.64it/s] 34%|███▍      | 172/500 [00:10<00:23, 14.06it/s] 35%|███▍      | 174/500 [00:10<00:23, 14.03it/s] 35%|███▌      | 176/500 [00:10<00:23, 13.53it/s] 36%|███▌      | 178/500 [00:11<00:24, 13.22it/s] 36%|███▌      | 180/500 [00:11<00:23, 13.70it/s] 36%|███▋      | 182/500 [00:11<00:21, 14.46it/s] 37%|███▋      | 184/500 [00:11<00:20, 15.05it/s] 37%|███▋      | 186/500 [00:11<00:20, 15.51it/s] 38%|███▊      | 188/500 [00:11<00:20, 15.08it/s] 38%|███▊      | 190/500 [00:11<00:20, 15.48it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.41it/s] 39%|███▉      | 194/500 [00:12<00:20, 15.25it/s] 39%|███▉      | 196/500 [00:12<00:21, 14.26it/s] 40%|███▉      | 198/500 [00:12<00:21, 13.90it/s] 40%|████      | 200/500 [00:12<00:22, 13.58it/s] 40%|████      | 202/500 [00:12<00:22, 13.08it/s] 41%|████      | 204/500 [00:12<00:22, 13.31it/s] 41%|████      | 206/500 [00:13<00:22, 13.00it/s] 42%|████▏     | 208/500 [00:13<00:22, 12.85it/s] 42%|████▏     | 210/500 [00:13<00:22, 12.80it/s] 42%|████▏     | 212/500 [00:13<00:21, 13.59it/s] 43%|████▎     | 214/500 [00:13<00:19, 14.35it/s] 43%|████▎     | 216/500 [00:13<00:19, 14.93it/s] 44%|████▎     | 218/500 [00:13<00:18, 15.10it/s] 44%|████▍     | 220/500 [00:14<00:18, 15.36it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.59it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.95it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.12it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.04it/s] 46%|████▌     | 230/500 [00:14<00:16, 15.97it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.19it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.15it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.04it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.05it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.02it/s] 48%|████▊     | 242/500 [00:15<00:16, 16.11it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.24it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.31it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.27it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.21it/s] 50%|█████     | 252/500 [00:16<00:15, 16.23it/s] 51%|█████     | 254/500 [00:16<00:15, 16.24it/s] 51%|█████     | 256/500 [00:16<00:14, 16.34it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.34it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.10it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.12it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.02it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.93it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.92it/s] 54%|█████▍    | 270/500 [00:17<00:14, 16.07it/s] 54%|█████▍    | 272/500 [00:17<00:14, 15.32it/s] 55%|█████▍    | 274/500 [00:17<00:15, 14.28it/s] 55%|█████▌    | 276/500 [00:17<00:16, 13.67it/s] 56%|█████▌    | 278/500 [00:17<00:16, 13.47it/s] 56%|█████▌    | 280/500 [00:17<00:15, 14.25it/s] 56%|█████▋    | 282/500 [00:18<00:14, 14.84it/s] 57%|█████▋    | 284/500 [00:18<00:14, 15.30it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.60it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.95it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.57it/s] 58%|█████▊    | 292/500 [00:18<00:14, 14.48it/s] 59%|█████▉    | 294/500 [00:18<00:14, 13.93it/s] 59%|█████▉    | 296/500 [00:18<00:13, 14.65it/s] 60%|█████▉    | 298/500 [00:19<00:13, 15.17it/s] 60%|██████    | 300/500 [00:19<00:12, 15.51it/s] 60%|██████    | 302/500 [00:19<00:12, 15.87it/s] 61%|██████    | 304/500 [00:19<00:12, 16.05it/s] 61%|██████    | 306/500 [00:19<00:11, 16.19it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.12it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.07it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.19it/s] 63%|██████▎   | 314/500 [00:20<00:11, 16.28it/s] 63%|██████▎   | 316/500 [00:20<00:11, 15.61it/s] 64%|██████▎   | 318/500 [00:20<00:12, 14.27it/s] 64%|██████▍   | 320/500 [00:20<00:13, 13.65it/s] 64%|██████▍   | 322/500 [00:20<00:13, 13.27it/s] 65%|██████▍   | 324/500 [00:20<00:12, 14.11it/s] 65%|██████▌   | 326/500 [00:20<00:11, 14.68it/s] 66%|██████▌   | 328/500 [00:21<00:11, 15.07it/s] 66%|██████▌   | 330/500 [00:21<00:11, 15.41it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.49it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.81it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.78it/s] 68%|██████▊   | 338/500 [00:21<00:10, 16.01it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.15it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.06it/s] 69%|██████▉   | 344/500 [00:22<00:09, 16.02it/s] 69%|██████▉   | 346/500 [00:22<00:09, 16.13it/s] 70%|██████▉   | 348/500 [00:22<00:09, 16.01it/s] 70%|███████   | 350/500 [00:22<00:09, 16.03it/s] 70%|███████   | 352/500 [00:22<00:09, 16.09it/s] 71%|███████   | 354/500 [00:22<00:09, 16.20it/s] 71%|███████   | 356/500 [00:22<00:08, 16.37it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.36it/s] 72%|███████▏  | 360/500 [00:23<00:08, 16.43it/s] 72%|███████▏  | 362/500 [00:23<00:08, 16.43it/s] 73%|███████▎  | 364/500 [00:23<00:08, 16.47it/s] 73%|███████▎  | 366/500 [00:23<00:08, 16.25it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.07it/s] 74%|███████▍  | 370/500 [00:23<00:08, 16.21it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.21it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 15.79it/s] 75%|███████▌  | 376/500 [00:24<00:07, 15.97it/s] 76%|███████▌  | 378/500 [00:24<00:07, 16.11it/s] 76%|███████▌  | 380/500 [00:24<00:07, 16.28it/s] 76%|███████▋  | 382/500 [00:24<00:07, 16.33it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.35it/s] 77%|███████▋  | 386/500 [00:24<00:06, 16.39it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.41it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.47it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.31it/s] 79%|███████▉  | 394/500 [00:25<00:06, 16.36it/s] 79%|███████▉  | 396/500 [00:25<00:06, 16.34it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.43it/s] 80%|████████  | 400/500 [00:25<00:06, 16.24it/s] 80%|████████  | 402/500 [00:25<00:06, 15.96it/s] 81%|████████  | 404/500 [00:25<00:05, 16.04it/s] 81%|████████  | 406/500 [00:25<00:05, 16.18it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.30it/s] 82%|████████▏ | 410/500 [00:26<00:05, 16.35it/s] 82%|████████▏ | 412/500 [00:26<00:05, 16.38it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.42it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.43it/s] 84%|████████▎ | 418/500 [00:26<00:04, 16.53it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.56it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.52it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.48it/s] 85%|████████▌ | 426/500 [00:27<00:04, 16.47it/s] 86%|████████▌ | 428/500 [00:27<00:04, 16.49it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.34it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.40it/s] 87%|████████▋ | 434/500 [00:27<00:03, 16.50it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.48it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.38it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.35it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.37it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.36it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.40it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.29it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.25it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.29it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.38it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.27it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.19it/s] 92%|█████████▏| 460/500 [00:29<00:02, 16.21it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.11it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.10it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.20it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.32it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.35it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.40it/s] 95%|█████████▍| 474/500 [00:30<00:01, 16.26it/s] 95%|█████████▌| 476/500 [00:30<00:01, 16.17it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.24it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.21it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.18it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.18it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.07it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.15it/s] 98%|█████████▊| 490/500 [00:31<00:00, 16.26it/s] 98%|█████████▊| 492/500 [00:31<00:00, 15.47it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.70it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.66it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.50it/s]100%|██████████| 500/500 [00:31<00:00, 14.99it/s]100%|██████████| 500/500 [00:31<00:00, 15.79it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  6
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:23,  6.18s/it]  1%|          | 3/500 [00:06<13:42,  1.66s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.92it/s]  2%|▏         | 11/500 [00:13<10:56,  1.34s/it]  3%|▎         | 13/500 [00:13<07:27,  1.09it/s]  3%|▎         | 15/500 [00:13<05:12,  1.55it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:20<09:46,  1.22s/it]  5%|▍         | 23/500 [00:20<06:57,  1.14it/s]  5%|▌         | 25/500 [00:20<04:58,  1.59it/s]  5%|▌         | 27/500 [00:20<03:38,  2.16it/s]  6%|▌         | 29/500 [00:20<02:44,  2.87it/s]  6%|▌         | 31/500 [00:27<09:45,  1.25s/it]  7%|▋         | 33/500 [00:27<06:57,  1.12it/s]  7%|▋         | 35/500 [00:27<04:59,  1.55it/s]  7%|▋         | 37/500 [00:27<03:37,  2.13it/s]  8%|▊         | 39/500 [00:27<02:43,  2.83it/s]  8%|▊         | 41/500 [00:34<09:17,  1.22s/it]  9%|▊         | 43/500 [00:34<06:38,  1.15it/s]  9%|▉         | 45/500 [00:34<04:46,  1.59it/s]  9%|▉         | 47/500 [00:34<03:28,  2.17it/s] 10%|▉         | 49/500 [00:34<02:34,  2.92it/s] 10%|█         | 51/500 [00:41<09:05,  1.22s/it] 11%|█         | 53/500 [00:41<06:29,  1.15it/s] 11%|█         | 55/500 [00:41<04:40,  1.59it/s] 11%|█▏        | 57/500 [00:41<03:23,  2.17it/s] 12%|█▏        | 59/500 [00:41<02:30,  2.93it/s] 12%|█▏        | 61/500 [00:48<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:48<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:48<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:48<03:18,  2.18it/s] 14%|█▍        | 69/500 [00:48<02:27,  2.92it/s] 14%|█▍        | 71/500 [00:55<08:26,  1.18s/it]Epoch:  1  	Training Loss: 0.023397838696837425
Test Loss:  0.7343237400054932
Valid Loss:  0.7459613084793091
Epoch:  2  	Training Loss: 0.745153546333313
Test Loss:  4.8987836837768555
Valid Loss:  4.783951282501221
Epoch:  3  	Training Loss: 4.827275276184082
Test Loss:  0.03661181405186653
Valid Loss:  0.03921856731176376
Epoch:  4  	Training Loss: 0.039225585758686066
Test Loss:  0.036609143018722534
Valid Loss:  0.039215754717588425
Epoch:  5  	Training Loss: 0.039222728461027145
Test Loss:  0.03660647198557854
Valid Loss:  0.039212942123413086
Epoch:  6  	Training Loss: 0.03921987861394882
Test Loss:  0.03660380840301514
Valid Loss:  0.03921012952923775
Epoch:  7  	Training Loss: 0.0392170213162899
Test Loss:  0.03660114109516144
Valid Loss:  0.03920732066035271
Epoch:  8  	Training Loss: 0.03921417146921158
Test Loss:  0.03659847006201744
Valid Loss:  0.03920450806617737
Epoch:  9  	Training Loss: 0.03921131789684296
Test Loss:  0.036595799028873444
Valid Loss:  0.03920169919729233
Epoch:  10  	Training Loss: 0.03920846804976463
Test Loss:  0.03659313917160034
Valid Loss:  0.03919889032840729
Epoch:  11  	Training Loss: 0.03920561820268631
Test Loss:  0.03659047186374664
Valid Loss:  0.03919608145952225
Epoch:  12  	Training Loss: 0.03920276463031769
Test Loss:  0.03657747805118561
Valid Loss:  0.03918231651186943
Epoch:  13  	Training Loss: 0.03918881714344025
Test Loss:  0.03656448423862457
Valid Loss:  0.03916855901479721
Epoch:  14  	Training Loss: 0.0391748808324337
Test Loss:  0.03655150532722473
Valid Loss:  0.03915480524301529
Epoch:  15  	Training Loss: 0.03916095197200775
Test Loss:  0.03653852641582489
Valid Loss:  0.03914106264710426
Epoch:  16  	Training Loss: 0.0391470231115818
Test Loss:  0.036525554955005646
Valid Loss:  0.039127327501773834
Epoch:  17  	Training Loss: 0.03913310170173645
Test Loss:  0.0365125872194767
Valid Loss:  0.03911358863115311
Epoch:  18  	Training Loss: 0.03911919146776199
Test Loss:  0.03649962693452835
Valid Loss:  0.03909986466169357
Epoch:  19  	Training Loss: 0.03910528123378754
Test Loss:  0.0364866703748703
Valid Loss:  0.03908614069223404
Epoch:  20  	Training Loss: 0.03909137845039368
Test Loss:  0.03647371754050255
Valid Loss:  0.039072420448064804
Epoch:  21  	Training Loss: 0.039077483117580414
Test Loss:  0.03646077215671539
Valid Loss:  0.03905871510505676
Epoch:  22  	Training Loss: 0.03906358778476715
Test Loss:  0.0364474356174469
Valid Loss:  0.039044588804244995
Epoch:  23  	Training Loss: 0.03904928267002106
Test Loss:  0.036434106528759
Valid Loss:  0.03903046250343323
Epoch:  24  	Training Loss: 0.039034973829984665
Test Loss:  0.036420788615942
Valid Loss:  0.039016347378492355
Epoch:  25  	Training Loss: 0.03902067616581917
Test Loss:  0.0364074669778347
Valid Loss:  0.03900223970413208
Epoch:  26  	Training Loss: 0.03900637850165367
Test Loss:  0.036394152790308
Valid Loss:  0.0389881357550621
Epoch:  27  	Training Loss: 0.03899209573864937
Test Loss:  0.036380842328071594
Valid Loss:  0.038974035531282425
Epoch:  28  	Training Loss: 0.03897780925035477
Test Loss:  0.03636753931641579
Valid Loss:  0.038959942758083344
Epoch:  29  	Training Loss: 0.03896353393793106
Test Loss:  0.03635425120592117
Valid Loss:  0.03894586116075516
Epoch:  30  	Training Loss: 0.03894926607608795
Test Loss:  0.036340951919555664
Valid Loss:  0.03893177956342697
Epoch:  31  	Training Loss: 0.03893499821424484
Test Loss:  0.03632766753435135
Valid Loss:  0.03891770541667938
Epoch:  32  	Training Loss: 0.03892074525356293
Test Loss:  0.036314111202955246
Valid Loss:  0.03890334069728851
Epoch:  33  	Training Loss: 0.03890619054436684
Test Loss:  0.03630055487155914
Valid Loss:  0.03888897970318794
Epoch:  34  	Training Loss: 0.03889164328575134
Test Loss:  0.036287009716033936
Valid Loss:  0.03887462615966797
Epoch:  35  	Training Loss: 0.038877107203006744
Test Loss:  0.03627346456050873
Valid Loss:  0.03886028006672859
Epoch:  36  	Training Loss: 0.038862571120262146
Test Loss:  0.036259934306144714
Valid Loss:  0.03884594142436981
Epoch:  37  	Training Loss: 0.038848042488098145
Test Loss:  0.0362464040517807
Valid Loss:  0.03883160650730133
Epoch:  38  	Training Loss: 0.03883352875709534
Test Loss:  0.03623288869857788
Valid Loss:  0.03881728649139404
Epoch:  39  	Training Loss: 0.03881901502609253
Test Loss:  0.036219365894794464
Valid Loss:  0.03880296275019646
Epoch:  40  	Training Loss: 0.03880450874567032
Test Loss:  0.03620585799217224
Valid Loss:  0.03878864645957947
Epoch:  41  	Training Loss: 0.038790009915828705
Test Loss:  0.03619235008955002
Valid Loss:  0.038774341344833374
Epoch:  42  	Training Loss: 0.03877551108598709
Test Loss:  0.036178551614284515
Valid Loss:  0.03875972330570221
Epoch:  43  	Training Loss: 0.038760703057050705
Test Loss:  0.03616475313901901
Valid Loss:  0.038745101541280746
Epoch:  44  	Training Loss: 0.03874589502811432
Test Loss:  0.0361509695649147
Valid Loss:  0.03873048722743988
Epoch:  45  	Training Loss: 0.03873109817504883
Test Loss:  0.036137185990810394
Valid Loss:  0.03871588408946991
Epoch:  46  	Training Loss: 0.03871630132198334
Test Loss:  0.036123406141996384
Valid Loss:  0.038701288402080536
Epoch:  47  	Training Loss: 0.038701511919498444
Test Loss:  0.03610963374376297
Valid Loss:  0.038686688989400864
Epoch:  48  	Training Loss: 0.03868672996759415
Test Loss:  0.036095865070819855
Valid Loss:  0.03867210075259209
Epoch:  49  	Training Loss: 0.03867195174098015
Test Loss:  0.036082103848457336
Valid Loss:  0.03865751624107361
Epoch:  50  	Training Loss: 0.038657184690237045
Test Loss:  0.036068350076675415
Valid Loss:  0.038642942905426025
Epoch:  51  	Training Loss: 0.03864242136478424
Test Loss:  0.036054596304893494
Valid Loss:  0.03862836956977844
Epoch:  52  	Training Loss: 0.038627661764621735
Test Loss:  0.03604065254330635
Valid Loss:  0.03861360251903534
Epoch:  53  	Training Loss: 0.038612693548202515
Test Loss:  0.036026712507009506
Valid Loss:  0.03859883174300194
Epoch:  54  	Training Loss: 0.03859773278236389
Test Loss:  0.03601278364658356
Valid Loss:  0.03858406841754913
Epoch:  55  	Training Loss: 0.038582783192396164
Test Loss:  0.035998858511447906
Valid Loss:  0.038569316267967224
Epoch:  56  	Training Loss: 0.03856784105300903
Test Loss:  0.035984937101602554
Valid Loss:  0.03855457156896591
Epoch:  57  	Training Loss: 0.0385528989136219
Test Loss:  0.0359710231423378
Valid Loss:  0.0385398343205452
Epoch:  58  	Training Loss: 0.038537971675395966
Test Loss:  0.03595711663365364
Valid Loss:  0.03852509707212448
Epoch:  59  	Training Loss: 0.03852304071187973
Test Loss:  0.035943225026130676
Valid Loss:  0.03851038217544556
Epoch:  60  	Training Loss: 0.03850812837481499
Test Loss:  0.03592932969331741
Valid Loss:  0.038495659828186035
Epoch:  61  	Training Loss: 0.03849321976304054
Test Loss:  0.03591544181108475
Valid Loss:  0.03848094493150711
Epoch:  62  	Training Loss: 0.038478314876556396
Test Loss:  0.035901375114917755
Valid Loss:  0.038466036319732666
Epoch:  63  	Training Loss: 0.03846321254968643
Test Loss:  0.03588730841875076
Valid Loss:  0.038451142609119415
Epoch:  64  	Training Loss: 0.038448117673397064
Test Loss:  0.035873252898454666
Valid Loss:  0.038436248898506165
Epoch:  65  	Training Loss: 0.03843303024768829
Test Loss:  0.035859204828739166
Valid Loss:  0.038421355187892914
Epoch:  66  	Training Loss: 0.03841795027256012
Test Loss:  0.035845156759023666
Valid Loss:  0.038406483829021454
Epoch:  67  	Training Loss: 0.03840287774801254
Test Loss:  0.03583111613988876
Valid Loss:  0.0383916050195694
Epoch:  68  	Training Loss: 0.03838781267404556
Test Loss:  0.035817086696624756
Valid Loss:  0.03837673366069794
Epoch:  69  	Training Loss: 0.03837275132536888
Test Loss:  0.035803064703941345
Valid Loss:  0.03836187720298767
Epoch:  70  	Training Loss: 0.0383576974272728
Test Loss:  0.03578904643654823
Valid Loss:  0.0383470244705677
Epoch:  71  	Training Loss: 0.038342658430337906
Test Loss:  0.03577503189444542
Valid Loss:  0.03833218291401863
Epoch:  72  	Training Loss: 0.038327619433403015
Test Loss:  0.03576095402240753
Valid Loss:  0.03831726312637329
 15%|█▍        | 73/500 [00:55<06:02,  1.18it/s] 15%|█▌        | 75/500 [00:55<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:55<03:11,  2.20it/s] 16%|█▌        | 79/500 [00:55<02:21,  2.97it/s] 16%|█▌        | 81/500 [01:01<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:02<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:02<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:02<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:02<02:19,  2.94it/s] 18%|█▊        | 91/500 [01:08<08:02,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:45,  1.18it/s] 19%|█▉        | 95/500 [01:09<04:08,  1.63it/s] 19%|█▉        | 97/500 [01:09<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:09<02:15,  2.96it/s] 20%|██        | 101/500 [01:15<08:02,  1.21s/it] 21%|██        | 103/500 [01:16<05:44,  1.15it/s] 21%|██        | 105/500 [01:16<04:07,  1.59it/s] 21%|██▏       | 107/500 [01:16<03:00,  2.18it/s] 22%|██▏       | 109/500 [01:16<02:13,  2.94it/s] 22%|██▏       | 111/500 [01:22<07:39,  1.18s/it] 23%|██▎       | 113/500 [01:22<05:28,  1.18it/s] 23%|██▎       | 115/500 [01:22<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:23<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:23<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:29<07:20,  1.16s/it] 25%|██▍       | 123/500 [01:29<05:14,  1.20it/s] 25%|██▌       | 125/500 [01:29<03:46,  1.65it/s] 25%|██▌       | 127/500 [01:29<02:46,  2.23it/s] 26%|██▌       | 129/500 [01:30<02:05,  2.95it/s] 26%|██▌       | 131/500 [01:36<07:19,  1.19s/it] 27%|██▋       | 133/500 [01:36<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:36<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:36<02:44,  2.21it/s] 28%|██▊       | 139/500 [01:36<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:43<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:43<05:06,  1.17it/s]Epoch:  73  	Training Loss: 0.038312509655952454
Test Loss:  0.03574687987565994
Valid Loss:  0.03830236196517944
Epoch:  74  	Training Loss: 0.03829740732908249
Test Loss:  0.03573283180594444
Valid Loss:  0.03828747570514679
Epoch:  75  	Training Loss: 0.03828233480453491
Test Loss:  0.035718802362680435
Valid Loss:  0.038272611796855927
Epoch:  76  	Training Loss: 0.038267284631729126
Test Loss:  0.03570479899644852
Valid Loss:  0.03825777396559715
Epoch:  77  	Training Loss: 0.03825225681066513
Test Loss:  0.035690806806087494
Valid Loss:  0.03824295848608017
Epoch:  78  	Training Loss: 0.03823723644018173
Test Loss:  0.035676829516887665
Valid Loss:  0.03822816163301468
Epoch:  79  	Training Loss: 0.03822224587202072
Test Loss:  0.03566287085413933
Valid Loss:  0.03821336850523949
Epoch:  80  	Training Loss: 0.03820725902915001
Test Loss:  0.03564892336726189
Valid Loss:  0.03819859027862549
Epoch:  81  	Training Loss: 0.03819228708744049
Test Loss:  0.03563498705625534
Valid Loss:  0.03818383067846298
Epoch:  82  	Training Loss: 0.03817732632160187
Test Loss:  0.03562144935131073
Valid Loss:  0.03816948086023331
Epoch:  83  	Training Loss: 0.03816279396414757
Test Loss:  0.03560791537165642
Valid Loss:  0.03815513849258423
Epoch:  84  	Training Loss: 0.038148269057273865
Test Loss:  0.035594403743743896
Valid Loss:  0.038140811026096344
Epoch:  85  	Training Loss: 0.03813375532627106
Test Loss:  0.03558088839054108
Valid Loss:  0.03812648355960846
Epoch:  86  	Training Loss: 0.038119249045848846
Test Loss:  0.035567380487918854
Valid Loss:  0.03811216726899147
Epoch:  87  	Training Loss: 0.038104746490716934
Test Loss:  0.03555388003587723
Valid Loss:  0.03809785470366478
Epoch:  88  	Training Loss: 0.038090258836746216
Test Loss:  0.0355403907597065
Valid Loss:  0.038083553314208984
Epoch:  89  	Training Loss: 0.0380757674574852
Test Loss:  0.03552690148353577
Valid Loss:  0.03806925565004349
Epoch:  90  	Training Loss: 0.038061290979385376
Test Loss:  0.03551342710852623
Valid Loss:  0.03805496543645859
Epoch:  91  	Training Loss: 0.03804682195186615
Test Loss:  0.035499949008226395
Valid Loss:  0.03804067522287369
Epoch:  92  	Training Loss: 0.03803235664963722
Test Loss:  0.035486042499542236
Valid Loss:  0.038025930523872375
Epoch:  93  	Training Loss: 0.03801742196083069
Test Loss:  0.035472139716148376
Valid Loss:  0.03801119327545166
Epoch:  94  	Training Loss: 0.03800249099731445
Test Loss:  0.035458240658044815
Valid Loss:  0.037996452301740646
Epoch:  95  	Training Loss: 0.03798757120966911
Test Loss:  0.03544435650110245
Valid Loss:  0.037981726229190826
Epoch:  96  	Training Loss: 0.03797265887260437
Test Loss:  0.035430483520030975
Valid Loss:  0.037967003881931305
Epoch:  97  	Training Loss: 0.037957750260829926
Test Loss:  0.035416603088378906
Valid Loss:  0.03795229271054268
Epoch:  98  	Training Loss: 0.03794284909963608
Test Loss:  0.03540273755788803
Valid Loss:  0.03793758898973465
Epoch:  99  	Training Loss: 0.037927962839603424
Test Loss:  0.03538886830210686
Valid Loss:  0.03792288154363632
Epoch:  100  	Training Loss: 0.03791307657957077
Test Loss:  0.035375021398067474
Valid Loss:  0.03790818899869919
Epoch:  101  	Training Loss: 0.03789819777011871
Test Loss:  0.03536117449402809
Valid Loss:  0.03789350390434265
Epoch:  102  	Training Loss: 0.03788333386182785
Test Loss:  0.03534715622663498
Valid Loss:  0.037878647446632385
Epoch:  103  	Training Loss: 0.037868283689022064
Test Loss:  0.03533315658569336
Valid Loss:  0.037863798439502716
Epoch:  104  	Training Loss: 0.03785324469208717
Test Loss:  0.03531915694475174
Valid Loss:  0.03784894943237305
Epoch:  105  	Training Loss: 0.03783821687102318
Test Loss:  0.035305172204971313
Valid Loss:  0.03783411532640457
Epoch:  106  	Training Loss: 0.03782319277524948
Test Loss:  0.03529118746519089
Valid Loss:  0.037819284945726395
Epoch:  107  	Training Loss: 0.03780817985534668
Test Loss:  0.03527721017599106
Valid Loss:  0.03780446574091911
Epoch:  108  	Training Loss: 0.03779316693544388
Test Loss:  0.03526324778795242
Valid Loss:  0.03778965771198273
Epoch:  109  	Training Loss: 0.03777816891670227
Test Loss:  0.03524927794933319
Valid Loss:  0.03777484595775604
Epoch:  110  	Training Loss: 0.03776317462325096
Test Loss:  0.03523532301187515
Valid Loss:  0.03776005282998085
Epoch:  111  	Training Loss: 0.03774818778038025
Test Loss:  0.03522137552499771
Valid Loss:  0.03774525225162506
Epoch:  112  	Training Loss: 0.037733208388090134
Test Loss:  0.03520738333463669
Valid Loss:  0.03773041069507599
Epoch:  113  	Training Loss: 0.03771818429231644
Test Loss:  0.03519340232014656
Valid Loss:  0.03771558403968811
Epoch:  114  	Training Loss: 0.03770316764712334
Test Loss:  0.03517942503094673
Valid Loss:  0.03770076110959053
Epoch:  115  	Training Loss: 0.037688158452510834
Test Loss:  0.0351654514670372
Valid Loss:  0.03768594190478325
Epoch:  116  	Training Loss: 0.03767315298318863
Test Loss:  0.035151489078998566
Valid Loss:  0.03767113387584686
Epoch:  117  	Training Loss: 0.03765815496444702
Test Loss:  0.03513752669095993
Valid Loss:  0.037656329572200775
Epoch:  118  	Training Loss: 0.03764316439628601
Test Loss:  0.03512357920408249
Valid Loss:  0.037641532719135284
Epoch:  119  	Training Loss: 0.037628185003995895
Test Loss:  0.03510963171720505
Valid Loss:  0.03762674331665039
Epoch:  120  	Training Loss: 0.03761320933699608
Test Loss:  0.0350956991314888
Valid Loss:  0.037611961364746094
Epoch:  121  	Training Loss: 0.03759823739528656
Test Loss:  0.035081759095191956
Valid Loss:  0.037597186863422394
Epoch:  122  	Training Loss: 0.03758327662944794
Test Loss:  0.03506789728999138
Valid Loss:  0.03758249431848526
Epoch:  123  	Training Loss: 0.03756839409470558
Test Loss:  0.0350540429353714
Valid Loss:  0.03756779432296753
Epoch:  124  	Training Loss: 0.03755351901054382
Test Loss:  0.03504019230604172
Valid Loss:  0.03755310922861099
Epoch:  125  	Training Loss: 0.037538643926382065
Test Loss:  0.035026345402002335
Valid Loss:  0.03753843158483505
Epoch:  126  	Training Loss: 0.0375237762928009
Test Loss:  0.035012517124414444
Valid Loss:  0.03752376511693001
Epoch:  127  	Training Loss: 0.037508927285671234
Test Loss:  0.034998685121536255
Valid Loss:  0.03750909864902496
Epoch:  128  	Training Loss: 0.037494078278541565
Test Loss:  0.03498486056923866
Valid Loss:  0.03749444708228111
Epoch:  129  	Training Loss: 0.037479229271411896
Test Loss:  0.03497104346752167
Valid Loss:  0.037479788064956665
Epoch:  130  	Training Loss: 0.03746439889073372
Test Loss:  0.03495723754167557
Valid Loss:  0.03746515139937401
Epoch:  131  	Training Loss: 0.03744956851005554
Test Loss:  0.03494343161582947
Valid Loss:  0.03745051473379135
Epoch:  132  	Training Loss: 0.03743474930524826
Test Loss:  0.03492971137166023
Valid Loss:  0.03743596374988556
Epoch:  133  	Training Loss: 0.037420012056827545
Test Loss:  0.034915991127491
Valid Loss:  0.037421420216560364
Epoch:  134  	Training Loss: 0.037405289709568024
Test Loss:  0.03490227460861206
Valid Loss:  0.037406887859106064
Epoch:  135  	Training Loss: 0.0373905673623085
Test Loss:  0.03488857299089432
Valid Loss:  0.03739235922694206
Epoch:  136  	Training Loss: 0.03737585246562958
Test Loss:  0.034874871373176575
Valid Loss:  0.03737783432006836
Epoch:  137  	Training Loss: 0.03736114874482155
Test Loss:  0.03486117720603943
Valid Loss:  0.03736332058906555
Epoch:  138  	Training Loss: 0.03734644874930382
Test Loss:  0.03484749048948288
Valid Loss:  0.03734882175922394
Epoch:  139  	Training Loss: 0.037331756204366684
Test Loss:  0.034833814948797226
Valid Loss:  0.03733431547880173
Epoch:  140  	Training Loss: 0.037317074835300446
Test Loss:  0.03482014685869217
Valid Loss:  0.03731982409954071
Epoch:  141  	Training Loss: 0.037302397191524506
Test Loss:  0.03480648621916771
Valid Loss:  0.03730534389615059
Epoch:  142  	Training Loss: 0.03728773444890976
Test Loss:  0.0347929373383522
Valid Loss:  0.037290968000888824
Epoch:  143  	Training Loss: 0.03727317973971367
Test Loss:  0.034779392182826996
Valid Loss:  0.03727661073207855
Epoch:  144  	Training Loss: 0.03725863993167877
Test Loss:   29%|██▉       | 145/500 [01:43<03:39,  1.61it/s] 29%|██▉       | 147/500 [01:43<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:43<01:58,  2.97it/s] 30%|███       | 151/500 [01:50<07:00,  1.20s/it] 31%|███       | 153/500 [01:50<05:00,  1.16it/s] 31%|███       | 155/500 [01:50<03:35,  1.60it/s] 31%|███▏      | 157/500 [01:50<02:37,  2.18it/s] 32%|███▏      | 159/500 [01:50<01:56,  2.93it/s] 32%|███▏      | 161/500 [01:57<06:49,  1.21s/it] 33%|███▎      | 163/500 [01:57<04:51,  1.15it/s] 33%|███▎      | 165/500 [01:57<03:29,  1.60it/s] 33%|███▎      | 167/500 [01:57<02:32,  2.19it/s] 34%|███▍      | 169/500 [01:57<01:52,  2.94it/s] 34%|███▍      | 171/500 [02:04<06:38,  1.21s/it] 35%|███▍      | 173/500 [02:04<04:44,  1.15it/s] 35%|███▌      | 175/500 [02:04<03:24,  1.59it/s] 35%|███▌      | 177/500 [02:04<02:28,  2.18it/s] 36%|███▌      | 179/500 [02:04<01:49,  2.94it/s] 36%|███▌      | 181/500 [02:11<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:11<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:11<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:11<02:20,  2.24it/s] 38%|███▊      | 189/500 [02:11<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:17<06:00,  1.17s/it] 39%|███▊      | 193/500 [02:18<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:18<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:18<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:18<01:39,  3.03it/s] 40%|████      | 201/500 [02:24<05:53,  1.18s/it] 41%|████      | 203/500 [02:24<04:11,  1.18it/s] 41%|████      | 205/500 [02:25<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:25<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:25<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:31<05:34,  1.16s/it] 43%|████▎     | 213/500 [02:31<03:59,  1.20it/s]0.03476584702730179
Valid Loss:  0.03726225346326828
Epoch:  145  	Training Loss: 0.037244100123643875
Test Loss:  0.03475232049822807
Valid Loss:  0.037247903645038605
Epoch:  146  	Training Loss: 0.03722957521677017
Test Loss:  0.03473879024386406
Valid Loss:  0.037233561277389526
Epoch:  147  	Training Loss: 0.03721504285931587
Test Loss:  0.03472527116537094
Valid Loss:  0.037219222635030746
Epoch:  148  	Training Loss: 0.03720053285360336
Test Loss:  0.03471175581216812
Valid Loss:  0.03720489889383316
Epoch:  149  	Training Loss: 0.037186022847890854
Test Loss:  0.0346982479095459
Valid Loss:  0.037190571427345276
Epoch:  150  	Training Loss: 0.03717151656746864
Test Loss:  0.03468474745750427
Valid Loss:  0.03717625513672829
Epoch:  151  	Training Loss: 0.03715702146291733
Test Loss:  0.034671247005462646
Valid Loss:  0.037161942571401596
Epoch:  152  	Training Loss: 0.03714253008365631
Test Loss:  0.03465791046619415
Valid Loss:  0.03714780882000923
Epoch:  153  	Training Loss: 0.03712821006774902
Test Loss:  0.034644581377506256
Valid Loss:  0.03713367134332657
Epoch:  154  	Training Loss: 0.03711389750242233
Test Loss:  0.03463125601410866
Valid Loss:  0.0371195487678051
Epoch:  155  	Training Loss: 0.03709959611296654
Test Loss:  0.034617938101291656
Valid Loss:  0.03710542991757393
Epoch:  156  	Training Loss: 0.03708529472351074
Test Loss:  0.03460462763905525
Valid Loss:  0.037091322243213654
Epoch:  157  	Training Loss: 0.03707100450992584
Test Loss:  0.03459131717681885
Valid Loss:  0.03707721829414368
Epoch:  158  	Training Loss: 0.03705672547221184
Test Loss:  0.03457802161574364
Valid Loss:  0.0370631143450737
Epoch:  159  	Training Loss: 0.037042442709207535
Test Loss:  0.034564726054668427
Valid Loss:  0.03704902529716492
Epoch:  160  	Training Loss: 0.037028174847364426
Test Loss:  0.03455144166946411
Valid Loss:  0.037034936249256134
Epoch:  161  	Training Loss: 0.037013906985521317
Test Loss:  0.034538157284259796
Valid Loss:  0.037020858377218246
Epoch:  162  	Training Loss: 0.0369996540248394
Test Loss:  0.03452497720718384
Valid Loss:  0.037006888538599014
Epoch:  163  	Training Loss: 0.03698550537228584
Test Loss:  0.03451180458068848
Valid Loss:  0.03699292987585068
Epoch:  164  	Training Loss: 0.03697136417031288
Test Loss:  0.034498635679483414
Valid Loss:  0.03697896748781204
Epoch:  165  	Training Loss: 0.03695723041892052
Test Loss:  0.03448547422885895
Valid Loss:  0.0369650237262249
Epoch:  166  	Training Loss: 0.03694310411810875
Test Loss:  0.03447231650352478
Valid Loss:  0.03695107623934746
Epoch:  167  	Training Loss: 0.03692898154258728
Test Loss:  0.03445916622877121
Valid Loss:  0.03693713620305061
Epoch:  168  	Training Loss: 0.03691486641764641
Test Loss:  0.034446023404598236
Valid Loss:  0.03692319989204407
Epoch:  169  	Training Loss: 0.03690075874328613
Test Loss:  0.03443288430571556
Valid Loss:  0.036909278482198715
Epoch:  170  	Training Loss: 0.036886654794216156
Test Loss:  0.03441975265741348
Valid Loss:  0.03689536079764366
Epoch:  171  	Training Loss: 0.036872558295726776
Test Loss:  0.0344066247344017
Valid Loss:  0.036881446838378906
Epoch:  172  	Training Loss: 0.03685847297310829
Test Loss:  0.03439367190003395
Valid Loss:  0.03686772286891937
Epoch:  173  	Training Loss: 0.03684457018971443
Test Loss:  0.034380730241537094
Valid Loss:  0.036854006350040436
Epoch:  174  	Training Loss: 0.03683067858219147
Test Loss:  0.03436778858304024
Valid Loss:  0.0368402898311615
Epoch:  175  	Training Loss: 0.036816783249378204
Test Loss:  0.03435485064983368
Valid Loss:  0.03682657331228256
Epoch:  176  	Training Loss: 0.036802902817726135
Test Loss:  0.034341923892498016
Valid Loss:  0.03681287541985512
Epoch:  177  	Training Loss: 0.03678902983665466
Test Loss:  0.034328997135162354
Valid Loss:  0.03679917752742767
Epoch:  178  	Training Loss: 0.03677515685558319
Test Loss:  0.034316081553697586
Valid Loss:  0.036785490810871124
Epoch:  179  	Training Loss: 0.036761291325092316
Test Loss:  0.03430316969752312
Valid Loss:  0.036771804094314575
Epoch:  180  	Training Loss: 0.03674743324518204
Test Loss:  0.03429026901721954
Valid Loss:  0.03675813227891922
Epoch:  181  	Training Loss: 0.036733586341142654
Test Loss:  0.03427736461162567
Valid Loss:  0.036744460463523865
Epoch:  182  	Training Loss: 0.03671973943710327
Test Loss:  0.03426463156938553
Valid Loss:  0.03673096001148224
Epoch:  183  	Training Loss: 0.036706071346998215
Test Loss:  0.03425190597772598
Valid Loss:  0.03671747073531151
Epoch:  184  	Training Loss: 0.036692410707473755
Test Loss:  0.03423918038606644
Valid Loss:  0.036703988909721375
Epoch:  185  	Training Loss: 0.036678753793239594
Test Loss:  0.03422646224498749
Valid Loss:  0.03669050335884094
Epoch:  186  	Training Loss: 0.03666510432958603
Test Loss:  0.03421374782919884
Valid Loss:  0.036677032709121704
Epoch:  187  	Training Loss: 0.036651454865932465
Test Loss:  0.034201040863990784
Valid Loss:  0.03666356950998306
Epoch:  188  	Training Loss: 0.036637820303440094
Test Loss:  0.03418833762407303
Valid Loss:  0.03665010258555412
Epoch:  189  	Training Loss: 0.03662418574094772
Test Loss:  0.03417564183473587
Valid Loss:  0.03663665056228638
Epoch:  190  	Training Loss: 0.03661055862903595
Test Loss:  0.03416294977068901
Valid Loss:  0.03662320226430893
Epoch:  191  	Training Loss: 0.036596935242414474
Test Loss:  0.03415026515722275
Valid Loss:  0.03660976141691208
Epoch:  192  	Training Loss: 0.036583323031663895
Test Loss:  0.03413774073123932
Valid Loss:  0.03659648820757866
Epoch:  193  	Training Loss: 0.03656988590955734
Test Loss:  0.034125231206417084
Valid Loss:  0.036583222448825836
Epoch:  194  	Training Loss: 0.03655645251274109
Test Loss:  0.03411271423101425
Valid Loss:  0.03656996786594391
Epoch:  195  	Training Loss: 0.03654302656650543
Test Loss:  0.03410021588206291
Valid Loss:  0.03655672073364258
Epoch:  196  	Training Loss: 0.03652960807085037
Test Loss:  0.034087710082530975
Valid Loss:  0.03654346987605095
Epoch:  197  	Training Loss: 0.03651618957519531
Test Loss:  0.034075215458869934
Valid Loss:  0.036530230194330215
Epoch:  198  	Training Loss: 0.03650277853012085
Test Loss:  0.03406272828578949
Valid Loss:  0.03651700168848038
Epoch:  199  	Training Loss: 0.03648938238620758
Test Loss:  0.03405024856328964
Valid Loss:  0.03650376945734024
Epoch:  200  	Training Loss: 0.03647598251700401
Test Loss:  0.034037765115499496
Valid Loss:  0.0364905521273613
Epoch:  201  	Training Loss: 0.03646259009838104
Test Loss:  0.034025292843580246
Valid Loss:  0.03647732734680176
Epoch:  202  	Training Loss: 0.03644920885562897
Test Loss:  0.03401299566030502
Valid Loss:  0.036464303731918335
Epoch:  203  	Training Loss: 0.036436013877391815
Test Loss:  0.034000709652900696
Valid Loss:  0.03645128756761551
Epoch:  204  	Training Loss: 0.03642282634973526
Test Loss:  0.03398842364549637
Valid Loss:  0.036438267678022385
Epoch:  205  	Training Loss: 0.0364096462726593
Test Loss:  0.033976152539253235
Valid Loss:  0.036425262689590454
Epoch:  206  	Training Loss: 0.03639646992087364
Test Loss:  0.0339638777077198
Valid Loss:  0.03641226142644882
Epoch:  207  	Training Loss: 0.03638330474495888
Test Loss:  0.03395161032676697
Valid Loss:  0.03639926016330719
Epoch:  208  	Training Loss: 0.036370135843753815
Test Loss:  0.03393934667110443
Valid Loss:  0.036386266350746155
Epoch:  209  	Training Loss: 0.03635697811841965
Test Loss:  0.03392709046602249
Valid Loss:  0.036373287439346313
Epoch:  210  	Training Loss: 0.03634382784366608
Test Loss:  0.03391484171152115
Valid Loss:  0.036360301077365875
Epoch:  211  	Training Loss: 0.0363306850194931
Test Loss:  0.033902592957019806
Valid Loss:  0.036347322165966034
Epoch:  212  	Training Loss: 0.03631754219532013
Test Loss:  0.033890508115291595
Valid Loss:  0.03633452206850052
Epoch:  213  	Training Loss: 0.036304574459791183
Test Loss:  0.033878426998853683
Valid Loss:  0.036321721971035004
Epoch:  214  	Training Loss: 0.03629160672426224
Test Loss:  0.03386634588241577
Valid Loss:  0.03630892187356949
Epoch:  215  	Training Loss: 0.03627864271402359
Test Loss:  0.03385427966713905
Valid Loss:   43%|████▎     | 215/500 [02:31<02:51,  1.66it/s] 43%|████▎     | 217/500 [02:31<02:04,  2.27it/s] 44%|████▍     | 219/500 [02:31<01:32,  3.04it/s] 44%|████▍     | 221/500 [02:38<05:25,  1.17s/it] 45%|████▍     | 223/500 [02:38<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:38<02:47,  1.65it/s] 45%|████▌     | 227/500 [02:38<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:38<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:45<05:13,  1.17s/it] 47%|████▋     | 233/500 [02:45<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:45<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:45<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:45<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:51<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:51<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:52<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:52<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:52<01:23,  3.01it/s] 50%|█████     | 251/500 [02:58<04:50,  1.17s/it] 51%|█████     | 253/500 [02:58<03:27,  1.19it/s] 51%|█████     | 255/500 [02:58<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:59<01:48,  2.25it/s] 52%|█████▏    | 259/500 [02:59<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:05<04:42,  1.18s/it] 53%|█████▎    | 263/500 [03:05<03:21,  1.18it/s] 53%|█████▎    | 265/500 [03:05<02:24,  1.63it/s] 53%|█████▎    | 267/500 [03:05<01:44,  2.23it/s] 54%|█████▍    | 269/500 [03:06<01:17,  2.98it/s] 54%|█████▍    | 271/500 [03:12<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:12<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:12<02:16,  1.64it/s] 55%|█████▌    | 277/500 [03:12<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:12<01:13,  3.01it/s] 56%|█████▌    | 281/500 [03:19<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:19<03:04,  1.18it/s] 57%|█████▋    | 285/500 [03:19<02:12,  1.63it/s]0.03629613667726517
Epoch:  216  	Training Loss: 0.036265693604946136
Test Loss:  0.03384220600128174
Valid Loss:  0.03628334775567055
Epoch:  217  	Training Loss: 0.03625274449586868
Test Loss:  0.03383014723658562
Valid Loss:  0.03627057000994682
Epoch:  218  	Training Loss: 0.03623979911208153
Test Loss:  0.033818092197179794
Valid Loss:  0.036257799714803696
Epoch:  219  	Training Loss: 0.03622686490416527
Test Loss:  0.03380603715777397
Valid Loss:  0.03624502569437027
Epoch:  220  	Training Loss: 0.03621393069624901
Test Loss:  0.03379398584365845
Valid Loss:  0.03623226284980774
Epoch:  221  	Training Loss: 0.036201003938913345
Test Loss:  0.03378194570541382
Valid Loss:  0.03621950373053551
Epoch:  222  	Training Loss: 0.03618808090686798
Test Loss:  0.03377009183168411
Valid Loss:  0.03620694577693939
Epoch:  223  	Training Loss: 0.03617536649107933
Test Loss:  0.0337582491338253
Valid Loss:  0.036194395273923874
Epoch:  224  	Training Loss: 0.03616265580058098
Test Loss:  0.03374641016125679
Valid Loss:  0.03618185222148895
Epoch:  225  	Training Loss: 0.03614995256066322
Test Loss:  0.03373457491397858
Valid Loss:  0.03616931661963463
Epoch:  226  	Training Loss: 0.03613725304603577
Test Loss:  0.03372275084257126
Valid Loss:  0.0361567884683609
Epoch:  227  	Training Loss: 0.03612455725669861
Test Loss:  0.033710919320583344
Valid Loss:  0.036144256591796875
Epoch:  228  	Training Loss: 0.036111872643232346
Test Loss:  0.03369910269975662
Valid Loss:  0.036131732165813446
Epoch:  229  	Training Loss: 0.03609919175505638
Test Loss:  0.0336872898042202
Valid Loss:  0.03611921891570091
Epoch:  230  	Training Loss: 0.036086514592170715
Test Loss:  0.03367547690868378
Valid Loss:  0.03610670566558838
Epoch:  231  	Training Loss: 0.03607384115457535
Test Loss:  0.03366367518901825
Valid Loss:  0.036094196140766144
Epoch:  232  	Training Loss: 0.03606117516756058
Test Loss:  0.03365204110741615
Valid Loss:  0.03608187288045883
Epoch:  233  	Training Loss: 0.03604868799448013
Test Loss:  0.033640407025814056
Valid Loss:  0.03606954962015152
Epoch:  234  	Training Loss: 0.036036208271980286
Test Loss:  0.033628784120082855
Valid Loss:  0.03605722635984421
Epoch:  235  	Training Loss: 0.036023736000061035
Test Loss:  0.033617161214351654
Valid Loss:  0.03604491800069809
Epoch:  236  	Training Loss: 0.036011263728141785
Test Loss:  0.03360554203391075
Valid Loss:  0.03603260964155197
Epoch:  237  	Training Loss: 0.03599879890680313
Test Loss:  0.033593934029340744
Valid Loss:  0.03602030873298645
Epoch:  238  	Training Loss: 0.035986341536045074
Test Loss:  0.03358232602477074
Valid Loss:  0.03600800782442093
Epoch:  239  	Training Loss: 0.03597388416528702
Test Loss:  0.03357072174549103
Valid Loss:  0.035995714366436005
Epoch:  240  	Training Loss: 0.03596143424510956
Test Loss:  0.033559124916791916
Valid Loss:  0.035983435809612274
Epoch:  241  	Training Loss: 0.035948991775512695
Test Loss:  0.0335475318133831
Valid Loss:  0.03597114980220795
Epoch:  242  	Training Loss: 0.03593655675649643
Test Loss:  0.03353608027100563
Valid Loss:  0.035959020256996155
Epoch:  243  	Training Loss: 0.035924267023801804
Test Loss:  0.033524636179208755
Valid Loss:  0.03594689071178436
Epoch:  244  	Training Loss: 0.035911984741687775
Test Loss:  0.03351318836212158
Valid Loss:  0.03593476116657257
Epoch:  245  	Training Loss: 0.035899702459573746
Test Loss:  0.033501751720905304
Valid Loss:  0.03592264652252197
Epoch:  246  	Training Loss: 0.035887427628040314
Test Loss:  0.033490315079689026
Valid Loss:  0.03591053560376167
Epoch:  247  	Training Loss: 0.03587516397237778
Test Loss:  0.03347888961434364
Valid Loss:  0.03589843213558197
Epoch:  248  	Training Loss: 0.03586290404200554
Test Loss:  0.03346746787428856
Valid Loss:  0.03588632494211197
Epoch:  249  	Training Loss: 0.0358506478369236
Test Loss:  0.033456042408943176
Valid Loss:  0.03587422892451286
Epoch:  250  	Training Loss: 0.03583839535713196
Test Loss:  0.033444635570049286
Valid Loss:  0.035862136632204056
Epoch:  251  	Training Loss: 0.03582615405321121
Test Loss:  0.0334332212805748
Valid Loss:  0.035850051790475845
Epoch:  252  	Training Loss: 0.03581390529870987
Test Loss:  0.03342196345329285
Valid Loss:  0.03583812713623047
Epoch:  253  	Training Loss: 0.035801827907562256
Test Loss:  0.03341071307659149
Valid Loss:  0.03582620620727539
Epoch:  254  	Training Loss: 0.03578975051641464
Test Loss:  0.03339945897459984
Valid Loss:  0.03581428900361061
Epoch:  255  	Training Loss: 0.03577768802642822
Test Loss:  0.03338821232318878
Valid Loss:  0.03580237925052643
Epoch:  256  	Training Loss: 0.035765618085861206
Test Loss:  0.033376969397068024
Valid Loss:  0.035790473222732544
Epoch:  257  	Training Loss: 0.035753559321165085
Test Loss:  0.03336573392152786
Valid Loss:  0.03577857464551926
Epoch:  258  	Training Loss: 0.03574150800704956
Test Loss:  0.0333544984459877
Valid Loss:  0.03576667606830597
Epoch:  259  	Training Loss: 0.035729456692934036
Test Loss:  0.033343274146318436
Valid Loss:  0.03575478494167328
Epoch:  260  	Training Loss: 0.03571741282939911
Test Loss:  0.03333204984664917
Valid Loss:  0.035742904990911484
Epoch:  261  	Training Loss: 0.03570537269115448
Test Loss:  0.033320825546979904
Valid Loss:  0.03573102504014969
Epoch:  262  	Training Loss: 0.03569334000349045
Test Loss:  0.03330975025892258
Valid Loss:  0.03571927919983864
Epoch:  263  	Training Loss: 0.03568144887685776
Test Loss:  0.03329867124557495
Valid Loss:  0.03570754826068878
Epoch:  264  	Training Loss: 0.035669565200805664
Test Loss:  0.03328759968280792
Valid Loss:  0.035695821046829224
Epoch:  265  	Training Loss: 0.03565768897533417
Test Loss:  0.03327653557062149
Valid Loss:  0.035684097558259964
Epoch:  266  	Training Loss: 0.03564581274986267
Test Loss:  0.03326546400785446
Valid Loss:  0.0356723815202713
Epoch:  267  	Training Loss: 0.03563394397497177
Test Loss:  0.033254411071538925
Valid Loss:  0.03566066920757294
Epoch:  268  	Training Loss: 0.03562208265066147
Test Loss:  0.03324335440993309
Valid Loss:  0.03564895689487457
Epoch:  269  	Training Loss: 0.035610221326351166
Test Loss:  0.03323230892419815
Valid Loss:  0.035637252032756805
Epoch:  270  	Training Loss: 0.03559836745262146
Test Loss:  0.03322125971317291
Valid Loss:  0.03562555089592934
Epoch:  271  	Training Loss: 0.035586513578891754
Test Loss:  0.03321021795272827
Valid Loss:  0.03561384975910187
Epoch:  272  	Training Loss: 0.035574670881032944
Test Loss:  0.03319927304983139
Valid Loss:  0.03560226410627365
Epoch:  273  	Training Loss: 0.03556292504072189
Test Loss:  0.03318832814693451
Valid Loss:  0.03559066727757454
Epoch:  274  	Training Loss: 0.03555118665099144
Test Loss:  0.03317738696932793
Valid Loss:  0.03557908162474632
Epoch:  275  	Training Loss: 0.035539451986551285
Test Loss:  0.03316645324230194
Valid Loss:  0.035567499697208405
Epoch:  276  	Training Loss: 0.03552772104740143
Test Loss:  0.033155523240566254
Valid Loss:  0.03555592894554138
Epoch:  277  	Training Loss: 0.03551599755883217
Test Loss:  0.033144593238830566
Valid Loss:  0.03554435446858406
Epoch:  278  	Training Loss: 0.03550427407026291
Test Loss:  0.033133670687675476
Valid Loss:  0.03553278371691704
Epoch:  279  	Training Loss: 0.035492558032274246
Test Loss:  0.03312275931239128
Valid Loss:  0.03552122414112091
Epoch:  280  	Training Loss: 0.03548084944486618
Test Loss:  0.03311184048652649
Valid Loss:  0.035509660840034485
Epoch:  281  	Training Loss: 0.035469137132167816
Test Loss:  0.03310093283653259
Valid Loss:  0.035498104989528656
Epoch:  282  	Training Loss: 0.03545743599534035
Test Loss:  0.03309018164873123
Valid Loss:  0.03548671677708626
Epoch:  283  	Training Loss: 0.03544589877128601
Test Loss:  0.03307943418622017
Valid Loss:  0.03547533228993416
Epoch:  284  	Training Loss: 0.03543437272310257
Test Loss:  0.033068686723709106
Valid Loss:  0.03546394780278206
Epoch:  285  	Training Loss: 0.03542284667491913
Test Loss:  0.03305794671177864
Valid Loss:  0.035452574491500854
Epoch:  286  	Training Loss: 0.03541132062673569
Test Loss:  0.033047210425138474
Valid Loss:  0.03544120490550995
 57%|█████▋    | 287/500 [03:19<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:19<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:25<04:03,  1.17s/it] 59%|█████▊    | 293/500 [03:26<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:26<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:26<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:26<01:06,  3.02it/s] 60%|██████    | 301/500 [03:32<03:52,  1.17s/it] 61%|██████    | 303/500 [03:32<02:45,  1.19it/s] 61%|██████    | 305/500 [03:32<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:33<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:33<01:03,  3.03it/s] 62%|██████▏   | 311/500 [03:39<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:39<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:39<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:40<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:40<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:46<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:46<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:46<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:46<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:46<00:57,  2.99it/s] 66%|██████▌   | 331/500 [03:53<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:53<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:53<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:53<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:53<00:53,  3.01it/s] 68%|██████▊   | 341/500 [03:59<03:05,  1.17s/it] 69%|██████▊   | 343/500 [04:00<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:00<01:34,  1.65it/s] 69%|██████▉   | 347/500 [04:00<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:00<00:50,  3.00it/s] 70%|███████   | 351/500 [04:06<02:55,  1.18s/it] 71%|███████   | 353/500 [04:07<02:04,  1.18it/s] 71%|███████   | 355/500 [04:07<01:29,  1.63it/s] 71%|███████▏  | 357/500 [04:07<01:04,  2.22it/s]Epoch:  287  	Training Loss: 0.03539980202913284
Test Loss:  0.0330364815890789
Valid Loss:  0.03542983531951904
Epoch:  288  	Training Loss: 0.035388290882110596
Test Loss:  0.03302575647830963
Valid Loss:  0.035418473184108734
Epoch:  289  	Training Loss: 0.035376787185668945
Test Loss:  0.03301502764225006
Valid Loss:  0.035407111048698425
Epoch:  290  	Training Loss: 0.035365283489227295
Test Loss:  0.033004313707351685
Valid Loss:  0.03539576381444931
Epoch:  291  	Training Loss: 0.035353779792785645
Test Loss:  0.03299359977245331
Valid Loss:  0.0353844091296196
Epoch:  292  	Training Loss: 0.03534229099750519
Test Loss:  0.03298300877213478
Valid Loss:  0.035373199731111526
Epoch:  293  	Training Loss: 0.03533093258738518
Test Loss:  0.03297243267297745
Valid Loss:  0.03536199405789375
Epoch:  294  	Training Loss: 0.035319581627845764
Test Loss:  0.032961852848529816
Valid Loss:  0.03535078465938568
Epoch:  295  	Training Loss: 0.035308241844177246
Test Loss:  0.03295128047466278
Valid Loss:  0.0353395938873291
Epoch:  296  	Training Loss: 0.03529689833521843
Test Loss:  0.032940708100795746
Valid Loss:  0.035328395664691925
Epoch:  297  	Training Loss: 0.03528555482625961
Test Loss:  0.032930146902799606
Valid Loss:  0.03531721234321594
Epoch:  298  	Training Loss: 0.03527422994375229
Test Loss:  0.03291958570480347
Valid Loss:  0.03530602902173996
Epoch:  299  	Training Loss: 0.035262901335954666
Test Loss:  0.032909028232097626
Valid Loss:  0.035294849425554276
Epoch:  300  	Training Loss: 0.03525157645344734
Test Loss:  0.032898470759391785
Valid Loss:  0.03528367355465889
Epoch:  301  	Training Loss: 0.03524026274681091
Test Loss:  0.03288792446255684
Valid Loss:  0.0352725014090538
Epoch:  302  	Training Loss: 0.035228945314884186
Test Loss:  0.03287750110030174
Valid Loss:  0.03526145964860916
Epoch:  303  	Training Loss: 0.0352177619934082
Test Loss:  0.032867081463336945
Valid Loss:  0.035250429064035416
Epoch:  304  	Training Loss: 0.03520658612251282
Test Loss:  0.032856665551662445
Valid Loss:  0.03523939475417137
Epoch:  305  	Training Loss: 0.03519541397690773
Test Loss:  0.032846249639987946
Valid Loss:  0.03522837162017822
Epoch:  306  	Training Loss: 0.03518424183130264
Test Loss:  0.03283584490418434
Valid Loss:  0.035217348486185074
Epoch:  307  	Training Loss: 0.03517308086156845
Test Loss:  0.03282544016838074
Valid Loss:  0.03520633280277252
Epoch:  308  	Training Loss: 0.035161927342414856
Test Loss:  0.03281503915786743
Valid Loss:  0.03519532084465027
Epoch:  309  	Training Loss: 0.03515077009797096
Test Loss:  0.03280464559793472
Valid Loss:  0.035184308886528015
Epoch:  310  	Training Loss: 0.035139620304107666
Test Loss:  0.03279424458742142
Valid Loss:  0.03517330437898636
Epoch:  311  	Training Loss: 0.03512847051024437
Test Loss:  0.032783858478069305
Valid Loss:  0.035162303596735
Epoch:  312  	Training Loss: 0.03511732816696167
Test Loss:  0.03277362138032913
Valid Loss:  0.03515145927667618
Epoch:  313  	Training Loss: 0.0351063497364521
Test Loss:  0.03276338800787926
Valid Loss:  0.03514062613248825
Epoch:  314  	Training Loss: 0.035095371305942535
Test Loss:  0.03275316208600998
Valid Loss:  0.03512978553771973
Epoch:  315  	Training Loss: 0.03508439660072327
Test Loss:  0.0327429324388504
Valid Loss:  0.035118959844112396
Epoch:  316  	Training Loss: 0.035073429346084595
Test Loss:  0.03273271024227142
Valid Loss:  0.03510813042521477
Epoch:  317  	Training Loss: 0.03506246209144592
Test Loss:  0.032722488045692444
Valid Loss:  0.035097308456897736
Epoch:  318  	Training Loss: 0.035051506012678146
Test Loss:  0.03271227329969406
Valid Loss:  0.035086486488580704
Epoch:  319  	Training Loss: 0.03504054620862007
Test Loss:  0.032702066004276276
Valid Loss:  0.03507567197084427
Epoch:  320  	Training Loss: 0.035029590129852295
Test Loss:  0.03269185125827789
Valid Loss:  0.035064857453107834
Epoch:  321  	Training Loss: 0.03501863777637482
Test Loss:  0.032681655138731
Valid Loss:  0.03505405783653259
Epoch:  322  	Training Loss: 0.035007696598768234
Test Loss:  0.03267154097557068
Valid Loss:  0.035043343901634216
Epoch:  323  	Training Loss: 0.03499684855341911
Test Loss:  0.03266143426299095
Valid Loss:  0.035032644867897034
Epoch:  324  	Training Loss: 0.03498601168394089
Test Loss:  0.03265132009983063
Valid Loss:  0.03502194955945015
Epoch:  325  	Training Loss: 0.03497517108917236
Test Loss:  0.0326412208378315
Valid Loss:  0.03501124680042267
Epoch:  326  	Training Loss: 0.034964337944984436
Test Loss:  0.03263112157583237
Valid Loss:  0.03500055521726608
Epoch:  327  	Training Loss: 0.03495350480079651
Test Loss:  0.032621026039123535
Valid Loss:  0.034989871084690094
Epoch:  328  	Training Loss: 0.03494268283247948
Test Loss:  0.0326109379529953
Valid Loss:  0.03497918322682381
Epoch:  329  	Training Loss: 0.034931860864162445
Test Loss:  0.032600849866867065
Valid Loss:  0.034968502819538116
Epoch:  330  	Training Loss: 0.03492104262113571
Test Loss:  0.03259076550602913
Valid Loss:  0.03495783358812332
Epoch:  331  	Training Loss: 0.03491022810339928
Test Loss:  0.03258068487048149
Valid Loss:  0.03494716063141823
Epoch:  332  	Training Loss: 0.03489942103624344
Test Loss:  0.03257071599364281
Valid Loss:  0.034936606884002686
Epoch:  333  	Training Loss: 0.03488872945308685
Test Loss:  0.03256075084209442
Valid Loss:  0.03492605313658714
Epoch:  334  	Training Loss: 0.03487803786993027
Test Loss:  0.032550785690546036
Valid Loss:  0.0349155068397522
Epoch:  335  	Training Loss: 0.034867361187934875
Test Loss:  0.03254082426428795
Valid Loss:  0.03490496426820755
Epoch:  336  	Training Loss: 0.03485667705535889
Test Loss:  0.03253086656332016
Valid Loss:  0.0348944291472435
Epoch:  337  	Training Loss: 0.034846000373363495
Test Loss:  0.03252091258764267
Valid Loss:  0.03488388657569885
Epoch:  338  	Training Loss: 0.0348353274166584
Test Loss:  0.032510966062545776
Valid Loss:  0.0348733589053154
Epoch:  339  	Training Loss: 0.034824661910533905
Test Loss:  0.03250102326273918
Valid Loss:  0.03486282750964165
Epoch:  340  	Training Loss: 0.03481400012969971
Test Loss:  0.03249108046293259
Valid Loss:  0.03485231101512909
Epoch:  341  	Training Loss: 0.03480334207415581
Test Loss:  0.03248114138841629
Valid Loss:  0.03484179079532623
Epoch:  342  	Training Loss: 0.03479268401861191
Test Loss:  0.032471299171447754
Valid Loss:  0.034831367433071136
Epoch:  343  	Training Loss: 0.03478212654590607
Test Loss:  0.03246145695447922
Valid Loss:  0.03482095152139664
Epoch:  344  	Training Loss: 0.03477157652378082
Test Loss:  0.03245161846280098
Valid Loss:  0.03481053560972214
Epoch:  345  	Training Loss: 0.03476102650165558
Test Loss:  0.03244178742170334
Valid Loss:  0.034800123423337936
Epoch:  346  	Training Loss: 0.03475048020482063
Test Loss:  0.0324319526553154
Valid Loss:  0.034789711236953735
Epoch:  347  	Training Loss: 0.03473993390798569
Test Loss:  0.03242212533950806
Valid Loss:  0.03477931022644043
Epoch:  348  	Training Loss: 0.03472939878702164
Test Loss:  0.03241230547428131
Valid Loss:  0.034768909215927124
Epoch:  349  	Training Loss: 0.03471886366605759
Test Loss:  0.03240247815847397
Valid Loss:  0.03475851193070412
Epoch:  350  	Training Loss: 0.03470833599567413
Test Loss:  0.03239266574382782
Valid Loss:  0.03474812209606171
Epoch:  351  	Training Loss: 0.03469780832529068
Test Loss:  0.03238284960389137
Valid Loss:  0.034737732261419296
Epoch:  352  	Training Loss: 0.034687284380197525
Test Loss:  0.032373152673244476
Valid Loss:  0.03472746163606644
Epoch:  353  	Training Loss: 0.03467688709497452
Test Loss:  0.03236345201730728
Valid Loss:  0.034717198461294174
Epoch:  354  	Training Loss: 0.03466648608446121
Test Loss:  0.032353758811950684
Valid Loss:  0.03470693528652191
Epoch:  355  	Training Loss: 0.034656088799238205
Test Loss:  0.032344065606594086
Valid Loss:  0.03469667583703995
Epoch:  356  	Training Loss: 0.034645698964595795
Test Loss:  0.032334379851818085
Valid Loss:  0.03468642383813858
Epoch:  357  	Training Loss: 0.03463531285524368
Test Loss:  0.032324694097042084
Valid Loss:  0.03467617183923721
Epoch:  358  	Training Loss: 0.03462492674589157 72%|███████▏  | 359/500 [04:07<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:13<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:13<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:13<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:14<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:14<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:20<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:20<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:20<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:20<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:20<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:27<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:27<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:27<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:27<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:27<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:34<02:08,  1.17s/it] 79%|███████▊  | 393/500 [04:34<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:34<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:34<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:34<00:33,  3.01it/s] 80%|████████  | 401/500 [04:40<01:57,  1.18s/it] 81%|████████  | 403/500 [04:41<01:22,  1.18it/s] 81%|████████  | 405/500 [04:41<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:41<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:41<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:47<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:47<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:48<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:48<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:48<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:54<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:54<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:54<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:55<00:32,  2.23it/s]
Test Loss:  0.03231501206755638
Valid Loss:  0.034665923565626144
Epoch:  359  	Training Loss: 0.034614548087120056
Test Loss:  0.032305337488651276
Valid Loss:  0.034655679017305374
Epoch:  360  	Training Loss: 0.03460416942834854
Test Loss:  0.03229565918445587
Valid Loss:  0.0346454381942749
Epoch:  361  	Training Loss: 0.03459379822015762
Test Loss:  0.03228599578142166
Valid Loss:  0.03463520482182503
Epoch:  362  	Training Loss: 0.034583430737257004
Test Loss:  0.03227639198303223
Valid Loss:  0.03462504595518112
Epoch:  363  	Training Loss: 0.034573137760162354
Test Loss:  0.032266803085803986
Valid Loss:  0.034614890813827515
Epoch:  364  	Training Loss: 0.0345628522336483
Test Loss:  0.032257214188575745
Valid Loss:  0.034604743123054504
Epoch:  365  	Training Loss: 0.034552574157714844
Test Loss:  0.0322476290166378
Valid Loss:  0.034594595432281494
Epoch:  366  	Training Loss: 0.03454229235649109
Test Loss:  0.03223804384469986
Valid Loss:  0.03458445519208908
Epoch:  367  	Training Loss: 0.03453201800584793
Test Loss:  0.03222846984863281
Valid Loss:  0.03457431495189667
Epoch:  368  	Training Loss: 0.03452175110578537
Test Loss:  0.03221889212727547
Valid Loss:  0.03456418216228485
Epoch:  369  	Training Loss: 0.03451148420572281
Test Loss:  0.03220932185649872
Valid Loss:  0.034554049372673035
Epoch:  370  	Training Loss: 0.034501224756240845
Test Loss:  0.03219975531101227
Valid Loss:  0.03454391658306122
Epoch:  371  	Training Loss: 0.03449096158146858
Test Loss:  0.03219018876552582
Valid Loss:  0.03453379124403
Epoch:  372  	Training Loss: 0.034480709582567215
Test Loss:  0.03218073025345802
Valid Loss:  0.03452378138899803
Epoch:  373  	Training Loss: 0.0344705730676651
Test Loss:  0.032171279191970825
Valid Loss:  0.03451377898454666
Epoch:  374  	Training Loss: 0.03446043282747269
Test Loss:  0.03216182813048363
Valid Loss:  0.03450377285480499
Epoch:  375  	Training Loss: 0.03445030003786087
Test Loss:  0.03215238079428673
Valid Loss:  0.03449377417564392
Epoch:  376  	Training Loss: 0.03444017469882965
Test Loss:  0.03214293718338013
Valid Loss:  0.034483782947063446
Epoch:  377  	Training Loss: 0.03443004935979843
Test Loss:  0.032133497297763824
Valid Loss:  0.03447379171848297
Epoch:  378  	Training Loss: 0.03441993147134781
Test Loss:  0.03212406486272812
Valid Loss:  0.034463800489902496
Epoch:  379  	Training Loss: 0.03440980985760689
Test Loss:  0.03211463242769241
Valid Loss:  0.03445381671190262
Epoch:  380  	Training Loss: 0.034399695694446564
Test Loss:  0.03210519999265671
Valid Loss:  0.03444383293390274
Epoch:  381  	Training Loss: 0.03438958898186684
Test Loss:  0.0320957750082016
Valid Loss:  0.03443385660648346
Epoch:  382  	Training Loss: 0.03437948226928711
Test Loss:  0.03208643198013306
Valid Loss:  0.03442396968603134
Epoch:  383  	Training Loss: 0.034369468688964844
Test Loss:  0.03207709267735481
Valid Loss:  0.03441409021615982
Epoch:  384  	Training Loss: 0.03435945510864258
Test Loss:  0.032067760825157166
Valid Loss:  0.0344042107462883
Epoch:  385  	Training Loss: 0.03434944897890091
Test Loss:  0.03205843269824982
Valid Loss:  0.034394338726997375
Epoch:  386  	Training Loss: 0.03433945029973984
Test Loss:  0.03204910457134247
Valid Loss:  0.03438446670770645
Epoch:  387  	Training Loss: 0.034329451620578766
Test Loss:  0.03203977644443512
Valid Loss:  0.034374598413705826
Epoch:  388  	Training Loss: 0.034319452941417694
Test Loss:  0.03203045576810837
Valid Loss:  0.0343647375702858
Epoch:  389  	Training Loss: 0.03430946171283722
Test Loss:  0.03202114254236221
Valid Loss:  0.03435487672686577
Epoch:  390  	Training Loss: 0.034299470484256744
Test Loss:  0.03201182186603546
Valid Loss:  0.03434501588344574
Epoch:  391  	Training Loss: 0.03428948298096657
Test Loss:  0.032002512365579605
Valid Loss:  0.03433515876531601
Epoch:  392  	Training Loss: 0.03427950292825699
Test Loss:  0.031993284821510315
Valid Loss:  0.03432539850473404
Epoch:  393  	Training Loss: 0.03426961600780487
Test Loss:  0.03198406472802162
Valid Loss:  0.034315645694732666
Epoch:  394  	Training Loss: 0.03425973281264305
Test Loss:  0.03197484835982323
Valid Loss:  0.034305889159440994
Epoch:  395  	Training Loss: 0.03424984961748123
Test Loss:  0.03196563571691513
Valid Loss:  0.03429613262414932
Epoch:  396  	Training Loss: 0.03423997387290001
Test Loss:  0.031956419348716736
Valid Loss:  0.034286387264728546
Epoch:  397  	Training Loss: 0.03423009812831879
Test Loss:  0.03194721043109894
Valid Loss:  0.03427664935588837
Epoch:  398  	Training Loss: 0.03422022610902786
Test Loss:  0.03193800151348114
Valid Loss:  0.03426690399646759
Epoch:  399  	Training Loss: 0.034210361540317535
Test Loss:  0.031928807497024536
Valid Loss:  0.03425717353820801
Epoch:  400  	Training Loss: 0.03420049697160721
Test Loss:  0.03191961348056793
Valid Loss:  0.034247443079948425
Epoch:  401  	Training Loss: 0.03419063985347748
Test Loss:  0.03191041201353073
Valid Loss:  0.034237708896398544
Epoch:  402  	Training Loss: 0.03418078273534775
Test Loss:  0.03190129995346069
Valid Loss:  0.034228064119815826
Epoch:  403  	Training Loss: 0.03417101129889488
Test Loss:  0.031892187893390656
Valid Loss:  0.03421842306852341
Epoch:  404  	Training Loss: 0.034161243587732315
Test Loss:  0.031883083283901215
Valid Loss:  0.03420878201723099
Epoch:  405  	Training Loss: 0.034151479601860046
Test Loss:  0.031873974949121475
Valid Loss:  0.03419914469122887
Epoch:  406  	Training Loss: 0.034141723066568375
Test Loss:  0.03186487779021263
Valid Loss:  0.03418951481580734
Epoch:  407  	Training Loss: 0.0341319665312767
Test Loss:  0.031855784356594086
Valid Loss:  0.03417988866567612
Epoch:  408  	Training Loss: 0.03412221372127533
Test Loss:  0.03184668347239494
Valid Loss:  0.03417026251554489
Epoch:  409  	Training Loss: 0.03411246836185455
Test Loss:  0.031837597489356995
Valid Loss:  0.03416064381599426
Epoch:  410  	Training Loss: 0.03410271927714348
Test Loss:  0.03182850778102875
Valid Loss:  0.034151025116443634
Epoch:  411  	Training Loss: 0.034092977643013
Test Loss:  0.0318194180727005
Valid Loss:  0.034141406416893005
Epoch:  412  	Training Loss: 0.03408323600888252
Test Loss:  0.031810395419597626
Valid Loss:  0.03413184732198715
Epoch:  413  	Training Loss: 0.03407355770468712
Test Loss:  0.03180136904120445
Valid Loss:  0.03412230312824249
Epoch:  414  	Training Loss: 0.03406388312578201
Test Loss:  0.03179234266281128
Valid Loss:  0.034112751483917236
Epoch:  415  	Training Loss: 0.034054212272167206
Test Loss:  0.031783327460289
Valid Loss:  0.03410320729017258
Epoch:  416  	Training Loss: 0.0340445414185524
Test Loss:  0.03177430480718613
Valid Loss:  0.034093670547008514
Epoch:  417  	Training Loss: 0.03403487429022789
Test Loss:  0.03176529332995415
Valid Loss:  0.03408413380384445
Epoch:  418  	Training Loss: 0.03402521461248398
Test Loss:  0.031756285578012466
Valid Loss:  0.03407459333539009
Epoch:  419  	Training Loss: 0.034015558660030365
Test Loss:  0.03174727410078049
Valid Loss:  0.034065067768096924
Epoch:  420  	Training Loss: 0.03400590270757675
Test Loss:  0.0317382737994194
Valid Loss:  0.03405553475022316
Epoch:  421  	Training Loss: 0.03399624675512314
Test Loss:  0.03172926977276802
Valid Loss:  0.03404600918292999
Epoch:  422  	Training Loss: 0.03398660197854042
Test Loss:  0.031720347702503204
Valid Loss:  0.03403656184673309
Epoch:  423  	Training Loss: 0.03397703543305397
Test Loss:  0.031711429357528687
Valid Loss:  0.03402712941169739
Epoch:  424  	Training Loss: 0.03396747261285782
Test Loss:  0.03170251101255417
Valid Loss:  0.034017689526081085
Epoch:  425  	Training Loss: 0.033957917243242264
Test Loss:  0.03169359639286995
Valid Loss:  0.03400826454162598
Epoch:  426  	Training Loss: 0.03394836187362671
Test Loss:  0.03168468177318573
Valid Loss:  0.03399883210659027
Epoch:  427  	Training Loss: 0.03393881022930145
Test Loss:  0.03167577460408211
Valid Loss:  0.033989403396844864
Epoch:  428  	Training Loss: 0.033929258584976196
Test Loss:  0.031666871160268784
Valid Loss:  0.033979982137680054
Epoch:  429  	Training Loss: 0.033919718116521835
Test Loss:  0.03165796771645546
Valid Loss:   86%|████████▌ | 429/500 [04:55<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:01<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:01<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:01<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:01<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:02<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:08<01:09,  1.19s/it] 89%|████████▊ | 443/500 [05:08<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:08<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:08<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:09<00:17,  2.97it/s] 90%|█████████ | 451/500 [05:15<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:15<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:15<00:27,  1.61it/s] 91%|█████████▏| 457/500 [05:15<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:15<00:13,  2.95it/s] 92%|█████████▏| 461/500 [05:22<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:22<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:22<00:14,  2.20it/s] 94%|█████████▍| 469/500 [05:22<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:29<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:29<00:22,  1.17it/s] 95%|█████████▌| 475/500 [05:29<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:29<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:36<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:36<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:36<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:36<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:36<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:42<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:43<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:43<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:43<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:43<00:00,  2.99it/s]100%|██████████| 500/500 [05:43<00:00,  1.46it/s]
0.03397056460380554
Epoch:  430  	Training Loss: 0.033910173922777176
Test Loss:  0.031649067997932434
Valid Loss:  0.03396114706993103
Epoch:  431  	Training Loss: 0.033900633454322815
Test Loss:  0.03164017200469971
Valid Loss:  0.03395172953605652
Epoch:  432  	Training Loss: 0.03389109671115875
Test Loss:  0.03163137286901474
Valid Loss:  0.03394242376089096
Epoch:  433  	Training Loss: 0.03388166427612305
Test Loss:  0.03162257373332977
Valid Loss:  0.033933114260435104
Epoch:  434  	Training Loss: 0.03387223929166794
Test Loss:  0.0316137820482254
Valid Loss:  0.033923812210559845
Epoch:  435  	Training Loss: 0.03386281430721283
Test Loss:  0.03160499036312103
Valid Loss:  0.03391450643539429
Epoch:  436  	Training Loss: 0.03385338932275772
Test Loss:  0.03159620240330696
Valid Loss:  0.033905208110809326
Epoch:  437  	Training Loss: 0.03384397178888321
Test Loss:  0.03158741816878319
Valid Loss:  0.03389591723680496
Epoch:  438  	Training Loss: 0.0338345542550087
Test Loss:  0.03157863765954971
Valid Loss:  0.03388661891222
Epoch:  439  	Training Loss: 0.03382514417171478
Test Loss:  0.03156986087560654
Valid Loss:  0.033877331763505936
Epoch:  440  	Training Loss: 0.03381573408842087
Test Loss:  0.03156108409166336
Valid Loss:  0.03386805206537247
Epoch:  441  	Training Loss: 0.03380632773041725
Test Loss:  0.03155231475830078
Valid Loss:  0.0338587686419487
Epoch:  442  	Training Loss: 0.03379692882299423
Test Loss:  0.03154359757900238
Valid Loss:  0.03384954854846001
Epoch:  443  	Training Loss: 0.03378758952021599
Test Loss:  0.031534887850284576
Valid Loss:  0.03384033590555191
Epoch:  444  	Training Loss: 0.033778250217437744
Test Loss:  0.03152618557214737
Valid Loss:  0.033831123262643814
Epoch:  445  	Training Loss: 0.033768922090530396
Test Loss:  0.031517479568719864
Valid Loss:  0.033821918070316315
Epoch:  446  	Training Loss: 0.03375959396362305
Test Loss:  0.03150877729058266
Valid Loss:  0.033812712877988815
Epoch:  447  	Training Loss: 0.033750269562006
Test Loss:  0.03150008246302605
Valid Loss:  0.033803507685661316
Epoch:  448  	Training Loss: 0.03374095261096954
Test Loss:  0.03149138763546944
Valid Loss:  0.03379430994391441
Epoch:  449  	Training Loss: 0.03373162820935249
Test Loss:  0.031482696533203125
Valid Loss:  0.03378511965274811
Epoch:  450  	Training Loss: 0.03372231870889664
Test Loss:  0.03147400543093681
Valid Loss:  0.033775925636291504
Epoch:  451  	Training Loss: 0.03371300548315048
Test Loss:  0.0314653217792511
Valid Loss:  0.0337667390704155
Epoch:  452  	Training Loss: 0.03370369225740433
Test Loss:  0.03145671635866165
Valid Loss:  0.03375763073563576
Epoch:  453  	Training Loss: 0.033694472163915634
Test Loss:  0.031448110938072205
Valid Loss:  0.03374853357672691
Epoch:  454  	Training Loss: 0.03368525207042694
Test Loss:  0.03143952041864395
Valid Loss:  0.03373943641781807
Epoch:  455  	Training Loss: 0.03367604315280914
Test Loss:  0.0314309224486351
Valid Loss:  0.03373034670948982
Epoch:  456  	Training Loss: 0.03366683050990105
Test Loss:  0.03142232820391655
Valid Loss:  0.033721257001161575
Epoch:  457  	Training Loss: 0.03365762159228325
Test Loss:  0.031413737684488297
Valid Loss:  0.03371216356754303
Epoch:  458  	Training Loss: 0.03364841267466545
Test Loss:  0.03140515089035034
Valid Loss:  0.03370307758450508
Epoch:  459  	Training Loss: 0.03363921120762825
Test Loss:  0.031396567821502686
Valid Loss:  0.03369399905204773
Epoch:  460  	Training Loss: 0.03363000974059105
Test Loss:  0.03138798475265503
Valid Loss:  0.033684924244880676
Epoch:  461  	Training Loss: 0.03362081199884415
Test Loss:  0.03137940540909767
Valid Loss:  0.033675841987133026
Epoch:  462  	Training Loss: 0.03361161798238754
Test Loss:  0.03137087821960449
Valid Loss:  0.03366682305932045
Epoch:  463  	Training Loss: 0.03360247611999512
Test Loss:  0.03136235103011131
Valid Loss:  0.033657804131507874
Epoch:  464  	Training Loss: 0.03359334170818329
Test Loss:  0.03135383129119873
Valid Loss:  0.0336487852036953
Epoch:  465  	Training Loss: 0.03358420729637146
Test Loss:  0.03134531155228615
Valid Loss:  0.03363977372646332
Epoch:  466  	Training Loss: 0.03357507660984993
Test Loss:  0.031336791813373566
Valid Loss:  0.03363076597452164
Epoch:  467  	Training Loss: 0.0335659496486187
Test Loss:  0.03132827579975128
Valid Loss:  0.03362175077199936
Epoch:  468  	Training Loss: 0.033556826412677765
Test Loss:  0.03131977096199989
Valid Loss:  0.03361275792121887
Epoch:  469  	Training Loss: 0.03354770690202713
Test Loss:  0.031311262398958206
Valid Loss:  0.03360375389456749
Epoch:  470  	Training Loss: 0.033538591116666794
Test Loss:  0.03130275756120682
Valid Loss:  0.033594757318496704
Epoch:  471  	Training Loss: 0.03352947533130646
Test Loss:  0.03129425272345543
Valid Loss:  0.03358576074242592
Epoch:  472  	Training Loss: 0.03352036327123642
Test Loss:  0.03128580376505852
Valid Loss:  0.03357682004570961
Epoch:  473  	Training Loss: 0.03351130336523056
Test Loss:  0.031277354806661606
Valid Loss:  0.0335678867995739
Epoch:  474  	Training Loss: 0.0335022509098053
Test Loss:  0.031268902122974396
Valid Loss:  0.03355894610285759
Epoch:  475  	Training Loss: 0.033493198454380035
Test Loss:  0.03126046061515808
Valid Loss:  0.033550016582012177
Epoch:  476  	Training Loss: 0.03348415344953537
Test Loss:  0.031252022832632065
Valid Loss:  0.033541083335876465
Epoch:  477  	Training Loss: 0.033475108444690704
Test Loss:  0.031243588775396347
Valid Loss:  0.03353216126561165
Epoch:  478  	Training Loss: 0.03346606716513634
Test Loss:  0.03123515658080578
Valid Loss:  0.03352323919534683
Epoch:  479  	Training Loss: 0.03345702588558197
Test Loss:  0.031226716935634613
Valid Loss:  0.033514320850372314
Epoch:  480  	Training Loss: 0.0334479920566082
Test Loss:  0.03121829405426979
Valid Loss:  0.033505409955978394
Epoch:  481  	Training Loss: 0.03343895822763443
Test Loss:  0.03120986744761467
Valid Loss:  0.033496495336294174
Epoch:  482  	Training Loss: 0.03342993184924126
Test Loss:  0.031201530247926712
Valid Loss:  0.033487673848867416
Epoch:  483  	Training Loss: 0.03342099487781525
Test Loss:  0.031193194910883904
Valid Loss:  0.03347885236144066
Epoch:  484  	Training Loss: 0.033412061631679535
Test Loss:  0.031184855848550797
Valid Loss:  0.0334700345993042
Epoch:  485  	Training Loss: 0.03340312838554382
Test Loss:  0.031176527962088585
Valid Loss:  0.03346122056245804
Epoch:  486  	Training Loss: 0.03339420258998871
Test Loss:  0.031168200075626373
Valid Loss:  0.033452413976192474
Epoch:  487  	Training Loss: 0.03338528051972389
Test Loss:  0.03115987405180931
Valid Loss:  0.03344360738992691
Epoch:  488  	Training Loss: 0.033376358449459076
Test Loss:  0.031151551753282547
Valid Loss:  0.033434800803661346
Epoch:  489  	Training Loss: 0.03336744010448456
Test Loss:  0.03114323318004608
Valid Loss:  0.03342600539326668
Epoch:  490  	Training Loss: 0.03335852548480034
Test Loss:  0.031134912744164467
Valid Loss:  0.03341720253229141
Epoch:  491  	Training Loss: 0.03334961086511612
Test Loss:  0.0311265978962183
Valid Loss:  0.03340841084718704
Epoch:  492  	Training Loss: 0.033340707421302795
Test Loss:  0.031118325889110565
Valid Loss:  0.033399660140275955
Epoch:  493  	Training Loss: 0.033331841230392456
Test Loss:  0.03111005760729313
Valid Loss:  0.03339091315865517
Epoch:  494  	Training Loss: 0.03332297503948212
Test Loss:  0.031101789325475693
Valid Loss:  0.03338216617703438
Epoch:  495  	Training Loss: 0.033314116299152374
Test Loss:  0.031093526631593704
Valid Loss:  0.033373426645994186
Epoch:  496  	Training Loss: 0.03330526128411293
Test Loss:  0.031085262075066566
Valid Loss:  0.033364683389663696
Epoch:  497  	Training Loss: 0.033296406269073486
Test Loss:  0.031077004969120026
Valid Loss:  0.0333559513092041
Epoch:  498  	Training Loss: 0.03328755497932434
Test Loss:  0.031068742275238037
Valid Loss:  0.03334721922874451
Epoch:  499  	Training Loss: 0.03327871114015579
Test Loss:  0.031060494482517242
Valid Loss:  0.03333849087357521
Epoch:  500  	Training Loss: 0.033269867300987244
Test Loss:  0.03105223923921585
Valid Loss:  0.03332975506782532
seed is  6
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:32,  6.20s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:53,  1.34s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:19<09:40,  1.21s/it]  5%|▍         | 23/500 [00:20<06:52,  1.16it/s]  5%|▌         | 25/500 [00:26<12:17,  1.55s/it]  5%|▌         | 27/500 [00:26<08:42,  1.11s/it]  6%|▌         | 29/500 [00:26<06:13,  1.26it/s]  6%|▌         | 31/500 [00:32<11:45,  1.50s/it]  7%|▋         | 33/500 [00:33<08:20,  1.07s/it]  7%|▋         | 35/500 [00:33<05:57,  1.30it/s]  7%|▋         | 37/500 [00:33<04:18,  1.79it/s]  8%|▊         | 39/500 [00:33<03:09,  2.43it/s]  8%|▊         | 41/500 [00:39<09:27,  1.24s/it]  9%|▊         | 43/500 [00:39<06:45,  1.13it/s]  9%|▉         | 45/500 [00:40<04:51,  1.56it/s]  9%|▉         | 47/500 [00:40<03:31,  2.14it/s] 10%|▉         | 49/500 [00:40<02:36,  2.88it/s] 10%|█         | 51/500 [00:46<08:54,  1.19s/it] 11%|█         | 53/500 [00:46<06:22,  1.17it/s] 11%|█         | 55/500 [00:46<04:35,  1.62it/s] 11%|█▏        | 57/500 [00:47<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:47<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:53<08:48,  1.20s/it] 13%|█▎        | 63/500 [00:53<06:17,  1.16it/s] 13%|█▎        | 65/500 [00:53<04:31,  1.60it/s] 13%|█▎        | 67/500 [00:54<03:17,  2.19it/s]Epoch:  1  	Training Loss: 0.023397838696837425
Test Loss:  0.0656304806470871
Valid Loss:  0.07032410800457001
Epoch:  2  	Training Loss: 0.06901456415653229
Test Loss:  0.0025873081758618355
Valid Loss:  0.0029919068329036236
Epoch:  3  	Training Loss: 0.003178772982209921
Test Loss:  0.002599848434329033
Valid Loss:  0.0029635652899742126
Epoch:  4  	Training Loss: 0.003162713721394539
Test Loss:  0.0025985955726355314
Valid Loss:  0.002950310241430998
Epoch:  5  	Training Loss: 0.0031525325030088425
Test Loss:  0.0025923913344740868
Valid Loss:  0.00294021749868989
Epoch:  6  	Training Loss: 0.003142799250781536
Test Loss:  0.002584699774160981
Valid Loss:  0.002931041643023491
Epoch:  7  	Training Loss: 0.0031331884674727917
Test Loss:  0.002576809609308839
Valid Loss:  0.0029224897734820843
Epoch:  8  	Training Loss: 0.003123773029074073
Test Loss:  0.0025692516937851906
Valid Loss:  0.002914507407695055
Epoch:  9  	Training Loss: 0.0031151478178799152
Test Loss:  0.002562273759394884
Valid Loss:  0.002907012589275837
Epoch:  10  	Training Loss: 0.0031070620752871037
Test Loss:  0.002555527724325657
Valid Loss:  0.002899852814152837
Epoch:  11  	Training Loss: 0.003099425695836544
Test Loss:  0.0025489565450698137
Valid Loss:  0.0028928066603839397
Epoch:  12  	Training Loss: 0.003092174418270588
Test Loss:  0.0023491871543228626
Valid Loss:  0.002795527456328273
Epoch:  13  	Training Loss: 0.002982189878821373
Test Loss:  0.0023666226770728827
Valid Loss:  0.0026738597080111504
Epoch:  14  	Training Loss: 0.0028982721269130707
Test Loss:  0.002210106234997511
Valid Loss:  0.002770098624750972
Epoch:  15  	Training Loss: 0.002931809052824974
Test Loss:  0.002437751740217209
Valid Loss:  0.0026256260462105274
Epoch:  16  	Training Loss: 0.0028985701501369476
Test Loss:  0.002153445966541767
Valid Loss:  0.0027313404716551304
Epoch:  17  	Training Loss: 0.0029138156678527594
Test Loss:  0.0024354765191674232
Valid Loss:  0.0025701012928038836
Epoch:  18  	Training Loss: 0.002874279860407114
Test Loss:  0.0021109217777848244
Valid Loss:  0.0026632859371602535
Epoch:  19  	Training Loss: 0.0028727143071591854
Test Loss:  0.002380823716521263
Valid Loss:  0.0025225095450878143
Epoch:  20  	Training Loss: 0.002840170869603753
Test Loss:  0.0020856945775449276
Valid Loss:  0.002654749434441328
Epoch:  21  	Training Loss: 0.0028694658540189266
Test Loss:  0.00239763967692852
Valid Loss:  0.0025168382562696934
Epoch:  22  	Training Loss: 0.0028473520651459694
Test Loss:  0.002038876060396433
Valid Loss:  0.0025026421062648296
Epoch:  23  	Training Loss: 0.002758616115897894
Test Loss:  0.002210678532719612
Valid Loss:  0.0023204218596220016
Epoch:  24  	Training Loss: 0.002670062705874443
Test Loss:  0.002044343389570713
Valid Loss:  0.0026666815392673016
Epoch:  25  	Training Loss: 0.0028697471134364605
Test Loss:  0.00257328269071877
Valid Loss:  0.002468252554535866
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.0028703988064080477
Test Loss:  0.001983850495889783
Valid Loss:  0.00220689969137311
Epoch:  27  	Training Loss: 0.002542850561439991
Test Loss:  0.0019042901694774628
Valid Loss:  0.0021615903824567795
Epoch:  28  	Training Loss: 0.0024914867244660854
Test Loss:  0.001869683968834579
Valid Loss:  0.0021402407437562943
Epoch:  29  	Training Loss: 0.002461605006828904
Test Loss:  0.0018496301490813494
Valid Loss:  0.0021292935125529766
Epoch:  30  	Training Loss: 0.002446909202262759
Test Loss:  0.0018366766162216663
Valid Loss:  0.0021227924153208733
Epoch:  31  	Training Loss: 0.0024376153014600277
Test Loss:  0.0018289926229044795
Valid Loss:  0.0021183330100029707
Epoch:  32  	Training Loss: 0.002431290689855814
Test Loss:  0.0018128611845895648
Valid Loss:  0.0021109669469296932
Epoch:  33  	Training Loss: 0.0024166156072169542
Test Loss:  0.0018095179693773389
Valid Loss:  0.002107598353177309
Epoch:  34  	Training Loss: 0.0024103359319269657
Test Loss:  0.0018083550967276096
Valid Loss:  0.0021066456101834774
Epoch:  35  	Training Loss: 0.0024071158841252327
Test Loss:  0.0018080868758261204
Valid Loss:  0.0021065010223537683
Epoch:  36  	Training Loss: 0.002405134728178382
Test Loss:  0.0018084363546222448
Valid Loss:  0.00210648775100708
Epoch:  37  	Training Loss: 0.0024037552066147327
Test Loss:  0.0018089332152158022
Valid Loss:  0.002106696367263794
Epoch:  38  	Training Loss: 0.0024027570616453886
Test Loss:  0.0018095287960022688
Valid Loss:  0.0021069603972136974
Epoch:  39  	Training Loss: 0.002401958219707012
Test Loss:  0.0018101203022524714
Valid Loss:  0.002107239793986082
Epoch:  40  	Training Loss: 0.0024013167712837458
Test Loss:  0.0018106794450432062
Valid Loss:  0.002107521053403616
Epoch:  41  	Training Loss: 0.002400811528787017
Test Loss:  0.001811124850064516
Valid Loss:  0.0021078246645629406
Epoch:  42  	Training Loss: 0.0024004282895475626
Test Loss:  0.0018054393585771322
Valid Loss:  0.0020978343673050404
Epoch:  43  	Training Loss: 0.002390672452747822
Test Loss:  0.001801410224288702
Valid Loss:  0.00209414167329669
Epoch:  44  	Training Loss: 0.002385648200288415
Test Loss:  0.0018007326871156693
Valid Loss:  0.0020930180326104164
Epoch:  45  	Training Loss: 0.0023830486461520195
Test Loss:  0.0017989743500947952
Valid Loss:  0.002093771006911993
Epoch:  46  	Training Loss: 0.0023815962485969067
Test Loss:  0.0018004716839641333
Valid Loss:  0.0020937754306942225
Epoch:  47  	Training Loss: 0.0023803790099918842
Test Loss:  0.0018003692384809256
Valid Loss:  0.0020940855611115694
Epoch:  48  	Training Loss: 0.002379265148192644
Test Loss:  0.0018013638909906149
Valid Loss:  0.0020942885894328356
Epoch:  49  	Training Loss: 0.002378249540925026
Test Loss:  0.0018011932261288166
Valid Loss:  0.002095090923830867
Epoch:  50  	Training Loss: 0.0023774849250912666
Test Loss:  0.0018020211718976498
Valid Loss:  0.002095585921779275
Epoch:  51  	Training Loss: 0.002376868389546871
Test Loss:  0.0017992809880524874
Valid Loss:  0.002096559852361679
Epoch:  52  	Training Loss: 0.0023756157606840134
Test Loss:  0.001801018137484789
Valid Loss:  0.002096213400363922
Epoch:  53  	Training Loss: 0.0023750117979943752
Test Loss:  0.0017996772658079863
Valid Loss:  0.0020968122407794
Epoch:  54  	Training Loss: 0.002374525647610426
Test Loss:  0.0018007486360147595
Valid Loss:  0.0020967191085219383
Epoch:  55  	Training Loss: 0.0023741326294839382
Test Loss:  0.0018000518903136253
Valid Loss:  0.0020971097983419895
Epoch:  56  	Training Loss: 0.002373796422034502
Test Loss:  0.0018007515463978052
Valid Loss:  0.0020970830228179693
Epoch:  57  	Training Loss: 0.00237350445240736
Test Loss:  0.0018002334982156754
Valid Loss:  0.0020973999053239822
Epoch:  58  	Training Loss: 0.0023732385598123074
Test Loss:  0.0018007957842200994
Valid Loss:  0.002097353572025895
Epoch:  59  	Training Loss: 0.002372991293668747
Test Loss:  0.001800473197363317
Valid Loss:  0.0020975498482584953
Epoch:  60  	Training Loss: 0.002372760558500886
Test Loss:  0.0018007829785346985
Valid Loss:  0.002097529824823141
Epoch:  61  	Training Loss: 0.0023725463543087244
Test Loss:  0.0018005156889557838
Valid Loss:  0.002097670454531908
Epoch:  62  	Training Loss: 0.0023723458871245384
Test Loss:  0.0017852800665423274
Valid Loss:  0.002091924427077174
Epoch:  63  	Training Loss: 0.0023633381351828575
Test Loss:  0.0017916887300089002
Valid Loss:  0.0020890829619020224
Epoch:  64  	Training Loss: 0.002362007275223732
Test Loss:  0.0017877953359857202
Valid Loss:  0.0020905639976263046
Epoch:  65  	Training Loss: 0.002361633349210024
Test Loss:  0.0017920250538736582
Valid Loss:  0.0020894515328109264
Epoch:  66  	Training Loss: 0.0023613593075424433
Test Loss:  0.0017894933698698878
Valid Loss:  0.002090508583933115
Epoch:  67  	Training Loss: 0.0023611290380358696
Test Loss:  0.001792009687051177
Valid Loss:  0.002089913934469223
Epoch:  68  	Training Loss: 0.002360960002988577
Test Loss:  0.0017897021025419235
Valid Loss:  0.002090893452987075
Epoch:  69  	Training Loss: 0.002360809361562133
Test Loss:  0.001792699913494289
 14%|█▍        | 69/500 [00:54<02:26,  2.94it/s] 14%|█▍        | 71/500 [01:00<08:31,  1.19s/it] 15%|█▍        | 73/500 [01:00<06:06,  1.17it/s] 15%|█▌        | 75/500 [01:00<04:23,  1.61it/s] 15%|█▌        | 77/500 [01:01<03:13,  2.18it/s] 16%|█▌        | 79/500 [01:01<02:23,  2.94it/s] 16%|█▌        | 81/500 [01:07<08:16,  1.19s/it] 17%|█▋        | 83/500 [01:07<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:07<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:07<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:08<02:18,  2.98it/s] 18%|█▊        | 91/500 [01:14<08:06,  1.19s/it] 19%|█▊        | 93/500 [01:14<05:47,  1.17it/s] 19%|█▉        | 95/500 [01:14<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:14<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:14<02:14,  2.98it/s] 20%|██        | 101/500 [01:21<07:49,  1.18s/it] 21%|██        | 103/500 [01:21<05:36,  1.18it/s] 21%|██        | 105/500 [01:21<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:21<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:21<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:28<07:41,  1.19s/it] 23%|██▎       | 113/500 [01:28<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:28<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:28<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:28<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:34<07:24,  1.17s/it] 25%|██▍       | 123/500 [01:35<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:35<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:35<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:35<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:41<07:18,  1.19s/it] 27%|██▋       | 133/500 [01:41<05:13,  1.17it/s] 27%|██▋       | 135/500 [01:42<03:45,  1.62it/s] 27%|██▋       | 137/500 [01:42<02:43,  2.22it/s]Valid Loss:  0.0020901362877339125
Epoch:  70  	Training Loss: 0.002360669430345297
Test Loss:  0.0017900126986205578
Valid Loss:  0.0020912042818963528
Epoch:  71  	Training Loss: 0.002360566984862089
Test Loss:  0.0017931988695636392
Valid Loss:  0.002090342342853546
Epoch:  72  	Training Loss: 0.0023604496382176876
Test Loss:  0.0017684304621070623
Valid Loss:  0.0020866505801677704
Epoch:  73  	Training Loss: 0.002350966678932309
Test Loss:  0.0017842742381617427
Valid Loss:  0.002072515431791544
Epoch:  74  	Training Loss: 0.0023438134230673313
Test Loss:  0.0017530051991343498
Valid Loss:  0.002073979005217552
Epoch:  75  	Training Loss: 0.0023376476019620895
Test Loss:  0.0017791626742109656
Valid Loss:  0.0020577777177095413
Epoch:  76  	Training Loss: 0.0023313951678574085
Test Loss:  0.0017413063906133175
Valid Loss:  0.00206169206649065
Epoch:  77  	Training Loss: 0.002325216308236122
Test Loss:  0.0017683601472526789
Valid Loss:  0.0020456057973206043
Epoch:  78  	Training Loss: 0.0023192192893475294
Test Loss:  0.0017305267974734306
Valid Loss:  0.002049974864348769
Epoch:  79  	Training Loss: 0.00231342576444149
Test Loss:  0.001759596518240869
Valid Loss:  0.0020337901078164577
Epoch:  80  	Training Loss: 0.002307702787220478
Test Loss:  0.0017185361357405782
Valid Loss:  0.0020394735038280487
Epoch:  81  	Training Loss: 0.002302063163369894
Test Loss:  0.0017515828367322683
Valid Loss:  0.0020223374012857676
Epoch:  82  	Training Loss: 0.002296414226293564
Test Loss:  0.001716067548841238
Valid Loss:  0.0020193930249661207
Epoch:  83  	Training Loss: 0.002286250703036785
Test Loss:  0.0017236535204574466
Valid Loss:  0.002014966681599617
Epoch:  84  	Training Loss: 0.0022839889861643314
Test Loss:  0.0017199832946062088
Valid Loss:  0.0020165659952908754
Epoch:  85  	Training Loss: 0.002283783396705985
Test Loss:  0.0017220606096088886
Valid Loss:  0.0020164630841463804
Epoch:  86  	Training Loss: 0.002283641602844
Test Loss:  0.0017215603729709983
Valid Loss:  0.0020171080250293016
Epoch:  87  	Training Loss: 0.0022835414856672287
Test Loss:  0.0017223777249455452
Valid Loss:  0.0020173038356006145
Epoch:  88  	Training Loss: 0.0022834553383290768
Test Loss:  0.0017224366310983896
Valid Loss:  0.0020176712423563004
Epoch:  89  	Training Loss: 0.002283381996676326
Test Loss:  0.0017226747004315257
Valid Loss:  0.0020180344581604004
Epoch:  90  	Training Loss: 0.0022833519615232944
Test Loss:  0.0017204461619257927
Valid Loss:  0.0020183224696666002
Epoch:  91  	Training Loss: 0.0022833163384348154
Test Loss:  0.0017235497944056988
Valid Loss:  0.002017783699557185
Epoch:  92  	Training Loss: 0.002283241134136915
Test Loss:  0.0017203879542648792
Valid Loss:  0.002003094647079706
Epoch:  93  	Training Loss: 0.002271829405799508
Test Loss:  0.0017173278611153364
Valid Loss:  0.0020008175633847713
Epoch:  94  	Training Loss: 0.0022701413836330175
Test Loss:  0.001715805963613093
Valid Loss:  0.0020007698331028223
Epoch:  95  	Training Loss: 0.0022699395194649696
Test Loss:  0.0017155952518805861
Valid Loss:  0.0020007845014333725
Epoch:  96  	Training Loss: 0.0022697607055306435
Test Loss:  0.001715957187116146
Valid Loss:  0.0020008243154734373
Epoch:  97  	Training Loss: 0.0022696119267493486
Test Loss:  0.001715469523333013
Valid Loss:  0.002001094166189432
Epoch:  98  	Training Loss: 0.0022695031948387623
Test Loss:  0.00171554833650589
Valid Loss:  0.002001240849494934
Epoch:  99  	Training Loss: 0.0022694109939038754
Test Loss:  0.001715043094009161
Valid Loss:  0.0020015686750411987
Epoch:  100  	Training Loss: 0.0022693180944770575
Test Loss:  0.0017152712680399418
Valid Loss:  0.0020017074421048164
Epoch:  101  	Training Loss: 0.0022692251950502396
Test Loss:  0.001714947633445263
Valid Loss:  0.0020019740331918
Epoch:  102  	Training Loss: 0.002269142773002386
Test Loss:  0.0016871949192136526
Valid Loss:  0.0020007253624498844
Epoch:  103  	Training Loss: 0.0022607380524277687
Test Loss:  0.0016688643954694271
Valid Loss:  0.0019692713394761086
Epoch:  104  	Training Loss: 0.0022315834648907185
Test Loss:  0.0016623771516606212
Valid Loss:  0.001962356735020876
Epoch:  105  	Training Loss: 0.002222344744950533
Test Loss:  0.001671466394327581
Valid Loss:  0.00196005217730999
Epoch:  106  	Training Loss: 0.002221314236521721
Test Loss:  0.0016654978971928358
Valid Loss:  0.001962861977517605
Epoch:  107  	Training Loss: 0.0022204765118658543
Test Loss:  0.001672443118877709
Valid Loss:  0.0019614207558333874
Epoch:  108  	Training Loss: 0.002219696994870901
Test Loss:  0.0016672118799760938
Valid Loss:  0.001964001450687647
Epoch:  109  	Training Loss: 0.0022191214375197887
Test Loss:  0.0016733305528759956
Valid Loss:  0.001962842419743538
Epoch:  110  	Training Loss: 0.002218639710918069
Test Loss:  0.0016687909374013543
Valid Loss:  0.001965218922123313
Epoch:  111  	Training Loss: 0.0022182792890816927
Test Loss:  0.0016744257882237434
Valid Loss:  0.001964092254638672
Epoch:  112  	Training Loss: 0.0022178818471729755
Test Loss:  0.0016712332144379616
Valid Loss:  0.001965881325304508
Epoch:  113  	Training Loss: 0.0022176560014486313
Test Loss:  0.0016743200831115246
Valid Loss:  0.001965869916602969
Epoch:  114  	Training Loss: 0.002217492088675499
Test Loss:  0.0016732008662074804
Valid Loss:  0.001966906012967229
Epoch:  115  	Training Loss: 0.002217372413724661
Test Loss:  0.0016747177578508854
Valid Loss:  0.001967133255675435
Epoch:  116  	Training Loss: 0.002217283006757498
Test Loss:  0.0016744154272601008
Valid Loss:  0.0019677758682519197
Epoch:  117  	Training Loss: 0.002217215485870838
Test Loss:  0.0016752161318436265
Valid Loss:  0.0019680429250001907
Epoch:  118  	Training Loss: 0.0022171647287905216
Test Loss:  0.0016752185765653849
Valid Loss:  0.0019684636499732733
Epoch:  119  	Training Loss: 0.002217124216258526
Test Loss:  0.0016756723634898663
Valid Loss:  0.001968704629689455
Epoch:  120  	Training Loss: 0.002217092551290989
Test Loss:  0.0016757692210376263
Valid Loss:  0.0019689914770424366
Epoch:  121  	Training Loss: 0.0022170674055814743
Test Loss:  0.0016760369762778282
Valid Loss:  0.0019691884517669678
Epoch:  122  	Training Loss: 0.0022170478478074074
Test Loss:  0.0016748937778174877
Valid Loss:  0.0019656617660075426
Epoch:  123  	Training Loss: 0.002213926985859871
Test Loss:  0.0016697023529559374
Valid Loss:  0.001963068265467882
Epoch:  124  	Training Loss: 0.002210690174251795
Test Loss:  0.0016689975745975971
Valid Loss:  0.0019595567137002945
Epoch:  125  	Training Loss: 0.0022076512686908245
Test Loss:  0.0016647826414555311
Valid Loss:  0.001957065425813198
Epoch:  126  	Training Loss: 0.002204679884016514
Test Loss:  0.0016638177912682295
Valid Loss:  0.00195364560931921
Epoch:  127  	Training Loss: 0.0022016256116330624
Test Loss:  0.0016594678163528442
Valid Loss:  0.0019512189319357276
Epoch:  128  	Training Loss: 0.0021986195351928473
Test Loss:  0.0016586233396083117
Valid Loss:  0.0019479321781545877
Epoch:  129  	Training Loss: 0.0021956453565508127
Test Loss:  0.0016544178361073136
Valid Loss:  0.0019455731380730867
Epoch:  130  	Training Loss: 0.002192701678723097
Test Loss:  0.0016536295879632235
Valid Loss:  0.00194234075024724
Epoch:  131  	Training Loss: 0.0021897489205002785
Test Loss:  0.0016496112802997231
Valid Loss:  0.0019399570301175117
Epoch:  132  	Training Loss: 0.002186825964599848
Test Loss:  0.0016505111707374454
Valid Loss:  0.0019348056521266699
Epoch:  133  	Training Loss: 0.002181687392294407
Test Loss:  0.0016431637341156602
Valid Loss:  0.001932249404489994
Epoch:  134  	Training Loss: 0.0021769267041236162
Test Loss:  0.0016415884019806981
Valid Loss:  0.0019283777801319957
Epoch:  135  	Training Loss: 0.002172327134758234
Test Loss:  0.0016372555401176214
Valid Loss:  0.0019253765931352973
Epoch:  136  	Training Loss: 0.0021679243072867393
Test Loss:  0.0016354485414922237
Valid Loss:  0.0019216923974454403
Epoch:  137  	Training Loss: 0.002163512632250786
Test Loss:  0.0016308862250298262
Valid Loss:  0.0019187491852790117
Epoch:  138  	Training Loss: 0.002159197349101305
Test Loss:  0.0016298305708914995
Valid Loss:   28%|██▊       | 139/500 [01:42<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:48<07:12,  1.20s/it] 29%|██▊       | 143/500 [01:48<05:08,  1.16it/s] 29%|██▉       | 145/500 [01:49<03:41,  1.60it/s] 29%|██▉       | 147/500 [01:49<02:41,  2.19it/s] 30%|██▉       | 149/500 [01:49<01:59,  2.94it/s] 30%|███       | 151/500 [01:55<06:58,  1.20s/it] 31%|███       | 153/500 [01:55<04:59,  1.16it/s] 31%|███       | 155/500 [01:56<03:35,  1.60it/s] 31%|███▏      | 157/500 [01:56<02:36,  2.19it/s] 32%|███▏      | 159/500 [01:56<01:55,  2.95it/s] 32%|███▏      | 161/500 [02:02<06:45,  1.20s/it] 33%|███▎      | 163/500 [02:02<04:49,  1.17it/s] 33%|███▎      | 165/500 [02:02<03:27,  1.61it/s] 33%|███▎      | 167/500 [02:03<02:30,  2.21it/s] 34%|███▍      | 169/500 [02:03<01:51,  2.97it/s] 34%|███▍      | 169/500 [02:14<01:51,  2.97it/s] 34%|███▍      | 171/500 [02:15<11:46,  2.15s/it] 35%|███▍      | 173/500 [02:16<08:18,  1.52s/it] 35%|███▌      | 175/500 [02:16<05:53,  1.09s/it] 35%|███▌      | 177/500 [02:16<04:12,  1.28it/s] 36%|███▌      | 179/500 [02:16<03:02,  1.76it/s] 36%|███▌      | 181/500 [02:22<07:15,  1.37s/it] 37%|███▋      | 183/500 [02:23<05:10,  1.02it/s] 37%|███▋      | 185/500 [02:23<03:41,  1.42it/s] 37%|███▋      | 187/500 [02:23<02:40,  1.95it/s] 38%|███▊      | 189/500 [02:23<01:57,  2.64it/s] 38%|███▊      | 191/500 [02:29<06:14,  1.21s/it] 39%|███▊      | 193/500 [02:29<04:27,  1.15it/s] 39%|███▉      | 195/500 [02:30<03:11,  1.59it/s] 39%|███▉      | 197/500 [02:30<02:19,  2.17it/s] 40%|███▉      | 199/500 [02:30<01:43,  2.92it/s] 40%|████      | 201/500 [02:36<06:00,  1.21s/it] 41%|████      | 203/500 [02:36<04:17,  1.15it/s] 41%|████      | 205/500 [02:37<03:04,  1.60it/s]0.0019148987485095859
Epoch:  139  	Training Loss: 0.0021549267694354057
Test Loss:  0.0016240597469732165
Valid Loss:  0.0019123160745948553
Epoch:  140  	Training Loss: 0.0021507050842046738
Test Loss:  0.0016233547357842326
Valid Loss:  0.0019083017250522971
Epoch:  141  	Training Loss: 0.00214644568040967
Test Loss:  0.001618763548322022
Valid Loss:  0.0019054021686315536
Epoch:  142  	Training Loss: 0.002142322715371847
Test Loss:  0.0016206023283302784
Valid Loss:  0.0018993375124409795
Epoch:  143  	Training Loss: 0.0021367233712226152
Test Loss:  0.001613282016478479
Valid Loss:  0.0018971955869346857
Epoch:  144  	Training Loss: 0.002132630441337824
Test Loss:  0.001611800747923553
Valid Loss:  0.0018939385190606117
Epoch:  145  	Training Loss: 0.002129004569724202
Test Loss:  0.0016083528753370047
Valid Loss:  0.0018915258115157485
Epoch:  146  	Training Loss: 0.002125557279214263
Test Loss:  0.0016063039656728506
Valid Loss:  0.0018888280028477311
Epoch:  147  	Training Loss: 0.00212233979254961
Test Loss:  0.0016040299087762833
Valid Loss:  0.0018861939897760749
Epoch:  148  	Training Loss: 0.0021193120628595352
Test Loss:  0.001601889729499817
Valid Loss:  0.0018835847731679678
Epoch:  149  	Training Loss: 0.0021164780482649803
Test Loss:  0.0015996838919818401
Valid Loss:  0.0018811746267601848
Epoch:  150  	Training Loss: 0.0021137166768312454
Test Loss:  0.0015977915609255433
Valid Loss:  0.0018786638975143433
Epoch:  151  	Training Loss: 0.002111012116074562
Test Loss:  0.0015960554592311382
Valid Loss:  0.0018761157989501953
Epoch:  152  	Training Loss: 0.002108335494995117
Test Loss:  0.0015855624806135893
Valid Loss:  0.0018673226004466414
Epoch:  153  	Training Loss: 0.002099885605275631
Test Loss:  0.0015792769845575094
Valid Loss:  0.0018613975262269378
Epoch:  154  	Training Loss: 0.0020946513395756483
Test Loss:  0.0015748308505862951
Valid Loss:  0.0018571587279438972
Epoch:  155  	Training Loss: 0.002090936992317438
Test Loss:  0.0015721764648333192
Valid Loss:  0.0018538236618041992
Epoch:  156  	Training Loss: 0.002088097156956792
Test Loss:  0.0015702751697972417
Valid Loss:  0.0018511954694986343
Epoch:  157  	Training Loss: 0.0020858680363744497
Test Loss:  0.0015692294109612703
Valid Loss:  0.0018493222305551171
Epoch:  158  	Training Loss: 0.0020841918885707855
Test Loss:  0.0015680980868637562
Valid Loss:  0.0018480895087122917
Epoch:  159  	Training Loss: 0.0020830370485782623
Test Loss:  0.0015679762000218034
Valid Loss:  0.001846778905019164
Epoch:  160  	Training Loss: 0.002082051942124963
Test Loss:  0.0015673546586185694
Valid Loss:  0.0018458554986864328
Epoch:  161  	Training Loss: 0.002081223065033555
Test Loss:  0.001567323342896998
Valid Loss:  0.001845001825131476
Epoch:  162  	Training Loss: 0.002080550417304039
Test Loss:  0.0015580184990540147
Valid Loss:  0.0018374340143054724
Epoch:  163  	Training Loss: 0.0020728043746203184
Test Loss:  0.0015566900838166475
Valid Loss:  0.001829438959248364
Epoch:  164  	Training Loss: 0.002067204564809799
Test Loss:  0.0015453649684786797
Valid Loss:  0.001826415304094553
Epoch:  165  	Training Loss: 0.0020624075550585985
Test Loss:  0.0015520593151450157
Valid Loss:  0.0018177928868681192
Epoch:  166  	Training Loss: 0.002057882957160473
Test Loss:  0.0015311352908611298
Valid Loss:  0.0018194084987044334
Epoch:  167  	Training Loss: 0.0020543215796351433
Test Loss:  0.001558623625896871
Valid Loss:  0.0018068377394229174
Epoch:  168  	Training Loss: 0.002052420750260353
Test Loss:  0.0015072128735482693
Valid Loss:  0.0018253946909680963
Epoch:  169  	Training Loss: 0.0020533613860607147
Test Loss:  0.0016049453988671303
Valid Loss:  0.0018000638810917735
Epoch:  170  	Training Loss: 0.0020601265132427216
Test Loss:  0.0014761476777493954
Valid Loss:  0.0018773090559989214
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.0020849001593887806
Test Loss:  0.0015064652543514967
Valid Loss:  0.0018090548692271113
Epoch:  172  	Training Loss: 0.0020425617694854736
Test Loss:  0.001523217186331749
Valid Loss:  0.0017991927452385426
Epoch:  173  	Training Loss: 0.0020396073814481497
Test Loss:  0.0015245098620653152
Valid Loss:  0.0017975295195356011
Epoch:  174  	Training Loss: 0.0020386981777846813
Test Loss:  0.0015240279026329517
Valid Loss:  0.001796517288312316
Epoch:  175  	Training Loss: 0.002037817146629095
Test Loss:  0.0015233634039759636
Valid Loss:  0.0017955729272216558
Epoch:  176  	Training Loss: 0.002036964986473322
Test Loss:  0.0015227197436615825
Valid Loss:  0.0017946690786629915
Epoch:  177  	Training Loss: 0.0020361654460430145
Test Loss:  0.0015220604836940765
Valid Loss:  0.0017937748925760388
Epoch:  178  	Training Loss: 0.0020353682339191437
Test Loss:  0.0015213971491903067
Valid Loss:  0.00179288221988827
Epoch:  179  	Training Loss: 0.002034576842561364
Test Loss:  0.0015208420809358358
Valid Loss:  0.0017919910605996847
Epoch:  180  	Training Loss: 0.0020337882451713085
Test Loss:  0.0015203745570033789
Valid Loss:  0.0017911921022459865
Epoch:  181  	Training Loss: 0.0020330040715634823
Test Loss:  0.001519987010397017
Valid Loss:  0.0017904412234202027
Epoch:  182  	Training Loss: 0.002032243413850665
Test Loss:  0.0015152768464758992
Valid Loss:  0.0017870157025754452
Epoch:  183  	Training Loss: 0.0020285742357373238
Test Loss:  0.00151239731349051
Valid Loss:  0.001783927669748664
Epoch:  184  	Training Loss: 0.002025764435529709
Test Loss:  0.0015103481709957123
Valid Loss:  0.0017814328894019127
Epoch:  185  	Training Loss: 0.0020237741991877556
Test Loss:  0.0015085890190675855
Valid Loss:  0.001779554644599557
Epoch:  186  	Training Loss: 0.0020220885053277016
Test Loss:  0.0015071615343913436
Valid Loss:  0.0017777697648853064
Epoch:  187  	Training Loss: 0.002020549029111862
Test Loss:  0.0015061597805470228
Valid Loss:  0.0017765054944902658
Epoch:  188  	Training Loss: 0.0020194805692881346
Test Loss:  0.0015052305534482002
Valid Loss:  0.0017754067666828632
Epoch:  189  	Training Loss: 0.002018560655415058
Test Loss:  0.0015043579041957855
Valid Loss:  0.001774459145963192
Epoch:  190  	Training Loss: 0.002017785096541047
Test Loss:  0.0015037443954497576
Valid Loss:  0.001773647265508771
Epoch:  191  	Training Loss: 0.0020171119831502438
Test Loss:  0.0015031337970867753
Valid Loss:  0.0017728516831994057
Epoch:  192  	Training Loss: 0.0020164591260254383
Test Loss:  0.001502373954281211
Valid Loss:  0.0017726764781400561
Epoch:  193  	Training Loss: 0.0020161522552371025
Test Loss:  0.0015019872225821018
Valid Loss:  0.0017724760109558702
Epoch:  194  	Training Loss: 0.002015881473198533
Test Loss:  0.0015017464756965637
Valid Loss:  0.0017723985947668552
Epoch:  195  	Training Loss: 0.0020156358368694782
Test Loss:  0.0015016738325357437
Valid Loss:  0.0017723443452268839
Epoch:  196  	Training Loss: 0.0020154875237494707
Test Loss:  0.0015017681289464235
Valid Loss:  0.001772269606590271
Epoch:  197  	Training Loss: 0.002015403239056468
Test Loss:  0.0015019774436950684
Valid Loss:  0.0017721690237522125
Epoch:  198  	Training Loss: 0.0020153673831373453
Test Loss:  0.0015021482249721885
Valid Loss:  0.0017720793839544058
Epoch:  199  	Training Loss: 0.002015340141952038
Test Loss:  0.0015022899024188519
Valid Loss:  0.001771995797753334
Epoch:  200  	Training Loss: 0.0020153166260570288
Test Loss:  0.0015024059684947133
Valid Loss:  0.00177191779948771
Epoch:  201  	Training Loss: 0.0020152947399765253
Test Loss:  0.0015024440363049507
Valid Loss:  0.0017718684393912554
Epoch:  202  	Training Loss: 0.0020152723882347345
Test Loss:  0.0015022106235846877
Valid Loss:  0.0017689100932329893
Epoch:  203  	Training Loss: 0.002012596232816577
Test Loss:  0.0015008855843916535
Valid Loss:  0.001766870031133294
Epoch:  204  	Training Loss: 0.002010469324886799
Test Loss:  0.0014995464589446783
Valid Loss:  0.001765287946909666
Epoch:  205  	Training Loss: 0.0020086062140762806
Test Loss:  0.0014984605368226767
Valid Loss:  0.0017637474229559302
Epoch:  206  	Training Loss: 0.002006842289119959
Test Loss:   41%|████▏     | 207/500 [02:37<02:14,  2.18it/s] 42%|████▏     | 209/500 [02:37<01:40,  2.90it/s] 42%|████▏     | 211/500 [02:43<05:47,  1.20s/it] 43%|████▎     | 213/500 [02:43<04:08,  1.16it/s] 43%|████▎     | 215/500 [02:44<02:58,  1.60it/s] 43%|████▎     | 217/500 [02:44<02:09,  2.18it/s] 44%|████▍     | 219/500 [02:44<01:36,  2.92it/s] 44%|████▍     | 221/500 [02:50<05:36,  1.21s/it] 45%|████▍     | 223/500 [02:50<04:00,  1.15it/s] 45%|████▌     | 225/500 [02:51<02:52,  1.59it/s] 45%|████▌     | 227/500 [02:51<02:05,  2.18it/s] 46%|████▌     | 229/500 [02:51<01:32,  2.94it/s] 46%|████▌     | 231/500 [02:57<05:19,  1.19s/it] 47%|████▋     | 233/500 [02:57<03:47,  1.17it/s] 47%|████▋     | 235/500 [02:57<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:58<01:58,  2.21it/s] 48%|████▊     | 239/500 [02:58<01:27,  2.98it/s] 48%|████▊     | 241/500 [03:04<05:10,  1.20s/it] 49%|████▊     | 243/500 [03:04<03:40,  1.16it/s] 49%|████▉     | 245/500 [03:04<02:38,  1.61it/s] 49%|████▉     | 247/500 [03:05<01:54,  2.20it/s] 50%|████▉     | 249/500 [03:05<01:24,  2.96it/s] 50%|█████     | 251/500 [03:11<04:54,  1.18s/it] 51%|█████     | 253/500 [03:11<03:30,  1.18it/s] 51%|█████     | 255/500 [03:11<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:11<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:12<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:18<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:18<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:18<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:18<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:18<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:25<04:35,  1.20s/it] 55%|█████▍    | 273/500 [03:25<03:15,  1.16it/s]0.0014975499361753464
Valid Loss:  0.0017623514868319035
Epoch:  207  	Training Loss: 0.002005325397476554
Test Loss:  0.0014966265298426151
Valid Loss:  0.001761267427355051
Epoch:  208  	Training Loss: 0.0020041088573634624
Test Loss:  0.0014959308318793774
Valid Loss:  0.0017603118903934956
Epoch:  209  	Training Loss: 0.0020030783489346504
Test Loss:  0.0014954374637454748
Valid Loss:  0.001759400824084878
Epoch:  210  	Training Loss: 0.0020021884702146053
Test Loss:  0.0014950388576835394
Valid Loss:  0.0017585044261068106
Epoch:  211  	Training Loss: 0.0020013307221233845
Test Loss:  0.001494663069024682
Valid Loss:  0.0017577700782567263
Epoch:  212  	Training Loss: 0.0020005591213703156
Test Loss:  0.0014882017858326435
Valid Loss:  0.0017560062697157264
Epoch:  213  	Training Loss: 0.0019978645723313093
Test Loss:  0.0014864387921988964
Valid Loss:  0.0017539877444505692
Epoch:  214  	Training Loss: 0.001996058039367199
Test Loss:  0.001485513523221016
Valid Loss:  0.0017526778392493725
Epoch:  215  	Training Loss: 0.001994872698560357
Test Loss:  0.0014850564766675234
Valid Loss:  0.0017517476808279753
Epoch:  216  	Training Loss: 0.0019940133206546307
Test Loss:  0.0014847565907984972
Valid Loss:  0.0017512219492346048
Epoch:  217  	Training Loss: 0.001993408892303705
Test Loss:  0.0014847901184111834
Valid Loss:  0.0017509963363409042
Epoch:  218  	Training Loss: 0.0019930684939026833
Test Loss:  0.0014848517021164298
Valid Loss:  0.0017508345190435648
Epoch:  219  	Training Loss: 0.0019928249530494213
Test Loss:  0.0014849540311843157
Valid Loss:  0.0017507760785520077
Epoch:  220  	Training Loss: 0.0019926391541957855
Test Loss:  0.0014851115411147475
Valid Loss:  0.0017507713055238128
Epoch:  221  	Training Loss: 0.001992530422285199
Test Loss:  0.0014852923341095448
Valid Loss:  0.001750763040035963
Epoch:  222  	Training Loss: 0.001992467325180769
Test Loss:  0.0014701742911711335
Valid Loss:  0.0017388311680406332
Epoch:  223  	Training Loss: 0.001978797372430563
Test Loss:  0.001458010170608759
Valid Loss:  0.0017272980185225606
Epoch:  224  	Training Loss: 0.0019672922790050507
Test Loss:  0.0014509798493236303
Valid Loss:  0.0017200963338837028
Epoch:  225  	Training Loss: 0.0019600801169872284
Test Loss:  0.0014465535059571266
Valid Loss:  0.0017164098098874092
Epoch:  226  	Training Loss: 0.00195583188906312
Test Loss:  0.00144332111813128
Valid Loss:  0.0017134060617536306
Epoch:  227  	Training Loss: 0.001952130813151598
Test Loss:  0.0014413298340514302
Valid Loss:  0.0017110402695834637
Epoch:  228  	Training Loss: 0.0019491679267957807
Test Loss:  0.001439780811779201
Valid Loss:  0.001709513133391738
Epoch:  229  	Training Loss: 0.0019468646496534348
Test Loss:  0.0014392007142305374
Valid Loss:  0.0017083550337702036
Epoch:  230  	Training Loss: 0.0019451570697128773
Test Loss:  0.0014383557718247175
Valid Loss:  0.0017073325579985976
Epoch:  231  	Training Loss: 0.001943495823070407
Test Loss:  0.0014378998894244432
Valid Loss:  0.0017062753904610872
Epoch:  232  	Training Loss: 0.0019418682204559445
Test Loss:  0.0014360571512952447
Valid Loss:  0.0017050873721018434
Epoch:  233  	Training Loss: 0.0019401072058826685
Test Loss:  0.0014348137192428112
Valid Loss:  0.0017040803795680404
Epoch:  234  	Training Loss: 0.0019386042840778828
Test Loss:  0.0014337182510644197
Valid Loss:  0.0017031894531100988
Epoch:  235  	Training Loss: 0.0019373060204088688
Test Loss:  0.0014327610842883587
Valid Loss:  0.0017023656982928514
Epoch:  236  	Training Loss: 0.0019361479207873344
Test Loss:  0.0014318791218101978
Valid Loss:  0.0017017227364704013
Epoch:  237  	Training Loss: 0.0019351214868947864
Test Loss:  0.0014312586281448603
Valid Loss:  0.0017011006129905581
Epoch:  238  	Training Loss: 0.0019341515144333243
Test Loss:  0.0014306321972981095
Valid Loss:  0.00170050747692585
Epoch:  239  	Training Loss: 0.0019332098308950663
Test Loss:  0.0014301352202892303
Valid Loss:  0.0016999037470668554
Epoch:  240  	Training Loss: 0.001932315295562148
Test Loss:  0.0014297813177108765
Valid Loss:  0.0016992981545627117
Epoch:  241  	Training Loss: 0.0019314773380756378
Test Loss:  0.0014294072752818465
Valid Loss:  0.0016988231800496578
Epoch:  242  	Training Loss: 0.0019307212205603719
Test Loss:  0.0014259344898164272
Valid Loss:  0.0016917072935029864
Epoch:  243  	Training Loss: 0.0019243176793679595
Test Loss:  0.0014224918559193611
Valid Loss:  0.0016865108627825975
Epoch:  244  	Training Loss: 0.001919495640322566
Test Loss:  0.0014194580726325512
Valid Loss:  0.0016823969781398773
Epoch:  245  	Training Loss: 0.0019153289031237364
Test Loss:  0.0014167346525937319
Valid Loss:  0.0016792520182207227
Epoch:  246  	Training Loss: 0.0019118874333798885
Test Loss:  0.0014143767766654491
Valid Loss:  0.001676937798038125
Epoch:  247  	Training Loss: 0.0019092070870101452
Test Loss:  0.0014122871216386557
Valid Loss:  0.0016753599047660828
Epoch:  248  	Training Loss: 0.001907146768644452
Test Loss:  0.0014103015419095755
Valid Loss:  0.0016742583829909563
Epoch:  249  	Training Loss: 0.0019054883159697056
Test Loss:  0.0014089422766119242
Valid Loss:  0.0016731878276914358
Epoch:  250  	Training Loss: 0.0019039598992094398
Test Loss:  0.001407994539476931
Valid Loss:  0.0016722232103347778
Epoch:  251  	Training Loss: 0.001902492018416524
Test Loss:  0.0014071156037971377
Valid Loss:  0.0016714534722268581
Epoch:  252  	Training Loss: 0.001901182346045971
Test Loss:  0.0014011551393195987
Valid Loss:  0.0016712963115423918
Epoch:  253  	Training Loss: 0.001899559167213738
Test Loss:  0.0013998460490256548
Valid Loss:  0.0016702762804925442
Epoch:  254  	Training Loss: 0.0018982180627062917
Test Loss:  0.001399182016029954
Valid Loss:  0.0016695264494046569
Epoch:  255  	Training Loss: 0.0018971016397699714
Test Loss:  0.001398776308633387
Valid Loss:  0.0016688749892637134
Epoch:  256  	Training Loss: 0.001896159490570426
Test Loss:  0.0013985899277031422
Valid Loss:  0.0016684997826814651
Epoch:  257  	Training Loss: 0.0018954320112243295
Test Loss:  0.001398614956997335
Valid Loss:  0.0016683109570294619
Epoch:  258  	Training Loss: 0.0018949605291709304
Test Loss:  0.0013987028505653143
Valid Loss:  0.0016682043205946684
Epoch:  259  	Training Loss: 0.0018945601768791676
Test Loss:  0.0013987170532345772
Valid Loss:  0.0016681450651958585
Epoch:  260  	Training Loss: 0.0018941687885671854
Test Loss:  0.0013988029677420855
Valid Loss:  0.0016680980334058404
Epoch:  261  	Training Loss: 0.0018937899731099606
Test Loss:  0.0013988768914714456
Valid Loss:  0.0016681684646755457
Epoch:  262  	Training Loss: 0.0018934460822492838
Test Loss:  0.0013946061953902245
Valid Loss:  0.001665507908910513
Epoch:  263  	Training Loss: 0.0018899088026955724
Test Loss:  0.0013926036190241575
Valid Loss:  0.0016638862434774637
Epoch:  264  	Training Loss: 0.0018877508118748665
Test Loss:  0.001391878118738532
Valid Loss:  0.0016628282610327005
Epoch:  265  	Training Loss: 0.0018863142468035221
Test Loss:  0.0013918394688516855
Valid Loss:  0.001662308699451387
Epoch:  266  	Training Loss: 0.0018853857181966305
Test Loss:  0.0013924435479566455
Valid Loss:  0.00166214257478714
Epoch:  267  	Training Loss: 0.0018849694170057774
Test Loss:  0.0013928995467722416
Valid Loss:  0.0016621161485090852
Epoch:  268  	Training Loss: 0.0018846290186047554
Test Loss:  0.0013933773152530193
Valid Loss:  0.0016621188260614872
Epoch:  269  	Training Loss: 0.0018843042198568583
Test Loss:  0.0013937230687588453
Valid Loss:  0.0016622516559436917
Epoch:  270  	Training Loss: 0.001884002354927361
Test Loss:  0.0013939609052613378
Valid Loss:  0.001662517781369388
Epoch:  271  	Training Loss: 0.0018837503157556057
Test Loss:  0.0013943822123110294
Valid Loss:  0.0016627346631139517
Epoch:  272  	Training Loss: 0.0018835776718333364
Test Loss:  0.001391010358929634
Valid Loss:  0.001662630820646882
Epoch:  273  	Training Loss: 0.0018825385486707091
Test Loss:  0.0013904834631830454
Valid Loss:  0.0016618408262729645
Epoch:  274  	Training Loss: 0.0018816418014466763
Test Loss:  0.0013900937046855688
Valid Loss:  0.0016611525788903236
 55%|█████▌    | 275/500 [03:25<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:25<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:25<01:14,  2.95it/s] 56%|█████▌    | 281/500 [03:32<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:32<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:32<02:13,  1.62it/s] 57%|█████▋    | 287/500 [03:32<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:32<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:39<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:39<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:39<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:39<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:39<01:06,  3.00it/s] 60%|██████    | 301/500 [03:45<03:53,  1.18s/it] 61%|██████    | 303/500 [03:46<02:46,  1.19it/s] 61%|██████    | 305/500 [03:46<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:46<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:46<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:52<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:52<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:53<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:53<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:53<01:00,  3.00it/s] 64%|██████▍   | 321/500 [03:59<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:59<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:59<01:47,  1.63it/s] 65%|██████▌   | 327/500 [04:00<01:17,  2.23it/s] 66%|██████▌   | 329/500 [04:00<00:56,  3.00it/s] 66%|██████▌   | 331/500 [04:06<03:19,  1.18s/it] 67%|██████▋   | 333/500 [04:06<02:21,  1.18it/s] 67%|██████▋   | 335/500 [04:06<01:40,  1.64it/s] 67%|██████▋   | 337/500 [04:06<01:12,  2.24it/s] 68%|██████▊   | 339/500 [04:06<00:53,  3.01it/s] 68%|██████▊   | 341/500 [04:13<03:08,  1.18s/it]Epoch:  275  	Training Loss: 0.0018808043096214533
Test Loss:  0.0013898496981710196
Valid Loss:  0.001660609501414001
Epoch:  276  	Training Loss: 0.0018801146652549505
Test Loss:  0.001389603945426643
Valid Loss:  0.0016601212555542588
Epoch:  277  	Training Loss: 0.0018794958014041185
Test Loss:  0.001389418845064938
Valid Loss:  0.0016596756177023053
Epoch:  278  	Training Loss: 0.001878929091617465
Test Loss:  0.0013892390998080373
Valid Loss:  0.0016592476749792695
Epoch:  279  	Training Loss: 0.001878407085314393
Test Loss:  0.0013891085982322693
Valid Loss:  0.0016588557045906782
Epoch:  280  	Training Loss: 0.0018779176753014326
Test Loss:  0.001389032113365829
Valid Loss:  0.0016584837576374412
Epoch:  281  	Training Loss: 0.001877468777820468
Test Loss:  0.0013890019617974758
Valid Loss:  0.0016581531381234527
Epoch:  282  	Training Loss: 0.0018770898459479213
Test Loss:  0.0013883702922612429
Valid Loss:  0.0016552479937672615
Epoch:  283  	Training Loss: 0.0018747423309832811
Test Loss:  0.0013859197497367859
Valid Loss:  0.0016535648610442877
Epoch:  284  	Training Loss: 0.0018729774747043848
Test Loss:  0.0013842522166669369
Valid Loss:  0.0016521983779966831
Epoch:  285  	Training Loss: 0.0018714007455855608
Test Loss:  0.0013830190291628242
Valid Loss:  0.0016509571578353643
Epoch:  286  	Training Loss: 0.0018699499778449535
Test Loss:  0.0013819572050124407
Valid Loss:  0.0016499802004545927
Epoch:  287  	Training Loss: 0.001868716673925519
Test Loss:  0.0013811878161504865
Valid Loss:  0.001649205689318478
Epoch:  288  	Training Loss: 0.0018676645122468472
Test Loss:  0.0013805110938847065
Valid Loss:  0.001648748992010951
Epoch:  289  	Training Loss: 0.0018668929114937782
Test Loss:  0.0013799932785332203
Valid Loss:  0.0016485289670526981
Epoch:  290  	Training Loss: 0.0018663295777514577
Test Loss:  0.001379799796268344
Valid Loss:  0.0016482400242239237
Epoch:  291  	Training Loss: 0.0018657853361219168
Test Loss:  0.0013796729035675526
Valid Loss:  0.0016479790210723877
Epoch:  292  	Training Loss: 0.0018652707803994417
Test Loss:  0.00137956696562469
Valid Loss:  0.0016473405994474888
Epoch:  293  	Training Loss: 0.0018644724041223526
Test Loss:  0.0013792659156024456
Valid Loss:  0.00164693349506706
Epoch:  294  	Training Loss: 0.0018638395704329014
Test Loss:  0.0013789914082735777
Valid Loss:  0.0016466237138956785
Epoch:  295  	Training Loss: 0.0018632578430697322
Test Loss:  0.0013787808129563928
Valid Loss:  0.001646318705752492
Epoch:  296  	Training Loss: 0.001862697652541101
Test Loss:  0.0013785819755867124
Valid Loss:  0.001646113465540111
Epoch:  297  	Training Loss: 0.0018622686620801687
Test Loss:  0.001378411427140236
Valid Loss:  0.0016459820326417685
Epoch:  298  	Training Loss: 0.0018619000911712646
Test Loss:  0.0013782728929072618
Valid Loss:  0.001645865966565907
Epoch:  299  	Training Loss: 0.0018615758744999766
Test Loss:  0.0013781448360532522
Valid Loss:  0.0016457493184134364
Epoch:  300  	Training Loss: 0.0018612804124131799
Test Loss:  0.0013780273729935288
Valid Loss:  0.0016456833109259605
Epoch:  301  	Training Loss: 0.0018610223196446896
Test Loss:  0.0013779790606349707
Valid Loss:  0.0016456138109788299
Epoch:  302  	Training Loss: 0.001860781922005117
Test Loss:  0.0013773436658084393
Valid Loss:  0.0016421456821262836
Epoch:  303  	Training Loss: 0.0018583289347589016
Test Loss:  0.0013751671649515629
Valid Loss:  0.0016400704625993967
Epoch:  304  	Training Loss: 0.0018562010955065489
Test Loss:  0.0013727463083341718
Valid Loss:  0.001638277666643262
Epoch:  305  	Training Loss: 0.0018542956095188856
Test Loss:  0.0013707979815080762
Valid Loss:  0.0016367376083508134
Epoch:  306  	Training Loss: 0.0018526233034208417
Test Loss:  0.00136936001945287
Valid Loss:  0.001635602442547679
Epoch:  307  	Training Loss: 0.0018511834787204862
Test Loss:  0.0013681368436664343
Valid Loss:  0.0016346934717148542
Epoch:  308  	Training Loss: 0.0018499979050830007
Test Loss:  0.001366984099149704
Valid Loss:  0.0016339237336069345
Epoch:  309  	Training Loss: 0.0018489656504243612
Test Loss:  0.001366164069622755
Valid Loss:  0.0016332478262484074
Epoch:  310  	Training Loss: 0.0018480633152648807
Test Loss:  0.001365469302982092
Valid Loss:  0.0016329296631738544
Epoch:  311  	Training Loss: 0.0018473854288458824
Test Loss:  0.0013650160981342196
Valid Loss:  0.0016326140612363815
Epoch:  312  	Training Loss: 0.0018467543413862586
Test Loss:  0.001361411064863205
Valid Loss:  0.0016272724606096745
Epoch:  313  	Training Loss: 0.0018410140182822943
Test Loss:  0.001357557950541377
Valid Loss:  0.0016232249327003956
Epoch:  314  	Training Loss: 0.0018361667171120644
Test Loss:  0.001354136737063527
Valid Loss:  0.0016197266522794962
Epoch:  315  	Training Loss: 0.0018317154608666897
Test Loss:  0.0013512857258319855
Valid Loss:  0.00161651405505836
Epoch:  316  	Training Loss: 0.0018276209011673927
Test Loss:  0.0013488262193277478
Valid Loss:  0.001613865839317441
Epoch:  317  	Training Loss: 0.0018241913057863712
Test Loss:  0.0013466705568134785
Valid Loss:  0.0016116031911224127
Epoch:  318  	Training Loss: 0.0018211326096206903
Test Loss:  0.0013448323588818312
Valid Loss:  0.0016095044557005167
Epoch:  319  	Training Loss: 0.0018183202482759953
Test Loss:  0.0013428798411041498
Valid Loss:  0.0016075650928542018
Epoch:  320  	Training Loss: 0.0018156738951802254
Test Loss:  0.0013411351246759295
Valid Loss:  0.0016057807952165604
Epoch:  321  	Training Loss: 0.0018132270779460669
Test Loss:  0.001339699374511838
Valid Loss:  0.0016041155904531479
Epoch:  322  	Training Loss: 0.0018109579104930162
Test Loss:  0.001332517946138978
Valid Loss:  0.0016022180207073689
Epoch:  323  	Training Loss: 0.0018080146983265877
Test Loss:  0.001331934006884694
Valid Loss:  0.0015994312707334757
Epoch:  324  	Training Loss: 0.001805588137358427
Test Loss:  0.001329813851043582
Valid Loss:  0.0015974714187905192
Epoch:  325  	Training Loss: 0.0018034162931144238
Test Loss:  0.0013286808971315622
Valid Loss:  0.0015958655858412385
Epoch:  326  	Training Loss: 0.0018017103429883718
Test Loss:  0.0013278042897582054
Valid Loss:  0.001594454050064087
Epoch:  327  	Training Loss: 0.001800271333195269
Test Loss:  0.0013266571331769228
Valid Loss:  0.001593171851709485
Epoch:  328  	Training Loss: 0.0017989074112847447
Test Loss:  0.0013256799429655075
Valid Loss:  0.001591881038621068
Epoch:  329  	Training Loss: 0.0017975466325879097
Test Loss:  0.0013247246388345957
Valid Loss:  0.0015906913904473186
Epoch:  330  	Training Loss: 0.0017962278798222542
Test Loss:  0.0013238443061709404
Valid Loss:  0.0015897389966994524
Epoch:  331  	Training Loss: 0.0017950657056644559
Test Loss:  0.001323056872934103
Valid Loss:  0.0015888928901404142
Epoch:  332  	Training Loss: 0.0017939872341230512
Test Loss:  0.0013243693392723799
Valid Loss:  0.0015855217352509499
Epoch:  333  	Training Loss: 0.0017914136406034231
Test Loss:  0.0013236147351562977
Valid Loss:  0.0015831943601369858
Epoch:  334  	Training Loss: 0.001789274625480175
Test Loss:  0.001322165597230196
Valid Loss:  0.0015813865466043353
Epoch:  335  	Training Loss: 0.001787450397387147
Test Loss:  0.0013207748997956514
Valid Loss:  0.0015798439271748066
Epoch:  336  	Training Loss: 0.001785807078704238
Test Loss:  0.0013195752399042249
Valid Loss:  0.0015786909498274326
Epoch:  337  	Training Loss: 0.0017844133544713259
Test Loss:  0.001318465219810605
Valid Loss:  0.0015777330845594406
Epoch:  338  	Training Loss: 0.0017831518780440092
Test Loss:  0.001317349961027503
Valid Loss:  0.001577118644490838
Epoch:  339  	Training Loss: 0.001782124163582921
Test Loss:  0.001316254143603146
Valid Loss:  0.0015767047880217433
Epoch:  340  	Training Loss: 0.0017813337035477161
Test Loss:  0.0013155731139704585
Valid Loss:  0.0015763017581775784
Epoch:  341  	Training Loss: 0.0017805988900363445
Test Loss:  0.0013150910381227732
Valid Loss:  0.0015759598463773727
Epoch:  342  	Training Loss: 0.001779929269105196
Test Loss:  0.0013125264085829258
Valid Loss:  0.0015724825207144022
Epoch:  343  	Training Loss: 0.0017762251663953066
Test Loss:  0.0013098721392452717
 69%|██████▊   | 343/500 [04:13<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:13<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:13<01:08,  2.22it/s] 70%|██████▉   | 349/500 [04:13<00:50,  2.99it/s] 70%|███████   | 351/500 [04:20<02:53,  1.17s/it] 71%|███████   | 353/500 [04:20<02:03,  1.19it/s] 71%|███████   | 355/500 [04:20<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:20<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:20<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:26<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:27<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:27<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:27<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:27<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:33<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:33<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:33<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:34<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:34<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:40<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:40<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:40<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:40<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:41<00:36,  3.03it/s] 78%|███████▊  | 391/500 [04:47<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:47<01:31,  1.18it/s] 79%|███████▉  | 395/500 [04:47<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:47<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:47<00:33,  2.99it/s] 80%|████████  | 401/500 [04:54<01:57,  1.19s/it] 81%|████████  | 403/500 [04:54<01:22,  1.17it/s] 81%|████████  | 405/500 [04:54<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:54<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:54<00:30,  2.98it/s] 82%|████████▏ | 411/500 [05:01<01:45,  1.19s/it]Valid Loss:  0.0015698601491749287
Epoch:  344  	Training Loss: 0.0017731004627421498
Test Loss:  0.0013080199714750051
Valid Loss:  0.0015674640890210867
Epoch:  345  	Training Loss: 0.0017702210461720824
Test Loss:  0.0013062384678050876
Valid Loss:  0.0015655311290174723
Epoch:  346  	Training Loss: 0.0017676370916888118
Test Loss:  0.0013047757092863321
Valid Loss:  0.0015639737248420715
Epoch:  347  	Training Loss: 0.001765458146110177
Test Loss:  0.0013039044570177794
Valid Loss:  0.00156269664876163
Epoch:  348  	Training Loss: 0.0017637198325246572
Test Loss:  0.001303156721405685
Valid Loss:  0.0015616288874298334
Epoch:  349  	Training Loss: 0.0017621219158172607
Test Loss:  0.0013022352941334248
Valid Loss:  0.001560764154419303
Epoch:  350  	Training Loss: 0.0017606278415769339
Test Loss:  0.0013018016470596194
Valid Loss:  0.001559810247272253
Epoch:  351  	Training Loss: 0.0017591945361346006
Test Loss:  0.0013012804556638002
Valid Loss:  0.001559054246172309
Epoch:  352  	Training Loss: 0.0017578754341229796
Test Loss:  0.0012980942847207189
Valid Loss:  0.0015551846008747816
Epoch:  353  	Training Loss: 0.0017537125386297703
Test Loss:  0.0012952740071341395
Valid Loss:  0.0015519724693149328
Epoch:  354  	Training Loss: 0.001750164432451129
Test Loss:  0.0012926757335662842
Valid Loss:  0.0015491569647565484
Epoch:  355  	Training Loss: 0.0017468531150370836
Test Loss:  0.001290316809900105
Valid Loss:  0.0015464683528989553
Epoch:  356  	Training Loss: 0.0017438107170164585
Test Loss:  0.0012882654555141926
Valid Loss:  0.0015442835865542293
Epoch:  357  	Training Loss: 0.0017413451569154859
Test Loss:  0.0012864663731306791
Valid Loss:  0.0015424207085743546
Epoch:  358  	Training Loss: 0.0017391298897564411
Test Loss:  0.0012849653139710426
Valid Loss:  0.0015407311730086803
Epoch:  359  	Training Loss: 0.0017371098510921001
Test Loss:  0.001283587422221899
Valid Loss:  0.001539144548587501
Epoch:  360  	Training Loss: 0.0017352476716041565
Test Loss:  0.0012823458528146148
Valid Loss:  0.0015377398813143373
Epoch:  361  	Training Loss: 0.0017335597658529878
Test Loss:  0.0012813173234462738
Valid Loss:  0.0015363609418272972
Epoch:  362  	Training Loss: 0.0017319535836577415
Test Loss:  0.0012804789002984762
Valid Loss:  0.001536310650408268
Epoch:  363  	Training Loss: 0.0017315158620476723
Test Loss:  0.0012803350109606981
Valid Loss:  0.0015360412653535604
Epoch:  364  	Training Loss: 0.0017310958355665207
Test Loss:  0.001280202530324459
Valid Loss:  0.001535765128210187
Epoch:  365  	Training Loss: 0.0017307077068835497
Test Loss:  0.0012800947297364473
Valid Loss:  0.0015354766510426998
Epoch:  366  	Training Loss: 0.001730339601635933
Test Loss:  0.0012799431569874287
Valid Loss:  0.0015351998154073954
Epoch:  367  	Training Loss: 0.0017299926839768887
Test Loss:  0.0012798267416656017
Valid Loss:  0.0015349083114415407
Epoch:  368  	Training Loss: 0.0017296476289629936
Test Loss:  0.0012797582894563675
Valid Loss:  0.0015346149448305368
Epoch:  369  	Training Loss: 0.0017293221317231655
Test Loss:  0.0012796067167073488
Valid Loss:  0.0015343449776992202
Epoch:  370  	Training Loss: 0.0017290401738137007
Test Loss:  0.0012794667854905128
Valid Loss:  0.0015340691898018122
Epoch:  371  	Training Loss: 0.0017287854570895433
Test Loss:  0.0012793943751603365
Valid Loss:  0.0015337811782956123
Epoch:  372  	Training Loss: 0.0017285310896113515
Test Loss:  0.0012787969317287207
Valid Loss:  0.0015299894148483872
Epoch:  373  	Training Loss: 0.001725519192405045
Test Loss:  0.001276661641895771
Valid Loss:  0.0015274719335138798
Epoch:  374  	Training Loss: 0.0017231305828318
Test Loss:  0.0012748560402542353
Valid Loss:  0.0015255881007760763
Epoch:  375  	Training Loss: 0.0017211844678968191
Test Loss:  0.0012731770984828472
Valid Loss:  0.0015244475798681378
Epoch:  376  	Training Loss: 0.0017197884153574705
Test Loss:  0.0012721725506708026
Valid Loss:  0.0015232587466016412
Epoch:  377  	Training Loss: 0.001718444051221013
Test Loss:  0.001271525165066123
Valid Loss:  0.0015220623463392258
Epoch:  378  	Training Loss: 0.0017171204090118408
Test Loss:  0.001270853215828538
Valid Loss:  0.001521119149401784
Epoch:  379  	Training Loss: 0.0017159383278340101
Test Loss:  0.0012700678780674934
Valid Loss:  0.001520397374406457
Epoch:  380  	Training Loss: 0.0017149250488728285
Test Loss:  0.001269458094611764
Valid Loss:  0.001519692363217473
Epoch:  381  	Training Loss: 0.0017140117706730962
Test Loss:  0.0012688753195106983
Valid Loss:  0.0015190521953627467
Epoch:  382  	Training Loss: 0.001713175093755126
Test Loss:  0.0012606148375198245
Valid Loss:  0.0015161875635385513
Epoch:  383  	Training Loss: 0.0017093420028686523
Test Loss:  0.0012569250538945198
Valid Loss:  0.0015134015120565891
Epoch:  384  	Training Loss: 0.0017061815597116947
Test Loss:  0.0012544144410640001
Valid Loss:  0.0015109728556126356
Epoch:  385  	Training Loss: 0.001703646732494235
Test Loss:  0.0012521406169980764
Valid Loss:  0.0015088539803400636
Epoch:  386  	Training Loss: 0.0017014944460242987
Test Loss:  0.0012506525963544846
Valid Loss:  0.0015072321984916925
Epoch:  387  	Training Loss: 0.0016995961777865887
Test Loss:  0.0012492021778598428
Valid Loss:  0.0015056843403726816
Epoch:  388  	Training Loss: 0.0016978058265522122
Test Loss:  0.0012483315076678991
Valid Loss:  0.001504335436038673
Epoch:  389  	Training Loss: 0.0016961712390184402
Test Loss:  0.0012476849369704723
Valid Loss:  0.0015032931696623564
Epoch:  390  	Training Loss: 0.00169481267221272
Test Loss:  0.0012471857480704784
Valid Loss:  0.0015023970045149326
Epoch:  391  	Training Loss: 0.0016936560859903693
Test Loss:  0.0012468146160244942
Valid Loss:  0.001501735532656312
Epoch:  392  	Training Loss: 0.001692666206508875
Test Loss:  0.001246864558197558
Valid Loss:  0.0015002228319644928
Epoch:  393  	Training Loss: 0.0016912801656872034
Test Loss:  0.0012460820144042373
Valid Loss:  0.0014989173505455256
Epoch:  394  	Training Loss: 0.0016899078618735075
Test Loss:  0.0012450842186808586
Valid Loss:  0.0014976592501625419
Epoch:  395  	Training Loss: 0.0016885518562048674
Test Loss:  0.0012440064456313848
Valid Loss:  0.0014964286237955093
Epoch:  396  	Training Loss: 0.0016872298438102007
Test Loss:  0.00124293752014637
Valid Loss:  0.0014951903140172362
Epoch:  397  	Training Loss: 0.001685919938609004
Test Loss:  0.001241869991645217
Valid Loss:  0.0014939564280211926
Epoch:  398  	Training Loss: 0.0016846224898472428
Test Loss:  0.0012408294714987278
Valid Loss:  0.0014927149750292301
Epoch:  399  	Training Loss: 0.0016833276022225618
Test Loss:  0.001239838544279337
Valid Loss:  0.0014914697967469692
Epoch:  400  	Training Loss: 0.00168203457724303
Test Loss:  0.0012388904578983784
Valid Loss:  0.0014902211260050535
Epoch:  401  	Training Loss: 0.0016807522624731064
Test Loss:  0.0012379871914163232
Valid Loss:  0.0014889981830492616
Epoch:  402  	Training Loss: 0.0016794956754893064
Test Loss:  0.0012341758701950312
Valid Loss:  0.0014846109552308917
Epoch:  403  	Training Loss: 0.0016745569882914424
Test Loss:  0.0012306574499234557
Valid Loss:  0.0014810521388426423
Epoch:  404  	Training Loss: 0.0016704130684956908
Test Loss:  0.0012277031783014536
Valid Loss:  0.0014779346529394388
Epoch:  405  	Training Loss: 0.0016667558811604977
Test Loss:  0.0012251207372173667
Valid Loss:  0.00147517048753798
Epoch:  406  	Training Loss: 0.001663430593907833
Test Loss:  0.0012227832339704037
Valid Loss:  0.0014725330984219909
Epoch:  407  	Training Loss: 0.0016602474497631192
Test Loss:  0.0012206238461658359
Valid Loss:  0.0014699979219585657
Epoch:  408  	Training Loss: 0.0016571874730288982
Test Loss:  0.0012182528153061867
Valid Loss:  0.0014677804429084063
Epoch:  409  	Training Loss: 0.0016542839584872127
Test Loss:  0.0012163547798991203
Valid Loss:  0.001465600566007197
Epoch:  410  	Training Loss: 0.001651496859267354
Test Loss:  0.0012143597705289721
Valid Loss:  0.0014634855324402452
Epoch:  411  	Training Loss: 0.0016487796092405915
Test Loss:  0.0012129507958889008
Valid Loss:  0.0014613147359341383
 83%|████████▎ | 413/500 [05:01<01:14,  1.17it/s] 83%|████████▎ | 415/500 [05:01<00:52,  1.62it/s] 83%|████████▎ | 417/500 [05:01<00:37,  2.21it/s] 84%|████████▍ | 419/500 [05:01<00:27,  2.98it/s] 84%|████████▍ | 421/500 [05:07<01:32,  1.18s/it] 85%|████████▍ | 423/500 [05:08<01:04,  1.18it/s] 85%|████████▌ | 425/500 [05:08<00:45,  1.64it/s] 85%|████████▌ | 427/500 [05:08<00:32,  2.24it/s] 86%|████████▌ | 429/500 [05:08<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:14<01:21,  1.19s/it] 87%|████████▋ | 433/500 [05:15<00:57,  1.18it/s] 87%|████████▋ | 435/500 [05:15<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:15<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:15<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:21<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:21<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:21<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:22<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:22<00:17,  3.00it/s] 90%|█████████ | 451/500 [05:28<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:28<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:28<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:28<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:29<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:35<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:35<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:35<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:35<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:35<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:42<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:42<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:42<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:42<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:42<00:07,  2.97it/s]Epoch:  412  	Training Loss: 0.001646130345761776
Test Loss:  0.0012044466566294432
Valid Loss:  0.0014534872025251389
Epoch:  413  	Training Loss: 0.0016380969900637865
Test Loss:  0.001198168145492673
Valid Loss:  0.001445923699066043
Epoch:  414  	Training Loss: 0.001630872953683138
Test Loss:  0.0011918828822672367
Valid Loss:  0.0014391844160854816
Epoch:  415  	Training Loss: 0.0016241990961134434
Test Loss:  0.0011858430225402117
Valid Loss:  0.0014328307006508112
Epoch:  416  	Training Loss: 0.0016177843790501356
Test Loss:  0.0011801632354035974
Valid Loss:  0.0014267490478232503
Epoch:  417  	Training Loss: 0.0016116005135700107
Test Loss:  0.0011747790267691016
Valid Loss:  0.0014210112858563662
Epoch:  418  	Training Loss: 0.0016057072207331657
Test Loss:  0.0011698672315105796
Valid Loss:  0.0014156131073832512
Epoch:  419  	Training Loss: 0.0016001621261239052
Test Loss:  0.0011650081723928452
Valid Loss:  0.0014105553273111582
Epoch:  420  	Training Loss: 0.0015948325162753463
Test Loss:  0.001160354120656848
Valid Loss:  0.0014055324718356133
Epoch:  421  	Training Loss: 0.001589626190252602
Test Loss:  0.001155831036157906
Valid Loss:  0.0014006217243149877
Epoch:  422  	Training Loss: 0.001584542216733098
Test Loss:  0.0011559769045561552
Valid Loss:  0.0013984101824462414
Epoch:  423  	Training Loss: 0.0015830136835575104
Test Loss:  0.001154304132796824
Valid Loss:  0.0013972631422802806
Epoch:  424  	Training Loss: 0.001581875840201974
Test Loss:  0.0011532842181622982
Valid Loss:  0.0013965354301035404
Epoch:  425  	Training Loss: 0.0015810932964086533
Test Loss:  0.0011525112204253674
Valid Loss:  0.0013961568474769592
Epoch:  426  	Training Loss: 0.0015806007431820035
Test Loss:  0.0011522527784109116
Valid Loss:  0.0013956970069557428
Epoch:  427  	Training Loss: 0.001580114709213376
Test Loss:  0.0011520441621541977
Valid Loss:  0.0013952814042568207
Epoch:  428  	Training Loss: 0.0015796408988535404
Test Loss:  0.001151875127106905
Valid Loss:  0.0013949895510450006
Epoch:  429  	Training Loss: 0.001579180359840393
Test Loss:  0.0011517377570271492
Valid Loss:  0.0013948220293968916
Epoch:  430  	Training Loss: 0.0015787661541253328
Test Loss:  0.0011514968937262893
Valid Loss:  0.0013947675470262766
Epoch:  431  	Training Loss: 0.0015784302959218621
Test Loss:  0.0011513406643643975
Valid Loss:  0.001394755789078772
Epoch:  432  	Training Loss: 0.0015781534602865577
Test Loss:  0.0011498380918055773
Valid Loss:  0.0013929172419011593
Epoch:  433  	Training Loss: 0.0015762709081172943
Test Loss:  0.0011483593843877316
Valid Loss:  0.0013912490103393793
Epoch:  434  	Training Loss: 0.0015744983684271574
Test Loss:  0.0011468541342765093
Valid Loss:  0.0013896528398618102
Epoch:  435  	Training Loss: 0.0015727505087852478
Test Loss:  0.0011454785708338022
Valid Loss:  0.0013880720362067223
Epoch:  436  	Training Loss: 0.0015710204606875777
Test Loss:  0.0011441151145845652
Valid Loss:  0.0013865281362086535
Epoch:  437  	Training Loss: 0.0015693026361986995
Test Loss:  0.0011430103331804276
Valid Loss:  0.001384953036904335
Epoch:  438  	Training Loss: 0.0015675921458750963
Test Loss:  0.001141851069405675
Valid Loss:  0.001383493305183947
Epoch:  439  	Training Loss: 0.0015659041237086058
Test Loss:  0.0011405963450670242
Valid Loss:  0.0013820996973663568
Epoch:  440  	Training Loss: 0.0015642414800822735
Test Loss:  0.0011396281188353896
Valid Loss:  0.0013807413633912802
Epoch:  441  	Training Loss: 0.0015626417007297277
Test Loss:  0.001138665247708559
Valid Loss:  0.001379398163408041
Epoch:  442  	Training Loss: 0.001561073586344719
Test Loss:  0.001135302591137588
Valid Loss:  0.0013774961698800325
Epoch:  443  	Training Loss: 0.001558696385473013
Test Loss:  0.0011332755675539374
Valid Loss:  0.0013755534309893847
Epoch:  444  	Training Loss: 0.0015567142982035875
Test Loss:  0.0011316802119836211
Valid Loss:  0.001373836537823081
Epoch:  445  	Training Loss: 0.001554990536533296
Test Loss:  0.0011302030179649591
Valid Loss:  0.001372321741655469
Epoch:  446  	Training Loss: 0.0015533298719674349
Test Loss:  0.0011288654059171677
Valid Loss:  0.001370804151520133
Epoch:  447  	Training Loss: 0.001551702618598938
Test Loss:  0.0011277587618678808
Valid Loss:  0.0013693057699128985
Epoch:  448  	Training Loss: 0.0015501200687140226
Test Loss:  0.0011268913513049483
Valid Loss:  0.0013679357944056392
Epoch:  449  	Training Loss: 0.0015487552154809237
Test Loss:  0.0011261428007856011
Valid Loss:  0.0013668140163645148
Epoch:  450  	Training Loss: 0.0015475820982828736
Test Loss:  0.00112549914047122
Valid Loss:  0.0013658178504556417
Epoch:  451  	Training Loss: 0.0015465274918824434
Test Loss:  0.0011248479131609201
Valid Loss:  0.001364890718832612
Epoch:  452  	Training Loss: 0.0015455330722033978
Test Loss:  0.0011215456761419773
Valid Loss:  0.0013636661460623145
Epoch:  453  	Training Loss: 0.0015436738030984998
Test Loss:  0.0011198963038623333
Valid Loss:  0.0013621574034914374
Epoch:  454  	Training Loss: 0.0015420096460729837
Test Loss:  0.001117958570830524
Valid Loss:  0.001360847381874919
Epoch:  455  	Training Loss: 0.0015404700534418225
Test Loss:  0.0011164022143930197
Valid Loss:  0.0013597797369584441
Epoch:  456  	Training Loss: 0.0015390621265396476
Test Loss:  0.001115249702706933
Valid Loss:  0.001358819892629981
Epoch:  457  	Training Loss: 0.00153786176815629
Test Loss:  0.0011142668081447482
Valid Loss:  0.001357965636998415
Epoch:  458  	Training Loss: 0.001536817755550146
Test Loss:  0.001113387057557702
Valid Loss:  0.001357207540422678
Epoch:  459  	Training Loss: 0.0015359045937657356
Test Loss:  0.001112538855522871
Valid Loss:  0.0013565183617174625
Epoch:  460  	Training Loss: 0.0015350704779848456
Test Loss:  0.00111194618511945
Valid Loss:  0.0013560049701482058
Epoch:  461  	Training Loss: 0.0015342955011874437
Test Loss:  0.0011113709770143032
Valid Loss:  0.001355510437861085
Epoch:  462  	Training Loss: 0.001533528440631926
Test Loss:  0.0011120059061795473
Valid Loss:  0.001354191335849464
Epoch:  463  	Training Loss: 0.0015324107371270657
Test Loss:  0.001111672492697835
Valid Loss:  0.0013534268364310265
Epoch:  464  	Training Loss: 0.0015315561322495341
Test Loss:  0.0011112440843135118
Valid Loss:  0.0013528096023947
Epoch:  465  	Training Loss: 0.0015308045549318194
Test Loss:  0.001110928482376039
Valid Loss:  0.0013523546513170004
Epoch:  466  	Training Loss: 0.0015301320236176252
Test Loss:  0.0011106196325272322
Valid Loss:  0.0013519632630050182
Epoch:  467  	Training Loss: 0.0015294800978153944
Test Loss:  0.0011104055447503924
Valid Loss:  0.001351616927422583
Epoch:  468  	Training Loss: 0.0015288719441741705
Test Loss:  0.0011103460565209389
Valid Loss:  0.0013513632584363222
Epoch:  469  	Training Loss: 0.001528314664028585
Test Loss:  0.0011104142758995295
Valid Loss:  0.0013511688448488712
Epoch:  470  	Training Loss: 0.001527820946648717
Test Loss:  0.0011105139274150133
Valid Loss:  0.0013510221615433693
Epoch:  471  	Training Loss: 0.0015273625031113625
Test Loss:  0.0011106779566034675
Valid Loss:  0.0013509753625839949
Epoch:  472  	Training Loss: 0.0015269559808075428
Test Loss:  0.0011073629138991237
Valid Loss:  0.0013478011824190617
Epoch:  473  	Training Loss: 0.0015234267339110374
Test Loss:  0.0011043822159990668
Valid Loss:  0.0013447736855596304
Epoch:  474  	Training Loss: 0.001520060934126377
Test Loss:  0.0011015894124284387
Valid Loss:  0.0013419769238680601
Epoch:  475  	Training Loss: 0.00151685974560678
Test Loss:  0.0010988907888531685
Valid Loss:  0.0013393386034294963
Epoch:  476  	Training Loss: 0.0015138322487473488
Test Loss:  0.0010963620152324438
Valid Loss:  0.0013368033105507493
Epoch:  477  	Training Loss: 0.0015109400264918804
Test Loss:  0.0010941247455775738
Valid Loss:  0.001334360335022211
Epoch:  478  	Training Loss: 0.0015081329038366675
Test Loss:  0.0010920246131718159
Valid Loss:  0.0013319274876266718
Epoch:  479  	Training Loss: 0.0015053784009069204
Test Loss:  0.0010900907218456268
Valid Loss:  0.0013295006938278675
Epoch:  480  	Training Loss: 0.0015026542823761702
Test Loss:  0.0010882505448535085
 96%|█████████▌| 481/500 [05:49<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:49<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:49<00:09,  1.61it/s] 97%|█████████▋| 487/500 [05:49<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:49<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:56<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:56<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:56<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:56<00:01,  2.20it/s]100%|█████████▉| 499/500 [05:56<00:00,  2.96it/s]100%|██████████| 500/500 [05:56<00:00,  1.40it/s]
Valid Loss:  0.0013270801864564419
Epoch:  481  	Training Loss: 0.0014999575214460492
Test Loss:  0.0010865702060982585
Valid Loss:  0.001324682030826807
Epoch:  482  	Training Loss: 0.0014973292127251625
Test Loss:  0.001083551556803286
Valid Loss:  0.0013230873737484217
Epoch:  483  	Training Loss: 0.0014950418844819069
Test Loss:  0.001081966795027256
Valid Loss:  0.0013211779296398163
Epoch:  484  	Training Loss: 0.0014928068267181516
Test Loss:  0.0010804107878357172
Valid Loss:  0.0013193684862926602
Epoch:  485  	Training Loss: 0.0014906395226716995
Test Loss:  0.0010789124062284827
Valid Loss:  0.001317579299211502
Epoch:  486  	Training Loss: 0.0014885363634675741
Test Loss:  0.0010774043621495366
Valid Loss:  0.0013158146757632494
Epoch:  487  	Training Loss: 0.0014864855911582708
Test Loss:  0.0010760214645415545
Valid Loss:  0.0013140887022018433
Epoch:  488  	Training Loss: 0.0014844886027276516
Test Loss:  0.0010745818726718426
Valid Loss:  0.0013124303659424186
Epoch:  489  	Training Loss: 0.0014825284015387297
Test Loss:  0.0010734536917880177
Valid Loss:  0.0013107554987072945
Epoch:  490  	Training Loss: 0.0014806656399741769
Test Loss:  0.0010721312137320638
Valid Loss:  0.0013091664295643568
Epoch:  491  	Training Loss: 0.0014788599219173193
Test Loss:  0.001070983475074172
Valid Loss:  0.001307531027123332
Epoch:  492  	Training Loss: 0.0014770854031667113
Test Loss:  0.0010688438778743148
Valid Loss:  0.0013042918872088194
Epoch:  493  	Training Loss: 0.001473958371207118
Test Loss:  0.0010661359410732985
Valid Loss:  0.0013016300508752465
Epoch:  494  	Training Loss: 0.0014712077099829912
Test Loss:  0.0010639219544827938
Valid Loss:  0.0012990609975531697
Epoch:  495  	Training Loss: 0.001468559494242072
Test Loss:  0.0010616802610456944
Valid Loss:  0.001296554459258914
Epoch:  496  	Training Loss: 0.0014659917214885354
Test Loss:  0.0010595412459224463
Valid Loss:  0.0012941868044435978
Epoch:  497  	Training Loss: 0.0014634638791903853
Test Loss:  0.0010575603228062391
Valid Loss:  0.0012919149594381452
Epoch:  498  	Training Loss: 0.0014610367361456156
Test Loss:  0.0010556858032941818
Valid Loss:  0.0012897623237222433
Epoch:  499  	Training Loss: 0.0014586575562134385
Test Loss:  0.0010538342176005244
Valid Loss:  0.0012876737164333463
Epoch:  500  	Training Loss: 0.0014563179574906826
Test Loss:  0.0010518975323066115
Valid Loss:  0.001285703619942069
seed is  7
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.55it/s]  1%|          | 4/500 [00:00<00:30, 16.19it/s]  1%|          | 6/500 [00:00<00:30, 16.42it/s]  2%|▏         | 8/500 [00:00<00:29, 16.54it/s]  2%|▏         | 10/500 [00:00<00:29, 16.53it/s]  2%|▏         | 12/500 [00:00<00:29, 16.58it/s]  3%|▎         | 14/500 [00:00<00:29, 16.61it/s]  3%|▎         | 16/500 [00:00<00:29, 16.56it/s]  4%|▎         | 18/500 [00:01<00:29, 16.60it/s]  4%|▍         | 20/500 [00:01<00:29, 16.45it/s]  4%|▍         | 22/500 [00:01<00:29, 16.33it/s]  5%|▍         | 24/500 [00:01<00:28, 16.44it/s]  5%|▌         | 26/500 [00:01<00:28, 16.54it/s]  6%|▌         | 28/500 [00:01<00:28, 16.53it/s]  6%|▌         | 30/500 [00:01<00:29, 16.15it/s]  6%|▋         | 32/500 [00:01<00:28, 16.27it/s]  7%|▋         | 34/500 [00:02<00:28, 16.34it/s]  7%|▋         | 36/500 [00:02<00:28, 16.41it/s]  8%|▊         | 38/500 [00:02<00:28, 16.42it/s]  8%|▊         | 40/500 [00:02<00:30, 15.28it/s]  8%|▊         | 42/500 [00:02<00:29, 15.63it/s]  9%|▉         | 44/500 [00:02<00:28, 15.89it/s]  9%|▉         | 46/500 [00:02<00:28, 16.09it/s] 10%|▉         | 48/500 [00:02<00:27, 16.25it/s] 10%|█         | 50/500 [00:03<00:27, 16.39it/s] 10%|█         | 52/500 [00:03<00:27, 16.45it/s] 11%|█         | 54/500 [00:03<00:27, 16.40it/s] 11%|█         | 56/500 [00:03<00:27, 16.44it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.49it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.48it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.49it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.47it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.56it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.59it/s] 14%|█▍        | 70/500 [00:04<00:25, 16.58it/s] 14%|█▍        | 72/500 [00:04<00:25, 16.56it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.34it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.28it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.21it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.27it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.14it/s] 17%|█▋        | 84/500 [00:05<00:27, 15.35it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.64it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.65it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.91it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.13it/s] 19%|█▉        | 94/500 [00:05<00:25, 16.22it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.27it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.42it/s] 20%|██        | 100/500 [00:06<00:24, 16.48it/s] 20%|██        | 102/500 [00:06<00:24, 16.22it/s] 21%|██        | 104/500 [00:06<00:24, 16.31it/s] 21%|██        | 106/500 [00:06<00:24, 16.33it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.18it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.19it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.32it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.38it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.44it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.31it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.34it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.40it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.50it/s]Epoch:  1  	Training Loss: 0.2657475471496582
Test Loss:  6246.4931640625
Valid Loss:  6262.857421875
Epoch:  2  	Training Loss: 6268.08544921875
Test Loss:  4.3209460069852774e+17
Valid Loss:  4.2828925967427174e+17
Epoch:  3  	Training Loss: 4.2916302782097e+17
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.49it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.52it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.36it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.38it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.41it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.35it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.23it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.19it/s] 28%|██▊       | 142/500 [00:08<00:22, 15.99it/s] 29%|██▉       | 144/500 [00:08<00:22, 16.17it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.32it/s] 30%|██▉       | 148/500 [00:09<00:23, 15.28it/s] 30%|███       | 150/500 [00:09<00:23, 14.94it/s] 30%|███       | 152/500 [00:09<00:22, 15.41it/s] 31%|███       | 154/500 [00:09<00:22, 15.69it/s] 31%|███       | 156/500 [00:09<00:21, 15.90it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.08it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.25it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.33it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.39it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.13it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.17it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.12it/s] 34%|███▍      | 172/500 [00:10<00:21, 15.17it/s] 35%|███▍      | 174/500 [00:10<00:20, 15.53it/s] 35%|███▌      | 176/500 [00:10<00:20, 15.82it/s] 36%|███▌      | 178/500 [00:10<00:20, 16.02it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.22it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.32it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.40it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.44it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.50it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.52it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.41it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.44it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.47it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.54it/s] 40%|████      | 200/500 [00:12<00:18, 16.53it/s] 40%|████      | 202/500 [00:12<00:18, 16.09it/s] 41%|████      | 204/500 [00:12<00:18, 15.84it/s] 41%|████      | 206/500 [00:12<00:18, 15.54it/s] 42%|████▏     | 208/500 [00:12<00:18, 15.72it/s] 42%|████▏     | 210/500 [00:12<00:18, 15.98it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.12it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.24it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.28it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.36it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.43it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.42it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.47it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.49it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.27it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.36it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.24it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.13it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.22it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.33it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.39it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.47it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.48it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.51it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.54it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.43it/s] 50%|█████     | 252/500 [00:15<00:15, 16.36it/s] 51%|█████     | 254/500 [00:15<00:15, 16.30it/s] 51%|█████     | 256/500 [00:15<00:14, 16.38it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.28it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.41it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.46it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.35it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.97it/s] 54%|█████▎    | 268/500 [00:16<00:14, 15.88it/s] 54%|█████▍    | 270/500 [00:16<00:14, 15.71it/s] 54%|█████▍    | 272/500 [00:16<00:14, 15.94it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.15it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.91it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.83it/s] 56%|█████▌    | 280/500 [00:17<00:14, 15.70it/s] 56%|█████▋    | 282/500 [00:17<00:14, 15.56it/s] 57%|█████▋    | 284/500 [00:17<00:13, 15.48it/s] 57%|█████▋    | 286/500 [00:17<00:13, 15.61it/s] 58%|█████▊    | 288/500 [00:17<00:13, 15.96it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.21it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.36it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.43it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.50it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.52it/s] 60%|██████    | 300/500 [00:18<00:12, 16.60it/s] 60%|██████    | 302/500 [00:18<00:11, 16.58it/s] 61%|██████    | 304/500 [00:18<00:11, 16.56it/s] 61%|██████    | 306/500 [00:18<00:11, 16.45it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.44it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.45it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.47it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.47it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.49it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.50it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.50it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.51it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.50it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.30it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.16it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.27it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.36it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.45it/s] 67%|██████▋   | 336/500 [00:20<00:09, 16.47it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.37it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.39it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.50it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.51it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.52it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.51it/s] 70%|███████   | 350/500 [00:21<00:09, 15.38it/s] 70%|███████   | 352/500 [00:21<00:09, 15.71it/s] 71%|███████   | 354/500 [00:21<00:09, 15.93it/s] 71%|███████   | 356/500 [00:21<00:08, 16.10it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.21it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.32it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.42it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.47it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.53it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.36it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.34it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.42it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.51it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.55it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.57it/s] 76%|███████▌  | 380/500 [00:23<00:07, 15.08it/s] 76%|███████▋  | 382/500 [00:23<00:07, 15.05it/s] 77%|███████▋  | 384/500 [00:23<00:07, 15.46it/s] 77%|███████▋  | 386/500 [00:23<00:07, 15.69it/s] 78%|███████▊  | 388/500 [00:23<00:07, 15.91it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.06it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.22it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.30it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.40it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.45it/s] 80%|████████  | 400/500 [00:24<00:06, 16.47it/s] 80%|████████  | 402/500 [00:24<00:05, 16.46it/s] 81%|████████  | 404/500 [00:24<00:06, 14.93it/s] 81%|████████  | 406/500 [00:25<00:06, 14.09it/s] 82%|████████▏ | 408/500 [00:25<00:06, 14.71it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.23it/s] 82%|████████▏ | 412/500 [00:25<00:05, 15.65it/s] 83%|████████▎ | 414/500 [00:25<00:05, 15.94it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.04it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.04it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.18it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.17it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.43it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.03it/s] 86%|████████▌ | 428/500 [00:26<00:04, 15.44it/s] 86%|████████▌ | 430/500 [00:26<00:04, 15.75it/s] 86%|████████▋ | 432/500 [00:26<00:04, 15.68it/s] 87%|████████▋ | 434/500 [00:26<00:04, 15.68it/s] 87%|████████▋ | 436/500 [00:26<00:04, 15.90it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.11it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.28it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.34it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.18it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.33it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.40it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.28it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.35it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.44it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.14it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.23it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.14it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.13it/s] 93%|█████████▎| 464/500 [00:28<00:02, 15.72it/s] 93%|█████████▎| 466/500 [00:28<00:02, 15.94it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.18it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.26it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.33it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.38it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.45it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.47it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.45it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.34it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.02it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.63it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.31it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.20it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.58it/s] 99%|█████████▉| 494/500 [00:30<00:00, 15.39it/s] 99%|█████████▉| 496/500 [00:30<00:00, 15.51it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 15.11it/s]100%|██████████| 500/500 [00:30<00:00, 15.29it/s]100%|██████████| 500/500 [00:30<00:00, 16.14it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  7
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:24,  6.30s/it]  1%|          | 3/500 [00:06<13:57,  1.69s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:50,  2.87it/s]  2%|▏         | 11/500 [00:13<10:52,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:19<09:26,  1.18s/it]  5%|▍         | 23/500 [00:20<06:42,  1.19it/s]  5%|▌         | 25/500 [00:20<04:48,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.25it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:07,  1.17s/it]  7%|▋         | 33/500 [00:26<06:31,  1.19it/s]  7%|▋         | 35/500 [00:26<04:41,  1.65it/s]  7%|▋         | 37/500 [00:27<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:53,  1.16s/it]  9%|▊         | 43/500 [00:33<06:21,  1.20it/s]  9%|▉         | 45/500 [00:33<04:34,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<08:41,  1.16s/it] 11%|█         | 53/500 [00:40<06:13,  1.20it/s] 11%|█         | 55/500 [00:40<04:28,  1.66it/s] 11%|█▏        | 57/500 [00:40<03:16,  2.26it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.03it/s] 12%|█▏        | 61/500 [00:47<08:44,  1.20s/it] 13%|█▎        | 63/500 [00:47<06:15,  1.16it/s] 13%|█▎        | 65/500 [00:47<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:47<03:17,  2.20it/s] 14%|█▍        | 69/500 [00:47<02:26,  2.95it/s] 14%|█▍        | 71/500 [00:53<08:22,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:59,  1.19it/s]Epoch:  1  	Training Loss: 0.2657475471496582
Test Loss:  8.059489250183105
Valid Loss:  7.945023536682129
Epoch:  2  	Training Loss: 7.955745697021484
Test Loss:  0.2739641070365906
Valid Loss:  0.272331178188324
Epoch:  3  	Training Loss: 0.27721208333969116
Test Loss:  0.2736111283302307
Valid Loss:  0.27198439836502075
Epoch:  4  	Training Loss: 0.27685999870300293
Test Loss:  0.2732585668563843
Valid Loss:  0.27163806557655334
Epoch:  5  	Training Loss: 0.2765083909034729
Test Loss:  0.27290645241737366
Valid Loss:  0.27129215002059937
Epoch:  6  	Training Loss: 0.2761571705341339
Test Loss:  0.27255475521087646
Valid Loss:  0.2709466814994812
Epoch:  7  	Training Loss: 0.2758064270019531
Test Loss:  0.2722035050392151
Valid Loss:  0.27060163021087646
Epoch:  8  	Training Loss: 0.27545610070228577
Test Loss:  0.2719954550266266
Valid Loss:  0.2704046964645386
Epoch:  9  	Training Loss: 0.27525609731674194
Test Loss:  0.2719954252243042
Valid Loss:  0.270404577255249
Epoch:  10  	Training Loss: 0.27525603771209717
Test Loss:  0.2719953656196594
Valid Loss:  0.27040451765060425
Epoch:  11  	Training Loss: 0.2752559781074524
Test Loss:  0.27199530601501465
Valid Loss:  0.2704044580459595
Epoch:  12  	Training Loss: 0.2752559185028076
Test Loss:  0.2719952464103699
Valid Loss:  0.2704043388366699
Epoch:  13  	Training Loss: 0.27525579929351807
Test Loss:  0.2719951272010803
Valid Loss:  0.27040424942970276
Epoch:  14  	Training Loss: 0.2752556800842285
Test Loss:  0.27199500799179077
Valid Loss:  0.2704041600227356
Epoch:  15  	Training Loss: 0.27525556087493896
Test Loss:  0.2719949185848236
Valid Loss:  0.27040404081344604
Epoch:  16  	Training Loss: 0.2752554714679718
Test Loss:  0.27199482917785645
Valid Loss:  0.2704039216041565
Epoch:  17  	Training Loss: 0.27525538206100464
Test Loss:  0.2719947099685669
Valid Loss:  0.27040383219718933
Epoch:  18  	Training Loss: 0.2752552628517151
Test Loss:  0.27199462056159973
Valid Loss:  0.27040374279022217
Epoch:  19  	Training Loss: 0.2752551734447479
Test Loss:  0.27199453115463257
Valid Loss:  0.2704036235809326
Epoch:  20  	Training Loss: 0.27525508403778076
Test Loss:  0.271994411945343
Valid Loss:  0.27040350437164307
Epoch:  21  	Training Loss: 0.2752549648284912
Test Loss:  0.27199432253837585
Valid Loss:  0.2704034149646759
Epoch:  22  	Training Loss: 0.27525484561920166
Test Loss:  0.2719942331314087
Valid Loss:  0.27040332555770874
Epoch:  23  	Training Loss: 0.2752547562122345
Test Loss:  0.27199411392211914
Valid Loss:  0.2704032063484192
Epoch:  24  	Training Loss: 0.27525463700294495
Test Loss:  0.2719939947128296
Valid Loss:  0.270403116941452
Epoch:  25  	Training Loss: 0.2752545475959778
Test Loss:  0.2719939351081848
Valid Loss:  0.2704029977321625
Epoch:  26  	Training Loss: 0.27525442838668823
Test Loss:  0.27199381589889526
Valid Loss:  0.2704029083251953
Epoch:  27  	Training Loss: 0.27525433897972107
Test Loss:  0.2719937264919281
Valid Loss:  0.27040278911590576
Epoch:  28  	Training Loss: 0.2752542495727539
Test Loss:  0.27199363708496094
Valid Loss:  0.2704026699066162
Epoch:  29  	Training Loss: 0.27525413036346436
Test Loss:  0.2719935178756714
Valid Loss:  0.27040258049964905
Epoch:  30  	Training Loss: 0.2752540111541748
Test Loss:  0.2719934284687042
Valid Loss:  0.2704024910926819
Epoch:  31  	Training Loss: 0.27525389194488525
Test Loss:  0.2719933092594147
Valid Loss:  0.27040237188339233
Epoch:  32  	Training Loss: 0.2752538025379181
Test Loss:  0.2719932198524475
Valid Loss:  0.27040228247642517
Epoch:  33  	Training Loss: 0.2752537131309509
Test Loss:  0.27199313044548035
Valid Loss:  0.270402193069458
Epoch:  34  	Training Loss: 0.2752535939216614
Test Loss:  0.2719930410385132
Valid Loss:  0.27040207386016846
Epoch:  35  	Training Loss: 0.2752534747123718
Test Loss:  0.27199292182922363
Valid Loss:  0.2704019844532013
Epoch:  36  	Training Loss: 0.27525338530540466
Test Loss:  0.27199283242225647
Valid Loss:  0.27040186524391174
Epoch:  37  	Training Loss: 0.2752532958984375
Test Loss:  0.2719927430152893
Valid Loss:  0.2704017758369446
Epoch:  38  	Training Loss: 0.27525317668914795
Test Loss:  0.27199262380599976
Valid Loss:  0.27040165662765503
Epoch:  39  	Training Loss: 0.2752530872821808
Test Loss:  0.2719925343990326
Valid Loss:  0.2704015374183655
Epoch:  40  	Training Loss: 0.27525296807289124
Test Loss:  0.27199244499206543
Valid Loss:  0.2704014480113983
Epoch:  41  	Training Loss: 0.2752528786659241
Test Loss:  0.2719923257827759
Valid Loss:  0.27040135860443115
Epoch:  42  	Training Loss: 0.2752527594566345
Test Loss:  0.2719922363758087
Valid Loss:  0.2704012393951416
Epoch:  43  	Training Loss: 0.27525264024734497
Test Loss:  0.27199211716651917
Valid Loss:  0.27040112018585205
Epoch:  44  	Training Loss: 0.2752525508403778
Test Loss:  0.271992027759552
Valid Loss:  0.2704010307788849
Epoch:  45  	Training Loss: 0.27525243163108826
Test Loss:  0.27199190855026245
Valid Loss:  0.2704009413719177
Epoch:  46  	Training Loss: 0.2752523422241211
Test Loss:  0.2719918489456177
Valid Loss:  0.2704008221626282
Epoch:  47  	Training Loss: 0.27525222301483154
Test Loss:  0.2719917297363281
Valid Loss:  0.270400732755661
Epoch:  48  	Training Loss: 0.27525216341018677
Test Loss:  0.27199167013168335
Valid Loss:  0.27040061354637146
Epoch:  49  	Training Loss: 0.2752520442008972
Test Loss:  0.2719915211200714
Valid Loss:  0.2704005241394043
Epoch:  50  	Training Loss: 0.27525192499160767
Test Loss:  0.27199143171310425
Valid Loss:  0.27040040493011475
Epoch:  51  	Training Loss: 0.2752518057823181
Test Loss:  0.2719913125038147
Valid Loss:  0.27040034532546997
Epoch:  52  	Training Loss: 0.27525171637535095
Test Loss:  0.27199122309684753
Valid Loss:  0.2704002261161804
Epoch:  53  	Training Loss: 0.2752515971660614
Test Loss:  0.27199113368988037
Valid Loss:  0.27040010690689087
Epoch:  54  	Training Loss: 0.27525150775909424
Test Loss:  0.2719910144805908
Valid Loss:  0.2703999876976013
Epoch:  55  	Training Loss: 0.2752513885498047
Test Loss:  0.27199092507362366
Valid Loss:  0.27039989829063416
Epoch:  56  	Training Loss: 0.2752512991428375
Test Loss:  0.2719908356666565
Valid Loss:  0.270399808883667
Epoch:  57  	Training Loss: 0.275251179933548
Test Loss:  0.27199071645736694
Valid Loss:  0.27039968967437744
Epoch:  58  	Training Loss: 0.2752510905265808
Test Loss:  0.2719906270503998
Valid Loss:  0.2703996002674103
Epoch:  59  	Training Loss: 0.27525097131729126
Test Loss:  0.2719905376434326
Valid Loss:  0.2703994810581207
Epoch:  60  	Training Loss: 0.2752508819103241
Test Loss:  0.27199044823646545
Valid Loss:  0.27039939165115356
Epoch:  61  	Training Loss: 0.27525076270103455
Test Loss:  0.2719903290271759
Valid Loss:  0.2703993022441864
Epoch:  62  	Training Loss: 0.2752506732940674
Test Loss:  0.27199023962020874
Valid Loss:  0.27039918303489685
Epoch:  63  	Training Loss: 0.27525055408477783
Test Loss:  0.2719901204109192
Valid Loss:  0.2703990936279297
Epoch:  64  	Training Loss: 0.27525046467781067
Test Loss:  0.271990031003952
Valid Loss:  0.27039897441864014
Epoch:  65  	Training Loss: 0.2752503454685211
Test Loss:  0.27198994159698486
Valid Loss:  0.27039891481399536
Epoch:  66  	Training Loss: 0.27525025606155396
Test Loss:  0.2719898223876953
Valid Loss:  0.2703987658023834
Epoch:  67  	Training Loss: 0.2752501368522644
Test Loss:  0.27198973298072815
Valid Loss:  0.27039867639541626
Epoch:  68  	Training Loss: 0.27525004744529724
Test Loss:  0.271989643573761
Valid Loss:  0.2703985571861267
Epoch:  69  	Training Loss: 0.2752499282360077
Test Loss:  0.27198952436447144
Valid Loss:  0.27039846777915955
Epoch:  70  	Training Loss: 0.27524980902671814
Test Loss:  0.2719894051551819
Valid Loss:  0.2703983783721924
Epoch:  71  	Training Loss: 0.275249719619751
Test Loss:  0.2719893455505371
Valid Loss:  0.27039825916290283
Epoch:  72  	Training Loss: 0.2752496004104614
Test Loss:  0.27198922634124756
Valid Loss:  0.2703981399536133
Epoch:  73  	Training Loss: 0.2752494812011719
Test Loss:  0.2719891667366028
Valid Loss:  0.27039802074432373
Epoch:  74  	Training Loss: 0.2752494215965271
Test Loss:  0.27198904752731323
 15%|█▌        | 75/500 [00:54<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:20,  3.01it/s] 16%|█▌        | 81/500 [01:00<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:01<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:07<07:57,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:07<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:07<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:07<02:12,  3.03it/s] 20%|██        | 101/500 [01:14<07:46,  1.17s/it] 21%|██        | 103/500 [01:14<05:33,  1.19it/s] 21%|██        | 105/500 [01:14<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.01it/s] 22%|██▏       | 111/500 [01:20<07:30,  1.16s/it] 23%|██▎       | 113/500 [01:21<05:22,  1.20it/s] 23%|██▎       | 115/500 [01:21<03:51,  1.66it/s] 23%|██▎       | 117/500 [01:21<02:49,  2.26it/s] 24%|██▍       | 119/500 [01:21<02:05,  3.04it/s] 24%|██▍       | 121/500 [01:27<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:27<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.25it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:34<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:34<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:34<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:34<02:42,  2.24it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.01it/s] 28%|██▊       | 141/500 [01:41<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:41<05:02,  1.18it/s] 29%|██▉       | 145/500 [01:41<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:41<02:38,  2.23it/s]Valid Loss:  0.27039793133735657
Epoch:  75  	Training Loss: 0.27524930238723755
Test Loss:  0.2719889283180237
Valid Loss:  0.2703978419303894
Epoch:  76  	Training Loss: 0.275249183177948
Test Loss:  0.2719888389110565
Valid Loss:  0.27039772272109985
Epoch:  77  	Training Loss: 0.2752491235733032
Test Loss:  0.27198874950408936
Valid Loss:  0.2703976333141327
Epoch:  78  	Training Loss: 0.2752489745616913
Test Loss:  0.2719886600971222
Valid Loss:  0.2703975439071655
Epoch:  79  	Training Loss: 0.2752488851547241
Test Loss:  0.27198854088783264
Valid Loss:  0.270397424697876
Epoch:  80  	Training Loss: 0.27524876594543457
Test Loss:  0.2719884514808655
Valid Loss:  0.2703973054885864
Epoch:  81  	Training Loss: 0.275248646736145
Test Loss:  0.2719883322715759
Valid Loss:  0.27039721608161926
Epoch:  82  	Training Loss: 0.27524855732917786
Test Loss:  0.2719882130622864
Valid Loss:  0.2703971266746521
Epoch:  83  	Training Loss: 0.2752484679222107
Test Loss:  0.2719881534576416
Valid Loss:  0.27039700746536255
Epoch:  84  	Training Loss: 0.27524834871292114
Test Loss:  0.27198803424835205
Valid Loss:  0.270396888256073
Epoch:  85  	Training Loss: 0.275248259305954
Test Loss:  0.2719879448413849
Valid Loss:  0.27039679884910583
Epoch:  86  	Training Loss: 0.27524814009666443
Test Loss:  0.27198782563209534
Valid Loss:  0.27039670944213867
Epoch:  87  	Training Loss: 0.27524805068969727
Test Loss:  0.2719877362251282
Valid Loss:  0.2703965902328491
Epoch:  88  	Training Loss: 0.2752479314804077
Test Loss:  0.2719876170158386
Valid Loss:  0.27039650082588196
Epoch:  89  	Training Loss: 0.27524781227111816
Test Loss:  0.27198752760887146
Valid Loss:  0.2703963816165924
Epoch:  90  	Training Loss: 0.275247722864151
Test Loss:  0.2719874382019043
Valid Loss:  0.27039629220962524
Epoch:  91  	Training Loss: 0.27524760365486145
Test Loss:  0.27198731899261475
Valid Loss:  0.2703961730003357
Epoch:  92  	Training Loss: 0.2752475142478943
Test Loss:  0.2719872295856476
Valid Loss:  0.27039608359336853
Epoch:  93  	Training Loss: 0.27524739503860474
Test Loss:  0.2719871401786804
Valid Loss:  0.270395964384079
Epoch:  94  	Training Loss: 0.27524733543395996
Test Loss:  0.27198702096939087
Valid Loss:  0.2703958749771118
Epoch:  95  	Training Loss: 0.2752472162246704
Test Loss:  0.2719869315624237
Valid Loss:  0.27039578557014465
Epoch:  96  	Training Loss: 0.27524709701538086
Test Loss:  0.27198684215545654
Valid Loss:  0.2703956663608551
Epoch:  97  	Training Loss: 0.2752469778060913
Test Loss:  0.271986722946167
Valid Loss:  0.27039557695388794
Epoch:  98  	Training Loss: 0.27524685859680176
Test Loss:  0.2719866633415222
Valid Loss:  0.2703954577445984
Epoch:  99  	Training Loss: 0.275246798992157
Test Loss:  0.27198654413223267
Valid Loss:  0.2703953683376312
Epoch:  100  	Training Loss: 0.27524667978286743
Test Loss:  0.2719864249229431
Valid Loss:  0.2703952491283417
Epoch:  101  	Training Loss: 0.2752465605735779
Test Loss:  0.27198633551597595
Valid Loss:  0.2703951597213745
Epoch:  102  	Training Loss: 0.2752464711666107
Test Loss:  0.2719862461090088
Valid Loss:  0.27039504051208496
Epoch:  103  	Training Loss: 0.27524638175964355
Test Loss:  0.2719861567020416
Valid Loss:  0.2703949213027954
Epoch:  104  	Training Loss: 0.275246262550354
Test Loss:  0.2719860374927521
Valid Loss:  0.27039483189582825
Epoch:  105  	Training Loss: 0.27524614334106445
Test Loss:  0.2719859182834625
Valid Loss:  0.2703947424888611
Epoch:  106  	Training Loss: 0.2752460241317749
Test Loss:  0.27198585867881775
Valid Loss:  0.27039462327957153
Epoch:  107  	Training Loss: 0.27524593472480774
Test Loss:  0.2719857394695282
Valid Loss:  0.270394504070282
Epoch:  108  	Training Loss: 0.2752458453178406
Test Loss:  0.27198565006256104
Valid Loss:  0.2703944146633148
Epoch:  109  	Training Loss: 0.275245726108551
Test Loss:  0.2719855308532715
Valid Loss:  0.27039432525634766
Epoch:  110  	Training Loss: 0.27524563670158386
Test Loss:  0.2719854414463043
Valid Loss:  0.2703942060470581
Epoch:  111  	Training Loss: 0.2752455174922943
Test Loss:  0.27198535203933716
Valid Loss:  0.27039411664009094
Epoch:  112  	Training Loss: 0.27524542808532715
Test Loss:  0.2719852328300476
Valid Loss:  0.2703940272331238
Epoch:  113  	Training Loss: 0.2752453088760376
Test Loss:  0.27198514342308044
Valid Loss:  0.27039390802383423
Epoch:  114  	Training Loss: 0.27524518966674805
Test Loss:  0.2719850540161133
Valid Loss:  0.2703937888145447
Epoch:  115  	Training Loss: 0.2752451002597809
Test Loss:  0.27198493480682373
Valid Loss:  0.2703937292098999
Epoch:  116  	Training Loss: 0.2752450108528137
Test Loss:  0.27198484539985657
Valid Loss:  0.27039358019828796
Epoch:  117  	Training Loss: 0.27524489164352417
Test Loss:  0.2719847559928894
Valid Loss:  0.2703934907913208
Epoch:  118  	Training Loss: 0.275244802236557
Test Loss:  0.27198463678359985
Valid Loss:  0.27039337158203125
Epoch:  119  	Training Loss: 0.27524468302726746
Test Loss:  0.2719845473766327
Valid Loss:  0.2703932821750641
Epoch:  120  	Training Loss: 0.2752445936203003
Test Loss:  0.2719844579696655
Valid Loss:  0.27039316296577454
Epoch:  121  	Training Loss: 0.27524447441101074
Test Loss:  0.271984338760376
Valid Loss:  0.2703930735588074
Epoch:  122  	Training Loss: 0.2752443552017212
Test Loss:  0.2719842493534088
Valid Loss:  0.2703929841518402
Epoch:  123  	Training Loss: 0.27524426579475403
Test Loss:  0.27198415994644165
Valid Loss:  0.27039286494255066
Epoch:  124  	Training Loss: 0.2752441465854645
Test Loss:  0.2719840407371521
Valid Loss:  0.2703927755355835
Epoch:  125  	Training Loss: 0.2752440571784973
Test Loss:  0.27198392152786255
Valid Loss:  0.27039265632629395
Epoch:  126  	Training Loss: 0.27524393796920776
Test Loss:  0.2719838619232178
Valid Loss:  0.2703925371170044
Epoch:  127  	Training Loss: 0.2752438485622406
Test Loss:  0.2719837427139282
Valid Loss:  0.27039244771003723
Epoch:  128  	Training Loss: 0.27524375915527344
Test Loss:  0.27198362350463867
Valid Loss:  0.27039235830307007
Epoch:  129  	Training Loss: 0.2752436399459839
Test Loss:  0.2719835340976715
Valid Loss:  0.2703922390937805
Epoch:  130  	Training Loss: 0.27524352073669434
Test Loss:  0.27198344469070435
Valid Loss:  0.27039211988449097
Epoch:  131  	Training Loss: 0.2752434015274048
Test Loss:  0.2719833254814148
Valid Loss:  0.2703920602798462
Epoch:  132  	Training Loss: 0.2752433121204376
Test Loss:  0.27198326587677
Valid Loss:  0.27039194107055664
Epoch:  133  	Training Loss: 0.27524319291114807
Test Loss:  0.27198314666748047
Valid Loss:  0.2703918516635895
Epoch:  134  	Training Loss: 0.2752431035041809
Test Loss:  0.2719830274581909
Valid Loss:  0.27039170265197754
Epoch:  135  	Training Loss: 0.27524301409721375
Test Loss:  0.27198296785354614
Valid Loss:  0.2703916132450104
Epoch:  136  	Training Loss: 0.2752429246902466
Test Loss:  0.2719828486442566
Valid Loss:  0.2703915238380432
Epoch:  137  	Training Loss: 0.27524277567863464
Test Loss:  0.27198275923728943
Valid Loss:  0.27039140462875366
Epoch:  138  	Training Loss: 0.2752426862716675
Test Loss:  0.2719826400279999
Valid Loss:  0.2703912854194641
Epoch:  139  	Training Loss: 0.27524256706237793
Test Loss:  0.2719825506210327
Valid Loss:  0.27039122581481934
Epoch:  140  	Training Loss: 0.2752424478530884
Test Loss:  0.27198243141174316
Valid Loss:  0.2703911066055298
Epoch:  141  	Training Loss: 0.2752423584461212
Test Loss:  0.2719823718070984
Valid Loss:  0.27039098739624023
Epoch:  142  	Training Loss: 0.27524226903915405
Test Loss:  0.27198225259780884
Valid Loss:  0.27039089798927307
Epoch:  143  	Training Loss: 0.2752421498298645
Test Loss:  0.2719821631908417
Valid Loss:  0.2703908085823059
Epoch:  144  	Training Loss: 0.27524206042289734
Test Loss:  0.27198201417922974
Valid Loss:  0.27039068937301636
Epoch:  145  	Training Loss: 0.2752419710159302
Test Loss:  0.27198195457458496
Valid Loss:  0.2703905701637268
Epoch:  146  	Training Loss: 0.2752418518066406
Test Loss:  0.2719818353652954
Valid Loss:  0.27039048075675964
Epoch:  147  	Training Loss: 0.2752417325973511
Test Loss:  0.27198174595832825
Valid Loss:  0.2703903913497925
 30%|██▉       | 149/500 [01:41<01:56,  3.00it/s] 30%|███       | 151/500 [01:48<06:50,  1.18s/it] 31%|███       | 153/500 [01:48<04:53,  1.18it/s] 31%|███       | 155/500 [01:48<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:48<02:33,  2.23it/s] 32%|███▏      | 159/500 [01:48<01:53,  3.01it/s] 32%|███▏      | 161/500 [01:54<06:35,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:22,  1.65it/s] 33%|███▎      | 167/500 [01:55<02:27,  2.25it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.03it/s] 34%|███▍      | 171/500 [02:01<06:24,  1.17s/it] 35%|███▍      | 173/500 [02:01<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:17,  1.65it/s] 35%|███▌      | 177/500 [02:02<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.02it/s] 36%|███▌      | 181/500 [02:08<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:08<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:08<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:09<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:15<06:00,  1.17s/it] 39%|███▊      | 193/500 [02:15<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:15<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:15<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:15<01:39,  3.03it/s] 40%|████      | 201/500 [02:22<05:49,  1.17s/it] 41%|████      | 203/500 [02:22<04:09,  1.19it/s] 41%|████      | 205/500 [02:22<02:58,  1.65it/s] 41%|████▏     | 207/500 [02:22<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.02it/s] 42%|████▏     | 211/500 [02:28<05:35,  1.16s/it] 43%|████▎     | 213/500 [02:28<03:59,  1.20it/s] 43%|████▎     | 215/500 [02:29<02:51,  1.66it/s] 43%|████▎     | 217/500 [02:29<02:04,  2.26it/s] 44%|████▍     | 219/500 [02:29<01:32,  3.05it/s]Epoch:  148  	Training Loss: 0.2752416431903839
Test Loss:  0.2719816565513611
Valid Loss:  0.27039027214050293
Epoch:  149  	Training Loss: 0.27524155378341675
Test Loss:  0.27198153734207153
Valid Loss:  0.27039018273353577
Epoch:  150  	Training Loss: 0.2752414345741272
Test Loss:  0.27198144793510437
Valid Loss:  0.2703900933265686
Epoch:  151  	Training Loss: 0.27524131536483765
Test Loss:  0.2719813585281372
Valid Loss:  0.27038997411727905
Epoch:  152  	Training Loss: 0.2752411961555481
Test Loss:  0.27198123931884766
Valid Loss:  0.2703898847103119
Epoch:  153  	Training Loss: 0.27524110674858093
Test Loss:  0.2719811499118805
Valid Loss:  0.2703897953033447
Epoch:  154  	Training Loss: 0.27524101734161377
Test Loss:  0.27198103070259094
Valid Loss:  0.2703896760940552
Epoch:  155  	Training Loss: 0.2752408981323242
Test Loss:  0.2719809412956238
Valid Loss:  0.2703895568847656
Epoch:  156  	Training Loss: 0.27524077892303467
Test Loss:  0.2719808518886566
Valid Loss:  0.2703894376754761
Epoch:  157  	Training Loss: 0.2752406895160675
Test Loss:  0.27198076248168945
Valid Loss:  0.2703893482685089
Epoch:  158  	Training Loss: 0.27524057030677795
Test Loss:  0.2719806432723999
Valid Loss:  0.27038925886154175
Epoch:  159  	Training Loss: 0.2752404808998108
Test Loss:  0.27198055386543274
Valid Loss:  0.2703891396522522
Epoch:  160  	Training Loss: 0.27524036169052124
Test Loss:  0.2719804644584656
Valid Loss:  0.27038902044296265
Epoch:  161  	Training Loss: 0.2752402722835541
Test Loss:  0.271980345249176
Valid Loss:  0.2703889310359955
Epoch:  162  	Training Loss: 0.2752401530742645
Test Loss:  0.27198025584220886
Valid Loss:  0.2703888416290283
Epoch:  163  	Training Loss: 0.27524006366729736
Test Loss:  0.2719801664352417
Valid Loss:  0.27038872241973877
Epoch:  164  	Training Loss: 0.2752399444580078
Test Loss:  0.27198004722595215
Valid Loss:  0.2703886032104492
Epoch:  165  	Training Loss: 0.27523982524871826
Test Loss:  0.271979957818985
Valid Loss:  0.27038851380348206
Epoch:  166  	Training Loss: 0.2752397358417511
Test Loss:  0.2719798684120178
Valid Loss:  0.2703884243965149
Epoch:  167  	Training Loss: 0.27523964643478394
Test Loss:  0.27197974920272827
Valid Loss:  0.27038830518722534
Epoch:  168  	Training Loss: 0.2752395570278168
Test Loss:  0.2719796299934387
Valid Loss:  0.2703881859779358
Epoch:  169  	Training Loss: 0.27523940801620483
Test Loss:  0.27197957038879395
Valid Loss:  0.270388126373291
Epoch:  170  	Training Loss: 0.27523931860923767
Test Loss:  0.2719794511795044
Valid Loss:  0.27038800716400146
Epoch:  171  	Training Loss: 0.2752392292022705
Test Loss:  0.27197936177253723
Valid Loss:  0.2703878879547119
Epoch:  172  	Training Loss: 0.27523910999298096
Test Loss:  0.27197927236557007
Valid Loss:  0.27038782835006714
Epoch:  173  	Training Loss: 0.2752390205860138
Test Loss:  0.2719791829586029
Valid Loss:  0.2703877091407776
Epoch:  174  	Training Loss: 0.27523893117904663
Test Loss:  0.27197906374931335
Valid Loss:  0.27038758993148804
Epoch:  175  	Training Loss: 0.2752388119697571
Test Loss:  0.2719789743423462
Valid Loss:  0.2703874707221985
Epoch:  176  	Training Loss: 0.27523869276046753
Test Loss:  0.27197885513305664
Valid Loss:  0.2703874111175537
Epoch:  177  	Training Loss: 0.27523860335350037
Test Loss:  0.2719787359237671
Valid Loss:  0.27038729190826416
Epoch:  178  	Training Loss: 0.2752385139465332
Test Loss:  0.2719786465167999
Valid Loss:  0.2703871726989746
Epoch:  179  	Training Loss: 0.27523839473724365
Test Loss:  0.27197855710983276
Valid Loss:  0.27038705348968506
Epoch:  180  	Training Loss: 0.2752382755279541
Test Loss:  0.2719784379005432
Valid Loss:  0.2703869342803955
Epoch:  181  	Training Loss: 0.27523818612098694
Test Loss:  0.27197834849357605
Valid Loss:  0.27038687467575073
Epoch:  182  	Training Loss: 0.2752380669116974
Test Loss:  0.2719782590866089
Valid Loss:  0.2703867554664612
Epoch:  183  	Training Loss: 0.2752379775047302
Test Loss:  0.27197813987731934
Valid Loss:  0.270386666059494
Epoch:  184  	Training Loss: 0.2752378582954407
Test Loss:  0.2719780504703522
Valid Loss:  0.27038654685020447
Epoch:  185  	Training Loss: 0.2752377390861511
Test Loss:  0.271977961063385
Valid Loss:  0.2703864574432373
Epoch:  186  	Training Loss: 0.27523764967918396
Test Loss:  0.27197784185409546
Valid Loss:  0.27038633823394775
Epoch:  187  	Training Loss: 0.2752375304698944
Test Loss:  0.2719777524471283
Valid Loss:  0.2703862488269806
Epoch:  188  	Training Loss: 0.27523744106292725
Test Loss:  0.27197766304016113
Valid Loss:  0.2703861594200134
Epoch:  189  	Training Loss: 0.2752373218536377
Test Loss:  0.2719775438308716
Valid Loss:  0.2703860402107239
Epoch:  190  	Training Loss: 0.2752372622489929
Test Loss:  0.27197742462158203
Valid Loss:  0.2703859210014343
Epoch:  191  	Training Loss: 0.27523714303970337
Test Loss:  0.27197736501693726
Valid Loss:  0.2703858017921448
Epoch:  192  	Training Loss: 0.2752370238304138
Test Loss:  0.2719772458076477
Valid Loss:  0.2703857421875
Epoch:  193  	Training Loss: 0.27523693442344666
Test Loss:  0.27197715640068054
Valid Loss:  0.27038562297821045
Epoch:  194  	Training Loss: 0.2752368450164795
Test Loss:  0.2719770669937134
Valid Loss:  0.2703855335712433
Epoch:  195  	Training Loss: 0.27523669600486755
Test Loss:  0.27197694778442383
Valid Loss:  0.2703854441642761
Epoch:  196  	Training Loss: 0.2752366065979004
Test Loss:  0.27197685837745667
Valid Loss:  0.2703853249549866
Epoch:  197  	Training Loss: 0.27523648738861084
Test Loss:  0.2719767689704895
Valid Loss:  0.270385205745697
Epoch:  198  	Training Loss: 0.2752363681793213
Test Loss:  0.27197664976119995
Valid Loss:  0.27038508653640747
Epoch:  199  	Training Loss: 0.2752363085746765
Test Loss:  0.2719765901565552
Valid Loss:  0.2703849971294403
Epoch:  200  	Training Loss: 0.27523618936538696
Test Loss:  0.2719764709472656
Valid Loss:  0.27038490772247314
Epoch:  201  	Training Loss: 0.2752360701560974
Test Loss:  0.2719763517379761
Valid Loss:  0.270384818315506
Epoch:  202  	Training Loss: 0.27523598074913025
Test Loss:  0.2719762325286865
Valid Loss:  0.27038466930389404
Epoch:  203  	Training Loss: 0.2752358615398407
Test Loss:  0.27197614312171936
Valid Loss:  0.27038460969924927
Epoch:  204  	Training Loss: 0.27523577213287354
Test Loss:  0.2719760537147522
Valid Loss:  0.2703844904899597
Epoch:  205  	Training Loss: 0.275235652923584
Test Loss:  0.27197593450546265
Valid Loss:  0.27038437128067017
Epoch:  206  	Training Loss: 0.27523553371429443
Test Loss:  0.27197587490081787
Valid Loss:  0.270384281873703
Epoch:  207  	Training Loss: 0.27523544430732727
Test Loss:  0.2719757556915283
Valid Loss:  0.27038419246673584
Epoch:  208  	Training Loss: 0.2752353549003601
Test Loss:  0.27197563648223877
Valid Loss:  0.2703840732574463
Epoch:  209  	Training Loss: 0.27523523569107056
Test Loss:  0.271975576877594
Valid Loss:  0.27038395404815674
Epoch:  210  	Training Loss: 0.2752351462841034
Test Loss:  0.27197545766830444
Valid Loss:  0.2703838646411896
Epoch:  211  	Training Loss: 0.27523502707481384
Test Loss:  0.2719753682613373
Valid Loss:  0.2703837752342224
Epoch:  212  	Training Loss: 0.2752349078655243
Test Loss:  0.27197524905204773
Valid Loss:  0.27038365602493286
Epoch:  213  	Training Loss: 0.27523481845855713
Test Loss:  0.27197515964508057
Valid Loss:  0.2703835368156433
Epoch:  214  	Training Loss: 0.2752346992492676
Test Loss:  0.271975040435791
Valid Loss:  0.27038344740867615
Epoch:  215  	Training Loss: 0.2752346098423004
Test Loss:  0.27197498083114624
Valid Loss:  0.270383358001709
Epoch:  216  	Training Loss: 0.27523449063301086
Test Loss:  0.2719748616218567
Valid Loss:  0.27038323879241943
Epoch:  217  	Training Loss: 0.2752344012260437
Test Loss:  0.2719747722148895
Valid Loss:  0.27038314938545227
Epoch:  218  	Training Loss: 0.27523428201675415
Test Loss:  0.2719746530056
Valid Loss:  0.2703830599784851
Epoch:  219  	Training Loss: 0.2752341628074646
Test Loss:  0.2719745635986328
Valid Loss:  0.27038294076919556
Epoch:  220  	Training Loss: 0.2752341032028198
Test Loss:  0.27197447419166565
Valid Loss:  0.270382821559906
 44%|████▍     | 221/500 [02:35<05:24,  1.16s/it] 45%|████▍     | 223/500 [02:35<03:51,  1.20it/s] 45%|████▌     | 225/500 [02:35<02:46,  1.66it/s] 45%|████▌     | 227/500 [02:35<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:36<01:29,  3.03it/s] 46%|████▌     | 231/500 [02:42<05:12,  1.16s/it] 47%|████▋     | 233/500 [02:42<03:42,  1.20it/s] 47%|████▋     | 235/500 [02:42<02:39,  1.66it/s] 47%|████▋     | 237/500 [02:42<01:56,  2.26it/s] 48%|████▊     | 239/500 [02:42<01:25,  3.04it/s] 48%|████▊     | 241/500 [02:49<05:00,  1.16s/it] 49%|████▊     | 243/500 [02:49<03:33,  1.20it/s] 49%|████▉     | 245/500 [02:49<02:33,  1.66it/s] 49%|████▉     | 247/500 [02:49<01:51,  2.27it/s] 50%|████▉     | 249/500 [02:49<01:22,  3.05it/s] 50%|█████     | 251/500 [02:55<04:47,  1.16s/it] 51%|█████     | 253/500 [02:55<03:25,  1.20it/s] 51%|█████     | 255/500 [02:56<02:27,  1.66it/s] 51%|█████▏    | 257/500 [02:56<01:47,  2.27it/s] 52%|█████▏    | 259/500 [02:56<01:19,  3.05it/s] 52%|█████▏    | 261/500 [03:02<04:36,  1.16s/it] 53%|█████▎    | 263/500 [03:02<03:16,  1.21it/s] 53%|█████▎    | 265/500 [03:02<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:02<01:42,  2.27it/s] 54%|█████▍    | 269/500 [03:02<01:15,  3.05it/s] 54%|█████▍    | 271/500 [03:09<04:26,  1.16s/it] 55%|█████▍    | 273/500 [03:09<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:09<02:15,  1.65it/s] 55%|█████▌    | 277/500 [03:09<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:09<01:12,  3.03it/s] 56%|█████▌    | 281/500 [03:15<04:14,  1.16s/it] 57%|█████▋    | 283/500 [03:16<03:00,  1.20it/s] 57%|█████▋    | 285/500 [03:16<02:09,  1.66it/s] 57%|█████▋    | 287/500 [03:16<01:34,  2.27it/s] 58%|█████▊    | 289/500 [03:16<01:09,  3.04it/s] 58%|█████▊    | 291/500 [03:22<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:22<02:53,  1.19it/s]Epoch:  221  	Training Loss: 0.2752339839935303
Test Loss:  0.2719743549823761
Valid Loss:  0.27038270235061646
Epoch:  222  	Training Loss: 0.2752338647842407
Test Loss:  0.27197426557540894
Valid Loss:  0.2703826427459717
Epoch:  223  	Training Loss: 0.27523377537727356
Test Loss:  0.2719741761684418
Valid Loss:  0.27038252353668213
Epoch:  224  	Training Loss: 0.2752336859703064
Test Loss:  0.2719740867614746
Valid Loss:  0.2703824043273926
Epoch:  225  	Training Loss: 0.27523356676101685
Test Loss:  0.27197396755218506
Valid Loss:  0.2703823149204254
Epoch:  226  	Training Loss: 0.2752334475517273
Test Loss:  0.2719738483428955
Valid Loss:  0.27038222551345825
Epoch:  227  	Training Loss: 0.27523332834243774
Test Loss:  0.27197375893592834
Valid Loss:  0.2703821063041687
Epoch:  228  	Training Loss: 0.2752332389354706
Test Loss:  0.2719736695289612
Valid Loss:  0.27038201689720154
Epoch:  229  	Training Loss: 0.27523311972618103
Test Loss:  0.27197355031967163
Valid Loss:  0.270381897687912
Epoch:  230  	Training Loss: 0.27523303031921387
Test Loss:  0.27197346091270447
Valid Loss:  0.2703818082809448
Epoch:  231  	Training Loss: 0.2752329409122467
Test Loss:  0.2719734013080597
Valid Loss:  0.2703816890716553
Epoch:  232  	Training Loss: 0.27523285150527954
Test Loss:  0.27197325229644775
Valid Loss:  0.2703815698623657
Epoch:  233  	Training Loss: 0.27523273229599
Test Loss:  0.271973192691803
Valid Loss:  0.27038151025772095
Epoch:  234  	Training Loss: 0.27523261308670044
Test Loss:  0.2719730734825134
Valid Loss:  0.2703813910484314
Epoch:  235  	Training Loss: 0.2752324938774109
Test Loss:  0.2719729542732239
Valid Loss:  0.27038127183914185
Epoch:  236  	Training Loss: 0.2752324342727661
Test Loss:  0.2719728648662567
Valid Loss:  0.2703811526298523
Epoch:  237  	Training Loss: 0.27523231506347656
Test Loss:  0.27197277545928955
Valid Loss:  0.27038106322288513
Epoch:  238  	Training Loss: 0.275232195854187
Test Loss:  0.27197265625
Valid Loss:  0.27038097381591797
Epoch:  239  	Training Loss: 0.27523207664489746
Test Loss:  0.27197256684303284
Valid Loss:  0.2703808546066284
Epoch:  240  	Training Loss: 0.2752319574356079
Test Loss:  0.2719724774360657
Valid Loss:  0.27038076519966125
Epoch:  241  	Training Loss: 0.27523186802864075
Test Loss:  0.2719723582267761
Valid Loss:  0.2703806757926941
Epoch:  242  	Training Loss: 0.2752317786216736
Test Loss:  0.27197226881980896
Valid Loss:  0.27038055658340454
Epoch:  243  	Training Loss: 0.2752316892147064
Test Loss:  0.2719721794128418
Valid Loss:  0.2703804671764374
Epoch:  244  	Training Loss: 0.27523157000541687
Test Loss:  0.27197206020355225
Valid Loss:  0.2703803479671478
Epoch:  245  	Training Loss: 0.2752314805984497
Test Loss:  0.2719719409942627
Valid Loss:  0.2703802287578583
Epoch:  246  	Training Loss: 0.27523136138916016
Test Loss:  0.2719718813896179
Valid Loss:  0.2703801393508911
Epoch:  247  	Training Loss: 0.2752312421798706
Test Loss:  0.27197176218032837
Valid Loss:  0.27038002014160156
Epoch:  248  	Training Loss: 0.27523112297058105
Test Loss:  0.2719717025756836
Valid Loss:  0.2703799605369568
Epoch:  249  	Training Loss: 0.2752310335636139
Test Loss:  0.27197158336639404
Valid Loss:  0.27037984132766724
Epoch:  250  	Training Loss: 0.27523091435432434
Test Loss:  0.2719714641571045
Valid Loss:  0.2703797221183777
Epoch:  251  	Training Loss: 0.2752308249473572
Test Loss:  0.27197137475013733
Valid Loss:  0.27037960290908813
Epoch:  252  	Training Loss: 0.27523073554039
Test Loss:  0.27197128534317017
Valid Loss:  0.27037951350212097
Epoch:  253  	Training Loss: 0.27523061633110046
Test Loss:  0.2719711661338806
Valid Loss:  0.2703794240951538
Epoch:  254  	Training Loss: 0.2752305269241333
Test Loss:  0.27197104692459106
Valid Loss:  0.27037930488586426
Epoch:  255  	Training Loss: 0.27523040771484375
Test Loss:  0.2719709873199463
Valid Loss:  0.2703792452812195
Epoch:  256  	Training Loss: 0.2752302885055542
Test Loss:  0.27197086811065674
Valid Loss:  0.27037912607192993
Epoch:  257  	Training Loss: 0.27523019909858704
Test Loss:  0.2719707489013672
Valid Loss:  0.2703790068626404
Epoch:  258  	Training Loss: 0.2752301096916199
Test Loss:  0.2719706594944
Valid Loss:  0.27037888765335083
Epoch:  259  	Training Loss: 0.2752299904823303
Test Loss:  0.27197057008743286
Valid Loss:  0.27037882804870605
Epoch:  260  	Training Loss: 0.27522987127304077
Test Loss:  0.2719705104827881
Valid Loss:  0.2703787088394165
Epoch:  261  	Training Loss: 0.2752297818660736
Test Loss:  0.27197039127349854
Valid Loss:  0.27037858963012695
Epoch:  262  	Training Loss: 0.27522969245910645
Test Loss:  0.271970272064209
Valid Loss:  0.2703784704208374
Epoch:  263  	Training Loss: 0.2752295732498169
Test Loss:  0.2719701826572418
Valid Loss:  0.27037838101387024
Epoch:  264  	Training Loss: 0.27522945404052734
Test Loss:  0.27197009325027466
Valid Loss:  0.2703782916069031
Epoch:  265  	Training Loss: 0.2752293646335602
Test Loss:  0.2719699740409851
Valid Loss:  0.2703781723976135
Epoch:  266  	Training Loss: 0.27522924542427063
Test Loss:  0.27196985483169556
Valid Loss:  0.27037808299064636
Epoch:  267  	Training Loss: 0.27522915601730347
Test Loss:  0.2719697654247284
Valid Loss:  0.2703779935836792
Epoch:  268  	Training Loss: 0.2752290368080139
Test Loss:  0.27196967601776123
Valid Loss:  0.27037787437438965
Epoch:  269  	Training Loss: 0.27522894740104675
Test Loss:  0.2719695568084717
Valid Loss:  0.2703777551651001
Epoch:  270  	Training Loss: 0.2752288579940796
Test Loss:  0.2719694972038269
Valid Loss:  0.27037766575813293
Epoch:  271  	Training Loss: 0.27522870898246765
Test Loss:  0.27196937799453735
Valid Loss:  0.27037757635116577
Epoch:  272  	Training Loss: 0.2752286195755005
Test Loss:  0.2719692885875702
Valid Loss:  0.2703774571418762
Epoch:  273  	Training Loss: 0.27522850036621094
Test Loss:  0.27196916937828064
Valid Loss:  0.27037733793258667
Epoch:  274  	Training Loss: 0.2752284109592438
Test Loss:  0.2719690799713135
Valid Loss:  0.2703772187232971
Epoch:  275  	Training Loss: 0.2752283215522766
Test Loss:  0.2719689607620239
Valid Loss:  0.27037712931632996
Epoch:  276  	Training Loss: 0.27522820234298706
Test Loss:  0.27196887135505676
Valid Loss:  0.2703770399093628
Epoch:  277  	Training Loss: 0.2752280831336975
Test Loss:  0.2719687819480896
Valid Loss:  0.27037695050239563
Epoch:  278  	Training Loss: 0.27522796392440796
Test Loss:  0.27196869254112244
Valid Loss:  0.27037686109542847
Epoch:  279  	Training Loss: 0.2752279043197632
Test Loss:  0.2719685733318329
Valid Loss:  0.2703767418861389
Epoch:  280  	Training Loss: 0.27522778511047363
Test Loss:  0.2719684839248657
Valid Loss:  0.27037662267684937
Epoch:  281  	Training Loss: 0.2752276659011841
Test Loss:  0.27196836471557617
Valid Loss:  0.2703765034675598
Epoch:  282  	Training Loss: 0.27522754669189453
Test Loss:  0.2719683051109314
Valid Loss:  0.27037641406059265
Epoch:  283  	Training Loss: 0.27522748708724976
Test Loss:  0.27196815609931946
Valid Loss:  0.2703763246536255
Epoch:  284  	Training Loss: 0.2752273678779602
Test Loss:  0.2719680964946747
Valid Loss:  0.27037620544433594
Epoch:  285  	Training Loss: 0.27522724866867065
Test Loss:  0.27196797728538513
Valid Loss:  0.2703760862350464
Epoch:  286  	Training Loss: 0.2752271592617035
Test Loss:  0.27196788787841797
Valid Loss:  0.2703759968280792
Epoch:  287  	Training Loss: 0.27522704005241394
Test Loss:  0.2719677984714508
Valid Loss:  0.27037590742111206
Epoch:  288  	Training Loss: 0.2752269506454468
Test Loss:  0.27196767926216125
Valid Loss:  0.2703757882118225
Epoch:  289  	Training Loss: 0.2752268314361572
Test Loss:  0.2719675898551941
Valid Loss:  0.27037566900253296
Epoch:  290  	Training Loss: 0.27522674202919006
Test Loss:  0.27196747064590454
Valid Loss:  0.2703755795955658
Epoch:  291  	Training Loss: 0.2752266526222229
Test Loss:  0.2719673812389374
Valid Loss:  0.27037549018859863
Epoch:  292  	Training Loss: 0.27522653341293335
Test Loss:  0.2719672918319702
Valid Loss:  0.2703753709793091
Epoch:  293  	Training Loss: 0.2752264142036438
Test Loss:  0.27196717262268066
Valid Loss:  0.2703753113746643
 59%|█████▉    | 295/500 [03:23<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:23<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:23<01:06,  3.03it/s] 60%|██████    | 301/500 [03:29<03:52,  1.17s/it] 61%|██████    | 303/500 [03:29<02:45,  1.19it/s] 61%|██████    | 305/500 [03:29<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:29<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:30<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:36<03:39,  1.16s/it] 63%|██████▎   | 313/500 [03:36<02:35,  1.20it/s] 63%|██████▎   | 315/500 [03:36<01:51,  1.66it/s] 63%|██████▎   | 317/500 [03:36<01:21,  2.26it/s] 64%|██████▍   | 319/500 [03:36<00:59,  3.04it/s] 64%|██████▍   | 321/500 [03:42<03:27,  1.16s/it] 65%|██████▍   | 323/500 [03:43<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:43<01:45,  1.66it/s] 65%|██████▌   | 327/500 [03:43<01:16,  2.26it/s] 66%|██████▌   | 329/500 [03:43<00:56,  3.04it/s] 66%|██████▌   | 331/500 [03:49<03:16,  1.16s/it] 67%|██████▋   | 333/500 [03:49<02:19,  1.20it/s] 67%|██████▋   | 335/500 [03:49<01:39,  1.66it/s] 67%|██████▋   | 337/500 [03:50<01:11,  2.26it/s] 68%|██████▊   | 339/500 [03:50<00:52,  3.04it/s] 68%|██████▊   | 341/500 [03:56<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:56<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:56<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:56<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:57<00:50,  3.02it/s] 70%|███████   | 351/500 [04:03<02:53,  1.17s/it] 71%|███████   | 353/500 [04:03<02:03,  1.19it/s] 71%|███████   | 355/500 [04:03<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:03<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:03<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:10<02:41,  1.16s/it] 73%|███████▎  | 363/500 [04:10<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:10<01:21,  1.65it/s]Epoch:  294  	Training Loss: 0.27522632479667664
Test Loss:  0.2719670832157135
Valid Loss:  0.27037516236305237
Epoch:  295  	Training Loss: 0.2752262353897095
Test Loss:  0.27196699380874634
Valid Loss:  0.2703750729560852
Epoch:  296  	Training Loss: 0.2752261161804199
Test Loss:  0.2719668745994568
Valid Loss:  0.27037498354911804
Epoch:  297  	Training Loss: 0.27522599697113037
Test Loss:  0.27196675539016724
Valid Loss:  0.2703748643398285
Epoch:  298  	Training Loss: 0.2752258777618408
Test Loss:  0.2719666659832001
Valid Loss:  0.27037477493286133
Epoch:  299  	Training Loss: 0.27522575855255127
Test Loss:  0.2719665765762329
Valid Loss:  0.2703746557235718
Epoch:  300  	Training Loss: 0.2752256989479065
Test Loss:  0.27196648716926575
Valid Loss:  0.2703745663166046
Epoch:  301  	Training Loss: 0.27522557973861694
Test Loss:  0.2719663679599762
Valid Loss:  0.27037444710731506
Epoch:  302  	Training Loss: 0.2752254605293274
Test Loss:  0.27196627855300903
Valid Loss:  0.2703743577003479
Epoch:  303  	Training Loss: 0.27522537112236023
Test Loss:  0.2719661593437195
Valid Loss:  0.27037423849105835
Epoch:  304  	Training Loss: 0.27522528171539307
Test Loss:  0.2719660699367523
Valid Loss:  0.2703741490840912
Epoch:  305  	Training Loss: 0.2752251625061035
Test Loss:  0.27196598052978516
Valid Loss:  0.270374059677124
Epoch:  306  	Training Loss: 0.27522504329681396
Test Loss:  0.271965891122818
Valid Loss:  0.2703739404678345
Epoch:  307  	Training Loss: 0.2752249836921692
Test Loss:  0.27196580171585083
Valid Loss:  0.2703738212585449
Epoch:  308  	Training Loss: 0.27522486448287964
Test Loss:  0.2719656825065613
Valid Loss:  0.27037370204925537
Epoch:  309  	Training Loss: 0.2752247452735901
Test Loss:  0.27196556329727173
Valid Loss:  0.2703736126422882
Epoch:  310  	Training Loss: 0.27522462606430054
Test Loss:  0.27196547389030457
Valid Loss:  0.27037352323532104
Epoch:  311  	Training Loss: 0.2752245366573334
Test Loss:  0.2719653844833374
Valid Loss:  0.2703734338283539
Epoch:  312  	Training Loss: 0.2752244174480438
Test Loss:  0.27196529507637024
Valid Loss:  0.27037331461906433
Epoch:  313  	Training Loss: 0.27522432804107666
Test Loss:  0.2719651758670807
Valid Loss:  0.2703731954097748
Epoch:  314  	Training Loss: 0.2752242088317871
Test Loss:  0.2719650864601135
Valid Loss:  0.2703731060028076
Epoch:  315  	Training Loss: 0.27522411942481995
Test Loss:  0.271964967250824
Valid Loss:  0.27037298679351807
Epoch:  316  	Training Loss: 0.2752240002155304
Test Loss:  0.2719649076461792
Valid Loss:  0.2703728973865509
Epoch:  317  	Training Loss: 0.27522391080856323
Test Loss:  0.27196478843688965
Valid Loss:  0.27037280797958374
Epoch:  318  	Training Loss: 0.2752237915992737
Test Loss:  0.2719646692276001
Valid Loss:  0.2703726887702942
Epoch:  319  	Training Loss: 0.27522367238998413
Test Loss:  0.27196457982063293
Valid Loss:  0.270372599363327
Epoch:  320  	Training Loss: 0.27522358298301697
Test Loss:  0.27196449041366577
Valid Loss:  0.2703724801540375
Epoch:  321  	Training Loss: 0.2752234935760498
Test Loss:  0.2719643712043762
Valid Loss:  0.2703723907470703
Epoch:  322  	Training Loss: 0.27522337436676025
Test Loss:  0.27196428179740906
Valid Loss:  0.27037227153778076
Epoch:  323  	Training Loss: 0.2752232551574707
Test Loss:  0.2719641923904419
Valid Loss:  0.2703721523284912
Epoch:  324  	Training Loss: 0.2752231955528259
Test Loss:  0.27196410298347473
Valid Loss:  0.27037206292152405
Epoch:  325  	Training Loss: 0.2752230763435364
Test Loss:  0.27196401357650757
Valid Loss:  0.2703719735145569
Epoch:  326  	Training Loss: 0.2752229571342468
Test Loss:  0.271963894367218
Valid Loss:  0.27037185430526733
Epoch:  327  	Training Loss: 0.2752228379249573
Test Loss:  0.27196377515792847
Valid Loss:  0.2703717350959778
Epoch:  328  	Training Loss: 0.2752227485179901
Test Loss:  0.2719636857509613
Valid Loss:  0.270371675491333
Epoch:  329  	Training Loss: 0.27522262930870056
Test Loss:  0.27196359634399414
Valid Loss:  0.27037155628204346
Epoch:  330  	Training Loss: 0.2752225399017334
Test Loss:  0.271963506937027
Valid Loss:  0.2703714370727539
Epoch:  331  	Training Loss: 0.27522242069244385
Test Loss:  0.2719634175300598
Valid Loss:  0.27037134766578674
Epoch:  332  	Training Loss: 0.2752223312854767
Test Loss:  0.2719632685184479
Valid Loss:  0.2703712582588196
Epoch:  333  	Training Loss: 0.2752222418785095
Test Loss:  0.2719632089138031
Valid Loss:  0.27037113904953003
Epoch:  334  	Training Loss: 0.27522212266921997
Test Loss:  0.27196308970451355
Valid Loss:  0.27037104964256287
Epoch:  335  	Training Loss: 0.2752220034599304
Test Loss:  0.2719630002975464
Valid Loss:  0.2703709602355957
Epoch:  336  	Training Loss: 0.27522191405296326
Test Loss:  0.27196288108825684
Valid Loss:  0.27037084102630615
Epoch:  337  	Training Loss: 0.2752217948436737
Test Loss:  0.27196282148361206
Valid Loss:  0.2703707218170166
Epoch:  338  	Training Loss: 0.27522170543670654
Test Loss:  0.2719627022743225
Valid Loss:  0.27037060260772705
Epoch:  339  	Training Loss: 0.275221586227417
Test Loss:  0.27196258306503296
Valid Loss:  0.2703705132007599
Epoch:  340  	Training Loss: 0.27522149682044983
Test Loss:  0.2719624936580658
Valid Loss:  0.2703704237937927
Epoch:  341  	Training Loss: 0.27522140741348267
Test Loss:  0.27196240425109863
Valid Loss:  0.2703703045845032
Epoch:  342  	Training Loss: 0.2752212882041931
Test Loss:  0.2719622850418091
Valid Loss:  0.270370215177536
Epoch:  343  	Training Loss: 0.27522116899490356
Test Loss:  0.2719621956348419
Valid Loss:  0.27037012577056885
Epoch:  344  	Training Loss: 0.2752210795879364
Test Loss:  0.27196210622787476
Valid Loss:  0.2703700065612793
Epoch:  345  	Training Loss: 0.27522096037864685
Test Loss:  0.2719619870185852
Valid Loss:  0.27036988735198975
Epoch:  346  	Training Loss: 0.2752208709716797
Test Loss:  0.27196189761161804
Valid Loss:  0.2703697979450226
Epoch:  347  	Training Loss: 0.27522075176239014
Test Loss:  0.2719618082046509
Valid Loss:  0.27036967873573303
Epoch:  348  	Training Loss: 0.2752206325531006
Test Loss:  0.27196168899536133
Valid Loss:  0.27036958932876587
Epoch:  349  	Training Loss: 0.27522051334381104
Test Loss:  0.27196159958839417
Valid Loss:  0.2703694701194763
Epoch:  350  	Training Loss: 0.27522042393684387
Test Loss:  0.271961510181427
Valid Loss:  0.27036938071250916
Epoch:  351  	Training Loss: 0.2752203345298767
Test Loss:  0.27196139097213745
Valid Loss:  0.270369291305542
Epoch:  352  	Training Loss: 0.27522021532058716
Test Loss:  0.2719613015651703
Valid Loss:  0.27036917209625244
Epoch:  353  	Training Loss: 0.2752201557159424
Test Loss:  0.2719612121582031
Valid Loss:  0.2703690826892853
Epoch:  354  	Training Loss: 0.27522000670433044
Test Loss:  0.2719610929489136
Valid Loss:  0.2703689634799957
Epoch:  355  	Training Loss: 0.2752199172973633
Test Loss:  0.271960973739624
Valid Loss:  0.27036887407302856
Epoch:  356  	Training Loss: 0.2752198278903961
Test Loss:  0.27196091413497925
Valid Loss:  0.270368754863739
Epoch:  357  	Training Loss: 0.27521970868110657
Test Loss:  0.2719607949256897
Valid Loss:  0.27036866545677185
Epoch:  358  	Training Loss: 0.2752196192741394
Test Loss:  0.27196070551872253
Valid Loss:  0.2703685164451599
Epoch:  359  	Training Loss: 0.27521950006484985
Test Loss:  0.271960586309433
Valid Loss:  0.27036845684051514
Epoch:  360  	Training Loss: 0.2752193808555603
Test Loss:  0.2719604969024658
Valid Loss:  0.2703683376312256
Epoch:  361  	Training Loss: 0.27521929144859314
Test Loss:  0.27196040749549866
Valid Loss:  0.27036821842193604
Epoch:  362  	Training Loss: 0.2752191722393036
Test Loss:  0.2719602882862091
Valid Loss:  0.27036812901496887
Epoch:  363  	Training Loss: 0.2752190828323364
Test Loss:  0.27196019887924194
Valid Loss:  0.2703680396080017
Epoch:  364  	Training Loss: 0.2752189636230469
Test Loss:  0.2719600796699524
Valid Loss:  0.27036792039871216
Epoch:  365  	Training Loss: 0.2752188742160797
Test Loss:  0.27195999026298523
Valid Loss:  0.270367830991745
Epoch:  366  	Training Loss: 0.27521878480911255
Test Loss:  0.27195990085601807
Valid Loss:  0.27036774158477783
 73%|███████▎  | 367/500 [04:10<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:10<00:43,  3.03it/s] 74%|███████▍  | 371/500 [04:16<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:16<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:17<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:17<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:17<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:23<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:23<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:23<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:24<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:24<00:36,  3.03it/s] 78%|███████▊  | 391/500 [04:30<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:30<01:28,  1.20it/s] 79%|███████▉  | 395/500 [04:30<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:30<00:45,  2.27it/s] 80%|███████▉  | 399/500 [04:30<00:33,  3.04it/s] 80%|████████  | 401/500 [04:37<01:55,  1.17s/it] 81%|████████  | 403/500 [04:37<01:21,  1.19it/s] 81%|████████  | 405/500 [04:37<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:37<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:37<00:30,  3.03it/s] 82%|████████▏ | 411/500 [04:43<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:44<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:44<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:44<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:44<00:26,  3.00it/s] 84%|████████▍ | 421/500 [04:50<01:32,  1.18s/it] 85%|████████▍ | 423/500 [04:50<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:51<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:51<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:51<00:23,  3.01it/s] 86%|████████▌ | 431/500 [04:57<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:57<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:57<00:39,  1.64it/s] 87%|████████▋ | 437/500 [04:57<00:28,  2.24it/s] 88%|████████▊ | 439/500 [04:58<00:20,  3.00it/s]Epoch:  367  	Training Loss: 0.275218665599823
Test Loss:  0.2719598114490509
Valid Loss:  0.2703676223754883
Epoch:  368  	Training Loss: 0.27521854639053345
Test Loss:  0.27195972204208374
Valid Loss:  0.27036750316619873
Epoch:  369  	Training Loss: 0.2752184569835663
Test Loss:  0.2719596028327942
Valid Loss:  0.27036741375923157
Epoch:  370  	Training Loss: 0.27521833777427673
Test Loss:  0.27195948362350464
Valid Loss:  0.2703673243522644
Epoch:  371  	Training Loss: 0.27521824836730957
Test Loss:  0.2719593942165375
Valid Loss:  0.27036720514297485
Epoch:  372  	Training Loss: 0.27521812915802
Test Loss:  0.2719593048095703
Valid Loss:  0.2703671157360077
Epoch:  373  	Training Loss: 0.27521803975105286
Test Loss:  0.27195918560028076
Valid Loss:  0.27036699652671814
Epoch:  374  	Training Loss: 0.2752179503440857
Test Loss:  0.2719590961933136
Valid Loss:  0.270366907119751
Epoch:  375  	Training Loss: 0.27521783113479614
Test Loss:  0.27195900678634644
Valid Loss:  0.2703667879104614
Epoch:  376  	Training Loss: 0.2752177119255066
Test Loss:  0.2719588875770569
Valid Loss:  0.27036669850349426
Epoch:  377  	Training Loss: 0.27521759271621704
Test Loss:  0.2719588279724121
Valid Loss:  0.2703665792942047
Epoch:  378  	Training Loss: 0.27521753311157227
Test Loss:  0.27195867896080017
Valid Loss:  0.27036648988723755
Epoch:  379  	Training Loss: 0.2752173840999603
Test Loss:  0.271958589553833
Valid Loss:  0.270366370677948
Epoch:  380  	Training Loss: 0.27521729469299316
Test Loss:  0.27195850014686584
Valid Loss:  0.27036628127098083
Epoch:  381  	Training Loss: 0.2752171754837036
Test Loss:  0.2719584107398987
Valid Loss:  0.27036619186401367
Epoch:  382  	Training Loss: 0.27521705627441406
Test Loss:  0.2719583213329315
Valid Loss:  0.2703660726547241
Epoch:  383  	Training Loss: 0.2752169966697693
Test Loss:  0.2719581723213196
Valid Loss:  0.27036598324775696
Epoch:  384  	Training Loss: 0.27521687746047974
Test Loss:  0.2719581127166748
Valid Loss:  0.2703658938407898
Epoch:  385  	Training Loss: 0.2752167582511902
Test Loss:  0.27195799350738525
Valid Loss:  0.27036577463150024
Epoch:  386  	Training Loss: 0.275216668844223
Test Loss:  0.2719579041004181
Valid Loss:  0.2703656554222107
Epoch:  387  	Training Loss: 0.27521654963493347
Test Loss:  0.2719578146934509
Valid Loss:  0.27036553621292114
Epoch:  388  	Training Loss: 0.2752164602279663
Test Loss:  0.2719576954841614
Valid Loss:  0.270365446805954
Epoch:  389  	Training Loss: 0.27521634101867676
Test Loss:  0.2719576060771942
Valid Loss:  0.2703653573989868
Epoch:  390  	Training Loss: 0.2752162516117096
Test Loss:  0.27195751667022705
Valid Loss:  0.27036523818969727
Epoch:  391  	Training Loss: 0.27521616220474243
Test Loss:  0.2719573974609375
Valid Loss:  0.2703651189804077
Epoch:  392  	Training Loss: 0.2752160429954529
Test Loss:  0.27195727825164795
Valid Loss:  0.27036502957344055
Epoch:  393  	Training Loss: 0.27521592378616333
Test Loss:  0.2719572186470032
Valid Loss:  0.2703649401664734
Epoch:  394  	Training Loss: 0.27521583437919617
Test Loss:  0.2719570994377136
Valid Loss:  0.27036482095718384
Epoch:  395  	Training Loss: 0.2752157151699066
Test Loss:  0.27195701003074646
Valid Loss:  0.2703647017478943
Epoch:  396  	Training Loss: 0.27521562576293945
Test Loss:  0.2719569206237793
Valid Loss:  0.2703646421432495
Epoch:  397  	Training Loss: 0.2752155065536499
Test Loss:  0.27195680141448975
Valid Loss:  0.27036452293395996
Epoch:  398  	Training Loss: 0.27521538734436035
Test Loss:  0.2719566822052002
Valid Loss:  0.2703644037246704
Epoch:  399  	Training Loss: 0.2752152979373932
Test Loss:  0.2719566226005554
Valid Loss:  0.27036431431770325
Epoch:  400  	Training Loss: 0.275215208530426
Test Loss:  0.27195650339126587
Valid Loss:  0.2703642249107361
Epoch:  401  	Training Loss: 0.2752150893211365
Test Loss:  0.2719563841819763
Valid Loss:  0.27036410570144653
Epoch:  402  	Training Loss: 0.2752149701118469
Test Loss:  0.27195629477500916
Valid Loss:  0.27036401629447937
Epoch:  403  	Training Loss: 0.27521488070487976
Test Loss:  0.271956205368042
Valid Loss:  0.2703639268875122
Epoch:  404  	Training Loss: 0.2752147912979126
Test Loss:  0.27195611596107483
Valid Loss:  0.27036380767822266
Epoch:  405  	Training Loss: 0.27521467208862305
Test Loss:  0.2719559669494629
Valid Loss:  0.2703636884689331
Epoch:  406  	Training Loss: 0.2752145528793335
Test Loss:  0.2719559073448181
Valid Loss:  0.27036356925964355
Epoch:  407  	Training Loss: 0.27521446347236633
Test Loss:  0.27195578813552856
Valid Loss:  0.2703634798526764
Epoch:  408  	Training Loss: 0.2752143442630768
Test Loss:  0.2719556987285614
Valid Loss:  0.27036339044570923
Epoch:  409  	Training Loss: 0.2752142548561096
Test Loss:  0.27195560932159424
Valid Loss:  0.2703632712364197
Epoch:  410  	Training Loss: 0.27521416544914246
Test Loss:  0.2719554901123047
Valid Loss:  0.2703631520271301
Epoch:  411  	Training Loss: 0.2752140462398529
Test Loss:  0.2719554305076599
Valid Loss:  0.27036309242248535
Epoch:  412  	Training Loss: 0.27521395683288574
Test Loss:  0.27195531129837036
Valid Loss:  0.2703629732131958
Epoch:  413  	Training Loss: 0.2752138376235962
Test Loss:  0.2719551920890808
Valid Loss:  0.27036285400390625
Epoch:  414  	Training Loss: 0.27521371841430664
Test Loss:  0.27195510268211365
Valid Loss:  0.2703627347946167
Epoch:  415  	Training Loss: 0.2752135992050171
Test Loss:  0.2719550132751465
Valid Loss:  0.27036264538764954
Epoch:  416  	Training Loss: 0.2752135097980499
Test Loss:  0.27195489406585693
Valid Loss:  0.2703625559806824
Epoch:  417  	Training Loss: 0.27521342039108276
Test Loss:  0.2719547748565674
Valid Loss:  0.2703624367713928
Epoch:  418  	Training Loss: 0.2752133011817932
Test Loss:  0.2719547152519226
Valid Loss:  0.27036234736442566
Epoch:  419  	Training Loss: 0.27521318197250366
Test Loss:  0.27195459604263306
Valid Loss:  0.2703622579574585
Epoch:  420  	Training Loss: 0.2752130925655365
Test Loss:  0.2719545066356659
Valid Loss:  0.27036213874816895
Epoch:  421  	Training Loss: 0.27521297335624695
Test Loss:  0.27195441722869873
Valid Loss:  0.2703620195388794
Epoch:  422  	Training Loss: 0.2752128839492798
Test Loss:  0.2719542980194092
Valid Loss:  0.27036193013191223
Epoch:  423  	Training Loss: 0.27521276473999023
Test Loss:  0.271954208612442
Valid Loss:  0.27036184072494507
Epoch:  424  	Training Loss: 0.27521267533302307
Test Loss:  0.27195411920547485
Valid Loss:  0.2703617215156555
Epoch:  425  	Training Loss: 0.2752125859260559
Test Loss:  0.2719539999961853
Valid Loss:  0.27036163210868835
Epoch:  426  	Training Loss: 0.27521246671676636
Test Loss:  0.27195391058921814
Valid Loss:  0.2703615427017212
Epoch:  427  	Training Loss: 0.2752123475074768
Test Loss:  0.271953821182251
Valid Loss:  0.27036142349243164
Epoch:  428  	Training Loss: 0.27521225810050964
Test Loss:  0.2719537019729614
Valid Loss:  0.2703613042831421
Epoch:  429  	Training Loss: 0.2752121686935425
Test Loss:  0.27195361256599426
Valid Loss:  0.2703612148761749
Epoch:  430  	Training Loss: 0.27521204948425293
Test Loss:  0.2719535231590271
Valid Loss:  0.2703610956668854
Epoch:  431  	Training Loss: 0.2752119302749634
Test Loss:  0.27195340394973755
Valid Loss:  0.2703610062599182
Epoch:  432  	Training Loss: 0.2752118408679962
Test Loss:  0.2719533145427704
Valid Loss:  0.27036091685295105
Epoch:  433  	Training Loss: 0.27521175146102905
Test Loss:  0.2719532251358032
Valid Loss:  0.2703607976436615
Epoch:  434  	Training Loss: 0.2752116322517395
Test Loss:  0.27195310592651367
Valid Loss:  0.27036070823669434
Epoch:  435  	Training Loss: 0.27521151304244995
Test Loss:  0.2719530165195465
Valid Loss:  0.2703605890274048
Epoch:  436  	Training Loss: 0.2752114236354828
Test Loss:  0.27195289731025696
Valid Loss:  0.27036046981811523
Epoch:  437  	Training Loss: 0.2752113342285156
Test Loss:  0.2719528079032898
Valid Loss:  0.2703603506088257
Epoch:  438  	Training Loss: 0.2752112150192261
Test Loss:  0.27195268869400024
Valid Loss:  0.2703602910041809
Epoch:  439  	Training Loss: 0.2752110958099365
Test Loss:  0.27195262908935547
Valid Loss:  0.27036017179489136
 88%|████████▊ | 441/500 [05:04<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:04<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:04<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:04<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:04<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:11<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:11<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:11<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:11<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:11<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:17<00:44,  1.15s/it] 93%|█████████▎| 463/500 [05:17<00:30,  1.21it/s] 93%|█████████▎| 465/500 [05:18<00:20,  1.67it/s] 93%|█████████▎| 467/500 [05:18<00:14,  2.27it/s] 94%|█████████▍| 469/500 [05:18<00:10,  3.05it/s] 94%|█████████▍| 471/500 [05:24<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:24<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:24<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:24<00:10,  2.26it/s] 96%|█████████▌| 479/500 [05:25<00:06,  3.04it/s] 96%|█████████▌| 481/500 [05:31<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:31<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:31<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:31<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:31<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:38<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:38<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:38<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:38<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:38<00:00,  3.01it/s]100%|██████████| 500/500 [05:38<00:00,  1.48it/s]
Epoch:  440  	Training Loss: 0.27521100640296936
Test Loss:  0.2719525098800659
Valid Loss:  0.2703600525856018
Epoch:  441  	Training Loss: 0.2752108871936798
Test Loss:  0.27195239067077637
Valid Loss:  0.27035999298095703
Epoch:  442  	Training Loss: 0.27521079778671265
Test Loss:  0.2719523310661316
Valid Loss:  0.2703598737716675
Epoch:  443  	Training Loss: 0.2752106785774231
Test Loss:  0.27195221185684204
Valid Loss:  0.27035975456237793
Epoch:  444  	Training Loss: 0.27521055936813354
Test Loss:  0.2719521224498749
Valid Loss:  0.2703596353530884
Epoch:  445  	Training Loss: 0.2752104699611664
Test Loss:  0.2719520330429077
Valid Loss:  0.2703595459461212
Epoch:  446  	Training Loss: 0.2752103805541992
Test Loss:  0.27195191383361816
Valid Loss:  0.27035945653915405
Epoch:  447  	Training Loss: 0.27521026134490967
Test Loss:  0.2719517946243286
Valid Loss:  0.2703593373298645
Epoch:  448  	Training Loss: 0.2752101421356201
Test Loss:  0.27195170521736145
Valid Loss:  0.27035924792289734
Epoch:  449  	Training Loss: 0.27521002292633057
Test Loss:  0.2719516158103943
Valid Loss:  0.2703591287136078
Epoch:  450  	Training Loss: 0.2752099633216858
Test Loss:  0.27195149660110474
Valid Loss:  0.2703590393066406
Epoch:  451  	Training Loss: 0.27520984411239624
Test Loss:  0.27195143699645996
Valid Loss:  0.2703589200973511
Epoch:  452  	Training Loss: 0.2752097249031067
Test Loss:  0.2719513177871704
Valid Loss:  0.2703588008880615
Epoch:  453  	Training Loss: 0.2752096354961395
Test Loss:  0.27195119857788086
Valid Loss:  0.27035874128341675
Epoch:  454  	Training Loss: 0.27520951628685
Test Loss:  0.2719511091709137
Valid Loss:  0.2703586220741272
Epoch:  455  	Training Loss: 0.2752094268798828
Test Loss:  0.27195101976394653
Valid Loss:  0.27035853266716003
Epoch:  456  	Training Loss: 0.27520930767059326
Test Loss:  0.27195093035697937
Valid Loss:  0.27035844326019287
Epoch:  457  	Training Loss: 0.2752091884613037
Test Loss:  0.2719508111476898
Valid Loss:  0.2703583240509033
Epoch:  458  	Training Loss: 0.27520909905433655
Test Loss:  0.27195072174072266
Valid Loss:  0.27035820484161377
Epoch:  459  	Training Loss: 0.2752090096473694
Test Loss:  0.2719506025314331
Valid Loss:  0.2703580856323242
Epoch:  460  	Training Loss: 0.2752089202404022
Test Loss:  0.27195054292678833
Valid Loss:  0.27035799622535706
Epoch:  461  	Training Loss: 0.2752087712287903
Test Loss:  0.2719504237174988
Valid Loss:  0.2703579068183899
Epoch:  462  	Training Loss: 0.2752086818218231
Test Loss:  0.2719503343105316
Valid Loss:  0.27035781741142273
Epoch:  463  	Training Loss: 0.27520859241485596
Test Loss:  0.27195024490356445
Valid Loss:  0.2703576982021332
Epoch:  464  	Training Loss: 0.2752085030078888
Test Loss:  0.2719501256942749
Valid Loss:  0.27035757899284363
Epoch:  465  	Training Loss: 0.27520838379859924
Test Loss:  0.27195003628730774
Valid Loss:  0.27035748958587646
Epoch:  466  	Training Loss: 0.2752082645893097
Test Loss:  0.2719499170780182
Valid Loss:  0.2703574001789093
Epoch:  467  	Training Loss: 0.27520817518234253
Test Loss:  0.271949827671051
Valid Loss:  0.27035728096961975
Epoch:  468  	Training Loss: 0.275208055973053
Test Loss:  0.2719497084617615
Valid Loss:  0.2703571915626526
Epoch:  469  	Training Loss: 0.2752079367637634
Test Loss:  0.2719495892524719
Valid Loss:  0.27035707235336304
Epoch:  470  	Training Loss: 0.27520787715911865
Test Loss:  0.27194952964782715
Valid Loss:  0.2703569531440735
Epoch:  471  	Training Loss: 0.2752077579498291
Test Loss:  0.2719494104385376
Valid Loss:  0.27035683393478394
Epoch:  472  	Training Loss: 0.27520763874053955
Test Loss:  0.27194932103157043
Valid Loss:  0.27035677433013916
Epoch:  473  	Training Loss: 0.27520751953125
Test Loss:  0.27194923162460327
Valid Loss:  0.2703566551208496
Epoch:  474  	Training Loss: 0.2752074599266052
Test Loss:  0.2719491124153137
Valid Loss:  0.27035656571388245
Epoch:  475  	Training Loss: 0.2752073407173157
Test Loss:  0.27194902300834656
Valid Loss:  0.2703564465045929
Epoch:  476  	Training Loss: 0.2752072215080261
Test Loss:  0.271948903799057
Valid Loss:  0.27035635709762573
Epoch:  477  	Training Loss: 0.27520713210105896
Test Loss:  0.27194881439208984
Valid Loss:  0.2703562378883362
Epoch:  478  	Training Loss: 0.2752070128917694
Test Loss:  0.2719487249851227
Valid Loss:  0.27035611867904663
Epoch:  479  	Training Loss: 0.27520692348480225
Test Loss:  0.27194860577583313
Valid Loss:  0.27035602927207947
Epoch:  480  	Training Loss: 0.2752068042755127
Test Loss:  0.27194851636886597
Valid Loss:  0.2703559398651123
Epoch:  481  	Training Loss: 0.27520671486854553
Test Loss:  0.2719484269618988
Valid Loss:  0.27035582065582275
Epoch:  482  	Training Loss: 0.275206595659256
Test Loss:  0.27194833755493164
Valid Loss:  0.2703557014465332
Epoch:  483  	Training Loss: 0.2752065062522888
Test Loss:  0.2719482183456421
Valid Loss:  0.27035561203956604
Epoch:  484  	Training Loss: 0.27520638704299927
Test Loss:  0.27194809913635254
Valid Loss:  0.2703555226325989
Epoch:  485  	Training Loss: 0.2752062678337097
Test Loss:  0.2719480097293854
Valid Loss:  0.2703554034233093
Epoch:  486  	Training Loss: 0.27520614862442017
Test Loss:  0.2719479203224182
Valid Loss:  0.2703552842140198
Epoch:  487  	Training Loss: 0.2752060890197754
Test Loss:  0.27194783091545105
Valid Loss:  0.270355224609375
Epoch:  488  	Training Loss: 0.27520596981048584
Test Loss:  0.2719477415084839
Valid Loss:  0.27035510540008545
Epoch:  489  	Training Loss: 0.2752058506011963
Test Loss:  0.27194762229919434
Valid Loss:  0.2703550159931183
Epoch:  490  	Training Loss: 0.27520573139190674
Test Loss:  0.2719475328922272
Valid Loss:  0.27035489678382874
Epoch:  491  	Training Loss: 0.2752056419849396
Test Loss:  0.2719474136829376
Valid Loss:  0.2703547775745392
Epoch:  492  	Training Loss: 0.2752055525779724
Test Loss:  0.27194732427597046
Valid Loss:  0.270354688167572
Epoch:  493  	Training Loss: 0.27520543336868286
Test Loss:  0.2719472348690033
Valid Loss:  0.27035456895828247
Epoch:  494  	Training Loss: 0.2752053141593933
Test Loss:  0.27194711565971375
Valid Loss:  0.2703545093536377
Epoch:  495  	Training Loss: 0.27520522475242615
Test Loss:  0.2719470262527466
Valid Loss:  0.27035439014434814
Epoch:  496  	Training Loss: 0.2752051055431366
Test Loss:  0.27194690704345703
Valid Loss:  0.2703542709350586
Epoch:  497  	Training Loss: 0.27520501613616943
Test Loss:  0.27194684743881226
Valid Loss:  0.27035418152809143
Epoch:  498  	Training Loss: 0.2752048969268799
Test Loss:  0.2719467282295227
Valid Loss:  0.2703540623188019
Epoch:  499  	Training Loss: 0.2752048075199127
Test Loss:  0.27194663882255554
Valid Loss:  0.2703539729118347
Epoch:  500  	Training Loss: 0.27520468831062317
Test Loss:  0.271946519613266
Valid Loss:  0.27035385370254517
seed is  7
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:11,  6.16s/it]  1%|          | 3/500 [00:06<13:40,  1.65s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.92it/s]  2%|▏         | 11/500 [00:12<10:38,  1.31s/it]  3%|▎         | 13/500 [00:13<07:15,  1.12it/s]  3%|▎         | 15/500 [00:13<05:04,  1.59it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:39,  3.02it/s]  4%|▍         | 21/500 [00:19<09:26,  1.18s/it]  5%|▍         | 23/500 [00:19<06:42,  1.18it/s]  5%|▌         | 25/500 [00:19<04:48,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.25it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:04,  1.16s/it]  7%|▋         | 33/500 [00:26<06:28,  1.20it/s]  7%|▋         | 35/500 [00:26<04:39,  1.66it/s]  7%|▋         | 37/500 [00:26<03:24,  2.27it/s]  8%|▊         | 39/500 [00:26<02:31,  3.05it/s]  8%|▊         | 41/500 [00:33<09:04,  1.19s/it]  9%|▊         | 43/500 [00:33<06:28,  1.18it/s]  9%|▉         | 45/500 [00:33<04:40,  1.62it/s]  9%|▉         | 47/500 [00:33<03:24,  2.22it/s] 10%|▉         | 49/500 [00:33<02:31,  2.99it/s] 10%|█         | 51/500 [00:39<08:42,  1.16s/it] 11%|█         | 53/500 [00:40<06:13,  1.20it/s] 11%|█         | 55/500 [00:40<04:28,  1.66it/s] 11%|█▏        | 57/500 [00:40<03:16,  2.26it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.02it/s] 12%|█▏        | 61/500 [00:46<08:28,  1.16s/it] 13%|█▎        | 63/500 [00:46<06:04,  1.20it/s] 13%|█▎        | 65/500 [00:46<04:21,  1.66it/s] 13%|█▎        | 67/500 [00:47<03:10,  2.27it/s] 14%|█▍        | 69/500 [00:47<02:21,  3.05it/s]Epoch:  1  	Training Loss: 0.2657475471496582
Test Loss:  0.6678821444511414
Valid Loss:  0.6618276238441467
Epoch:  2  	Training Loss: 0.6486039161682129
Test Loss:  0.29201221466064453
Valid Loss:  0.32835108041763306
Epoch:  3  	Training Loss: 0.32876479625701904
Test Loss:  0.07469658553600311
Valid Loss:  0.08397901803255081
Epoch:  4  	Training Loss: 0.07776810228824615
Test Loss:  0.053930725902318954
Valid Loss:  0.06340689957141876
Epoch:  5  	Training Loss: 0.0584229901432991
Test Loss:  0.03491345793008804
Valid Loss:  0.0424325056374073
Epoch:  6  	Training Loss: 0.038997065275907516
Test Loss:  0.02302965521812439
Valid Loss:  0.028427323326468468
Epoch:  7  	Training Loss: 0.0261613130569458
Test Loss:  0.01813959889113903
Valid Loss:  0.02239849418401718
Epoch:  8  	Training Loss: 0.02051178365945816
Test Loss:  0.014716855250298977
Valid Loss:  0.018218085169792175
Epoch:  9  	Training Loss: 0.016704177483916283
Test Loss:  0.012138547375798225
Valid Loss:  0.015024630352854729
Epoch:  10  	Training Loss: 0.013752520084381104
Test Loss:  0.010053304955363274
Valid Loss:  0.0124232592061162
Epoch:  11  	Training Loss: 0.011386298574507236
Test Loss:  0.008401365950703621
Valid Loss:  0.010366140864789486
Epoch:  12  	Training Loss: 0.009501617401838303
Test Loss:  0.008220820687711239
Valid Loss:  0.009152784943580627
Epoch:  13  	Training Loss: 0.008913182653486729
Test Loss:  0.00706592109054327
Valid Loss:  0.008752121590077877
Epoch:  14  	Training Loss: 0.007976120337843895
Test Loss:  0.007394666783511639
Valid Loss:  0.007978107780218124
Epoch:  15  	Training Loss: 0.00787538755685091
Test Loss:  0.006156046874821186
Valid Loss:  0.007616237737238407
Epoch:  16  	Training Loss: 0.006912859622389078
Test Loss:  0.006336351856589317
Valid Loss:  0.006438237614929676
Epoch:  17  	Training Loss: 0.006513900123536587
Test Loss:  0.005998281762003899
Valid Loss:  0.00733083114027977
Epoch:  18  	Training Loss: 0.006655666045844555
Test Loss:  0.00551615422591567
Valid Loss:  0.005347970873117447
Epoch:  19  	Training Loss: 0.005545100662857294
Test Loss:  0.004789488390088081
Valid Loss:  0.005896363407373428
Epoch:  20  	Training Loss: 0.005355444736778736
Test Loss:  0.004403562285006046
Valid Loss:  0.004218737129122019
Epoch:  21  	Training Loss: 0.004390953574329615
Test Loss:  0.0036521931178867817
Valid Loss:  0.00455908477306366
Epoch:  22  	Training Loss: 0.004143096506595612
Test Loss:  0.0025330251082777977
Valid Loss:  0.0031673372723162174
Epoch:  23  	Training Loss: 0.002921491861343384
Test Loss:  0.002322685904800892
Valid Loss:  0.00282821012660861
Epoch:  24  	Training Loss: 0.0026569957844913006
Test Loss:  0.0021951759699732065
Valid Loss:  0.002644617110490799
Epoch:  25  	Training Loss: 0.0025023184716701508
Test Loss:  0.0020782146602869034
Valid Loss:  0.002494164276868105
Epoch:  26  	Training Loss: 0.002367395907640457
Test Loss:  0.0019705132581293583
Valid Loss:  0.002359979785978794
Epoch:  27  	Training Loss: 0.002245131181553006
Test Loss:  0.0018708843272179365
Valid Loss:  0.002237125299870968
Epoch:  28  	Training Loss: 0.0021332050673663616
Test Loss:  0.0017788299592211843
Valid Loss:  0.0021246294490993023
Epoch:  29  	Training Loss: 0.0020302338525652885
Test Loss:  0.0016935747116804123
Valid Loss:  0.0020210607908666134
Epoch:  30  	Training Loss: 0.001935347798280418
Test Loss:  0.0016150819137692451
Valid Loss:  0.001925626304000616
Epoch:  31  	Training Loss: 0.001847586827352643
Test Loss:  0.0015427202451974154
Valid Loss:  0.0018368499586358666
Epoch:  32  	Training Loss: 0.0017671464011073112
Test Loss:  0.0014729846734553576
Valid Loss:  0.001742243068292737
Epoch:  33  	Training Loss: 0.0016854061977937818
Test Loss:  0.001398240216076374
Valid Loss:  0.0016534016467630863
Epoch:  34  	Training Loss: 0.0016045381780713797
Test Loss:  0.0013169473968446255
Valid Loss:  0.001562003861181438
Epoch:  35  	Training Loss: 0.0015194118022918701
Test Loss:  0.0012674444587901235
Valid Loss:  0.001493923831731081
Epoch:  36  	Training Loss: 0.0014610057696700096
Test Loss:  0.0012209336273372173
Valid Loss:  0.0014328272081911564
Epoch:  37  	Training Loss: 0.0014077553059905767
Test Loss:  0.0011745664523914456
Valid Loss:  0.001379535417072475
Epoch:  38  	Training Loss: 0.0013591349124908447
Test Loss:  0.0011347330873832107
Valid Loss:  0.0013276113895699382
Epoch:  39  	Training Loss: 0.0013137434143573046
Test Loss:  0.001096244202926755
Valid Loss:  0.0012812011409550905
Epoch:  40  	Training Loss: 0.0012721809325739741
Test Loss:  0.0010590354213491082
Valid Loss:  0.0012395568192005157
Epoch:  41  	Training Loss: 0.0012341203400865197
Test Loss:  0.0010273123625665903
Valid Loss:  0.0011984980665147305
Epoch:  42  	Training Loss: 0.0011983427684754133
Test Loss:  0.0009286848362535238
Valid Loss:  0.0011069168103858829
Epoch:  43  	Training Loss: 0.0011160294525325298
Test Loss:  0.0008778662886470556
Valid Loss:  0.0010423175990581512
Epoch:  44  	Training Loss: 0.0010633160127326846
Test Loss:  0.0008396654156967998
Valid Loss:  0.0009940837044268847
Epoch:  45  	Training Loss: 0.00102457613684237
Test Loss:  0.0008101779967546463
Valid Loss:  0.0009581549093127251
Epoch:  46  	Training Loss: 0.0009963727788999677
Test Loss:  0.0007881647907197475
Valid Loss:  0.0009290516609326005
Epoch:  47  	Training Loss: 0.0009743253467604518
Test Loss:  0.0007703108713030815
Valid Loss:  0.0009059930453076959
Epoch:  48  	Training Loss: 0.0009568369714543223
Test Loss:  0.0007555095944553614
Valid Loss:  0.0008866523276083171
Epoch:  49  	Training Loss: 0.000942539656534791
Test Loss:  0.0007434491999447346
Valid Loss:  0.0008705131476745009
Epoch:  50  	Training Loss: 0.00093082245439291
Test Loss:  0.0007320587174035609
Valid Loss:  0.0008576800464652479
Epoch:  51  	Training Loss: 0.0009208663832396269
Test Loss:  0.0007238219259306788
Valid Loss:  0.0008460439275950193
Epoch:  52  	Training Loss: 0.0009122316841967404
Test Loss:  0.0007205160800367594
Valid Loss:  0.0008105456945486367
Epoch:  53  	Training Loss: 0.0008865247946232557
Test Loss:  0.0006855113315396011
Valid Loss:  0.0007956688059493899
Epoch:  54  	Training Loss: 0.0008687169756740332
Test Loss:  0.0006852045189589262
Valid Loss:  0.0007766679627820849
Epoch:  55  	Training Loss: 0.0008553300285711884
Test Loss:  0.000663797021843493
Valid Loss:  0.000766968703828752
Epoch:  56  	Training Loss: 0.0008446627762168646
Test Loss:  0.0006610840791836381
Valid Loss:  0.0007546773995272815
Epoch:  57  	Training Loss: 0.0008353184093721211
Test Loss:  0.0006457699928432703
Valid Loss:  0.0007467047544196248
Epoch:  58  	Training Loss: 0.0008267053635790944
Test Loss:  0.0006414970848709345
Valid Loss:  0.0007370830280706286
Epoch:  59  	Training Loss: 0.0008190571097657084
Test Loss:  0.0006299541564658284
Valid Loss:  0.0007299227290786803
Epoch:  60  	Training Loss: 0.0008120889542624354
Test Loss:  0.0006247517885640264
Valid Loss:  0.0007222705753520131
Epoch:  61  	Training Loss: 0.0008056821534410119
Test Loss:  0.0006162510253489017
Valid Loss:  0.0007161421235650778
Epoch:  62  	Training Loss: 0.0007996587664820254
Test Loss:  0.0005942619172856212
Valid Loss:  0.0006909047951921821
Epoch:  63  	Training Loss: 0.0007752064848318696
Test Loss:  0.0005808169371448457
Valid Loss:  0.0006783087737858295
Epoch:  64  	Training Loss: 0.0007622968405485153
Test Loss:  0.0005696138832718134
Valid Loss:  0.0006671880837529898
Epoch:  65  	Training Loss: 0.0007512954762205482
Test Loss:  0.0005605564801953733
Valid Loss:  0.0006570239784196019
Epoch:  66  	Training Loss: 0.0007419472094625235
Test Loss:  0.0005518766702152789
Valid Loss:  0.0006480427109636366
Epoch:  67  	Training Loss: 0.0007338161231018603
Test Loss:  0.0005440554232336581
Valid Loss:  0.0006404095911420882
Epoch:  68  	Training Loss: 0.0007265631575137377
Test Loss:  0.0005367831327021122
Valid Loss:  0.0006333549390546978
Epoch:  69  	Training Loss: 0.0007197641534730792
Test Loss:  0.0005302585777826607
Valid Loss:  0.0006265002302825451
Epoch:  70  	Training Loss: 0.0007132473401725292
Test Loss:  0.0005249177338555455
Valid Loss:   14%|█▍        | 71/500 [00:53<08:23,  1.17s/it] 15%|█▍        | 73/500 [00:53<05:59,  1.19it/s] 15%|█▌        | 75/500 [00:53<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:53<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:09,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:49,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:00<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:00<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:07<07:55,  1.16s/it] 19%|█▊        | 93/500 [01:07<05:39,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:04,  1.66it/s] 19%|█▉        | 97/500 [01:07<02:57,  2.26it/s] 20%|█▉        | 99/500 [01:07<02:11,  3.04it/s] 20%|██        | 101/500 [01:13<07:42,  1.16s/it] 21%|██        | 103/500 [01:13<05:30,  1.20it/s] 21%|██        | 105/500 [01:14<03:57,  1.66it/s] 21%|██▏       | 107/500 [01:14<02:54,  2.26it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:20<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:20<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:20<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:21<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:27<07:20,  1.16s/it] 25%|██▍       | 123/500 [01:27<05:14,  1.20it/s] 25%|██▌       | 125/500 [01:27<03:46,  1.66it/s] 25%|██▌       | 127/500 [01:27<02:45,  2.26it/s] 26%|██▌       | 129/500 [01:27<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:34<07:13,  1.17s/it] 27%|██▋       | 133/500 [01:34<05:09,  1.18it/s] 27%|██▋       | 135/500 [01:34<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:34<02:42,  2.24it/s]0.0006199389463290572
Epoch:  71  	Training Loss: 0.0007074503228068352
Test Loss:  0.000519869732670486
Valid Loss:  0.0006143957725726068
Epoch:  72  	Training Loss: 0.0007025578524917364
Test Loss:  0.0005193304386921227
Valid Loss:  0.0006117215380072594
Epoch:  73  	Training Loss: 0.0007009057444520295
Test Loss:  0.0005171033553779125
Valid Loss:  0.0006099739111959934
Epoch:  74  	Training Loss: 0.0006995984585955739
Test Loss:  0.0005157315172255039
Valid Loss:  0.000608402828220278
Epoch:  75  	Training Loss: 0.0006985240615904331
Test Loss:  0.0005145703325979412
Valid Loss:  0.000607004389166832
Epoch:  76  	Training Loss: 0.0006975920405238867
Test Loss:  0.0005134788225404918
Valid Loss:  0.0006058299914002419
Epoch:  77  	Training Loss: 0.0006968098459765315
Test Loss:  0.0005124583840370178
Valid Loss:  0.0006048083305358887
Epoch:  78  	Training Loss: 0.0006961104809306562
Test Loss:  0.0005116125685162842
Valid Loss:  0.0006038755527697504
Epoch:  79  	Training Loss: 0.0006954643176868558
Test Loss:  0.0005108007462695241
Valid Loss:  0.0006030415534041822
Epoch:  80  	Training Loss: 0.0006948572117835283
Test Loss:  0.000510031939484179
Valid Loss:  0.0006022583693265915
Epoch:  81  	Training Loss: 0.0006942722829990089
Test Loss:  0.0005093325744383037
Valid Loss:  0.0006015240214765072
Epoch:  82  	Training Loss: 0.000693713198415935
Test Loss:  0.0005103758303448558
Valid Loss:  0.0005985930911265314
Epoch:  83  	Training Loss: 0.0006918306462466717
Test Loss:  0.000505766598507762
Valid Loss:  0.000598026264924556
Epoch:  84  	Training Loss: 0.0006907850038260221
Test Loss:  0.0005065417499281466
Valid Loss:  0.0005970214260742068
Epoch:  85  	Training Loss: 0.000690194487106055
Test Loss:  0.0005049215396866202
Valid Loss:  0.0005967656034044921
Epoch:  86  	Training Loss: 0.0006897003040648997
Test Loss:  0.0005053967470303178
Valid Loss:  0.000596166355535388
Epoch:  87  	Training Loss: 0.0006892618257552385
Test Loss:  0.0005045313737355173
Valid Loss:  0.0005959683330729604
Epoch:  88  	Training Loss: 0.0006888560601510108
Test Loss:  0.0005050149047747254
Valid Loss:  0.0005955416709184647
Epoch:  89  	Training Loss: 0.0006884815520606935
Test Loss:  0.000504480442032218
Valid Loss:  0.0005954981897957623
Epoch:  90  	Training Loss: 0.000688133470248431
Test Loss:  0.0005048845196142793
Valid Loss:  0.0005953004001639783
Epoch:  91  	Training Loss: 0.0006878218846395612
Test Loss:  0.0005043917335569859
Valid Loss:  0.0005954267689958215
Epoch:  92  	Training Loss: 0.0006875807885080576
Test Loss:  0.0004978614742867649
Valid Loss:  0.0005915771471336484
Epoch:  93  	Training Loss: 0.0006832568906247616
Test Loss:  0.0004969552392140031
Valid Loss:  0.0005868747248314321
Epoch:  94  	Training Loss: 0.000679165474139154
Test Loss:  0.000489508849568665
Valid Loss:  0.0005838594515807927
Epoch:  95  	Training Loss: 0.0006751601467840374
Test Loss:  0.0004899888881482184
Valid Loss:  0.0005790778668597341
Epoch:  96  	Training Loss: 0.0006712166359648108
Test Loss:  0.0004817289300262928
Valid Loss:  0.000576465274207294
Epoch:  97  	Training Loss: 0.0006673607276752591
Test Loss:  0.0004837757151108235
Valid Loss:  0.0005714910221286118
Epoch:  98  	Training Loss: 0.0006635886966250837
Test Loss:  0.0004742422024719417
Valid Loss:  0.0005694020073860884
Epoch:  99  	Training Loss: 0.0006598914624191821
Test Loss:  0.000478606962133199
Valid Loss:  0.0005641246680170298
Epoch:  100  	Training Loss: 0.0006563003407791257
Test Loss:  0.00046688830479979515
Valid Loss:  0.0005627808859571815
Epoch:  101  	Training Loss: 0.0006528811063617468
Test Loss:  0.0004749902291223407
Valid Loss:  0.0005570439388975501
Epoch:  102  	Training Loss: 0.0006496013374999166
Test Loss:  0.00044444529339671135
Valid Loss:  0.0005424030241556466
Epoch:  103  	Training Loss: 0.0006312252953648567
Test Loss:  0.00044341443572193384
Valid Loss:  0.0005271249683573842
Epoch:  104  	Training Loss: 0.0006188443512655795
Test Loss:  0.0004298191634006798
Valid Loss:  0.0005162655143067241
Epoch:  105  	Training Loss: 0.0006081997998990119
Test Loss:  0.0004228111356496811
Valid Loss:  0.0005051492480561137
Epoch:  106  	Training Loss: 0.0005984771996736526
Test Loss:  0.00041371045517735183
Valid Loss:  0.0004953420720994473
Epoch:  107  	Training Loss: 0.0005895327776670456
Test Loss:  0.00040655897464603186
Valid Loss:  0.0004863465728703886
Epoch:  108  	Training Loss: 0.0005812373710796237
Test Loss:  0.00039981724694371223
Valid Loss:  0.00047852995339781046
Epoch:  109  	Training Loss: 0.0005738360341638327
Test Loss:  0.00039339717477560043
Valid Loss:  0.00047186081064864993
Epoch:  110  	Training Loss: 0.0005670738173648715
Test Loss:  0.0003881024313159287
Valid Loss:  0.00046585730160586536
Epoch:  111  	Training Loss: 0.0005609802901744843
Test Loss:  0.00038302812026813626
Valid Loss:  0.00046055071288719773
Epoch:  112  	Training Loss: 0.0005552889779210091
Test Loss:  0.0003821828286163509
Valid Loss:  0.00045654730638489127
Epoch:  113  	Training Loss: 0.000551765609998256
Test Loss:  0.0003789334441535175
Valid Loss:  0.00045379469520412385
Epoch:  114  	Training Loss: 0.0005487125017680228
Test Loss:  0.0003766800509765744
Valid Loss:  0.0004513530875556171
Epoch:  115  	Training Loss: 0.0005459609674289823
Test Loss:  0.0003744772984646261
Valid Loss:  0.00044911855366081
Epoch:  116  	Training Loss: 0.0005433524493128061
Test Loss:  0.0003725250717252493
Valid Loss:  0.00044702281593345106
Epoch:  117  	Training Loss: 0.0005408680299296975
Test Loss:  0.0003709791926667094
Valid Loss:  0.00044501712545752525
Epoch:  118  	Training Loss: 0.000538477033842355
Test Loss:  0.0003693371545523405
Valid Loss:  0.00044331641402095556
Epoch:  119  	Training Loss: 0.0005362496012821794
Test Loss:  0.0003680906374938786
Valid Loss:  0.00044161707046441734
Epoch:  120  	Training Loss: 0.0005341265932656825
Test Loss:  0.00036661807098425925
Valid Loss:  0.0004401843179948628
Epoch:  121  	Training Loss: 0.0005321724456734955
Test Loss:  0.0003655353211797774
Valid Loss:  0.00043881035526283085
Epoch:  122  	Training Loss: 0.0005304039223119617
Test Loss:  0.00035677626146934927
Valid Loss:  0.0004374426498543471
Epoch:  123  	Training Loss: 0.0005261136684566736
Test Loss:  0.0003594574227463454
Valid Loss:  0.00043367830221541226
Epoch:  124  	Training Loss: 0.0005217452999204397
Test Loss:  0.00035201734863221645
Valid Loss:  0.00043222607928328216
Epoch:  125  	Training Loss: 0.000517519423738122
Test Loss:  0.00035437740734778345
Valid Loss:  0.00042867095908150077
Epoch:  126  	Training Loss: 0.000513429578859359
Test Loss:  0.0003475096309557557
Valid Loss:  0.0004272370133548975
Epoch:  127  	Training Loss: 0.0005094029475003481
Test Loss:  0.0003492527175694704
Valid Loss:  0.0004238274123053998
Epoch:  128  	Training Loss: 0.0005051882471889257
Test Loss:  0.00034281163243576884
Valid Loss:  0.0004223353462293744
Epoch:  129  	Training Loss: 0.0005008014268241823
Test Loss:  0.00034440442686900496
Valid Loss:  0.00041908517596311867
Epoch:  130  	Training Loss: 0.0004965229309163988
Test Loss:  0.000337890291120857
Valid Loss:  0.0004178020462859422
Epoch:  131  	Training Loss: 0.0004921214422211051
Test Loss:  0.000339627469656989
Valid Loss:  0.0004145347629673779
Epoch:  132  	Training Loss: 0.0004878824984189123
Test Loss:  0.000340378494001925
Valid Loss:  0.0004146394203417003
Epoch:  133  	Training Loss: 0.00048775674076750875
Test Loss:  0.00034037663135677576
Valid Loss:  0.0004148351727053523
Epoch:  134  	Training Loss: 0.000487653975142166
Test Loss:  0.00034050323301926255
Valid Loss:  0.00041500560473650694
Epoch:  135  	Training Loss: 0.00048756878823041916
Test Loss:  0.00034060142934322357
Valid Loss:  0.0004151665489189327
Epoch:  136  	Training Loss: 0.00048750010319054127
Test Loss:  0.00034069677349179983
Valid Loss:  0.0004153238842263818
Epoch:  137  	Training Loss: 0.00048744637751951814
Test Loss:  0.00034078594762831926
Valid Loss:  0.0004154737980570644
Epoch:  138  	Training Loss: 0.00048740478814579546
Test Loss:  0.0003408778866287321
Valid Loss:  0.0004156061913818121
 28%|██▊       | 139/500 [01:34<02:00,  3.01it/s] 28%|██▊       | 141/500 [01:40<06:57,  1.16s/it] 29%|██▊       | 143/500 [01:41<04:58,  1.20it/s] 29%|██▉       | 145/500 [01:41<03:34,  1.66it/s] 29%|██▉       | 147/500 [01:41<02:36,  2.26it/s] 30%|██▉       | 149/500 [01:41<01:56,  3.02it/s] 30%|███       | 151/500 [01:47<06:43,  1.16s/it] 31%|███       | 153/500 [01:47<04:48,  1.20it/s] 31%|███       | 155/500 [01:47<03:27,  1.66it/s] 31%|███▏      | 157/500 [01:48<02:31,  2.27it/s] 32%|███▏      | 159/500 [01:48<01:51,  3.05it/s] 32%|███▏      | 161/500 [01:54<06:33,  1.16s/it] 33%|███▎      | 163/500 [01:54<04:41,  1.20it/s] 33%|███▎      | 165/500 [01:54<03:21,  1.66it/s] 33%|███▎      | 167/500 [01:54<02:26,  2.27it/s] 34%|███▍      | 169/500 [01:54<01:48,  3.05it/s] 34%|███▍      | 171/500 [02:01<06:23,  1.17s/it] 35%|███▍      | 173/500 [02:01<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:01<03:17,  1.65it/s] 35%|███▌      | 177/500 [02:01<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:01<01:46,  3.03it/s] 36%|███▌      | 181/500 [02:08<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:08<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:08<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:08<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:08<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:14<06:03,  1.17s/it] 39%|███▊      | 193/500 [02:15<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:15<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:15<01:40,  3.01it/s] 40%|████      | 201/500 [02:21<05:47,  1.16s/it] 41%|████      | 203/500 [02:21<04:08,  1.20it/s] 41%|████      | 205/500 [02:21<02:58,  1.65it/s]Epoch:  139  	Training Loss: 0.00048736861208453774
Test Loss:  0.0003409628407098353
Valid Loss:  0.00041572671034373343
Epoch:  140  	Training Loss: 0.00048733543371781707
Test Loss:  0.000341039733029902
Valid Loss:  0.0004158381780143827
Epoch:  141  	Training Loss: 0.00048730752314440906
Test Loss:  0.00034110399428755045
Valid Loss:  0.00041594155482016504
Epoch:  142  	Training Loss: 0.00048728371621109545
Test Loss:  0.0003383003640919924
Valid Loss:  0.00041365617653355
Epoch:  143  	Training Loss: 0.00048500014236196876
Test Loss:  0.0003365786396898329
Valid Loss:  0.0004115024348720908
Epoch:  144  	Training Loss: 0.0004829551908187568
Test Loss:  0.0003347645397298038
Valid Loss:  0.000409607746405527
Epoch:  145  	Training Loss: 0.0004810932732652873
Test Loss:  0.00033302808878943324
Valid Loss:  0.00040782851283438504
Epoch:  146  	Training Loss: 0.000479303824249655
Test Loss:  0.0003314499626867473
Valid Loss:  0.00040606799302622676
Epoch:  147  	Training Loss: 0.00047757281572557986
Test Loss:  0.0003299107193015516
Valid Loss:  0.00040433369576931
Epoch:  148  	Training Loss: 0.00047590883332304657
Test Loss:  0.00032849301351234317
Valid Loss:  0.0004026262031402439
Epoch:  149  	Training Loss: 0.00047430081758648157
Test Loss:  0.00032726716017350554
Valid Loss:  0.0004009456024505198
Epoch:  150  	Training Loss: 0.0004727790947072208
Test Loss:  0.00032613976509310305
Valid Loss:  0.00039935929817147553
Epoch:  151  	Training Loss: 0.000471453124191612
Test Loss:  0.0003251005837228149
Valid Loss:  0.0003979999164585024
Epoch:  152  	Training Loss: 0.00047030061250552535
Test Loss:  0.00032569997711107135
Valid Loss:  0.00039725302485749125
Epoch:  153  	Training Loss: 0.000469976948807016
Test Loss:  0.00032448855927214026
Valid Loss:  0.00039689079858362675
Epoch:  154  	Training Loss: 0.00046970168477855623
Test Loss:  0.0003248974680900574
Valid Loss:  0.00039631748222745955
Epoch:  155  	Training Loss: 0.00046945695066824555
Test Loss:  0.0003239883226342499
Valid Loss:  0.0003960049361921847
Epoch:  156  	Training Loss: 0.0004692221409641206
Test Loss:  0.00032424856908619404
Valid Loss:  0.00039553755777888
Epoch:  157  	Training Loss: 0.00046901433961465955
Test Loss:  0.00032358677708543837
Valid Loss:  0.0003952793194912374
Epoch:  158  	Training Loss: 0.00046883150935173035
Test Loss:  0.0003237319178879261
Valid Loss:  0.0003949046949855983
Epoch:  159  	Training Loss: 0.00046865397598594427
Test Loss:  0.00032323505729436874
Valid Loss:  0.00039466709131374955
Epoch:  160  	Training Loss: 0.00046848662896081805
Test Loss:  0.0003233052557334304
Valid Loss:  0.0003943533229175955
Epoch:  161  	Training Loss: 0.0004683250153902918
Test Loss:  0.00032292172545567155
Valid Loss:  0.0003941364702768624
Epoch:  162  	Training Loss: 0.00046817021211609244
Test Loss:  0.00032212521182373166
Valid Loss:  0.0003933932457584888
Epoch:  163  	Training Loss: 0.0004674775409512222
Test Loss:  0.00032155870576389134
Valid Loss:  0.0003926900390069932
Epoch:  164  	Training Loss: 0.00046685896813869476
Test Loss:  0.0003210281429346651
Valid Loss:  0.0003920508606825024
Epoch:  165  	Training Loss: 0.00046627543633803725
Test Loss:  0.00032049883157014847
Valid Loss:  0.0003914174158126116
Epoch:  166  	Training Loss: 0.00046571166603825986
Test Loss:  0.0003199866332579404
Valid Loss:  0.00039080422720871866
Epoch:  167  	Training Loss: 0.0004651708877645433
Test Loss:  0.00031947382376529276
Valid Loss:  0.0003902074240613729
Epoch:  168  	Training Loss: 0.00046463642502203584
Test Loss:  0.00031896622385829687
Valid Loss:  0.0003896541311405599
Epoch:  169  	Training Loss: 0.00046411732910200953
Test Loss:  0.0003184762899763882
Valid Loss:  0.0003891156811732799
Epoch:  170  	Training Loss: 0.0004636302182916552
Test Loss:  0.0003180422936566174
Valid Loss:  0.0003885937621816993
Epoch:  171  	Training Loss: 0.0004631647316273302
Test Loss:  0.0003176149330101907
Valid Loss:  0.0003880751319229603
Epoch:  172  	Training Loss: 0.0004627043381333351
Test Loss:  0.00031147210393100977
Valid Loss:  0.00038493864121846855
Epoch:  173  	Training Loss: 0.000458282302133739
Test Loss:  0.00031222315737977624
Valid Loss:  0.00038038688944652677
Epoch:  174  	Training Loss: 0.0004539575020316988
Test Loss:  0.00030434090876951814
Valid Loss:  0.00037832121597602963
Epoch:  175  	Training Loss: 0.0004496130277402699
Test Loss:  0.000307705020532012
Valid Loss:  0.00037346003227867186
Epoch:  176  	Training Loss: 0.0004452982684597373
Test Loss:  0.0002973254886455834
Valid Loss:  0.0003727175935637206
Epoch:  177  	Training Loss: 0.00044132611947134137
Test Loss:  0.00030526280170306563
Valid Loss:  0.00036716973409056664
Epoch:  178  	Training Loss: 0.0004376121796667576
Test Loss:  0.00029038856155239046
Valid Loss:  0.0003683420654851943
Epoch:  179  	Training Loss: 0.0004339353763498366
Test Loss:  0.0003047123027499765
Valid Loss:  0.0003612989094108343
Epoch:  180  	Training Loss: 0.00043027507490478456
Test Loss:  0.0002830545709002763
Valid Loss:  0.00036576850106939673
Epoch:  181  	Training Loss: 0.00042701588245108724
Test Loss:  0.00030901460559107363
Valid Loss:  0.00035671977093443274
Epoch:  182  	Training Loss: 0.00042466912418603897
Test Loss:  0.0002809010329656303
Valid Loss:  0.00035292431130073965
Epoch:  183  	Training Loss: 0.00041691382648423314
Test Loss:  0.0002869166783057153
Valid Loss:  0.0003468577633611858
Epoch:  184  	Training Loss: 0.0004122884711250663
Test Loss:  0.00027734419563785195
Valid Loss:  0.0003449143550824374
Epoch:  185  	Training Loss: 0.0004088002606295049
Test Loss:  0.0002780736540444195
Valid Loss:  0.0003420265857130289
Epoch:  186  	Training Loss: 0.0004060089122503996
Test Loss:  0.00027397103258408606
Valid Loss:  0.0003403554146643728
Epoch:  187  	Training Loss: 0.00040359178092330694
Test Loss:  0.0002733105793595314
Valid Loss:  0.00033836072543635964
Epoch:  188  	Training Loss: 0.0004013666184619069
Test Loss:  0.00027101964224129915
Valid Loss:  0.00033686196547932923
Epoch:  189  	Training Loss: 0.00039938976988196373
Test Loss:  0.0002699821488931775
Valid Loss:  0.0003353108186274767
Epoch:  190  	Training Loss: 0.00039752630982548
Test Loss:  0.0002683091734070331
Valid Loss:  0.0003340068506076932
Epoch:  191  	Training Loss: 0.000395826471503824
Test Loss:  0.00026716513093560934
Valid Loss:  0.00033271245774812996
Epoch:  192  	Training Loss: 0.0003942013718187809
Test Loss:  0.00026009982684627175
Valid Loss:  0.0003304421261418611
Epoch:  193  	Training Loss: 0.0003887090424541384
Test Loss:  0.0002620381419546902
Valid Loss:  0.000326108536683023
Epoch:  194  	Training Loss: 0.000383390870410949
Test Loss:  0.00025327084586024284
Valid Loss:  0.00032516999635845423
Epoch:  195  	Training Loss: 0.0003782250569202006
Test Loss:  0.0002591654774732888
Valid Loss:  0.00032035779440775514
Epoch:  196  	Training Loss: 0.00037336672539822757
Test Loss:  0.0002470514737069607
Valid Loss:  0.00032135596848092973
Epoch:  197  	Training Loss: 0.00036873482167720795
Test Loss:  0.0002592485980130732
Valid Loss:  0.00031564757227897644
Epoch:  198  	Training Loss: 0.00036462018033489585
Test Loss:  0.0002413212787359953
Valid Loss:  0.000319929065881297
Epoch:  199  	Training Loss: 0.00036111162626184523
Test Loss:  0.00026285432977601886
Valid Loss:  0.0003124008362647146
Epoch:  200  	Training Loss: 0.00035800706245936453
Test Loss:  0.0002366042317589745
Valid Loss:  0.00032241991721093655
Epoch:  201  	Training Loss: 0.0003562455822248012
Test Loss:  0.00027513448731042445
Valid Loss:  0.0003131708363071084
Epoch:  202  	Training Loss: 0.0003565961087588221
Test Loss:  0.00023268788936547935
Valid Loss:  0.0003176195896230638
Epoch:  203  	Training Loss: 0.0003523835039231926
Test Loss:  0.0002646123175509274
Valid Loss:  0.00030640442855656147
Epoch:  204  	Training Loss: 0.000348753877915442
Test Loss:  0.00023013641475699842
Valid Loss:  0.0003104273055214435
Epoch:  205  	Training Loss: 0.0003455606347415596
Test Loss:  0.00025627983268350363
Valid Loss:  0.0003010624786838889
Epoch:  206  	Training Loss: 0.0003427262417972088
Test Loss:   41%|████▏     | 207/500 [02:22<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:22<01:35,  3.03it/s] 42%|████▏     | 211/500 [02:28<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:28<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:28<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:28<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:28<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:35<05:25,  1.17s/it] 45%|████▍     | 223/500 [02:35<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:35<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:35<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:35<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:41<05:13,  1.17s/it] 47%|████▋     | 233/500 [02:42<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:42<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:42<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:42<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:48<05:02,  1.17s/it] 49%|████▊     | 243/500 [02:48<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:48<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:49<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:49<01:23,  3.01it/s] 50%|█████     | 251/500 [02:55<04:53,  1.18s/it] 51%|█████     | 253/500 [02:55<03:29,  1.18it/s] 51%|█████     | 255/500 [02:55<02:29,  1.63it/s] 51%|█████▏    | 257/500 [02:55<01:48,  2.23it/s] 52%|█████▏    | 259/500 [02:56<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:02<04:36,  1.16s/it] 53%|█████▎    | 263/500 [03:02<03:16,  1.20it/s] 53%|█████▎    | 265/500 [03:02<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:02<01:42,  2.27it/s] 54%|█████▍    | 269/500 [03:02<01:15,  3.05it/s] 54%|█████▍    | 271/500 [03:08<04:25,  1.16s/it]0.0002280861372128129
Valid Loss:  0.0003045137273147702
Epoch:  207  	Training Loss: 0.00034018041333183646
Test Loss:  0.0002494746877346188
Valid Loss:  0.0002966367464978248
Epoch:  208  	Training Loss: 0.00033790123416110873
Test Loss:  0.00022628766600973904
Valid Loss:  0.000299550942145288
Epoch:  209  	Training Loss: 0.00033580957097001374
Test Loss:  0.00024380284594371915
Valid Loss:  0.00029287621146067977
Epoch:  210  	Training Loss: 0.00033388673909939826
Test Loss:  0.00022464938228949904
Valid Loss:  0.00029526720754802227
Epoch:  211  	Training Loss: 0.0003321461845189333
Test Loss:  0.0002389958535786718
Valid Loss:  0.00028963154181838036
Epoch:  212  	Training Loss: 0.00033049925696104765
Test Loss:  0.00022897256712894887
Valid Loss:  0.0002896880905609578
Epoch:  213  	Training Loss: 0.0003287130093667656
Test Loss:  0.0002296808670507744
Valid Loss:  0.00028916788869537413
Epoch:  214  	Training Loss: 0.00032827776158228517
Test Loss:  0.00022920998162589967
Valid Loss:  0.000288693408947438
Epoch:  215  	Training Loss: 0.00032746317447163165
Test Loss:  0.00022833095863461494
Valid Loss:  0.00028755635139532387
Epoch:  216  	Training Loss: 0.00032587250461801887
Test Loss:  0.00022715554223395884
Valid Loss:  0.0002861393732018769
Epoch:  217  	Training Loss: 0.0003240270889364183
Test Loss:  0.0002262454217998311
Valid Loss:  0.0002849972224794328
Epoch:  218  	Training Loss: 0.00032258674036711454
Test Loss:  0.000225631330977194
Valid Loss:  0.00028430920792743564
Epoch:  219  	Training Loss: 0.00032170844497159123
Test Loss:  0.00022516449098475277
Valid Loss:  0.00028387209749780595
Epoch:  220  	Training Loss: 0.00032116088550537825
Test Loss:  0.0002247643715236336
Valid Loss:  0.00028347494662739336
Epoch:  221  	Training Loss: 0.0003207134432159364
Test Loss:  0.00022444044589065015
Valid Loss:  0.00028313504299148917
Epoch:  222  	Training Loss: 0.00032033753814175725
Test Loss:  0.00022363345487974584
Valid Loss:  0.00028127781115472317
Epoch:  223  	Training Loss: 0.0003187705879099667
Test Loss:  0.0002217629225924611
Valid Loss:  0.00027993146795779467
Epoch:  224  	Training Loss: 0.00031736865639686584
Test Loss:  0.00022054187138564885
Valid Loss:  0.0002786095137707889
Epoch:  225  	Training Loss: 0.0003160946653224528
Test Loss:  0.0002192348038079217
Valid Loss:  0.00027742149541154504
Epoch:  226  	Training Loss: 0.00031489174580201507
Test Loss:  0.00021807485609315336
Valid Loss:  0.0002762999793048948
Epoch:  227  	Training Loss: 0.000313752971123904
Test Loss:  0.00021697187912650406
Valid Loss:  0.00027524749748408794
Epoch:  228  	Training Loss: 0.00031267080339603126
Test Loss:  0.00021595277939923108
Valid Loss:  0.00027427769964560866
Epoch:  229  	Training Loss: 0.0003116208827123046
Test Loss:  0.00021501316223293543
Valid Loss:  0.000273356941761449
Epoch:  230  	Training Loss: 0.00031060169567354023
Test Loss:  0.00021414361253846437
Valid Loss:  0.0002724698861129582
Epoch:  231  	Training Loss: 0.0003096240689046681
Test Loss:  0.00021333211043383926
Valid Loss:  0.000271628494374454
Epoch:  232  	Training Loss: 0.0003086892538703978
Test Loss:  0.00021182512864470482
Valid Loss:  0.0002700925979297608
Epoch:  233  	Training Loss: 0.0003070843522436917
Test Loss:  0.00021052503143437207
Valid Loss:  0.0002686929074116051
Epoch:  234  	Training Loss: 0.00030564164626412094
Test Loss:  0.00020936975488439202
Valid Loss:  0.00026735171559266746
Epoch:  235  	Training Loss: 0.00030432228231802583
Test Loss:  0.0002083266736008227
Valid Loss:  0.00026609416818246245
Epoch:  236  	Training Loss: 0.0003031163359992206
Test Loss:  0.00020735198631882668
Valid Loss:  0.000264944217633456
Epoch:  237  	Training Loss: 0.00030198629247024655
Test Loss:  0.0002064096333924681
Valid Loss:  0.0002638271253090352
Epoch:  238  	Training Loss: 0.0003008812782354653
Test Loss:  0.000205567353987135
Valid Loss:  0.0002627609937917441
Epoch:  239  	Training Loss: 0.00029982050182297826
Test Loss:  0.0002047990565188229
Valid Loss:  0.00026172958314418793
Epoch:  240  	Training Loss: 0.0002988027990795672
Test Loss:  0.00020406523253768682
Valid Loss:  0.000260755157796666
Epoch:  241  	Training Loss: 0.0002978490956593305
Test Loss:  0.00020337742171250284
Valid Loss:  0.00025983856176026165
Epoch:  242  	Training Loss: 0.0002969576162286103
Test Loss:  0.00020350466365925968
Valid Loss:  0.000258754997048527
Epoch:  243  	Training Loss: 0.0002960937563329935
Test Loss:  0.00020251551177352667
Valid Loss:  0.00025825772900134325
Epoch:  244  	Training Loss: 0.00029540230752900243
Test Loss:  0.00020196025434415787
Valid Loss:  0.00025781692238524556
Epoch:  245  	Training Loss: 0.0002948472974821925
Test Loss:  0.00020150937780272216
Valid Loss:  0.00025745254242792726
Epoch:  246  	Training Loss: 0.0002943593717645854
Test Loss:  0.0002011305623454973
Valid Loss:  0.00025715038646012545
Epoch:  247  	Training Loss: 0.000293929100735113
Test Loss:  0.00020079662499483675
Valid Loss:  0.0002569148491602391
Epoch:  248  	Training Loss: 0.00029355072183534503
Test Loss:  0.00020054398919455707
Valid Loss:  0.000256704690400511
Epoch:  249  	Training Loss: 0.0002932014758698642
Test Loss:  0.00020032597240060568
Valid Loss:  0.00025652541080489755
Epoch:  250  	Training Loss: 0.00029287728830240667
Test Loss:  0.0002001521352212876
Valid Loss:  0.00025636478676460683
Epoch:  251  	Training Loss: 0.0002925751614384353
Test Loss:  0.00019998106290586293
Valid Loss:  0.00025623146211728454
Epoch:  252  	Training Loss: 0.0002922985004261136
Test Loss:  0.0001976189378183335
Valid Loss:  0.0002542940201237798
Epoch:  253  	Training Loss: 0.00029023183742538095
Test Loss:  0.00019579014042392373
Valid Loss:  0.00025249479222111404
Epoch:  254  	Training Loss: 0.0002883865963667631
Test Loss:  0.00019427723600529134
Valid Loss:  0.00025080243358388543
Epoch:  255  	Training Loss: 0.0002866875729523599
Test Loss:  0.00019296850950922817
Valid Loss:  0.0002492065541446209
Epoch:  256  	Training Loss: 0.0002851138124242425
Test Loss:  0.00019179035734850913
Valid Loss:  0.0002476991794537753
Epoch:  257  	Training Loss: 0.0002836478815879673
Test Loss:  0.0001907074183691293
Valid Loss:  0.0002462821430526674
Epoch:  258  	Training Loss: 0.0002822733949869871
Test Loss:  0.00018961611203849316
Valid Loss:  0.00024493387900292873
Epoch:  259  	Training Loss: 0.0002809834259096533
Test Loss:  0.00018874352099373937
Valid Loss:  0.00024367438163608313
Epoch:  260  	Training Loss: 0.00027977273566648364
Test Loss:  0.00018781248945742846
Valid Loss:  0.00024245659005828202
Epoch:  261  	Training Loss: 0.00027864339062944055
Test Loss:  0.0001871044369181618
Valid Loss:  0.0002413029142189771
Epoch:  262  	Training Loss: 0.0002775763859972358
Test Loss:  0.0001886364188976586
Valid Loss:  0.00023968836467247456
Epoch:  263  	Training Loss: 0.0002764057135209441
Test Loss:  0.00018616506713442504
Valid Loss:  0.0002389941510045901
Epoch:  264  	Training Loss: 0.00027533897082321346
Test Loss:  0.00018640910275280476
Valid Loss:  0.0002378843491896987
Epoch:  265  	Training Loss: 0.0002743162913247943
Test Loss:  0.000185092183528468
Valid Loss:  0.00023720892204437405
Epoch:  266  	Training Loss: 0.0002733709989115596
Test Loss:  0.0001849046238930896
Valid Loss:  0.00023647738271392882
Epoch:  267  	Training Loss: 0.0002725298691075295
Test Loss:  0.00018410233315080404
Valid Loss:  0.00023596550454385579
Epoch:  268  	Training Loss: 0.0002717707247938961
Test Loss:  0.00018377965898253024
Valid Loss:  0.00023545246222056448
Epoch:  269  	Training Loss: 0.00027108602807857096
Test Loss:  0.00018322389223612845
Valid Loss:  0.00023504087585024536
Epoch:  270  	Training Loss: 0.0002704802027437836
Test Loss:  0.00018288384308107197
Valid Loss:  0.00023465490085072815
Epoch:  271  	Training Loss: 0.00026994431391358376
Test Loss:  0.00018252385780215263
Valid Loss:  0.00023427975247614086
Epoch:  272  	Training Loss: 0.00026943275588564575
Test Loss:  0.00017758429748937488
Valid Loss:  0.00023413081362377852
Epoch:  273  	Training Loss: 0.0002660769096110016
Test Loss:  0.0001766624627634883
Valid Loss:   55%|█████▍    | 273/500 [03:09<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:09<02:15,  1.66it/s] 55%|█████▌    | 277/500 [03:09<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:09<01:12,  3.03it/s] 56%|█████▌    | 281/500 [03:15<04:13,  1.16s/it] 57%|█████▋    | 283/500 [03:15<03:00,  1.20it/s] 57%|█████▋    | 285/500 [03:16<02:09,  1.66it/s] 57%|█████▋    | 287/500 [03:16<01:33,  2.27it/s] 58%|█████▊    | 289/500 [03:16<01:09,  3.04it/s] 58%|█████▊    | 291/500 [03:22<04:03,  1.16s/it] 59%|█████▊    | 293/500 [03:22<02:53,  1.20it/s] 59%|█████▉    | 295/500 [03:22<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:22<01:29,  2.26it/s] 60%|█████▉    | 299/500 [03:23<01:06,  3.03it/s] 60%|██████    | 301/500 [03:29<03:50,  1.16s/it] 61%|██████    | 303/500 [03:29<02:44,  1.20it/s] 61%|██████    | 305/500 [03:29<01:57,  1.66it/s] 61%|██████▏   | 307/500 [03:29<01:25,  2.26it/s] 62%|██████▏   | 309/500 [03:29<01:02,  3.03it/s] 62%|██████▏   | 311/500 [03:36<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:36<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:36<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:36<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:36<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:42<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:42<02:29,  1.19it/s] 65%|██████▌   | 325/500 [03:43<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:43<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:43<00:56,  3.02it/s] 66%|██████▌   | 331/500 [03:49<03:16,  1.16s/it] 67%|██████▋   | 333/500 [03:49<02:19,  1.20it/s] 67%|██████▋   | 335/500 [03:49<01:39,  1.66it/s] 67%|██████▋   | 337/500 [03:49<01:11,  2.27it/s] 68%|██████▊   | 339/500 [03:50<00:52,  3.04it/s]0.00023294679704122245
Epoch:  274  	Training Loss: 0.0002635892597027123
Test Loss:  0.00017580340499989688
Valid Loss:  0.00023184006568044424
Epoch:  275  	Training Loss: 0.00026116662775166333
Test Loss:  0.00017515382205601782
Valid Loss:  0.0002307170070707798
Epoch:  276  	Training Loss: 0.0002589084324426949
Test Loss:  0.00017452353495173156
Valid Loss:  0.00022967395489104092
Epoch:  277  	Training Loss: 0.0002568013151176274
Test Loss:  0.0001738563587423414
Valid Loss:  0.00022865587379783392
Epoch:  278  	Training Loss: 0.00025478703901171684
Test Loss:  0.00017298707098234445
Valid Loss:  0.00022768843336962163
Epoch:  279  	Training Loss: 0.0002527767210267484
Test Loss:  0.00017221842426806688
Valid Loss:  0.00022670975886285305
Epoch:  280  	Training Loss: 0.0002508631441742182
Test Loss:  0.00017145127640105784
Valid Loss:  0.00022561836522072554
Epoch:  281  	Training Loss: 0.00024902744917199016
Test Loss:  0.0001706996699795127
Valid Loss:  0.0002244871575385332
Epoch:  282  	Training Loss: 0.0002472605847287923
Test Loss:  0.00017247465439140797
Valid Loss:  0.00021982291946187615
Epoch:  283  	Training Loss: 0.0002443389385007322
Test Loss:  0.00017067865701392293
Valid Loss:  0.0002182449388783425
Epoch:  284  	Training Loss: 0.00024295099137816578
Test Loss:  0.00016965324175544083
Valid Loss:  0.00021705287508666515
Epoch:  285  	Training Loss: 0.00024192853015847504
Test Loss:  0.00016892366693355143
Valid Loss:  0.0002161785087082535
Epoch:  286  	Training Loss: 0.00024114131520036608
Test Loss:  0.00016836942813824862
Valid Loss:  0.00021551412646658719
Epoch:  287  	Training Loss: 0.00024050130741670728
Test Loss:  0.00016793687245808542
Valid Loss:  0.00021499412832781672
Epoch:  288  	Training Loss: 0.00023994906223379076
Test Loss:  0.0001675932144280523
Valid Loss:  0.00021455666865222156
Epoch:  289  	Training Loss: 0.00023948153830133379
Test Loss:  0.0001672956714173779
Valid Loss:  0.0002142201119568199
Epoch:  290  	Training Loss: 0.000239081826293841
Test Loss:  0.00016704376321285963
Valid Loss:  0.0002139484859071672
Epoch:  291  	Training Loss: 0.00023873246391303837
Test Loss:  0.00016681088891346008
Valid Loss:  0.0002137272385880351
Epoch:  292  	Training Loss: 0.00023842908558435738
Test Loss:  0.00016505137318745255
Valid Loss:  0.00021298957290127873
Epoch:  293  	Training Loss: 0.00023737052106298506
Test Loss:  0.00016461446648463607
Valid Loss:  0.00021210293925832957
Epoch:  294  	Training Loss: 0.0002365017426200211
Test Loss:  0.00016401175525970757
Valid Loss:  0.00021134622511453927
Epoch:  295  	Training Loss: 0.00023570933262817562
Test Loss:  0.00016352800594177097
Valid Loss:  0.0002105828607454896
Epoch:  296  	Training Loss: 0.0002349689311813563
Test Loss:  0.00016297164256684482
Valid Loss:  0.00020986999152228236
Epoch:  297  	Training Loss: 0.00023427221458405256
Test Loss:  0.00016243569552898407
Valid Loss:  0.00020918370864819735
Epoch:  298  	Training Loss: 0.0002336063189432025
Test Loss:  0.00016192253679037094
Valid Loss:  0.00020852420129813254
Epoch:  299  	Training Loss: 0.00023297767620533705
Test Loss:  0.000161431118613109
Valid Loss:  0.00020788193796761334
Epoch:  300  	Training Loss: 0.00023237994173541665
Test Loss:  0.00016096032049972564
Valid Loss:  0.00020724994828924537
Epoch:  301  	Training Loss: 0.00023180257994681597
Test Loss:  0.00016050151316449046
Valid Loss:  0.00020662804308813065
Epoch:  302  	Training Loss: 0.00023124455765355378
Test Loss:  0.00016026676166802645
Valid Loss:  0.0002063463907688856
Epoch:  303  	Training Loss: 0.00023099302779883146
Test Loss:  0.0001600919058546424
Valid Loss:  0.00020604343444574624
Epoch:  304  	Training Loss: 0.00023074487398844212
Test Loss:  0.00015990504471119493
Valid Loss:  0.0002057500823866576
Epoch:  305  	Training Loss: 0.00023050003801472485
Test Loss:  0.00015967112267389894
Valid Loss:  0.00020548133761622012
Epoch:  306  	Training Loss: 0.0002302584471181035
Test Loss:  0.0001595013018231839
Valid Loss:  0.00020518983365036547
Epoch:  307  	Training Loss: 0.00023002097441349179
Test Loss:  0.0001593235065229237
Valid Loss:  0.00020490909810177982
Epoch:  308  	Training Loss: 0.00022978975903242826
Test Loss:  0.00015909766079857945
Valid Loss:  0.00020465240231715143
Epoch:  309  	Training Loss: 0.00022956161410547793
Test Loss:  0.00015893549425527453
Valid Loss:  0.00020437230705283582
Epoch:  310  	Training Loss: 0.0002293347497470677
Test Loss:  0.00015876222460065037
Valid Loss:  0.00020410044817253947
Epoch:  311  	Training Loss: 0.00022911137784831226
Test Loss:  0.0001585430873092264
Valid Loss:  0.00020385048992466182
Epoch:  312  	Training Loss: 0.0002288910181960091
Test Loss:  0.00015847288887016475
Valid Loss:  0.00020246834901627153
Epoch:  313  	Training Loss: 0.0002278406172990799
Test Loss:  0.00015820941189303994
Valid Loss:  0.0002014633791986853
Epoch:  314  	Training Loss: 0.0002270268159918487
Test Loss:  0.0001577810908202082
Valid Loss:  0.00020070705795660615
Epoch:  315  	Training Loss: 0.00022634404012933373
Test Loss:  0.0001573121699038893
Valid Loss:  0.0002000615932047367
Epoch:  316  	Training Loss: 0.00022571900626644492
Test Loss:  0.00015681653167121112
Valid Loss:  0.00019948516273871064
Epoch:  317  	Training Loss: 0.0002251446567242965
Test Loss:  0.00015633142902515829
Valid Loss:  0.00019897034508176148
Epoch:  318  	Training Loss: 0.00022460403852164745
Test Loss:  0.00015585104119963944
Valid Loss:  0.00019850002718158066
Epoch:  319  	Training Loss: 0.00022409851953852922
Test Loss:  0.00015537184663116932
Valid Loss:  0.00019806613272521645
Epoch:  320  	Training Loss: 0.00022363039897754788
Test Loss:  0.00015492780948989093
Valid Loss:  0.0001976519706659019
Epoch:  321  	Training Loss: 0.00022317792172543705
Test Loss:  0.00015454061212949455
Valid Loss:  0.00019725316087715328
Epoch:  322  	Training Loss: 0.00022273766808211803
Test Loss:  0.00014767248649150133
Valid Loss:  0.00019436930597294122
Epoch:  323  	Training Loss: 0.0002172304957639426
Test Loss:  0.00014787113468628377
Valid Loss:  0.00018897023983299732
Epoch:  324  	Training Loss: 0.000211240621865727
Test Loss:  0.00014054073835723102
Valid Loss:  0.00018639941117726266
Epoch:  325  	Training Loss: 0.00020509738533291966
Test Loss:  0.00014062257832847536
Valid Loss:  0.00018070393707603216
Epoch:  326  	Training Loss: 0.0001987109426409006
Test Loss:  0.00013275889796204865
Valid Loss:  0.00017812350415624678
Epoch:  327  	Training Loss: 0.00019194462220184505
Test Loss:  0.00013262925494927913
Valid Loss:  0.00017181350267492235
Epoch:  328  	Training Loss: 0.00018505469779483974
Test Loss:  0.0001249496708624065
Valid Loss:  0.00016882154159247875
Epoch:  329  	Training Loss: 0.00017852301243692636
Test Loss:  0.00012490333756431937
Valid Loss:  0.00016206401051022112
Epoch:  330  	Training Loss: 0.00017233265680260956
Test Loss:  0.00011733281280612573
Valid Loss:  0.0001598757808096707
Epoch:  331  	Training Loss: 0.0001663677830947563
Test Loss:  0.00011765205999836326
Valid Loss:  0.00015334755880758166
Epoch:  332  	Training Loss: 0.0001606191653991118
Test Loss:  0.0001162687040050514
Valid Loss:  0.00015335041098296642
Epoch:  333  	Training Loss: 0.00016012188280001283
Test Loss:  0.00011576936230994761
Valid Loss:  0.00015308233560062945
Epoch:  334  	Training Loss: 0.000159749950398691
Test Loss:  0.00011543568689376116
Valid Loss:  0.00015276609337888658
Epoch:  335  	Training Loss: 0.00015940979938022792
Test Loss:  0.00011514560901559889
Valid Loss:  0.0001524521067040041
Epoch:  336  	Training Loss: 0.00015909160720184445
Test Loss:  0.00011487743176985532
Valid Loss:  0.00015215034363791347
Epoch:  337  	Training Loss: 0.00015879582497291267
Test Loss:  0.0001146215945482254
Valid Loss:  0.00015185991651378572
Epoch:  338  	Training Loss: 0.00015851357602514327
Test Loss:  0.00011437541979830712
Valid Loss:  0.00015157926827669144
Epoch:  339  	Training Loss: 0.000158244016347453
Test Loss:  0.00011414056643843651
Valid Loss:  0.0001513107563368976
Epoch:  340  	Training Loss: 0.00015798673848621547
Test Loss:  0.0001139139203587547
Valid Loss:   68%|██████▊   | 341/500 [03:56<03:04,  1.16s/it] 69%|██████▊   | 343/500 [03:56<02:10,  1.20it/s] 69%|██████▉   | 345/500 [03:56<01:33,  1.66it/s] 69%|██████▉   | 347/500 [03:56<01:07,  2.27it/s] 70%|██████▉   | 349/500 [03:56<00:49,  3.04it/s] 70%|███████   | 351/500 [04:03<02:53,  1.16s/it] 71%|███████   | 353/500 [04:03<02:02,  1.20it/s] 71%|███████   | 355/500 [04:03<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:03<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:03<00:46,  3.03it/s] 72%|███████▏  | 361/500 [04:09<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:09<01:54,  1.19it/s] 73%|███████▎  | 365/500 [04:10<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:10<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:10<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:16<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:16<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:16<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:17<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:17<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:23<02:18,  1.16s/it] 77%|███████▋  | 383/500 [04:23<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:23<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:23<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:23<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:30<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:30<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:30<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:30<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:30<00:33,  3.00it/s] 80%|████████  | 401/500 [04:37<01:55,  1.17s/it] 81%|████████  | 403/500 [04:37<01:21,  1.19it/s] 81%|████████  | 405/500 [04:37<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:37<00:41,  2.24it/s]0.00015104938938748091
Epoch:  341  	Training Loss: 0.00015773996710777283
Test Loss:  0.00011369521234882995
Valid Loss:  0.00015079256263561547
Epoch:  342  	Training Loss: 0.00015750080638099462
Test Loss:  0.00010921540524577722
Valid Loss:  0.00014695683785248548
Epoch:  343  	Training Loss: 0.00015160317707341164
Test Loss:  0.0001066173572326079
Valid Loss:  0.00014265674690250307
Epoch:  344  	Training Loss: 0.00014619927969761193
Test Loss:  0.00010270432539982721
Valid Loss:  0.00013958863564766943
Epoch:  345  	Training Loss: 0.0001410406839568168
Test Loss:  0.00010000397742260247
Valid Loss:  0.00013567502901423723
Epoch:  346  	Training Loss: 0.00013620301615446806
Test Loss:  9.604608931113034e-05
Valid Loss:  0.00013264620793052018
Epoch:  347  	Training Loss: 0.00013161540846340358
Test Loss:  9.36732831178233e-05
Valid Loss:  0.00012838930706493556
Epoch:  348  	Training Loss: 0.0001271815854124725
Test Loss:  9.00623927009292e-05
Valid Loss:  0.00012511920067481697
Epoch:  349  	Training Loss: 0.00012293874169699848
Test Loss:  8.795423491392285e-05
Valid Loss:  0.00012106574286008254
Epoch:  350  	Training Loss: 0.00011885723506566137
Test Loss:  8.466088911518455e-05
Valid Loss:  0.00011815303878393024
Epoch:  351  	Training Loss: 0.00011497780360514298
Test Loss:  8.279888425022364e-05
Valid Loss:  0.0001143997214967385
Epoch:  352  	Training Loss: 0.00011122181604150683
Test Loss:  7.907471444923431e-05
Valid Loss:  0.00011290208203718066
Epoch:  353  	Training Loss: 0.00010857093730010092
Test Loss:  7.766226190142334e-05
Valid Loss:  0.0001104819166357629
Epoch:  354  	Training Loss: 0.00010640457912813872
Test Loss:  7.607795851072297e-05
Valid Loss:  0.00010831837425939739
Epoch:  355  	Training Loss: 0.00010431509872432798
Test Loss:  7.458231993950903e-05
Valid Loss:  0.00010620684770401567
Epoch:  356  	Training Loss: 0.00010229008330497891
Test Loss:  7.313406968023628e-05
Valid Loss:  0.00010416981967864558
Epoch:  357  	Training Loss: 0.00010032720456365496
Test Loss:  7.173590711317956e-05
Valid Loss:  0.00010220468539046124
Epoch:  358  	Training Loss: 9.842438157647848e-05
Test Loss:  7.038530748104677e-05
Valid Loss:  0.00010030668636318296
Epoch:  359  	Training Loss: 9.656421025283635e-05
Test Loss:  6.90456508891657e-05
Valid Loss:  9.846592729445547e-05
Epoch:  360  	Training Loss: 9.473256068304181e-05
Test Loss:  6.77727148286067e-05
Valid Loss:  9.667046833783388e-05
Epoch:  361  	Training Loss: 9.295588824898005e-05
Test Loss:  6.65396946715191e-05
Valid Loss:  9.493525431025773e-05
Epoch:  362  	Training Loss: 9.123240306507796e-05
Test Loss:  6.429359200410545e-05
Valid Loss:  9.114308340940624e-05
Epoch:  363  	Training Loss: 8.755724411457777e-05
Test Loss:  6.164901424199343e-05
Valid Loss:  8.819488721201196e-05
Epoch:  364  	Training Loss: 8.420950325671583e-05
Test Loss:  5.978131957817823e-05
Valid Loss:  8.509898907504976e-05
Epoch:  365  	Training Loss: 8.111167699098587e-05
Test Loss:  5.75666235818062e-05
Valid Loss:  8.244921627920121e-05
Epoch:  366  	Training Loss: 7.82105780672282e-05
Test Loss:  5.597532435785979e-05
Valid Loss:  7.970215665409341e-05
Epoch:  367  	Training Loss: 7.553253090009093e-05
Test Loss:  5.407672142609954e-05
Valid Loss:  7.737339910818264e-05
Epoch:  368  	Training Loss: 7.302920857910067e-05
Test Loss:  5.256180156720802e-05
Valid Loss:  7.48022721381858e-05
Epoch:  369  	Training Loss: 7.065348472679034e-05
Test Loss:  5.088371835881844e-05
Valid Loss:  7.246524910442531e-05
Epoch:  370  	Training Loss: 6.838816625531763e-05
Test Loss:  4.945154068991542e-05
Valid Loss:  7.01372919138521e-05
Epoch:  371  	Training Loss: 6.616893369937316e-05
Test Loss:  4.786913268617354e-05
Valid Loss:  6.803114229114726e-05
Epoch:  372  	Training Loss: 6.404035957530141e-05
Test Loss:  4.801031536771916e-05
Valid Loss:  6.787339225411415e-05
Epoch:  373  	Training Loss: 6.397456309059635e-05
Test Loss:  4.8092253564391285e-05
Valid Loss:  6.777257658541203e-05
Epoch:  374  	Training Loss: 6.393450894393027e-05
Test Loss:  4.813785199075937e-05
Valid Loss:  6.769738683942705e-05
Epoch:  375  	Training Loss: 6.390354974428192e-05
Test Loss:  4.816302316612564e-05
Valid Loss:  6.763770215911791e-05
Epoch:  376  	Training Loss: 6.38814817648381e-05
Test Loss:  4.815385182155296e-05
Valid Loss:  6.760359974578023e-05
Epoch:  377  	Training Loss: 6.386164022842422e-05
Test Loss:  4.8149733629543334e-05
Valid Loss:  6.757068331353366e-05
Epoch:  378  	Training Loss: 6.384340667864308e-05
Test Loss:  4.814851126866415e-05
Valid Loss:  6.753968773409724e-05
Epoch:  379  	Training Loss: 6.382656283676624e-05
Test Loss:  4.8149569920497015e-05
Valid Loss:  6.751013279426843e-05
Epoch:  380  	Training Loss: 6.3812178268563e-05
Test Loss:  4.817619628738612e-05
Valid Loss:  6.746577855665237e-05
Epoch:  381  	Training Loss: 6.379895785357803e-05
Test Loss:  4.816772707272321e-05
Valid Loss:  6.744475103914738e-05
Epoch:  382  	Training Loss: 6.37857592664659e-05
Test Loss:  4.7541157982777804e-05
Valid Loss:  6.667441630270332e-05
Epoch:  383  	Training Loss: 6.294442573562264e-05
Test Loss:  4.7110861487453803e-05
Valid Loss:  6.586412928299978e-05
Epoch:  384  	Training Loss: 6.213301821844652e-05
Test Loss:  4.644845466827974e-05
Valid Loss:  6.51794471195899e-05
Epoch:  385  	Training Loss: 6.134100840426981e-05
Test Loss:  4.6113691496429965e-05
Valid Loss:  6.440944707719609e-05
Epoch:  386  	Training Loss: 6.058108920115046e-05
Test Loss:  4.5473854697775096e-05
Valid Loss:  6.378602120094001e-05
Epoch:  387  	Training Loss: 5.985336611047387e-05
Test Loss:  4.522665039985441e-05
Valid Loss:  6.3055515056476e-05
Epoch:  388  	Training Loss: 5.915274959988892e-05
Test Loss:  4.454542795429006e-05
Valid Loss:  6.250382284633815e-05
Epoch:  389  	Training Loss: 5.846982094226405e-05
Test Loss:  4.438464384293184e-05
Valid Loss:  6.180327181937173e-05
Epoch:  390  	Training Loss: 5.780379433417693e-05
Test Loss:  4.368453301140107e-05
Valid Loss:  6.129962275736034e-05
Epoch:  391  	Training Loss: 5.716080340789631e-05
Test Loss:  4.3613916204776615e-05
Valid Loss:  6.0632562963292e-05
Epoch:  392  	Training Loss: 5.654188134940341e-05
Test Loss:  4.341067688073963e-05
Valid Loss:  6.051039963494986e-05
Epoch:  393  	Training Loss: 5.644541670335457e-05
Test Loss:  4.330643423600122e-05
Valid Loss:  6.039729487383738e-05
Epoch:  394  	Training Loss: 5.63627909286879e-05
Test Loss:  4.323502798797563e-05
Valid Loss:  6.028611460351385e-05
Epoch:  395  	Training Loss: 5.628298458759673e-05
Test Loss:  4.317415732657537e-05
Valid Loss:  6.0175581893417984e-05
Epoch:  396  	Training Loss: 5.620472802547738e-05
Test Loss:  4.311766315368004e-05
Valid Loss:  6.006761032040231e-05
Epoch:  397  	Training Loss: 5.612754466710612e-05
Test Loss:  4.3062282202299684e-05
Valid Loss:  5.996138497721404e-05
Epoch:  398  	Training Loss: 5.6051372666843235e-05
Test Loss:  4.300758155295625e-05
Valid Loss:  5.985723691992462e-05
Epoch:  399  	Training Loss: 5.5976081057451665e-05
Test Loss:  4.295251710573211e-05
Valid Loss:  5.975474778097123e-05
Epoch:  400  	Training Loss: 5.590196087723598e-05
Test Loss:  4.2897838284261525e-05
Valid Loss:  5.965386299067177e-05
Epoch:  401  	Training Loss: 5.582834273809567e-05
Test Loss:  4.28425264544785e-05
Valid Loss:  5.955421511316672e-05
Epoch:  402  	Training Loss: 5.57555649720598e-05
Test Loss:  4.270369390724227e-05
Valid Loss:  5.9248613979434595e-05
Epoch:  403  	Training Loss: 5.551559297600761e-05
Test Loss:  4.253846054780297e-05
Valid Loss:  5.8954799897037446e-05
Epoch:  404  	Training Loss: 5.5281358072534204e-05
Test Loss:  4.2376548663014546e-05
Valid Loss:  5.866796709597111e-05
Epoch:  405  	Training Loss: 5.505238368641585e-05
Test Loss:  4.221581184538081e-05
Valid Loss:  5.838769720867276e-05
Epoch:  406  	Training Loss: 5.4828393331263214e-05
Test Loss:  4.205697769066319e-05
Valid Loss:  5.811323717352934e-05
Epoch:  407  	Training Loss: 5.4609408834949136e-05
Test Loss:  4.190191611996852e-05
Valid Loss:  5.784527456853539e-05
Epoch:  408  	Training Loss: 5.439497181214392e-05
Test Loss:  4.1750998207135126e-05
 82%|████████▏ | 409/500 [04:37<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:43<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:44<01:14,  1.18it/s] 83%|████████▎ | 415/500 [04:44<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:44<00:37,  2.22it/s] 84%|████████▍ | 419/500 [04:44<00:27,  2.98it/s] 84%|████████▍ | 421/500 [04:50<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:50<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:50<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:51<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:51<00:23,  3.01it/s] 86%|████████▌ | 431/500 [04:57<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:57<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:57<00:39,  1.64it/s] 87%|████████▋ | 437/500 [04:57<00:28,  2.24it/s] 88%|████████▊ | 439/500 [04:58<00:20,  3.01it/s] 88%|████████▊ | 441/500 [05:04<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:04<00:48,  1.19it/s] 89%|████████▉ | 445/500 [05:04<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:04<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:04<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:11<00:56,  1.16s/it] 91%|█████████ | 453/500 [05:11<00:39,  1.21it/s] 91%|█████████ | 455/500 [05:11<00:27,  1.67it/s] 91%|█████████▏| 457/500 [05:11<00:18,  2.27it/s] 92%|█████████▏| 459/500 [05:11<00:13,  3.06it/s] 92%|█████████▏| 461/500 [05:23<01:21,  2.09s/it] 93%|█████████▎| 463/500 [05:24<00:54,  1.48s/it] 93%|█████████▎| 465/500 [05:24<00:37,  1.06s/it] 93%|█████████▎| 467/500 [05:24<00:25,  1.31it/s] 94%|█████████▍| 469/500 [05:24<00:17,  1.81it/s] 94%|█████████▍| 471/500 [05:30<00:38,  1.32s/it] 95%|█████████▍| 473/500 [05:30<00:25,  1.06it/s]Valid Loss:  5.758259794674814e-05
Epoch:  409  	Training Loss: 5.418528962763958e-05
Test Loss:  4.1603656427469105e-05
Valid Loss:  5.7325167290400714e-05
Epoch:  410  	Training Loss: 5.398007124313153e-05
Test Loss:  4.146014543948695e-05
Valid Loss:  5.707349191652611e-05
Epoch:  411  	Training Loss: 5.3779273002874106e-05
Test Loss:  4.132094181841239e-05
Valid Loss:  5.682679693563841e-05
Epoch:  412  	Training Loss: 5.358277849154547e-05
Test Loss:  4.047257243655622e-05
Valid Loss:  5.5707801948301494e-05
Epoch:  413  	Training Loss: 5.2423078159336e-05
Test Loss:  3.987540549132973e-05
Valid Loss:  5.462258923216723e-05
Epoch:  414  	Training Loss: 5.133470403961837e-05
Test Loss:  3.921923052985221e-05
Valid Loss:  5.36049046786502e-05
Epoch:  415  	Training Loss: 5.02872426295653e-05
Test Loss:  3.863634992740117e-05
Valid Loss:  5.263730781734921e-05
Epoch:  416  	Training Loss: 4.929264832753688e-05
Test Loss:  3.805910819210112e-05
Valid Loss:  5.171325756236911e-05
Epoch:  417  	Training Loss: 4.8328187403967604e-05
Test Loss:  3.7517049349844456e-05
Valid Loss:  5.083384894533083e-05
Epoch:  418  	Training Loss: 4.740897202282213e-05
Test Loss:  3.697411739267409e-05
Valid Loss:  4.9998539907392114e-05
Epoch:  419  	Training Loss: 4.653331416193396e-05
Test Loss:  3.644858952611685e-05
Valid Loss:  4.920337596558966e-05
Epoch:  420  	Training Loss: 4.569842712953687e-05
Test Loss:  3.5950710298493505e-05
Valid Loss:  4.8446519940625876e-05
Epoch:  421  	Training Loss: 4.490224819164723e-05
Test Loss:  3.547738742781803e-05
Valid Loss:  4.772488318849355e-05
Epoch:  422  	Training Loss: 4.414138675201684e-05
Test Loss:  3.492282485240139e-05
Valid Loss:  4.6927241783123463e-05
Epoch:  423  	Training Loss: 4.335189441917464e-05
Test Loss:  3.446081609581597e-05
Valid Loss:  4.6175147872418165e-05
Epoch:  424  	Training Loss: 4.260108107700944e-05
Test Loss:  3.4018368751276284e-05
Valid Loss:  4.5462307753041387e-05
Epoch:  425  	Training Loss: 4.18830277340021e-05
Test Loss:  3.358276444487274e-05
Valid Loss:  4.477507172850892e-05
Epoch:  426  	Training Loss: 4.1195911762770265e-05
Test Loss:  3.318078233860433e-05
Valid Loss:  4.412222187966108e-05
Epoch:  427  	Training Loss: 4.0529881516704336e-05
Test Loss:  3.277906580478884e-05
Valid Loss:  4.348417860455811e-05
Epoch:  428  	Training Loss: 3.988511161878705e-05
Test Loss:  3.2411822758149356e-05
Valid Loss:  4.2878178646788e-05
Epoch:  429  	Training Loss: 3.9267099054995924e-05
Test Loss:  3.2054442272055894e-05
Valid Loss:  4.229753540130332e-05
Epoch:  430  	Training Loss: 3.8675432733725756e-05
Test Loss:  3.171111529809423e-05
Valid Loss:  4.173530396656133e-05
Epoch:  431  	Training Loss: 3.810809721471742e-05
Test Loss:  3.13943310175091e-05
Valid Loss:  4.1202292777597904e-05
Epoch:  432  	Training Loss: 3.7564022932201624e-05
Test Loss:  3.143435242236592e-05
Valid Loss:  4.121192614547908e-05
Epoch:  433  	Training Loss: 3.756031219381839e-05
Test Loss:  3.14544013235718e-05
Valid Loss:  4.121271922485903e-05
Epoch:  434  	Training Loss: 3.755844954866916e-05
Test Loss:  3.1471357942791656e-05
Valid Loss:  4.121620440855622e-05
Epoch:  435  	Training Loss: 3.755719808395952e-05
Test Loss:  3.148136966046877e-05
Valid Loss:  4.1217728721676394e-05
Epoch:  436  	Training Loss: 3.755622310563922e-05
Test Loss:  3.1487434171140194e-05
Valid Loss:  4.121832171222195e-05
Epoch:  437  	Training Loss: 3.75554955098778e-05
Test Loss:  3.14905155391898e-05
Valid Loss:  4.1217528632842004e-05
Epoch:  438  	Training Loss: 3.7554826121777296e-05
Test Loss:  3.14920034725219e-05
Valid Loss:  4.1216313547920436e-05
Epoch:  439  	Training Loss: 3.7554087612079456e-05
Test Loss:  3.149265830870718e-05
Valid Loss:  4.1214625525753945e-05
Epoch:  440  	Training Loss: 3.75533927581273e-05
Test Loss:  3.149276381009258e-05
Valid Loss:  4.1212875657947734e-05
Epoch:  441  	Training Loss: 3.755285797524266e-05
Test Loss:  3.149244002997875e-05
Valid Loss:  4.1211096686311066e-05
Epoch:  442  	Training Loss: 3.755219222512096e-05
Test Loss:  3.153349825879559e-05
Valid Loss:  4.121282108826563e-05
Epoch:  443  	Training Loss: 3.754904173547402e-05
Test Loss:  3.155284866807051e-05
Valid Loss:  4.1211962525267154e-05
Epoch:  444  	Training Loss: 3.754775752895512e-05
Test Loss:  3.156183083774522e-05
Valid Loss:  4.120959056308493e-05
Epoch:  445  	Training Loss: 3.75468771380838e-05
Test Loss:  3.1565825338475406e-05
Valid Loss:  4.120600351598114e-05
Epoch:  446  	Training Loss: 3.754604404093698e-05
Test Loss:  3.156798265990801e-05
Valid Loss:  4.120262383366935e-05
Epoch:  447  	Training Loss: 3.7545119994319975e-05
Test Loss:  3.156872116960585e-05
Valid Loss:  4.119870573049411e-05
Epoch:  448  	Training Loss: 3.754432691494003e-05
Test Loss:  3.1568841222906485e-05
Valid Loss:  4.119511868339032e-05
Epoch:  449  	Training Loss: 3.7543570215348154e-05
Test Loss:  3.156898310407996e-05
Valid Loss:  4.119138611713424e-05
Epoch:  450  	Training Loss: 3.754272620426491e-05
Test Loss:  3.1568815757054836e-05
Valid Loss:  4.118763899896294e-05
Epoch:  451  	Training Loss: 3.7541954952757806e-05
Test Loss:  3.156837192364037e-05
Valid Loss:  4.11842338507995e-05
Epoch:  452  	Training Loss: 3.754131466848776e-05
Test Loss:  3.108474629698321e-05
Valid Loss:  4.096048724022694e-05
Epoch:  453  	Training Loss: 3.7294488720363006e-05
Test Loss:  3.1488496460951865e-05
Valid Loss:  4.0923914639279246e-05
Epoch:  454  	Training Loss: 3.709566226461902e-05
Test Loss:  3.0469882403849624e-05
Valid Loss:  4.066725159646012e-05
Epoch:  455  	Training Loss: 3.700050729094073e-05
Test Loss:  3.256278432672843e-05
Valid Loss:  4.1300998418591917e-05
Epoch:  456  	Training Loss: 3.722255496541038e-05
Test Loss:  3.066729914280586e-05
Valid Loss:  4.1821636841632426e-05
Epoch:  457  	Training Loss: 3.8468737329822034e-05
Test Loss:  4.144468402955681e-05
Valid Loss:  4.800687020178884e-05
Epoch:  458  	Training Loss: 4.328328213887289e-05
Test Loss:  4.9711143219610676e-05
Valid Loss:  6.398552795872092e-05
Epoch:  459  	Training Loss: 6.218974885996431e-05
Test Loss:  0.00012719305232167244
Valid Loss:  0.00012458895798772573
Epoch:  460  	Training Loss: 0.00011814988101832569
Test Loss:  0.00019053445430472493
Valid Loss:  0.00020815573225263506
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.00021134744747541845
Test Loss:  7.484569505322725e-05
Valid Loss:  9.0270877990406e-05
Epoch:  462  	Training Loss: 8.940046245697886e-05
Test Loss:  3.5469274735078216e-05
Valid Loss:  4.775919660460204e-05
Epoch:  463  	Training Loss: 4.4825625082012266e-05
Test Loss:  3.360174741828814e-05
Valid Loss:  4.4781394535675645e-05
Epoch:  464  	Training Loss: 4.1516206692904234e-05
Test Loss:  3.311263571958989e-05
Valid Loss:  4.369150337879546e-05
Epoch:  465  	Training Loss: 4.0346214518649504e-05
Test Loss:  3.255343472119421e-05
Valid Loss:  4.282114969100803e-05
Epoch:  466  	Training Loss: 3.946241122321226e-05
Test Loss:  3.1976032914826646e-05
Valid Loss:  4.210212136968039e-05
Epoch:  467  	Training Loss: 3.874349931720644e-05
Test Loss:  3.171528805978596e-05
Valid Loss:  4.168640953139402e-05
Epoch:  468  	Training Loss: 3.829667912214063e-05
Test Loss:  3.158432082273066e-05
Valid Loss:  4.140516830375418e-05
Epoch:  469  	Training Loss: 3.800068225245923e-05
Test Loss:  3.151721466565505e-05
Valid Loss:  4.1229472117265686e-05
Epoch:  470  	Training Loss: 3.7776622775709257e-05
Test Loss:  3.140405533486046e-05
Valid Loss:  4.11185719713103e-05
Epoch:  471  	Training Loss: 3.758654202101752e-05
Test Loss:  3.141083288937807e-05
Valid Loss:  4.102893581148237e-05
Epoch:  472  	Training Loss: 3.7443285691551864e-05
Test Loss:  3.133526479359716e-05
Valid Loss:  4.091741720912978e-05
Epoch:  473  	Training Loss: 3.7246467400109395e-05
Test Loss:  3.122205816907808e-05
Valid Loss:  4.08041087212041e-05
Epoch:  474  	Training Loss: 3.707510040840134e-05
Test Loss:  3.11024887196254e-05
Valid Loss:  4.068755151820369e-05
Epoch:  475  	Training Loss: 3.691705933306366e-05
Test Loss:   95%|█████████▌| 475/500 [05:30<00:17,  1.47it/s] 95%|█████████▌| 477/500 [05:31<00:11,  2.02it/s] 96%|█████████▌| 479/500 [05:31<00:07,  2.73it/s] 96%|█████████▌| 481/500 [05:37<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:37<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:37<00:05,  2.19it/s] 98%|█████████▊| 489/500 [05:38<00:03,  2.95it/s] 98%|█████████▊| 491/500 [05:44<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:44<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:44<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:44<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:44<00:00,  3.00it/s]100%|██████████| 500/500 [05:44<00:00,  1.45it/s]
3.0988099751994014e-05
Valid Loss:  4.0570135752204806e-05
Epoch:  476  	Training Loss: 3.676762571558356e-05
Test Loss:  3.088408993789926e-05
Valid Loss:  4.04516831622459e-05
Epoch:  477  	Training Loss: 3.662398739834316e-05
Test Loss:  3.078693043789826e-05
Valid Loss:  4.0332153730560094e-05
Epoch:  478  	Training Loss: 3.648484198492952e-05
Test Loss:  3.069538433919661e-05
Valid Loss:  4.0211314626503736e-05
Epoch:  479  	Training Loss: 3.634893801063299e-05
Test Loss:  3.060763265239075e-05
Valid Loss:  4.008917312603444e-05
Epoch:  480  	Training Loss: 3.6215598811395466e-05
Test Loss:  3.052345709875226e-05
Valid Loss:  3.996589657617733e-05
Epoch:  481  	Training Loss: 3.608451515901834e-05
Test Loss:  3.0442077331827022e-05
Valid Loss:  3.984173235949129e-05
Epoch:  482  	Training Loss: 3.595514499465935e-05
Test Loss:  3.0543003958882764e-05
Valid Loss:  3.977846427005716e-05
Epoch:  483  	Training Loss: 3.587208630051464e-05
Test Loss:  3.052348620258272e-05
Valid Loss:  3.969557292293757e-05
Epoch:  484  	Training Loss: 3.5808043321594596e-05
Test Loss:  3.0482364309136756e-05
Valid Loss:  3.960835238103755e-05
Epoch:  485  	Training Loss: 3.5745535569731146e-05
Test Loss:  3.043794640689157e-05
Valid Loss:  3.952131373807788e-05
Epoch:  486  	Training Loss: 3.5683755413629115e-05
Test Loss:  3.0393806810025126e-05
Valid Loss:  3.9435595681425184e-05
Epoch:  487  	Training Loss: 3.5622684663394466e-05
Test Loss:  3.0349954613484442e-05
Valid Loss:  3.935081622330472e-05
Epoch:  488  	Training Loss: 3.556256342562847e-05
Test Loss:  3.0306608095997944e-05
Valid Loss:  3.926674253307283e-05
Epoch:  489  	Training Loss: 3.550302790245041e-05
Test Loss:  3.0263419830589555e-05
Valid Loss:  3.918422953574918e-05
Epoch:  490  	Training Loss: 3.544425271684304e-05
Test Loss:  3.022031523869373e-05
Valid Loss:  3.910377563443035e-05
Epoch:  491  	Training Loss: 3.538651071721688e-05
Test Loss:  3.0174727726262063e-05
Valid Loss:  3.9023878343869e-05
Epoch:  492  	Training Loss: 3.53295799868647e-05
Test Loss:  2.9980468752910383e-05
Valid Loss:  3.891455344273709e-05
Epoch:  493  	Training Loss: 3.523864143062383e-05
Test Loss:  2.987129846587777e-05
Valid Loss:  3.8850299461046234e-05
Epoch:  494  	Training Loss: 3.5169283364666626e-05
Test Loss:  2.9797429306199774e-05
Valid Loss:  3.879885116475634e-05
Epoch:  495  	Training Loss: 3.510564420139417e-05
Test Loss:  2.974051676574163e-05
Valid Loss:  3.8752139516873285e-05
Epoch:  496  	Training Loss: 3.50445116055198e-05
Test Loss:  2.96924335998483e-05
Valid Loss:  3.8706442865077406e-05
Epoch:  497  	Training Loss: 3.498492878861725e-05
Test Loss:  2.9649570933543146e-05
Valid Loss:  3.8660837162751704e-05
Epoch:  498  	Training Loss: 3.492635369184427e-05
Test Loss:  2.960974416055251e-05
Valid Loss:  3.8614663935732096e-05
Epoch:  499  	Training Loss: 3.4868666261900216e-05
Test Loss:  2.9572063795058057e-05
Valid Loss:  3.8567370211239904e-05
Epoch:  500  	Training Loss: 3.481168096186593e-05
Test Loss:  2.9536118745454587e-05
Valid Loss:  3.8519185181939974e-05
seed is  8
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.28it/s]  1%|          | 4/500 [00:00<00:31, 15.97it/s]  1%|          | 6/500 [00:00<00:30, 16.01it/s]  2%|▏         | 8/500 [00:00<00:30, 15.94it/s]  2%|▏         | 10/500 [00:00<00:30, 15.81it/s]  2%|▏         | 12/500 [00:00<00:30, 15.92it/s]  3%|▎         | 14/500 [00:00<00:30, 15.88it/s]  3%|▎         | 16/500 [00:01<00:30, 15.93it/s]  4%|▎         | 18/500 [00:01<00:30, 16.02it/s]  4%|▍         | 20/500 [00:01<00:29, 16.19it/s]  4%|▍         | 22/500 [00:01<00:29, 16.33it/s]  5%|▍         | 24/500 [00:01<00:29, 16.26it/s]  5%|▌         | 26/500 [00:01<00:29, 16.27it/s]  6%|▌         | 28/500 [00:01<00:28, 16.28it/s]  6%|▌         | 30/500 [00:01<00:29, 16.19it/s]  6%|▋         | 32/500 [00:02<00:30, 15.36it/s]  7%|▋         | 34/500 [00:02<00:30, 15.44it/s]  7%|▋         | 36/500 [00:02<00:31, 14.89it/s]  8%|▊         | 38/500 [00:02<00:31, 14.59it/s]  8%|▊         | 40/500 [00:02<00:30, 15.06it/s]  8%|▊         | 42/500 [00:02<00:29, 15.29it/s]  9%|▉         | 44/500 [00:02<00:29, 15.55it/s]  9%|▉         | 46/500 [00:02<00:28, 15.73it/s] 10%|▉         | 48/500 [00:03<00:28, 15.67it/s] 10%|█         | 50/500 [00:03<00:28, 15.86it/s] 10%|█         | 52/500 [00:03<00:28, 15.76it/s] 11%|█         | 54/500 [00:03<00:27, 15.95it/s] 11%|█         | 56/500 [00:03<00:27, 16.15it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.32it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.39it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.35it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.27it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.32it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.35it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.40it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.42it/s] 15%|█▍        | 74/500 [00:04<00:25, 16.43it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.49it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.53it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.50it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.48it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.48it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.44it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.44it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.12it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.24it/s] 19%|█▉        | 94/500 [00:05<00:25, 16.05it/s] 19%|█▉        | 96/500 [00:05<00:25, 15.92it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.08it/s] 20%|██        | 100/500 [00:06<00:24, 16.19it/s] 20%|██        | 102/500 [00:06<00:24, 16.30it/s] 21%|██        | 104/500 [00:06<00:24, 16.30it/s] 21%|██        | 106/500 [00:06<00:24, 16.33it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.35it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.25it/s] 22%|██▏       | 112/500 [00:06<00:24, 16.07it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.90it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.82it/s] 24%|██▎       | 118/500 [00:07<00:26, 14.18it/s] 24%|██▍       | 120/500 [00:07<00:25, 14.68it/s] 24%|██▍       | 122/500 [00:07<00:25, 15.06it/s] 25%|██▍       | 124/500 [00:07<00:24, 15.21it/s]Epoch:  1  	Training Loss: 0.02771417796611786
Test Loss:  74.6805191040039
Valid Loss:  74.70651245117188
Epoch:  2  	Training Loss: 74.61727142333984
Test Loss:  746734592.0
Valid Loss:  743994240.0
Epoch:  3  	Training Loss: 746053376.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  125  	Training Loss: nan
 25%|██▌       | 126/500 [00:07<00:24, 15.35it/s] 26%|██▌       | 128/500 [00:08<00:24, 15.28it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.49it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.62it/s] 27%|██▋       | 134/500 [00:08<00:22, 15.92it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.04it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.12it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.25it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.23it/s] 29%|██▉       | 144/500 [00:09<00:22, 16.05it/s] 29%|██▉       | 146/500 [00:09<00:22, 16.00it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.97it/s] 30%|███       | 150/500 [00:09<00:22, 15.85it/s] 30%|███       | 152/500 [00:09<00:22, 15.68it/s] 31%|███       | 154/500 [00:09<00:21, 15.75it/s] 31%|███       | 156/500 [00:09<00:21, 15.99it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.16it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.28it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.32it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.38it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.38it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.38it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.39it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.28it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.28it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.32it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.37it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.38it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.38it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.39it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.39it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.42it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.47it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.48it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.41it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.17it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.18it/s] 40%|████      | 200/500 [00:12<00:18, 16.18it/s] 40%|████      | 202/500 [00:12<00:18, 15.99it/s] 41%|████      | 204/500 [00:12<00:18, 16.15it/s] 41%|████      | 206/500 [00:12<00:18, 16.20it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.32it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.34it/s] 42%|████▏     | 212/500 [00:13<00:18, 15.94it/s] 43%|████▎     | 214/500 [00:13<00:18, 15.80it/s] 43%|████▎     | 216/500 [00:13<00:17, 15.91it/s] 44%|████▎     | 218/500 [00:13<00:17, 15.91it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.14it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.29it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.33it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.28it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.27it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.01it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.82it/s] 47%|████▋     | 234/500 [00:14<00:16, 15.81it/s] 47%|████▋     | 236/500 [00:14<00:16, 15.85it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.01it/s] 48%|████▊     | 240/500 [00:14<00:16, 16.22it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.26it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.35it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.37it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.42it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  249  	Training Loss: nan
 50%|█████     | 250/500 [00:15<00:15, 16.27it/s] 50%|█████     | 252/500 [00:15<00:15, 16.18it/s] 51%|█████     | 254/500 [00:15<00:15, 16.25it/s] 51%|█████     | 256/500 [00:15<00:15, 16.23it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.38it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.40it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.46it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.50it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.48it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.37it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.32it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.40it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.28it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.31it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.28it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.25it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.17it/s] 57%|█████▋    | 284/500 [00:17<00:14, 14.95it/s] 57%|█████▋    | 286/500 [00:17<00:13, 15.32it/s] 58%|█████▊    | 288/500 [00:17<00:13, 15.63it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.91it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.04it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.17it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.15it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.30it/s] 60%|██████    | 300/500 [00:18<00:12, 16.31it/s] 60%|██████    | 302/500 [00:18<00:12, 16.37it/s] 61%|██████    | 304/500 [00:18<00:12, 16.31it/s] 61%|██████    | 306/500 [00:19<00:12, 16.05it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.68it/s] 62%|██████▏   | 310/500 [00:19<00:12, 15.62it/s] 62%|██████▏   | 312/500 [00:19<00:11, 15.71it/s] 63%|██████▎   | 314/500 [00:19<00:11, 15.83it/s] 63%|██████▎   | 316/500 [00:19<00:11, 15.90it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.84it/s] 64%|██████▍   | 320/500 [00:19<00:11, 15.88it/s] 64%|██████▍   | 322/500 [00:20<00:11, 16.03it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.15it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.24it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.26it/s] 66%|██████▌   | 330/500 [00:20<00:10, 15.70it/s] 66%|██████▋   | 332/500 [00:20<00:10, 15.32it/s] 67%|██████▋   | 334/500 [00:20<00:10, 15.57it/s] 67%|██████▋   | 336/500 [00:20<00:10, 15.80it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.83it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.92it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.00it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.01it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.04it/s] 70%|██████▉   | 348/500 [00:21<00:09, 15.95it/s] 70%|███████   | 350/500 [00:21<00:09, 16.07it/s] 70%|███████   | 352/500 [00:21<00:09, 16.16it/s] 71%|███████   | 354/500 [00:22<00:09, 15.62it/s] 71%|███████   | 356/500 [00:22<00:09, 15.64it/s] 72%|███████▏  | 358/500 [00:22<00:09, 15.51it/s] 72%|███████▏  | 360/500 [00:22<00:08, 15.58it/s] 72%|███████▏  | 362/500 [00:22<00:09, 15.24it/s] 73%|███████▎  | 364/500 [00:22<00:08, 15.48it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.71it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.70it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.75it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.95it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  373  	Training Loss: nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.07it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.11it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.11it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.23it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.27it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.14it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.22it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.28it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.34it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.22it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.22it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.04it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.03it/s] 80%|████████  | 400/500 [00:24<00:06, 16.12it/s] 80%|████████  | 402/500 [00:25<00:06, 16.21it/s] 81%|████████  | 404/500 [00:25<00:05, 16.17it/s] 81%|████████  | 406/500 [00:25<00:05, 16.23it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.28it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.23it/s] 82%|████████▏ | 412/500 [00:25<00:05, 15.03it/s] 83%|████████▎ | 414/500 [00:25<00:05, 15.29it/s] 83%|████████▎ | 416/500 [00:25<00:05, 15.50it/s] 84%|████████▎ | 418/500 [00:26<00:05, 15.76it/s] 84%|████████▍ | 420/500 [00:26<00:05, 15.72it/s] 84%|████████▍ | 422/500 [00:26<00:04, 15.80it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.65it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.58it/s] 86%|████████▌ | 428/500 [00:26<00:04, 15.81it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.03it/s] 86%|████████▋ | 432/500 [00:26<00:04, 15.99it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.04it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.11it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.16it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.25it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.18it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.24it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.25it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.21it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.02it/s] 90%|█████████ | 452/500 [00:28<00:03, 16.00it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.08it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.05it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.22it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.25it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.38it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.44it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.04it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.10it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.98it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.09it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.17it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.21it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.35it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.36it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.44it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.43it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.42it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.17it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.65it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.84it/s] 99%|█████████▉| 494/500 [00:30<00:00, 15.99it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.12it/s]Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  497  	Training Loss: nan
100%|█████████▉| 498/500 [00:31<00:00, 16.19it/s]100%|██████████| 500/500 [00:31<00:00, 16.03it/s]100%|██████████| 500/500 [00:31<00:00, 16.03it/s]
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  8
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:55,  6.12s/it]  1%|          | 3/500 [00:06<13:33,  1.64s/it]  1%|          | 5/500 [00:06<06:50,  1.21it/s]  1%|▏         | 7/500 [00:06<04:08,  1.98it/s]  2%|▏         | 9/500 [00:06<02:46,  2.95it/s]  2%|▏         | 11/500 [00:12<10:40,  1.31s/it]  3%|▎         | 13/500 [00:13<07:16,  1.11it/s]  3%|▎         | 15/500 [00:13<05:04,  1.59it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:38,  3.03it/s]  4%|▍         | 21/500 [00:19<09:21,  1.17s/it]  5%|▍         | 23/500 [00:19<06:38,  1.20it/s]  5%|▌         | 25/500 [00:19<04:45,  1.66it/s]  5%|▌         | 27/500 [00:19<03:28,  2.27it/s]  6%|▌         | 29/500 [00:20<02:34,  3.05it/s]  6%|▌         | 31/500 [00:26<09:07,  1.17s/it]  7%|▋         | 33/500 [00:26<06:31,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.64it/s]  7%|▋         | 37/500 [00:26<03:26,  2.24it/s]  8%|▊         | 39/500 [00:26<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<08:54,  1.16s/it]  9%|▊         | 43/500 [00:33<06:22,  1.19it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:39<08:42,  1.16s/it] 11%|█         | 53/500 [00:39<06:14,  1.19it/s] 11%|█         | 55/500 [00:40<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:40<03:16,  2.25it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.02it/s] 12%|█▏        | 61/500 [00:46<08:32,  1.17s/it] 13%|█▎        | 63/500 [00:46<06:05,  1.19it/s] 13%|█▎        | 65/500 [00:46<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:11,  2.26it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.03it/s] 14%|█▍        | 71/500 [00:53<08:16,  1.16s/it]Epoch:  1  	Training Loss: 0.02771417796611786
Test Loss:  0.6028557419776917
Valid Loss:  0.6143365502357483
Epoch:  2  	Training Loss: 0.6117247939109802
Test Loss:  1.6779495477676392
Valid Loss:  1.637162685394287
Epoch:  3  	Training Loss: 1.6585931777954102
Test Loss:  0.022283446043729782
Valid Loss:  0.027577094733715057
Epoch:  4  	Training Loss: 0.025391850620508194
Test Loss:  0.022250166162848473
Valid Loss:  0.02753736451268196
Epoch:  5  	Training Loss: 0.025352880358695984
Test Loss:  0.022217079997062683
Valid Loss:  0.02749784290790558
Epoch:  6  	Training Loss: 0.02531413361430168
Test Loss:  0.022184181958436966
Valid Loss:  0.027458542957901955
Epoch:  7  	Training Loss: 0.02527560666203499
Test Loss:  0.02215147763490677
Valid Loss:  0.027419453486800194
Epoch:  8  	Training Loss: 0.025237299501895905
Test Loss:  0.022118953987956047
Valid Loss:  0.027380570769309998
Epoch:  9  	Training Loss: 0.02519920840859413
Test Loss:  0.0220866110175848
Valid Loss:  0.027341898530721664
Epoch:  10  	Training Loss: 0.02516133524477482
Test Loss:  0.022054452449083328
Valid Loss:  0.027303436771035194
Epoch:  11  	Training Loss: 0.02512367069721222
Test Loss:  0.02202247828245163
Valid Loss:  0.027265168726444244
Epoch:  12  	Training Loss: 0.025086214765906334
Test Loss:  0.02198314480483532
Valid Loss:  0.027218161150813103
Epoch:  13  	Training Loss: 0.02504011057317257
Test Loss:  0.0219440758228302
Valid Loss:  0.02717144973576069
Epoch:  14  	Training Loss: 0.024994313716888428
Test Loss:  0.021905263885855675
Valid Loss:  0.027125030755996704
Epoch:  15  	Training Loss: 0.02494882047176361
Test Loss:  0.021866708993911743
Valid Loss:  0.02707890421152115
Epoch:  16  	Training Loss: 0.02490363083779812
Test Loss:  0.021828411146998405
Valid Loss:  0.027033060789108276
Epoch:  17  	Training Loss: 0.024858735501766205
Test Loss:  0.021790366619825363
Valid Loss:  0.026987504214048386
Epoch:  18  	Training Loss: 0.02481413260102272
Test Loss:  0.02175256982445717
Valid Loss:  0.02694222331047058
Epoch:  19  	Training Loss: 0.024769820272922516
Test Loss:  0.021715015172958374
Valid Loss:  0.026897218078374863
Epoch:  20  	Training Loss: 0.024725794792175293
Test Loss:  0.02167770266532898
Valid Loss:  0.02685248665511608
Epoch:  21  	Training Loss: 0.024682048708200455
Test Loss:  0.021640634164214134
Valid Loss:  0.026808027178049088
Epoch:  22  	Training Loss: 0.024638589471578598
Test Loss:  0.021604524925351143
Valid Loss:  0.02676481381058693
Epoch:  23  	Training Loss: 0.02459620125591755
Test Loss:  0.021568672731518745
Valid Loss:  0.026721887290477753
Epoch:  24  	Training Loss: 0.024554116651415825
Test Loss:  0.021533073857426643
Valid Loss:  0.026679251343011856
Epoch:  25  	Training Loss: 0.02451232448220253
Test Loss:  0.021497728303074837
Valid Loss:  0.02663690224289894
Epoch:  26  	Training Loss: 0.024470822885632515
Test Loss:  0.02146262675523758
Valid Loss:  0.026594825088977814
Epoch:  27  	Training Loss: 0.02442960999906063
Test Loss:  0.02142776921391487
Valid Loss:  0.02655302919447422
Epoch:  28  	Training Loss: 0.02438868209719658
Test Loss:  0.021393153816461563
Valid Loss:  0.026511505246162415
Epoch:  29  	Training Loss: 0.02434803545475006
Test Loss:  0.021358773112297058
Valid Loss:  0.02647024765610695
Epoch:  30  	Training Loss: 0.02430766262114048
Test Loss:  0.021324632689356804
Valid Loss:  0.02642926573753357
Epoch:  31  	Training Loss: 0.024267565459012985
Test Loss:  0.021290723234415054
Valid Loss:  0.026388537138700485
Epoch:  32  	Training Loss: 0.024227742105722427
Test Loss:  0.0212584026157856
Valid Loss:  0.02634967677295208
Epoch:  33  	Training Loss: 0.02418980374932289
Test Loss:  0.02122628316283226
Valid Loss:  0.026311049237847328
Epoch:  34  	Training Loss: 0.024152103811502457
Test Loss:  0.021194374188780785
Valid Loss:  0.026272650808095932
Epoch:  35  	Training Loss: 0.024114642292261124
Test Loss:  0.02116265892982483
Valid Loss:  0.02623448148369789
Epoch:  36  	Training Loss: 0.024077411741018295
Test Loss:  0.02113114297389984
Valid Loss:  0.02619653381407261
Epoch:  37  	Training Loss: 0.02404041588306427
Test Loss:  0.021099822595715523
Valid Loss:  0.026158807799220085
Epoch:  38  	Training Loss: 0.0240036454051733
Test Loss:  0.021068692207336426
Valid Loss:  0.02612130343914032
Epoch:  39  	Training Loss: 0.02396710216999054
Test Loss:  0.02103775553405285
Valid Loss:  0.026084018871188164
Epoch:  40  	Training Loss: 0.023930782452225685
Test Loss:  0.021007005125284195
Valid Loss:  0.026046941056847572
Epoch:  41  	Training Loss: 0.02389468252658844
Test Loss:  0.020976439118385315
Valid Loss:  0.02601008117198944
Epoch:  42  	Training Loss: 0.023858804255723953
Test Loss:  0.02094672992825508
Valid Loss:  0.02597421407699585
Epoch:  43  	Training Loss: 0.023823946714401245
Test Loss:  0.020917188376188278
Valid Loss:  0.025938542559742928
Epoch:  44  	Training Loss: 0.023789461702108383
Test Loss:  0.020888105034828186
Valid Loss:  0.025903446599841118
Epoch:  45  	Training Loss: 0.023755565285682678
Test Loss:  0.0208596084266901
Valid Loss:  0.025868549942970276
Epoch:  46  	Training Loss: 0.023721877485513687
Test Loss:  0.020831365138292313
Valid Loss:  0.025833850726485252
Epoch:  47  	Training Loss: 0.02368846908211708
Test Loss:  0.020803391933441162
Valid Loss:  0.025799518451094627
Epoch:  48  	Training Loss: 0.02365543320775032
Test Loss:  0.020775683224201202
Valid Loss:  0.02576555497944355
Epoch:  49  	Training Loss: 0.023622792214155197
Test Loss:  0.020748239010572433
Valid Loss:  0.025732310488820076
Epoch:  50  	Training Loss: 0.02359061874449253
Test Loss:  0.02072114869952202
Valid Loss:  0.025699548423290253
Epoch:  51  	Training Loss: 0.023558909073472023
Test Loss:  0.020694397389888763
Valid Loss:  0.02566711977124214
Epoch:  52  	Training Loss: 0.023527614772319794
Test Loss:  0.020668350160121918
Valid Loss:  0.025635479018092155
Epoch:  53  	Training Loss: 0.02349715307354927
Test Loss:  0.020642684772610664
Valid Loss:  0.025604519993066788
Epoch:  54  	Training Loss: 0.023467201739549637
Test Loss:  0.020617228001356125
Valid Loss:  0.02557406574487686
Epoch:  55  	Training Loss: 0.023437514901161194
Test Loss:  0.020591948181390762
Valid Loss:  0.02554396726191044
Epoch:  56  	Training Loss: 0.02340802736580372
Test Loss:  0.020566929131746292
Valid Loss:  0.025514155626296997
Epoch:  57  	Training Loss: 0.023378755897283554
Test Loss:  0.020542189478874207
Valid Loss:  0.02548464760184288
Epoch:  58  	Training Loss: 0.023349812254309654
Test Loss:  0.02051764354109764
Valid Loss:  0.02545536495745182
Epoch:  59  	Training Loss: 0.023321116343140602
Test Loss:  0.020493321120738983
Valid Loss:  0.025426320731639862
Epoch:  60  	Training Loss: 0.023292696103453636
Test Loss:  0.020469166338443756
Valid Loss:  0.025397468358278275
Epoch:  61  	Training Loss: 0.023264504969120026
Test Loss:  0.020445257425308228
Valid Loss:  0.02536887861788273
Epoch:  62  	Training Loss: 0.023236572742462158
Test Loss:  0.020423218607902527
Valid Loss:  0.02534252405166626
Epoch:  63  	Training Loss: 0.02321087196469307
Test Loss:  0.020401351153850555
Valid Loss:  0.0253163892775774
Epoch:  64  	Training Loss: 0.023185331374406815
Test Loss:  0.020379628986120224
Valid Loss:  0.025290556252002716
Epoch:  65  	Training Loss: 0.02315995842218399
Test Loss:  0.020358040928840637
Valid Loss:  0.025264877825975418
Epoch:  66  	Training Loss: 0.023134745657444
Test Loss:  0.02033662423491478
Valid Loss:  0.025239361450076103
Epoch:  67  	Training Loss: 0.023109693080186844
Test Loss:  0.020315350964665413
Valid Loss:  0.025214040651917458
Epoch:  68  	Training Loss: 0.023084819316864014
Test Loss:  0.02029421553015709
Valid Loss:  0.025188898667693138
Epoch:  69  	Training Loss: 0.023060113191604614
Test Loss:  0.02027321234345436
Valid Loss:  0.025163907557725906
Epoch:  70  	Training Loss: 0.02303556352853775
Test Loss:  0.020252332091331482
Valid Loss:  0.025139085948467255
Epoch:  71  	Training Loss: 0.02301117032766342
Test Loss:  0.02023158222436905
Valid Loss:  0.02511443756520748
Epoch:  72  	Training Loss: 0.02298692986369133
Test Loss:   15%|█▍        | 73/500 [00:53<05:54,  1.20it/s] 15%|█▌        | 75/500 [00:53<04:15,  1.66it/s] 15%|█▌        | 77/500 [00:53<03:06,  2.27it/s] 16%|█▌        | 79/500 [00:53<02:18,  3.03it/s] 16%|█▌        | 81/500 [01:00<08:05,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:46,  1.20it/s] 17%|█▋        | 85/500 [01:00<04:09,  1.67it/s] 17%|█▋        | 87/500 [01:00<03:01,  2.28it/s] 18%|█▊        | 89/500 [01:00<02:14,  3.06it/s] 18%|█▊        | 91/500 [01:06<08:00,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:43,  1.18it/s] 19%|█▉        | 95/500 [01:07<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:07<03:00,  2.24it/s] 20%|█▉        | 99/500 [01:07<02:13,  3.01it/s] 20%|██        | 101/500 [01:13<07:40,  1.16s/it] 21%|██        | 103/500 [01:13<05:28,  1.21it/s] 21%|██        | 105/500 [01:13<03:56,  1.67it/s] 21%|██▏       | 107/500 [01:13<02:52,  2.28it/s] 22%|██▏       | 109/500 [01:14<02:07,  3.07it/s] 22%|██▏       | 111/500 [01:20<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:20<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:20<03:54,  1.65it/s] 23%|██▎       | 117/500 [01:20<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:20<02:05,  3.03it/s] 24%|██▍       | 121/500 [01:27<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:27<05:15,  1.19it/s] 25%|██▌       | 125/500 [01:27<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:27<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:27<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:33<07:10,  1.17s/it] 27%|██▋       | 133/500 [01:34<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:34<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:34<02:41,  2.25it/s] 28%|██▊       | 139/500 [01:34<01:59,  3.03it/s] 28%|██▊       | 141/500 [01:40<06:58,  1.17s/it]0.020217038691043854
Valid Loss:  0.025097506120800972
Epoch:  73  	Training Loss: 0.02297012135386467
Test Loss:  0.020202582702040672
Valid Loss:  0.02508065290749073
Epoch:  74  	Training Loss: 0.022953368723392487
Test Loss:  0.020188404247164726
Valid Loss:  0.025063857436180115
Epoch:  75  	Training Loss: 0.022936679422855377
Test Loss:  0.020174279808998108
Valid Loss:  0.02504713460803032
Epoch:  76  	Training Loss: 0.022920066490769386
Test Loss:  0.020160198211669922
Valid Loss:  0.0250304713845253
Epoch:  77  	Training Loss: 0.022903520613908768
Test Loss:  0.02014617621898651
Valid Loss:  0.0250138770788908
Epoch:  78  	Training Loss: 0.022887032479047775
Test Loss:  0.02013220265507698
Valid Loss:  0.02499733678996563
Epoch:  79  	Training Loss: 0.022870605811476707
Test Loss:  0.02011827938258648
Valid Loss:  0.024980857968330383
Epoch:  80  	Training Loss: 0.022854238748550415
Test Loss:  0.020104404538869858
Valid Loss:  0.02496444433927536
Epoch:  81  	Training Loss: 0.02283792942762375
Test Loss:  0.020090583711862564
Valid Loss:  0.024948084726929665
Epoch:  82  	Training Loss: 0.022821683436632156
Test Loss:  0.02007875218987465
Valid Loss:  0.024934127926826477
Epoch:  83  	Training Loss: 0.02280784770846367
Test Loss:  0.020067019388079643
Valid Loss:  0.02492026425898075
Epoch:  84  	Training Loss: 0.02279413305222988
Test Loss:  0.020055320113897324
Valid Loss:  0.024906441569328308
Epoch:  85  	Training Loss: 0.022780459374189377
Test Loss:  0.02004365622997284
Valid Loss:  0.024892665445804596
Epoch:  86  	Training Loss: 0.022766828536987305
Test Loss:  0.02003202587366104
Valid Loss:  0.024878930300474167
Epoch:  87  	Training Loss: 0.022753234952688217
Test Loss:  0.02002043090760708
Valid Loss:  0.024865228682756424
Epoch:  88  	Training Loss: 0.022739684209227562
Test Loss:  0.020008869469165802
Valid Loss:  0.024851571768522263
Epoch:  89  	Training Loss: 0.02272617071866989
Test Loss:  0.019997337833046913
Valid Loss:  0.024837948381900787
Epoch:  90  	Training Loss: 0.022712700068950653
Test Loss:  0.01998583972454071
Valid Loss:  0.024824371561408043
Epoch:  91  	Training Loss: 0.0226992666721344
Test Loss:  0.019974377006292343
Valid Loss:  0.024810831993818283
Epoch:  92  	Training Loss: 0.022685876116156578
Test Loss:  0.019963670521974564
Valid Loss:  0.024798210710287094
Epoch:  93  	Training Loss: 0.02267342060804367
Test Loss:  0.019953057169914246
Valid Loss:  0.02478567510843277
Epoch:  94  	Training Loss: 0.02266107127070427
Test Loss:  0.019942473620176315
Valid Loss:  0.024773167446255684
Epoch:  95  	Training Loss: 0.022648794576525688
Test Loss:  0.019931979477405548
Valid Loss:  0.02476074919104576
Epoch:  96  	Training Loss: 0.02263660356402397
Test Loss:  0.019921516999602318
Valid Loss:  0.024748358875513077
Epoch:  97  	Training Loss: 0.02262444794178009
Test Loss:  0.01991107687354088
Valid Loss:  0.024736003950238228
Epoch:  98  	Training Loss: 0.022612323984503746
Test Loss:  0.019900668412446976
Valid Loss:  0.024723682552576065
Epoch:  99  	Training Loss: 0.022600237280130386
Test Loss:  0.019890286028385162
Valid Loss:  0.024711396545171738
Epoch:  100  	Training Loss: 0.022588182240724564
Test Loss:  0.019879931584000587
Valid Loss:  0.02469913847744465
Epoch:  101  	Training Loss: 0.022576160728931427
Test Loss:  0.019869599491357803
Valid Loss:  0.024686915799975395
Epoch:  102  	Training Loss: 0.022564172744750977
Test Loss:  0.019859563559293747
Valid Loss:  0.024675048887729645
Epoch:  103  	Training Loss: 0.02255253493785858
Test Loss:  0.01984955370426178
Valid Loss:  0.02466321736574173
Epoch:  104  	Training Loss: 0.022540949285030365
Test Loss:  0.019839640706777573
Valid Loss:  0.02465146780014038
Epoch:  105  	Training Loss: 0.02252945303916931
Test Loss:  0.019829746335744858
Valid Loss:  0.024639742448925972
Epoch:  106  	Training Loss: 0.022517990320920944
Test Loss:  0.019819878041744232
Valid Loss:  0.02462805062532425
Epoch:  107  	Training Loss: 0.022506559267640114
Test Loss:  0.019810032099485397
Valid Loss:  0.024616390466690063
Epoch:  108  	Training Loss: 0.022495176643133163
Test Loss:  0.019800273701548576
Valid Loss:  0.024604802951216698
Epoch:  109  	Training Loss: 0.02248387411236763
Test Loss:  0.019790543243288994
Valid Loss:  0.024593252688646317
Epoch:  110  	Training Loss: 0.022472605109214783
Test Loss:  0.019780833274126053
Valid Loss:  0.024581724777817726
Epoch:  111  	Training Loss: 0.022461388260126114
Test Loss:  0.019771214574575424
Valid Loss:  0.024570278823375702
Epoch:  112  	Training Loss: 0.02245023474097252
Test Loss:  0.019761741161346436
Valid Loss:  0.024559011682868004
Epoch:  113  	Training Loss: 0.02243925631046295
Test Loss:  0.019752291962504387
Valid Loss:  0.024547772482037544
Epoch:  114  	Training Loss: 0.022428307682275772
Test Loss:  0.019742866978049278
Valid Loss:  0.024536553770303726
Epoch:  115  	Training Loss: 0.022417394444346428
Test Loss:  0.01973346620798111
Valid Loss:  0.02452537603676319
Epoch:  116  	Training Loss: 0.02240651100873947
Test Loss:  0.01972409151494503
Valid Loss:  0.024514220654964447
Epoch:  117  	Training Loss: 0.022395659238100052
Test Loss:  0.01971474289894104
Valid Loss:  0.024503104388713837
Epoch:  118  	Training Loss: 0.02238483913242817
Test Loss:  0.01970542222261429
Valid Loss:  0.024492016062140465
Epoch:  119  	Training Loss: 0.022374050691723824
Test Loss:  0.019696123898029327
Valid Loss:  0.02448096126317978
Epoch:  120  	Training Loss: 0.022363292053341866
Test Loss:  0.019686847925186157
Valid Loss:  0.024469934403896332
Epoch:  121  	Training Loss: 0.022352565079927444
Test Loss:  0.019677598029375076
Valid Loss:  0.024458933621644974
Epoch:  122  	Training Loss: 0.022341866046190262
Test Loss:  0.019668471068143845
Valid Loss:  0.02444808930158615
Epoch:  123  	Training Loss: 0.022331321612000465
Test Loss:  0.019659366458654404
Valid Loss:  0.02443726919591427
Epoch:  124  	Training Loss: 0.022320803254842758
Test Loss:  0.019650287926197052
Valid Loss:  0.024426480755209923
Epoch:  125  	Training Loss: 0.022310318425297737
Test Loss:  0.01964123174548149
Valid Loss:  0.024415716528892517
Epoch:  126  	Training Loss: 0.022299861535429955
Test Loss:  0.01963219977915287
Valid Loss:  0.02440498024225235
Epoch:  127  	Training Loss: 0.02228943444788456
Test Loss:  0.0196232907474041
Valid Loss:  0.024394270032644272
Epoch:  128  	Training Loss: 0.022279035300016403
Test Loss:  0.019614413380622864
Valid Loss:  0.024383587762713432
Epoch:  129  	Training Loss: 0.022268664091825485
Test Loss:  0.019605562090873718
Valid Loss:  0.02437293529510498
Epoch:  130  	Training Loss: 0.022258318960666656
Test Loss:  0.019596729427576065
Valid Loss:  0.02436230331659317
Epoch:  131  	Training Loss: 0.022248003631830215
Test Loss:  0.019587920978665352
Valid Loss:  0.024351701140403748
Epoch:  132  	Training Loss: 0.022237718105316162
Test Loss:  0.019579192623496056
Valid Loss:  0.024341188371181488
Epoch:  133  	Training Loss: 0.02222752571105957
Test Loss:  0.01957048289477825
Valid Loss:  0.024330703541636467
Epoch:  134  	Training Loss: 0.022217359393835068
Test Loss:  0.019561799243092537
Valid Loss:  0.024320248514413834
Epoch:  135  	Training Loss: 0.022207219153642654
Test Loss:  0.019553130492568016
Valid Loss:  0.024309812113642693
Epoch:  136  	Training Loss: 0.022197110578417778
Test Loss:  0.019544489681720734
Valid Loss:  0.02429940178990364
Epoch:  137  	Training Loss: 0.022187024354934692
Test Loss:  0.019535865634679794
Valid Loss:  0.024289024993777275
Epoch:  138  	Training Loss: 0.022176969796419144
Test Loss:  0.019527263939380646
Valid Loss:  0.024278663098812103
Epoch:  139  	Training Loss: 0.022166935727000237
Test Loss:  0.019518686458468437
Valid Loss:  0.02426833286881447
Epoch:  140  	Training Loss: 0.022156933322548866
Test Loss:  0.01951012760400772
Valid Loss:  0.024258024990558624
Epoch:  141  	Training Loss: 0.022146955132484436
Test Loss:  0.019501592963933945
Valid Loss:  0.02424773946404457
Epoch:  142  	Training Loss: 0.022137001156806946
Test Loss:  0.019493192434310913
Valid Loss:  0.02423761785030365
 29%|██▊       | 143/500 [01:40<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:40<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:41<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:41<01:55,  3.03it/s] 30%|███       | 151/500 [01:47<06:48,  1.17s/it] 31%|███       | 153/500 [01:47<04:51,  1.19it/s] 31%|███       | 155/500 [01:47<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:47<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:48<01:53,  3.02it/s] 32%|███▏      | 161/500 [01:54<06:35,  1.17s/it] 33%|███▎      | 163/500 [01:54<04:42,  1.19it/s] 33%|███▎      | 165/500 [01:54<03:23,  1.65it/s] 33%|███▎      | 167/500 [01:54<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:54<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:01<06:23,  1.17s/it] 35%|███▍      | 173/500 [02:01<04:33,  1.19it/s] 35%|███▌      | 175/500 [02:01<03:16,  1.65it/s] 35%|███▌      | 177/500 [02:01<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:01<01:45,  3.03it/s] 36%|███▌      | 181/500 [02:07<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:08<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:08<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:08<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:08<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:14<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:14<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:14<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:15<02:14,  2.26it/s] 40%|███▉      | 199/500 [02:15<01:39,  3.03it/s] 40%|████      | 201/500 [02:21<05:46,  1.16s/it] 41%|████      | 203/500 [02:21<04:07,  1.20it/s] 41%|████      | 205/500 [02:21<02:57,  1.66it/s] 41%|████▏     | 207/500 [02:21<02:09,  2.27it/s] 42%|████▏     | 209/500 [02:21<01:35,  3.05it/s] 42%|████▏     | 211/500 [02:28<05:35,  1.16s/it]Epoch:  143  	Training Loss: 0.022127211093902588
Test Loss:  0.019484810531139374
Valid Loss:  0.024227522313594818
Epoch:  144  	Training Loss: 0.022117439657449722
Test Loss:  0.019476450979709625
Valid Loss:  0.024217447265982628
Epoch:  145  	Training Loss: 0.022107698023319244
Test Loss:  0.01946811005473137
Valid Loss:  0.024207398295402527
Epoch:  146  	Training Loss: 0.022097982466220856
Test Loss:  0.019459795206785202
Valid Loss:  0.024197377264499664
Epoch:  147  	Training Loss: 0.022088289260864258
Test Loss:  0.019451497122645378
Valid Loss:  0.02418738603591919
Epoch:  148  	Training Loss: 0.02207862213253975
Test Loss:  0.01944330893456936
Valid Loss:  0.024177417159080505
Epoch:  149  	Training Loss: 0.02206897735595703
Test Loss:  0.019435176625847816
Valid Loss:  0.024167463183403015
Epoch:  150  	Training Loss: 0.022059358656406403
Test Loss:  0.01942705735564232
Valid Loss:  0.024157533422112465
Epoch:  151  	Training Loss: 0.022049766033887863
Test Loss:  0.01941896602511406
Valid Loss:  0.024147633463144302
Epoch:  152  	Training Loss: 0.022040192037820816
Test Loss:  0.01941092126071453
Valid Loss:  0.024137787520885468
Epoch:  153  	Training Loss: 0.02203068509697914
Test Loss:  0.019402898848056793
Valid Loss:  0.024127967655658722
Epoch:  154  	Training Loss: 0.02202119678258896
Test Loss:  0.019394895061850548
Valid Loss:  0.024118170142173767
Epoch:  155  	Training Loss: 0.022011756896972656
Test Loss:  0.019386934116482735
Valid Loss:  0.024108439683914185
Epoch:  156  	Training Loss: 0.02200237289071083
Test Loss:  0.01937899738550186
Valid Loss:  0.02409873716533184
Epoch:  157  	Training Loss: 0.021993011236190796
Test Loss:  0.019371073693037033
Valid Loss:  0.024089056998491287
Epoch:  158  	Training Loss: 0.02198367565870285
Test Loss:  0.019363172352313995
Valid Loss:  0.024079401046037674
Epoch:  159  	Training Loss: 0.021974358707666397
Test Loss:  0.01935529336333275
Valid Loss:  0.02406987175345421
Epoch:  160  	Training Loss: 0.021965069696307182
Test Loss:  0.019347431138157845
Valid Loss:  0.024060361087322235
Epoch:  161  	Training Loss: 0.02195580117404461
Test Loss:  0.019339583814144135
Valid Loss:  0.024050870910286903
Epoch:  162  	Training Loss: 0.021946560591459274
Test Loss:  0.019331861287355423
Valid Loss:  0.02404152601957321
Epoch:  163  	Training Loss: 0.021937474608421326
Test Loss:  0.0193241648375988
Valid Loss:  0.024032214656472206
Epoch:  164  	Training Loss: 0.021928414702415466
Test Loss:  0.01931648701429367
Valid Loss:  0.02402292937040329
Epoch:  165  	Training Loss: 0.0219193734228611
Test Loss:  0.019308827817440033
Valid Loss:  0.024013660848140717
Epoch:  166  	Training Loss: 0.02191036008298397
Test Loss:  0.019301190972328186
Valid Loss:  0.024004418402910233
Epoch:  167  	Training Loss: 0.021901369094848633
Test Loss:  0.019293567165732384
Valid Loss:  0.02399519458413124
Epoch:  168  	Training Loss: 0.021892398595809937
Test Loss:  0.01928597129881382
Valid Loss:  0.02398599684238434
Epoch:  169  	Training Loss: 0.02188345231115818
Test Loss:  0.019278384745121002
Valid Loss:  0.02397681400179863
Epoch:  170  	Training Loss: 0.021874532103538513
Test Loss:  0.019270818680524826
Valid Loss:  0.02396766096353531
Epoch:  171  	Training Loss: 0.02186562865972519
Test Loss:  0.01926327496767044
Valid Loss:  0.02395852655172348
Epoch:  172  	Training Loss: 0.021856751292943954
Test Loss:  0.019255727529525757
Valid Loss:  0.02394939586520195
Epoch:  173  	Training Loss: 0.02184787578880787
Test Loss:  0.019248202443122864
Valid Loss:  0.023940276354551315
Epoch:  174  	Training Loss: 0.021839022636413574
Test Loss:  0.019240695983171463
Valid Loss:  0.023931188508868217
Epoch:  175  	Training Loss: 0.02183019369840622
Test Loss:  0.019233208149671555
Valid Loss:  0.023922119289636612
Epoch:  176  	Training Loss: 0.021821387112140656
Test Loss:  0.01922573894262314
Valid Loss:  0.023913078010082245
Epoch:  177  	Training Loss: 0.021812599152326584
Test Loss:  0.019218286499381065
Valid Loss:  0.023904047906398773
Epoch:  178  	Training Loss: 0.021803833544254303
Test Loss:  0.019210848957300186
Valid Loss:  0.02389504201710224
Epoch:  179  	Training Loss: 0.021795092150568962
Test Loss:  0.01920343190431595
Valid Loss:  0.02388608455657959
Epoch:  180  	Training Loss: 0.021786373108625412
Test Loss:  0.019196033477783203
Valid Loss:  0.0238772165030241
Epoch:  181  	Training Loss: 0.021777672693133354
Test Loss:  0.0191886555403471
Valid Loss:  0.023868368938565254
Epoch:  182  	Training Loss: 0.021768994629383087
Test Loss:  0.01918128877878189
Valid Loss:  0.023859549313783646
Epoch:  183  	Training Loss: 0.021760348230600357
Test Loss:  0.01917394995689392
Valid Loss:  0.02385074645280838
Epoch:  184  	Training Loss: 0.02175171673297882
Test Loss:  0.019166620448231697
Valid Loss:  0.023841962218284607
Epoch:  185  	Training Loss: 0.021743107587099075
Test Loss:  0.019159309566020966
Valid Loss:  0.023833204060792923
Epoch:  186  	Training Loss: 0.02173451893031597
Test Loss:  0.019152015447616577
Valid Loss:  0.023824460804462433
Epoch:  187  	Training Loss: 0.02172595076262951
Test Loss:  0.019144736230373383
Valid Loss:  0.023815741762518883
Epoch:  188  	Training Loss: 0.021717404946684837
Test Loss:  0.01913747936487198
Valid Loss:  0.023807043209671974
Epoch:  189  	Training Loss: 0.021708877757191658
Test Loss:  0.01913023367524147
Valid Loss:  0.023798368871212006
Epoch:  190  	Training Loss: 0.02170037105679512
Test Loss:  0.019123006612062454
Valid Loss:  0.023789703845977783
Epoch:  191  	Training Loss: 0.021691882982850075
Test Loss:  0.01911579631268978
Valid Loss:  0.02378106117248535
Epoch:  192  	Training Loss: 0.02168341726064682
Test Loss:  0.01910872384905815
Valid Loss:  0.023772533982992172
Epoch:  193  	Training Loss: 0.02167505770921707
Test Loss:  0.019101720303297043
Valid Loss:  0.02376401796936989
Epoch:  194  	Training Loss: 0.021666716784238815
Test Loss:  0.019094733521342278
Valid Loss:  0.023755528032779694
Epoch:  195  	Training Loss: 0.02165839821100235
Test Loss:  0.019087757915258408
Valid Loss:  0.02374705672264099
Epoch:  196  	Training Loss: 0.021650096401572227
Test Loss:  0.01908080279827118
Valid Loss:  0.023738596588373184
Epoch:  197  	Training Loss: 0.021641813218593597
Test Loss:  0.019073862582445145
Valid Loss:  0.023730158805847168
Epoch:  198  	Training Loss: 0.02163354493677616
Test Loss:  0.019066937267780304
Valid Loss:  0.023721735924482346
Epoch:  199  	Training Loss: 0.021625300869345665
Test Loss:  0.019060038030147552
Valid Loss:  0.023713354021310806
Epoch:  200  	Training Loss: 0.02161707729101181
Test Loss:  0.019053157418966293
Valid Loss:  0.02370498701930046
Epoch:  201  	Training Loss: 0.02160886861383915
Test Loss:  0.01904628425836563
Valid Loss:  0.02369663119316101
Epoch:  202  	Training Loss: 0.02160067856311798
Test Loss:  0.019039545208215714
Valid Loss:  0.023688437417149544
Epoch:  203  	Training Loss: 0.021592646837234497
Test Loss:  0.019032826647162437
Valid Loss:  0.023680265992879868
Epoch:  204  	Training Loss: 0.021584630012512207
Test Loss:  0.019026121124625206
Valid Loss:  0.023672107607126236
Epoch:  205  	Training Loss: 0.02157662995159626
Test Loss:  0.01901942864060402
Valid Loss:  0.023663964122533798
Epoch:  206  	Training Loss: 0.021568648517131805
Test Loss:  0.019012749195098877
Valid Loss:  0.02365584671497345
Epoch:  207  	Training Loss: 0.021560687571763992
Test Loss:  0.019006099551916122
Valid Loss:  0.02364775538444519
Epoch:  208  	Training Loss: 0.021552760154008865
Test Loss:  0.018999489024281502
Valid Loss:  0.023639721795916557
Epoch:  209  	Training Loss: 0.021544920280575752
Test Loss:  0.018992897123098373
Valid Loss:  0.023631706833839417
Epoch:  210  	Training Loss: 0.02153710275888443
Test Loss:  0.018986310809850693
Valid Loss:  0.023623697459697723
Epoch:  211  	Training Loss: 0.02152930572628975
Test Loss:  0.018979744985699654
Valid Loss:  0.023615717887878418
Epoch:  212  	Training Loss: 0.021521523594856262
Test Loss:  0.018973149359226227
Valid Loss:  0.023607689887285233
Epoch:  213  	Training Loss: 0.02151370234787464
Test Loss:   43%|████▎     | 213/500 [02:28<03:59,  1.20it/s] 43%|████▎     | 215/500 [02:28<02:52,  1.66it/s] 43%|████▎     | 217/500 [02:28<02:05,  2.26it/s] 44%|████▍     | 219/500 [02:28<01:32,  3.04it/s] 44%|████▍     | 221/500 [02:34<05:24,  1.16s/it] 45%|████▍     | 223/500 [02:34<03:51,  1.20it/s] 45%|████▌     | 225/500 [02:35<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:35<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:35<01:29,  3.04it/s] 46%|████▌     | 231/500 [02:41<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:41<03:43,  1.19it/s] 47%|████▋     | 235/500 [02:41<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:42<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:42<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:48<05:02,  1.17s/it] 49%|████▊     | 243/500 [02:48<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:48<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:48<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:48<01:23,  3.01it/s] 50%|█████     | 251/500 [02:55<04:54,  1.18s/it] 51%|█████     | 253/500 [02:55<03:29,  1.18it/s] 51%|█████     | 255/500 [02:55<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:55<01:49,  2.23it/s] 52%|█████▏    | 259/500 [02:55<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:01<04:37,  1.16s/it] 53%|█████▎    | 263/500 [03:02<03:17,  1.20it/s] 53%|█████▎    | 265/500 [03:02<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:02<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:02<01:16,  3.04it/s] 54%|█████▍    | 271/500 [03:08<04:23,  1.15s/it] 55%|█████▍    | 273/500 [03:08<03:07,  1.21it/s] 55%|█████▌    | 275/500 [03:08<02:14,  1.67it/s] 55%|█████▌    | 277/500 [03:09<01:37,  2.29it/s] 56%|█████▌    | 279/500 [03:09<01:11,  3.07it/s] 56%|█████▌    | 281/500 [03:15<04:13,  1.16s/it] 57%|█████▋    | 283/500 [03:15<03:00,  1.20it/s]0.018966563045978546
Valid Loss:  0.02359967865049839
Epoch:  214  	Training Loss: 0.021505897864699364
Test Loss:  0.018959997221827507
Valid Loss:  0.02359168976545334
Epoch:  215  	Training Loss: 0.021498113870620728
Test Loss:  0.018953442573547363
Valid Loss:  0.02358371764421463
Epoch:  216  	Training Loss: 0.021490346640348434
Test Loss:  0.018946902826428413
Valid Loss:  0.023575764149427414
Epoch:  217  	Training Loss: 0.021482601761817932
Test Loss:  0.018940383568406105
Valid Loss:  0.02356782928109169
Epoch:  218  	Training Loss: 0.021474871784448624
Test Loss:  0.01893387734889984
Valid Loss:  0.02355990931391716
Epoch:  219  	Training Loss: 0.021467162296175957
Test Loss:  0.018927382305264473
Valid Loss:  0.02355200983583927
Epoch:  220  	Training Loss: 0.021459469571709633
Test Loss:  0.018920905888080597
Valid Loss:  0.023544128984212875
Epoch:  221  	Training Loss: 0.021451793611049652
Test Loss:  0.018914438784122467
Valid Loss:  0.023536261171102524
Epoch:  222  	Training Loss: 0.021444136276841164
Test Loss:  0.018907971680164337
Valid Loss:  0.023528382182121277
Epoch:  223  	Training Loss: 0.02143646776676178
Test Loss:  0.018901515752077103
Valid Loss:  0.02352052368223667
Epoch:  224  	Training Loss: 0.021428819745779037
Test Loss:  0.01889507845044136
Valid Loss:  0.023512687534093857
Epoch:  225  	Training Loss: 0.021421190351247787
Test Loss:  0.018888652324676514
Valid Loss:  0.023504864424467087
Epoch:  226  	Training Loss: 0.02141357772052288
Test Loss:  0.01888223923742771
Valid Loss:  0.02349705621600151
Epoch:  227  	Training Loss: 0.021405983716249466
Test Loss:  0.0188758447766304
Valid Loss:  0.023489266633987427
Epoch:  228  	Training Loss: 0.021398404613137245
Test Loss:  0.018869459629058838
Valid Loss:  0.023481491953134537
Epoch:  229  	Training Loss: 0.021390844136476517
Test Loss:  0.018863094970583916
Valid Loss:  0.023473739624023438
Epoch:  230  	Training Loss: 0.02138330042362213
Test Loss:  0.01885673776268959
Valid Loss:  0.023466002196073532
Epoch:  231  	Training Loss: 0.02137577533721924
Test Loss:  0.018850399181246758
Valid Loss:  0.023458275943994522
Epoch:  232  	Training Loss: 0.02136826515197754
Test Loss:  0.018844086676836014
Valid Loss:  0.023450590670108795
Epoch:  233  	Training Loss: 0.021360788494348526
Test Loss:  0.018837790936231613
Valid Loss:  0.023442920297384262
Epoch:  234  	Training Loss: 0.021353326737880707
Test Loss:  0.01883150264620781
Valid Loss:  0.023435255512595177
Epoch:  235  	Training Loss: 0.02134588733315468
Test Loss:  0.018825232982635498
Valid Loss:  0.023427613079547882
Epoch:  236  	Training Loss: 0.021338459104299545
Test Loss:  0.01881897822022438
Valid Loss:  0.02341998927295208
Epoch:  237  	Training Loss: 0.021331051364541054
Test Loss:  0.01881273277103901
Valid Loss:  0.02341238409280777
Epoch:  238  	Training Loss: 0.021323656663298607
Test Loss:  0.01880650594830513
Valid Loss:  0.023404791951179504
Epoch:  239  	Training Loss: 0.0213162824511528
Test Loss:  0.01880030333995819
Valid Loss:  0.023397233337163925
Epoch:  240  	Training Loss: 0.02130892314016819
Test Loss:  0.018794111907482147
Valid Loss:  0.02338968962430954
Epoch:  241  	Training Loss: 0.02130158059298992
Test Loss:  0.018787935376167297
Valid Loss:  0.02338215708732605
Epoch:  242  	Training Loss: 0.021294258534908295
Test Loss:  0.01878177374601364
Valid Loss:  0.02337464690208435
Epoch:  243  	Training Loss: 0.021286949515342712
Test Loss:  0.01877562329173088
Valid Loss:  0.023367147892713547
Epoch:  244  	Training Loss: 0.02127966284751892
Test Loss:  0.018769484013319016
Valid Loss:  0.023359661921858788
Epoch:  245  	Training Loss: 0.021272404119372368
Test Loss:  0.018763381987810135
Valid Loss:  0.02335222065448761
Epoch:  246  	Training Loss: 0.021265186369419098
Test Loss:  0.01875728741288185
Valid Loss:  0.02334478870034218
Epoch:  247  	Training Loss: 0.021257983520627022
Test Loss:  0.01875121146440506
Valid Loss:  0.023337379097938538
Epoch:  248  	Training Loss: 0.021250799298286438
Test Loss:  0.018745144829154015
Valid Loss:  0.02332998439669609
Epoch:  249  	Training Loss: 0.0212436281144619
Test Loss:  0.018739093095064163
Valid Loss:  0.02332260273396969
Epoch:  250  	Training Loss: 0.021236473694443703
Test Loss:  0.018733054399490356
Valid Loss:  0.02331523969769478
Epoch:  251  	Training Loss: 0.021229337900877
Test Loss:  0.018727026879787445
Valid Loss:  0.023307889699935913
Epoch:  252  	Training Loss: 0.021222218871116638
Test Loss:  0.018720995634794235
Valid Loss:  0.02330053225159645
Epoch:  253  	Training Loss: 0.021215088665485382
Test Loss:  0.01871497556567192
Valid Loss:  0.023293185979127884
Epoch:  254  	Training Loss: 0.02120797522366047
Test Loss:  0.0187089666724205
Valid Loss:  0.023285862058401108
Epoch:  255  	Training Loss: 0.02120088040828705
Test Loss:  0.018702974542975426
Valid Loss:  0.023278549313545227
Epoch:  256  	Training Loss: 0.021193798631429672
Test Loss:  0.018696991726756096
Valid Loss:  0.02327125146985054
Epoch:  257  	Training Loss: 0.02118673175573349
Test Loss:  0.018691029399633408
Valid Loss:  0.023263975977897644
Epoch:  258  	Training Loss: 0.0211796872317791
Test Loss:  0.018685072660446167
Valid Loss:  0.023256709799170494
Epoch:  259  	Training Loss: 0.021172653883695602
Test Loss:  0.01867913454771042
Valid Loss:  0.02324945479631424
Epoch:  260  	Training Loss: 0.0211656354367733
Test Loss:  0.01867320016026497
Valid Loss:  0.023242220282554626
Epoch:  261  	Training Loss: 0.02115863375365734
Test Loss:  0.018667282536625862
Valid Loss:  0.02323499694466591
Epoch:  262  	Training Loss: 0.021151643246412277
Test Loss:  0.018661390990018845
Valid Loss:  0.02322779968380928
Epoch:  263  	Training Loss: 0.02114468812942505
Test Loss:  0.018655508756637573
Valid Loss:  0.023220617324113846
Epoch:  264  	Training Loss: 0.021137742325663567
Test Loss:  0.018649637699127197
Valid Loss:  0.023213457316160202
Epoch:  265  	Training Loss: 0.021130811423063278
Test Loss:  0.018643779680132866
Valid Loss:  0.023206312209367752
Epoch:  266  	Training Loss: 0.02112390100955963
Test Loss:  0.01863793283700943
Valid Loss:  0.023199182003736496
Epoch:  267  	Training Loss: 0.02111700549721718
Test Loss:  0.01863209903240204
Valid Loss:  0.023192068561911583
Epoch:  268  	Training Loss: 0.02111012116074562
Test Loss:  0.01862628012895584
Valid Loss:  0.023184962570667267
Epoch:  269  	Training Loss: 0.021103251725435257
Test Loss:  0.01862046867609024
Valid Loss:  0.023177877068519592
Epoch:  270  	Training Loss: 0.021096397191286087
Test Loss:  0.018614672124385834
Valid Loss:  0.023170802742242813
Epoch:  271  	Training Loss: 0.02108955755829811
Test Loss:  0.018608881160616875
Valid Loss:  0.023163743317127228
Epoch:  272  	Training Loss: 0.02108273096382618
Test Loss:  0.01860314980149269
Valid Loss:  0.023156743496656418
Epoch:  273  	Training Loss: 0.021075967699289322
Test Loss:  0.018597420305013657
Valid Loss:  0.0231497623026371
Epoch:  274  	Training Loss: 0.0210692398250103
Test Loss:  0.018591739237308502
Valid Loss:  0.023142825812101364
Epoch:  275  	Training Loss: 0.021062541753053665
Test Loss:  0.018586071208119392
Valid Loss:  0.02313590794801712
Epoch:  276  	Training Loss: 0.021055862307548523
Test Loss:  0.018580414354801178
Valid Loss:  0.023128997534513474
Epoch:  277  	Training Loss: 0.021049190312623978
Test Loss:  0.018574770539999008
Valid Loss:  0.023122107610106468
Epoch:  278  	Training Loss: 0.021042540669441223
Test Loss:  0.018569136038422585
Valid Loss:  0.02311522886157036
Epoch:  279  	Training Loss: 0.021035902202129364
Test Loss:  0.018563520163297653
Valid Loss:  0.02310836687684059
Epoch:  280  	Training Loss: 0.0210292786359787
Test Loss:  0.018557902425527573
Valid Loss:  0.02310151234269142
Epoch:  281  	Training Loss: 0.02102266624569893
Test Loss:  0.018552303314208984
Valid Loss:  0.023094672709703445
Epoch:  282  	Training Loss: 0.02101607248187065
Test Loss:  0.018546760082244873
Valid Loss:  0.02308790385723114
Epoch:  283  	Training Loss: 0.021009542047977448
Test Loss:  0.01854122243821621
Valid Loss:  0.023081142455339432
 57%|█████▋    | 285/500 [03:15<02:09,  1.66it/s] 57%|█████▋    | 287/500 [03:15<01:33,  2.27it/s] 58%|█████▊    | 289/500 [03:15<01:09,  3.05it/s] 58%|█████▊    | 291/500 [03:22<04:02,  1.16s/it] 59%|█████▊    | 293/500 [03:22<02:52,  1.20it/s] 59%|█████▉    | 295/500 [03:22<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:22<01:29,  2.27it/s] 60%|█████▉    | 299/500 [03:22<01:05,  3.05it/s] 60%|██████    | 301/500 [03:28<03:52,  1.17s/it] 61%|██████    | 303/500 [03:29<02:45,  1.19it/s] 61%|██████    | 305/500 [03:29<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:29<01:25,  2.24it/s] 62%|██████▏   | 309/500 [03:29<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:35<03:39,  1.16s/it] 63%|██████▎   | 313/500 [03:35<02:35,  1.20it/s] 63%|██████▎   | 315/500 [03:35<01:51,  1.66it/s] 63%|██████▎   | 317/500 [03:36<01:20,  2.27it/s] 64%|██████▍   | 319/500 [03:36<00:59,  3.04it/s] 64%|██████▍   | 321/500 [03:42<03:28,  1.17s/it] 65%|██████▍   | 323/500 [03:42<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:42<01:45,  1.65it/s] 65%|██████▌   | 327/500 [03:42<01:16,  2.26it/s] 66%|██████▌   | 329/500 [03:42<00:56,  3.04it/s] 66%|██████▌   | 331/500 [03:49<03:16,  1.17s/it] 67%|██████▋   | 333/500 [03:49<02:19,  1.19it/s] 67%|██████▋   | 335/500 [03:49<01:39,  1.65it/s] 67%|██████▋   | 337/500 [03:49<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:49<00:53,  3.03it/s] 68%|██████▊   | 341/500 [03:55<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:56<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:56<01:34,  1.65it/s] 69%|██████▉   | 347/500 [03:56<01:07,  2.25it/s] 70%|██████▉   | 349/500 [03:56<00:49,  3.02it/s] 70%|███████   | 351/500 [04:02<02:53,  1.16s/it] 71%|███████   | 353/500 [04:02<02:02,  1.20it/s]Epoch:  284  	Training Loss: 0.02100302278995514
Test Loss:  0.018535705283284187
Valid Loss:  0.023074395954608917
Epoch:  285  	Training Loss: 0.020996522158384323
Test Loss:  0.018530191853642464
Valid Loss:  0.023067668080329895
Epoch:  286  	Training Loss: 0.020990032702684402
Test Loss:  0.01852470263838768
Valid Loss:  0.023060958832502365
Epoch:  287  	Training Loss: 0.020983556285500526
Test Loss:  0.018519215285778046
Valid Loss:  0.023054255172610283
Epoch:  288  	Training Loss: 0.020977098494768143
Test Loss:  0.018513750284910202
Valid Loss:  0.02304757386445999
Epoch:  289  	Training Loss: 0.020970650017261505
Test Loss:  0.018508296459913254
Valid Loss:  0.023040905594825745
Epoch:  290  	Training Loss: 0.02096421830356121
Test Loss:  0.01850285194814205
Valid Loss:  0.02303425222635269
Epoch:  291  	Training Loss: 0.02095779776573181
Test Loss:  0.018497426062822342
Valid Loss:  0.023027610033750534
Epoch:  292  	Training Loss: 0.020951392129063606
Test Loss:  0.018491972237825394
Valid Loss:  0.023020949214696884
Epoch:  293  	Training Loss: 0.020944969728589058
Test Loss:  0.01848653517663479
Valid Loss:  0.02301429770886898
Epoch:  294  	Training Loss: 0.020938560366630554
Test Loss:  0.018481101840734482
Valid Loss:  0.02300766110420227
Epoch:  295  	Training Loss: 0.020932165905833244
Test Loss:  0.018475713208317757
Valid Loss:  0.023001063615083694
Epoch:  296  	Training Loss: 0.020925816148519516
Test Loss:  0.01847032830119133
Valid Loss:  0.022994481027126312
Epoch:  297  	Training Loss: 0.020919479429721832
Test Loss:  0.018464960157871246
Valid Loss:  0.022987913340330124
Epoch:  298  	Training Loss: 0.02091315947473049
Test Loss:  0.01845959573984146
Valid Loss:  0.02298135869204998
Epoch:  299  	Training Loss: 0.020906854420900345
Test Loss:  0.01845424622297287
Valid Loss:  0.02297482267022133
Epoch:  300  	Training Loss: 0.020900562405586243
Test Loss:  0.018448906019330025
Valid Loss:  0.022968288511037827
Epoch:  301  	Training Loss: 0.020894283428788185
Test Loss:  0.018443576991558075
Valid Loss:  0.022961776703596115
Epoch:  302  	Training Loss: 0.02088801935315132
Test Loss:  0.018438242375850677
Valid Loss:  0.02295525372028351
Epoch:  303  	Training Loss: 0.020881744101643562
Test Loss:  0.018432920798659325
Valid Loss:  0.022948749363422394
Epoch:  304  	Training Loss: 0.020875483751296997
Test Loss:  0.018427610397338867
Valid Loss:  0.022942259907722473
Epoch:  305  	Training Loss: 0.020869242027401924
Test Loss:  0.018422309309244156
Valid Loss:  0.0229357797652483
Epoch:  306  	Training Loss: 0.020863007754087448
Test Loss:  0.01841701567173004
Valid Loss:  0.02292931079864502
Epoch:  307  	Training Loss: 0.020856793969869614
Test Loss:  0.01841173879802227
Valid Loss:  0.022922854870557785
Epoch:  308  	Training Loss: 0.020850589498877525
Test Loss:  0.018406469374895096
Valid Loss:  0.022916417568922043
Epoch:  309  	Training Loss: 0.02084439806640148
Test Loss:  0.018401209264993668
Valid Loss:  0.022909991443157196
Epoch:  310  	Training Loss: 0.020838219672441483
Test Loss:  0.018395962193608284
Valid Loss:  0.022903574630618095
Epoch:  311  	Training Loss: 0.020832059904932976
Test Loss:  0.018390748649835587
Valid Loss:  0.022897198796272278
Epoch:  312  	Training Loss: 0.020825935527682304
Test Loss:  0.0183855053037405
Valid Loss:  0.022890795022249222
Epoch:  313  	Training Loss: 0.020819786936044693
Test Loss:  0.01838027685880661
Valid Loss:  0.022884398698806763
Epoch:  314  	Training Loss: 0.020813649520277977
Test Loss:  0.018375052139163017
Valid Loss:  0.022878017276525497
Epoch:  315  	Training Loss: 0.020807527005672455
Test Loss:  0.01836984232068062
Valid Loss:  0.022871650755405426
Epoch:  316  	Training Loss: 0.020801417529582977
Test Loss:  0.018364641815423965
Valid Loss:  0.0228652935475111
Epoch:  317  	Training Loss: 0.020795319229364395
Test Loss:  0.0183594711124897
Valid Loss:  0.022858958691358566
Epoch:  318  	Training Loss: 0.020789239555597305
Test Loss:  0.018354307860136032
Valid Loss:  0.022852635011076927
Epoch:  319  	Training Loss: 0.02078316919505596
Test Loss:  0.01834915205836296
Valid Loss:  0.022846326231956482
Epoch:  320  	Training Loss: 0.02077711559832096
Test Loss:  0.01834401860833168
Valid Loss:  0.022840026766061783
Epoch:  321  	Training Loss: 0.020771075040102005
Test Loss:  0.0183388814330101
Valid Loss:  0.022833744063973427
Epoch:  322  	Training Loss: 0.020765047520399094
Test Loss:  0.018333803862333298
Valid Loss:  0.022827528417110443
Epoch:  323  	Training Loss: 0.020759087055921555
Test Loss:  0.018328741192817688
Valid Loss:  0.022821325808763504
Epoch:  324  	Training Loss: 0.02075313776731491
Test Loss:  0.018323682248592377
Valid Loss:  0.022815130650997162
Epoch:  325  	Training Loss: 0.02074720524251461
Test Loss:  0.01831863820552826
Valid Loss:  0.02280895784497261
Epoch:  326  	Training Loss: 0.020741280168294907
Test Loss:  0.018313603475689888
Valid Loss:  0.022802788764238358
Epoch:  327  	Training Loss: 0.020735371857881546
Test Loss:  0.018308576196432114
Valid Loss:  0.0227966345846653
Epoch:  328  	Training Loss: 0.02072947658598423
Test Loss:  0.018303561955690384
Valid Loss:  0.022790495306253433
Epoch:  329  	Training Loss: 0.02072359435260296
Test Loss:  0.01829855516552925
Valid Loss:  0.022784367203712463
Epoch:  330  	Training Loss: 0.02071772702038288
Test Loss:  0.018293559551239014
Valid Loss:  0.02277824655175209
Epoch:  331  	Training Loss: 0.02071186900138855
Test Loss:  0.018288571387529373
Valid Loss:  0.02277214266359806
Epoch:  332  	Training Loss: 0.020706024020910263
Test Loss:  0.01828356832265854
Valid Loss:  0.02276601828634739
Epoch:  333  	Training Loss: 0.020700164139270782
Test Loss:  0.0182785727083683
Valid Loss:  0.022759899497032166
Epoch:  334  	Training Loss: 0.0206943117082119
Test Loss:  0.018273591995239258
Valid Loss:  0.022753799334168434
Epoch:  335  	Training Loss: 0.02068847231566906
Test Loss:  0.018268615007400513
Valid Loss:  0.022747714072465897
Epoch:  336  	Training Loss: 0.020682651549577713
Test Loss:  0.018263651058077812
Valid Loss:  0.022741632536053658
Epoch:  337  	Training Loss: 0.020676836371421814
Test Loss:  0.018258696421980858
Valid Loss:  0.022735562175512314
Epoch:  338  	Training Loss: 0.020671037957072258
Test Loss:  0.01825374737381935
Valid Loss:  0.022729504853487015
Epoch:  339  	Training Loss: 0.0206652469933033
Test Loss:  0.01824881136417389
Valid Loss:  0.022723466157913208
Epoch:  340  	Training Loss: 0.02065947651863098
Test Loss:  0.018243880942463875
Valid Loss:  0.02271743305027485
Epoch:  341  	Training Loss: 0.020653709769248962
Test Loss:  0.018238961696624756
Valid Loss:  0.022711411118507385
Epoch:  342  	Training Loss: 0.020647957921028137
Test Loss:  0.018234053626656532
Valid Loss:  0.022705400362610817
Epoch:  343  	Training Loss: 0.020642220973968506
Test Loss:  0.018229154869914055
Valid Loss:  0.022699406370520592
Epoch:  344  	Training Loss: 0.02063649147748947
Test Loss:  0.018224261701107025
Valid Loss:  0.022693417966365814
Epoch:  345  	Training Loss: 0.02063077688217163
Test Loss:  0.01821938157081604
Valid Loss:  0.02268744260072708
Epoch:  346  	Training Loss: 0.020625077188014984
Test Loss:  0.018214507028460503
Valid Loss:  0.022681480273604393
Epoch:  347  	Training Loss: 0.020619388669729233
Test Loss:  0.01820966601371765
Valid Loss:  0.022675558924674988
Epoch:  348  	Training Loss: 0.020613739266991615
Test Loss:  0.018204841762781143
Valid Loss:  0.022669648751616478
Epoch:  349  	Training Loss: 0.020608099177479744
Test Loss:  0.018200024962425232
Valid Loss:  0.022663749754428864
Epoch:  350  	Training Loss: 0.020602472126483917
Test Loss:  0.01819521375000477
Valid Loss:  0.022657865658402443
Epoch:  351  	Training Loss: 0.020596858114004135
Test Loss:  0.0181904137134552
Valid Loss:  0.022651992738246918
Epoch:  352  	Training Loss: 0.02059125527739525
Test Loss:  0.018185636028647423
Valid Loss:  0.022646138444542885
Epoch:  353  	Training Loss: 0.02058567851781845
Test Loss:  0.018180862069129944
Valid Loss:  0.022640299052000046
Epoch:  354  	Training Loss: 0.020580114796757698
Test Loss:   71%|███████   | 355/500 [04:02<01:27,  1.66it/s] 71%|███████▏  | 357/500 [04:03<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:03<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:09<02:41,  1.16s/it] 73%|███████▎  | 363/500 [04:09<01:54,  1.20it/s] 73%|███████▎  | 365/500 [04:09<01:21,  1.66it/s] 73%|███████▎  | 367/500 [04:09<00:58,  2.27it/s] 74%|███████▍  | 369/500 [04:09<00:42,  3.05it/s] 74%|███████▍  | 371/500 [04:16<02:29,  1.16s/it] 75%|███████▍  | 373/500 [04:16<01:45,  1.20it/s] 75%|███████▌  | 375/500 [04:16<01:15,  1.66it/s] 75%|███████▌  | 377/500 [04:16<00:54,  2.26it/s] 76%|███████▌  | 379/500 [04:16<00:39,  3.03it/s] 76%|███████▌  | 381/500 [04:22<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:23<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:23<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:23<00:50,  2.26it/s] 78%|███████▊  | 389/500 [04:23<00:36,  3.04it/s] 78%|███████▊  | 391/500 [04:29<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:29<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:30<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:30<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:30<00:33,  3.01it/s] 80%|████████  | 401/500 [04:36<01:54,  1.16s/it] 81%|████████  | 403/500 [04:36<01:20,  1.20it/s] 81%|████████  | 405/500 [04:36<00:57,  1.66it/s] 81%|████████▏ | 407/500 [04:36<00:40,  2.27it/s] 82%|████████▏ | 409/500 [04:36<00:29,  3.05it/s] 82%|████████▏ | 411/500 [04:43<01:43,  1.17s/it] 83%|████████▎ | 413/500 [04:43<01:12,  1.19it/s] 83%|████████▎ | 415/500 [04:43<00:51,  1.65it/s] 83%|████████▎ | 417/500 [04:43<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:43<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:49<01:32,  1.16s/it] 85%|████████▍ | 423/500 [04:50<01:04,  1.19it/s]0.01817609742283821
Valid Loss:  0.022634468972682953
Epoch:  355  	Training Loss: 0.02057456038892269
Test Loss:  0.018171343952417374
Valid Loss:  0.022628653794527054
Epoch:  356  	Training Loss: 0.020569022744894028
Test Loss:  0.018166612833738327
Valid Loss:  0.022622855380177498
Epoch:  357  	Training Loss: 0.02056349441409111
Test Loss:  0.018161894753575325
Valid Loss:  0.02261706441640854
Epoch:  358  	Training Loss: 0.02055797353386879
Test Loss:  0.01815718412399292
Valid Loss:  0.022611284628510475
Epoch:  359  	Training Loss: 0.020552469417452812
Test Loss:  0.01815248280763626
Valid Loss:  0.022605519741773605
Epoch:  360  	Training Loss: 0.02054697647690773
Test Loss:  0.0181477852165699
Valid Loss:  0.02259976416826248
Epoch:  361  	Training Loss: 0.020541496574878693
Test Loss:  0.018143098801374435
Valid Loss:  0.022594021633267403
Epoch:  362  	Training Loss: 0.02053602784872055
Test Loss:  0.018138445913791656
Valid Loss:  0.02258831262588501
Epoch:  363  	Training Loss: 0.020530594512820244
Test Loss:  0.018133820965886116
Valid Loss:  0.022582627832889557
Epoch:  364  	Training Loss: 0.02052517607808113
Test Loss:  0.018129199743270874
Valid Loss:  0.0225769504904747
Epoch:  365  	Training Loss: 0.020519763231277466
Test Loss:  0.018124572932720184
Valid Loss:  0.022571278735995293
Epoch:  366  	Training Loss: 0.020514367148280144
Test Loss:  0.018119968473911285
Valid Loss:  0.022565625607967377
Epoch:  367  	Training Loss: 0.020508982241153717
Test Loss:  0.018115375190973282
Valid Loss:  0.02255997434258461
Epoch:  368  	Training Loss: 0.020503604784607887
Test Loss:  0.018110789358615875
Valid Loss:  0.022554337978363037
Epoch:  369  	Training Loss: 0.020498238503932953
Test Loss:  0.018106194213032722
Valid Loss:  0.02254870906472206
Epoch:  370  	Training Loss: 0.020492887124419212
Test Loss:  0.01810162514448166
Valid Loss:  0.02254309505224228
Epoch:  371  	Training Loss: 0.02048754319548607
Test Loss:  0.018097061663866043
Valid Loss:  0.022537488490343094
Epoch:  372  	Training Loss: 0.020482219755649567
Test Loss:  0.018092509359121323
Valid Loss:  0.022531893104314804
Epoch:  373  	Training Loss: 0.020476890727877617
Test Loss:  0.0180879645049572
Valid Loss:  0.02252631075680256
Epoch:  374  	Training Loss: 0.020471569150686264
Test Loss:  0.01808343082666397
Valid Loss:  0.02252073585987091
Epoch:  375  	Training Loss: 0.020466264337301254
Test Loss:  0.01807890273630619
Valid Loss:  0.02251517027616501
Epoch:  376  	Training Loss: 0.02046097069978714
Test Loss:  0.018074382096529007
Valid Loss:  0.022509615868330002
Epoch:  377  	Training Loss: 0.020455684512853622
Test Loss:  0.01806987076997757
Valid Loss:  0.02250407636165619
Epoch:  378  	Training Loss: 0.0204504132270813
Test Loss:  0.01806536689400673
Valid Loss:  0.022498540580272675
Epoch:  379  	Training Loss: 0.02044515125453472
Test Loss:  0.018060872331261635
Valid Loss:  0.022493019700050354
Epoch:  380  	Training Loss: 0.02043990232050419
Test Loss:  0.018056385219097137
Valid Loss:  0.02248750627040863
Epoch:  381  	Training Loss: 0.02043466456234455
Test Loss:  0.018051907420158386
Valid Loss:  0.022482002153992653
Epoch:  382  	Training Loss: 0.02042943611741066
Test Loss:  0.01804742030799389
Valid Loss:  0.02247648686170578
Epoch:  383  	Training Loss: 0.020424196496605873
Test Loss:  0.01804293692111969
Valid Loss:  0.022470980882644653
Epoch:  384  	Training Loss: 0.02041896991431713
Test Loss:  0.018038464710116386
Valid Loss:  0.022465484216809273
Epoch:  385  	Training Loss: 0.020413754507899284
Test Loss:  0.01803399808704853
Valid Loss:  0.022459998726844788
Epoch:  386  	Training Loss: 0.020408546552062035
Test Loss:  0.018029537051916122
Valid Loss:  0.02245452255010605
Epoch:  387  	Training Loss: 0.02040335163474083
Test Loss:  0.01802508905529976
Valid Loss:  0.022449057549238205
Epoch:  388  	Training Loss: 0.02039816789329052
Test Loss:  0.01802065223455429
Valid Loss:  0.022443599998950958
Epoch:  389  	Training Loss: 0.020392991602420807
Test Loss:  0.018016211688518524
Valid Loss:  0.022438153624534607
Epoch:  390  	Training Loss: 0.020387832075357437
Test Loss:  0.018011782318353653
Valid Loss:  0.022432714700698853
Epoch:  391  	Training Loss: 0.020382676273584366
Test Loss:  0.018007362261414528
Valid Loss:  0.022427285090088844
Epoch:  392  	Training Loss: 0.02037753537297249
Test Loss:  0.01800292544066906
Valid Loss:  0.022421838715672493
Epoch:  393  	Training Loss: 0.020372377708554268
Test Loss:  0.017998497933149338
Valid Loss:  0.022416403517127037
Epoch:  394  	Training Loss: 0.020367231220006943
Test Loss:  0.017994076013565063
Valid Loss:  0.022410979494452477
Epoch:  395  	Training Loss: 0.020362097769975662
Test Loss:  0.017989668995141983
Valid Loss:  0.022405559197068214
Epoch:  396  	Training Loss: 0.020356975495815277
Test Loss:  0.017985260114073753
Valid Loss:  0.022400151938199997
Epoch:  397  	Training Loss: 0.02035185880959034
Test Loss:  0.01798086240887642
Valid Loss:  0.022394752129912376
Epoch:  398  	Training Loss: 0.020346755161881447
Test Loss:  0.017976470291614532
Valid Loss:  0.02238936349749565
Epoch:  399  	Training Loss: 0.02034166269004345
Test Loss:  0.01797209121286869
Valid Loss:  0.022383984178304672
Epoch:  400  	Training Loss: 0.020336579531431198
Test Loss:  0.017967715859413147
Valid Loss:  0.02237860858440399
Epoch:  401  	Training Loss: 0.020331505686044693
Test Loss:  0.017963344231247902
Valid Loss:  0.022373251616954803
Epoch:  402  	Training Loss: 0.020326443016529083
Test Loss:  0.017959000542759895
Valid Loss:  0.022367920726537704
Epoch:  403  	Training Loss: 0.02032141014933586
Test Loss:  0.017954666167497635
Valid Loss:  0.022362597286701202
Epoch:  404  	Training Loss: 0.020316384732723236
Test Loss:  0.017950335517525673
Valid Loss:  0.022357285022735596
Epoch:  405  	Training Loss: 0.020311370491981506
Test Loss:  0.017946014180779457
Valid Loss:  0.022351978346705437
Epoch:  406  	Training Loss: 0.020306363701820374
Test Loss:  0.01794169656932354
Valid Loss:  0.022346684709191322
Epoch:  407  	Training Loss: 0.020301369950175285
Test Loss:  0.01793738827109337
Valid Loss:  0.022341396659612656
Epoch:  408  	Training Loss: 0.020296383649110794
Test Loss:  0.017933087423443794
Valid Loss:  0.022336117923259735
Epoch:  409  	Training Loss: 0.020291408523917198
Test Loss:  0.017928792163729668
Valid Loss:  0.02233085036277771
Epoch:  410  	Training Loss: 0.020286448299884796
Test Loss:  0.01792452484369278
Valid Loss:  0.022325607016682625
Epoch:  411  	Training Loss: 0.02028149552643299
Test Loss:  0.01792026497423649
Valid Loss:  0.022320367395877838
Epoch:  412  	Training Loss: 0.020276550203561783
Test Loss:  0.0179159976541996
Valid Loss:  0.022315120324492455
Epoch:  413  	Training Loss: 0.02027159556746483
Test Loss:  0.01791173592209816
Valid Loss:  0.02230987697839737
Epoch:  414  	Training Loss: 0.02026665396988392
Test Loss:  0.017907485365867615
Valid Loss:  0.02230464667081833
Epoch:  415  	Training Loss: 0.020261721685528755
Test Loss:  0.01790323480963707
Valid Loss:  0.022299421951174736
Epoch:  416  	Training Loss: 0.020256798714399338
Test Loss:  0.01789899542927742
Valid Loss:  0.022294212132692337
Epoch:  417  	Training Loss: 0.020251886919140816
Test Loss:  0.01789475977420807
Valid Loss:  0.022289006039500237
Epoch:  418  	Training Loss: 0.02024698257446289
Test Loss:  0.017890535295009613
Valid Loss:  0.022283807396888733
Epoch:  419  	Training Loss: 0.02024208754301071
Test Loss:  0.017886314541101456
Valid Loss:  0.022278623655438423
Epoch:  420  	Training Loss: 0.020237203687429428
Test Loss:  0.017882101237773895
Valid Loss:  0.022273443639278412
Epoch:  421  	Training Loss: 0.02023232914507389
Test Loss:  0.017877891659736633
Valid Loss:  0.022268272936344147
Epoch:  422  	Training Loss: 0.02022746205329895
Test Loss:  0.017873693257570267
Valid Loss:  0.022263117134571075
Epoch:  423  	Training Loss: 0.020222606137394905
Test Loss:  0.017869502305984497
Valid Loss:  0.0222579687833786
Epoch:  424  	Training Loss: 0.020217757672071457
Test Loss:  0.017865311354398727
Valid Loss:  0.022252824157476425
 85%|████████▌ | 425/500 [04:50<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:50<00:32,  2.25it/s] 86%|████████▌ | 429/500 [04:50<00:23,  3.03it/s] 86%|████████▌ | 431/500 [04:56<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:56<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:57<00:39,  1.65it/s] 87%|████████▋ | 437/500 [04:57<00:28,  2.25it/s] 88%|████████▊ | 439/500 [04:57<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:03<01:08,  1.16s/it] 89%|████████▊ | 443/500 [05:03<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:03<00:33,  1.66it/s] 89%|████████▉ | 447/500 [05:03<00:23,  2.27it/s] 90%|████████▉ | 449/500 [05:04<00:16,  3.05it/s] 90%|█████████ | 451/500 [05:10<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:10<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:10<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:10<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:10<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:17<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:17<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:17<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:17<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:17<00:10,  3.03it/s] 94%|█████████▍| 471/500 [05:23<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:24<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:24<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:24<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:24<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:30<00:22,  1.16s/it] 97%|█████████▋| 483/500 [05:30<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:30<00:09,  1.66it/s] 97%|█████████▋| 487/500 [05:30<00:05,  2.27it/s] 98%|█████████▊| 489/500 [05:31<00:03,  3.04it/s] 98%|█████████▊| 491/500 [05:37<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:37<00:05,  1.20it/s]Epoch:  425  	Training Loss: 0.020212918519973755
Test Loss:  0.01786113530397415
Valid Loss:  0.022247692570090294
Epoch:  426  	Training Loss: 0.02020808681845665
Test Loss:  0.017856961116194725
Valid Loss:  0.02224256470799446
Epoch:  427  	Training Loss: 0.02020327001810074
Test Loss:  0.01785282790660858
Valid Loss:  0.022237492725253105
Epoch:  428  	Training Loss: 0.020198484882712364
Test Loss:  0.017848700284957886
Valid Loss:  0.022232424467802048
Epoch:  429  	Training Loss: 0.020193712785840034
Test Loss:  0.01784457638859749
Valid Loss:  0.02222735993564129
Epoch:  430  	Training Loss: 0.0201889481395483
Test Loss:  0.017840467393398285
Valid Loss:  0.022222308441996574
Epoch:  431  	Training Loss: 0.020184196531772614
Test Loss:  0.01783636026084423
Valid Loss:  0.022217262536287308
Epoch:  432  	Training Loss: 0.020179450511932373
Test Loss:  0.017832256853580475
Valid Loss:  0.022212229669094086
Epoch:  433  	Training Loss: 0.02017470821738243
Test Loss:  0.01782815530896187
Valid Loss:  0.022207189351320267
Epoch:  434  	Training Loss: 0.020169973373413086
Test Loss:  0.017824064940214157
Valid Loss:  0.02220216765999794
Epoch:  435  	Training Loss: 0.020165247842669487
Test Loss:  0.017819982022047043
Valid Loss:  0.02219715528190136
Epoch:  436  	Training Loss: 0.020160535350441933
Test Loss:  0.01781589910387993
Valid Loss:  0.022192146629095078
Epoch:  437  	Training Loss: 0.020155828446149826
Test Loss:  0.01781182736158371
Valid Loss:  0.02218714915215969
Epoch:  438  	Training Loss: 0.020151136443018913
Test Loss:  0.017807792872190475
Valid Loss:  0.022182196378707886
Epoch:  439  	Training Loss: 0.020146474242210388
Test Loss:  0.017803771421313286
Valid Loss:  0.022177256643772125
Epoch:  440  	Training Loss: 0.02014181949198246
Test Loss:  0.017799753695726395
Valid Loss:  0.02217232435941696
Epoch:  441  	Training Loss: 0.020137175917625427
Test Loss:  0.017795739695429802
Valid Loss:  0.022167397662997246
Epoch:  442  	Training Loss: 0.02013254165649414
Test Loss:  0.0177917443215847
Valid Loss:  0.022162487730383873
Epoch:  443  	Training Loss: 0.020127922296524048
Test Loss:  0.01778775453567505
Valid Loss:  0.022157594561576843
Epoch:  444  	Training Loss: 0.02012331783771515
Test Loss:  0.017783772200345993
Valid Loss:  0.022152703255414963
Epoch:  445  	Training Loss: 0.020118720829486847
Test Loss:  0.017779793590307236
Valid Loss:  0.022147826850414276
Epoch:  446  	Training Loss: 0.02011413499712944
Test Loss:  0.017775826156139374
Valid Loss:  0.02214295230805874
Epoch:  447  	Training Loss: 0.02010955661535263
Test Loss:  0.017771858721971512
Valid Loss:  0.022138088941574097
Epoch:  448  	Training Loss: 0.020104989409446716
Test Loss:  0.017767922952771187
Valid Loss:  0.02213324047625065
Epoch:  449  	Training Loss: 0.020100431516766548
Test Loss:  0.01776399277150631
Valid Loss:  0.022128399461507797
Epoch:  450  	Training Loss: 0.020095882937312126
Test Loss:  0.01776007190346718
Valid Loss:  0.02212356962263584
Epoch:  451  	Training Loss: 0.0200913418084383
Test Loss:  0.017756149172782898
Valid Loss:  0.022118745371699333
Epoch:  452  	Training Loss: 0.02008681371808052
Test Loss:  0.017752230167388916
Valid Loss:  0.022113913670182228
Epoch:  453  	Training Loss: 0.020082280039787292
Test Loss:  0.017748309299349785
Valid Loss:  0.02210909128189087
Epoch:  454  	Training Loss: 0.02007775381207466
Test Loss:  0.017744403332471848
Valid Loss:  0.022104278206825256
Epoch:  455  	Training Loss: 0.020073238760232925
Test Loss:  0.01774049550294876
Valid Loss:  0.02209947258234024
Epoch:  456  	Training Loss: 0.020068731158971786
Test Loss:  0.01773660071194172
Valid Loss:  0.02209467440843582
Epoch:  457  	Training Loss: 0.020064232870936394
Test Loss:  0.017732711508870125
Valid Loss:  0.022089887410402298
Epoch:  458  	Training Loss: 0.020059743896126747
Test Loss:  0.01772882603108883
Valid Loss:  0.02208510786294937
Epoch:  459  	Training Loss: 0.020055260509252548
Test Loss:  0.01772494986653328
Valid Loss:  0.022080332040786743
Epoch:  460  	Training Loss: 0.020050784572958946
Test Loss:  0.01772107556462288
Valid Loss:  0.02207556739449501
Epoch:  461  	Training Loss: 0.020046323537826538
Test Loss:  0.017717208713293076
Valid Loss:  0.022070815786719322
Epoch:  462  	Training Loss: 0.020041868090629578
Test Loss:  0.017713360488414764
Valid Loss:  0.022066080942749977
Epoch:  463  	Training Loss: 0.020037434995174408
Test Loss:  0.01770951971411705
Valid Loss:  0.022061355412006378
Epoch:  464  	Training Loss: 0.020033007487654686
Test Loss:  0.017705686390399933
Valid Loss:  0.022056639194488525
Epoch:  465  	Training Loss: 0.02002859115600586
Test Loss:  0.017701853066682816
Valid Loss:  0.02205192856490612
Epoch:  466  	Training Loss: 0.02002418041229248
Test Loss:  0.01769804209470749
Valid Loss:  0.022047225385904312
Epoch:  467  	Training Loss: 0.020019778981804848
Test Loss:  0.01769423857331276
Valid Loss:  0.02204253152012825
Epoch:  468  	Training Loss: 0.02001538872718811
Test Loss:  0.017690446227788925
Valid Loss:  0.022037848830223083
Epoch:  469  	Training Loss: 0.02001100592315197
Test Loss:  0.01768665388226509
Valid Loss:  0.022033169865608215
Epoch:  470  	Training Loss: 0.020006632432341576
Test Loss:  0.017682870849967003
Valid Loss:  0.02202850580215454
Epoch:  471  	Training Loss: 0.020002268254756927
Test Loss:  0.017679093405604362
Valid Loss:  0.022023839876055717
Epoch:  472  	Training Loss: 0.019997909665107727
Test Loss:  0.017675301060080528
Valid Loss:  0.022019166499376297
Epoch:  473  	Training Loss: 0.01999354362487793
Test Loss:  0.01767151802778244
Valid Loss:  0.022014502435922623
Epoch:  474  	Training Loss: 0.01998918503522873
Test Loss:  0.017667781561613083
Valid Loss:  0.02200988493859768
Epoch:  475  	Training Loss: 0.019984856247901917
Test Loss:  0.017664041370153427
Valid Loss:  0.022005274891853333
Epoch:  476  	Training Loss: 0.019980538636446
Test Loss:  0.017660312354564667
Valid Loss:  0.022000666707754135
Epoch:  477  	Training Loss: 0.01997622847557068
Test Loss:  0.017656588926911354
Valid Loss:  0.02199607715010643
Epoch:  478  	Training Loss: 0.019971927627921104
Test Loss:  0.01765287294983864
Valid Loss:  0.021991487592458725
Epoch:  479  	Training Loss: 0.019967632368206978
Test Loss:  0.01764916069805622
Valid Loss:  0.021986909210681915
Epoch:  480  	Training Loss: 0.019963348284363747
Test Loss:  0.017645452171564102
Valid Loss:  0.021982338279485703
Epoch:  481  	Training Loss: 0.019959069788455963
Test Loss:  0.01764175295829773
Valid Loss:  0.021977776661515236
Epoch:  482  	Training Loss: 0.019954802468419075
Test Loss:  0.017638061195611954
Valid Loss:  0.021973220631480217
Epoch:  483  	Training Loss: 0.019950546324253082
Test Loss:  0.017634376883506775
Valid Loss:  0.021968675777316093
Epoch:  484  	Training Loss: 0.019946295768022537
Test Loss:  0.017630696296691895
Valid Loss:  0.021964136511087418
Epoch:  485  	Training Loss: 0.019942056387662888
Test Loss:  0.017627019435167313
Valid Loss:  0.021959606558084488
Epoch:  486  	Training Loss: 0.019937828183174133
Test Loss:  0.017623353749513626
Valid Loss:  0.021955082193017006
Epoch:  487  	Training Loss: 0.019933601841330528
Test Loss:  0.01761968806385994
Valid Loss:  0.02195056900382042
Epoch:  488  	Training Loss: 0.019929388538002968
Test Loss:  0.01761602982878685
Valid Loss:  0.021946057677268982
Epoch:  489  	Training Loss: 0.019925180822610855
Test Loss:  0.017612379044294357
Valid Loss:  0.021941550076007843
Epoch:  490  	Training Loss: 0.01992098242044449
Test Loss:  0.017608731985092163
Valid Loss:  0.021937057375907898
Epoch:  491  	Training Loss: 0.019916793331503868
Test Loss:  0.017605088651180267
Valid Loss:  0.0219325702637434
Epoch:  492  	Training Loss: 0.019912609830498695
Test Loss:  0.017601456493139267
Valid Loss:  0.021928103640675545
Epoch:  493  	Training Loss: 0.019908444955945015
Test Loss:  0.017597835510969162
Valid Loss:  0.02192363701760769
Epoch:  494  	Training Loss: 0.019904285669326782
Test Loss:  0.017594218254089355
Valid Loss:  0.021919183433055878
Epoch:  495  	Training Loss: 0.019900135695934296
Test Loss:   99%|█████████▉| 495/500 [05:37<00:03,  1.66it/s] 99%|█████████▉| 497/500 [05:37<00:01,  2.26it/s]100%|█████████▉| 499/500 [05:37<00:00,  3.02it/s]100%|██████████| 500/500 [05:37<00:00,  1.48it/s]
0.017590604722499847
Valid Loss:  0.021914731711149216
Epoch:  496  	Training Loss: 0.019895995035767555
Test Loss:  0.017587002366781235
Valid Loss:  0.021910294890403748
Epoch:  497  	Training Loss: 0.019891861826181412
Test Loss:  0.017583400011062622
Valid Loss:  0.02190585806965828
Epoch:  498  	Training Loss: 0.019887734204530716
Test Loss:  0.017579801380634308
Valid Loss:  0.021901432424783707
Epoch:  499  	Training Loss: 0.019883617758750916
Test Loss:  0.017576206475496292
Valid Loss:  0.021897008642554283
Epoch:  500  	Training Loss: 0.019879506900906563
Test Loss:  0.017572622746229172
Valid Loss:  0.021892596036195755
seed is  8
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:31,  6.20s/it]  1%|          | 3/500 [00:06<13:42,  1.66s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:47,  2.92it/s]  2%|▏         | 11/500 [00:12<10:41,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:25<17:01,  2.13s/it]  5%|▍         | 23/500 [00:26<11:57,  1.50s/it]  5%|▌         | 25/500 [00:26<08:26,  1.07s/it]  5%|▌         | 27/500 [00:26<06:01,  1.31it/s]  6%|▌         | 29/500 [00:26<04:20,  1.81it/s]  6%|▌         | 31/500 [00:32<10:20,  1.32s/it]  7%|▋         | 33/500 [00:32<07:21,  1.06it/s]  7%|▋         | 35/500 [00:32<05:16,  1.47it/s]  7%|▋         | 37/500 [00:33<03:49,  2.02it/s]  8%|▊         | 39/500 [00:33<02:49,  2.72it/s]  8%|▊         | 41/500 [00:39<09:05,  1.19s/it]  9%|▊         | 43/500 [00:39<06:29,  1.17it/s]  9%|▉         | 45/500 [00:39<04:40,  1.62it/s]  9%|▉         | 47/500 [00:39<03:24,  2.21it/s] 10%|▉         | 49/500 [00:39<02:31,  2.97it/s] 10%|█         | 51/500 [00:46<08:44,  1.17s/it] 11%|█         | 53/500 [00:46<06:13,  1.20it/s] 11%|█         | 55/500 [00:46<04:29,  1.65it/s] 11%|█▏        | 57/500 [00:46<03:15,  2.26it/s] 12%|█▏        | 59/500 [00:46<02:25,  3.04it/s] 12%|█▏        | 61/500 [00:52<08:26,  1.15s/it] 13%|█▎        | 63/500 [00:52<06:02,  1.21it/s] 13%|█▎        | 65/500 [00:53<04:21,  1.67it/s] 13%|█▎        | 67/500 [00:53<03:10,  2.27it/s]Epoch:  1  	Training Loss: 0.02771417796611786
Test Loss:  0.032586224377155304
Valid Loss:  0.03715353459119797
Epoch:  2  	Training Loss: 0.03448515757918358
Test Loss:  0.014049550518393517
Valid Loss:  0.017414411529898643
Epoch:  3  	Training Loss: 0.01585971936583519
Test Loss:  0.012249559164047241
Valid Loss:  0.015014145523309708
Epoch:  4  	Training Loss: 0.013841163367033005
Test Loss:  0.01129900198429823
Valid Loss:  0.013734610751271248
Epoch:  5  	Training Loss: 0.012742243707180023
Test Loss:  0.010407503694295883
Valid Loss:  0.012613092549145222
Epoch:  6  	Training Loss: 0.011735967360436916
Test Loss:  0.009630034677684307
Valid Loss:  0.011704601347446442
Epoch:  7  	Training Loss: 0.01089503988623619
Test Loss:  0.009310237132012844
Valid Loss:  0.011229423806071281
Epoch:  8  	Training Loss: 0.010475236922502518
Test Loss:  0.009213695302605629
Valid Loss:  0.011054289527237415
Epoch:  9  	Training Loss: 0.010340142995119095
Test Loss:  0.009109489619731903
Valid Loss:  0.010959148406982422
Epoch:  10  	Training Loss: 0.010240302421152592
Test Loss:  0.009037259966135025
Valid Loss:  0.010832887142896652
Epoch:  11  	Training Loss: 0.010143478401005268
Test Loss:  0.00896562822163105
Valid Loss:  0.010737063363194466
Epoch:  12  	Training Loss: 0.010062610730528831
Test Loss:  0.0069009121507406235
Valid Loss:  0.0077975960448384285
Epoch:  13  	Training Loss: 0.0075438679195940495
Test Loss:  0.007664264179766178
Valid Loss:  0.009737035259604454
Epoch:  14  	Training Loss: 0.0089377760887146
Test Loss:  0.017815954983234406
Valid Loss:  0.016054362058639526
Epoch:  15  	Training Loss: 0.01681174337863922
Test Loss:  0.02918522246181965
Valid Loss:  0.032715804874897
Epoch:  16  	Training Loss: 0.0313042476773262
Test Loss:  0.013610021211206913
Valid Loss:  0.012716002762317657
Epoch:  17  	Training Loss: 0.0132171381264925
Test Loss:  0.003529150504618883
Valid Loss:  0.00397106958553195
Epoch:  18  	Training Loss: 0.004037800244987011
Test Loss:  0.0030456995591521263
Valid Loss:  0.0036667981185019016
Epoch:  19  	Training Loss: 0.0037093583960086107
Test Loss:  0.0028932862915098667
Valid Loss:  0.003495165379717946
Epoch:  20  	Training Loss: 0.0035666306503117085
Test Loss:  0.0027782791294157505
Valid Loss:  0.0033513198141008615
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.0034515182487666607
Test Loss:  0.002583257155492902
Valid Loss:  0.0030844449065625668
Epoch:  22  	Training Loss: 0.0032204000744968653
Test Loss:  0.0022516800090670586
Valid Loss:  0.0026771724224090576
Epoch:  23  	Training Loss: 0.0028687287122011185
Test Loss:  0.0020630734506994486
Valid Loss:  0.0024528768844902515
Epoch:  24  	Training Loss: 0.0026642302982509136
Test Loss:  0.001977528678253293
Valid Loss:  0.0023637418635189533
Epoch:  25  	Training Loss: 0.0025876625441014767
Test Loss:  0.0019339569844305515
Valid Loss:  0.00231723440811038
Epoch:  26  	Training Loss: 0.0025470624677836895
Test Loss:  0.0019038824830204248
Valid Loss:  0.0022891107946634293
Epoch:  27  	Training Loss: 0.0025215810164809227
Test Loss:  0.0018807182786986232
Valid Loss:  0.002266429830342531
Epoch:  28  	Training Loss: 0.0025011671241372824
Test Loss:  0.0018628216348588467
Valid Loss:  0.002245672047138214
Epoch:  29  	Training Loss: 0.00248286547139287
Test Loss:  0.0018462457228451967
Valid Loss:  0.0022267955355346203
Epoch:  30  	Training Loss: 0.002466076985001564
Test Loss:  0.0018309307051822543
Valid Loss:  0.0022095164749771357
Epoch:  31  	Training Loss: 0.00245073763653636
Test Loss:  0.0018175921868532896
Valid Loss:  0.0021930572111159563
Epoch:  32  	Training Loss: 0.0024362478870898485
Test Loss:  0.0018083180766552687
Valid Loss:  0.0021716493647545576
Epoch:  33  	Training Loss: 0.002416490111500025
Test Loss:  0.0017781604547053576
Valid Loss:  0.002129031578078866
Epoch:  34  	Training Loss: 0.002368668792769313
Test Loss:  0.0017407317645847797
Valid Loss:  0.002091072266921401
Epoch:  35  	Training Loss: 0.0023324768990278244
Test Loss:  0.0017036008648574352
Valid Loss:  0.0020380683708935976
Epoch:  36  	Training Loss: 0.0022864725906401873
Test Loss:  0.001667332835495472
Valid Loss:  0.0020016967318952084
Epoch:  37  	Training Loss: 0.002251198748126626
Test Loss:  0.0016484166262671351
Valid Loss:  0.0019873157143592834
Epoch:  38  	Training Loss: 0.0022324807941913605
Test Loss:  0.0016340725123882294
Valid Loss:  0.0019815233536064625
Epoch:  39  	Training Loss: 0.002224331721663475
Test Loss:  0.0016307893674820662
Valid Loss:  0.001976387808099389
Epoch:  40  	Training Loss: 0.0022189985029399395
Test Loss:  0.001625722274184227
Valid Loss:  0.0019737323746085167
Epoch:  41  	Training Loss: 0.0022147728595882654
Test Loss:  0.0016244815196841955
Valid Loss:  0.001971225254237652
Epoch:  42  	Training Loss: 0.0022112512961030006
Test Loss:  0.0015922823222354054
Valid Loss:  0.001950426958501339
Epoch:  43  	Training Loss: 0.00218698987737298
Test Loss:  0.0015853103250265121
Valid Loss:  0.0019273068755865097
Epoch:  44  	Training Loss: 0.0021658071782439947
Test Loss:  0.0015609643887728453
Valid Loss:  0.0019126113038510084
Epoch:  45  	Training Loss: 0.002148253610357642
Test Loss:  0.0015599458711221814
Valid Loss:  0.0018944405019283295
Epoch:  46  	Training Loss: 0.002132698893547058
Test Loss:  0.0015357165830209851
Valid Loss:  0.0018833930371329188
Epoch:  47  	Training Loss: 0.0021182752680033445
Test Loss:  0.0015374983195215464
Valid Loss:  0.0018672170117497444
Epoch:  48  	Training Loss: 0.0021050043869763613
Test Loss:  0.0015145884826779366
Valid Loss:  0.0018577370792627335
Epoch:  49  	Training Loss: 0.002092265523970127
Test Loss:  0.0015188001561909914
Valid Loss:  0.0018422572175040841
Epoch:  50  	Training Loss: 0.0020800582133233547
Test Loss:  0.0014963336288928986
Valid Loss:  0.0018344325944781303
Epoch:  51  	Training Loss: 0.0020682229660451412
Test Loss:  0.0015025988686829805
Valid Loss:  0.0018198741599917412
Epoch:  52  	Training Loss: 0.0020569665357470512
Test Loss:  0.001461209962144494
Valid Loss:  0.0017736067529767752
Epoch:  53  	Training Loss: 0.002010318683460355
Test Loss:  0.0014341083588078618
Valid Loss:  0.0017435501795262098
Epoch:  54  	Training Loss: 0.0019809878431260586
Test Loss:  0.0014155544340610504
Valid Loss:  0.0017236049752682447
Epoch:  55  	Training Loss: 0.0019624163396656513
Test Loss:  0.001403879257850349
Valid Loss:  0.0017082823906093836
Epoch:  56  	Training Loss: 0.0019487764220684767
Test Loss:  0.0013957389164716005
Valid Loss:  0.0016972576268017292
Epoch:  57  	Training Loss: 0.001938318251632154
Test Loss:  0.0013882197672501206
Valid Loss:  0.0016889283433556557
Epoch:  58  	Training Loss: 0.0019295114325359464
Test Loss:  0.0013824302004650235
Valid Loss:  0.0016814364353194833
Epoch:  59  	Training Loss: 0.0019221676047891378
Test Loss:  0.0013767427299171686
Valid Loss:  0.0016741296276450157
Epoch:  60  	Training Loss: 0.0019151358865201473
Test Loss:  0.0013713340740650892
Valid Loss:  0.0016670174663886428
Epoch:  61  	Training Loss: 0.001908211736008525
Test Loss:  0.001366183627396822
Valid Loss:  0.0016602204414084554
Epoch:  62  	Training Loss: 0.0019015080761164427
Test Loss:  0.0013587563298642635
Valid Loss:  0.0016404681373387575
Epoch:  63  	Training Loss: 0.0018841540440917015
Test Loss:  0.001340699614956975
Valid Loss:  0.0016292775981128216
Epoch:  64  	Training Loss: 0.0018716943450272083
Test Loss:  0.001331152394413948
Valid Loss:  0.001619979739189148
Epoch:  65  	Training Loss: 0.0018618992762640119
Test Loss:  0.0013226581504568458
Valid Loss:  0.0016124120447784662
Epoch:  66  	Training Loss: 0.0018533654510974884
Test Loss:  0.0013153438922017813
Valid Loss:  0.0016058783512562513
Epoch:  67  	Training Loss: 0.00184541754424572
Test Loss:  0.0013093765592202544
Valid Loss:  0.0015999663155525923
Epoch:  68  	Training Loss: 0.0018380056135356426
Test Loss:  0.0013039649929851294
Valid Loss:  0.0015944845508784056
Epoch:  69  	Training Loss: 0.0018310964806005359
Test Loss:  0.0012990236282348633
Valid Loss:  14%|█▍        | 69/500 [00:53<02:22,  3.03it/s] 14%|█▍        | 71/500 [00:59<08:20,  1.17s/it] 15%|█▍        | 73/500 [00:59<05:57,  1.19it/s] 15%|█▌        | 75/500 [00:59<04:17,  1.65it/s] 15%|█▌        | 77/500 [00:59<03:07,  2.25it/s] 16%|█▌        | 79/500 [01:00<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:06<08:18,  1.19s/it] 17%|█▋        | 83/500 [01:06<05:56,  1.17it/s] 17%|█▋        | 85/500 [01:06<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:06<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:07<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:13<07:58,  1.17s/it] 19%|█▊        | 93/500 [01:13<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:13<04:06,  1.65it/s] 19%|█▉        | 97/500 [01:13<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:13<02:13,  3.01it/s] 20%|██        | 101/500 [01:20<07:46,  1.17s/it] 21%|██        | 103/500 [01:20<05:33,  1.19it/s] 21%|██        | 105/500 [01:20<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:20<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:20<02:09,  3.01it/s] 22%|██▏       | 111/500 [01:26<07:32,  1.16s/it] 23%|██▎       | 113/500 [01:26<05:22,  1.20it/s] 23%|██▎       | 115/500 [01:27<03:52,  1.66it/s] 23%|██▎       | 117/500 [01:27<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:27<02:07,  2.99it/s] 24%|██▍       | 121/500 [01:33<07:25,  1.18s/it] 25%|██▍       | 123/500 [01:33<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:33<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:34<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:34<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:40<07:09,  1.16s/it] 27%|██▋       | 133/500 [01:40<05:06,  1.20it/s] 27%|██▋       | 135/500 [01:40<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:40<02:41,  2.25it/s] 0.001589376013725996
Epoch:  70  	Training Loss: 0.0018245317041873932
Test Loss:  0.0012942780740559101
Valid Loss:  0.0015845668967813253
Epoch:  71  	Training Loss: 0.0018182308413088322
Test Loss:  0.0012893739622086287
Valid Loss:  0.001579999690875411
Epoch:  72  	Training Loss: 0.001812135917134583
Test Loss:  0.0012687171110883355
Valid Loss:  0.0015694734174758196
Epoch:  73  	Training Loss: 0.0017974539659917355
Test Loss:  0.001260185381397605
Valid Loss:  0.001550967339426279
Epoch:  74  	Training Loss: 0.0017785532400012016
Test Loss:  0.001247925916686654
Valid Loss:  0.0015405939193442464
Epoch:  75  	Training Loss: 0.0017666146159172058
Test Loss:  0.0012419067788869143
Valid Loss:  0.001530640060082078
Epoch:  76  	Training Loss: 0.0017561917193233967
Test Loss:  0.0012329139281064272
Valid Loss:  0.001521883998066187
Epoch:  77  	Training Loss: 0.0017461255192756653
Test Loss:  0.0012264270335435867
Valid Loss:  0.0015126799698919058
Epoch:  78  	Training Loss: 0.001736324280500412
Test Loss:  0.0012181031052023172
Valid Loss:  0.0015042346203699708
Epoch:  79  	Training Loss: 0.0017266108188778162
Test Loss:  0.0012033369857817888
Valid Loss:  0.001492468873038888
Epoch:  80  	Training Loss: 0.0017130973283201456
Test Loss:  0.0011540115810930729
Valid Loss:  0.0014521293342113495
Epoch:  81  	Training Loss: 0.0016709063202142715
Test Loss:  0.001140393316745758
Valid Loss:  0.001429903437383473
Epoch:  82  	Training Loss: 0.0016468251124024391
Test Loss:  0.0011453304905444384
Valid Loss:  0.0014223427278921008
Epoch:  83  	Training Loss: 0.0016399233136326075
Test Loss:  0.0011413509491831064
Valid Loss:  0.0014195109251886606
Epoch:  84  	Training Loss: 0.001635420834645629
Test Loss:  0.001138723106123507
Valid Loss:  0.001416573068127036
Epoch:  85  	Training Loss: 0.0016312042716890574
Test Loss:  0.0011365169193595648
Valid Loss:  0.0014137174002826214
Epoch:  86  	Training Loss: 0.0016272467328235507
Test Loss:  0.0011341538047417998
Valid Loss:  0.0014109961921349168
Epoch:  87  	Training Loss: 0.0016235627699643373
Test Loss:  0.0011322381906211376
Valid Loss:  0.0014086068840697408
Epoch:  88  	Training Loss: 0.0016201502876356244
Test Loss:  0.0011302817147225142
Valid Loss:  0.0014063077978789806
Epoch:  89  	Training Loss: 0.0016168892616406083
Test Loss:  0.0011289259418845177
Valid Loss:  0.0014040486421436071
Epoch:  90  	Training Loss: 0.0016137893544510007
Test Loss:  0.0011275458382442594
Valid Loss:  0.0014018052024766803
Epoch:  91  	Training Loss: 0.0016107528936117887
Test Loss:  0.0011260660830885172
Valid Loss:  0.0013995782937854528
Epoch:  92  	Training Loss: 0.0016077866312116385
Test Loss:  0.0011177200358361006
Valid Loss:  0.0013789426302537322
Epoch:  93  	Training Loss: 0.0015881414292380214
Test Loss:  0.0010932013392448425
Valid Loss:  0.0013746221084147692
Epoch:  94  	Training Loss: 0.0015793615020811558
Test Loss:  0.0010942211374640465
Valid Loss:  0.001365267438814044
Epoch:  95  	Training Loss: 0.0015720643568783998
Test Loss:  0.001082598464563489
Valid Loss:  0.001360735041089356
Epoch:  96  	Training Loss: 0.001565373968333006
Test Loss:  0.0010820799507200718
Valid Loss:  0.001353615429252386
Epoch:  97  	Training Loss: 0.00155920023098588
Test Loss:  0.0010746155166998506
Valid Loss:  0.001349045429378748
Epoch:  98  	Training Loss: 0.0015531247481703758
Test Loss:  0.0010725018801167607
Valid Loss:  0.0013431390980258584
Epoch:  99  	Training Loss: 0.0015473138773813844
Test Loss:  0.001067386707291007
Valid Loss:  0.0013383077457547188
Epoch:  100  	Training Loss: 0.0015416964888572693
Test Loss:  0.0010644984431564808
Valid Loss:  0.0013329536886885762
Epoch:  101  	Training Loss: 0.0015361723490059376
Test Loss:  0.0010604736162349582
Valid Loss:  0.0013282028958201408
Epoch:  102  	Training Loss: 0.0015308762667700648
Test Loss:  0.0010698779951781034
Valid Loss:  0.0013131974264979362
Epoch:  103  	Training Loss: 0.0015134622808545828
Test Loss:  0.0010591928148642182
Valid Loss:  0.0013066581450402737
Epoch:  104  	Training Loss: 0.0015035662800073624
Test Loss:  0.0010541722876951098
Valid Loss:  0.0013014778960496187
Epoch:  105  	Training Loss: 0.0014962975401431322
Test Loss:  0.0010500585194677114
Valid Loss:  0.0012976957950741053
Epoch:  106  	Training Loss: 0.0014907433651387691
Test Loss:  0.001046394812874496
Valid Loss:  0.0012946893693879247
Epoch:  107  	Training Loss: 0.0014865752309560776
Test Loss:  0.0010439888574182987
Valid Loss:  0.0012921112356707454
Epoch:  108  	Training Loss: 0.001483165891841054
Test Loss:  0.00104167265817523
Valid Loss:  0.0012901772279292345
Epoch:  109  	Training Loss: 0.0014802261721342802
Test Loss:  0.0010401415638625622
Valid Loss:  0.0012885918840765953
Epoch:  110  	Training Loss: 0.0014775728341192007
Test Loss:  0.0010388935916125774
Valid Loss:  0.0012870216742157936
Epoch:  111  	Training Loss: 0.0014750964473932981
Test Loss:  0.0010377627331763506
Valid Loss:  0.0012854828964918852
Epoch:  112  	Training Loss: 0.0014728254172950983
Test Loss:  0.0010326053015887737
Valid Loss:  0.0012850838247686625
Epoch:  113  	Training Loss: 0.0014712121337652206
Test Loss:  0.0010311203077435493
Valid Loss:  0.0012842041905969381
Epoch:  114  	Training Loss: 0.0014698628801852465
Test Loss:  0.0010306641925126314
Valid Loss:  0.0012832003412768245
Epoch:  115  	Training Loss: 0.0014686855720356107
Test Loss:  0.0010304797906428576
Valid Loss:  0.0012822062708437443
Epoch:  116  	Training Loss: 0.0014675999991595745
Test Loss:  0.001030338928103447
Valid Loss:  0.0012812161585316062
Epoch:  117  	Training Loss: 0.0014665568014606833
Test Loss:  0.0010302537120878696
Valid Loss:  0.0012802827404811978
Epoch:  118  	Training Loss: 0.0014656218700110912
Test Loss:  0.0010301417205482721
Valid Loss:  0.0012793689966201782
Epoch:  119  	Training Loss: 0.0014647133648395538
Test Loss:  0.001030021463520825
Valid Loss:  0.001278465148061514
Epoch:  120  	Training Loss: 0.0014638891443610191
Test Loss:  0.0010300176218152046
Valid Loss:  0.0012776567600667477
Epoch:  121  	Training Loss: 0.0014631709782406688
Test Loss:  0.001030057086609304
Valid Loss:  0.0012769100721925497
Epoch:  122  	Training Loss: 0.0014625370968133211
Test Loss:  0.001023156219162047
Valid Loss:  0.0012515067355707288
Epoch:  123  	Training Loss: 0.0014403668465092778
Test Loss:  0.0009887429187074304
Valid Loss:  0.0012378990650177002
Epoch:  124  	Training Loss: 0.001424247631803155
Test Loss:  0.0009857728146016598
Valid Loss:  0.001224161242134869
Epoch:  125  	Training Loss: 0.0014108163304626942
Test Loss:  0.0009678697679191828
Valid Loss:  0.0012155267177149653
Epoch:  126  	Training Loss: 0.001399945467710495
Test Loss:  0.0009642670047469437
Valid Loss:  0.00120625551789999
Epoch:  127  	Training Loss: 0.001390119781717658
Test Loss:  0.0009524080087430775
Valid Loss:  0.0011992135550826788
Epoch:  128  	Training Loss: 0.0013811156386509538
Test Loss:  0.0009485012851655483
Valid Loss:  0.0011922896374017
Epoch:  129  	Training Loss: 0.001372691011056304
Test Loss:  0.0009405130986124277
Valid Loss:  0.0011860027443617582
Epoch:  130  	Training Loss: 0.0013644829159602523
Test Loss:  0.0009361960110254586
Valid Loss:  0.0011796895414590836
Epoch:  131  	Training Loss: 0.001356682158075273
Test Loss:  0.0009302293183282018
Valid Loss:  0.0011741530615836382
Epoch:  132  	Training Loss: 0.0013491959543898702
Test Loss:  0.0009210387943312526
Valid Loss:  0.0011684400960803032
Epoch:  133  	Training Loss: 0.0013413331471383572
Test Loss:  0.0009194513550028205
Valid Loss:  0.0011616902193054557
Epoch:  134  	Training Loss: 0.0013338752323761582
Test Loss:  0.0009123557829298079
Valid Loss:  0.0011559652630239725
Epoch:  135  	Training Loss: 0.001326636760495603
Test Loss:  0.000908512098249048
Valid Loss:  0.001149965450167656
Epoch:  136  	Training Loss: 0.0013195835053920746
Test Loss:  0.000903610372915864
Valid Loss:  0.0011443031253293157
Epoch:  137  	Training Loss: 0.0013126942794770002
Test Loss:  0.0008993042865768075
Valid Loss:  0.0011388782877475023
Epoch:  138  	Training Loss: 0.0013060136698186398
Test Loss:  0.0008947734022513032
 28%|██▊       | 139/500 [01:40<01:59,  3.02it/s] 28%|██▊       | 141/500 [01:47<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:47<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:47<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:47<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:47<01:56,  3.01it/s] 30%|███       | 151/500 [01:54<06:49,  1.17s/it] 31%|███       | 153/500 [01:54<04:52,  1.19it/s] 31%|███       | 155/500 [01:54<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:54<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:54<01:53,  3.00it/s] 32%|███▏      | 161/500 [02:00<06:31,  1.16s/it] 33%|███▎      | 163/500 [02:00<04:39,  1.20it/s] 33%|███▎      | 165/500 [02:00<03:21,  1.66it/s] 33%|███▎      | 167/500 [02:01<02:26,  2.27it/s] 34%|███▍      | 169/500 [02:01<01:48,  3.04it/s] 34%|███▍      | 171/500 [02:07<06:22,  1.16s/it] 35%|███▍      | 173/500 [02:07<04:33,  1.20it/s] 35%|███▌      | 175/500 [02:07<03:16,  1.66it/s] 35%|███▌      | 177/500 [02:07<02:23,  2.26it/s] 36%|███▌      | 179/500 [02:08<01:45,  3.03it/s] 36%|███▌      | 181/500 [02:14<06:07,  1.15s/it] 37%|███▋      | 183/500 [02:14<04:22,  1.21it/s] 37%|███▋      | 185/500 [02:14<03:08,  1.67it/s] 37%|███▋      | 187/500 [02:14<02:17,  2.28it/s] 38%|███▊      | 189/500 [02:14<01:42,  3.04it/s] 38%|███▊      | 191/500 [02:21<06:12,  1.20s/it] 39%|███▊      | 193/500 [02:21<04:25,  1.16it/s] 39%|███▉      | 195/500 [02:21<03:10,  1.60it/s] 39%|███▉      | 197/500 [02:21<02:19,  2.18it/s] 40%|███▉      | 199/500 [02:21<01:42,  2.93it/s] 40%|████      | 201/500 [02:27<05:50,  1.17s/it] 41%|████      | 203/500 [02:28<04:09,  1.19it/s] 41%|████      | 205/500 [02:28<02:59,  1.64it/s]Valid Loss:  0.0011335231829434633
Epoch:  139  	Training Loss: 0.0012994296848773956
Test Loss:  0.0008903138805180788
Valid Loss:  0.0011283683124929667
Epoch:  140  	Training Loss: 0.0012930240482091904
Test Loss:  0.0008860208326950669
Valid Loss:  0.0011232815450057387
Epoch:  141  	Training Loss: 0.001286761136725545
Test Loss:  0.0008815168985165656
Valid Loss:  0.0011183684691786766
Epoch:  142  	Training Loss: 0.001280676806345582
Test Loss:  0.000879185157828033
Valid Loss:  0.0011106978636234999
Epoch:  143  	Training Loss: 0.0012736150529235601
Test Loss:  0.0008746090461499989
Valid Loss:  0.001104793744161725
Epoch:  144  	Training Loss: 0.0012675852049142122
Test Loss:  0.0008707575034350157
Valid Loss:  0.0011000533122569323
Epoch:  145  	Training Loss: 0.0012623595539480448
Test Loss:  0.0008670830284245312
Valid Loss:  0.0010960893705487251
Epoch:  146  	Training Loss: 0.0012577855959534645
Test Loss:  0.0008641615277156234
Valid Loss:  0.0010927626863121986
Epoch:  147  	Training Loss: 0.001253714901395142
Test Loss:  0.0008614785620011389
Valid Loss:  0.0010897994507104158
Epoch:  148  	Training Loss: 0.0012499962467700243
Test Loss:  0.000858598155900836
Valid Loss:  0.0010873314458876848
Epoch:  149  	Training Loss: 0.0012465615291148424
Test Loss:  0.0008567905751988292
Valid Loss:  0.0010848139645531774
Epoch:  150  	Training Loss: 0.0012433575466275215
Test Loss:  0.0008548970217816532
Valid Loss:  0.0010824666824191809
Epoch:  151  	Training Loss: 0.0012404052540659904
Test Loss:  0.0008535475935786963
Valid Loss:  0.0010801973985508084
Epoch:  152  	Training Loss: 0.001237708842381835
Test Loss:  0.0008407772984355688
Valid Loss:  0.0010753469541668892
Epoch:  153  	Training Loss: 0.0012303475523367524
Test Loss:  0.0008362469961866736
Valid Loss:  0.001072871033102274
Epoch:  154  	Training Loss: 0.0012252787128090858
Test Loss:  0.000835996528621763
Valid Loss:  0.0010705868480727077
Epoch:  155  	Training Loss: 0.0012217916082590818
Test Loss:  0.0008351645665243268
Valid Loss:  0.0010685876477509737
Epoch:  156  	Training Loss: 0.0012188411783427
Test Loss:  0.000834532780572772
Valid Loss:  0.0010667325695976615
Epoch:  157  	Training Loss: 0.001216240576468408
Test Loss:  0.0008334625163115561
Valid Loss:  0.0010650360491126776
Epoch:  158  	Training Loss: 0.0012138430029153824
Test Loss:  0.0008322609355673194
Valid Loss:  0.001063428120687604
Epoch:  159  	Training Loss: 0.0012116676662117243
Test Loss:  0.0008323078509420156
Valid Loss:  0.0010615107603371143
Epoch:  160  	Training Loss: 0.001209690235555172
Test Loss:  0.0008313485304825008
Valid Loss:  0.0010597246000543237
Epoch:  161  	Training Loss: 0.0012078180443495512
Test Loss:  0.0008301637717522681
Valid Loss:  0.0010579812806099653
Epoch:  162  	Training Loss: 0.0012060373555868864
Test Loss:  0.0008219362935051322
Valid Loss:  0.00104551762342453
Epoch:  163  	Training Loss: 0.00119476905092597
Test Loss:  0.0008152846712619066
Valid Loss:  0.0010357493301853538
Epoch:  164  	Training Loss: 0.0011862007668241858
Test Loss:  0.0008096829988062382
Valid Loss:  0.0010280226124450564
Epoch:  165  	Training Loss: 0.0011794401798397303
Test Loss:  0.0008047269657254219
Valid Loss:  0.0010212752968072891
Epoch:  166  	Training Loss: 0.001173328491859138
Test Loss:  0.0008001878159120679
Valid Loss:  0.0010151838650926948
Epoch:  167  	Training Loss: 0.0011677565053105354
Test Loss:  0.0007958617061376572
Valid Loss:  0.0010096379555761814
Epoch:  168  	Training Loss: 0.0011626696214079857
Test Loss:  0.0007915511960163713
Valid Loss:  0.0010047191753983498
Epoch:  169  	Training Loss: 0.0011581792496144772
Test Loss:  0.0007875754963606596
Valid Loss:  0.0010002246126532555
Epoch:  170  	Training Loss: 0.001153932185843587
Test Loss:  0.0007841929909773171
Valid Loss:  0.000995883485302329
Epoch:  171  	Training Loss: 0.001149850431829691
Test Loss:  0.0007809967501088977
Valid Loss:  0.000991676701232791
Epoch:  172  	Training Loss: 0.0011458436492830515
Test Loss:  0.0007690384518355131
Valid Loss:  0.0009856857359409332
Epoch:  173  	Training Loss: 0.001138917519710958
Test Loss:  0.0007633366622030735
Valid Loss:  0.0009805259760469198
Epoch:  174  	Training Loss: 0.001133437966927886
Test Loss:  0.0007577736396342516
Valid Loss:  0.0009768498130142689
Epoch:  175  	Training Loss: 0.001128874602727592
Test Loss:  0.0007537739002145827
Valid Loss:  0.000973719812463969
Epoch:  176  	Training Loss: 0.0011250426759943366
Test Loss:  0.0007507989066652954
Valid Loss:  0.0009708356228657067
Epoch:  177  	Training Loss: 0.001121538458392024
Test Loss:  0.0007479038904421031
Valid Loss:  0.0009681826923042536
Epoch:  178  	Training Loss: 0.0011180846486240625
Test Loss:  0.000743896933272481
Valid Loss:  0.0009645704412832856
Epoch:  179  	Training Loss: 0.0011136038228869438
Test Loss:  0.0007408410310745239
Valid Loss:  0.0009613491129130125
Epoch:  180  	Training Loss: 0.001109475502744317
Test Loss:  0.000739540031645447
Valid Loss:  0.0009591011912561953
Epoch:  181  	Training Loss: 0.0011063645360991359
Test Loss:  0.0007371247047558427
Valid Loss:  0.0009573366260156035
Epoch:  182  	Training Loss: 0.0011034650960937142
Test Loss:  0.0007366079371422529
Valid Loss:  0.0009526771609671414
Epoch:  183  	Training Loss: 0.0010974481701850891
Test Loss:  0.0007347193895839155
Valid Loss:  0.0009488140931352973
Epoch:  184  	Training Loss: 0.0010924546513706446
Test Loss:  0.0007323857862502337
Valid Loss:  0.0009453552775084972
Epoch:  185  	Training Loss: 0.001087995944544673
Test Loss:  0.0007301741279661655
Valid Loss:  0.0009421518188901246
Epoch:  186  	Training Loss: 0.001083939103409648
Test Loss:  0.000728046172298491
Valid Loss:  0.0009390185005031526
Epoch:  187  	Training Loss: 0.001080157933756709
Test Loss:  0.0007258766563609242
Valid Loss:  0.0009359474061056972
Epoch:  188  	Training Loss: 0.0010765886399894953
Test Loss:  0.0007235230877995491
Valid Loss:  0.0009328903397545218
Epoch:  189  	Training Loss: 0.0010731080546975136
Test Loss:  0.0007213352946564555
Valid Loss:  0.0009299122029915452
Epoch:  190  	Training Loss: 0.0010696997633203864
Test Loss:  0.0007190443575382233
Valid Loss:  0.0009270233567804098
Epoch:  191  	Training Loss: 0.0010664146393537521
Test Loss:  0.0007167306030169129
Valid Loss:  0.0009241353254765272
Epoch:  192  	Training Loss: 0.0010631951736286283
Test Loss:  0.0007118362700566649
Valid Loss:  0.0009196890750899911
Epoch:  193  	Training Loss: 0.001058722846210003
Test Loss:  0.0007081489311531186
Valid Loss:  0.0009158916072919965
Epoch:  194  	Training Loss: 0.0010548087302595377
Test Loss:  0.0007050964049994946
Valid Loss:  0.000912455259822309
Epoch:  195  	Training Loss: 0.0010511920554563403
Test Loss:  0.0007023435900919139
Valid Loss:  0.0009092608233913779
Epoch:  196  	Training Loss: 0.0010478321928530931
Test Loss:  0.0006999796023592353
Valid Loss:  0.0009062823373824358
Epoch:  197  	Training Loss: 0.0010446598753333092
Test Loss:  0.0006977516459301114
Valid Loss:  0.0009035015827976167
Epoch:  198  	Training Loss: 0.0010416186414659023
Test Loss:  0.0006956104771234095
Valid Loss:  0.0009009115747176111
Epoch:  199  	Training Loss: 0.0010387697257101536
Test Loss:  0.0006935895071364939
Valid Loss:  0.0008983847219496965
Epoch:  200  	Training Loss: 0.001036015572026372
Test Loss:  0.0006917080609127879
Valid Loss:  0.0008960305713117123
Epoch:  201  	Training Loss: 0.0010334675898775458
Test Loss:  0.0006900407606735826
Valid Loss:  0.0008938536630012095
Epoch:  202  	Training Loss: 0.001031043822877109
Test Loss:  0.0006874521495774388
Valid Loss:  0.0008875446510501206
Epoch:  203  	Training Loss: 0.001025657169520855
Test Loss:  0.0006847766926512122
Valid Loss:  0.0008832530584186316
Epoch:  204  	Training Loss: 0.0010216990485787392
Test Loss:  0.0006818784750066698
Valid Loss:  0.0008795020403340459
Epoch:  205  	Training Loss: 0.0010181186953559518
Test Loss:  0.0006788803730159998
Valid Loss:  0.0008761478820815682
Epoch:  206  	Training Loss: 0.0010148455621674657
Test Loss:  0.000676170049700886
Valid Loss:  0.0008731393609195948
 41%|████▏     | 207/500 [02:28<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:28<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:34<05:39,  1.17s/it] 43%|████▎     | 213/500 [02:34<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:35<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:35<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:35<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:41<05:34,  1.20s/it] 45%|████▍     | 223/500 [02:41<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:42<02:51,  1.61it/s] 45%|████▌     | 227/500 [02:42<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:42<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:48<05:12,  1.16s/it] 47%|████▋     | 233/500 [02:48<03:42,  1.20it/s] 47%|████▋     | 235/500 [02:48<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:48<01:56,  2.26it/s] 48%|████▊     | 239/500 [02:48<01:26,  3.03it/s] 48%|████▊     | 241/500 [02:55<05:04,  1.17s/it] 49%|████▊     | 243/500 [02:55<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:55<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:55<01:53,  2.24it/s] 50%|████▉     | 249/500 [02:55<01:23,  2.99it/s] 50%|█████     | 251/500 [03:02<04:51,  1.17s/it] 51%|█████     | 253/500 [03:02<03:27,  1.19it/s] 51%|█████     | 255/500 [03:02<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:02<01:48,  2.25it/s] 52%|█████▏    | 259/500 [03:02<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:08<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:08<03:18,  1.19it/s] 53%|█████▎    | 265/500 [03:09<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:09<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:09<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:15<04:25,  1.16s/it] 55%|█████▍    | 273/500 [03:15<03:09,  1.20it/s]Epoch:  207  	Training Loss: 0.0010118228383362293
Test Loss:  0.000673542614094913
Valid Loss:  0.0008702481864020228
Epoch:  208  	Training Loss: 0.0010089298011735082
Test Loss:  0.000671011337544769
Valid Loss:  0.0008674949058331549
Epoch:  209  	Training Loss: 0.001006151083856821
Test Loss:  0.0006687918212264776
Valid Loss:  0.0008648440707474947
Epoch:  210  	Training Loss: 0.0010034632869064808
Test Loss:  0.0006666411645710468
Valid Loss:  0.0008622630266472697
Epoch:  211  	Training Loss: 0.0010008396347984672
Test Loss:  0.0006646087858825922
Valid Loss:  0.0008597606793045998
Epoch:  212  	Training Loss: 0.0009982739575207233
Test Loss:  0.000664110470097512
Valid Loss:  0.0008563799783587456
Epoch:  213  	Training Loss: 0.0009950022213160992
Test Loss:  0.0006618602783419192
Valid Loss:  0.0008535720990039408
Epoch:  214  	Training Loss: 0.0009920320007950068
Test Loss:  0.0006593076977878809
Valid Loss:  0.0008509758627042174
Epoch:  215  	Training Loss: 0.0009891596855595708
Test Loss:  0.0006568734534084797
Valid Loss:  0.0008485136786475778
Epoch:  216  	Training Loss: 0.0009863943560048938
Test Loss:  0.0006545315263792872
Valid Loss:  0.0008463415433652699
Epoch:  217  	Training Loss: 0.0009837039979174733
Test Loss:  0.0006524155032821
Valid Loss:  0.0008442421676591039
Epoch:  218  	Training Loss: 0.0009810562478378415
Test Loss:  0.0006503930781036615
Valid Loss:  0.0008421906968578696
Epoch:  219  	Training Loss: 0.0009784332942217588
Test Loss:  0.0006484305486083031
Valid Loss:  0.0008401955128647387
Epoch:  220  	Training Loss: 0.000975846080109477
Test Loss:  0.000646541768219322
Valid Loss:  0.0008382561500184238
Epoch:  221  	Training Loss: 0.0009732783073559403
Test Loss:  0.0006447149207815528
Valid Loss:  0.0008363425731658936
Epoch:  222  	Training Loss: 0.0009707463323138654
Test Loss:  0.0006395572563633323
Valid Loss:  0.0008333659498021007
Epoch:  223  	Training Loss: 0.0009668753482401371
Test Loss:  0.0006363123538903892
Valid Loss:  0.0008304216316901147
Epoch:  224  	Training Loss: 0.0009632036089897156
Test Loss:  0.0006335749058052897
Valid Loss:  0.000827514159027487
Epoch:  225  	Training Loss: 0.0009595878655090928
Test Loss:  0.0006310383905656636
Valid Loss:  0.000824586721137166
Epoch:  226  	Training Loss: 0.0009560234029777348
Test Loss:  0.0006286294665187597
Valid Loss:  0.0008216670248657465
Epoch:  227  	Training Loss: 0.000952508591581136
Test Loss:  0.0006262142560444772
Valid Loss:  0.000818741274997592
Epoch:  228  	Training Loss: 0.0009490217198617756
Test Loss:  0.0006237969500944018
Valid Loss:  0.0008158226264640689
Epoch:  229  	Training Loss: 0.0009455617982894182
Test Loss:  0.000621370505541563
Valid Loss:  0.0008129106718115509
Epoch:  230  	Training Loss: 0.0009421377326361835
Test Loss:  0.0006189618143253028
Valid Loss:  0.0008100178092718124
Epoch:  231  	Training Loss: 0.000938757904805243
Test Loss:  0.0006165271624922752
Valid Loss:  0.0008071352494880557
Epoch:  232  	Training Loss: 0.0009353997884318233
Test Loss:  0.0006095632561482489
Valid Loss:  0.0008006792049854994
Epoch:  233  	Training Loss: 0.0009281547390855849
Test Loss:  0.0006039657164365053
Valid Loss:  0.0007968286518007517
Epoch:  234  	Training Loss: 0.0009237127960659564
Test Loss:  0.0005993296508677304
Valid Loss:  0.0007941012736409903
Epoch:  235  	Training Loss: 0.0009207910625264049
Test Loss:  0.0005960541893728077
Valid Loss:  0.0007917567854747176
Epoch:  236  	Training Loss: 0.0009183724178001285
Test Loss:  0.0005933439242653549
Valid Loss:  0.0007896832539699972
Epoch:  237  	Training Loss: 0.0009163510985672474
Test Loss:  0.0005912315100431442
Valid Loss:  0.0007878122269175947
Epoch:  238  	Training Loss: 0.0009145502699539065
Test Loss:  0.0005894635105505586
Valid Loss:  0.0007861206540837884
Epoch:  239  	Training Loss: 0.0009129412937909365
Test Loss:  0.0005880280514247715
Valid Loss:  0.0007845743093639612
Epoch:  240  	Training Loss: 0.0009114333661273122
Test Loss:  0.0005867100553587079
Valid Loss:  0.0007832229021005332
Epoch:  241  	Training Loss: 0.0009100441820919514
Test Loss:  0.000585505913477391
Valid Loss:  0.0007819684105925262
Epoch:  242  	Training Loss: 0.0009087675134651363
Test Loss:  0.0005972512299194932
Valid Loss:  0.00078093126649037
Epoch:  243  	Training Loss: 0.0009048957726918161
Test Loss:  0.0005928826285526156
Valid Loss:  0.0007807639194652438
Epoch:  244  	Training Loss: 0.000902369269169867
Test Loss:  0.0005932222120463848
Valid Loss:  0.0007807303918525577
Epoch:  245  	Training Loss: 0.0009003281011246145
Test Loss:  0.0005925360019318759
Valid Loss:  0.0007806343492120504
Epoch:  246  	Training Loss: 0.0008985285530798137
Test Loss:  0.0005921893753111362
Valid Loss:  0.0007805207278579473
Epoch:  247  	Training Loss: 0.0008968936163000762
Test Loss:  0.0005917474045418203
Valid Loss:  0.000780352158471942
Epoch:  248  	Training Loss: 0.0008953823707997799
Test Loss:  0.0005913053173571825
Valid Loss:  0.0007801696774549782
Epoch:  249  	Training Loss: 0.0008939934195950627
Test Loss:  0.0005909292958676815
Valid Loss:  0.0007799789309501648
Epoch:  250  	Training Loss: 0.0008926927694119513
Test Loss:  0.0005905696889385581
Valid Loss:  0.0007797579164616764
Epoch:  251  	Training Loss: 0.0008914506761357188
Test Loss:  0.0005902335979044437
Valid Loss:  0.0007795105339027941
Epoch:  252  	Training Loss: 0.0008902566623874009
Test Loss:  0.0005810958100482821
Valid Loss:  0.0007780025480315089
Epoch:  253  	Training Loss: 0.0008873046608641744
Test Loss:  0.0005825849948450923
Valid Loss:  0.000775251304730773
Epoch:  254  	Training Loss: 0.0008848168072290719
Test Loss:  0.0005782339721918106
Valid Loss:  0.0007738636340945959
Epoch:  255  	Training Loss: 0.0008826790726743639
Test Loss:  0.000578157720156014
Valid Loss:  0.0007719229906797409
Epoch:  256  	Training Loss: 0.0008807245176285505
Test Loss:  0.0005759324412792921
Valid Loss:  0.0007706015603616834
Epoch:  257  	Training Loss: 0.000878889870364219
Test Loss:  0.000575393671169877
Valid Loss:  0.0007691055652685463
Epoch:  258  	Training Loss: 0.0008771914290264249
Test Loss:  0.0005739912739954889
Valid Loss:  0.00076794478809461
Epoch:  259  	Training Loss: 0.000875605212058872
Test Loss:  0.0005733444122597575
Valid Loss:  0.0007668199250474572
Epoch:  260  	Training Loss: 0.0008741595083847642
Test Loss:  0.000572335731703788
Valid Loss:  0.0007658187532797456
Epoch:  261  	Training Loss: 0.0008727947133593261
Test Loss:  0.0005716798477806151
Valid Loss:  0.0007648960454389453
Epoch:  262  	Training Loss: 0.0008715373114682734
Test Loss:  0.0005695444997400045
Valid Loss:  0.0007615444483235478
Epoch:  263  	Training Loss: 0.0008679949678480625
Test Loss:  0.0005664994241669774
Valid Loss:  0.0007587531581521034
Epoch:  264  	Training Loss: 0.0008648133371025324
Test Loss:  0.0005647279322147369
Valid Loss:  0.0007559849182143807
Epoch:  265  	Training Loss: 0.0008617726271040738
Test Loss:  0.0005623592296615243
Valid Loss:  0.0007533877505920827
Epoch:  266  	Training Loss: 0.0008588008931837976
Test Loss:  0.0005606141639873385
Valid Loss:  0.0007508473936468363
Epoch:  267  	Training Loss: 0.0008558831177651882
Test Loss:  0.000558659725356847
Valid Loss:  0.0007484628586098552
Epoch:  268  	Training Loss: 0.0008530381601303816
Test Loss:  0.0005569062777794898
Valid Loss:  0.0007461479399353266
Epoch:  269  	Training Loss: 0.0008502856944687665
Test Loss:  0.0005550527712330222
Valid Loss:  0.0007439465261995792
Epoch:  270  	Training Loss: 0.0008476478978991508
Test Loss:  0.0005534942611120641
Valid Loss:  0.0007417749729938805
Epoch:  271  	Training Loss: 0.0008451167959719896
Test Loss:  0.000551896111574024
Valid Loss:  0.0007396931760013103
Epoch:  272  	Training Loss: 0.0008426374988630414
Test Loss:  0.0005503357970155776
Valid Loss:  0.0007360279560089111
Epoch:  273  	Training Loss: 0.0008386066183447838
Test Loss:  0.0005480621475726366
Valid Loss:  0.0007325500482693315
Epoch:  274  	Training Loss: 0.0008347599068656564
Test Loss:  0.0005455318605527282
Valid Loss:  0.0007291536894626915
Epoch:  275  	Training Loss: 0.0008310351404361427
Test Loss:  55%|█████▌    | 275/500 [03:15<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:15<01:38,  2.25it/s] 56%|█████▌    | 279/500 [03:16<01:13,  3.03it/s] 56%|█████▌    | 281/500 [03:22<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:22<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:22<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:22<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:22<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:29<04:09,  1.19s/it] 59%|█████▊    | 293/500 [03:29<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:29<02:06,  1.62it/s] 59%|█████▉    | 297/500 [03:29<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:29<01:07,  2.97it/s] 60%|██████    | 301/500 [03:36<03:52,  1.17s/it] 61%|██████    | 303/500 [03:36<02:45,  1.19it/s] 61%|██████    | 305/500 [03:36<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:36<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:36<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:42<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:43<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:43<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:43<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:43<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:49<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:49<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:49<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:50<01:16,  2.25it/s] 66%|██████▌   | 329/500 [03:50<00:56,  3.02it/s] 66%|██████▌   | 331/500 [03:56<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:56<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:56<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:56<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:57<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:03<03:06,  1.17s/it] 0.0005429626326076686
Valid Loss:  0.0007258193218149245
Epoch:  276  	Training Loss: 0.0008274007122963667
Test Loss:  0.000540376640856266
Valid Loss:  0.000722520228009671
Epoch:  277  	Training Loss: 0.0008238479495048523
Test Loss:  0.0005378068308345973
Valid Loss:  0.000719257746823132
Epoch:  278  	Training Loss: 0.0008203896577470005
Test Loss:  0.0005352695588953793
Valid Loss:  0.0007160811219364405
Epoch:  279  	Training Loss: 0.0008170062210410833
Test Loss:  0.0005327294929884374
Valid Loss:  0.0007129665464162827
Epoch:  280  	Training Loss: 0.000813669990748167
Test Loss:  0.0005302566569298506
Valid Loss:  0.00070987205253914
Epoch:  281  	Training Loss: 0.0008103783475235105
Test Loss:  0.0005279546021483839
Valid Loss:  0.0007068457780405879
Epoch:  282  	Training Loss: 0.0008071465417742729
Test Loss:  0.0005243069608695805
Valid Loss:  0.0007042717770673335
Epoch:  283  	Training Loss: 0.0008045333670452237
Test Loss:  0.0005221090978011489
Valid Loss:  0.0007018478354439139
Epoch:  284  	Training Loss: 0.000802199705503881
Test Loss:  0.0005202180473133922
Valid Loss:  0.0006997501477599144
Epoch:  285  	Training Loss: 0.0008000085363164544
Test Loss:  0.00051844835979864
Valid Loss:  0.000697790295816958
Epoch:  286  	Training Loss: 0.0007979350630193949
Test Loss:  0.0005167905474081635
Valid Loss:  0.0006959339370951056
Epoch:  287  	Training Loss: 0.0007959448266774416
Test Loss:  0.0005153166130185127
Valid Loss:  0.000694137648679316
Epoch:  288  	Training Loss: 0.0007940271752886474
Test Loss:  0.0005139830755069852
Valid Loss:  0.0006924917688593268
Epoch:  289  	Training Loss: 0.000792263715993613
Test Loss:  0.0005126502946950495
Valid Loss:  0.0006909759249538183
Epoch:  290  	Training Loss: 0.0007905826787464321
Test Loss:  0.000511458667460829
Valid Loss:  0.0006895124679431319
Epoch:  291  	Training Loss: 0.0007889529806561768
Test Loss:  0.0005103311268612742
Valid Loss:  0.0006880814908072352
Epoch:  292  	Training Loss: 0.0007873785798437893
Test Loss:  0.0005131743964739144
Valid Loss:  0.0006860936991870403
Epoch:  293  	Training Loss: 0.0007846036460250616
Test Loss:  0.0005100247217342257
Valid Loss:  0.0006844695890322328
Epoch:  294  	Training Loss: 0.0007820870378054678
Test Loss:  0.0005093047511763871
Valid Loss:  0.0006828678888268769
Epoch:  295  	Training Loss: 0.0007796978461556137
Test Loss:  0.0005077427485957742
Valid Loss:  0.0006813561194576323
Epoch:  296  	Training Loss: 0.0007774290279485285
Test Loss:  0.0005065221339464188
Valid Loss:  0.0006798848044127226
Epoch:  297  	Training Loss: 0.0007752267410978675
Test Loss:  0.000505250645801425
Valid Loss:  0.0006784695433452725
Epoch:  298  	Training Loss: 0.0007730825454927981
Test Loss:  0.000504099705722183
Valid Loss:  0.0006771329790353775
Epoch:  299  	Training Loss: 0.0007710737409070134
Test Loss:  0.0005030578467994928
Valid Loss:  0.0006758586969226599
Epoch:  300  	Training Loss: 0.0007691555074416101
Test Loss:  0.0005020674434490502
Valid Loss:  0.0006747093284502625
Epoch:  301  	Training Loss: 0.0007672818028368056
Test Loss:  0.0005011289613321424
Valid Loss:  0.0006735720671713352
Epoch:  302  	Training Loss: 0.0007654657820239663
Test Loss:  0.0004993333714082837
Valid Loss:  0.0006730528548359871
Epoch:  303  	Training Loss: 0.0007644542492926121
Test Loss:  0.0004983508842997253
Valid Loss:  0.000672655354719609
Epoch:  304  	Training Loss: 0.0007635520305484533
Test Loss:  0.0004978013457730412
Valid Loss:  0.0006722849793732166
Epoch:  305  	Training Loss: 0.0007627187296748161
Test Loss:  0.000497385102789849
Valid Loss:  0.0006719153607264161
Epoch:  306  	Training Loss: 0.0007619219832122326
Test Loss:  0.0004970632726326585
Valid Loss:  0.0006715632043778896
Epoch:  307  	Training Loss: 0.0007611856563016772
Test Loss:  0.0004967711865901947
Valid Loss:  0.0006712102331221104
Epoch:  308  	Training Loss: 0.0007604800630360842
Test Loss:  0.0004965299740433693
Valid Loss:  0.0006708635482937098
Epoch:  309  	Training Loss: 0.0007598057272844017
Test Loss:  0.000496352615300566
Valid Loss:  0.000670561334118247
Epoch:  310  	Training Loss: 0.0007591650355607271
Test Loss:  0.0004961824743077159
Valid Loss:  0.0006702652317471802
Epoch:  311  	Training Loss: 0.0007585596176795661
Test Loss:  0.000496000808198005
Valid Loss:  0.0006699631921947002
Epoch:  312  	Training Loss: 0.0007579795201309025
Test Loss:  0.0004690297646448016
Valid Loss:  0.0006482649478130043
Epoch:  313  	Training Loss: 0.0007362031610682607
Test Loss:  0.00047395331785082817
Valid Loss:  0.0006388057954609394
Epoch:  314  	Training Loss: 0.0007265158928930759
Test Loss:  0.0004572006582748145
Valid Loss:  0.0006337665254250169
Epoch:  315  	Training Loss: 0.0007198204402811825
Test Loss:  0.00046508319792337716
Valid Loss:  0.0006281636306084692
Epoch:  316  	Training Loss: 0.0007139027584344149
Test Loss:  0.00045016984222456813
Valid Loss:  0.0006242235540412366
Epoch:  317  	Training Loss: 0.0007082727970555425
Test Loss:  0.00045787743874825537
Valid Loss:  0.0006193107110448182
Epoch:  318  	Training Loss: 0.0007029137341305614
Test Loss:  0.00044435937888920307
Valid Loss:  0.000615830474998802
Epoch:  319  	Training Loss: 0.000697870971634984
Test Loss:  0.0004514975589700043
Valid Loss:  0.0006113917334005237
Epoch:  320  	Training Loss: 0.0006929637165740132
Test Loss:  0.0004390321846585721
Valid Loss:  0.0006081036990508437
Epoch:  321  	Training Loss: 0.0006882495945319533
Test Loss:  0.00044551826431415975
Valid Loss:  0.0006040366715751588
Epoch:  322  	Training Loss: 0.0006837330292910337
Test Loss:  0.00044221148709766567
Valid Loss:  0.0005989475757814944
Epoch:  323  	Training Loss: 0.0006769498577341437
Test Loss:  0.000438565737567842
Valid Loss:  0.0005943657597526908
Epoch:  324  	Training Loss: 0.0006712040631100535
Test Loss:  0.00043531859409995377
Valid Loss:  0.0005899304524064064
Epoch:  325  	Training Loss: 0.0006659645587205887
Test Loss:  0.0004318926949054003
Valid Loss:  0.0005855848430655897
Epoch:  326  	Training Loss: 0.0006610342534258962
Test Loss:  0.0004286784096620977
Valid Loss:  0.000581344764214009
Epoch:  327  	Training Loss: 0.0006563358474522829
Test Loss:  0.0004254470986779779
Valid Loss:  0.0005771793075837195
Epoch:  328  	Training Loss: 0.0006517983274534345
Test Loss:  0.00042245996883139014
Valid Loss:  0.0005731675191782415
Epoch:  329  	Training Loss: 0.0006474024849012494
Test Loss:  0.00041955331107601523
Valid Loss:  0.0005692244740203023
Epoch:  330  	Training Loss: 0.0006431645597331226
Test Loss:  0.0004166846629232168
Valid Loss:  0.0005654094275087118
Epoch:  331  	Training Loss: 0.0006390988128259778
Test Loss:  0.000414019450545311
Valid Loss:  0.0005616947310045362
Epoch:  332  	Training Loss: 0.0006351969204843044
Test Loss:  0.0004006546805612743
Valid Loss:  0.0005550020141527057
Epoch:  333  	Training Loss: 0.0006286085117608309
Test Loss:  0.00039726635441184044
Valid Loss:  0.0005496782250702381
Epoch:  334  	Training Loss: 0.0006237938068807125
Test Loss:  0.00039341807132586837
Valid Loss:  0.0005451650940813124
Epoch:  335  	Training Loss: 0.0006195795722305775
Test Loss:  0.00039034488145262003
Valid Loss:  0.0005411187303252518
Epoch:  336  	Training Loss: 0.0006157666794024408
Test Loss:  0.00038749369559809566
Valid Loss:  0.0005374588654376566
Epoch:  337  	Training Loss: 0.0006122228223830462
Test Loss:  0.00038511870661750436
Valid Loss:  0.0005340424249880016
Epoch:  338  	Training Loss: 0.0006088858935981989
Test Loss:  0.000382706755772233
Valid Loss:  0.0005307346000336111
Epoch:  339  	Training Loss: 0.0006056376732885838
Test Loss:  0.00038032850716263056
Valid Loss:  0.0005275835283100605
Epoch:  340  	Training Loss: 0.0006024555768817663
Test Loss:  0.0003782161511480808
Valid Loss:  0.0005246028304100037
Epoch:  341  	Training Loss: 0.000599399209022522
Test Loss:  0.0003761814150493592
Valid Loss:  0.0005217432044446468
Epoch:  342  	Training Loss: 0.0005964700831100345
Test Loss:  0.00037690007593482733
Valid Loss:  0.000520719273481518
Epoch:  343  	Training Loss: 0.0005947661120444536
Test Loss:  0.0003763769054785371
Valid Loss:   69%|██████▊   | 343/500 [04:03<02:12,  1.19it/s] 69%|██████▉   | 345/500 [04:03<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:03<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:03<00:50,  3.02it/s] 70%|███████   | 351/500 [04:10<02:53,  1.17s/it] 71%|███████   | 353/500 [04:10<02:03,  1.19it/s] 71%|███████   | 355/500 [04:10<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:10<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:10<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:16<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:16<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:17<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:17<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:17<00:43,  3.03it/s] 74%|███████▍  | 371/500 [04:23<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:23<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:23<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:24<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:24<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:30<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:30<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:30<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:30<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:30<00:36,  3.00it/s] 78%|███████▊  | 391/500 [04:37<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:37<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:37<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:37<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:37<00:33,  2.99it/s] 80%|████████  | 401/500 [04:44<01:55,  1.17s/it] 81%|████████  | 403/500 [04:44<01:21,  1.19it/s] 81%|████████  | 405/500 [04:44<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:44<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:44<00:30,  3.03it/s]0.0005197760765440762
Epoch:  344  	Training Loss: 0.0005931936320848763
Test Loss:  0.0003757125814445317
Valid Loss:  0.0005188592476770282
Epoch:  345  	Training Loss: 0.000591678312048316
Test Loss:  0.0003750250907614827
Valid Loss:  0.0005179840372875333
Epoch:  346  	Training Loss: 0.0005902142147533596
Test Loss:  0.000374365015886724
Valid Loss:  0.0005171234370209277
Epoch:  347  	Training Loss: 0.0005888022715225816
Test Loss:  0.0003737207152880728
Valid Loss:  0.0005162678426131606
Epoch:  348  	Training Loss: 0.0005874338676221669
Test Loss:  0.0003730816242750734
Valid Loss:  0.0005154084064997733
Epoch:  349  	Training Loss: 0.0005860911915078759
Test Loss:  0.0003724361304193735
Valid Loss:  0.0005145439645275474
Epoch:  350  	Training Loss: 0.0005847722059115767
Test Loss:  0.00037178280763328075
Valid Loss:  0.0005136747495271266
Epoch:  351  	Training Loss: 0.0005834734183736145
Test Loss:  0.00037111894926056266
Valid Loss:  0.0005128101329319179
Epoch:  352  	Training Loss: 0.0005822072853334248
Test Loss:  0.0003709562588483095
Valid Loss:  0.0005108376499265432
Epoch:  353  	Training Loss: 0.0005799101199954748
Test Loss:  0.00036975962575525045
Valid Loss:  0.0005088809411972761
Epoch:  354  	Training Loss: 0.0005776892649009824
Test Loss:  0.0003683935501612723
Valid Loss:  0.0005069734179414809
Epoch:  355  	Training Loss: 0.0005755310412496328
Test Loss:  0.0003670104197226465
Valid Loss:  0.0005051049520261586
Epoch:  356  	Training Loss: 0.0005734304431825876
Test Loss:  0.00036569125950336456
Valid Loss:  0.0005032811895944178
Epoch:  357  	Training Loss: 0.0005713819991797209
Test Loss:  0.0003644471289590001
Valid Loss:  0.0005014801281504333
Epoch:  358  	Training Loss: 0.000569366617128253
Test Loss:  0.00036325317341834307
Valid Loss:  0.00049971928820014
Epoch:  359  	Training Loss: 0.0005673780688084662
Test Loss:  0.0003620765346568078
Valid Loss:  0.0004980057710781693
Epoch:  360  	Training Loss: 0.0005654181586578488
Test Loss:  0.00036088854540139437
Valid Loss:  0.0004963399260304868
Epoch:  361  	Training Loss: 0.000563486129976809
Test Loss:  0.00035967392614111304
Valid Loss:  0.0004947297275066376
Epoch:  362  	Training Loss: 0.000561608059797436
Test Loss:  0.00035749137168750167
Valid Loss:  0.0004925554385408759
Epoch:  363  	Training Loss: 0.0005593639798462391
Test Loss:  0.0003556754090823233
Valid Loss:  0.0004904646193608642
Epoch:  364  	Training Loss: 0.0005571675137616694
Test Loss:  0.00035400071647018194
Valid Loss:  0.0004884597146883607
Epoch:  365  	Training Loss: 0.0005550068453885615
Test Loss:  0.00035240506986156106
Valid Loss:  0.00048650422831997275
Epoch:  366  	Training Loss: 0.0005528769688680768
Test Loss:  0.0003508871595840901
Valid Loss:  0.00048458424862474203
Epoch:  367  	Training Loss: 0.000550766650121659
Test Loss:  0.00034940880141220987
Valid Loss:  0.0004826981748919934
Epoch:  368  	Training Loss: 0.0005486794398166239
Test Loss:  0.0003479414153844118
Valid Loss:  0.0004808481899090111
Epoch:  369  	Training Loss: 0.0005466219154186547
Test Loss:  0.0003465082263574004
Valid Loss:  0.00047903344966471195
Epoch:  370  	Training Loss: 0.0005445924471132457
Test Loss:  0.0003451244265306741
Valid Loss:  0.00047724353498779237
Epoch:  371  	Training Loss: 0.0005425806157290936
Test Loss:  0.000343771418556571
Valid Loss:  0.0004754678229801357
Epoch:  372  	Training Loss: 0.0005405812407843769
Test Loss:  0.0003422062727622688
Valid Loss:  0.00047379598254337907
Epoch:  373  	Training Loss: 0.0005386350676417351
Test Loss:  0.00034136080648750067
Valid Loss:  0.0004724610480479896
Epoch:  374  	Training Loss: 0.000536887557245791
Test Loss:  0.00034058812889270484
Valid Loss:  0.0004713382513727993
Epoch:  375  	Training Loss: 0.0005352606531232595
Test Loss:  0.00033984912442974746
Valid Loss:  0.0004702893493231386
Epoch:  376  	Training Loss: 0.0005337116308510303
Test Loss:  0.000339019694365561
Valid Loss:  0.00046925837523303926
Epoch:  377  	Training Loss: 0.0005321892094798386
Test Loss:  0.0003382400027476251
Valid Loss:  0.00046826049219816923
Epoch:  378  	Training Loss: 0.0005307067767716944
Test Loss:  0.00033749439171515405
Valid Loss:  0.00046733577619306743
Epoch:  379  	Training Loss: 0.0005292942514643073
Test Loss:  0.0003369096084497869
Valid Loss:  0.00046649150317534804
Epoch:  380  	Training Loss: 0.0005279353354126215
Test Loss:  0.0003362962161190808
Valid Loss:  0.00046566867968067527
Epoch:  381  	Training Loss: 0.0005266049993224442
Test Loss:  0.0003356266242917627
Valid Loss:  0.00046483500045724213
Epoch:  382  	Training Loss: 0.0005252915434539318
Test Loss:  0.0003339658142067492
Valid Loss:  0.0004625130968634039
Epoch:  383  	Training Loss: 0.0005227960646152496
Test Loss:  0.0003323401615489274
Valid Loss:  0.00046025565825402737
Epoch:  384  	Training Loss: 0.0005203522741794586
Test Loss:  0.0003307485021650791
Valid Loss:  0.00045802321983501315
Epoch:  385  	Training Loss: 0.0005179567961022258
Test Loss:  0.00032920989906415343
Valid Loss:  0.0004558138025458902
Epoch:  386  	Training Loss: 0.0005156047409400344
Test Loss:  0.00032769274548627436
Valid Loss:  0.00045362941455096006
Epoch:  387  	Training Loss: 0.0005132931983098388
Test Loss:  0.00032619578996673226
Valid Loss:  0.0004514711326919496
Epoch:  388  	Training Loss: 0.0005110205383971334
Test Loss:  0.00032474100589752197
Valid Loss:  0.0004493384330999106
Epoch:  389  	Training Loss: 0.0005087848985567689
Test Loss:  0.0003233257739339024
Valid Loss:  0.00044723303290084004
Epoch:  390  	Training Loss: 0.0005065895384177566
Test Loss:  0.000321934960084036
Valid Loss:  0.0004451592976693064
Epoch:  391  	Training Loss: 0.0005044381832703948
Test Loss:  0.0003205678076483309
Valid Loss:  0.000443127762991935
Epoch:  392  	Training Loss: 0.0005023353733122349
Test Loss:  0.00031919003231450915
Valid Loss:  0.0004419361357577145
Epoch:  393  	Training Loss: 0.0005010641179978848
Test Loss:  0.00031823755125515163
Valid Loss:  0.00044081290252506733
Epoch:  394  	Training Loss: 0.0004998203366994858
Test Loss:  0.0003173674049321562
Valid Loss:  0.0004397343145683408
Epoch:  395  	Training Loss: 0.0004985955310985446
Test Loss:  0.00031654315534979105
Valid Loss:  0.00043869251385331154
Epoch:  396  	Training Loss: 0.0004973873146809638
Test Loss:  0.00031575473258271813
Valid Loss:  0.00043768450268544257
Epoch:  397  	Training Loss: 0.0004961971426382661
Test Loss:  0.00031499244505539536
Valid Loss:  0.00043670195736922324
Epoch:  398  	Training Loss: 0.0004950173897668719
Test Loss:  0.00031425495399162173
Valid Loss:  0.00043574103619903326
Epoch:  399  	Training Loss: 0.0004938471829518676
Test Loss:  0.0003135402803309262
Valid Loss:  0.0004347984795458615
Epoch:  400  	Training Loss: 0.0004926858237013221
Test Loss:  0.00031283957650884986
Valid Loss:  0.0004338716098573059
Epoch:  401  	Training Loss: 0.0004915330791845918
Test Loss:  0.0003121505433227867
Valid Loss:  0.0004329598159529269
Epoch:  402  	Training Loss: 0.0004903883673250675
Test Loss:  0.0003105106297880411
Valid Loss:  0.0004313550889492035
Epoch:  403  	Training Loss: 0.0004883806686848402
Test Loss:  0.00030949374195188284
Valid Loss:  0.00042978330748155713
Epoch:  404  	Training Loss: 0.0004863985232077539
Test Loss:  0.00030832155607640743
Valid Loss:  0.0004282203735783696
Epoch:  405  	Training Loss: 0.00048443739069625735
Test Loss:  0.0003072017279919237
Valid Loss:  0.0004266696341801435
Epoch:  406  	Training Loss: 0.0004824940988328308
Test Loss:  0.00030607759254053235
Valid Loss:  0.00042512925574555993
Epoch:  407  	Training Loss: 0.0004805668140761554
Test Loss:  0.00030496035469695926
Valid Loss:  0.00042360014049336314
Epoch:  408  	Training Loss: 0.00047865312080830336
Test Loss:  0.0003038458526134491
Valid Loss:  0.0004220806295052171
Epoch:  409  	Training Loss: 0.0004767530190292746
Test Loss:  0.0003027347265742719
Valid Loss:  0.0004205724108032882
Epoch:  410  	Training Loss: 0.0004748682549688965
Test Loss:  0.0003016397822648287
Valid Loss:  0.00041907376726157963
Epoch:  411  	Training Loss: 0.0004729993233922869
Test Loss:  0.0003005437320098281
 82%|████████▏ | 411/500 [04:50<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:51<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:51<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:51<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:51<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:57<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:57<01:04,  1.20it/s] 85%|████████▌ | 425/500 [04:57<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:58<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:58<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:04<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:04<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:04<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:04<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:05<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:11<01:08,  1.16s/it] 89%|████████▊ | 443/500 [05:11<00:47,  1.20it/s] 89%|████████▉ | 445/500 [05:11<00:33,  1.66it/s] 89%|████████▉ | 447/500 [05:11<00:23,  2.27it/s] 90%|████████▉ | 449/500 [05:11<00:16,  3.05it/s] 90%|█████████ | 451/500 [05:18<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:18<00:39,  1.20it/s] 91%|█████████ | 455/500 [05:18<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:18<00:19,  2.26it/s] 92%|█████████▏| 459/500 [05:18<00:13,  3.04it/s] 92%|█████████▏| 461/500 [05:24<00:45,  1.16s/it] 93%|█████████▎| 463/500 [05:24<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:25<00:21,  1.66it/s] 93%|█████████▎| 467/500 [05:25<00:14,  2.27it/s] 94%|█████████▍| 469/500 [05:25<00:10,  3.05it/s] 94%|█████████▍| 471/500 [05:31<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:31<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:31<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:31<00:10,  2.26it/s]Valid Loss:  0.0004175828071311116
Epoch:  412  	Training Loss: 0.00047114212065935135
Test Loss:  0.00029871362494304776
Valid Loss:  0.000414422363974154
Epoch:  413  	Training Loss: 0.00046669511357322335
Test Loss:  0.0002962729486171156
Valid Loss:  0.00041136887739412487
Epoch:  414  	Training Loss: 0.00046267107245512307
Test Loss:  0.00029444298706948757
Valid Loss:  0.0004084458341822028
Epoch:  415  	Training Loss: 0.0004589552991092205
Test Loss:  0.0002921594132203609
Valid Loss:  0.00040556391468271613
Epoch:  416  	Training Loss: 0.0004554460756480694
Test Loss:  0.000290409050649032
Valid Loss:  0.0004027548711746931
Epoch:  417  	Training Loss: 0.00045206292998045683
Test Loss:  0.0002881733817048371
Valid Loss:  0.0003999917535111308
Epoch:  418  	Training Loss: 0.00044873810838907957
Test Loss:  0.0002864570706151426
Valid Loss:  0.0003972702252212912
Epoch:  419  	Training Loss: 0.0004454513837117702
Test Loss:  0.00028426945209503174
Valid Loss:  0.00039455131627619267
Epoch:  420  	Training Loss: 0.00044217408867552876
Test Loss:  0.0002825105329975486
Valid Loss:  0.0003918526927009225
Epoch:  421  	Training Loss: 0.00043891521636396646
Test Loss:  0.0002803304814733565
Valid Loss:  0.0003891734522767365
Epoch:  422  	Training Loss: 0.0004356741555966437
Test Loss:  0.00027935003163293004
Valid Loss:  0.00038791931001469493
Epoch:  423  	Training Loss: 0.0004340918967500329
Test Loss:  0.00027852458879351616
Valid Loss:  0.0003866950573865324
Epoch:  424  	Training Loss: 0.00043257162906229496
Test Loss:  0.0002777365152724087
Valid Loss:  0.0003854788956232369
Epoch:  425  	Training Loss: 0.00043110051774419844
Test Loss:  0.00027695964672602713
Valid Loss:  0.00038425251841545105
Epoch:  426  	Training Loss: 0.00042965749162249267
Test Loss:  0.0002761675277724862
Valid Loss:  0.00038301918539218605
Epoch:  427  	Training Loss: 0.00042824301635846496
Test Loss:  0.00027535937260836363
Valid Loss:  0.0003817774704657495
Epoch:  428  	Training Loss: 0.00042684751679189503
Test Loss:  0.0002745313977357
Valid Loss:  0.000380531360860914
Epoch:  429  	Training Loss: 0.0004254744271747768
Test Loss:  0.00027369853341951966
Valid Loss:  0.0003792855713982135
Epoch:  430  	Training Loss: 0.0004241219721734524
Test Loss:  0.0002728577528614551
Valid Loss:  0.000378038443159312
Epoch:  431  	Training Loss: 0.0004227856989018619
Test Loss:  0.00027201208285987377
Valid Loss:  0.00037679015076719224
Epoch:  432  	Training Loss: 0.0004214627551846206
Test Loss:  0.0002727550163399428
Valid Loss:  0.0003758057428058237
Epoch:  433  	Training Loss: 0.0004198107635602355
Test Loss:  0.0002717605384532362
Valid Loss:  0.00037456100108101964
Epoch:  434  	Training Loss: 0.0004182317352388054
Test Loss:  0.0002707835810724646
Valid Loss:  0.0003733174817170948
Epoch:  435  	Training Loss: 0.00041666370816528797
Test Loss:  0.0002698087482713163
Valid Loss:  0.0003720744280144572
Epoch:  436  	Training Loss: 0.00041510647861287
Test Loss:  0.00026883487589657307
Valid Loss:  0.00037083434290252626
Epoch:  437  	Training Loss: 0.0004135619383305311
Test Loss:  0.0002678676100913435
Valid Loss:  0.0003696056082844734
Epoch:  438  	Training Loss: 0.00041203087312169373
Test Loss:  0.0002669052337296307
Valid Loss:  0.00036838813684880733
Epoch:  439  	Training Loss: 0.0004105152911506593
Test Loss:  0.00026593709480948746
Valid Loss:  0.0003671934246085584
Epoch:  440  	Training Loss: 0.00040902526234276593
Test Loss:  0.00026496476493775845
Valid Loss:  0.0003660109650809318
Epoch:  441  	Training Loss: 0.00040756314410828054
Test Loss:  0.0002640028251335025
Valid Loss:  0.00036484445445239544
Epoch:  442  	Training Loss: 0.0004061328945681453
Test Loss:  0.0002632289833854884
Valid Loss:  0.0003635644097812474
Epoch:  443  	Training Loss: 0.0004051855066791177
Test Loss:  0.0002625329070724547
Valid Loss:  0.0003624571836553514
Epoch:  444  	Training Loss: 0.00040430782246403396
Test Loss:  0.00026190222706645727
Valid Loss:  0.00036147533683106303
Epoch:  445  	Training Loss: 0.000403474026825279
Test Loss:  0.0002613179967738688
Valid Loss:  0.00036058539990335703
Epoch:  446  	Training Loss: 0.00040266773430630565
Test Loss:  0.00026076813810504973
Valid Loss:  0.00035976324579678476
Epoch:  447  	Training Loss: 0.0004018792824354023
Test Loss:  0.00026024325052276254
Valid Loss:  0.00035899391514249146
Epoch:  448  	Training Loss: 0.00040110520785674453
Test Loss:  0.0002597353304736316
Valid Loss:  0.00035826623206958175
Epoch:  449  	Training Loss: 0.0004003394569735974
Test Loss:  0.0002592429518699646
Valid Loss:  0.000357575889211148
Epoch:  450  	Training Loss: 0.00039958168053999543
Test Loss:  0.0002587594208307564
Valid Loss:  0.00035690830554813147
Epoch:  451  	Training Loss: 0.00039882867713458836
Test Loss:  0.0002582869492471218
Valid Loss:  0.00035626065800897777
Epoch:  452  	Training Loss: 0.00039808155270293355
Test Loss:  0.0002556807012297213
Valid Loss:  0.00035555570502765477
Epoch:  453  	Training Loss: 0.0003967930970247835
Test Loss:  0.0002564224414527416
Valid Loss:  0.0003554850409273058
Epoch:  454  	Training Loss: 0.00039568403735756874
Test Loss:  0.00025580215151421726
Valid Loss:  0.0003551359986886382
Epoch:  455  	Training Loss: 0.00039467267924919724
Test Loss:  0.0002557031693868339
Valid Loss:  0.00035483745159581304
Epoch:  456  	Training Loss: 0.0003937234287150204
Test Loss:  0.00025534926680848
Valid Loss:  0.00035444891545921564
Epoch:  457  	Training Loss: 0.00039281134377233684
Test Loss:  0.0002550533681642264
Valid Loss:  0.0003540261823218316
Epoch:  458  	Training Loss: 0.00039193418342620134
Test Loss:  0.000254714279435575
Valid Loss:  0.00035356360604055226
Epoch:  459  	Training Loss: 0.0003910743980668485
Test Loss:  0.00025436998112127185
Valid Loss:  0.0003530725953169167
Epoch:  460  	Training Loss: 0.0003902284079231322
Test Loss:  0.0002539674169383943
Valid Loss:  0.000352546718204394
Epoch:  461  	Training Loss: 0.00038941079401411116
Test Loss:  0.00025359028950333595
Valid Loss:  0.0003520158934406936
Epoch:  462  	Training Loss: 0.0003886065096594393
Test Loss:  0.0002528526238165796
Valid Loss:  0.0003510693786665797
Epoch:  463  	Training Loss: 0.00038782984483987093
Test Loss:  0.00025216321228072047
Valid Loss:  0.00035014719469472766
Epoch:  464  	Training Loss: 0.00038706016493961215
Test Loss:  0.00025150919100269675
Valid Loss:  0.0003492362448014319
Epoch:  465  	Training Loss: 0.0003862932207994163
Test Loss:  0.0002508761244826019
Valid Loss:  0.0003483367618173361
Epoch:  466  	Training Loss: 0.0003855261311400682
Test Loss:  0.0002502452698536217
Valid Loss:  0.00034744705772027373
Epoch:  467  	Training Loss: 0.00038475965266115963
Test Loss:  0.0002496151137165725
Valid Loss:  0.00034657353535294533
Epoch:  468  	Training Loss: 0.0003840009740088135
Test Loss:  0.00024899106938391924
Valid Loss:  0.00034571578726172447
Epoch:  469  	Training Loss: 0.0003832498914562166
Test Loss:  0.0002483775024302304
Valid Loss:  0.0003448770730756223
Epoch:  470  	Training Loss: 0.00038250855868682265
Test Loss:  0.0002477722300682217
Valid Loss:  0.00034405553014948964
Epoch:  471  	Training Loss: 0.00038177770329639316
Test Loss:  0.00024718529311940074
Valid Loss:  0.00034324941225349903
Epoch:  472  	Training Loss: 0.0003810604684986174
Test Loss:  0.00024704300449229777
Valid Loss:  0.0003428913769312203
Epoch:  473  	Training Loss: 0.0003805667511187494
Test Loss:  0.000246758630964905
Valid Loss:  0.00034253770718351007
Epoch:  474  	Training Loss: 0.0003800857812166214
Test Loss:  0.0002465399738866836
Valid Loss:  0.0003422275185585022
Epoch:  475  	Training Loss: 0.0003796103992499411
Test Loss:  0.0002461016410961747
Valid Loss:  0.00034189707366749644
Epoch:  476  	Training Loss: 0.00037907069781795144
Test Loss:  0.0002452262560836971
Valid Loss:  0.0003410876961424947
Epoch:  477  	Training Loss: 0.00037817301927134395
Test Loss:  0.00024389663303736597
Valid Loss:  0.0003397198743186891
Epoch:  478  	Training Loss: 0.0003766531590372324
Test Loss:  0.00024182477500289679
Valid Loss:  0.00033735588658601046
 96%|█████████▌| 479/500 [05:32<00:06,  3.04it/s] 96%|█████████▌| 481/500 [05:38<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:38<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:38<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:38<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:38<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:45<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:45<00:05,  1.20it/s] 99%|█████████▉| 495/500 [05:45<00:03,  1.66it/s] 99%|█████████▉| 497/500 [05:45<00:01,  2.26it/s]100%|█████████▉| 499/500 [05:45<00:00,  3.03it/s]100%|██████████| 500/500 [05:45<00:00,  1.45it/s]
Epoch:  479  	Training Loss: 0.00037417554995045066
Test Loss:  0.00024016814131755382
Valid Loss:  0.0003348229220137
Epoch:  480  	Training Loss: 0.000371666596038267
Test Loss:  0.00023965034051798284
Valid Loss:  0.0003331403713673353
Epoch:  481  	Training Loss: 0.0003699539811350405
Test Loss:  0.00023951225739438087
Valid Loss:  0.00033238454489037395
Epoch:  482  	Training Loss: 0.00036889477632939816
Test Loss:  0.00024070817744359374
Valid Loss:  0.00033263477962464094
Epoch:  483  	Training Loss: 0.0003685099072754383
Test Loss:  0.0002408672880847007
Valid Loss:  0.0003325726429466158
Epoch:  484  	Training Loss: 0.0003681964008137584
Test Loss:  0.0002407838765066117
Valid Loss:  0.00033244339283555746
Epoch:  485  	Training Loss: 0.00036789229488931596
Test Loss:  0.00024064708850346506
Valid Loss:  0.00033230416011065245
Epoch:  486  	Training Loss: 0.0003675992484204471
Test Loss:  0.00024047898477874696
Valid Loss:  0.0003321878029964864
Epoch:  487  	Training Loss: 0.0003673231112770736
Test Loss:  0.0002403292164672166
Valid Loss:  0.0003320775576867163
Epoch:  488  	Training Loss: 0.0003670525620691478
Test Loss:  0.0002401739766355604
Valid Loss:  0.00033198221353814006
Epoch:  489  	Training Loss: 0.00036679458571597934
Test Loss:  0.00024004344595596194
Valid Loss:  0.0003318880626466125
Epoch:  490  	Training Loss: 0.000366538530215621
Test Loss:  0.0002399094810243696
Valid Loss:  0.00033179239835590124
Epoch:  491  	Training Loss: 0.00036628503585234284
Test Loss:  0.0002397707139607519
Valid Loss:  0.0003316959773655981
Epoch:  492  	Training Loss: 0.00036603573244065046
Test Loss:  0.00023683681502006948
Valid Loss:  0.00033030344638973475
Epoch:  493  	Training Loss: 0.0003650136641226709
Test Loss:  0.00023689810768701136
Valid Loss:  0.0003293887129984796
Epoch:  494  	Training Loss: 0.0003640717768575996
Test Loss:  0.00023587762552779168
Valid Loss:  0.0003284041304141283
Epoch:  495  	Training Loss: 0.0003631612053140998
Test Loss:  0.0002353539312025532
Valid Loss:  0.0003275296767242253
Epoch:  496  	Training Loss: 0.0003622688236646354
Test Loss:  0.0002346866822335869
Valid Loss:  0.00032667163759469986
Epoch:  497  	Training Loss: 0.00036138849100098014
Test Loss:  0.00023411060101352632
Valid Loss:  0.00032585623557679355
Epoch:  498  	Training Loss: 0.0003605197125580162
Test Loss:  0.00023353195865638554
Valid Loss:  0.0003250595764257014
Epoch:  499  	Training Loss: 0.00035965960705652833
Test Loss:  0.00023298620362766087
Valid Loss:  0.0003242840466555208
Epoch:  500  	Training Loss: 0.00035880497307516634
Test Loss:  0.00023244088515639305
Valid Loss:  0.00032352638663724065
seed is  9
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:36, 13.74it/s]  1%|          | 4/500 [00:00<00:33, 14.65it/s]  1%|          | 6/500 [00:00<00:32, 15.33it/s]  2%|▏         | 8/500 [00:00<00:31, 15.74it/s]  2%|▏         | 10/500 [00:00<00:31, 15.79it/s]  2%|▏         | 12/500 [00:00<00:30, 15.99it/s]  3%|▎         | 14/500 [00:00<00:30, 16.17it/s]  3%|▎         | 16/500 [00:01<00:30, 15.95it/s]  4%|▎         | 18/500 [00:01<00:30, 15.99it/s]  4%|▍         | 20/500 [00:01<00:30, 15.92it/s]  4%|▍         | 22/500 [00:01<00:29, 16.03it/s]  5%|▍         | 24/500 [00:01<00:29, 16.05it/s]  5%|▌         | 26/500 [00:01<00:29, 16.04it/s]  6%|▌         | 28/500 [00:01<00:29, 16.15it/s]  6%|▌         | 30/500 [00:01<00:28, 16.24it/s]  6%|▋         | 32/500 [00:02<00:29, 15.86it/s]  7%|▋         | 34/500 [00:02<00:28, 16.09it/s]  7%|▋         | 36/500 [00:02<00:28, 16.17it/s]  8%|▊         | 38/500 [00:02<00:29, 15.56it/s]  8%|▊         | 40/500 [00:02<00:29, 15.42it/s]  8%|▊         | 42/500 [00:02<00:29, 15.39it/s]  9%|▉         | 44/500 [00:02<00:28, 15.73it/s]  9%|▉         | 46/500 [00:02<00:28, 15.99it/s] 10%|▉         | 48/500 [00:03<00:28, 16.12it/s] 10%|█         | 50/500 [00:03<00:27, 16.19it/s] 10%|█         | 52/500 [00:03<00:27, 16.26it/s] 11%|█         | 54/500 [00:03<00:27, 16.23it/s] 11%|█         | 56/500 [00:03<00:27, 16.15it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.13it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.07it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.09it/s] 13%|█▎        | 64/500 [00:04<00:27, 16.13it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.23it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.27it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.32it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.35it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.00it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.89it/s] 16%|█▌        | 78/500 [00:04<00:27, 15.62it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.65it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.86it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.05it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.14it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.11it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.20it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.32it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.36it/s] 19%|█▉        | 96/500 [00:06<00:25, 16.10it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.98it/s] 20%|██        | 100/500 [00:06<00:25, 15.82it/s] 20%|██        | 102/500 [00:06<00:25, 15.77it/s] 21%|██        | 104/500 [00:06<00:25, 15.75it/s] 21%|██        | 106/500 [00:06<00:24, 15.90it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.98it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.11it/s] 22%|██▏       | 112/500 [00:07<00:23, 16.19it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.99it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.97it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.10it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.16it/s] 24%|██▍       | 122/500 [00:07<00:23, 15.99it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.11it/s]Epoch:  1  	Training Loss: 0.08815442025661469
Test Loss:  2158.34521484375
Valid Loss:  2151.54345703125
Epoch:  2  	Training Loss: 2153.61572265625
Test Loss:  954965308735488.0
Valid Loss:  946861980516352.0
Epoch:  3  	Training Loss: 948879205859328.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.07it/s] 26%|██▌       | 128/500 [00:08<00:23, 15.83it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.63it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.83it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.37it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.58it/s] 28%|██▊       | 138/500 [00:08<00:23, 15.72it/s] 28%|██▊       | 140/500 [00:08<00:22, 15.88it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.01it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.82it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.65it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.65it/s] 30%|███       | 150/500 [00:09<00:22, 15.84it/s] 30%|███       | 152/500 [00:09<00:21, 16.03it/s] 31%|███       | 154/500 [00:09<00:21, 16.13it/s] 31%|███       | 156/500 [00:09<00:21, 16.06it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.15it/s] 32%|███▏      | 160/500 [00:10<00:21, 16.12it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.19it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.18it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.11it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.14it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.18it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.31it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.25it/s] 35%|███▌      | 176/500 [00:11<00:20, 16.14it/s] 36%|███▌      | 178/500 [00:11<00:20, 16.09it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.05it/s] 36%|███▋      | 182/500 [00:11<00:19, 15.98it/s] 37%|███▋      | 184/500 [00:11<00:19, 15.81it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.08it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.09it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.17it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.94it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.99it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.99it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.76it/s] 40%|████      | 200/500 [00:12<00:18, 15.88it/s] 40%|████      | 202/500 [00:12<00:18, 15.83it/s] 41%|████      | 204/500 [00:12<00:18, 15.83it/s] 41%|████      | 206/500 [00:12<00:18, 15.96it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.86it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.90it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.07it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.03it/s] 43%|████▎     | 216/500 [00:13<00:17, 15.95it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.06it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.12it/s] 44%|████▍     | 222/500 [00:13<00:17, 15.97it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.84it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.72it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.78it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.59it/s] 46%|████▋     | 232/500 [00:14<00:17, 15.59it/s] 47%|████▋     | 234/500 [00:14<00:16, 15.78it/s] 47%|████▋     | 236/500 [00:14<00:16, 15.73it/s] 48%|████▊     | 238/500 [00:14<00:16, 15.80it/s] 48%|████▊     | 240/500 [00:15<00:16, 15.77it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.61it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.74it/s] 49%|████▉     | 246/500 [00:15<00:15, 15.92it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.02it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.00it/s] 50%|█████     | 252/500 [00:15<00:15, 15.99it/s] 51%|█████     | 254/500 [00:15<00:15, 15.83it/s] 51%|█████     | 256/500 [00:16<00:15, 15.87it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.97it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.96it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.07it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.18it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.23it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.31it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.33it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.01it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.38it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.52it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.80it/s] 56%|█████▌    | 280/500 [00:17<00:13, 15.95it/s] 56%|█████▋    | 282/500 [00:17<00:13, 15.77it/s] 57%|█████▋    | 284/500 [00:17<00:13, 15.79it/s] 57%|█████▋    | 286/500 [00:17<00:13, 15.97it/s] 58%|█████▊    | 288/500 [00:18<00:13, 16.08it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.18it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.10it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.23it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.32it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.32it/s] 60%|██████    | 300/500 [00:18<00:12, 16.20it/s] 60%|██████    | 302/500 [00:18<00:12, 16.22it/s] 61%|██████    | 304/500 [00:19<00:12, 16.28it/s] 61%|██████    | 306/500 [00:19<00:12, 16.11it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.20it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.28it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.18it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.11it/s] 63%|██████▎   | 316/500 [00:19<00:12, 15.33it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.55it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.70it/s] 64%|██████▍   | 322/500 [00:20<00:11, 15.89it/s] 65%|██████▍   | 324/500 [00:20<00:11, 15.94it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.07it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.15it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.25it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.33it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.37it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.03it/s] 68%|██████▊   | 338/500 [00:21<00:10, 16.07it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.90it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.05it/s] 69%|██████▉   | 344/500 [00:21<00:09, 15.95it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.08it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.20it/s] 70%|███████   | 350/500 [00:21<00:09, 16.34it/s] 70%|███████   | 352/500 [00:22<00:09, 15.94it/s] 71%|███████   | 354/500 [00:22<00:09, 15.57it/s] 71%|███████   | 356/500 [00:22<00:09, 15.66it/s] 72%|███████▏  | 358/500 [00:22<00:09, 14.75it/s] 72%|███████▏  | 360/500 [00:22<00:09, 15.13it/s] 72%|███████▏  | 362/500 [00:22<00:08, 15.50it/s] 73%|███████▎  | 364/500 [00:22<00:08, 15.43it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.65it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.83it/s] 74%|███████▍  | 370/500 [00:23<00:08, 16.02it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.79it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:08, 15.67it/s] 75%|███████▌  | 376/500 [00:23<00:07, 15.83it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.01it/s] 76%|███████▌  | 380/500 [00:23<00:07, 15.96it/s] 76%|███████▋  | 382/500 [00:23<00:07, 15.94it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.91it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.86it/s] 78%|███████▊  | 388/500 [00:24<00:07, 15.98it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.04it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.00it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.09it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.17it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.33it/s] 80%|████████  | 400/500 [00:25<00:06, 15.16it/s] 80%|████████  | 402/500 [00:25<00:06, 15.28it/s] 81%|████████  | 404/500 [00:25<00:06, 15.40it/s] 81%|████████  | 406/500 [00:25<00:06, 15.37it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.68it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.89it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.03it/s] 83%|████████▎ | 414/500 [00:25<00:05, 15.79it/s] 83%|████████▎ | 416/500 [00:26<00:05, 14.99it/s] 84%|████████▎ | 418/500 [00:26<00:05, 15.13it/s] 84%|████████▍ | 420/500 [00:26<00:05, 15.17it/s] 84%|████████▍ | 422/500 [00:26<00:05, 15.46it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.68it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.72it/s] 86%|████████▌ | 428/500 [00:26<00:04, 15.68it/s] 86%|████████▌ | 430/500 [00:27<00:04, 15.86it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.03it/s] 87%|████████▋ | 434/500 [00:27<00:04, 16.15it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.13it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.19it/s] 88%|████████▊ | 440/500 [00:27<00:03, 15.91it/s] 88%|████████▊ | 442/500 [00:27<00:03, 15.89it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.05it/s] 89%|████████▉ | 446/500 [00:28<00:03, 15.96it/s] 90%|████████▉ | 448/500 [00:28<00:03, 15.92it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.06it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.05it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.11it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.21it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.25it/s] 92%|█████████▏| 460/500 [00:28<00:02, 15.77it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.93it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.02it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.14it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.17it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.12it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.17it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.04it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.07it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.19it/s] 96%|█████████▌| 480/500 [00:30<00:01, 16.17it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.14it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.97it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.91it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.90it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.10it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.05it/s] 99%|█████████▉| 494/500 [00:31<00:00, 15.97it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.09it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.22it/s]100%|██████████| 500/500 [00:31<00:00, 16.11it/s]100%|██████████| 500/500 [00:31<00:00, 15.94it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  9
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:32,  6.20s/it]  1%|          | 3/500 [00:06<13:43,  1.66s/it]  1%|          | 5/500 [00:06<06:54,  1.19it/s]  1%|▏         | 7/500 [00:06<04:11,  1.96it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:39,  1.31s/it]  3%|▎         | 13/500 [00:13<07:16,  1.12it/s]  3%|▎         | 15/500 [00:13<05:04,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:32,  1.20s/it]  5%|▍         | 23/500 [00:19<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:14,  1.18s/it]  7%|▋         | 33/500 [00:26<06:36,  1.18it/s]  7%|▋         | 35/500 [00:32<11:48,  1.52s/it]  7%|▋         | 37/500 [00:33<08:23,  1.09s/it]  8%|▊         | 39/500 [00:33<06:00,  1.28it/s]  8%|▊         | 41/500 [00:45<18:18,  2.39s/it]  9%|▊         | 43/500 [00:45<12:55,  1.70s/it]  9%|▉         | 45/500 [00:51<16:02,  2.12s/it]  9%|▉         | 47/500 [00:51<11:20,  1.50s/it] 10%|▉         | 49/500 [00:52<08:03,  1.07s/it] 10%|█         | 51/500 [01:04<19:31,  2.61s/it] 11%|█         | 53/500 [01:04<13:48,  1.85s/it] 11%|█         | 55/500 [01:10<16:37,  2.24s/it] 11%|█▏        | 57/500 [01:11<11:44,  1.59s/it] 12%|█▏        | 59/500 [01:11<08:19,  1.13s/it] 12%|█▏        | 61/500 [01:23<19:18,  2.64s/it] 13%|█▎        | 63/500 [01:23<13:36,  1.87s/it] 13%|█▎        | 65/500 [01:29<16:17,  2.25s/it]Epoch:  1  	Training Loss: 0.08815440535545349
Test Loss:  43.904937744140625
Valid Loss:  43.42928695678711
Epoch:  2  	Training Loss: 43.662269592285156
Test Loss:  12.300677299499512
Valid Loss:  12.006486892700195
Epoch:  3  	Training Loss: 12.070653915405273
Test Loss:  0.3401554822921753
Valid Loss:  0.3222082555294037
Epoch:  4  	Training Loss: 0.3254936635494232
Test Loss:  0.09261392056941986
Valid Loss:  0.09575027227401733
Epoch:  5  	Training Loss: 0.09684235602617264
Test Loss:  0.09225766360759735
Valid Loss:  0.09521844983100891
Epoch:  6  	Training Loss: 0.09639599919319153
Test Loss:  0.09210547059774399
Valid Loss:  0.0949166789650917
Epoch:  7  	Training Loss: 0.0961800366640091
Test Loss:  0.09200524538755417
Valid Loss:  0.09472128748893738
Epoch:  8  	Training Loss: 0.09604386985301971
Test Loss:  0.09195204079151154
Valid Loss:  0.0946316123008728
Epoch:  9  	Training Loss: 0.09596459567546844
Test Loss:  0.09192416071891785
Valid Loss:  0.094581738114357
Epoch:  10  	Training Loss: 0.09591616690158844
Test Loss:  0.09190532565116882
Valid Loss:  0.09454832971096039
Epoch:  11  	Training Loss: 0.09588456153869629
Test Loss:  0.09189118444919586
Valid Loss:  0.09452302753925323
Epoch:  12  	Training Loss: 0.0958605706691742
Test Loss:  0.09188254177570343
Valid Loss:  0.09450621902942657
Epoch:  13  	Training Loss: 0.09584546089172363
Test Loss:  0.09187775105237961
Valid Loss:  0.09449512511491776
Epoch:  14  	Training Loss: 0.09583485126495361
Test Loss:  0.09187532961368561
Valid Loss:  0.09448996931314468
Epoch:  15  	Training Loss: 0.09582839906215668
Test Loss:  0.09187392890453339
Valid Loss:  0.09448686242103577
Epoch:  16  	Training Loss: 0.0958249419927597
Test Loss:  0.09187290072441101
Valid Loss:  0.09448445588350296
Epoch:  17  	Training Loss: 0.09582233428955078
Test Loss:  0.09187223017215729
Valid Loss:  0.09448331594467163
Epoch:  18  	Training Loss: 0.09582065045833588
Test Loss:  0.09187179058790207
Valid Loss:  0.0944826751947403
Epoch:  19  	Training Loss: 0.0958196222782135
Test Loss:  0.09187150001525879
Valid Loss:  0.09448249638080597
Epoch:  20  	Training Loss: 0.0958189070224762
Test Loss:  0.09187129139900208
Valid Loss:  0.09448255598545074
Epoch:  21  	Training Loss: 0.09581834077835083
Test Loss:  0.09187112748622894
Valid Loss:  0.09448263049125671
Epoch:  22  	Training Loss: 0.09581787139177322
Test Loss:  0.09187103807926178
Valid Loss:  0.09448273479938507
Epoch:  23  	Training Loss: 0.09581762552261353
Test Loss:  0.091870978474617
Valid Loss:  0.09448283165693283
Epoch:  24  	Training Loss: 0.09581741690635681
Test Loss:  0.09187094122171402
Valid Loss:  0.09448294341564178
Epoch:  25  	Training Loss: 0.09581723809242249
Test Loss:  0.09187090396881104
Valid Loss:  0.09448304772377014
Epoch:  26  	Training Loss: 0.09581711143255234
Test Loss:  0.09187088906764984
Valid Loss:  0.09448317438364029
Epoch:  27  	Training Loss: 0.09581699967384338
Test Loss:  0.09187088906764984
Valid Loss:  0.09448328614234924
Epoch:  28  	Training Loss: 0.09581691771745682
Test Loss:  0.09187088906764984
Valid Loss:  0.09448334574699402
Epoch:  29  	Training Loss: 0.09581689536571503
Test Loss:  0.09187088906764984
Valid Loss:  0.09448341280221939
Epoch:  30  	Training Loss: 0.09581685811281204
Test Loss:  0.09187088161706924
Valid Loss:  0.09448346495628357
Epoch:  31  	Training Loss: 0.09581682085990906
Test Loss:  0.09187087416648865
Valid Loss:  0.09448351711034775
Epoch:  32  	Training Loss: 0.09581680595874786
Test Loss:  0.09187088161706924
Valid Loss:  0.09448353201150894
Epoch:  33  	Training Loss: 0.09581680595874786
Test Loss:  0.09187088906764984
Valid Loss:  0.09448353946208954
Epoch:  34  	Training Loss: 0.09581680595874786
Test Loss:  0.09187088906764984
Valid Loss:  0.09448355436325073
Epoch:  35  	Training Loss: 0.09581680595874786
Test Loss:  0.09187088906764984
Valid Loss:  0.09448356926441193
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.09581680595874786
Test Loss:  0.09187088906764984
Valid Loss:  0.09448357671499252
Epoch:  37  	Training Loss: 0.09581680595874786
Test Loss:  0.09187088906764984
Valid Loss:  0.09448356926441193
Epoch:  38  	Training Loss: 0.09581680595874786
Test Loss:  0.09187088906764984
Valid Loss:  0.09448357671499252
Epoch:  39  	Training Loss: 0.09581680595874786
Test Loss:  0.09187088906764984
Valid Loss:  0.09448358416557312
Epoch:  40  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.09581680595874786
Test Loss:  0.09187088906764984
Valid Loss:  0.09448358416557312
Epoch:  42  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448358416557312
Epoch:  43  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  44  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  45  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  47  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  48  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  49  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  50  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  52  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  53  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  54  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  55  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  57  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  58  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  59  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  60  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088161706924
Valid Loss:  0.09448359906673431
Epoch:  62  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  63  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  64  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  65  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
 13%|█▎        | 67/500 [01:30<11:30,  1.59s/it] 14%|█▍        | 69/500 [01:30<08:09,  1.14s/it] 14%|█▍        | 71/500 [01:42<18:58,  2.65s/it] 15%|█▍        | 73/500 [01:42<13:22,  1.88s/it] 15%|█▌        | 75/500 [01:49<15:57,  2.25s/it] 15%|█▌        | 77/500 [01:49<11:16,  1.60s/it] 16%|█▌        | 79/500 [01:49<07:59,  1.14s/it] 16%|█▌        | 81/500 [02:01<18:38,  2.67s/it] 17%|█▋        | 83/500 [02:01<13:08,  1.89s/it] 17%|█▋        | 85/500 [02:08<15:46,  2.28s/it] 17%|█▋        | 87/500 [02:08<11:08,  1.62s/it] 18%|█▊        | 89/500 [02:08<07:53,  1.15s/it] 18%|█▊        | 91/500 [02:20<18:03,  2.65s/it] 19%|█▊        | 93/500 [02:21<12:43,  1.88s/it] 19%|█▉        | 95/500 [02:27<15:08,  2.24s/it] 19%|█▉        | 97/500 [02:27<10:42,  1.59s/it] 20%|█▉        | 99/500 [02:27<07:35,  1.14s/it] 20%|██        | 101/500 [02:39<17:30,  2.63s/it] 21%|██        | 103/500 [02:39<12:19,  1.86s/it] 21%|██        | 105/500 [02:46<14:43,  2.24s/it] 21%|██▏       | 107/500 [02:46<10:24,  1.59s/it] 22%|██▏       | 109/500 [02:46<07:23,  1.13s/it] 22%|██▏       | 109/500 [02:57<07:23,  1.13s/it] 22%|██▏       | 111/500 [02:58<17:10,  2.65s/it] 23%|██▎       | 113/500 [02:58<12:05,  1.88s/it] 23%|██▎       | 115/500 [03:05<14:28,  2.26s/it] 23%|██▎       | 117/500 [03:05<10:12,  1.60s/it] 24%|██▍       | 119/500 [03:05<07:14,  1.14s/it] 24%|██▍       | 119/500 [03:17<07:14,  1.14s/it] 24%|██▍       | 121/500 [03:17<16:36,  2.63s/it] 25%|██▍       | 123/500 [03:17<11:41,  1.86s/it]Epoch:  66  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  67  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  68  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  69  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  70  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  72  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  73  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  74  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  75  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  77  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  78  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  79  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  80  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  82  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  83  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  84  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  85  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  87  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  88  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  89  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  90  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  92  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  93  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  94  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  95  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  97  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  98  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  99  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  100  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  102  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  103  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  104  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  105  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  107  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  108  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  109  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  110  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  112  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  113  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  114  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  115  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  117  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  118  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  119  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  120  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  122  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  123  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  124  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  125  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
 25%|██▌       | 125/500 [03:23<13:55,  2.23s/it] 25%|██▌       | 127/500 [03:24<09:49,  1.58s/it] 26%|██▌       | 129/500 [03:24<06:57,  1.13s/it] 26%|██▌       | 131/500 [03:36<16:08,  2.63s/it] 27%|██▋       | 133/500 [03:36<11:22,  1.86s/it] 27%|██▋       | 135/500 [03:42<13:32,  2.23s/it] 27%|██▋       | 137/500 [03:42<09:33,  1.58s/it] 28%|██▊       | 139/500 [03:43<06:46,  1.13s/it] 28%|██▊       | 141/500 [03:55<15:41,  2.62s/it] 29%|██▊       | 143/500 [03:55<11:02,  1.86s/it] 29%|██▉       | 145/500 [04:01<13:11,  2.23s/it] 29%|██▉       | 147/500 [04:01<09:19,  1.59s/it] 30%|██▉       | 149/500 [04:01<06:36,  1.13s/it] 30%|███       | 151/500 [04:14<15:15,  2.62s/it] 31%|███       | 153/500 [04:14<10:44,  1.86s/it] 31%|███       | 155/500 [04:20<12:51,  2.24s/it] 31%|███▏      | 157/500 [04:20<09:04,  1.59s/it] 32%|███▏      | 159/500 [04:20<06:25,  1.13s/it] 32%|███▏      | 161/500 [04:33<14:58,  2.65s/it] 33%|███▎      | 163/500 [04:33<10:32,  1.88s/it] 33%|███▎      | 165/500 [04:39<12:32,  2.25s/it] 33%|███▎      | 167/500 [04:39<08:50,  1.59s/it] 34%|███▍      | 169/500 [04:39<06:17,  1.14s/it] 34%|███▍      | 171/500 [04:52<14:30,  2.65s/it] 35%|███▍      | 173/500 [04:52<10:12,  1.87s/it] 35%|███▌      | 175/500 [04:58<12:09,  2.24s/it] 35%|███▌      | 177/500 [04:58<08:34,  1.59s/it] 36%|███▌      | 179/500 [04:58<06:04,  1.13s/it] 36%|███▌      | 181/500 [05:11<14:07,  2.66s/it] 37%|███▋      | 183/500 [05:11<09:56,  1.88s/it]**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  127  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  128  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  129  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  130  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  132  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  133  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  134  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  135  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  137  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  138  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  139  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  140  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  142  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  143  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  144  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  145  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  147  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  148  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  149  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  150  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  152  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  153  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  154  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  155  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  157  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  158  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  159  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  160  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  162  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  163  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  164  	Training Loss: 0.09581679105758667
Test Loss:  0.09187089651823044
Valid Loss:  0.09448359906673431
Epoch:  165  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  167  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  168  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  169  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  170  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  172  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  173  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  174  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  175  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  177  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  178  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  179  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  180  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  182  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  183  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  184  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
 37%|███▋      | 185/500 [05:17<11:49,  2.25s/it] 37%|███▋      | 187/500 [05:17<08:20,  1.60s/it] 38%|███▊      | 189/500 [05:17<05:54,  1.14s/it] 38%|███▊      | 191/500 [05:30<13:35,  2.64s/it] 39%|███▊      | 193/500 [05:30<09:33,  1.87s/it] 39%|███▉      | 195/500 [05:36<11:23,  2.24s/it] 39%|███▉      | 197/500 [05:36<08:01,  1.59s/it] 40%|███▉      | 199/500 [05:36<05:41,  1.13s/it] 40%|███▉      | 199/500 [05:47<05:41,  1.13s/it] 40%|████      | 201/500 [05:49<13:11,  2.65s/it] 41%|████      | 203/500 [05:49<09:16,  1.87s/it] 41%|████      | 205/500 [05:55<11:02,  2.25s/it] 41%|████▏     | 207/500 [05:55<07:47,  1.59s/it] 42%|████▏     | 209/500 [05:55<05:30,  1.14s/it] 42%|████▏     | 209/500 [06:07<05:30,  1.14s/it] 42%|████▏     | 211/500 [06:08<12:43,  2.64s/it] 43%|████▎     | 213/500 [06:08<08:57,  1.87s/it] 43%|████▎     | 215/500 [06:14<10:38,  2.24s/it] 43%|████▎     | 217/500 [06:14<07:29,  1.59s/it] 44%|████▍     | 219/500 [06:14<05:18,  1.13s/it] 44%|████▍     | 221/500 [06:27<12:15,  2.64s/it] 45%|████▍     | 223/500 [06:27<08:37,  1.87s/it] 45%|████▌     | 225/500 [06:33<10:16,  2.24s/it] 45%|████▌     | 227/500 [06:33<07:14,  1.59s/it] 46%|████▌     | 229/500 [06:33<05:07,  1.13s/it] 46%|████▌     | 231/500 [06:46<11:52,  2.65s/it] 47%|████▋     | 233/500 [06:46<08:21,  1.88s/it] 47%|████▋     | 235/500 [06:52<09:59,  2.26s/it] 47%|████▋     | 237/500 [06:52<07:02,  1.60s/it] 48%|████▊     | 239/500 [06:52<04:58,  1.14s/it] 48%|████▊     | 241/500 [07:05<11:27,  2.65s/it] 49%|████▊     | 243/500 [07:05<08:03,  1.88s/it]Epoch:  185  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  187  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  188  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  189  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  190  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  192  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  193  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  194  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  195  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  197  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  198  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  199  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  200  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  202  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  203  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  204  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  205  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  207  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  208  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  209  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  210  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  212  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  213  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  214  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  215  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  217  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  218  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  219  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  220  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  222  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  223  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  224  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  225  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  227  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  228  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  229  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  230  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  232  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  233  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  234  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  235  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  237  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  238  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  239  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  240  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  242  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  243  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
 49%|████▉     | 245/500 [07:11<09:34,  2.25s/it] 49%|████▉     | 247/500 [07:11<06:44,  1.60s/it] 50%|████▉     | 249/500 [07:11<04:46,  1.14s/it] 50%|█████     | 251/500 [07:24<11:05,  2.67s/it] 51%|█████     | 253/500 [07:24<07:47,  1.89s/it] 51%|█████     | 255/500 [07:30<09:15,  2.27s/it] 51%|█████▏    | 257/500 [07:30<06:30,  1.61s/it] 52%|█████▏    | 259/500 [07:31<04:36,  1.15s/it] 52%|█████▏    | 261/500 [07:43<10:39,  2.67s/it] 53%|█████▎    | 263/500 [07:43<07:28,  1.89s/it] 53%|█████▎    | 265/500 [07:49<08:52,  2.26s/it] 53%|█████▎    | 267/500 [07:50<06:14,  1.61s/it] 54%|█████▍    | 269/500 [07:50<04:24,  1.15s/it] 54%|█████▍    | 271/500 [08:02<10:10,  2.66s/it] 55%|█████▍    | 273/500 [08:02<07:08,  1.89s/it] 55%|█████▌    | 275/500 [08:09<08:28,  2.26s/it] 55%|█████▌    | 277/500 [08:09<05:57,  1.60s/it] 56%|█████▌    | 279/500 [08:09<04:12,  1.14s/it] 56%|█████▌    | 281/500 [08:21<09:43,  2.66s/it] 57%|█████▋    | 283/500 [08:21<06:48,  1.88s/it] 57%|█████▋    | 285/500 [08:28<08:06,  2.26s/it] 57%|█████▋    | 287/500 [08:28<05:41,  1.60s/it] 58%|█████▊    | 289/500 [08:28<04:00,  1.14s/it] 58%|█████▊    | 291/500 [08:40<09:17,  2.67s/it] 59%|█████▊    | 293/500 [08:41<06:31,  1.89s/it] 59%|█████▉    | 295/500 [08:47<07:45,  2.27s/it] 59%|█████▉    | 297/500 [08:47<05:26,  1.61s/it] 60%|█████▉    | 299/500 [08:47<03:50,  1.15s/it] 60%|██████    | 301/500 [09:00<08:55,  2.69s/it]Epoch:  244  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  245  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  247  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  248  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  249  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  250  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  252  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  253  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  254  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  255  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  257  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  258  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  259  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  260  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  262  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  263  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  264  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  265  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  267  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  268  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  269  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  270  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  272  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  273  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  274  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  275  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  277  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  278  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088161706924
Valid Loss:  0.09448359161615372
Epoch:  279  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  280  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  282  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  283  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  284  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  285  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  287  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  288  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  289  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  290  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  292  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  293  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  294  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  295  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  297  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  298  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  299  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  300  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  302  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
 61%|██████    | 303/500 [09:00<06:14,  1.90s/it] 61%|██████    | 305/500 [09:06<07:27,  2.29s/it] 61%|██████▏   | 307/500 [09:06<05:14,  1.63s/it] 62%|██████▏   | 309/500 [09:07<03:41,  1.16s/it] 62%|██████▏   | 309/500 [09:17<03:41,  1.16s/it] 62%|██████▏   | 311/500 [09:19<08:28,  2.69s/it] 63%|██████▎   | 313/500 [09:19<05:56,  1.90s/it] 63%|██████▎   | 315/500 [09:25<06:59,  2.27s/it] 63%|██████▎   | 317/500 [09:26<04:54,  1.61s/it] 64%|██████▍   | 319/500 [09:26<03:27,  1.15s/it] 64%|██████▍   | 319/500 [09:37<03:27,  1.15s/it] 64%|██████▍   | 321/500 [09:38<07:58,  2.67s/it] 65%|██████▍   | 323/500 [09:38<05:34,  1.89s/it] 65%|██████▌   | 325/500 [09:45<06:38,  2.28s/it] 65%|██████▌   | 327/500 [09:45<04:39,  1.61s/it] 66%|██████▌   | 329/500 [09:45<03:16,  1.15s/it] 66%|██████▌   | 329/500 [09:57<03:16,  1.15s/it] 66%|██████▌   | 331/500 [09:57<07:30,  2.67s/it] 67%|██████▋   | 333/500 [09:58<05:15,  1.89s/it] 67%|██████▋   | 335/500 [10:04<06:12,  2.26s/it] 67%|██████▋   | 337/500 [10:04<04:21,  1.60s/it] 68%|██████▊   | 339/500 [10:04<03:03,  1.14s/it] 68%|██████▊   | 341/500 [10:16<07:00,  2.65s/it] 69%|██████▊   | 343/500 [10:16<04:54,  1.87s/it] 69%|██████▉   | 345/500 [10:23<05:48,  2.25s/it] 69%|██████▉   | 347/500 [10:23<04:04,  1.60s/it] 70%|██████▉   | 349/500 [10:23<02:51,  1.14s/it] 70%|███████   | 351/500 [10:35<06:34,  2.65s/it] 71%|███████   | 353/500 [10:35<04:35,  1.87s/it] 71%|███████   | 355/500 [10:42<05:27,  2.26s/it] 71%|███████▏  | 357/500 [10:42<03:48,  1.60s/it] 72%|███████▏  | 359/500 [10:42<02:40,  1.14s/it] 72%|███████▏  | 361/500 [10:54<06:08,  2.65s/it]Epoch:  303  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  304  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  305  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  307  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  308  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  309  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  310  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  312  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  313  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  314  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  315  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  317  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  318  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  319  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  320  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  322  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  323  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  324  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  325  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  327  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  328  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  329  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  330  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  332  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  333  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  334  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  335  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  337  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  338  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  339  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  340  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  342  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  343  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  344  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  345  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  347  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  348  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  349  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  350  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  352  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  353  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  354  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  355  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  357  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  358  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  359  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  360  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
 73%|███████▎  | 363/500 [10:55<04:16,  1.88s/it] 73%|███████▎  | 365/500 [11:01<05:03,  2.24s/it] 73%|███████▎  | 367/500 [11:01<03:31,  1.59s/it] 74%|███████▍  | 369/500 [11:01<02:28,  1.14s/it] 74%|███████▍  | 371/500 [11:13<05:41,  2.64s/it] 75%|███████▍  | 373/500 [11:14<03:57,  1.87s/it] 75%|███████▌  | 375/500 [11:20<04:39,  2.24s/it] 75%|███████▌  | 377/500 [11:20<03:15,  1.59s/it] 76%|███████▌  | 379/500 [11:20<02:17,  1.14s/it] 76%|███████▌  | 381/500 [11:33<05:18,  2.68s/it] 77%|███████▋  | 383/500 [11:33<03:41,  1.90s/it] 77%|███████▋  | 385/500 [11:39<04:19,  2.26s/it] 77%|███████▋  | 387/500 [11:39<03:01,  1.60s/it] 78%|███████▊  | 389/500 [11:39<02:06,  1.14s/it] 78%|███████▊  | 391/500 [11:52<04:48,  2.65s/it] 79%|███████▊  | 393/500 [11:52<03:20,  1.87s/it] 79%|███████▉  | 395/500 [11:58<03:56,  2.25s/it] 79%|███████▉  | 397/500 [11:58<02:44,  1.60s/it] 80%|███████▉  | 399/500 [11:58<01:55,  1.14s/it] 80%|████████  | 401/500 [12:11<04:23,  2.66s/it] 81%|████████  | 403/500 [12:11<03:02,  1.88s/it] 81%|████████  | 405/500 [12:17<03:33,  2.25s/it] 81%|████████▏ | 407/500 [12:17<02:28,  1.60s/it] 82%|████████▏ | 409/500 [12:17<01:43,  1.14s/it] 82%|████████▏ | 411/500 [12:30<03:55,  2.65s/it] 83%|████████▎ | 413/500 [12:30<02:43,  1.88s/it] 83%|████████▎ | 415/500 [12:36<03:11,  2.25s/it] 83%|████████▎ | 417/500 [12:36<02:12,  1.60s/it] 84%|████████▍ | 419/500 [12:36<01:32,  1.14s/it]Epoch:  362  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  363  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359161615372
Epoch:  364  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  365  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  367  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  368  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  369  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  370  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  372  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  373  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  374  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  375  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  377  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  378  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  379  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  380  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  382  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  383  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  384  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  385  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  387  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  388  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  389  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  390  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  392  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  393  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  394  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  395  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  397  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  398  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  399  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  400  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  402  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  403  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  404  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  405  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  407  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  408  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  409  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  410  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  412  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  413  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  414  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  415  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088161706924
Valid Loss:  0.09448359906673431
Epoch:  417  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  418  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  419  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  420  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
 84%|████████▍ | 419/500 [12:47<01:32,  1.14s/it] 84%|████████▍ | 421/500 [12:49<03:32,  2.69s/it] 85%|████████▍ | 423/500 [12:49<02:26,  1.90s/it] 85%|████████▌ | 425/500 [12:55<02:50,  2.27s/it] 85%|████████▌ | 427/500 [12:55<01:57,  1.61s/it] 86%|████████▌ | 429/500 [12:56<01:21,  1.15s/it] 86%|████████▌ | 429/500 [13:07<01:21,  1.15s/it] 86%|████████▌ | 431/500 [13:08<03:04,  2.68s/it] 87%|████████▋ | 433/500 [13:08<02:06,  1.89s/it] 87%|████████▋ | 435/500 [13:15<02:27,  2.27s/it] 87%|████████▋ | 437/500 [13:15<01:41,  1.61s/it] 88%|████████▊ | 439/500 [13:15<01:10,  1.15s/it] 88%|████████▊ | 439/500 [13:27<01:10,  1.15s/it] 88%|████████▊ | 441/500 [13:27<02:38,  2.69s/it] 89%|████████▊ | 443/500 [13:28<01:48,  1.91s/it] 89%|████████▉ | 445/500 [13:34<02:05,  2.27s/it] 89%|████████▉ | 447/500 [13:34<01:25,  1.61s/it] 90%|████████▉ | 449/500 [13:34<00:58,  1.15s/it] 90%|█████████ | 451/500 [13:47<02:11,  2.68s/it] 91%|█████████ | 453/500 [13:47<01:29,  1.89s/it] 91%|█████████ | 455/500 [13:53<01:41,  2.25s/it] 91%|█████████▏| 457/500 [13:53<01:08,  1.60s/it] 92%|█████████▏| 459/500 [13:53<00:46,  1.14s/it] 92%|█████████▏| 461/500 [14:05<01:43,  2.65s/it] 93%|█████████▎| 463/500 [14:06<01:09,  1.87s/it] 93%|█████████▎| 465/500 [14:12<01:19,  2.26s/it] 93%|█████████▎| 467/500 [14:12<00:52,  1.60s/it] 94%|█████████▍| 469/500 [14:12<00:35,  1.14s/it] 94%|█████████▍| 471/500 [14:25<01:16,  2.65s/it] 95%|█████████▍| 473/500 [14:25<00:50,  1.88s/it] 95%|█████████▌| 475/500 [14:31<00:56,  2.27s/it] 95%|█████████▌| 477/500 [14:31<00:37,  1.61s/it] 96%|█████████▌| 479/500 [14:31<00:24,  1.15s/it]Epoch:  421  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  422  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  423  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  424  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  425  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  427  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  428  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  429  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  430  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  432  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  433  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  434  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  435  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  437  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  438  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  439  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  440  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  442  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  443  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  444  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  445  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  447  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  448  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  449  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  450  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  452  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  453  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  454  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  455  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  457  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  458  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  459  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  460  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  462  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  463  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  464  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  465  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  467  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  468  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  469  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  470  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  472  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  473  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  474  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  475  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  477  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  478  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  479  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  480  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
 96%|█████████▌| 481/500 [14:44<00:51,  2.70s/it] 97%|█████████▋| 483/500 [14:44<00:32,  1.91s/it] 97%|█████████▋| 485/500 [14:50<00:34,  2.29s/it] 97%|█████████▋| 487/500 [14:51<00:21,  1.63s/it] 98%|█████████▊| 489/500 [14:51<00:12,  1.16s/it] 98%|█████████▊| 491/500 [15:03<00:24,  2.69s/it] 99%|█████████▊| 493/500 [15:03<00:13,  1.90s/it] 99%|█████████▉| 495/500 [15:10<00:11,  2.27s/it] 99%|█████████▉| 497/500 [15:10<00:04,  1.61s/it]100%|█████████▉| 499/500 [15:10<00:01,  1.15s/it]100%|██████████| 500/500 [15:16<00:00,  1.83s/it]
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  482  	Training Loss: 0.09581679850816727
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  483  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  484  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  485  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  487  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  488  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  489  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  490  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  492  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  493  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  494  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  495  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  497  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  498  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  499  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
Epoch:  500  	Training Loss: 0.09581679105758667
Test Loss:  0.09187088906764984
Valid Loss:  0.09448359906673431
**************************************************learning rate decay**************************************************
seed is  9
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:39,  6.21s/it]  1%|          | 3/500 [00:06<13:46,  1.66s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.89it/s]  2%|▏         | 11/500 [00:13<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:19<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.62it/s]  5%|▌         | 27/500 [00:20<03:32,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:13,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:26<04:44,  1.64it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<09:01,  1.18s/it]  9%|▊         | 43/500 [00:33<06:28,  1.18it/s]  9%|▉         | 45/500 [00:39<11:32,  1.52s/it]  9%|▉         | 47/500 [00:40<08:12,  1.09s/it] 10%|▉         | 49/500 [00:40<05:51,  1.28it/s] 10%|█         | 51/500 [00:46<11:15,  1.50s/it] 11%|█         | 53/500 [00:46<08:00,  1.07s/it] 11%|█         | 55/500 [00:46<05:44,  1.29it/s] 11%|█▏        | 57/500 [00:46<04:09,  1.78it/s] 12%|█▏        | 59/500 [00:47<03:02,  2.41it/s] 12%|█▏        | 61/500 [00:53<09:00,  1.23s/it] 13%|█▎        | 63/500 [00:53<06:26,  1.13it/s] 13%|█▎        | 65/500 [00:53<04:37,  1.57it/s] 13%|█▎        | 67/500 [00:53<03:22,  2.13it/s] 14%|█▍        | 69/500 [00:53<02:30,  2.86it/s]Epoch:  1  	Training Loss: 0.08815440535545349
Test Loss:  3.279719829559326
Valid Loss:  3.3158600330352783
Epoch:  2  	Training Loss: 3.341135025024414
Test Loss:  5.787670135498047
Valid Loss:  5.971205711364746
Epoch:  3  	Training Loss: 6.052565574645996
Test Loss:  0.824862003326416
Valid Loss:  0.8358688354492188
Epoch:  4  	Training Loss: 0.8348880410194397
Test Loss:  0.8237804174423218
Valid Loss:  0.8350369930267334
Epoch:  5  	Training Loss: 0.8339613080024719
Test Loss:  0.8227576017379761
Valid Loss:  0.834230899810791
Epoch:  6  	Training Loss: 0.8330478668212891
Test Loss:  0.8214381337165833
Valid Loss:  0.8330095410346985
Epoch:  7  	Training Loss: 0.831836998462677
Test Loss:  0.8137519359588623
Valid Loss:  0.8254811763763428
Epoch:  8  	Training Loss: 0.8241396546363831
Test Loss:  0.7753533124923706
Valid Loss:  0.7860236167907715
Epoch:  9  	Training Loss: 0.7841148376464844
Test Loss:  0.7392683029174805
Valid Loss:  0.7489852905273438
Epoch:  10  	Training Loss: 0.7465549111366272
Test Loss:  0.7053238749504089
Valid Loss:  0.7141997814178467
Epoch:  11  	Training Loss: 0.7112840414047241
Test Loss:  0.6733863353729248
Valid Loss:  0.6815252304077148
Epoch:  12  	Training Loss: 0.6781595945358276
Test Loss:  0.09746304154396057
Valid Loss:  0.11521930247545242
Epoch:  13  	Training Loss: 0.11306329071521759
Test Loss:  0.0588679239153862
Valid Loss:  0.0713634341955185
Epoch:  14  	Training Loss: 0.06903380155563354
Test Loss:  0.03932170197367668
Valid Loss:  0.0487356074154377
Epoch:  15  	Training Loss: 0.04642011970281601
Test Loss:  0.02914339303970337
Valid Loss:  0.036761973053216934
Epoch:  16  	Training Loss: 0.03449731692671776
Test Loss:  0.024873748421669006
Valid Loss:  0.031562741845846176
Epoch:  17  	Training Loss: 0.029403412714600563
Test Loss:  0.024453023448586464
Valid Loss:  0.03093215450644493
Epoch:  18  	Training Loss: 0.02890447899699211
Test Loss:  0.024067439138889313
Valid Loss:  0.030390415340662003
Epoch:  19  	Training Loss: 0.028451180085539818
Test Loss:  0.02367391623556614
Valid Loss:  0.029873071238398552
Epoch:  20  	Training Loss: 0.028003685176372528
Test Loss:  0.02357843704521656
Valid Loss:  0.029694952070713043
Epoch:  21  	Training Loss: 0.027895035222172737
Test Loss:  0.023136509582400322
Valid Loss:  0.029146170243620872
Epoch:  22  	Training Loss: 0.027373667806386948
Test Loss:  0.020342126488685608
Valid Loss:  0.02530970796942711
Epoch:  23  	Training Loss: 0.02381095476448536
Test Loss:  0.017244841903448105
Valid Loss:  0.021030616015195847
Epoch:  24  	Training Loss: 0.01997111365199089
Test Loss:  0.016206558793783188
Valid Loss:  0.01999129168689251
Epoch:  25  	Training Loss: 0.01886671781539917
Test Loss:  0.01575027033686638
Valid Loss:  0.01928984373807907
Epoch:  26  	Training Loss: 0.018216460943222046
Test Loss:  0.015313833951950073
Valid Loss:  0.018785569816827774
Epoch:  27  	Training Loss: 0.017730388790369034
Test Loss:  0.015015285462141037
Valid Loss:  0.01836363412439823
Epoch:  28  	Training Loss: 0.017313897609710693
Test Loss:  0.01473376527428627
Valid Loss:  0.01802602782845497
Epoch:  29  	Training Loss: 0.01696047931909561
Test Loss:  0.014486369676887989
Valid Loss:  0.017748668789863586
Epoch:  30  	Training Loss: 0.016660640016198158
Test Loss:  0.014255988411605358
Valid Loss:  0.017494598403573036
Epoch:  31  	Training Loss: 0.016382992267608643
Test Loss:  0.014044886454939842
Valid Loss:  0.017255842685699463
Epoch:  32  	Training Loss: 0.016124755144119263
Test Loss:  0.010112575255334377
Valid Loss:  0.012089578434824944
Epoch:  33  	Training Loss: 0.011045603081583977
Test Loss:  0.027934052050113678
Valid Loss:  0.02850138396024704
Epoch:  34  	Training Loss: 0.02880914695560932
Test Loss:  0.017139732837677002
Valid Loss:  0.019374608993530273
Epoch:  35  	Training Loss: 0.018118811771273613
Test Loss:  0.015926361083984375
Valid Loss:  0.01797356829047203
Epoch:  36  	Training Loss: 0.017691634595394135
Test Loss:  0.011020784266293049
Valid Loss:  0.013696448877453804
Epoch:  37  	Training Loss: 0.012483199127018452
Test Loss:  0.008313259109854698
Valid Loss:  0.009988218545913696
Epoch:  38  	Training Loss: 0.009353097528219223
Test Loss:  0.00432897824794054
Valid Loss:  0.005689783021807671
Epoch:  39  	Training Loss: 0.0051951538771390915
Test Loss:  0.003176758298650384
Valid Loss:  0.0037748231552541256
Epoch:  40  	Training Loss: 0.0036050674971193075
Test Loss:  0.004548394586890936
Valid Loss:  0.005381378345191479
Epoch:  41  	Training Loss: 0.005173742771148682
Test Loss:  0.019124846905469894
Valid Loss:  0.01768229901790619
Epoch:  42  	Training Loss: 0.018674109131097794
Test Loss:  0.011998499743640423
Valid Loss:  0.013108085840940475
Epoch:  43  	Training Loss: 0.012798835523426533
Test Loss:  0.020293299108743668
Valid Loss:  0.020226625725626945
Epoch:  44  	Training Loss: 0.020119573920965195
Test Loss:  0.005816491320729256
Valid Loss:  0.006905388552695513
Epoch:  45  	Training Loss: 0.006435009650886059
Test Loss:  0.0030648894608020782
Valid Loss:  0.003119062166661024
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.003115913597866893
Test Loss:  0.0025861298199743032
Valid Loss:  0.002643799874931574
Epoch:  47  	Training Loss: 0.0026447633281350136
Test Loss:  0.0022295608650892973
Valid Loss:  0.0022253633942455053
Epoch:  48  	Training Loss: 0.0022616577334702015
Test Loss:  0.001818107208237052
Valid Loss:  0.0017732681008055806
Epoch:  49  	Training Loss: 0.001841824036091566
Test Loss:  0.001390501856803894
Valid Loss:  0.0013597025536000729
Epoch:  50  	Training Loss: 0.0014376590261235833
Test Loss:  0.0010818428127095103
Valid Loss:  0.001064919400960207
Epoch:  51  	Training Loss: 0.0011554921511560678
Test Loss:  0.0009064890327863395
Valid Loss:  0.000897119811270386
Epoch:  52  	Training Loss: 0.0009962196927517653
Test Loss:  0.0008668795344419777
Valid Loss:  0.0008646652568131685
Epoch:  53  	Training Loss: 0.0009633384179323912
Test Loss:  0.0008406632114201784
Valid Loss:  0.0008402251405641437
Epoch:  54  	Training Loss: 0.0009402369614690542
Test Loss:  0.0008200611337088048
Valid Loss:  0.0008196503622457385
Epoch:  55  	Training Loss: 0.0009216288453899324
Test Loss:  0.0008026706636883318
Valid Loss:  0.0008017014479264617
Epoch:  56  	Training Loss: 0.0009065466001629829
Test Loss:  0.0007875333540141582
Valid Loss:  0.0007859832840040326
Epoch:  57  	Training Loss: 0.0008941214764490724
Test Loss:  0.00077438895823434
Valid Loss:  0.0007725037285126746
Epoch:  58  	Training Loss: 0.0008835907792672515
Test Loss:  0.000762676470912993
Valid Loss:  0.0007611915352754295
Epoch:  59  	Training Loss: 0.0008744494989514351
Test Loss:  0.0007524125394411385
Valid Loss:  0.0007520049111917615
Epoch:  60  	Training Loss: 0.0008671403047628701
Test Loss:  0.0007440723129548132
Valid Loss:  0.0007446912932209671
Epoch:  61  	Training Loss: 0.0008613751269876957
Test Loss:  0.0007368188817054033
Valid Loss:  0.0007378836162388325
Epoch:  62  	Training Loss: 0.0008562319562770426
Test Loss:  0.00058026984333992
Valid Loss:  0.000596643250901252
Epoch:  63  	Training Loss: 0.0007117643253877759
Test Loss:  0.0004961565718986094
Valid Loss:  0.0005032380577176809
Epoch:  64  	Training Loss: 0.0006121248006820679
Test Loss:  0.0004271928919479251
Valid Loss:  0.0004487750702537596
Epoch:  65  	Training Loss: 0.000549152959138155
Test Loss:  0.0003872790257446468
Valid Loss:  0.00041484262328594923
Epoch:  66  	Training Loss: 0.00050314114196226
Test Loss:  0.000349107023794204
Valid Loss:  0.00038832591963000596
Epoch:  67  	Training Loss: 0.0004640235856641084
Test Loss:  0.0003186404355801642
Valid Loss:  0.0003687930293381214
Epoch:  68  	Training Loss: 0.00043043578625656664
Test Loss:  0.0002923085121437907
Valid Loss:  0.0003527228836901486
Epoch:  69  	Training Loss: 0.00040134898154065013
Test Loss:  0.0002687339438125491
Valid Loss:  0.00033851087209768593
Epoch:  70  	Training Loss: 0.00037297772360034287
Test Loss:  0.0002463199198246002
Valid Loss:  0.00032227905467152596
 14%|█▍        | 71/500 [01:00<08:25,  1.18s/it] 15%|█▍        | 73/500 [01:00<06:01,  1.18it/s] 15%|█▌        | 75/500 [01:00<04:20,  1.63it/s] 15%|█▌        | 77/500 [01:00<03:09,  2.23it/s] 16%|█▌        | 79/500 [01:00<02:21,  2.98it/s] 16%|█▌        | 81/500 [01:07<08:16,  1.19s/it] 17%|█▋        | 83/500 [01:07<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:07<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:07<03:07,  2.20it/s] 18%|█▊        | 89/500 [01:07<02:18,  2.96it/s] 18%|█▊        | 91/500 [01:13<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:14<05:43,  1.19it/s] 19%|█▉        | 95/500 [01:14<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:14<03:01,  2.23it/s] 20%|█▉        | 99/500 [01:14<02:13,  2.99it/s] 20%|██        | 101/500 [01:20<07:45,  1.17s/it] 21%|██        | 103/500 [01:20<05:32,  1.19it/s] 21%|██        | 105/500 [01:20<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:21<02:55,  2.25it/s] 22%|██▏       | 109/500 [01:21<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:27<07:38,  1.18s/it] 23%|██▎       | 113/500 [01:27<05:27,  1.18it/s] 23%|██▎       | 115/500 [01:27<03:56,  1.63it/s] 23%|██▎       | 117/500 [01:27<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:28<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:34<07:31,  1.19s/it] 25%|██▍       | 123/500 [01:34<05:22,  1.17it/s] 25%|██▌       | 125/500 [01:34<03:52,  1.62it/s] 25%|██▌       | 127/500 [01:34<02:49,  2.20it/s] 26%|██▌       | 129/500 [01:34<02:05,  2.96it/s] 26%|██▌       | 131/500 [01:41<07:11,  1.17s/it] 27%|██▋       | 133/500 [01:41<05:09,  1.19it/s] 27%|██▋       | 135/500 [01:41<03:43,  1.64it/s] 27%|██▋       | 137/500 [01:41<02:42,  2.24it/s]Epoch:  71  	Training Loss: 0.000346029584761709
Test Loss:  0.0002271418779855594
Valid Loss:  0.00030781200621277094
Epoch:  72  	Training Loss: 0.000322277017403394
Test Loss:  0.00022148352582007647
Valid Loss:  0.00030404370045289397
Epoch:  73  	Training Loss: 0.000308220274746418
Test Loss:  0.00021702676895074546
Valid Loss:  0.00030167889781296253
Epoch:  74  	Training Loss: 0.0002956455573439598
Test Loss:  0.00021205793018452823
Valid Loss:  0.0002984388265758753
Epoch:  75  	Training Loss: 0.00028485682560130954
Test Loss:  0.000207754535949789
Valid Loss:  0.0002951224450953305
Epoch:  76  	Training Loss: 0.0002749328559730202
Test Loss:  0.00020401115762069821
Valid Loss:  0.00029167404863983393
Epoch:  77  	Training Loss: 0.00026604143204167485
Test Loss:  0.00020068089361302555
Valid Loss:  0.0002861727261915803
Epoch:  78  	Training Loss: 0.0002576123515609652
Test Loss:  0.00019624590640887618
Valid Loss:  0.0002798338246066123
Epoch:  79  	Training Loss: 0.0002497766981832683
Test Loss:  0.0001914819295052439
Valid Loss:  0.00027397050871513784
Epoch:  80  	Training Loss: 0.00024253303126897663
Test Loss:  0.00018697019550018013
Valid Loss:  0.00026840934879146516
Epoch:  81  	Training Loss: 0.00023571515339426696
Test Loss:  0.00018270750297233462
Valid Loss:  0.0002632098039612174
Epoch:  82  	Training Loss: 0.00022950483253225684
Test Loss:  0.0001824159116949886
Valid Loss:  0.0002628973452374339
Epoch:  83  	Training Loss: 0.00022926471137907356
Test Loss:  0.00018212597933597863
Valid Loss:  0.00026258762227371335
Epoch:  84  	Training Loss: 0.00022902638011146337
Test Loss:  0.00018183726933784783
Valid Loss:  0.0002622811880428344
Epoch:  85  	Training Loss: 0.00022879053722135723
Test Loss:  0.0001815503928810358
Valid Loss:  0.0002619774895720184
Epoch:  86  	Training Loss: 0.00022855718270875514
Test Loss:  0.0001812725531635806
Valid Loss:  0.00026168316253460944
Epoch:  87  	Training Loss: 0.00022832717513665557
Test Loss:  0.00018099597946275026
Valid Loss:  0.00026139116380363703
Epoch:  88  	Training Loss: 0.00022809853544458747
Test Loss:  0.0001807205262593925
Valid Loss:  0.00026110204635187984
Epoch:  89  	Training Loss: 0.0002278722240589559
Test Loss:  0.00018044635362457484
Valid Loss:  0.00026081534451805055
Epoch:  90  	Training Loss: 0.0002276479353895411
Test Loss:  0.00018018233822658658
Valid Loss:  0.0002605374320410192
Epoch:  91  	Training Loss: 0.0002274269936606288
Test Loss:  0.00017991829372476786
Valid Loss:  0.00026026112027466297
Epoch:  92  	Training Loss: 0.00022720723063685
Test Loss:  0.0001646273594815284
Valid Loss:  0.0002450394968036562
Epoch:  93  	Training Loss: 0.00021143628691788763
Test Loss:  0.00015330045425798744
Valid Loss:  0.00023426880943588912
Epoch:  94  	Training Loss: 0.00020002134260721505
Test Loss:  0.00014336439198814332
Valid Loss:  0.00022457145678345114
Epoch:  95  	Training Loss: 0.0001904951932374388
Test Loss:  0.00013458781177178025
Valid Loss:  0.0002154958201572299
Epoch:  96  	Training Loss: 0.00018236403411719948
Test Loss:  0.0001271715882467106
Valid Loss:  0.0002077364915749058
Epoch:  97  	Training Loss: 0.00017531358753331006
Test Loss:  0.00012066950148437172
Valid Loss:  0.00020046855206601322
Epoch:  98  	Training Loss: 0.0001683988084550947
Test Loss:  0.00011454262130428106
Valid Loss:  0.0001933413150254637
Epoch:  99  	Training Loss: 0.00016166933346539736
Test Loss:  0.00010908706462942064
Valid Loss:  0.00018674296734388918
Epoch:  100  	Training Loss: 0.00015522602188866585
Test Loss:  0.00010427900997456163
Valid Loss:  0.00018078576249536127
Epoch:  101  	Training Loss: 0.00014911183097865433
Test Loss:  9.949559171218425e-05
Valid Loss:  0.00017493746418040246
Epoch:  102  	Training Loss: 0.00014296073641162366
Test Loss:  9.619276534067467e-05
Valid Loss:  0.0001700468419585377
Epoch:  103  	Training Loss: 0.00013793687685392797
Test Loss:  9.294453775510192e-05
Valid Loss:  0.0001654958468861878
Epoch:  104  	Training Loss: 0.00013337474956642836
Test Loss:  8.96703713806346e-05
Valid Loss:  0.0001612178166396916
Epoch:  105  	Training Loss: 0.00012904146569781005
Test Loss:  8.654473640490323e-05
Valid Loss:  0.00015713587345089763
Epoch:  106  	Training Loss: 0.00012495894043240696
Test Loss:  8.355236059287563e-05
Valid Loss:  0.0001529376459075138
Epoch:  107  	Training Loss: 0.00012102840992156416
Test Loss:  8.06853495305404e-05
Valid Loss:  0.0001489133428549394
Epoch:  108  	Training Loss: 0.00011726062803063542
Test Loss:  7.797751459293067e-05
Valid Loss:  0.00014511094195768237
Epoch:  109  	Training Loss: 0.00011371660366421565
Test Loss:  7.535508484579623e-05
Valid Loss:  0.0001414040889358148
Epoch:  110  	Training Loss: 0.00011018052464351058
Test Loss:  7.288053166121244e-05
Valid Loss:  0.00013789617514703423
Epoch:  111  	Training Loss: 0.00010687409667298198
Test Loss:  7.054561865516007e-05
Valid Loss:  0.00013457499153446406
Epoch:  112  	Training Loss: 0.0001037717011058703
Test Loss:  6.868830678286031e-05
Valid Loss:  0.00013280684652272612
Epoch:  113  	Training Loss: 0.00010309441131539643
Test Loss:  6.76187191857025e-05
Valid Loss:  0.00013173380284570158
Epoch:  114  	Training Loss: 0.00010275141539750621
Test Loss:  6.692789611406624e-05
Valid Loss:  0.00013098744966555387
Epoch:  115  	Training Loss: 0.00010252192441839725
Test Loss:  6.64355538901873e-05
Valid Loss:  0.0001304105098824948
Epoch:  116  	Training Loss: 0.00010233541979687288
Test Loss:  6.605531962122768e-05
Valid Loss:  0.00012993144628126174
Epoch:  117  	Training Loss: 0.00010216897499049082
Test Loss:  6.5743995946832e-05
Valid Loss:  0.00012951467942912132
Epoch:  118  	Training Loss: 0.00010201512486673892
Test Loss:  6.547599332407117e-05
Valid Loss:  0.00012913797399960458
Epoch:  119  	Training Loss: 0.00010186842700932175
Test Loss:  6.523798947455361e-05
Valid Loss:  0.00012878842244390398
Epoch:  120  	Training Loss: 0.00010172775364480913
Test Loss:  6.502192263724282e-05
Valid Loss:  0.00012846413301303983
Epoch:  121  	Training Loss: 0.00010159373778151348
Test Loss:  6.482310709543526e-05
Valid Loss:  0.00012815732043236494
Epoch:  122  	Training Loss: 0.00010146442946279421
Test Loss:  6.45973050268367e-05
Valid Loss:  0.00012780239921994507
Epoch:  123  	Training Loss: 0.0001013447908917442
Test Loss:  6.439787830458954e-05
Valid Loss:  0.0001275131362490356
Epoch:  124  	Training Loss: 0.00010125245898962021
Test Loss:  6.422643491532654e-05
Valid Loss:  0.0001272715162485838
Epoch:  125  	Training Loss: 0.00010117168858414516
Test Loss:  6.408155604731292e-05
Valid Loss:  0.00012706487905234098
Epoch:  126  	Training Loss: 0.00010109725553775206
Test Loss:  6.396013486664742e-05
Valid Loss:  0.0001268866180907935
Epoch:  127  	Training Loss: 0.00010102606756845489
Test Loss:  6.38573183096014e-05
Valid Loss:  0.0001267097977688536
Epoch:  128  	Training Loss: 0.00010095724428538233
Test Loss:  6.376911915140226e-05
Valid Loss:  0.00012654592865146697
Epoch:  129  	Training Loss: 0.0001008901308523491
Test Loss:  6.367845344357193e-05
Valid Loss:  0.0001263968733837828
Epoch:  130  	Training Loss: 0.00010082397056976333
Test Loss:  6.359013787005097e-05
Valid Loss:  0.0001262596488231793
Epoch:  131  	Training Loss: 0.00010075836325995624
Test Loss:  6.35096657788381e-05
Valid Loss:  0.0001261301658814773
Epoch:  132  	Training Loss: 0.00010069367999676615
Test Loss:  6.344377470668405e-05
Valid Loss:  0.0001260315766558051
Epoch:  133  	Training Loss: 0.00010065623791888356
Test Loss:  6.337930972222239e-05
Valid Loss:  0.00012593642168212682
Epoch:  134  	Training Loss: 0.00010061962530016899
Test Loss:  6.331654731184244e-05
Valid Loss:  0.0001258436677744612
Epoch:  135  	Training Loss: 0.0001005839803838171
Test Loss:  6.325385038508102e-05
Valid Loss:  0.00012575392611324787
Epoch:  136  	Training Loss: 0.00010054974700324237
Test Loss:  6.31925868219696e-05
Valid Loss:  0.00012566460645757616
Epoch:  137  	Training Loss: 0.00010051629215013236
Test Loss:  6.313112680800259e-05
Valid Loss:  0.00012557681475300342
Epoch:  138  	Training Loss: 0.00010048340482171625
Test Loss:  6.307045259745792e-05
 28%|██▊       | 139/500 [01:41<02:00,  3.01it/s] 28%|██▊       | 141/500 [01:48<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:48<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:48<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:48<02:37,  2.25it/s] 30%|██▉       | 149/500 [01:48<01:56,  3.02it/s] 30%|███       | 151/500 [01:54<06:54,  1.19s/it] 31%|███       | 153/500 [01:55<04:56,  1.17it/s] 31%|███       | 155/500 [01:55<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:55<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:55<01:54,  2.98it/s] 32%|███▏      | 161/500 [02:01<06:35,  1.17s/it] 33%|███▎      | 163/500 [02:01<04:42,  1.19it/s] 33%|███▎      | 165/500 [02:01<03:24,  1.64it/s] 33%|███▎      | 167/500 [02:02<02:28,  2.24it/s] 34%|███▍      | 169/500 [02:02<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:08<06:33,  1.19s/it] 35%|███▍      | 173/500 [02:08<04:40,  1.17it/s] 35%|███▌      | 175/500 [02:08<03:21,  1.61it/s] 35%|███▌      | 177/500 [02:09<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:09<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:15<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:15<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:15<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:15<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:16<01:45,  2.96it/s] 38%|███▊      | 191/500 [02:22<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:22<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:22<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:22<02:16,  2.21it/s] 40%|███▉      | 199/500 [02:22<01:40,  2.98it/s] 40%|████      | 201/500 [02:29<05:51,  1.18s/it] 41%|████      | 203/500 [02:29<04:10,  1.18it/s] 41%|████      | 205/500 [02:29<02:59,  1.64it/s]Valid Loss:  0.00012548998347483575
Epoch:  139  	Training Loss: 0.0001004514197120443
Test Loss:  6.300995300989598e-05
Valid Loss:  0.0001254049566341564
Epoch:  140  	Training Loss: 0.00010041994391940534
Test Loss:  6.295055209193379e-05
Valid Loss:  0.00012532206892501563
Epoch:  141  	Training Loss: 0.00010038877371698618
Test Loss:  6.289126758929342e-05
Valid Loss:  0.00012523983605206013
Epoch:  142  	Training Loss: 0.00010035849845735356
Test Loss:  6.249079160625115e-05
Valid Loss:  0.0001248714979737997
Epoch:  143  	Training Loss: 0.00010021404887083918
Test Loss:  6.226426194189116e-05
Valid Loss:  0.0001246402389369905
Epoch:  144  	Training Loss: 0.0001001179771265015
Test Loss:  6.210993888089433e-05
Valid Loss:  0.000124463826068677
Epoch:  145  	Training Loss: 0.00010003385250456631
Test Loss:  6.198853225214407e-05
Valid Loss:  0.00012431194772943854
Epoch:  146  	Training Loss: 9.995333675760776e-05
Test Loss:  6.188321276567876e-05
Valid Loss:  0.00012417248217388988
Epoch:  147  	Training Loss: 9.987366502173245e-05
Test Loss:  6.178570038173348e-05
Valid Loss:  0.0001240397396031767
Epoch:  148  	Training Loss: 9.979480819310993e-05
Test Loss:  6.16921461187303e-05
Valid Loss:  0.00012390971824061126
Epoch:  149  	Training Loss: 9.971439430955797e-05
Test Loss:  6.160126940812916e-05
Valid Loss:  0.0001237814867636189
Epoch:  150  	Training Loss: 9.963485354091972e-05
Test Loss:  6.151193520054221e-05
Valid Loss:  0.00012365475413389504
Epoch:  151  	Training Loss: 9.95550217339769e-05
Test Loss:  6.142388156149536e-05
Valid Loss:  0.0001235299278050661
Epoch:  152  	Training Loss: 9.947633952833712e-05
Test Loss:  6.176241004141048e-05
Valid Loss:  0.00012362588313408196
Epoch:  153  	Training Loss: 9.928443614626303e-05
Test Loss:  6.183717050589621e-05
Valid Loss:  0.00012357397645246238
Epoch:  154  	Training Loss: 9.919401054503396e-05
Test Loss:  6.179633783176541e-05
Valid Loss:  0.00012345478171482682
Epoch:  155  	Training Loss: 9.912234236253425e-05
Test Loss:  6.171548011479899e-05
Valid Loss:  0.00012330414028838277
Epoch:  156  	Training Loss: 9.905413025990129e-05
Test Loss:  6.162286445032805e-05
Valid Loss:  0.00012314406922087073
Epoch:  157  	Training Loss: 9.898701682686806e-05
Test Loss:  6.153019785415381e-05
Valid Loss:  0.00012298714136704803
Epoch:  158  	Training Loss: 9.892115485854447e-05
Test Loss:  6.144116923678666e-05
Valid Loss:  0.00012283684918656945
Epoch:  159  	Training Loss: 9.885642066365108e-05
Test Loss:  6.13571610301733e-05
Valid Loss:  0.0001226941531058401
Epoch:  160  	Training Loss: 9.879257413558662e-05
Test Loss:  6.127919186837971e-05
Valid Loss:  0.00012255756882950664
Epoch:  161  	Training Loss: 9.872937516774982e-05
Test Loss:  6.120635225670412e-05
Valid Loss:  0.00012242728553246707
Epoch:  162  	Training Loss: 9.866658365353942e-05
Test Loss:  6.02215040998999e-05
Valid Loss:  0.00012161297490820289
Epoch:  163  	Training Loss: 9.845639578998089e-05
Test Loss:  6.0256264987401664e-05
Valid Loss:  0.00012163742212578654
Epoch:  164  	Training Loss: 9.844620944932103e-05
Test Loss:  6.0267517255852e-05
Valid Loss:  0.00012164279178250581
Epoch:  165  	Training Loss: 9.843640145845711e-05
Test Loss:  6.027901326888241e-05
Valid Loss:  0.00012164774670964107
Epoch:  166  	Training Loss: 9.842668077908456e-05
Test Loss:  6.0290200053714216e-05
Valid Loss:  0.00012165351654402912
Epoch:  167  	Training Loss: 9.841716382652521e-05
Test Loss:  6.030126678524539e-05
Valid Loss:  0.00012165878433734179
Epoch:  168  	Training Loss: 9.840758139034733e-05
Test Loss:  6.0312391724437475e-05
Valid Loss:  0.00012166486703790724
Epoch:  169  	Training Loss: 9.839840640779585e-05
Test Loss:  6.0323811339912936e-05
Valid Loss:  0.00012167022214271128
Epoch:  170  	Training Loss: 9.838931873673573e-05
Test Loss:  6.033480167388916e-05
Valid Loss:  0.00012167590466560796
Epoch:  171  	Training Loss: 9.838018740992993e-05
Test Loss:  6.03457483521197e-05
Valid Loss:  0.00012168165994808078
Epoch:  172  	Training Loss: 9.837136894930154e-05
Test Loss:  6.016823317622766e-05
Valid Loss:  0.00012128445087000728
Epoch:  173  	Training Loss: 9.824775042943656e-05
Test Loss:  6.00127168581821e-05
Valid Loss:  0.00012092811084585264
Epoch:  174  	Training Loss: 9.814286750042811e-05
Test Loss:  5.9895392041653395e-05
Valid Loss:  0.00012065853661624715
Epoch:  175  	Training Loss: 9.806133311940357e-05
Test Loss:  5.9795558627229184e-05
Valid Loss:  0.00012043734022881836
Epoch:  176  	Training Loss: 9.798975224839523e-05
Test Loss:  5.9706493630073965e-05
Valid Loss:  0.00012024492025375366
Epoch:  177  	Training Loss: 9.792225318960845e-05
Test Loss:  5.962348950561136e-05
Valid Loss:  0.00012007234909106046
Epoch:  178  	Training Loss: 9.785777365323156e-05
Test Loss:  5.954416701570153e-05
Valid Loss:  0.00011991324572591111
Epoch:  179  	Training Loss: 9.7795928013511e-05
Test Loss:  5.946751480223611e-05
Valid Loss:  0.00011975127563346177
Epoch:  180  	Training Loss: 9.773515921551734e-05
Test Loss:  5.9392656112322584e-05
Valid Loss:  0.00011959167750319466
Epoch:  181  	Training Loss: 9.767529263626784e-05
Test Loss:  5.931958730798215e-05
Valid Loss:  0.00011943740537390113
Epoch:  182  	Training Loss: 9.761685214471072e-05
Test Loss:  5.893239358556457e-05
Valid Loss:  0.00011904447455890477
Epoch:  183  	Training Loss: 9.751845936989412e-05
Test Loss:  5.881480683456175e-05
Valid Loss:  0.00011886854190379381
Epoch:  184  	Training Loss: 9.746513387653977e-05
Test Loss:  5.8760575484484434e-05
Valid Loss:  0.00011874318443005905
Epoch:  185  	Training Loss: 9.7415701020509e-05
Test Loss:  5.872394103789702e-05
Valid Loss:  0.00011863237159559503
Epoch:  186  	Training Loss: 9.73668647930026e-05
Test Loss:  5.8691686717793345e-05
Valid Loss:  0.0001185251385322772
Epoch:  187  	Training Loss: 9.731914906296879e-05
Test Loss:  5.866131323273294e-05
Valid Loss:  0.00011841975356219336
Epoch:  188  	Training Loss: 9.727133874548599e-05
Test Loss:  5.863156548002735e-05
Valid Loss:  0.0001183163039968349
Epoch:  189  	Training Loss: 9.722441609483212e-05
Test Loss:  5.8602283388609067e-05
Valid Loss:  0.00011821470252471045
Epoch:  190  	Training Loss: 9.717815555632114e-05
Test Loss:  5.857339419890195e-05
Valid Loss:  0.00011811286094598472
Epoch:  191  	Training Loss: 9.713198232930154e-05
Test Loss:  5.8545279898680747e-05
Valid Loss:  0.00011801288201240823
Epoch:  192  	Training Loss: 9.708642028272152e-05
Test Loss:  5.8630517742130905e-05
Valid Loss:  0.0001178725142381154
Epoch:  193  	Training Loss: 9.688572026789188e-05
Test Loss:  5.8630874264054e-05
Valid Loss:  0.00011771972640417516
Epoch:  194  	Training Loss: 9.67104933806695e-05
Test Loss:  5.859207158209756e-05
Valid Loss:  0.00011755053856177256
Epoch:  195  	Training Loss: 9.654174209572375e-05
Test Loss:  5.8533336414257064e-05
Valid Loss:  0.00011736899614334106
Epoch:  196  	Training Loss: 9.637395851314068e-05
Test Loss:  5.844317638548091e-05
Valid Loss:  0.00011711182014551014
Epoch:  197  	Training Loss: 9.61990372161381e-05
Test Loss:  5.833886825712398e-05
Valid Loss:  0.00011686193465720862
Epoch:  198  	Training Loss: 9.602756472304463e-05
Test Loss:  5.823142782901414e-05
Valid Loss:  0.00011661756434477866
Epoch:  199  	Training Loss: 9.585884981788695e-05
Test Loss:  5.812508970848285e-05
Valid Loss:  0.00011637921852525324
Epoch:  200  	Training Loss: 9.569284156896174e-05
Test Loss:  5.802219675388187e-05
Valid Loss:  0.00011615121911745518
Epoch:  201  	Training Loss: 9.553150448482484e-05
Test Loss:  5.792203955934383e-05
Valid Loss:  0.0001159298699349165
Epoch:  202  	Training Loss: 9.537470032228157e-05
Test Loss:  5.620840238407254e-05
Valid Loss:  0.00011308510875096545
Epoch:  203  	Training Loss: 9.205579408444464e-05
Test Loss:  5.451410106616095e-05
Valid Loss:  0.00011032752809114754
Epoch:  204  	Training Loss: 8.899721433408558e-05
Test Loss:  5.2850718930130824e-05
Valid Loss:  0.00010764782200567424
Epoch:  205  	Training Loss: 8.612179226474836e-05
Test Loss:  5.1230890676379204e-05
Valid Loss:  0.00010505787213332951
Epoch:  206  	Training Loss: 8.341956709045917e-05
 41%|████▏     | 207/500 [02:29<02:11,  2.24it/s] 42%|████▏     | 209/500 [02:29<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:35<05:35,  1.16s/it] 43%|████▎     | 213/500 [02:36<03:59,  1.20it/s] 43%|████▎     | 215/500 [02:36<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:36<02:05,  2.26it/s] 44%|████▍     | 219/500 [02:36<01:32,  3.04it/s] 44%|████▍     | 221/500 [02:42<05:27,  1.17s/it] 45%|████▍     | 223/500 [02:42<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:43<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:43<02:01,  2.24it/s] 46%|████▌     | 229/500 [02:43<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:49<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:49<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:49<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:50<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:50<01:27,  3.00it/s] 48%|████▊     | 241/500 [02:56<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:56<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:56<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:56<01:53,  2.22it/s] 50%|████▉     | 249/500 [02:57<01:23,  2.99it/s] 50%|█████     | 251/500 [03:03<04:53,  1.18s/it] 51%|█████     | 253/500 [03:03<03:29,  1.18it/s] 51%|█████     | 255/500 [03:03<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:03<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:03<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:10<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:10<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:10<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:10<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:10<01:18,  2.96it/s] 54%|█████▍    | 271/500 [03:17<04:31,  1.19s/it] 55%|█████▍    | 273/500 [03:17<03:14,  1.17it/s]Test Loss:  4.964816616848111e-05
Valid Loss:  0.00010254166409140453
Epoch:  207  	Training Loss: 8.086365414783359e-05
Test Loss:  4.811026155948639e-05
Valid Loss:  0.00010011080303229392
Epoch:  208  	Training Loss: 7.844258652767166e-05
Test Loss:  4.6603883674833924e-05
Valid Loss:  9.773176134331152e-05
Epoch:  209  	Training Loss: 7.608549640281126e-05
Test Loss:  4.515504406299442e-05
Valid Loss:  9.544358181301504e-05
Epoch:  210  	Training Loss: 7.38504168111831e-05
Test Loss:  4.375814023660496e-05
Valid Loss:  9.324010898126289e-05
Epoch:  211  	Training Loss: 7.172898040153086e-05
Test Loss:  4.2413088522152975e-05
Valid Loss:  9.112036786973476e-05
Epoch:  212  	Training Loss: 6.971119728405029e-05
Test Loss:  4.211374471196905e-05
Valid Loss:  9.081437747227028e-05
Epoch:  213  	Training Loss: 6.963557098060846e-05
Test Loss:  4.203797288937494e-05
Valid Loss:  9.069823136087507e-05
Epoch:  214  	Training Loss: 6.95870621711947e-05
Test Loss:  4.196313602733426e-05
Valid Loss:  9.058635623659939e-05
Epoch:  215  	Training Loss: 6.954664422664791e-05
Test Loss:  4.1906147089321166e-05
Valid Loss:  9.049979416886345e-05
Epoch:  216  	Training Loss: 6.951618706807494e-05
Test Loss:  4.185469151707366e-05
Valid Loss:  9.041688463184983e-05
Epoch:  217  	Training Loss: 6.948789086891338e-05
Test Loss:  4.1808241803664714e-05
Valid Loss:  9.034005051944405e-05
Epoch:  218  	Training Loss: 6.946116627659649e-05
Test Loss:  4.176320362603292e-05
Valid Loss:  9.026474435813725e-05
Epoch:  219  	Training Loss: 6.943575863260776e-05
Test Loss:  4.1721992602106184e-05
Valid Loss:  9.019687422551215e-05
Epoch:  220  	Training Loss: 6.941292667761445e-05
Test Loss:  4.168476152699441e-05
Valid Loss:  9.013541421154514e-05
Epoch:  221  	Training Loss: 6.93910988047719e-05
Test Loss:  4.164941856288351e-05
Valid Loss:  9.007561311591417e-05
Epoch:  222  	Training Loss: 6.937033322174102e-05
Test Loss:  4.1175633668899536e-05
Valid Loss:  8.916534716263413e-05
Epoch:  223  	Training Loss: 6.885961192892864e-05
Test Loss:  4.0968247049022466e-05
Valid Loss:  8.874112972989678e-05
Epoch:  224  	Training Loss: 6.862010195618495e-05
Test Loss:  4.083779640495777e-05
Valid Loss:  8.850853191688657e-05
Epoch:  225  	Training Loss: 6.84769474901259e-05
Test Loss:  4.072766751050949e-05
Valid Loss:  8.835289190756157e-05
Epoch:  226  	Training Loss: 6.83655816828832e-05
Test Loss:  4.063141022925265e-05
Valid Loss:  8.822744712233543e-05
Epoch:  227  	Training Loss: 6.826451135566458e-05
Test Loss:  4.054051896673627e-05
Valid Loss:  8.81197047419846e-05
Epoch:  228  	Training Loss: 6.817108805989847e-05
Test Loss:  4.045544847031124e-05
Valid Loss:  8.802251250017434e-05
Epoch:  229  	Training Loss: 6.80874363752082e-05
Test Loss:  4.037571488879621e-05
Valid Loss:  8.794830500846729e-05
Epoch:  230  	Training Loss: 6.801589915994555e-05
Test Loss:  4.0301303670275956e-05
Valid Loss:  8.788042759988457e-05
Epoch:  231  	Training Loss: 6.79518561810255e-05
Test Loss:  4.023282599519007e-05
Valid Loss:  8.781307406025007e-05
Epoch:  232  	Training Loss: 6.789179315092042e-05
Test Loss:  3.968017335864715e-05
Valid Loss:  8.734964649192989e-05
Epoch:  233  	Training Loss: 6.770969775971025e-05
Test Loss:  3.944742275052704e-05
Valid Loss:  8.714877185411751e-05
Epoch:  234  	Training Loss: 6.761970871593803e-05
Test Loss:  3.9350081351585686e-05
Valid Loss:  8.705595973879099e-05
Epoch:  235  	Training Loss: 6.755465437890962e-05
Test Loss:  3.9313883462455124e-05
Valid Loss:  8.701122715137899e-05
Epoch:  236  	Training Loss: 6.749659951310605e-05
Test Loss:  3.9305563404923305e-05
Valid Loss:  8.698736201040447e-05
Epoch:  237  	Training Loss: 6.744220445398241e-05
Test Loss:  3.931007086066529e-05
Valid Loss:  8.697493467479944e-05
Epoch:  238  	Training Loss: 6.738976662745699e-05
Test Loss:  3.9320235373452306e-05
Valid Loss:  8.696624718140811e-05
Epoch:  239  	Training Loss: 6.733895861543715e-05
Test Loss:  3.9332870073849335e-05
Valid Loss:  8.695964061189443e-05
Epoch:  240  	Training Loss: 6.72893802402541e-05
Test Loss:  3.9345693949144334e-05
Valid Loss:  8.695315773366019e-05
Epoch:  241  	Training Loss: 6.724154081894085e-05
Test Loss:  3.935783024644479e-05
Valid Loss:  8.694693678990006e-05
Epoch:  242  	Training Loss: 6.719439988955855e-05
Test Loss:  3.937678411602974e-05
Valid Loss:  8.69236173457466e-05
Epoch:  243  	Training Loss: 6.715956260450184e-05
Test Loss:  3.9405749703291804e-05
Valid Loss:  8.691167022334412e-05
Epoch:  244  	Training Loss: 6.712893082294613e-05
Test Loss:  3.9438586100004613e-05
Valid Loss:  8.690563117852435e-05
Epoch:  245  	Training Loss: 6.710177694913e-05
Test Loss:  3.947335062548518e-05
Valid Loss:  8.690352842677385e-05
Epoch:  246  	Training Loss: 6.707814463879913e-05
Test Loss:  3.950790414819494e-05
Valid Loss:  8.690381946507841e-05
Epoch:  247  	Training Loss: 6.70570952934213e-05
Test Loss:  3.954181738663465e-05
Valid Loss:  8.690598770044744e-05
Epoch:  248  	Training Loss: 6.703838153043762e-05
Test Loss:  3.9574482798343524e-05
Valid Loss:  8.690943650435656e-05
Epoch:  249  	Training Loss: 6.702182145090774e-05
Test Loss:  3.9605503843631595e-05
Valid Loss:  8.691233233548701e-05
Epoch:  250  	Training Loss: 6.700700032524765e-05
Test Loss:  3.963552080676891e-05
Valid Loss:  8.691680704941973e-05
Epoch:  251  	Training Loss: 6.699393998133019e-05
Test Loss:  3.966346412198618e-05
Valid Loss:  8.69206924107857e-05
Epoch:  252  	Training Loss: 6.698255310766399e-05
Test Loss:  3.764191205846146e-05
Valid Loss:  8.29269556561485e-05
Epoch:  253  	Training Loss: 6.291692261584103e-05
Test Loss:  3.580888005672023e-05
Valid Loss:  7.941098738228902e-05
Epoch:  254  	Training Loss: 5.939126276643947e-05
Test Loss:  3.411661964491941e-05
Valid Loss:  7.620953692821786e-05
Epoch:  255  	Training Loss: 5.6287732149939984e-05
Test Loss:  3.255031697335653e-05
Valid Loss:  7.326359627768397e-05
Epoch:  256  	Training Loss: 5.3540927183348686e-05
Test Loss:  3.109271347057074e-05
Valid Loss:  7.04838676028885e-05
Epoch:  257  	Training Loss: 5.105791933601722e-05
Test Loss:  2.9734794225078076e-05
Valid Loss:  6.788954488001764e-05
Epoch:  258  	Training Loss: 4.88037258037366e-05
Test Loss:  2.848678377631586e-05
Valid Loss:  6.549136014655232e-05
Epoch:  259  	Training Loss: 4.680053098127246e-05
Test Loss:  2.734331246756483e-05
Valid Loss:  6.327220762614161e-05
Epoch:  260  	Training Loss: 4.497677582548931e-05
Test Loss:  2.628070615173783e-05
Valid Loss:  6.117926386650652e-05
Epoch:  261  	Training Loss: 4.33010354754515e-05
Test Loss:  2.5313849619124085e-05
Valid Loss:  5.925157529418357e-05
Epoch:  262  	Training Loss: 4.180562973488122e-05
Test Loss:  2.4835087970132008e-05
Valid Loss:  5.8850124332821e-05
Epoch:  263  	Training Loss: 4.169028397882357e-05
Test Loss:  2.4561591999372467e-05
Valid Loss:  5.8578716561896726e-05
Epoch:  264  	Training Loss: 4.163834819337353e-05
Test Loss:  2.4378077796427533e-05
Valid Loss:  5.833082104800269e-05
Epoch:  265  	Training Loss: 4.1598679672461e-05
Test Loss:  2.42441710724961e-05
Valid Loss:  5.813697862322442e-05
Epoch:  266  	Training Loss: 4.157015064265579e-05
Test Loss:  2.413885886198841e-05
Valid Loss:  5.794211756438017e-05
Epoch:  267  	Training Loss: 4.153726331423968e-05
Test Loss:  2.4052951630437747e-05
Valid Loss:  5.7786623074207455e-05
Epoch:  268  	Training Loss: 4.151230677962303e-05
Test Loss:  2.398188917140942e-05
Valid Loss:  5.765815876657143e-05
Epoch:  269  	Training Loss: 4.149195592617616e-05
Test Loss:  2.3925938876345754e-05
Valid Loss:  5.755261008744128e-05
Epoch:  270  	Training Loss: 4.147454819758423e-05
Test Loss:  2.388132270425558e-05
Valid Loss:  5.746501119574532e-05
Epoch:  271  	Training Loss: 4.145897401031107e-05
Test Loss:  2.3846609110478312e-05
Valid Loss:  5.739060361520387e-05
Epoch:  272  	Training Loss: 4.144450576859526e-05
Test Loss:  2.3789954866515473e-05
Valid Loss:  5.726508243242279e-05
Epoch:  273  	Training Loss: 4.1386760130990297e-05
Test Loss:  2.374163523199968e-05
Valid Loss:  5.713911377824843e-05
Epoch:  274  	Training Loss: 4.132456524530426e-05
Test Loss:   55%|█████▌    | 275/500 [03:17<02:19,  1.61it/s] 55%|█████▌    | 277/500 [03:17<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:17<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:23<04:18,  1.18s/it] 57%|█████▋    | 283/500 [03:24<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:24<02:12,  1.63it/s] 57%|█████▋    | 287/500 [03:24<01:35,  2.22it/s] 58%|█████▊    | 289/500 [03:24<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:30<04:03,  1.16s/it] 59%|█████▊    | 293/500 [03:30<02:53,  1.20it/s] 59%|█████▉    | 295/500 [03:31<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:31<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:31<01:06,  3.02it/s] 60%|██████    | 301/500 [03:37<03:53,  1.17s/it] 61%|██████    | 303/500 [03:37<02:45,  1.19it/s] 61%|██████    | 305/500 [03:37<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:37<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:38<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:44<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:44<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:44<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:44<01:21,  2.23it/s] 64%|██████▍   | 319/500 [03:44<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:51<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:51<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:51<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:51<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:51<00:56,  3.01it/s] 66%|██████▌   | 331/500 [03:58<03:18,  1.18s/it] 67%|██████▋   | 333/500 [03:58<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:58<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:58<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:58<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:04<03:05,  1.16s/it]2.3695494746789336e-05
Valid Loss:  5.701643385691568e-05
Epoch:  275  	Training Loss: 4.126386920688674e-05
Test Loss:  2.3650829461985268e-05
Valid Loss:  5.6896093155955896e-05
Epoch:  276  	Training Loss: 4.1204497392755e-05
Test Loss:  2.3607146431459114e-05
Valid Loss:  5.677804438164458e-05
Epoch:  277  	Training Loss: 4.114602052140981e-05
Test Loss:  2.3564138246001676e-05
Valid Loss:  5.666215292876586e-05
Epoch:  278  	Training Loss: 4.108930443180725e-05
Test Loss:  2.3521730327047408e-05
Valid Loss:  5.654759661410935e-05
Epoch:  279  	Training Loss: 4.1033657907973975e-05
Test Loss:  2.3480679374188185e-05
Valid Loss:  5.6435201258864254e-05
Epoch:  280  	Training Loss: 4.097915370948613e-05
Test Loss:  2.3440703444066457e-05
Valid Loss:  5.632494139717892e-05
Epoch:  281  	Training Loss: 4.0925940993474796e-05
Test Loss:  2.3401647922582924e-05
Valid Loss:  5.621676245937124e-05
Epoch:  282  	Training Loss: 4.087392153451219e-05
Test Loss:  2.252146259706933e-05
Valid Loss:  5.438886000774801e-05
Epoch:  283  	Training Loss: 3.9485730667365715e-05
Test Loss:  2.1800009562866762e-05
Valid Loss:  5.272669659461826e-05
Epoch:  284  	Training Loss: 3.818392724497244e-05
Test Loss:  2.10669659281848e-05
Valid Loss:  5.1102397264912724e-05
Epoch:  285  	Training Loss: 3.696142812259495e-05
Test Loss:  2.0552066416712478e-05
Valid Loss:  4.957987039233558e-05
Epoch:  286  	Training Loss: 3.584586374927312e-05
Test Loss:  2.030941323027946e-05
Valid Loss:  4.818687739316374e-05
Epoch:  287  	Training Loss: 3.490808012429625e-05
Test Loss:  2.0156294340267777e-05
Valid Loss:  4.69369551865384e-05
Epoch:  288  	Training Loss: 3.408571865293197e-05
Test Loss:  1.9997147319372743e-05
Valid Loss:  4.5731241698376834e-05
Epoch:  289  	Training Loss: 3.3302927477052435e-05
Test Loss:  1.985248673008755e-05
Valid Loss:  4.458255716599524e-05
Epoch:  290  	Training Loss: 3.2629453926347196e-05
Test Loss:  1.971849997062236e-05
Valid Loss:  4.363298285170458e-05
Epoch:  291  	Training Loss: 3.211029616068117e-05
Test Loss:  1.9596955098677427e-05
Valid Loss:  4.272150545148179e-05
Epoch:  292  	Training Loss: 3.161047789035365e-05
Test Loss:  1.956135020009242e-05
Valid Loss:  4.253034421708435e-05
Epoch:  293  	Training Loss: 3.154490696033463e-05
Test Loss:  1.9455561414361e-05
Valid Loss:  4.236026870785281e-05
Epoch:  294  	Training Loss: 3.149837357341312e-05
Test Loss:  1.9352657545823604e-05
Valid Loss:  4.220878327032551e-05
Epoch:  295  	Training Loss: 3.1456147553399205e-05
Test Loss:  1.925959440995939e-05
Valid Loss:  4.207402525935322e-05
Epoch:  296  	Training Loss: 3.1417468562722206e-05
Test Loss:  1.917685949592851e-05
Valid Loss:  4.195246583549306e-05
Epoch:  297  	Training Loss: 3.138149622827768e-05
Test Loss:  1.910235732793808e-05
Valid Loss:  4.1843391954898834e-05
Epoch:  298  	Training Loss: 3.1347983167506754e-05
Test Loss:  1.9035265722777694e-05
Valid Loss:  4.174337300355546e-05
Epoch:  299  	Training Loss: 3.1316259992308915e-05
Test Loss:  1.8974136764882132e-05
Valid Loss:  4.165171048953198e-05
Epoch:  300  	Training Loss: 3.12862430291716e-05
Test Loss:  1.89186139323283e-05
Valid Loss:  4.156659997534007e-05
Epoch:  301  	Training Loss: 3.1257513910532e-05
Test Loss:  1.8867573089664802e-05
Valid Loss:  4.1487372072879225e-05
Epoch:  302  	Training Loss: 3.1230323656927794e-05
Test Loss:  1.862367571447976e-05
Valid Loss:  4.1227824112866074e-05
Epoch:  303  	Training Loss: 3.113720958936028e-05
Test Loss:  1.8548460502643138e-05
Valid Loss:  4.106966662220657e-05
Epoch:  304  	Training Loss: 3.105971700279042e-05
Test Loss:  1.8392180209048092e-05
Valid Loss:  4.0885526686906815e-05
Epoch:  305  	Training Loss: 3.098931483691558e-05
Test Loss:  1.830976725614164e-05
Valid Loss:  4.074999742442742e-05
Epoch:  306  	Training Loss: 3.092498809564859e-05
Test Loss:  1.819566750782542e-05
Valid Loss:  4.060909850522876e-05
Epoch:  307  	Training Loss: 3.0866161978337914e-05
Test Loss:  1.8118058505933732e-05
Valid Loss:  4.049447306897491e-05
Epoch:  308  	Training Loss: 3.081161412410438e-05
Test Loss:  1.8030881619779393e-05
Valid Loss:  4.038320912513882e-05
Epoch:  309  	Training Loss: 3.0760733352508396e-05
Test Loss:  1.7962176571018063e-05
Valid Loss:  4.028735565952957e-05
Epoch:  310  	Training Loss: 3.07141053781379e-05
Test Loss:  1.789050475053955e-05
Valid Loss:  4.019710831926204e-05
Epoch:  311  	Training Loss: 3.067290526814759e-05
Test Loss:  1.783347033779137e-05
Valid Loss:  4.011908458778635e-05
Epoch:  312  	Training Loss: 3.06354122585617e-05
Test Loss:  1.7868111171992496e-05
Valid Loss:  3.936830398743041e-05
Epoch:  313  	Training Loss: 3.0152938052196987e-05
Test Loss:  1.780880120350048e-05
Valid Loss:  3.858706259052269e-05
Epoch:  314  	Training Loss: 2.9690154406125657e-05
Test Loss:  1.78026566572953e-05
Valid Loss:  3.786317029152997e-05
Epoch:  315  	Training Loss: 2.924555701611098e-05
Test Loss:  1.7756003217073157e-05
Valid Loss:  3.713950718520209e-05
Epoch:  316  	Training Loss: 2.8818305509048514e-05
Test Loss:  1.7730111721903086e-05
Valid Loss:  3.6452143831411377e-05
Epoch:  317  	Training Loss: 2.845250128302723e-05
Test Loss:  1.7689026208245195e-05
Valid Loss:  3.5862707591149956e-05
Epoch:  318  	Training Loss: 2.8146874683443457e-05
Test Loss:  1.765610431903042e-05
Valid Loss:  3.5295914130983874e-05
Epoch:  319  	Training Loss: 2.7844736905535683e-05
Test Loss:  1.7614673197385855e-05
Valid Loss:  3.4739336115308106e-05
Epoch:  320  	Training Loss: 2.7551650418899953e-05
Test Loss:  1.75789919012459e-05
Valid Loss:  3.420128268771805e-05
Epoch:  321  	Training Loss: 2.726768798311241e-05
Test Loss:  1.75399018189637e-05
Valid Loss:  3.367596218595281e-05
Epoch:  322  	Training Loss: 2.6992369384970516e-05
Test Loss:  1.7487796867499128e-05
Valid Loss:  3.358444519108161e-05
Epoch:  323  	Training Loss: 2.6958823582390323e-05
Test Loss:  1.7511933037894778e-05
Valid Loss:  3.354127693455666e-05
Epoch:  324  	Training Loss: 2.6926714781438932e-05
Test Loss:  1.750402407196816e-05
Valid Loss:  3.348020254634321e-05
Epoch:  325  	Training Loss: 2.689588291104883e-05
Test Loss:  1.7511982150608674e-05
Valid Loss:  3.343137723277323e-05
Epoch:  326  	Training Loss: 2.6865838663070463e-05
Test Loss:  1.7514090359327383e-05
Valid Loss:  3.3380558306816965e-05
Epoch:  327  	Training Loss: 2.683681304915808e-05
Test Loss:  1.7519399989396334e-05
Valid Loss:  3.3333562896586955e-05
Epoch:  328  	Training Loss: 2.6808635084307753e-05
Test Loss:  1.7522386769996956e-05
Valid Loss:  3.328569800942205e-05
Epoch:  329  	Training Loss: 2.678130658750888e-05
Test Loss:  1.7526188457850367e-05
Valid Loss:  3.323943747091107e-05
Epoch:  330  	Training Loss: 2.6755002181744203e-05
Test Loss:  1.7530148397781886e-05
Valid Loss:  3.319445386296138e-05
Epoch:  331  	Training Loss: 2.672925438673701e-05
Test Loss:  1.753418837324716e-05
Valid Loss:  3.315023423056118e-05
Epoch:  332  	Training Loss: 2.6704316042014398e-05
Test Loss:  1.7485224816482514e-05
Valid Loss:  3.3077252737712115e-05
Epoch:  333  	Training Loss: 2.6695859560277313e-05
Test Loss:  1.7460648450651206e-05
Valid Loss:  3.302488767076284e-05
Epoch:  334  	Training Loss: 2.668925662874244e-05
Test Loss:  1.7434387700632215e-05
Valid Loss:  3.297624789411202e-05
Epoch:  335  	Training Loss: 2.6683328542276286e-05
Test Loss:  1.7412196029908955e-05
Valid Loss:  3.293401459814049e-05
Epoch:  336  	Training Loss: 2.6678137146518566e-05
Test Loss:  1.739215076668188e-05
Valid Loss:  3.289569212938659e-05
Epoch:  337  	Training Loss: 2.6673138563637622e-05
Test Loss:  1.7373058653902262e-05
Valid Loss:  3.286074934294447e-05
Epoch:  338  	Training Loss: 2.666853106347844e-05
Test Loss:  1.7355490854242817e-05
Valid Loss:  3.282907709944993e-05
Epoch:  339  	Training Loss: 2.6664061806513928e-05
Test Loss:  1.7339832993457094e-05
Valid Loss:  3.28009991790168e-05
Epoch:  340  	Training Loss: 2.6660145522328094e-05
Test Loss:  1.732484088279307e-05
Valid Loss:  3.2775562431197613e-05
Epoch:  341  	Training Loss: 2.665638385224156e-05
Test Loss:  1.7311482224613428e-05
Valid Loss:  3.275342533015646e-05
 69%|██████▊   | 343/500 [04:04<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:05<01:33,  1.65it/s] 69%|██████▉   | 347/500 [04:05<01:07,  2.26it/s] 70%|██████▉   | 349/500 [04:05<00:49,  3.03it/s] 70%|███████   | 351/500 [04:11<02:55,  1.18s/it] 71%|███████   | 353/500 [04:11<02:04,  1.18it/s] 71%|███████   | 355/500 [04:11<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:12<01:05,  2.19it/s] 72%|███████▏  | 359/500 [04:12<00:48,  2.90it/s] 72%|███████▏  | 361/500 [04:18<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:18<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:18<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:18<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:19<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:25<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:25<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:25<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:25<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:25<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:32<02:21,  1.19s/it] 76%|███████▋  | 382/500 [04:32<01:57,  1.00it/s] 77%|███████▋  | 384/500 [04:32<01:19,  1.45it/s] 77%|███████▋  | 386/500 [04:32<00:55,  2.06it/s] 78%|███████▊  | 388/500 [04:32<00:39,  2.83it/s] 78%|███████▊  | 390/500 [04:33<00:29,  3.77it/s] 78%|███████▊  | 392/500 [04:39<02:05,  1.16s/it] 79%|███████▉  | 394/500 [04:39<01:27,  1.21it/s] 79%|███████▉  | 396/500 [04:39<01:02,  1.68it/s] 80%|███████▉  | 398/500 [04:39<00:44,  2.29it/s] 80%|████████  | 400/500 [04:39<00:32,  3.09it/s] 80%|████████  | 402/500 [04:46<01:55,  1.17s/it] 81%|████████  | 404/500 [04:46<01:20,  1.19it/s] 81%|████████  | 406/500 [04:46<00:57,  1.64it/s] 82%|████████▏ | 408/500 [04:46<00:41,  2.23it/s]Epoch:  342  	Training Loss: 2.665278771019075e-05
Test Loss:  1.7322443454759195e-05
Valid Loss:  3.274888877058402e-05
Epoch:  343  	Training Loss: 2.6644751415005885e-05
Test Loss:  1.7323372958344407e-05
Valid Loss:  3.274229675298557e-05
Epoch:  344  	Training Loss: 2.663724808371626e-05
Test Loss:  1.7320664483122528e-05
Valid Loss:  3.273393667768687e-05
Epoch:  345  	Training Loss: 2.6630239517544396e-05
Test Loss:  1.731630982249044e-05
Valid Loss:  3.27233319694642e-05
Epoch:  346  	Training Loss: 2.6623332814779133e-05
Test Loss:  1.731126758386381e-05
Valid Loss:  3.271153036621399e-05
Epoch:  347  	Training Loss: 2.6616584364091977e-05
Test Loss:  1.730571784719359e-05
Valid Loss:  3.269808803452179e-05
Epoch:  348  	Training Loss: 2.6610105123836547e-05
Test Loss:  1.7299425962846726e-05
Valid Loss:  3.2683958124835044e-05
Epoch:  349  	Training Loss: 2.6603640435496345e-05
Test Loss:  1.7293124983552843e-05
Valid Loss:  3.2668835046933964e-05
Epoch:  350  	Training Loss: 2.659751771716401e-05
Test Loss:  1.7286329239141196e-05
Valid Loss:  3.2652871595928445e-05
Epoch:  351  	Training Loss: 2.659141864569392e-05
Test Loss:  1.727972994558513e-05
Valid Loss:  3.2636460673529655e-05
Epoch:  352  	Training Loss: 2.6585292289382778e-05
Test Loss:  1.7232181562576443e-05
Valid Loss:  3.2110270694829524e-05
Epoch:  353  	Training Loss: 2.6311681722290814e-05
Test Loss:  1.720647378533613e-05
Valid Loss:  3.16156838380266e-05
Epoch:  354  	Training Loss: 2.6044799597002566e-05
Test Loss:  1.718015846563503e-05
Valid Loss:  3.112853300990537e-05
Epoch:  355  	Training Loss: 2.5781881049624644e-05
Test Loss:  1.715253347356338e-05
Valid Loss:  3.065418059122749e-05
Epoch:  356  	Training Loss: 2.552616388129536e-05
Test Loss:  1.7125681551988237e-05
Valid Loss:  3.0293887903098948e-05
Epoch:  357  	Training Loss: 2.5285706215072423e-05
Test Loss:  1.7099579054047354e-05
Valid Loss:  3.0069673812249675e-05
Epoch:  358  	Training Loss: 2.5122941224253736e-05
Test Loss:  1.7075613868655637e-05
Valid Loss:  2.9851851650164463e-05
Epoch:  359  	Training Loss: 2.4992852559080347e-05
Test Loss:  1.705281283648219e-05
Valid Loss:  2.9685284971492365e-05
Epoch:  360  	Training Loss: 2.48938213189831e-05
Test Loss:  1.7031274182954803e-05
Valid Loss:  2.952216163976118e-05
Epoch:  361  	Training Loss: 2.4796339857857674e-05
Test Loss:  1.7010395822580904e-05
Valid Loss:  2.9361588531173766e-05
Epoch:  362  	Training Loss: 2.4700235371710733e-05
Test Loss:  1.7045817003236152e-05
Valid Loss:  2.9351302146096714e-05
Epoch:  363  	Training Loss: 2.466924888722133e-05
Test Loss:  1.7070087778847665e-05
Valid Loss:  2.9341017580009066e-05
Epoch:  364  	Training Loss: 2.4644214136060327e-05
Test Loss:  1.708569652691949e-05
Valid Loss:  2.9329145036172122e-05
Epoch:  365  	Training Loss: 2.4621860575280152e-05
Test Loss:  1.7095615476137027e-05
Valid Loss:  2.9316577638383023e-05
Epoch:  366  	Training Loss: 2.4600680262665264e-05
Test Loss:  1.7101832781918347e-05
Valid Loss:  2.930344271590002e-05
Epoch:  367  	Training Loss: 2.4580356694059446e-05
Test Loss:  1.710521428321954e-05
Valid Loss:  2.9289820304256864e-05
Epoch:  368  	Training Loss: 2.456064976286143e-05
Test Loss:  1.7107100575231016e-05
Valid Loss:  2.927659261331428e-05
Epoch:  369  	Training Loss: 2.4541470338590443e-05
Test Loss:  1.7107337043853477e-05
Valid Loss:  2.9263113901834004e-05
Epoch:  370  	Training Loss: 2.4522521925973706e-05
Test Loss:  1.7107151506934315e-05
Valid Loss:  2.9249438739498146e-05
Epoch:  371  	Training Loss: 2.4504166503902525e-05
Test Loss:  1.7106509403674863e-05
Valid Loss:  2.9236834961920977e-05
Epoch:  372  	Training Loss: 2.448634768370539e-05
Test Loss:  1.7030966773745604e-05
Valid Loss:  2.910920920839999e-05
Epoch:  373  	Training Loss: 2.444093297526706e-05
Test Loss:  1.699617314443458e-05
Valid Loss:  2.8998536436120048e-05
Epoch:  374  	Training Loss: 2.440046773699578e-05
Test Loss:  1.6974949176074006e-05
Valid Loss:  2.889582174248062e-05
Epoch:  375  	Training Loss: 2.43619524553651e-05
Test Loss:  1.696052640909329e-05
Valid Loss:  2.8799606297980063e-05
Epoch:  376  	Training Loss: 2.4324250261997804e-05
Test Loss:  1.6948559277807362e-05
Valid Loss:  2.870767275453545e-05
Epoch:  377  	Training Loss: 2.4291397494380362e-05
Test Loss:  1.6939007764449343e-05
Valid Loss:  2.866035902115982e-05
Epoch:  378  	Training Loss: 2.4275286705233157e-05
Test Loss:  1.6931307982304133e-05
Valid Loss:  2.861702159862034e-05
Epoch:  379  	Training Loss: 2.425962156848982e-05
Test Loss:  1.6925090676522814e-05
Valid Loss:  2.8577196644619107e-05
Epoch:  380  	Training Loss: 2.4244382075266913e-05
Test Loss:  1.692053410806693e-05
Valid Loss:  2.8540147468447685e-05
Epoch:  381  	Training Loss: 2.422943725832738e-05
Test Loss:  1.6916494132601656e-05
Valid Loss:  2.8505175578175113e-05
Epoch:  382  	Training Loss: 2.4214859877247363e-05
Test Loss:  1.693969352345448e-05
Valid Loss:  2.849495103873778e-05
Epoch:  383  	Training Loss: 2.4164372007362545e-05
Test Loss:  1.6947233234532177e-05
Valid Loss:  2.847021823981777e-05
Epoch:  384  	Training Loss: 2.4115541236824356e-05
Test Loss:  1.694945603958331e-05
Valid Loss:  2.8441094400477596e-05
Epoch:  385  	Training Loss: 2.4067248887149617e-05
Test Loss:  1.6949285054579377e-05
Valid Loss:  2.841002969944384e-05
Epoch:  386  	Training Loss: 2.4019622287596576e-05
Test Loss:  1.6947995391092263e-05
Valid Loss:  2.8378464776324108e-05
Epoch:  387  	Training Loss: 2.3972967028385028e-05
Test Loss:  1.6946050891419873e-05
Valid Loss:  2.834755287040025e-05
Epoch:  388  	Training Loss: 2.3927257643663324e-05
Test Loss:  1.6942072761594318e-05
Valid Loss:  2.8316408133832738e-05
Epoch:  389  	Training Loss: 2.3882519599283114e-05
Test Loss:  1.6937521650106646e-05
Valid Loss:  2.828588185366243e-05
Epoch:  390  	Training Loss: 2.3838623746996745e-05
Test Loss:  1.693266494839918e-05
Valid Loss:  2.8254882636247203e-05
Epoch:  391  	Training Loss: 2.3795419110683724e-05
Test Loss:  1.692757723503746e-05
Valid Loss:  2.822475289576687e-05
Epoch:  392  	Training Loss: 2.3753073037369177e-05
Test Loss:  1.6994212273857556e-05
Valid Loss:  2.8196562197990716e-05
Epoch:  393  	Training Loss: 2.3716547730145976e-05
Test Loss:  1.6994543329929e-05
Valid Loss:  2.8179505534353666e-05
Epoch:  394  	Training Loss: 2.3692820832366124e-05
Test Loss:  1.6982339730020612e-05
Valid Loss:  2.8159574867459014e-05
Epoch:  395  	Training Loss: 2.36701343965251e-05
Test Loss:  1.6967069313977845e-05
Valid Loss:  2.8137676054029725e-05
Epoch:  396  	Training Loss: 2.3648184651392512e-05
Test Loss:  1.6950254575931467e-05
Valid Loss:  2.811519880197011e-05
Epoch:  397  	Training Loss: 2.3627691916772164e-05
Test Loss:  1.6934858649619855e-05
Valid Loss:  2.8093019864172675e-05
Epoch:  398  	Training Loss: 2.3607926777913235e-05
Test Loss:  1.6921607311815023e-05
Valid Loss:  2.8071088308934122e-05
Epoch:  399  	Training Loss: 2.358876372454688e-05
Test Loss:  1.6909245459828526e-05
Valid Loss:  2.804813630064018e-05
Epoch:  400  	Training Loss: 2.356977347517386e-05
Test Loss:  1.6896974557312205e-05
Valid Loss:  2.8024573111906648e-05
Epoch:  401  	Training Loss: 2.3551292542833835e-05
Test Loss:  1.6885463992366567e-05
Valid Loss:  2.8001937607768923e-05
Epoch:  402  	Training Loss: 2.3533426428912207e-05
Test Loss:  1.6592828615102917e-05
Valid Loss:  2.7749189030146226e-05
Epoch:  403  	Training Loss: 2.346352266613394e-05
Test Loss:  1.6822625184431672e-05
Valid Loss:  2.7914145903196186e-05
Epoch:  404  	Training Loss: 2.339551065233536e-05
Test Loss:  1.65796882356517e-05
Valid Loss:  2.7697704354068264e-05
Epoch:  405  	Training Loss: 2.3329121177084744e-05
Test Loss:  1.675275416346267e-05
Valid Loss:  2.7818368835141882e-05
Epoch:  406  	Training Loss: 2.3263310140464455e-05
Test Loss:  1.6553589375689626e-05
Valid Loss:  2.763343036349397e-05
Epoch:  407  	Training Loss: 2.319718259968795e-05
Test Loss:  1.668272125243675e-05
Valid Loss:  2.7718573619495146e-05
Epoch:  408  	Training Loss: 2.3130716726882383e-05
Test Loss:  1.651557431614492e-05
Valid Loss:  2.7560048692976125e-05
 82%|████████▏ | 410/500 [04:46<00:29,  3.00it/s] 82%|████████▏ | 412/500 [04:52<01:43,  1.17s/it] 83%|████████▎ | 414/500 [04:53<01:12,  1.19it/s] 83%|████████▎ | 416/500 [04:53<00:50,  1.65it/s] 84%|████████▎ | 418/500 [04:53<00:36,  2.25it/s] 84%|████████▍ | 420/500 [04:53<00:26,  3.02it/s] 84%|████████▍ | 422/500 [04:59<01:30,  1.17s/it] 85%|████████▍ | 424/500 [04:59<01:03,  1.20it/s] 85%|████████▌ | 426/500 [05:00<00:45,  1.64it/s] 86%|████████▌ | 428/500 [05:00<00:32,  2.24it/s] 86%|████████▌ | 430/500 [05:00<00:23,  3.01it/s] 86%|████████▋ | 432/500 [05:06<01:18,  1.16s/it] 87%|████████▋ | 434/500 [05:06<00:54,  1.21it/s] 87%|████████▋ | 436/500 [05:06<00:38,  1.67it/s] 88%|████████▊ | 438/500 [05:06<00:27,  2.27it/s] 88%|████████▊ | 440/500 [05:06<00:19,  3.05it/s] 88%|████████▊ | 442/500 [05:13<01:07,  1.16s/it] 89%|████████▉ | 444/500 [05:13<00:46,  1.20it/s] 89%|████████▉ | 446/500 [05:13<00:32,  1.66it/s] 90%|████████▉ | 448/500 [05:13<00:22,  2.26it/s] 90%|█████████ | 450/500 [05:13<00:16,  3.03it/s] 90%|█████████ | 452/500 [05:20<00:56,  1.18s/it] 91%|█████████ | 454/500 [05:20<00:38,  1.19it/s] 91%|█████████ | 456/500 [05:20<00:26,  1.64it/s] 92%|█████████▏| 458/500 [05:20<00:18,  2.22it/s] 92%|█████████▏| 460/500 [05:20<00:13,  2.97it/s] 92%|█████████▏| 462/500 [05:26<00:44,  1.17s/it] 93%|█████████▎| 464/500 [05:26<00:30,  1.19it/s] 93%|█████████▎| 466/500 [05:27<00:20,  1.65it/s] 94%|█████████▎| 468/500 [05:27<00:14,  2.25it/s] 94%|█████████▍| 470/500 [05:27<00:09,  3.02it/s] 94%|█████████▍| 472/500 [05:33<00:33,  1.20s/it] 95%|█████████▍| 474/500 [05:33<00:22,  1.16it/s]Epoch:  409  	Training Loss: 2.3061693354975432e-05
Test Loss:  1.660248017287813e-05
Valid Loss:  2.7615620638243854e-05
Epoch:  410  	Training Loss: 2.2994065147941e-05
Test Loss:  1.6462352505186573e-05
Valid Loss:  2.7482950827106833e-05
Epoch:  411  	Training Loss: 2.292742283316329e-05
Test Loss:  1.6526133549632505e-05
Valid Loss:  2.7522128220880404e-05
Epoch:  412  	Training Loss: 2.2861859179101884e-05
Test Loss:  1.654801963013597e-05
Valid Loss:  2.7507303457241505e-05
Epoch:  413  	Training Loss: 2.2852153051644564e-05
Test Loss:  1.6558718925807625e-05
Valid Loss:  2.7503136152517982e-05
Epoch:  414  	Training Loss: 2.2844593331683427e-05
Test Loss:  1.6564537872909568e-05
Valid Loss:  2.7502077500685118e-05
Epoch:  415  	Training Loss: 2.2837444703327492e-05
Test Loss:  1.656703170738183e-05
Valid Loss:  2.7502235752763227e-05
Epoch:  416  	Training Loss: 2.2830618036095984e-05
Test Loss:  1.6567948478041217e-05
Valid Loss:  2.750198109424673e-05
Epoch:  417  	Training Loss: 2.2824053303338587e-05
Test Loss:  1.6568163118790835e-05
Valid Loss:  2.7501366275828332e-05
Epoch:  418  	Training Loss: 2.2817628632765263e-05
Test Loss:  1.6567746570217423e-05
Valid Loss:  2.7499496354721487e-05
Epoch:  419  	Training Loss: 2.281142951687798e-05
Test Loss:  1.6566871636314318e-05
Valid Loss:  2.749692248471547e-05
Epoch:  420  	Training Loss: 2.280537228216417e-05
Test Loss:  1.6565925761824474e-05
Valid Loss:  2.7493770176079124e-05
Epoch:  421  	Training Loss: 2.2799453290645033e-05
Test Loss:  1.6564670659136027e-05
Valid Loss:  2.7489604690345004e-05
Epoch:  422  	Training Loss: 2.279376712976955e-05
Test Loss:  1.644925941945985e-05
Valid Loss:  2.7407060770201497e-05
Epoch:  423  	Training Loss: 2.2769381757825613e-05
Test Loss:  1.6422294720541686e-05
Valid Loss:  2.7374864657758735e-05
Epoch:  424  	Training Loss: 2.2753540179110132e-05
Test Loss:  1.6415348000009544e-05
Valid Loss:  2.7354724807082675e-05
Epoch:  425  	Training Loss: 2.2738306142855436e-05
Test Loss:  1.6412906916229986e-05
Valid Loss:  2.733811197686009e-05
Epoch:  426  	Training Loss: 2.2723270376445726e-05
Test Loss:  1.6411915567005053e-05
Valid Loss:  2.732276334427297e-05
Epoch:  427  	Training Loss: 2.2708813048666343e-05
Test Loss:  1.641156995901838e-05
Valid Loss:  2.730878441070672e-05
Epoch:  428  	Training Loss: 2.2694517610943876e-05
Test Loss:  1.6411860997322947e-05
Valid Loss:  2.7295151085127145e-05
Epoch:  429  	Training Loss: 2.2680578695144504e-05
Test Loss:  1.6412413970101625e-05
Valid Loss:  2.728223626036197e-05
Epoch:  430  	Training Loss: 2.2666717995889485e-05
Test Loss:  1.6413343473686837e-05
Valid Loss:  2.7269936254015192e-05
Epoch:  431  	Training Loss: 2.265325929329265e-05
Test Loss:  1.6414065612480044e-05
Valid Loss:  2.7257814508629963e-05
Epoch:  432  	Training Loss: 2.263999340357259e-05
Test Loss:  1.6431406038464047e-05
Valid Loss:  2.7281563234282658e-05
Epoch:  433  	Training Loss: 2.2636348148807883e-05
Test Loss:  1.64442062668968e-05
Valid Loss:  2.7299392968416214e-05
Epoch:  434  	Training Loss: 2.2633275875705294e-05
Test Loss:  1.6453728676424362e-05
Valid Loss:  2.7313173632137477e-05
Epoch:  435  	Training Loss: 2.2630505554843694e-05
Test Loss:  1.6461121049360372e-05
Valid Loss:  2.7325144401402213e-05
Epoch:  436  	Training Loss: 2.2628028091276065e-05
Test Loss:  1.6467174646095373e-05
Valid Loss:  2.7335005142958835e-05
Epoch:  437  	Training Loss: 2.262559428345412e-05
Test Loss:  1.647271892579738e-05
Valid Loss:  2.73435034614522e-05
Epoch:  438  	Training Loss: 2.2623211407335475e-05
Test Loss:  1.6477031749673188e-05
Valid Loss:  2.735141242737882e-05
Epoch:  439  	Training Loss: 2.2620974050369114e-05
Test Loss:  1.6481088096043095e-05
Valid Loss:  2.73582772933878e-05
Epoch:  440  	Training Loss: 2.261878762510605e-05
Test Loss:  1.648450779612176e-05
Valid Loss:  2.736458191066049e-05
Epoch:  441  	Training Loss: 2.261664303659927e-05
Test Loss:  1.6487372704432346e-05
Valid Loss:  2.7370679163141176e-05
Epoch:  442  	Training Loss: 2.26146057684673e-05
Test Loss:  1.6483945728396066e-05
Valid Loss:  2.728109211602714e-05
Epoch:  443  	Training Loss: 2.2595058908336796e-05
Test Loss:  1.6454865544801578e-05
Valid Loss:  2.7200068871024996e-05
Epoch:  444  	Training Loss: 2.257817322970368e-05
Test Loss:  1.6422956832684577e-05
Valid Loss:  2.7124602638650686e-05
Epoch:  445  	Training Loss: 2.256235711683985e-05
Test Loss:  1.6391237295465544e-05
Valid Loss:  2.7053629310103133e-05
Epoch:  446  	Training Loss: 2.2546964828507043e-05
Test Loss:  1.6356005289708264e-05
Valid Loss:  2.69863085122779e-05
Epoch:  447  	Training Loss: 2.2531719878315926e-05
Test Loss:  1.6321280781994574e-05
Valid Loss:  2.6922842152998783e-05
Epoch:  448  	Training Loss: 2.251737896585837e-05
Test Loss:  1.6287815014948137e-05
Valid Loss:  2.6863281163969077e-05
Epoch:  449  	Training Loss: 2.250365105282981e-05
Test Loss:  1.62551186804194e-05
Valid Loss:  2.680634497664869e-05
Epoch:  450  	Training Loss: 2.2490316041512415e-05
Test Loss:  1.6224832506850362e-05
Valid Loss:  2.6751102268463e-05
Epoch:  451  	Training Loss: 2.2477126549347304e-05
Test Loss:  1.619436989130918e-05
Valid Loss:  2.669838249858003e-05
Epoch:  452  	Training Loss: 2.246453004772775e-05
Test Loss:  1.6223479178734124e-05
Valid Loss:  2.6727728254627436e-05
Epoch:  453  	Training Loss: 2.2452630219049752e-05
Test Loss:  1.623973366804421e-05
Valid Loss:  2.6744855858851224e-05
Epoch:  454  	Training Loss: 2.244178904220462e-05
Test Loss:  1.6248848623945378e-05
Valid Loss:  2.6753345082397573e-05
Epoch:  455  	Training Loss: 2.243098606413696e-05
Test Loss:  1.62587602972053e-05
Valid Loss:  2.6733312552096322e-05
Epoch:  456  	Training Loss: 2.2417851141653955e-05
Test Loss:  1.6257874449365772e-05
Valid Loss:  2.671034962986596e-05
Epoch:  457  	Training Loss: 2.240533103758935e-05
Test Loss:  1.625259938009549e-05
Valid Loss:  2.6687124773161486e-05
Epoch:  458  	Training Loss: 2.2393263861886226e-05
Test Loss:  1.6245518054347485e-05
Valid Loss:  2.6663921744329855e-05
Epoch:  459  	Training Loss: 2.238120578113012e-05
Test Loss:  1.6238233001786284e-05
Valid Loss:  2.664187559275888e-05
Epoch:  460  	Training Loss: 2.2369275029632263e-05
Test Loss:  1.6237745512626134e-05
Valid Loss:  2.6599787815939635e-05
Epoch:  461  	Training Loss: 2.2350957806338556e-05
Test Loss:  1.6237288946285844e-05
Valid Loss:  2.654120180523023e-05
Epoch:  462  	Training Loss: 2.232782389910426e-05
Test Loss:  1.6158739526872523e-05
Valid Loss:  2.6417234039399773e-05
Epoch:  463  	Training Loss: 2.2263673599809408e-05
Test Loss:  1.6086618416011333e-05
Valid Loss:  2.631081770232413e-05
Epoch:  464  	Training Loss: 2.220187889179215e-05
Test Loss:  1.6021660485421307e-05
Valid Loss:  2.621961357363034e-05
Epoch:  465  	Training Loss: 2.2143120077089407e-05
Test Loss:  1.596323818375822e-05
Valid Loss:  2.61402838077629e-05
Epoch:  466  	Training Loss: 2.2084288502810523e-05
Test Loss:  1.590919418958947e-05
Valid Loss:  2.607008718769066e-05
Epoch:  467  	Training Loss: 2.2026961232768372e-05
Test Loss:  1.585951031302102e-05
Valid Loss:  2.600751759018749e-05
Epoch:  468  	Training Loss: 2.1970763555145822e-05
Test Loss:  1.581308970344253e-05
Valid Loss:  2.595157093310263e-05
Epoch:  469  	Training Loss: 2.1915588149568066e-05
Test Loss:  1.576955219206866e-05
Valid Loss:  2.5900324544636533e-05
Epoch:  470  	Training Loss: 2.1860698325326666e-05
Test Loss:  1.572815017425455e-05
Valid Loss:  2.5852310500340536e-05
Epoch:  471  	Training Loss: 2.180561023124028e-05
Test Loss:  1.5688036000938155e-05
Valid Loss:  2.580706677690614e-05
Epoch:  472  	Training Loss: 2.175143890781328e-05
Test Loss:  1.5637413525837474e-05
Valid Loss:  2.5744588128873147e-05
Epoch:  473  	Training Loss: 2.1732234017690644e-05
Test Loss:  1.5610914488206618e-05
Valid Loss:  2.569860953371972e-05
Epoch:  474  	Training Loss: 2.1714742615586147e-05
Test Loss:  1.5592297131661326e-05
Valid Loss:  2.5657569494796917e-05
Epoch:  475  	Training Loss: 2.169750223401934e-05
Test Loss:  1.557482755742967e-05
Valid Loss:  2.5617642677389085e-05
 95%|█████████▌| 476/500 [05:34<00:14,  1.61it/s] 96%|█████████▌| 478/500 [05:34<00:10,  2.20it/s] 96%|█████████▌| 480/500 [05:34<00:06,  2.96it/s] 96%|█████████▋| 482/500 [05:40<00:20,  1.16s/it] 97%|█████████▋| 484/500 [05:40<00:13,  1.20it/s] 97%|█████████▋| 486/500 [05:40<00:08,  1.66it/s] 98%|█████████▊| 488/500 [05:40<00:05,  2.26it/s] 98%|█████████▊| 490/500 [05:41<00:03,  3.01it/s] 98%|█████████▊| 492/500 [05:47<00:09,  1.17s/it] 99%|█████████▉| 494/500 [05:47<00:05,  1.19it/s] 99%|█████████▉| 496/500 [05:47<00:02,  1.64it/s]100%|█████████▉| 498/500 [05:47<00:00,  2.24it/s]100%|██████████| 500/500 [05:47<00:00,  3.01it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
Epoch:  476  	Training Loss: 2.1680858480976894e-05
Test Loss:  1.555800008645747e-05
Valid Loss:  2.557949483161792e-05
Epoch:  477  	Training Loss: 2.1664593077730387e-05
Test Loss:  1.554244227008894e-05
Valid Loss:  2.5542685762047768e-05
Epoch:  478  	Training Loss: 2.1648658730555326e-05
Test Loss:  1.552719550090842e-05
Valid Loss:  2.5507262762403116e-05
Epoch:  479  	Training Loss: 2.1633051801472902e-05
Test Loss:  1.5513702237512916e-05
Valid Loss:  2.5472552806604654e-05
Epoch:  480  	Training Loss: 2.161747033824213e-05
Test Loss:  1.5499785149586387e-05
Valid Loss:  2.5438605007366277e-05
Epoch:  481  	Training Loss: 2.1602059860015288e-05
Test Loss:  1.548675209050998e-05
Valid Loss:  2.5404211555724032e-05
Epoch:  482  	Training Loss: 2.1586936782114208e-05
Test Loss:  1.5538242223556153e-05
Valid Loss:  2.545956158428453e-05
Epoch:  483  	Training Loss: 2.1558993466896936e-05
Test Loss:  1.5571966287097894e-05
Valid Loss:  2.5495401132502593e-05
Epoch:  484  	Training Loss: 2.153414061467629e-05
Test Loss:  1.55940288095735e-05
Valid Loss:  2.5518364054732956e-05
Epoch:  485  	Training Loss: 2.1511001250473782e-05
Test Loss:  1.5608595276717097e-05
Valid Loss:  2.5532937797834165e-05
Epoch:  486  	Training Loss: 2.1488622223841958e-05
Test Loss:  1.5617501048836857e-05
Valid Loss:  2.5541514332871884e-05
Epoch:  487  	Training Loss: 2.146690349036362e-05
Test Loss:  1.5623310900991783e-05
Valid Loss:  2.5546609322191216e-05
Epoch:  488  	Training Loss: 2.144583413610235e-05
Test Loss:  1.56269616127247e-05
Valid Loss:  2.554887942096684e-05
Epoch:  489  	Training Loss: 2.1425139493658207e-05
Test Loss:  1.5629524568794295e-05
Valid Loss:  2.5549172278260812e-05
Epoch:  490  	Training Loss: 2.1405056031653658e-05
Test Loss:  1.5630874258931726e-05
Valid Loss:  2.5548652047291398e-05
Epoch:  491  	Training Loss: 2.138523996109143e-05
Test Loss:  1.5631700080120936e-05
Valid Loss:  2.5547651603119448e-05
Epoch:  492  	Training Loss: 2.1366015062085353e-05
Test Loss:  1.559383235871792e-05
Valid Loss:  2.5506718884571455e-05
Epoch:  493  	Training Loss: 2.1349333110265434e-05
Test Loss:  1.556173083372414e-05
Valid Loss:  2.546757423260715e-05
Epoch:  494  	Training Loss: 2.1333580662030727e-05
Test Loss:  1.5532627003267407e-05
Valid Loss:  2.5429333618376404e-05
Epoch:  495  	Training Loss: 2.131818837369792e-05
Test Loss:  1.5505407645832747e-05
Valid Loss:  2.539227352826856e-05
Epoch:  496  	Training Loss: 2.130319262505509e-05
Test Loss:  1.5479838111787103e-05
Valid Loss:  2.5356288460898213e-05
Epoch:  497  	Training Loss: 2.1288446077960543e-05
Test Loss:  1.5455805623787455e-05
Valid Loss:  2.5322489818790928e-05
Epoch:  498  	Training Loss: 2.1273999664117582e-05
Test Loss:  1.543334474263247e-05
Valid Loss:  2.529157245589886e-05
Epoch:  499  	Training Loss: 2.125997343682684e-05
Test Loss:  1.5411707863677293e-05
Valid Loss:  2.5261739210691303e-05
Epoch:  500  	Training Loss: 2.1246049072942697e-05
Test Loss:  1.5391142369480804e-05
Valid Loss:  2.5232700863853097e-05
seed is  10
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 14.76it/s]  1%|          | 4/500 [00:00<00:32, 15.14it/s]  1%|          | 6/500 [00:00<00:31, 15.55it/s]  2%|▏         | 8/500 [00:00<00:31, 15.83it/s]  2%|▏         | 10/500 [00:00<00:30, 15.86it/s]  2%|▏         | 12/500 [00:00<00:30, 15.75it/s]  3%|▎         | 14/500 [00:00<00:30, 15.91it/s]  3%|▎         | 16/500 [00:01<00:30, 15.96it/s]  4%|▎         | 18/500 [00:01<00:29, 16.14it/s]  4%|▍         | 20/500 [00:01<00:29, 16.29it/s]  4%|▍         | 22/500 [00:01<00:29, 16.41it/s]  5%|▍         | 24/500 [00:01<00:29, 16.39it/s]  5%|▌         | 26/500 [00:01<00:29, 16.11it/s]  6%|▌         | 28/500 [00:01<00:29, 16.26it/s]  6%|▌         | 30/500 [00:01<00:28, 16.22it/s]  6%|▋         | 32/500 [00:01<00:28, 16.18it/s]  7%|▋         | 34/500 [00:02<00:28, 16.26it/s]  7%|▋         | 36/500 [00:02<00:28, 16.34it/s]  8%|▊         | 38/500 [00:02<00:28, 16.27it/s]  8%|▊         | 40/500 [00:02<00:28, 16.28it/s]  8%|▊         | 42/500 [00:02<00:28, 16.30it/s]  9%|▉         | 44/500 [00:02<00:27, 16.38it/s]  9%|▉         | 46/500 [00:02<00:29, 15.50it/s] 10%|▉         | 48/500 [00:03<00:29, 15.51it/s] 10%|█         | 50/500 [00:03<00:28, 15.62it/s] 10%|█         | 52/500 [00:03<00:28, 15.82it/s] 11%|█         | 54/500 [00:03<00:28, 15.89it/s] 11%|█         | 56/500 [00:03<00:27, 16.02it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.16it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.26it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.17it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.67it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.68it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.93it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.86it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.52it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.68it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.78it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.82it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.72it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.76it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.80it/s] 17%|█▋        | 86/500 [00:05<00:26, 15.74it/s] 18%|█▊        | 88/500 [00:05<00:26, 15.75it/s] 18%|█▊        | 90/500 [00:05<00:25, 15.97it/s] 18%|█▊        | 92/500 [00:05<00:25, 15.86it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.95it/s] 19%|█▉        | 96/500 [00:06<00:25, 16.06it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.48it/s] 20%|██        | 100/500 [00:06<00:26, 15.35it/s] 20%|██        | 102/500 [00:06<00:25, 15.47it/s] 21%|██        | 104/500 [00:06<00:25, 15.79it/s] 21%|██        | 106/500 [00:06<00:24, 15.77it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.97it/s] 22%|██▏       | 110/500 [00:06<00:24, 15.97it/s] 22%|██▏       | 112/500 [00:07<00:24, 15.99it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.15it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.21it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.11it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.08it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.05it/s] 25%|██▍       | 124/500 [00:07<00:23, 15.97it/s]Epoch:  1  	Training Loss: 0.0674632117152214
Test Loss:  670.0780029296875
Valid Loss:  670.207275390625
Epoch:  2  	Training Loss: 669.6630249023438
Test Loss:  3872450412544.0
Valid Loss:  3841032192000.0
Epoch:  3  	Training Loss: 3849236774912.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.12it/s] 26%|██▌       | 128/500 [00:08<00:23, 15.83it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.96it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.01it/s] 27%|██▋       | 134/500 [00:08<00:22, 15.93it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.84it/s] 28%|██▊       | 138/500 [00:08<00:23, 15.28it/s] 28%|██▊       | 140/500 [00:08<00:23, 15.58it/s] 28%|██▊       | 142/500 [00:08<00:22, 15.80it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.99it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.17it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.11it/s] 30%|███       | 150/500 [00:09<00:21, 16.01it/s] 30%|███       | 152/500 [00:09<00:21, 16.01it/s] 31%|███       | 154/500 [00:09<00:21, 16.01it/s] 31%|███       | 156/500 [00:09<00:21, 15.99it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.15it/s] 32%|███▏      | 160/500 [00:10<00:22, 14.90it/s] 32%|███▏      | 162/500 [00:10<00:22, 14.87it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.33it/s] 33%|███▎      | 166/500 [00:10<00:21, 15.73it/s] 34%|███▎      | 168/500 [00:10<00:20, 15.81it/s] 34%|███▍      | 170/500 [00:10<00:21, 15.36it/s] 34%|███▍      | 172/500 [00:10<00:21, 15.57it/s] 35%|███▍      | 174/500 [00:10<00:20, 15.76it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.83it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.84it/s] 36%|███▌      | 180/500 [00:11<00:20, 15.99it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.05it/s] 37%|███▋      | 184/500 [00:11<00:19, 15.82it/s] 37%|███▋      | 186/500 [00:11<00:19, 15.96it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.12it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.22it/s] 38%|███▊      | 192/500 [00:12<00:19, 16.19it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.29it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.99it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.89it/s] 40%|████      | 200/500 [00:12<00:19, 15.73it/s] 40%|████      | 202/500 [00:12<00:18, 15.79it/s] 41%|████      | 204/500 [00:12<00:18, 15.84it/s] 41%|████      | 206/500 [00:12<00:18, 15.57it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.74it/s] 42%|████▏     | 210/500 [00:13<00:18, 15.88it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.04it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.23it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.08it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.10it/s] 44%|████▍     | 220/500 [00:13<00:17, 15.96it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.04it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.05it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.99it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.98it/s] 46%|████▌     | 230/500 [00:14<00:17, 15.87it/s] 46%|████▋     | 232/500 [00:14<00:16, 15.86it/s] 47%|████▋     | 234/500 [00:14<00:16, 15.90it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.09it/s] 48%|████▊     | 238/500 [00:14<00:16, 15.95it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.13it/s] 48%|████▊     | 242/500 [00:15<00:16, 16.08it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.58it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.78it/s] 50%|████▉     | 248/500 [00:15<00:15, 15.93it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 15.77it/s] 50%|█████     | 252/500 [00:15<00:15, 15.50it/s] 51%|█████     | 254/500 [00:15<00:15, 15.64it/s] 51%|█████     | 256/500 [00:16<00:15, 15.70it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.90it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.12it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.21it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.23it/s] 53%|█████▎    | 266/500 [00:16<00:14, 15.92it/s] 54%|█████▎    | 268/500 [00:16<00:14, 15.92it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.03it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.14it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.25it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.18it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.21it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.33it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.34it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.34it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.32it/s] 58%|█████▊    | 288/500 [00:18<00:12, 16.36it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.38it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.35it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.05it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.92it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.04it/s] 60%|██████    | 300/500 [00:18<00:12, 16.13it/s] 60%|██████    | 302/500 [00:18<00:12, 16.18it/s] 61%|██████    | 304/500 [00:19<00:12, 16.27it/s] 61%|██████    | 306/500 [00:19<00:11, 16.21it/s] 62%|██████▏   | 308/500 [00:19<00:12, 15.96it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.06it/s] 62%|██████▏   | 312/500 [00:19<00:11, 15.89it/s] 63%|██████▎   | 314/500 [00:19<00:11, 15.77it/s] 63%|██████▎   | 316/500 [00:19<00:11, 15.83it/s] 64%|██████▎   | 318/500 [00:19<00:11, 15.98it/s] 64%|██████▍   | 320/500 [00:20<00:11, 15.97it/s] 64%|██████▍   | 322/500 [00:20<00:11, 16.10it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.24it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.28it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.37it/s] 66%|██████▌   | 330/500 [00:20<00:10, 15.62it/s] 66%|██████▋   | 332/500 [00:20<00:10, 15.74it/s] 67%|██████▋   | 334/500 [00:20<00:10, 15.58it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.12it/s] 68%|██████▊   | 338/500 [00:21<00:10, 15.27it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.50it/s] 68%|██████▊   | 342/500 [00:21<00:10, 15.71it/s] 69%|██████▉   | 344/500 [00:21<00:09, 15.79it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.03it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.20it/s] 70%|███████   | 350/500 [00:21<00:09, 16.19it/s] 70%|███████   | 352/500 [00:22<00:09, 16.07it/s] 71%|███████   | 354/500 [00:22<00:09, 15.98it/s] 71%|███████   | 356/500 [00:22<00:08, 16.02it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.12it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.18it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.03it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.16it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.20it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.30it/s] 74%|███████▍  | 370/500 [00:23<00:07, 16.36it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.40it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.22it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.15it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.03it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.11it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.16it/s] 77%|███████▋  | 384/500 [00:24<00:07, 16.20it/s] 77%|███████▋  | 386/500 [00:24<00:06, 16.33it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.17it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.15it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.12it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.16it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.22it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.22it/s] 80%|████████  | 400/500 [00:25<00:06, 16.03it/s] 80%|████████  | 402/500 [00:25<00:06, 16.16it/s] 81%|████████  | 404/500 [00:25<00:05, 16.14it/s] 81%|████████  | 406/500 [00:25<00:05, 16.07it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.22it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.34it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.36it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.44it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.22it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.29it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.30it/s] 84%|████████▍ | 422/500 [00:26<00:05, 15.49it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.56it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.72it/s] 86%|████████▌ | 428/500 [00:26<00:04, 15.86it/s] 86%|████████▌ | 430/500 [00:26<00:04, 15.40it/s] 86%|████████▋ | 432/500 [00:27<00:04, 15.68it/s] 87%|████████▋ | 434/500 [00:27<00:04, 15.61it/s] 87%|████████▋ | 436/500 [00:27<00:04, 15.64it/s] 88%|████████▊ | 438/500 [00:27<00:03, 15.77it/s] 88%|████████▊ | 440/500 [00:27<00:03, 15.82it/s] 88%|████████▊ | 442/500 [00:27<00:03, 15.64it/s] 89%|████████▉ | 444/500 [00:27<00:03, 15.71it/s] 89%|████████▉ | 446/500 [00:27<00:03, 15.66it/s] 90%|████████▉ | 448/500 [00:28<00:03, 15.89it/s] 90%|█████████ | 450/500 [00:28<00:03, 15.74it/s] 90%|█████████ | 452/500 [00:28<00:03, 15.96it/s] 91%|█████████ | 454/500 [00:28<00:02, 15.96it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.08it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.03it/s] 92%|█████████▏| 460/500 [00:28<00:02, 15.90it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.02it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.04it/s] 93%|█████████▎| 466/500 [00:29<00:02, 15.92it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.03it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.05it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.19it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.23it/s] 95%|█████████▌| 476/500 [00:29<00:01, 15.26it/s] 96%|█████████▌| 478/500 [00:29<00:01, 15.00it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.22it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.43it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.57it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.80it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.93it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.12it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.17it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.04it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.93it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.07it/s]100%|██████████| 500/500 [00:31<00:00, 16.19it/s]100%|██████████| 500/500 [00:31<00:00, 15.95it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  10
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:24,  6.30s/it]  1%|          | 3/500 [00:06<13:57,  1.68s/it]  1%|          | 5/500 [00:06<07:01,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.87it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:28,  1.19s/it]  5%|▍         | 23/500 [00:20<06:43,  1.18it/s]  5%|▌         | 25/500 [00:20<04:49,  1.64it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:36,  3.02it/s]  6%|▌         | 31/500 [00:26<09:08,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.65it/s]  7%|▋         | 37/500 [00:27<03:26,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:56,  1.17s/it]  9%|▊         | 43/500 [00:33<06:23,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.03it/s] 10%|█         | 51/500 [00:40<08:50,  1.18s/it] 11%|█         | 53/500 [00:40<06:19,  1.18it/s] 11%|█         | 55/500 [00:40<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:40<03:18,  2.23it/s] 12%|█▏        | 59/500 [00:40<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:47<08:36,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:53<08:21,  1.17s/it]Epoch:  1  	Training Loss: 0.06746320426464081
Test Loss:  16.471271514892578
Valid Loss:  16.32676887512207
Epoch:  2  	Training Loss: 16.393627166748047
Test Loss:  0.07282626628875732
Valid Loss:  0.07501183450222015
Epoch:  3  	Training Loss: 0.07611898332834244
Test Loss:  0.07150432467460632
Valid Loss:  0.07370413839817047
Epoch:  4  	Training Loss: 0.07477588951587677
Test Loss:  0.0702105313539505
Valid Loss:  0.07242432236671448
Epoch:  5  	Training Loss: 0.07346117496490479
Test Loss:  0.0689443051815033
Valid Loss:  0.0711718276143074
Epoch:  6  	Training Loss: 0.0721743106842041
Test Loss:  0.06770513951778412
Valid Loss:  0.06994612514972687
Epoch:  7  	Training Loss: 0.07091472297906876
Test Loss:  0.0664924830198288
Valid Loss:  0.0687466561794281
Epoch:  8  	Training Loss: 0.06968188285827637
Test Loss:  0.06530579179525375
Valid Loss:  0.0675729289650917
Epoch:  9  	Training Loss: 0.06847526133060455
Test Loss:  0.064144566655159
Valid Loss:  0.0664243996143341
Epoch:  10  	Training Loss: 0.06729432940483093
Test Loss:  0.06300827860832214
Valid Loss:  0.0653005838394165
Epoch:  11  	Training Loss: 0.06613858044147491
Test Loss:  0.06189645826816559
Valid Loss:  0.06420096755027771
Epoch:  12  	Training Loss: 0.06500750780105591
Test Loss:  0.060853760689496994
Valid Loss:  0.06317601352930069
Epoch:  13  	Training Loss: 0.06395141035318375
Test Loss:  0.05983433127403259
Valid Loss:  0.062173955142498016
Epoch:  14  	Training Loss: 0.06291868537664413
Test Loss:  0.05883768945932388
Valid Loss:  0.0611942820250988
Epoch:  15  	Training Loss: 0.06190881505608559
Test Loss:  0.057863254100084305
Valid Loss:  0.060236454010009766
Epoch:  16  	Training Loss: 0.06092125177383423
Test Loss:  0.05691055208444595
Valid Loss:  0.059300001710653305
Epoch:  17  	Training Loss: 0.05995551496744156
Test Loss:  0.05597907677292824
Valid Loss:  0.058384403586387634
Epoch:  18  	Training Loss: 0.05901108682155609
Test Loss:  0.055068355053663254
Valid Loss:  0.057489216327667236
Epoch:  19  	Training Loss: 0.05808750540018082
Test Loss:  0.05417787283658981
Valid Loss:  0.05661392956972122
Epoch:  20  	Training Loss: 0.05718425661325455
Test Loss:  0.05330720543861389
Valid Loss:  0.05575810372829437
Epoch:  21  	Training Loss: 0.05630090832710266
Test Loss:  0.05252442881464958
Valid Loss:  0.054989494383335114
Epoch:  22  	Training Loss: 0.05550665035843849
Test Loss:  0.05189182981848717
Valid Loss:  0.05437207221984863
Epoch:  23  	Training Loss: 0.054868027567863464
Test Loss:  0.05127035453915596
Valid Loss:  0.05376552790403366
Epoch:  24  	Training Loss: 0.05424045771360397
Test Loss:  0.05065976083278656
Valid Loss:  0.053169816732406616
Epoch:  25  	Training Loss: 0.05362381041049957
Test Loss:  0.05005975067615509
Valid Loss:  0.052584610879421234
Epoch:  26  	Training Loss: 0.05301784723997116
Test Loss:  0.04947010427713394
Valid Loss:  0.052009593695402145
Epoch:  27  	Training Loss: 0.05242226645350456
Test Loss:  0.0488906130194664
Valid Loss:  0.05144459754228592
Epoch:  28  	Training Loss: 0.05183689668774605
Test Loss:  0.048321157693862915
Valid Loss:  0.05088941007852554
Epoch:  29  	Training Loss: 0.0512615330517292
Test Loss:  0.04776151478290558
Valid Loss:  0.050343841314315796
Epoch:  30  	Training Loss: 0.0506959930062294
Test Loss:  0.04721152037382126
Valid Loss:  0.04980764538049698
Epoch:  31  	Training Loss: 0.05014009773731232
Test Loss:  0.04667096585035324
Valid Loss:  0.049280665814876556
Epoch:  32  	Training Loss: 0.04959370568394661
Test Loss:  0.04613792896270752
Valid Loss:  0.048761025071144104
Epoch:  33  	Training Loss: 0.04905478283762932
Test Loss:  0.04561413452029228
Valid Loss:  0.04825039580464363
Epoch:  34  	Training Loss: 0.048525094985961914
Test Loss:  0.04509945958852768
Valid Loss:  0.04774865508079529
Epoch:  35  	Training Loss: 0.04800451174378395
Test Loss:  0.044593699276447296
Valid Loss:  0.04725559800863266
Epoch:  36  	Training Loss: 0.04749284312129021
Test Loss:  0.044096704572439194
Valid Loss:  0.04677107185125351
Epoch:  37  	Training Loss: 0.04698994383215904
Test Loss:  0.043608345091342926
Valid Loss:  0.04629496484994888
Epoch:  38  	Training Loss: 0.04649565741419792
Test Loss:  0.04312844201922417
Valid Loss:  0.04582710191607475
Epoch:  39  	Training Loss: 0.0460098460316658
Test Loss:  0.04265686869621277
Valid Loss:  0.04536734148859978
Epoch:  40  	Training Loss: 0.045532334595918655
Test Loss:  0.042193446308374405
Valid Loss:  0.04491551220417023
Epoch:  41  	Training Loss: 0.04506298154592514
Test Loss:  0.04173804074525833
Valid Loss:  0.04447151720523834
Epoch:  42  	Training Loss: 0.04460164159536362
Test Loss:  0.041292641311883926
Valid Loss:  0.044037241488695145
Epoch:  43  	Training Loss: 0.04415031149983406
Test Loss:  0.04085495322942734
Valid Loss:  0.04361046850681305
Epoch:  44  	Training Loss: 0.04370671138167381
Test Loss:  0.040424831211566925
Valid Loss:  0.043191082775592804
Epoch:  45  	Training Loss: 0.04327067732810974
Test Loss:  0.040002137422561646
Valid Loss:  0.04277890920639038
Epoch:  46  	Training Loss: 0.042842067778110504
Test Loss:  0.03958677500486374
Valid Loss:  0.04237386956810951
Epoch:  47  	Training Loss: 0.04242078214883804
Test Loss:  0.039178553968667984
Valid Loss:  0.04197576642036438
Epoch:  48  	Training Loss: 0.042006637901067734
Test Loss:  0.03877733647823334
Valid Loss:  0.041584499180316925
Epoch:  49  	Training Loss: 0.041599515825510025
Test Loss:  0.03838302940130234
Valid Loss:  0.04119995981454849
Epoch:  50  	Training Loss: 0.04119931161403656
Test Loss:  0.03799549862742424
Valid Loss:  0.040822017937898636
Epoch:  51  	Training Loss: 0.0408058688044548
Test Loss:  0.037614598870277405
Valid Loss:  0.040450502187013626
Epoch:  52  	Training Loss: 0.0404190756380558
Test Loss:  0.037240903824567795
Valid Loss:  0.04008599370718002
Epoch:  53  	Training Loss: 0.040039483457803726
Test Loss:  0.03687360882759094
Valid Loss:  0.03972771018743515
Epoch:  54  	Training Loss: 0.0396663174033165
Test Loss:  0.036512602120637894
Valid Loss:  0.03937556594610214
Epoch:  55  	Training Loss: 0.03929945454001427
Test Loss:  0.03615779057145119
Valid Loss:  0.03902941569685936
Epoch:  56  	Training Loss: 0.03893878683447838
Test Loss:  0.03580905497074127
Valid Loss:  0.03868921473622322
Epoch:  57  	Training Loss: 0.03858419507741928
Test Loss:  0.03546633571386337
Valid Loss:  0.038354817777872086
Epoch:  58  	Training Loss: 0.038235604763031006
Test Loss:  0.03512944281101227
Valid Loss:  0.038026079535484314
Epoch:  59  	Training Loss: 0.037892844527959824
Test Loss:  0.0347982719540596
Valid Loss:  0.03770294040441513
Epoch:  60  	Training Loss: 0.037555839866399765
Test Loss:  0.03447277843952179
Valid Loss:  0.037385277450084686
Epoch:  61  	Training Loss: 0.03722450137138367
Test Loss:  0.0341527983546257
Valid Loss:  0.037072986364364624
Epoch:  62  	Training Loss: 0.036898672580718994
Test Loss:  0.03383335471153259
Valid Loss:  0.036761198192834854
Epoch:  63  	Training Loss: 0.03657333180308342
Test Loss:  0.03351922333240509
Valid Loss:  0.03645460307598114
Epoch:  64  	Training Loss: 0.03625332564115524
Test Loss:  0.033210307359695435
Valid Loss:  0.03615308552980423
Epoch:  65  	Training Loss: 0.035938560962677
Test Loss:  0.03290654346346855
Valid Loss:  0.03585655987262726
Epoch:  66  	Training Loss: 0.03562894091010094
Test Loss:  0.032607827335596085
Valid Loss:  0.03556494787335396
Epoch:  67  	Training Loss: 0.035324376076459885
Test Loss:  0.03231407701969147
Valid Loss:  0.03527812659740448
Epoch:  68  	Training Loss: 0.035024795681238174
Test Loss:  0.03202516585588455
Valid Loss:  0.03499605506658554
Epoch:  69  	Training Loss: 0.03473006188869476
Test Loss:  0.03174109011888504
Valid Loss:  0.03471861407160759
Epoch:  70  	Training Loss: 0.03444014489650726
Test Loss:  0.03146173432469368
Valid Loss:  0.03444574028253555
Epoch:  71  	Training Loss: 0.03415494039654732
Test Loss:  0.0311870239675045
Valid Loss:  0.03417733684182167
Epoch:  72  	Training Loss: 0.03387435898184776
Test Loss:  0.030920814722776413
Valid Loss:  0.033917199820280075
 15%|█▍        | 73/500 [00:54<05:57,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:17,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.26it/s] 16%|█▌        | 79/500 [00:54<02:18,  3.03it/s] 16%|█▌        | 81/500 [01:00<08:12,  1.18s/it] 17%|█▋        | 83/500 [01:00<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:00<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<07:57,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:07<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:07<02:58,  2.25it/s] 20%|█▉        | 99/500 [01:08<02:12,  3.02it/s] 20%|██        | 101/500 [01:14<07:50,  1.18s/it] 21%|██        | 103/500 [01:14<05:36,  1.18it/s] 21%|██        | 105/500 [01:14<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:14<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:14<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:21<07:43,  1.19s/it] 23%|██▎       | 113/500 [01:21<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:21<03:58,  1.62it/s] 23%|██▎       | 117/500 [01:21<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:21<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:28<07:28,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:20,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:50,  1.62it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.22it/s] 26%|██▌       | 129/500 [01:28<02:04,  2.98it/s] 26%|██▌       | 131/500 [01:34<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:35<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:41<06:57,  1.16s/it]Epoch:  73  	Training Loss: 0.03360237553715706
Test Loss:  0.03065904974937439
Valid Loss:  0.03366135433316231
Epoch:  74  	Training Loss: 0.033334825187921524
Test Loss:  0.030401689931750298
Valid Loss:  0.033409710973501205
Epoch:  75  	Training Loss: 0.03307165205478668
Test Loss:  0.030148644000291824
Valid Loss:  0.03316229581832886
Epoch:  76  	Training Loss: 0.032812803983688354
Test Loss:  0.029899779707193375
Valid Loss:  0.03291893005371094
Epoch:  77  	Training Loss: 0.032558172941207886
Test Loss:  0.02965501695871353
Valid Loss:  0.03267960250377655
Epoch:  78  	Training Loss: 0.03230768442153931
Test Loss:  0.029414299875497818
Valid Loss:  0.032444149255752563
Epoch:  79  	Training Loss: 0.03206126391887665
Test Loss:  0.029177561402320862
Valid Loss:  0.03221259266138077
Epoch:  80  	Training Loss: 0.031818825751543045
Test Loss:  0.028944747522473335
Valid Loss:  0.03198479488492012
Epoch:  81  	Training Loss: 0.03158031031489372
Test Loss:  0.028715739026665688
Valid Loss:  0.03176073729991913
Epoch:  82  	Training Loss: 0.031345631927251816
Test Loss:  0.028489604592323303
Valid Loss:  0.03153947368264198
Epoch:  83  	Training Loss: 0.03111385554075241
Test Loss:  0.028267186135053635
Valid Loss:  0.031321801245212555
Epoch:  84  	Training Loss: 0.030885791406035423
Test Loss:  0.028048396110534668
Valid Loss:  0.031107675284147263
Epoch:  85  	Training Loss: 0.030661385506391525
Test Loss:  0.027833187952637672
Valid Loss:  0.030897017568349838
Epoch:  86  	Training Loss: 0.030440576374530792
Test Loss:  0.027621500194072723
Valid Loss:  0.03068975917994976
Epoch:  87  	Training Loss: 0.03022330440580845
Test Loss:  0.027413245290517807
Valid Loss:  0.030485864728689194
Epoch:  88  	Training Loss: 0.030009500682353973
Test Loss:  0.02720840647816658
Valid Loss:  0.030285408720374107
Epoch:  89  	Training Loss: 0.029799245297908783
Test Loss:  0.02700786478817463
Valid Loss:  0.03008921630680561
Epoch:  90  	Training Loss: 0.02959393337368965
Test Loss:  0.026812715455889702
Valid Loss:  0.029898537322878838
Epoch:  91  	Training Loss: 0.029393941164016724
Test Loss:  0.02662140130996704
Valid Loss:  0.029712053015828133
Epoch:  92  	Training Loss: 0.029197586700320244
Test Loss:  0.026435699313879013
Valid Loss:  0.02953077107667923
Epoch:  93  	Training Loss: 0.029006781056523323
Test Loss:  0.026253554970026016
Valid Loss:  0.029352646321058273
Epoch:  94  	Training Loss: 0.028819549828767776
Test Loss:  0.02607474848628044
Valid Loss:  0.029177604243159294
Epoch:  95  	Training Loss: 0.028635572642087936
Test Loss:  0.025898940861225128
Valid Loss:  0.0290053840726614
Epoch:  96  	Training Loss: 0.028454583138227463
Test Loss:  0.025726016610860825
Valid Loss:  0.028835877776145935
Epoch:  97  	Training Loss: 0.02827649936079979
Test Loss:  0.025555886328220367
Valid Loss:  0.028668999671936035
Epoch:  98  	Training Loss: 0.02810119464993477
Test Loss:  0.025388438254594803
Valid Loss:  0.02850465476512909
Epoch:  99  	Training Loss: 0.027928538620471954
Test Loss:  0.02522358112037182
Valid Loss:  0.028342805802822113
Epoch:  100  	Training Loss: 0.027758484706282616
Test Loss:  0.02506127581000328
Valid Loss:  0.028183385729789734
Epoch:  101  	Training Loss: 0.02759096398949623
Test Loss:  0.024901460856199265
Valid Loss:  0.028026416897773743
Epoch:  102  	Training Loss: 0.02742597460746765
Test Loss:  0.024744588881731033
Valid Loss:  0.027872469276189804
Epoch:  103  	Training Loss: 0.027264155447483063
Test Loss:  0.02459016442298889
Valid Loss:  0.027720840647816658
Epoch:  104  	Training Loss: 0.02710474282503128
Test Loss:  0.024438083171844482
Valid Loss:  0.02757149562239647
Epoch:  105  	Training Loss: 0.026947680860757828
Test Loss:  0.024288315325975418
Valid Loss:  0.02742435410618782
Epoch:  106  	Training Loss: 0.02679295279085636
Test Loss:  0.024140819907188416
Valid Loss:  0.02727939561009407
Epoch:  107  	Training Loss: 0.02664049342274666
Test Loss:  0.023995548486709595
Valid Loss:  0.027136530727148056
Epoch:  108  	Training Loss: 0.02649025246500969
Test Loss:  0.023852501064538956
Valid Loss:  0.026995792984962463
Epoch:  109  	Training Loss: 0.026342222467064857
Test Loss:  0.023711569607257843
Valid Loss:  0.02685713768005371
Epoch:  110  	Training Loss: 0.026196351274847984
Test Loss:  0.023572750389575958
Valid Loss:  0.02672046236693859
Epoch:  111  	Training Loss: 0.026052599772810936
Test Loss:  0.023436004295945168
Valid Loss:  0.026585794985294342
Epoch:  112  	Training Loss: 0.025910917669534683
Test Loss:  0.023298678919672966
Valid Loss:  0.02645065076649189
Epoch:  113  	Training Loss: 0.025768674910068512
Test Loss:  0.023163430392742157
Valid Loss:  0.02631746418774128
Epoch:  114  	Training Loss: 0.025628508999943733
Test Loss:  0.02303016372025013
Valid Loss:  0.026186184957623482
Epoch:  115  	Training Loss: 0.025490324944257736
Test Loss:  0.022898877039551735
Valid Loss:  0.026056814938783646
Epoch:  116  	Training Loss: 0.025354135781526566
Test Loss:  0.02276954986155033
Valid Loss:  0.025929296389222145
Epoch:  117  	Training Loss: 0.02521989494562149
Test Loss:  0.022642111405730247
Valid Loss:  0.025803619995713234
Epoch:  118  	Training Loss: 0.025087565183639526
Test Loss:  0.022516541182994843
Valid Loss:  0.025679729878902435
Epoch:  119  	Training Loss: 0.024957116693258286
Test Loss:  0.022392818704247475
Valid Loss:  0.025557611137628555
Epoch:  120  	Training Loss: 0.024828527122735977
Test Loss:  0.022270936518907547
Valid Loss:  0.025437206029891968
Epoch:  121  	Training Loss: 0.024701759219169617
Test Loss:  0.022150767967104912
Valid Loss:  0.02531854249536991
Epoch:  122  	Training Loss: 0.024576786905527115
Test Loss:  0.02203373983502388
Valid Loss:  0.025202888995409012
Epoch:  123  	Training Loss: 0.024454988539218903
Test Loss:  0.0219184011220932
Valid Loss:  0.025088850408792496
Epoch:  124  	Training Loss: 0.02433488704264164
Test Loss:  0.02180470898747444
Valid Loss:  0.024976368993520737
Epoch:  125  	Training Loss: 0.024216443300247192
Test Loss:  0.021692637354135513
Valid Loss:  0.02486545220017433
Epoch:  126  	Training Loss: 0.024099644273519516
Test Loss:  0.02158217504620552
Valid Loss:  0.02475607581436634
Epoch:  127  	Training Loss: 0.02398446947336197
Test Loss:  0.02147330716252327
Valid Loss:  0.024648193269968033
Epoch:  128  	Training Loss: 0.023870889097452164
Test Loss:  0.021365968510508537
Valid Loss:  0.024541866034269333
Epoch:  129  	Training Loss: 0.02375887706875801
Test Loss:  0.021260159090161324
Valid Loss:  0.024436958134174347
Epoch:  130  	Training Loss: 0.023648381233215332
Test Loss:  0.021155834197998047
Valid Loss:  0.024333423003554344
Epoch:  131  	Training Loss: 0.02353936806321144
Test Loss:  0.021052997559309006
Valid Loss:  0.024231335148215294
Epoch:  132  	Training Loss: 0.02343185991048813
Test Loss:  0.0209518913179636
Valid Loss:  0.024130865931510925
Epoch:  133  	Training Loss: 0.023326098918914795
Test Loss:  0.020852189511060715
Valid Loss:  0.02403172291815281
Epoch:  134  	Training Loss: 0.023221706971526146
Test Loss:  0.020753884688019753
Valid Loss:  0.023933902382850647
Epoch:  135  	Training Loss: 0.02311873435974121
Test Loss:  0.020656902343034744
Valid Loss:  0.02383735030889511
Epoch:  136  	Training Loss: 0.023017097264528275
Test Loss:  0.02056128904223442
Valid Loss:  0.023742055520415306
Epoch:  137  	Training Loss: 0.022916797548532486
Test Loss:  0.02046693116426468
Valid Loss:  0.023648053407669067
Epoch:  138  	Training Loss: 0.02281785011291504
Test Loss:  0.020373865962028503
Valid Loss:  0.023555295541882515
Epoch:  139  	Training Loss: 0.02272019535303116
Test Loss:  0.020282071083784103
Valid Loss:  0.02346372790634632
Epoch:  140  	Training Loss: 0.022623827680945396
Test Loss:  0.020191507413983345
Valid Loss:  0.023373400792479515
Epoch:  141  	Training Loss: 0.022528719156980515
Test Loss:  0.020102154463529587
Valid Loss:  0.023284219205379486
Epoch:  142  	Training Loss: 0.022434838116168976
Test Loss:  0.02001204527914524
Valid Loss:  0.023194249719381332
Epoch:  143  	Training Loss: 0.02234010398387909
Test Loss:  0.01992315798997879
Valid Loss:   29%|██▊       | 143/500 [01:41<04:58,  1.20it/s] 29%|██▉       | 145/500 [01:41<03:34,  1.66it/s] 29%|██▉       | 147/500 [01:42<02:36,  2.26it/s] 30%|██▉       | 149/500 [01:42<01:55,  3.04it/s] 30%|███       | 151/500 [01:48<06:48,  1.17s/it] 31%|███       | 153/500 [01:48<04:51,  1.19it/s] 31%|███       | 155/500 [01:48<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:48<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:49<01:52,  3.02it/s] 32%|███▏      | 161/500 [01:55<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:23,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:02<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.63it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:08<06:16,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:15<06:05,  1.18s/it] 39%|███▊      | 193/500 [02:15<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:16,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  2.99it/s] 40%|████      | 201/500 [02:22<05:55,  1.19s/it] 41%|████      | 203/500 [02:22<04:12,  1.17it/s] 41%|████      | 205/500 [02:22<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:23<01:37,  3.00it/s] 42%|████▏     | 211/500 [02:29<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:01,  1.19it/s]0.023105435073375702
Epoch:  144  	Training Loss: 0.02224661037325859
Test Loss:  0.01983541250228882
Valid Loss:  0.023017780855298042
Epoch:  145  	Training Loss: 0.02215433306992054
Test Loss:  0.019748849794268608
Valid Loss:  0.022931275889277458
Epoch:  146  	Training Loss: 0.022063247859477997
Test Loss:  0.019663436338305473
Valid Loss:  0.02284584566950798
Epoch:  147  	Training Loss: 0.021973326802253723
Test Loss:  0.019579172134399414
Valid Loss:  0.022761503234505653
Epoch:  148  	Training Loss: 0.02188454568386078
Test Loss:  0.019496027380228043
Valid Loss:  0.022678187116980553
Epoch:  149  	Training Loss: 0.021796897053718567
Test Loss:  0.019413955509662628
Valid Loss:  0.02259591780602932
Epoch:  150  	Training Loss: 0.021710332483053207
Test Loss:  0.01933296024799347
Valid Loss:  0.02251467853784561
Epoch:  151  	Training Loss: 0.021624859422445297
Test Loss:  0.019253026694059372
Valid Loss:  0.022434428334236145
Epoch:  152  	Training Loss: 0.021540462970733643
Test Loss:  0.019174940884113312
Valid Loss:  0.02235589362680912
Epoch:  153  	Training Loss: 0.02145792730152607
Test Loss:  0.01909785158932209
Valid Loss:  0.022278346121311188
Epoch:  154  	Training Loss: 0.02137642540037632
Test Loss:  0.019021740183234215
Valid Loss:  0.022201739251613617
Epoch:  155  	Training Loss: 0.021295936778187752
Test Loss:  0.018946634605526924
Valid Loss:  0.02212607115507126
Epoch:  156  	Training Loss: 0.021216418594121933
Test Loss:  0.018872447311878204
Valid Loss:  0.022051271051168442
Epoch:  157  	Training Loss: 0.021137872710824013
Test Loss:  0.01879921182990074
Valid Loss:  0.021977387368679047
Epoch:  158  	Training Loss: 0.021060273051261902
Test Loss:  0.018726859241724014
Valid Loss:  0.021904373541474342
Epoch:  159  	Training Loss: 0.020983600988984108
Test Loss:  0.018655426800251007
Valid Loss:  0.02183225005865097
Epoch:  160  	Training Loss: 0.020907863974571228
Test Loss:  0.018584903329610825
Valid Loss:  0.02176094427704811
Epoch:  161  	Training Loss: 0.02083301916718483
Test Loss:  0.018515238538384438
Valid Loss:  0.02169046550989151
Epoch:  162  	Training Loss: 0.02075905352830887
Test Loss:  0.018445314839482307
Valid Loss:  0.021619606763124466
Epoch:  163  	Training Loss: 0.020684728398919106
Test Loss:  0.01837628334760666
Valid Loss:  0.02154957316815853
Epoch:  164  	Training Loss: 0.020611273124814034
Test Loss:  0.018308117985725403
Valid Loss:  0.021480342373251915
Epoch:  165  	Training Loss: 0.020538687705993652
Test Loss:  0.0182407945394516
Valid Loss:  0.021411921828985214
Epoch:  166  	Training Loss: 0.020466946065425873
Test Loss:  0.018174245953559875
Valid Loss:  0.021344322711229324
Epoch:  167  	Training Loss: 0.020396053791046143
Test Loss:  0.018108529970049858
Valid Loss:  0.021277479827404022
Epoch:  168  	Training Loss: 0.020325982943177223
Test Loss:  0.018043607473373413
Valid Loss:  0.02121136710047722
Epoch:  169  	Training Loss: 0.020256701856851578
Test Loss:  0.017979461699724197
Valid Loss:  0.021145999431610107
Epoch:  170  	Training Loss: 0.020188219845294952
Test Loss:  0.017916053533554077
Valid Loss:  0.02108137309551239
Epoch:  171  	Training Loss: 0.02012050896883011
Test Loss:  0.017853379249572754
Valid Loss:  0.02101750299334526
Epoch:  172  	Training Loss: 0.020053591579198837
Test Loss:  0.017792873084545135
Valid Loss:  0.020955540239810944
Epoch:  173  	Training Loss: 0.01998882181942463
Test Loss:  0.017733044922351837
Valid Loss:  0.0208942499011755
Epoch:  174  	Training Loss: 0.019924797117710114
Test Loss:  0.01767389476299286
Valid Loss:  0.02083362638950348
Epoch:  175  	Training Loss: 0.019861454144120216
Test Loss:  0.017615418881177902
Valid Loss:  0.020773593336343765
Epoch:  176  	Training Loss: 0.01979876682162285
Test Loss:  0.017557594925165176
Valid Loss:  0.02071419544517994
Epoch:  177  	Training Loss: 0.019736774265766144
Test Loss:  0.017500432208180428
Valid Loss:  0.020655430853366852
Epoch:  178  	Training Loss: 0.01967545971274376
Test Loss:  0.017443886026740074
Valid Loss:  0.020597290247678757
Epoch:  179  	Training Loss: 0.01961480639874935
Test Loss:  0.017387956380844116
Valid Loss:  0.020539775490760803
Epoch:  180  	Training Loss: 0.019554808735847473
Test Loss:  0.017332613468170166
Valid Loss:  0.02048284187912941
Epoch:  181  	Training Loss: 0.019495422020554543
Test Loss:  0.017277907580137253
Valid Loss:  0.02042645588517189
Epoch:  182  	Training Loss: 0.01943664625287056
Test Loss:  0.01722351647913456
Valid Loss:  0.020370300859212875
Epoch:  183  	Training Loss: 0.0193781740963459
Test Loss:  0.017169717699289322
Valid Loss:  0.020314684137701988
Epoch:  184  	Training Loss: 0.019320297986268997
Test Loss:  0.017116503790020943
Valid Loss:  0.02025960199534893
Epoch:  185  	Training Loss: 0.01926300674676895
Test Loss:  0.017063844949007034
Valid Loss:  0.020205045118927956
Epoch:  186  	Training Loss: 0.019206296652555466
Test Loss:  0.017011739313602448
Valid Loss:  0.020151114091277122
Epoch:  187  	Training Loss: 0.01915016584098339
Test Loss:  0.016960181295871735
Valid Loss:  0.02009766921401024
Epoch:  188  	Training Loss: 0.019094597548246384
Test Loss:  0.016909148544073105
Valid Loss:  0.02004472352564335
Epoch:  189  	Training Loss: 0.019039567559957504
Test Loss:  0.016858648508787155
Valid Loss:  0.019992314279079437
Epoch:  190  	Training Loss: 0.018985118716955185
Test Loss:  0.016808679327368736
Valid Loss:  0.019940493628382683
Epoch:  191  	Training Loss: 0.018931211903691292
Test Loss:  0.016759205609560013
Valid Loss:  0.01988913305103779
Epoch:  192  	Training Loss: 0.018877845257520676
Test Loss:  0.01671084575355053
Valid Loss:  0.019838742911815643
Epoch:  193  	Training Loss: 0.018825607374310493
Test Loss:  0.016662966459989548
Valid Loss:  0.019788891077041626
Epoch:  194  	Training Loss: 0.018773898482322693
Test Loss:  0.016615577042102814
Valid Loss:  0.0197395421564579
Epoch:  195  	Training Loss: 0.018722686916589737
Test Loss:  0.016568660736083984
Valid Loss:  0.019690614193677902
Epoch:  196  	Training Loss: 0.018671967089176178
Test Loss:  0.016522223129868507
Valid Loss:  0.019642125815153122
Epoch:  197  	Training Loss: 0.018621716648340225
Test Loss:  0.016476240009069443
Valid Loss:  0.01959405466914177
Epoch:  198  	Training Loss: 0.018571939319372177
Test Loss:  0.016430700197815895
Valid Loss:  0.019546424970030785
Epoch:  199  	Training Loss: 0.01852261833846569
Test Loss:  0.016385622322559357
Valid Loss:  0.019499242305755615
Epoch:  200  	Training Loss: 0.01847377046942711
Test Loss:  0.01634095422923565
Valid Loss:  0.01945246197283268
Epoch:  201  	Training Loss: 0.01842537336051464
Test Loss:  0.016296720132231712
Valid Loss:  0.019406061619520187
Epoch:  202  	Training Loss: 0.018377413973212242
Test Loss:  0.01625247858464718
Valid Loss:  0.01935957372188568
Epoch:  203  	Training Loss: 0.01832939311861992
Test Loss:  0.016208648681640625
Valid Loss:  0.019313491880893707
Epoch:  204  	Training Loss: 0.01828181929886341
Test Loss:  0.016165215522050858
Valid Loss:  0.019267775118350983
Epoch:  205  	Training Loss: 0.018234658986330032
Test Loss:  0.01612219586968422
Valid Loss:  0.019222501665353775
Epoch:  206  	Training Loss: 0.018187930807471275
Test Loss:  0.016079558059573174
Valid Loss:  0.01917765662074089
Epoch:  207  	Training Loss: 0.018141640350222588
Test Loss:  0.01603735238313675
Valid Loss:  0.01913328282535076
Epoch:  208  	Training Loss: 0.018095791339874268
Test Loss:  0.015995508059859276
Valid Loss:  0.019089242443442345
Epoch:  209  	Training Loss: 0.01805032230913639
Test Loss:  0.015954041853547096
Valid Loss:  0.019045546650886536
Epoch:  210  	Training Loss: 0.018005238845944405
Test Loss:  0.015912959352135658
Valid Loss:  0.01900223270058632
Epoch:  211  	Training Loss: 0.01796054095029831
Test Loss:  0.015872225165367126
Valid Loss:  0.01895926147699356
Epoch:  212  	Training Loss: 0.017916228622198105
Test Loss:  0.015832163393497467
Valid Loss:  0.018916836008429527
Epoch:  213  	Training Loss: 0.017872609198093414
Test Loss:  0.015792476013302803
Valid Loss:  0.018874743953347206
Epoch:  214  	Training Loss: 0.017829325050115585
 43%|████▎     | 215/500 [02:29<02:53,  1.65it/s] 43%|████▎     | 217/500 [02:29<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:30<01:32,  3.02it/s] 44%|████▍     | 221/500 [02:36<05:22,  1.16s/it] 45%|████▍     | 223/500 [02:36<03:49,  1.21it/s] 45%|████▌     | 225/500 [02:36<02:45,  1.67it/s] 45%|████▌     | 227/500 [02:36<01:59,  2.28it/s] 46%|████▌     | 229/500 [02:36<01:28,  3.06it/s] 46%|████▌     | 231/500 [02:43<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:43<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.00it/s] 48%|████▊     | 241/500 [02:49<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.00it/s] 50%|█████     | 251/500 [02:56<04:50,  1.17s/it] 51%|█████     | 253/500 [02:56<03:26,  1.20it/s] 51%|█████     | 255/500 [02:56<02:28,  1.65it/s] 51%|█████▏    | 257/500 [02:57<01:47,  2.26it/s] 52%|█████▏    | 259/500 [02:57<01:19,  3.04it/s] 52%|█████▏    | 261/500 [03:03<04:38,  1.16s/it] 53%|█████▎    | 263/500 [03:03<03:17,  1.20it/s] 53%|█████▎    | 265/500 [03:03<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:03<01:42,  2.27it/s] 54%|█████▍    | 269/500 [03:03<01:15,  3.05it/s] 54%|█████▍    | 271/500 [03:10<04:26,  1.17s/it] 55%|█████▍    | 273/500 [03:10<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:10<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:10<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:10<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:16<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:02,  1.19it/s]Test Loss:  0.015753109008073807
Valid Loss:  0.018832992762327194
Epoch:  215  	Training Loss: 0.017786407843232155
Test Loss:  0.015714123845100403
Valid Loss:  0.0187915600836277
Epoch:  216  	Training Loss: 0.017743850126862526
Test Loss:  0.015675455331802368
Valid Loss:  0.018750447779893875
Epoch:  217  	Training Loss: 0.017701642587780952
Test Loss:  0.015637144446372986
Valid Loss:  0.01870962232351303
Epoch:  218  	Training Loss: 0.01765977218747139
Test Loss:  0.015599135309457779
Valid Loss:  0.0186691265553236
Epoch:  219  	Training Loss: 0.017618246376514435
Test Loss:  0.015561467036604881
Valid Loss:  0.018628939986228943
Epoch:  220  	Training Loss: 0.017577048391103745
Test Loss:  0.015524111688137054
Valid Loss:  0.018589049577713013
Epoch:  221  	Training Loss: 0.017536185681819916
Test Loss:  0.015487054362893105
Valid Loss:  0.01854943484067917
Epoch:  222  	Training Loss: 0.017495643347501755
Test Loss:  0.015449919737875462
Valid Loss:  0.018509626388549805
Epoch:  223  	Training Loss: 0.017454955726861954
Test Loss:  0.015413078479468822
Valid Loss:  0.01847017928957939
Epoch:  224  	Training Loss: 0.017414603382349014
Test Loss:  0.015376528725028038
Valid Loss:  0.01843101531267166
Epoch:  225  	Training Loss: 0.017374565824866295
Test Loss:  0.01534029096364975
Valid Loss:  0.018392132595181465
Epoch:  226  	Training Loss: 0.017334841191768646
Test Loss:  0.015304328873753548
Valid Loss:  0.01835349202156067
Epoch:  227  	Training Loss: 0.017295395955443382
Test Loss:  0.015268657356500626
Valid Loss:  0.018315136432647705
Epoch:  228  	Training Loss: 0.01725626178085804
Test Loss:  0.01523327175527811
Valid Loss:  0.018276996910572052
Epoch:  229  	Training Loss: 0.01721738651394844
Test Loss:  0.015198137611150742
Valid Loss:  0.01823912374675274
Epoch:  230  	Training Loss: 0.017178820446133614
Test Loss:  0.015163278207182884
Valid Loss:  0.018201492726802826
Epoch:  231  	Training Loss: 0.01714051514863968
Test Loss:  0.015128694474697113
Valid Loss:  0.01816413179039955
Epoch:  232  	Training Loss: 0.017102498561143875
Test Loss:  0.015094464644789696
Valid Loss:  0.018127012997865677
Epoch:  233  	Training Loss: 0.017064832150936127
Test Loss:  0.015060468576848507
Valid Loss:  0.018090225756168365
Epoch:  234  	Training Loss: 0.017027471214532852
Test Loss:  0.015026755630970001
Valid Loss:  0.01805368810892105
Epoch:  235  	Training Loss: 0.016990359872579575
Test Loss:  0.014993269927799702
Valid Loss:  0.01801738329231739
Epoch:  236  	Training Loss: 0.016953516751527786
Test Loss:  0.014960011467337608
Valid Loss:  0.017981287091970444
Epoch:  237  	Training Loss: 0.016916919499635696
Test Loss:  0.014927010983228683
Valid Loss:  0.017945412546396255
Epoch:  238  	Training Loss: 0.0168805830180645
Test Loss:  0.014894245192408562
Valid Loss:  0.01790984347462654
Epoch:  239  	Training Loss: 0.016844486817717552
Test Loss:  0.014861692674458027
Valid Loss:  0.01787448301911354
Epoch:  240  	Training Loss: 0.016808627173304558
Test Loss:  0.014829372055828571
Valid Loss:  0.017839353531599045
Epoch:  241  	Training Loss: 0.016773007810115814
Test Loss:  0.014797274023294449
Valid Loss:  0.01780441775918007
Epoch:  242  	Training Loss: 0.016737623140215874
Test Loss:  0.01476537436246872
Valid Loss:  0.01776963844895363
Epoch:  243  	Training Loss: 0.01670243963599205
Test Loss:  0.014733674004673958
Valid Loss:  0.017735041677951813
Epoch:  244  	Training Loss: 0.01666746288537979
Test Loss:  0.014702217653393745
Valid Loss:  0.017700642347335815
Epoch:  245  	Training Loss: 0.01663270965218544
Test Loss:  0.014670931734144688
Valid Loss:  0.017666475847363472
Epoch:  246  	Training Loss: 0.016598202288150787
Test Loss:  0.014639895409345627
Valid Loss:  0.01763249933719635
Epoch:  247  	Training Loss: 0.016563910990953445
Test Loss:  0.014609050936996937
Valid Loss:  0.017598720267415047
Epoch:  248  	Training Loss: 0.016529837623238564
Test Loss:  0.01457840297371149
Valid Loss:  0.017565131187438965
Epoch:  249  	Training Loss: 0.016495972871780396
Test Loss:  0.014547953382134438
Valid Loss:  0.01753171905875206
Epoch:  250  	Training Loss: 0.016462307423353195
Test Loss:  0.014517729170620441
Valid Loss:  0.017498519271612167
Epoch:  251  	Training Loss: 0.016428876668214798
Test Loss:  0.014487694948911667
Valid Loss:  0.017465535551309586
Epoch:  252  	Training Loss: 0.01639566384255886
Test Loss:  0.014457999728620052
Valid Loss:  0.017432838678359985
Epoch:  253  	Training Loss: 0.016362769529223442
Test Loss:  0.01442851684987545
Valid Loss:  0.017400316894054413
Epoch:  254  	Training Loss: 0.01633007638156414
Test Loss:  0.014399213716387749
Valid Loss:  0.017367959022521973
Epoch:  255  	Training Loss: 0.016297584399580956
Test Loss:  0.014370093122124672
Valid Loss:  0.01733582280576229
Epoch:  256  	Training Loss: 0.016265274956822395
Test Loss:  0.014341139234602451
Valid Loss:  0.017303839325904846
Epoch:  257  	Training Loss: 0.016233162954449654
Test Loss:  0.014312408864498138
Valid Loss:  0.01727202534675598
Epoch:  258  	Training Loss: 0.01620122604072094
Test Loss:  0.014283818192780018
Valid Loss:  0.01724039390683174
Epoch:  259  	Training Loss: 0.016169482842087746
Test Loss:  0.014255421236157417
Valid Loss:  0.017208924517035484
Epoch:  260  	Training Loss: 0.01613791659474373
Test Loss:  0.014227187260985374
Valid Loss:  0.017177585512399673
Epoch:  261  	Training Loss: 0.016106538474559784
Test Loss:  0.014199107885360718
Valid Loss:  0.01714641973376274
Epoch:  262  	Training Loss: 0.016075333580374718
Test Loss:  0.014170747250318527
Valid Loss:  0.017115037888288498
Epoch:  263  	Training Loss: 0.016043830662965775
Test Loss:  0.014142544008791447
Valid Loss:  0.0170837864279747
Epoch:  264  	Training Loss: 0.016012489795684814
Test Loss:  0.014114483259618282
Valid Loss:  0.017052723094820976
Epoch:  265  	Training Loss: 0.01598132774233818
Test Loss:  0.014086597599089146
Valid Loss:  0.017021801322698593
Epoch:  266  	Training Loss: 0.01595035009086132
Test Loss:  0.014058873057365417
Valid Loss:  0.01699104718863964
Epoch:  267  	Training Loss: 0.015919512137770653
Test Loss:  0.014031313359737396
Valid Loss:  0.01696043834090233
Epoch:  268  	Training Loss: 0.015888864174485207
Test Loss:  0.014003878459334373
Valid Loss:  0.016930002719163895
Epoch:  269  	Training Loss: 0.01585838384926319
Test Loss:  0.013976627960801125
Valid Loss:  0.01689968630671501
Epoch:  270  	Training Loss: 0.015828052535653114
Test Loss:  0.013949536718428135
Valid Loss:  0.016869517043232918
Epoch:  271  	Training Loss: 0.015797892585396767
Test Loss:  0.013922598212957382
Valid Loss:  0.01683947443962097
Epoch:  272  	Training Loss: 0.015767894685268402
Test Loss:  0.013895743526518345
Valid Loss:  0.016809547320008278
Epoch:  273  	Training Loss: 0.015738001093268394
Test Loss:  0.013869037851691246
Valid Loss:  0.01677975431084633
Epoch:  274  	Training Loss: 0.015708256512880325
Test Loss:  0.013842507265508175
Valid Loss:  0.016750093549489975
Epoch:  275  	Training Loss: 0.01567867025732994
Test Loss:  0.013816100545227528
Valid Loss:  0.01672055386006832
Epoch:  276  	Training Loss: 0.015649238601326942
Test Loss:  0.01378986332565546
Valid Loss:  0.0166911780834198
Epoch:  277  	Training Loss: 0.01561996154487133
Test Loss:  0.013763738796114922
Valid Loss:  0.016661886125802994
Epoch:  278  	Training Loss: 0.015590820461511612
Test Loss:  0.013737747445702553
Valid Loss:  0.016632739454507828
Epoch:  279  	Training Loss: 0.015561826527118683
Test Loss:  0.013711913488805294
Valid Loss:  0.016603710129857063
Epoch:  280  	Training Loss: 0.015532974153757095
Test Loss:  0.013686195015907288
Valid Loss:  0.016574792563915253
Epoch:  281  	Training Loss: 0.015504259616136551
Test Loss:  0.013660624623298645
Valid Loss:  0.01654599979519844
Epoch:  282  	Training Loss: 0.015475686639547348
Test Loss:  0.013635171577334404
Valid Loss:  0.016517331823706627
Epoch:  283  	Training Loss: 0.01544724591076374
Test Loss:  0.013609841465950012
Valid Loss:  0.016488783061504364
Epoch:  284  	Training Loss: 0.015418932773172855
Test Loss:  0.013584633357822895
Valid Loss:   57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:17<01:09,  3.02it/s] 58%|█████▊    | 291/500 [03:23<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:23<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.23it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.01it/s] 60%|██████    | 301/500 [03:30<03:52,  1.17s/it] 61%|██████    | 303/500 [03:30<02:45,  1.19it/s] 61%|██████    | 305/500 [03:30<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:30<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:31<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:37<03:39,  1.16s/it] 63%|██████▎   | 313/500 [03:37<02:36,  1.20it/s] 63%|██████▎   | 315/500 [03:37<01:51,  1.66it/s] 63%|██████▎   | 317/500 [03:37<01:20,  2.26it/s] 64%|██████▍   | 319/500 [03:37<00:59,  3.03it/s] 64%|██████▍   | 321/500 [03:44<03:30,  1.17s/it] 65%|██████▍   | 323/500 [03:44<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:44<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:44<01:17,  2.25it/s] 66%|██████▌   | 329/500 [03:44<00:56,  3.02it/s] 66%|██████▌   | 331/500 [03:50<03:20,  1.19s/it] 67%|██████▋   | 333/500 [03:51<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:51<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:51<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:51<00:53,  2.98it/s] 68%|██████▊   | 341/500 [03:57<03:04,  1.16s/it] 69%|██████▊   | 343/500 [03:57<02:10,  1.20it/s] 69%|██████▉   | 345/500 [03:57<01:33,  1.66it/s] 69%|██████▉   | 347/500 [03:58<01:07,  2.27it/s] 70%|██████▉   | 349/500 [03:58<00:49,  3.05it/s] 70%|███████   | 351/500 [04:04<02:55,  1.18s/it] 71%|███████   | 353/500 [04:04<02:03,  1.19it/s]0.016460351645946503
Epoch:  285  	Training Loss: 0.01539074257016182
Test Loss:  0.013559548184275627
Valid Loss:  0.01643201895058155
Epoch:  286  	Training Loss: 0.015362693928182125
Test Loss:  0.013534588739275932
Valid Loss:  0.01640380173921585
Epoch:  287  	Training Loss: 0.015334762632846832
Test Loss:  0.013509745709598064
Valid Loss:  0.01637566089630127
Epoch:  288  	Training Loss: 0.015306966379284859
Test Loss:  0.013485034927725792
Valid Loss:  0.016347672790288925
Epoch:  289  	Training Loss: 0.01527930237352848
Test Loss:  0.013460416346788406
Valid Loss:  0.016319753602147102
Epoch:  290  	Training Loss: 0.01525175292044878
Test Loss:  0.013435941189527512
Valid Loss:  0.016291987150907516
Epoch:  291  	Training Loss: 0.015224337577819824
Test Loss:  0.013411575928330421
Valid Loss:  0.016264310106635094
Epoch:  292  	Training Loss: 0.015197033062577248
Test Loss:  0.013387668877840042
Valid Loss:  0.016237055882811546
Epoch:  293  	Training Loss: 0.015170218423008919
Test Loss:  0.01336386427283287
Valid Loss:  0.0162099227309227
Epoch:  294  	Training Loss: 0.015143527649343014
Test Loss:  0.013340167701244354
Valid Loss:  0.016182871535420418
Epoch:  295  	Training Loss: 0.01511694211512804
Test Loss:  0.013316582888364792
Valid Loss:  0.01615593209862709
Epoch:  296  	Training Loss: 0.015090469270944595
Test Loss:  0.013293078169226646
Valid Loss:  0.01612906903028488
Epoch:  297  	Training Loss: 0.015064087696373463
Test Loss:  0.013269682414829731
Valid Loss:  0.016102291643619537
Epoch:  298  	Training Loss: 0.015037821605801582
Test Loss:  0.013246381655335426
Valid Loss:  0.01607561856508255
Epoch:  299  	Training Loss: 0.015011658892035484
Test Loss:  0.01322319358587265
Valid Loss:  0.01604902185499668
Epoch:  300  	Training Loss: 0.01498560793697834
Test Loss:  0.013200094923377037
Valid Loss:  0.01602252572774887
Epoch:  301  	Training Loss: 0.014959649182856083
Test Loss:  0.013177110813558102
Valid Loss:  0.015996109694242477
Epoch:  302  	Training Loss: 0.014933811500668526
Test Loss:  0.013154195621609688
Valid Loss:  0.01596982590854168
Epoch:  303  	Training Loss: 0.014908058568835258
Test Loss:  0.013131358660757542
Valid Loss:  0.015943609178066254
Epoch:  304  	Training Loss: 0.014882415533065796
Test Loss:  0.01310863345861435
Valid Loss:  0.015917520970106125
Epoch:  305  	Training Loss: 0.014856869354844093
Test Loss:  0.013085974380373955
Valid Loss:  0.015891514718532562
Epoch:  306  	Training Loss: 0.014831417240202427
Test Loss:  0.013063428923487663
Valid Loss:  0.015865575522184372
Epoch:  307  	Training Loss: 0.014806065708398819
Test Loss:  0.013040965422987938
Valid Loss:  0.01583973877131939
Epoch:  308  	Training Loss: 0.014780810102820396
Test Loss:  0.013018583878874779
Valid Loss:  0.015813959762454033
Epoch:  309  	Training Loss: 0.014755635522305965
Test Loss:  0.012996303848922253
Valid Loss:  0.015788258984684944
Epoch:  310  	Training Loss: 0.014730574563145638
Test Loss:  0.012974077835679054
Valid Loss:  0.01576264761388302
Epoch:  311  	Training Loss: 0.014705602079629898
Test Loss:  0.012951966375112534
Valid Loss:  0.015737127512693405
Epoch:  312  	Training Loss: 0.014680705964565277
Test Loss:  0.012929674237966537
Valid Loss:  0.01571148820221424
Epoch:  313  	Training Loss: 0.014655658043920994
Test Loss:  0.012907477095723152
Valid Loss:  0.015685925260186195
Epoch:  314  	Training Loss: 0.014630699530243874
Test Loss:  0.012885361909866333
Valid Loss:  0.015660442411899567
Epoch:  315  	Training Loss: 0.014605831354856491
Test Loss:  0.01286332868039608
Valid Loss:  0.015635035932064056
Epoch:  316  	Training Loss: 0.014581052586436272
Test Loss:  0.012841382063925266
Valid Loss:  0.015609708614647388
Epoch:  317  	Training Loss: 0.01455636415630579
Test Loss:  0.012819517403841019
Valid Loss:  0.015584456734359264
Epoch:  318  	Training Loss: 0.014531762339174747
Test Loss:  0.01279773935675621
Valid Loss:  0.015559264458715916
Epoch:  319  	Training Loss: 0.014507241547107697
Test Loss:  0.012776011601090431
Valid Loss:  0.015534155070781708
Epoch:  320  	Training Loss: 0.014482809230685234
Test Loss:  0.012754376046359539
Valid Loss:  0.015509121119976044
Epoch:  321  	Training Loss: 0.014458460733294487
Test Loss:  0.012732820585370064
Valid Loss:  0.015484156087040901
Epoch:  322  	Training Loss: 0.014434193260967731
Test Loss:  0.012711411342024803
Valid Loss:  0.015459342859685421
Epoch:  323  	Training Loss: 0.014410082250833511
Test Loss:  0.012690072879195213
Valid Loss:  0.01543459203094244
Epoch:  324  	Training Loss: 0.014386050403118134
Test Loss:  0.012668819166719913
Valid Loss:  0.01540993619710207
Epoch:  325  	Training Loss: 0.01436210423707962
Test Loss:  0.012647628784179688
Valid Loss:  0.015385333448648453
Epoch:  326  	Training Loss: 0.014338239096105099
Test Loss:  0.012626510113477707
Valid Loss:  0.015360794961452484
Epoch:  327  	Training Loss: 0.014314443804323673
Test Loss:  0.012605475261807442
Valid Loss:  0.015336360782384872
Epoch:  328  	Training Loss: 0.014290740713477135
Test Loss:  0.012584500014781952
Valid Loss:  0.015312002040445805
Epoch:  329  	Training Loss: 0.014267116785049438
Test Loss:  0.012563574127852917
Valid Loss:  0.01528769638389349
Epoch:  330  	Training Loss: 0.014243563637137413
Test Loss:  0.012542749755084515
Valid Loss:  0.015263445675373077
Epoch:  331  	Training Loss: 0.01422008965164423
Test Loss:  0.012521995231509209
Valid Loss:  0.015239289030432701
Epoch:  332  	Training Loss: 0.014196700416505337
Test Loss:  0.012501150369644165
Valid Loss:  0.01521505881100893
Epoch:  333  	Training Loss: 0.014173222705721855
Test Loss:  0.012480402365326881
Valid Loss:  0.015190886333584785
Epoch:  334  	Training Loss: 0.014149831607937813
Test Loss:  0.0124597093090415
Valid Loss:  0.015166789293289185
Epoch:  335  	Training Loss: 0.014126507565379143
Test Loss:  0.012439100071787834
Valid Loss:  0.015142745338380337
Epoch:  336  	Training Loss: 0.014103269204497337
Test Loss:  0.012418552301824093
Valid Loss:  0.0151187963783741
Epoch:  337  	Training Loss: 0.014080099761486053
Test Loss:  0.01239807903766632
Valid Loss:  0.015094867907464504
Epoch:  338  	Training Loss: 0.01405700109899044
Test Loss:  0.012377637438476086
Valid Loss:  0.015071040019392967
Epoch:  339  	Training Loss: 0.014033978804945946
Test Loss:  0.012357298284769058
Valid Loss:  0.015047246590256691
Epoch:  340  	Training Loss: 0.014011034741997719
Test Loss:  0.012337020598351955
Valid Loss:  0.015023531392216682
Epoch:  341  	Training Loss: 0.013988155871629715
Test Loss:  0.012316801585257053
Valid Loss:  0.014999878592789173
Epoch:  342  	Training Loss: 0.013965344056487083
Test Loss:  0.012296916916966438
Valid Loss:  0.014976558275520802
Epoch:  343  	Training Loss: 0.013942874036729336
Test Loss:  0.01227707788348198
Valid Loss:  0.014953261241316795
Epoch:  344  	Training Loss: 0.013920484110713005
Test Loss:  0.012257304042577744
Valid Loss:  0.014930046163499355
Epoch:  345  	Training Loss: 0.013898164965212345
Test Loss:  0.012237589806318283
Valid Loss:  0.014906857162714005
Epoch:  346  	Training Loss: 0.013875896111130714
Test Loss:  0.012217937037348747
Valid Loss:  0.014883759431540966
Epoch:  347  	Training Loss: 0.013853698968887329
Test Loss:  0.012198356911540031
Valid Loss:  0.014860686846077442
Epoch:  348  	Training Loss: 0.013831563293933868
Test Loss:  0.012178825214505196
Valid Loss:  0.014837697148323059
Epoch:  349  	Training Loss: 0.013809488154947758
Test Loss:  0.012159343808889389
Valid Loss:  0.014814764261245728
Epoch:  350  	Training Loss: 0.013787489384412766
Test Loss:  0.012139919213950634
Valid Loss:  0.014791866764426231
Epoch:  351  	Training Loss: 0.013765545561909676
Test Loss:  0.01212056539952755
Valid Loss:  0.014769047498703003
Epoch:  352  	Training Loss: 0.013743659481406212
Test Loss:  0.012100919149816036
Valid Loss:  0.01474602147936821
Epoch:  353  	Training Loss: 0.013721505180001259
Test Loss:  0.012081336230039597
Valid Loss:  0.014723042026162148
Epoch:  354  	Training Loss: 0.013699410483241081
Test Loss:  0.012061817571520805
Valid Loss:  0.014700125902891159
 71%|███████   | 355/500 [04:04<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:04<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:11<02:43,  1.18s/it] 73%|███████▎  | 363/500 [04:11<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:11<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:11<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:11<00:43,  3.00it/s] 74%|███████▍  | 371/500 [04:18<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:18<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:18<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:18<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:24<02:18,  1.16s/it] 77%|███████▋  | 383/500 [04:24<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:25<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:25<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:25<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:31<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:31<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:31<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:32<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:32<00:33,  2.99it/s] 80%|████████  | 401/500 [04:38<01:56,  1.18s/it] 81%|████████  | 403/500 [04:38<01:22,  1.18it/s] 81%|████████  | 405/500 [04:38<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:38<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.00it/s] 82%|████████▏ | 411/500 [04:45<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:45<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:45<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:45<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:45<00:27,  2.96it/s] 84%|████████▍ | 421/500 [04:52<01:32,  1.18s/it] 85%|████████▍ | 423/500 [04:52<01:05,  1.18it/s]Epoch:  355  	Training Loss: 0.013677379116415977
Test Loss:  0.012042349204421043
Valid Loss:  0.014677274972200394
Epoch:  356  	Training Loss: 0.013655410148203373
Test Loss:  0.012022942304611206
Valid Loss:  0.014654457569122314
Epoch:  357  	Training Loss: 0.013633504509925842
Test Loss:  0.012003579176962376
Valid Loss:  0.01463169977068901
Epoch:  358  	Training Loss: 0.013611659407615662
Test Loss:  0.011984286829829216
Valid Loss:  0.014609001576900482
Epoch:  359  	Training Loss: 0.013589875772595406
Test Loss:  0.011965058743953705
Valid Loss:  0.014586380682885647
Epoch:  360  	Training Loss: 0.013568160124123096
Test Loss:  0.011945861391723156
Valid Loss:  0.014563802629709244
Epoch:  361  	Training Loss: 0.013546505011618137
Test Loss:  0.011926739476621151
Valid Loss:  0.014541279524564743
Epoch:  362  	Training Loss: 0.013524909503757954
Test Loss:  0.011907786130905151
Valid Loss:  0.01451889704912901
Epoch:  363  	Training Loss: 0.013503480702638626
Test Loss:  0.011888891458511353
Valid Loss:  0.014496530406177044
Epoch:  364  	Training Loss: 0.013482114300131798
Test Loss:  0.011870022863149643
Valid Loss:  0.014474241062998772
Epoch:  365  	Training Loss: 0.013460807502269745
Test Loss:  0.0118512362241745
Valid Loss:  0.014451989904046059
Epoch:  366  	Training Loss: 0.013439556583762169
Test Loss:  0.011832496151328087
Valid Loss:  0.014429787173867226
Epoch:  367  	Training Loss: 0.013418355025351048
Test Loss:  0.011813795194029808
Valid Loss:  0.014407661743462086
Epoch:  368  	Training Loss: 0.01339721865952015
Test Loss:  0.011795138008892536
Valid Loss:  0.01438554935157299
Epoch:  369  	Training Loss: 0.013376142829656601
Test Loss:  0.011776544153690338
Valid Loss:  0.014363505877554417
Epoch:  370  	Training Loss: 0.013355107046663761
Test Loss:  0.011757995001971722
Valid Loss:  0.01434151828289032
Epoch:  371  	Training Loss: 0.013334136456251144
Test Loss:  0.011739497072994709
Valid Loss:  0.014319566078484058
Epoch:  372  	Training Loss: 0.013313211500644684
Test Loss:  0.011720724403858185
Valid Loss:  0.014297368936240673
Epoch:  373  	Training Loss: 0.013291999697685242
Test Loss:  0.011701968498528004
Valid Loss:  0.014275250025093555
Epoch:  374  	Training Loss: 0.013270838186144829
Test Loss:  0.011683288961648941
Valid Loss:  0.014253167435526848
Epoch:  375  	Training Loss: 0.013249730691313744
Test Loss:  0.01166464202105999
Valid Loss:  0.014231115579605103
Epoch:  376  	Training Loss: 0.01322868000715971
Test Loss:  0.011646049097180367
Valid Loss:  0.014209132641553879
Epoch:  377  	Training Loss: 0.013207675889134407
Test Loss:  0.011627532541751862
Valid Loss:  0.014187183231115341
Epoch:  378  	Training Loss: 0.0131867416203022
Test Loss:  0.011609043926000595
Valid Loss:  0.014165296219289303
Epoch:  379  	Training Loss: 0.013165848329663277
Test Loss:  0.011590586975216866
Valid Loss:  0.014143437147140503
Epoch:  380  	Training Loss: 0.013145018368959427
Test Loss:  0.011572200804948807
Valid Loss:  0.014121646992862225
Epoch:  381  	Training Loss: 0.01312423124909401
Test Loss:  0.011553862132132053
Valid Loss:  0.014099881052970886
Epoch:  382  	Training Loss: 0.013103500008583069
Test Loss:  0.01153594721108675
Valid Loss:  0.014078528620302677
Epoch:  383  	Training Loss: 0.013083239085972309
Test Loss:  0.011518089100718498
Valid Loss:  0.014057222753763199
Epoch:  384  	Training Loss: 0.013063020072877407
Test Loss:  0.011500265449285507
Valid Loss:  0.014035950414836407
Epoch:  385  	Training Loss: 0.013042845763266087
Test Loss:  0.011482509784400463
Valid Loss:  0.01401473954319954
Epoch:  386  	Training Loss: 0.01302272081375122
Test Loss:  0.01146477647125721
Valid Loss:  0.013993550091981888
Epoch:  387  	Training Loss: 0.013002658262848854
Test Loss:  0.011447075754404068
Valid Loss:  0.013972445391118526
Epoch:  388  	Training Loss: 0.012982629239559174
Test Loss:  0.011429453268647194
Valid Loss:  0.013951357454061508
Epoch:  389  	Training Loss: 0.012962667271494865
Test Loss:  0.01141185313463211
Valid Loss:  0.013930317014455795
Epoch:  390  	Training Loss: 0.01294273603707552
Test Loss:  0.011394299566745758
Valid Loss:  0.013909312896430492
Epoch:  391  	Training Loss: 0.012922858819365501
Test Loss:  0.011376781389117241
Valid Loss:  0.013888371177017689
Epoch:  392  	Training Loss: 0.012903020717203617
Test Loss:  0.01135899219661951
Valid Loss:  0.013867194764316082
Epoch:  393  	Training Loss: 0.012882919982075691
Test Loss:  0.011341266334056854
Valid Loss:  0.013846088200807571
Epoch:  394  	Training Loss: 0.01286287046968937
Test Loss:  0.011323584243655205
Valid Loss:  0.013825029134750366
Epoch:  395  	Training Loss: 0.012842878699302673
Test Loss:  0.011305954307317734
Valid Loss:  0.013804002664983273
Epoch:  396  	Training Loss: 0.012822931632399559
Test Loss:  0.011288352310657501
Valid Loss:  0.013783023692667484
Epoch:  397  	Training Loss: 0.012803029268980026
Test Loss:  0.011270774528384209
Valid Loss:  0.013762087561190128
Epoch:  398  	Training Loss: 0.012783168815076351
Test Loss:  0.011253269389271736
Valid Loss:  0.013741180300712585
Epoch:  399  	Training Loss: 0.01276335958391428
Test Loss:  0.011235792189836502
Valid Loss:  0.01372033916413784
Epoch:  400  	Training Loss: 0.012743594124913216
Test Loss:  0.011218363419175148
Valid Loss:  0.013699516654014587
Epoch:  401  	Training Loss: 0.012723889201879501
Test Loss:  0.011200975626707077
Valid Loss:  0.01367875374853611
Epoch:  402  	Training Loss: 0.012704218737781048
Test Loss:  0.011183906346559525
Valid Loss:  0.013658247888088226
Epoch:  403  	Training Loss: 0.012684864923357964
Test Loss:  0.011166865937411785
Valid Loss:  0.013637798838317394
Epoch:  404  	Training Loss: 0.01266557164490223
Test Loss:  0.011149863712489605
Valid Loss:  0.013617368414998055
Epoch:  405  	Training Loss: 0.012646308168768883
Test Loss:  0.011132915504276752
Valid Loss:  0.013596977107226849
Epoch:  406  	Training Loss: 0.012627089396119118
Test Loss:  0.011115980334579945
Valid Loss:  0.013576645404100418
Epoch:  407  	Training Loss: 0.012607920914888382
Test Loss:  0.01109908428043127
Valid Loss:  0.013556331396102905
Epoch:  408  	Training Loss: 0.012588785029947758
Test Loss:  0.011082231998443604
Valid Loss:  0.01353607326745987
Epoch:  409  	Training Loss: 0.01256970502436161
Test Loss:  0.011065442115068436
Valid Loss:  0.013515842147171497
Epoch:  410  	Training Loss: 0.012550653889775276
Test Loss:  0.01104867085814476
Valid Loss:  0.0134956743568182
Epoch:  411  	Training Loss: 0.01253165490925312
Test Loss:  0.011031941510736942
Valid Loss:  0.013475512154400349
Epoch:  412  	Training Loss: 0.012512697838246822
Test Loss:  0.011015207506716251
Valid Loss:  0.013455383479595184
Epoch:  413  	Training Loss: 0.012493731454014778
Test Loss:  0.010998495854437351
Valid Loss:  0.013435297645628452
Epoch:  414  	Training Loss: 0.012474809773266315
Test Loss:  0.010981842875480652
Valid Loss:  0.013415222987532616
Epoch:  415  	Training Loss: 0.012455930933356285
Test Loss:  0.010965198278427124
Valid Loss:  0.013395213522017002
Epoch:  416  	Training Loss: 0.012437096796929836
Test Loss:  0.010948613286018372
Valid Loss:  0.013375243172049522
Epoch:  417  	Training Loss: 0.012418298982083797
Test Loss:  0.010932061821222305
Valid Loss:  0.013355289585888386
Epoch:  418  	Training Loss: 0.012399550527334213
Test Loss:  0.010915553197264671
Valid Loss:  0.013335379771888256
Epoch:  419  	Training Loss: 0.01238083466887474
Test Loss:  0.010899067856371403
Valid Loss:  0.013315519317984581
Epoch:  420  	Training Loss: 0.012362160719931126
Test Loss:  0.010882634669542313
Valid Loss:  0.013295705430209637
Epoch:  421  	Training Loss: 0.012343536131083965
Test Loss:  0.010866211727261543
Valid Loss:  0.01327591948211193
Epoch:  422  	Training Loss: 0.012324949726462364
Test Loss:  0.010849659331142902
Valid Loss:  0.013256029225885868
Epoch:  423  	Training Loss: 0.012306204065680504
Test Loss:  0.010833139531314373
Valid Loss:  0.013236165046691895
Epoch:  424  	Training Loss: 0.012287507764995098
Test Loss:  0.010816643014550209
Valid Loss:  0.013216337189078331
 85%|████████▌ | 425/500 [04:52<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:52<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:52<00:23,  3.00it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.64it/s] 87%|████████▋ | 437/500 [04:59<00:28,  2.24it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:05<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:05<00:48,  1.19it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:12<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:12<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:12<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:19<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:19<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:26<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:26<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:26<00:10,  2.21it/s] 96%|█████████▌| 479/500 [05:26<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:33<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.18it/s]Epoch:  425  	Training Loss: 0.01226884126663208
Test Loss:  0.010800188407301903
Valid Loss:  0.013196553103625774
Epoch:  426  	Training Loss: 0.01225021481513977
Test Loss:  0.010783765465021133
Valid Loss:  0.013176817446947098
Epoch:  427  	Training Loss: 0.012231636792421341
Test Loss:  0.010767368599772453
Valid Loss:  0.013157103210687637
Epoch:  428  	Training Loss: 0.012213096022605896
Test Loss:  0.010751036927103996
Valid Loss:  0.013137418776750565
Epoch:  429  	Training Loss: 0.012194594368338585
Test Loss:  0.010734738782048225
Valid Loss:  0.013117803260684013
Epoch:  430  	Training Loss: 0.012176141142845154
Test Loss:  0.010718464851379395
Valid Loss:  0.013098213821649551
Epoch:  431  	Training Loss: 0.012157708406448364
Test Loss:  0.010702203959226608
Valid Loss:  0.013078633695840836
Epoch:  432  	Training Loss: 0.012139320373535156
Test Loss:  0.010686138644814491
Valid Loss:  0.013059208169579506
Epoch:  433  	Training Loss: 0.012121103703975677
Test Loss:  0.010670091956853867
Valid Loss:  0.013039831072092056
Epoch:  434  	Training Loss: 0.01210293360054493
Test Loss:  0.01065407320857048
Valid Loss:  0.013020453974604607
Epoch:  435  	Training Loss: 0.012084792368113995
Test Loss:  0.01063811220228672
Valid Loss:  0.01300112996250391
Epoch:  436  	Training Loss: 0.012066692113876343
Test Loss:  0.010622184723615646
Valid Loss:  0.012981826439499855
Epoch:  437  	Training Loss: 0.012048630975186825
Test Loss:  0.010606274008750916
Valid Loss:  0.012962587177753448
Epoch:  438  	Training Loss: 0.012030605226755142
Test Loss:  0.010590411722660065
Valid Loss:  0.012943337671458721
Epoch:  439  	Training Loss: 0.01201261579990387
Test Loss:  0.01057456061244011
Valid Loss:  0.012924161739647388
Epoch:  440  	Training Loss: 0.011994661763310432
Test Loss:  0.010558746755123138
Valid Loss:  0.012904984876513481
Epoch:  441  	Training Loss: 0.011976748704910278
Test Loss:  0.010542972944676876
Valid Loss:  0.012885868549346924
Epoch:  442  	Training Loss: 0.011958856135606766
Test Loss:  0.010527240112423897
Valid Loss:  0.012866800650954247
Epoch:  443  	Training Loss: 0.011941023170948029
Test Loss:  0.010511519387364388
Valid Loss:  0.012847757898271084
Epoch:  444  	Training Loss: 0.011923214420676231
Test Loss:  0.010495839640498161
Valid Loss:  0.012828761711716652
Epoch:  445  	Training Loss: 0.011905448511242867
Test Loss:  0.010480202734470367
Valid Loss:  0.012809798121452332
Epoch:  446  	Training Loss: 0.011887714266777039
Test Loss:  0.01046457327902317
Valid Loss:  0.012790841050446033
Epoch:  447  	Training Loss: 0.011870011687278748
Test Loss:  0.01044898945838213
Valid Loss:  0.01277194544672966
Epoch:  448  	Training Loss: 0.011852340772747993
Test Loss:  0.010433435440063477
Valid Loss:  0.012753074057400227
Epoch:  449  	Training Loss: 0.011834720149636269
Test Loss:  0.010417900048196316
Valid Loss:  0.012734245508909225
Epoch:  450  	Training Loss: 0.01181713119149208
Test Loss:  0.01040242426097393
Valid Loss:  0.012715439312160015
Epoch:  451  	Training Loss: 0.011799572966992855
Test Loss:  0.01038696151226759
Valid Loss:  0.012696679681539536
Epoch:  452  	Training Loss: 0.01178206317126751
Test Loss:  0.010371634736657143
Valid Loss:  0.012678064405918121
Epoch:  453  	Training Loss: 0.011764680966734886
Test Loss:  0.01035633496940136
Valid Loss:  0.012659459374845028
Epoch:  454  	Training Loss: 0.011747336946427822
Test Loss:  0.010341060347855091
Valid Loss:  0.012640890665352345
Epoch:  455  	Training Loss: 0.011730024591088295
Test Loss:  0.01032582763582468
Valid Loss:  0.01262237410992384
Epoch:  456  	Training Loss: 0.011712746694684029
Test Loss:  0.01031060703098774
Valid Loss:  0.01260387897491455
Epoch:  457  	Training Loss: 0.011695505119860172
Test Loss:  0.010295430198311806
Valid Loss:  0.012585405260324478
Epoch:  458  	Training Loss: 0.011678295210003853
Test Loss:  0.010280299931764603
Valid Loss:  0.012566978111863136
Epoch:  459  	Training Loss: 0.01166112907230854
Test Loss:  0.010265182703733444
Valid Loss:  0.012548597529530525
Epoch:  460  	Training Loss: 0.011643990874290466
Test Loss:  0.010250097140669823
Valid Loss:  0.012530237436294556
Epoch:  461  	Training Loss: 0.011626888066530228
Test Loss:  0.010235056281089783
Valid Loss:  0.012511922046542168
Epoch:  462  	Training Loss: 0.011609818786382675
Test Loss:  0.010220259428024292
Valid Loss:  0.012493830174207687
Epoch:  463  	Training Loss: 0.011593029834330082
Test Loss:  0.010205518454313278
Valid Loss:  0.012475770898163319
Epoch:  464  	Training Loss: 0.01157628558576107
Test Loss:  0.010190799832344055
Valid Loss:  0.012457750737667084
Epoch:  465  	Training Loss: 0.01155956368893385
Test Loss:  0.010176112875342369
Valid Loss:  0.012439750134944916
Epoch:  466  	Training Loss: 0.011542880907654762
Test Loss:  0.010161442682147026
Valid Loss:  0.012421823106706142
Epoch:  467  	Training Loss: 0.011526225134730339
Test Loss:  0.010146812535822392
Valid Loss:  0.01240389421582222
Epoch:  468  	Training Loss: 0.011509605683386326
Test Loss:  0.010132204741239548
Valid Loss:  0.012386007234454155
Epoch:  469  	Training Loss: 0.0114930160343647
Test Loss:  0.010117623955011368
Valid Loss:  0.0123681565746665
Epoch:  470  	Training Loss: 0.011476462706923485
Test Loss:  0.010103062726557255
Valid Loss:  0.012350333854556084
Epoch:  471  	Training Loss: 0.01145994197577238
Test Loss:  0.010088551789522171
Valid Loss:  0.01233254186809063
Epoch:  472  	Training Loss: 0.011443454772233963
Test Loss:  0.010073864832520485
Valid Loss:  0.012314632534980774
Epoch:  473  	Training Loss: 0.011426787823438644
Test Loss:  0.010059187188744545
Valid Loss:  0.012296730652451515
Epoch:  474  	Training Loss: 0.011410151608288288
Test Loss:  0.010044548660516739
Valid Loss:  0.01227889396250248
Epoch:  475  	Training Loss: 0.011393561027944088
Test Loss:  0.010029928758740425
Valid Loss:  0.01226106472313404
Epoch:  476  	Training Loss: 0.01137698907405138
Test Loss:  0.010015354491770267
Valid Loss:  0.012243272736668587
Epoch:  477  	Training Loss: 0.011360462754964828
Test Loss:  0.01000080443918705
Valid Loss:  0.012225523591041565
Epoch:  478  	Training Loss: 0.011343959718942642
Test Loss:  0.0099862739443779
Valid Loss:  0.012207805179059505
Epoch:  479  	Training Loss: 0.011327498592436314
Test Loss:  0.009971778839826584
Valid Loss:  0.012190105393528938
Epoch:  480  	Training Loss: 0.011311057955026627
Test Loss:  0.009957322850823402
Valid Loss:  0.01217244565486908
Epoch:  481  	Training Loss: 0.011294655501842499
Test Loss:  0.009942876175045967
Valid Loss:  0.012154807336628437
Epoch:  482  	Training Loss: 0.01127828098833561
Test Loss:  0.009928224608302116
Valid Loss:  0.012136999517679214
Epoch:  483  	Training Loss: 0.011261699721217155
Test Loss:  0.009913607500493526
Valid Loss:  0.01211921963840723
Epoch:  484  	Training Loss: 0.01124514639377594
Test Loss:  0.00989900715649128
Valid Loss:  0.01210147887468338
Epoch:  485  	Training Loss: 0.011228621006011963
Test Loss:  0.009884453378617764
Valid Loss:  0.01208378467708826
Epoch:  486  	Training Loss: 0.011212131939828396
Test Loss:  0.009869917295873165
Valid Loss:  0.012066099792718887
Epoch:  487  	Training Loss: 0.011195676401257515
Test Loss:  0.009855400770902634
Valid Loss:  0.012048431672155857
Epoch:  488  	Training Loss: 0.011179251596331596
Test Loss:  0.00984092615544796
Valid Loss:  0.01203082874417305
Epoch:  489  	Training Loss: 0.01116285938769579
Test Loss:  0.00982646830379963
Valid Loss:  0.012013234198093414
Epoch:  490  	Training Loss: 0.01114649698138237
Test Loss:  0.009812038391828537
Valid Loss:  0.011995676904916763
Epoch:  491  	Training Loss: 0.01113017275929451
Test Loss:  0.009797662496566772
Valid Loss:  0.011978153139352798
Epoch:  492  	Training Loss: 0.011113866232335567
Test Loss:  0.009783373214304447
Valid Loss:  0.011960726231336594
Epoch:  493  	Training Loss: 0.011097690090537071
Test Loss:  0.009769114665687084
Valid Loss:  0.011943353340029716
Epoch:  494  	Training Loss: 0.011081546545028687
Test Loss:  0.009754886850714684
Valid Loss:  0.011926013976335526
Epoch:  495  	Training Loss: 0.01106543093919754
 99%|█████████▉| 495/500 [05:40<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.23it/s]100%|█████████▉| 499/500 [05:40<00:00,  3.00it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
Test Loss:  0.009740673005580902
Valid Loss:  0.011908667162060738
Epoch:  496  	Training Loss: 0.011049343273043633
Test Loss:  0.009726513177156448
Valid Loss:  0.011891404166817665
Epoch:  497  	Training Loss: 0.011033293791115284
Test Loss:  0.009712355211377144
Valid Loss:  0.011874131858348846
Epoch:  498  	Training Loss: 0.011017272248864174
Test Loss:  0.009698241949081421
Valid Loss:  0.011856913566589355
Epoch:  499  	Training Loss: 0.011001281440258026
Test Loss:  0.009684154763817787
Valid Loss:  0.011839699000120163
Epoch:  500  	Training Loss: 0.01098532322794199
Test Loss:  0.009670102968811989
Valid Loss:  0.011822523549199104
seed is  10
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:15,  6.16s/it]  1%|          | 3/500 [00:06<13:38,  1.65s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.94it/s]  2%|▏         | 11/500 [00:12<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:13<05:06,  1.58it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:31,  1.19s/it]  5%|▍         | 23/500 [00:19<06:45,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:26<09:16,  1.19s/it]  7%|▋         | 33/500 [00:26<06:38,  1.17it/s]  7%|▋         | 35/500 [00:26<04:47,  1.62it/s]  7%|▋         | 37/500 [00:27<03:29,  2.21it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<08:57,  1.17s/it]  9%|▊         | 43/500 [00:33<06:24,  1.19it/s]  9%|▉         | 45/500 [00:39<11:35,  1.53s/it]  9%|▉         | 47/500 [00:39<08:14,  1.09s/it] 10%|▉         | 49/500 [00:40<05:53,  1.28it/s] 10%|█         | 51/500 [00:46<11:03,  1.48s/it] 11%|█         | 53/500 [00:46<07:51,  1.06s/it] 11%|█         | 55/500 [00:46<05:37,  1.32it/s] 11%|█▏        | 57/500 [00:46<04:04,  1.81it/s] 12%|█▏        | 59/500 [00:46<02:58,  2.47it/s] 12%|█▏        | 61/500 [00:53<08:52,  1.21s/it] 13%|█▎        | 63/500 [00:53<06:20,  1.15it/s] 13%|█▎        | 65/500 [00:53<04:33,  1.59it/s] 13%|█▎        | 67/500 [00:53<03:19,  2.17it/s] 14%|█▍        | 69/500 [00:53<02:27,  2.93it/s]Epoch:  1  	Training Loss: 0.06746320426464081
Test Loss:  0.15699632465839386
Valid Loss:  0.16187520325183868
Epoch:  2  	Training Loss: 0.15781596302986145
Test Loss:  1.055221438407898
Valid Loss:  1.0218108892440796
Epoch:  3  	Training Loss: 1.0332391262054443
Test Loss:  0.03743666410446167
Valid Loss:  0.043625183403491974
Epoch:  4  	Training Loss: 0.03991922736167908
Test Loss:  0.03668273240327835
Valid Loss:  0.04304419830441475
Epoch:  5  	Training Loss: 0.03931000828742981
Test Loss:  0.036321476101875305
Valid Loss:  0.04272271692752838
Epoch:  6  	Training Loss: 0.0389961302280426
Test Loss:  0.03609546646475792
Valid Loss:  0.042530037462711334
Epoch:  7  	Training Loss: 0.03880401328206062
Test Loss:  0.03589795529842377
Valid Loss:  0.0423627607524395
Epoch:  8  	Training Loss: 0.038637109100818634
Test Loss:  0.035722516477108
Valid Loss:  0.0422128401696682
Epoch:  9  	Training Loss: 0.038488857448101044
Test Loss:  0.035561807453632355
Valid Loss:  0.04207441210746765
Epoch:  10  	Training Loss: 0.03835538029670715
Test Loss:  0.03541465848684311
Valid Loss:  0.04195193946361542
Epoch:  11  	Training Loss: 0.0382380448281765
Test Loss:  0.035281553864479065
Valid Loss:  0.04184206575155258
Epoch:  12  	Training Loss: 0.03813431039452553
Test Loss:  0.03367691487073898
Valid Loss:  0.040399376302957535
Epoch:  13  	Training Loss: 0.036768846213817596
Test Loss:  0.030517365783452988
Valid Loss:  0.03701610118150711
Epoch:  14  	Training Loss: 0.03364218771457672
Test Loss:  0.028142716735601425
Valid Loss:  0.034411512315273285
Epoch:  15  	Training Loss: 0.03122883476316929
Test Loss:  0.02647375501692295
Valid Loss:  0.03253372013568878
Epoch:  16  	Training Loss: 0.02948804385960102
Test Loss:  0.02501545287668705
Valid Loss:  0.030858492478728294
Epoch:  17  	Training Loss: 0.027937166392803192
Test Loss:  0.02368297427892685
Valid Loss:  0.029308704659342766
Epoch:  18  	Training Loss: 0.02652382105588913
Test Loss:  0.02246009185910225
Valid Loss:  0.027861710637807846
Epoch:  19  	Training Loss: 0.025207065045833588
Test Loss:  0.021328428760170937
Valid Loss:  0.026502657681703568
Epoch:  20  	Training Loss: 0.02397553063929081
Test Loss:  0.020263127982616425
Valid Loss:  0.025227494537830353
Epoch:  21  	Training Loss: 0.022819742560386658
Test Loss:  0.019272562116384506
Valid Loss:  0.024022620171308517
Epoch:  22  	Training Loss: 0.021729979664087296
Test Loss:  0.017951780930161476
Valid Loss:  0.02225680835545063
Epoch:  23  	Training Loss: 0.020132049918174744
Test Loss:  0.01282479241490364
Valid Loss:  0.01606631651520729
Epoch:  24  	Training Loss: 0.014748907648026943
Test Loss:  0.009836860001087189
Valid Loss:  0.012386828660964966
Epoch:  25  	Training Loss: 0.011234717443585396
Test Loss:  0.007830502465367317
Valid Loss:  0.009568790905177593
Epoch:  26  	Training Loss: 0.008947948925197124
Test Loss:  0.006087545305490494
Valid Loss:  0.007864143699407578
Epoch:  27  	Training Loss: 0.007223077118396759
Test Loss:  0.005383007228374481
Valid Loss:  0.006300720386207104
Epoch:  28  	Training Loss: 0.006077749654650688
Test Loss:  0.004195377230644226
Valid Loss:  0.005555514246225357
Epoch:  29  	Training Loss: 0.005225711967796087
Test Loss:  0.004169868770986795
Valid Loss:  0.004671634174883366
Epoch:  30  	Training Loss: 0.004668190144002438
Test Loss:  0.0032391753047704697
Valid Loss:  0.0043655214831233025
Epoch:  31  	Training Loss: 0.004229845479130745
Test Loss:  0.003512490075081587
Valid Loss:  0.003809003159403801
Epoch:  32  	Training Loss: 0.003928324673324823
Test Loss:  0.0026517107617110014
Valid Loss:  0.0033585175406187773
Epoch:  33  	Training Loss: 0.0033736915793269873
Test Loss:  0.0025898385792970657
Valid Loss:  0.0033002523705363274
Epoch:  34  	Training Loss: 0.003315858542919159
Test Loss:  0.0025705769658088684
Valid Loss:  0.0032577309757471085
Epoch:  35  	Training Loss: 0.0032838541083037853
Test Loss:  0.0025515067391097546
Valid Loss:  0.003220328828319907
Epoch:  36  	Training Loss: 0.0032553807832300663
Test Loss:  0.0025325482711195946
Valid Loss:  0.00318605056963861
Epoch:  37  	Training Loss: 0.0032291142269968987
Test Loss:  0.0025138258934020996
Valid Loss:  0.0031543411314487457
Epoch:  38  	Training Loss: 0.003204720327630639
Test Loss:  0.0024951386731117964
Valid Loss:  0.0031243651174008846
Epoch:  39  	Training Loss: 0.003181689651682973
Test Loss:  0.00247747078537941
Valid Loss:  0.0030961467418819666
Epoch:  40  	Training Loss: 0.0031601660884916782
Test Loss:  0.0024602022022008896
Valid Loss:  0.0030696894973516464
Epoch:  41  	Training Loss: 0.003140163142234087
Test Loss:  0.00244395574554801
Valid Loss:  0.003044669982045889
Epoch:  42  	Training Loss: 0.003121420042589307
Test Loss:  0.003500281600281596
Valid Loss:  0.0032816375605762005
Epoch:  43  	Training Loss: 0.003641168586909771
Test Loss:  0.012587269768118858
Valid Loss:  0.01515900157392025
Epoch:  44  	Training Loss: 0.01458079181611538
Test Loss:  0.07539496570825577
Valid Loss:  0.06898118555545807
Epoch:  45  	Training Loss: 0.07147817313671112
Test Loss:  0.06981726735830307
Valid Loss:  0.0769406408071518
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.07501272857189178
Test Loss:  0.04320463538169861
Valid Loss:  0.04915709048509598
Epoch:  47  	Training Loss: 0.04748375341296196
Test Loss:  0.03202268108725548
Valid Loss:  0.037178367376327515
Epoch:  48  	Training Loss: 0.03565170615911484
Test Loss:  0.024432498961687088
Valid Loss:  0.028982412070035934
Epoch:  49  	Training Loss: 0.027598276734352112
Test Loss:  0.01914658211171627
Valid Loss:  0.023225683718919754
Epoch:  50  	Training Loss: 0.021954014897346497
Test Loss:  0.01544477790594101
Valid Loss:  0.01914084330201149
Epoch:  51  	Training Loss: 0.0179657731205225
Test Loss:  0.012843072414398193
Valid Loss:  0.016220668330788612
Epoch:  52  	Training Loss: 0.015137068927288055
Test Loss:  0.009162990376353264
Valid Loss:  0.011953039094805717
Epoch:  53  	Training Loss: 0.011109684593975544
Test Loss:  0.007308616768568754
Valid Loss:  0.009650572203099728
Epoch:  54  	Training Loss: 0.008996591903269291
Test Loss:  0.006536051630973816
Valid Loss:  0.008658555336296558
Epoch:  55  	Training Loss: 0.008100367151200771
Test Loss:  0.006313176825642586
Valid Loss:  0.0082996916025877
Epoch:  56  	Training Loss: 0.007786556147038937
Test Loss:  0.00619732728227973
Valid Loss:  0.008105332963168621
Epoch:  57  	Training Loss: 0.0076363543048501015
Test Loss:  0.006117682904005051
Valid Loss:  0.007978680543601513
Epoch:  58  	Training Loss: 0.007533087395131588
Test Loss:  0.0060478560626506805
Valid Loss:  0.007868270389735699
Epoch:  59  	Training Loss: 0.007440932095050812
Test Loss:  0.005982949864119291
Valid Loss:  0.0077664656564593315
Epoch:  60  	Training Loss: 0.007354958914220333
Test Loss:  0.005921082105487585
Valid Loss:  0.007671595085412264
Epoch:  61  	Training Loss: 0.007273356895893812
Test Loss:  0.005861520767211914
Valid Loss:  0.007581334561109543
Epoch:  62  	Training Loss: 0.007195950485765934
Test Loss:  0.0050946734845638275
Valid Loss:  0.0068294573575258255
Epoch:  63  	Training Loss: 0.006441785022616386
Test Loss:  0.004510028287768364
Valid Loss:  0.0061515383422374725
Epoch:  64  	Training Loss: 0.005805486813187599
Test Loss:  0.0040502725169062614
Valid Loss:  0.005563563201576471
Epoch:  65  	Training Loss: 0.005267149303108454
Test Loss:  0.0036850953474640846
Valid Loss:  0.005063184536993504
Epoch:  66  	Training Loss: 0.004826181568205357
Test Loss:  0.0034274498466402292
Valid Loss:  0.004630939569324255
Epoch:  67  	Training Loss: 0.004464604891836643
Test Loss:  0.003231041133403778
Valid Loss:  0.004295968450605869
Epoch:  68  	Training Loss: 0.004177886992692947
Test Loss:  0.0030850879848003387
Valid Loss:  0.004046631045639515
Epoch:  69  	Training Loss: 0.0039561898447573185
Test Loss:  0.002965169958770275
Valid Loss:  0.0038682403974235058
Epoch:  70  	Training Loss: 0.00378918694332242
Test Loss:  0.0028923656791448593
Valid Loss:  0.0037114585284143686
 14%|█▍        | 71/500 [00:59<08:23,  1.17s/it] 15%|█▍        | 73/500 [00:59<05:58,  1.19it/s] 15%|█▌        | 75/500 [01:00<04:18,  1.64it/s] 15%|█▌        | 77/500 [01:00<03:08,  2.24it/s] 16%|█▌        | 79/500 [01:00<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:06<08:06,  1.16s/it] 17%|█▋        | 83/500 [01:06<05:47,  1.20it/s] 17%|█▋        | 85/500 [01:06<04:10,  1.66it/s] 17%|█▋        | 87/500 [01:06<03:02,  2.27it/s] 18%|█▊        | 89/500 [01:07<02:15,  3.04it/s] 18%|█▊        | 91/500 [01:13<08:00,  1.17s/it] 19%|█▊        | 93/500 [01:13<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:13<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:13<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:13<02:13,  3.01it/s] 20%|██        | 101/500 [01:20<07:43,  1.16s/it] 21%|██        | 103/500 [01:20<05:31,  1.20it/s] 21%|██        | 105/500 [01:20<03:58,  1.66it/s] 21%|██▏       | 107/500 [01:20<02:54,  2.26it/s] 22%|██▏       | 109/500 [01:20<02:09,  3.03it/s] 22%|██▏       | 109/500 [01:33<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:33<13:36,  2.10s/it] 23%|██▎       | 113/500 [01:33<09:36,  1.49s/it] 23%|██▎       | 115/500 [01:33<06:49,  1.06s/it] 23%|██▎       | 117/500 [01:33<04:52,  1.31it/s] 24%|██▍       | 119/500 [01:33<03:31,  1.80it/s] 24%|██▍       | 121/500 [01:45<14:09,  2.24s/it] 25%|██▍       | 123/500 [01:46<09:59,  1.59s/it] 25%|██▌       | 125/500 [01:46<07:05,  1.13s/it] 25%|██▌       | 127/500 [01:46<05:03,  1.23it/s] 26%|██▌       | 129/500 [01:46<03:38,  1.70it/s] 26%|██▌       | 131/500 [01:52<08:14,  1.34s/it] 27%|██▋       | 133/500 [01:52<05:51,  1.05it/s] 27%|██▋       | 135/500 [01:52<04:11,  1.45it/s] 27%|██▋       | 137/500 [01:53<03:02,  1.99it/s]Epoch:  71  	Training Loss: 0.00366422813385725
Test Loss:  0.0027941518928855658
Valid Loss:  0.003594369860365987
Epoch:  72  	Training Loss: 0.0035645170137286186
Test Loss:  0.002696569077670574
Valid Loss:  0.003354877233505249
Epoch:  73  	Training Loss: 0.003381927963346243
Test Loss:  0.0025530834682285786
Valid Loss:  0.003199679544195533
Epoch:  74  	Training Loss: 0.003249596105888486
Test Loss:  0.0024720970541238785
Valid Loss:  0.0030666731763631105
Epoch:  75  	Training Loss: 0.003146670525893569
Test Loss:  0.002377768512815237
Valid Loss:  0.00296246400102973
Epoch:  76  	Training Loss: 0.003064878284931183
Test Loss:  0.002328878967091441
Valid Loss:  0.0028705354779958725
Epoch:  77  	Training Loss: 0.0029981303960084915
Test Loss:  0.0022622637916356325
Valid Loss:  0.002801281865686178
Epoch:  78  	Training Loss: 0.002943896921351552
Test Loss:  0.0022324370220303535
Valid Loss:  0.0027390304021537304
Epoch:  79  	Training Loss: 0.002898369450122118
Test Loss:  0.002186492783948779
Valid Loss:  0.002692295704036951
Epoch:  80  	Training Loss: 0.0028604650869965553
Test Loss:  0.002167852595448494
Valid Loss:  0.0026458054780960083
Epoch:  81  	Training Loss: 0.002827135846018791
Test Loss:  0.002136142458766699
Valid Loss:  0.002610784489661455
Epoch:  82  	Training Loss: 0.0028002860490232706
Test Loss:  0.002080186503008008
Valid Loss:  0.0025206231512129307
Epoch:  83  	Training Loss: 0.00271794106811285
Test Loss:  0.002079329453408718
Valid Loss:  0.002516323234885931
Epoch:  84  	Training Loss: 0.0027141307946294546
Test Loss:  0.002079704776406288
Valid Loss:  0.002511978382244706
Epoch:  85  	Training Loss: 0.0027116104029119015
Test Loss:  0.002078928053379059
Valid Loss:  0.0025083657819777727
Epoch:  86  	Training Loss: 0.002709378022700548
Test Loss:  0.002077875891700387
Valid Loss:  0.0025049797259271145
Epoch:  87  	Training Loss: 0.0027072932571172714
Test Loss:  0.002076739678159356
Valid Loss:  0.002501674694940448
Epoch:  88  	Training Loss: 0.002705287653952837
Test Loss:  0.0020752865821123123
Valid Loss:  0.002498563611879945
Epoch:  89  	Training Loss: 0.0027033546939492226
Test Loss:  0.0020738537423312664
Valid Loss:  0.002495669759809971
Epoch:  90  	Training Loss: 0.0027014720253646374
Test Loss:  0.0020721908658742905
Valid Loss:  0.0024929088540375233
Epoch:  91  	Training Loss: 0.002699659438803792
Test Loss:  0.0020703510381281376
Valid Loss:  0.0024902569130063057
Epoch:  92  	Training Loss: 0.002697926014661789
Test Loss:  0.0020658886060118675
Valid Loss:  0.0024894566740840673
Epoch:  93  	Training Loss: 0.0026969932951033115
Test Loss:  0.0020619421266019344
Valid Loss:  0.0024887723848223686
Epoch:  94  	Training Loss: 0.0026962084230035543
Test Loss:  0.002058445941656828
Valid Loss:  0.002488180063664913
Epoch:  95  	Training Loss: 0.0026955422945320606
Test Loss:  0.002055344171822071
Valid Loss:  0.0024876571260392666
Epoch:  96  	Training Loss: 0.002694971626624465
Test Loss:  0.002052584197372198
Valid Loss:  0.0024871889036148787
Epoch:  97  	Training Loss: 0.002694477792829275
Test Loss:  0.0020501255057752132
Valid Loss:  0.0024867611937224865
Epoch:  98  	Training Loss: 0.002694044727832079
Test Loss:  0.0020479310769587755
Valid Loss:  0.002486366778612137
Epoch:  99  	Training Loss: 0.0026936617214232683
Test Loss:  0.002045969245955348
Valid Loss:  0.002485996577888727
Epoch:  100  	Training Loss: 0.002693318761885166
Test Loss:  0.0020442120730876923
Valid Loss:  0.002485643606632948
Epoch:  101  	Training Loss: 0.0026930070016533136
Test Loss:  0.0020426372066140175
Valid Loss:  0.002485305070877075
Epoch:  102  	Training Loss: 0.002692721551284194
Test Loss:  0.002131122862920165
Valid Loss:  0.0024167727679014206
Epoch:  103  	Training Loss: 0.002675040392205119
Test Loss:  0.0019942782819271088
Valid Loss:  0.002460482297465205
Epoch:  104  	Training Loss: 0.0026662410236895084
Test Loss:  0.0021067080087959766
Valid Loss:  0.0024118658620864153
Epoch:  105  	Training Loss: 0.0026660067960619926
Test Loss:  0.0019893115386366844
Valid Loss:  0.0024527001660317183
Epoch:  106  	Training Loss: 0.002661461243405938
Test Loss:  0.002098551020026207
Valid Loss:  0.002408236265182495
Epoch:  107  	Training Loss: 0.0026625264436006546
Test Loss:  0.001986380899325013
Valid Loss:  0.0024482770822942257
Epoch:  108  	Training Loss: 0.002659242134541273
Test Loss:  0.0020946969743818045
Valid Loss:  0.0024056127294898033
Epoch:  109  	Training Loss: 0.0026608051266521215
Test Loss:  0.001984554808586836
Valid Loss:  0.002444013487547636
Epoch:  110  	Training Loss: 0.0026572509668767452
Test Loss:  0.0020911283791065216
Valid Loss:  0.002402953803539276
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.002659131307154894
Test Loss:  0.0020037146750837564
Valid Loss:  0.0023911597672849894
Epoch:  112  	Training Loss: 0.002625248162075877
Test Loss:  0.0019963248632848263
Valid Loss:  0.002383258193731308
Epoch:  113  	Training Loss: 0.0026188488118350506
Test Loss:  0.001991982338950038
Valid Loss:  0.0023754481226205826
Epoch:  114  	Training Loss: 0.0026132995262742043
Test Loss:  0.0019875415600836277
Valid Loss:  0.002369245048612356
Epoch:  115  	Training Loss: 0.0026095579378306866
Test Loss:  0.0019484234508126974
Valid Loss:  0.0023894812911748886
Epoch:  116  	Training Loss: 0.0026135880034416914
Test Loss:  0.0019889255054295063
Valid Loss:  0.0023626049514859915
Epoch:  117  	Training Loss: 0.0026024742983281612
Test Loss:  0.0019811950623989105
Valid Loss:  0.0023582179564982653
Epoch:  118  	Training Loss: 0.0025980782229453325
Test Loss:  0.0019792092498391867
Valid Loss:  0.0023532353807240725
Epoch:  119  	Training Loss: 0.002594179939478636
Test Loss:  0.0019477782770991325
Valid Loss:  0.0023694103583693504
Epoch:  120  	Training Loss: 0.0025962619110941887
Test Loss:  0.001980334986001253
Valid Loss:  0.002348995301872492
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.002588000614196062
Test Loss:  0.0019442846532911062
Valid Loss:  0.002320565516129136
Epoch:  122  	Training Loss: 0.002558167790994048
Test Loss:  0.001942214323207736
Valid Loss:  0.0023188262712210417
Epoch:  123  	Training Loss: 0.0025558583438396454
Test Loss:  0.001940511167049408
Valid Loss:  0.0023171138018369675
Epoch:  124  	Training Loss: 0.0025537502951920033
Test Loss:  0.0019388560904189944
Valid Loss:  0.0023158949334174395
Epoch:  125  	Training Loss: 0.0025517044123262167
Test Loss:  0.0019373050890862942
Valid Loss:  0.0023147149477154016
Epoch:  126  	Training Loss: 0.002549797063693404
Test Loss:  0.0019358815625309944
Valid Loss:  0.0023135128431022167
Epoch:  127  	Training Loss: 0.002547946758568287
Test Loss:  0.0019345779437571764
Valid Loss:  0.0023123447317630053
Epoch:  128  	Training Loss: 0.0025461711920797825
Test Loss:  0.001933720544911921
Valid Loss:  0.002311085816472769
Epoch:  129  	Training Loss: 0.0025446179788559675
Test Loss:  0.0019330430077388883
Valid Loss:  0.0023098860401660204
Epoch:  130  	Training Loss: 0.0025431516114622355
Test Loss:  0.0019329773494973779
Valid Loss:  0.0023086778819561005
Epoch:  131  	Training Loss: 0.0025420566089451313
Test Loss:  0.0019331283401697874
Valid Loss:  0.002307507209479809
Epoch:  132  	Training Loss: 0.0025410798843950033
Test Loss:  0.0019341274164617062
Valid Loss:  0.002306515583768487
Epoch:  133  	Training Loss: 0.002540638204663992
Test Loss:  0.0019347204361110926
Valid Loss:  0.0023057134822010994
Epoch:  134  	Training Loss: 0.0025402256287634373
Test Loss:  0.0019350128713995218
Valid Loss:  0.0023050494492053986
Epoch:  135  	Training Loss: 0.0025398312136530876
Test Loss:  0.0019350822549313307
Valid Loss:  0.0023044836707413197
Epoch:  136  	Training Loss: 0.002539448207244277
Test Loss:  0.00193498726002872
Valid Loss:  0.0023039905354380608
Epoch:  137  	Training Loss: 0.002539072884246707
Test Loss:  0.001934773987159133
Valid Loss:  0.002303550485521555
 28%|██▊       | 139/500 [01:53<02:13,  2.70it/s] 28%|██▊       | 141/500 [01:59<07:14,  1.21s/it] 29%|██▊       | 143/500 [01:59<05:09,  1.15it/s] 29%|██▉       | 145/500 [01:59<03:42,  1.59it/s] 29%|██▉       | 147/500 [01:59<02:42,  2.18it/s] 30%|██▉       | 149/500 [02:00<01:59,  2.94it/s] 30%|███       | 151/500 [02:06<06:50,  1.18s/it] 31%|███       | 153/500 [02:06<04:52,  1.19it/s] 31%|███       | 155/500 [02:06<03:30,  1.64it/s] 31%|███▏      | 157/500 [02:06<02:33,  2.24it/s] 32%|███▏      | 159/500 [02:06<01:53,  3.02it/s] 32%|███▏      | 161/500 [02:13<06:39,  1.18s/it] 33%|███▎      | 163/500 [02:13<04:44,  1.18it/s] 33%|███▎      | 165/500 [02:13<03:24,  1.63it/s] 33%|███▎      | 167/500 [02:13<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:13<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:19<06:22,  1.16s/it] 35%|███▍      | 173/500 [02:19<04:32,  1.20it/s] 35%|███▌      | 175/500 [02:20<03:16,  1.66it/s] 35%|███▌      | 177/500 [02:20<02:22,  2.26it/s] 36%|███▌      | 179/500 [02:20<01:45,  3.04it/s] 36%|███▌      | 181/500 [02:26<06:14,  1.17s/it] 37%|███▋      | 183/500 [02:26<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:26<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:27<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:27<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:33<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:33<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:33<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:33<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:33<01:39,  3.02it/s] 40%|████      | 201/500 [02:40<05:51,  1.18s/it] 41%|████      | 203/500 [02:40<04:10,  1.18it/s] 41%|████      | 205/500 [02:40<03:00,  1.63it/s]Epoch:  138  	Training Loss: 0.00253876019269228
Test Loss:  0.0019348716596141458
Valid Loss:  0.0023029963485896587
Epoch:  139  	Training Loss: 0.00253849383443594
Test Loss:  0.001934814266860485
Valid Loss:  0.002302509266883135
Epoch:  140  	Training Loss: 0.002538235392421484
Test Loss:  0.0019346470944583416
Valid Loss:  0.002302073175087571
Epoch:  141  	Training Loss: 0.0025379823055118322
Test Loss:  0.0019344453467056155
Valid Loss:  0.0023016631603240967
Epoch:  142  	Training Loss: 0.002537735039368272
Test Loss:  0.0019186092540621758
Valid Loss:  0.0022912444546818733
Epoch:  143  	Training Loss: 0.002527782227844
Test Loss:  0.0019074509618803859
Valid Loss:  0.0022839587181806564
Epoch:  144  	Training Loss: 0.0025201307144016027
Test Loss:  0.0018993427511304617
Valid Loss:  0.00227756449021399
Epoch:  145  	Training Loss: 0.00251379725523293
Test Loss:  0.0018938591238111258
Valid Loss:  0.0022730613127350807
Epoch:  146  	Training Loss: 0.002509314101189375
Test Loss:  0.001889171078801155
Valid Loss:  0.0022691087797284126
Epoch:  147  	Training Loss: 0.0025055119767785072
Test Loss:  0.001886158948764205
Valid Loss:  0.0022658330854028463
Epoch:  148  	Training Loss: 0.0025023461785167456
Test Loss:  0.0018833503127098083
Valid Loss:  0.002262583002448082
Epoch:  149  	Training Loss: 0.002499324968084693
Test Loss:  0.0018811735790222883
Valid Loss:  0.0022596055641770363
Epoch:  150  	Training Loss: 0.002496470231562853
Test Loss:  0.0018795040668919683
Valid Loss:  0.0022569417487829924
Epoch:  151  	Training Loss: 0.0024937728885561228
Test Loss:  0.0018780609825626016
Valid Loss:  0.0022544539533555508
Epoch:  152  	Training Loss: 0.002491404302418232
Test Loss:  0.0018832939676940441
Valid Loss:  0.002250377554446459
Epoch:  153  	Training Loss: 0.0024900841526687145
Test Loss:  0.0018860448617488146
Valid Loss:  0.0022475861478596926
Epoch:  154  	Training Loss: 0.002489242237061262
Test Loss:  0.0018873271765187383
Valid Loss:  0.00224542198702693
Epoch:  155  	Training Loss: 0.0024885465390980244
Test Loss:  0.0018877503462135792
Valid Loss:  0.0022436114959418774
Epoch:  156  	Training Loss: 0.0024879174306988716
Test Loss:  0.0018876863177865744
Valid Loss:  0.0022420173045247793
Epoch:  157  	Training Loss: 0.002487325808033347
Test Loss:  0.0018873512744903564
Valid Loss:  0.0022405660711228848
Epoch:  158  	Training Loss: 0.0024867632891982794
Test Loss:  0.001886839745566249
Valid Loss:  0.0022392196115106344
Epoch:  159  	Training Loss: 0.002486232668161392
Test Loss:  0.001886271871626377
Valid Loss:  0.002237945096567273
Epoch:  160  	Training Loss: 0.002485721604898572
Test Loss:  0.001885683974251151
Valid Loss:  0.0022367299534380436
Epoch:  161  	Training Loss: 0.0024852287024259567
Test Loss:  0.0018850958440452814
Valid Loss:  0.002235562540590763
Epoch:  162  	Training Loss: 0.0024847695603966713
Test Loss:  0.0018849787302315235
Valid Loss:  0.0022354735992848873
Epoch:  163  	Training Loss: 0.002484721364453435
Test Loss:  0.0018848625477403402
Valid Loss:  0.0022353834938257933
Epoch:  164  	Training Loss: 0.0024846734013408422
Test Loss:  0.0018847488099709153
Valid Loss:  0.0022352964151650667
Epoch:  165  	Training Loss: 0.002484625903889537
Test Loss:  0.0018846355378627777
Valid Loss:  0.002235204679891467
Epoch:  166  	Training Loss: 0.0024845791049301624
Test Loss:  0.0018845249433070421
Valid Loss:  0.0022351150400936604
Epoch:  167  	Training Loss: 0.0024845318403095007
Test Loss:  0.0018844163278117776
Valid Loss:  0.0022350260987877846
Epoch:  168  	Training Loss: 0.002484484575688839
Test Loss:  0.0018843086436390877
Valid Loss:  0.002234937157481909
Epoch:  169  	Training Loss: 0.0024844377767294645
Test Loss:  0.0018842029385268688
Valid Loss:  0.002234845655038953
Epoch:  170  	Training Loss: 0.00248439097777009
Test Loss:  0.0018840988632291555
Valid Loss:  0.0022347569465637207
Epoch:  171  	Training Loss: 0.002484343945980072
Test Loss:  0.0018839968834072351
Valid Loss:  0.002234666608273983
Epoch:  172  	Training Loss: 0.002484297612681985
Test Loss:  0.001870816806331277
Valid Loss:  0.0022127542179077864
Epoch:  173  	Training Loss: 0.0024663012009114027
Test Loss:  0.0018591787666082382
Valid Loss:  0.002196960849687457
Epoch:  174  	Training Loss: 0.0024524182081222534
Test Loss:  0.0018483935855329037
Valid Loss:  0.002184726996347308
Epoch:  175  	Training Loss: 0.0024407273158431053
Test Loss:  0.0018377944361418486
Valid Loss:  0.0021740924566984177
Epoch:  176  	Training Loss: 0.0024303430691361427
Test Loss:  0.0018278524512425065
Valid Loss:  0.0021642562933266163
Epoch:  177  	Training Loss: 0.0024206514935940504
Test Loss:  0.001818828983232379
Valid Loss:  0.0021547749638557434
Epoch:  178  	Training Loss: 0.0024113485123962164
Test Loss:  0.0018098247237503529
Valid Loss:  0.00214587664231658
Epoch:  179  	Training Loss: 0.0024022869765758514
Test Loss:  0.0018018248956650496
Valid Loss:  0.0021369517780840397
Epoch:  180  	Training Loss: 0.002393358387053013
Test Loss:  0.0017932923510670662
Valid Loss:  0.00212840479798615
Epoch:  181  	Training Loss: 0.0023845513351261616
Test Loss:  0.001785749802365899
Valid Loss:  0.002119785640388727
Epoch:  182  	Training Loss: 0.0023758828174322844
Test Loss:  0.001788799767382443
Valid Loss:  0.002117303665727377
Epoch:  183  	Training Loss: 0.0023747081868350506
Test Loss:  0.0017902879044413567
Valid Loss:  0.002116482937708497
Epoch:  184  	Training Loss: 0.002374399919062853
Test Loss:  0.0017900463426485658
Valid Loss:  0.0021163998171687126
Epoch:  185  	Training Loss: 0.0023743384517729282
Test Loss:  0.0017898264341056347
Valid Loss:  0.0021163192577660084
Epoch:  186  	Training Loss: 0.002374280011281371
Test Loss:  0.0017896302742883563
Valid Loss:  0.002116250805556774
Epoch:  187  	Training Loss: 0.0023742318153381348
Test Loss:  0.0017894513439387083
Valid Loss:  0.0021161865442991257
Epoch:  188  	Training Loss: 0.0023741903714835644
Test Loss:  0.001789307571016252
Valid Loss:  0.002116129733622074
Epoch:  189  	Training Loss: 0.0023741507902741432
Test Loss:  0.0017891803290694952
Valid Loss:  0.0021160761825740337
Epoch:  190  	Training Loss: 0.002374120522290468
Test Loss:  0.0017886534333229065
Valid Loss:  0.002116164658218622
Epoch:  191  	Training Loss: 0.0023740872275084257
Test Loss:  0.0017886378336697817
Valid Loss:  0.0021161003969609737
Epoch:  192  	Training Loss: 0.0023740523029118776
Test Loss:  0.001788183581084013
Valid Loss:  0.0021155644208192825
Epoch:  193  	Training Loss: 0.0023731477558612823
Test Loss:  0.001787728164345026
Valid Loss:  0.0021150431130081415
Epoch:  194  	Training Loss: 0.0023722671903669834
Test Loss:  0.0017872531898319721
Valid Loss:  0.002114558592438698
Epoch:  195  	Training Loss: 0.0023714443668723106
Test Loss:  0.0017867798451334238
Valid Loss:  0.0021140840835869312
Epoch:  196  	Training Loss: 0.00237063504755497
Test Loss:  0.0017864244291558862
Valid Loss:  0.0021136528812348843
Epoch:  197  	Training Loss: 0.0023698394652456045
Test Loss:  0.001786152715794742
Valid Loss:  0.0021132933907210827
Epoch:  198  	Training Loss: 0.0023690739180892706
Test Loss:  0.0017858569044619799
Valid Loss:  0.0021129644010215998
Epoch:  199  	Training Loss: 0.0023683507461100817
Test Loss:  0.0017855658661574125
Valid Loss:  0.002112641464918852
Epoch:  200  	Training Loss: 0.0023676613345742226
Test Loss:  0.0017852539895102382
Valid Loss:  0.0021123462356626987
Epoch:  201  	Training Loss: 0.0023670061491429806
Test Loss:  0.0017849259311333299
Valid Loss:  0.002112075686454773
Epoch:  202  	Training Loss: 0.0023664021864533424
Test Loss:  0.0017283866181969643
Valid Loss:  0.0020897616632282734
Epoch:  203  	Training Loss: 0.0023375581949949265
Test Loss:  0.0017042020335793495
Valid Loss:  0.00207474990747869
Epoch:  204  	Training Loss: 0.0023189729545265436
Test Loss:  0.0016899699112400413
Valid Loss:  0.0020622843876481056
Epoch:  205  	Training Loss: 0.002303335815668106
Test Loss:  0.0016845890786498785
Valid Loss:  0.0020532708149403334
Epoch:  206  	Training Loss: 0.002293200232088566
Test Loss:  0.001679621753282845
Valid Loss:   41%|████▏     | 207/500 [02:40<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:40<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:47<05:44,  1.19s/it] 43%|████▎     | 213/500 [02:47<04:05,  1.17it/s] 43%|████▎     | 215/500 [02:47<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:47<02:07,  2.21it/s] 44%|████▍     | 219/500 [02:47<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:54<05:34,  1.20s/it] 45%|████▍     | 223/500 [02:54<03:58,  1.16it/s] 45%|████▌     | 225/500 [02:54<02:51,  1.61it/s] 45%|████▌     | 227/500 [02:54<02:04,  2.20it/s] 46%|████▌     | 229/500 [02:54<01:31,  2.96it/s] 46%|████▌     | 231/500 [03:00<05:13,  1.17s/it] 47%|████▋     | 233/500 [03:01<03:43,  1.20it/s] 47%|████▋     | 235/500 [03:01<02:40,  1.65it/s] 47%|████▋     | 237/500 [03:01<01:56,  2.26it/s] 48%|████▊     | 239/500 [03:01<01:26,  3.03it/s] 48%|████▊     | 241/500 [03:07<05:05,  1.18s/it] 49%|████▊     | 243/500 [03:07<03:38,  1.17it/s] 49%|████▉     | 245/500 [03:08<02:37,  1.62it/s] 49%|████▉     | 247/500 [03:08<01:54,  2.21it/s] 50%|████▉     | 249/500 [03:08<01:24,  2.97it/s] 50%|█████     | 251/500 [03:14<04:51,  1.17s/it] 51%|█████     | 253/500 [03:14<03:27,  1.19it/s] 51%|█████     | 255/500 [03:14<02:29,  1.64it/s] 51%|█████▏    | 257/500 [03:14<01:48,  2.24it/s] 52%|█████▏    | 259/500 [03:15<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:21<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:21<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:21<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:21<01:44,  2.24it/s] 54%|█████▍    | 269/500 [03:21<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:28<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:28<03:09,  1.20it/s]0.0020457450300455093
Epoch:  207  	Training Loss: 0.0022856835275888443
Test Loss:  0.0016779936850070953
Valid Loss:  0.002039051614701748
Epoch:  208  	Training Loss: 0.0022796925622969866
Test Loss:  0.0016753864474594593
Valid Loss:  0.0020329123362898827
Epoch:  209  	Training Loss: 0.0022741928696632385
Test Loss:  0.0016736820107325912
Valid Loss:  0.002027412410825491
Epoch:  210  	Training Loss: 0.002269755583256483
Test Loss:  0.0016717832768335938
Valid Loss:  0.0020220286678522825
Epoch:  211  	Training Loss: 0.0022654510103166103
Test Loss:  0.0016697251703590155
Valid Loss:  0.002017064718529582
Epoch:  212  	Training Loss: 0.0022612917236983776
Test Loss:  0.0016752863302826881
Valid Loss:  0.0020110371988266706
Epoch:  213  	Training Loss: 0.002257891930639744
Test Loss:  0.0016789330402389169
Valid Loss:  0.0020067619625478983
Epoch:  214  	Training Loss: 0.0022553117014467716
Test Loss:  0.0016812331741675735
Valid Loss:  0.00200353330001235
Epoch:  215  	Training Loss: 0.0022531473077833652
Test Loss:  0.0016823955811560154
Valid Loss:  0.0020009547006338835
Epoch:  216  	Training Loss: 0.002251196652650833
Test Loss:  0.0016828845255076885
Valid Loss:  0.0019987975247204304
Epoch:  217  	Training Loss: 0.002249370329082012
Test Loss:  0.0016829458763822913
Valid Loss:  0.001996949315071106
Epoch:  218  	Training Loss: 0.0022476348094642162
Test Loss:  0.0016826249193400145
Valid Loss:  0.001995354425162077
Epoch:  219  	Training Loss: 0.0022459267638623714
Test Loss:  0.00168203457724303
Valid Loss:  0.001993888523429632
Epoch:  220  	Training Loss: 0.002244233153760433
Test Loss:  0.0016812208341434598
Valid Loss:  0.0019925101660192013
Epoch:  221  	Training Loss: 0.0022425479255616665
Test Loss:  0.0016802545869722962
Valid Loss:  0.0019911914132535458
Epoch:  222  	Training Loss: 0.0022408966906368732
Test Loss:  0.0016815445851534605
Valid Loss:  0.0019901928026229143
Epoch:  223  	Training Loss: 0.0022399509325623512
Test Loss:  0.0016826899955049157
Valid Loss:  0.001989325974136591
Epoch:  224  	Training Loss: 0.002239118330180645
Test Loss:  0.0016837251605466008
Valid Loss:  0.001988539006561041
Epoch:  225  	Training Loss: 0.0022383579052984715
Test Loss:  0.001684754271991551
Valid Loss:  0.001987854717299342
Epoch:  226  	Training Loss: 0.00223764986731112
Test Loss:  0.0016857272712513804
Valid Loss:  0.001987295225262642
Epoch:  227  	Training Loss: 0.0022369883954524994
Test Loss:  0.0016865149373188615
Valid Loss:  0.0019868097733706236
Epoch:  228  	Training Loss: 0.002236388623714447
Test Loss:  0.0016871686093509197
Valid Loss:  0.0019863746128976345
Epoch:  229  	Training Loss: 0.0022358244750648737
Test Loss:  0.001687717391178012
Valid Loss:  0.0019859871827065945
Epoch:  230  	Training Loss: 0.0022353080566972494
Test Loss:  0.0016881301999092102
Valid Loss:  0.00198563514277339
Epoch:  231  	Training Loss: 0.002234808634966612
Test Loss:  0.0016884729266166687
Valid Loss:  0.001985318725928664
Epoch:  232  	Training Loss: 0.002234354615211487
Test Loss:  0.001685051480308175
Valid Loss:  0.0019857008010149
Epoch:  233  	Training Loss: 0.0022335327230393887
Test Loss:  0.0016841139877215028
Valid Loss:  0.0019856898579746485
Epoch:  234  	Training Loss: 0.0022330444771796465
Test Loss:  0.0016839455347508192
Valid Loss:  0.0019855350255966187
Epoch:  235  	Training Loss: 0.0022325762547552586
Test Loss:  0.0016838812734931707
Valid Loss:  0.001985374605283141
Epoch:  236  	Training Loss: 0.0022321222350001335
Test Loss:  0.0016838121227920055
Valid Loss:  0.0019852393306791782
Epoch:  237  	Training Loss: 0.002231732476502657
Test Loss:  0.0016837725415825844
Valid Loss:  0.0019850977696478367
Epoch:  238  	Training Loss: 0.0022313566878437996
Test Loss:  0.0016837513539940119
Valid Loss:  0.0019849706441164017
Epoch:  239  	Training Loss: 0.002231003949418664
Test Loss:  0.0016837837174534798
Valid Loss:  0.001984839793294668
Epoch:  240  	Training Loss: 0.002230654703453183
Test Loss:  0.0016838714946061373
Valid Loss:  0.001984704751521349
Epoch:  241  	Training Loss: 0.002230309648439288
Test Loss:  0.0016836045542731881
Valid Loss:  0.0019846814684569836
Epoch:  242  	Training Loss: 0.002229978796094656
Test Loss:  0.0016791574889793992
Valid Loss:  0.0019832677207887173
Epoch:  243  	Training Loss: 0.0022278232499957085
Test Loss:  0.00167566176969558
Valid Loss:  0.0019819834269583225
Epoch:  244  	Training Loss: 0.0022260798141360283
Test Loss:  0.0016728100599721074
Valid Loss:  0.0019808581564575434
Epoch:  245  	Training Loss: 0.0022246921434998512
Test Loss:  0.0016702183056622744
Valid Loss:  0.00197988236322999
Epoch:  246  	Training Loss: 0.0022234832867980003
Test Loss:  0.001668066717684269
Valid Loss:  0.001979116816073656
Epoch:  247  	Training Loss: 0.0022224527783691883
Test Loss:  0.0016663481947034597
Valid Loss:  0.0019785002805292606
Epoch:  248  	Training Loss: 0.002221522154286504
Test Loss:  0.001664705341681838
Valid Loss:  0.001977892592549324
Epoch:  249  	Training Loss: 0.0022206567227840424
Test Loss:  0.0016634240746498108
Valid Loss:  0.0019773212261497974
Epoch:  250  	Training Loss: 0.002219877205789089
Test Loss:  0.00166247074957937
Valid Loss:  0.001976896310225129
Epoch:  251  	Training Loss: 0.0022191964089870453
Test Loss:  0.0016616485081613064
Valid Loss:  0.00197654590010643
Epoch:  252  	Training Loss: 0.0022186352871358395
Test Loss:  0.0016621302347630262
Valid Loss:  0.0019763384480029345
Epoch:  253  	Training Loss: 0.00221860408782959
Test Loss:  0.0016625826247036457
Valid Loss:  0.0019761426374316216
Epoch:  254  	Training Loss: 0.002218575682491064
Test Loss:  0.0016630094032734632
Valid Loss:  0.00197596475481987
Epoch:  255  	Training Loss: 0.0022185510024428368
Test Loss:  0.0016634089406579733
Valid Loss:  0.0019757989794015884
Epoch:  256  	Training Loss: 0.0022185305133461952
Test Loss:  0.0016637861263006926
Valid Loss:  0.001975645776838064
Epoch:  257  	Training Loss: 0.002218510489910841
Test Loss:  0.0016641386318951845
Valid Loss:  0.0019755028188228607
Epoch:  258  	Training Loss: 0.002218494424596429
Test Loss:  0.0016644711140543222
Valid Loss:  0.0019753703381866217
Epoch:  259  	Training Loss: 0.002218480221927166
Test Loss:  0.0016647821757942438
Valid Loss:  0.001975246239453554
Epoch:  260  	Training Loss: 0.002218466717749834
Test Loss:  0.0016650739125907421
Valid Loss:  0.0019751335494220257
Epoch:  261  	Training Loss: 0.0022184557747095823
Test Loss:  0.0016653493512421846
Valid Loss:  0.0019750273786485195
Epoch:  262  	Training Loss: 0.002218445995822549
Test Loss:  0.0016655625076964498
Valid Loss:  0.0019749929197132587
Epoch:  263  	Training Loss: 0.00221837405115366
Test Loss:  0.0016657529631629586
Valid Loss:  0.0019749668426811695
Epoch:  264  	Training Loss: 0.0022183030378073454
Test Loss:  0.0016658835811540484
Valid Loss:  0.0019749579951167107
Epoch:  265  	Training Loss: 0.00221823388710618
Test Loss:  0.00166599964722991
Valid Loss:  0.0019749558996409178
Epoch:  266  	Training Loss: 0.0022181652020663023
Test Loss:  0.001666105119511485
Valid Loss:  0.0019749694038182497
Epoch:  267  	Training Loss: 0.0022181058302521706
Test Loss:  0.0016661988338455558
Valid Loss:  0.0019749896600842476
Epoch:  268  	Training Loss: 0.0022180459927767515
Test Loss:  0.0016662876587361097
Valid Loss:  0.001975015504285693
Epoch:  269  	Training Loss: 0.0022179868537932634
Test Loss:  0.0016663670539855957
Valid Loss:  0.0019750415813177824
Epoch:  270  	Training Loss: 0.002217927249148488
Test Loss:  0.0016664405120536685
Valid Loss:  0.0019750716164708138
Epoch:  271  	Training Loss: 0.002217868110165
Test Loss:  0.0016665097791701555
Valid Loss:  0.0019751025829464197
Epoch:  272  	Training Loss: 0.002217809436842799
Test Loss:  0.0016669596079736948
Valid Loss:  0.0019750078208744526
Epoch:  273  	Training Loss: 0.0022177917417138815
Test Loss:  0.001667374512180686
Valid Loss:  0.0019749244675040245
Epoch:  274  	Training Loss: 0.0022177756763994694
Test Loss:  0.0016677571693435311
Valid Loss:  0.0019748504273593426
Epoch:  275  	Training Loss: 0.0022177614737302065
Test Loss:  0.0016681095585227013
 55%|█████▌    | 275/500 [03:28<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:28<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:28<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:34<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:35<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:35<02:11,  1.63it/s] 57%|█████▋    | 287/500 [03:35<01:35,  2.23it/s] 58%|█████▊    | 289/500 [03:35<01:10,  2.99it/s] 58%|█████▊    | 291/500 [03:41<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:41<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:42<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:42<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:42<01:06,  3.03it/s] 60%|██████    | 301/500 [03:48<03:53,  1.17s/it] 61%|██████    | 303/500 [03:48<02:45,  1.19it/s] 61%|██████    | 305/500 [03:48<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:48<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:49<01:03,  3.01it/s] 62%|██████▏   | 311/500 [03:55<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:55<02:36,  1.20it/s] 63%|██████▎   | 315/500 [03:55<01:51,  1.66it/s] 63%|██████▎   | 317/500 [03:55<01:20,  2.26it/s] 64%|██████▍   | 319/500 [03:55<00:59,  3.05it/s] 64%|██████▍   | 321/500 [04:02<03:27,  1.16s/it] 65%|██████▍   | 323/500 [04:02<02:27,  1.20it/s] 65%|██████▌   | 325/500 [04:02<01:45,  1.66it/s] 65%|██████▌   | 327/500 [04:02<01:16,  2.26it/s] 66%|██████▌   | 329/500 [04:02<00:56,  3.05it/s] 66%|██████▌   | 331/500 [04:08<03:17,  1.17s/it] 67%|██████▋   | 333/500 [04:08<02:20,  1.19it/s] 67%|██████▋   | 335/500 [04:09<01:40,  1.65it/s] 67%|██████▋   | 337/500 [04:09<01:12,  2.25it/s] 68%|██████▊   | 339/500 [04:09<00:53,  3.03it/s] 68%|██████▊   | 341/500 [04:15<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:15<02:13,  1.18it/s]Valid Loss:  0.0019747852347791195
Epoch:  276  	Training Loss: 0.002217749832198024
Test Loss:  0.0016684358706697822
Valid Loss:  0.0019747272599488497
Epoch:  277  	Training Loss: 0.002217738889157772
Test Loss:  0.0016687349416315556
Valid Loss:  0.0019746781326830387
Epoch:  278  	Training Loss: 0.0022177300415933132
Test Loss:  0.0016690118936821818
Valid Loss:  0.00197463296353817
Epoch:  279  	Training Loss: 0.0022177225910127163
Test Loss:  0.0016692673088982701
Valid Loss:  0.0019745947793126106
Epoch:  280  	Training Loss: 0.0022177151404321194
Test Loss:  0.001669502817094326
Valid Loss:  0.0019745626486837864
Epoch:  281  	Training Loss: 0.002217708621174097
Test Loss:  0.0016697188839316368
Valid Loss:  0.0019745337776839733
Epoch:  282  	Training Loss: 0.0022177030332386494
Test Loss:  0.0016674748621881008
Valid Loss:  0.0019736308604478836
Epoch:  283  	Training Loss: 0.002216325607150793
Test Loss:  0.0016658392269164324
Valid Loss:  0.0019729509949684143
Epoch:  284  	Training Loss: 0.0022151919547468424
Test Loss:  0.0016646850854158401
Valid Loss:  0.0019724173471331596
Epoch:  285  	Training Loss: 0.002214205451309681
Test Loss:  0.0016637786757200956
Valid Loss:  0.001972069963812828
Epoch:  286  	Training Loss: 0.0022134091705083847
Test Loss:  0.0016631903126835823
Valid Loss:  0.0019718469120562077
Epoch:  287  	Training Loss: 0.0022127905394881964
Test Loss:  0.0016629025340080261
Valid Loss:  0.0019716499373316765
Epoch:  288  	Training Loss: 0.0022123060189187527
Test Loss:  0.001662823953665793
Valid Loss:  0.001971492078155279
Epoch:  289  	Training Loss: 0.0022118850611150265
Test Loss:  0.001662753289565444
Valid Loss:  0.0019713370129466057
Epoch:  290  	Training Loss: 0.002211487852036953
Test Loss:  0.0016629984602332115
Valid Loss:  0.0019710890483111143
Epoch:  291  	Training Loss: 0.002211124636232853
Test Loss:  0.0016632282640784979
Valid Loss:  0.001970885321497917
Epoch:  292  	Training Loss: 0.0022107723634690046
Test Loss:  0.0016631954349577427
Valid Loss:  0.0019706932362169027
Epoch:  293  	Training Loss: 0.0022105290554463863
Test Loss:  0.0016631635371595621
Valid Loss:  0.001970507437363267
Epoch:  294  	Training Loss: 0.0022103055380284786
Test Loss:  0.0016631436301395297
Valid Loss:  0.0019703407306224108
Epoch:  295  	Training Loss: 0.00221010809764266
Test Loss:  0.0016631491016596556
Valid Loss:  0.0019701761193573475
Epoch:  296  	Training Loss: 0.0022099241614341736
Test Loss:  0.0016631865873932838
Valid Loss:  0.0019700343254953623
Epoch:  297  	Training Loss: 0.002209772588685155
Test Loss:  0.001663245726376772
Valid Loss:  0.0019698981195688248
Epoch:  298  	Training Loss: 0.0022096221800893545
Test Loss:  0.0016633106861263514
Valid Loss:  0.001969792414456606
Epoch:  299  	Training Loss: 0.0022094841115176678
Test Loss:  0.0016633679624646902
Valid Loss:  0.0019696883391588926
Epoch:  300  	Training Loss: 0.0022093518637120724
Test Loss:  0.0016634240746498108
Valid Loss:  0.001969590550288558
Epoch:  301  	Training Loss: 0.002209228463470936
Test Loss:  0.0016637557419016957
Valid Loss:  0.001969385426491499
Epoch:  302  	Training Loss: 0.0022091171704232693
Test Loss:  0.001663874601945281
Valid Loss:  0.001969386823475361
Epoch:  303  	Training Loss: 0.0022091083228588104
Test Loss:  0.001664265408180654
Valid Loss:  0.0019692827481776476
Epoch:  304  	Training Loss: 0.002209099940955639
Test Loss:  0.0016646076692268252
Valid Loss:  0.00196919497102499
Epoch:  305  	Training Loss: 0.0022090962156653404
Test Loss:  0.0016646264120936394
Valid Loss:  0.0019692282658070326
Epoch:  306  	Training Loss: 0.00220909109339118
Test Loss:  0.0016649289755150676
Valid Loss:  0.0019691521301865578
Epoch:  307  	Training Loss: 0.0022090859711170197
Test Loss:  0.0016651959158480167
Valid Loss:  0.0019690878689289093
Epoch:  308  	Training Loss: 0.002209081780165434
Test Loss:  0.0016654308419674635
Valid Loss:  0.0019690324552357197
Epoch:  309  	Training Loss: 0.0022090794518589973
Test Loss:  0.0016653533093631268
Valid Loss:  0.0019690943881869316
Epoch:  310  	Training Loss: 0.0022090780548751354
Test Loss:  0.0016655733343213797
Valid Loss:  0.0019690440967679024
Epoch:  311  	Training Loss: 0.0022090752609074116
Test Loss:  0.001665767515078187
Valid Loss:  0.0019690017215907574
Epoch:  312  	Training Loss: 0.0022090724669396877
Test Loss:  0.001665901392698288
Valid Loss:  0.0019677188247442245
Epoch:  313  	Training Loss: 0.0022077837493270636
Test Loss:  0.00166616914793849
Valid Loss:  0.0019664927385747433
Epoch:  314  	Training Loss: 0.0022065446246415377
Test Loss:  0.0016664585564285517
Valid Loss:  0.001965352799743414
Epoch:  315  	Training Loss: 0.002205449156463146
Test Loss:  0.0016666545998305082
Valid Loss:  0.0019645015709102154
Epoch:  316  	Training Loss: 0.002204572781920433
Test Loss:  0.001666798023506999
Valid Loss:  0.0019637392833828926
Epoch:  317  	Training Loss: 0.002203764393925667
Test Loss:  0.001666917698457837
Valid Loss:  0.001963096670806408
Epoch:  318  	Training Loss: 0.0022030137479305267
Test Loss:  0.0016670661279931664
Valid Loss:  0.0019625292625278234
Epoch:  319  	Training Loss: 0.0022023413330316544
Test Loss:  0.0016671812627464533
Valid Loss:  0.0019619837403297424
Epoch:  320  	Training Loss: 0.0022016968578100204
Test Loss:  0.0016672555357217789
Valid Loss:  0.0019614864140748978
Epoch:  321  	Training Loss: 0.0022010980173945427
Test Loss:  0.0016673033824190497
Valid Loss:  0.001961006550118327
Epoch:  322  	Training Loss: 0.002200513845309615
Test Loss:  0.001665985444560647
Valid Loss:  0.0019607553258538246
Epoch:  323  	Training Loss: 0.002200213260948658
Test Loss:  0.0016649968456476927
Valid Loss:  0.0019605918787419796
Epoch:  324  	Training Loss: 0.0021999990567564964
Test Loss:  0.0016632541082799435
Valid Loss:  0.0019606826826930046
Epoch:  325  	Training Loss: 0.002199882408604026
Test Loss:  0.0016629117308184505
Valid Loss:  0.001960564637556672
Epoch:  326  	Training Loss: 0.0021997811272740364
Test Loss:  0.0016626303549855947
Valid Loss:  0.0019605038687586784
Epoch:  327  	Training Loss: 0.0021997191943228245
Test Loss:  0.0016614841297268867
Valid Loss:  0.001960678491741419
Epoch:  328  	Training Loss: 0.0021997098810970783
Test Loss:  0.0016615730710327625
Valid Loss:  0.001960580702871084
Epoch:  329  	Training Loss: 0.002199687296524644
Test Loss:  0.0016611511819064617
Valid Loss:  0.0019606088753789663
Epoch:  330  	Training Loss: 0.0021996807772666216
Test Loss:  0.0016608202131465077
Valid Loss:  0.001960622612386942
Epoch:  331  	Training Loss: 0.0021996772848069668
Test Loss:  0.0016610394231975079
Valid Loss:  0.001960513647645712
Epoch:  332  	Training Loss: 0.0021996835712343454
Test Loss:  0.0016588377766311169
Valid Loss:  0.0019602999091148376
Epoch:  333  	Training Loss: 0.002198945265263319
Test Loss:  0.001658060820773244
Valid Loss:  0.0019597967620939016
Epoch:  334  	Training Loss: 0.0021983212791383266
Test Loss:  0.0016565017867833376
Valid Loss:  0.0019595820922404528
Epoch:  335  	Training Loss: 0.0021977853029966354
Test Loss:  0.0016563551034778357
Valid Loss:  0.0019592423923313618
Epoch:  336  	Training Loss: 0.002197391353547573
Test Loss:  0.0016552070155739784
Valid Loss:  0.0019592372700572014
Epoch:  337  	Training Loss: 0.002197065157815814
Test Loss:  0.0016552915330976248
Valid Loss:  0.001959017477929592
Epoch:  338  	Training Loss: 0.002196857240051031
Test Loss:  0.001654530526138842
Valid Loss:  0.00195906450971961
Epoch:  339  	Training Loss: 0.002196728950366378
Test Loss:  0.0016549836145713925
Valid Loss:  0.0019588423892855644
Epoch:  340  	Training Loss: 0.002196634653955698
Test Loss:  0.0016543443780392408
Valid Loss:  0.0019588996656239033
Epoch:  341  	Training Loss: 0.002196542453020811
Test Loss:  0.0016548149287700653
Valid Loss:  0.0019586910493671894
Epoch:  342  	Training Loss: 0.0021964418701827526
Test Loss:  0.001655055209994316
Valid Loss:  0.0019586458802223206
Epoch:  343  	Training Loss: 0.0021964367479085922
Test Loss:  0.0016552744200453162
Valid Loss:  0.001958604669198394
Epoch:  344  	Training Loss: 0.002196433488279581
Test Loss:   69%|██████▉   | 345/500 [04:15<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:16<01:08,  2.22it/s] 70%|██████▉   | 349/500 [04:16<00:50,  2.99it/s] 70%|███████   | 351/500 [04:22<02:57,  1.19s/it] 71%|███████   | 353/500 [04:22<02:05,  1.18it/s] 71%|███████   | 355/500 [04:22<01:29,  1.63it/s] 71%|███████▏  | 357/500 [04:22<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:23<00:47,  2.99it/s] 72%|███████▏  | 361/500 [04:29<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:29<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:29<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:29<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:29<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:36<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:36<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:36<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:36<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:36<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:43<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:43<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:43<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:43<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:43<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:49<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:49<01:29,  1.20it/s] 79%|███████▉  | 395/500 [04:49<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:50<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:50<00:33,  3.04it/s] 80%|████████  | 401/500 [04:56<01:55,  1.17s/it] 81%|████████  | 403/500 [04:56<01:21,  1.19it/s] 81%|████████  | 405/500 [05:02<02:24,  1.52s/it] 81%|████████▏ | 407/500 [05:03<01:40,  1.08s/it] 82%|████████▏ | 409/500 [05:03<01:10,  1.29it/s] 82%|████████▏ | 411/500 [05:09<02:13,  1.50s/it]0.0016554788453504443
Valid Loss:  0.001958567649126053
Epoch:  345  	Training Loss: 0.0021964292973279953
Test Loss:  0.0016556655755266547
Valid Loss:  0.001958534587174654
Epoch:  346  	Training Loss: 0.0021964269690215588
Test Loss:  0.001655839616432786
Valid Loss:  0.0019585047848522663
Epoch:  347  	Training Loss: 0.0021964251063764095
Test Loss:  0.0016559979412704706
Valid Loss:  0.001958478009328246
Epoch:  348  	Training Loss: 0.0021964223124086857
Test Loss:  0.001656144391745329
Valid Loss:  0.0019584528636187315
Epoch:  349  	Training Loss: 0.0021964209154248238
Test Loss:  0.0016562792006880045
Valid Loss:  0.0019584328401833773
Epoch:  350  	Training Loss: 0.002196419518440962
Test Loss:  0.0016564035322517157
Valid Loss:  0.0019584118854254484
Epoch:  351  	Training Loss: 0.0021964181214571
Test Loss:  0.0016565180849283934
Valid Loss:  0.001958393957465887
Epoch:  352  	Training Loss: 0.002196416724473238
Test Loss:  0.0016556287882849574
Valid Loss:  0.0019571122247725725
Epoch:  353  	Training Loss: 0.0021953326649963856
Test Loss:  0.0016554933972656727
Valid Loss:  0.00195606192573905
Epoch:  354  	Training Loss: 0.0021945813205093145
Test Loss:  0.001655295491218567
Valid Loss:  0.0019553531892597675
Epoch:  355  	Training Loss: 0.0021940809674561024
Test Loss:  0.0016551234293729067
Valid Loss:  0.001954777166247368
Epoch:  356  	Training Loss: 0.002193646039813757
Test Loss:  0.0016549729043617845
Valid Loss:  0.001954382285475731
Epoch:  357  	Training Loss: 0.002193319145590067
Test Loss:  0.0016547691775485873
Valid Loss:  0.0019541317597031593
Epoch:  358  	Training Loss: 0.0021931014489382505
Test Loss:  0.001654507010243833
Valid Loss:  0.001954044448211789
Epoch:  359  	Training Loss: 0.0021929871290922165
Test Loss:  0.0016542174853384495
Valid Loss:  0.0019540584180504084
Epoch:  360  	Training Loss: 0.0021929461508989334
Test Loss:  0.0016544590471312404
Valid Loss:  0.0019539673812687397
Epoch:  361  	Training Loss: 0.0021929095964878798
Test Loss:  0.0016542018856853247
Valid Loss:  0.0019539864733815193
Epoch:  362  	Training Loss: 0.002192872343584895
Test Loss:  0.0016541793011128902
Valid Loss:  0.0019540018402040005
Epoch:  363  	Training Loss: 0.002192871179431677
Test Loss:  0.0016541581135243177
Valid Loss:  0.001954016275703907
Epoch:  364  	Training Loss: 0.0021928702481091022
Test Loss:  0.001654137158766389
Valid Loss:  0.0019540307112038136
Epoch:  365  	Training Loss: 0.002192869782447815
Test Loss:  0.0016541186487302184
Valid Loss:  0.001954043982550502
Epoch:  366  	Training Loss: 0.0021928693167865276
Test Loss:  0.0016541010700166225
Valid Loss:  0.001954060047864914
Epoch:  367  	Training Loss: 0.0021928686182945967
Test Loss:  0.0016540840733796358
Valid Loss:  0.001954072155058384
Epoch:  368  	Training Loss: 0.002192867686972022
Test Loss:  0.00165406777523458
Valid Loss:  0.0019540884532034397
Epoch:  369  	Training Loss: 0.002192866988480091
Test Loss:  0.0016540531069040298
Valid Loss:  0.001954101026058197
Epoch:  370  	Training Loss: 0.0021928660571575165
Test Loss:  0.001654038205742836
Valid Loss:  0.0019541140645742416
Epoch:  371  	Training Loss: 0.002192865591496229
Test Loss:  0.001654026098549366
Valid Loss:  0.001954126637428999
Epoch:  372  	Training Loss: 0.002192865125834942
Test Loss:  0.0016541697550565004
Valid Loss:  0.001954043051227927
Epoch:  373  	Training Loss: 0.0021927969064563513
Test Loss:  0.0016543015372008085
Valid Loss:  0.0019539939239621162
Epoch:  374  	Training Loss: 0.0021927393972873688
Test Loss:  0.0016543875681236386
Valid Loss:  0.00195398461073637
Epoch:  375  	Training Loss: 0.0021927033085376024
Test Loss:  0.0016544386744499207
Valid Loss:  0.0019539915956556797
Epoch:  376  	Training Loss: 0.002192678162828088
Test Loss:  0.0016544531099498272
Valid Loss:  0.0019540097564458847
Epoch:  377  	Training Loss: 0.0021926627960056067
Test Loss:  0.0016544420504942536
Valid Loss:  0.0019540367648005486
Epoch:  378  	Training Loss: 0.002192653249949217
Test Loss:  0.001654436462558806
Valid Loss:  0.001954067498445511
Epoch:  379  	Training Loss: 0.0021926448680460453
Test Loss:  0.001654439838603139
Valid Loss:  0.001954099629074335
Epoch:  380  	Training Loss: 0.0021926402114331722
Test Loss:  0.0016544136451557279
Valid Loss:  0.0019541357178241014
Epoch:  381  	Training Loss: 0.002192636951804161
Test Loss:  0.0016543958336114883
Valid Loss:  0.001954170409590006
Epoch:  382  	Training Loss: 0.002192635089159012
Test Loss:  0.001654147868975997
Valid Loss:  0.0019529527053236961
Epoch:  383  	Training Loss: 0.0021912783849984407
Test Loss:  0.001653875457122922
Valid Loss:  0.0019517577020451427
Epoch:  384  	Training Loss: 0.0021899393759667873
Test Loss:  0.0016536214388906956
Valid Loss:  0.0019505840027704835
Epoch:  385  	Training Loss: 0.002188616432249546
Test Loss:  0.0016533839516341686
Valid Loss:  0.0019494325388222933
Epoch:  386  	Training Loss: 0.002187323058024049
Test Loss:  0.0016530278371647
Valid Loss:  0.001948329620063305
Epoch:  387  	Training Loss: 0.0021860534325242043
Test Loss:  0.0016525490209460258
Valid Loss:  0.0019472731510177255
Epoch:  388  	Training Loss: 0.0021848182659596205
Test Loss:  0.0016518640331923962
Valid Loss:  0.001946288626641035
Epoch:  389  	Training Loss: 0.002183594275265932
Test Loss:  0.001651161815971136
Valid Loss:  0.0019453115528449416
Epoch:  390  	Training Loss: 0.0021823726128786802
Test Loss:  0.001650447491556406
Valid Loss:  0.001944337971508503
Epoch:  391  	Training Loss: 0.002181154675781727
Test Loss:  0.0016497187316417694
Valid Loss:  0.0019433697452768683
Epoch:  392  	Training Loss: 0.00217993906699121
Test Loss:  0.0016447154339402914
Valid Loss:  0.0019437603186815977
Epoch:  393  	Training Loss: 0.002179104834794998
Test Loss:  0.0016430492978543043
Valid Loss:  0.0019434180576354265
Epoch:  394  	Training Loss: 0.002178507624194026
Test Loss:  0.0016421983018517494
Valid Loss:  0.0019428649684414268
Epoch:  395  	Training Loss: 0.002177917631343007
Test Loss:  0.001641641603782773
Valid Loss:  0.00194226810708642
Epoch:  396  	Training Loss: 0.0021773725748062134
Test Loss:  0.0016412248369306326
Valid Loss:  0.0019417998846620321
Epoch:  397  	Training Loss: 0.002176956506446004
Test Loss:  0.0016408931696787477
Valid Loss:  0.001941398368217051
Epoch:  398  	Training Loss: 0.0021766023710370064
Test Loss:  0.0016405583592131734
Valid Loss:  0.0019410146633163095
Epoch:  399  	Training Loss: 0.002176274312660098
Test Loss:  0.0016402488108724356
Valid Loss:  0.0019406937062740326
Epoch:  400  	Training Loss: 0.002175987930968404
Test Loss:  0.0016400222666561604
Valid Loss:  0.0019403928890824318
Epoch:  401  	Training Loss: 0.002175720175728202
Test Loss:  0.0016397901345044374
Valid Loss:  0.0019400937017053366
Epoch:  402  	Training Loss: 0.002175457775592804
Test Loss:  0.001639725873246789
Valid Loss:  0.0019400888122618198
Epoch:  403  	Training Loss: 0.002175457775592804
Test Loss:  0.001639673369936645
Valid Loss:  0.001940081245265901
Epoch:  404  	Training Loss: 0.002175457775592804
Test Loss:  0.0016396266873925924
Valid Loss:  0.001940072514116764
Epoch:  405  	Training Loss: 0.0021754568442702293
Test Loss:  0.0016395880375057459
Valid Loss:  0.0019400634337216616
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.002175456378608942
Test Loss:  0.001639607478864491
Valid Loss:  0.0019397055730223656
Epoch:  407  	Training Loss: 0.0021752119064331055
Test Loss:  0.0016396522987633944
Valid Loss:  0.001939373672939837
Epoch:  408  	Training Loss: 0.0021749907173216343
Test Loss:  0.0016397391445934772
Valid Loss:  0.0019390962552279234
Epoch:  409  	Training Loss: 0.002174795838072896
Test Loss:  0.0016398096922785044
Valid Loss:  0.0019388574874028563
Epoch:  410  	Training Loss: 0.002174633089452982
Test Loss:  0.0016398621955886483
Valid Loss:  0.00193864107131958
Epoch:  411  	Training Loss: 0.0021744915284216404
Test Loss:  0.0016399347223341465
Valid Loss:  0.0019384529441595078
Epoch:  412  	Training Loss: 0.002174372086301446
Test Loss:   83%|████████▎ | 413/500 [05:09<01:33,  1.07s/it] 83%|████████▎ | 415/500 [05:09<01:05,  1.30it/s] 83%|████████▎ | 417/500 [05:09<00:46,  1.79it/s] 84%|████████▍ | 419/500 [05:10<00:33,  2.44it/s] 84%|████████▍ | 421/500 [05:16<01:37,  1.23s/it] 85%|████████▍ | 423/500 [05:16<01:07,  1.13it/s] 85%|████████▌ | 425/500 [05:16<00:47,  1.57it/s] 85%|████████▌ | 427/500 [05:16<00:34,  2.15it/s] 86%|████████▌ | 429/500 [05:16<00:24,  2.89it/s] 86%|████████▌ | 431/500 [05:23<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:23<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:23<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:23<00:28,  2.21it/s] 88%|████████▊ | 439/500 [05:23<00:20,  2.97it/s] 88%|████████▊ | 441/500 [05:29<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:30<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:30<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:30<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:30<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:36<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:36<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:37<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:37<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:37<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:49<01:22,  2.11s/it] 93%|█████████▎| 463/500 [05:49<00:55,  1.50s/it] 93%|█████████▎| 465/500 [05:50<00:37,  1.07s/it] 93%|█████████▎| 467/500 [05:50<00:25,  1.30it/s] 94%|█████████▍| 469/500 [05:50<00:17,  1.80it/s] 94%|█████████▍| 471/500 [06:02<01:06,  2.28s/it] 95%|█████████▍| 473/500 [06:03<00:43,  1.61s/it] 95%|█████████▌| 475/500 [06:09<00:51,  2.07s/it] 95%|█████████▌| 477/500 [06:09<00:33,  1.47s/it]0.001639878610149026
Valid Loss:  0.0019383346661925316
Epoch:  413  	Training Loss: 0.0021742789540439844
Test Loss:  0.001639812020584941
Valid Loss:  0.0019382546888664365
Epoch:  414  	Training Loss: 0.0021742070093750954
Test Loss:  0.0016397119034081697
Valid Loss:  0.0019382195314392447
Epoch:  415  	Training Loss: 0.0021741739474236965
Test Loss:  0.0016396312275901437
Valid Loss:  0.0019381839083507657
Epoch:  416  	Training Loss: 0.002174143912270665
Test Loss:  0.001639560330659151
Valid Loss:  0.001938158879056573
Epoch:  417  	Training Loss: 0.0021741201635450125
Test Loss:  0.0016395028214901686
Valid Loss:  0.0019381329184398055
Epoch:  418  	Training Loss: 0.0021740964148193598
Test Loss:  0.0016394504345953465
Valid Loss:  0.0019381062593311071
Epoch:  419  	Training Loss: 0.0021740724332630634
Test Loss:  0.0016394045669585466
Valid Loss:  0.001938080182299018
Epoch:  420  	Training Loss: 0.0021740486845374107
Test Loss:  0.001639367314055562
Valid Loss:  0.0019380529411137104
Epoch:  421  	Training Loss: 0.0021740260999649763
Test Loss:  0.001639345195144415
Valid Loss:  0.0019380248850211501
Epoch:  422  	Training Loss: 0.0021740025840699673
Test Loss:  0.0016396143473684788
Valid Loss:  0.0019374543335288763
Epoch:  423  	Training Loss: 0.0021734945476055145
Test Loss:  0.0016395605634897947
Valid Loss:  0.0019370203372091055
Epoch:  424  	Training Loss: 0.0021730070002377033
Test Loss:  0.0016394606791436672
Valid Loss:  0.001936637214384973
Epoch:  425  	Training Loss: 0.0021725415717810392
Test Loss:  0.0016393285477533937
Valid Loss:  0.0019362817984074354
Epoch:  426  	Training Loss: 0.0021721073426306248
Test Loss:  0.0016391598619520664
Valid Loss:  0.001935949083417654
Epoch:  427  	Training Loss: 0.0021716810297220945
Test Loss:  0.001638965681195259
Valid Loss:  0.001935653854161501
Epoch:  428  	Training Loss: 0.0021712598390877247
Test Loss:  0.001638770685531199
Valid Loss:  0.0019353831885382533
Epoch:  429  	Training Loss: 0.002170857507735491
Test Loss:  0.0016385532217100263
Valid Loss:  0.0019351434893906116
Epoch:  430  	Training Loss: 0.0021704963874071836
Test Loss:  0.0016383843030780554
Valid Loss:  0.00193490250967443
Epoch:  431  	Training Loss: 0.0021701373625546694
Test Loss:  0.001638218411244452
Valid Loss:  0.0019346605986356735
Epoch:  432  	Training Loss: 0.0021697808988392353
Test Loss:  0.0016381401801481843
Valid Loss:  0.001934676431119442
Epoch:  433  	Training Loss: 0.0021697795018553734
Test Loss:  0.0016380642773583531
Valid Loss:  0.0019346894696354866
Epoch:  434  	Training Loss: 0.002169777872040868
Test Loss:  0.0016379898879677057
Valid Loss:  0.0019347035558894277
Epoch:  435  	Training Loss: 0.002169775776565075
Test Loss:  0.0016379181761294603
Valid Loss:  0.0019347165944054723
Epoch:  436  	Training Loss: 0.0021697748452425003
Test Loss:  0.0016378492582589388
Valid Loss:  0.0019347292836755514
Epoch:  437  	Training Loss: 0.0021697739139199257
Test Loss:  0.0016377794090658426
Valid Loss:  0.0019347427878528833
Epoch:  438  	Training Loss: 0.0021697725169360638
Test Loss:  0.0016377123538404703
Valid Loss:  0.001934755127876997
Epoch:  439  	Training Loss: 0.0021697713527828455
Test Loss:  0.0016376480925828218
Valid Loss:  0.001934766536578536
Epoch:  440  	Training Loss: 0.0021697699557989836
Test Loss:  0.0016375842969864607
Valid Loss:  0.0019347771303728223
Epoch:  441  	Training Loss: 0.0021697692573070526
Test Loss:  0.0016375230625271797
Valid Loss:  0.001934790052473545
Epoch:  442  	Training Loss: 0.0021697687916457653
Test Loss:  0.001637265901081264
Valid Loss:  0.0019348623463883996
Epoch:  443  	Training Loss: 0.002169761573895812
Test Loss:  0.0016370689263567328
Valid Loss:  0.0019349174108356237
Epoch:  444  	Training Loss: 0.002169756218791008
Test Loss:  0.0016369195654988289
Valid Loss:  0.001934962347149849
Epoch:  445  	Training Loss: 0.0021697513293474913
Test Loss:  0.0016368041979148984
Valid Loss:  0.0019349962240085006
Epoch:  446  	Training Loss: 0.002169747604057193
Test Loss:  0.0016367152566090226
Valid Loss:  0.00193502358160913
Epoch:  447  	Training Loss: 0.0021697429474443197
Test Loss:  0.0016366476193070412
Valid Loss:  0.0019350445363670588
Epoch:  448  	Training Loss: 0.0021697399206459522
Test Loss:  0.0016365955816581845
Valid Loss:  0.0019350619986653328
Epoch:  449  	Training Loss: 0.002169737359508872
Test Loss:  0.0016365551855415106
Valid Loss:  0.0019350762013345957
Epoch:  450  	Training Loss: 0.00216973340138793
Test Loss:  0.0016365251503884792
Valid Loss:  0.0019350878428667784
Epoch:  451  	Training Loss: 0.002169730607420206
Test Loss:  0.0016365011688321829
Valid Loss:  0.0019350990187376738
Epoch:  452  	Training Loss: 0.0021697289776057005
Test Loss:  0.0016363407485187054
Valid Loss:  0.0019351367373019457
Epoch:  453  	Training Loss: 0.002169729210436344
Test Loss:  0.0016364443581551313
Valid Loss:  0.001935114385560155
Epoch:  454  	Training Loss: 0.0021697289776057005
Test Loss:  0.0016362899914383888
Valid Loss:  0.0019351508235558867
Epoch:  455  	Training Loss: 0.0021697282791137695
Test Loss:  0.0016363977920264006
Valid Loss:  0.0019351285882294178
Epoch:  456  	Training Loss: 0.0021697289776057005
Test Loss:  0.0016362471505999565
Valid Loss:  0.0019351635128259659
Epoch:  457  	Training Loss: 0.002169728511944413
Test Loss:  0.0016363589093089104
Valid Loss:  0.0019351388327777386
Epoch:  458  	Training Loss: 0.002169728744775057
Test Loss:  0.001636213157325983
Valid Loss:  0.001935173524543643
Epoch:  459  	Training Loss: 0.0021697268821299076
Test Loss:  0.001636328175663948
Valid Loss:  0.0019351488444954157
Epoch:  460  	Training Loss: 0.002169728744775057
Test Loss:  0.0016361838206648827
Valid Loss:  0.0019351817900314927
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.002169727347791195
Test Loss:  0.0016357747372239828
Valid Loss:  0.0019351252121850848
Epoch:  462  	Training Loss: 0.00216958811506629
Test Loss:  0.0016357558779418468
Valid Loss:  0.0019351288210600615
Epoch:  463  	Training Loss: 0.002169588580727577
Test Loss:  0.0016357387648895383
Valid Loss:  0.001935128471814096
Epoch:  464  	Training Loss: 0.00216958811506629
Test Loss:  0.0016357210697606206
Valid Loss:  0.0019351296359673142
Epoch:  465  	Training Loss: 0.002169588580727577
Test Loss:  0.001635705935768783
Valid Loss:  0.001935130450874567
Epoch:  466  	Training Loss: 0.0021695878822356462
Test Loss:  0.0016356904525309801
Valid Loss:  0.0019351312657818198
Epoch:  467  	Training Loss: 0.00216958811506629
Test Loss:  0.0016356762498617172
Valid Loss:  0.0019351323135197163
Epoch:  468  	Training Loss: 0.0021695878822356462
Test Loss:  0.0016356633277609944
Valid Loss:  0.001935132429935038
Epoch:  469  	Training Loss: 0.002169588580727577
Test Loss:  0.0016356504056602716
Valid Loss:  0.0019351321971043944
Epoch:  470  	Training Loss: 0.00216958811506629
Test Loss:  0.001635638065636158
Valid Loss:  0.0019351321971043944
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.00216958811506629
Test Loss:  0.0016356379492208362
Valid Loss:  0.0019351328955963254
Epoch:  472  	Training Loss: 0.002169588580727577
Test Loss:  0.0016356350388377905
Valid Loss:  0.0019351334776729345
Epoch:  473  	Training Loss: 0.002169588580727577
Test Loss:  0.0016356328269466758
Valid Loss:  0.0019351332448422909
Epoch:  474  	Training Loss: 0.00216958811506629
Test Loss:  0.001635630032978952
Valid Loss:  0.001935133128426969
Epoch:  475  	Training Loss: 0.00216958811506629
Test Loss:  0.001635626656934619
Valid Loss:  0.0019351323135197163
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0021695876494050026
Test Loss:  0.001635651453398168
Valid Loss:  0.0019350883085280657
Epoch:  477  	Training Loss: 0.0021695434115827084
Test Loss:  0.0016356746200472116
Valid Loss:  0.0019350447691977024
 96%|█████████▌| 479/500 [06:09<00:22,  1.05s/it] 96%|█████████▌| 481/500 [06:15<00:31,  1.67s/it] 97%|█████████▋| 483/500 [06:16<00:20,  1.19s/it] 97%|█████████▋| 485/500 [06:16<00:12,  1.17it/s] 97%|█████████▋| 487/500 [06:16<00:08,  1.61it/s] 98%|█████████▊| 489/500 [06:16<00:04,  2.20it/s] 98%|█████████▊| 491/500 [06:22<00:11,  1.26s/it] 99%|█████████▊| 493/500 [06:22<00:06,  1.11it/s] 99%|█████████▉| 495/500 [06:22<00:03,  1.54it/s] 99%|█████████▉| 497/500 [06:23<00:01,  2.11it/s]100%|█████████▉| 499/500 [06:23<00:00,  2.83it/s]100%|██████████| 500/500 [06:23<00:00,  1.30it/s]
Epoch:  478  	Training Loss: 0.002169497311115265
Test Loss:  0.0016356976702809334
Valid Loss:  0.0019350008806213737
Epoch:  479  	Training Loss: 0.0021694526076316833
Test Loss:  0.0016357202548533678
Valid Loss:  0.0019349574577063322
Epoch:  480  	Training Loss: 0.002169407671317458
Test Loss:  0.0016357454005628824
Valid Loss:  0.001934914500452578
Epoch:  481  	Training Loss: 0.002169362036511302
Test Loss:  0.0016357670538127422
Valid Loss:  0.0019348710775375366
Epoch:  482  	Training Loss: 0.002169317100197077
Test Loss:  0.0016357706626877189
Valid Loss:  0.001934827771037817
Epoch:  483  	Training Loss: 0.0021692723967134953
Test Loss:  0.0016357742715626955
Valid Loss:  0.0019347858615219593
Epoch:  484  	Training Loss: 0.0021692272275686264
Test Loss:  0.0016357761342078447
Valid Loss:  0.0019347432535141706
Epoch:  485  	Training Loss: 0.002169182989746332
Test Loss:  0.0016357788117602468
Valid Loss:  0.0019347011111676693
Epoch:  486  	Training Loss: 0.0021691375877708197
Test Loss:  0.0016357804415747523
Valid Loss:  0.0019346603658050299
Epoch:  487  	Training Loss: 0.0021690931171178818
Test Loss:  0.0016357791610062122
Valid Loss:  0.0019346174085512757
Epoch:  488  	Training Loss: 0.0021690484136343002
Test Loss:  0.0016357789281755686
Valid Loss:  0.0019345770124346018
Epoch:  489  	Training Loss: 0.002169003477320075
Test Loss:  0.0016357783460989594
Valid Loss:  0.0019345344044268131
Epoch:  490  	Training Loss: 0.00216895854100585
Test Loss:  0.0016357768326997757
Valid Loss:  0.0019344930769875646
Epoch:  491  	Training Loss: 0.002168913371860981
Test Loss:  0.0016357750864699483
Valid Loss:  0.0019344511674717069
Epoch:  492  	Training Loss: 0.002168868901208043
Test Loss:  0.0016357825370505452
Valid Loss:  0.0019344096072018147
Epoch:  493  	Training Loss: 0.0021688237320631742
Test Loss:  0.0016357895219698548
Valid Loss:  0.0019343687454238534
Epoch:  494  	Training Loss: 0.0021687836851924658
Test Loss:  0.0016357970889657736
Valid Loss:  0.0019343296298757195
Epoch:  495  	Training Loss: 0.002168741775676608
Test Loss:  0.0016358018619939685
Valid Loss:  0.0019342880696058273
Epoch:  496  	Training Loss: 0.002168701495975256
Test Loss:  0.0016358067514374852
Valid Loss:  0.0019342496525496244
Epoch:  497  	Training Loss: 0.0021686588879674673
Test Loss:  0.0016358117572963238
Valid Loss:  0.001934207626618445
Epoch:  498  	Training Loss: 0.002168618608266115
Test Loss:  0.0016358164139091969
Valid Loss:  0.0019341683946549892
Epoch:  499  	Training Loss: 0.002168577630072832
Test Loss:  0.0016358200227841735
Valid Loss:  0.0019341285806149244
Epoch:  500  	Training Loss: 0.0021685357205569744
Test Loss:  0.001635823049582541
Valid Loss:  0.0019340893486514688
seed is  11
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.25it/s]  1%|          | 4/500 [00:00<00:31, 15.72it/s]  1%|          | 6/500 [00:00<00:31, 15.91it/s]  2%|▏         | 8/500 [00:00<00:30, 16.13it/s]  2%|▏         | 10/500 [00:00<00:30, 16.14it/s]  2%|▏         | 12/500 [00:00<00:30, 15.91it/s]  3%|▎         | 14/500 [00:00<00:30, 15.95it/s]  3%|▎         | 16/500 [00:00<00:30, 16.13it/s]  4%|▎         | 18/500 [00:01<00:29, 16.26it/s]  4%|▍         | 20/500 [00:01<00:29, 16.34it/s]  4%|▍         | 22/500 [00:01<00:29, 16.23it/s]  5%|▍         | 24/500 [00:01<00:29, 16.15it/s]  5%|▌         | 26/500 [00:01<00:29, 16.30it/s]  6%|▌         | 28/500 [00:01<00:28, 16.43it/s]  6%|▌         | 30/500 [00:01<00:28, 16.48it/s]  6%|▋         | 32/500 [00:01<00:29, 16.01it/s]  7%|▋         | 34/500 [00:02<00:28, 16.14it/s]  7%|▋         | 36/500 [00:02<00:29, 15.80it/s]  8%|▊         | 38/500 [00:02<00:29, 15.87it/s]  8%|▊         | 40/500 [00:02<00:28, 15.94it/s]  8%|▊         | 42/500 [00:02<00:28, 16.01it/s]  9%|▉         | 44/500 [00:02<00:28, 15.96it/s]  9%|▉         | 46/500 [00:02<00:28, 15.95it/s] 10%|▉         | 48/500 [00:02<00:28, 16.11it/s] 10%|█         | 50/500 [00:03<00:28, 15.95it/s] 10%|█         | 52/500 [00:03<00:28, 15.94it/s] 11%|█         | 54/500 [00:03<00:27, 15.96it/s] 11%|█         | 56/500 [00:03<00:27, 16.11it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.16it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.26it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.37it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.26it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.29it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.39it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.34it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.19it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.14it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.17it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.23it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.24it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.32it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.30it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.41it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.40it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.37it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.24it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.27it/s] 19%|█▉        | 96/500 [00:05<00:25, 16.14it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.28it/s] 20%|██        | 100/500 [00:06<00:24, 16.27it/s] 20%|██        | 102/500 [00:06<00:24, 16.29it/s] 21%|██        | 104/500 [00:06<00:24, 16.37it/s] 21%|██        | 106/500 [00:06<00:24, 16.26it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.30it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.29it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.36it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.63it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.82it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.07it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.20it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.28it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.01it/s]Epoch:  1  	Training Loss: 0.031252775341272354
Test Loss:  181.1407012939453
Valid Loss:  181.2593536376953
Epoch:  2  	Training Loss: 181.13751220703125
Test Loss:  5651752448.0
Valid Loss:  5629349888.0
Epoch:  3  	Training Loss: 5640950272.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 15.93it/s] 26%|██▌       | 128/500 [00:07<00:23, 16.08it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.12it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.10it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.01it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.97it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.12it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.00it/s] 28%|██▊       | 142/500 [00:08<00:23, 15.53it/s] 29%|██▉       | 144/500 [00:08<00:24, 14.43it/s] 29%|██▉       | 146/500 [00:09<00:24, 14.65it/s] 30%|██▉       | 148/500 [00:09<00:23, 15.11it/s] 30%|███       | 150/500 [00:09<00:22, 15.40it/s] 30%|███       | 152/500 [00:09<00:22, 15.55it/s] 31%|███       | 154/500 [00:09<00:21, 15.76it/s] 31%|███       | 156/500 [00:09<00:21, 15.95it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.03it/s] 32%|███▏      | 160/500 [00:09<00:21, 16.04it/s] 32%|███▏      | 162/500 [00:10<00:21, 16.09it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.07it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.22it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.25it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.25it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.30it/s] 35%|███▍      | 174/500 [00:10<00:20, 16.23it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.28it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.26it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.33it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.27it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.28it/s] 37%|███▋      | 186/500 [00:11<00:19, 15.89it/s] 38%|███▊      | 188/500 [00:11<00:19, 15.92it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.15it/s] 38%|███▊      | 192/500 [00:11<00:19, 15.93it/s] 39%|███▉      | 194/500 [00:12<00:19, 16.06it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.16it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.13it/s] 40%|████      | 200/500 [00:12<00:18, 16.23it/s] 40%|████      | 202/500 [00:12<00:18, 16.09it/s] 41%|████      | 204/500 [00:12<00:18, 16.09it/s] 41%|████      | 206/500 [00:12<00:18, 15.83it/s] 42%|████▏     | 208/500 [00:12<00:18, 16.04it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.17it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.23it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.38it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.27it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.39it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.40it/s] 44%|████▍     | 222/500 [00:13<00:17, 15.96it/s] 45%|████▍     | 224/500 [00:13<00:17, 15.82it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.86it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.09it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.21it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.32it/s] 47%|████▋     | 234/500 [00:14<00:17, 15.42it/s] 47%|████▋     | 236/500 [00:14<00:17, 14.95it/s] 48%|████▊     | 238/500 [00:14<00:17, 15.30it/s] 48%|████▊     | 240/500 [00:14<00:16, 15.69it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.77it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.91it/s] 49%|████▉     | 246/500 [00:15<00:15, 15.96it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.13it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.19it/s] 50%|█████     | 252/500 [00:15<00:15, 16.18it/s] 51%|█████     | 254/500 [00:15<00:15, 15.82it/s] 51%|█████     | 256/500 [00:15<00:15, 15.96it/s] 52%|█████▏    | 258/500 [00:16<00:15, 16.09it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.73it/s] 52%|█████▏    | 262/500 [00:16<00:15, 15.62it/s] 53%|█████▎    | 264/500 [00:16<00:14, 15.91it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.01it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.01it/s] 54%|█████▍    | 270/500 [00:16<00:14, 15.96it/s] 54%|█████▍    | 272/500 [00:16<00:14, 15.97it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.99it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.14it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.31it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.38it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.32it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.34it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.34it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.38it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.44it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.49it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.17it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.27it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.91it/s] 60%|██████    | 300/500 [00:18<00:12, 15.86it/s] 60%|██████    | 302/500 [00:18<00:12, 16.03it/s] 61%|██████    | 304/500 [00:18<00:12, 16.14it/s] 61%|██████    | 306/500 [00:19<00:11, 16.22it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.24it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.28it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.35it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.32it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.25it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.05it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.11it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.22it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.33it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.40it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.42it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.41it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.45it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.29it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.06it/s] 68%|██████▊   | 338/500 [00:21<00:10, 16.20it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.22it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.12it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.19it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.15it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.00it/s] 70%|███████   | 350/500 [00:21<00:09, 16.06it/s] 70%|███████   | 352/500 [00:21<00:09, 16.06it/s] 71%|███████   | 354/500 [00:22<00:09, 15.94it/s] 71%|███████   | 356/500 [00:22<00:08, 16.03it/s] 72%|███████▏  | 358/500 [00:22<00:08, 15.87it/s] 72%|███████▏  | 360/500 [00:22<00:08, 15.87it/s] 72%|███████▏  | 362/500 [00:22<00:08, 15.79it/s] 73%|███████▎  | 364/500 [00:22<00:08, 15.71it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.82it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.91it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.72it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.71it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 15.94it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.11it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.11it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.12it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.05it/s] 77%|███████▋  | 384/500 [00:23<00:07, 15.68it/s] 77%|███████▋  | 386/500 [00:24<00:07, 15.94it/s] 78%|███████▊  | 388/500 [00:24<00:07, 15.79it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.03it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.17it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.19it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.14it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.12it/s] 80%|████████  | 400/500 [00:24<00:06, 16.20it/s] 80%|████████  | 402/500 [00:25<00:06, 16.26it/s] 81%|████████  | 404/500 [00:25<00:05, 16.33it/s] 81%|████████  | 406/500 [00:25<00:05, 16.36it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.28it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.06it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.06it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.15it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.27it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.23it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.26it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.27it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.32it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.37it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.25it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.13it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.06it/s] 87%|████████▋ | 434/500 [00:26<00:04, 15.99it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.12it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.21it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.31it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.18it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.15it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.18it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.08it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.14it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.19it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.25it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.94it/s] 92%|█████████▏| 458/500 [00:28<00:02, 15.97it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.01it/s] 92%|█████████▏| 462/500 [00:28<00:02, 15.91it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.01it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.04it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.14it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.28it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.73it/s] 95%|█████████▍| 474/500 [00:29<00:01, 15.14it/s] 95%|█████████▌| 476/500 [00:29<00:01, 15.34it/s] 96%|█████████▌| 478/500 [00:29<00:01, 15.60it/s] 96%|█████████▌| 480/500 [00:29<00:01, 15.22it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.52it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.80it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.96it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.09it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.83it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.96it/s] 99%|█████████▉| 494/500 [00:30<00:00, 15.93it/s] 99%|█████████▉| 496/500 [00:30<00:00, 15.58it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.81it/s]100%|██████████| 500/500 [00:31<00:00, 15.99it/s]100%|██████████| 500/500 [00:31<00:00, 16.06it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  11
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:58,  6.25s/it]  1%|          | 3/500 [00:06<13:49,  1.67s/it]  1%|          | 5/500 [00:06<06:57,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.01it/s]  4%|▍         | 21/500 [00:19<09:36,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:17,  1.19s/it]  7%|▋         | 33/500 [00:26<06:37,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:33,  2.99it/s]  8%|▊         | 41/500 [00:33<09:03,  1.18s/it]  9%|▊         | 43/500 [00:33<06:27,  1.18it/s]  9%|▉         | 45/500 [00:33<04:39,  1.63it/s]  9%|▉         | 47/500 [00:33<03:23,  2.23it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:51,  1.18s/it] 11%|█         | 53/500 [00:40<06:19,  1.18it/s] 11%|█         | 55/500 [00:40<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:40<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:40<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:47<08:31,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:05,  1.20it/s] 13%|█▎        | 65/500 [00:47<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:11,  2.26it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.03it/s] 14%|█▍        | 71/500 [00:54<08:23,  1.17s/it]Epoch:  1  	Training Loss: 0.031252775341272354
Test Loss:  1.6889753341674805
Valid Loss:  1.6959381103515625
Epoch:  2  	Training Loss: 1.697256326675415
Test Loss:  1.2636151313781738
Valid Loss:  1.2328822612762451
Epoch:  3  	Training Loss: 1.2494957447052002
Test Loss:  0.05334288626909256
Valid Loss:  0.05332519859075546
Epoch:  4  	Training Loss: 0.05441160127520561
Test Loss:  0.03216108679771423
Valid Loss:  0.03465372323989868
Epoch:  5  	Training Loss: 0.03459668532013893
Test Loss:  0.0315089151263237
Valid Loss:  0.034463800489902496
Epoch:  6  	Training Loss: 0.03417574614286423
Test Loss:  0.031293563544750214
Valid Loss:  0.03414718806743622
Epoch:  7  	Training Loss: 0.033899180591106415
Test Loss:  0.031207527965307236
Valid Loss:  0.03400854021310806
Epoch:  8  	Training Loss: 0.033773235976696014
Test Loss:  0.03119295835494995
Valid Loss:  0.03396756947040558
Epoch:  9  	Training Loss: 0.033739738166332245
Test Loss:  0.031166773289442062
Valid Loss:  0.03393268585205078
Epoch:  10  	Training Loss: 0.03370770066976547
Test Loss:  0.03114323690533638
Valid Loss:  0.033897556364536285
Epoch:  11  	Training Loss: 0.03367620334029198
Test Loss:  0.0311193335801363
Valid Loss:  0.03386317938566208
Epoch:  12  	Training Loss: 0.033645108342170715
Test Loss:  0.031095819547772408
Valid Loss:  0.03383022919297218
Epoch:  13  	Training Loss: 0.03361518681049347
Test Loss:  0.031071970239281654
Valid Loss:  0.03379785269498825
Epoch:  14  	Training Loss: 0.033585742115974426
Test Loss:  0.03105391189455986
Valid Loss:  0.03376460075378418
Epoch:  15  	Training Loss: 0.03355681896209717
Test Loss:  0.03102908656001091
Valid Loss:  0.03373347222805023
Epoch:  16  	Training Loss: 0.0335281565785408
Test Loss:  0.031010225415229797
Valid Loss:  0.033701494336128235
Epoch:  17  	Training Loss: 0.033499933779239655
Test Loss:  0.030987676233053207
Valid Loss:  0.03367077186703682
Epoch:  18  	Training Loss: 0.03347213938832283
Test Loss:  0.030967898666858673
Valid Loss:  0.033639974892139435
Epoch:  19  	Training Loss: 0.033444710075855255
Test Loss:  0.030947651714086533
Valid Loss:  0.03360974043607712
Epoch:  20  	Training Loss: 0.033417683094739914
Test Loss:  0.030926961451768875
Valid Loss:  0.033580176532268524
Epoch:  21  	Training Loss: 0.033390991389751434
Test Loss:  0.030905816704034805
Valid Loss:  0.03355134651064873
Epoch:  22  	Training Loss: 0.03336459398269653
Test Loss:  0.030884377658367157
Valid Loss:  0.03352300822734833
Epoch:  23  	Training Loss: 0.0333385095000267
Test Loss:  0.030865725129842758
Valid Loss:  0.033494122326374054
Epoch:  24  	Training Loss: 0.03331279754638672
Test Loss:  0.0308467298746109
Valid Loss:  0.03346587345004082
Epoch:  25  	Training Loss: 0.0332874096930027
Test Loss:  0.03082761913537979
Valid Loss:  0.03343817964196205
Epoch:  26  	Training Loss: 0.03326231613755226
Test Loss:  0.030808405950665474
Valid Loss:  0.03341098502278328
Epoch:  27  	Training Loss: 0.033237479627132416
Test Loss:  0.030789047479629517
Valid Loss:  0.03338424861431122
Epoch:  28  	Training Loss: 0.033212874084711075
Test Loss:  0.030769525095820427
Valid Loss:  0.03335792198777199
Epoch:  29  	Training Loss: 0.033188484609127045
Test Loss:  0.0307498499751091
Valid Loss:  0.03333196043968201
Epoch:  30  	Training Loss: 0.0331643670797348
Test Loss:  0.030732106417417526
Valid Loss:  0.033305574208498
Epoch:  31  	Training Loss: 0.033140629529953
Test Loss:  0.030714161694049835
Valid Loss:  0.033279675990343094
Epoch:  32  	Training Loss: 0.033117182552814484
Test Loss:  0.03069622814655304
Valid Loss:  0.03325437381863594
Epoch:  33  	Training Loss: 0.03309419006109238
Test Loss:  0.030678099021315575
Valid Loss:  0.033229485154151917
Epoch:  34  	Training Loss: 0.03307141363620758
Test Loss:  0.030659791082143784
Valid Loss:  0.03320494294166565
Epoch:  35  	Training Loss: 0.03304882347583771
Test Loss:  0.030641455203294754
Valid Loss:  0.03318072110414505
Epoch:  36  	Training Loss: 0.03302641212940216
Test Loss:  0.030623581260442734
Valid Loss:  0.033156879246234894
Epoch:  37  	Training Loss: 0.033004164695739746
Test Loss:  0.03060634806752205
Valid Loss:  0.03313400596380234
Epoch:  38  	Training Loss: 0.03298208862543106
Test Loss:  0.03059014305472374
Valid Loss:  0.033110275864601135
Epoch:  39  	Training Loss: 0.03296041488647461
Test Loss:  0.030573930591344833
Valid Loss:  0.033087000250816345
Epoch:  40  	Training Loss: 0.03293893113732338
Test Loss:  0.03055773302912712
Valid Loss:  0.033064160495996475
Epoch:  41  	Training Loss: 0.03291763365268707
Test Loss:  0.030541550368070602
Valid Loss:  0.03304170072078705
Epoch:  42  	Training Loss: 0.0328965038061142
Test Loss:  0.030525341629981995
Valid Loss:  0.03301949426531792
Epoch:  43  	Training Loss: 0.03287553787231445
Test Loss:  0.030510134994983673
Valid Loss:  0.032996587455272675
Epoch:  44  	Training Loss: 0.03285487741231918
Test Loss:  0.030494915321469307
Valid Loss:  0.032974135130643845
Epoch:  45  	Training Loss: 0.03283442556858063
Test Loss:  0.030479678884148598
Valid Loss:  0.03295211121439934
Epoch:  46  	Training Loss: 0.03281417489051819
Test Loss:  0.030464451760053635
Valid Loss:  0.03293045610189438
Epoch:  47  	Training Loss: 0.03279409930109978
Test Loss:  0.030449192970991135
Valid Loss:  0.03290913254022598
Epoch:  48  	Training Loss: 0.0327741801738739
Test Loss:  0.030433906242251396
Valid Loss:  0.03288811445236206
Epoch:  49  	Training Loss: 0.032754406332969666
Test Loss:  0.030418572947382927
Valid Loss:  0.032867372035980225
Epoch:  50  	Training Loss: 0.032734863460063934
Test Loss:  0.030404340475797653
Valid Loss:  0.032846033573150635
Epoch:  51  	Training Loss: 0.032715532928705215
Test Loss:  0.03039005771279335
Valid Loss:  0.03282506763935089
Epoch:  52  	Training Loss: 0.03269639611244202
Test Loss:  0.03037578985095024
Valid Loss:  0.03280454874038696
Epoch:  53  	Training Loss: 0.03267752379179001
Test Loss:  0.030361469835042953
Valid Loss:  0.03278433904051781
Epoch:  54  	Training Loss: 0.03265880420804024
Test Loss:  0.030347079038619995
Valid Loss:  0.03276441991329193
Epoch:  55  	Training Loss: 0.03264031559228897
Test Loss:  0.030333854258060455
Valid Loss:  0.03274406120181084
Epoch:  56  	Training Loss: 0.03262199088931084
Test Loss:  0.030320540070533752
Valid Loss:  0.03272407874464989
Epoch:  57  	Training Loss: 0.03260386735200882
Test Loss:  0.03030715323984623
Valid Loss:  0.03270441293716431
Epoch:  58  	Training Loss: 0.03258591890335083
Test Loss:  0.030293673276901245
Valid Loss:  0.0326850451529026
Epoch:  59  	Training Loss: 0.032568130642175674
Test Loss:  0.030280105769634247
Valid Loss:  0.032665930688381195
Epoch:  60  	Training Loss: 0.03255047649145126
Test Loss:  0.030266474932432175
Valid Loss:  0.03264707326889038
Epoch:  61  	Training Loss: 0.03253296762704849
Test Loss:  0.030252758413553238
Valid Loss:  0.03262842819094658
Epoch:  62  	Training Loss: 0.03251555934548378
Test Loss:  0.030239012092351913
Valid Loss:  0.032609812915325165
Epoch:  63  	Training Loss: 0.03249809518456459
Test Loss:  0.030225642025470734
Valid Loss:  0.032591380178928375
Epoch:  64  	Training Loss: 0.032480813562870026
Test Loss:  0.030213918536901474
Valid Loss:  0.03257211670279503
Epoch:  65  	Training Loss: 0.03246381878852844
Test Loss:  0.03020046465098858
Valid Loss:  0.03255416825413704
Epoch:  66  	Training Loss: 0.032446928322315216
Test Loss:  0.030188757926225662
Valid Loss:  0.032535433769226074
Epoch:  67  	Training Loss: 0.032430171966552734
Test Loss:  0.030177002772688866
Valid Loss:  0.032517023384571075
Epoch:  68  	Training Loss: 0.03241361677646637
Test Loss:  0.03016522340476513
Valid Loss:  0.03249889612197876
Epoch:  69  	Training Loss: 0.032397251576185226
Test Loss:  0.030153397470712662
Valid Loss:  0.032481029629707336
Epoch:  70  	Training Loss: 0.032381050288677216
Test Loss:  0.030141547322273254
Valid Loss:  0.032463397830724716
Epoch:  71  	Training Loss: 0.03236500173807144
Test Loss:  0.03012964315712452
Valid Loss:  0.03244596719741821
Epoch:  72  	Training Loss: 0.03234907612204552
Test Loss:  0.030117813497781754
Valid Loss:   15%|█▍        | 73/500 [00:54<06:00,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  3.01it/s] 16%|█▌        | 81/500 [01:00<08:11,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:51,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:07<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:07<04:06,  1.65it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:08<02:12,  3.02it/s] 20%|██        | 101/500 [01:14<07:45,  1.17s/it] 21%|██        | 103/500 [01:14<05:33,  1.19it/s] 21%|██        | 105/500 [01:14<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:14<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:21<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.23it/s] 24%|██▍       | 119/500 [01:21<02:07,  3.00it/s] 24%|██▍       | 121/500 [01:27<07:20,  1.16s/it] 25%|██▍       | 123/500 [01:28<05:15,  1.20it/s] 25%|██▌       | 125/500 [01:28<03:46,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:45,  2.26it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:34<07:09,  1.16s/it] 27%|██▋       | 133/500 [01:34<05:06,  1.20it/s] 27%|██▋       | 135/500 [01:34<03:40,  1.65it/s] 27%|██▋       | 137/500 [01:35<02:40,  2.26it/s] 28%|██▊       | 139/500 [01:35<01:58,  3.04it/s] 28%|██▊       | 141/500 [01:41<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:41<05:00,  1.19it/s]0.03242883086204529
Epoch:  73  	Training Loss: 0.0323333814740181
Test Loss:  0.03010592609643936
Valid Loss:  0.0324118547141552
Epoch:  74  	Training Loss: 0.03231777995824814
Test Loss:  0.030094005167484283
Valid Loss:  0.032395027577877045
Epoch:  75  	Training Loss: 0.03230239078402519
Test Loss:  0.03008309006690979
Valid Loss:  0.03237811475992203
Epoch:  76  	Training Loss: 0.0322871208190918
Test Loss:  0.030072104185819626
Valid Loss:  0.03236140310764313
Epoch:  77  	Training Loss: 0.03227200359106064
Test Loss:  0.030061041936278343
Valid Loss:  0.03234487399458885
Epoch:  78  	Training Loss: 0.03225700557231903
Test Loss:  0.030049921944737434
Valid Loss:  0.032328516244888306
Epoch:  79  	Training Loss: 0.032242126762866974
Test Loss:  0.03003881126642227
Valid Loss:  0.03231232613325119
Epoch:  80  	Training Loss: 0.03222734481096268
Test Loss:  0.03002794086933136
Valid Loss:  0.03229627013206482
Epoch:  81  	Training Loss: 0.03221265971660614
Test Loss:  0.03001706674695015
Valid Loss:  0.0322803258895874
Epoch:  82  	Training Loss: 0.03219804912805557
Test Loss:  0.03000626713037491
Valid Loss:  0.032264593988657
Epoch:  83  	Training Loss: 0.032183609902858734
Test Loss:  0.029995471239089966
Valid Loss:  0.03224895894527435
Epoch:  84  	Training Loss: 0.032169241458177567
Test Loss:  0.02998521737754345
Valid Loss:  0.032233431935310364
Epoch:  85  	Training Loss: 0.03215494751930237
Test Loss:  0.02997504733502865
Valid Loss:  0.032218001782894135
Epoch:  86  	Training Loss: 0.032140787690877914
Test Loss:  0.029965076595544815
Valid Loss:  0.032202623784542084
Epoch:  87  	Training Loss: 0.03212684392929077
Test Loss:  0.029955191537737846
Valid Loss:  0.03218758851289749
Epoch:  88  	Training Loss: 0.03211301565170288
Test Loss:  0.02994535304605961
Valid Loss:  0.032172735780477524
Epoch:  89  	Training Loss: 0.03209928423166275
Test Loss:  0.029935570433735847
Valid Loss:  0.03215806558728218
Epoch:  90  	Training Loss: 0.032085634768009186
Test Loss:  0.029925823211669922
Valid Loss:  0.032143548130989075
Epoch:  91  	Training Loss: 0.03207206726074219
Test Loss:  0.029916122555732727
Valid Loss:  0.03212917596101761
Epoch:  92  	Training Loss: 0.03205856680870056
Test Loss:  0.02990635484457016
Valid Loss:  0.03211482986807823
Epoch:  93  	Training Loss: 0.03204503282904625
Test Loss:  0.029896628111600876
Valid Loss:  0.0321006178855896
Epoch:  94  	Training Loss: 0.03203156590461731
Test Loss:  0.029886923730373383
Valid Loss:  0.03208652138710022
Epoch:  95  	Training Loss: 0.0320182740688324
Test Loss:  0.029877521097660065
Valid Loss:  0.03207210451364517
Epoch:  96  	Training Loss: 0.03200510889291763
Test Loss:  0.029868148267269135
Valid Loss:  0.032057859003543854
Epoch:  97  	Training Loss: 0.03199202939867973
Test Loss:  0.02985881268978119
Valid Loss:  0.03204377740621567
Epoch:  98  	Training Loss: 0.03197905421257019
Test Loss:  0.029849519953131676
Valid Loss:  0.03202985227108002
Epoch:  99  	Training Loss: 0.031966160982847214
Test Loss:  0.029840243980288506
Valid Loss:  0.032016053795814514
Epoch:  100  	Training Loss: 0.03195333480834961
Test Loss:  0.029830988496541977
Valid Loss:  0.032002370804548264
Epoch:  101  	Training Loss: 0.03194056823849678
Test Loss:  0.02982175722718239
Valid Loss:  0.031988807022571564
Epoch:  102  	Training Loss: 0.03192787244915962
Test Loss:  0.0298127643764019
Valid Loss:  0.031975552439689636
Epoch:  103  	Training Loss: 0.03191544860601425
Test Loss:  0.029803793877363205
Valid Loss:  0.031962402164936066
Epoch:  104  	Training Loss: 0.03190308436751366
Test Loss:  0.029794849455356598
Valid Loss:  0.03194933757185936
Epoch:  105  	Training Loss: 0.03189077600836754
Test Loss:  0.029785916209220886
Valid Loss:  0.03193635493516922
Epoch:  106  	Training Loss: 0.0318785160779953
Test Loss:  0.02977735921740532
Valid Loss:  0.031923167407512665
Epoch:  107  	Training Loss: 0.03186647593975067
Test Loss:  0.029768826439976692
Valid Loss:  0.03191011771559715
Epoch:  108  	Training Loss: 0.03185452148318291
Test Loss:  0.02976030483841896
Valid Loss:  0.03189718723297119
Epoch:  109  	Training Loss: 0.03184264153242111
Test Loss:  0.029751792550086975
Valid Loss:  0.03188437223434448
Epoch:  110  	Training Loss: 0.03183082863688469
Test Loss:  0.029743293300271034
Valid Loss:  0.03187166154384613
Epoch:  111  	Training Loss: 0.03181908279657364
Test Loss:  0.02973480522632599
Valid Loss:  0.03185904771089554
Epoch:  112  	Training Loss: 0.03180740773677826
Test Loss:  0.02972598373889923
Valid Loss:  0.031846191734075546
Epoch:  113  	Training Loss: 0.031795430928468704
Test Loss:  0.02971716970205307
Valid Loss:  0.031833402812480927
Epoch:  114  	Training Loss: 0.03178349882364273
Test Loss:  0.02970835752785206
Valid Loss:  0.03182069957256317
Epoch:  115  	Training Loss: 0.03177161514759064
Test Loss:  0.029699567705392838
Valid Loss:  0.031808070838451385
Epoch:  116  	Training Loss: 0.03175978735089302
Test Loss:  0.02969077043235302
Valid Loss:  0.03179551661014557
Epoch:  117  	Training Loss: 0.03174798935651779
Test Loss:  0.0296819806098938
Valid Loss:  0.03178301453590393
Epoch:  118  	Training Loss: 0.031736236065626144
Test Loss:  0.029673198238015175
Valid Loss:  0.031770579516887665
Epoch:  119  	Training Loss: 0.03172452002763748
Test Loss:  0.029664436355233192
Valid Loss:  0.03175821155309677
Epoch:  120  	Training Loss: 0.0317128524184227
Test Loss:  0.02965567260980606
Valid Loss:  0.03174588456749916
Epoch:  121  	Training Loss: 0.031701214611530304
Test Loss:  0.029646921902894974
Valid Loss:  0.03173360973596573
Epoch:  122  	Training Loss: 0.03168973699212074
Test Loss:  0.029638923704624176
Valid Loss:  0.03172152489423752
Epoch:  123  	Training Loss: 0.031678661704063416
Test Loss:  0.02963091805577278
Valid Loss:  0.031709518283605576
Epoch:  124  	Training Loss: 0.03166763484477997
Test Loss:  0.029622912406921387
Valid Loss:  0.0316975861787796
Epoch:  125  	Training Loss: 0.031656697392463684
Test Loss:  0.029615402221679688
Valid Loss:  0.03168565407395363
Epoch:  126  	Training Loss: 0.03164585307240486
Test Loss:  0.02960789203643799
Valid Loss:  0.03167383372783661
Epoch:  127  	Training Loss: 0.0316351056098938
Test Loss:  0.0296003557741642
Valid Loss:  0.031662117689847946
Epoch:  128  	Training Loss: 0.031624432653188705
Test Loss:  0.029592806473374367
Valid Loss:  0.03165049105882645
Epoch:  129  	Training Loss: 0.03161383792757988
Test Loss:  0.029585249722003937
Valid Loss:  0.03163895383477211
Epoch:  130  	Training Loss: 0.031603313982486725
Test Loss:  0.02957765944302082
Valid Loss:  0.031627483665943146
Epoch:  131  	Training Loss: 0.03159284219145775
Test Loss:  0.029570050537586212
Valid Loss:  0.031616099178791046
Epoch:  132  	Training Loss: 0.03158241882920265
Test Loss:  0.029562383890151978
Valid Loss:  0.03160472959280014
Epoch:  133  	Training Loss: 0.03157201409339905
Test Loss:  0.02955469861626625
Valid Loss:  0.031593434512615204
Epoch:  134  	Training Loss: 0.031561657786369324
Test Loss:  0.02954699471592903
Valid Loss:  0.03158217668533325
Epoch:  135  	Training Loss: 0.03155133128166199
Test Loss:  0.029539281502366066
Valid Loss:  0.031570982187986374
Epoch:  136  	Training Loss: 0.03154105693101883
Test Loss:  0.029531557112932205
Valid Loss:  0.03155982866883278
Epoch:  137  	Training Loss: 0.03153081610798836
Test Loss:  0.0295238196849823
Valid Loss:  0.03154872730374336
Epoch:  138  	Training Loss: 0.03152061253786087
Test Loss:  0.029516074806451797
Valid Loss:  0.03153765946626663
Epoch:  139  	Training Loss: 0.03151043504476547
Test Loss:  0.029508311301469803
Valid Loss:  0.03152662515640259
Epoch:  140  	Training Loss: 0.03150030970573425
Test Loss:  0.02950117364525795
Valid Loss:  0.031515706330537796
Epoch:  141  	Training Loss: 0.031490352004766464
Test Loss:  0.029494009912014008
Valid Loss:  0.03150483965873718
Epoch:  142  	Training Loss: 0.03148045018315315
Test Loss:  0.029486777260899544
Valid Loss:  0.03149397298693657
Epoch:  143  	Training Loss: 0.03147054463624954
Test Loss:  0.029479511082172394
Valid Loss:  0.03148315101861954
 29%|██▉       | 145/500 [01:41<03:35,  1.64it/s] 29%|██▉       | 147/500 [01:41<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.02it/s] 30%|███       | 151/500 [01:48<06:42,  1.15s/it] 31%|███       | 153/500 [01:48<04:47,  1.21it/s] 31%|███       | 155/500 [01:48<03:26,  1.67it/s] 31%|███▏      | 157/500 [01:48<02:30,  2.27it/s] 32%|███▏      | 159/500 [01:48<01:51,  3.05it/s] 32%|███▏      | 161/500 [01:55<06:38,  1.18s/it] 33%|███▎      | 163/500 [01:55<04:44,  1.18it/s] 33%|███▎      | 165/500 [01:55<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:55<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:55<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:01<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:02<02:25,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:08<06:22,  1.20s/it] 37%|███▋      | 183/500 [02:09<04:33,  1.16it/s] 37%|███▋      | 185/500 [02:09<03:16,  1.60it/s] 37%|███▋      | 187/500 [02:09<02:22,  2.19it/s] 38%|███▊      | 189/500 [02:09<01:45,  2.95it/s] 38%|███▊      | 191/500 [02:15<06:04,  1.18s/it] 39%|███▊      | 193/500 [02:15<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.00it/s] 40%|████      | 201/500 [02:22<05:47,  1.16s/it] 41%|████      | 203/500 [02:22<04:07,  1.20it/s] 41%|████      | 205/500 [02:22<02:57,  1.66it/s] 41%|████▏     | 207/500 [02:22<02:09,  2.26it/s] 42%|████▏     | 209/500 [02:22<01:35,  3.04it/s] 42%|████▏     | 211/500 [02:29<05:33,  1.16s/it] 43%|████▎     | 213/500 [02:29<03:57,  1.21it/s]Epoch:  144  	Training Loss: 0.031460683792829514
Test Loss:  0.0294722281396389
Valid Loss:  0.03147238492965698
Epoch:  145  	Training Loss: 0.03145087510347366
Test Loss:  0.029464907944202423
Valid Loss:  0.03146165609359741
Epoch:  146  	Training Loss: 0.0314411036670208
Test Loss:  0.029457565397024155
Valid Loss:  0.03145097196102142
Epoch:  147  	Training Loss: 0.03143136948347092
Test Loss:  0.029450200498104095
Valid Loss:  0.03144032508134842
Epoch:  148  	Training Loss: 0.03142166882753372
Test Loss:  0.029442818835377693
Valid Loss:  0.0314297154545784
Epoch:  149  	Training Loss: 0.03141200542449951
Test Loss:  0.029435405507683754
Valid Loss:  0.03141912445425987
Epoch:  150  	Training Loss: 0.03140236437320709
Test Loss:  0.029427990317344666
Valid Loss:  0.03140857815742493
Epoch:  151  	Training Loss: 0.031392794102430344
Test Loss:  0.0294212494045496
Valid Loss:  0.03139820694923401
Epoch:  152  	Training Loss: 0.031383343040943146
Test Loss:  0.029414422810077667
Valid Loss:  0.031387846916913986
Epoch:  153  	Training Loss: 0.03137390688061714
Test Loss:  0.0294075608253479
Valid Loss:  0.03137754648923874
Epoch:  154  	Training Loss: 0.03136453777551651
Test Loss:  0.029401380568742752
Valid Loss:  0.031367454677820206
Epoch:  155  	Training Loss: 0.03135524317622185
Test Loss:  0.029394418001174927
Valid Loss:  0.031357232481241226
Epoch:  156  	Training Loss: 0.031346000730991364
Test Loss:  0.029388152062892914
Valid Loss:  0.03134724497795105
Epoch:  157  	Training Loss: 0.031336814165115356
Test Loss:  0.029381077736616135
Valid Loss:  0.031337082386016846
Epoch:  158  	Training Loss: 0.031327709555625916
Test Loss:  0.0293747391551733
Valid Loss:  0.031327176839113235
Epoch:  159  	Training Loss: 0.03131863847374916
Test Loss:  0.029368342831730843
Valid Loss:  0.03131730854511261
Epoch:  160  	Training Loss: 0.03130963444709778
Test Loss:  0.029361896216869354
Valid Loss:  0.03130747377872467
Epoch:  161  	Training Loss: 0.03130068629980087
Test Loss:  0.02935539186000824
Valid Loss:  0.03129766881465912
Epoch:  162  	Training Loss: 0.03129178658127785
Test Loss:  0.029348865151405334
Valid Loss:  0.03128791227936745
Epoch:  163  	Training Loss: 0.03128295764327049
Test Loss:  0.029342293739318848
Valid Loss:  0.031278178095817566
Epoch:  164  	Training Loss: 0.03127416968345642
Test Loss:  0.02933567948639393
Valid Loss:  0.031268469989299774
Epoch:  165  	Training Loss: 0.03126542642712593
Test Loss:  0.02932901494204998
Valid Loss:  0.031258776783943176
Epoch:  166  	Training Loss: 0.03125670552253723
Test Loss:  0.02932247705757618
Valid Loss:  0.03124910220503807
Epoch:  167  	Training Loss: 0.031248018145561218
Test Loss:  0.029316049069166183
Valid Loss:  0.03123943880200386
Epoch:  168  	Training Loss: 0.031239360570907593
Test Loss:  0.02930961176753044
Valid Loss:  0.031229786574840546
Epoch:  169  	Training Loss: 0.031230805441737175
Test Loss:  0.0293036587536335
Valid Loss:  0.031220488250255585
Epoch:  170  	Training Loss: 0.03122229129076004
Test Loss:  0.029297683387994766
Valid Loss:  0.031211214140057564
Epoch:  171  	Training Loss: 0.03121383860707283
Test Loss:  0.029291696846485138
Valid Loss:  0.03120194748044014
Epoch:  172  	Training Loss: 0.0312054343521595
Test Loss:  0.029285676777362823
Valid Loss:  0.03119269572198391
Epoch:  173  	Training Loss: 0.031197067350149155
Test Loss:  0.029279641807079315
Valid Loss:  0.031183455139398575
Epoch:  174  	Training Loss: 0.031188741326332092
Test Loss:  0.029273580759763718
Valid Loss:  0.031174222007393837
Epoch:  175  	Training Loss: 0.031180448830127716
Test Loss:  0.029267501085996628
Valid Loss:  0.031165000051259995
Epoch:  176  	Training Loss: 0.031172189861536026
Test Loss:  0.029261399060487747
Valid Loss:  0.0311557836830616
Epoch:  177  	Training Loss: 0.031163964420557022
Test Loss:  0.029255280271172523
Valid Loss:  0.031146572902798653
Epoch:  178  	Training Loss: 0.031155765056610107
Test Loss:  0.029249144718050957
Valid Loss:  0.03113737516105175
Epoch:  179  	Training Loss: 0.031147588044404984
Test Loss:  0.029242996126413345
Valid Loss:  0.031128184869885445
Epoch:  180  	Training Loss: 0.03113943710923195
Test Loss:  0.02923683077096939
Valid Loss:  0.031119000166654587
Epoch:  181  	Training Loss: 0.031131310388445854
Test Loss:  0.029230650514364243
Valid Loss:  0.031109817326068878
Epoch:  182  	Training Loss: 0.03112320601940155
Test Loss:  0.029224812984466553
Valid Loss:  0.031100982800126076
Epoch:  183  	Training Loss: 0.031115464866161346
Test Loss:  0.029218975454568863
Valid Loss:  0.031092166900634766
Epoch:  184  	Training Loss: 0.031107813119888306
Test Loss:  0.029213719069957733
Valid Loss:  0.031083807349205017
Epoch:  185  	Training Loss: 0.031100261956453323
Test Loss:  0.02920844405889511
Valid Loss:  0.031075462698936462
Epoch:  186  	Training Loss: 0.031092766672372818
Test Loss:  0.029203128069639206
Valid Loss:  0.031067118048667908
Epoch:  187  	Training Loss: 0.03108530305325985
Test Loss:  0.029197797179222107
Valid Loss:  0.031058769673109055
Epoch:  188  	Training Loss: 0.031077886000275612
Test Loss:  0.029192430898547173
Valid Loss:  0.0310504250228405
Epoch:  189  	Training Loss: 0.031070493161678314
Test Loss:  0.029187053442001343
Valid Loss:  0.03104209154844284
Epoch:  190  	Training Loss: 0.03106314316391945
Test Loss:  0.029181640595197678
Valid Loss:  0.031033746898174286
Epoch:  191  	Training Loss: 0.031055811792612076
Test Loss:  0.02917621098458767
Valid Loss:  0.031025415286421776
Epoch:  192  	Training Loss: 0.031048566102981567
Test Loss:  0.029171165078878403
Valid Loss:  0.0310173612087965
Epoch:  193  	Training Loss: 0.031041134148836136
Test Loss:  0.029166074469685555
Valid Loss:  0.03100929968059063
Epoch:  194  	Training Loss: 0.031033756211400032
Test Loss:  0.029160931706428528
Valid Loss:  0.031001223251223564
Epoch:  195  	Training Loss: 0.031026415526866913
Test Loss:  0.029155757278203964
Valid Loss:  0.030993148684501648
Epoch:  196  	Training Loss: 0.031019125133752823
Test Loss:  0.02915054000914097
Valid Loss:  0.03098505735397339
Epoch:  197  	Training Loss: 0.031011873856186867
Test Loss:  0.02914527803659439
Valid Loss:  0.030976951122283936
Epoch:  198  	Training Loss: 0.0310046523809433
Test Loss:  0.029139984399080276
Valid Loss:  0.030968839302659035
Epoch:  199  	Training Loss: 0.03099745512008667
Test Loss:  0.029134653508663177
Valid Loss:  0.03096071258187294
Epoch:  200  	Training Loss: 0.03099028393626213
Test Loss:  0.02912929281592369
Valid Loss:  0.030952580273151398
Epoch:  201  	Training Loss: 0.030983146280050278
Test Loss:  0.029123906046152115
Valid Loss:  0.030944442376494408
Epoch:  202  	Training Loss: 0.030976032838225365
Test Loss:  0.029118508100509644
Valid Loss:  0.03093632496893406
Epoch:  203  	Training Loss: 0.030968960374593735
Test Loss:  0.02911309525370598
Valid Loss:  0.03092820756137371
Epoch:  204  	Training Loss: 0.03096192330121994
Test Loss:  0.029107650741934776
Valid Loss:  0.030920077115297318
Epoch:  205  	Training Loss: 0.03095489740371704
Test Loss:  0.029102198779582977
Valid Loss:  0.03091195784509182
Epoch:  206  	Training Loss: 0.03094789758324623
Test Loss:  0.029096711426973343
Valid Loss:  0.030903823673725128
Epoch:  207  	Training Loss: 0.030940905213356018
Test Loss:  0.029091212898492813
Valid Loss:  0.030895687639713287
Epoch:  208  	Training Loss: 0.030934052541851997
Test Loss:  0.029087161645293236
Valid Loss:  0.030888766050338745
Epoch:  209  	Training Loss: 0.03092721477150917
Test Loss:  0.02908155508339405
Valid Loss:  0.030880574136972427
Epoch:  210  	Training Loss: 0.030920449644327164
Test Loss:  0.029077433049678802
Valid Loss:  0.030873645097017288
Epoch:  211  	Training Loss: 0.030913669615983963
Test Loss:  0.029073219746351242
Valid Loss:  0.03086666762828827
Epoch:  212  	Training Loss: 0.03090701624751091
Test Loss:  0.029067404568195343
Valid Loss:  0.030858339741826057
Epoch:  213  	Training Loss: 0.03090030699968338
Test Loss:  0.02906307578086853
Valid Loss:  0.030851271003484726
Epoch:  214  	Training Loss: 0.030893590301275253
Test Loss:  0.029058661311864853
Valid Loss:   43%|████▎     | 215/500 [02:29<02:50,  1.67it/s] 43%|████▎     | 217/500 [02:29<02:04,  2.28it/s] 44%|████▍     | 219/500 [02:29<01:31,  3.06it/s] 44%|████▍     | 221/500 [02:35<05:23,  1.16s/it] 45%|████▍     | 223/500 [02:35<03:50,  1.20it/s] 45%|████▌     | 225/500 [02:36<02:46,  1.66it/s] 45%|████▌     | 227/500 [02:36<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:36<01:29,  3.03it/s] 46%|████▌     | 231/500 [02:42<05:12,  1.16s/it] 47%|████▋     | 233/500 [02:42<03:43,  1.20it/s] 47%|████▋     | 235/500 [02:42<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:43<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:49<05:02,  1.17s/it] 49%|████▊     | 243/500 [02:49<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:49<02:34,  1.65it/s] 49%|████▉     | 247/500 [02:49<01:52,  2.25it/s] 50%|████▉     | 249/500 [02:49<01:23,  3.01it/s] 50%|█████     | 251/500 [02:56<04:53,  1.18s/it] 51%|█████     | 253/500 [02:56<03:29,  1.18it/s] 51%|█████     | 255/500 [02:56<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:56<01:49,  2.23it/s] 52%|█████▏    | 259/500 [02:56<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:03<04:38,  1.16s/it] 53%|█████▎    | 263/500 [03:03<03:18,  1.20it/s] 53%|█████▎    | 265/500 [03:03<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:03<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:03<01:16,  3.03it/s] 54%|█████▍    | 271/500 [03:09<04:26,  1.16s/it] 55%|█████▍    | 273/500 [03:09<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:10<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:10<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:10<01:12,  3.04it/s] 56%|█████▌    | 281/500 [03:16<04:13,  1.16s/it] 57%|█████▋    | 283/500 [03:16<03:00,  1.20it/s]0.030844150111079216
Epoch:  215  	Training Loss: 0.030886922031641006
Test Loss:  0.029054204002022743
Valid Loss:  0.030837025493383408
Epoch:  216  	Training Loss: 0.030880313366651535
Test Loss:  0.02904968336224556
Valid Loss:  0.030829863622784615
Epoch:  217  	Training Loss: 0.030873749405145645
Test Loss:  0.0290451068431139
Valid Loss:  0.030822671949863434
Epoch:  218  	Training Loss: 0.03086722269654274
Test Loss:  0.029040474444627762
Valid Loss:  0.030815456062555313
Epoch:  219  	Training Loss: 0.03086073324084282
Test Loss:  0.029035791754722595
Valid Loss:  0.030808206647634506
Epoch:  220  	Training Loss: 0.03085428476333618
Test Loss:  0.02903105318546295
Valid Loss:  0.030800936743617058
Epoch:  221  	Training Loss: 0.030847858637571335
Test Loss:  0.029026273638010025
Valid Loss:  0.03079363889992237
Epoch:  222  	Training Loss: 0.030841462314128876
Test Loss:  0.029021399095654488
Valid Loss:  0.030786268413066864
Epoch:  223  	Training Loss: 0.030835064128041267
Test Loss:  0.029017314314842224
Valid Loss:  0.03077961504459381
Epoch:  224  	Training Loss: 0.030828695744276047
Test Loss:  0.029012314975261688
Valid Loss:  0.030772177502512932
Epoch:  225  	Training Loss: 0.030822385102510452
Test Loss:  0.02900812402367592
Valid Loss:  0.030765458941459656
Epoch:  226  	Training Loss: 0.030816087499260902
Test Loss:  0.029003862291574478
Valid Loss:  0.030758704990148544
Epoch:  227  	Training Loss: 0.030809832736849785
Test Loss:  0.028999527916312218
Valid Loss:  0.030751895159482956
Epoch:  228  	Training Loss: 0.030803609639406204
Test Loss:  0.028995130211114883
Valid Loss:  0.030745048075914383
Epoch:  229  	Training Loss: 0.03079742193222046
Test Loss:  0.028990672901272774
Valid Loss:  0.03073817305266857
Epoch:  230  	Training Loss: 0.0307912677526474
Test Loss:  0.028986157849431038
Valid Loss:  0.030731262639164925
Epoch:  231  	Training Loss: 0.03078514337539673
Test Loss:  0.028981652110815048
Valid Loss:  0.03072432428598404
Epoch:  232  	Training Loss: 0.030779043212532997
Test Loss:  0.028977153822779655
Valid Loss:  0.030717309564352036
Epoch:  233  	Training Loss: 0.03077293187379837
Test Loss:  0.028972633183002472
Valid Loss:  0.030710265040397644
Epoch:  234  	Training Loss: 0.030766839161515236
Test Loss:  0.028968092054128647
Valid Loss:  0.030703198164701462
Epoch:  235  	Training Loss: 0.030760768800973892
Test Loss:  0.028963526710867882
Valid Loss:  0.03069610521197319
Epoch:  236  	Training Loss: 0.030754711478948593
Test Loss:  0.028958939015865326
Valid Loss:  0.03068898618221283
Epoch:  237  	Training Loss: 0.030748676508665085
Test Loss:  0.028954338282346725
Valid Loss:  0.030681844800710678
Epoch:  238  	Training Loss: 0.03074265643954277
Test Loss:  0.028949718922376633
Valid Loss:  0.03067469224333763
Epoch:  239  	Training Loss: 0.03073665127158165
Test Loss:  0.028945088386535645
Valid Loss:  0.03066752478480339
Epoch:  240  	Training Loss: 0.030730662867426872
Test Loss:  0.02894044667482376
Valid Loss:  0.030660342425107956
Epoch:  241  	Training Loss: 0.03072468936443329
Test Loss:  0.028935786336660385
Valid Loss:  0.03065314330160618
Epoch:  242  	Training Loss: 0.0307187307626009
Test Loss:  0.02893126755952835
Valid Loss:  0.030646078288555145
Epoch:  243  	Training Loss: 0.030712932348251343
Test Loss:  0.028926726430654526
Valid Loss:  0.030639009550213814
Epoch:  244  	Training Loss: 0.030707135796546936
Test Loss:  0.028922181576490402
Valid Loss:  0.030631927773356438
Epoch:  245  	Training Loss: 0.030701367184519768
Test Loss:  0.02891763672232628
Valid Loss:  0.030624844133853912
Epoch:  246  	Training Loss: 0.030695607885718346
Test Loss:  0.028913075104355812
Valid Loss:  0.030617745593190193
Epoch:  247  	Training Loss: 0.030689852312207222
Test Loss:  0.028908517211675644
Valid Loss:  0.03061065264046192
Epoch:  248  	Training Loss: 0.03068411909043789
Test Loss:  0.028903957456350327
Valid Loss:  0.0306035615503788
Epoch:  249  	Training Loss: 0.030678406357765198
Test Loss:  0.028899971395730972
Valid Loss:  0.0305972658097744
Epoch:  250  	Training Loss: 0.03067278303205967
Test Loss:  0.028895962983369827
Valid Loss:  0.030590930953621864
Epoch:  251  	Training Loss: 0.030667195096611977
Test Loss:  0.028891921043395996
Valid Loss:  0.030584566295146942
Epoch:  252  	Training Loss: 0.030661631375551224
Test Loss:  0.02888774685561657
Valid Loss:  0.030578019097447395
Epoch:  253  	Training Loss: 0.03065595030784607
Test Loss:  0.028883539140224457
Valid Loss:  0.030571449548006058
Epoch:  254  	Training Loss: 0.030650289729237556
Test Loss:  0.028879303485155106
Valid Loss:  0.030564842745661736
Epoch:  255  	Training Loss: 0.030644647777080536
Test Loss:  0.028875049203634262
Valid Loss:  0.030558209866285324
Epoch:  256  	Training Loss: 0.030639030039310455
Test Loss:  0.028870772570371628
Valid Loss:  0.030551549047231674
Epoch:  257  	Training Loss: 0.03063342534005642
Test Loss:  0.028866469860076904
Valid Loss:  0.030544864013791084
Epoch:  258  	Training Loss: 0.030627837404608727
Test Loss:  0.028862152248620987
Valid Loss:  0.030538156628608704
Epoch:  259  	Training Loss: 0.030622266232967377
Test Loss:  0.028857823461294174
Valid Loss:  0.03053142875432968
Epoch:  260  	Training Loss: 0.030616704374551773
Test Loss:  0.028853466734290123
Valid Loss:  0.030524682253599167
Epoch:  261  	Training Loss: 0.030611157417297363
Test Loss:  0.028849098831415176
Valid Loss:  0.03051792085170746
Epoch:  262  	Training Loss: 0.03060562163591385
Test Loss:  0.028844643384218216
Valid Loss:  0.030511103570461273
Epoch:  263  	Training Loss: 0.03060004860162735
Test Loss:  0.028840171173214912
Valid Loss:  0.030504267662763596
Epoch:  264  	Training Loss: 0.030594477429986
Test Loss:  0.028835680335760117
Valid Loss:  0.030497413128614426
Epoch:  265  	Training Loss: 0.030588917434215546
Test Loss:  0.028831180185079575
Valid Loss:  0.03049054928123951
Epoch:  266  	Training Loss: 0.03058336302638054
Test Loss:  0.028826672583818436
Valid Loss:  0.030483681708574295
Epoch:  267  	Training Loss: 0.03057781793177128
Test Loss:  0.028822150081396103
Valid Loss:  0.030476801097393036
Epoch:  268  	Training Loss: 0.030572274699807167
Test Loss:  0.028817616403102875
Valid Loss:  0.03046991676092148
Epoch:  269  	Training Loss: 0.0305667445063591
Test Loss:  0.028813078999519348
Valid Loss:  0.030463017523288727
Epoch:  270  	Training Loss: 0.030561236664652824
Test Loss:  0.028809165582060814
Valid Loss:  0.030456962063908577
Epoch:  271  	Training Loss: 0.030555803328752518
Test Loss:  0.028805214911699295
Valid Loss:  0.030450861901044846
Epoch:  272  	Training Loss: 0.03055039420723915
Test Loss:  0.02880130335688591
Valid Loss:  0.030444776639342308
Epoch:  273  	Training Loss: 0.0305450689047575
Test Loss:  0.02879735827445984
Valid Loss:  0.030438661575317383
Epoch:  274  	Training Loss: 0.030539769679307938
Test Loss:  0.02879338711500168
Valid Loss:  0.030432509258389473
Epoch:  275  	Training Loss: 0.03053448721766472
Test Loss:  0.02878938801586628
Valid Loss:  0.030426329001784325
Epoch:  276  	Training Loss: 0.030529223382472992
Test Loss:  0.02878536470234394
Valid Loss:  0.03042011335492134
Epoch:  277  	Training Loss: 0.030523981899023056
Test Loss:  0.028781313449144363
Valid Loss:  0.030413875356316566
Epoch:  278  	Training Loss: 0.030518759042024612
Test Loss:  0.02877724915742874
Valid Loss:  0.030407607555389404
Epoch:  279  	Training Loss: 0.030513547360897064
Test Loss:  0.02877316065132618
Valid Loss:  0.03040132112801075
Epoch:  280  	Training Loss: 0.03050835430622101
Test Loss:  0.028769053518772125
Valid Loss:  0.030395012348890305
Epoch:  281  	Training Loss: 0.03050321899354458
Test Loss:  0.028765607625246048
Valid Loss:  0.0303895752876997
Epoch:  282  	Training Loss: 0.030498087406158447
Test Loss:  0.02876211889088154
Valid Loss:  0.030384093523025513
Epoch:  283  	Training Loss: 0.030493011698126793
Test Loss:  0.02875857800245285
Valid Loss:  0.0303785540163517
Epoch:  284  	Training Loss: 0.03048796020448208
Test Loss:  0.028755005449056625
Valid Loss:  0.030372966080904007
Epoch:  285  	Training Loss: 0.030482936650514603
 57%|█████▋    | 285/500 [03:16<02:09,  1.66it/s] 57%|█████▋    | 287/500 [03:16<01:34,  2.26it/s] 58%|█████▊    | 289/500 [03:17<01:09,  3.04it/s] 58%|█████▊    | 291/500 [03:23<04:03,  1.16s/it] 59%|█████▊    | 293/500 [03:23<02:52,  1.20it/s] 59%|█████▉    | 295/500 [03:23<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:23<01:29,  2.27it/s] 60%|█████▉    | 299/500 [03:23<01:05,  3.05it/s] 60%|██████    | 301/500 [03:30<03:52,  1.17s/it] 61%|██████    | 303/500 [03:30<02:45,  1.19it/s] 61%|██████    | 305/500 [03:30<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:30<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:30<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:36<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:37<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:37<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:37<01:22,  2.21it/s] 64%|██████▍   | 319/500 [03:37<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:43<03:35,  1.20s/it] 65%|██████▍   | 323/500 [03:44<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:44<01:49,  1.60it/s] 65%|██████▌   | 327/500 [03:44<01:19,  2.18it/s] 66%|██████▌   | 329/500 [03:44<00:58,  2.93it/s] 66%|██████▌   | 331/500 [03:50<03:18,  1.18s/it] 67%|██████▋   | 333/500 [03:50<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:50<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:51<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:51<00:53,  3.02it/s] 68%|██████▊   | 341/500 [03:57<03:06,  1.17s/it] 69%|██████▊   | 343/500 [03:57<02:12,  1.19it/s] 69%|██████▉   | 345/500 [03:57<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:57<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:58<00:50,  3.00it/s] 70%|███████   | 351/500 [04:04<02:55,  1.18s/it] 71%|███████   | 353/500 [04:04<02:04,  1.18it/s] 71%|███████   | 355/500 [04:04<01:29,  1.63it/s]Test Loss:  0.02875138819217682
Valid Loss:  0.030367324128746986
Epoch:  286  	Training Loss: 0.030477937310934067
Test Loss:  0.028747739270329475
Valid Loss:  0.03036164492368698
Epoch:  287  	Training Loss: 0.030472971498966217
Test Loss:  0.02874404564499855
Valid Loss:  0.030355915427207947
Epoch:  288  	Training Loss: 0.030468015000224113
Test Loss:  0.02874031849205494
Valid Loss:  0.03035014122724533
Epoch:  289  	Training Loss: 0.0304630845785141
Test Loss:  0.02873656526207924
Valid Loss:  0.030344337224960327
Epoch:  290  	Training Loss: 0.030458170920610428
Test Loss:  0.02873278595507145
Valid Loss:  0.030338512733578682
Epoch:  291  	Training Loss: 0.030453305691480637
Test Loss:  0.02872971072793007
Valid Loss:  0.030333591625094414
Epoch:  292  	Training Loss: 0.030448447912931442
Test Loss:  0.02872595377266407
Valid Loss:  0.03032774105668068
Epoch:  293  	Training Loss: 0.03044373169541359
Test Loss:  0.028722897171974182
Valid Loss:  0.03032279759645462
Epoch:  294  	Training Loss: 0.030439013615250587
Test Loss:  0.02871977910399437
Valid Loss:  0.03031778708100319
Epoch:  295  	Training Loss: 0.030434317886829376
Test Loss:  0.02871660329401493
Valid Loss:  0.03031269833445549
Epoch:  296  	Training Loss: 0.030429648235440254
Test Loss:  0.028713352978229523
Valid Loss:  0.03030753880739212
Epoch:  297  	Training Loss: 0.03042498417198658
Test Loss:  0.028710056096315384
Valid Loss:  0.030302317813038826
Epoch:  298  	Training Loss: 0.030420344322919846
Test Loss:  0.028706692159175873
Valid Loss:  0.030297016724944115
Epoch:  299  	Training Loss: 0.03041570633649826
Test Loss:  0.028703290969133377
Valid Loss:  0.03029167279601097
Epoch:  300  	Training Loss: 0.030411094427108765
Test Loss:  0.028699826449155807
Valid Loss:  0.030286263674497604
Epoch:  301  	Training Loss: 0.03040647879242897
Test Loss:  0.028696328401565552
Valid Loss:  0.030280809849500656
Epoch:  302  	Training Loss: 0.03040187992155552
Test Loss:  0.02869262546300888
Valid Loss:  0.030275164172053337
Epoch:  303  	Training Loss: 0.030397139489650726
Test Loss:  0.028688887134194374
Valid Loss:  0.030269484966993332
Epoch:  304  	Training Loss: 0.03039240464568138
Test Loss:  0.02868511900305748
Valid Loss:  0.030263762921094894
Epoch:  305  	Training Loss: 0.03038768656551838
Test Loss:  0.02868131920695305
Valid Loss:  0.03025801293551922
Epoch:  306  	Training Loss: 0.030382975935935974
Test Loss:  0.02867749333381653
Valid Loss:  0.030252229422330856
Epoch:  307  	Training Loss: 0.030378278344869614
Test Loss:  0.02867364138364792
Valid Loss:  0.030246416106820107
Epoch:  308  	Training Loss: 0.030373590067029
Test Loss:  0.02866976708173752
Valid Loss:  0.030240584164857864
Epoch:  309  	Training Loss: 0.030368942767381668
Test Loss:  0.028666673228144646
Valid Loss:  0.03023575060069561
Epoch:  310  	Training Loss: 0.030364321544766426
Test Loss:  0.028663530945777893
Valid Loss:  0.030230853706598282
Epoch:  311  	Training Loss: 0.030359724536538124
Test Loss:  0.028660336509346962
Valid Loss:  0.03022589534521103
Epoch:  312  	Training Loss: 0.03035515733063221
Test Loss:  0.02865694649517536
Valid Loss:  0.03022073768079281
Epoch:  313  	Training Loss: 0.03035048022866249
Test Loss:  0.028653506189584732
Valid Loss:  0.030215520411729813
Epoch:  314  	Training Loss: 0.030345816165208817
Test Loss:  0.028650006279349327
Valid Loss:  0.030210234224796295
Epoch:  315  	Training Loss: 0.030341165140271187
Test Loss:  0.028646457940340042
Valid Loss:  0.0302048958837986
Epoch:  316  	Training Loss: 0.03033652901649475
Test Loss:  0.028642868623137474
Valid Loss:  0.030199505388736725
Epoch:  317  	Training Loss: 0.03033190220594406
Test Loss:  0.028639238327741623
Valid Loss:  0.03019406646490097
Epoch:  318  	Training Loss: 0.030327286571264267
Test Loss:  0.028635568916797638
Valid Loss:  0.030188584700226784
Epoch:  319  	Training Loss: 0.030322685837745667
Test Loss:  0.02863186225295067
Valid Loss:  0.030183058232069016
Epoch:  320  	Training Loss: 0.030318088829517365
Test Loss:  0.028628118336200714
Valid Loss:  0.030177492648363113
Epoch:  321  	Training Loss: 0.030313510447740555
Test Loss:  0.02862435020506382
Valid Loss:  0.030171897262334824
Epoch:  322  	Training Loss: 0.030308939516544342
Test Loss:  0.028620881959795952
Valid Loss:  0.030166596174240112
Epoch:  323  	Training Loss: 0.03030470758676529
Test Loss:  0.028617389500141144
Valid Loss:  0.030161261558532715
Epoch:  324  	Training Loss: 0.030300496146082878
Test Loss:  0.028613874688744545
Valid Loss:  0.030155900865793228
Epoch:  325  	Training Loss: 0.030296288430690765
Test Loss:  0.028610337525606155
Valid Loss:  0.03015052154660225
Epoch:  326  	Training Loss: 0.0302920863032341
Test Loss:  0.028606776148080826
Valid Loss:  0.030145108699798584
Epoch:  327  	Training Loss: 0.03028789721429348
Test Loss:  0.028603196144104004
Valid Loss:  0.030139679089188576
Epoch:  328  	Training Loss: 0.03028370998799801
Test Loss:  0.02859959751367569
Valid Loss:  0.030134228989481926
Epoch:  329  	Training Loss: 0.030279528349637985
Test Loss:  0.028595980256795883
Valid Loss:  0.030128760263323784
Epoch:  330  	Training Loss: 0.03027535229921341
Test Loss:  0.028592348098754883
Valid Loss:  0.0301232747733593
Epoch:  331  	Training Loss: 0.03027118369936943
Test Loss:  0.028588704764842987
Valid Loss:  0.030117778107523918
Epoch:  332  	Training Loss: 0.030267026275396347
Test Loss:  0.028584850952029228
Valid Loss:  0.030112067237496376
Epoch:  333  	Training Loss: 0.030262665823101997
Test Loss:  0.028580987825989723
Valid Loss:  0.03010633960366249
Epoch:  334  	Training Loss: 0.030258316546678543
Test Loss:  0.02857711911201477
Valid Loss:  0.030100608244538307
Epoch:  335  	Training Loss: 0.03025401011109352
Test Loss:  0.02857406809926033
Valid Loss:  0.030095916241407394
Epoch:  336  	Training Loss: 0.030249718576669693
Test Loss:  0.02857097238302231
Valid Loss:  0.030091168358922005
Epoch:  337  	Training Loss: 0.030245453119277954
Test Loss:  0.028567828238010406
Valid Loss:  0.03008636087179184
Epoch:  338  	Training Loss: 0.030241210013628006
Test Loss:  0.028564635664224625
Valid Loss:  0.030081501230597496
Epoch:  339  	Training Loss: 0.030236974358558655
Test Loss:  0.028561394661664963
Valid Loss:  0.030076587572693825
Epoch:  340  	Training Loss: 0.030232753604650497
Test Loss:  0.028558097779750824
Valid Loss:  0.030071603134274483
Epoch:  341  	Training Loss: 0.03022853471338749
Test Loss:  0.028554767370224
Valid Loss:  0.030066583305597305
Epoch:  342  	Training Loss: 0.030224334448575974
Test Loss:  0.028551355004310608
Valid Loss:  0.0300615057349205
Epoch:  343  	Training Loss: 0.030220123007893562
Test Loss:  0.028547905385494232
Valid Loss:  0.030056387186050415
Epoch:  344  	Training Loss: 0.03021591529250145
Test Loss:  0.028544414788484573
Valid Loss:  0.03005122020840645
Epoch:  345  	Training Loss: 0.030211716890335083
Test Loss:  0.028540894389152527
Valid Loss:  0.030046019703149796
Epoch:  346  	Training Loss: 0.030207516625523567
Test Loss:  0.028537333011627197
Valid Loss:  0.03004077821969986
Epoch:  347  	Training Loss: 0.03020332008600235
Test Loss:  0.028533753007650375
Valid Loss:  0.030035512521862984
Epoch:  348  	Training Loss: 0.03019913099706173
Test Loss:  0.02853013388812542
Valid Loss:  0.030030207708477974
Epoch:  349  	Training Loss: 0.03019494190812111
Test Loss:  0.028526494279503822
Valid Loss:  0.030024874955415726
Epoch:  350  	Training Loss: 0.030190758407115936
Test Loss:  0.028522830456495285
Valid Loss:  0.030019517987966537
Epoch:  351  	Training Loss: 0.030186571180820465
Test Loss:  0.02851913869380951
Valid Loss:  0.03001413494348526
Epoch:  352  	Training Loss: 0.03018238954246044
Test Loss:  0.028515523299574852
Valid Loss:  0.030008796602487564
Epoch:  353  	Training Loss: 0.030178293585777283
Test Loss:  0.02851187251508236
Valid Loss:  0.030003443360328674
Epoch:  354  	Training Loss: 0.030174190178513527
Test Loss:  0.028508221730589867
Valid Loss:  0.02999807335436344
Epoch:  355  	Training Loss: 0.030170097947120667
Test Loss:  0.028504550457000732
Valid Loss:  0.029992688447237015
 71%|███████▏  | 357/500 [04:04<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:04<00:47,  2.98it/s] 72%|███████▏  | 361/500 [04:11<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:11<01:57,  1.17it/s] 73%|███████▎  | 365/500 [04:11<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:11<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:11<00:44,  2.97it/s] 74%|███████▍  | 371/500 [04:18<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:18<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:18<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:18<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:18<00:40,  2.98it/s] 76%|███████▌  | 381/500 [04:25<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:25<01:40,  1.17it/s] 77%|███████▋  | 385/500 [04:25<01:11,  1.62it/s] 77%|███████▋  | 387/500 [04:25<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:25<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:32<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:32<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:32<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:32<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:32<00:34,  2.97it/s] 80%|████████  | 401/500 [04:38<01:56,  1.17s/it] 81%|████████  | 403/500 [04:38<01:21,  1.18it/s] 81%|████████  | 405/500 [04:39<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.23it/s] 82%|████████▏ | 409/500 [04:39<00:30,  2.99it/s] 82%|████████▏ | 411/500 [04:45<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:45<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:45<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:46<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:52<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:52<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:52<00:45,  1.64it/s]Epoch:  356  	Training Loss: 0.030166015028953552
Test Loss:  0.028500862419605255
Valid Loss:  0.02998734451830387
Epoch:  357  	Training Loss: 0.03016192466020584
Test Loss:  0.028497163206338882
Valid Loss:  0.029982155188918114
Epoch:  358  	Training Loss: 0.030157845467329025
Test Loss:  0.028493452817201614
Valid Loss:  0.029976962134242058
Epoch:  359  	Training Loss: 0.030153773725032806
Test Loss:  0.028489723801612854
Valid Loss:  0.029971754178404808
Epoch:  360  	Training Loss: 0.03014969825744629
Test Loss:  0.028485998511314392
Valid Loss:  0.029966548085212708
Epoch:  361  	Training Loss: 0.03014563024044037
Test Loss:  0.028482258319854736
Valid Loss:  0.029961340129375458
Epoch:  362  	Training Loss: 0.030141569674015045
Test Loss:  0.02847844734787941
Valid Loss:  0.02995605766773224
Epoch:  363  	Training Loss: 0.030137447640299797
Test Loss:  0.028474628925323486
Valid Loss:  0.02995077520608902
Epoch:  364  	Training Loss: 0.030133329331874847
Test Loss:  0.028470812365412712
Valid Loss:  0.0299454964697361
Epoch:  365  	Training Loss: 0.030129222199320793
Test Loss:  0.028466984629631042
Valid Loss:  0.02994021400809288
Epoch:  366  	Training Loss: 0.03012511506676674
Test Loss:  0.028463151305913925
Valid Loss:  0.029934925958514214
Epoch:  367  	Training Loss: 0.030121011659502983
Test Loss:  0.028459321707487106
Valid Loss:  0.029929641634225845
Epoch:  368  	Training Loss: 0.030116958543658257
Test Loss:  0.028456345200538635
Valid Loss:  0.029925188049674034
Epoch:  369  	Training Loss: 0.03011293150484562
Test Loss:  0.028453312814235687
Valid Loss:  0.029920676723122597
Epoch:  370  	Training Loss: 0.03010891005396843
Test Loss:  0.02845022827386856
Valid Loss:  0.029916131868958473
Epoch:  371  	Training Loss: 0.030104905366897583
Test Loss:  0.028447110205888748
Valid Loss:  0.02991156280040741
Epoch:  372  	Training Loss: 0.03010091371834278
Test Loss:  0.028444061055779457
Valid Loss:  0.029907066375017166
Epoch:  373  	Training Loss: 0.030097052454948425
Test Loss:  0.028440963476896286
Valid Loss:  0.029902532696723938
Epoch:  374  	Training Loss: 0.030093198642134666
Test Loss:  0.02843783237040043
Valid Loss:  0.029897969216108322
Epoch:  375  	Training Loss: 0.030089352279901505
Test Loss:  0.02843465656042099
Valid Loss:  0.02989337220788002
Epoch:  376  	Training Loss: 0.030085507780313492
Test Loss:  0.028431450948119164
Valid Loss:  0.029888752847909927
Epoch:  377  	Training Loss: 0.030081672593951225
Test Loss:  0.0284282099455595
Valid Loss:  0.029884098097682
Epoch:  378  	Training Loss: 0.030077848583459854
Test Loss:  0.028424929827451706
Valid Loss:  0.029879411682486534
Epoch:  379  	Training Loss: 0.030074015259742737
Test Loss:  0.02842162735760212
Valid Loss:  0.029874708503484726
Epoch:  380  	Training Loss: 0.030070200562477112
Test Loss:  0.02841830626130104
Valid Loss:  0.029870126396417618
Epoch:  381  	Training Loss: 0.030066391453146935
Test Loss:  0.028414953500032425
Valid Loss:  0.02986554242670536
Epoch:  382  	Training Loss: 0.030062584206461906
Test Loss:  0.02841152809560299
Valid Loss:  0.02986089512705803
Epoch:  383  	Training Loss: 0.03005872294306755
Test Loss:  0.028408076614141464
Valid Loss:  0.029856231063604355
Epoch:  384  	Training Loss: 0.030054863542318344
Test Loss:  0.028404600918293
Valid Loss:  0.029851559549570084
Epoch:  385  	Training Loss: 0.030051006004214287
Test Loss:  0.028401104733347893
Valid Loss:  0.02984687127172947
Epoch:  386  	Training Loss: 0.03004714846611023
Test Loss:  0.02839759737253189
Valid Loss:  0.029842182993888855
Epoch:  387  	Training Loss: 0.03004330024123192
Test Loss:  0.028394140303134918
Valid Loss:  0.029837477952241898
Epoch:  388  	Training Loss: 0.03003944642841816
Test Loss:  0.028390783816576004
Valid Loss:  0.029832763597369194
Epoch:  389  	Training Loss: 0.0300355926156044
Test Loss:  0.02838742360472679
Valid Loss:  0.029828038066625595
Epoch:  390  	Training Loss: 0.03003174252808094
Test Loss:  0.028384048491716385
Valid Loss:  0.029823455959558487
Epoch:  391  	Training Loss: 0.03002789244055748
Test Loss:  0.02838066965341568
Valid Loss:  0.029818933457136154
Epoch:  392  	Training Loss: 0.030024047940969467
Test Loss:  0.028377193957567215
Valid Loss:  0.02981432154774666
Epoch:  393  	Training Loss: 0.03002011403441429
Test Loss:  0.028373725712299347
Valid Loss:  0.029809720814228058
Epoch:  394  	Training Loss: 0.03001619689166546
Test Loss:  0.02837025374174118
Valid Loss:  0.029805125668644905
Epoch:  395  	Training Loss: 0.030012279748916626
Test Loss:  0.02836677059531212
Valid Loss:  0.029800530523061752
Epoch:  396  	Training Loss: 0.03000837005674839
Test Loss:  0.028363289311528206
Valid Loss:  0.02979593724012375
Epoch:  397  	Training Loss: 0.030004465952515602
Test Loss:  0.028359800577163696
Valid Loss:  0.029791340231895447
Epoch:  398  	Training Loss: 0.030000563710927963
Test Loss:  0.028356309980154037
Valid Loss:  0.02978675067424774
Epoch:  399  	Training Loss: 0.029996663331985474
Test Loss:  0.02835281938314438
Valid Loss:  0.029782159253954887
Epoch:  400  	Training Loss: 0.02999277226626873
Test Loss:  0.02834933251142502
Valid Loss:  0.02977757900953293
Epoch:  401  	Training Loss: 0.029988886788487434
Test Loss:  0.02834584377706051
Valid Loss:  0.029773004353046417
Epoch:  402  	Training Loss: 0.029985003173351288
Test Loss:  0.028342487290501595
Valid Loss:  0.029768571257591248
Epoch:  403  	Training Loss: 0.029981274157762527
Test Loss:  0.028339136391878128
Valid Loss:  0.029764141887426376
Epoch:  404  	Training Loss: 0.029977548867464066
Test Loss:  0.028335778042674065
Valid Loss:  0.029759714379906654
Epoch:  405  	Training Loss: 0.029973823577165604
Test Loss:  0.028332415968179703
Valid Loss:  0.02975529059767723
Epoch:  406  	Training Loss: 0.02997010014951229
Test Loss:  0.02832905575633049
Valid Loss:  0.029750864952802658
Epoch:  407  	Training Loss: 0.029966380447149277
Test Loss:  0.028325699269771576
Valid Loss:  0.029746446758508682
Epoch:  408  	Training Loss: 0.02996267005801201
Test Loss:  0.02832234650850296
Valid Loss:  0.029742036014795303
Epoch:  409  	Training Loss: 0.02995896339416504
Test Loss:  0.028318991884589195
Valid Loss:  0.029737628996372223
Epoch:  410  	Training Loss: 0.02995525859296322
Test Loss:  0.02831563539803028
Valid Loss:  0.02973322756588459
Epoch:  411  	Training Loss: 0.029951555654406548
Test Loss:  0.028312278911471367
Valid Loss:  0.029728824272751808
Epoch:  412  	Training Loss: 0.029947858303785324
Test Loss:  0.028309039771556854
Valid Loss:  0.029724527150392532
Epoch:  413  	Training Loss: 0.029944278299808502
Test Loss:  0.02830580249428749
Valid Loss:  0.029720241203904152
Epoch:  414  	Training Loss: 0.02994069643318653
Test Loss:  0.028302568942308426
Valid Loss:  0.02971595525741577
Epoch:  415  	Training Loss: 0.029937125742435455
Test Loss:  0.02829933539032936
Valid Loss:  0.02971167489886284
Epoch:  416  	Training Loss: 0.02993355505168438
Test Loss:  0.028296101838350296
Valid Loss:  0.029707401990890503
Epoch:  417  	Training Loss: 0.02992998994886875
Test Loss:  0.02829287201166153
Valid Loss:  0.029703132808208466
Epoch:  418  	Training Loss: 0.02992643229663372
Test Loss:  0.028289640322327614
Valid Loss:  0.029698863625526428
Epoch:  419  	Training Loss: 0.02992287091910839
Test Loss:  0.028286416083574295
Valid Loss:  0.029694609344005585
Epoch:  420  	Training Loss: 0.029919322580099106
Test Loss:  0.028283197432756424
Valid Loss:  0.02969035506248474
Epoch:  421  	Training Loss: 0.02991577982902527
Test Loss:  0.028279978781938553
Valid Loss:  0.029686111956834793
Epoch:  422  	Training Loss: 0.02991224080324173
Test Loss:  0.02827679179608822
Valid Loss:  0.029681919142603874
Epoch:  423  	Training Loss: 0.029908746480941772
Test Loss:  0.028273606672883034
Valid Loss:  0.029677731916308403
Epoch:  424  	Training Loss: 0.029905255883932114
Test Loss:  0.028270423412322998
Valid Loss:  0.029673544690012932
Epoch:  425  	Training Loss: 0.029901772737503052
Test Loss:  0.02826724573969841
Valid Loss:  0.02966936305165291
Epoch:  426  	Training Loss: 0.02989828959107399
Test Loss:  0.028264060616493225
 85%|████████▌ | 427/500 [04:52<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:52<00:23,  3.00it/s] 86%|████████▌ | 431/500 [04:59<01:19,  1.16s/it] 87%|████████▋ | 433/500 [04:59<00:55,  1.20it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.66it/s] 87%|████████▋ | 437/500 [04:59<00:27,  2.26it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.04it/s] 88%|████████▊ | 441/500 [05:05<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.19it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:12<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:12<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:19<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:19<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:26<00:33,  1.16s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.20it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.66it/s] 95%|█████████▌| 477/500 [05:26<00:10,  2.27it/s] 96%|█████████▌| 479/500 [05:26<00:06,  3.06it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.16s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.20it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.66it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.26it/s] 98%|█████████▊| 489/500 [05:33<00:03,  3.05it/s] 98%|█████████▊| 491/500 [05:39<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:39<00:05,  1.20it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.65it/s]Valid Loss:  0.02966519072651863
Epoch:  427  	Training Loss: 0.029894808307290077
Test Loss:  0.028260882943868637
Valid Loss:  0.029661010950803757
Epoch:  428  	Training Loss: 0.029891327023506165
Test Loss:  0.02825770527124405
Valid Loss:  0.029656842350959778
Epoch:  429  	Training Loss: 0.02988785319030285
Test Loss:  0.02825453132390976
Valid Loss:  0.029652677476406097
Epoch:  430  	Training Loss: 0.029884381219744682
Test Loss:  0.02825135737657547
Valid Loss:  0.029648512601852417
Epoch:  431  	Training Loss: 0.029880909249186516
Test Loss:  0.02824818715453148
Valid Loss:  0.029644358903169632
Epoch:  432  	Training Loss: 0.029877442866563797
Test Loss:  0.028244903311133385
Valid Loss:  0.0296400748193264
Epoch:  433  	Training Loss: 0.02987385168671608
Test Loss:  0.028241613879799843
Valid Loss:  0.029635794460773468
Epoch:  434  	Training Loss: 0.02987026236951351
Test Loss:  0.02823833003640175
Valid Loss:  0.029631517827510834
Epoch:  435  	Training Loss: 0.029866676777601242
Test Loss:  0.028235644102096558
Valid Loss:  0.02962760254740715
Epoch:  436  	Training Loss: 0.029863152652978897
Test Loss:  0.02823292836546898
Valid Loss:  0.029623670503497124
Epoch:  437  	Training Loss: 0.02985963597893715
Test Loss:  0.028230169788002968
Valid Loss:  0.02961972914636135
Epoch:  438  	Training Loss: 0.0298561230301857
Test Loss:  0.028227388858795166
Valid Loss:  0.029615774750709534
Epoch:  439  	Training Loss: 0.02985261380672455
Test Loss:  0.02822457067668438
Valid Loss:  0.029611807316541672
Epoch:  440  	Training Loss: 0.029849110171198845
Test Loss:  0.028221726417541504
Valid Loss:  0.029607824981212616
Epoch:  441  	Training Loss: 0.02984561026096344
Test Loss:  0.028218869119882584
Valid Loss:  0.02960383892059326
Epoch:  442  	Training Loss: 0.02984211966395378
Test Loss:  0.02821602299809456
Valid Loss:  0.029599865898489952
Epoch:  443  	Training Loss: 0.02983866073191166
Test Loss:  0.02821316570043564
Valid Loss:  0.029595885425806046
Epoch:  444  	Training Loss: 0.029835209250450134
Test Loss:  0.028210286051034927
Valid Loss:  0.029591908678412437
Epoch:  445  	Training Loss: 0.029831767082214355
Test Loss:  0.028207391500473022
Valid Loss:  0.029587915167212486
Epoch:  446  	Training Loss: 0.029828328639268875
Test Loss:  0.028204474598169327
Valid Loss:  0.029583921656012535
Epoch:  447  	Training Loss: 0.029824895784258842
Test Loss:  0.028201550245285034
Valid Loss:  0.029579920694231987
Epoch:  448  	Training Loss: 0.029821470379829407
Test Loss:  0.028198599815368652
Valid Loss:  0.029575912281870842
Epoch:  449  	Training Loss: 0.029818041250109673
Test Loss:  0.028195641934871674
Valid Loss:  0.029571907594799995
Epoch:  450  	Training Loss: 0.029814627021551132
Test Loss:  0.0281926728785038
Valid Loss:  0.029567889869213104
Epoch:  451  	Training Loss: 0.029811207205057144
Test Loss:  0.02818968892097473
Valid Loss:  0.029563874006271362
Epoch:  452  	Training Loss: 0.02980779856443405
Test Loss:  0.028186582028865814
Valid Loss:  0.02955976314842701
Epoch:  453  	Training Loss: 0.029804285615682602
Test Loss:  0.0281834676861763
Valid Loss:  0.029555650427937508
Epoch:  454  	Training Loss: 0.02980078011751175
Test Loss:  0.028180338442325592
Valid Loss:  0.029551535844802856
Epoch:  455  	Training Loss: 0.029797272756695747
Test Loss:  0.028177205473184586
Valid Loss:  0.029547421261668205
Epoch:  456  	Training Loss: 0.029793772846460342
Test Loss:  0.028174063190817833
Valid Loss:  0.029543304815888405
Epoch:  457  	Training Loss: 0.029790276661515236
Test Loss:  0.028170917183160782
Valid Loss:  0.029539186507463455
Epoch:  458  	Training Loss: 0.02978678047657013
Test Loss:  0.028167763724923134
Valid Loss:  0.029535070061683655
Epoch:  459  	Training Loss: 0.02978329360485077
Test Loss:  0.028164606541395187
Valid Loss:  0.029530953615903854
Epoch:  460  	Training Loss: 0.029779810458421707
Test Loss:  0.02816145122051239
Valid Loss:  0.029526839032769203
Epoch:  461  	Training Loss: 0.029776323586702347
Test Loss:  0.02815828286111355
Valid Loss:  0.02952272817492485
Epoch:  462  	Training Loss: 0.029772846028208733
Test Loss:  0.028155086562037468
Valid Loss:  0.029518581926822662
Epoch:  463  	Training Loss: 0.02976933866739273
Test Loss:  0.02815188653767109
Valid Loss:  0.029514441266655922
Epoch:  464  	Training Loss: 0.029765835031867027
Test Loss:  0.028148695826530457
Valid Loss:  0.029510311782360077
Epoch:  465  	Training Loss: 0.029762350022792816
Test Loss:  0.02814549393951893
Valid Loss:  0.029506180435419083
Epoch:  466  	Training Loss: 0.029758857563138008
Test Loss:  0.028142297640442848
Valid Loss:  0.02950204908847809
Epoch:  467  	Training Loss: 0.029755374416708946
Test Loss:  0.028139103204011917
Valid Loss:  0.02949792705476284
Epoch:  468  	Training Loss: 0.029751896858215332
Test Loss:  0.028135912492871284
Valid Loss:  0.029493926092982292
Epoch:  469  	Training Loss: 0.029748432338237762
Test Loss:  0.028132718056440353
Valid Loss:  0.029489990323781967
Epoch:  470  	Training Loss: 0.029744967818260193
Test Loss:  0.02812952548265457
Valid Loss:  0.02948606386780739
Epoch:  471  	Training Loss: 0.029741507023572922
Test Loss:  0.02812633477151394
Valid Loss:  0.029482144862413406
Epoch:  472  	Training Loss: 0.029738053679466248
Test Loss:  0.028123194351792336
Valid Loss:  0.02947826124727726
Epoch:  473  	Training Loss: 0.02973468229174614
Test Loss:  0.028120649978518486
Valid Loss:  0.02947458252310753
Epoch:  474  	Training Loss: 0.029731327667832375
Test Loss:  0.028118064627051353
Valid Loss:  0.02947090193629265
Epoch:  475  	Training Loss: 0.02972797490656376
Test Loss:  0.02811545878648758
Valid Loss:  0.029467249289155006
Epoch:  476  	Training Loss: 0.029724640771746635
Test Loss:  0.028112810105085373
Valid Loss:  0.029463589191436768
Epoch:  477  	Training Loss: 0.029721304774284363
Test Loss:  0.028110140934586525
Valid Loss:  0.02945994772017002
Epoch:  478  	Training Loss: 0.029717976227402687
Test Loss:  0.028107447549700737
Valid Loss:  0.029456306248903275
Epoch:  479  	Training Loss: 0.02971465513110161
Test Loss:  0.028104720637202263
Valid Loss:  0.029452670365571976
Epoch:  480  	Training Loss: 0.029711341485381126
Test Loss:  0.028101976960897446
Valid Loss:  0.029449045658111572
Epoch:  481  	Training Loss: 0.029708031564950943
Test Loss:  0.02809920348227024
Valid Loss:  0.02944542095065117
Epoch:  482  	Training Loss: 0.029704727232456207
Test Loss:  0.028096219524741173
Valid Loss:  0.029441624879837036
Epoch:  483  	Training Loss: 0.02970123663544655
Test Loss:  0.028093213215470314
Valid Loss:  0.029437832534313202
Epoch:  484  	Training Loss: 0.02969774603843689
Test Loss:  0.02809019573032856
Valid Loss:  0.029434045776724815
Epoch:  485  	Training Loss: 0.029694266617298126
Test Loss:  0.028087161481380463
Valid Loss:  0.029430262744426727
Epoch:  486  	Training Loss: 0.02969079092144966
Test Loss:  0.02808411791920662
Valid Loss:  0.029426492750644684
Epoch:  487  	Training Loss: 0.029687324538826942
Test Loss:  0.028081052005290985
Valid Loss:  0.029422719031572342
Epoch:  488  	Training Loss: 0.029683854430913925
Test Loss:  0.028077978640794754
Valid Loss:  0.029418952763080597
Epoch:  489  	Training Loss: 0.029680391773581505
Test Loss:  0.028074897825717926
Valid Loss:  0.02941519394516945
Epoch:  490  	Training Loss: 0.029676934704184532
Test Loss:  0.028071800246834755
Valid Loss:  0.02941143698990345
Epoch:  491  	Training Loss: 0.029673483222723007
Test Loss:  0.028068695217370987
Valid Loss:  0.029407689347863197
Epoch:  492  	Training Loss: 0.02967003360390663
Test Loss:  0.028065580874681473
Valid Loss:  0.029403939843177795
Epoch:  493  	Training Loss: 0.029666587710380554
Test Loss:  0.02806246653199196
Valid Loss:  0.029400203377008438
Epoch:  494  	Training Loss: 0.029663152992725372
Test Loss:  0.028059346601366997
Valid Loss:  0.02939647063612938
Epoch:  495  	Training Loss: 0.02965972200036049
Test Loss:  0.028056219220161438
Valid Loss:  0.02939274162054062
Epoch:  496  	Training Loss: 0.029656298458576202
Test Loss:  0.02805308625102043
Valid Loss:  0.029389021918177605
 99%|█████████▉| 497/500 [05:40<00:01,  2.26it/s]100%|█████████▉| 499/500 [05:40<00:00,  3.03it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
Epoch:  497  	Training Loss: 0.029652874916791916
Test Loss:  0.02804994210600853
Valid Loss:  0.029385298490524292
Epoch:  498  	Training Loss: 0.02964945137500763
Test Loss:  0.028046801686286926
Valid Loss:  0.029381582513451576
Epoch:  499  	Training Loss: 0.02964603714644909
Test Loss:  0.02804364264011383
Valid Loss:  0.02937786839902401
Epoch:  500  	Training Loss: 0.029642615467309952
Test Loss:  0.028040489181876183
Valid Loss:  0.02937415800988674
seed is  11
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:13,  6.16s/it]  1%|          | 3/500 [00:06<13:39,  1.65s/it]  1%|          | 5/500 [00:06<06:53,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:12<10:41,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:39,  3.02it/s]  4%|▍         | 21/500 [00:25<17:10,  2.15s/it]  5%|▍         | 23/500 [00:26<12:02,  1.52s/it]  5%|▌         | 25/500 [00:26<08:30,  1.07s/it]  5%|▌         | 27/500 [00:26<06:03,  1.30it/s]  6%|▌         | 29/500 [00:26<04:22,  1.80it/s]  6%|▌         | 31/500 [00:32<10:29,  1.34s/it]  7%|▋         | 33/500 [00:32<07:28,  1.04it/s]  7%|▋         | 35/500 [00:33<05:21,  1.45it/s]  7%|▋         | 37/500 [00:33<03:53,  1.99it/s]  8%|▊         | 39/500 [00:33<02:51,  2.69it/s]  8%|▊         | 41/500 [00:39<09:12,  1.20s/it]  9%|▊         | 43/500 [00:39<06:34,  1.16it/s]  9%|▉         | 45/500 [00:39<04:44,  1.60it/s]  9%|▉         | 47/500 [00:40<03:26,  2.19it/s] 10%|▉         | 49/500 [00:40<02:32,  2.95it/s] 10%|█         | 51/500 [00:46<08:52,  1.19s/it] 11%|█         | 53/500 [00:46<06:20,  1.18it/s] 11%|█         | 55/500 [00:46<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:46<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:47<02:27,  3.00it/s] 12%|█▏        | 61/500 [00:53<08:38,  1.18s/it] 13%|█▎        | 63/500 [00:53<06:10,  1.18it/s] 13%|█▎        | 65/500 [00:53<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:53<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:53<02:23,  3.00it/s]Epoch:  1  	Training Loss: 0.031252775341272354
Test Loss:  0.19469426572322845
Valid Loss:  0.19936272501945496
Epoch:  2  	Training Loss: 0.1948360800743103
Test Loss:  0.023570530116558075
Valid Loss:  0.02909204177558422
Epoch:  3  	Training Loss: 0.02644679695367813
Test Loss:  0.016320500522851944
Valid Loss:  0.020917711779475212
Epoch:  4  	Training Loss: 0.01893601194024086
Test Loss:  0.013929550535976887
Valid Loss:  0.017923735082149506
Epoch:  5  	Training Loss: 0.016310982406139374
Test Loss:  0.01283230073750019
Valid Loss:  0.01642470806837082
Epoch:  6  	Training Loss: 0.015032690949738026
Test Loss:  0.0120948301628232
Valid Loss:  0.015406284481287003
Epoch:  7  	Training Loss: 0.014157330617308617
Test Loss:  0.01147637888789177
Valid Loss:  0.014577001333236694
Epoch:  8  	Training Loss: 0.013430695980787277
Test Loss:  0.010915584862232208
Valid Loss:  0.013847343623638153
Epoch:  9  	Training Loss: 0.012780570425093174
Test Loss:  0.010396264493465424
Valid Loss:  0.013184722512960434
Epoch:  10  	Training Loss: 0.012185011059045792
Test Loss:  0.009913695976138115
Valid Loss:  0.01257510669529438
Epoch:  11  	Training Loss: 0.011635204777121544
Test Loss:  0.009465854614973068
Valid Loss:  0.012012028135359287
Epoch:  12  	Training Loss: 0.011127259582281113
Test Loss:  0.005662587005645037
Valid Loss:  0.007615732494741678
Epoch:  13  	Training Loss: 0.007100917398929596
Test Loss:  0.006366953253746033
Valid Loss:  0.006823936477303505
Epoch:  14  	Training Loss: 0.006864933297038078
Test Loss:  0.009314336813986301
Valid Loss:  0.012493297457695007
Epoch:  15  	Training Loss: 0.011852243915200233
Test Loss:  0.03632700443267822
Valid Loss:  0.03240066394209862
Epoch:  16  	Training Loss: 0.03400622308254242
Test Loss:  0.04514350742101669
Valid Loss:  0.05236321687698364
Epoch:  17  	Training Loss: 0.05163896083831787
Test Loss:  0.0396893285214901
Valid Loss:  0.03802754729986191
Epoch:  18  	Training Loss: 0.039131924510002136
Test Loss:  0.0054022688418626785
Valid Loss:  0.00788919348269701
Epoch:  19  	Training Loss: 0.00770486518740654
Test Loss:  0.004878412466496229
Valid Loss:  0.005448947660624981
Epoch:  20  	Training Loss: 0.005579044111073017
Test Loss:  0.003755559679120779
Valid Loss:  0.005038434639573097
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.005042385775595903
Test Loss:  0.003966928459703922
Valid Loss:  0.004510854370892048
Epoch:  22  	Training Loss: 0.004724110476672649
Test Loss:  0.003420647233724594
Valid Loss:  0.004251537844538689
Epoch:  23  	Training Loss: 0.004407966509461403
Test Loss:  0.0032586059533059597
Valid Loss:  0.004005972761660814
Epoch:  24  	Training Loss: 0.004192485939711332
Test Loss:  0.003166374284774065
Valid Loss:  0.0038757831789553165
Epoch:  25  	Training Loss: 0.004075797274708748
Test Loss:  0.003160004736855626
Valid Loss:  0.0038182693533599377
Epoch:  26  	Training Loss: 0.004034511744976044
Test Loss:  0.003157472237944603
Valid Loss:  0.0037961103953421116
Epoch:  27  	Training Loss: 0.004017623607069254
Test Loss:  0.003152571152895689
Valid Loss:  0.0037904141936451197
Epoch:  28  	Training Loss: 0.004010974429547787
Test Loss:  0.0031733757350593805
Valid Loss:  0.0037756431847810745
Epoch:  29  	Training Loss: 0.004007663112133741
Test Loss:  0.003154775593429804
Valid Loss:  0.0037762951105833054
Epoch:  30  	Training Loss: 0.004005121067166328
Test Loss:  0.0031642871908843517
Valid Loss:  0.0037671029567718506
Epoch:  31  	Training Loss: 0.004002876114100218
Test Loss:  0.003149519907310605
Valid Loss:  0.003767689224332571
Epoch:  32  	Training Loss: 0.004001129884272814
Test Loss:  0.0030893483199179173
Valid Loss:  0.0036798850633203983
Epoch:  33  	Training Loss: 0.0039209285750985146
Test Loss:  0.0029850692953914404
Valid Loss:  0.0035182139836251736
Epoch:  34  	Training Loss: 0.003782220184803009
Test Loss:  0.002889798255637288
Valid Loss:  0.003363171126693487
Epoch:  35  	Training Loss: 0.0036555142141878605
Test Loss:  0.002840727334842086
Valid Loss:  0.003284284146502614
Epoch:  36  	Training Loss: 0.0035852957516908646
Test Loss:  0.002809574594721198
Valid Loss:  0.0032628292683511972
Epoch:  37  	Training Loss: 0.0035523748956620693
Test Loss:  0.0027884384617209435
Valid Loss:  0.0032548604067415
Epoch:  38  	Training Loss: 0.0035388674587011337
Test Loss:  0.002772103063762188
Valid Loss:  0.0032509558368474245
Epoch:  39  	Training Loss: 0.0035310450475662947
Test Loss:  0.002760589588433504
Valid Loss:  0.0032478407956659794
Epoch:  40  	Training Loss: 0.0035246710758656263
Test Loss:  0.0027528912760317326
Valid Loss:  0.0032458542846143246
Epoch:  41  	Training Loss: 0.003519387450069189
Test Loss:  0.0027464875020086765
Valid Loss:  0.003244728548452258
Epoch:  42  	Training Loss: 0.003515089163556695
Test Loss:  0.0026589510962367058
Valid Loss:  0.003258985001593828
Epoch:  43  	Training Loss: 0.003500556806102395
Test Loss:  0.0027385219000279903
Valid Loss:  0.0032195383682847023
Epoch:  44  	Training Loss: 0.0034867930226027966
Test Loss:  0.002635797020047903
Valid Loss:  0.0032431455329060555
Epoch:  45  	Training Loss: 0.003476192243397236
Test Loss:  0.002737976610660553
Valid Loss:  0.0032006585970520973
Epoch:  46  	Training Loss: 0.0034666131250560284
Test Loss:  0.002616469282656908
Valid Loss:  0.0032324905041605234
Epoch:  47  	Training Loss: 0.0034580742940306664
Test Loss:  0.0027403035201132298
Valid Loss:  0.003183887340128422
Epoch:  48  	Training Loss: 0.0034503054339438677
Test Loss:  0.002597321756184101
Valid Loss:  0.0032247642520815134
Epoch:  49  	Training Loss: 0.003443682100623846
Test Loss:  0.0027475133538246155
Valid Loss:  0.0031691184267401695
Epoch:  50  	Training Loss: 0.0034380685538053513
Test Loss:  0.002578173531219363
Valid Loss:  0.0032206254545599222
Epoch:  51  	Training Loss: 0.0034332105424255133
Test Loss:  0.0027588126249611378
Valid Loss:  0.0031559811905026436
Epoch:  52  	Training Loss: 0.0034289967734366655
Test Loss:  0.00247694319114089
Valid Loss:  0.0029756934382021427
Epoch:  53  	Training Loss: 0.003237369004637003
Test Loss:  0.0024053629022091627
Valid Loss:  0.00278259115293622
Epoch:  54  	Training Loss: 0.0030803175177425146
Test Loss:  0.0022306875325739384
Valid Loss:  0.002633320866152644
Epoch:  55  	Training Loss: 0.0029298202134668827
Test Loss:  0.0021410398185253143
Valid Loss:  0.0024978674482554197
Epoch:  56  	Training Loss: 0.002804594347253442
Test Loss:  0.00204461719840765
Valid Loss:  0.0023859755601733923
Epoch:  57  	Training Loss: 0.002694623777642846
Test Loss:  0.0019552488811314106
Valid Loss:  0.0023149054031819105
Epoch:  58  	Training Loss: 0.0026233545504510403
Test Loss:  0.001891515450552106
Valid Loss:  0.0022173887118697166
Epoch:  59  	Training Loss: 0.002527871634811163
Test Loss:  0.0018139858730137348
Valid Loss:  0.0021360910031944513
Epoch:  60  	Training Loss: 0.002441905438899994
Test Loss:  0.0017522210255265236
Valid Loss:  0.0020678448490798473
Epoch:  61  	Training Loss: 0.0023688729852437973
Test Loss:  0.0016947364201769233
Valid Loss:  0.0020096125081181526
Epoch:  62  	Training Loss: 0.0023073661141097546
Test Loss:  0.0016378468135371804
Valid Loss:  0.0019287794129922986
Epoch:  63  	Training Loss: 0.0022207237780094147
Test Loss:  0.001599979354068637
Valid Loss:  0.0019156439229846
Epoch:  64  	Training Loss: 0.002197670517489314
Test Loss:  0.0015703331446275115
Valid Loss:  0.0019146029371768236
Epoch:  65  	Training Loss: 0.002185648772865534
Test Loss:  0.0016132115852087736
Valid Loss:  0.0018981283064931631
Epoch:  66  	Training Loss: 0.002179473638534546
Test Loss:  0.0015406794846057892
Valid Loss:  0.0019217967055737972
Epoch:  67  	Training Loss: 0.0021764945704489946
Test Loss:  0.0016377989668399096
Valid Loss:  0.0018927047494798899
Epoch:  68  	Training Loss: 0.0021748426370322704
Test Loss:  0.0015268947463482618
Valid Loss:  0.001944537041708827
Epoch:  69  	Training Loss: 0.0021831912454217672
Test Loss:  0.0016597254434600472
Valid Loss:  0.0018865115707740188
 14%|█▍        | 71/500 [01:00<08:24,  1.18s/it] 15%|█▍        | 73/500 [01:00<06:00,  1.18it/s] 15%|█▌        | 75/500 [01:00<04:19,  1.64it/s] 15%|█▌        | 77/500 [01:00<03:09,  2.24it/s] 16%|█▌        | 79/500 [01:00<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:07<08:15,  1.18s/it] 17%|█▋        | 83/500 [01:07<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:07<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:07<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:07<02:16,  3.00it/s] 18%|█▊        | 91/500 [01:13<07:57,  1.17s/it] 19%|█▊        | 93/500 [01:13<05:40,  1.19it/s] 19%|█▉        | 95/500 [01:14<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:14<02:58,  2.26it/s] 20%|█▉        | 99/500 [01:14<02:11,  3.04it/s] 20%|██        | 101/500 [01:20<07:46,  1.17s/it] 21%|██        | 103/500 [01:20<05:33,  1.19it/s] 21%|██        | 105/500 [01:20<03:59,  1.65it/s] 21%|██▏       | 107/500 [01:20<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:21<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:27<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:27<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:27<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:27<02:50,  2.24it/s] 24%|██▍       | 119/500 [01:27<02:06,  3.00it/s] 24%|██▍       | 121/500 [01:34<07:23,  1.17s/it] 25%|██▍       | 123/500 [01:34<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:34<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:34<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:34<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:40<07:09,  1.16s/it] 27%|██▋       | 133/500 [01:40<05:05,  1.20it/s] 27%|██▋       | 135/500 [01:41<03:39,  1.66it/s] 27%|██▋       | 137/500 [01:41<02:39,  2.27it/s]Epoch:  70  	Training Loss: 0.002169078914448619
Test Loss:  0.0015155787114053965
Valid Loss:  0.0019531729631125927
Epoch:  71  	Training Loss: 0.0021814480423927307
Test Loss:  0.0016790436347946525
Valid Loss:  0.0018859838601201773
Epoch:  72  	Training Loss: 0.002168356440961361
Test Loss:  0.001574092311784625
Valid Loss:  0.0018868802580982447
Epoch:  73  	Training Loss: 0.002150497632101178
Test Loss:  0.0015702316304668784
Valid Loss:  0.0018810636829584837
Epoch:  74  	Training Loss: 0.0021413450594991446
Test Loss:  0.00156647979747504
Valid Loss:  0.001876335241831839
Epoch:  75  	Training Loss: 0.002133364789187908
Test Loss:  0.0015632882714271545
Valid Loss:  0.0018724135588854551
Epoch:  76  	Training Loss: 0.002126461360603571
Test Loss:  0.0015606869710609317
Valid Loss:  0.0018691291334107518
Epoch:  77  	Training Loss: 0.0021203835494816303
Test Loss:  0.0015585781075060368
Valid Loss:  0.0018664104864001274
Epoch:  78  	Training Loss: 0.0021149858366698027
Test Loss:  0.0015567783266305923
Valid Loss:  0.0018641354981809855
Epoch:  79  	Training Loss: 0.0021101885940879583
Test Loss:  0.0015552749391645193
Valid Loss:  0.0018622284987941384
Epoch:  80  	Training Loss: 0.002105928026139736
Test Loss:  0.0015539005398750305
Valid Loss:  0.0018606223165988922
Epoch:  81  	Training Loss: 0.0021021023858338594
Test Loss:  0.0015528160147368908
Valid Loss:  0.0018592402338981628
Epoch:  82  	Training Loss: 0.0020986897870898247
Test Loss:  0.0015520142624154687
Valid Loss:  0.001857234165072441
Epoch:  83  	Training Loss: 0.0020945474971085787
Test Loss:  0.0015506022609770298
Valid Loss:  0.0018556786235421896
Epoch:  84  	Training Loss: 0.0020908648148179054
Test Loss:  0.001549385953694582
Valid Loss:  0.001854467554949224
Epoch:  85  	Training Loss: 0.002087546745315194
Test Loss:  0.0015482869930565357
Valid Loss:  0.0018534245900809765
Epoch:  86  	Training Loss: 0.002084592590108514
Test Loss:  0.001547304098494351
Valid Loss:  0.0018524894258007407
Epoch:  87  	Training Loss: 0.002081936690956354
Test Loss:  0.001546394545584917
Valid Loss:  0.0018516536802053452
Epoch:  88  	Training Loss: 0.0020795557647943497
Test Loss:  0.001545601524412632
Valid Loss:  0.0018508812645450234
Epoch:  89  	Training Loss: 0.0020773843862116337
Test Loss:  0.0015449282946065068
Valid Loss:  0.0018501507584005594
Epoch:  90  	Training Loss: 0.0020754397846758366
Test Loss:  0.001544369850307703
Valid Loss:  0.001849499181844294
Epoch:  91  	Training Loss: 0.0020736870355904102
Test Loss:  0.0015439054695889354
Valid Loss:  0.0018488517962396145
Epoch:  92  	Training Loss: 0.002072034403681755
Test Loss:  0.0015236808685585856
Valid Loss:  0.0018240422941744328
Epoch:  93  	Training Loss: 0.0020484584383666515
Test Loss:  0.0015028659254312515
Valid Loss:  0.0018046637997031212
Epoch:  94  	Training Loss: 0.0020283292979002
Test Loss:  0.0014880646485835314
Valid Loss:  0.0017899245722219348
Epoch:  95  	Training Loss: 0.002012919168919325
Test Loss:  0.0014746737433597445
Valid Loss:  0.0017776472959667444
Epoch:  96  	Training Loss: 0.002000406850129366
Test Loss:  0.0014648304786533117
Valid Loss:  0.001766229048371315
Epoch:  97  	Training Loss: 0.0019899571780115366
Test Loss:  0.0014559626579284668
Valid Loss:  0.0017572877695783973
Epoch:  98  	Training Loss: 0.001981125446036458
Test Loss:  0.0014498785603791475
Valid Loss:  0.0017501928377896547
Epoch:  99  	Training Loss: 0.0019733523949980736
Test Loss:  0.001444659079425037
Valid Loss:  0.0017438589129596949
Epoch:  100  	Training Loss: 0.0019664582796394825
Test Loss:  0.0014414016623049974
Valid Loss:  0.0017381623620167375
Epoch:  101  	Training Loss: 0.001961302012205124
Test Loss:  0.0014387601986527443
Valid Loss:  0.0017331955023109913
Epoch:  102  	Training Loss: 0.001957078231498599
Test Loss:  0.0014263867633417249
Valid Loss:  0.0016937509644776583
Epoch:  103  	Training Loss: 0.0019239954417571425
Test Loss:  0.0013639361131936312
Valid Loss:  0.0016888892278075218
Epoch:  104  	Training Loss: 0.0019062731880694628
Test Loss:  0.0013778109569102526
Valid Loss:  0.0016455594450235367
Epoch:  105  	Training Loss: 0.001875537447631359
Test Loss:  0.0013267716858536005
Valid Loss:  0.0016357230488210917
Epoch:  106  	Training Loss: 0.0018574572168290615
Test Loss:  0.0013355663977563381
Valid Loss:  0.0016097347252070904
Epoch:  107  	Training Loss: 0.0018395246006548405
Test Loss:  0.0013022057246416807
Valid Loss:  0.0016014908906072378
Epoch:  108  	Training Loss: 0.0018245340324938297
Test Loss:  0.001300751231610775
Valid Loss:  0.0015876389807090163
Epoch:  109  	Training Loss: 0.0018132580444216728
Test Loss:  0.0012879788409918547
Valid Loss:  0.0015799215761944652
Epoch:  110  	Training Loss: 0.0018032541265711188
Test Loss:  0.0012815213995054364
Valid Loss:  0.0015719322254881263
Epoch:  111  	Training Loss: 0.0017940814141184092
Test Loss:  0.0012717731297016144
Valid Loss:  0.0015656528994441032
Epoch:  112  	Training Loss: 0.0017858267528936267
Test Loss:  0.0012733677867799997
Valid Loss:  0.0015552020631730556
Epoch:  113  	Training Loss: 0.0017758499598130584
Test Loss:  0.0012676332844421268
Valid Loss:  0.0015500100562348962
Epoch:  114  	Training Loss: 0.0017677935538813472
Test Loss:  0.0012657026527449489
Valid Loss:  0.0015455023385584354
Epoch:  115  	Training Loss: 0.001760614919476211
Test Loss:  0.0012637798208743334
Valid Loss:  0.0015417598187923431
Epoch:  116  	Training Loss: 0.0017541287234053016
Test Loss:  0.0012616276508197188
Valid Loss:  0.0015393036883324385
Epoch:  117  	Training Loss: 0.0017485267017036676
Test Loss:  0.0012601797934621572
Valid Loss:  0.0015380765544250607
Epoch:  118  	Training Loss: 0.0017444435507059097
Test Loss:  0.0012582908384501934
Valid Loss:  0.0015374076319858432
Epoch:  119  	Training Loss: 0.001741070649586618
Test Loss:  0.0012582207564264536
Valid Loss:  0.0015363957500085235
Epoch:  120  	Training Loss: 0.0017380499048158526
Test Loss:  0.001257044030353427
Valid Loss:  0.0015359818935394287
Epoch:  121  	Training Loss: 0.0017354197334498167
Test Loss:  0.0012574070133268833
Valid Loss:  0.0015353368362411857
Epoch:  122  	Training Loss: 0.0017330057453364134
Test Loss:  0.0012246451806277037
Valid Loss:  0.0015216072788462043
Epoch:  123  	Training Loss: 0.001711759832687676
Test Loss:  0.0012539960443973541
Valid Loss:  0.001513844821602106
Epoch:  124  	Training Loss: 0.0017080266261473298
Test Loss:  0.0012350522447377443
Valid Loss:  0.001518699573352933
Epoch:  125  	Training Loss: 0.0017059431411325932
Test Loss:  0.0012489976361393929
Valid Loss:  0.0015165883814916015
Epoch:  126  	Training Loss: 0.0017045906279236078
Test Loss:  0.0012383332941681147
Valid Loss:  0.0015191612765192986
Epoch:  127  	Training Loss: 0.0017034844495356083
Test Loss:  0.0012487524654716253
Valid Loss:  0.001517618540674448
Epoch:  128  	Training Loss: 0.0017024492844939232
Test Loss:  0.0012421158608049154
Valid Loss:  0.0015198019100353122
Epoch:  129  	Training Loss: 0.0017016908386722207
Test Loss:  0.0012484816834330559
Valid Loss:  0.001519564539194107
Epoch:  130  	Training Loss: 0.0017011419404298067
Test Loss:  0.0012426214525476098
Valid Loss:  0.0015213442966341972
Epoch:  131  	Training Loss: 0.001700743567198515
Test Loss:  0.001249896828085184
Valid Loss:  0.0015205041272565722
Epoch:  132  	Training Loss: 0.0017002858221530914
Test Loss:  0.0012004774762317538
Valid Loss:  0.0014809591230005026
Epoch:  133  	Training Loss: 0.001661526272073388
Test Loss:  0.001193783711642027
Valid Loss:  0.0014463651459664106
Epoch:  134  	Training Loss: 0.0016358054708689451
Test Loss:  0.0011634749826043844
Valid Loss:  0.0014302441850304604
Epoch:  135  	Training Loss: 0.0016157783102244139
Test Loss:  0.00116502377204597
Valid Loss:  0.001407478703185916
Epoch:  136  	Training Loss: 0.0015980289317667484
Test Loss:  0.0011428777361288667
Valid Loss:  0.0013972234446555376
Epoch:  137  	Training Loss: 0.001585961552336812
Test Loss:  0.0011482128174975514
Valid Loss:  0.0013798944419249892
Epoch:  138  	Training Loss: 0.0015757556539028883
Test Loss:  0.0011288172099739313
Valid Loss:   28%|██▊       | 139/500 [01:41<01:58,  3.05it/s] 28%|██▊       | 141/500 [01:47<07:00,  1.17s/it] 29%|██▊       | 143/500 [01:47<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:47<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:48<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:48<01:55,  3.03it/s] 30%|███       | 151/500 [01:54<06:49,  1.17s/it] 31%|███       | 153/500 [01:54<04:51,  1.19it/s] 31%|███       | 155/500 [01:54<03:29,  1.64it/s] 31%|███▏      | 157/500 [01:54<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:54<01:52,  3.02it/s] 32%|███▏      | 161/500 [02:01<06:36,  1.17s/it] 33%|███▎      | 163/500 [02:01<04:43,  1.19it/s] 33%|███▎      | 165/500 [02:01<03:23,  1.65it/s] 33%|███▎      | 167/500 [02:01<02:28,  2.25it/s] 34%|███▍      | 169/500 [02:01<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:08<06:24,  1.17s/it] 35%|███▍      | 173/500 [02:08<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:08<03:17,  1.65it/s] 35%|███▌      | 177/500 [02:08<02:23,  2.25it/s] 36%|███▌      | 179/500 [02:08<01:45,  3.03it/s] 36%|███▌      | 181/500 [02:14<06:11,  1.16s/it] 37%|███▋      | 183/500 [02:14<04:25,  1.20it/s] 37%|███▋      | 185/500 [02:15<03:10,  1.65it/s] 37%|███▋      | 187/500 [02:15<02:18,  2.26it/s] 38%|███▊      | 189/500 [02:15<01:42,  3.04it/s] 38%|███▊      | 191/500 [02:21<06:02,  1.17s/it] 39%|███▊      | 193/500 [02:21<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:21<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:21<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:22<01:40,  3.01it/s] 40%|████      | 201/500 [02:28<05:47,  1.16s/it] 41%|████      | 203/500 [02:28<04:07,  1.20it/s] 41%|████      | 205/500 [02:28<02:57,  1.66it/s]0.0013727350160479546
Epoch:  139  	Training Loss: 0.001567896455526352
Test Loss:  0.0011370927095413208
Valid Loss:  0.0013587711146101356
Epoch:  140  	Training Loss: 0.0015597377205267549
Test Loss:  0.001121008419431746
Valid Loss:  0.001355221844278276
Epoch:  141  	Training Loss: 0.0015525107737630606
Test Loss:  0.0011300023179501295
Valid Loss:  0.0013458612374961376
Epoch:  142  	Training Loss: 0.0015452681109309196
Test Loss:  0.0010271839564666152
Valid Loss:  0.0013021845370531082
Epoch:  143  	Training Loss: 0.0014861978124827147
Test Loss:  0.0010803501354530454
Valid Loss:  0.0012626778334379196
Epoch:  144  	Training Loss: 0.0014593598898500204
Test Loss:  0.0009961501928046346
Valid Loss:  0.0012672224547713995
Epoch:  145  	Training Loss: 0.0014422391541302204
Test Loss:  0.0010610574390739202
Valid Loss:  0.0012383797438815236
Epoch:  146  	Training Loss: 0.001427171751856804
Test Loss:  0.0009775660000741482
Valid Loss:  0.0012467247433960438
Epoch:  147  	Training Loss: 0.0014132182113826275
Test Loss:  0.0010433228453621268
Valid Loss:  0.0012198908952996135
Epoch:  148  	Training Loss: 0.0014011873863637447
Test Loss:  0.0009590990957804024
Valid Loss:  0.001231698552146554
Epoch:  149  	Training Loss: 0.0013915459858253598
Test Loss:  0.0010342905297875404
Valid Loss:  0.0012032852973788977
Epoch:  150  	Training Loss: 0.0013807056238874793
Test Loss:  0.0009459598222747445
Valid Loss:  0.001216760603711009
Epoch:  151  	Training Loss: 0.0013703552540391684
Test Loss:  0.0010208530584350228
Valid Loss:  0.0011877059005200863
Epoch:  152  	Training Loss: 0.001359510119073093
Test Loss:  0.0009509085793979466
Valid Loss:  0.0011902699479833245
Epoch:  153  	Training Loss: 0.001346169039607048
Test Loss:  0.0009803327266126871
Valid Loss:  0.0011740138288587332
Epoch:  154  	Training Loss: 0.0013399997260421515
Test Loss:  0.0009456404950469732
Valid Loss:  0.0011782057117670774
Epoch:  155  	Training Loss: 0.0013355058617889881
Test Loss:  0.0009668385027907789
Valid Loss:  0.0011680558091029525
Epoch:  156  	Training Loss: 0.0013319700956344604
Test Loss:  0.0009428842458873987
Valid Loss:  0.0011712287086993456
Epoch:  157  	Training Loss: 0.0013288750778883696
Test Loss:  0.000959086581133306
Valid Loss:  0.001163416774943471
Epoch:  158  	Training Loss: 0.0013259992701932788
Test Loss:  0.0009409927879460156
Valid Loss:  0.001165517489425838
Epoch:  159  	Training Loss: 0.0013233120553195477
Test Loss:  0.0009532721014693379
Valid Loss:  0.0011595282703638077
Epoch:  160  	Training Loss: 0.0013208568561822176
Test Loss:  0.0009390211198478937
Valid Loss:  0.001161058316938579
Epoch:  161  	Training Loss: 0.001318658352829516
Test Loss:  0.0009494935511611402
Valid Loss:  0.001156040234491229
Epoch:  162  	Training Loss: 0.0013164973352104425
Test Loss:  0.0009431795915588737
Valid Loss:  0.0011568483896553516
Epoch:  163  	Training Loss: 0.0013151663588359952
Test Loss:  0.0009456545813009143
Valid Loss:  0.0011564220767468214
Epoch:  164  	Training Loss: 0.0013141471426934004
Test Loss:  0.0009441550355404615
Valid Loss:  0.0011566417524591088
Epoch:  165  	Training Loss: 0.0013132392195984721
Test Loss:  0.0009446914773434401
Valid Loss:  0.0011564568849280477
Epoch:  166  	Training Loss: 0.0013123862445354462
Test Loss:  0.0009442308801226318
Valid Loss:  0.001156362472102046
Epoch:  167  	Training Loss: 0.001311571104452014
Test Loss:  0.0009442096343263984
Valid Loss:  0.0011561254505068064
Epoch:  168  	Training Loss: 0.0013107848353683949
Test Loss:  0.0009440245339646935
Valid Loss:  0.0011558752739802003
Epoch:  169  	Training Loss: 0.001310023944824934
Test Loss:  0.0009439595160074532
Valid Loss:  0.001155595644377172
Epoch:  170  	Training Loss: 0.0013092911103740335
Test Loss:  0.0009438468841835856
Valid Loss:  0.0011553310323506594
Epoch:  171  	Training Loss: 0.0013085936661809683
Test Loss:  0.0009435879765078425
Valid Loss:  0.0011551559437066317
Epoch:  172  	Training Loss: 0.0013079482596367598
Test Loss:  0.0009368265746161342
Valid Loss:  0.0011458462104201317
Epoch:  173  	Training Loss: 0.001297248643822968
Test Loss:  0.0009350641630589962
Valid Loss:  0.0011425556149333715
Epoch:  174  	Training Loss: 0.0012928391806781292
Test Loss:  0.0009338190429843962
Valid Loss:  0.0011402341770008206
Epoch:  175  	Training Loss: 0.001289519714191556
Test Loss:  0.0009329137392342091
Valid Loss:  0.0011383213568478823
Epoch:  176  	Training Loss: 0.001286935992538929
Test Loss:  0.0009318001684732735
Valid Loss:  0.0011365518439561129
Epoch:  177  	Training Loss: 0.0012849022168666124
Test Loss:  0.000931132584810257
Valid Loss:  0.0011349127162247896
Epoch:  178  	Training Loss: 0.0012833040673285723
Test Loss:  0.0009301583049818873
Valid Loss:  0.0011334499577060342
Epoch:  179  	Training Loss: 0.0012819855473935604
Test Loss:  0.0009297926444560289
Valid Loss:  0.0011320445919409394
Epoch:  180  	Training Loss: 0.001280756900086999
Test Loss:  0.000929162953980267
Valid Loss:  0.0011307841632515192
Epoch:  181  	Training Loss: 0.0012796389637514949
Test Loss:  0.0009284626576118171
Valid Loss:  0.0011295182630419731
Epoch:  182  	Training Loss: 0.001278570620343089
Test Loss:  0.0009287241264246404
Valid Loss:  0.0011267510708421469
Epoch:  183  	Training Loss: 0.001276854076422751
Test Loss:  0.0009260106598958373
Valid Loss:  0.0011259150924161077
Epoch:  184  	Training Loss: 0.0012760648969560862
Test Loss:  0.0009248484275303781
Valid Loss:  0.001125045702792704
Epoch:  185  	Training Loss: 0.001275438815355301
Test Loss:  0.0009240371291525662
Valid Loss:  0.0011243012268096209
Epoch:  186  	Training Loss: 0.0012749286834150553
Test Loss:  0.0009234270546585321
Valid Loss:  0.0011237391736358404
Epoch:  187  	Training Loss: 0.0012744602281600237
Test Loss:  0.0009237953345291317
Valid Loss:  0.0011230690870434046
Epoch:  188  	Training Loss: 0.0012740676756948233
Test Loss:  0.000922340783290565
Valid Loss:  0.0011231726966798306
Epoch:  189  	Training Loss: 0.0012737682554870844
Test Loss:  0.0009228045819327235
Valid Loss:  0.0011228079674765468
Epoch:  190  	Training Loss: 0.0012735435739159584
Test Loss:  0.0009224462555721402
Valid Loss:  0.0011227369541302323
Epoch:  191  	Training Loss: 0.0012733846670016646
Test Loss:  0.0009222574299201369
Valid Loss:  0.0011226787464693189
Epoch:  192  	Training Loss: 0.0012732564937323332
Test Loss:  0.0009209264535456896
Valid Loss:  0.001118068816140294
Epoch:  193  	Training Loss: 0.0012697693891823292
Test Loss:  0.0009179913904517889
Valid Loss:  0.0011151856742799282
Epoch:  194  	Training Loss: 0.0012670214055106044
Test Loss:  0.0009153754799626768
Valid Loss:  0.0011130840284749866
Epoch:  195  	Training Loss: 0.0012649644631892443
Test Loss:  0.0009134998545050621
Valid Loss:  0.0011116620153188705
Epoch:  196  	Training Loss: 0.0012633642181754112
Test Loss:  0.0009119707392528653
Valid Loss:  0.0011106859892606735
Epoch:  197  	Training Loss: 0.0012620880734175444
Test Loss:  0.0009104483760893345
Valid Loss:  0.0011101376730948687
Epoch:  198  	Training Loss: 0.0012611564015969634
Test Loss:  0.0009097089059650898
Valid Loss:  0.0011095567606389523
Epoch:  199  	Training Loss: 0.0012602971401065588
Test Loss:  0.0009091949323192239
Valid Loss:  0.0011089470935985446
Epoch:  200  	Training Loss: 0.0012594480067491531
Test Loss:  0.0009087250800803304
Valid Loss:  0.0011083497665822506
Epoch:  201  	Training Loss: 0.001258606556802988
Test Loss:  0.0009084180928766727
Valid Loss:  0.0011077683884650469
Epoch:  202  	Training Loss: 0.0012577875750139356
Test Loss:  0.0008781052310951054
Valid Loss:  0.0010850648395717144
Epoch:  203  	Training Loss: 0.0012338926317170262
Test Loss:  0.0008654812118038535
Valid Loss:  0.0010725457686930895
Epoch:  204  	Training Loss: 0.0012188423424959183
Test Loss:  0.0008606606861576438
Valid Loss:  0.00106486224103719
Epoch:  205  	Training Loss: 0.001210198039188981
Test Loss:  0.0008576501859351993
Valid Loss:  0.0010594194754958153
Epoch:  206  	Training Loss: 0.0012041640002280474
Test Loss:  0.0008554154774174094
Valid Loss:  0.0010553665924817324
 41%|████▏     | 207/500 [02:28<02:09,  2.25it/s] 42%|████▏     | 209/500 [02:28<01:36,  3.02it/s] 42%|████▏     | 211/500 [02:35<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:35<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:35<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:35<02:06,  2.23it/s] 44%|████▍     | 219/500 [02:35<01:33,  2.99it/s] 44%|████▍     | 221/500 [02:42<05:31,  1.19s/it] 45%|████▍     | 223/500 [02:42<03:56,  1.17it/s] 45%|████▌     | 225/500 [02:42<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:42<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:42<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:48<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:49<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:49<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:49<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:49<01:27,  2.99it/s] 48%|████▊     | 241/500 [02:55<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:55<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:55<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:56<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:56<01:23,  3.00it/s] 50%|█████     | 251/500 [03:02<04:48,  1.16s/it] 51%|█████     | 253/500 [03:02<03:25,  1.20it/s] 51%|█████     | 255/500 [03:02<02:27,  1.66it/s] 51%|█████▏    | 257/500 [03:02<01:47,  2.26it/s] 52%|█████▏    | 259/500 [03:02<01:19,  3.03it/s] 52%|█████▏    | 261/500 [03:09<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:09<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:09<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:09<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:09<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:16<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:16<03:11,  1.18it/s]Epoch:  207  	Training Loss: 0.0011993704829365015
Test Loss:  0.0008537991670891643
Valid Loss:  0.001052135368809104
Epoch:  208  	Training Loss: 0.0011956305243074894
Test Loss:  0.0008522145799361169
Valid Loss:  0.0010493213776499033
Epoch:  209  	Training Loss: 0.001192558789625764
Test Loss:  0.000851298333145678
Valid Loss:  0.001046857563778758
Epoch:  210  	Training Loss: 0.0011900367680937052
Test Loss:  0.000850141397677362
Valid Loss:  0.0010445653460919857
Epoch:  211  	Training Loss: 0.001187773304991424
Test Loss:  0.0008489459869451821
Valid Loss:  0.0010425501968711615
Epoch:  212  	Training Loss: 0.0011857838835567236
Test Loss:  0.0008376811747439206
Valid Loss:  0.0010345234768465161
Epoch:  213  	Training Loss: 0.0011765796225517988
Test Loss:  0.0008335763122886419
Valid Loss:  0.0010277490364387631
Epoch:  214  	Training Loss: 0.0011705245124176145
Test Loss:  0.000829347176477313
Valid Loss:  0.0010226164013147354
Epoch:  215  	Training Loss: 0.0011657638242468238
Test Loss:  0.0008264906937256455
Valid Loss:  0.0010182729456573725
Epoch:  216  	Training Loss: 0.0011617871932685375
Test Loss:  0.0008246375946328044
Valid Loss:  0.001014653011225164
Epoch:  217  	Training Loss: 0.0011585999745875597
Test Loss:  0.00082240323536098
Valid Loss:  0.001011490821838379
Epoch:  218  	Training Loss: 0.0011556320823729038
Test Loss:  0.0008208284270949662
Valid Loss:  0.0010085671674460173
Epoch:  219  	Training Loss: 0.001153104705736041
Test Loss:  0.0008191898232325912
Valid Loss:  0.0010059371124953032
Epoch:  220  	Training Loss: 0.0011508390307426453
Test Loss:  0.0008175199036486447
Valid Loss:  0.0010034509468823671
Epoch:  221  	Training Loss: 0.0011486391304060817
Test Loss:  0.0008158268174156547
Valid Loss:  0.0010010837577283382
Epoch:  222  	Training Loss: 0.0011465270072221756
Test Loss:  0.0008136332617141306
Valid Loss:  0.0009980150498449802
Epoch:  223  	Training Loss: 0.0011437964858487248
Test Loss:  0.0008107222383841872
Valid Loss:  0.0009957043221220374
Epoch:  224  	Training Loss: 0.0011414831969887018
Test Loss:  0.0008090545306913555
Valid Loss:  0.0009934515692293644
Epoch:  225  	Training Loss: 0.001139332540333271
Test Loss:  0.0008068726165220141
Valid Loss:  0.0009916762355715036
Epoch:  226  	Training Loss: 0.0011374398600310087
Test Loss:  0.0008055595681071281
Valid Loss:  0.0009898392017930746
Epoch:  227  	Training Loss: 0.0011355794267728925
Test Loss:  0.0008038488449528813
Valid Loss:  0.000988186802715063
Epoch:  228  	Training Loss: 0.0011338137555867434
Test Loss:  0.0008027461590245366
Valid Loss:  0.0009865544270724058
Epoch:  229  	Training Loss: 0.0011321625206619501
Test Loss:  0.0008016056381165981
Valid Loss:  0.0009850467322394252
Epoch:  230  	Training Loss: 0.0011306857923045754
Test Loss:  0.0008004525443539023
Valid Loss:  0.0009836333338171244
Epoch:  231  	Training Loss: 0.0011292793788015842
Test Loss:  0.0007993214530870318
Valid Loss:  0.0009822824504226446
Epoch:  232  	Training Loss: 0.0011279403697699308
Test Loss:  0.0008000994566828012
Valid Loss:  0.0009770597098395228
Epoch:  233  	Training Loss: 0.0011235310230404139
Test Loss:  0.0007973517058417201
Valid Loss:  0.00097401172388345
Epoch:  234  	Training Loss: 0.0011204644106328487
Test Loss:  0.0007950714789330959
Valid Loss:  0.0009718121727928519
Epoch:  235  	Training Loss: 0.001117979409173131
Test Loss:  0.0007929832790978253
Valid Loss:  0.0009705119300633669
Epoch:  236  	Training Loss: 0.0011161987204104662
Test Loss:  0.0007913046283647418
Valid Loss:  0.0009697282803244889
Epoch:  237  	Training Loss: 0.0011149572674185038
Test Loss:  0.0007904538651928306
Valid Loss:  0.0009690301958471537
Epoch:  238  	Training Loss: 0.0011138683184981346
Test Loss:  0.0007898584590293467
Valid Loss:  0.0009683267562650144
Epoch:  239  	Training Loss: 0.0011128387413918972
Test Loss:  0.0007896575843915343
Valid Loss:  0.0009676914196461439
Epoch:  240  	Training Loss: 0.0011118316324427724
Test Loss:  0.000789437850471586
Valid Loss:  0.000967229250818491
Epoch:  241  	Training Loss: 0.0011108883190900087
Test Loss:  0.0007892588619142771
Valid Loss:  0.0009669075370766222
Epoch:  242  	Training Loss: 0.0011100168339908123
Test Loss:  0.0007787791546434164
Valid Loss:  0.0009484122274443507
Epoch:  243  	Training Loss: 0.0010919703636318445
Test Loss:  0.000762167910579592
Valid Loss:  0.0009411151986569166
Epoch:  244  	Training Loss: 0.0010834939312189817
Test Loss:  0.000759883550927043
Valid Loss:  0.000935705320443958
Epoch:  245  	Training Loss: 0.0010772761888802052
Test Loss:  0.0007550317095592618
Valid Loss:  0.0009318215306848288
Epoch:  246  	Training Loss: 0.0010718608973547816
Test Loss:  0.0007519535138271749
Valid Loss:  0.0009286089334636927
Epoch:  247  	Training Loss: 0.00106708612293005
Test Loss:  0.0007483722292818129
Valid Loss:  0.0009262653184123337
Epoch:  248  	Training Loss: 0.0010629098396748304
Test Loss:  0.0007457075407728553
Valid Loss:  0.0009242179221473634
Epoch:  249  	Training Loss: 0.0010591051541268826
Test Loss:  0.0007436324376612902
Valid Loss:  0.0009220745414495468
Epoch:  250  	Training Loss: 0.0010554299224168062
Test Loss:  0.000741712749004364
Valid Loss:  0.0009198760380968451
Epoch:  251  	Training Loss: 0.0010518357157707214
Test Loss:  0.0007399035384878516
Valid Loss:  0.00091770343715325
Epoch:  252  	Training Loss: 0.001048294478096068
Test Loss:  0.0007323732716031373
Valid Loss:  0.0009149144170805812
Epoch:  253  	Training Loss: 0.0010436337906867266
Test Loss:  0.0007293670205399394
Valid Loss:  0.0009120537433773279
Epoch:  254  	Training Loss: 0.001039900816977024
Test Loss:  0.0007265146705321968
Valid Loss:  0.000909658963792026
Epoch:  255  	Training Loss: 0.0010367950890213251
Test Loss:  0.0007240859558805823
Valid Loss:  0.0009077468421310186
Epoch:  256  	Training Loss: 0.0010341443121433258
Test Loss:  0.0007206929149106145
Valid Loss:  0.0009058041032403708
Epoch:  257  	Training Loss: 0.001031704479828477
Test Loss:  0.0007199714309535921
Valid Loss:  0.0009040487930178642
Epoch:  258  	Training Loss: 0.0010294067906215787
Test Loss:  0.0007170297903940082
Valid Loss:  0.0009026124607771635
Epoch:  259  	Training Loss: 0.0010273945517838001
Test Loss:  0.0007167993462644517
Valid Loss:  0.0009013070957735181
Epoch:  260  	Training Loss: 0.0010255337692797184
Test Loss:  0.000714306952431798
Valid Loss:  0.0009000893915072083
Epoch:  261  	Training Loss: 0.0010238022077828646
Test Loss:  0.0007144395494833589
Valid Loss:  0.0008990659844130278
Epoch:  262  	Training Loss: 0.0010221605189144611
Test Loss:  0.0007150660385377705
Valid Loss:  0.0008968539768829942
Epoch:  263  	Training Loss: 0.0010192201007157564
Test Loss:  0.0007123050163500011
Valid Loss:  0.000895340577699244
Epoch:  264  	Training Loss: 0.0010165649000555277
Test Loss:  0.0007109527359716594
Valid Loss:  0.0008936799131333828
Epoch:  265  	Training Loss: 0.0010140647646039724
Test Loss:  0.0007092958549037576
Valid Loss:  0.00089215615298599
Epoch:  266  	Training Loss: 0.0010117014171555638
Test Loss:  0.0007078038761392236
Valid Loss:  0.0008906400762498379
Epoch:  267  	Training Loss: 0.0010094443568959832
Test Loss:  0.0007067612023092806
Valid Loss:  0.0008890917524695396
Epoch:  268  	Training Loss: 0.001007224665954709
Test Loss:  0.0007053149165585637
Valid Loss:  0.0008876738720573485
Epoch:  269  	Training Loss: 0.0010050720302388072
Test Loss:  0.0007042328361421824
Valid Loss:  0.0008861874230206013
Epoch:  270  	Training Loss: 0.001002998324111104
Test Loss:  0.0007026775274425745
Valid Loss:  0.0008848131401464343
Epoch:  271  	Training Loss: 0.0010010229889303446
Test Loss:  0.0007014655857346952
Valid Loss:  0.0008833829779177904
Epoch:  272  	Training Loss: 0.000999094103462994
Test Loss:  0.0006990089314058423
Valid Loss:  0.0008832017192617059
Epoch:  273  	Training Loss: 0.0009983552154153585
Test Loss:  0.0006984192878007889
Valid Loss:  0.0008826731354929507
Epoch:  274  	Training Loss: 0.0009976653382182121
Test Loss:  0.0006980462349019945
Valid Loss:  0.0008821430383250117
Epoch:  275  	Training Loss: 0.0009969875682145357
Test Loss:   55%|█████▌    | 275/500 [03:16<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:16<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:16<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:22<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:22<03:01,  1.20it/s] 57%|█████▋    | 285/500 [03:23<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:23<01:34,  2.26it/s] 58%|█████▊    | 289/500 [03:23<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:29<04:09,  1.19s/it] 59%|█████▊    | 293/500 [03:29<02:57,  1.17it/s] 59%|█████▉    | 295/500 [03:30<02:08,  1.60it/s] 59%|█████▉    | 297/500 [03:30<01:32,  2.19it/s] 60%|█████▉    | 299/500 [03:30<01:08,  2.92it/s] 60%|██████    | 301/500 [03:36<03:55,  1.18s/it] 61%|██████    | 303/500 [03:36<02:47,  1.18it/s] 61%|██████    | 305/500 [03:36<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:37<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:37<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:43<03:42,  1.18s/it] 63%|██████▎   | 313/500 [03:43<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:43<01:53,  1.64it/s] 63%|██████▎   | 317/500 [03:43<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:44<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:50<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:50<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:50<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:50<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:50<00:56,  3.00it/s] 66%|██████▌   | 331/500 [03:57<03:18,  1.17s/it] 67%|██████▋   | 333/500 [03:57<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:57<01:40,  1.64it/s] 67%|██████▋   | 337/500 [03:57<01:12,  2.24it/s] 68%|██████▊   | 339/500 [03:57<00:53,  3.01it/s] 68%|██████▊   | 341/500 [04:03<03:06,  1.17s/it]0.0006977000739425421
Valid Loss:  0.0008816185873001814
Epoch:  276  	Training Loss: 0.0009963327320292592
Test Loss:  0.000697355717420578
Valid Loss:  0.0008811006555333734
Epoch:  277  	Training Loss: 0.0009956908179447055
Test Loss:  0.0006970107788220048
Valid Loss:  0.0008805961115285754
Epoch:  278  	Training Loss: 0.0009950699750334024
Test Loss:  0.0006966685177758336
Valid Loss:  0.0008800920331850648
Epoch:  279  	Training Loss: 0.0009944585617631674
Test Loss:  0.0006963271298445761
Valid Loss:  0.000879596802406013
Epoch:  280  	Training Loss: 0.0009938642615452409
Test Loss:  0.0006959770107641816
Valid Loss:  0.0008791006985120475
Epoch:  281  	Training Loss: 0.0009932797402143478
Test Loss:  0.0006956345750950277
Valid Loss:  0.0008786139078438282
Epoch:  282  	Training Loss: 0.000992706511169672
Test Loss:  0.0006967908120714128
Valid Loss:  0.0008771773427724838
Epoch:  283  	Training Loss: 0.0009915512055158615
Test Loss:  0.0006947873043827713
Valid Loss:  0.0008766211103647947
Epoch:  284  	Training Loss: 0.0009905487531796098
Test Loss:  0.0006944494671188295
Valid Loss:  0.0008758400217629969
Epoch:  285  	Training Loss: 0.0009896436240524054
Test Loss:  0.0006936265854164958
Valid Loss:  0.0008753652800805867
Epoch:  286  	Training Loss: 0.0009888331405818462
Test Loss:  0.0006930642994120717
Valid Loss:  0.0008749434491619468
Epoch:  287  	Training Loss: 0.0009881091536954045
Test Loss:  0.0006926084752194583
Valid Loss:  0.0008746054954826832
Epoch:  288  	Training Loss: 0.0009874526876956224
Test Loss:  0.0006920420564711094
Valid Loss:  0.0008743926300667226
Epoch:  289  	Training Loss: 0.0009868904016911983
Test Loss:  0.0006919294828549027
Valid Loss:  0.000874095712788403
Epoch:  290  	Training Loss: 0.0009863425511866808
Test Loss:  0.00069163937587291
Valid Loss:  0.0008738649194128811
Epoch:  291  	Training Loss: 0.0009858127450570464
Test Loss:  0.0006915241247043014
Valid Loss:  0.0008736010640859604
Epoch:  292  	Training Loss: 0.0009852871298789978
Test Loss:  0.0006882617017254233
Valid Loss:  0.0008708682144060731
Epoch:  293  	Training Loss: 0.0009821788407862186
Test Loss:  0.0006869893986731768
Valid Loss:  0.0008687689551152289
Epoch:  294  	Training Loss: 0.0009798661340028048
Test Loss:  0.0006859826971776783
Valid Loss:  0.0008674000855535269
Epoch:  295  	Training Loss: 0.0009782244451344013
Test Loss:  0.0006853202939964831
Valid Loss:  0.000866240356117487
Epoch:  296  	Training Loss: 0.000976782408542931
Test Loss:  0.0006847854238003492
Valid Loss:  0.0008651821408420801
Epoch:  297  	Training Loss: 0.0009754895581863821
Test Loss:  0.0006844338495284319
Valid Loss:  0.0008642385946586728
Epoch:  298  	Training Loss: 0.0009744098642840981
Test Loss:  0.0006842723814770579
Valid Loss:  0.0008635014528408647
Epoch:  299  	Training Loss: 0.0009734797058627009
Test Loss:  0.0006841016584075987
Valid Loss:  0.0008628614596091211
Epoch:  300  	Training Loss: 0.0009726469870656729
Test Loss:  0.0006838715635240078
Valid Loss:  0.0008623076137155294
Epoch:  301  	Training Loss: 0.0009718951187096536
Test Loss:  0.0006836935062892735
Valid Loss:  0.0008617843268439174
Epoch:  302  	Training Loss: 0.0009712303290143609
Test Loss:  0.0006793608190491796
Valid Loss:  0.000858725281432271
Epoch:  303  	Training Loss: 0.0009676582994870842
Test Loss:  0.000677750853355974
Valid Loss:  0.0008560011629015207
Epoch:  304  	Training Loss: 0.0009648107225075364
Test Loss:  0.0006751265027560294
Valid Loss:  0.000853824894875288
Epoch:  305  	Training Loss: 0.00096219836268574
Test Loss:  0.0006737918010912836
Valid Loss:  0.0008518886752426624
Epoch:  306  	Training Loss: 0.0009599222103133798
Test Loss:  0.0006722387042827904
Valid Loss:  0.0008503755088895559
Epoch:  307  	Training Loss: 0.0009579462930560112
Test Loss:  0.0006713215261697769
Valid Loss:  0.0008489512838423252
Epoch:  308  	Training Loss: 0.0009562212508171797
Test Loss:  0.0006701217498630285
Valid Loss:  0.0008476321236230433
Epoch:  309  	Training Loss: 0.0009545424254611135
Test Loss:  0.0006693039322271943
Valid Loss:  0.0008463888079859316
Epoch:  310  	Training Loss: 0.0009528941591270268
Test Loss:  0.0006685137050226331
Valid Loss:  0.0008452231995761395
Epoch:  311  	Training Loss: 0.0009513804106973112
Test Loss:  0.0006678130012005568
Valid Loss:  0.0008441178360953927
Epoch:  312  	Training Loss: 0.0009500497253611684
Test Loss:  0.0006634427700191736
Valid Loss:  0.0008404616382904351
Epoch:  313  	Training Loss: 0.0009460915462113917
Test Loss:  0.000661799218505621
Valid Loss:  0.0008366766851395369
Epoch:  314  	Training Loss: 0.0009426790056750178
Test Loss:  0.0006586703239008784
Valid Loss:  0.0008336068713106215
Epoch:  315  	Training Loss: 0.0009396065725013614
Test Loss:  0.0006563132046721876
Valid Loss:  0.0008307349635288119
Epoch:  316  	Training Loss: 0.0009367848979309201
Test Loss:  0.0006538331508636475
Valid Loss:  0.0008281729533337057
Epoch:  317  	Training Loss: 0.0009341227123513818
Test Loss:  0.0006515658460557461
Valid Loss:  0.0008257483714260161
Epoch:  318  	Training Loss: 0.0009316372452303767
Test Loss:  0.0006494332919828594
Valid Loss:  0.0008233753032982349
Epoch:  319  	Training Loss: 0.0009292491595260799
Test Loss:  0.0006474591791629791
Valid Loss:  0.0008210348896682262
Epoch:  320  	Training Loss: 0.0009269349975511432
Test Loss:  0.0006457409472204745
Valid Loss:  0.000818774220533669
Epoch:  321  	Training Loss: 0.0009247948182746768
Test Loss:  0.0006432686932384968
Valid Loss:  0.000817025313153863
Epoch:  322  	Training Loss: 0.0009229304851032794
Test Loss:  0.0006432574591599405
Valid Loss:  0.000813495134934783
Epoch:  323  	Training Loss: 0.0009205691749230027
Test Loss:  0.0006411689682863653
Valid Loss:  0.0008115607779473066
Epoch:  324  	Training Loss: 0.0009191930876113474
Test Loss:  0.0006398371187970042
Valid Loss:  0.0008101023267954588
Epoch:  325  	Training Loss: 0.0009181116474792361
Test Loss:  0.0006389000918716192
Valid Loss:  0.0008089016773737967
Epoch:  326  	Training Loss: 0.0009171739220619202
Test Loss:  0.0006382633000612259
Valid Loss:  0.0008079081308096647
Epoch:  327  	Training Loss: 0.000916328513994813
Test Loss:  0.0006377663230523467
Valid Loss:  0.0008071343181654811
Epoch:  328  	Training Loss: 0.0009155499283224344
Test Loss:  0.0006374111399054527
Valid Loss:  0.0008065564325079322
Epoch:  329  	Training Loss: 0.0009148330427706242
Test Loss:  0.0006371285417117178
Valid Loss:  0.0008061269763857126
Epoch:  330  	Training Loss: 0.0009141737828031182
Test Loss:  0.000636706012301147
Valid Loss:  0.0008058939129114151
Epoch:  331  	Training Loss: 0.0009136032895185053
Test Loss:  0.0006365099106915295
Valid Loss:  0.0008056898950599134
Epoch:  332  	Training Loss: 0.0009130510734394193
Test Loss:  0.0006324735004454851
Valid Loss:  0.0008046722505241632
Epoch:  333  	Training Loss: 0.0009113551350310445
Test Loss:  0.0006310891476459801
Valid Loss:  0.0008036004728637636
Epoch:  334  	Training Loss: 0.0009099160670302808
Test Loss:  0.0006302336696535349
Valid Loss:  0.0008026733412407339
Epoch:  335  	Training Loss: 0.0009086368954740465
Test Loss:  0.0006296725478023291
Valid Loss:  0.000801851274445653
Epoch:  336  	Training Loss: 0.0009075346169993281
Test Loss:  0.0006290283636189997
Valid Loss:  0.0008010572637431324
Epoch:  337  	Training Loss: 0.0009064605692401528
Test Loss:  0.0006283886032178998
Valid Loss:  0.0008002629037946463
Epoch:  338  	Training Loss: 0.0009053924586623907
Test Loss:  0.0006278268992900848
Valid Loss:  0.0007995222695171833
Epoch:  339  	Training Loss: 0.0009043425088748336
Test Loss:  0.0006273632170632482
Valid Loss:  0.0007988513680174947
Epoch:  340  	Training Loss: 0.0009033805690705776
Test Loss:  0.0006269965087994933
Valid Loss:  0.0007982485694810748
Epoch:  341  	Training Loss: 0.0009025651379488409
Test Loss:  0.0006266179261729121
Valid Loss:  0.0007977220229804516
Epoch:  342  	Training Loss: 0.0009018164710141718
Test Loss:  0.0006187765393406153
Valid Loss:  0.0007904724916443229
Epoch:  343  	Training Loss: 0.0008950488991104066
Test Loss:  0.0006141025805845857
Valid Loss:   69%|██████▊   | 343/500 [04:04<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:04<01:34,  1.65it/s] 69%|██████▉   | 347/500 [04:04<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:04<00:50,  3.02it/s] 70%|███████   | 351/500 [04:10<02:55,  1.18s/it] 71%|███████   | 353/500 [04:10<02:04,  1.18it/s] 71%|███████   | 355/500 [04:11<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:11<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:11<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:17<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:17<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:17<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:18<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:18<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:24<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:24<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:24<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:24<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:24<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:31<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:31<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:31<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:31<00:50,  2.24it/s] 78%|███████▊  | 389/500 [04:31<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:38<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:38<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:38<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:38<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:38<00:33,  3.02it/s] 80%|████████  | 401/500 [04:44<01:55,  1.17s/it] 81%|████████  | 403/500 [04:44<01:21,  1.19it/s] 81%|████████  | 405/500 [04:45<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:45<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:45<00:30,  3.03it/s] 82%|████████▏ | 411/500 [04:51<01:44,  1.17s/it]0.0007845778600312769
Epoch:  344  	Training Loss: 0.0008895645150914788
Test Loss:  0.0006098111625760794
Valid Loss:  0.0007793048280291259
Epoch:  345  	Training Loss: 0.000884687528014183
Test Loss:  0.0006066779606044292
Valid Loss:  0.0007751440862193704
Epoch:  346  	Training Loss: 0.0008808100828900933
Test Loss:  0.0006037105340510607
Valid Loss:  0.0007714790408499539
Epoch:  347  	Training Loss: 0.0008774136658757925
Test Loss:  0.0006014492246322334
Valid Loss:  0.0007682667928747833
Epoch:  348  	Training Loss: 0.0008744001388549805
Test Loss:  0.0005991811631247401
Valid Loss:  0.0007652275962755084
Epoch:  349  	Training Loss: 0.0008715974981896579
Test Loss:  0.0005973558872938156
Valid Loss:  0.0007624358986504376
Epoch:  350  	Training Loss: 0.0008689675014466047
Test Loss:  0.0005957124521955848
Valid Loss:  0.0007599745877087116
Epoch:  351  	Training Loss: 0.0008665883797220886
Test Loss:  0.0005941715789958835
Valid Loss:  0.0007577802170999348
Epoch:  352  	Training Loss: 0.0008645359193906188
Test Loss:  0.0005939103430137038
Valid Loss:  0.0007548258872702718
Epoch:  353  	Training Loss: 0.000861720705870539
Test Loss:  0.000591360148973763
Valid Loss:  0.000752420979551971
Epoch:  354  	Training Loss: 0.0008590802899561822
Test Loss:  0.0005892690387554467
Valid Loss:  0.0007500264327973127
Epoch:  355  	Training Loss: 0.0008564736926928163
Test Loss:  0.0005871693138033152
Valid Loss:  0.000747733167372644
Epoch:  356  	Training Loss: 0.000853943987749517
Test Loss:  0.0005852443282492459
Valid Loss:  0.0007454954320564866
Epoch:  357  	Training Loss: 0.0008514603832736611
Test Loss:  0.0005833340110257268
Valid Loss:  0.0007433124119415879
Epoch:  358  	Training Loss: 0.0008490087930113077
Test Loss:  0.0005814904579892755
Valid Loss:  0.0007412061095237732
Epoch:  359  	Training Loss: 0.0008466148283332586
Test Loss:  0.0005796902696602046
Valid Loss:  0.000739178154617548
Epoch:  360  	Training Loss: 0.0008442517137154937
Test Loss:  0.0005779378116130829
Valid Loss:  0.0007371720857918262
Epoch:  361  	Training Loss: 0.000841904547996819
Test Loss:  0.000576217076741159
Valid Loss:  0.0007351856329478323
Epoch:  362  	Training Loss: 0.0008395718759857118
Test Loss:  0.000567749491892755
Valid Loss:  0.0007255527307279408
Epoch:  363  	Training Loss: 0.000829923665151
Test Loss:  0.000562206027098
Valid Loss:  0.0007203777204267681
Epoch:  364  	Training Loss: 0.0008250013925135136
Test Loss:  0.000558543368242681
Valid Loss:  0.000716794456820935
Epoch:  365  	Training Loss: 0.0008214801782742143
Test Loss:  0.0005562705337069929
Valid Loss:  0.0007140202214941382
Epoch:  366  	Training Loss: 0.000818653788883239
Test Loss:  0.0005543110892176628
Valid Loss:  0.0007120377849787474
Epoch:  367  	Training Loss: 0.0008164577302522957
Test Loss:  0.0005526126478798687
Valid Loss:  0.0007104567484930158
Epoch:  368  	Training Loss: 0.0008146362961269915
Test Loss:  0.0005516986129805446
Valid Loss:  0.0007088995771482587
Epoch:  369  	Training Loss: 0.0008129600319080055
Test Loss:  0.000550952972844243
Valid Loss:  0.00070740602677688
Epoch:  370  	Training Loss: 0.0008113197982311249
Test Loss:  0.0005502229323610663
Valid Loss:  0.0007060604984872043
Epoch:  371  	Training Loss: 0.0008098190883174539
Test Loss:  0.0005494250799529254
Valid Loss:  0.0007048374973237514
Epoch:  372  	Training Loss: 0.0008084194851107895
Test Loss:  0.000545095419511199
Valid Loss:  0.0007031933637335896
Epoch:  373  	Training Loss: 0.0008063833229243755
Test Loss:  0.000543877249583602
Valid Loss:  0.0007011417183093727
Epoch:  374  	Training Loss: 0.0008045657305046916
Test Loss:  0.0005421699024736881
Valid Loss:  0.0006993761053308845
Epoch:  375  	Training Loss: 0.0008028254378587008
Test Loss:  0.0005405408446677029
Valid Loss:  0.0006976987351663411
Epoch:  376  	Training Loss: 0.0008011133759282529
Test Loss:  0.0005391333252191544
Valid Loss:  0.0006960316095501184
Epoch:  377  	Training Loss: 0.0007994236657395959
Test Loss:  0.0005377370398491621
Valid Loss:  0.0006943835178390145
Epoch:  378  	Training Loss: 0.0007977536879479885
Test Loss:  0.0005364843527786434
Valid Loss:  0.0006927697104401886
Epoch:  379  	Training Loss: 0.0007961058290675282
Test Loss:  0.000535383471287787
Valid Loss:  0.0006912261596880853
Epoch:  380  	Training Loss: 0.0007945492980070412
Test Loss:  0.0005343022057786584
Valid Loss:  0.0006898052524775267
Epoch:  381  	Training Loss: 0.0007931503932923079
Test Loss:  0.0005333175649866462
Valid Loss:  0.0006885802140459418
Epoch:  382  	Training Loss: 0.0007918933406472206
Test Loss:  0.0005333469016477466
Valid Loss:  0.0006800192059017718
Epoch:  383  	Training Loss: 0.0007832612609490752
Test Loss:  0.0005243315827101469
Valid Loss:  0.0006787213496863842
Epoch:  384  	Training Loss: 0.0007803195621818304
Test Loss:  0.000526066985912621
Valid Loss:  0.0006771908956579864
Epoch:  385  	Training Loss: 0.0007781627355143428
Test Loss:  0.0005233398405835032
Valid Loss:  0.0006769123720005155
Epoch:  386  	Training Loss: 0.0007765697664581239
Test Loss:  0.0005240007885731757
Valid Loss:  0.0006763782585039735
Epoch:  387  	Training Loss: 0.0007751432713121176
Test Loss:  0.0005230811075307429
Valid Loss:  0.000676122959703207
Epoch:  388  	Training Loss: 0.0007738515269011259
Test Loss:  0.0005230109672993422
Valid Loss:  0.0006757880328223109
Epoch:  389  	Training Loss: 0.0007726860349066556
Test Loss:  0.0005223171901889145
Valid Loss:  0.0006755595677532256
Epoch:  390  	Training Loss: 0.0007716127438470721
Test Loss:  0.0005224118358455598
Valid Loss:  0.0006751767359673977
Epoch:  391  	Training Loss: 0.000770589685998857
Test Loss:  0.00052195496391505
Valid Loss:  0.0006748136947862804
Epoch:  392  	Training Loss: 0.0007696009706705809
Test Loss:  0.0005082163843326271
Valid Loss:  0.0006694311741739511
Epoch:  393  	Training Loss: 0.0007630361360497773
Test Loss:  0.0005034971400164068
Valid Loss:  0.0006655637989751995
Epoch:  394  	Training Loss: 0.0007590912282466888
Test Loss:  0.0005009305896237493
Valid Loss:  0.0006624922971241176
Epoch:  395  	Training Loss: 0.0007558435900136828
Test Loss:  0.0004982986720278859
Valid Loss:  0.000659943965729326
Epoch:  396  	Training Loss: 0.0007529548602178693
Test Loss:  0.000496697670314461
Valid Loss:  0.0006582033820450306
Epoch:  397  	Training Loss: 0.0007507420377805829
Test Loss:  0.000493682804517448
Valid Loss:  0.0006560503970831633
Epoch:  398  	Training Loss: 0.0007488814881071448
Test Loss:  0.0004942083032801747
Valid Loss:  0.0006550614489242435
Epoch:  399  	Training Loss: 0.0007475189631804824
Test Loss:  0.0004905877867713571
Valid Loss:  0.0006529674865305424
Epoch:  400  	Training Loss: 0.0007461589993909001
Test Loss:  0.0004914818564429879
Valid Loss:  0.0006513672415167093
Epoch:  401  	Training Loss: 0.0007443532813340425
Test Loss:  0.0004895956953987479
Valid Loss:  0.0006498062866739929
Epoch:  402  	Training Loss: 0.0007429628167301416
Test Loss:  0.0004929148126393557
Valid Loss:  0.0006428087363019586
Epoch:  403  	Training Loss: 0.0007350208470597863
Test Loss:  0.000489946745801717
Valid Loss:  0.0006394701777026057
Epoch:  404  	Training Loss: 0.0007300192955881357
Test Loss:  0.00048773176968097687
Valid Loss:  0.0006369643961079419
Epoch:  405  	Training Loss: 0.000726233352907002
Test Loss:  0.0004863333306275308
Valid Loss:  0.0006352637428790331
Epoch:  406  	Training Loss: 0.0007234073127619922
Test Loss:  0.00048524729209020734
Valid Loss:  0.0006338587263599038
Epoch:  407  	Training Loss: 0.0007211039774119854
Test Loss:  0.0004844695795327425
Valid Loss:  0.0006326921284198761
Epoch:  408  	Training Loss: 0.000719209376256913
Test Loss:  0.0004839469911530614
Valid Loss:  0.0006317172665148973
Epoch:  409  	Training Loss: 0.0007175600621849298
Test Loss:  0.00048350903671234846
Valid Loss:  0.000630864524282515
Epoch:  410  	Training Loss: 0.0007161180255934596
Test Loss:  0.000483116862596944
Valid Loss:  0.0006300727836787701
Epoch:  411  	Training Loss: 0.0007148695294745266
Test Loss:  0.00048277294263243675
Valid Loss:  0.0006292980397120118
 83%|████████▎ | 413/500 [04:51<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:51<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:52<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:52<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:58<01:31,  1.16s/it] 85%|████████▍ | 423/500 [04:58<01:04,  1.20it/s] 85%|████████▌ | 425/500 [04:58<00:45,  1.66it/s] 85%|████████▌ | 427/500 [04:58<00:32,  2.26it/s] 86%|████████▌ | 429/500 [04:58<00:23,  3.04it/s] 86%|████████▌ | 431/500 [05:05<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:05<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:05<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:05<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:05<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:12<01:10,  1.19s/it] 89%|████████▊ | 443/500 [05:12<00:48,  1.17it/s] 89%|████████▉ | 445/500 [05:12<00:33,  1.62it/s] 89%|████████▉ | 447/500 [05:12<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:12<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:18<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:19<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:19<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:19<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:19<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:25<00:45,  1.16s/it] 93%|█████████▎| 463/500 [05:25<00:30,  1.19it/s] 93%|█████████▎| 465/500 [05:25<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:26<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:26<00:10,  3.03it/s] 94%|█████████▍| 471/500 [05:32<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:32<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:38<00:38,  1.53s/it] 95%|█████████▌| 477/500 [05:39<00:25,  1.10s/it]Epoch:  412  	Training Loss: 0.0007137530483305454
Test Loss:  0.0004816710716113448
Valid Loss:  0.0006274316692724824
Epoch:  413  	Training Loss: 0.0007126028649508953
Test Loss:  0.00048014873755164444
Valid Loss:  0.0006262214155867696
Epoch:  414  	Training Loss: 0.000711813336238265
Test Loss:  0.00047893577720969915
Valid Loss:  0.000625358079560101
Epoch:  415  	Training Loss: 0.0007111533777788281
Test Loss:  0.0004781002353411168
Valid Loss:  0.0006246138364076614
Epoch:  416  	Training Loss: 0.0007105105323716998
Test Loss:  0.00047748186625540257
Valid Loss:  0.0006238803616724908
Epoch:  417  	Training Loss: 0.0007098708301782608
Test Loss:  0.0004769421648234129
Valid Loss:  0.0006231609731912613
Epoch:  418  	Training Loss: 0.0007092364248819649
Test Loss:  0.00047644803998991847
Valid Loss:  0.000622464984189719
Epoch:  419  	Training Loss: 0.0007086431724019349
Test Loss:  0.0004758085997309536
Valid Loss:  0.0006219067145138979
Epoch:  420  	Training Loss: 0.0007081147632561624
Test Loss:  0.00047544069821015
Valid Loss:  0.0006213139276951551
Epoch:  421  	Training Loss: 0.0007076075999066234
Test Loss:  0.0004748897335957736
Valid Loss:  0.0006208294653333724
Epoch:  422  	Training Loss: 0.0007071307627484202
Test Loss:  0.0004712821391876787
Valid Loss:  0.0006089079543016851
Epoch:  423  	Training Loss: 0.0006973678828217089
Test Loss:  0.00045892284833826125
Valid Loss:  0.0006042382447049022
Epoch:  424  	Training Loss: 0.0006917269201949239
Test Loss:  0.0004559193621389568
Valid Loss:  0.0006002477020956576
Epoch:  425  	Training Loss: 0.0006882455782033503
Test Loss:  0.00045125896576792
Valid Loss:  0.0005982296424917877
Epoch:  426  	Training Loss: 0.0006858559790998697
Test Loss:  0.00044964809785597026
Valid Loss:  0.000596342608332634
Epoch:  427  	Training Loss: 0.0006839307025074959
Test Loss:  0.00044763911864720285
Valid Loss:  0.0005951320054009557
Epoch:  428  	Training Loss: 0.000682361307553947
Test Loss:  0.00044653279474005103
Valid Loss:  0.0005942205898463726
Epoch:  429  	Training Loss: 0.0006811154307797551
Test Loss:  0.0004454098525457084
Valid Loss:  0.0005935889203101397
Epoch:  430  	Training Loss: 0.0006800449918955564
Test Loss:  0.00044494442408904433
Valid Loss:  0.0005929898470640182
Epoch:  431  	Training Loss: 0.0006790598854422569
Test Loss:  0.0004441117343958467
Valid Loss:  0.0005926021840423346
Epoch:  432  	Training Loss: 0.000678161857649684
Test Loss:  0.0004479142662603408
Valid Loss:  0.000586751033551991
Epoch:  433  	Training Loss: 0.0006693269242532551
Test Loss:  0.0004381744656711817
Valid Loss:  0.0005831392481923103
Epoch:  434  	Training Loss: 0.0006631861324422061
Test Loss:  0.00043996190652251244
Valid Loss:  0.0005795471952296793
Epoch:  435  	Training Loss: 0.0006581858033314347
Test Loss:  0.00043439160799607635
Valid Loss:  0.0005767082329839468
Epoch:  436  	Training Loss: 0.0006538789020851254
Test Loss:  0.00043437775457277894
Valid Loss:  0.0005736435414291918
Epoch:  437  	Training Loss: 0.00064992462284863
Test Loss:  0.0004306567716412246
Valid Loss:  0.0005707148229703307
Epoch:  438  	Training Loss: 0.0006461859447881579
Test Loss:  0.0004296106053516269
Valid Loss:  0.000567752169445157
Epoch:  439  	Training Loss: 0.0006426346371881664
Test Loss:  0.0004268366319593042
Valid Loss:  0.0005650341627188027
Epoch:  440  	Training Loss: 0.0006392752984538674
Test Loss:  0.0004255824023857713
Valid Loss:  0.000562292174436152
Epoch:  441  	Training Loss: 0.0006360659608617425
Test Loss:  0.0004232671926729381
Valid Loss:  0.0005596448900178075
Epoch:  442  	Training Loss: 0.00063304603099823
Test Loss:  0.00042163790203630924
Valid Loss:  0.0005580355646088719
Epoch:  443  	Training Loss: 0.0006311151664704084
Test Loss:  0.00042089802445843816
Valid Loss:  0.0005563180311582983
Epoch:  444  	Training Loss: 0.0006292842444963753
Test Loss:  0.0004193811328150332
Valid Loss:  0.0005547029431909323
Epoch:  445  	Training Loss: 0.0006274963379837573
Test Loss:  0.0004184729768894613
Valid Loss:  0.0005530309863388538
Epoch:  446  	Training Loss: 0.0006258159410208464
Test Loss:  0.00041705495095811784
Valid Loss:  0.0005513993673957884
Epoch:  447  	Training Loss: 0.0006241698283702135
Test Loss:  0.00041608005994930863
Valid Loss:  0.0005497137317433953
Epoch:  448  	Training Loss: 0.0006225565448403358
Test Loss:  0.0004147823201492429
Valid Loss:  0.0005480806576088071
Epoch:  449  	Training Loss: 0.000620983075350523
Test Loss:  0.00041379049071110785
Valid Loss:  0.00054642598843202
Epoch:  450  	Training Loss: 0.000619427184574306
Test Loss:  0.00041250319918617606
Valid Loss:  0.0005448058946058154
Epoch:  451  	Training Loss: 0.0006179079646244645
Test Loss:  0.00041149003664031625
Valid Loss:  0.0005431663012132049
Epoch:  452  	Training Loss: 0.0006164201768115163
Test Loss:  0.0004091684822924435
Valid Loss:  0.0005392293096520007
Epoch:  453  	Training Loss: 0.0006131489644758403
Test Loss:  0.0004055080935359001
Valid Loss:  0.0005360665963962674
Epoch:  454  	Training Loss: 0.0006102788029238582
Test Loss:  0.0004035864258185029
Valid Loss:  0.0005331761203706264
Epoch:  455  	Training Loss: 0.0006077495636418462
Test Loss:  0.0004012139397673309
Valid Loss:  0.0005308180116117001
Epoch:  456  	Training Loss: 0.000605492910835892
Test Loss:  0.00039981253212317824
Valid Loss:  0.0005286803934723139
Epoch:  457  	Training Loss: 0.0006034589605405927
Test Loss:  0.0003980575129389763
Valid Loss:  0.0005267845699563622
Epoch:  458  	Training Loss: 0.0006015792023390532
Test Loss:  0.00039689207915216684
Valid Loss:  0.0005250615067780018
Epoch:  459  	Training Loss: 0.0005998376873321831
Test Loss:  0.0003958541783504188
Valid Loss:  0.0005234781419858336
Epoch:  460  	Training Loss: 0.0005981615977361798
Test Loss:  0.00039497463149018586
Valid Loss:  0.0005219520535320044
Epoch:  461  	Training Loss: 0.0005965393502265215
Test Loss:  0.00039405812276527286
Valid Loss:  0.0005204868502914906
Epoch:  462  	Training Loss: 0.0005949384067207575
Test Loss:  0.00038105587009340525
Valid Loss:  0.0005157709820196033
Epoch:  463  	Training Loss: 0.0005884213605895638
Test Loss:  0.00038530450547114015
Valid Loss:  0.0005106121534481645
Epoch:  464  	Training Loss: 0.0005839463556185365
Test Loss:  0.0003711578028742224
Valid Loss:  0.0005090277409180999
Epoch:  465  	Training Loss: 0.0005803027888759971
Test Loss:  0.0003826379543170333
Valid Loss:  0.0005050580366514623
Epoch:  466  	Training Loss: 0.0005774496821686625
Test Loss:  0.0003643559757620096
Valid Loss:  0.0005052365595474839
Epoch:  467  	Training Loss: 0.0005751634016633034
Test Loss:  0.00038397705066017807
Valid Loss:  0.0005016155773773789
Epoch:  468  	Training Loss: 0.0005733620491810143
Test Loss:  0.00035851442953571677
Valid Loss:  0.0005038991803303361
Epoch:  469  	Training Loss: 0.0005720674525946379
Test Loss:  0.0003903806209564209
Valid Loss:  0.0005003559635952115
Epoch:  470  	Training Loss: 0.0005715336883440614
Test Loss:  0.00035359986941330135
Valid Loss:  0.0005058504175394773
Epoch:  471  	Training Loss: 0.0005719901528209448
Test Loss:  0.0004037667531520128
Valid Loss:  0.0005029018502682447
Epoch:  472  	Training Loss: 0.0005738180479966104
Test Loss:  0.0003687693097162992
Valid Loss:  0.0004913999000564218
Epoch:  473  	Training Loss: 0.0005621406598947942
Test Loss:  0.00036582586471922696
Valid Loss:  0.0004899170016869903
Epoch:  474  	Training Loss: 0.0005597486160695553
Test Loss:  0.00036467527388595045
Valid Loss:  0.0004888686817139387
Epoch:  475  	Training Loss: 0.0005578204290941358
Test Loss:  0.0003639081842266023
Valid Loss:  0.0004881314525846392
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.0005563120357692242
Test Loss:  0.0003613715525716543
Valid Loss:  0.0004870538250543177
Epoch:  477  	Training Loss: 0.0005547783803194761
Test Loss:  0.00035997305531054735
Valid Loss:  0.00048602581955492496
Epoch:  478  	Training Loss: 0.0005533770890906453
Test Loss:  0.00035900648799724877
Valid Loss:  0.0004850186232943088
 96%|█████████▌| 479/500 [05:39<00:16,  1.27it/s] 96%|█████████▌| 481/500 [05:45<00:28,  1.49s/it] 97%|█████████▋| 483/500 [05:45<00:18,  1.07s/it] 97%|█████████▋| 485/500 [05:45<00:11,  1.31it/s] 97%|█████████▋| 487/500 [05:45<00:07,  1.80it/s] 98%|█████████▊| 489/500 [05:46<00:04,  2.45it/s] 98%|█████████▊| 491/500 [05:52<00:11,  1.25s/it] 99%|█████████▊| 493/500 [05:52<00:06,  1.12it/s] 99%|█████████▉| 495/500 [05:52<00:03,  1.55it/s] 99%|█████████▉| 497/500 [05:52<00:01,  2.11it/s]100%|█████████▉| 499/500 [05:52<00:00,  2.84it/s]100%|██████████| 500/500 [05:53<00:00,  1.42it/s]
Epoch:  479  	Training Loss: 0.0005520455306395888
Test Loss:  0.00035815604496747255
Valid Loss:  0.0004840198380406946
Epoch:  480  	Training Loss: 0.0005507488967850804
Test Loss:  0.00035735094570554793
Valid Loss:  0.00048302975483238697
Epoch:  481  	Training Loss: 0.0005494765937328339
Test Loss:  0.00035659235436469316
Valid Loss:  0.00048205669736489654
Epoch:  482  	Training Loss: 0.0005482424749061465
Test Loss:  0.0003556491283234209
Valid Loss:  0.00047989009181037545
Epoch:  483  	Training Loss: 0.0005462871631607413
Test Loss:  0.000354061892721802
Valid Loss:  0.0004781605093739927
Epoch:  484  	Training Loss: 0.0005446526920422912
Test Loss:  0.000352329108864069
Valid Loss:  0.00047674172674305737
Epoch:  485  	Training Loss: 0.0005432397010736167
Test Loss:  0.0003507305809762329
Valid Loss:  0.00047560600796714425
Epoch:  486  	Training Loss: 0.0005420018569566309
Test Loss:  0.0003494108095765114
Valid Loss:  0.0004746409540530294
Epoch:  487  	Training Loss: 0.0005409023142419755
Test Loss:  0.0003483103937469423
Valid Loss:  0.0004737653653137386
Epoch:  488  	Training Loss: 0.0005399250658228993
Test Loss:  0.0003473244432825595
Valid Loss:  0.00047303823521360755
Epoch:  489  	Training Loss: 0.0005390838487073779
Test Loss:  0.00034647586289793253
Valid Loss:  0.0004723495803773403
Epoch:  490  	Training Loss: 0.0005382848903536797
Test Loss:  0.00034570370917208493
Valid Loss:  0.0004717269621323794
Epoch:  491  	Training Loss: 0.0005375490873120725
Test Loss:  0.0003450172662269324
Valid Loss:  0.0004711361543741077
Epoch:  492  	Training Loss: 0.0005368529818952084
Test Loss:  0.0003443955210968852
Valid Loss:  0.0004707002663053572
Epoch:  493  	Training Loss: 0.0005360090872272849
Test Loss:  0.0003439408028498292
Valid Loss:  0.00047027459368109703
Epoch:  494  	Training Loss: 0.0005352014559321105
Test Loss:  0.0003435620747040957
Valid Loss:  0.0004698571574408561
Epoch:  495  	Training Loss: 0.0005344230448827147
Test Loss:  0.0003432181547395885
Valid Loss:  0.0004694476956501603
Epoch:  496  	Training Loss: 0.0005336705944500864
Test Loss:  0.00034289350151084363
Valid Loss:  0.0004690439673140645
Epoch:  497  	Training Loss: 0.0005329420091584325
Test Loss:  0.0003425789764150977
Valid Loss:  0.0004686468164436519
Epoch:  498  	Training Loss: 0.0005322349024936557
Test Loss:  0.000342279439792037
Valid Loss:  0.0004682561557274312
Epoch:  499  	Training Loss: 0.0005315474700182676
Test Loss:  0.0003419961140025407
Valid Loss:  0.00046787303290329874
Epoch:  500  	Training Loss: 0.0005308794789016247
Test Loss:  0.0003417145926505327
Valid Loss:  0.0004674961674027145
seed is  12
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:33, 14.66it/s]  1%|          | 4/500 [00:00<00:32, 15.22it/s]  1%|          | 6/500 [00:00<00:31, 15.66it/s]  2%|▏         | 8/500 [00:00<00:31, 15.84it/s]  2%|▏         | 10/500 [00:00<00:30, 15.96it/s]  2%|▏         | 12/500 [00:00<00:30, 16.11it/s]  3%|▎         | 14/500 [00:00<00:29, 16.28it/s]  3%|▎         | 16/500 [00:00<00:29, 16.38it/s]  4%|▎         | 18/500 [00:01<00:29, 16.34it/s]  4%|▍         | 20/500 [00:01<00:29, 16.20it/s]  4%|▍         | 22/500 [00:01<00:29, 16.06it/s]  5%|▍         | 24/500 [00:01<00:29, 16.06it/s]  5%|▌         | 26/500 [00:01<00:29, 15.86it/s]  6%|▌         | 28/500 [00:01<00:29, 15.75it/s]  6%|▌         | 30/500 [00:01<00:29, 15.99it/s]  6%|▋         | 32/500 [00:02<00:29, 16.10it/s]  7%|▋         | 34/500 [00:02<00:28, 16.21it/s]  7%|▋         | 36/500 [00:02<00:28, 16.29it/s]  8%|▊         | 38/500 [00:02<00:28, 16.31it/s]  8%|▊         | 40/500 [00:02<00:28, 16.30it/s]  8%|▊         | 42/500 [00:02<00:28, 16.34it/s]  9%|▉         | 44/500 [00:02<00:27, 16.42it/s]  9%|▉         | 46/500 [00:02<00:28, 15.91it/s] 10%|▉         | 48/500 [00:02<00:28, 16.06it/s] 10%|█         | 50/500 [00:03<00:27, 16.16it/s] 10%|█         | 52/500 [00:03<00:27, 16.15it/s] 11%|█         | 54/500 [00:03<00:27, 16.08it/s] 11%|█         | 56/500 [00:03<00:27, 16.09it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.23it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.02it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.18it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.20it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.28it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.38it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.06it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.17it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.21it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.34it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.23it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.23it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.11it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.28it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.39it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.41it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.41it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.47it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.35it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.43it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.49it/s] 20%|██        | 100/500 [00:06<00:24, 16.46it/s] 20%|██        | 102/500 [00:06<00:24, 16.46it/s] 21%|██        | 104/500 [00:06<00:24, 16.47it/s] 21%|██        | 106/500 [00:06<00:23, 16.53it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.52it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.27it/s] 22%|██▏       | 112/500 [00:06<00:24, 16.02it/s] 23%|██▎       | 114/500 [00:07<00:24, 15.89it/s] 23%|██▎       | 116/500 [00:07<00:24, 15.86it/s] 24%|██▎       | 118/500 [00:07<00:24, 15.79it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.01it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.05it/s] 25%|██▍       | 124/500 [00:07<00:23, 15.93it/s]Epoch:  1  	Training Loss: 0.19500896334648132
Test Loss:  5566.056640625
Valid Loss:  5539.0810546875
Epoch:  2  	Training Loss: 5531.84130859375
Test Loss:  7.874766874439844e+17
Valid Loss:  7.806002730043965e+17
Epoch:  3  	Training Loss: 7.82261909951873e+17
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.13it/s] 26%|██▌       | 128/500 [00:07<00:23, 16.14it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.13it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.74it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.67it/s] 27%|██▋       | 136/500 [00:08<00:23, 15.53it/s] 28%|██▊       | 138/500 [00:08<00:22, 15.83it/s] 28%|██▊       | 140/500 [00:08<00:22, 15.87it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.02it/s] 29%|██▉       | 144/500 [00:08<00:22, 16.09it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.20it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.18it/s] 30%|███       | 150/500 [00:09<00:21, 16.04it/s] 30%|███       | 152/500 [00:09<00:21, 15.90it/s] 31%|███       | 154/500 [00:09<00:21, 15.96it/s] 31%|███       | 156/500 [00:09<00:21, 16.06it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.10it/s] 32%|███▏      | 160/500 [00:09<00:21, 16.05it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.98it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.97it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.03it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.22it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.32it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.34it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.42it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.41it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.48it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.48it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.29it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.28it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.16it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.14it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.20it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.27it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.33it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.30it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.38it/s] 40%|████      | 200/500 [00:12<00:18, 16.44it/s] 40%|████      | 202/500 [00:12<00:18, 16.41it/s] 41%|████      | 204/500 [00:12<00:18, 16.44it/s] 41%|████      | 206/500 [00:12<00:17, 16.50it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.43it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.47it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.37it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.13it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.18it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.29it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.25it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.21it/s] 45%|████▍     | 224/500 [00:13<00:17, 15.93it/s] 45%|████▌     | 226/500 [00:13<00:17, 15.98it/s] 46%|████▌     | 228/500 [00:14<00:17, 15.94it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.03it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.17it/s] 47%|████▋     | 234/500 [00:14<00:16, 15.93it/s] 47%|████▋     | 236/500 [00:14<00:16, 15.73it/s] 48%|████▊     | 238/500 [00:14<00:16, 15.44it/s] 48%|████▊     | 240/500 [00:14<00:16, 15.66it/s] 48%|████▊     | 242/500 [00:15<00:17, 14.86it/s] 49%|████▉     | 244/500 [00:15<00:18, 14.04it/s] 49%|████▉     | 246/500 [00:15<00:17, 14.40it/s] 50%|████▉     | 248/500 [00:15<00:17, 14.82it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:16, 15.19it/s] 50%|█████     | 252/500 [00:15<00:15, 15.58it/s] 51%|█████     | 254/500 [00:15<00:15, 15.68it/s] 51%|█████     | 256/500 [00:15<00:15, 15.68it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.64it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.71it/s] 52%|█████▏    | 262/500 [00:16<00:14, 15.90it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.04it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.11it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.16it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.14it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.14it/s] 55%|█████▍    | 274/500 [00:17<00:14, 16.09it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.22it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.28it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.37it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.45it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.52it/s] 57%|█████▋    | 286/500 [00:17<00:12, 16.55it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.59it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.48it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.06it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.04it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.12it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.26it/s] 60%|██████    | 300/500 [00:18<00:12, 16.35it/s] 60%|██████    | 302/500 [00:18<00:12, 16.44it/s] 61%|██████    | 304/500 [00:18<00:11, 16.42it/s] 61%|██████    | 306/500 [00:19<00:11, 16.46it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.32it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.42it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.36it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.29it/s] 63%|██████▎   | 316/500 [00:19<00:11, 15.96it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.00it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.07it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.19it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.27it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.33it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.36it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.32it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.23it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.15it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.15it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.21it/s] 68%|██████▊   | 340/500 [00:21<00:10, 15.97it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.10it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.24it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.36it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.45it/s] 70%|███████   | 350/500 [00:21<00:09, 16.19it/s] 70%|███████   | 352/500 [00:21<00:09, 16.03it/s] 71%|███████   | 354/500 [00:21<00:09, 15.73it/s] 71%|███████   | 356/500 [00:22<00:09, 15.57it/s] 72%|███████▏  | 358/500 [00:22<00:08, 15.80it/s] 72%|███████▏  | 360/500 [00:22<00:09, 15.53it/s] 72%|███████▏  | 362/500 [00:22<00:08, 15.68it/s] 73%|███████▎  | 364/500 [00:22<00:08, 15.94it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.13it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.01it/s] 74%|███████▍  | 370/500 [00:22<00:08, 15.92it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.89it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.00it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.15it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.19it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.31it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.40it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.34it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.33it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.29it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.35it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.34it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.31it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.31it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.19it/s] 80%|████████  | 400/500 [00:24<00:06, 16.24it/s] 80%|████████  | 402/500 [00:24<00:06, 16.24it/s] 81%|████████  | 404/500 [00:25<00:05, 16.36it/s] 81%|████████  | 406/500 [00:25<00:05, 15.82it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.96it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.14it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.24it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.33it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.40it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.44it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.28it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.19it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.20it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.29it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.25it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.24it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.21it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.24it/s] 87%|████████▋ | 436/500 [00:27<00:06, 10.51it/s] 88%|████████▊ | 438/500 [00:27<00:07,  8.04it/s] 88%|████████▊ | 440/500 [00:27<00:06,  9.00it/s] 88%|████████▊ | 442/500 [00:27<00:05, 10.32it/s] 89%|████████▉ | 444/500 [00:28<00:04, 11.53it/s] 89%|████████▉ | 446/500 [00:28<00:04, 12.61it/s] 90%|████████▉ | 448/500 [00:28<00:03, 13.46it/s] 90%|█████████ | 450/500 [00:28<00:03, 13.94it/s] 90%|█████████ | 452/500 [00:28<00:03, 14.51it/s] 91%|█████████ | 454/500 [00:28<00:03, 14.64it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.02it/s] 92%|█████████▏| 458/500 [00:28<00:02, 15.15it/s] 92%|█████████▏| 460/500 [00:29<00:02, 15.34it/s] 92%|█████████▏| 462/500 [00:29<00:02, 15.46it/s] 93%|█████████▎| 464/500 [00:29<00:02, 15.47it/s] 93%|█████████▎| 466/500 [00:29<00:02, 15.66it/s] 94%|█████████▎| 468/500 [00:29<00:02, 15.63it/s] 94%|█████████▍| 470/500 [00:29<00:01, 15.72it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.87it/s] 95%|█████████▍| 474/500 [00:29<00:01, 15.87it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.55it/s] 96%|█████████▌| 478/500 [00:30<00:01, 15.43it/s] 96%|█████████▌| 480/500 [00:30<00:01, 15.76it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.01it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.14it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.26it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.35it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.28it/s] 98%|█████████▊| 492/500 [00:31<00:00, 16.09it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.15it/s] 99%|█████████▉| 496/500 [00:31<00:00, 15.96it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.17it/s]100%|██████████| 500/500 [00:31<00:00, 16.31it/s]100%|██████████| 500/500 [00:31<00:00, 15.83it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  12
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:40,  6.21s/it]  1%|          | 3/500 [00:06<13:46,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:24,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:29,  1.19s/it]  5%|▍         | 23/500 [00:19<06:44,  1.18it/s]  5%|▌         | 25/500 [00:20<04:50,  1.64it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.64it/s]  7%|▋         | 37/500 [00:27<03:25,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<08:51,  1.16s/it]  9%|▊         | 43/500 [00:33<06:20,  1.20it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:20,  2.26it/s] 10%|▉         | 49/500 [00:33<02:28,  3.03it/s] 10%|█         | 51/500 [00:40<08:42,  1.16s/it] 11%|█         | 53/500 [00:40<06:14,  1.19it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:27,  2.98it/s] 12%|█▏        | 61/500 [00:46<08:31,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:05,  1.20it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.01it/s] 14%|█▍        | 71/500 [00:53<08:25,  1.18s/it] 15%|█▍        | 73/500 [00:53<06:01,  1.18it/s]Epoch:  1  	Training Loss: 0.19500894844532013
Test Loss:  9.142292976379395
Valid Loss:  9.017607688903809
Epoch:  2  	Training Loss: 9.034324645996094
Test Loss:  0.1905754953622818
Valid Loss:  0.19186922907829285
Epoch:  3  	Training Loss: 0.1952880322933197
Test Loss:  0.19037482142448425
Valid Loss:  0.19166992604732513
Epoch:  4  	Training Loss: 0.1950852870941162
Test Loss:  0.1901741921901703
Valid Loss:  0.19147062301635742
Epoch:  5  	Training Loss: 0.1948825716972351
Test Loss:  0.18997570872306824
Valid Loss:  0.19127459824085236
Epoch:  6  	Training Loss: 0.1946849226951599
Test Loss:  0.18985795974731445
Valid Loss:  0.1911715716123581
Epoch:  7  	Training Loss: 0.1945750117301941
Test Loss:  0.18981248140335083
Valid Loss:  0.1911260485649109
Epoch:  8  	Training Loss: 0.19452977180480957
Test Loss:  0.1897781938314438
Valid Loss:  0.19109085202217102
Epoch:  9  	Training Loss: 0.1944950819015503
Test Loss:  0.18974722921848297
Valid Loss:  0.191059872508049
Epoch:  10  	Training Loss: 0.19446320831775665
Test Loss:  0.18971771001815796
Valid Loss:  0.19102953374385834
Epoch:  11  	Training Loss: 0.1944323480129242
Test Loss:  0.18968887627124786
Valid Loss:  0.19099943339824677
Epoch:  12  	Training Loss: 0.19440194964408875
Test Loss:  0.18968385457992554
Valid Loss:  0.19099396467208862
Epoch:  13  	Training Loss: 0.19439664483070374
Test Loss:  0.18967899680137634
Valid Loss:  0.1909887194633484
Epoch:  14  	Training Loss: 0.19439156353473663
Test Loss:  0.1896742582321167
Valid Loss:  0.19098380208015442
Epoch:  15  	Training Loss: 0.19438661634922028
Test Loss:  0.1896696388721466
Valid Loss:  0.19097900390625
Epoch:  16  	Training Loss: 0.19438177347183228
Test Loss:  0.1896650493144989
Valid Loss:  0.19097432494163513
Epoch:  17  	Training Loss: 0.19437700510025024
Test Loss:  0.18966048955917358
Valid Loss:  0.19096975028514862
Epoch:  18  	Training Loss: 0.19437232613563538
Test Loss:  0.18965594470500946
Valid Loss:  0.1909651756286621
Epoch:  19  	Training Loss: 0.1943676769733429
Test Loss:  0.18965139985084534
Valid Loss:  0.1909606158733368
Epoch:  20  	Training Loss: 0.1943630576133728
Test Loss:  0.1896468847990036
Valid Loss:  0.19095608592033386
Epoch:  21  	Training Loss: 0.1943584680557251
Test Loss:  0.18964236974716187
Valid Loss:  0.19095154106616974
Epoch:  22  	Training Loss: 0.194353848695755
Test Loss:  0.18963763117790222
Valid Loss:  0.19094669818878174
Epoch:  23  	Training Loss: 0.19434894621372223
Test Loss:  0.18963292241096497
Valid Loss:  0.19094187021255493
Epoch:  24  	Training Loss: 0.19434404373168945
Test Loss:  0.1896282434463501
Valid Loss:  0.19093701243400574
Epoch:  25  	Training Loss: 0.19433912634849548
Test Loss:  0.18962351977825165
Valid Loss:  0.19093216955661774
Epoch:  26  	Training Loss: 0.1943342238664627
Test Loss:  0.18961882591247559
Valid Loss:  0.19092735648155212
Epoch:  27  	Training Loss: 0.19432932138442993
Test Loss:  0.18961411714553833
Valid Loss:  0.19092249870300293
Epoch:  28  	Training Loss: 0.19432441890239716
Test Loss:  0.18960940837860107
Valid Loss:  0.19091767072677612
Epoch:  29  	Training Loss: 0.19431951642036438
Test Loss:  0.1896047294139862
Valid Loss:  0.19091284275054932
Epoch:  30  	Training Loss: 0.1943146139383316
Test Loss:  0.18960002064704895
Valid Loss:  0.19090799987316132
Epoch:  31  	Training Loss: 0.19430971145629883
Test Loss:  0.1895953267812729
Valid Loss:  0.1909031718969345
Epoch:  32  	Training Loss: 0.19430480897426605
Test Loss:  0.18959058821201324
Valid Loss:  0.19089829921722412
Epoch:  33  	Training Loss: 0.1942998617887497
Test Loss:  0.1895858496427536
Valid Loss:  0.19089341163635254
Epoch:  34  	Training Loss: 0.19429489970207214
Test Loss:  0.18958111107349396
Valid Loss:  0.19088852405548096
Epoch:  35  	Training Loss: 0.19428996741771698
Test Loss:  0.1895763874053955
Valid Loss:  0.19088363647460938
Epoch:  36  	Training Loss: 0.19428500533103943
Test Loss:  0.18957163393497467
Valid Loss:  0.1908787488937378
Epoch:  37  	Training Loss: 0.19428005814552307
Test Loss:  0.18956688046455383
Valid Loss:  0.1908738613128662
Epoch:  38  	Training Loss: 0.1942751109600067
Test Loss:  0.18956217169761658
Valid Loss:  0.19086898863315582
Epoch:  39  	Training Loss: 0.19427016377449036
Test Loss:  0.18955740332603455
Valid Loss:  0.19086410105228424
Epoch:  40  	Training Loss: 0.194265216588974
Test Loss:  0.1895526796579361
Valid Loss:  0.19085921347141266
Epoch:  41  	Training Loss: 0.19426026940345764
Test Loss:  0.18954792618751526
Valid Loss:  0.19085434079170227
Epoch:  42  	Training Loss: 0.1942553073167801
Test Loss:  0.1895432323217392
Valid Loss:  0.19084948301315308
Epoch:  43  	Training Loss: 0.19425037503242493
Test Loss:  0.18953850865364075
Valid Loss:  0.19084462523460388
Epoch:  44  	Training Loss: 0.19424545764923096
Test Loss:  0.1895337998867035
Valid Loss:  0.1908397674560547
Epoch:  45  	Training Loss: 0.1942405253648758
Test Loss:  0.18952907621860504
Valid Loss:  0.1908348947763443
Epoch:  46  	Training Loss: 0.19423559308052063
Test Loss:  0.18952438235282898
Valid Loss:  0.1908300518989563
Epoch:  47  	Training Loss: 0.19423067569732666
Test Loss:  0.18951964378356934
Valid Loss:  0.1908251941204071
Epoch:  48  	Training Loss: 0.1942257583141327
Test Loss:  0.18951493501663208
Valid Loss:  0.19082032144069672
Epoch:  49  	Training Loss: 0.19422081112861633
Test Loss:  0.18951022624969482
Valid Loss:  0.19081546366214752
Epoch:  50  	Training Loss: 0.19421589374542236
Test Loss:  0.18950551748275757
Valid Loss:  0.19081059098243713
Epoch:  51  	Training Loss: 0.194210946559906
Test Loss:  0.18950077891349792
Valid Loss:  0.19080574810504913
Epoch:  52  	Training Loss: 0.19420602917671204
Test Loss:  0.18949609994888306
Valid Loss:  0.19080092012882233
Epoch:  53  	Training Loss: 0.19420112669467926
Test Loss:  0.1894914209842682
Valid Loss:  0.19079607725143433
Epoch:  54  	Training Loss: 0.19419622421264648
Test Loss:  0.18948674201965332
Valid Loss:  0.19079124927520752
Epoch:  55  	Training Loss: 0.1941913217306137
Test Loss:  0.18948204815387726
Valid Loss:  0.1907864212989807
Epoch:  56  	Training Loss: 0.19418643414974213
Test Loss:  0.1894773691892624
Valid Loss:  0.1907815933227539
Epoch:  57  	Training Loss: 0.19418153166770935
Test Loss:  0.18947267532348633
Valid Loss:  0.1907767653465271
Epoch:  58  	Training Loss: 0.19417661428451538
Test Loss:  0.18946799635887146
Valid Loss:  0.1907719224691391
Epoch:  59  	Training Loss: 0.1941717118024826
Test Loss:  0.1894633024930954
Valid Loss:  0.1907670795917511
Epoch:  60  	Training Loss: 0.19416680932044983
Test Loss:  0.18945859372615814
Valid Loss:  0.1907622516155243
Epoch:  61  	Training Loss: 0.19416190683841705
Test Loss:  0.18945391476154327
Valid Loss:  0.19075742363929749
Epoch:  62  	Training Loss: 0.19415700435638428
Test Loss:  0.1894492208957672
Valid Loss:  0.19075258076190948
Epoch:  63  	Training Loss: 0.1941521018743515
Test Loss:  0.18944454193115234
Valid Loss:  0.19074776768684387
Epoch:  64  	Training Loss: 0.19414719939231873
Test Loss:  0.1894398331642151
Valid Loss:  0.19074292480945587
Epoch:  65  	Training Loss: 0.19414231181144714
Test Loss:  0.18943515419960022
Valid Loss:  0.19073809683322906
Epoch:  66  	Training Loss: 0.19413739442825317
Test Loss:  0.18943047523498535
Valid Loss:  0.19073328375816345
Epoch:  67  	Training Loss: 0.1941325068473816
Test Loss:  0.18942579627037048
Valid Loss:  0.19072844088077545
Epoch:  68  	Training Loss: 0.19412758946418762
Test Loss:  0.18942110240459442
Valid Loss:  0.19072362780570984
Epoch:  69  	Training Loss: 0.19412270188331604
Test Loss:  0.18941642343997955
Valid Loss:  0.19071878492832184
Epoch:  70  	Training Loss: 0.19411781430244446
Test Loss:  0.1894117295742035
Valid Loss:  0.19071397185325623
Epoch:  71  	Training Loss: 0.19411292672157288
Test Loss:  0.18940705060958862
Valid Loss:  0.19070914387702942
Epoch:  72  	Training Loss: 0.1941080093383789
Test Loss:  0.18940237164497375
Valid Loss:  0.1907043159008026
Epoch:  73  	Training Loss: 0.19410313665866852
Test Loss:  0.18939772248268127
Valid Loss:  0.1906995177268982
 15%|█▌        | 75/500 [00:54<04:20,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:00<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:00<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<07:56,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:40,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:04,  1.65it/s] 19%|█▉        | 97/500 [01:07<02:58,  2.26it/s] 20%|█▉        | 99/500 [01:07<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:48,  1.17s/it] 21%|██        | 103/500 [01:14<05:35,  1.18it/s] 21%|██        | 105/500 [01:14<04:02,  1.63it/s] 21%|██▏       | 107/500 [01:14<02:56,  2.22it/s] 22%|██▏       | 109/500 [01:14<02:10,  2.99it/s] 22%|██▏       | 111/500 [01:20<07:30,  1.16s/it] 23%|██▎       | 113/500 [01:21<05:21,  1.20it/s] 23%|██▎       | 115/500 [01:21<03:51,  1.67it/s] 23%|██▎       | 117/500 [01:21<02:48,  2.28it/s] 24%|██▍       | 119/500 [01:21<02:04,  3.06it/s] 24%|██▍       | 121/500 [01:27<07:22,  1.17s/it] 25%|██▍       | 123/500 [01:27<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:27<03:49,  1.63it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:28<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:34<07:09,  1.16s/it] 27%|██▋       | 133/500 [01:34<05:05,  1.20it/s] 27%|██▋       | 135/500 [01:34<03:39,  1.66it/s] 27%|██▋       | 137/500 [01:34<02:40,  2.27it/s] 28%|██▊       | 139/500 [01:34<01:58,  3.05it/s] 28%|██▊       | 141/500 [01:41<07:01,  1.17s/it] 29%|██▊       | 143/500 [01:41<05:00,  1.19it/s] 29%|██▉       | 145/500 [01:41<03:36,  1.64it/s]Epoch:  74  	Training Loss: 0.19409826397895813
Test Loss:  0.1893930435180664
Valid Loss:  0.1906946897506714
Epoch:  75  	Training Loss: 0.19409339129924774
Test Loss:  0.18938837945461273
Valid Loss:  0.19068989157676697
Epoch:  76  	Training Loss: 0.19408850371837616
Test Loss:  0.18938371539115906
Valid Loss:  0.19068509340286255
Epoch:  77  	Training Loss: 0.19408363103866577
Test Loss:  0.1893790364265442
Valid Loss:  0.19068026542663574
Epoch:  78  	Training Loss: 0.1940787434577942
Test Loss:  0.1893743872642517
Valid Loss:  0.19067546725273132
Epoch:  79  	Training Loss: 0.1940738558769226
Test Loss:  0.18936970829963684
Valid Loss:  0.1906706690788269
Epoch:  80  	Training Loss: 0.19406898319721222
Test Loss:  0.18936504423618317
Valid Loss:  0.1906658411026001
Epoch:  81  	Training Loss: 0.19406411051750183
Test Loss:  0.1893603801727295
Valid Loss:  0.19066104292869568
Epoch:  82  	Training Loss: 0.19405922293663025
Test Loss:  0.1893557459115982
Valid Loss:  0.19065625965595245
Epoch:  83  	Training Loss: 0.19405439496040344
Test Loss:  0.18935108184814453
Valid Loss:  0.19065147638320923
Epoch:  84  	Training Loss: 0.19404953718185425
Test Loss:  0.18934646248817444
Valid Loss:  0.190646693110466
Epoch:  85  	Training Loss: 0.19404467940330505
Test Loss:  0.18934181332588196
Valid Loss:  0.19064190983772278
Epoch:  86  	Training Loss: 0.19403982162475586
Test Loss:  0.18933719396591187
Valid Loss:  0.19063714146614075
Epoch:  87  	Training Loss: 0.19403497874736786
Test Loss:  0.18933254480361938
Valid Loss:  0.19063234329223633
Epoch:  88  	Training Loss: 0.19403012096881866
Test Loss:  0.1893278956413269
Valid Loss:  0.1906275749206543
Epoch:  89  	Training Loss: 0.19402527809143066
Test Loss:  0.18932324647903442
Valid Loss:  0.19062279164791107
Epoch:  90  	Training Loss: 0.19402043521404266
Test Loss:  0.18931862711906433
Valid Loss:  0.19061800837516785
Epoch:  91  	Training Loss: 0.19401559233665466
Test Loss:  0.18931397795677185
Valid Loss:  0.19061324000358582
Epoch:  92  	Training Loss: 0.19401073455810547
Test Loss:  0.18930935859680176
Valid Loss:  0.19060847163200378
Epoch:  93  	Training Loss: 0.19400590658187866
Test Loss:  0.18930473923683167
Valid Loss:  0.19060370326042175
Epoch:  94  	Training Loss: 0.19400107860565186
Test Loss:  0.18930014967918396
Valid Loss:  0.1905989646911621
Epoch:  95  	Training Loss: 0.19399625062942505
Test Loss:  0.18929551541805267
Valid Loss:  0.19059419631958008
Epoch:  96  	Training Loss: 0.19399142265319824
Test Loss:  0.18929091095924377
Valid Loss:  0.19058944284915924
Epoch:  97  	Training Loss: 0.19398659467697144
Test Loss:  0.1892862766981125
Valid Loss:  0.1905846893787384
Epoch:  98  	Training Loss: 0.19398179650306702
Test Loss:  0.1892816722393036
Valid Loss:  0.19057992100715637
Epoch:  99  	Training Loss: 0.19397693872451782
Test Loss:  0.1892770528793335
Valid Loss:  0.19057518243789673
Epoch:  100  	Training Loss: 0.1939721405506134
Test Loss:  0.1892724335193634
Valid Loss:  0.1905704140663147
Epoch:  101  	Training Loss: 0.1939672976732254
Test Loss:  0.1892678141593933
Valid Loss:  0.19056564569473267
Epoch:  102  	Training Loss: 0.1939624845981598
Test Loss:  0.1892632097005844
Valid Loss:  0.19056090712547302
Epoch:  103  	Training Loss: 0.19395767152309418
Test Loss:  0.1892586201429367
Valid Loss:  0.19055618345737457
Epoch:  104  	Training Loss: 0.19395285844802856
Test Loss:  0.1892540156841278
Valid Loss:  0.19055144488811493
Epoch:  105  	Training Loss: 0.19394804537296295
Test Loss:  0.1892494261264801
Valid Loss:  0.19054670631885529
Epoch:  106  	Training Loss: 0.19394324719905853
Test Loss:  0.1892448365688324
Valid Loss:  0.19054198265075684
Epoch:  107  	Training Loss: 0.1939384639263153
Test Loss:  0.1892402470111847
Valid Loss:  0.190537229180336
Epoch:  108  	Training Loss: 0.1939336359500885
Test Loss:  0.1892356425523758
Valid Loss:  0.19053250551223755
Epoch:  109  	Training Loss: 0.19392883777618408
Test Loss:  0.1892310529947281
Valid Loss:  0.1905277669429779
Epoch:  110  	Training Loss: 0.19392403960227966
Test Loss:  0.18922646343708038
Valid Loss:  0.19052302837371826
Epoch:  111  	Training Loss: 0.19391924142837524
Test Loss:  0.18922185897827148
Valid Loss:  0.190518319606781
Epoch:  112  	Training Loss: 0.19391442835330963
Test Loss:  0.18921728432178497
Valid Loss:  0.19051359593868256
Epoch:  113  	Training Loss: 0.1939096450805664
Test Loss:  0.18921272456645966
Valid Loss:  0.1905088722705841
Epoch:  114  	Training Loss: 0.19390487670898438
Test Loss:  0.18920814990997314
Valid Loss:  0.19050416350364685
Epoch:  115  	Training Loss: 0.19390010833740234
Test Loss:  0.18920357525348663
Valid Loss:  0.1904994547367096
Epoch:  116  	Training Loss: 0.1938953399658203
Test Loss:  0.18919900059700012
Valid Loss:  0.19049474596977234
Epoch:  117  	Training Loss: 0.1938905417919159
Test Loss:  0.1891944408416748
Valid Loss:  0.19049003720283508
Epoch:  118  	Training Loss: 0.19388577342033386
Test Loss:  0.1891898512840271
Valid Loss:  0.19048532843589783
Epoch:  119  	Training Loss: 0.19388099014759064
Test Loss:  0.18918529152870178
Valid Loss:  0.19048061966896057
Epoch:  120  	Training Loss: 0.1938762217760086
Test Loss:  0.18918073177337646
Valid Loss:  0.19047591090202332
Epoch:  121  	Training Loss: 0.19387143850326538
Test Loss:  0.18917614221572876
Valid Loss:  0.19047120213508606
Epoch:  122  	Training Loss: 0.19386667013168335
Test Loss:  0.18917161226272583
Valid Loss:  0.1904665231704712
Epoch:  123  	Training Loss: 0.19386190176010132
Test Loss:  0.1891670525074005
Valid Loss:  0.19046181440353394
Epoch:  124  	Training Loss: 0.19385714828968048
Test Loss:  0.1891624927520752
Valid Loss:  0.19045712053775787
Epoch:  125  	Training Loss: 0.19385239481925964
Test Loss:  0.18915793299674988
Valid Loss:  0.1904524266719818
Epoch:  126  	Training Loss: 0.1938476264476776
Test Loss:  0.18915337324142456
Valid Loss:  0.19044773280620575
Epoch:  127  	Training Loss: 0.19384285807609558
Test Loss:  0.18914882838726044
Valid Loss:  0.1904430389404297
Epoch:  128  	Training Loss: 0.19383810460567474
Test Loss:  0.1891442835330963
Valid Loss:  0.19043835997581482
Epoch:  129  	Training Loss: 0.1938333511352539
Test Loss:  0.1891397088766098
Valid Loss:  0.19043366611003876
Epoch:  130  	Training Loss: 0.19382858276367188
Test Loss:  0.18913514912128448
Valid Loss:  0.1904289722442627
Epoch:  131  	Training Loss: 0.19382381439208984
Test Loss:  0.18913060426712036
Valid Loss:  0.19042427837848663
Epoch:  132  	Training Loss: 0.1938190758228302
Test Loss:  0.18912607431411743
Valid Loss:  0.19041961431503296
Epoch:  133  	Training Loss: 0.19381432235240936
Test Loss:  0.1891215443611145
Valid Loss:  0.19041495025157928
Epoch:  134  	Training Loss: 0.1938095986843109
Test Loss:  0.18911701440811157
Valid Loss:  0.19041027128696442
Epoch:  135  	Training Loss: 0.19380486011505127
Test Loss:  0.18911246955394745
Valid Loss:  0.19040560722351074
Epoch:  136  	Training Loss: 0.19380012154579163
Test Loss:  0.1891079545021057
Valid Loss:  0.19040094316005707
Epoch:  137  	Training Loss: 0.19379538297653198
Test Loss:  0.18910342454910278
Valid Loss:  0.1903962790966034
Epoch:  138  	Training Loss: 0.19379065930843353
Test Loss:  0.18909889459609985
Valid Loss:  0.19039160013198853
Epoch:  139  	Training Loss: 0.1937859207391739
Test Loss:  0.18909434974193573
Valid Loss:  0.19038695096969604
Epoch:  140  	Training Loss: 0.19378119707107544
Test Loss:  0.189089834690094
Valid Loss:  0.19038227200508118
Epoch:  141  	Training Loss: 0.1937764585018158
Test Loss:  0.18908530473709106
Valid Loss:  0.1903775930404663
Epoch:  142  	Training Loss: 0.19377171993255615
Test Loss:  0.18908078968524933
Valid Loss:  0.19037297368049622
Epoch:  143  	Training Loss: 0.1937670260667801
Test Loss:  0.18907630443572998
Valid Loss:  0.19036833941936493
Epoch:  144  	Training Loss: 0.19376231729984283
Test Loss:  0.18907180428504944
Valid Loss:  0.19036372005939484
Epoch:  145  	Training Loss: 0.19375762343406677
Test Loss:  0.1890673041343689
Valid Loss:  0.19035907089710236
Epoch:  146  	Training Loss: 0.19375291466712952
Test Loss:  0.18906280398368835 29%|██▉       | 147/500 [01:41<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:41<01:58,  2.95it/s] 30%|███       | 151/500 [01:48<06:48,  1.17s/it] 31%|███       | 153/500 [01:48<04:50,  1.19it/s] 31%|███       | 155/500 [01:48<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:48<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:48<01:52,  3.03it/s] 32%|███▏      | 161/500 [01:54<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:54<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:23,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:01<06:32,  1.19s/it] 35%|███▍      | 173/500 [02:01<04:39,  1.17it/s] 35%|███▌      | 175/500 [02:02<03:20,  1.62it/s] 35%|███▌      | 177/500 [02:02<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:02<01:47,  2.98it/s] 36%|███▌      | 181/500 [02:08<06:18,  1.19s/it] 37%|███▋      | 183/500 [02:08<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:08<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:09<02:21,  2.22it/s] 38%|███▊      | 189/500 [02:09<01:44,  2.98it/s] 38%|███▊      | 191/500 [02:15<06:06,  1.19s/it] 39%|███▊      | 193/500 [02:15<04:21,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:15<02:16,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.00it/s] 40%|████      | 201/500 [02:22<05:53,  1.18s/it] 41%|████      | 203/500 [02:22<04:11,  1.18it/s] 41%|████      | 205/500 [02:22<03:00,  1.63it/s] 41%|████▏     | 207/500 [02:22<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:22<01:36,  3.00it/s] 42%|████▏     | 211/500 [02:29<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:29<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:29<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:29<02:06,  2.23it/s]
Valid Loss:  0.19035445153713226
Epoch:  147  	Training Loss: 0.19374822080135345
Test Loss:  0.1890583038330078
Valid Loss:  0.19034981727600098
Epoch:  148  	Training Loss: 0.1937435269355774
Test Loss:  0.18905381858348846
Valid Loss:  0.1903451681137085
Epoch:  149  	Training Loss: 0.19373881816864014
Test Loss:  0.18904930353164673
Valid Loss:  0.1903405487537384
Epoch:  150  	Training Loss: 0.19373413920402527
Test Loss:  0.1890448033809662
Valid Loss:  0.19033591449260712
Epoch:  151  	Training Loss: 0.193729430437088
Test Loss:  0.18904031813144684
Valid Loss:  0.19033128023147583
Epoch:  152  	Training Loss: 0.19372472167015076
Test Loss:  0.18903586268424988
Valid Loss:  0.19032667577266693
Epoch:  153  	Training Loss: 0.1937200427055359
Test Loss:  0.18903139233589172
Valid Loss:  0.19032207131385803
Epoch:  154  	Training Loss: 0.19371537864208221
Test Loss:  0.18902689218521118
Valid Loss:  0.19031746685504913
Epoch:  155  	Training Loss: 0.19371071457862854
Test Loss:  0.18902243673801422
Valid Loss:  0.19031286239624023
Epoch:  156  	Training Loss: 0.19370603561401367
Test Loss:  0.18901795148849487
Valid Loss:  0.19030824303627014
Epoch:  157  	Training Loss: 0.19370137155056
Test Loss:  0.18901348114013672
Valid Loss:  0.19030365347862244
Epoch:  158  	Training Loss: 0.19369669258594513
Test Loss:  0.18900901079177856
Valid Loss:  0.19029903411865234
Epoch:  159  	Training Loss: 0.19369201362133026
Test Loss:  0.1890045404434204
Valid Loss:  0.19029444456100464
Epoch:  160  	Training Loss: 0.1936873495578766
Test Loss:  0.18900007009506226
Valid Loss:  0.19028982520103455
Epoch:  161  	Training Loss: 0.19368267059326172
Test Loss:  0.1889955997467041
Valid Loss:  0.19028522074222565
Epoch:  162  	Training Loss: 0.19367800652980804
Test Loss:  0.18899114429950714
Valid Loss:  0.19028063118457794
Epoch:  163  	Training Loss: 0.19367334246635437
Test Loss:  0.18898668885231018
Valid Loss:  0.19027602672576904
Epoch:  164  	Training Loss: 0.1936686933040619
Test Loss:  0.18898223340511322
Valid Loss:  0.19027146697044373
Epoch:  165  	Training Loss: 0.1936640441417694
Test Loss:  0.18897776305675507
Valid Loss:  0.19026687741279602
Epoch:  166  	Training Loss: 0.19365938007831573
Test Loss:  0.1889733076095581
Valid Loss:  0.19026225805282593
Epoch:  167  	Training Loss: 0.19365471601486206
Test Loss:  0.18896885216236115
Valid Loss:  0.19025766849517822
Epoch:  168  	Training Loss: 0.19365006685256958
Test Loss:  0.18896439671516418
Valid Loss:  0.1902530938386917
Epoch:  169  	Training Loss: 0.1936454027891159
Test Loss:  0.18895992636680603
Valid Loss:  0.190248504281044
Epoch:  170  	Training Loss: 0.19364075362682343
Test Loss:  0.18895548582077026
Valid Loss:  0.1902439147233963
Epoch:  171  	Training Loss: 0.19363608956336975
Test Loss:  0.1889510154724121
Valid Loss:  0.1902393251657486
Epoch:  172  	Training Loss: 0.19363144040107727
Test Loss:  0.18894660472869873
Valid Loss:  0.19023478031158447
Epoch:  173  	Training Loss: 0.19362683594226837
Test Loss:  0.18894219398498535
Valid Loss:  0.19023025035858154
Epoch:  174  	Training Loss: 0.19362223148345947
Test Loss:  0.18893781304359436
Valid Loss:  0.19022570550441742
Epoch:  175  	Training Loss: 0.19361762702465057
Test Loss:  0.18893340229988098
Valid Loss:  0.1902211606502533
Epoch:  176  	Training Loss: 0.19361302256584167
Test Loss:  0.1889289915561676
Valid Loss:  0.19021663069725037
Epoch:  177  	Training Loss: 0.19360841810703278
Test Loss:  0.18892458081245422
Valid Loss:  0.19021208584308624
Epoch:  178  	Training Loss: 0.19360382854938507
Test Loss:  0.18892018496990204
Valid Loss:  0.19020754098892212
Epoch:  179  	Training Loss: 0.19359922409057617
Test Loss:  0.18891575932502747
Valid Loss:  0.1902030110359192
Epoch:  180  	Training Loss: 0.19359460473060608
Test Loss:  0.18891137838363647
Valid Loss:  0.19019848108291626
Epoch:  181  	Training Loss: 0.19359001517295837
Test Loss:  0.1889069676399231
Valid Loss:  0.19019395112991333
Epoch:  182  	Training Loss: 0.19358539581298828
Test Loss:  0.18890255689620972
Valid Loss:  0.1901894062757492
Epoch:  183  	Training Loss: 0.19358080625534058
Test Loss:  0.18889814615249634
Valid Loss:  0.19018486142158508
Epoch:  184  	Training Loss: 0.19357621669769287
Test Loss:  0.18889373540878296
Valid Loss:  0.19018033146858215
Epoch:  185  	Training Loss: 0.19357159733772278
Test Loss:  0.18888933956623077
Valid Loss:  0.19017580151557922
Epoch:  186  	Training Loss: 0.19356700778007507
Test Loss:  0.1888849437236786
Valid Loss:  0.1901712566614151
Epoch:  187  	Training Loss: 0.19356240332126617
Test Loss:  0.1888805329799652
Valid Loss:  0.19016674160957336
Epoch:  188  	Training Loss: 0.19355779886245728
Test Loss:  0.18887612223625183
Valid Loss:  0.19016219675540924
Epoch:  189  	Training Loss: 0.19355320930480957
Test Loss:  0.18887171149253845
Valid Loss:  0.19015765190124512
Epoch:  190  	Training Loss: 0.19354860484600067
Test Loss:  0.18886733055114746
Valid Loss:  0.19015313684940338
Epoch:  191  	Training Loss: 0.19354400038719177
Test Loss:  0.18886291980743408
Valid Loss:  0.19014859199523926
Epoch:  192  	Training Loss: 0.19353941082954407
Test Loss:  0.1888585388660431
Valid Loss:  0.19014409184455872
Epoch:  193  	Training Loss: 0.19353482127189636
Test Loss:  0.1888541579246521
Valid Loss:  0.19013957679271698
Epoch:  194  	Training Loss: 0.19353026151657104
Test Loss:  0.1888497769832611
Valid Loss:  0.19013507664203644
Epoch:  195  	Training Loss: 0.19352567195892334
Test Loss:  0.18884539604187012
Valid Loss:  0.1901305615901947
Epoch:  196  	Training Loss: 0.19352111220359802
Test Loss:  0.18884101510047913
Valid Loss:  0.19012606143951416
Epoch:  197  	Training Loss: 0.1935165524482727
Test Loss:  0.18883663415908813
Valid Loss:  0.19012154638767242
Epoch:  198  	Training Loss: 0.193511962890625
Test Loss:  0.18883226811885834
Valid Loss:  0.1901170313358307
Epoch:  199  	Training Loss: 0.1935073882341385
Test Loss:  0.18882788717746735
Valid Loss:  0.19011253118515015
Epoch:  200  	Training Loss: 0.19350281357765198
Test Loss:  0.18882352113723755
Valid Loss:  0.1901080310344696
Epoch:  201  	Training Loss: 0.19349825382232666
Test Loss:  0.18881914019584656
Valid Loss:  0.19010350108146667
Epoch:  202  	Training Loss: 0.19349366426467896
Test Loss:  0.18881478905677795
Valid Loss:  0.1900990605354309
Epoch:  203  	Training Loss: 0.19348913431167603
Test Loss:  0.18881043791770935
Valid Loss:  0.19009457528591156
Epoch:  204  	Training Loss: 0.1934846043586731
Test Loss:  0.18880608677864075
Valid Loss:  0.1900900900363922
Epoch:  205  	Training Loss: 0.19348005950450897
Test Loss:  0.18880173563957214
Valid Loss:  0.19008561968803406
Epoch:  206  	Training Loss: 0.19347551465034485
Test Loss:  0.18879738450050354
Valid Loss:  0.1900811493396759
Epoch:  207  	Training Loss: 0.19347098469734192
Test Loss:  0.18879304826259613
Valid Loss:  0.19007666409015656
Epoch:  208  	Training Loss: 0.1934664249420166
Test Loss:  0.18878871202468872
Valid Loss:  0.1900722086429596
Epoch:  209  	Training Loss: 0.19346190989017487
Test Loss:  0.18878436088562012
Valid Loss:  0.19006773829460144
Epoch:  210  	Training Loss: 0.19345736503601074
Test Loss:  0.1887800097465515
Valid Loss:  0.1900632530450821
Epoch:  211  	Training Loss: 0.19345282018184662
Test Loss:  0.1887756735086441
Valid Loss:  0.19005876779556274
Epoch:  212  	Training Loss: 0.1934482902288437
Test Loss:  0.1887713372707367
Valid Loss:  0.19005432724952698
Epoch:  213  	Training Loss: 0.19344377517700195
Test Loss:  0.18876701593399048
Valid Loss:  0.1900498867034912
Epoch:  214  	Training Loss: 0.19343926012516022
Test Loss:  0.18876269459724426
Valid Loss:  0.19004544615745544
Epoch:  215  	Training Loss: 0.19343475997447968
Test Loss:  0.18875838816165924
Valid Loss:  0.19004100561141968
Epoch:  216  	Training Loss: 0.19343024492263794
Test Loss:  0.18875406682491302
Valid Loss:  0.19003655016422272
Epoch:  217  	Training Loss: 0.1934257447719574
Test Loss:  0.1887497454881668
Valid Loss:  0.19003209471702576
Epoch:  218  	Training Loss: 0.19342121481895447
Test Loss:  0.1887454241514206
Valid Loss:  0.19002765417099
 44%|████▍     | 219/500 [02:29<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:35<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:36<03:53,  1.19it/s] 45%|████▌     | 225/500 [02:36<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:36<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:36<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:42<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:47,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:43<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:43<01:27,  2.99it/s] 48%|████▊     | 241/500 [02:49<05:04,  1.17s/it] 49%|████▊     | 243/500 [02:49<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:49<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:50<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.02it/s] 50%|█████     | 251/500 [02:56<04:50,  1.17s/it] 51%|█████     | 253/500 [02:56<03:26,  1.20it/s] 51%|█████     | 255/500 [02:56<02:28,  1.65it/s] 51%|█████▏    | 257/500 [02:56<01:47,  2.26it/s] 52%|█████▏    | 259/500 [02:56<01:19,  3.04it/s] 52%|█████▏    | 261/500 [03:03<04:37,  1.16s/it] 53%|█████▎    | 263/500 [03:03<03:17,  1.20it/s] 53%|█████▎    | 265/500 [03:03<02:21,  1.66it/s] 53%|█████▎    | 267/500 [03:03<01:42,  2.27it/s] 54%|█████▍    | 269/500 [03:03<01:15,  3.06it/s] 54%|█████▍    | 271/500 [03:09<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:10<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:10<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:10<01:38,  2.25it/s] 56%|█████▌    | 279/500 [03:10<01:12,  3.03it/s] 56%|█████▌    | 281/500 [03:16<04:17,  1.17s/it] 57%|█████▋    | 283/500 [03:16<03:03,  1.19it/s] 57%|█████▋    | 285/500 [03:16<02:11,  1.64it/s] 57%|█████▋    | 287/500 [03:17<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:17<01:10,  3.01it/s]Epoch:  219  	Training Loss: 0.19341672956943512
Test Loss:  0.18874110281467438
Valid Loss:  0.19002321362495422
Epoch:  220  	Training Loss: 0.19341221451759338
Test Loss:  0.18873679637908936
Valid Loss:  0.19001877307891846
Epoch:  221  	Training Loss: 0.19340769946575165
Test Loss:  0.18873247504234314
Valid Loss:  0.1900143325328827
Epoch:  222  	Training Loss: 0.1934031993150711
Test Loss:  0.1887281835079193
Valid Loss:  0.1900099217891693
Epoch:  223  	Training Loss: 0.19339871406555176
Test Loss:  0.18872389197349548
Valid Loss:  0.19000551104545593
Epoch:  224  	Training Loss: 0.1933942586183548
Test Loss:  0.18871960043907166
Valid Loss:  0.19000110030174255
Epoch:  225  	Training Loss: 0.19338977336883545
Test Loss:  0.18871533870697021
Valid Loss:  0.18999668955802917
Epoch:  226  	Training Loss: 0.1933853030204773
Test Loss:  0.1887110471725464
Valid Loss:  0.1899922788143158
Epoch:  227  	Training Loss: 0.19338081777095795
Test Loss:  0.18870677053928375
Valid Loss:  0.18998786807060242
Epoch:  228  	Training Loss: 0.1933763474225998
Test Loss:  0.18870249390602112
Valid Loss:  0.18998345732688904
Epoch:  229  	Training Loss: 0.19337189197540283
Test Loss:  0.1886981874704361
Valid Loss:  0.18997904658317566
Epoch:  230  	Training Loss: 0.19336740672588348
Test Loss:  0.18869392573833466
Valid Loss:  0.18997463583946228
Epoch:  231  	Training Loss: 0.19336292147636414
Test Loss:  0.18868963420391083
Valid Loss:  0.1899702250957489
Epoch:  232  	Training Loss: 0.19335846602916718
Test Loss:  0.1886853724718094
Valid Loss:  0.1899658441543579
Epoch:  233  	Training Loss: 0.19335401058197021
Test Loss:  0.18868109583854675
Valid Loss:  0.18996146321296692
Epoch:  234  	Training Loss: 0.19334954023361206
Test Loss:  0.18867681920528412
Valid Loss:  0.18995706737041473
Epoch:  235  	Training Loss: 0.1933450996875763
Test Loss:  0.18867255747318268
Valid Loss:  0.18995267152786255
Epoch:  236  	Training Loss: 0.19334062933921814
Test Loss:  0.18866828083992004
Valid Loss:  0.18994827568531036
Epoch:  237  	Training Loss: 0.19333618879318237
Test Loss:  0.1886640191078186
Valid Loss:  0.18994387984275818
Epoch:  238  	Training Loss: 0.19333171844482422
Test Loss:  0.18865975737571716
Valid Loss:  0.1899394989013672
Epoch:  239  	Training Loss: 0.19332727789878845
Test Loss:  0.18865548074245453
Valid Loss:  0.189935103058815
Epoch:  240  	Training Loss: 0.1933228075504303
Test Loss:  0.1886512041091919
Valid Loss:  0.18993070721626282
Epoch:  241  	Training Loss: 0.19331836700439453
Test Loss:  0.18864694237709045
Valid Loss:  0.18992632627487183
Epoch:  242  	Training Loss: 0.19331391155719757
Test Loss:  0.1886427104473114
Valid Loss:  0.18992197513580322
Epoch:  243  	Training Loss: 0.193309485912323
Test Loss:  0.18863847851753235
Valid Loss:  0.18991760909557343
Epoch:  244  	Training Loss: 0.19330507516860962
Test Loss:  0.1886342614889145
Valid Loss:  0.18991327285766602
Epoch:  245  	Training Loss: 0.19330066442489624
Test Loss:  0.18863004446029663
Valid Loss:  0.1899089217185974
Epoch:  246  	Training Loss: 0.19329625368118286
Test Loss:  0.18862579762935638
Valid Loss:  0.1899045705795288
Epoch:  247  	Training Loss: 0.19329184293746948
Test Loss:  0.18862158060073853
Valid Loss:  0.1899002194404602
Epoch:  248  	Training Loss: 0.1932874321937561
Test Loss:  0.18861733376979828
Valid Loss:  0.1898958683013916
Epoch:  249  	Training Loss: 0.19328302145004272
Test Loss:  0.18861311674118042
Valid Loss:  0.189891517162323
Epoch:  250  	Training Loss: 0.19327861070632935
Test Loss:  0.18860889971256256
Valid Loss:  0.1898871660232544
Epoch:  251  	Training Loss: 0.19327418506145477
Test Loss:  0.1886046677827835
Valid Loss:  0.1898828148841858
Epoch:  252  	Training Loss: 0.1932697892189026
Test Loss:  0.18860046565532684
Valid Loss:  0.18987849354743958
Epoch:  253  	Training Loss: 0.1932653933763504
Test Loss:  0.18859624862670898
Valid Loss:  0.18987417221069336
Epoch:  254  	Training Loss: 0.19326099753379822
Test Loss:  0.18859204649925232
Valid Loss:  0.18986985087394714
Epoch:  255  	Training Loss: 0.19325661659240723
Test Loss:  0.18858784437179565
Valid Loss:  0.18986549973487854
Epoch:  256  	Training Loss: 0.19325222074985504
Test Loss:  0.188583642244339
Valid Loss:  0.18986117839813232
Epoch:  257  	Training Loss: 0.19324782490730286
Test Loss:  0.18857944011688232
Valid Loss:  0.1898568570613861
Epoch:  258  	Training Loss: 0.19324344396591187
Test Loss:  0.18857522308826447
Valid Loss:  0.1898525357246399
Epoch:  259  	Training Loss: 0.1932390332221985
Test Loss:  0.1885710060596466
Valid Loss:  0.1898481845855713
Epoch:  260  	Training Loss: 0.1932346671819687
Test Loss:  0.18856680393218994
Valid Loss:  0.18984387814998627
Epoch:  261  	Training Loss: 0.1932302713394165
Test Loss:  0.18856260180473328
Valid Loss:  0.18983954191207886
Epoch:  262  	Training Loss: 0.19322587549686432
Test Loss:  0.188558429479599
Valid Loss:  0.18983525037765503
Epoch:  263  	Training Loss: 0.19322152435779572
Test Loss:  0.18855425715446472
Valid Loss:  0.1898309588432312
Epoch:  264  	Training Loss: 0.19321715831756592
Test Loss:  0.18855008482933044
Valid Loss:  0.18982665240764618
Epoch:  265  	Training Loss: 0.19321280717849731
Test Loss:  0.18854589760303497
Valid Loss:  0.18982234597206116
Epoch:  266  	Training Loss: 0.19320844113826752
Test Loss:  0.1885417103767395
Valid Loss:  0.18981805443763733
Epoch:  267  	Training Loss: 0.19320407509803772
Test Loss:  0.18853753805160522
Valid Loss:  0.1898137629032135
Epoch:  268  	Training Loss: 0.19319970905780792
Test Loss:  0.18853333592414856
Valid Loss:  0.18980945646762848
Epoch:  269  	Training Loss: 0.19319534301757812
Test Loss:  0.18852916359901428
Valid Loss:  0.18980515003204346
Epoch:  270  	Training Loss: 0.19319099187850952
Test Loss:  0.18852499127388
Valid Loss:  0.18980085849761963
Epoch:  271  	Training Loss: 0.19318662583827972
Test Loss:  0.18852080404758453
Valid Loss:  0.1897965669631958
Epoch:  272  	Training Loss: 0.19318225979804993
Test Loss:  0.18851666152477264
Valid Loss:  0.18979230523109436
Epoch:  273  	Training Loss: 0.1931779384613037
Test Loss:  0.18851250410079956
Valid Loss:  0.18978802859783173
Epoch:  274  	Training Loss: 0.1931736171245575
Test Loss:  0.18850836157798767
Valid Loss:  0.1897837519645691
Epoch:  275  	Training Loss: 0.19316929578781128
Test Loss:  0.18850421905517578
Valid Loss:  0.18977949023246765
Epoch:  276  	Training Loss: 0.19316495954990387
Test Loss:  0.1885000765323639
Valid Loss:  0.1897752285003662
Epoch:  277  	Training Loss: 0.19316062331199646
Test Loss:  0.1884959191083908
Valid Loss:  0.18977096676826477
Epoch:  278  	Training Loss: 0.19315630197525024
Test Loss:  0.18849177658557892
Valid Loss:  0.18976670503616333
Epoch:  279  	Training Loss: 0.19315196573734283
Test Loss:  0.18848761916160583
Valid Loss:  0.1897624135017395
Epoch:  280  	Training Loss: 0.19314764440059662
Test Loss:  0.18848347663879395
Valid Loss:  0.18975815176963806
Epoch:  281  	Training Loss: 0.1931433081626892
Test Loss:  0.18847933411598206
Valid Loss:  0.18975389003753662
Epoch:  282  	Training Loss: 0.193138986825943
Test Loss:  0.18847520649433136
Valid Loss:  0.18974965810775757
Epoch:  283  	Training Loss: 0.19313469529151917
Test Loss:  0.18847107887268066
Valid Loss:  0.18974541127681732
Epoch:  284  	Training Loss: 0.19313037395477295
Test Loss:  0.18846696615219116
Valid Loss:  0.18974119424819946
Epoch:  285  	Training Loss: 0.19312608242034912
Test Loss:  0.18846283853054047
Valid Loss:  0.18973693251609802
Epoch:  286  	Training Loss: 0.1931217908859253
Test Loss:  0.18845872581005096
Valid Loss:  0.18973271548748016
Epoch:  287  	Training Loss: 0.19311748445034027
Test Loss:  0.18845459818840027
Valid Loss:  0.18972846865653992
Epoch:  288  	Training Loss: 0.19311320781707764
Test Loss:  0.18845048546791077
Valid Loss:  0.18972423672676086
Epoch:  289  	Training Loss: 0.19310888648033142
Test Loss:  0.18844637274742126
Valid Loss:  0.1897200047969818
Epoch:  290  	Training Loss: 0.1931045949459076
Test Loss:  0.18844226002693176
Valid Loss:  0.18971577286720276
Epoch:  291  	Training Loss: 0.19310030341148376
 58%|█████▊    | 291/500 [03:23<04:07,  1.18s/it] 59%|█████▊    | 293/500 [03:23<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:23<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:24<01:31,  2.21it/s] 60%|█████▉    | 299/500 [03:24<01:07,  2.97it/s] 60%|██████    | 301/500 [03:30<03:52,  1.17s/it] 61%|██████    | 303/500 [03:30<02:45,  1.19it/s] 61%|██████    | 305/500 [03:30<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:30<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:30<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:37<03:42,  1.18s/it] 63%|██████▎   | 313/500 [03:37<02:37,  1.18it/s] 63%|██████▎   | 315/500 [03:37<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:37<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:37<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:44<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:44<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:44<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:44<01:18,  2.22it/s] 66%|██████▌   | 329/500 [03:44<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:50<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:51<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:51<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:51<01:14,  2.20it/s] 68%|██████▊   | 339/500 [03:51<00:54,  2.96it/s] 68%|██████▊   | 341/500 [03:57<03:09,  1.19s/it] 69%|██████▊   | 343/500 [03:58<02:14,  1.17it/s] 69%|██████▉   | 345/500 [03:58<01:35,  1.62it/s] 69%|██████▉   | 347/500 [03:58<01:09,  2.22it/s] 70%|██████▉   | 349/500 [03:58<00:50,  2.98it/s] 70%|███████   | 351/500 [04:04<02:57,  1.19s/it] 71%|███████   | 353/500 [04:04<02:06,  1.17it/s] 71%|███████   | 355/500 [04:05<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:05<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:05<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:11<02:44,  1.18s/it]Test Loss:  0.18843813240528107
Valid Loss:  0.1897115260362625
Epoch:  292  	Training Loss: 0.19309601187705994
Test Loss:  0.18843404948711395
Valid Loss:  0.18970730900764465
Epoch:  293  	Training Loss: 0.1930917501449585
Test Loss:  0.18842995166778564
Valid Loss:  0.18970312178134918
Epoch:  294  	Training Loss: 0.19308747351169586
Test Loss:  0.18842585384845734
Valid Loss:  0.1896989345550537
Epoch:  295  	Training Loss: 0.19308319687843323
Test Loss:  0.18842178583145142
Valid Loss:  0.18969470262527466
Epoch:  296  	Training Loss: 0.1930789351463318
Test Loss:  0.1884176880121231
Valid Loss:  0.189690500497818
Epoch:  297  	Training Loss: 0.19307468831539154
Test Loss:  0.1884135901927948
Valid Loss:  0.18968629837036133
Epoch:  298  	Training Loss: 0.1930704116821289
Test Loss:  0.18840950727462769
Valid Loss:  0.18968211114406586
Epoch:  299  	Training Loss: 0.19306614995002747
Test Loss:  0.18840542435646057
Valid Loss:  0.18967792391777039
Epoch:  300  	Training Loss: 0.19306188821792603
Test Loss:  0.18840134143829346
Valid Loss:  0.18967370688915253
Epoch:  301  	Training Loss: 0.19305762648582458
Test Loss:  0.18839725852012634
Valid Loss:  0.18966948986053467
Epoch:  302  	Training Loss: 0.19305336475372314
Test Loss:  0.18839319050312042
Valid Loss:  0.18966533243656158
Epoch:  303  	Training Loss: 0.1930491328239441
Test Loss:  0.1883891373872757
Valid Loss:  0.1896611601114273
Epoch:  304  	Training Loss: 0.19304490089416504
Test Loss:  0.18838506937026978
Valid Loss:  0.18965698778629303
Epoch:  305  	Training Loss: 0.193040668964386
Test Loss:  0.18838103115558624
Valid Loss:  0.18965281546115875
Epoch:  306  	Training Loss: 0.19303643703460693
Test Loss:  0.18837696313858032
Valid Loss:  0.18964865803718567
Epoch:  307  	Training Loss: 0.19303220510482788
Test Loss:  0.1883729100227356
Valid Loss:  0.1896444708108902
Epoch:  308  	Training Loss: 0.19302797317504883
Test Loss:  0.18836884200572968
Valid Loss:  0.18964031338691711
Epoch:  309  	Training Loss: 0.19302374124526978
Test Loss:  0.18836480379104614
Valid Loss:  0.18963614106178284
Epoch:  310  	Training Loss: 0.19301950931549072
Test Loss:  0.18836073577404022
Valid Loss:  0.18963198363780975
Epoch:  311  	Training Loss: 0.19301530718803406
Test Loss:  0.1883566975593567
Valid Loss:  0.18962779641151428
Epoch:  312  	Training Loss: 0.193011075258255
Test Loss:  0.18835264444351196
Valid Loss:  0.1896236538887024
Epoch:  313  	Training Loss: 0.19300684332847595
Test Loss:  0.18834862112998962
Valid Loss:  0.1896195113658905
Epoch:  314  	Training Loss: 0.1930026412010193
Test Loss:  0.1883445680141449
Valid Loss:  0.18961535394191742
Epoch:  315  	Training Loss: 0.19299843907356262
Test Loss:  0.18834054470062256
Valid Loss:  0.18961121141910553
Epoch:  316  	Training Loss: 0.19299422204494476
Test Loss:  0.18833650648593903
Valid Loss:  0.18960705399513245
Epoch:  317  	Training Loss: 0.1929900199174881
Test Loss:  0.1883324682712555
Valid Loss:  0.18960291147232056
Epoch:  318  	Training Loss: 0.19298581779003143
Test Loss:  0.18832844495773315
Valid Loss:  0.18959876894950867
Epoch:  319  	Training Loss: 0.19298160076141357
Test Loss:  0.18832439184188843
Valid Loss:  0.18959461152553558
Epoch:  320  	Training Loss: 0.19297738373279572
Test Loss:  0.1883203685283661
Valid Loss:  0.1895904690027237
Epoch:  321  	Training Loss: 0.19297316670417786
Test Loss:  0.18831634521484375
Valid Loss:  0.1895863264799118
Epoch:  322  	Training Loss: 0.19296897947788239
Test Loss:  0.1883123219013214
Valid Loss:  0.1895821988582611
Epoch:  323  	Training Loss: 0.19296479225158691
Test Loss:  0.18830831348896027
Valid Loss:  0.1895781010389328
Epoch:  324  	Training Loss: 0.19296061992645264
Test Loss:  0.18830430507659912
Valid Loss:  0.1895739734172821
Epoch:  325  	Training Loss: 0.19295644760131836
Test Loss:  0.18830032646656036
Valid Loss:  0.1895698606967926
Epoch:  326  	Training Loss: 0.19295227527618408
Test Loss:  0.18829631805419922
Valid Loss:  0.1895657479763031
Epoch:  327  	Training Loss: 0.1929481029510498
Test Loss:  0.18829230964183807
Valid Loss:  0.1895616352558136
Epoch:  328  	Training Loss: 0.19294393062591553
Test Loss:  0.18828831613063812
Valid Loss:  0.1895575374364853
Epoch:  329  	Training Loss: 0.19293975830078125
Test Loss:  0.18828430771827698
Valid Loss:  0.1895534098148346
Epoch:  330  	Training Loss: 0.19293558597564697
Test Loss:  0.18828029930591583
Valid Loss:  0.1895492970943451
Epoch:  331  	Training Loss: 0.1929314136505127
Test Loss:  0.1882762908935547
Valid Loss:  0.1895451843738556
Epoch:  332  	Training Loss: 0.19292724132537842
Test Loss:  0.18827232718467712
Valid Loss:  0.18954110145568848
Epoch:  333  	Training Loss: 0.19292306900024414
Test Loss:  0.18826833367347717
Valid Loss:  0.18953700363636017
Epoch:  334  	Training Loss: 0.19291892647743225
Test Loss:  0.18826434016227722
Valid Loss:  0.18953292071819305
Epoch:  335  	Training Loss: 0.19291478395462036
Test Loss:  0.18826036155223846
Valid Loss:  0.18952880799770355
Epoch:  336  	Training Loss: 0.19291062653064728
Test Loss:  0.1882563829421997
Valid Loss:  0.18952472507953644
Epoch:  337  	Training Loss: 0.1929064691066742
Test Loss:  0.18825238943099976
Valid Loss:  0.18952062726020813
Epoch:  338  	Training Loss: 0.1929023265838623
Test Loss:  0.188248410820961
Valid Loss:  0.18951652944087982
Epoch:  339  	Training Loss: 0.19289818406105042
Test Loss:  0.18824443221092224
Valid Loss:  0.1895124316215515
Epoch:  340  	Training Loss: 0.19289402663707733
Test Loss:  0.1882404386997223
Valid Loss:  0.1895083487033844
Epoch:  341  	Training Loss: 0.19288986921310425
Test Loss:  0.18823646008968353
Valid Loss:  0.1895042508840561
Epoch:  342  	Training Loss: 0.19288571178913116
Test Loss:  0.18823251128196716
Valid Loss:  0.18950021266937256
Epoch:  343  	Training Loss: 0.19288158416748047
Test Loss:  0.188228577375412
Valid Loss:  0.18949615955352783
Epoch:  344  	Training Loss: 0.19287750124931335
Test Loss:  0.18822462856769562
Valid Loss:  0.1894921064376831
Epoch:  345  	Training Loss: 0.19287338852882385
Test Loss:  0.18822067975997925
Valid Loss:  0.18948805332183838
Epoch:  346  	Training Loss: 0.19286927580833435
Test Loss:  0.18821674585342407
Valid Loss:  0.18948400020599365
Epoch:  347  	Training Loss: 0.19286516308784485
Test Loss:  0.1882128119468689
Valid Loss:  0.18947994709014893
Epoch:  348  	Training Loss: 0.19286103546619415
Test Loss:  0.18820886313915253
Valid Loss:  0.1894758939743042
Epoch:  349  	Training Loss: 0.19285693764686584
Test Loss:  0.18820491433143616
Valid Loss:  0.18947185575962067
Epoch:  350  	Training Loss: 0.19285283982753754
Test Loss:  0.1882009655237198
Valid Loss:  0.18946780264377594
Epoch:  351  	Training Loss: 0.19284871220588684
Test Loss:  0.1881970465183258
Valid Loss:  0.1894637495279312
Epoch:  352  	Training Loss: 0.19284461438655853
Test Loss:  0.18819311261177063
Valid Loss:  0.18945972621440887
Epoch:  353  	Training Loss: 0.19284051656723022
Test Loss:  0.18818917870521545
Valid Loss:  0.18945568799972534
Epoch:  354  	Training Loss: 0.1928364336490631
Test Loss:  0.18818527460098267
Valid Loss:  0.1894516497850418
Epoch:  355  	Training Loss: 0.1928323209285736
Test Loss:  0.1881813257932663
Valid Loss:  0.18944762647151947
Epoch:  356  	Training Loss: 0.1928282380104065
Test Loss:  0.18817740678787231
Valid Loss:  0.18944358825683594
Epoch:  357  	Training Loss: 0.19282415509223938
Test Loss:  0.18817347288131714
Valid Loss:  0.1894395649433136
Epoch:  358  	Training Loss: 0.19282007217407227
Test Loss:  0.18816955387592316
Valid Loss:  0.18943552672863007
Epoch:  359  	Training Loss: 0.19281595945358276
Test Loss:  0.18816563487052917
Valid Loss:  0.18943148851394653
Epoch:  360  	Training Loss: 0.19281187653541565
Test Loss:  0.188161700963974
Valid Loss:  0.1894274652004242
Epoch:  361  	Training Loss: 0.19280779361724854
Test Loss:  0.1881577968597412
Valid Loss:  0.18942342698574066
Epoch:  362  	Training Loss: 0.19280371069908142
Test Loss:  0.18815389275550842
Valid Loss:  0.1894194334745407
Epoch:  363  	Training Loss: 0.1927996426820755
Test Loss:  0.18815001845359802
Valid Loss:   73%|███████▎  | 363/500 [04:11<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:11<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:12<00:43,  3.00it/s] 74%|███████▍  | 371/500 [04:18<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:18<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:18<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:19<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:25<02:18,  1.17s/it] 77%|███████▋  | 383/500 [04:25<01:37,  1.19it/s] 77%|███████▋  | 385/500 [04:25<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:25<00:49,  2.26it/s] 78%|███████▊  | 389/500 [04:25<00:36,  3.04it/s] 78%|███████▊  | 391/500 [04:32<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:32<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:32<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:32<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:32<00:33,  3.04it/s] 80%|████████  | 401/500 [04:38<01:56,  1.17s/it] 81%|████████  | 403/500 [04:38<01:21,  1.19it/s] 81%|████████  | 405/500 [04:39<00:58,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:45<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:45<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:45<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:46<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:52<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:52<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:52<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:52<00:32,  2.22it/s] 86%|████████▌ | 429/500 [04:53<00:23,  2.99it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.65it/s]0.18941542506217957
Epoch:  364  	Training Loss: 0.19279560446739197
Test Loss:  0.18814611434936523
Valid Loss:  0.189411461353302
Epoch:  365  	Training Loss: 0.19279153645038605
Test Loss:  0.18814222514629364
Valid Loss:  0.18940746784210205
Epoch:  366  	Training Loss: 0.19278749823570251
Test Loss:  0.18813833594322205
Valid Loss:  0.1894034743309021
Epoch:  367  	Training Loss: 0.1927834451198578
Test Loss:  0.18813444674015045
Valid Loss:  0.18939946591854095
Epoch:  368  	Training Loss: 0.19277939200401306
Test Loss:  0.18813055753707886
Valid Loss:  0.1893954575061798
Epoch:  369  	Training Loss: 0.19277533888816833
Test Loss:  0.18812668323516846
Valid Loss:  0.18939147889614105
Epoch:  370  	Training Loss: 0.1927712857723236
Test Loss:  0.18812277913093567
Valid Loss:  0.1893874704837799
Epoch:  371  	Training Loss: 0.19276723265647888
Test Loss:  0.18811890482902527
Valid Loss:  0.18938349187374115
Epoch:  372  	Training Loss: 0.19276317954063416
Test Loss:  0.18811503052711487
Valid Loss:  0.1893795281648636
Epoch:  373  	Training Loss: 0.19275915622711182
Test Loss:  0.18811118602752686
Valid Loss:  0.18937554955482483
Epoch:  374  	Training Loss: 0.19275513291358948
Test Loss:  0.18810731172561646
Valid Loss:  0.18937158584594727
Epoch:  375  	Training Loss: 0.19275110960006714
Test Loss:  0.18810345232486725
Valid Loss:  0.1893676370382309
Epoch:  376  	Training Loss: 0.1927470862865448
Test Loss:  0.18809959292411804
Valid Loss:  0.18936365842819214
Epoch:  377  	Training Loss: 0.19274306297302246
Test Loss:  0.18809573352336884
Valid Loss:  0.18935970962047577
Epoch:  378  	Training Loss: 0.19273903965950012
Test Loss:  0.18809187412261963
Valid Loss:  0.189355731010437
Epoch:  379  	Training Loss: 0.19273501634597778
Test Loss:  0.18808801472187042
Valid Loss:  0.18935176730155945
Epoch:  380  	Training Loss: 0.19273099303245544
Test Loss:  0.18808415532112122
Valid Loss:  0.18934780359268188
Epoch:  381  	Training Loss: 0.1927269697189331
Test Loss:  0.18808028101921082
Valid Loss:  0.18934383988380432
Epoch:  382  	Training Loss: 0.19272294640541077
Test Loss:  0.188076451420784
Valid Loss:  0.18933992087841034
Epoch:  383  	Training Loss: 0.19271895289421082
Test Loss:  0.18807262182235718
Valid Loss:  0.18933598697185516
Epoch:  384  	Training Loss: 0.19271495938301086
Test Loss:  0.18806880712509155
Valid Loss:  0.1893320381641388
Epoch:  385  	Training Loss: 0.1927109658718109
Test Loss:  0.18806496262550354
Valid Loss:  0.18932810425758362
Epoch:  386  	Training Loss: 0.19270697236061096
Test Loss:  0.18806111812591553
Valid Loss:  0.18932417035102844
Epoch:  387  	Training Loss: 0.192702978849411
Test Loss:  0.1880573034286499
Valid Loss:  0.18932025134563446
Epoch:  388  	Training Loss: 0.19269900023937225
Test Loss:  0.18805347383022308
Valid Loss:  0.1893163025379181
Epoch:  389  	Training Loss: 0.1926950067281723
Test Loss:  0.18804964423179626
Valid Loss:  0.18931236863136292
Epoch:  390  	Training Loss: 0.19269101321697235
Test Loss:  0.18804579973220825
Valid Loss:  0.18930844962596893
Epoch:  391  	Training Loss: 0.1926870197057724
Test Loss:  0.18804198503494263
Valid Loss:  0.18930450081825256
Epoch:  392  	Training Loss: 0.19268304109573364
Test Loss:  0.188038170337677
Valid Loss:  0.18930059671401978
Epoch:  393  	Training Loss: 0.19267907738685608
Test Loss:  0.18803437054157257
Valid Loss:  0.189296692609787
Epoch:  394  	Training Loss: 0.19267511367797852
Test Loss:  0.18803057074546814
Valid Loss:  0.1892927885055542
Epoch:  395  	Training Loss: 0.19267114996910095
Test Loss:  0.18802675604820251
Valid Loss:  0.1892888844013214
Epoch:  396  	Training Loss: 0.1926671862602234
Test Loss:  0.1880229413509369
Valid Loss:  0.18928498029708862
Epoch:  397  	Training Loss: 0.19266322255134583
Test Loss:  0.18801915645599365
Valid Loss:  0.18928106129169464
Epoch:  398  	Training Loss: 0.19265925884246826
Test Loss:  0.18801534175872803
Valid Loss:  0.18927717208862305
Epoch:  399  	Training Loss: 0.1926552951335907
Test Loss:  0.1880115419626236
Valid Loss:  0.18927325308322906
Epoch:  400  	Training Loss: 0.19265133142471313
Test Loss:  0.18800774216651917
Valid Loss:  0.18926934897899628
Epoch:  401  	Training Loss: 0.19264736771583557
Test Loss:  0.18800392746925354
Valid Loss:  0.1892654448747635
Epoch:  402  	Training Loss: 0.192643404006958
Test Loss:  0.1880001425743103
Valid Loss:  0.18926158547401428
Epoch:  403  	Training Loss: 0.19263947010040283
Test Loss:  0.18799638748168945
Valid Loss:  0.1892576813697815
Epoch:  404  	Training Loss: 0.19263553619384766
Test Loss:  0.1879926174879074
Valid Loss:  0.18925383687019348
Epoch:  405  	Training Loss: 0.19263161718845367
Test Loss:  0.18798884749412537
Valid Loss:  0.18924996256828308
Epoch:  406  	Training Loss: 0.1926276832818985
Test Loss:  0.18798506259918213
Valid Loss:  0.18924608826637268
Epoch:  407  	Training Loss: 0.19262376427650452
Test Loss:  0.18798129260540009
Valid Loss:  0.18924221396446228
Epoch:  408  	Training Loss: 0.19261981546878815
Test Loss:  0.18797752261161804
Valid Loss:  0.18923833966255188
Epoch:  409  	Training Loss: 0.19261589646339417
Test Loss:  0.187973752617836
Valid Loss:  0.18923446536064148
Epoch:  410  	Training Loss: 0.192611962556839
Test Loss:  0.18796996772289276
Valid Loss:  0.18923059105873108
Epoch:  411  	Training Loss: 0.192608043551445
Test Loss:  0.18796619772911072
Valid Loss:  0.18922671675682068
Epoch:  412  	Training Loss: 0.19260410964488983
Test Loss:  0.18796242773532867
Valid Loss:  0.18922285735607147
Epoch:  413  	Training Loss: 0.19260019063949585
Test Loss:  0.18795867264270782
Valid Loss:  0.18921899795532227
Epoch:  414  	Training Loss: 0.19259625673294067
Test Loss:  0.18795490264892578
Valid Loss:  0.18921512365341187
Epoch:  415  	Training Loss: 0.19259235262870789
Test Loss:  0.18795114755630493
Valid Loss:  0.18921127915382385
Epoch:  416  	Training Loss: 0.1925884187221527
Test Loss:  0.18794739246368408
Valid Loss:  0.18920740485191345
Epoch:  417  	Training Loss: 0.19258451461791992
Test Loss:  0.18794360756874084
Valid Loss:  0.18920354545116425
Epoch:  418  	Training Loss: 0.19258061051368713
Test Loss:  0.18793985247612
Valid Loss:  0.18919968605041504
Epoch:  419  	Training Loss: 0.19257667660713196
Test Loss:  0.18793608248233795
Valid Loss:  0.18919581174850464
Epoch:  420  	Training Loss: 0.19257275760173798
Test Loss:  0.1879323422908783
Valid Loss:  0.18919196724891663
Epoch:  421  	Training Loss: 0.1925688534975052
Test Loss:  0.18792855739593506
Valid Loss:  0.18918810784816742
Epoch:  422  	Training Loss: 0.1925649344921112
Test Loss:  0.1879248321056366
Valid Loss:  0.1891842782497406
Epoch:  423  	Training Loss: 0.1925610452890396
Test Loss:  0.18792110681533813
Valid Loss:  0.18918046355247498
Epoch:  424  	Training Loss: 0.1925571709871292
Test Loss:  0.18791738152503967
Valid Loss:  0.18917664885520935
Epoch:  425  	Training Loss: 0.19255328178405762
Test Loss:  0.1879136562347412
Valid Loss:  0.18917280435562134
Epoch:  426  	Training Loss: 0.19254940748214722
Test Loss:  0.18790991604328156
Valid Loss:  0.1891689896583557
Epoch:  427  	Training Loss: 0.19254553318023682
Test Loss:  0.1879062056541443
Valid Loss:  0.1891651600599289
Epoch:  428  	Training Loss: 0.19254164397716522
Test Loss:  0.18790246546268463
Valid Loss:  0.18916133046150208
Epoch:  429  	Training Loss: 0.19253775477409363
Test Loss:  0.18789875507354736
Valid Loss:  0.18915751576423645
Epoch:  430  	Training Loss: 0.19253388047218323
Test Loss:  0.1878950148820877
Valid Loss:  0.18915370106697083
Epoch:  431  	Training Loss: 0.19253000617027283
Test Loss:  0.18789128959178925
Valid Loss:  0.1891498565673828
Epoch:  432  	Training Loss: 0.19252613186836243
Test Loss:  0.18788760900497437
Valid Loss:  0.18914608657360077
Epoch:  433  	Training Loss: 0.19252228736877441
Test Loss:  0.18788392841815948
Valid Loss:  0.18914230167865753
Epoch:  434  	Training Loss: 0.1925184577703476
Test Loss:  0.1878802478313446
Valid Loss:  0.1891385316848755
Epoch:  435  	Training Loss: 0.19251462817192078
Test Loss:  0.18787655234336853
Valid Loss:  0.18913474678993225
 87%|████████▋ | 437/500 [04:59<00:27,  2.26it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.04it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:06<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:13<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:13<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:13<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:19<00:46,  1.18s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:26<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:27<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.19s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:34<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.20s/it] 99%|█████████▊| 493/500 [05:40<00:06,  1.16it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.61it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.19it/s]100%|█████████▉| 499/500 [05:41<00:00,  2.93it/s]100%|██████████| 500/500 [05:41<00:00,  1.47it/s]
Epoch:  436  	Training Loss: 0.19251078367233276
Test Loss:  0.18787285685539246
Valid Loss:  0.189130961894989
Epoch:  437  	Training Loss: 0.19250693917274475
Test Loss:  0.18786919116973877
Valid Loss:  0.18912717700004578
Epoch:  438  	Training Loss: 0.19250309467315674
Test Loss:  0.1878654956817627
Valid Loss:  0.18912340700626373
Epoch:  439  	Training Loss: 0.19249926507472992
Test Loss:  0.18786181509494781
Valid Loss:  0.1891196370124817
Epoch:  440  	Training Loss: 0.1924954354763031
Test Loss:  0.18785810470581055
Valid Loss:  0.18911585211753845
Epoch:  441  	Training Loss: 0.1924915909767151
Test Loss:  0.18785443902015686
Valid Loss:  0.18911203742027283
Epoch:  442  	Training Loss: 0.19248774647712708
Test Loss:  0.18785077333450317
Valid Loss:  0.18910829722881317
Epoch:  443  	Training Loss: 0.19248394668102264
Test Loss:  0.1878471076488495
Valid Loss:  0.18910455703735352
Epoch:  444  	Training Loss: 0.1924801468849182
Test Loss:  0.1878434419631958
Valid Loss:  0.18910080194473267
Epoch:  445  	Training Loss: 0.1924763172864914
Test Loss:  0.18783977627754211
Valid Loss:  0.18909701704978943
Epoch:  446  	Training Loss: 0.19247251749038696
Test Loss:  0.18783614039421082
Valid Loss:  0.18909326195716858
Epoch:  447  	Training Loss: 0.19246870279312134
Test Loss:  0.18783247470855713
Valid Loss:  0.18908952176570892
Epoch:  448  	Training Loss: 0.1924648880958557
Test Loss:  0.18782880902290344
Valid Loss:  0.18908576667308807
Epoch:  449  	Training Loss: 0.19246108829975128
Test Loss:  0.18782515823841095
Valid Loss:  0.18908202648162842
Epoch:  450  	Training Loss: 0.19245727360248566
Test Loss:  0.18782147765159607
Valid Loss:  0.18907827138900757
Epoch:  451  	Training Loss: 0.19245347380638123
Test Loss:  0.18781782686710358
Valid Loss:  0.18907450139522552
Epoch:  452  	Training Loss: 0.1924496591091156
Test Loss:  0.18781420588493347
Valid Loss:  0.18907079100608826
Epoch:  453  	Training Loss: 0.19244588911533356
Test Loss:  0.18781058490276337
Valid Loss:  0.1890670657157898
Epoch:  454  	Training Loss: 0.19244210422039032
Test Loss:  0.18780693411827087
Valid Loss:  0.18906334042549133
Epoch:  455  	Training Loss: 0.19243833422660828
Test Loss:  0.18780332803726196
Valid Loss:  0.18905961513519287
Epoch:  456  	Training Loss: 0.19243454933166504
Test Loss:  0.18779970705509186
Valid Loss:  0.1890559196472168
Epoch:  457  	Training Loss: 0.1924307942390442
Test Loss:  0.18779605627059937
Valid Loss:  0.18905219435691833
Epoch:  458  	Training Loss: 0.19242700934410095
Test Loss:  0.18779245018959045
Valid Loss:  0.18904846906661987
Epoch:  459  	Training Loss: 0.19242322444915771
Test Loss:  0.18778881430625916
Valid Loss:  0.1890447437763214
Epoch:  460  	Training Loss: 0.19241945445537567
Test Loss:  0.18778519332408905
Valid Loss:  0.18904103338718414
Epoch:  461  	Training Loss: 0.19241568446159363
Test Loss:  0.18778157234191895
Valid Loss:  0.18903730809688568
Epoch:  462  	Training Loss: 0.1924118995666504
Test Loss:  0.18777793645858765
Valid Loss:  0.1890336126089096
Epoch:  463  	Training Loss: 0.19240814447402954
Test Loss:  0.18777433037757874
Valid Loss:  0.18902990221977234
Epoch:  464  	Training Loss: 0.1924043893814087
Test Loss:  0.18777072429656982
Valid Loss:  0.18902619183063507
Epoch:  465  	Training Loss: 0.19240063428878784
Test Loss:  0.18776708841323853
Valid Loss:  0.1890224814414978
Epoch:  466  	Training Loss: 0.192396879196167
Test Loss:  0.18776348233222961
Valid Loss:  0.18901878595352173
Epoch:  467  	Training Loss: 0.19239310920238495
Test Loss:  0.1877598762512207
Valid Loss:  0.18901507556438446
Epoch:  468  	Training Loss: 0.1923893392086029
Test Loss:  0.1877562552690506
Valid Loss:  0.1890113651752472
Epoch:  469  	Training Loss: 0.19238558411598206
Test Loss:  0.1877526342868805
Valid Loss:  0.18900766968727112
Epoch:  470  	Training Loss: 0.1923818141222
Test Loss:  0.18774902820587158
Valid Loss:  0.18900394439697266
Epoch:  471  	Training Loss: 0.19237805902957916
Test Loss:  0.18774542212486267
Valid Loss:  0.18900024890899658
Epoch:  472  	Training Loss: 0.1923743039369583
Test Loss:  0.18774184584617615
Valid Loss:  0.1889965832233429
Epoch:  473  	Training Loss: 0.19237056374549866
Test Loss:  0.18773825466632843
Valid Loss:  0.18899290263652802
Epoch:  474  	Training Loss: 0.1923668384552002
Test Loss:  0.1877346634864807
Valid Loss:  0.18898922204971313
Epoch:  475  	Training Loss: 0.19236311316490173
Test Loss:  0.1877310872077942
Valid Loss:  0.18898555636405945
Epoch:  476  	Training Loss: 0.19235938787460327
Test Loss:  0.18772748112678528
Valid Loss:  0.18898189067840576
Epoch:  477  	Training Loss: 0.1923556625843048
Test Loss:  0.18772391974925995
Valid Loss:  0.18897821009159088
Epoch:  478  	Training Loss: 0.19235193729400635
Test Loss:  0.18772032856941223
Valid Loss:  0.188974529504776
Epoch:  479  	Training Loss: 0.19234821200370789
Test Loss:  0.1877167522907257
Valid Loss:  0.18897086381912231
Epoch:  480  	Training Loss: 0.19234447181224823
Test Loss:  0.1877131462097168
Valid Loss:  0.18896718323230743
Epoch:  481  	Training Loss: 0.19234074652194977
Test Loss:  0.18770956993103027
Valid Loss:  0.18896350264549255
Epoch:  482  	Training Loss: 0.1923370063304901
Test Loss:  0.18770602345466614
Valid Loss:  0.18895985186100006
Epoch:  483  	Training Loss: 0.19233331084251404
Test Loss:  0.1877024620771408
Valid Loss:  0.18895620107650757
Epoch:  484  	Training Loss: 0.19232961535453796
Test Loss:  0.18769890069961548
Valid Loss:  0.18895256519317627
Epoch:  485  	Training Loss: 0.1923259198665619
Test Loss:  0.18769535422325134
Valid Loss:  0.18894892930984497
Epoch:  486  	Training Loss: 0.19232220947742462
Test Loss:  0.187691792845726
Valid Loss:  0.18894527852535248
Epoch:  487  	Training Loss: 0.19231851398944855
Test Loss:  0.18768823146820068
Valid Loss:  0.18894162774085999
Epoch:  488  	Training Loss: 0.19231480360031128
Test Loss:  0.18768467009067535
Valid Loss:  0.1889379769563675
Epoch:  489  	Training Loss: 0.1923111081123352
Test Loss:  0.18768110871315002
Valid Loss:  0.188934326171875
Epoch:  490  	Training Loss: 0.19230741262435913
Test Loss:  0.1876775622367859
Valid Loss:  0.1889306902885437
Epoch:  491  	Training Loss: 0.19230371713638306
Test Loss:  0.18767400085926056
Valid Loss:  0.1889270544052124
Epoch:  492  	Training Loss: 0.19230002164840698
Test Loss:  0.18767046928405762
Valid Loss:  0.1889234185218811
Epoch:  493  	Training Loss: 0.1922963410615921
Test Loss:  0.18766692280769348
Valid Loss:  0.188919797539711
Epoch:  494  	Training Loss: 0.19229266047477722
Test Loss:  0.18766339123249054
Valid Loss:  0.1889161765575409
Epoch:  495  	Training Loss: 0.19228899478912354
Test Loss:  0.1876598596572876
Valid Loss:  0.1889125555753708
Epoch:  496  	Training Loss: 0.19228531420230865
Test Loss:  0.18765631318092346
Valid Loss:  0.18890893459320068
Epoch:  497  	Training Loss: 0.19228163361549377
Test Loss:  0.1876527965068817
Valid Loss:  0.18890532851219177
Epoch:  498  	Training Loss: 0.1922779679298401
Test Loss:  0.18764925003051758
Valid Loss:  0.18890169262886047
Epoch:  499  	Training Loss: 0.192274272441864
Test Loss:  0.18764571845531464
Valid Loss:  0.18889805674552917
Epoch:  500  	Training Loss: 0.19227060675621033
Test Loss:  0.1876421868801117
Valid Loss:  0.18889445066452026
seed is  12
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:00,  6.25s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:13,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<10:42,  1.31s/it]  3%|▎         | 13/500 [00:13<07:18,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:49,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.21it/s]  6%|▌         | 29/500 [00:20<02:37,  2.98it/s]  6%|▌         | 31/500 [00:26<09:16,  1.19s/it]  7%|▋         | 33/500 [00:26<06:37,  1.17it/s]  7%|▋         | 35/500 [00:27<04:46,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<08:59,  1.18s/it]  9%|▊         | 43/500 [00:33<06:25,  1.18it/s]  9%|▉         | 45/500 [00:33<04:38,  1.64it/s]  9%|▉         | 47/500 [00:33<03:23,  2.23it/s] 10%|▉         | 49/500 [00:34<02:31,  2.97it/s] 10%|█         | 51/500 [00:40<08:57,  1.20s/it] 11%|█         | 53/500 [00:40<06:24,  1.16it/s] 11%|█         | 55/500 [00:40<04:36,  1.61it/s] 11%|█▏        | 57/500 [00:40<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.95it/s] 12%|█▏        | 61/500 [00:47<08:39,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.62it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.22it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.99it/s]Epoch:  1  	Training Loss: 0.19500894844532013
Test Loss:  0.8254742622375488
Valid Loss:  0.819623589515686
Epoch:  2  	Training Loss: 0.8134691715240479
Test Loss:  1.3965857028961182
Valid Loss:  1.4537301063537598
Epoch:  3  	Training Loss: 1.4737818241119385
Test Loss:  0.4643763303756714
Valid Loss:  0.46459484100341797
Epoch:  4  	Training Loss: 0.4609106779098511
Test Loss:  0.28703466057777405
Valid Loss:  0.28898823261260986
Epoch:  5  	Training Loss: 0.28197190165519714
Test Loss:  0.2090783268213272
Valid Loss:  0.2146081179380417
Epoch:  6  	Training Loss: 0.20582786202430725
Test Loss:  0.16718342900276184
Valid Loss:  0.1758190542459488
Epoch:  7  	Training Loss: 0.166336789727211
Test Loss:  0.14484497904777527
Valid Loss:  0.15602834522724152
Epoch:  8  	Training Loss: 0.146121084690094
Test Loss:  0.13152071833610535
Valid Loss:  0.14451304078102112
Epoch:  9  	Training Loss: 0.1341904103755951
Test Loss:  0.12195497006177902
Valid Loss:  0.13610339164733887
Epoch:  10  	Training Loss: 0.12570181488990784
Test Loss:  0.11445300281047821
Valid Loss:  0.12943637371063232
Epoch:  11  	Training Loss: 0.11911722272634506
Test Loss:  0.10832390934228897
Valid Loss:  0.12390194088220596
Epoch:  12  	Training Loss: 0.11375854164361954
Test Loss:  0.03651459515094757
Valid Loss:  0.047093138098716736
Epoch:  13  	Training Loss: 0.042519461363554
Test Loss:  0.026286277920007706
Valid Loss:  0.032405003905296326
Epoch:  14  	Training Loss: 0.02969376929104328
Test Loss:  0.021874360740184784
Valid Loss:  0.026790348812937737
Epoch:  15  	Training Loss: 0.02461611106991768
Test Loss:  0.018525607883930206
Valid Loss:  0.02288861945271492
Epoch:  16  	Training Loss: 0.020875360816717148
Test Loss:  0.016645003110170364
Valid Loss:  0.020892111584544182
Epoch:  17  	Training Loss: 0.01885172724723816
Test Loss:  0.015454849228262901
Valid Loss:  0.019528226926922798
Epoch:  18  	Training Loss: 0.01755504123866558
Test Loss:  0.014430288225412369
Valid Loss:  0.018298031762242317
Epoch:  19  	Training Loss: 0.016444848850369453
Test Loss:  0.013513628393411636
Valid Loss:  0.017178062349557877
Epoch:  20  	Training Loss: 0.015444407239556313
Test Loss:  0.012698457576334476
Valid Loss:  0.01613691635429859
Epoch:  21  	Training Loss: 0.014520185999572277
Test Loss:  0.011962678283452988
Valid Loss:  0.015182269737124443
Epoch:  22  	Training Loss: 0.013681052252650261
Test Loss:  0.009269867092370987
Valid Loss:  0.011576484888792038
Epoch:  23  	Training Loss: 0.010686639696359634
Test Loss:  0.0074663651175796986
Valid Loss:  0.009199416264891624
Epoch:  24  	Training Loss: 0.00846702978014946
Test Loss:  0.0052491347305476665
Valid Loss:  0.006209851708263159
Epoch:  25  	Training Loss: 0.005843741353601217
Test Loss:  0.003401347668841481
Valid Loss:  0.004073945805430412
Epoch:  26  	Training Loss: 0.0038233003579080105
Test Loss:  0.0022963397204875946
Valid Loss:  0.002801010850816965
Epoch:  27  	Training Loss: 0.002620686311274767
Test Loss:  0.0016656401567161083
Valid Loss:  0.0020765825174748898
Epoch:  28  	Training Loss: 0.0019366375636309385
Test Loss:  0.0012995472643524408
Valid Loss:  0.0016406953800469637
Epoch:  29  	Training Loss: 0.0015278278151527047
Test Loss:  0.001076872693374753
Valid Loss:  0.0013729328056797385
Epoch:  30  	Training Loss: 0.0012781561817973852
Test Loss:  0.0009329310269095004
Valid Loss:  0.001190224546007812
Epoch:  31  	Training Loss: 0.0011135165113955736
Test Loss:  0.0008300645276904106
Valid Loss:  0.0010643703863024712
Epoch:  32  	Training Loss: 0.0010005178628489375
Test Loss:  0.0006826033350080252
Valid Loss:  0.0009153920109383762
Epoch:  33  	Training Loss: 0.0008706322405487299
Test Loss:  0.0006527563091367483
Valid Loss:  0.000830955570563674
Epoch:  34  	Training Loss: 0.0008093992946669459
Test Loss:  0.0006057728896848857
Valid Loss:  0.0007922931108623743
Epoch:  35  	Training Loss: 0.0007778896833769977
Test Loss:  0.0006001758156344295
Valid Loss:  0.0007642005803063512
Epoch:  36  	Training Loss: 0.0007594313938170671
Test Loss:  0.00057863665279001
Valid Loss:  0.0007483436493203044
Epoch:  37  	Training Loss: 0.00074717216193676
Test Loss:  0.000574454024899751
Valid Loss:  0.0007337774732150137
Epoch:  38  	Training Loss: 0.0007378732552751899
Test Loss:  0.0005612552631646395
Valid Loss:  0.0007231765193864703
Epoch:  39  	Training Loss: 0.0007296998519450426
Test Loss:  0.0005561878206208348
Valid Loss:  0.0007127485005185008
Epoch:  40  	Training Loss: 0.0007222126005217433
Test Loss:  0.0005472778575494885
Valid Loss:  0.0007047875551506877
Epoch:  41  	Training Loss: 0.0007154276827350259
Test Loss:  0.0005428580334410071
Valid Loss:  0.0006976769072934985
Epoch:  42  	Training Loss: 0.0007096765330061316
Test Loss:  0.0005253407871350646
Valid Loss:  0.0006778968963772058
Epoch:  43  	Training Loss: 0.000691205495968461
Test Loss:  0.0005095002707093954
Valid Loss:  0.0006623620865866542
Epoch:  44  	Training Loss: 0.0006760222604498267
Test Loss:  0.0004973153118044138
Valid Loss:  0.0006480058655142784
Epoch:  45  	Training Loss: 0.0006623439840041101
Test Loss:  0.0004848238895647228
Valid Loss:  0.0006345177534967661
Epoch:  46  	Training Loss: 0.0006495004054158926
Test Loss:  0.000473815540317446
Valid Loss:  0.0006216996116563678
Epoch:  47  	Training Loss: 0.0006375787197612226
Test Loss:  0.0004632831842172891
Valid Loss:  0.0006099253660067916
Epoch:  48  	Training Loss: 0.0006266429554671049
Test Loss:  0.00045360042713582516
Valid Loss:  0.0005991228390485048
Epoch:  49  	Training Loss: 0.0006167018436826766
Test Loss:  0.000444466044427827
Valid Loss:  0.0005888809682801366
Epoch:  50  	Training Loss: 0.0006073116674087942
Test Loss:  0.00043617974733933806
Valid Loss:  0.0005791228613816202
Epoch:  51  	Training Loss: 0.0005985455354675651
Test Loss:  0.0004286156326998025
Valid Loss:  0.0005700222682207823
Epoch:  52  	Training Loss: 0.0005906105507165194
Test Loss:  0.0003800683480221778
Valid Loss:  0.000538696302101016
Epoch:  53  	Training Loss: 0.0005604566540569067
Test Loss:  0.000373351969756186
Valid Loss:  0.000511885154992342
Epoch:  54  	Training Loss: 0.0005355689208954573
Test Loss:  0.0003460937296040356
Valid Loss:  0.0004917806945741177
Epoch:  55  	Training Loss: 0.0005144893657416105
Test Loss:  0.00033949746284633875
Valid Loss:  0.0004731612862087786
Epoch:  56  	Training Loss: 0.0004958024946972728
Test Loss:  0.00032238088897429407
Valid Loss:  0.0004570955061353743
Epoch:  57  	Training Loss: 0.000479016947792843
Test Loss:  0.00031392910750582814
Valid Loss:  0.00044259836431592703
Epoch:  58  	Training Loss: 0.0004637438978534192
Test Loss:  0.0003036002453882247
Valid Loss:  0.0004301216686144471
Epoch:  59  	Training Loss: 0.0004502431256696582
Test Loss:  0.000297208724077791
Valid Loss:  0.00042015244252979755
Epoch:  60  	Training Loss: 0.0004392688279040158
Test Loss:  0.0002898618404287845
Valid Loss:  0.00041253172094002366
Epoch:  61  	Training Loss: 0.000430057174526155
Test Loss:  0.000284531619399786
Valid Loss:  0.0004056316684000194
Epoch:  62  	Training Loss: 0.0004220436094328761
Test Loss:  0.0002899740356951952
Valid Loss:  0.0003967017401009798
Epoch:  63  	Training Loss: 0.00041507044807076454
Test Loss:  0.00029026117408648133
Valid Loss:  0.0003939367306884378
Epoch:  64  	Training Loss: 0.00041300070006400347
Test Loss:  0.0002889773459173739
Valid Loss:  0.00039165146881714463
Epoch:  65  	Training Loss: 0.00041120871901512146
Test Loss:  0.00028748903423547745
Valid Loss:  0.000389556516893208
Epoch:  66  	Training Loss: 0.0004095355106983334
Test Loss:  0.0002860822423826903
Valid Loss:  0.00038779625901952386
Epoch:  67  	Training Loss: 0.00040810159407556057
Test Loss:  0.00028479311731643975
Valid Loss:  0.0003862529410980642
Epoch:  68  	Training Loss: 0.00040687332511879504
Test Loss:  0.0002836327184922993
Valid Loss:  0.00038484419928863645
Epoch:  69  	Training Loss: 0.0004058150516357273
Test Loss:  0.00028256792575120926
Valid Loss:  0.0003835315874312073
Epoch:  70  	Training Loss: 0.00040488800732418895
Test Loss:  0.0002816763299051672
Valid Loss:  0.000382367754355073
 14%|█▍        | 71/500 [00:54<08:27,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:02,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:21,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:01<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:01<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:03,  2.25it/s] 18%|█▊        | 89/500 [01:01<02:15,  3.02it/s] 18%|█▊        | 91/500 [01:07<08:00,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:43,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:07,  1.64it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:44,  1.16s/it] 21%|██        | 103/500 [01:14<05:31,  1.20it/s] 21%|██        | 105/500 [01:14<03:58,  1.65it/s] 21%|██▏       | 107/500 [01:14<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:15<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:21<07:35,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:28<07:21,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:15,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:34<07:13,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:09,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.24it/s]Epoch:  71  	Training Loss: 0.0004040814528707415
Test Loss:  0.0002808876452036202
Valid Loss:  0.0003813668736256659
Epoch:  72  	Training Loss: 0.0004033322329632938
Test Loss:  0.0002779701608233154
Valid Loss:  0.0003770848852582276
Epoch:  73  	Training Loss: 0.00039971625665202737
Test Loss:  0.0002755748573690653
Valid Loss:  0.00037545792292803526
Epoch:  74  	Training Loss: 0.00039876799564808607
Test Loss:  0.0002746348618529737
Valid Loss:  0.0003744117566384375
Epoch:  75  	Training Loss: 0.00039825623389333487
Test Loss:  0.0002739896881394088
Valid Loss:  0.00037378157139755785
Epoch:  76  	Training Loss: 0.00039801880484446883
Test Loss:  0.00027352210599929094
Valid Loss:  0.0003733574412763119
Epoch:  77  	Training Loss: 0.00039788419962860644
Test Loss:  0.00027327248244546354
Valid Loss:  0.0003730208263732493
Epoch:  78  	Training Loss: 0.00039779063081368804
Test Loss:  0.00027303610113449395
Valid Loss:  0.0003727549337781966
Epoch:  79  	Training Loss: 0.00039773213211447
Test Loss:  0.00027282044175080955
Valid Loss:  0.00037254777271300554
Epoch:  80  	Training Loss: 0.00039769598515704274
Test Loss:  0.00027265894459560513
Valid Loss:  0.00037237798096612096
Epoch:  81  	Training Loss: 0.00039766880217939615
Test Loss:  0.0002725533558987081
Valid Loss:  0.00037222448736429214
Epoch:  82  	Training Loss: 0.00039764633402228355
Test Loss:  0.00025117071345448494
Valid Loss:  0.00035654802923090756
Epoch:  83  	Training Loss: 0.00038380103069357574
Test Loss:  0.0002441461547277868
Valid Loss:  0.0003424761234782636
Epoch:  84  	Training Loss: 0.00037181650986894965
Test Loss:  0.0002339684870094061
Valid Loss:  0.0003295818460173905
Epoch:  85  	Training Loss: 0.00036052113864570856
Test Loss:  0.00022465668735094368
Valid Loss:  0.00031744761508889496
Epoch:  86  	Training Loss: 0.0003503659972921014
Test Loss:  0.00021551217650994658
Valid Loss:  0.00030580186285078526
Epoch:  87  	Training Loss: 0.00034109107218682766
Test Loss:  0.00020775047596544027
Valid Loss:  0.00029549477039836347
Epoch:  88  	Training Loss: 0.00033226440427824855
Test Loss:  0.00020006560953333974
Valid Loss:  0.00028604138060472906
Epoch:  89  	Training Loss: 0.0003233386669307947
Test Loss:  0.00019326870096847415
Valid Loss:  0.0002775600296445191
Epoch:  90  	Training Loss: 0.00031478144228458405
Test Loss:  0.00018669958808459342
Valid Loss:  0.00026797072496265173
Epoch:  91  	Training Loss: 0.0003055867273360491
Test Loss:  0.00017958716489374638
Valid Loss:  0.00025808607460930943
Epoch:  92  	Training Loss: 0.0002963151491712779
Test Loss:  0.0001790363749023527
Valid Loss:  0.00025597497005946934
Epoch:  93  	Training Loss: 0.0002931425115093589
Test Loss:  0.00017744061187840998
Valid Loss:  0.00025397271383553743
Epoch:  94  	Training Loss: 0.00029026062111370265
Test Loss:  0.00017672347894404083
Valid Loss:  0.00025225768331438303
Epoch:  95  	Training Loss: 0.00028781566652469337
Test Loss:  0.00017604909953661263
Valid Loss:  0.0002507889876142144
Epoch:  96  	Training Loss: 0.0002857621293514967
Test Loss:  0.00017521045811008662
Valid Loss:  0.0002493933425284922
Epoch:  97  	Training Loss: 0.0002838816144503653
Test Loss:  0.00017475479398854077
Valid Loss:  0.00024816839140839875
Epoch:  98  	Training Loss: 0.0002822932437993586
Test Loss:  0.00017426797421649098
Valid Loss:  0.00024706340627744794
Epoch:  99  	Training Loss: 0.00028089250554330647
Test Loss:  0.00017370075511280447
Valid Loss:  0.0002459938987158239
Epoch:  100  	Training Loss: 0.0002795886539388448
Test Loss:  0.00017321767518296838
Valid Loss:  0.00024497215053997934
Epoch:  101  	Training Loss: 0.0002783923118840903
Test Loss:  0.00017295638099312782
Valid Loss:  0.00024407211458310485
Epoch:  102  	Training Loss: 0.00027735502226278186
Test Loss:  0.00016657239757478237
Valid Loss:  0.00023554320796392858
Epoch:  103  	Training Loss: 0.0002692905836738646
Test Loss:  0.00016104261158034205
Valid Loss:  0.0002272986457683146
Epoch:  104  	Training Loss: 0.00026183994486927986
Test Loss:  0.00015606525994371623
Valid Loss:  0.00021989519882481545
Epoch:  105  	Training Loss: 0.00025476180599071085
Test Loss:  0.0001515892072347924
Valid Loss:  0.00021382051636464894
Epoch:  106  	Training Loss: 0.00024855005904100835
Test Loss:  0.00014694200945086777
Valid Loss:  0.0002072650531772524
Epoch:  107  	Training Loss: 0.0002424317062832415
Test Loss:  0.00014224238111637533
Valid Loss:  0.00019986205734312534
Epoch:  108  	Training Loss: 0.0002364533138461411
Test Loss:  0.00013804930495098233
Valid Loss:  0.00019340758444741368
Epoch:  109  	Training Loss: 0.00023111511836759746
Test Loss:  0.00013433456479106098
Valid Loss:  0.00018770343740470707
Epoch:  110  	Training Loss: 0.00022621337848249823
Test Loss:  0.00013081601355224848
Valid Loss:  0.00018242697115056217
Epoch:  111  	Training Loss: 0.0002214720007032156
Test Loss:  0.00012708280701190233
Valid Loss:  0.00017755462613422424
Epoch:  112  	Training Loss: 0.00021692979498766363
Test Loss:  0.00012925892951898277
Valid Loss:  0.00017727765953168273
Epoch:  113  	Training Loss: 0.0002148798666894436
Test Loss:  0.00012851365318056196
Valid Loss:  0.00017646745254751295
Epoch:  114  	Training Loss: 0.00021335724159143865
Test Loss:  0.00012905531912110746
Valid Loss:  0.00017623158055357635
Epoch:  115  	Training Loss: 0.0002121693396475166
Test Loss:  0.00012923467147629708
Valid Loss:  0.0001760243612807244
Epoch:  116  	Training Loss: 0.00021122803445905447
Test Loss:  0.0001296026457566768
Valid Loss:  0.00017596367979422212
Epoch:  117  	Training Loss: 0.0002104731393046677
Test Loss:  0.0001299229043070227
Valid Loss:  0.00017595180543139577
Epoch:  118  	Training Loss: 0.00020986418530810624
Test Loss:  0.0001302624004893005
Valid Loss:  0.00017599196871742606
Epoch:  119  	Training Loss: 0.0002093752264045179
Test Loss:  0.00013058252807240933
Valid Loss:  0.00017605959146749228
Epoch:  120  	Training Loss: 0.00020897948706988245
Test Loss:  0.00013088833657093346
Valid Loss:  0.0001761392632033676
Epoch:  121  	Training Loss: 0.0002086543245241046
Test Loss:  0.0001311719825025648
Valid Loss:  0.00017622916493564844
Epoch:  122  	Training Loss: 0.00020838537602685392
Test Loss:  0.00013098045019432902
Valid Loss:  0.0001761235762387514
Epoch:  123  	Training Loss: 0.00020825161482207477
Test Loss:  0.00013096306065563112
Valid Loss:  0.00017606515029910952
Epoch:  124  	Training Loss: 0.00020812588627450168
Test Loss:  0.00013098379713483155
Valid Loss:  0.00017601693980395794
Epoch:  125  	Training Loss: 0.00020800351921934634
Test Loss:  0.00013101317745167762
Valid Loss:  0.00017597102851141244
Epoch:  126  	Training Loss: 0.00020788697293028235
Test Loss:  0.0001310475345235318
Valid Loss:  0.00017593087977729738
Epoch:  127  	Training Loss: 0.00020778097677975893
Test Loss:  0.00013108368148095906
Valid Loss:  0.0001758965663611889
Epoch:  128  	Training Loss: 0.00020768374088220298
Test Loss:  0.00013111965381540358
Valid Loss:  0.00017586263129487634
Epoch:  129  	Training Loss: 0.00020758810569532216
Test Loss:  0.00013115452020429075
Valid Loss:  0.00017582754662726074
Epoch:  130  	Training Loss: 0.00020749474060721695
Test Loss:  0.0001311874366365373
Valid Loss:  0.0001757930003805086
Epoch:  131  	Training Loss: 0.00020740320906043053
Test Loss:  0.00013121865049470216
Valid Loss:  0.00017575769743416458
Epoch:  132  	Training Loss: 0.00020731358381453902
Test Loss:  0.00012985244393348694
Valid Loss:  0.00017458293586969376
Epoch:  133  	Training Loss: 0.00020596889953594655
Test Loss:  0.00012937604333274066
Valid Loss:  0.00017378160555381328
Epoch:  134  	Training Loss: 0.00020480644889175892
Test Loss:  0.00012890681682620198
Valid Loss:  0.00017300630861427635
Epoch:  135  	Training Loss: 0.00020374247105792165
Test Loss:  0.00012849863560404629
Valid Loss:  0.00017230308731086552
Epoch:  136  	Training Loss: 0.0002027572481893003
Test Loss:  0.00012810771295335144
Valid Loss:  0.0001717039558570832
Epoch:  137  	Training Loss: 0.00020186032634228468
Test Loss:  0.00012773436901625246
Valid Loss:  0.00017115563969127834
 28%|██▊       | 139/500 [01:35<02:00,  3.01it/s] 28%|██▊       | 141/500 [01:41<07:02,  1.18s/it] 29%|██▊       | 143/500 [01:41<05:01,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:37,  1.64it/s] 29%|██▉       | 147/500 [01:42<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:42<01:57,  2.97it/s] 30%|███       | 151/500 [01:48<06:54,  1.19s/it] 31%|███       | 153/500 [01:48<04:56,  1.17it/s] 31%|███       | 155/500 [01:49<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:49<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:49<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:55<06:41,  1.18s/it] 33%|███▎      | 163/500 [01:55<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:55<03:26,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:30,  2.22it/s] 34%|███▍      | 169/500 [01:56<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:02<06:26,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.24it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:09<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:09<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:09<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:09<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:09<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:16<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:16<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:16<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:16<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:16<01:41,  2.97it/s] 40%|████      | 201/500 [02:23<05:52,  1.18s/it] 41%|████      | 203/500 [02:23<04:11,  1.18it/s]Epoch:  138  	Training Loss: 0.00020105035218875855
Test Loss:  0.0001274112582905218
Valid Loss:  0.00017065534484572709
Epoch:  139  	Training Loss: 0.00020030757877975702
Test Loss:  0.00012710929149761796
Valid Loss:  0.0001701895089354366
Epoch:  140  	Training Loss: 0.00019961172074545175
Test Loss:  0.00012680042709689587
Valid Loss:  0.00016979525389615446
Epoch:  141  	Training Loss: 0.00019899035396520048
Test Loss:  0.00012656678154598922
Valid Loss:  0.00016945652896538377
Epoch:  142  	Training Loss: 0.00019844049529638141
Test Loss:  0.00012476087431423366
Valid Loss:  0.00016622187104076147
Epoch:  143  	Training Loss: 0.00019507939578033984
Test Loss:  0.0001230229390785098
Valid Loss:  0.00016300260904245079
Epoch:  144  	Training Loss: 0.00019187043653801084
Test Loss:  0.00012089680967619643
Valid Loss:  0.0001595847716089338
Epoch:  145  	Training Loss: 0.00018893620290327817
Test Loss:  0.00011892213660757989
Valid Loss:  0.00015577583690173924
Epoch:  146  	Training Loss: 0.00018614836153574288
Test Loss:  0.0001172385091194883
Valid Loss:  0.0001525935804238543
Epoch:  147  	Training Loss: 0.00018380855908617377
Test Loss:  0.00011575158714549616
Valid Loss:  0.0001498322671977803
Epoch:  148  	Training Loss: 0.0001817452721297741
Test Loss:  0.00011447635188233107
Valid Loss:  0.00014750612899661064
Epoch:  149  	Training Loss: 0.00018000215641222894
Test Loss:  0.00011334848386468366
Valid Loss:  0.00014547168393619359
Epoch:  150  	Training Loss: 0.0001783993502613157
Test Loss:  0.00011231741518713534
Valid Loss:  0.00014363409718498588
Epoch:  151  	Training Loss: 0.0001769076188793406
Test Loss:  0.00011109256593044847
Valid Loss:  0.00014197255950421095
Epoch:  152  	Training Loss: 0.00017545200535096228
Test Loss:  0.0001087046111933887
Valid Loss:  0.0001397176383761689
Epoch:  153  	Training Loss: 0.0001738226565066725
Test Loss:  0.00010824510536622256
Valid Loss:  0.00013921043137088418
Epoch:  154  	Training Loss: 0.00017345089872833341
Test Loss:  0.00010808142542373389
Valid Loss:  0.00013894369476474822
Epoch:  155  	Training Loss: 0.00017319046310149133
Test Loss:  0.00010799769370350987
Valid Loss:  0.0001387408992741257
Epoch:  156  	Training Loss: 0.00017295393627136946
Test Loss:  0.00010794452100526541
Valid Loss:  0.0001385651994496584
Epoch:  157  	Training Loss: 0.0001727317285258323
Test Loss:  0.00010790846135932952
Valid Loss:  0.00013840642350260168
Epoch:  158  	Training Loss: 0.00017252052202820778
Test Loss:  0.00010788296640384942
Valid Loss:  0.00013825857604388148
Epoch:  159  	Training Loss: 0.00017231967649422586
Test Loss:  0.00010786017082864419
Valid Loss:  0.00013811801909469068
Epoch:  160  	Training Loss: 0.00017212808597832918
Test Loss:  0.00010783887410070747
Valid Loss:  0.0001379821333102882
Epoch:  161  	Training Loss: 0.0001719440915621817
Test Loss:  0.00010781761375255883
Valid Loss:  0.00013785509509034455
Epoch:  162  	Training Loss: 0.00017176871187984943
Test Loss:  0.00010832199768628925
Valid Loss:  0.00013789201329927891
Epoch:  163  	Training Loss: 0.00017122141434811056
Test Loss:  0.00010866003867704421
Valid Loss:  0.00013787709758616984
Epoch:  164  	Training Loss: 0.00017076822405215353
Test Loss:  0.00010895154264289886
Valid Loss:  0.00013786565978080034
Epoch:  165  	Training Loss: 0.00017040084640029818
Test Loss:  0.0001092343736672774
Valid Loss:  0.0001378761080559343
Epoch:  166  	Training Loss: 0.0001701057917671278
Test Loss:  0.00010950221621897072
Valid Loss:  0.00013791095989290625
Epoch:  167  	Training Loss: 0.00016985699767246842
Test Loss:  0.00010976076009683311
Valid Loss:  0.00013796194980386645
Epoch:  168  	Training Loss: 0.00016964302631095052
Test Loss:  0.00011002870451193303
Valid Loss:  0.00013802503235638142
Epoch:  169  	Training Loss: 0.00016946002142503858
Test Loss:  0.00011028468725271523
Valid Loss:  0.00013808594667352736
Epoch:  170  	Training Loss: 0.0001693062367849052
Test Loss:  0.00011052418267354369
Valid Loss:  0.00013815074635203928
Epoch:  171  	Training Loss: 0.00016918056644499302
Test Loss:  0.00011074541544076055
Valid Loss:  0.00013821086031384766
Epoch:  172  	Training Loss: 0.00016906808014027774
Test Loss:  0.00011100208212155849
Valid Loss:  0.00013823364861309528
Epoch:  173  	Training Loss: 0.00016891371342353523
Test Loss:  0.00011143893789267167
Valid Loss:  0.00013839994790032506
Epoch:  174  	Training Loss: 0.00016879066242836416
Test Loss:  0.0001117767023970373
Valid Loss:  0.0001385187788400799
Epoch:  175  	Training Loss: 0.00016869476530700922
Test Loss:  0.00011209951480850577
Valid Loss:  0.00013864637003280222
Epoch:  176  	Training Loss: 0.00016862008487805724
Test Loss:  0.00011235890269745141
Valid Loss:  0.00013874215073883533
Epoch:  177  	Training Loss: 0.00016855791909620166
Test Loss:  0.00011260457540629432
Valid Loss:  0.0001388378586852923
Epoch:  178  	Training Loss: 0.00016850609972607344
Test Loss:  0.00011282113700872287
Valid Loss:  0.0001389296376146376
Epoch:  179  	Training Loss: 0.00016846202197484672
Test Loss:  0.00011301686754450202
Valid Loss:  0.0001390164252370596
Epoch:  180  	Training Loss: 0.0001684239541646093
Test Loss:  0.00011319150507915765
Valid Loss:  0.00013909449626225978
Epoch:  181  	Training Loss: 0.00016839134332258254
Test Loss:  0.0001133478872361593
Valid Loss:  0.0001391641126247123
Epoch:  182  	Training Loss: 0.00016836209397297353
Test Loss:  0.00011101866402896121
Valid Loss:  0.0001376151922158897
Epoch:  183  	Training Loss: 0.00016633971245028079
Test Loss:  0.00010813958215294406
Valid Loss:  0.00013555094483308494
Epoch:  184  	Training Loss: 0.00016506460087839514
Test Loss:  0.00010699915583245456
Valid Loss:  0.00013474200386554003
Epoch:  185  	Training Loss: 0.00016410622629337013
Test Loss:  0.00010581566311884671
Valid Loss:  0.00013382811448536813
Epoch:  186  	Training Loss: 0.0001633024075999856
Test Loss:  0.00010517392365727574
Valid Loss:  0.00013327415217645466
Epoch:  187  	Training Loss: 0.0001625830918783322
Test Loss:  0.0001045763201545924
Valid Loss:  0.00013271617353893816
Epoch:  188  	Training Loss: 0.00016190903261303902
Test Loss:  0.00010417628800496459
Valid Loss:  0.0001322748721577227
Epoch:  189  	Training Loss: 0.00016126643458846956
Test Loss:  0.00010383357584942132
Valid Loss:  0.000131855602376163
Epoch:  190  	Training Loss: 0.00016064687224570662
Test Loss:  0.00010356051643611863
Valid Loss:  0.00013147969730198383
Epoch:  191  	Training Loss: 0.00016004839562810957
Test Loss:  0.00010332649981137365
Valid Loss:  0.0001311277155764401
Epoch:  192  	Training Loss: 0.00015946885105222464
Test Loss:  0.00010292683145962656
Valid Loss:  0.00013059274351689965
Epoch:  193  	Training Loss: 0.00015912888920865953
Test Loss:  0.00010303137241862714
Valid Loss:  0.00013044806837569922
Epoch:  194  	Training Loss: 0.00015884843014646322
Test Loss:  0.00010313837265130132
Valid Loss:  0.0001303134486079216
Epoch:  195  	Training Loss: 0.00015858127153478563
Test Loss:  0.00010323623428121209
Valid Loss:  0.00013017785386182368
Epoch:  196  	Training Loss: 0.0001583224511705339
Test Loss:  0.00010332531383028254
Valid Loss:  0.00013004177890252322
Epoch:  197  	Training Loss: 0.0001580717507749796
Test Loss:  0.00010340281005483121
Valid Loss:  0.00012990475806873292
Epoch:  198  	Training Loss: 0.00015782861737534404
Test Loss:  0.00010346889030188322
Valid Loss:  0.00012977374717593193
Epoch:  199  	Training Loss: 0.00015759217785671353
Test Loss:  0.0001035296663758345
Valid Loss:  0.00012966402573511004
Epoch:  200  	Training Loss: 0.0001573714253026992
Test Loss:  0.00010358803410781547
Valid Loss:  0.0001295661204494536
Epoch:  201  	Training Loss: 0.00015716211055405438
Test Loss:  0.00010365214984631166
Valid Loss:  0.00012947186769451946
Epoch:  202  	Training Loss: 0.00015696059563197196
Test Loss:  0.00010307058255420998
Valid Loss:  0.00012902161688543856
Epoch:  203  	Training Loss: 0.00015613243158441037
Test Loss:  0.0001022265714709647
Valid Loss:  0.00012826675083488226
Epoch:  204  	Training Loss: 0.00015542823530267924
Test Loss:  0.00010155136260436848
Valid Loss:   41%|████      | 205/500 [02:23<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.22it/s] 42%|████▏     | 209/500 [02:23<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:29<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:30<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:30<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:30<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:30<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:36<05:30,  1.19s/it] 45%|████▍     | 223/500 [02:36<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:37<02:49,  1.63it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.22it/s] 46%|████▌     | 229/500 [02:37<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:43<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:45,  1.19it/s] 47%|████▋     | 235/500 [02:43<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:44<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:50<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:50<03:38,  1.17it/s] 49%|████▉     | 245/500 [02:50<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:50<01:54,  2.22it/s] 50%|████▉     | 249/500 [02:51<01:24,  2.99it/s] 50%|█████     | 251/500 [02:57<04:54,  1.18s/it] 51%|█████     | 253/500 [02:57<03:30,  1.18it/s] 51%|█████     | 255/500 [02:57<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:57<01:49,  2.22it/s] 52%|█████▏    | 259/500 [02:57<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:04<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:04<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:04<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:04<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:04<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:11<04:29,  1.18s/it]0.0001276345574297011
Epoch:  205  	Training Loss: 0.00015475625696126372
Test Loss:  0.00010094956087414175
Valid Loss:  0.0001270472421310842
Epoch:  206  	Training Loss: 0.0001541059755254537
Test Loss:  0.00010039434710051864
Valid Loss:  0.0001264850579900667
Epoch:  207  	Training Loss: 0.0001534654584247619
Test Loss:  9.987979137804359e-05
Valid Loss:  0.00012594510917551816
Epoch:  208  	Training Loss: 0.00015283309039659798
Test Loss:  9.939839947037399e-05
Valid Loss:  0.00012542479089461267
Epoch:  209  	Training Loss: 0.00015220649947877973
Test Loss:  9.894251707009971e-05
Valid Loss:  0.0001249200286110863
Epoch:  210  	Training Loss: 0.0001515860203653574
Test Loss:  9.850706555880606e-05
Valid Loss:  0.00012442682054825127
Epoch:  211  	Training Loss: 0.00015097035793587565
Test Loss:  9.808749746298417e-05
Valid Loss:  0.0001239435950992629
Epoch:  212  	Training Loss: 0.00015035913384053856
Test Loss:  9.756763756740838e-05
Valid Loss:  0.00012350831821095198
Epoch:  213  	Training Loss: 0.00014997523976489902
Test Loss:  9.714165207697079e-05
Valid Loss:  0.00012313670595176518
Epoch:  214  	Training Loss: 0.00014961569104343653
Test Loss:  9.677647904027253e-05
Valid Loss:  0.0001228038890985772
Epoch:  215  	Training Loss: 0.00014926839503459632
Test Loss:  9.645626414567232e-05
Valid Loss:  0.00012249677092768252
Epoch:  216  	Training Loss: 0.00014893259503878653
Test Loss:  9.617657633498311e-05
Valid Loss:  0.00012221226643305272
Epoch:  217  	Training Loss: 0.00014860756346024573
Test Loss:  9.593322465661913e-05
Valid Loss:  0.0001219486293848604
Epoch:  218  	Training Loss: 0.00014829117571935058
Test Loss:  9.571883856551722e-05
Valid Loss:  0.00012170182162662968
Epoch:  219  	Training Loss: 0.00014798007032368332
Test Loss:  9.552414121571928e-05
Valid Loss:  0.00012146891822339967
Epoch:  220  	Training Loss: 0.0001476734905736521
Test Loss:  9.53457347350195e-05
Valid Loss:  0.00012124320346629247
Epoch:  221  	Training Loss: 0.00014737233868800104
Test Loss:  9.518486331216991e-05
Valid Loss:  0.000121028017019853
Epoch:  222  	Training Loss: 0.00014707542140968144
Test Loss:  9.585166117176414e-05
Valid Loss:  0.00012091447570128366
Epoch:  223  	Training Loss: 0.0001461595529690385
Test Loss:  9.631257853470743e-05
Valid Loss:  0.0001207883469760418
Epoch:  224  	Training Loss: 0.0001454880548408255
Test Loss:  9.683574899099767e-05
Valid Loss:  0.0001208151807077229
Epoch:  225  	Training Loss: 0.00014498285599984229
Test Loss:  9.721187234390527e-05
Valid Loss:  0.0001208014800795354
Epoch:  226  	Training Loss: 0.00014459023077506572
Test Loss:  9.758269879966974e-05
Valid Loss:  0.0001208409812534228
Epoch:  227  	Training Loss: 0.0001442778157070279
Test Loss:  9.785107977222651e-05
Valid Loss:  0.00012084610352758318
Epoch:  228  	Training Loss: 0.00014402103261090815
Test Loss:  9.809173934627324e-05
Valid Loss:  0.00012086334027117118
Epoch:  229  	Training Loss: 0.00014380311768036336
Test Loss:  9.825974120758474e-05
Valid Loss:  0.00012084710033377632
Epoch:  230  	Training Loss: 0.0001436106686014682
Test Loss:  9.840457641985267e-05
Valid Loss:  0.00012083377077942714
Epoch:  231  	Training Loss: 0.00014344058581627905
Test Loss:  9.85025180852972e-05
Valid Loss:  0.00012079958105459809
Epoch:  232  	Training Loss: 0.00014328934776131064
Test Loss:  9.697132190922275e-05
Valid Loss:  0.00011995908425888047
Epoch:  233  	Training Loss: 0.00014216642011888325
Test Loss:  9.48811139096506e-05
Valid Loss:  0.00011805691610788926
Epoch:  234  	Training Loss: 0.0001413653080817312
Test Loss:  9.420254355063662e-05
Valid Loss:  0.00011779661872424185
Epoch:  235  	Training Loss: 0.00014077882224228233
Test Loss:  9.280283120460808e-05
Valid Loss:  0.00011652464309008792
Epoch:  236  	Training Loss: 0.00014033207844477147
Test Loss:  9.250687435269356e-05
Valid Loss:  0.0001165125286206603
Epoch:  237  	Training Loss: 0.00013998446229379624
Test Loss:  9.151765698334202e-05
Valid Loss:  0.00011559527047211304
Epoch:  238  	Training Loss: 0.000139703624881804
Test Loss:  9.143393253907561e-05
Valid Loss:  0.00011569935304578394
Epoch:  239  	Training Loss: 0.0001394662685925141
Test Loss:  9.069724183063954e-05
Valid Loss:  0.00011499927495606244
Epoch:  240  	Training Loss: 0.00013926043175160885
Test Loss:  9.071349631994963e-05
Valid Loss:  0.00011514253856148571
Epoch:  241  	Training Loss: 0.0001390744437230751
Test Loss:  9.013873932417482e-05
Valid Loss:  0.00011457745131338015
Epoch:  242  	Training Loss: 0.0001389021927025169
Test Loss:  9.026253246702254e-05
Valid Loss:  0.0001145858404925093
Epoch:  243  	Training Loss: 0.0001384745119139552
Test Loss:  9.030989167513326e-05
Valid Loss:  0.000114581169327721
Epoch:  244  	Training Loss: 0.0001381168985972181
Test Loss:  9.038590360432863e-05
Valid Loss:  0.00011457139044068754
Epoch:  245  	Training Loss: 0.00013784534530714154
Test Loss:  9.046809282153845e-05
Valid Loss:  0.00011455935600679368
Epoch:  246  	Training Loss: 0.00013762206071987748
Test Loss:  9.052696987055242e-05
Valid Loss:  0.00011453540355432779
Epoch:  247  	Training Loss: 0.0001374193379888311
Test Loss:  9.059940930455923e-05
Valid Loss:  0.00011452149192336947
Epoch:  248  	Training Loss: 0.0001372391707263887
Test Loss:  9.068251529242843e-05
Valid Loss:  0.00011450830788817257
Epoch:  249  	Training Loss: 0.00013707982725463808
Test Loss:  9.075844718609005e-05
Valid Loss:  0.00011449301382526755
Epoch:  250  	Training Loss: 0.00013693470100406557
Test Loss:  9.084082557819784e-05
Valid Loss:  0.00011448410805314779
Epoch:  251  	Training Loss: 0.00013679996482096612
Test Loss:  9.091116953641176e-05
Valid Loss:  0.00011446834832895547
Epoch:  252  	Training Loss: 0.00013667075836565346
Test Loss:  9.096290887100622e-05
Valid Loss:  0.00011431969323894009
Epoch:  253  	Training Loss: 0.00013641596888191998
Test Loss:  9.116813453147188e-05
Valid Loss:  0.00011430987069616094
Epoch:  254  	Training Loss: 0.00013619684614241123
Test Loss:  9.139954636339098e-05
Valid Loss:  0.00011434478801675141
Epoch:  255  	Training Loss: 0.00013600595411844552
Test Loss:  9.160864283330739e-05
Valid Loss:  0.00011437537614256144
Epoch:  256  	Training Loss: 0.00013583822874352336
Test Loss:  9.183742804452777e-05
Valid Loss:  0.00011444343545008451
Epoch:  257  	Training Loss: 0.00013569367001764476
Test Loss:  9.204057278111577e-05
Valid Loss:  0.00011450624151621014
Epoch:  258  	Training Loss: 0.00013556788326241076
Test Loss:  9.220775245921686e-05
Valid Loss:  0.00011455193453002721
Epoch:  259  	Training Loss: 0.00013545341789722443
Test Loss:  9.235934703610837e-05
Valid Loss:  0.00011459186498541385
Epoch:  260  	Training Loss: 0.00013534958998207003
Test Loss:  9.250041330233216e-05
Valid Loss:  0.00011463109694886953
Epoch:  261  	Training Loss: 0.00013525548274628818
Test Loss:  9.264184336643666e-05
Valid Loss:  0.00011467927834019065
Epoch:  262  	Training Loss: 0.00013517067418433726
Test Loss:  9.24306150409393e-05
Valid Loss:  0.00011433543113525957
Epoch:  263  	Training Loss: 0.00013468880206346512
Test Loss:  9.221828076988459e-05
Valid Loss:  0.00011400457879062742
Epoch:  264  	Training Loss: 0.00013422867050394416
Test Loss:  9.198386396747082e-05
Valid Loss:  0.00011366685794200748
Epoch:  265  	Training Loss: 0.00013378658331930637
Test Loss:  9.173570288112387e-05
Valid Loss:  0.00011333081783959642
Epoch:  266  	Training Loss: 0.00013336165284272283
Test Loss:  9.148778190137818e-05
Valid Loss:  0.0001129976735683158
Epoch:  267  	Training Loss: 0.00013295157987158746
Test Loss:  9.12467367015779e-05
Valid Loss:  0.00011267614172538742
Epoch:  268  	Training Loss: 0.0001325556804658845
Test Loss:  9.100214811041951e-05
Valid Loss:  0.00011235800775466487
Epoch:  269  	Training Loss: 0.0001321717572864145
Test Loss:  9.075607522390783e-05
Valid Loss:  0.00011204260226804763
Epoch:  270  	Training Loss: 0.0001317970163654536
Test Loss:  9.050559310708195e-05
Valid Loss:  0.00011172587983310223
Epoch:  271  	Training Loss: 0.00013142988609615713
Test Loss:  9.025647887028754e-05
Valid Loss:  0.0001114144833991304
 55%|█████▍    | 273/500 [03:11<03:11,  1.18it/s] 55%|█████▌    | 275/500 [03:11<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:11<01:39,  2.24it/s] 56%|█████▌    | 279/500 [03:11<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:17<04:17,  1.18s/it] 57%|█████▋    | 283/500 [03:18<03:03,  1.18it/s] 57%|█████▋    | 285/500 [03:18<02:13,  1.62it/s] 57%|█████▋    | 287/500 [03:18<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:18<01:11,  2.94it/s] 58%|█████▊    | 291/500 [03:24<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:24<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:25<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:25<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:25<01:06,  3.00it/s] 60%|██████    | 301/500 [03:31<03:56,  1.19s/it] 61%|██████    | 303/500 [03:31<02:48,  1.17it/s] 61%|██████    | 305/500 [03:31<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:32<01:27,  2.21it/s] 62%|██████▏   | 309/500 [03:32<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:38<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:38<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:38<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.25it/s] 64%|██████▍   | 319/500 [03:39<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:45<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:45<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:45<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:45<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:45<00:56,  3.00it/s] 66%|██████▌   | 331/500 [03:52<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:52<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:52<01:40,  1.63it/s] 67%|██████▋   | 337/500 [03:52<01:13,  2.23it/s]Epoch:  272  	Training Loss: 0.0001310721127083525
Test Loss:  8.816523040877655e-05
Valid Loss:  0.00010885200754273683
Epoch:  273  	Training Loss: 0.00012885083560831845
Test Loss:  8.614659600425512e-05
Valid Loss:  0.00010660749831004068
Epoch:  274  	Training Loss: 0.0001269642962142825
Test Loss:  8.440947567578405e-05
Valid Loss:  0.00010468324762769043
Epoch:  275  	Training Loss: 0.00012530192907433957
Test Loss:  8.272773993667215e-05
Valid Loss:  0.00010293596278643236
Epoch:  276  	Training Loss: 0.00012366793816909194
Test Loss:  8.111880742944777e-05
Valid Loss:  0.00010136964556295425
Epoch:  277  	Training Loss: 0.00012217594485264271
Test Loss:  7.957562047522515e-05
Valid Loss:  0.00010000119800679386
Epoch:  278  	Training Loss: 0.00012082459579687566
Test Loss:  7.815567369107157e-05
Valid Loss:  9.87330058705993e-05
Epoch:  279  	Training Loss: 0.00011949436157010496
Test Loss:  7.691648352192715e-05
Valid Loss:  9.759307431522757e-05
Epoch:  280  	Training Loss: 0.00011828446440631524
Test Loss:  7.584010745631531e-05
Valid Loss:  9.657701593823731e-05
Epoch:  281  	Training Loss: 0.00011717643064912409
Test Loss:  7.489857671316713e-05
Valid Loss:  9.5661889645271e-05
Epoch:  282  	Training Loss: 0.0001161408654297702
Test Loss:  7.539115904364735e-05
Valid Loss:  9.582669008523226e-05
Epoch:  283  	Training Loss: 0.00011581156286410987
Test Loss:  7.56652225391008e-05
Valid Loss:  9.581608173903078e-05
Epoch:  284  	Training Loss: 0.00011553662625374272
Test Loss:  7.589332381030545e-05
Valid Loss:  9.57974698394537e-05
Epoch:  285  	Training Loss: 0.00011530006304383278
Test Loss:  7.60866460041143e-05
Valid Loss:  9.578357276041061e-05
Epoch:  286  	Training Loss: 0.00011509054456837475
Test Loss:  7.625333819305524e-05
Valid Loss:  9.577015589457005e-05
Epoch:  287  	Training Loss: 0.0001149084564531222
Test Loss:  7.640437979716808e-05
Valid Loss:  9.576524462318048e-05
Epoch:  288  	Training Loss: 0.00011475094652269036
Test Loss:  7.657123205717653e-05
Valid Loss:  9.576127922628075e-05
Epoch:  289  	Training Loss: 0.00011461967369541526
Test Loss:  7.674991502426565e-05
Valid Loss:  9.578385652275756e-05
Epoch:  290  	Training Loss: 0.00011450790043454617
Test Loss:  7.692209328524768e-05
Valid Loss:  9.581072663422674e-05
Epoch:  291  	Training Loss: 0.00011441164679126814
Test Loss:  7.707301847403869e-05
Valid Loss:  9.583929204382002e-05
Epoch:  292  	Training Loss: 0.00011432560131652281
Test Loss:  7.692181679885834e-05
Valid Loss:  9.547646186547354e-05
Epoch:  293  	Training Loss: 0.000114213049528189
Test Loss:  7.708006887696683e-05
Valid Loss:  9.562636842019856e-05
Epoch:  294  	Training Loss: 0.00011411136802053079
Test Loss:  7.705966709181666e-05
Valid Loss:  9.550724644213915e-05
Epoch:  295  	Training Loss: 0.00011401742813177407
Test Loss:  7.715074752923101e-05
Valid Loss:  9.55389259615913e-05
Epoch:  296  	Training Loss: 0.00011394610919523984
Test Loss:  7.725269824732095e-05
Valid Loss:  9.553047129884362e-05
Epoch:  297  	Training Loss: 0.00011388333223294467
Test Loss:  7.737800478935242e-05
Valid Loss:  9.558800957165658e-05
Epoch:  298  	Training Loss: 0.00011382570664864033
Test Loss:  7.747769268462434e-05
Valid Loss:  9.560025500832126e-05
Epoch:  299  	Training Loss: 0.0001137731596827507
Test Loss:  7.758410356473178e-05
Valid Loss:  9.564574429532513e-05
Epoch:  300  	Training Loss: 0.00011372486187610775
Test Loss:  7.766358612570912e-05
Valid Loss:  9.566504741087556e-05
Epoch:  301  	Training Loss: 0.00011368073319317773
Test Loss:  7.773812103550881e-05
Valid Loss:  9.569131361786276e-05
Epoch:  302  	Training Loss: 0.00011364021338522434
Test Loss:  7.781866588629782e-05
Valid Loss:  9.568829409545287e-05
Epoch:  303  	Training Loss: 0.00011362116492819041
Test Loss:  7.793529948685318e-05
Valid Loss:  9.575080184731632e-05
Epoch:  304  	Training Loss: 0.0001136053615482524
Test Loss:  7.803723565302789e-05
Valid Loss:  9.579820471117273e-05
Epoch:  305  	Training Loss: 0.00011359167547198012
Test Loss:  7.813324191374704e-05
Valid Loss:  9.584403596818447e-05
Epoch:  306  	Training Loss: 0.00011357995390426368
Test Loss:  7.822223415132612e-05
Valid Loss:  9.588738612364978e-05
Epoch:  307  	Training Loss: 0.00011356992035871372
Test Loss:  7.83052237238735e-05
Valid Loss:  9.59276658250019e-05
Epoch:  308  	Training Loss: 0.00011356082541169599
Test Loss:  7.838231249479577e-05
Valid Loss:  9.596555901225656e-05
Epoch:  309  	Training Loss: 0.00011355306196492165
Test Loss:  7.845353684388101e-05
Valid Loss:  9.600121120456606e-05
Epoch:  310  	Training Loss: 0.00011354687012499198
Test Loss:  7.852039561839774e-05
Valid Loss:  9.603440412320197e-05
Epoch:  311  	Training Loss: 0.00011354104208294302
Test Loss:  7.858216122258455e-05
Valid Loss:  9.606509411241859e-05
Epoch:  312  	Training Loss: 0.00011353623995091766
Test Loss:  7.696530519751832e-05
Valid Loss:  9.539104212308303e-05
Epoch:  313  	Training Loss: 0.00011242795881116763
Test Loss:  7.499153434764594e-05
Valid Loss:  9.348319144919515e-05
Epoch:  314  	Training Loss: 0.00011160877329530194
Test Loss:  7.433058635797352e-05
Valid Loss:  9.323158883489668e-05
Epoch:  315  	Training Loss: 0.000110956076241564
Test Loss:  7.328223728109151e-05
Valid Loss:  9.214817691827193e-05
Epoch:  316  	Training Loss: 0.00011038088996428996
Test Loss:  7.293961243703961e-05
Valid Loss:  9.196166502078995e-05
Epoch:  317  	Training Loss: 0.00010984802065650001
Test Loss:  7.230715709738433e-05
Valid Loss:  9.12411414901726e-05
Epoch:  318  	Training Loss: 0.00010935240425169468
Test Loss:  7.208243914647028e-05
Valid Loss:  9.10654416657053e-05
Epoch:  319  	Training Loss: 0.00010888281394727528
Test Loss:  7.166633440647274e-05
Valid Loss:  9.055806731339544e-05
Epoch:  320  	Training Loss: 0.0001084342657122761
Test Loss:  7.150534656830132e-05
Valid Loss:  9.037295239977539e-05
Epoch:  321  	Training Loss: 0.00010800317249959335
Test Loss:  7.121932867448777e-05
Valid Loss:  8.998832345241681e-05
Epoch:  322  	Training Loss: 0.00010758821736089885
Test Loss:  6.929808296263218e-05
Valid Loss:  8.821190567687154e-05
Epoch:  323  	Training Loss: 0.00010562824172666296
Test Loss:  6.796475645387545e-05
Valid Loss:  8.701629849383608e-05
Epoch:  324  	Training Loss: 0.00010428877430967987
Test Loss:  6.690062582492828e-05
Valid Loss:  8.613328827777877e-05
Epoch:  325  	Training Loss: 0.00010323406604584306
Test Loss:  6.599163316423073e-05
Valid Loss:  8.542637806385756e-05
Epoch:  326  	Training Loss: 0.00010236063826596364
Test Loss:  6.524237687699497e-05
Valid Loss:  8.484350109938532e-05
Epoch:  327  	Training Loss: 0.00010163312981603667
Test Loss:  6.463803583756089e-05
Valid Loss:  8.436545613221824e-05
Epoch:  328  	Training Loss: 0.00010102489613927901
Test Loss:  6.409778143279254e-05
Valid Loss:  8.39511922094971e-05
Epoch:  329  	Training Loss: 0.00010046134411823004
Test Loss:  6.361817213473842e-05
Valid Loss:  8.359614730579779e-05
Epoch:  330  	Training Loss: 9.99466356006451e-05
Test Loss:  6.320429383777082e-05
Valid Loss:  8.328310650540516e-05
Epoch:  331  	Training Loss: 9.94667352642864e-05
Test Loss:  6.284557457547635e-05
Valid Loss:  8.300459012389183e-05
Epoch:  332  	Training Loss: 9.90249973256141e-05
Test Loss:  6.185397796798497e-05
Valid Loss:  8.182226156350225e-05
Epoch:  333  	Training Loss: 9.829334157984704e-05
Test Loss:  6.128134555183351e-05
Valid Loss:  8.119232370518148e-05
Epoch:  334  	Training Loss: 9.774080535862595e-05
Test Loss:  6.0860336816404015e-05
Valid Loss:  8.076349331531674e-05
Epoch:  335  	Training Loss: 9.723324910737574e-05
Test Loss:  6.051020318409428e-05
Valid Loss:  8.042163972277194e-05
Epoch:  336  	Training Loss: 9.674695320427418e-05
Test Loss:  6.020282307872549e-05
Valid Loss:  8.012299076654017e-05
Epoch:  337  	Training Loss: 9.627635154174641e-05
Test Loss:  5.9924375818809494e-05
Valid Loss:  7.985069532878697e-05
Epoch:  338  	Training Loss: 9.581344784237444e-05
Test Loss:  5.965423406451009e-05
Valid Loss:  7.959407230373472e-05
Epoch:  339  	Training Loss: 9.53552225837484e-05
Test Loss:  5.937723472015932e-05
Valid Loss:   68%|██████▊   | 339/500 [03:52<00:53,  3.00it/s] 68%|██████▊   | 341/500 [03:58<03:06,  1.17s/it] 69%|██████▊   | 343/500 [03:59<02:12,  1.19it/s] 69%|██████▉   | 345/500 [03:59<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:59<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:59<00:50,  3.00it/s] 70%|███████   | 351/500 [04:05<02:55,  1.18s/it] 71%|███████   | 353/500 [04:05<02:04,  1.18it/s] 71%|███████   | 355/500 [04:06<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:06<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:06<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:12<02:44,  1.19s/it] 73%|███████▎  | 363/500 [04:12<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:12<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:13<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:13<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:19<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:19<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:19<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:19<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:19<00:39,  3.03it/s] 76%|███████▌  | 381/500 [04:26<02:17,  1.16s/it] 77%|███████▋  | 383/500 [04:26<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:26<01:09,  1.66it/s] 77%|███████▋  | 387/500 [04:26<00:49,  2.26it/s] 78%|███████▊  | 389/500 [04:26<00:36,  3.04it/s] 78%|███████▊  | 391/500 [04:32<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:33<01:29,  1.19it/s] 79%|███████▉  | 395/500 [04:33<01:03,  1.65it/s] 79%|███████▉  | 397/500 [04:33<00:45,  2.25it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.03it/s] 80%|████████  | 401/500 [04:39<01:57,  1.18s/it] 81%|████████  | 403/500 [04:39<01:22,  1.18it/s] 81%|████████  | 405/500 [04:40<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:40<00:41,  2.23it/s]7.93489016359672e-05
Epoch:  340  	Training Loss: 9.491013042861596e-05
Test Loss:  5.9119043726241216e-05
Valid Loss:  7.911609282018617e-05
Epoch:  341  	Training Loss: 9.447756747249514e-05
Test Loss:  5.887836232432164e-05
Valid Loss:  7.889496919233352e-05
Epoch:  342  	Training Loss: 9.40562822506763e-05
Test Loss:  5.891314140171744e-05
Valid Loss:  7.849516987334937e-05
Epoch:  343  	Training Loss: 9.357128874398768e-05
Test Loss:  5.920346302445978e-05
Valid Loss:  7.84790754551068e-05
Epoch:  344  	Training Loss: 9.316855721408501e-05
Test Loss:  5.9471123677212745e-05
Valid Loss:  7.845873915357515e-05
Epoch:  345  	Training Loss: 9.282384417019784e-05
Test Loss:  5.974137457087636e-05
Valid Loss:  7.846904190955684e-05
Epoch:  346  	Training Loss: 9.252789459424093e-05
Test Loss:  6.000829307595268e-05
Valid Loss:  7.849856046959758e-05
Epoch:  347  	Training Loss: 9.227418922819197e-05
Test Loss:  6.0269936511758715e-05
Valid Loss:  7.854525756556541e-05
Epoch:  348  	Training Loss: 9.205663081957027e-05
Test Loss:  6.052453682059422e-05
Valid Loss:  7.860350160626695e-05
Epoch:  349  	Training Loss: 9.187020623357967e-05
Test Loss:  6.077110447222367e-05
Valid Loss:  7.867116801207885e-05
Epoch:  350  	Training Loss: 9.171011333819479e-05
Test Loss:  6.100835162214935e-05
Valid Loss:  7.874544826336205e-05
Epoch:  351  	Training Loss: 9.157290332950652e-05
Test Loss:  6.123608909547329e-05
Valid Loss:  7.88238103268668e-05
Epoch:  352  	Training Loss: 9.145559306489304e-05
Test Loss:  5.98706174059771e-05
Valid Loss:  7.857382297515869e-05
Epoch:  353  	Training Loss: 9.043162572197616e-05
Test Loss:  5.919583418290131e-05
Valid Loss:  7.815277785994112e-05
Epoch:  354  	Training Loss: 9.000469435704872e-05
Test Loss:  5.863566912012175e-05
Valid Loss:  7.77480672695674e-05
Epoch:  355  	Training Loss: 8.960804552771151e-05
Test Loss:  5.817590863443911e-05
Valid Loss:  7.739104330539703e-05
Epoch:  356  	Training Loss: 8.92325333552435e-05
Test Loss:  5.7797529734671116e-05
Valid Loss:  7.708050543442369e-05
Epoch:  357  	Training Loss: 8.88755894266069e-05
Test Loss:  5.746783426729962e-05
Valid Loss:  7.67993406043388e-05
Epoch:  358  	Training Loss: 8.852931932779029e-05
Test Loss:  5.7165299949701875e-05
Valid Loss:  7.654468936379999e-05
Epoch:  359  	Training Loss: 8.819045615382493e-05
Test Loss:  5.688544479198754e-05
Valid Loss:  7.630915206391364e-05
Epoch:  360  	Training Loss: 8.785722457105294e-05
Test Loss:  5.663377669407055e-05
Valid Loss:  7.60870025260374e-05
Epoch:  361  	Training Loss: 8.753161819186062e-05
Test Loss:  5.639602750306949e-05
Valid Loss:  7.587834261357784e-05
Epoch:  362  	Training Loss: 8.721076301299036e-05
Test Loss:  5.53925201529637e-05
Valid Loss:  7.444235234288499e-05
Epoch:  363  	Training Loss: 8.666724897921085e-05
Test Loss:  5.5462460295530036e-05
Valid Loss:  7.437844760715961e-05
Epoch:  364  	Training Loss: 8.652340329717845e-05
Test Loss:  5.558334669331089e-05
Valid Loss:  7.439117325702682e-05
Epoch:  365  	Training Loss: 8.639208681415766e-05
Test Loss:  5.57071907678619e-05
Valid Loss:  7.44141434552148e-05
Epoch:  366  	Training Loss: 8.627044735476375e-05
Test Loss:  5.582991798291914e-05
Valid Loss:  7.444070797646418e-05
Epoch:  367  	Training Loss: 8.615759725216776e-05
Test Loss:  5.595108450506814e-05
Valid Loss:  7.447054667863995e-05
Epoch:  368  	Training Loss: 8.605299808550626e-05
Test Loss:  5.607104321825318e-05
Valid Loss:  7.450331759173423e-05
Epoch:  369  	Training Loss: 8.595586405135691e-05
Test Loss:  5.618906288873404e-05
Valid Loss:  7.453821308445185e-05
Epoch:  370  	Training Loss: 8.586600597482175e-05
Test Loss:  5.6305532780243084e-05
Valid Loss:  7.457556785084307e-05
Epoch:  371  	Training Loss: 8.578276174375787e-05
Test Loss:  5.6420012697344646e-05
Valid Loss:  7.46139558032155e-05
Epoch:  372  	Training Loss: 8.570561476517469e-05
Test Loss:  5.654769847751595e-05
Valid Loss:  7.475880556739867e-05
Epoch:  373  	Training Loss: 8.537424582755193e-05
Test Loss:  5.642522592097521e-05
Valid Loss:  7.456172170350328e-05
Epoch:  374  	Training Loss: 8.509620965924114e-05
Test Loss:  5.632325337501243e-05
Valid Loss:  7.438987086061388e-05
Epoch:  375  	Training Loss: 8.483462443109602e-05
Test Loss:  5.621917443932034e-05
Valid Loss:  7.423856004606932e-05
Epoch:  376  	Training Loss: 8.458229422103614e-05
Test Loss:  5.611478991340846e-05
Valid Loss:  7.410567923216149e-05
Epoch:  377  	Training Loss: 8.435288327746093e-05
Test Loss:  5.606405466096476e-05
Valid Loss:  7.399763126159087e-05
Epoch:  378  	Training Loss: 8.416760101681575e-05
Test Loss:  5.605873593594879e-05
Valid Loss:  7.393032137770206e-05
Epoch:  379  	Training Loss: 8.400170190725476e-05
Test Loss:  5.6060467613860965e-05
Valid Loss:  7.387525693047792e-05
Epoch:  380  	Training Loss: 8.384867396671325e-05
Test Loss:  5.605320984614082e-05
Valid Loss:  7.382679905276746e-05
Epoch:  381  	Training Loss: 8.370273280888796e-05
Test Loss:  5.6067921832436696e-05
Valid Loss:  7.379171438515186e-05
Epoch:  382  	Training Loss: 8.35848186397925e-05
Test Loss:  5.5538803280796856e-05
Valid Loss:  7.351046951953322e-05
Epoch:  383  	Training Loss: 8.29656928544864e-05
Test Loss:  5.489572504302487e-05
Valid Loss:  7.301400910364464e-05
Epoch:  384  	Training Loss: 8.238515874836594e-05
Test Loss:  5.430146848084405e-05
Valid Loss:  7.256327080540359e-05
Epoch:  385  	Training Loss: 8.182365854736418e-05
Test Loss:  5.378672358347103e-05
Valid Loss:  7.21611431799829e-05
Epoch:  386  	Training Loss: 8.129695925163105e-05
Test Loss:  5.333075387170538e-05
Valid Loss:  7.180069951573387e-05
Epoch:  387  	Training Loss: 8.078945393208414e-05
Test Loss:  5.293055437505245e-05
Valid Loss:  7.147578435251489e-05
Epoch:  388  	Training Loss: 8.030932804103941e-05
Test Loss:  5.257916564005427e-05
Valid Loss:  7.118457870092243e-05
Epoch:  389  	Training Loss: 7.984787953319028e-05
Test Loss:  5.225844506639987e-05
Valid Loss:  7.090266444720328e-05
Epoch:  390  	Training Loss: 7.940042996779084e-05
Test Loss:  5.195717676542699e-05
Valid Loss:  7.062306394800544e-05
Epoch:  391  	Training Loss: 7.896701572462916e-05
Test Loss:  5.165903712622821e-05
Valid Loss:  7.034438021946698e-05
Epoch:  392  	Training Loss: 7.853496936149895e-05
Test Loss:  5.145957038621418e-05
Valid Loss:  6.996252341195941e-05
Epoch:  393  	Training Loss: 7.832229312043637e-05
Test Loss:  5.168329880689271e-05
Valid Loss:  7.010168337728828e-05
Epoch:  394  	Training Loss: 7.815335993655026e-05
Test Loss:  5.178922219783999e-05
Valid Loss:  7.011624256847426e-05
Epoch:  395  	Training Loss: 7.800291496096179e-05
Test Loss:  5.1910305046476424e-05
Valid Loss:  7.0162073825486e-05
Epoch:  396  	Training Loss: 7.786777860019356e-05
Test Loss:  5.201518433750607e-05
Valid Loss:  7.020104385446757e-05
Epoch:  397  	Training Loss: 7.774766709189862e-05
Test Loss:  5.211654206505045e-05
Valid Loss:  7.024126534815878e-05
Epoch:  398  	Training Loss: 7.764229667373002e-05
Test Loss:  5.221191167947836e-05
Valid Loss:  7.028150139376521e-05
Epoch:  399  	Training Loss: 7.754718535579741e-05
Test Loss:  5.2298659284133464e-05
Valid Loss:  7.031881250441074e-05
Epoch:  400  	Training Loss: 7.746061601210386e-05
Test Loss:  5.2374962251633406e-05
Valid Loss:  7.035369344521314e-05
Epoch:  401  	Training Loss: 7.738033309578896e-05
Test Loss:  5.244485510047525e-05
Valid Loss:  7.038752664811909e-05
Epoch:  402  	Training Loss: 7.731061486992985e-05
Test Loss:  5.187249553273432e-05
Valid Loss:  7.002615893725306e-05
Epoch:  403  	Training Loss: 7.681698480155319e-05
Test Loss:  5.134271123097278e-05
Valid Loss:  6.964601925574243e-05
Epoch:  404  	Training Loss: 7.641849515493959e-05
Test Loss:  5.086110832053237e-05
Valid Loss:  6.928272341610864e-05
Epoch:  405  	Training Loss: 7.60629482101649e-05
Test Loss:  5.043319470132701e-05
Valid Loss:  6.89382286509499e-05
Epoch:  406  	Training Loss: 7.573867333121598e-05
Test Loss:  5.006146966479719e-05
Valid Loss:  6.86279236106202e-05
Epoch:  407  	Training Loss: 7.544385152868927e-05
Test Loss:  4.9730369937606156e-05
Valid Loss:  6.835057865828276e-05
 82%|████████▏ | 409/500 [04:40<00:30,  2.97it/s] 82%|████████▏ | 411/500 [04:46<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:46<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:47<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:53<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.26it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.04it/s] 86%|████████▌ | 431/500 [05:00<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:00<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:00<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:00<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:12<02:02,  2.08s/it] 89%|████████▊ | 443/500 [05:13<01:24,  1.48s/it] 89%|████████▉ | 445/500 [05:13<00:57,  1.05s/it] 89%|████████▉ | 447/500 [05:13<00:40,  1.32it/s] 90%|████████▉ | 449/500 [05:13<00:28,  1.82it/s] 90%|█████████ | 451/500 [05:19<01:04,  1.33s/it] 91%|█████████ | 453/500 [05:19<00:44,  1.05it/s] 91%|█████████ | 455/500 [05:20<00:30,  1.46it/s] 91%|█████████▏| 457/500 [05:20<00:21,  2.01it/s] 92%|█████████▏| 459/500 [05:20<00:15,  2.72it/s] 92%|█████████▏| 461/500 [05:26<00:46,  1.20s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:26<00:21,  1.61it/s] 93%|█████████▎| 467/500 [05:26<00:14,  2.21it/s] 94%|█████████▍| 469/500 [05:27<00:10,  2.97it/s] 94%|█████████▍| 471/500 [05:33<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:33<00:22,  1.18it/s]Epoch:  408  	Training Loss: 7.516715413657948e-05
Test Loss:  4.943315070704557e-05
Valid Loss:  6.81048768456094e-05
Epoch:  409  	Training Loss: 7.491062569897622e-05
Test Loss:  4.9173795559909195e-05
Valid Loss:  6.788718019379303e-05
Epoch:  410  	Training Loss: 7.466966053470969e-05
Test Loss:  4.894752419204451e-05
Valid Loss:  6.769331957912073e-05
Epoch:  411  	Training Loss: 7.444183574989438e-05
Test Loss:  4.874892329098657e-05
Valid Loss:  6.751935870852321e-05
Epoch:  412  	Training Loss: 7.422460475936532e-05
Test Loss:  4.858493048232049e-05
Valid Loss:  6.73262620694004e-05
Epoch:  413  	Training Loss: 7.412894046865404e-05
Test Loss:  4.845234434469603e-05
Valid Loss:  6.71718007652089e-05
Epoch:  414  	Training Loss: 7.404493226204067e-05
Test Loss:  4.834276478504762e-05
Valid Loss:  6.70506851747632e-05
Epoch:  415  	Training Loss: 7.397124136332422e-05
Test Loss:  4.826129588764161e-05
Valid Loss:  6.695989577565342e-05
Epoch:  416  	Training Loss: 7.391255348920822e-05
Test Loss:  4.8207501095021144e-05
Valid Loss:  6.689246220048517e-05
Epoch:  417  	Training Loss: 7.386366632999852e-05
Test Loss:  4.8163805331569165e-05
Valid Loss:  6.68384600430727e-05
Epoch:  418  	Training Loss: 7.381812611129135e-05
Test Loss:  4.812860061065294e-05
Valid Loss:  6.679767102468759e-05
Epoch:  419  	Training Loss: 7.378045847872272e-05
Test Loss:  4.811942926608026e-05
Valid Loss:  6.678012141492218e-05
Epoch:  420  	Training Loss: 7.374932465609163e-05
Test Loss:  4.8113131924765185e-05
Valid Loss:  6.676535122096539e-05
Epoch:  421  	Training Loss: 7.371926039922982e-05
Test Loss:  4.8112444346770644e-05
Valid Loss:  6.675531767541543e-05
Epoch:  422  	Training Loss: 7.369051309069619e-05
Test Loss:  4.7671026550233364e-05
Valid Loss:  6.656599725829437e-05
Epoch:  423  	Training Loss: 7.31582404114306e-05
Test Loss:  4.715432442026213e-05
Valid Loss:  6.605059024877846e-05
Epoch:  424  	Training Loss: 7.279533019755036e-05
Test Loss:  4.672287468565628e-05
Valid Loss:  6.562951602973044e-05
Epoch:  425  	Training Loss: 7.242739957291633e-05
Test Loss:  4.632501440937631e-05
Valid Loss:  6.523149204440415e-05
Epoch:  426  	Training Loss: 7.206833106465638e-05
Test Loss:  4.597137376549654e-05
Valid Loss:  6.485336780315265e-05
Epoch:  427  	Training Loss: 7.172409095801413e-05
Test Loss:  4.566137067740783e-05
Valid Loss:  6.448339991038665e-05
Epoch:  428  	Training Loss: 7.139035733416677e-05
Test Loss:  4.538527718978003e-05
Valid Loss:  6.41413644189015e-05
Epoch:  429  	Training Loss: 7.106000703061e-05
Test Loss:  4.5127369958208874e-05
Valid Loss:  6.382042192853987e-05
Epoch:  430  	Training Loss: 7.072839071042836e-05
Test Loss:  4.488085687626153e-05
Valid Loss:  6.350241892505437e-05
Epoch:  431  	Training Loss: 7.040357741061598e-05
Test Loss:  4.464992161956616e-05
Valid Loss:  6.319988460745662e-05
Epoch:  432  	Training Loss: 7.008343527559191e-05
Test Loss:  4.3954787543043494e-05
Valid Loss:  6.202768418006599e-05
Epoch:  433  	Training Loss: 6.984569336054847e-05
Test Loss:  4.7621066187275574e-05
Valid Loss:  6.588621181435883e-05
Epoch:  434  	Training Loss: 7.03325349604711e-05
Test Loss:  4.6398909034905955e-05
Valid Loss:  6.358149403240532e-05
Epoch:  435  	Training Loss: 7.318741700146347e-05
Test Loss:  6.785940786357969e-05
Valid Loss:  8.633174729766324e-05
Epoch:  436  	Training Loss: 8.472653280477971e-05
Test Loss:  9.53562994254753e-05
Valid Loss:  0.0001091745070880279
Epoch:  437  	Training Loss: 0.00012811407214030623
Test Loss:  0.00028957711765542626
Valid Loss:  0.00030509402859024704
Epoch:  438  	Training Loss: 0.0002837136562447995
Test Loss:  0.0007568102446384728
Valid Loss:  0.0007499889470636845
Epoch:  439  	Training Loss: 0.0008048620074987411
Test Loss:  0.0023218803107738495
Valid Loss:  0.002280430169776082
Epoch:  440  	Training Loss: 0.0022122389636933804
Test Loss:  0.0060317544266581535
Valid Loss:  0.005876470357179642
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.006018201820552349
Test Loss:  0.0014537917450070381
Valid Loss:  0.0013894280418753624
Epoch:  442  	Training Loss: 0.001479446655139327
Test Loss:  0.0002891187323257327
Valid Loss:  0.0002855490311048925
Epoch:  443  	Training Loss: 0.00031812541419640183
Test Loss:  9.268566645914689e-05
Valid Loss:  0.0001044627497321926
Epoch:  444  	Training Loss: 0.00011402390373405069
Test Loss:  6.612675497308373e-05
Valid Loss:  8.259913738584146e-05
Epoch:  445  	Training Loss: 8.303727372549474e-05
Test Loss:  6.289330485742539e-05
Valid Loss:  8.080581028480083e-05
Epoch:  446  	Training Loss: 7.822923362255096e-05
Test Loss:  6.203190423548222e-05
Valid Loss:  8.040271495701745e-05
Epoch:  447  	Training Loss: 7.704185554757714e-05
Test Loss:  6.1242506490089e-05
Valid Loss:  7.974808977451175e-05
Epoch:  448  	Training Loss: 7.637240923941135e-05
Test Loss:  6.0426522395573556e-05
Valid Loss:  7.896230090409517e-05
Epoch:  449  	Training Loss: 7.58270762162283e-05
Test Loss:  5.963441071799025e-05
Valid Loss:  7.816980360075831e-05
Epoch:  450  	Training Loss: 7.534919859608635e-05
Test Loss:  5.8892532251775265e-05
Valid Loss:  7.741933950455859e-05
Epoch:  451  	Training Loss: 7.492593431379646e-05
Test Loss:  5.8206249377690256e-05
Valid Loss:  7.672618085052818e-05
Epoch:  452  	Training Loss: 7.45506476960145e-05
Test Loss:  5.764734305557795e-05
Valid Loss:  7.60762341087684e-05
Epoch:  453  	Training Loss: 7.430938421748579e-05
Test Loss:  5.7174784160451964e-05
Valid Loss:  7.553252362413332e-05
Epoch:  454  	Training Loss: 7.410653779515997e-05
Test Loss:  5.676852015312761e-05
Valid Loss:  7.507033296860754e-05
Epoch:  455  	Training Loss: 7.392995757982135e-05
Test Loss:  5.641338793793693e-05
Valid Loss:  7.46721270843409e-05
Epoch:  456  	Training Loss: 7.377228030236438e-05
Test Loss:  5.6097993365256116e-05
Valid Loss:  7.432307756971568e-05
Epoch:  457  	Training Loss: 7.362817268585786e-05
Test Loss:  5.581446748692542e-05
Valid Loss:  7.401368930004537e-05
Epoch:  458  	Training Loss: 7.349432416958734e-05
Test Loss:  5.55558071937412e-05
Valid Loss:  7.373573316726834e-05
Epoch:  459  	Training Loss: 7.336819544434547e-05
Test Loss:  5.53176760149654e-05
Valid Loss:  7.348431972786784e-05
Epoch:  460  	Training Loss: 7.32473999960348e-05
Test Loss:  5.5096061259973794e-05
Valid Loss:  7.325324258999899e-05
Epoch:  461  	Training Loss: 7.313172682188451e-05
Test Loss:  5.488805254572071e-05
Valid Loss:  7.303705206140876e-05
Epoch:  462  	Training Loss: 7.301858568098396e-05
Test Loss:  5.4783911764388904e-05
Valid Loss:  7.316678966162726e-05
Epoch:  463  	Training Loss: 7.268101762747392e-05
Test Loss:  5.452087498269975e-05
Valid Loss:  7.296058174688369e-05
Epoch:  464  	Training Loss: 7.249421469168738e-05
Test Loss:  5.4207019275054336e-05
Valid Loss:  7.265794556587934e-05
Epoch:  465  	Training Loss: 7.233680662466213e-05
Test Loss:  5.389675061451271e-05
Valid Loss:  7.234596705529839e-05
Epoch:  466  	Training Loss: 7.219683902803808e-05
Test Loss:  5.360375507734716e-05
Valid Loss:  7.205073779914528e-05
Epoch:  467  	Training Loss: 7.207233284134418e-05
Test Loss:  5.333141234586947e-05
Valid Loss:  7.17758375685662e-05
Epoch:  468  	Training Loss: 7.196090882644057e-05
Test Loss:  5.307921674102545e-05
Valid Loss:  7.152227772166952e-05
Epoch:  469  	Training Loss: 7.186126458691433e-05
Test Loss:  5.2845851314486936e-05
Valid Loss:  7.128834840841591e-05
Epoch:  470  	Training Loss: 7.17717848601751e-05
Test Loss:  5.262891500024125e-05
Valid Loss:  7.106995326466858e-05
Epoch:  471  	Training Loss: 7.168701995396987e-05
Test Loss:  5.242721817921847e-05
Valid Loss:  7.086734694894403e-05
Epoch:  472  	Training Loss: 7.161094254115596e-05
Test Loss:  5.226844223216176e-05
Valid Loss:  7.071463187457994e-05
Epoch:  473  	Training Loss: 7.157052459660918e-05
Test Loss:  5.2124443755019456e-05
Valid Loss:  7.057916081976146e-05
Epoch:  474  	Training Loss: 7.15340138413012e-05
Test Loss:  5.1991286454722285e-05
Valid Loss:  7.045541133265942e-05
 95%|█████████▌| 475/500 [05:33<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:33<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:33<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.16s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.26it/s] 98%|█████████▊| 489/500 [05:40<00:03,  3.03it/s] 98%|█████████▊| 491/500 [05:46<00:10,  1.16s/it] 99%|█████████▊| 493/500 [05:47<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:47<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:47<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:47<00:00,  3.01it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
Epoch:  475  	Training Loss: 7.150122110033408e-05
Test Loss:  5.1866511057596654e-05
Valid Loss:  7.034066220512614e-05
Epoch:  476  	Training Loss: 7.147170981625095e-05
Test Loss:  5.1749600970651954e-05
Valid Loss:  7.023339276202023e-05
Epoch:  477  	Training Loss: 7.144502887967974e-05
Test Loss:  5.1639632147271186e-05
Valid Loss:  7.013307185843587e-05
Epoch:  478  	Training Loss: 7.142083632061258e-05
Test Loss:  5.1535706006689e-05
Valid Loss:  7.003911741776392e-05
Epoch:  479  	Training Loss: 7.13991466909647e-05
Test Loss:  5.14385974383913e-05
Valid Loss:  6.995085277594626e-05
Epoch:  480  	Training Loss: 7.137944339774549e-05
Test Loss:  5.1347145927138627e-05
Valid Loss:  6.986791413510218e-05
Epoch:  481  	Training Loss: 7.136170461308211e-05
Test Loss:  5.1260798500152305e-05
Valid Loss:  6.978977035032585e-05
Epoch:  482  	Training Loss: 7.134579209377989e-05
Test Loss:  5.1199265726609156e-05
Valid Loss:  6.973926065256819e-05
Epoch:  483  	Training Loss: 7.132541213650256e-05
Test Loss:  5.113551014801487e-05
Valid Loss:  6.968707020860165e-05
Epoch:  484  	Training Loss: 7.130653102649376e-05
Test Loss:  5.107370816404e-05
Valid Loss:  6.96386196068488e-05
Epoch:  485  	Training Loss: 7.128973084036261e-05
Test Loss:  5.101185161038302e-05
Valid Loss:  6.958874291740358e-05
Epoch:  486  	Training Loss: 7.127314165700227e-05
Test Loss:  5.095403321320191e-05
Valid Loss:  6.954203126952052e-05
Epoch:  487  	Training Loss: 7.125883712433279e-05
Test Loss:  5.089650221634656e-05
Valid Loss:  6.94949267199263e-05
Epoch:  488  	Training Loss: 7.124507828848436e-05
Test Loss:  5.0840582844102755e-05
Valid Loss:  6.944922643015161e-05
Epoch:  489  	Training Loss: 7.123251270968467e-05
Test Loss:  5.0794711569324136e-05
Valid Loss:  6.940837920410559e-05
Epoch:  490  	Training Loss: 7.122248644009233e-05
Test Loss:  5.075137232779525e-05
Valid Loss:  6.937089347047731e-05
Epoch:  491  	Training Loss: 7.121351518435404e-05
Test Loss:  5.0713479140540585e-05
Valid Loss:  6.933594704605639e-05
Epoch:  492  	Training Loss: 7.120556256268173e-05
Test Loss:  5.0387956434860826e-05
Valid Loss:  6.904720066813752e-05
Epoch:  493  	Training Loss: 7.097810885170475e-05
Test Loss:  5.010009408579208e-05
Valid Loss:  6.879420834593475e-05
Epoch:  494  	Training Loss: 7.078374619595706e-05
Test Loss:  4.984506085747853e-05
Valid Loss:  6.85722625348717e-05
Epoch:  495  	Training Loss: 7.061970245558769e-05
Test Loss:  4.9620804929872975e-05
Valid Loss:  6.837806722614914e-05
Epoch:  496  	Training Loss: 7.048262341413647e-05
Test Loss:  4.942243322147988e-05
Valid Loss:  6.820779526606202e-05
Epoch:  497  	Training Loss: 7.036811439320445e-05
Test Loss:  4.924608947476372e-05
Valid Loss:  6.805738667026162e-05
Epoch:  498  	Training Loss: 7.027040555840358e-05
Test Loss:  4.90902311867103e-05
Valid Loss:  6.79257937008515e-05
Epoch:  499  	Training Loss: 7.018882024567574e-05
Test Loss:  4.895195161225274e-05
Valid Loss:  6.78091382724233e-05
Epoch:  500  	Training Loss: 7.012062997091562e-05
Test Loss:  4.882931170868687e-05
Valid Loss:  6.770687468815595e-05
seed is  13
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.41it/s]  1%|          | 4/500 [00:00<00:29, 16.61it/s]  1%|          | 6/500 [00:00<00:29, 16.66it/s]  2%|▏         | 8/500 [00:00<00:29, 16.69it/s]  2%|▏         | 10/500 [00:00<00:29, 16.65it/s]  2%|▏         | 12/500 [00:00<00:29, 16.61it/s]  3%|▎         | 14/500 [00:00<00:29, 16.48it/s]  3%|▎         | 16/500 [00:00<00:29, 16.51it/s]  4%|▎         | 18/500 [00:01<00:29, 16.53it/s]  4%|▍         | 20/500 [00:01<00:29, 16.54it/s]  4%|▍         | 22/500 [00:01<00:28, 16.56it/s]  5%|▍         | 24/500 [00:01<00:28, 16.47it/s]  5%|▌         | 26/500 [00:01<00:28, 16.50it/s]  6%|▌         | 28/500 [00:01<00:28, 16.45it/s]  6%|▌         | 30/500 [00:01<00:28, 16.31it/s]  6%|▋         | 32/500 [00:01<00:28, 16.21it/s]  7%|▋         | 34/500 [00:02<00:28, 16.33it/s]  7%|▋         | 36/500 [00:02<00:28, 16.42it/s]  8%|▊         | 38/500 [00:02<00:27, 16.53it/s]  8%|▊         | 40/500 [00:02<00:27, 16.55it/s]  8%|▊         | 42/500 [00:02<00:27, 16.58it/s]  9%|▉         | 44/500 [00:02<00:27, 16.59it/s]  9%|▉         | 46/500 [00:02<00:27, 16.60it/s] 10%|▉         | 48/500 [00:02<00:27, 16.51it/s] 10%|█         | 50/500 [00:03<00:28, 15.87it/s] 10%|█         | 52/500 [00:03<00:27, 16.08it/s] 11%|█         | 54/500 [00:03<00:27, 16.24it/s] 11%|█         | 56/500 [00:03<00:27, 16.37it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.41it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.51it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.44it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.21it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.36it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.49it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.40it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.44it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.38it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.94it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.11it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.31it/s] 16%|█▋        | 82/500 [00:04<00:25, 16.46it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.50it/s] 17%|█▋        | 86/500 [00:05<00:24, 16.57it/s] 18%|█▊        | 88/500 [00:05<00:24, 16.57it/s] 18%|█▊        | 90/500 [00:05<00:24, 16.41it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.36it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.29it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.30it/s] 20%|█▉        | 98/500 [00:05<00:24, 16.29it/s] 20%|██        | 100/500 [00:06<00:24, 16.36it/s] 20%|██        | 102/500 [00:06<00:24, 16.38it/s] 21%|██        | 104/500 [00:06<00:24, 16.36it/s] 21%|██        | 106/500 [00:06<00:23, 16.42it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.42it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.48it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.41it/s] 23%|██▎       | 114/500 [00:06<00:23, 16.46it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.49it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.56it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.51it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.34it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.21it/s]Epoch:  1  	Training Loss: 0.050132326781749725
Test Loss:  363.0594482421875
Valid Loss:  363.37298583984375
Epoch:  2  	Training Loss: 363.15789794921875
Test Loss:  45793808384.0
Valid Loss:  45548691456.0
Epoch:  3  	Training Loss: 45657202688.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.04it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.21it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.35it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.42it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.50it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.34it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.48it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.47it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.40it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.24it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.19it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.34it/s] 30%|███       | 150/500 [00:09<00:21, 16.49it/s] 30%|███       | 152/500 [00:09<00:21, 16.56it/s] 31%|███       | 154/500 [00:09<00:20, 16.62it/s] 31%|███       | 156/500 [00:09<00:20, 16.64it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.68it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.56it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.63it/s] 33%|███▎      | 164/500 [00:09<00:20, 16.64it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.68it/s] 34%|███▎      | 168/500 [00:10<00:19, 16.70it/s] 34%|███▍      | 170/500 [00:10<00:19, 16.70it/s] 34%|███▍      | 172/500 [00:10<00:19, 16.71it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.60it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.54it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.54it/s] 36%|███▌      | 180/500 [00:10<00:19, 16.52it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.42it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.45it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.51it/s] 38%|███▊      | 188/500 [00:11<00:18, 16.49it/s] 38%|███▊      | 190/500 [00:11<00:18, 16.52it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.58it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.50it/s] 39%|███▉      | 196/500 [00:11<00:18, 16.54it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.58it/s] 40%|████      | 200/500 [00:12<00:18, 16.62it/s] 40%|████      | 202/500 [00:12<00:17, 16.62it/s] 41%|████      | 204/500 [00:12<00:17, 16.58it/s] 41%|████      | 206/500 [00:12<00:17, 16.47it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.37it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.42it/s] 42%|████▏     | 212/500 [00:12<00:17, 16.38it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.48it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.55it/s] 44%|████▎     | 218/500 [00:13<00:16, 16.60it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.62it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.66it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.54it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.57it/s] 46%|████▌     | 228/500 [00:13<00:16, 16.62it/s] 46%|████▌     | 230/500 [00:13<00:16, 16.65it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.66it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.62it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.48it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.49it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.46it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.50it/s] 49%|████▉     | 244/500 [00:14<00:15, 16.55it/s] 49%|████▉     | 246/500 [00:14<00:15, 16.55it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.56it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.62it/s] 50%|█████     | 252/500 [00:15<00:14, 16.62it/s] 51%|█████     | 254/500 [00:15<00:14, 16.54it/s] 51%|█████     | 256/500 [00:15<00:14, 16.51it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.62it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.68it/s] 52%|█████▏    | 262/500 [00:15<00:14, 16.68it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.69it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.62it/s] 54%|█████▎    | 268/500 [00:16<00:13, 16.66it/s] 54%|█████▍    | 270/500 [00:16<00:13, 16.70it/s] 54%|█████▍    | 272/500 [00:16<00:13, 16.61it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.60it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.63it/s] 56%|█████▌    | 278/500 [00:16<00:13, 16.65it/s] 56%|█████▌    | 280/500 [00:16<00:13, 16.67it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.69it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.51it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.41it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.42it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.47it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.51it/s] 59%|█████▉    | 294/500 [00:17<00:12, 16.50it/s] 59%|█████▉    | 296/500 [00:17<00:12, 16.55it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.52it/s] 60%|██████    | 300/500 [00:18<00:12, 16.43it/s] 60%|██████    | 302/500 [00:18<00:12, 16.35it/s] 61%|██████    | 304/500 [00:18<00:11, 16.36it/s] 61%|██████    | 306/500 [00:18<00:11, 16.43it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.56it/s] 62%|██████▏   | 310/500 [00:18<00:11, 16.53it/s] 62%|██████▏   | 312/500 [00:18<00:11, 16.48it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.56it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.57it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.51it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.36it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.20it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.30it/s] 65%|██████▌   | 326/500 [00:19<00:10, 16.09it/s] 66%|██████▌   | 328/500 [00:19<00:10, 16.19it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.29it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.27it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.39it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.38it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.35it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.43it/s] 68%|██████▊   | 342/500 [00:20<00:09, 16.32it/s] 69%|██████▉   | 344/500 [00:20<00:09, 16.39it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.42it/s] 70%|██████▉   | 348/500 [00:21<00:09, 15.90it/s] 70%|███████   | 350/500 [00:21<00:09, 15.99it/s] 70%|███████   | 352/500 [00:21<00:09, 16.03it/s] 71%|███████   | 354/500 [00:21<00:09, 16.21it/s] 71%|███████   | 356/500 [00:21<00:08, 16.35it/s] 72%|███████▏  | 358/500 [00:21<00:08, 16.37it/s] 72%|███████▏  | 360/500 [00:21<00:08, 16.23it/s] 72%|███████▏  | 362/500 [00:21<00:08, 16.31it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.45it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.43it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.41it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.50it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.59it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.64it/s] 75%|███████▌  | 376/500 [00:22<00:07, 16.63it/s] 76%|███████▌  | 378/500 [00:22<00:07, 16.67it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.71it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.57it/s] 77%|███████▋  | 384/500 [00:23<00:07, 15.25it/s] 77%|███████▋  | 386/500 [00:23<00:07, 15.49it/s] 78%|███████▊  | 388/500 [00:23<00:07, 15.80it/s] 78%|███████▊  | 390/500 [00:23<00:06, 15.97it/s] 78%|███████▊  | 392/500 [00:23<00:06, 16.14it/s] 79%|███████▉  | 394/500 [00:23<00:06, 16.26it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.36it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.40it/s] 80%|████████  | 400/500 [00:24<00:06, 16.32it/s] 80%|████████  | 402/500 [00:24<00:05, 16.40it/s] 81%|████████  | 404/500 [00:24<00:05, 16.49it/s] 81%|████████  | 406/500 [00:24<00:05, 16.52it/s] 82%|████████▏ | 408/500 [00:24<00:05, 16.55it/s] 82%|████████▏ | 410/500 [00:24<00:05, 16.54it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.43it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.38it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.39it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.44it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.53it/s] 84%|████████▍ | 422/500 [00:25<00:04, 16.54it/s] 85%|████████▍ | 424/500 [00:25<00:04, 16.47it/s] 85%|████████▌ | 426/500 [00:25<00:04, 16.43it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.41it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.09it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.11it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.09it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.22it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.39it/s] 88%|████████▊ | 440/500 [00:26<00:03, 16.41it/s] 88%|████████▊ | 442/500 [00:26<00:03, 16.51it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.36it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.25it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.17it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.19it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.31it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.43it/s] 91%|█████████ | 456/500 [00:27<00:02, 16.47it/s] 92%|█████████▏| 458/500 [00:27<00:02, 16.45it/s] 92%|█████████▏| 460/500 [00:27<00:02, 16.38it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.40it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.30it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.37it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.50it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.53it/s] 94%|█████████▍| 472/500 [00:28<00:01, 16.60it/s] 95%|█████████▍| 474/500 [00:28<00:01, 16.62it/s] 95%|█████████▌| 476/500 [00:28<00:01, 16.63it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.56it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.41it/s] 96%|█████████▋| 482/500 [00:29<00:01, 15.54it/s] 97%|█████████▋| 484/500 [00:29<00:01, 14.41it/s] 97%|█████████▋| 486/500 [00:29<00:01, 13.75it/s] 98%|█████████▊| 488/500 [00:29<00:00, 14.03it/s] 98%|█████████▊| 490/500 [00:29<00:00, 14.59it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.17it/s] 99%|█████████▉| 494/500 [00:30<00:00, 15.49it/s] 99%|█████████▉| 496/500 [00:30<00:00, 15.65it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 15.94it/s]100%|██████████| 500/500 [00:30<00:00, 16.14it/s]100%|██████████| 500/500 [00:30<00:00, 16.37it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  13
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:31,  6.20s/it]  1%|          | 3/500 [00:06<13:44,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:33,  1.30s/it]  3%|▎         | 13/500 [00:12<07:12,  1.13it/s]  3%|▎         | 15/500 [00:13<05:01,  1.61it/s]  3%|▎         | 17/500 [00:13<03:35,  2.24it/s]  4%|▍         | 19/500 [00:13<02:37,  3.05it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:19<06:47,  1.17it/s]  5%|▌         | 25/500 [00:19<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:09,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.65it/s]  7%|▋         | 37/500 [00:26<03:25,  2.25it/s]  8%|▊         | 39/500 [00:26<02:32,  3.03it/s]  8%|▊         | 41/500 [00:33<09:02,  1.18s/it]  9%|▊         | 43/500 [00:33<06:27,  1.18it/s]  9%|▉         | 45/500 [00:33<04:38,  1.63it/s]  9%|▉         | 47/500 [00:33<03:23,  2.23it/s] 10%|▉         | 49/500 [00:33<02:30,  2.99it/s] 10%|█         | 51/500 [00:40<08:46,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.25it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.02it/s] 12%|█▏        | 61/500 [00:46<08:35,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:08,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:53<08:24,  1.18s/it] 15%|█▍        | 73/500 [00:53<06:00,  1.18it/s]Epoch:  1  	Training Loss: 0.050132326781749725
Test Loss:  233.67059326171875
Valid Loss:  232.7844696044922
Epoch:  2  	Training Loss: 234.58767700195312
Test Loss:  19416.615234375
Valid Loss:  19086.2421875
Epoch:  3  	Training Loss: 19180.640625
Test Loss:  1.3250336647033691
Valid Loss:  1.325119972229004
Epoch:  4  	Training Loss: 1.3145792484283447
Test Loss:  1.2782549858093262
Valid Loss:  1.2785385847091675
Epoch:  5  	Training Loss: 1.2676736116409302
Test Loss:  1.2372848987579346
Valid Loss:  1.2392243146896362
Epoch:  6  	Training Loss: 1.2279458045959473
Test Loss:  1.205451250076294
Valid Loss:  1.208798885345459
Epoch:  7  	Training Loss: 1.1970787048339844
Test Loss:  1.1761205196380615
Valid Loss:  1.1803404092788696
Epoch:  8  	Training Loss: 1.1686198711395264
Test Loss:  1.1484460830688477
Valid Loss:  1.1532256603240967
Epoch:  9  	Training Loss: 1.1415596008300781
Test Loss:  1.1218295097351074
Valid Loss:  1.1269932985305786
Epoch:  10  	Training Loss: 1.1153596639633179
Test Loss:  1.0959482192993164
Valid Loss:  1.1013597249984741
Epoch:  11  	Training Loss: 1.0897955894470215
Test Loss:  1.0707626342773438
Valid Loss:  1.0763416290283203
Epoch:  12  	Training Loss: 1.064854621887207
Test Loss:  1.0633571147918701
Valid Loss:  1.068986177444458
Epoch:  13  	Training Loss: 1.0575228929519653
Test Loss:  1.056006669998169
Valid Loss:  1.0616854429244995
Epoch:  14  	Training Loss: 1.0502464771270752
Test Loss:  1.0487115383148193
Valid Loss:  1.0544394254684448
Epoch:  15  	Training Loss: 1.0430268049240112
Test Loss:  1.0414685010910034
Valid Loss:  1.047244906425476
Epoch:  16  	Training Loss: 1.035861611366272
Test Loss:  1.034289836883545
Valid Loss:  1.0401065349578857
Epoch:  17  	Training Loss: 1.0287549495697021
Test Loss:  1.0271648168563843
Valid Loss:  1.0330212116241455
Epoch:  18  	Training Loss: 1.0217018127441406
Test Loss:  1.0200928449630737
Valid Loss:  1.0259885787963867
Epoch:  19  	Training Loss: 1.0147041082382202
Test Loss:  1.0130743980407715
Valid Loss:  1.0190085172653198
Epoch:  20  	Training Loss: 1.0077613592147827
Test Loss:  1.0061182975769043
Valid Loss:  1.012084722518921
Epoch:  21  	Training Loss: 1.0008764266967773
Test Loss:  0.9992119669914246
Valid Loss:  1.0052101612091064
Epoch:  22  	Training Loss: 0.9940409660339355
Test Loss:  0.9917860627174377
Valid Loss:  0.9978127479553223
Epoch:  23  	Training Loss: 0.9866658449172974
Test Loss:  0.9844188690185547
Valid Loss:  0.9904736876487732
Epoch:  24  	Training Loss: 0.9793492555618286
Test Loss:  0.9771094918251038
Valid Loss:  0.9831924438476562
Epoch:  25  	Training Loss: 0.9720912575721741
Test Loss:  0.9698596000671387
Valid Loss:  0.9759706258773804
Epoch:  26  	Training Loss: 0.9648944139480591
Test Loss:  0.9626696705818176
Valid Loss:  0.968809187412262
Epoch:  27  	Training Loss: 0.9577587842941284
Test Loss:  0.955537736415863
Valid Loss:  0.96170574426651
Epoch:  28  	Training Loss: 0.950681209564209
Test Loss:  0.9484621286392212
Valid Loss:  0.9546583294868469
Epoch:  29  	Training Loss: 0.9436601400375366
Test Loss:  0.9414435029029846
Valid Loss:  0.9476680755615234
Epoch:  30  	Training Loss: 0.9366962909698486
Test Loss:  0.9344801902770996
Valid Loss:  0.940735936164856
Epoch:  31  	Training Loss: 0.9297874569892883
Test Loss:  0.9275715351104736
Valid Loss:  0.9338598251342773
Epoch:  32  	Training Loss: 0.9229331016540527
Test Loss:  0.9205143451690674
Valid Loss:  0.9268363118171692
Epoch:  33  	Training Loss: 0.9159261584281921
Test Loss:  0.9135161638259888
Valid Loss:  0.9198729991912842
Epoch:  34  	Training Loss: 0.9089765548706055
Test Loss:  0.906578004360199
Valid Loss:  0.912970781326294
Epoch:  35  	Training Loss: 0.902084231376648
Test Loss:  0.8996963500976562
Valid Loss:  0.9061248302459717
Epoch:  36  	Training Loss: 0.8952481150627136
Test Loss:  0.8928708434104919
Valid Loss:  0.8993346691131592
Epoch:  37  	Training Loss: 0.8884681463241577
Test Loss:  0.8861010074615479
Valid Loss:  0.8926000595092773
Epoch:  38  	Training Loss: 0.8817435503005981
Test Loss:  0.8793866634368896
Valid Loss:  0.8859205842018127
Epoch:  39  	Training Loss: 0.8750743865966797
Test Loss:  0.8727269172668457
Valid Loss:  0.879295289516449
Epoch:  40  	Training Loss: 0.8684595823287964
Test Loss:  0.8661214113235474
Valid Loss:  0.8727241158485413
Epoch:  41  	Training Loss: 0.8618988990783691
Test Loss:  0.8595700263977051
Valid Loss:  0.866206705570221
Epoch:  42  	Training Loss: 0.8553928136825562
Test Loss:  0.8531962633132935
Valid Loss:  0.8598667979240417
Epoch:  43  	Training Loss: 0.8490633964538574
Test Loss:  0.8468717336654663
Valid Loss:  0.853575587272644
Epoch:  44  	Training Loss: 0.8427827954292297
Test Loss:  0.8405957818031311
Valid Loss:  0.8473332524299622
Epoch:  45  	Training Loss: 0.8365507125854492
Test Loss:  0.8343684673309326
Valid Loss:  0.8411434888839722
Epoch:  46  	Training Loss: 0.8303674459457397
Test Loss:  0.8281900882720947
Valid Loss:  0.8350042700767517
Epoch:  47  	Training Loss: 0.8242334127426147
Test Loss:  0.8220593333244324
Valid Loss:  0.8289123773574829
Epoch:  48  	Training Loss: 0.8181467056274414
Test Loss:  0.815976083278656
Valid Loss:  0.8228676319122314
Epoch:  49  	Training Loss: 0.8121073246002197
Test Loss:  0.8099395036697388
Valid Loss:  0.8168693780899048
Epoch:  50  	Training Loss: 0.8061145544052124
Test Loss:  0.8039494156837463
Valid Loss:  0.8109171390533447
Epoch:  51  	Training Loss: 0.8001688718795776
Test Loss:  0.7980067133903503
Valid Loss:  0.8050118684768677
Epoch:  52  	Training Loss: 0.7942702770233154
Test Loss:  0.7919850945472717
Valid Loss:  0.7990317940711975
Epoch:  53  	Training Loss: 0.7882965803146362
Test Loss:  0.7860115766525269
Valid Loss:  0.7930995225906372
Epoch:  54  	Training Loss: 0.7823711633682251
Test Loss:  0.7800866365432739
Valid Loss:  0.7872153520584106
Epoch:  55  	Training Loss: 0.7764943838119507
Test Loss:  0.7742087244987488
Valid Loss:  0.7813778519630432
Epoch:  56  	Training Loss: 0.7706642746925354
Test Loss:  0.7683777809143066
Valid Loss:  0.7755868434906006
Epoch:  57  	Training Loss: 0.764880895614624
Test Loss:  0.7625933289527893
Valid Loss:  0.7698420286178589
Epoch:  58  	Training Loss: 0.7591437697410583
Test Loss:  0.7568550705909729
Valid Loss:  0.7641428709030151
Epoch:  59  	Training Loss: 0.7534526586532593
Test Loss:  0.7511624693870544
Valid Loss:  0.7584891319274902
Epoch:  60  	Training Loss: 0.7478069067001343
Test Loss:  0.7455153465270996
Valid Loss:  0.7528805136680603
Epoch:  61  	Training Loss: 0.7422063946723938
Test Loss:  0.7399131655693054
Valid Loss:  0.7473163604736328
Epoch:  62  	Training Loss: 0.7366505265235901
Test Loss:  0.7344631552696228
Valid Loss:  0.7419027090072632
Epoch:  63  	Training Loss: 0.7312456369400024
Test Loss:  0.7290566563606262
Valid Loss:  0.7365309000015259
Epoch:  64  	Training Loss: 0.7258825302124023
Test Loss:  0.7236915826797485
Valid Loss:  0.7312000393867493
Epoch:  65  	Training Loss: 0.720560610294342
Test Loss:  0.7183676958084106
Valid Loss:  0.7259100675582886
Epoch:  66  	Training Loss: 0.7152804136276245
Test Loss:  0.7130852937698364
Valid Loss:  0.7206613421440125
Epoch:  67  	Training Loss: 0.710041344165802
Test Loss:  0.7078436017036438
Valid Loss:  0.7154528498649597
Epoch:  68  	Training Loss: 0.7048426866531372
Test Loss:  0.7026422023773193
Valid Loss:  0.7102855443954468
Epoch:  69  	Training Loss: 0.6996842622756958
Test Loss:  0.6974807381629944
Valid Loss:  0.7051588296890259
Epoch:  70  	Training Loss: 0.69456547498703
Test Loss:  0.6923595666885376
Valid Loss:  0.7000720500946045
Epoch:  71  	Training Loss: 0.6894872188568115
Test Loss:  0.6872776746749878
Valid Loss:  0.6950243711471558
Epoch:  72  	Training Loss: 0.6844481229782104
Test Loss:  0.6823335886001587
Valid Loss:  0.6901149153709412
Epoch:  73  	Training Loss: 0.6795493960380554
Test Loss:  0.6774288415908813
Valid Loss:  0.6852446794509888
Epoch:  74  	Training Loss: 0.6746903657913208
Test Loss:  0.6725633144378662
Valid Loss:  0.6804130673408508
Epoch:  75  	Training Loss: 0.6698700785636902
Test Loss:  0.6677364110946655
Valid Loss:   15%|█▌        | 75/500 [00:54<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.23it/s] 16%|█▌        | 79/500 [00:54<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:00<08:08,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:48,  1.20it/s] 17%|█▋        | 85/500 [01:00<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:00<03:03,  2.26it/s] 18%|█▊        | 89/500 [01:01<02:15,  3.03it/s] 18%|█▊        | 91/500 [01:07<08:04,  1.19s/it] 19%|█▊        | 93/500 [01:07<05:46,  1.18it/s] 19%|█▉        | 95/500 [01:07<04:09,  1.63it/s] 19%|█▉        | 97/500 [01:07<03:01,  2.22it/s] 20%|█▉        | 99/500 [01:07<02:14,  2.98it/s] 20%|██        | 101/500 [01:14<07:44,  1.16s/it] 21%|██        | 103/500 [01:14<05:32,  1.20it/s] 21%|██        | 105/500 [01:14<03:58,  1.65it/s] 21%|██▏       | 107/500 [01:14<02:53,  2.26it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:20<07:31,  1.16s/it] 23%|██▎       | 113/500 [01:21<05:22,  1.20it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:21<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:27<07:29,  1.19s/it] 25%|██▍       | 123/500 [01:27<05:20,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.22it/s] 26%|██▌       | 129/500 [01:28<02:04,  2.99it/s] 26%|██▌       | 131/500 [01:34<07:13,  1.18s/it] 27%|██▋       | 133/500 [01:34<05:09,  1.18it/s] 27%|██▋       | 135/500 [01:34<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.24it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.01it/s] 28%|██▊       | 141/500 [01:41<06:58,  1.17s/it] 29%|██▊       | 143/500 [01:41<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:41<03:34,  1.65it/s] 29%|██▉       | 147/500 [01:41<02:36,  2.25it/s]0.6756197810173035
Epoch:  76  	Training Loss: 0.6650881767272949
Test Loss:  0.6629475355148315
Valid Loss:  0.6708642244338989
Epoch:  77  	Training Loss: 0.660344123840332
Test Loss:  0.6581969261169434
Valid Loss:  0.6661465167999268
Epoch:  78  	Training Loss: 0.6556378602981567
Test Loss:  0.6534836292266846
Valid Loss:  0.6614656448364258
Epoch:  79  	Training Loss: 0.6509687900543213
Test Loss:  0.6488074660301208
Valid Loss:  0.6568216681480408
Epoch:  80  	Training Loss: 0.646336555480957
Test Loss:  0.6441683173179626
Valid Loss:  0.6522144079208374
Epoch:  81  	Training Loss: 0.6417410373687744
Test Loss:  0.6395658254623413
Valid Loss:  0.6476433277130127
Epoch:  82  	Training Loss: 0.63718181848526
Test Loss:  0.6350603699684143
Valid Loss:  0.6431683301925659
Epoch:  83  	Training Loss: 0.6327195167541504
Test Loss:  0.6305879354476929
Valid Loss:  0.6387260556221008
Epoch:  84  	Training Loss: 0.6282898783683777
Test Loss:  0.6261484622955322
Valid Loss:  0.6343164443969727
Epoch:  85  	Training Loss: 0.6238937377929688
Test Loss:  0.6217427849769592
Valid Loss:  0.6299401521682739
Epoch:  86  	Training Loss: 0.619530975818634
Test Loss:  0.6173696517944336
Valid Loss:  0.6255960464477539
Epoch:  87  	Training Loss: 0.6152005195617676
Test Loss:  0.6130285859107971
Valid Loss:  0.6212837100028992
Epoch:  88  	Training Loss: 0.610901951789856
Test Loss:  0.6087194681167603
Valid Loss:  0.6170029640197754
Epoch:  89  	Training Loss: 0.6066351532936096
Test Loss:  0.6044436097145081
Valid Loss:  0.6127555966377258
Epoch:  90  	Training Loss: 0.6024006605148315
Test Loss:  0.600200355052948
Valid Loss:  0.6085399985313416
Epoch:  91  	Training Loss: 0.5981980562210083
Test Loss:  0.5959882736206055
Valid Loss:  0.6043552160263062
Epoch:  92  	Training Loss: 0.5940264463424683
Test Loss:  0.592269778251648
Valid Loss:  0.6006624102592468
Epoch:  93  	Training Loss: 0.5903487205505371
Test Loss:  0.5885696411132812
Valid Loss:  0.5969884395599365
Epoch:  94  	Training Loss: 0.5866889953613281
Test Loss:  0.5848876237869263
Valid Loss:  0.5933331251144409
Epoch:  95  	Training Loss: 0.5830472707748413
Test Loss:  0.5812239646911621
Valid Loss:  0.5896956920623779
Epoch:  96  	Training Loss: 0.5794236660003662
Test Loss:  0.5775781869888306
Valid Loss:  0.5860761404037476
Epoch:  97  	Training Loss: 0.575817883014679
Test Loss:  0.5739508867263794
Valid Loss:  0.5824746489524841
Epoch:  98  	Training Loss: 0.5722302198410034
Test Loss:  0.5703416466712952
Valid Loss:  0.5788911581039429
Epoch:  99  	Training Loss: 0.5686606168746948
Test Loss:  0.5667510032653809
Valid Loss:  0.5753257274627686
Epoch:  100  	Training Loss: 0.5651095509529114
Test Loss:  0.563178300857544
Valid Loss:  0.5717782378196716
Epoch:  101  	Training Loss: 0.5615763664245605
Test Loss:  0.5596235394477844
Valid Loss:  0.5682482719421387
Epoch:  102  	Training Loss: 0.5580608248710632
Test Loss:  0.5558682680130005
Valid Loss:  0.5645190477371216
Epoch:  103  	Training Loss: 0.5543476343154907
Test Loss:  0.5521388053894043
Valid Loss:  0.560815155506134
Epoch:  104  	Training Loss: 0.5506599545478821
Test Loss:  0.5484354496002197
Valid Loss:  0.5571370124816895
Epoch:  105  	Training Loss: 0.5469980835914612
Test Loss:  0.544757604598999
Valid Loss:  0.5534842610359192
Epoch:  106  	Training Loss: 0.5433614253997803
Test Loss:  0.541105329990387
Valid Loss:  0.5498566627502441
Epoch:  107  	Training Loss: 0.5397500991821289
Test Loss:  0.5374785661697388
Valid Loss:  0.5462542772293091
Epoch:  108  	Training Loss: 0.5361639261245728
Test Loss:  0.5338766574859619
Valid Loss:  0.5426765084266663
Epoch:  109  	Training Loss: 0.5326024889945984
Test Loss:  0.5303001403808594
Valid Loss:  0.5391237139701843
Epoch:  110  	Training Loss: 0.5290659666061401
Test Loss:  0.5267481803894043
Valid Loss:  0.5355952978134155
Epoch:  111  	Training Loss: 0.5255538821220398
Test Loss:  0.5232208967208862
Valid Loss:  0.5320912599563599
Epoch:  112  	Training Loss: 0.5220661759376526
Test Loss:  0.5194026231765747
Valid Loss:  0.5282971858978271
Epoch:  113  	Training Loss: 0.5182902812957764
Test Loss:  0.5156198740005493
Valid Loss:  0.5245381593704224
Epoch:  114  	Training Loss: 0.5145494937896729
Test Loss:  0.5118717551231384
Valid Loss:  0.520813524723053
Epoch:  115  	Training Loss: 0.5108430981636047
Test Loss:  0.5081580877304077
Valid Loss:  0.5171228647232056
Epoch:  116  	Training Loss: 0.5071706771850586
Test Loss:  0.5044783353805542
Valid Loss:  0.5134658813476562
Epoch:  117  	Training Loss: 0.503531813621521
Test Loss:  0.500832200050354
Valid Loss:  0.5098419189453125
Epoch:  118  	Training Loss: 0.4999261498451233
Test Loss:  0.4972189664840698
Valid Loss:  0.5062508583068848
Epoch:  119  	Training Loss: 0.4963531494140625
Test Loss:  0.493638813495636
Valid Loss:  0.5026923418045044
Epoch:  120  	Training Loss: 0.4928128719329834
Test Loss:  0.49009114503860474
Valid Loss:  0.49916601181030273
Epoch:  121  	Training Loss: 0.48930466175079346
Test Loss:  0.4865756928920746
Valid Loss:  0.4956715404987335
Epoch:  122  	Training Loss: 0.48582831025123596
Test Loss:  0.4833514988422394
Valid Loss:  0.49246668815612793
Epoch:  123  	Training Loss: 0.4826406240463257
Test Loss:  0.4801493287086487
Valid Loss:  0.48928356170654297
Epoch:  124  	Training Loss: 0.47947460412979126
Test Loss:  0.4769691526889801
Valid Loss:  0.4861223101615906
Epoch:  125  	Training Loss: 0.4763304591178894
Test Loss:  0.4738108217716217
Valid Loss:  0.4829825758934021
Epoch:  126  	Training Loss: 0.47320792078971863
Test Loss:  0.4706745445728302
Valid Loss:  0.47986432909965515
Epoch:  127  	Training Loss: 0.4701070785522461
Test Loss:  0.46756070852279663
Valid Loss:  0.47676751017570496
Epoch:  128  	Training Loss: 0.4670276939868927
Test Loss:  0.4644680917263031
Valid Loss:  0.4736916422843933
Epoch:  129  	Training Loss: 0.46396923065185547
Test Loss:  0.4613969027996063
Valid Loss:  0.4706369638442993
Epoch:  130  	Training Loss: 0.46093225479125977
Test Loss:  0.45834702253341675
Valid Loss:  0.4676040709018707
Epoch:  131  	Training Loss: 0.457916259765625
Test Loss:  0.4553179144859314
Valid Loss:  0.464591920375824
Epoch:  132  	Training Loss: 0.45492076873779297
Test Loss:  0.45235222578048706
Valid Loss:  0.4616432189941406
Epoch:  133  	Training Loss: 0.4519895315170288
Test Loss:  0.4494074583053589
Valid Loss:  0.45871520042419434
Epoch:  134  	Training Loss: 0.44907885789871216
Test Loss:  0.44648319482803345
Valid Loss:  0.4558074474334717
Epoch:  135  	Training Loss: 0.44618844985961914
Test Loss:  0.4435792863368988
Valid Loss:  0.4529202878475189
Epoch:  136  	Training Loss: 0.44331830739974976
Test Loss:  0.440696120262146
Valid Loss:  0.45005396008491516
Epoch:  137  	Training Loss: 0.4404686689376831
Test Loss:  0.4378330707550049
Valid Loss:  0.447207510471344
Epoch:  138  	Training Loss: 0.43763893842697144
Test Loss:  0.43498992919921875
Valid Loss:  0.4443807303905487
Epoch:  139  	Training Loss: 0.43482890725135803
Test Loss:  0.43216681480407715
Valid Loss:  0.44157373905181885
Epoch:  140  	Training Loss: 0.4320385456085205
Test Loss:  0.4293634593486786
Valid Loss:  0.43878623843193054
Epoch:  141  	Training Loss: 0.4292677640914917
Test Loss:  0.4265795946121216
Valid Loss:  0.4360180199146271
Epoch:  142  	Training Loss: 0.42651623487472534
Test Loss:  0.4238646328449249
Valid Loss:  0.4333181083202362
Epoch:  143  	Training Loss: 0.4238331615924835
Test Loss:  0.4211672246456146
Valid Loss:  0.4306355118751526
Epoch:  144  	Training Loss: 0.4211673438549042
Test Loss:  0.41848719120025635
Valid Loss:  0.42797020077705383
Epoch:  145  	Training Loss: 0.4185188114643097
Test Loss:  0.41582444310188293
Valid Loss:  0.4253218472003937
Epoch:  146  	Training Loss: 0.4158872365951538
Test Loss:  0.41317886114120483
Valid Loss:  0.42269042134284973
Epoch:  147  	Training Loss: 0.4132726490497589
Test Loss:  0.41055047512054443
Valid Loss:  0.42007601261138916
Epoch:  148  	Training Loss: 0.4106751084327698
Test Loss:  0.40793919563293457
Valid Loss:  0.41747838258743286
Epoch:  149  	Training Loss: 0.4080945551395416
Test Loss:   30%|██▉       | 149/500 [01:41<01:56,  3.02it/s] 30%|███       | 151/500 [01:48<06:46,  1.17s/it] 31%|███       | 153/500 [01:48<04:50,  1.19it/s] 31%|███       | 155/500 [01:48<03:28,  1.65it/s] 31%|███▏      | 157/500 [01:48<02:32,  2.26it/s] 32%|███▏      | 159/500 [01:48<01:52,  3.03it/s] 32%|███▏      | 161/500 [01:54<06:33,  1.16s/it] 33%|███▎      | 163/500 [01:55<04:41,  1.20it/s] 33%|███▎      | 165/500 [01:55<03:22,  1.66it/s] 33%|███▎      | 167/500 [01:55<02:27,  2.26it/s] 34%|███▍      | 169/500 [01:55<01:48,  3.04it/s] 34%|███▍      | 171/500 [02:01<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:01<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:08<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:08<04:31,  1.17it/s] 37%|███▋      | 185/500 [02:08<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:09<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:09<01:44,  2.97it/s] 38%|███▊      | 191/500 [02:15<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:15<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:15<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:16<01:40,  2.99it/s] 40%|████      | 201/500 [02:22<05:55,  1.19s/it] 41%|████      | 203/500 [02:22<04:13,  1.17it/s] 41%|████      | 205/500 [02:22<03:01,  1.62it/s] 41%|████▏     | 207/500 [02:22<02:12,  2.22it/s] 42%|████▏     | 209/500 [02:22<01:37,  2.98it/s] 42%|████▏     | 211/500 [02:29<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:29<02:52,  1.65it/s] 43%|████▎     | 217/500 [02:29<02:05,  2.25it/s] 44%|████▍     | 219/500 [02:29<01:33,  2.99it/s] 44%|████▍     | 221/500 [02:36<05:29,  1.18s/it]0.4053448438644409
Valid Loss:  0.41489744186401367
Epoch:  150  	Training Loss: 0.4055306911468506
Test Loss:  0.4027673006057739
Valid Loss:  0.4123331904411316
Epoch:  151  	Training Loss: 0.4029833972454071
Test Loss:  0.4002063274383545
Valid Loss:  0.4097852408885956
Epoch:  152  	Training Loss: 0.4004526138305664
Test Loss:  0.3972739279270172
Valid Loss:  0.40686672925949097
Epoch:  153  	Training Loss: 0.39755457639694214
Test Loss:  0.39437276124954224
Valid Loss:  0.40397918224334717
Epoch:  154  	Training Loss: 0.3946874439716339
Test Loss:  0.3915025591850281
Valid Loss:  0.40112221240997314
Epoch:  155  	Training Loss: 0.3918508291244507
Test Loss:  0.3886626958847046
Valid Loss:  0.3982953727245331
Epoch:  156  	Training Loss: 0.38904422521591187
Test Loss:  0.3858528435230255
Valid Loss:  0.3954981863498688
Epoch:  157  	Training Loss: 0.3862672448158264
Test Loss:  0.3830726146697998
Valid Loss:  0.39273035526275635
Epoch:  158  	Training Loss: 0.3835195004940033
Test Loss:  0.3803216814994812
Valid Loss:  0.38999152183532715
Epoch:  159  	Training Loss: 0.38080084323883057
Test Loss:  0.37759965658187866
Valid Loss:  0.3872813582420349
Epoch:  160  	Training Loss: 0.37811076641082764
Test Loss:  0.37490612268447876
Valid Loss:  0.3845992982387543
Epoch:  161  	Training Loss: 0.3754487633705139
Test Loss:  0.37224119901657104
Valid Loss:  0.38194510340690613
Epoch:  162  	Training Loss: 0.37281450629234314
Test Loss:  0.3698241114616394
Valid Loss:  0.3795379102230072
Epoch:  163  	Training Loss: 0.37042567133903503
Test Loss:  0.367423415184021
Valid Loss:  0.3771468698978424
Epoch:  164  	Training Loss: 0.36805295944213867
Test Loss:  0.3650391101837158
Valid Loss:  0.37477201223373413
Epoch:  165  	Training Loss: 0.36569643020629883
Test Loss:  0.3626708984375
Valid Loss:  0.37241315841674805
Epoch:  166  	Training Loss: 0.3633558452129364
Test Loss:  0.3603189289569855
Valid Loss:  0.37007027864456177
Epoch:  167  	Training Loss: 0.3610312342643738
Test Loss:  0.3579828441143036
Valid Loss:  0.3677431344985962
Epoch:  168  	Training Loss: 0.3587223291397095
Test Loss:  0.3556627631187439
Valid Loss:  0.3654317855834961
Epoch:  169  	Training Loss: 0.35642921924591064
Test Loss:  0.3533583879470825
Valid Loss:  0.3631359934806824
Epoch:  170  	Training Loss: 0.3541516065597534
Test Loss:  0.3510698080062866
Valid Loss:  0.36085569858551025
Epoch:  171  	Training Loss: 0.35188958048820496
Test Loss:  0.3487967550754547
Valid Loss:  0.35859084129333496
Epoch:  172  	Training Loss: 0.34964287281036377
Test Loss:  0.3465522825717926
Valid Loss:  0.35635489225387573
Epoch:  173  	Training Loss: 0.3474244773387909
Test Loss:  0.34432321786880493
Valid Loss:  0.35413435101509094
Epoch:  174  	Training Loss: 0.34522128105163574
Test Loss:  0.34210941195487976
Valid Loss:  0.3519288897514343
Epoch:  175  	Training Loss: 0.34303322434425354
Test Loss:  0.33991092443466187
Valid Loss:  0.3497384786605835
Epoch:  176  	Training Loss: 0.34086015820503235
Test Loss:  0.33772745728492737
Valid Loss:  0.3475629687309265
Epoch:  177  	Training Loss: 0.3387020230293274
Test Loss:  0.3355589509010315
Valid Loss:  0.34540224075317383
Epoch:  178  	Training Loss: 0.33655861020088196
Test Loss:  0.3334053158760071
Valid Loss:  0.3432562053203583
Epoch:  179  	Training Loss: 0.33442986011505127
Test Loss:  0.33126652240753174
Valid Loss:  0.34112483263015747
Epoch:  180  	Training Loss: 0.3323157727718353
Test Loss:  0.32914233207702637
Valid Loss:  0.33900851011276245
Epoch:  181  	Training Loss: 0.33021605014801025
Test Loss:  0.3270328640937805
Valid Loss:  0.3369065821170807
Epoch:  182  	Training Loss: 0.32813072204589844
Test Loss:  0.3249635398387909
Valid Loss:  0.3348439931869507
Epoch:  183  	Training Loss: 0.32608461380004883
Test Loss:  0.3229079246520996
Valid Loss:  0.3327949047088623
Epoch:  184  	Training Loss: 0.32405200600624084
Test Loss:  0.3208659291267395
Valid Loss:  0.33075931668281555
Epoch:  185  	Training Loss: 0.3220328092575073
Test Loss:  0.3188374638557434
Valid Loss:  0.3287371098995209
Epoch:  186  	Training Loss: 0.3200269937515259
Test Loss:  0.3168224096298218
Valid Loss:  0.32672813534736633
Epoch:  187  	Training Loss: 0.31803444027900696
Test Loss:  0.3148207366466522
Valid Loss:  0.3247324228286743
Epoch:  188  	Training Loss: 0.3160551190376282
Test Loss:  0.3128322958946228
Valid Loss:  0.3227497339248657
Epoch:  189  	Training Loss: 0.3140888214111328
Test Loss:  0.31085705757141113
Valid Loss:  0.32078009843826294
Epoch:  190  	Training Loss: 0.31213557720184326
Test Loss:  0.30889493227005005
Valid Loss:  0.3188234567642212
Epoch:  191  	Training Loss: 0.31019526720046997
Test Loss:  0.30694580078125
Valid Loss:  0.31687963008880615
Epoch:  192  	Training Loss: 0.30826783180236816
Test Loss:  0.3049359917640686
Valid Loss:  0.3148750066757202
Epoch:  193  	Training Loss: 0.3062799572944641
Test Loss:  0.3029404580593109
Valid Loss:  0.31288450956344604
Epoch:  194  	Training Loss: 0.3043062388896942
Test Loss:  0.30095916986465454
Valid Loss:  0.31090807914733887
Epoch:  195  	Training Loss: 0.3023465573787689
Test Loss:  0.2989920377731323
Valid Loss:  0.3089456856250763
Epoch:  196  	Training Loss: 0.30040085315704346
Test Loss:  0.2970389127731323
Valid Loss:  0.3069971203804016
Epoch:  197  	Training Loss: 0.2984689772129059
Test Loss:  0.29509973526000977
Valid Loss:  0.30506235361099243
Epoch:  198  	Training Loss: 0.2965508997440338
Test Loss:  0.2931743860244751
Valid Loss:  0.3031412363052368
Epoch:  199  	Training Loss: 0.2946464717388153
Test Loss:  0.29126274585723877
Valid Loss:  0.3012337386608124
Epoch:  200  	Training Loss: 0.2927556037902832
Test Loss:  0.2893648147583008
Valid Loss:  0.29933974146842957
Epoch:  201  	Training Loss: 0.2908782660961151
Test Loss:  0.28748029470443726
Valid Loss:  0.29745906591415405
Epoch:  202  	Training Loss: 0.28901416063308716
Test Loss:  0.2856300175189972
Valid Loss:  0.2956124246120453
Epoch:  203  	Training Loss: 0.28718405961990356
Test Loss:  0.28379249572753906
Valid Loss:  0.2937784194946289
Epoch:  204  	Training Loss: 0.28536662459373474
Test Loss:  0.2819676399230957
Valid Loss:  0.29195693135261536
Epoch:  205  	Training Loss: 0.2835616171360016
Test Loss:  0.28015536069869995
Valid Loss:  0.29014790058135986
Epoch:  206  	Training Loss: 0.2817690372467041
Test Loss:  0.27835556864738464
Valid Loss:  0.2883511483669281
Epoch:  207  	Training Loss: 0.2799888253211975
Test Loss:  0.2765681743621826
Valid Loss:  0.28656670451164246
Epoch:  208  	Training Loss: 0.2782208323478699
Test Loss:  0.2747930884361267
Valid Loss:  0.2847944498062134
Epoch:  209  	Training Loss: 0.2764649987220764
Test Loss:  0.27303025126457214
Valid Loss:  0.2830342650413513
Epoch:  210  	Training Loss: 0.27472126483917236
Test Loss:  0.27127954363822937
Valid Loss:  0.2812860906124115
Epoch:  211  	Training Loss: 0.2729894518852234
Test Loss:  0.26954081654548645
Valid Loss:  0.279549777507782
Epoch:  212  	Training Loss: 0.2712695598602295
Test Loss:  0.26782840490341187
Valid Loss:  0.277839720249176
Epoch:  213  	Training Loss: 0.2695758044719696
Test Loss:  0.26612770557403564
Valid Loss:  0.2761411666870117
Epoch:  214  	Training Loss: 0.26789361238479614
Test Loss:  0.2644386291503906
Valid Loss:  0.27445411682128906
Epoch:  215  	Training Loss: 0.26622286438941956
Test Loss:  0.26276111602783203
Valid Loss:  0.27277857065200806
Epoch:  216  	Training Loss: 0.26456356048583984
Test Loss:  0.2610950469970703
Valid Loss:  0.271114319562912
Epoch:  217  	Training Loss: 0.26291561126708984
Test Loss:  0.25944042205810547
Valid Loss:  0.26946136355400085
Epoch:  218  	Training Loss: 0.2612788677215576
Test Loss:  0.2577970623970032
Valid Loss:  0.2678195834159851
Epoch:  219  	Training Loss: 0.25965332984924316
Test Loss:  0.2561652958393097
Valid Loss:  0.26618891954421997
Epoch:  220  	Training Loss: 0.2580389380455017
Test Loss:  0.2545449137687683
Valid Loss:  0.26456934213638306
Epoch:  221  	Training Loss: 0.2564355134963989
Test Loss:  0.25293561816215515
Valid Loss:  0.2629607021808624
Epoch:  222  	Training Loss: 0.2548430562019348
Test Loss:   45%|████▍     | 223/500 [02:36<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:36<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:36<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:42<05:16,  1.18s/it] 47%|████▋     | 233/500 [02:42<03:45,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:49<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:49<03:36,  1.18it/s] 49%|████▉     | 245/500 [02:49<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.01it/s] 50%|█████     | 251/500 [02:56<04:52,  1.18s/it] 51%|█████     | 253/500 [02:56<03:28,  1.18it/s] 51%|█████     | 255/500 [02:56<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:56<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:57<01:20,  3.00it/s] 52%|█████▏    | 261/500 [03:03<04:39,  1.17s/it] 53%|█████▎    | 263/500 [03:03<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:03<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:03<01:43,  2.25it/s] 54%|█████▍    | 269/500 [03:03<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:09<04:26,  1.16s/it] 55%|█████▍    | 273/500 [03:10<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:10<02:16,  1.65it/s] 55%|█████▌    | 277/500 [03:10<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:10<01:14,  2.98it/s] 56%|█████▌    | 281/500 [03:16<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:16<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:34,  2.26it/s] 58%|█████▊    | 289/500 [03:17<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:23<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:23<02:54,  1.19it/s]0.25134024024009705
Valid Loss:  0.2613658308982849
Epoch:  223  	Training Loss: 0.2532643675804138
Test Loss:  0.2497558295726776
Valid Loss:  0.2597818374633789
Epoch:  224  	Training Loss: 0.2516965866088867
Test Loss:  0.24818240106105804
Valid Loss:  0.2582087516784668
Epoch:  225  	Training Loss: 0.25013962388038635
Test Loss:  0.24661996960639954
Valid Loss:  0.2566465139389038
Epoch:  226  	Training Loss: 0.2485934942960739
Test Loss:  0.24506832659244537
Valid Loss:  0.2550949454307556
Epoch:  227  	Training Loss: 0.24705804884433746
Test Loss:  0.24352748692035675
Valid Loss:  0.2535540759563446
Epoch:  228  	Training Loss: 0.24553325772285461
Test Loss:  0.24199725687503815
Valid Loss:  0.25202369689941406
Epoch:  229  	Training Loss: 0.24401891231536865
Test Loss:  0.24047771096229553
Valid Loss:  0.25050389766693115
Epoch:  230  	Training Loss: 0.24251514673233032
Test Loss:  0.23896858096122742
Valid Loss:  0.24899446964263916
Epoch:  231  	Training Loss: 0.24102169275283813
Test Loss:  0.23747003078460693
Valid Loss:  0.24749541282653809
Epoch:  232  	Training Loss: 0.23953869938850403
Test Loss:  0.23596662282943726
Valid Loss:  0.2459915280342102
Epoch:  233  	Training Loss: 0.23805058002471924
Test Loss:  0.23447385430335999
Valid Loss:  0.24449823796749115
Epoch:  234  	Training Loss: 0.2365730106830597
Test Loss:  0.23299168050289154
Valid Loss:  0.24301539361476898
Epoch:  235  	Training Loss: 0.23510593175888062
Test Loss:  0.2315199375152588
Valid Loss:  0.24154287576675415
Epoch:  236  	Training Loss: 0.2336490899324417
Test Loss:  0.23005862534046173
Valid Loss:  0.24008069932460785
Epoch:  237  	Training Loss: 0.23220258951187134
Test Loss:  0.22860755026340485
Valid Loss:  0.23862870037555695
Epoch:  238  	Training Loss: 0.23076622188091278
Test Loss:  0.22716684639453888
Valid Loss:  0.23718689382076263
Epoch:  239  	Training Loss: 0.22934004664421082
Test Loss:  0.22573624551296234
Valid Loss:  0.23575516045093536
Epoch:  240  	Training Loss: 0.2279238998889923
Test Loss:  0.22431574761867523
Valid Loss:  0.2343333661556244
Epoch:  241  	Training Loss: 0.2265177071094513
Test Loss:  0.22290527820587158
Valid Loss:  0.2329215556383133
Epoch:  242  	Training Loss: 0.22512145340442657
Test Loss:  0.2214922308921814
Valid Loss:  0.231506809592247
Epoch:  243  	Training Loss: 0.22372257709503174
Test Loss:  0.2200894057750702
Valid Loss:  0.23010224103927612
Epoch:  244  	Training Loss: 0.22233381867408752
Test Loss:  0.2186969369649887
Valid Loss:  0.22870787978172302
Epoch:  245  	Training Loss: 0.2209552526473999
Test Loss:  0.21731451153755188
Valid Loss:  0.2273235023021698
Epoch:  246  	Training Loss: 0.21958662569522858
Test Loss:  0.21594221889972687
Valid Loss:  0.22594915330410004
Epoch:  247  	Training Loss: 0.2182280272245407
Test Loss:  0.21457983553409576
Valid Loss:  0.22458459436893463
Epoch:  248  	Training Loss: 0.21687918901443481
Test Loss:  0.21322733163833618
Valid Loss:  0.22322985529899597
Epoch:  249  	Training Loss: 0.21554014086723328
Test Loss:  0.2118847370147705
Valid Loss:  0.22188493609428406
Epoch:  250  	Training Loss: 0.21421083807945251
Test Loss:  0.21055182814598083
Valid Loss:  0.22054961323738098
Epoch:  251  	Training Loss: 0.21289116144180298
Test Loss:  0.20922867953777313
Valid Loss:  0.21922393143177032
Epoch:  252  	Training Loss: 0.2115810662508011
Test Loss:  0.20792865753173828
Valid Loss:  0.21792149543762207
Epoch:  253  	Training Loss: 0.21029403805732727
Test Loss:  0.20663809776306152
Valid Loss:  0.21662846207618713
Epoch:  254  	Training Loss: 0.20901638269424438
Test Loss:  0.20535701513290405
Valid Loss:  0.21534478664398193
Epoch:  255  	Training Loss: 0.20774804055690765
Test Loss:  0.204085111618042
Valid Loss:  0.21407023072242737
Epoch:  256  	Training Loss: 0.20648881793022156
Test Loss:  0.2028225064277649
Valid Loss:  0.2128048837184906
Epoch:  257  	Training Loss: 0.2052387297153473
Test Loss:  0.2015690803527832
Valid Loss:  0.2115486115217209
Epoch:  258  	Training Loss: 0.20399773120880127
Test Loss:  0.20032477378845215
Valid Loss:  0.21030139923095703
Epoch:  259  	Training Loss: 0.20276571810245514
Test Loss:  0.1990894228219986
Valid Loss:  0.2090630829334259
Epoch:  260  	Training Loss: 0.20154258608818054
Test Loss:  0.19786307215690613
Valid Loss:  0.20783361792564392
Epoch:  261  	Training Loss: 0.2003282904624939
Test Loss:  0.1966455578804016
Valid Loss:  0.2066129893064499
Epoch:  262  	Training Loss: 0.19912278652191162
Test Loss:  0.19544173777103424
Valid Loss:  0.20540618896484375
Epoch:  263  	Training Loss: 0.19793091714382172
Test Loss:  0.19424685835838318
Valid Loss:  0.20420821011066437
Epoch:  264  	Training Loss: 0.19674785435199738
Test Loss:  0.19306081533432007
Valid Loss:  0.20301903784275055
Epoch:  265  	Training Loss: 0.19557353854179382
Test Loss:  0.19188353419303894
Valid Loss:  0.20183853805065155
Epoch:  266  	Training Loss: 0.1944078952074051
Test Loss:  0.1907149851322174
Valid Loss:  0.2006666660308838
Epoch:  267  	Training Loss: 0.193250834941864
Test Loss:  0.1895550787448883
Valid Loss:  0.1995033621788025
Epoch:  268  	Training Loss: 0.192102313041687
Test Loss:  0.18840371072292328
Valid Loss:  0.1983485370874405
Epoch:  269  	Training Loss: 0.19096224009990692
Test Loss:  0.18726083636283875
Valid Loss:  0.1972021460533142
Epoch:  270  	Training Loss: 0.18983055651187897
Test Loss:  0.18612639605998993
Valid Loss:  0.19606409966945648
Epoch:  271  	Training Loss: 0.1887071579694748
Test Loss:  0.18500028550624847
Valid Loss:  0.19493433833122253
Epoch:  272  	Training Loss: 0.1875920444726944
Test Loss:  0.18387369811534882
Valid Loss:  0.19380399584770203
Epoch:  273  	Training Loss: 0.18647626042366028
Test Loss:  0.18275539577007294
Valid Loss:  0.19268187880516052
Epoch:  274  	Training Loss: 0.18536868691444397
Test Loss:  0.18164527416229248
Valid Loss:  0.1915678232908249
Epoch:  275  	Training Loss: 0.18426921963691711
Test Loss:  0.18054361641407013
Valid Loss:  0.1904621720314026
Epoch:  276  	Training Loss: 0.18317832052707672
Test Loss:  0.17945003509521484
Valid Loss:  0.18936452269554138
Epoch:  277  	Training Loss: 0.18209537863731384
Test Loss:  0.17836451530456543
Valid Loss:  0.18827486038208008
Epoch:  278  	Training Loss: 0.18102039396762848
Test Loss:  0.17728687822818756
Valid Loss:  0.18719297647476196
Epoch:  279  	Training Loss: 0.1799534261226654
Test Loss:  0.17621742188930511
Valid Loss:  0.1861192137002945
Epoch:  280  	Training Loss: 0.1788945347070694
Test Loss:  0.17515577375888824
Valid Loss:  0.18505319952964783
Epoch:  281  	Training Loss: 0.1778433620929718
Test Loss:  0.17410188913345337
Valid Loss:  0.1839948296546936
Epoch:  282  	Training Loss: 0.17679986357688904
Test Loss:  0.1730322241783142
Valid Loss:  0.1829201877117157
Epoch:  283  	Training Loss: 0.17573945224285126
Test Loss:  0.171970933675766
Valid Loss:  0.18185344338417053
Epoch:  284  	Training Loss: 0.17468687891960144
Test Loss:  0.17091700434684753
Valid Loss:  0.18079400062561035
Epoch:  285  	Training Loss: 0.1736416071653366
Test Loss:  0.16987046599388123
Valid Loss:  0.17974187433719635
Epoch:  286  	Training Loss: 0.17260363698005676
Test Loss:  0.1688312292098999
Valid Loss:  0.17869701981544495
Epoch:  287  	Training Loss: 0.17157289385795593
Test Loss:  0.16779932379722595
Valid Loss:  0.17765940725803375
Epoch:  288  	Training Loss: 0.1705493927001953
Test Loss:  0.16677546501159668
Valid Loss:  0.1766289323568344
Epoch:  289  	Training Loss: 0.16953301429748535
Test Loss:  0.16575932502746582
Valid Loss:  0.17560558021068573
Epoch:  290  	Training Loss: 0.16852369904518127
Test Loss:  0.16475032269954681
Valid Loss:  0.17458927631378174
Epoch:  291  	Training Loss: 0.1675214320421219
Test Loss:  0.16374832391738892
Valid Loss:  0.17357997596263885
Epoch:  292  	Training Loss: 0.1665261685848236
Test Loss:  0.16274617612361908
Valid Loss:  0.17257890105247498
Epoch:  293  	Training Loss: 0.16553688049316406
Test Loss:  0.16203954815864563
Valid Loss:  0.17192372679710388
Epoch:  294  	Training Loss: 0.16486936807632446
Test Loss:  0.16171526908874512
Valid Loss:  0.1716073751449585
 59%|█████▉    | 295/500 [03:23<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.01it/s] 60%|██████    | 301/500 [03:30<03:52,  1.17s/it] 61%|██████    | 303/500 [03:30<02:45,  1.19it/s] 61%|██████    | 305/500 [03:30<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:30<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:30<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:37<03:39,  1.16s/it] 63%|██████▎   | 313/500 [03:37<02:36,  1.20it/s] 63%|██████▎   | 315/500 [03:37<01:51,  1.66it/s] 63%|██████▎   | 317/500 [03:37<01:21,  2.26it/s] 64%|██████▍   | 319/500 [03:37<00:59,  3.03it/s] 64%|██████▍   | 321/500 [03:44<03:35,  1.20s/it] 65%|██████▍   | 323/500 [03:44<02:32,  1.16it/s] 65%|██████▌   | 325/500 [03:44<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:44<01:18,  2.20it/s] 66%|██████▌   | 329/500 [03:44<00:57,  2.96it/s] 66%|██████▌   | 331/500 [03:51<03:20,  1.19s/it] 67%|██████▋   | 333/500 [03:51<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:51<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:51<01:13,  2.22it/s] 68%|██████▊   | 339/500 [03:51<00:54,  2.98it/s] 68%|██████▊   | 341/500 [03:57<03:07,  1.18s/it] 69%|██████▊   | 343/500 [03:57<02:13,  1.18it/s] 69%|██████▉   | 345/500 [03:58<01:35,  1.63it/s] 69%|██████▉   | 347/500 [03:58<01:08,  2.23it/s] 70%|██████▉   | 349/500 [03:58<00:50,  3.00it/s] 70%|███████   | 351/500 [04:04<02:56,  1.18s/it] 71%|███████   | 353/500 [04:04<02:04,  1.18it/s] 71%|███████   | 355/500 [04:04<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:05<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:05<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:11<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:11<01:55,  1.19it/s] 73%|███████▎  | 365/500 [04:11<01:22,  1.64it/s]Epoch:  295  	Training Loss: 0.16453763842582703
Test Loss:  0.16156169772148132
Valid Loss:  0.17143641412258148
Epoch:  296  	Training Loss: 0.16436326503753662
Test Loss:  0.16147685050964355
Valid Loss:  0.17133387923240662
Epoch:  297  	Training Loss: 0.1642679125070572
Test Loss:  0.1614285409450531
Valid Loss:  0.17127227783203125
Epoch:  298  	Training Loss: 0.16421276330947876
Test Loss:  0.16139152646064758
Valid Loss:  0.17123086750507355
Epoch:  299  	Training Loss: 0.16416847705841064
Test Loss:  0.16136068105697632
Valid Loss:  0.17119696736335754
Epoch:  300  	Training Loss: 0.16413366794586182
Test Loss:  0.16133058071136475
Valid Loss:  0.17116492986679077
Epoch:  301  	Training Loss: 0.1641024947166443
Test Loss:  0.16130143404006958
Valid Loss:  0.17113351821899414
Epoch:  302  	Training Loss: 0.16407276690006256
Test Loss:  0.16127198934555054
Valid Loss:  0.1711016148328781
Epoch:  303  	Training Loss: 0.16404277086257935
Test Loss:  0.1612425595521927
Valid Loss:  0.1710698902606964
Epoch:  304  	Training Loss: 0.16401290893554688
Test Loss:  0.16121312975883484
Valid Loss:  0.17103850841522217
Epoch:  305  	Training Loss: 0.16398322582244873
Test Loss:  0.16118371486663818
Valid Loss:  0.1710071563720703
Epoch:  306  	Training Loss: 0.16395354270935059
Test Loss:  0.16115431487560272
Valid Loss:  0.17097583413124084
Epoch:  307  	Training Loss: 0.16392427682876587
Test Loss:  0.1611253321170807
Valid Loss:  0.170944944024086
Epoch:  308  	Training Loss: 0.16389545798301697
Test Loss:  0.16109636425971985
Valid Loss:  0.17091405391693115
Epoch:  309  	Training Loss: 0.16386663913726807
Test Loss:  0.161067396402359
Valid Loss:  0.1708831936120987
Epoch:  310  	Training Loss: 0.16383783519268036
Test Loss:  0.16103845834732056
Valid Loss:  0.17085231840610504
Epoch:  311  	Training Loss: 0.16380903124809265
Test Loss:  0.1610095053911209
Valid Loss:  0.17082147300243378
Epoch:  312  	Training Loss: 0.16378024220466614
Test Loss:  0.1609800010919571
Valid Loss:  0.17078998684883118
Epoch:  313  	Training Loss: 0.16375088691711426
Test Loss:  0.16095048189163208
Valid Loss:  0.17075853049755096
Epoch:  314  	Training Loss: 0.16372153162956238
Test Loss:  0.16092097759246826
Valid Loss:  0.17072705924510956
Epoch:  315  	Training Loss: 0.1636921763420105
Test Loss:  0.16089148819446564
Valid Loss:  0.17069561779499054
Epoch:  316  	Training Loss: 0.163662850856781
Test Loss:  0.1608620136976242
Valid Loss:  0.17066419124603271
Epoch:  317  	Training Loss: 0.1636335253715515
Test Loss:  0.16083255410194397
Valid Loss:  0.1706327497959137
Epoch:  318  	Training Loss: 0.16360419988632202
Test Loss:  0.16080310940742493
Valid Loss:  0.17060133814811707
Epoch:  319  	Training Loss: 0.16357487440109253
Test Loss:  0.1607736498117447
Valid Loss:  0.17056992650032043
Epoch:  320  	Training Loss: 0.16354557871818542
Test Loss:  0.16074420511722565
Valid Loss:  0.1705385446548462
Epoch:  321  	Training Loss: 0.16351628303527832
Test Loss:  0.1607147753238678
Valid Loss:  0.17050716280937195
Epoch:  322  	Training Loss: 0.1634870171546936
Test Loss:  0.16068480908870697
Valid Loss:  0.17047517001628876
Epoch:  323  	Training Loss: 0.16345717012882233
Test Loss:  0.16065481305122375
Valid Loss:  0.17044319212436676
Epoch:  324  	Training Loss: 0.16342750191688538
Test Loss:  0.16062530875205994
Valid Loss:  0.17041167616844177
Epoch:  325  	Training Loss: 0.16339866816997528
Test Loss:  0.16059623658657074
Valid Loss:  0.170380637049675
Epoch:  326  	Training Loss: 0.1633705496788025
Test Loss:  0.16056716442108154
Valid Loss:  0.1703496128320694
Epoch:  327  	Training Loss: 0.1633424460887909
Test Loss:  0.16053810715675354
Valid Loss:  0.1703185737133026
Epoch:  328  	Training Loss: 0.1633143573999405
Test Loss:  0.16050933301448822
Valid Loss:  0.1702875792980194
Epoch:  329  	Training Loss: 0.1632862687110901
Test Loss:  0.1604819893836975
Valid Loss:  0.1702565848827362
Epoch:  330  	Training Loss: 0.16325819492340088
Test Loss:  0.1604546308517456
Valid Loss:  0.170225590467453
Epoch:  331  	Training Loss: 0.16323012113571167
Test Loss:  0.16042876243591309
Valid Loss:  0.170194610953331
Epoch:  332  	Training Loss: 0.16320206224918365
Test Loss:  0.1604025810956955
Valid Loss:  0.17016300559043884
Epoch:  333  	Training Loss: 0.16317342221736908
Test Loss:  0.1603764295578003
Valid Loss:  0.17013141512870789
Epoch:  334  	Training Loss: 0.1631447970867157
Test Loss:  0.16035029292106628
Valid Loss:  0.17009982466697693
Epoch:  335  	Training Loss: 0.1631161868572235
Test Loss:  0.16032415628433228
Valid Loss:  0.17006823420524597
Epoch:  336  	Training Loss: 0.1630876064300537
Test Loss:  0.16029801964759827
Valid Loss:  0.1700366735458374
Epoch:  337  	Training Loss: 0.16305899620056152
Test Loss:  0.16027188301086426
Valid Loss:  0.17000511288642883
Epoch:  338  	Training Loss: 0.16303066909313202
Test Loss:  0.16024616360664368
Valid Loss:  0.16997404396533966
Epoch:  339  	Training Loss: 0.16300295293331146
Test Loss:  0.16022047400474548
Valid Loss:  0.1699429750442505
Epoch:  340  	Training Loss: 0.1629752516746521
Test Loss:  0.16019532084465027
Valid Loss:  0.1699119508266449
Epoch:  341  	Training Loss: 0.16294759511947632
Test Loss:  0.1601717174053192
Valid Loss:  0.16988137364387512
Epoch:  342  	Training Loss: 0.16292104125022888
Test Loss:  0.16014805436134338
Valid Loss:  0.16985072195529938
Epoch:  343  	Training Loss: 0.16289454698562622
Test Loss:  0.16012439131736755
Valid Loss:  0.16982008516788483
Epoch:  344  	Training Loss: 0.16286805272102356
Test Loss:  0.16010072827339172
Valid Loss:  0.16978943347930908
Epoch:  345  	Training Loss: 0.1628415882587433
Test Loss:  0.16007709503173828
Valid Loss:  0.16975882649421692
Epoch:  346  	Training Loss: 0.16281510889530182
Test Loss:  0.16005346179008484
Valid Loss:  0.16972821950912476
Epoch:  347  	Training Loss: 0.16278865933418274
Test Loss:  0.1600298285484314
Valid Loss:  0.1696976125240326
Epoch:  348  	Training Loss: 0.16276219487190247
Test Loss:  0.16000621020793915
Valid Loss:  0.16966700553894043
Epoch:  349  	Training Loss: 0.16273576021194458
Test Loss:  0.1599825918674469
Valid Loss:  0.16963642835617065
Epoch:  350  	Training Loss: 0.1627093255519867
Test Loss:  0.15995898842811584
Valid Loss:  0.16960585117340088
Epoch:  351  	Training Loss: 0.1626828908920288
Test Loss:  0.1599353849887848
Valid Loss:  0.1695753037929535
Epoch:  352  	Training Loss: 0.1626564860343933
Test Loss:  0.15991201996803284
Valid Loss:  0.16954410076141357
Epoch:  353  	Training Loss: 0.16262951493263245
Test Loss:  0.15988969802856445
Valid Loss:  0.16951292753219604
Epoch:  354  	Training Loss: 0.16260257363319397
Test Loss:  0.15986737608909607
Valid Loss:  0.1694817692041397
Epoch:  355  	Training Loss: 0.1625756323337555
Test Loss:  0.15984505414962769
Valid Loss:  0.16945062577724457
Epoch:  356  	Training Loss: 0.1625487059354782
Test Loss:  0.1598227471113205
Valid Loss:  0.16941946744918823
Epoch:  357  	Training Loss: 0.16252177953720093
Test Loss:  0.1598004698753357
Valid Loss:  0.16938833892345428
Epoch:  358  	Training Loss: 0.16249488294124603
Test Loss:  0.1597781777381897
Valid Loss:  0.16935722529888153
Epoch:  359  	Training Loss: 0.16246797144412994
Test Loss:  0.1597558856010437
Valid Loss:  0.16932612657546997
Epoch:  360  	Training Loss: 0.16244108974933624
Test Loss:  0.1597336083650589
Valid Loss:  0.16929501295089722
Epoch:  361  	Training Loss: 0.16241420805454254
Test Loss:  0.15971136093139648
Valid Loss:  0.16926392912864685
Epoch:  362  	Training Loss: 0.16238731145858765
Test Loss:  0.15968866646289825
Valid Loss:  0.16923224925994873
Epoch:  363  	Training Loss: 0.16235995292663574
Test Loss:  0.15966637432575226
Valid Loss:  0.1692006140947342
Epoch:  364  	Training Loss: 0.16233259439468384
Test Loss:  0.15964551270008087
Valid Loss:  0.16916896402835846
Epoch:  365  	Training Loss: 0.16230542957782745
Test Loss:  0.15962499380111694
Valid Loss:  0.1691378653049469
Epoch:  366  	Training Loss: 0.16227898001670837
Test Loss:  0.1596044898033142
Valid Loss:  0.16910675168037415
Epoch:  367  	Training Loss: 0.1622525304555893
 73%|███████▎  | 367/500 [04:11<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:12<00:43,  3.02it/s] 74%|███████▍  | 371/500 [04:18<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:18<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:18<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:18<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:18<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:25<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:25<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:25<01:09,  1.64it/s] 77%|███████▋  | 387/500 [04:25<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:25<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:31<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:32<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:32<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:32<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:32<00:33,  2.99it/s] 80%|████████  | 401/500 [04:38<01:55,  1.17s/it] 81%|████████  | 403/500 [04:38<01:21,  1.19it/s] 81%|████████  | 405/500 [04:39<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.03it/s] 82%|████████▏ | 411/500 [04:45<01:46,  1.19s/it] 83%|████████▎ | 413/500 [04:45<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:45<00:52,  1.61it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.19it/s] 84%|████████▍ | 419/500 [04:46<00:27,  2.94it/s] 84%|████████▍ | 421/500 [04:52<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:52<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:52<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:52<00:32,  2.25it/s] 86%|████████▌ | 429/500 [04:52<00:23,  3.02it/s] 86%|████████▌ | 431/500 [04:59<01:21,  1.18s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.18it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.63it/s] 87%|████████▋ | 437/500 [04:59<00:28,  2.22it/s]Test Loss:  0.15958398580551147
Valid Loss:  0.16907566785812378
Epoch:  368  	Training Loss: 0.1622260957956314
Test Loss:  0.15956401824951172
Valid Loss:  0.1690445989370346
Epoch:  369  	Training Loss: 0.16219967603683472
Test Loss:  0.15954531729221344
Valid Loss:  0.16901351511478424
Epoch:  370  	Training Loss: 0.1621735692024231
Test Loss:  0.15952761471271515
Valid Loss:  0.16898295283317566
Epoch:  371  	Training Loss: 0.16214820742607117
Test Loss:  0.1595112681388855
Valid Loss:  0.16895297169685364
Epoch:  372  	Training Loss: 0.1621236354112625
Test Loss:  0.15949490666389465
Valid Loss:  0.16892299056053162
Epoch:  373  	Training Loss: 0.1620994210243225
Test Loss:  0.1594785749912262
Valid Loss:  0.1688929945230484
Epoch:  374  	Training Loss: 0.1620752215385437
Test Loss:  0.15946224331855774
Valid Loss:  0.16886302828788757
Epoch:  375  	Training Loss: 0.1620510220527649
Test Loss:  0.15944591164588928
Valid Loss:  0.16883307695388794
Epoch:  376  	Training Loss: 0.16202682256698608
Test Loss:  0.15942957997322083
Valid Loss:  0.16880309581756592
Epoch:  377  	Training Loss: 0.16200265288352966
Test Loss:  0.15941324830055237
Valid Loss:  0.16877315938472748
Epoch:  378  	Training Loss: 0.16197848320007324
Test Loss:  0.1593969464302063
Valid Loss:  0.16874322295188904
Epoch:  379  	Training Loss: 0.16195429861545563
Test Loss:  0.15938062965869904
Valid Loss:  0.1687133014202118
Epoch:  380  	Training Loss: 0.1619301438331604
Test Loss:  0.15936432778835297
Valid Loss:  0.16868337988853455
Epoch:  381  	Training Loss: 0.1619066447019577
Test Loss:  0.15934860706329346
Valid Loss:  0.16865454614162445
Epoch:  382  	Training Loss: 0.16188418865203857
Test Loss:  0.15933261811733246
Valid Loss:  0.16862522065639496
Epoch:  383  	Training Loss: 0.1618613749742508
Test Loss:  0.15931664407253265
Valid Loss:  0.16859591007232666
Epoch:  384  	Training Loss: 0.161838561296463
Test Loss:  0.15930068492889404
Valid Loss:  0.16856661438941956
Epoch:  385  	Training Loss: 0.16181576251983643
Test Loss:  0.15928500890731812
Valid Loss:  0.16853787004947662
Epoch:  386  	Training Loss: 0.1617937982082367
Test Loss:  0.1592693328857422
Valid Loss:  0.16850915551185608
Epoch:  387  	Training Loss: 0.16177186369895935
Test Loss:  0.15925367176532745
Valid Loss:  0.16848042607307434
Epoch:  388  	Training Loss: 0.16174989938735962
Test Loss:  0.1592380255460739
Valid Loss:  0.1684516966342926
Epoch:  389  	Training Loss: 0.16172796487808228
Test Loss:  0.15922236442565918
Valid Loss:  0.16842299699783325
Epoch:  390  	Training Loss: 0.16170603036880493
Test Loss:  0.15920671820640564
Valid Loss:  0.1683942973613739
Epoch:  391  	Training Loss: 0.16168412566184998
Test Loss:  0.1591910719871521
Valid Loss:  0.16836561262607574
Epoch:  392  	Training Loss: 0.16166220605373383
Test Loss:  0.15917518734931946
Valid Loss:  0.16833648085594177
Epoch:  393  	Training Loss: 0.16163992881774902
Test Loss:  0.15915930271148682
Valid Loss:  0.1683073341846466
Epoch:  394  	Training Loss: 0.1616176813840866
Test Loss:  0.15914341807365417
Valid Loss:  0.16827821731567383
Epoch:  395  	Training Loss: 0.1615954339504242
Test Loss:  0.15912753343582153
Valid Loss:  0.16824913024902344
Epoch:  396  	Training Loss: 0.16157320141792297
Test Loss:  0.15911166369915009
Valid Loss:  0.16822001338005066
Epoch:  397  	Training Loss: 0.16155095398426056
Test Loss:  0.15909579396247864
Valid Loss:  0.16819091141223907
Epoch:  398  	Training Loss: 0.16152870655059814
Test Loss:  0.15907993912696838
Valid Loss:  0.16816183924674988
Epoch:  399  	Training Loss: 0.1615065038204193
Test Loss:  0.15906405448913574
Valid Loss:  0.16813276708126068
Epoch:  400  	Training Loss: 0.16148430109024048
Test Loss:  0.15904822945594788
Valid Loss:  0.16810369491577148
Epoch:  401  	Training Loss: 0.1614621877670288
Test Loss:  0.1590326726436615
Valid Loss:  0.16807521879673004
Epoch:  402  	Training Loss: 0.16144084930419922
Test Loss:  0.1590169370174408
Valid Loss:  0.16804632544517517
Epoch:  403  	Training Loss: 0.16141921281814575
Test Loss:  0.1590011864900589
Valid Loss:  0.16801747679710388
Epoch:  404  	Training Loss: 0.16139759123325348
Test Loss:  0.1589854508638382
Valid Loss:  0.1679885983467102
Epoch:  405  	Training Loss: 0.1613759696483612
Test Loss:  0.1589697301387787
Valid Loss:  0.1679597645998001
Epoch:  406  	Training Loss: 0.16135436296463013
Test Loss:  0.15895399451255798
Valid Loss:  0.16793091595172882
Epoch:  407  	Training Loss: 0.16133275628089905
Test Loss:  0.15893828868865967
Valid Loss:  0.16790208220481873
Epoch:  408  	Training Loss: 0.16131114959716797
Test Loss:  0.15892256796360016
Valid Loss:  0.16787326335906982
Epoch:  409  	Training Loss: 0.16128955781459808
Test Loss:  0.15890684723854065
Valid Loss:  0.16784444451332092
Epoch:  410  	Training Loss: 0.1612679660320282
Test Loss:  0.15889114141464233
Valid Loss:  0.16781562566757202
Epoch:  411  	Training Loss: 0.1612463891506195
Test Loss:  0.15887543559074402
Valid Loss:  0.1677868366241455
Epoch:  412  	Training Loss: 0.161224827170372
Test Loss:  0.15885955095291138
Valid Loss:  0.16775770485401154
Epoch:  413  	Training Loss: 0.16120298206806183
Test Loss:  0.15884366631507874
Valid Loss:  0.16772855818271637
Epoch:  414  	Training Loss: 0.16118115186691284
Test Loss:  0.1588277816772461
Valid Loss:  0.1676994264125824
Epoch:  415  	Training Loss: 0.16115933656692505
Test Loss:  0.15881189703941345
Valid Loss:  0.16767042875289917
Epoch:  416  	Training Loss: 0.16113750636577606
Test Loss:  0.1587960124015808
Valid Loss:  0.16764435172080994
Epoch:  417  	Training Loss: 0.16111576557159424
Test Loss:  0.15878048539161682
Valid Loss:  0.16761928796768188
Epoch:  418  	Training Loss: 0.1610948145389557
Test Loss:  0.15876494348049164
Valid Loss:  0.16759470105171204
Epoch:  419  	Training Loss: 0.161074697971344
Test Loss:  0.1587500274181366
Valid Loss:  0.16757233440876007
Epoch:  420  	Training Loss: 0.16105547547340393
Test Loss:  0.15873515605926514
Valid Loss:  0.1675499975681305
Epoch:  421  	Training Loss: 0.16103625297546387
Test Loss:  0.1587202548980713
Valid Loss:  0.16752764582633972
Epoch:  422  	Training Loss: 0.1610170304775238
Test Loss:  0.1587052345275879
Valid Loss:  0.16750505566596985
Epoch:  423  	Training Loss: 0.16099761426448822
Test Loss:  0.15869015455245972
Valid Loss:  0.16748246550559998
Epoch:  424  	Training Loss: 0.16097818315029144
Test Loss:  0.158676415681839
Valid Loss:  0.1674599051475525
Epoch:  425  	Training Loss: 0.16095876693725586
Test Loss:  0.1586630493402481
Valid Loss:  0.1674388349056244
Epoch:  426  	Training Loss: 0.16093936562538147
Test Loss:  0.15865084528923035
Valid Loss:  0.16741794347763062
Epoch:  427  	Training Loss: 0.1609199345111847
Test Loss:  0.15863919258117676
Valid Loss:  0.16739708185195923
Epoch:  428  	Training Loss: 0.1609005481004715
Test Loss:  0.15862753987312317
Valid Loss:  0.16737622022628784
Epoch:  429  	Training Loss: 0.1608811616897583
Test Loss:  0.15861588716506958
Valid Loss:  0.16735535860061646
Epoch:  430  	Training Loss: 0.1608617603778839
Test Loss:  0.158604234457016
Valid Loss:  0.16733449697494507
Epoch:  431  	Training Loss: 0.16084250807762146
Test Loss:  0.1585928350687027
Valid Loss:  0.16731411218643188
Epoch:  432  	Training Loss: 0.16082406044006348
Test Loss:  0.15858158469200134
Valid Loss:  0.16729401051998138
Epoch:  433  	Training Loss: 0.16080617904663086
Test Loss:  0.15857034921646118
Valid Loss:  0.16727492213249207
Epoch:  434  	Training Loss: 0.16078828275203705
Test Loss:  0.15855911374092102
Valid Loss:  0.1672564446926117
Epoch:  435  	Training Loss: 0.16077041625976562
Test Loss:  0.15854787826538086
Valid Loss:  0.1672379970550537
Epoch:  436  	Training Loss: 0.1607527732849121
Test Loss:  0.1585369110107422
Valid Loss:  0.16721995174884796
Epoch:  437  	Training Loss: 0.16073572635650635
Test Loss:  0.15852591395378113
Valid Loss:  0.1672019064426422
Epoch:  438  	Training Loss: 0.1607186496257782
Test Loss:  0.15851496160030365
Valid Loss:  0.16718387603759766
Epoch:  439  	Training Loss: 0.16070160269737244
Test Loss:  0.15850397944450378
Valid Loss:   88%|████████▊ | 439/500 [04:59<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:06<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.03it/s] 90%|█████████ | 451/500 [05:12<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:19<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:26<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:26<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:27<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:33<00:03,  3.03it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.25it/s]100%|█████████▉| 499/500 [05:40<00:00,  3.02it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
0.1671658307313919
Epoch:  440  	Training Loss: 0.16068457067012787
Test Loss:  0.1584930121898651
Valid Loss:  0.16714781522750854
Epoch:  441  	Training Loss: 0.1606675237417221
Test Loss:  0.15848204493522644
Valid Loss:  0.16712981462478638
Epoch:  442  	Training Loss: 0.16065077483654022
Test Loss:  0.1584712713956833
Valid Loss:  0.16711211204528809
Epoch:  443  	Training Loss: 0.16063442826271057
Test Loss:  0.15846049785614014
Valid Loss:  0.1670943796634674
Epoch:  444  	Training Loss: 0.16061806678771973
Test Loss:  0.15844972431659698
Valid Loss:  0.16707667708396912
Epoch:  445  	Training Loss: 0.16060173511505127
Test Loss:  0.15843895077705383
Valid Loss:  0.16705897450447083
Epoch:  446  	Training Loss: 0.16058538854122162
Test Loss:  0.15842820703983307
Valid Loss:  0.16704127192497253
Epoch:  447  	Training Loss: 0.16056904196739197
Test Loss:  0.15841743350028992
Valid Loss:  0.16702358424663544
Epoch:  448  	Training Loss: 0.1605527102947235
Test Loss:  0.15840667486190796
Valid Loss:  0.16700589656829834
Epoch:  449  	Training Loss: 0.16053640842437744
Test Loss:  0.158395916223526
Valid Loss:  0.16698822379112244
Epoch:  450  	Training Loss: 0.16052007675170898
Test Loss:  0.15838515758514404
Valid Loss:  0.16697053611278534
Epoch:  451  	Training Loss: 0.16050374507904053
Test Loss:  0.15837442874908447
Valid Loss:  0.16695287823677063
Epoch:  452  	Training Loss: 0.16048744320869446
Test Loss:  0.15836359560489655
Valid Loss:  0.16693507134914398
Epoch:  453  	Training Loss: 0.16047102212905884
Test Loss:  0.15835276246070862
Valid Loss:  0.16691729426383972
Epoch:  454  	Training Loss: 0.16045460104942322
Test Loss:  0.15834194421768188
Valid Loss:  0.16689950227737427
Epoch:  455  	Training Loss: 0.1604381650686264
Test Loss:  0.15833112597465515
Valid Loss:  0.16688172519207
Epoch:  456  	Training Loss: 0.16042175889015198
Test Loss:  0.1583203375339508
Valid Loss:  0.16686394810676575
Epoch:  457  	Training Loss: 0.16040535271167755
Test Loss:  0.15830950438976288
Valid Loss:  0.16684618592262268
Epoch:  458  	Training Loss: 0.16038894653320312
Test Loss:  0.15829870104789734
Valid Loss:  0.16682842373847961
Epoch:  459  	Training Loss: 0.1603725552558899
Test Loss:  0.1582878828048706
Valid Loss:  0.16681066155433655
Epoch:  460  	Training Loss: 0.16035616397857666
Test Loss:  0.15827707946300507
Valid Loss:  0.16679289937019348
Epoch:  461  	Training Loss: 0.1603401154279709
Test Loss:  0.15826654434204102
Valid Loss:  0.16677558422088623
Epoch:  462  	Training Loss: 0.16032452881336212
Test Loss:  0.15825596451759338
Valid Loss:  0.1667582094669342
Epoch:  463  	Training Loss: 0.1603088676929474
Test Loss:  0.15824541449546814
Valid Loss:  0.16674083471298218
Epoch:  464  	Training Loss: 0.16029322147369385
Test Loss:  0.1582348346710205
Valid Loss:  0.16672345995903015
Epoch:  465  	Training Loss: 0.1602775752544403
Test Loss:  0.15822428464889526
Valid Loss:  0.16670608520507812
Epoch:  466  	Training Loss: 0.16026194393634796
Test Loss:  0.15821370482444763
Valid Loss:  0.1666887402534485
Epoch:  467  	Training Loss: 0.16024631261825562
Test Loss:  0.1582031548023224
Valid Loss:  0.16667136549949646
Epoch:  468  	Training Loss: 0.16023075580596924
Test Loss:  0.15819311141967773
Valid Loss:  0.16665489971637726
Epoch:  469  	Training Loss: 0.16021589934825897
Test Loss:  0.15818436443805695
Valid Loss:  0.1666395366191864
Epoch:  470  	Training Loss: 0.16020134091377258
Test Loss:  0.15817588567733765
Valid Loss:  0.16662460565567017
Epoch:  471  	Training Loss: 0.1601872742176056
Test Loss:  0.15816739201545715
Valid Loss:  0.16660964488983154
Epoch:  472  	Training Loss: 0.1601732075214386
Test Loss:  0.15815886855125427
Valid Loss:  0.1665947437286377
Epoch:  473  	Training Loss: 0.16015908122062683
Test Loss:  0.1581503301858902
Valid Loss:  0.16658124327659607
Epoch:  474  	Training Loss: 0.1601451337337494
Test Loss:  0.15814203023910522
Valid Loss:  0.16656814515590668
Epoch:  475  	Training Loss: 0.1601317822933197
Test Loss:  0.15813374519348145
Valid Loss:  0.16655504703521729
Epoch:  476  	Training Loss: 0.16011841595172882
Test Loss:  0.15812544524669647
Valid Loss:  0.1665419340133667
Epoch:  477  	Training Loss: 0.16010510921478271
Test Loss:  0.1581173837184906
Valid Loss:  0.16652920842170715
Epoch:  478  	Training Loss: 0.16009265184402466
Test Loss:  0.15810954570770264
Valid Loss:  0.16651684045791626
Epoch:  479  	Training Loss: 0.16008076071739197
Test Loss:  0.15810170769691467
Valid Loss:  0.16650448739528656
Epoch:  480  	Training Loss: 0.16006885468959808
Test Loss:  0.1580938994884491
Valid Loss:  0.16649210453033447
Epoch:  481  	Training Loss: 0.1600569635629654
Test Loss:  0.15808607637882233
Valid Loss:  0.16647976636886597
Epoch:  482  	Training Loss: 0.1600450724363327
Test Loss:  0.15807820856571198
Valid Loss:  0.1664673388004303
Epoch:  483  	Training Loss: 0.16003328561782837
Test Loss:  0.15807059407234192
Valid Loss:  0.16645532846450806
Epoch:  484  	Training Loss: 0.1600220650434494
Test Loss:  0.15806297957897186
Valid Loss:  0.16644330322742462
Epoch:  485  	Training Loss: 0.16001082956790924
Test Loss:  0.1580553650856018
Valid Loss:  0.16643261909484863
Epoch:  486  	Training Loss: 0.1599997878074646
Test Loss:  0.15804798901081085
Valid Loss:  0.1664223074913025
Epoch:  487  	Training Loss: 0.15998923778533936
Test Loss:  0.1580406129360199
Valid Loss:  0.16641198098659515
Epoch:  488  	Training Loss: 0.15997883677482605
Test Loss:  0.15803346037864685
Valid Loss:  0.16640198230743408
Epoch:  489  	Training Loss: 0.15996894240379333
Test Loss:  0.1580263376235962
Valid Loss:  0.1663919985294342
Epoch:  490  	Training Loss: 0.159959077835083
Test Loss:  0.15801918506622314
Valid Loss:  0.16638314723968506
Epoch:  491  	Training Loss: 0.1599491834640503
Test Loss:  0.1580120474100113
Valid Loss:  0.16637444496154785
Epoch:  492  	Training Loss: 0.15993931889533997
Test Loss:  0.15800490975379944
Valid Loss:  0.16636577248573303
Epoch:  493  	Training Loss: 0.15992940962314606
Test Loss:  0.1579977571964264
Valid Loss:  0.16635705530643463
Epoch:  494  	Training Loss: 0.15991950035095215
Test Loss:  0.15799058973789215
Valid Loss:  0.16634835302829742
Epoch:  495  	Training Loss: 0.15990987420082092
Test Loss:  0.1579836755990982
Valid Loss:  0.1663399487733841
Epoch:  496  	Training Loss: 0.15990062057971954
Test Loss:  0.15797674655914307
Valid Loss:  0.16633152961730957
Epoch:  497  	Training Loss: 0.15989136695861816
Test Loss:  0.1579698622226715
Valid Loss:  0.16632312536239624
Epoch:  498  	Training Loss: 0.1598820984363556
Test Loss:  0.15796294808387756
Valid Loss:  0.1663147211074829
Epoch:  499  	Training Loss: 0.1598728597164154
Test Loss:  0.15795603394508362
Valid Loss:  0.16630631685256958
Epoch:  500  	Training Loss: 0.1598639190196991
Test Loss:  0.15794935822486877
Valid Loss:  0.16629821062088013
seed is  13
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:48,  6.35s/it]  1%|          | 3/500 [00:06<14:04,  1.70s/it]  1%|          | 5/500 [00:06<07:05,  1.16it/s]  1%|▏         | 7/500 [00:06<04:17,  1.92it/s]  2%|▏         | 9/500 [00:06<02:52,  2.85it/s]  2%|▏         | 11/500 [00:13<10:46,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:20<09:41,  1.21s/it]  5%|▍         | 23/500 [00:20<06:53,  1.15it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.20it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:06,  1.17s/it]  7%|▋         | 33/500 [00:26<06:29,  1.20it/s]  7%|▋         | 35/500 [00:33<11:47,  1.52s/it]  7%|▋         | 37/500 [00:33<08:23,  1.09s/it]  8%|▊         | 39/500 [00:33<06:02,  1.27it/s]  8%|▊         | 41/500 [00:39<11:31,  1.51s/it]  9%|▊         | 43/500 [00:39<08:11,  1.08s/it]  9%|▉         | 45/500 [00:40<05:51,  1.29it/s]  9%|▉         | 47/500 [00:40<04:13,  1.79it/s] 10%|▉         | 49/500 [00:40<03:05,  2.43it/s] 10%|█         | 51/500 [00:46<09:16,  1.24s/it] 11%|█         | 53/500 [00:46<06:39,  1.12it/s] 11%|█         | 55/500 [00:47<04:47,  1.55it/s] 11%|█▏        | 57/500 [00:47<03:28,  2.12it/s] 12%|█▏        | 59/500 [00:47<02:34,  2.85it/s] 12%|█▏        | 61/500 [00:53<08:46,  1.20s/it] 13%|█▎        | 63/500 [00:53<06:16,  1.16it/s] 13%|█▎        | 65/500 [01:00<11:15,  1.55s/it] 13%|█▎        | 67/500 [01:00<08:01,  1.11s/it] 14%|█▍        | 69/500 [01:00<05:44,  1.25it/s]Epoch:  1  	Training Loss: 0.050132326781749725
Test Loss:  19.04962921142578
Valid Loss:  19.205734252929688
Epoch:  2  	Training Loss: 19.373445510864258
Test Loss:  6594.70654296875
Valid Loss:  6524.771484375
Epoch:  3  	Training Loss: 6569.826171875
Test Loss:  4.102845191955566
Valid Loss:  4.1187663078308105
Epoch:  4  	Training Loss: 4.137338638305664
Test Loss:  4.089315414428711
Valid Loss:  4.104791641235352
Epoch:  5  	Training Loss: 4.123167991638184
Test Loss:  4.075836658477783
Valid Loss:  4.090872764587402
Epoch:  6  	Training Loss: 4.109053611755371
Test Loss:  4.062413215637207
Valid Loss:  4.077011585235596
Epoch:  7  	Training Loss: 4.094997406005859
Test Loss:  4.049039840698242
Valid Loss:  4.063204765319824
Epoch:  8  	Training Loss: 4.080996513366699
Test Loss:  4.0357208251953125
Valid Loss:  4.0494537353515625
Epoch:  9  	Training Loss: 4.067052841186523
Test Loss:  4.022454261779785
Valid Loss:  4.035759449005127
Epoch:  10  	Training Loss: 4.053165435791016
Test Loss:  4.009238243103027
Valid Loss:  4.02211856842041
Epoch:  11  	Training Loss: 4.039332866668701
Test Loss:  3.996074676513672
Valid Loss:  4.008533477783203
Epoch:  12  	Training Loss: 4.025556564331055
Test Loss:  176.3706512451172
Valid Loss:  171.48268127441406
Epoch:  13  	Training Loss: 170.7926025390625
Test Loss:  0.5933094620704651
Valid Loss:  0.6052370071411133
Epoch:  14  	Training Loss: 0.6056429743766785
Test Loss:  0.5932791233062744
Valid Loss:  0.6051861643791199
Epoch:  15  	Training Loss: 0.6056005954742432
Test Loss:  0.5932450294494629
Valid Loss:  0.6051331758499146
Epoch:  16  	Training Loss: 0.6055581569671631
Test Loss:  0.5932109355926514
Valid Loss:  0.6050801873207092
Epoch:  17  	Training Loss: 0.6055158376693726
Test Loss:  0.5931768417358398
Valid Loss:  0.6050271391868591
Epoch:  18  	Training Loss: 0.6054731607437134
Test Loss:  0.5931419730186462
Valid Loss:  0.6049730181694031
Epoch:  19  	Training Loss: 0.6054288148880005
Test Loss:  0.5931070446968079
Valid Loss:  0.6049187779426575
Epoch:  20  	Training Loss: 0.6053844690322876
Test Loss:  0.5930721759796143
Valid Loss:  0.6048645973205566
Epoch:  21  	Training Loss: 0.6053401231765747
Test Loss:  0.5930373072624207
Valid Loss:  0.6048104763031006
Epoch:  22  	Training Loss: 0.605295717716217
Test Loss:  24.827239990234375
Valid Loss:  23.755237579345703
Epoch:  23  	Training Loss: 23.72713851928711
Test Loss:  0.16270872950553894
Valid Loss:  0.18112701177597046
Epoch:  24  	Training Loss: 0.17592760920524597
Test Loss:  0.14071542024612427
Valid Loss:  0.16227498650550842
Epoch:  25  	Training Loss: 0.15732097625732422
Test Loss:  0.13335153460502625
Valid Loss:  0.15482327342033386
Epoch:  26  	Training Loss: 0.1504184901714325
Test Loss:  0.12876518070697784
Valid Loss:  0.1499776393175125
Epoch:  27  	Training Loss: 0.14646685123443604
Test Loss:  0.12529033422470093
Valid Loss:  0.14682510495185852
Epoch:  28  	Training Loss: 0.143556147813797
Test Loss:  0.12248953431844711
Valid Loss:  0.144464910030365
Epoch:  29  	Training Loss: 0.14122845232486725
Test Loss:  0.12018390744924545
Valid Loss:  0.14263023436069489
Epoch:  30  	Training Loss: 0.13936173915863037
Test Loss:  0.11833080649375916
Valid Loss:  0.14120039343833923
Epoch:  31  	Training Loss: 0.13786868751049042
Test Loss:  0.11677367240190506
Valid Loss:  0.14004585146903992
Epoch:  32  	Training Loss: 0.13661989569664001
Test Loss:  0.1741742342710495
Valid Loss:  0.14909479022026062
Epoch:  33  	Training Loss: 0.15299805998802185
Test Loss:  0.1344868242740631
Valid Loss:  0.15939809381961823
Epoch:  34  	Training Loss: 0.15571776032447815
Test Loss:  0.13444381952285767
Valid Loss:  0.15932399034500122
Epoch:  35  	Training Loss: 0.15563009679317474
Test Loss:  0.13439702987670898
Valid Loss:  0.15924681723117828
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.15550661087036133
Test Loss:  0.22563715279102325
Valid Loss:  0.2041451781988144
Epoch:  37  	Training Loss: 0.2096158266067505
Test Loss:  0.16797992587089539
Valid Loss:  0.19611474871635437
Epoch:  38  	Training Loss: 0.19279569387435913
Test Loss:  0.03705447167158127
Valid Loss:  0.050484538078308105
Epoch:  39  	Training Loss: 0.046037230640649796
Test Loss:  0.02541755884885788
Valid Loss:  0.036386191844940186
Epoch:  40  	Training Loss: 0.032299548387527466
Test Loss:  0.022195272147655487
Valid Loss:  0.0321730300784111
Epoch:  41  	Training Loss: 0.02839254029095173
Test Loss:  0.02049773931503296
Valid Loss:  0.029713701456785202
Epoch:  42  	Training Loss: 0.026193682104349136
Test Loss:  0.02002831920981407
Valid Loss:  0.02849286049604416
Epoch:  43  	Training Loss: 0.025221407413482666
Test Loss:  0.019703511148691177
Valid Loss:  0.027898117899894714
Epoch:  44  	Training Loss: 0.024757783859968185
Test Loss:  0.019309351220726967
Valid Loss:  0.02750207670032978
Epoch:  45  	Training Loss: 0.024398569017648697
Test Loss:  0.018710307776927948
Valid Loss:  0.026945602148771286
Epoch:  46  	Training Loss: 0.02387130632996559
Test Loss:  0.018644988536834717
Valid Loss:  0.02708519995212555
Epoch:  47  	Training Loss: 0.02397197112441063
Test Loss:  0.01869496889412403
Valid Loss:  0.026801884174346924
Epoch:  48  	Training Loss: 0.023813415318727493
Test Loss:  0.018459655344486237
Valid Loss:  0.026559142395853996
Epoch:  49  	Training Loss: 0.02359061688184738
Test Loss:  0.01815742254257202
Valid Loss:  0.0262936819344759
Epoch:  50  	Training Loss: 0.023326558992266655
Test Loss:  0.017741534858942032
Valid Loss:  0.02590992860496044
Epoch:  51  	Training Loss: 0.022952226921916008
Test Loss:  0.017613910138607025
Valid Loss:  0.025762734934687614
Epoch:  52  	Training Loss: 0.02281196601688862
Test Loss:  0.01633559912443161
Valid Loss:  0.022808631882071495
Epoch:  53  	Training Loss: 0.020450878888368607
Test Loss:  0.01617252267897129
Valid Loss:  0.02176693081855774
Epoch:  54  	Training Loss: 0.01970876008272171
Test Loss:  0.016139229759573936
Valid Loss:  0.021280188113451004
Epoch:  55  	Training Loss: 0.019363973289728165
Test Loss:  0.016071951016783714
Valid Loss:  0.02096957340836525
Epoch:  56  	Training Loss: 0.01911971904337406
Test Loss:  0.01597738452255726
Valid Loss:  0.020724274218082428
Epoch:  57  	Training Loss: 0.018912769854068756
Test Loss:  0.015864543616771698
Valid Loss:  0.020514871925115585
Epoch:  58  	Training Loss: 0.01872626692056656
Test Loss:  0.0157456137239933
Valid Loss:  0.020329011604189873
Epoch:  59  	Training Loss: 0.018552925437688828
Test Loss:  0.015634097158908844
Valid Loss:  0.020151637494564056
Epoch:  60  	Training Loss: 0.018389809876680374
Test Loss:  0.015517335385084152
Valid Loss:  0.019983593374490738
Epoch:  61  	Training Loss: 0.018233496695756912
Test Loss:  0.015410414896905422
Valid Loss:  0.019820399582386017
Epoch:  62  	Training Loss: 0.018085630610585213
Test Loss:  0.013229500502347946
Valid Loss:  0.01920124515891075
Epoch:  63  	Training Loss: 0.017178310081362724
Test Loss:  0.021008044481277466
Valid Loss:  0.021381407976150513
Epoch:  64  	Training Loss: 0.020851019769906998
Test Loss:  0.03641554340720177
Valid Loss:  0.048920661211013794
Epoch:  65  	Training Loss: 0.04543915018439293
Test Loss:  0.09411432594060898
Valid Loss:  0.08537440747022629
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.0879983901977539
Test Loss:  0.0371536947786808
Valid Loss:  0.0357525534927845
Epoch:  67  	Training Loss: 0.035309888422489166
Test Loss:  0.023629553616046906
Valid Loss:  0.024480905383825302
Epoch:  68  	Training Loss: 0.02381170354783535
Test Loss:  0.01949310675263405
Valid Loss:  0.020858794450759888
Epoch:  69  	Training Loss: 0.020393434911966324
Test Loss:  0.01764284446835518
Valid Loss:  0.018773602321743965
Epoch:  70  	Training Loss: 0.01856936514377594
Test Loss:  0.01662566140294075
Valid Loss:  0.017308082431554794
Epoch:  71  	Training Loss: 0.017321065068244934
Test Loss:  0.01578442193567753
Valid Loss:   14%|█▍        | 71/500 [01:06<11:00,  1.54s/it] 15%|█▍        | 73/500 [01:07<07:50,  1.10s/it] 15%|█▌        | 75/500 [01:07<05:35,  1.27it/s] 15%|█▌        | 77/500 [01:07<04:02,  1.74it/s] 16%|█▌        | 79/500 [01:07<02:58,  2.36it/s] 16%|█▌        | 81/500 [01:13<08:42,  1.25s/it] 17%|█▋        | 83/500 [01:14<06:12,  1.12it/s] 17%|█▋        | 85/500 [01:14<04:28,  1.55it/s] 17%|█▋        | 87/500 [01:14<03:16,  2.10it/s] 18%|█▊        | 89/500 [01:14<02:25,  2.83it/s] 18%|█▊        | 91/500 [01:20<08:08,  1.19s/it] 19%|█▊        | 93/500 [01:20<05:48,  1.17it/s] 19%|█▉        | 95/500 [01:21<04:12,  1.60it/s] 19%|█▉        | 97/500 [01:21<03:03,  2.19it/s] 20%|█▉        | 99/500 [01:21<02:15,  2.95it/s] 20%|██        | 101/500 [01:27<07:48,  1.17s/it] 21%|██        | 103/500 [01:27<05:33,  1.19it/s] 21%|██        | 105/500 [01:27<04:00,  1.65it/s] 21%|██▏       | 107/500 [01:27<02:54,  2.25it/s] 22%|██▏       | 109/500 [01:28<02:09,  3.03it/s] 22%|██▏       | 111/500 [01:34<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:34<05:26,  1.18it/s] 23%|██▎       | 115/500 [01:34<03:55,  1.64it/s] 23%|██▎       | 117/500 [01:34<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:34<02:06,  3.00it/s] 24%|██▍       | 121/500 [01:41<07:23,  1.17s/it] 25%|██▍       | 123/500 [01:41<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:41<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:41<02:46,  2.23it/s] 26%|██▌       | 129/500 [01:41<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:48<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:48<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:48<03:43,  1.63it/s] 27%|██▋       | 137/500 [01:48<02:42,  2.23it/s] 28%|██▊       | 139/500 [01:48<02:00,  3.00it/s] 28%|██▊       | 141/500 [01:54<07:00,  1.17s/it]0.016168830916285515
Epoch:  72  	Training Loss: 0.01632198691368103
Test Loss:  0.01547420583665371
Valid Loss:  0.016018563881516457
Epoch:  73  	Training Loss: 0.016149526461958885
Test Loss:  0.01521534938365221
Valid Loss:  0.015906188637018204
Epoch:  74  	Training Loss: 0.016008781269192696
Test Loss:  0.014993784949183464
Valid Loss:  0.015811003744602203
Epoch:  75  	Training Loss: 0.01588684692978859
Test Loss:  0.014814777299761772
Valid Loss:  0.015743467956781387
Epoch:  76  	Training Loss: 0.015793021768331528
Test Loss:  0.014662086963653564
Valid Loss:  0.015689227730035782
Epoch:  77  	Training Loss: 0.015715939924120903
Test Loss:  0.014534378424286842
Valid Loss:  0.015644285827875137
Epoch:  78  	Training Loss: 0.015651144087314606
Test Loss:  0.01442235428839922
Valid Loss:  0.015604074113070965
Epoch:  79  	Training Loss: 0.015594634227454662
Test Loss:  0.014327130280435085
Valid Loss:  0.015571095049381256
Epoch:  80  	Training Loss: 0.01554381288588047
Test Loss:  0.014244211837649345
Valid Loss:  0.015543191693723202
Epoch:  81  	Training Loss: 0.015498088672757149
Test Loss:  0.014169516041874886
Valid Loss:  0.015518402680754662
Epoch:  82  	Training Loss: 0.015457993373274803
Test Loss:  0.014194485731422901
Valid Loss:  0.015509295277297497
Epoch:  83  	Training Loss: 0.015452125109732151
Test Loss:  0.014215430244803429
Valid Loss:  0.01550241094082594
Epoch:  84  	Training Loss: 0.015447890385985374
Test Loss:  0.014232862740755081
Valid Loss:  0.015497108921408653
Epoch:  85  	Training Loss: 0.015444749966263771
Test Loss:  0.014247274026274681
Valid Loss:  0.015492936596274376
Epoch:  86  	Training Loss: 0.015442339703440666
Test Loss:  0.014259112067520618
Valid Loss:  0.015489584766328335
Epoch:  87  	Training Loss: 0.015440419316291809
Test Loss:  0.014268778264522552
Valid Loss:  0.015486832708120346
Epoch:  88  	Training Loss: 0.015438828617334366
Test Loss:  0.014276627451181412
Valid Loss:  0.015484519302845001
Epoch:  89  	Training Loss: 0.015437453985214233
Test Loss:  0.014282961376011372
Valid Loss:  0.01548253558576107
Epoch:  90  	Training Loss: 0.015436230227351189
Test Loss:  0.014288030564785004
Valid Loss:  0.015480795875191689
Epoch:  91  	Training Loss: 0.01543510239571333
Test Loss:  0.014292051084339619
Valid Loss:  0.015479249879717827
Epoch:  92  	Training Loss: 0.015434039756655693
Test Loss:  0.01424398273229599
Valid Loss:  0.015443350188434124
Epoch:  93  	Training Loss: 0.015396960079669952
Test Loss:  0.01420443132519722
Valid Loss:  0.0154120409861207
Epoch:  94  	Training Loss: 0.015363802202045918
Test Loss:  0.014168956317007542
Valid Loss:  0.015382768586277962
Epoch:  95  	Training Loss: 0.015334018506109715
Test Loss:  0.014141328632831573
Valid Loss:  0.015357661060988903
Epoch:  96  	Training Loss: 0.015308702364563942
Test Loss:  0.01411515288054943
Valid Loss:  0.01533418521285057
Epoch:  97  	Training Loss: 0.015285516157746315
Test Loss:  0.014090980403125286
Valid Loss:  0.015312299132347107
Epoch:  98  	Training Loss: 0.015265300869941711
Test Loss:  0.014070641249418259
Valid Loss:  0.015292482450604439
Epoch:  99  	Training Loss: 0.015248745679855347
Test Loss:  0.014054163359105587
Valid Loss:  0.015275208279490471
Epoch:  100  	Training Loss: 0.015235595405101776
Test Loss:  0.014038207940757275
Valid Loss:  0.01525849848985672
Epoch:  101  	Training Loss: 0.015224029310047626
Test Loss:  0.014024585485458374
Valid Loss:  0.015244945883750916
Epoch:  102  	Training Loss: 0.015214772894978523
Test Loss:  0.01380179263651371
Valid Loss:  0.015239551663398743
Epoch:  103  	Training Loss: 0.015153289772570133
Test Loss:  0.013667087070643902
Valid Loss:  0.015242204070091248
Epoch:  104  	Training Loss: 0.015116814523935318
Test Loss:  0.013581760227680206
Valid Loss:  0.015245117247104645
Epoch:  105  	Training Loss: 0.015094077214598656
Test Loss:  0.013523612171411514
Valid Loss:  0.015246422030031681
Epoch:  106  	Training Loss: 0.015076209791004658
Test Loss:  0.013485202565789223
Valid Loss:  0.015246817842125893
Epoch:  107  	Training Loss: 0.01506134308874607
Test Loss:  0.013454988598823547
Valid Loss:  0.015247015282511711
Epoch:  108  	Training Loss: 0.015048987232148647
Test Loss:  0.0134299136698246
Valid Loss:  0.01524675078690052
Epoch:  109  	Training Loss: 0.015038028359413147
Test Loss:  0.013412450440227985
Valid Loss:  0.015245605260133743
Epoch:  110  	Training Loss: 0.015028409659862518
Test Loss:  0.01339859887957573
Valid Loss:  0.015244262292981148
Epoch:  111  	Training Loss: 0.015019549056887627
Test Loss:  0.013385704718530178
Valid Loss:  0.01524318940937519
Epoch:  112  	Training Loss: 0.015011448413133621
Test Loss:  0.012559860944747925
Valid Loss:  0.014490602537989616
Epoch:  113  	Training Loss: 0.014364941045641899
Test Loss:  0.012070583179593086
Valid Loss:  0.013937084935605526
Epoch:  114  	Training Loss: 0.013904931955039501
Test Loss:  0.011599543504416943
Valid Loss:  0.013404354453086853
Epoch:  115  	Training Loss: 0.013419641181826591
Test Loss:  0.011158512905240059
Valid Loss:  0.012873541563749313
Epoch:  116  	Training Loss: 0.012912461534142494
Test Loss:  0.010759798809885979
Valid Loss:  0.0123599236831069
Epoch:  117  	Training Loss: 0.012416841462254524
Test Loss:  0.010280812159180641
Valid Loss:  0.011850220151245594
Epoch:  118  	Training Loss: 0.0119010703638196
Test Loss:  0.009775318205356598
Valid Loss:  0.011351825669407845
Epoch:  119  	Training Loss: 0.01139060128480196
Test Loss:  0.00923582911491394
Valid Loss:  0.01086261123418808
Epoch:  120  	Training Loss: 0.010863489471375942
Test Loss:  0.008741682395339012
Valid Loss:  0.01038335170596838
Epoch:  121  	Training Loss: 0.010350048542022705
Test Loss:  0.008287029340863228
Valid Loss:  0.009908776730298996
Epoch:  122  	Training Loss: 0.009857907891273499
Test Loss:  0.007817864418029785
Valid Loss:  0.008868299424648285
Epoch:  123  	Training Loss: 0.008976113982498646
Test Loss:  0.007482967339456081
Valid Loss:  0.008206160739064217
Epoch:  124  	Training Loss: 0.008407212793827057
Test Loss:  0.007139507215470076
Valid Loss:  0.007746719755232334
Epoch:  125  	Training Loss: 0.007965998724102974
Test Loss:  0.006850221194326878
Valid Loss:  0.007397495210170746
Epoch:  126  	Training Loss: 0.0075850170105695724
Test Loss:  0.006618941202759743
Valid Loss:  0.007148047909140587
Epoch:  127  	Training Loss: 0.007289111614227295
Test Loss:  0.006426535546779633
Valid Loss:  0.006963958032429218
Epoch:  128  	Training Loss: 0.0070464713498950005
Test Loss:  0.006267431657761335
Valid Loss:  0.006827167235314846
Epoch:  129  	Training Loss: 0.006854435428977013
Test Loss:  0.00613521970808506
Valid Loss:  0.006660905666649342
Epoch:  130  	Training Loss: 0.006686157546937466
Test Loss:  0.005984961055219173
Valid Loss:  0.006481564603745937
Epoch:  131  	Training Loss: 0.006524860858917236
Test Loss:  0.005836456082761288
Valid Loss:  0.006317500490695238
Epoch:  132  	Training Loss: 0.006386104505509138
Test Loss:  0.004827817901968956
Valid Loss:  0.0058023640885949135
Epoch:  133  	Training Loss: 0.005840279161930084
Test Loss:  0.004483163356781006
Valid Loss:  0.005569334141910076
Epoch:  134  	Training Loss: 0.005607977043837309
Test Loss:  0.004290246404707432
Valid Loss:  0.005374268628656864
Epoch:  135  	Training Loss: 0.005420325789600611
Test Loss:  0.004138117656111717
Valid Loss:  0.005190952681005001
Epoch:  136  	Training Loss: 0.005247032269835472
Test Loss:  0.0040063560009002686
Valid Loss:  0.00502684386447072
Epoch:  137  	Training Loss: 0.005086159333586693
Test Loss:  0.0038959502708166838
Valid Loss:  0.004876833409070969
Epoch:  138  	Training Loss: 0.0049382103607058525
Test Loss:  0.0037916714791208506
Valid Loss:  0.004735374823212624
Epoch:  139  	Training Loss: 0.0047995345667004585
Test Loss:  0.0037146294489502907
Valid Loss:  0.004606780596077442
Epoch:  140  	Training Loss: 0.004679116420447826
Test Loss:  0.0036367010325193405
Valid Loss:  0.0044884043745696545
Epoch:  141  	Training Loss: 0.004571842961013317
Test Loss:  0.0035646199248731136
Valid Loss:  0.004378891550004482
 29%|██▊       | 143/500 [01:54<05:01,  1.18it/s] 29%|██▉       | 145/500 [01:55<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:55<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:55<01:59,  2.94it/s] 30%|███       | 151/500 [02:01<06:56,  1.19s/it] 31%|███       | 153/500 [02:01<04:57,  1.17it/s] 31%|███       | 155/500 [02:02<03:33,  1.61it/s] 31%|███▏      | 157/500 [02:02<02:35,  2.21it/s] 32%|███▏      | 159/500 [02:02<01:54,  2.97it/s] 32%|███▏      | 161/500 [02:08<06:43,  1.19s/it] 33%|███▎      | 163/500 [02:08<04:48,  1.17it/s] 33%|███▎      | 165/500 [02:08<03:27,  1.62it/s] 33%|███▎      | 167/500 [02:09<02:30,  2.21it/s] 34%|███▍      | 169/500 [02:09<01:51,  2.98it/s] 34%|███▍      | 171/500 [02:15<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:15<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:15<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:15<02:25,  2.23it/s] 36%|███▌      | 179/500 [02:16<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:22<06:12,  1.17s/it] 37%|███▋      | 183/500 [02:22<04:25,  1.19it/s] 37%|███▋      | 185/500 [02:22<03:11,  1.65it/s] 37%|███▋      | 187/500 [02:22<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:22<01:42,  3.02it/s] 38%|███▊      | 191/500 [02:29<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:29<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:29<03:05,  1.65it/s] 39%|███▉      | 197/500 [02:29<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:29<01:40,  3.01it/s] 40%|████      | 201/500 [02:35<05:49,  1.17s/it] 41%|████      | 203/500 [02:36<04:08,  1.19it/s] 41%|████      | 205/500 [02:36<02:58,  1.65it/s] 41%|████▏     | 207/500 [02:36<02:09,  2.26it/s] 42%|████▏     | 209/500 [02:36<01:35,  3.03it/s]Epoch:  142  	Training Loss: 0.004474314860999584
Test Loss:  0.0035153012722730637
Valid Loss:  0.004286517389118671
Epoch:  143  	Training Loss: 0.004395660944283009
Test Loss:  0.0034635625779628754
Valid Loss:  0.004208686295896769
Epoch:  144  	Training Loss: 0.004320729058235884
Test Loss:  0.0034150017891079187
Valid Loss:  0.0041438862681388855
Epoch:  145  	Training Loss: 0.004249516874551773
Test Loss:  0.0033688130788505077
Valid Loss:  0.0040873209945857525
Epoch:  146  	Training Loss: 0.004184693098068237
Test Loss:  0.00333586847409606
Valid Loss:  0.0040395003743469715
Epoch:  147  	Training Loss: 0.004126672632992268
Test Loss:  0.0033199116587638855
Valid Loss:  0.00399796525016427
Epoch:  148  	Training Loss: 0.004081909544765949
Test Loss:  0.0033104089088737965
Valid Loss:  0.003962792921811342
Epoch:  149  	Training Loss: 0.004045466426759958
Test Loss:  0.0032930169254541397
Valid Loss:  0.003934627864509821
Epoch:  150  	Training Loss: 0.004013792611658573
Test Loss:  0.003265314269810915
Valid Loss:  0.003911617677658796
Epoch:  151  	Training Loss: 0.0039850445464253426
Test Loss:  0.0032552778720855713
Valid Loss:  0.003886376041918993
Epoch:  152  	Training Loss: 0.003958908841013908
Test Loss:  0.0032528559677302837
Valid Loss:  0.003885936923325062
Epoch:  153  	Training Loss: 0.0039574080146849155
Test Loss:  0.0032504447735846043
Valid Loss:  0.003885498736053705
Epoch:  154  	Training Loss: 0.003955911844968796
Test Loss:  0.003248043591156602
Valid Loss:  0.0038850619457662106
Epoch:  155  	Training Loss: 0.003954422660171986
Test Loss:  0.003245652886107564
Valid Loss:  0.0038846253883093596
Epoch:  156  	Training Loss: 0.003952939063310623
Test Loss:  0.0032432733569294214
Valid Loss:  0.0038841869682073593
Epoch:  157  	Training Loss: 0.003951461054384708
Test Loss:  0.0032409061677753925
Valid Loss:  0.003883745986968279
Epoch:  158  	Training Loss: 0.003949988633394241
Test Loss:  0.0032385499216616154
Valid Loss:  0.0038833091966807842
Epoch:  159  	Training Loss: 0.003948523662984371
Test Loss:  0.0032362043857574463
Valid Loss:  0.0038828724063932896
Epoch:  160  	Training Loss: 0.003947063349187374
Test Loss:  0.0032338679302483797
Valid Loss:  0.003882432822138071
Epoch:  161  	Training Loss: 0.003945608623325825
Test Loss:  0.003231542883440852
Valid Loss:  0.003881996963173151
Epoch:  162  	Training Loss: 0.003944160416722298
Test Loss:  0.003214529249817133
Valid Loss:  0.003846680512651801
Epoch:  163  	Training Loss: 0.0039041966665536165
Test Loss:  0.0031884615309536457
Valid Loss:  0.003818915691226721
Epoch:  164  	Training Loss: 0.00386851467192173
Test Loss:  0.0031762029975652695
Valid Loss:  0.0037921611219644547
Epoch:  165  	Training Loss: 0.0038390434347093105
Test Loss:  0.00316776055842638
Valid Loss:  0.0037690014578402042
Epoch:  166  	Training Loss: 0.003813871182501316
Test Loss:  0.0031500468030571938
Valid Loss:  0.003750617615878582
Epoch:  167  	Training Loss: 0.0037910931278020144
Test Loss:  0.0031333407387137413
Valid Loss:  0.0037342440336942673
Epoch:  168  	Training Loss: 0.0037701979745179415
Test Loss:  0.003118029795587063
Valid Loss:  0.0037195184268057346
Epoch:  169  	Training Loss: 0.0037509773392230272
Test Loss:  0.0031040478497743607
Valid Loss:  0.0037062796764075756
Epoch:  170  	Training Loss: 0.003733298508450389
Test Loss:  0.0030909294728189707
Valid Loss:  0.0036943089216947556
Epoch:  171  	Training Loss: 0.0037169717252254486
Test Loss:  0.0030790925957262516
Valid Loss:  0.0036835218779742718
Epoch:  172  	Training Loss: 0.0037018493749201298
Test Loss:  0.0030654440633952618
Valid Loss:  0.003683649469166994
Epoch:  173  	Training Loss: 0.003699735039845109
Test Loss:  0.0030575538985431194
Valid Loss:  0.003682974725961685
Epoch:  174  	Training Loss: 0.003698143642395735
Test Loss:  0.003052634419873357
Valid Loss:  0.0036817388609051704
Epoch:  175  	Training Loss: 0.0036967198830097914
Test Loss:  0.003049321938306093
Valid Loss:  0.003680208697915077
Epoch:  176  	Training Loss: 0.003695396240800619
Test Loss:  0.003046831116080284
Valid Loss:  0.003678490873426199
Epoch:  177  	Training Loss: 0.003694087965413928
Test Loss:  0.0030447805766016245
Valid Loss:  0.003676779568195343
Epoch:  178  	Training Loss: 0.003692787140607834
Test Loss:  0.003042966593056917
Valid Loss:  0.0036750282160937786
Epoch:  179  	Training Loss: 0.0036914898082613945
Test Loss:  0.0030413055792450905
Valid Loss:  0.0036732512526214123
Epoch:  180  	Training Loss: 0.0036901957355439663
Test Loss:  0.003039816627278924
Valid Loss:  0.0036714670713990927
Epoch:  181  	Training Loss: 0.003688906552270055
Test Loss:  0.003038369119167328
Valid Loss:  0.003669794648885727
Epoch:  182  	Training Loss: 0.0036876185331493616
Test Loss:  0.0030428539030253887
Valid Loss:  0.0036646672524511814
Epoch:  183  	Training Loss: 0.003683605697005987
Test Loss:  0.0030452762730419636
Valid Loss:  0.0036613703705370426
Epoch:  184  	Training Loss: 0.0036806981079280376
Test Loss:  0.003046428319066763
Valid Loss:  0.0036592220421880484
Epoch:  185  	Training Loss: 0.003678317181766033
Test Loss:  0.0030468280892819166
Valid Loss:  0.0036577964201569557
Epoch:  186  	Training Loss: 0.0036763353273272514
Test Loss:  0.0030466769821941853
Valid Loss:  0.003656558459624648
Epoch:  187  	Training Loss: 0.0036745532415807247
Test Loss:  0.003046318655833602
Valid Loss:  0.0036555975675582886
Epoch:  188  	Training Loss: 0.0036729294806718826
Test Loss:  0.0030454806983470917
Valid Loss:  0.0036550245713442564
Epoch:  189  	Training Loss: 0.003671573009341955
Test Loss:  0.0030446797609329224
Valid Loss:  0.003654654137790203
Epoch:  190  	Training Loss: 0.0036703029181808233
Test Loss:  0.0030437358655035496
Valid Loss:  0.003654728876426816
Epoch:  191  	Training Loss: 0.003669165540486574
Test Loss:  0.0030428858008235693
Valid Loss:  0.0036547952331602573
Epoch:  192  	Training Loss: 0.003668100805953145
Test Loss:  0.0030418396927416325
Valid Loss:  0.003654507687315345
Epoch:  193  	Training Loss: 0.0036673066206276417
Test Loss:  0.00304090091958642
Valid Loss:  0.0036542050074785948
Epoch:  194  	Training Loss: 0.003666526637971401
Test Loss:  0.0030400464311242104
Valid Loss:  0.003653889987617731
Epoch:  195  	Training Loss: 0.003665756434202194
Test Loss:  0.003039260394871235
Valid Loss:  0.0036535654217004776
Epoch:  196  	Training Loss: 0.003664996474981308
Test Loss:  0.0030386296566575766
Valid Loss:  0.003653373336419463
Epoch:  197  	Training Loss: 0.003664245828986168
Test Loss:  0.003038081107661128
Valid Loss:  0.003653298132121563
Epoch:  198  	Training Loss: 0.0036635184660553932
Test Loss:  0.0030373791232705116
Valid Loss:  0.0036532082594931126
Epoch:  199  	Training Loss: 0.0036628444213420153
Test Loss:  0.003036744659766555
Valid Loss:  0.0036532054655253887
Epoch:  200  	Training Loss: 0.0036621782928705215
Test Loss:  0.003036161419004202
Valid Loss:  0.003653190564364195
Epoch:  201  	Training Loss: 0.0036615196149796247
Test Loss:  0.0030354352202266455
Valid Loss:  0.0036531330551952124
Epoch:  202  	Training Loss: 0.003660911228507757
Test Loss:  0.003037756308913231
Valid Loss:  0.003627684200182557
Epoch:  203  	Training Loss: 0.0036389618180692196
Test Loss:  0.003032314358279109
Valid Loss:  0.003606969490647316
Epoch:  204  	Training Loss: 0.0036199248861521482
Test Loss:  0.003022683784365654
Valid Loss:  0.0035888005513697863
Epoch:  205  	Training Loss: 0.0036023836582899094
Test Loss:  0.0030110508669167757
Valid Loss:  0.003572125919163227
Epoch:  206  	Training Loss: 0.003585886675864458
Test Loss:  0.00299864262342453
Valid Loss:  0.003556501120328903
Epoch:  207  	Training Loss: 0.0035702597815543413
Test Loss:  0.0029861079528927803
Valid Loss:  0.0035417024046182632
Epoch:  208  	Training Loss: 0.003555411472916603
Test Loss:  0.0029737779404968023
Valid Loss:  0.003527591470628977
Epoch:  209  	Training Loss: 0.00354119879193604
Test Loss:  0.0029615950770676136
Valid Loss:  0.003513618838042021
Epoch:  210  	Training Loss: 0.0035270301159471273
Test Loss:  0.0029495353810489178
Valid Loss:  0.003499676240608096
 42%|████▏     | 211/500 [02:42<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:42<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:43<02:55,  1.62it/s] 43%|████▎     | 217/500 [02:43<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:43<01:35,  2.96it/s] 44%|████▍     | 221/500 [02:49<05:32,  1.19s/it] 45%|████▍     | 223/500 [02:49<03:57,  1.17it/s] 45%|████▌     | 225/500 [02:49<02:50,  1.62it/s] 45%|████▌     | 227/500 [02:50<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:50<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:56<05:13,  1.17s/it] 47%|████▋     | 233/500 [02:56<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:56<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:56<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:56<01:26,  3.01it/s] 48%|████▊     | 241/500 [03:03<05:05,  1.18s/it] 49%|████▊     | 243/500 [03:03<03:38,  1.18it/s] 49%|████▉     | 245/500 [03:03<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:03<01:53,  2.22it/s] 50%|████▉     | 249/500 [03:03<01:24,  2.98it/s] 50%|█████     | 251/500 [03:10<04:54,  1.18s/it] 51%|█████     | 253/500 [03:10<03:29,  1.18it/s] 51%|█████     | 255/500 [03:10<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:10<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:10<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:16<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:17<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:17<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:17<01:45,  2.21it/s] 54%|█████▍    | 269/500 [03:17<01:17,  2.97it/s] 54%|█████▍    | 271/500 [03:23<04:31,  1.19s/it] 55%|█████▍    | 273/500 [03:24<03:13,  1.17it/s] 55%|█████▌    | 275/500 [03:24<02:18,  1.62it/s] 55%|█████▌    | 277/500 [03:24<01:40,  2.22it/s]Epoch:  211  	Training Loss: 0.0035127955488860607
Test Loss:  0.002937863115221262
Valid Loss:  0.0034862812608480453
Epoch:  212  	Training Loss: 0.003499103244394064
Test Loss:  0.0029372856952250004
Valid Loss:  0.0034721451811492443
Epoch:  213  	Training Loss: 0.0034815859980881214
Test Loss:  0.0029227009508758783
Valid Loss:  0.003464238252490759
Epoch:  214  	Training Loss: 0.0034677935764193535
Test Loss:  0.0029104999266564846
Valid Loss:  0.003458352293819189
Epoch:  215  	Training Loss: 0.003456525504589081
Test Loss:  0.0029002998489886522
Valid Loss:  0.003454021643847227
Epoch:  216  	Training Loss: 0.0034472947008907795
Test Loss:  0.0028917761519551277
Valid Loss:  0.0034508993849158287
Epoch:  217  	Training Loss: 0.003439751686528325
Test Loss:  0.002884611487388611
Valid Loss:  0.0034487247467041016
Epoch:  218  	Training Loss: 0.0034335250966250896
Test Loss:  0.0028785918839275837
Valid Loss:  0.0034472825936973095
Epoch:  219  	Training Loss: 0.0034283315762877464
Test Loss:  0.0028734689112752676
Valid Loss:  0.0034463126212358475
Epoch:  220  	Training Loss: 0.003423866583034396
Test Loss:  0.002869074000045657
Valid Loss:  0.003445687470957637
Epoch:  221  	Training Loss: 0.003420087043195963
Test Loss:  0.0028652853798121214
Valid Loss:  0.0034453037660568953
Epoch:  222  	Training Loss: 0.0034168607089668512
Test Loss:  0.0028492617420852184
Valid Loss:  0.0034433454275131226
Epoch:  223  	Training Loss: 0.0034093940630555153
Test Loss:  0.002841260749846697
Valid Loss:  0.0034398215357214212
Epoch:  224  	Training Loss: 0.003402562579140067
Test Loss:  0.0028345708269625902
Valid Loss:  0.0034365798346698284
Epoch:  225  	Training Loss: 0.0033959439024329185
Test Loss:  0.0028282073326408863
Valid Loss:  0.0034334207884967327
Epoch:  226  	Training Loss: 0.0033895832020789385
Test Loss:  0.002821904607117176
Valid Loss:  0.0034304321743547916
Epoch:  227  	Training Loss: 0.0033835717476904392
Test Loss:  0.0028158894274383783
Valid Loss:  0.0034275115467607975
Epoch:  228  	Training Loss: 0.0033777793869376183
Test Loss:  0.0028099073097109795
Valid Loss:  0.0034247280564159155
Epoch:  229  	Training Loss: 0.0033723630476742983
Test Loss:  0.002803935669362545
Valid Loss:  0.003422088921070099
Epoch:  230  	Training Loss: 0.0033673737198114395
Test Loss:  0.002798243425786495
Valid Loss:  0.0034194861073046923
Epoch:  231  	Training Loss: 0.003362641204148531
Test Loss:  0.002792822662740946
Valid Loss:  0.0034168967977166176
Epoch:  232  	Training Loss: 0.0033580109011381865
Test Loss:  0.0027958424761891365
Valid Loss:  0.003413311904296279
Epoch:  233  	Training Loss: 0.0033543831668794155
Test Loss:  0.0027942750602960587
Valid Loss:  0.003411055076867342
Epoch:  234  	Training Loss: 0.0033511153887957335
Test Loss:  0.002791865263134241
Valid Loss:  0.0034091726411134005
Epoch:  235  	Training Loss: 0.0033480788115411997
Test Loss:  0.0027894130907952785
Valid Loss:  0.0034074571449309587
Epoch:  236  	Training Loss: 0.0033452447969466448
Test Loss:  0.0027870771009474993
Valid Loss:  0.0034058562014251947
Epoch:  237  	Training Loss: 0.003342593787238002
Test Loss:  0.002784878946840763
Valid Loss:  0.0034043467603623867
Epoch:  238  	Training Loss: 0.003340123686939478
Test Loss:  0.0027828419115394354
Valid Loss:  0.0034029516391456127
Epoch:  239  	Training Loss: 0.003337899688631296
Test Loss:  0.0027809140738099813
Valid Loss:  0.003401620779186487
Epoch:  240  	Training Loss: 0.003335806541144848
Test Loss:  0.0027790889143943787
Valid Loss:  0.0034003444015979767
Epoch:  241  	Training Loss: 0.0033338400535285473
Test Loss:  0.0027773946058005095
Valid Loss:  0.0033991490490734577
Epoch:  242  	Training Loss: 0.0033320204820483923
Test Loss:  0.002770138904452324
Valid Loss:  0.0033806951250880957
Epoch:  243  	Training Loss: 0.003314424306154251
Test Loss:  0.002761211944743991
Valid Loss:  0.003364906646311283
Epoch:  244  	Training Loss: 0.0032981750555336475
Test Loss:  0.002750649582594633
Valid Loss:  0.0033504487946629524
Epoch:  245  	Training Loss: 0.003282725578173995
Test Loss:  0.002738763578236103
Valid Loss:  0.0033361976966261864
Epoch:  246  	Training Loss: 0.003267585765570402
Test Loss:  0.0027262154035270214
Valid Loss:  0.0033219086471945047
Epoch:  247  	Training Loss: 0.0032520932145416737
Test Loss:  0.002713216468691826
Valid Loss:  0.0033075036481022835
Epoch:  248  	Training Loss: 0.003236536169424653
Test Loss:  0.002700322074815631
Valid Loss:  0.003293416928499937
Epoch:  249  	Training Loss: 0.003221497405320406
Test Loss:  0.0026871482841670513
Valid Loss:  0.0032796149607747793
Epoch:  250  	Training Loss: 0.003206893103197217
Test Loss:  0.0026728049851953983
Valid Loss:  0.0032659994903951883
Epoch:  251  	Training Loss: 0.003192608943209052
Test Loss:  0.0026586418971419334
Valid Loss:  0.00325253838673234
Epoch:  252  	Training Loss: 0.003178588580340147
Test Loss:  0.0026558919344097376
Valid Loss:  0.003252222202718258
Epoch:  253  	Training Loss: 0.003176644444465637
Test Loss:  0.0026530746836215258
Valid Loss:  0.0032519535161554813
Epoch:  254  	Training Loss: 0.0031747426837682724
Test Loss:  0.002650214359164238
Valid Loss:  0.0032517225481569767
Epoch:  255  	Training Loss: 0.0031728807371109724
Test Loss:  0.002647327957674861
Valid Loss:  0.003251527901738882
Epoch:  256  	Training Loss: 0.0031710583716630936
Test Loss:  0.002644429448992014
Valid Loss:  0.003251365851610899
Epoch:  257  	Training Loss: 0.0031692718621343374
Test Loss:  0.0026415293104946613
Valid Loss:  0.003251228481531143
Epoch:  258  	Training Loss: 0.0031675223726779222
Test Loss:  0.0026386349927634
Valid Loss:  0.003251119516789913
Epoch:  259  	Training Loss: 0.0031658064108341932
Test Loss:  0.002635752549394965
Valid Loss:  0.0032510319724678993
Epoch:  260  	Training Loss: 0.0031636408530175686
Test Loss:  0.0026316531002521515
Valid Loss:  0.003250968176871538
Epoch:  261  	Training Loss: 0.0031605807598680258
Test Loss:  0.0026275664567947388
Valid Loss:  0.0032509276643395424
Epoch:  262  	Training Loss: 0.0031575593166053295
Test Loss:  0.0024140095338225365
Valid Loss:  0.0029686924535781145
Epoch:  263  	Training Loss: 0.0029094992205500603
Test Loss:  0.0022101004142314196
Valid Loss:  0.002745965262874961
Epoch:  264  	Training Loss: 0.0027069065254181623
Test Loss:  0.002040140563622117
Valid Loss:  0.002567688003182411
Epoch:  265  	Training Loss: 0.0025433336850255728
Test Loss:  0.0018950753146782517
Valid Loss:  0.0024183220230042934
Epoch:  266  	Training Loss: 0.0024055312387645245
Test Loss:  0.00176415522582829
Valid Loss:  0.002279854379594326
Epoch:  267  	Training Loss: 0.002283485373482108
Test Loss:  0.0016481225611642003
Valid Loss:  0.0021537519060075283
Epoch:  268  	Training Loss: 0.00217157369479537
Test Loss:  0.0015455496031790972
Valid Loss:  0.0020339651964604855
Epoch:  269  	Training Loss: 0.002069540321826935
Test Loss:  0.0014542164281010628
Valid Loss:  0.0019231067271903157
Epoch:  270  	Training Loss: 0.0019761931616812944
Test Loss:  0.0013721765717491508
Valid Loss:  0.0018219634657725692
Epoch:  271  	Training Loss: 0.0018902706215158105
Test Loss:  0.0012995869619771838
Valid Loss:  0.001731660682708025
Epoch:  272  	Training Loss: 0.0018127725925296545
Test Loss:  0.001307730213738978
Valid Loss:  0.0017063419800251722
Epoch:  273  	Training Loss: 0.0017868711147457361
Test Loss:  0.0013178146909922361
Valid Loss:  0.0016923535149544477
Epoch:  274  	Training Loss: 0.0017722711199894547
Test Loss:  0.0013273603981360793
Valid Loss:  0.0016846002545207739
Epoch:  275  	Training Loss: 0.001763868611305952
Test Loss:  0.001335427863523364
Valid Loss:  0.0016802900936454535
Epoch:  276  	Training Loss: 0.0017588648479431868
Test Loss:  0.0013418104499578476
Valid Loss:  0.0016778809949755669
Epoch:  277  	Training Loss: 0.0017557262908667326
Test Loss:  0.0013466208474710584
Valid Loss:  0.0016765252221375704
Epoch:  278  	Training Loss: 0.001753613236360252
Test Loss:  0.0013500937493517995
Valid Loss:  0.0016757553676143289
Epoch:  279  	Training Loss: 0.0017520661931484938
Test Loss:  0.001352480729110539
Valid Loss:   56%|█████▌    | 279/500 [03:24<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:30<04:24,  1.21s/it] 57%|█████▋    | 283/500 [03:31<03:08,  1.15it/s] 57%|█████▋    | 285/500 [03:31<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:31<01:37,  2.18it/s] 58%|█████▊    | 289/500 [03:31<01:11,  2.94it/s] 58%|█████▊    | 291/500 [03:37<04:05,  1.18s/it] 59%|█████▊    | 293/500 [03:37<02:54,  1.18it/s] 59%|█████▉    | 295/500 [03:37<02:05,  1.64it/s] 59%|█████▉    | 297/500 [03:38<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:38<01:06,  3.01it/s] 60%|██████    | 301/500 [03:44<03:58,  1.20s/it] 61%|██████    | 303/500 [03:44<02:49,  1.16it/s] 61%|██████    | 305/500 [03:44<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:45<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:45<01:04,  2.95it/s] 62%|██████▏   | 311/500 [03:51<03:44,  1.19s/it] 63%|██████▎   | 313/500 [03:51<02:39,  1.17it/s] 63%|██████▎   | 315/500 [03:51<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:51<01:22,  2.22it/s] 64%|██████▍   | 319/500 [03:52<01:00,  2.98it/s] 64%|██████▍   | 321/500 [03:58<03:32,  1.18s/it] 65%|██████▍   | 323/500 [03:58<02:30,  1.18it/s] 65%|██████▌   | 325/500 [03:58<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:58<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:58<00:57,  2.97it/s] 66%|██████▌   | 331/500 [04:05<03:20,  1.18s/it] 67%|██████▋   | 333/500 [04:05<02:23,  1.17it/s] 67%|██████▋   | 335/500 [04:05<01:42,  1.62it/s] 67%|██████▋   | 337/500 [04:05<01:13,  2.21it/s] 68%|██████▊   | 339/500 [04:05<00:54,  2.97it/s] 68%|██████▊   | 341/500 [04:12<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:12<02:12,  1.18it/s] 69%|██████▉   | 345/500 [04:12<01:34,  1.63it/s] 69%|██████▉   | 347/500 [04:12<01:08,  2.23it/s]0.0016753142699599266
Epoch:  280  	Training Loss: 0.001750831725075841
Test Loss:  0.0013540104264393449
Valid Loss:  0.0016750567592680454
Epoch:  281  	Training Loss: 0.0017497712979093194
Test Loss:  0.0013548813294619322
Valid Loss:  0.001674905070103705
Epoch:  282  	Training Loss: 0.001748810987919569
Test Loss:  0.0012505771592259407
Valid Loss:  0.001582364086061716
Epoch:  283  	Training Loss: 0.0016634019557386637
Test Loss:  0.0011671172687783837
Valid Loss:  0.001503578620031476
Epoch:  284  	Training Loss: 0.001592062646523118
Test Loss:  0.001098572975024581
Valid Loss:  0.001435230951756239
Epoch:  285  	Training Loss: 0.001531058456748724
Test Loss:  0.0010415068827569485
Valid Loss:  0.0013753445819020271
Epoch:  286  	Training Loss: 0.0014783291844651103
Test Loss:  0.0009933203691616654
Valid Loss:  0.0013224794529378414
Epoch:  287  	Training Loss: 0.0014322163769975305
Test Loss:  0.0009525344357825816
Valid Loss:  0.0012760395184159279
Epoch:  288  	Training Loss: 0.0013921710196882486
Test Loss:  0.0009174251463264227
Valid Loss:  0.0012345733121037483
Epoch:  289  	Training Loss: 0.0013562540989369154
Test Loss:  0.0008870528545230627
Valid Loss:  0.0011979296104982495
Epoch:  290  	Training Loss: 0.0013246487360447645
Test Loss:  0.0008605311159044504
Valid Loss:  0.0011654568370431662
Epoch:  291  	Training Loss: 0.001296765636652708
Test Loss:  0.0008375459583476186
Valid Loss:  0.0011362585937604308
Epoch:  292  	Training Loss: 0.0012721320381388068
Test Loss:  0.0008247691439464688
Valid Loss:  0.0011069339234381914
Epoch:  293  	Training Loss: 0.0012389072217047215
Test Loss:  0.0008049512398429215
Valid Loss:  0.0010848994133993983
Epoch:  294  	Training Loss: 0.001210648799315095
Test Loss:  0.0007881488418206573
Valid Loss:  0.0010661926353350282
Epoch:  295  	Training Loss: 0.0011861578095704317
Test Loss:  0.000773769395891577
Valid Loss:  0.0010503343073651195
Epoch:  296  	Training Loss: 0.0011648876825347543
Test Loss:  0.000761436007451266
Valid Loss:  0.0010368663351982832
Epoch:  297  	Training Loss: 0.0011463644914329052
Test Loss:  0.0007508384296670556
Valid Loss:  0.0010254050139337778
Epoch:  298  	Training Loss: 0.001130192307755351
Test Loss:  0.0007417179294861853
Valid Loss:  0.0010156251955777407
Epoch:  299  	Training Loss: 0.0011160389985889196
Test Loss:  0.0007338372524827719
Valid Loss:  0.001007257029414177
Epoch:  300  	Training Loss: 0.0011036056093871593
Test Loss:  0.000727008271496743
Valid Loss:  0.0010000666370615363
Epoch:  301  	Training Loss: 0.0010926444083452225
Test Loss:  0.0007210668991319835
Valid Loss:  0.0009938589064404368
Epoch:  302  	Training Loss: 0.001082942821085453
Test Loss:  0.0007099262438714504
Valid Loss:  0.000993096036836505
Epoch:  303  	Training Loss: 0.0010785417398437858
Test Loss:  0.000707344152033329
Valid Loss:  0.000989873195067048
Epoch:  304  	Training Loss: 0.0010747058549895883
Test Loss:  0.0007050487329252064
Valid Loss:  0.000986637081950903
Epoch:  305  	Training Loss: 0.0010709617054089904
Test Loss:  0.0007028066902421415
Valid Loss:  0.0009834615048021078
Epoch:  306  	Training Loss: 0.0010672988137230277
Test Loss:  0.0007006175583228469
Valid Loss:  0.0009803479770198464
Epoch:  307  	Training Loss: 0.001063715317286551
Test Loss:  0.0006984509527683258
Valid Loss:  0.0009772920748218894
Epoch:  308  	Training Loss: 0.0010602090042084455
Test Loss:  0.0006962977349758148
Valid Loss:  0.000974291586317122
Epoch:  309  	Training Loss: 0.0010567742865532637
Test Loss:  0.0006941877072677016
Valid Loss:  0.0009713429608382285
Epoch:  310  	Training Loss: 0.0010534096509218216
Test Loss:  0.0006921191234141588
Valid Loss:  0.0009684456163085997
Epoch:  311  	Training Loss: 0.001050112652592361
Test Loss:  0.0006900893058627844
Valid Loss:  0.0009655954199843109
Epoch:  312  	Training Loss: 0.0010468792170286179
Test Loss:  0.0006688172579742968
Valid Loss:  0.0009271285962313414
Epoch:  313  	Training Loss: 0.0010163234546780586
Test Loss:  0.0006511855171993375
Valid Loss:  0.0008942900458350778
Epoch:  314  	Training Loss: 0.0009903935715556145
Test Loss:  0.0006368546164594591
Valid Loss:  0.0008655337151139975
Epoch:  315  	Training Loss: 0.0009679881623014808
Test Loss:  0.0006244862452149391
Valid Loss:  0.0008400626247748733
Epoch:  316  	Training Loss: 0.0009483944741077721
Test Loss:  0.0006137918098829687
Valid Loss:  0.000817451102193445
Epoch:  317  	Training Loss: 0.0009312260081060231
Test Loss:  0.0006047594361007214
Valid Loss:  0.0007973313331604004
Epoch:  318  	Training Loss: 0.0009161544730886817
Test Loss:  0.0005967763718217611
Valid Loss:  0.0007793864933773875
Epoch:  319  	Training Loss: 0.0009028983768075705
Test Loss:  0.0005896399961784482
Valid Loss:  0.0007633448694832623
Epoch:  320  	Training Loss: 0.0008912138291634619
Test Loss:  0.0005832404131069779
Valid Loss:  0.0007489710696972907
Epoch:  321  	Training Loss: 0.0008809288847260177
Test Loss:  0.0005775309400632977
Valid Loss:  0.0007361691095866263
Epoch:  322  	Training Loss: 0.0008719139150343835
Test Loss:  0.0005686000804416835
Valid Loss:  0.0007335892878472805
Epoch:  323  	Training Loss: 0.0008662614272907376
Test Loss:  0.0005620912415906787
Valid Loss:  0.0007311222143471241
Epoch:  324  	Training Loss: 0.0008612658712081611
Test Loss:  0.0005570476641878486
Valid Loss:  0.0007286515319719911
Epoch:  325  	Training Loss: 0.0008566321339458227
Test Loss:  0.0005529203917831182
Valid Loss:  0.0007261678110808134
Epoch:  326  	Training Loss: 0.0008522325078956783
Test Loss:  0.0005493837525136769
Valid Loss:  0.0007236877572722733
Epoch:  327  	Training Loss: 0.0008480074466206133
Test Loss:  0.0005462373374029994
Valid Loss:  0.0007212331984192133
Epoch:  328  	Training Loss: 0.0008439334924332798
Test Loss:  0.0005433496553450823
Valid Loss:  0.0007188793388195336
Epoch:  329  	Training Loss: 0.0008399997605010867
Test Loss:  0.0005406503332778811
Valid Loss:  0.0007165939314290881
Epoch:  330  	Training Loss: 0.0008362049120478332
Test Loss:  0.0005380951915867627
Valid Loss:  0.0007143557886593044
Epoch:  331  	Training Loss: 0.0008325147209689021
Test Loss:  0.0005356455221772194
Valid Loss:  0.0007122269016690552
Epoch:  332  	Training Loss: 0.0008289302932098508
Test Loss:  0.0005371906445361674
Valid Loss:  0.0007110197329893708
Epoch:  333  	Training Loss: 0.0008277060696855187
Test Loss:  0.0005387001438066363
Valid Loss:  0.0007099689682945609
Epoch:  334  	Training Loss: 0.0008266418008133769
Test Loss:  0.000540168141014874
Valid Loss:  0.0007090563885867596
Epoch:  335  	Training Loss: 0.0008257171721197665
Test Loss:  0.0005415889900177717
Valid Loss:  0.0007082620868459344
Epoch:  336  	Training Loss: 0.0008249134989455342
Test Loss:  0.0005429604789242148
Valid Loss:  0.0007075734902173281
Epoch:  337  	Training Loss: 0.000824214774183929
Test Loss:  0.0005442773690447211
Valid Loss:  0.0007069737766869366
Epoch:  338  	Training Loss: 0.0008236074354499578
Test Loss:  0.000545540708117187
Valid Loss:  0.000706452236045152
Epoch:  339  	Training Loss: 0.0008230791427195072
Test Loss:  0.0005467482842504978
Valid Loss:  0.0007059992058202624
Epoch:  340  	Training Loss: 0.0008226199424825609
Test Loss:  0.0005478996317833662
Valid Loss:  0.0007056043250486255
Epoch:  341  	Training Loss: 0.0008222211617976427
Test Loss:  0.0005489949253387749
Valid Loss:  0.0007052618893794715
Epoch:  342  	Training Loss: 0.0008218737784773111
Test Loss:  0.0005330501007847488
Valid Loss:  0.0007034288719296455
Epoch:  343  	Training Loss: 0.0008154779206961393
Test Loss:  0.0005242543993517756
Valid Loss:  0.0007014883449301124
Epoch:  344  	Training Loss: 0.0008109574555419385
Test Loss:  0.0005184114561416209
Valid Loss:  0.0006990908295847476
Epoch:  345  	Training Loss: 0.0008069134782999754
Test Loss:  0.0005138861597515643
Valid Loss:  0.0006963476189412177
Epoch:  346  	Training Loss: 0.0008029625751078129
Test Loss:  0.0005099928239360452
Valid Loss:  0.0006934640114195645
Epoch:  347  	Training Loss: 0.0007990801241248846
Test Loss:  0.0005064395954832435
Valid Loss:  0.0006905535119585693
 70%|██████▉   | 349/500 [04:12<00:50,  3.00it/s] 70%|███████   | 351/500 [04:19<02:58,  1.20s/it] 71%|███████   | 353/500 [04:19<02:05,  1.17it/s] 71%|███████   | 355/500 [04:19<01:29,  1.61it/s] 71%|███████▏  | 357/500 [04:19<01:04,  2.20it/s] 72%|███████▏  | 359/500 [04:19<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:25<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:26<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:26<01:23,  1.63it/s] 73%|███████▎  | 367/500 [04:26<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:26<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:32<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:32<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:33<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:33<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:33<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:39<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:39<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:39<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:40<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:40<00:37,  3.00it/s] 78%|███████▊  | 391/500 [04:46<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:46<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:46<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:46<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:46<00:33,  3.01it/s] 80%|████████  | 401/500 [04:53<01:56,  1.18s/it] 81%|████████  | 403/500 [04:53<01:21,  1.18it/s] 81%|████████  | 405/500 [04:53<00:58,  1.64it/s] 81%|████████▏ | 407/500 [04:53<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:53<00:30,  3.00it/s] 82%|████████▏ | 411/500 [05:00<01:45,  1.19s/it] 83%|████████▎ | 413/500 [05:00<01:14,  1.17it/s] 83%|████████▎ | 415/500 [05:00<00:52,  1.62it/s]Epoch:  348  	Training Loss: 0.000795253086835146
Test Loss:  0.0005031004548072815
Valid Loss:  0.0006877143168821931
Epoch:  349  	Training Loss: 0.000791491474956274
Test Loss:  0.00049987604143098
Valid Loss:  0.0006849257042631507
Epoch:  350  	Training Loss: 0.0007877884199842811
Test Loss:  0.0004967403365299106
Valid Loss:  0.0006821883143857121
Epoch:  351  	Training Loss: 0.0007841238984838128
Test Loss:  0.0004936711629852653
Valid Loss:  0.000679473509080708
Epoch:  352  	Training Loss: 0.0007805058266967535
Test Loss:  0.0004932816373184323
Valid Loss:  0.0006778312381356955
Epoch:  353  	Training Loss: 0.000779298017732799
Test Loss:  0.0004929163260385394
Valid Loss:  0.0006762763950973749
Epoch:  354  	Training Loss: 0.0007781769963912666
Test Loss:  0.0004925680696032941
Valid Loss:  0.0006748156156390905
Epoch:  355  	Training Loss: 0.000777138804551214
Test Loss:  0.000492233200930059
Valid Loss:  0.0006734250346198678
Epoch:  356  	Training Loss: 0.0007761541055515409
Test Loss:  0.000491914339363575
Valid Loss:  0.0006720883538946509
Epoch:  357  	Training Loss: 0.0007752107921987772
Test Loss:  0.0004916036268696189
Valid Loss:  0.000670810928568244
Epoch:  358  	Training Loss: 0.0007743153255432844
Test Loss:  0.0004913039738312364
Valid Loss:  0.000669577915687114
Epoch:  359  	Training Loss: 0.0007734515820629895
Test Loss:  0.0004910201532766223
Valid Loss:  0.0006683854153379798
Epoch:  360  	Training Loss: 0.0007726165931671858
Test Loss:  0.0004907622351311147
Valid Loss:  0.000667230342514813
Epoch:  361  	Training Loss: 0.0007718202541582286
Test Loss:  0.0004904869711026549
Valid Loss:  0.0006661405204795301
Epoch:  362  	Training Loss: 0.0007710708305239677
Test Loss:  0.00048280408373102546
Valid Loss:  0.0006512537365779281
Epoch:  363  	Training Loss: 0.0007582262624055147
Test Loss:  0.00047497524064965546
Valid Loss:  0.0006375238299369812
Epoch:  364  	Training Loss: 0.0007461584755219519
Test Loss:  0.00046727381413802505
Valid Loss:  0.0006246565608307719
Epoch:  365  	Training Loss: 0.0007347135688178241
Test Loss:  0.00045984156895428896
Valid Loss:  0.0006125516956672072
Epoch:  366  	Training Loss: 0.0007238523103296757
Test Loss:  0.0004527816781774163
Valid Loss:  0.0006012441590428352
Epoch:  367  	Training Loss: 0.0007136737694963813
Test Loss:  0.00044614338548853993
Valid Loss:  0.0005906308069825172
Epoch:  368  	Training Loss: 0.0007040947675704956
Test Loss:  0.0004398660094011575
Valid Loss:  0.000580530846491456
Epoch:  369  	Training Loss: 0.0006949283415451646
Test Loss:  0.00043389463098719716
Valid Loss:  0.000570928561501205
Epoch:  370  	Training Loss: 0.0006861593574285507
Test Loss:  0.000428198603913188
Valid Loss:  0.0005618062568828464
Epoch:  371  	Training Loss: 0.0006777731468901038
Test Loss:  0.0004227595927659422
Valid Loss:  0.0005531258066184819
Epoch:  372  	Training Loss: 0.0006697425851598382
Test Loss:  0.0004189403844065964
Valid Loss:  0.0005459832027554512
Epoch:  373  	Training Loss: 0.0006640494684688747
Test Loss:  0.00041529309237375855
Valid Loss:  0.0005392576567828655
Epoch:  374  	Training Loss: 0.0006586355157196522
Test Loss:  0.0004118540673516691
Valid Loss:  0.0005330241983756423
Epoch:  375  	Training Loss: 0.0006535990396514535
Test Loss:  0.0004085827386006713
Valid Loss:  0.0005271181580610573
Epoch:  376  	Training Loss: 0.0006487701321020722
Test Loss:  0.0004054661258123815
Valid Loss:  0.0005215183482505381
Epoch:  377  	Training Loss: 0.0006441386649385095
Test Loss:  0.0004024891823064536
Valid Loss:  0.0005162113811820745
Epoch:  378  	Training Loss: 0.0006396963144652545
Test Loss:  0.0003996525192633271
Valid Loss:  0.0005111712962388992
Epoch:  379  	Training Loss: 0.0006354268989525735
Test Loss:  0.0003969477547798306
Valid Loss:  0.0005063824355602264
Epoch:  380  	Training Loss: 0.0006313207559287548
Test Loss:  0.00039436499355360866
Valid Loss:  0.0005018283845856786
Epoch:  381  	Training Loss: 0.000627368688583374
Test Loss:  0.0003918974834959954
Valid Loss:  0.0004974963376298547
Epoch:  382  	Training Loss: 0.0006235620239749551
Test Loss:  0.0003901789605151862
Valid Loss:  0.000495838699862361
Epoch:  383  	Training Loss: 0.0006208413979038596
Test Loss:  0.00038854920421727
Valid Loss:  0.0004942549276165664
Epoch:  384  	Training Loss: 0.0006182255456224084
Test Loss:  0.0003869849315378815
Valid Loss:  0.0004927405971102417
Epoch:  385  	Training Loss: 0.0006157036405056715
Test Loss:  0.0003854724927805364
Valid Loss:  0.0004912855802103877
Epoch:  386  	Training Loss: 0.0006132660782895982
Test Loss:  0.0003840015269815922
Valid Loss:  0.0004898839979432523
Epoch:  387  	Training Loss: 0.0006109079113230109
Test Loss:  0.0003825624589808285
Valid Loss:  0.000488536898046732
Epoch:  388  	Training Loss: 0.0006086298963055015
Test Loss:  0.0003811533097177744
Valid Loss:  0.0004872328427154571
Epoch:  389  	Training Loss: 0.0006064153858460486
Test Loss:  0.0003797720419242978
Valid Loss:  0.00048596682609058917
Epoch:  390  	Training Loss: 0.0006042647291906178
Test Loss:  0.00037840785807929933
Valid Loss:  0.0004847431555390358
Epoch:  391  	Training Loss: 0.0006021746667101979
Test Loss:  0.00037706762668676674
Valid Loss:  0.000483549025375396
Epoch:  392  	Training Loss: 0.0006001346046105027
Test Loss:  0.0003772524942178279
Valid Loss:  0.0004780256131198257
Epoch:  393  	Training Loss: 0.0005947480676695704
Test Loss:  0.00037602847442030907
Valid Loss:  0.0004730947548523545
Epoch:  394  	Training Loss: 0.000589861418120563
Test Loss:  0.00037415081169456244
Valid Loss:  0.00046864323667250574
Epoch:  395  	Training Loss: 0.0005852936301380396
Test Loss:  0.00037205900298431516
Valid Loss:  0.0004646734450943768
Epoch:  396  	Training Loss: 0.0005809901631437242
Test Loss:  0.0003699521184898913
Valid Loss:  0.00046093814307823777
Epoch:  397  	Training Loss: 0.0005769278504885733
Test Loss:  0.000367915810784325
Valid Loss:  0.00045741835492663085
Epoch:  398  	Training Loss: 0.000573090510442853
Test Loss:  0.00036598267615772784
Valid Loss:  0.0004540986265055835
Epoch:  399  	Training Loss: 0.0005694631254300475
Test Loss:  0.0003641621442511678
Valid Loss:  0.0004509656864684075
Epoch:  400  	Training Loss: 0.0005660330643877387
Test Loss:  0.0003624548844527453
Valid Loss:  0.00044801097828894854
Epoch:  401  	Training Loss: 0.0005627888021990657
Test Loss:  0.00036085565807297826
Valid Loss:  0.0004452223365660757
Epoch:  402  	Training Loss: 0.0005597193376161158
Test Loss:  0.00036084861494600773
Valid Loss:  0.0004452104039955884
Epoch:  403  	Training Loss: 0.0005597047274932265
Test Loss:  0.00036084200837649405
Valid Loss:  0.00044519867515191436
Epoch:  404  	Training Loss: 0.0005596904084086418
Test Loss:  0.0003608351689763367
Valid Loss:  0.0004451867425814271
Epoch:  405  	Training Loss: 0.0005596764385700226
Test Loss:  0.000360828940756619
Valid Loss:  0.00044517481001093984
Epoch:  406  	Training Loss: 0.0005596615374088287
Test Loss:  0.00036082224687561393
Valid Loss:  0.0004451637505553663
Epoch:  407  	Training Loss: 0.0005596473347395658
Test Loss:  0.00036081543657928705
Valid Loss:  0.00044515199260786176
Epoch:  408  	Training Loss: 0.000559633132070303
Test Loss:  0.0003608091501519084
Valid Loss:  0.0004451401182450354
Epoch:  409  	Training Loss: 0.0005596185219474137
Test Loss:  0.0003608028346206993
Valid Loss:  0.00044512870954349637
Epoch:  410  	Training Loss: 0.0005596043774858117
Test Loss:  0.00036079599522054195
Valid Loss:  0.00044511689338833094
Epoch:  411  	Training Loss: 0.0005595898837782443
Test Loss:  0.0003607893013395369
Valid Loss:  0.0004451059503480792
Epoch:  412  	Training Loss: 0.0005595757393166423
Test Loss:  0.0003505423665046692
Valid Loss:  0.00044447206892073154
Epoch:  413  	Training Loss: 0.0005569399800151587
Test Loss:  0.00034886563662439585
Valid Loss:  0.0004431307897903025
Epoch:  414  	Training Loss: 0.0005551343783736229
Test Loss:  0.0003472093085292727
Valid Loss:  0.000441814394434914
Epoch:  415  	Training Loss: 0.0005533567164093256
Test Loss:  0.0003456194535829127
Valid Loss:  0.0004405278596095741
 83%|████████▎ | 417/500 [05:00<00:37,  2.22it/s] 84%|████████▍ | 419/500 [05:00<00:27,  2.98it/s] 84%|████████▍ | 421/500 [05:07<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:07<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:07<00:46,  1.61it/s] 85%|████████▌ | 427/500 [05:07<00:33,  2.21it/s] 86%|████████▌ | 429/500 [05:07<00:23,  2.96it/s] 86%|████████▌ | 431/500 [05:13<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:14<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:14<00:40,  1.62it/s] 87%|████████▋ | 437/500 [05:14<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:14<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:20<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:20<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:21<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:21<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:21<00:17,  3.00it/s] 90%|█████████ | 451/500 [05:27<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:27<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:27<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:27<00:19,  2.26it/s] 92%|█████████▏| 459/500 [05:28<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:34<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:34<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:34<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:34<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:34<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:41<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:41<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:41<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:41<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:41<00:07,  3.00it/s] 96%|█████████▌| 481/500 [05:48<00:22,  1.18s/it]Epoch:  416  	Training Loss: 0.0005516126402653754
Test Loss:  0.00034406399936415255
Valid Loss:  0.00043926015496253967
Epoch:  417  	Training Loss: 0.0005498906830325723
Test Loss:  0.00034253831836394966
Valid Loss:  0.00043801887659356
Epoch:  418  	Training Loss: 0.000548208539839834
Test Loss:  0.00034103827783837914
Valid Loss:  0.00043680507224053144
Epoch:  419  	Training Loss: 0.0005465551512315869
Test Loss:  0.00033957045525312424
Valid Loss:  0.0004356058198027313
Epoch:  420  	Training Loss: 0.0005449186428450048
Test Loss:  0.0003381264104973525
Valid Loss:  0.00043442228343337774
Epoch:  421  	Training Loss: 0.0005432975012809038
Test Loss:  0.0003367052413523197
Valid Loss:  0.0004332533571869135
Epoch:  422  	Training Loss: 0.0005416980129666626
Test Loss:  0.00033875397639349103
Valid Loss:  0.0004299405263736844
Epoch:  423  	Training Loss: 0.0005381134105846286
Test Loss:  0.00033791910391300917
Valid Loss:  0.00042729120468720794
Epoch:  424  	Training Loss: 0.0005349608254618943
Test Loss:  0.00033681822242215276
Valid Loss:  0.00042492180364206433
Epoch:  425  	Training Loss: 0.0005320332129485905
Test Loss:  0.00033577345311641693
Valid Loss:  0.0004229783662594855
Epoch:  426  	Training Loss: 0.00052930653328076
Test Loss:  0.0003348151803947985
Valid Loss:  0.0004211663908790797
Epoch:  427  	Training Loss: 0.000526762509252876
Test Loss:  0.0003339354880154133
Valid Loss:  0.00041947283898480237
Epoch:  428  	Training Loss: 0.0005243842024356127
Test Loss:  0.0003331270709168166
Valid Loss:  0.00041788609814830124
Epoch:  429  	Training Loss: 0.0005221585743129253
Test Loss:  0.00033238151809200644
Valid Loss:  0.00041639700066298246
Epoch:  430  	Training Loss: 0.0005200718296691775
Test Loss:  0.00033169251400977373
Valid Loss:  0.0004149989690631628
Epoch:  431  	Training Loss: 0.0005181042943149805
Test Loss:  0.00033103834721259773
Valid Loss:  0.0004136623756494373
Epoch:  432  	Training Loss: 0.0005162316374480724
Test Loss:  0.000329296279232949
Valid Loss:  0.00041278573917225003
Epoch:  433  	Training Loss: 0.0005149623611941934
Test Loss:  0.00032857112819328904
Valid Loss:  0.00041184129077009857
Epoch:  434  	Training Loss: 0.0005137943662703037
Test Loss:  0.00032812898280099034
Valid Loss:  0.00041091052116826177
Epoch:  435  	Training Loss: 0.0005126864416524768
Test Loss:  0.0003277817158959806
Valid Loss:  0.0004100202349945903
Epoch:  436  	Training Loss: 0.0005116335232742131
Test Loss:  0.0003274773480370641
Valid Loss:  0.0004091783193871379
Epoch:  437  	Training Loss: 0.0005106807802803814
Test Loss:  0.0003272306057624519
Valid Loss:  0.00040846149204298854
Epoch:  438  	Training Loss: 0.0005098569090478122
Test Loss:  0.00032702210592105985
Valid Loss:  0.0004077771445736289
Epoch:  439  	Training Loss: 0.000509069359395653
Test Loss:  0.000326835666783154
Valid Loss:  0.0004071270814165473
Epoch:  440  	Training Loss: 0.0005083163268864155
Test Loss:  0.0003266654093749821
Valid Loss:  0.00040650885784998536
Epoch:  441  	Training Loss: 0.0005075951339676976
Test Loss:  0.00032650987850502133
Valid Loss:  0.00040592229925096035
Epoch:  442  	Training Loss: 0.0005069051403552294
Test Loss:  0.00032622789149172604
Valid Loss:  0.00040201409137807786
Epoch:  443  	Training Loss: 0.0005030779866501689
Test Loss:  0.0003248462453484535
Valid Loss:  0.0003989277174696326
Epoch:  444  	Training Loss: 0.0005000000819563866
Test Loss:  0.0003228873829357326
Valid Loss:  0.0003962454211432487
Epoch:  445  	Training Loss: 0.0004972591996192932
Test Loss:  0.00032069021835923195
Valid Loss:  0.0003938247391488403
Epoch:  446  	Training Loss: 0.0004947293200530112
Test Loss:  0.0003184416564181447
Valid Loss:  0.00039161910535767674
Epoch:  447  	Training Loss: 0.0004923760425299406
Test Loss:  0.00031622365349903703
Valid Loss:  0.000389565626392141
Epoch:  448  	Training Loss: 0.000490133126731962
Test Loss:  0.0003140761982649565
Valid Loss:  0.00038764538476243615
Epoch:  449  	Training Loss: 0.00048800124204717577
Test Loss:  0.00031200851663015783
Valid Loss:  0.0003858388226944953
Epoch:  450  	Training Loss: 0.0004859463660977781
Test Loss:  0.0003100251778960228
Valid Loss:  0.00038415027665905654
Epoch:  451  	Training Loss: 0.0004839539178647101
Test Loss:  0.0003081506001763046
Valid Loss:  0.0003825393505394459
Epoch:  452  	Training Loss: 0.0004820171161554754
Test Loss:  0.00030364797567017376
Valid Loss:  0.0003814758383668959
Epoch:  453  	Training Loss: 0.0004801626782864332
Test Loss:  0.00030103520839475095
Valid Loss:  0.0003805815940722823
Epoch:  454  	Training Loss: 0.0004786248900927603
Test Loss:  0.0002992523950524628
Valid Loss:  0.00037969747791066766
Epoch:  455  	Training Loss: 0.00047717016423121095
Test Loss:  0.0002978518605232239
Valid Loss:  0.00037880439776927233
Epoch:  456  	Training Loss: 0.0004757454735226929
Test Loss:  0.00029663232271559536
Valid Loss:  0.0003779057296924293
Epoch:  457  	Training Loss: 0.0004743380122818053
Test Loss:  0.0002955024247057736
Valid Loss:  0.0003770079929381609
Epoch:  458  	Training Loss: 0.0004729445499833673
Test Loss:  0.00029441743390634656
Valid Loss:  0.0003761138068512082
Epoch:  459  	Training Loss: 0.0004715639224741608
Test Loss:  0.000293359044007957
Valid Loss:  0.00037522439379245043
Epoch:  460  	Training Loss: 0.00047019688645377755
Test Loss:  0.0002923196880146861
Valid Loss:  0.0003743494162335992
Epoch:  461  	Training Loss: 0.00046885712072253227
Test Loss:  0.0002912921190727502
Valid Loss:  0.0003734802012331784
Epoch:  462  	Training Loss: 0.00046752928756177425
Test Loss:  0.0002909497998189181
Valid Loss:  0.00037262108526192605
Epoch:  463  	Training Loss: 0.0004667807661462575
Test Loss:  0.0002906531735789031
Valid Loss:  0.00037183493259362876
Epoch:  464  	Training Loss: 0.00046609743731096387
Test Loss:  0.0002903958666138351
Valid Loss:  0.0003711138269864023
Epoch:  465  	Training Loss: 0.00046547254896722734
Test Loss:  0.0002901730185840279
Valid Loss:  0.0003704517730511725
Epoch:  466  	Training Loss: 0.000464899989310652
Test Loss:  0.00028998026391491294
Valid Loss:  0.00036984169855713844
Epoch:  467  	Training Loss: 0.0004643738502636552
Test Loss:  0.00028981329523958266
Valid Loss:  0.00036927982000634074
Epoch:  468  	Training Loss: 0.00046388909686356783
Test Loss:  0.000289669435005635
Valid Loss:  0.0003687596181407571
Epoch:  469  	Training Loss: 0.00046344223665073514
Test Loss:  0.0002895444631576538
Valid Loss:  0.00036827748408541083
Epoch:  470  	Training Loss: 0.0004630281764548272
Test Loss:  0.00028943613870069385
Valid Loss:  0.0003678303328342736
Epoch:  471  	Training Loss: 0.0004626467707566917
Test Loss:  0.00028934149304404855
Valid Loss:  0.0003674185136333108
Epoch:  472  	Training Loss: 0.00046229816507548094
Test Loss:  0.00029056594939902425
Valid Loss:  0.0003671222075354308
Epoch:  473  	Training Loss: 0.0004618485691025853
Test Loss:  0.000291460077278316
Valid Loss:  0.00036687502870336175
Epoch:  474  	Training Loss: 0.00046150822890922427
Test Loss:  0.00029209291096776724
Valid Loss:  0.00036664880462922156
Epoch:  475  	Training Loss: 0.0004612316261045635
Test Loss:  0.0002925288863480091
Valid Loss:  0.00036643099156208336
Epoch:  476  	Training Loss: 0.0004609939642250538
Test Loss:  0.0002928168105427176
Valid Loss:  0.00036621603067032993
Epoch:  477  	Training Loss: 0.0004607815353665501
Test Loss:  0.00029299576999619603
Valid Loss:  0.0003660052898339927
Epoch:  478  	Training Loss: 0.00046058898442424834
Test Loss:  0.0002930950140580535
Valid Loss:  0.0003657981869764626
Epoch:  479  	Training Loss: 0.00046040903544053435
Test Loss:  0.0002931347698904574
Valid Loss:  0.0003655959735624492
Epoch:  480  	Training Loss: 0.0004602394183166325
Test Loss:  0.00029313209233805537
Valid Loss:  0.0003653980093076825
Epoch:  481  	Training Loss: 0.00046007742639631033
Test Loss:  0.000293101416900754
Valid Loss:  0.00036520487628877163
Epoch:  482  	Training Loss: 0.0004599225358106196
Test Loss:  0.00027565588243305683
Valid Loss:  0.0003624532255344093
Epoch:  483  	Training Loss: 0.00045478655374608934
Test Loss:  0.00027309678262099624
 97%|█████████▋| 483/500 [05:48<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:48<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:48<00:05,  2.22it/s] 98%|█████████▊| 489/500 [05:48<00:03,  2.98it/s] 98%|█████████▊| 491/500 [05:54<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:55<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:55<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:55<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:55<00:00,  2.97it/s]100%|██████████| 500/500 [05:55<00:00,  1.41it/s]
Valid Loss:  0.00036166125210002065
Epoch:  484  	Training Loss: 0.00045378843788057566
Test Loss:  0.0002719028852880001
Valid Loss:  0.00036072832881473005
Epoch:  485  	Training Loss: 0.00045290921116247773
Test Loss:  0.00027090776711702347
Valid Loss:  0.00035988062154501677
Epoch:  486  	Training Loss: 0.00045208021765574813
Test Loss:  0.00026999099645763636
Valid Loss:  0.0003591485437937081
Epoch:  487  	Training Loss: 0.0004512964515015483
Test Loss:  0.0002691216941457242
Valid Loss:  0.0003584513906389475
Epoch:  488  	Training Loss: 0.0004505562246777117
Test Loss:  0.0002682921476662159
Valid Loss:  0.00035778642632067204
Epoch:  489  	Training Loss: 0.0004498559865169227
Test Loss:  0.0002674994175322354
Valid Loss:  0.0003571541456039995
Epoch:  490  	Training Loss: 0.00044919364154338837
Test Loss:  0.0002667421358637512
Valid Loss:  0.00035655073588714004
Epoch:  491  	Training Loss: 0.0004485664248932153
Test Loss:  0.00026601762510836124
Valid Loss:  0.00035597526584751904
Epoch:  492  	Training Loss: 0.0004479727940633893
Test Loss:  0.00026845786487683654
Valid Loss:  0.00035421474603936076
Epoch:  493  	Training Loss: 0.00044538325164467096
Test Loss:  0.0002681841724552214
Valid Loss:  0.0003531287075020373
Epoch:  494  	Training Loss: 0.00044326484203338623
Test Loss:  0.0002674960414879024
Valid Loss:  0.00035216190735809505
Epoch:  495  	Training Loss: 0.0004412811831571162
Test Loss:  0.000266764109255746
Valid Loss:  0.0003512593684718013
Epoch:  496  	Training Loss: 0.00043940372415818274
Test Loss:  0.0002660497557371855
Valid Loss:  0.0003504012420307845
Epoch:  497  	Training Loss: 0.00043761738925240934
Test Loss:  0.0002653461997397244
Valid Loss:  0.0003495845594443381
Epoch:  498  	Training Loss: 0.00043591836583800614
Test Loss:  0.0002646585926413536
Valid Loss:  0.0003487950307317078
Epoch:  499  	Training Loss: 0.0004342962638475001
Test Loss:  0.00026399028138257563
Valid Loss:  0.00034804263850674033
Epoch:  500  	Training Loss: 0.0004327462229412049
Test Loss:  0.0002633331168908626
Valid Loss:  0.0003473067772574723
seed is  14
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:32, 15.30it/s]  1%|          | 4/500 [00:00<00:31, 15.96it/s]  1%|          | 6/500 [00:00<00:30, 16.28it/s]  2%|▏         | 8/500 [00:00<00:30, 16.34it/s]  2%|▏         | 10/500 [00:00<00:29, 16.38it/s]  2%|▏         | 12/500 [00:00<00:29, 16.47it/s]  3%|▎         | 14/500 [00:00<00:29, 16.53it/s]  3%|▎         | 16/500 [00:00<00:29, 16.19it/s]  4%|▎         | 18/500 [00:01<00:29, 16.12it/s]  4%|▍         | 20/500 [00:01<00:29, 16.23it/s]  4%|▍         | 22/500 [00:01<00:29, 16.22it/s]  5%|▍         | 24/500 [00:01<00:29, 16.33it/s]  5%|▌         | 26/500 [00:01<00:28, 16.37it/s]  6%|▌         | 28/500 [00:01<00:28, 16.46it/s]  6%|▌         | 30/500 [00:01<00:28, 16.42it/s]  6%|▋         | 32/500 [00:01<00:28, 16.40it/s]  7%|▋         | 34/500 [00:02<00:28, 16.38it/s]  7%|▋         | 36/500 [00:02<00:28, 16.44it/s]  8%|▊         | 38/500 [00:02<00:28, 16.48it/s]  8%|▊         | 40/500 [00:02<00:27, 16.49it/s]  8%|▊         | 42/500 [00:02<00:27, 16.53it/s]  9%|▉         | 44/500 [00:02<00:27, 16.52it/s]  9%|▉         | 46/500 [00:02<00:27, 16.51it/s] 10%|▉         | 48/500 [00:02<00:27, 16.57it/s] 10%|█         | 50/500 [00:03<00:27, 16.53it/s] 10%|█         | 52/500 [00:03<00:27, 16.43it/s] 11%|█         | 54/500 [00:03<00:28, 15.51it/s] 11%|█         | 56/500 [00:03<00:27, 15.87it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.04it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.19it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.10it/s] 13%|█▎        | 64/500 [00:03<00:27, 16.07it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.25it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.37it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.42it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.24it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.38it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.46it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.25it/s] 16%|█▌        | 80/500 [00:04<00:26, 16.06it/s] 16%|█▋        | 82/500 [00:05<00:26, 16.04it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.15it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.13it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.24it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.31it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.40it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.46it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.45it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.50it/s] 20%|██        | 100/500 [00:06<00:24, 16.38it/s] 20%|██        | 102/500 [00:06<00:24, 16.27it/s] 21%|██        | 104/500 [00:06<00:24, 16.20it/s] 21%|██        | 106/500 [00:06<00:24, 16.33it/s] 22%|██▏       | 108/500 [00:06<00:24, 16.16it/s] 22%|██▏       | 110/500 [00:06<00:24, 16.20it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.17it/s] 23%|██▎       | 114/500 [00:07<00:24, 16.08it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.01it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.12it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.19it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.15it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.28it/s]Epoch:  1  	Training Loss: 0.2827312648296356
Test Loss:  4669.46533203125
Valid Loss:  4674.7470703125
Epoch:  2  	Training Loss: 4672.244140625
Test Loss:  217832990179328.0
Valid Loss:  215950754316288.0
Epoch:  3  	Training Loss: 216410752024576.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.32it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.29it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.41it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.40it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.35it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.26it/s] 28%|██▊       | 138/500 [00:08<00:24, 15.05it/s] 28%|██▊       | 140/500 [00:08<00:25, 14.40it/s] 28%|██▊       | 142/500 [00:08<00:23, 15.01it/s] 29%|██▉       | 144/500 [00:08<00:23, 15.47it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.81it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.00it/s] 30%|███       | 150/500 [00:09<00:21, 16.12it/s] 30%|███       | 152/500 [00:09<00:21, 16.26it/s] 31%|███       | 154/500 [00:09<00:21, 16.30it/s] 31%|███       | 156/500 [00:09<00:20, 16.45it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.45it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.46it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.32it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.32it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.25it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.19it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.17it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.22it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.34it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.39it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.44it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.42it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.44it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.40it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.34it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.20it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.08it/s] 38%|███▊      | 192/500 [00:11<00:19, 16.17it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.29it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.37it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.40it/s] 40%|████      | 200/500 [00:12<00:18, 16.41it/s] 40%|████      | 202/500 [00:12<00:18, 16.41it/s] 41%|████      | 204/500 [00:12<00:18, 16.33it/s] 41%|████      | 206/500 [00:12<00:18, 16.23it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.31it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.38it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.27it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.25it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.33it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.37it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.47it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.48it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.52it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.34it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.26it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.35it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.49it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.52it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.41it/s] 48%|████▊     | 238/500 [00:14<00:15, 16.42it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.44it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.45it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.43it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.32it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.36it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.42it/s] 50%|█████     | 252/500 [00:15<00:15, 15.94it/s] 51%|█████     | 254/500 [00:15<00:15, 15.63it/s] 51%|█████     | 256/500 [00:15<00:15, 15.93it/s] 52%|█████▏    | 258/500 [00:15<00:15, 16.11it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.20it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.25it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.11it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.07it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.21it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.32it/s] 54%|█████▍    | 272/500 [00:16<00:14, 15.77it/s] 55%|█████▍    | 274/500 [00:16<00:14, 15.27it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.65it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.78it/s] 56%|█████▌    | 280/500 [00:17<00:13, 15.91it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.13it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.21it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.19it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.34it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.37it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.37it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.13it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.12it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.27it/s] 60%|██████    | 300/500 [00:18<00:12, 16.35it/s] 60%|██████    | 302/500 [00:18<00:12, 16.38it/s] 61%|██████    | 304/500 [00:18<00:11, 16.47it/s] 61%|██████    | 306/500 [00:18<00:11, 16.55it/s] 62%|██████▏   | 308/500 [00:18<00:11, 16.56it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.59it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.51it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.40it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.26it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.23it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.13it/s] 64%|██████▍   | 322/500 [00:19<00:11, 16.11it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.17it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.23it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.35it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.36it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.36it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.33it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.34it/s] 68%|██████▊   | 338/500 [00:20<00:10, 16.13it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.08it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.16it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.32it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.40it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.27it/s] 70%|███████   | 350/500 [00:21<00:09, 16.39it/s] 70%|███████   | 352/500 [00:21<00:08, 16.45it/s] 71%|███████   | 354/500 [00:21<00:08, 16.33it/s] 71%|███████   | 356/500 [00:21<00:08, 16.43it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.36it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.26it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.25it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.33it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.33it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.43it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.49it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.51it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.55it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.48it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.38it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.42it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.51it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.51it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.54it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.56it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.60it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.46it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.47it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.52it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.42it/s] 80%|████████  | 400/500 [00:24<00:06, 16.17it/s] 80%|████████  | 402/500 [00:24<00:06, 16.19it/s] 81%|████████  | 404/500 [00:24<00:05, 16.30it/s] 81%|████████  | 406/500 [00:24<00:05, 16.38it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.42it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.51it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.55it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.55it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.46it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.43it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.46it/s] 84%|████████▍ | 422/500 [00:25<00:05, 15.42it/s] 85%|████████▍ | 424/500 [00:26<00:04, 15.59it/s] 85%|████████▌ | 426/500 [00:26<00:04, 15.83it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.03it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.16it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.26it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.34it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.22it/s] 88%|████████▊ | 438/500 [00:26<00:03, 16.37it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.44it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.37it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.42it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.42it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.48it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.48it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.23it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.25it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.30it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.40it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.47it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.51it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.50it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.55it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.55it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.51it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.56it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.59it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.57it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.54it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.52it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.58it/s] 97%|█████████▋| 484/500 [00:29<00:01, 15.86it/s] 97%|█████████▋| 486/500 [00:29<00:00, 15.90it/s] 98%|█████████▊| 488/500 [00:29<00:00, 15.87it/s] 98%|█████████▊| 490/500 [00:30<00:00, 15.98it/s] 98%|█████████▊| 492/500 [00:30<00:00, 15.99it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.12it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.26it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.28it/s]100%|██████████| 500/500 [00:30<00:00, 16.40it/s]100%|██████████| 500/500 [00:30<00:00, 16.27it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  14
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:47,  6.23s/it]  1%|          | 3/500 [00:06<13:51,  1.67s/it]  1%|          | 5/500 [00:06<07:04,  1.17it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:53,  2.83it/s]  2%|▏         | 11/500 [00:13<10:48,  1.33s/it]  3%|▎         | 13/500 [00:13<07:22,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.98it/s]  6%|▌         | 31/500 [00:26<09:13,  1.18s/it]  7%|▋         | 33/500 [00:26<06:35,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.98it/s]  8%|▊         | 41/500 [00:33<08:56,  1.17s/it]  9%|▊         | 43/500 [00:33<06:25,  1.18it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:34<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:42,  1.16s/it] 11%|█         | 53/500 [00:40<06:14,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.25it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.02it/s] 12%|█▏        | 61/500 [00:47<08:34,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:07,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.02it/s]Epoch:  1  	Training Loss: 0.2827312648296356
Test Loss:  0.021667227149009705
Valid Loss:  0.025255315005779266
Epoch:  2  	Training Loss: 0.024454031139612198
Test Loss:  0.014233564026653767
Valid Loss:  0.017549071460962296
Epoch:  3  	Training Loss: 0.016208581626415253
Test Loss:  0.012216996401548386
Valid Loss:  0.015045518055558205
Epoch:  4  	Training Loss: 0.013860827311873436
Test Loss:  0.010518680326640606
Valid Loss:  0.012927725911140442
Epoch:  5  	Training Loss: 0.011905751191079617
Test Loss:  0.009080027230083942
Valid Loss:  0.01113075204193592
Epoch:  6  	Training Loss: 0.010257592424750328
Test Loss:  0.007870705798268318
Valid Loss:  0.009623691439628601
Epoch:  7  	Training Loss: 0.008876146748661995
Test Loss:  0.006859784014523029
Valid Loss:  0.008368158712983131
Epoch:  8  	Training Loss: 0.007727682590484619
Test Loss:  0.006018772721290588
Valid Loss:  0.007330114021897316
Epoch:  9  	Training Loss: 0.006776954047381878
Test Loss:  0.0053084660321474075
Valid Loss:  0.006447864230722189
Epoch:  10  	Training Loss: 0.005976617336273193
Test Loss:  0.004708041436970234
Valid Loss:  0.005702014081180096
Epoch:  11  	Training Loss: 0.005302849225699902
Test Loss:  0.004200598690658808
Valid Loss:  0.005071679595857859
Epoch:  12  	Training Loss: 0.004736247006803751
Test Loss:  0.003771989606320858
Valid Loss:  0.004539602901786566
Epoch:  13  	Training Loss: 0.004260707646608353
Test Loss:  0.0034101097844541073
Valid Loss:  0.004095067270100117
Epoch:  14  	Training Loss: 0.0038632014766335487
Test Loss:  0.0031036240980029106
Valid Loss:  0.003716196632012725
Epoch:  15  	Training Loss: 0.0035271786618977785
Test Loss:  0.002843316877260804
Valid Loss:  0.0033939797431230545
Epoch:  16  	Training Loss: 0.003243059851229191
Test Loss:  0.0026214311365038157
Valid Loss:  0.0031198356300592422
Epoch:  17  	Training Loss: 0.003002801677212119
Test Loss:  0.0024327191058546305
Valid Loss:  0.002886247355490923
Epoch:  18  	Training Loss: 0.002799973590299487
Test Loss:  0.0022724722512066364
Valid Loss:  0.002689089858904481
Epoch:  19  	Training Loss: 0.0026301774196326733
Test Loss:  0.002135638613253832
Valid Loss:  0.0025224536657333374
Epoch:  20  	Training Loss: 0.002487002406269312
Test Loss:  0.002019600011408329
Valid Loss:  0.0023792688734829426
Epoch:  21  	Training Loss: 0.002365507185459137
Test Loss:  0.0019198774825781584
Valid Loss:  0.0022567622363567352
Epoch:  22  	Training Loss: 0.0022623389959335327
Test Loss:  0.0018346712458878756
Valid Loss:  0.0021517148707062006
Epoch:  23  	Training Loss: 0.002174841472879052
Test Loss:  0.001761783380061388
Valid Loss:  0.0020613984670490026
Epoch:  24  	Training Loss: 0.002100468846037984
Test Loss:  0.0016986995469778776
Valid Loss:  0.0019837645813822746
Epoch:  25  	Training Loss: 0.0020371759310364723
Test Loss:  0.0016444765496999025
Valid Loss:  0.0019166599959135056
Epoch:  26  	Training Loss: 0.001983255846425891
Test Loss:  0.0015976706054061651
Valid Loss:  0.001858759787864983
Epoch:  27  	Training Loss: 0.0019372699316591024
Test Loss:  0.001557378564029932
Valid Loss:  0.001809039618819952
Epoch:  28  	Training Loss: 0.00189799047075212
Test Loss:  0.0015225656097754836
Valid Loss:  0.0017660434823483229
Epoch:  29  	Training Loss: 0.001864383346401155
Test Loss:  0.0014923911076039076
Valid Loss:  0.001729122013784945
Epoch:  30  	Training Loss: 0.0018355821957811713
Test Loss:  0.001466379384510219
Valid Loss:  0.0016970377182587981
Epoch:  31  	Training Loss: 0.0018109142547473311
Test Loss:  0.0014439411461353302
Valid Loss:  0.0016691606724634767
Epoch:  32  	Training Loss: 0.001789886737242341
Test Loss:  0.0014246050268411636
Valid Loss:  0.0016450549010187387
Epoch:  33  	Training Loss: 0.0017718470189720392
Test Loss:  0.0014071050100028515
Valid Loss:  0.001624417258426547
Epoch:  34  	Training Loss: 0.00175645318813622
Test Loss:  0.0013933805748820305
Valid Loss:  0.0016057020984590054
Epoch:  35  	Training Loss: 0.0017435136251151562
Test Loss:  0.0013808272778987885
Valid Loss:  0.001589632243849337
Epoch:  36  	Training Loss: 0.0017325186636298895
Test Loss:  0.0013693575747311115
Valid Loss:  0.001575883594341576
Epoch:  37  	Training Loss: 0.0017231435049325228
Test Loss:  0.0013594162883237004
Valid Loss:  0.0015638584736734629
Epoch:  38  	Training Loss: 0.0017151756910607219
Test Loss:  0.0013505796669051051
Valid Loss:  0.001553474459797144
Epoch:  39  	Training Loss: 0.0017083969432860613
Test Loss:  0.0013427726225927472
Valid Loss:  0.001544453203678131
Epoch:  40  	Training Loss: 0.0017026197165250778
Test Loss:  0.0013366591883823276
Valid Loss:  0.0015361355617642403
Epoch:  41  	Training Loss: 0.0016977110644802451
Test Loss:  0.0013305617030709982
Valid Loss:  0.0015291509917005897
Epoch:  42  	Training Loss: 0.0016935280291363597
Test Loss:  0.0013252436183393002
Valid Loss:  0.0015230212593451142
Epoch:  43  	Training Loss: 0.0016899645561352372
Test Loss:  0.0013204733841121197
Valid Loss:  0.0015176802407950163
Epoch:  44  	Training Loss: 0.0016869138926267624
Test Loss:  0.0013162352843210101
Valid Loss:  0.0015129991807043552
Epoch:  45  	Training Loss: 0.001684296759776771
Test Loss:  0.0013124658726155758
Valid Loss:  0.0015088929794728756
Epoch:  46  	Training Loss: 0.0016820428427308798
Test Loss:  0.0013090912252664566
Valid Loss:  0.0015052814269438386
Epoch:  47  	Training Loss: 0.0016801150050014257
Test Loss:  0.0013066967949271202
Valid Loss:  0.0015017975820228457
Epoch:  48  	Training Loss: 0.001678477507084608
Test Loss:  0.0013042418286204338
Valid Loss:  0.0014988011680543423
Epoch:  49  	Training Loss: 0.0016770807560533285
Test Loss:  0.0013019139878451824
Valid Loss:  0.0014961964916437864
Epoch:  50  	Training Loss: 0.0016758863348513842
Test Loss:  0.0012997651938349009
Valid Loss:  0.0014939059037715197
Epoch:  51  	Training Loss: 0.0016748555935919285
Test Loss:  0.001297823037020862
Valid Loss:  0.0014918704982846975
Epoch:  52  	Training Loss: 0.0016739644343033433
Test Loss:  0.00129610241856426
Valid Loss:  0.0014900679234415293
Epoch:  53  	Training Loss: 0.0016731915529817343
Test Loss:  0.0012945904163643718
Valid Loss:  0.001488467794843018
Epoch:  54  	Training Loss: 0.0016725147143006325
Test Loss:  0.001293281908147037
Valid Loss:  0.0014870405429974198
Epoch:  55  	Training Loss: 0.0016719233244657516
Test Loss:  0.0012921006418764591
Valid Loss:  0.0014857640489935875
Epoch:  56  	Training Loss: 0.0016714013181626797
Test Loss:  0.0012910549994558096
Valid Loss:  0.0014846236445009708
Epoch:  57  	Training Loss: 0.001670938334427774
Test Loss:  0.0012901161098852754
Valid Loss:  0.001483603031374514
Epoch:  58  	Training Loss: 0.0016705211019143462
Test Loss:  0.0012893031816929579
Valid Loss:  0.001482662744820118
Epoch:  59  	Training Loss: 0.0016701630083844066
Test Loss:  0.001288857776671648
Valid Loss:  0.001481678569689393
Epoch:  60  	Training Loss: 0.0016698575345799327
Test Loss:  0.0012884950265288353
Valid Loss:  0.001480722799897194
Epoch:  61  	Training Loss: 0.001669605728238821
Test Loss:  0.0012878051493316889
Valid Loss:  0.0014799779746681452
Epoch:  62  	Training Loss: 0.0016693907091394067
Test Loss:  0.0012875078245997429
Valid Loss:  0.0014791644643992186
Epoch:  63  	Training Loss: 0.0016692025819793344
Test Loss:  0.0012866297038272023
Valid Loss:  0.0014786620158702135
Epoch:  64  	Training Loss: 0.001669037970714271
Test Loss:  0.0012864968739449978
Valid Loss:  0.0014779451303184032
Epoch:  65  	Training Loss: 0.0016689049080014229
Test Loss:  0.0012859692797064781
Valid Loss:  0.0014774291776120663
Epoch:  66  	Training Loss: 0.0016687765019014478
Test Loss:  0.0012856479734182358
Valid Loss:  0.0014768920373171568
Epoch:  67  	Training Loss: 0.0016686744056642056
Test Loss:  0.0012851415667682886
Valid Loss:  0.0014764908701181412
Epoch:  68  	Training Loss: 0.001668578595854342
Test Loss:  0.001285154139623046
Valid Loss:  0.0014759247424080968
Epoch:  69  	Training Loss: 0.0016684981528669596
Test Loss:  0.001284298487007618
Valid Loss:  0.0014757458120584488
Epoch:  70  	Training Loss: 0.0016684243455529213
Test Loss:   14%|█▍        | 71/500 [00:54<08:30,  1.19s/it] 15%|█▍        | 73/500 [00:54<06:05,  1.17it/s] 15%|█▌        | 75/500 [00:54<04:23,  1.61it/s] 15%|█▌        | 77/500 [00:54<03:12,  2.19it/s] 16%|█▌        | 79/500 [00:54<02:22,  2.95it/s] 16%|█▌        | 81/500 [01:00<08:12,  1.17s/it] 17%|█▋        | 83/500 [01:01<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:15,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.22it/s] 18%|█▊        | 89/500 [01:01<02:20,  2.93it/s] 18%|█▊        | 91/500 [01:07<08:08,  1.20s/it] 19%|█▊        | 93/500 [01:08<05:49,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:08<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.97it/s] 20%|██        | 101/500 [01:14<07:49,  1.18s/it] 21%|██        | 103/500 [01:14<05:35,  1.18it/s] 21%|██        | 105/500 [01:14<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:15<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:15<02:12,  2.96it/s] 22%|██▏       | 111/500 [01:21<07:41,  1.19s/it] 23%|██▎       | 113/500 [01:21<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:21<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:22<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:22<02:08,  2.97it/s] 24%|██▍       | 121/500 [01:28<07:21,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:15,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.02it/s] 26%|██▌       | 131/500 [01:35<07:10,  1.17s/it] 27%|██▋       | 133/500 [01:35<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:35<02:41,  2.25it/s]0.0012842591386288404
Valid Loss:  0.001475317869335413
Epoch:  71  	Training Loss: 0.0016683593858033419
Test Loss:  0.0012842362048104405
Valid Loss:  0.0014748985413461924
Epoch:  72  	Training Loss: 0.0016683000139892101
Test Loss:  0.0012834235094487667
Valid Loss:  0.00147481937892735
Epoch:  73  	Training Loss: 0.0016682475106790662
Test Loss:  0.0012835541274398565
Valid Loss:  0.0014744352083653212
Epoch:  74  	Training Loss: 0.0016682008281350136
Test Loss:  0.0012833978980779648
Valid Loss:  0.0014741551131010056
Epoch:  75  	Training Loss: 0.001668155426159501
Test Loss:  0.0012829432962462306
Valid Loss:  0.0014740354381501675
Epoch:  76  	Training Loss: 0.0016681177075952291
Test Loss:  0.0012829010374844074
Valid Loss:  0.0014737804885953665
Epoch:  77  	Training Loss: 0.001668078824877739
Test Loss:  0.0012827478349208832
Valid Loss:  0.0014735870063304901
Epoch:  78  	Training Loss: 0.001668046461418271
Test Loss:  0.0012826562160626054
Valid Loss:  0.0014733821153640747
Epoch:  79  	Training Loss: 0.0016680118860676885
Test Loss:  0.00128259661141783
Valid Loss:  0.0014731745468452573
Epoch:  80  	Training Loss: 0.0016679804539307952
Test Loss:  0.0012824451550841331
Valid Loss:  0.0014730170369148254
Epoch:  81  	Training Loss: 0.0016679537948220968
Test Loss:  0.0012819720432162285
Valid Loss:  0.0014730143593624234
Epoch:  82  	Training Loss: 0.0016679289983585477
Test Loss:  0.0012820051051676273
Valid Loss:  0.0014728410169482231
Epoch:  83  	Training Loss: 0.0016679029213264585
Test Loss:  0.0012820863630622625
Valid Loss:  0.0014726496301591396
Epoch:  84  	Training Loss: 0.0016678764950484037
Test Loss:  0.0012818063842132688
Valid Loss:  0.0014726079534739256
Epoch:  85  	Training Loss: 0.0016678533283993602
Test Loss:  0.0012818262912333012
Valid Loss:  0.00147246103733778
Epoch:  86  	Training Loss: 0.0016678294632583857
Test Loss:  0.0012817531824111938
Valid Loss:  0.0014723576605319977
Epoch:  87  	Training Loss: 0.0016678066458553076
Test Loss:  0.00128170067910105
Valid Loss:  0.0014722499763593078
Epoch:  88  	Training Loss: 0.001667785458266735
Test Loss:  0.001281615113839507
Valid Loss:  0.0014721521874889731
Epoch:  89  	Training Loss: 0.0016677621752023697
Test Loss:  0.001281537814065814
Valid Loss:  0.0014720752369612455
Epoch:  90  	Training Loss: 0.0016677412204444408
Test Loss:  0.001281463773921132
Valid Loss:  0.0014719993341714144
Epoch:  91  	Training Loss: 0.001667720964178443
Test Loss:  0.0012813941575586796
Valid Loss:  0.0014719280879944563
Epoch:  92  	Training Loss: 0.0016677004750818014
Test Loss:  0.0012809938052669168
Valid Loss:  0.001471999567002058
Epoch:  93  	Training Loss: 0.0016676814993843436
Test Loss:  0.0012812973000109196
Valid Loss:  0.0014718250604346395
Epoch:  94  	Training Loss: 0.0016676632221788168
Test Loss:  0.0012810486368834972
Valid Loss:  0.0014718447346240282
Epoch:  95  	Training Loss: 0.0016676443628966808
Test Loss:  0.001281196717172861
Valid Loss:  0.001471719820983708
Epoch:  96  	Training Loss: 0.0016676243394613266
Test Loss:  0.0012811508495360613
Valid Loss:  0.001471665222197771
Epoch:  97  	Training Loss: 0.0016676068771630526
Test Loss:  0.0012811010237783194
Valid Loss:  0.00147161609493196
Epoch:  98  	Training Loss: 0.0016675891820341349
Test Loss:  0.001281060976907611
Valid Loss:  0.0014715669676661491
Epoch:  99  	Training Loss: 0.0016675691585987806
Test Loss:  0.0012810173211619258
Valid Loss:  0.0014715224970132113
Epoch:  100  	Training Loss: 0.0016675530932843685
Test Loss:  0.00128097680862993
Valid Loss:  0.001471483032219112
Epoch:  101  	Training Loss: 0.0016675360966473818
Test Loss:  0.0012807652819901705
Valid Loss:  0.0014715094584971666
Epoch:  102  	Training Loss: 0.0016675179358571768
Test Loss:  0.0012809186009690166
Valid Loss:  0.001471416326239705
Epoch:  103  	Training Loss: 0.0016675011720508337
Test Loss:  0.0012808766914531589
Valid Loss:  0.0014713788405060768
Epoch:  104  	Training Loss: 0.0016674844082444906
Test Loss:  0.0012807883322238922
Valid Loss:  0.001471364637836814
Epoch:  105  	Training Loss: 0.0016674649668857455
Test Loss:  0.0012808218598365784
Valid Loss:  0.0014713127166032791
Epoch:  106  	Training Loss: 0.001667449134401977
Test Loss:  0.0012807545717805624
Valid Loss:  0.001471297349780798
Epoch:  107  	Training Loss: 0.0016674312064424157
Test Loss:  0.0012807688908651471
Valid Loss:  0.0014712547417730093
Epoch:  108  	Training Loss: 0.00166741490829736
Test Loss:  0.0012807372258976102
Valid Loss:  0.0014712268020957708
Epoch:  109  	Training Loss: 0.0016673966310918331
Test Loss:  0.00128070916980505
Valid Loss:  0.0014711981639266014
Epoch:  110  	Training Loss: 0.0016673814970999956
Test Loss:  0.0012806858867406845
Valid Loss:  0.0014711751136928797
Epoch:  111  	Training Loss: 0.0016673647332936525
Test Loss:  0.0012806616723537445
Valid Loss:  0.0014711428666487336
Epoch:  112  	Training Loss: 0.0016673437785357237
Test Loss:  0.0012806383892893791
Valid Loss:  0.001471119001507759
Epoch:  113  	Training Loss: 0.0016673326026648283
Test Loss:  0.0012806151062250137
Valid Loss:  0.001471100840717554
Epoch:  114  	Training Loss: 0.0016673160716891289
Test Loss:  0.0012805918231606483
Valid Loss:  0.001471080118790269
Epoch:  115  	Training Loss: 0.0016673008212819695
Test Loss:  0.0012805736623704433
Valid Loss:  0.0014710507821291685
Epoch:  116  	Training Loss: 0.001667282311245799
Test Loss:  0.0012805541045963764
Valid Loss:  0.0014710318064317107
Epoch:  117  	Training Loss: 0.001667268224991858
Test Loss:  0.001280531520023942
Valid Loss:  0.0014710142277181149
Epoch:  118  	Training Loss: 0.001667253440245986
Test Loss:  0.001280510681681335
Valid Loss:  0.001470991875976324
Epoch:  119  	Training Loss: 0.001667235977947712
Test Loss:  0.0012804935686290264
Valid Loss:  0.0014709692914038897
Epoch:  120  	Training Loss: 0.0016672220081090927
Test Loss:  0.001280477736145258
Valid Loss:  0.0014709557872265577
Epoch:  121  	Training Loss: 0.0016672052443027496
Test Loss:  0.0012804598081856966
Valid Loss:  0.0014709344832226634
Epoch:  122  	Training Loss: 0.001667188247665763
Test Loss:  0.0012804437428712845
Valid Loss:  0.0014709143433719873
Epoch:  123  	Training Loss: 0.0016671725315973163
Test Loss:  0.0012804230209439993
Valid Loss:  0.0014708999078720808
Epoch:  124  	Training Loss: 0.0016671555349603295
Test Loss:  0.0012804032303392887
Valid Loss:  0.001470884308218956
Epoch:  125  	Training Loss: 0.0016671408666297793
Test Loss:  0.001280390890315175
Valid Loss:  0.001470866845920682
Epoch:  126  	Training Loss: 0.0016671292250975966
Test Loss:  0.0012803752906620502
Valid Loss:  0.001470850664190948
Epoch:  127  	Training Loss: 0.0016671130433678627
Test Loss:  0.001280359923839569
Valid Loss:  0.0014708316884934902
Epoch:  128  	Training Loss: 0.0016670981422066689
Test Loss:  0.0012803443241864443
Valid Loss:  0.0014708153903484344
Epoch:  129  	Training Loss: 0.0016670823097229004
Test Loss:  0.0012803311692550778
Valid Loss:  0.001470800954848528
Epoch:  130  	Training Loss: 0.0016670681070536375
Test Loss:  0.001280317548662424
Valid Loss:  0.0014707862865179777
Epoch:  131  	Training Loss: 0.0016670532058924437
Test Loss:  0.0012803029967471957
Valid Loss:  0.001470770570449531
Epoch:  132  	Training Loss: 0.0016670397017151117
Test Loss:  0.0012802905403077602
Valid Loss:  0.0014707553200423717
Epoch:  133  	Training Loss: 0.0016670249169692397
Test Loss:  0.0012802756391465664
Valid Loss:  0.0014707401860505342
Epoch:  134  	Training Loss: 0.0016670087352395058
Test Loss:  0.0012802605051547289
Valid Loss:  0.0014707252848893404
Epoch:  135  	Training Loss: 0.001666997093707323
Test Loss:  0.0012802480487152934
Valid Loss:  0.0014707117807120085
Epoch:  136  	Training Loss: 0.0016669798642396927
Test Loss:  0.0012802394339814782
Valid Loss:  0.0014706943184137344
Epoch:  137  	Training Loss: 0.001666966243647039
Test Loss:  0.0012802251148968935
Valid Loss:  0.0014706779038533568
Epoch:  138  	Training Loss: 0.0016669508768245578
Test Loss:  0.001280209282413125
Valid Loss:  0.0014706694055348635
Epoch:  139  	Training Loss: 0.0016669387696310878
Test Loss:  28%|██▊       | 139/500 [01:35<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:42<07:06,  1.19s/it] 29%|██▊       | 143/500 [01:42<05:04,  1.17it/s] 29%|██▉       | 145/500 [01:42<03:38,  1.62it/s] 29%|██▉       | 147/500 [01:42<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:42<01:58,  2.97it/s] 30%|███       | 151/500 [01:48<06:45,  1.16s/it] 31%|███       | 153/500 [01:48<04:50,  1.20it/s] 31%|███       | 155/500 [01:49<03:28,  1.65it/s] 31%|███▏      | 157/500 [01:49<02:32,  2.26it/s] 32%|███▏      | 159/500 [01:49<01:52,  3.03it/s] 32%|███▏      | 161/500 [01:55<06:44,  1.19s/it] 33%|███▎      | 163/500 [01:55<04:48,  1.17it/s] 33%|███▎      | 165/500 [01:56<03:27,  1.62it/s] 33%|███▎      | 167/500 [01:56<02:31,  2.20it/s] 34%|███▍      | 169/500 [01:56<01:51,  2.96it/s] 34%|███▍      | 171/500 [02:02<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:38,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:03<02:26,  2.21it/s] 36%|███▌      | 179/500 [02:03<01:48,  2.97it/s] 36%|███▌      | 181/500 [02:09<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:27,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:16<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:16<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:06,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:16,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:42,  2.94it/s] 40%|████      | 201/500 [02:23<05:55,  1.19s/it] 41%|████      | 203/500 [02:23<04:13,  1.17it/s] 41%|████      | 205/500 [02:23<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:23<02:12,  2.21it/s] 0.001280196593143046
Valid Loss:  0.001470655668526888
Epoch:  140  	Training Loss: 0.001666923868469894
Test Loss:  0.0012801866978406906
Valid Loss:  0.0014706412330269814
Epoch:  141  	Training Loss: 0.0016669115284457803
Test Loss:  0.0012801758712157607
Valid Loss:  0.0014706330839544535
Epoch:  142  	Training Loss: 0.001666900236159563
Test Loss:  0.0012801631819456816
Valid Loss:  0.0014706207439303398
Epoch:  143  	Training Loss: 0.001666887430474162
Test Loss:  0.0012801534030586481
Valid Loss:  0.0014706074725836515
Epoch:  144  	Training Loss: 0.0016668750904500484
Test Loss:  0.0012801394332200289
Valid Loss:  0.0014705948997288942
Epoch:  145  	Training Loss: 0.0016668618191033602
Test Loss:  0.0012801258126273751
Valid Loss:  0.0014705830253660679
Epoch:  146  	Training Loss: 0.0016668499447405338
Test Loss:  0.0012801128905266523
Valid Loss:  0.0014705698704347014
Epoch:  147  	Training Loss: 0.0016668348107486963
Test Loss:  0.001280102296732366
Valid Loss:  0.001470562070608139
Epoch:  148  	Training Loss: 0.0016668259631842375
Test Loss:  0.0012800905387848616
Valid Loss:  0.0014705484500154853
Epoch:  149  	Training Loss: 0.0016668119933456182
Test Loss:  0.0012800802942365408
Valid Loss:  0.0014705328503623605
Epoch:  150  	Training Loss: 0.001666798023506999
Test Loss:  0.0012800677213817835
Valid Loss:  0.0014705235371366143
Epoch:  151  	Training Loss: 0.0016667861491441727
Test Loss:  0.0012800541007891297
Valid Loss:  0.00147051305975765
Epoch:  152  	Training Loss: 0.0016667714808136225
Test Loss:  0.001280041877180338
Valid Loss:  0.0014705001376569271
Epoch:  153  	Training Loss: 0.0016667582094669342
Test Loss:  0.0012800332624465227
Valid Loss:  0.001470492104999721
Epoch:  154  	Training Loss: 0.0016667473828420043
Test Loss:  0.00128002162091434
Valid Loss:  0.0014704789500683546
Epoch:  155  	Training Loss: 0.0016667345771566033
Test Loss:  0.001280010212212801
Valid Loss:  0.0014704668428748846
Epoch:  156  	Training Loss: 0.0016667218878865242
Test Loss:  0.0012800028780475259
Valid Loss:  0.0014704576460644603
Epoch:  157  	Training Loss: 0.0016667116433382034
Test Loss:  0.0012799907708540559
Valid Loss:  0.001470448449254036
Epoch:  158  	Training Loss: 0.0016666981391608715
Test Loss:  0.0012799804098904133
Valid Loss:  0.0014704375062137842
Epoch:  159  	Training Loss: 0.0016666885931044817
Test Loss:  0.0012799695832654834
Valid Loss:  0.0014704219065606594
Epoch:  160  	Training Loss: 0.0016666767187416553
Test Loss:  0.0012799601536244154
Valid Loss:  0.001470410730689764
Epoch:  161  	Training Loss: 0.001666664145886898
Test Loss:  0.001279951655305922
Valid Loss:  0.0014704018831253052
Epoch:  162  	Training Loss: 0.001666652038693428
Test Loss:  0.0012799391988664865
Valid Loss:  0.0014703928027302027
Epoch:  163  	Training Loss: 0.0016666422598063946
Test Loss:  0.0012799293035641313
Valid Loss:  0.0014703802298754454
Epoch:  164  	Training Loss: 0.0016666320152580738
Test Loss:  0.001279919408261776
Valid Loss:  0.0014703723136335611
Epoch:  165  	Training Loss: 0.0016666232841089368
Test Loss:  0.0012799068354070187
Valid Loss:  0.0014703614870086312
Epoch:  166  	Training Loss: 0.0016666115261614323
Test Loss:  0.001279899151995778
Valid Loss:  0.0014703469350934029
Epoch:  167  	Training Loss: 0.0016666025621816516
Test Loss:  0.00127988844178617
Valid Loss:  0.0014703413471579552
Epoch:  168  	Training Loss: 0.0016665904549881816
Test Loss:  0.001279880991205573
Valid Loss:  0.0014703323831781745
Epoch:  169  	Training Loss: 0.0016665799776092172
Test Loss:  0.0012798681855201721
Valid Loss:  0.0014703224878758192
Epoch:  170  	Training Loss: 0.0016665705479681492
Test Loss:  0.0012798593379557133
Valid Loss:  0.001470309915021062
Epoch:  171  	Training Loss: 0.0016665589064359665
Test Loss:  0.0012798476964235306
Valid Loss:  0.0014703014167025685
Epoch:  172  	Training Loss: 0.0016665504081174731
Test Loss:  0.0012798410607501864
Valid Loss:  0.0014702952466905117
Epoch:  173  	Training Loss: 0.0016665414441376925
Test Loss:  0.0012798311654478312
Valid Loss:  0.0014702881453558803
Epoch:  174  	Training Loss: 0.001666528987698257
Test Loss:  0.0012798185925930738
Valid Loss:  0.0014702781336382031
Epoch:  175  	Training Loss: 0.0016665192088112235
Test Loss:  0.0012798116076737642
Valid Loss:  0.001470267539843917
Epoch:  176  	Training Loss: 0.0016665097791701555
Test Loss:  0.0012798015959560871
Valid Loss:  0.0014702569460496306
Epoch:  177  	Training Loss: 0.001666501397266984
Test Loss:  0.0012797904200851917
Valid Loss:  0.0014702464686706662
Epoch:  178  	Training Loss: 0.0016664895229041576
Test Loss:  0.001279781456105411
Valid Loss:  0.001470236573368311
Epoch:  179  	Training Loss: 0.0016664790455251932
Test Loss:  0.0012797722592949867
Valid Loss:  0.0014702251646667719
Epoch:  180  	Training Loss: 0.0016664717113599181
Test Loss:  0.0012797631788998842
Valid Loss:  0.0014702202752232552
Epoch:  181  	Training Loss: 0.0016664628637954593
Test Loss:  0.0012797557283192873
Valid Loss:  0.0014702142216265202
Epoch:  182  	Training Loss: 0.0016664520371705294
Test Loss:  0.001279744552448392
Valid Loss:  0.0014702046755701303
Epoch:  183  	Training Loss: 0.0016664438880980015
Test Loss:  0.0012797347735613585
Valid Loss:  0.0014701980398967862
Epoch:  184  	Training Loss: 0.0016664338763803244
Test Loss:  0.0012797246454283595
Valid Loss:  0.0014701904729008675
Epoch:  185  	Training Loss: 0.0016664236318320036
Test Loss:  0.001279712887480855
Valid Loss:  0.0014701816253364086
Epoch:  186  	Training Loss: 0.001666415249928832
Test Loss:  0.0012797004310414195
Valid Loss:  0.0014701716136187315
Epoch:  187  	Training Loss: 0.001666405238211155
Test Loss:  0.0012796934461221099
Valid Loss:  0.00147016323171556
Epoch:  188  	Training Loss: 0.0016663956921547651
Test Loss:  0.0012796830851584673
Valid Loss:  0.0014701534528285265
Epoch:  189  	Training Loss: 0.0016663852147758007
Test Loss:  0.0012796773808076978
Valid Loss:  0.001470146351493895
Epoch:  190  	Training Loss: 0.0016663775313645601
Test Loss:  0.0012796656228601933
Valid Loss:  0.0014701382024213672
Epoch:  191  	Training Loss: 0.0016663658898323774
Test Loss:  0.0012796560768038034
Valid Loss:  0.0014701285399496555
Epoch:  192  	Training Loss: 0.0016663572750985622
Test Loss:  0.0012796428054571152
Valid Loss:  0.0014701206237077713
Epoch:  193  	Training Loss: 0.0016663465648889542
Test Loss:  0.001279635587707162
Valid Loss:  0.001470112823881209
Epoch:  194  	Training Loss: 0.0016663395799696445
Test Loss:  0.0012796291848644614
Valid Loss:  0.0014701001346111298
Epoch:  195  	Training Loss: 0.0016663293354213238
Test Loss:  0.0012796232476830482
Valid Loss:  0.0014700953615829349
Epoch:  196  	Training Loss: 0.0016663187416270375
Test Loss:  0.0012796090450137854
Valid Loss:  0.001470087794587016
Epoch:  197  	Training Loss: 0.0016663095448166132
Test Loss:  0.0012795969378203154
Valid Loss:  0.0014700806932523847
Epoch:  198  	Training Loss: 0.0016662979032844305
Test Loss:  0.001279592514038086
Valid Loss:  0.0014700733590871096
Epoch:  199  	Training Loss: 0.00166629021987319
Test Loss:  0.0012795800575986505
Valid Loss:  0.0014700625324621797
Epoch:  200  	Training Loss: 0.0016662806738168001
Test Loss:  0.001279572257772088
Valid Loss:  0.0014700539177283645
Epoch:  201  	Training Loss: 0.0016662718262523413
Test Loss:  0.0012795650400221348
Valid Loss:  0.0014700435567647219
Epoch:  202  	Training Loss: 0.0016662650741636753
Test Loss:  0.0012795511865988374
Valid Loss:  0.0014700349420309067
Epoch:  203  	Training Loss: 0.0016662569250911474
Test Loss:  0.001279541291296482
Valid Loss:  0.0014700284227728844
Epoch:  204  	Training Loss: 0.001666247844696045
Test Loss:  0.0012795350048691034
Valid Loss:  0.001470018643885851
Epoch:  205  	Training Loss: 0.0016662382986396551
Test Loss:  0.0012795261573046446
Valid Loss:  0.001470012590289116
Epoch:  206  	Training Loss: 0.0016662281705066562
Test Loss:  0.0012795203365385532
Valid Loss:  0.0014700042083859444
Epoch:  207  	Training Loss: 0.0016662217676639557
Test Loss:  0.0012795103248208761
Valid Loss:  0.0014699959428980947
 42%|████▏     | 209/500 [02:23<01:37,  2.97it/s] 42%|████▏     | 211/500 [02:30<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:30<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:30<02:54,  1.63it/s] 43%|████▎     | 217/500 [02:30<02:07,  2.23it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:36<05:26,  1.17s/it] 45%|████▍     | 223/500 [02:36<03:52,  1.19it/s] 45%|████▌     | 225/500 [02:37<02:47,  1.64it/s] 45%|████▌     | 227/500 [02:37<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:37<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:43<05:15,  1.17s/it] 47%|████▋     | 233/500 [02:43<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:43<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:44<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:50<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.00it/s] 50%|█████     | 251/500 [02:57<04:51,  1.17s/it] 51%|█████     | 253/500 [02:57<03:27,  1.19it/s] 51%|█████     | 255/500 [02:57<02:28,  1.64it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.25it/s] 52%|█████▏    | 259/500 [02:57<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:04<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:04<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:10<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:10<03:10,  1.19it/s] 55%|█████▌    | 275/500 [03:11<02:16,  1.64it/s]Epoch:  208  	Training Loss: 0.001666211523115635
Test Loss:  0.0012794998474419117
Valid Loss:  0.0014699905877932906
Epoch:  209  	Training Loss: 0.0016662054695189
Test Loss:  0.0012794861104339361
Valid Loss:  0.0014699824387207627
Epoch:  210  	Training Loss: 0.0016661930130794644
Test Loss:  0.0012794838985428214
Valid Loss:  0.0014699718449264765
Epoch:  211  	Training Loss: 0.001666185213252902
Test Loss:  0.0012794681824743748
Valid Loss:  0.001469964161515236
Epoch:  212  	Training Loss: 0.0016661786939948797
Test Loss:  0.001279461313970387
Valid Loss:  0.0014699550811201334
Epoch:  213  	Training Loss: 0.0016661698464304209
Test Loss:  0.0012794535141438246
Valid Loss:  0.0014699480962008238
Epoch:  214  	Training Loss: 0.0016661598347127438
Test Loss:  0.0012794442009180784
Valid Loss:  0.0014699451858177781
Epoch:  215  	Training Loss: 0.001666153664700687
Test Loss:  0.001279433025047183
Valid Loss:  0.0014699329622089863
Epoch:  216  	Training Loss: 0.0016661436529830098
Test Loss:  0.001279426272958517
Valid Loss:  0.0014699255116283894
Epoch:  217  	Training Loss: 0.001666136085987091
Test Loss:  0.0012794160284101963
Valid Loss:  0.001469918293878436
Epoch:  218  	Training Loss: 0.0016661263071000576
Test Loss:  0.0012794084614142776
Valid Loss:  0.0014699085149914026
Epoch:  219  	Training Loss: 0.0016661190893501043
Test Loss:  0.0012793969362974167
Valid Loss:  0.001469901530072093
Epoch:  220  	Training Loss: 0.0016661116387695074
Test Loss:  0.0012793861096724868
Valid Loss:  0.0014698955928906798
Epoch:  221  	Training Loss: 0.0016661050030961633
Test Loss:  0.0012793780770152807
Valid Loss:  0.0014698849990963936
Epoch:  222  	Training Loss: 0.001666097086854279
Test Loss:  0.0012793720234185457
Valid Loss:  0.0014698740560561419
Epoch:  223  	Training Loss: 0.0016660880064591765
Test Loss:  0.0012793620117008686
Valid Loss:  0.001469873357564211
Epoch:  224  	Training Loss: 0.0016660784604027867
Test Loss:  0.0012793533969670534
Valid Loss:  0.00146986055187881
Epoch:  225  	Training Loss: 0.00166607229039073
Test Loss:  0.0012793445494025946
Valid Loss:  0.0014698533341288567
Epoch:  226  	Training Loss: 0.0016660632099956274
Test Loss:  0.0012793364003300667
Valid Loss:  0.0014698455343022943
Epoch:  227  	Training Loss: 0.0016660557594150305
Test Loss:  0.0012793302303180099
Valid Loss:  0.0014698418090119958
Epoch:  228  	Training Loss: 0.001666047377511859
Test Loss:  0.0012793159112334251
Valid Loss:  0.0014698316808789968
Epoch:  229  	Training Loss: 0.0016660387627780437
Test Loss:  0.001279309974052012
Valid Loss:  0.0014698256272822618
Epoch:  230  	Training Loss: 0.001666033174842596
Test Loss:  0.001279298448935151
Valid Loss:  0.0014698200393468142
Epoch:  231  	Training Loss: 0.0016660250257700682
Test Loss:  0.0012792940251529217
Valid Loss:  0.0014698109589517117
Epoch:  232  	Training Loss: 0.0016660182736814022
Test Loss:  0.0012792844790965319
Valid Loss:  0.001469803391955793
Epoch:  233  	Training Loss: 0.0016660093097016215
Test Loss:  0.001279274234548211
Valid Loss:  0.0014697944279760122
Epoch:  234  	Training Loss: 0.0016660024411976337
Test Loss:  0.001279264222830534
Valid Loss:  0.0014697853475809097
Epoch:  235  	Training Loss: 0.0016659942921251059
Test Loss:  0.001279253512620926
Valid Loss:  0.0014697783626616001
Epoch:  236  	Training Loss: 0.0016659869579598308
Test Loss:  0.00127924676053226
Valid Loss:  0.0014697718434035778
Epoch:  237  	Training Loss: 0.0016659795073792338
Test Loss:  0.0012792429188266397
Valid Loss:  0.0014697678852826357
Epoch:  238  	Training Loss: 0.0016659724060446024
Test Loss:  0.001279229298233986
Valid Loss:  0.001469757524318993
Epoch:  239  	Training Loss: 0.0016659649554640055
Test Loss:  0.001279221149161458
Valid Loss:  0.0014697503065690398
Epoch:  240  	Training Loss: 0.001665957155637443
Test Loss:  0.001279215794056654
Valid Loss:  0.0014697450678795576
Epoch:  241  	Training Loss: 0.0016659494722262025
Test Loss:  0.0012792060151696205
Valid Loss:  0.0014697385486215353
Epoch:  242  	Training Loss: 0.0016659413231536746
Test Loss:  0.0012792005436494946
Valid Loss:  0.0014697310980409384
Epoch:  243  	Training Loss: 0.001665937015786767
Test Loss:  0.001279190182685852
Valid Loss:  0.0014697264414280653
Epoch:  244  	Training Loss: 0.0016659288667142391
Test Loss:  0.0012791797053068876
Valid Loss:  0.0014697201550006866
Epoch:  245  	Training Loss: 0.0016659216489642859
Test Loss:  0.0012791729532182217
Valid Loss:  0.0014697108417749405
Epoch:  246  	Training Loss: 0.0016659125685691833
Test Loss:  0.0012791645713150501
Valid Loss:  0.0014697045553475618
Epoch:  247  	Training Loss: 0.0016659065149724483
Test Loss:  0.0012791529297828674
Valid Loss:  0.001469699665904045
Epoch:  248  	Training Loss: 0.0016658979002386332
Test Loss:  0.0012791450135409832
Valid Loss:  0.0014696902362629771
Epoch:  249  	Training Loss: 0.0016658890526741743
Test Loss:  0.0012791405897587538
Valid Loss:  0.0014696866273880005
Epoch:  250  	Training Loss: 0.0016658821841701865
Test Loss:  0.001279131043702364
Valid Loss:  0.0014696777798235416
Epoch:  251  	Training Loss: 0.001665875082835555
Test Loss:  0.0012791266199201345
Valid Loss:  0.00146966811735183
Epoch:  252  	Training Loss: 0.0016658715903759003
Test Loss:  0.001279118238016963
Valid Loss:  0.0014696619473397732
Epoch:  253  	Training Loss: 0.0016658604145050049
Test Loss:  0.0012791117187589407
Valid Loss:  0.0014696603175252676
Epoch:  254  	Training Loss: 0.0016658544773235917
Test Loss:  0.0012791049666702747
Valid Loss:  0.001469647977501154
Epoch:  255  	Training Loss: 0.0016658490058034658
Test Loss:  0.0012790937907993793
Valid Loss:  0.0014696447178721428
Epoch:  256  	Training Loss: 0.0016658422537147999
Test Loss:  0.0012790921609848738
Valid Loss:  0.0014696377329528332
Epoch:  257  	Training Loss: 0.0016658342210575938
Test Loss:  0.0012790823820978403
Valid Loss:  0.0014696307480335236
Epoch:  258  	Training Loss: 0.0016658264212310314
Test Loss:  0.0012790737673640251
Valid Loss:  0.0014696225989609957
Epoch:  259  	Training Loss: 0.0016658192034810781
Test Loss:  0.001279068412259221
Valid Loss:  0.0014696179423481226
Epoch:  260  	Training Loss: 0.0016658136155456305
Test Loss:  0.0012790574692189693
Valid Loss:  0.001469610258936882
Epoch:  261  	Training Loss: 0.0016658054664731026
Test Loss:  0.00127905304543674
Valid Loss:  0.0014696046710014343
Epoch:  262  	Training Loss: 0.0016657988307997584
Test Loss:  0.001279046991840005
Valid Loss:  0.001469597453251481
Epoch:  263  	Training Loss: 0.001665791030973196
Test Loss:  0.0012790365144610405
Valid Loss:  0.0014695929130539298
Epoch:  264  	Training Loss: 0.0016657845117151737
Test Loss:  0.0012790336040779948
Valid Loss:  0.0014695848803967237
Epoch:  265  	Training Loss: 0.0016657784581184387
Test Loss:  0.0012790239416062832
Valid Loss:  0.0014695781283080578
Epoch:  266  	Training Loss: 0.0016657719388604164
Test Loss:  0.0012790178880095482
Valid Loss:  0.0014695695135742426
Epoch:  267  	Training Loss: 0.0016657629748806357
Test Loss:  0.0012790123000741005
Valid Loss:  0.0014695655554533005
Epoch:  268  	Training Loss: 0.0016657570376992226
Test Loss:  0.0012790100881829858
Valid Loss:  0.0014695592690259218
Epoch:  269  	Training Loss: 0.0016657491214573383
Test Loss:  0.0012790027540177107
Valid Loss:  0.0014695526333525777
Epoch:  270  	Training Loss: 0.0016657450469210744
Test Loss:  0.0012789936736226082
Valid Loss:  0.0014695447171106935
Epoch:  271  	Training Loss: 0.0016657374799251556
Test Loss:  0.0012789892498403788
Valid Loss:  0.0014695415738970041
Epoch:  272  	Training Loss: 0.0016657309606671333
Test Loss:  0.00127898168284446
Valid Loss:  0.0014695341233164072
Epoch:  273  	Training Loss: 0.001665726536884904
Test Loss:  0.0012789738830178976
Valid Loss:  0.0014695264399051666
Epoch:  274  	Training Loss: 0.001665719086304307
Test Loss:  0.0012789701577275991
Valid Loss:  0.0014695196878165007
Epoch:  275  	Training Loss: 0.0016657127998769283
Test Loss:  0.0012789629399776459
Valid Loss:  0.0014695104910060763
Epoch:  276  	Training Loss: 0.0016657087253406644
Test Loss:  0.0012789573520421982
 55%|█████▌    | 277/500 [03:11<01:39,  2.25it/s] 56%|█████▌    | 279/500 [03:11<01:13,  3.02it/s] 56%|█████▌    | 281/500 [03:17<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.64it/s] 57%|█████▋    | 287/500 [03:18<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:18<01:10,  3.00it/s] 58%|█████▊    | 291/500 [03:24<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:24<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.24it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.01it/s] 60%|██████    | 301/500 [03:31<03:55,  1.18s/it] 61%|██████    | 303/500 [03:31<02:47,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:31<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:38<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:38<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:38<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:38<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:45<03:31,  1.18s/it] 65%|██████▍   | 323/500 [03:45<02:30,  1.17it/s] 65%|██████▌   | 325/500 [03:45<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:45<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:45<00:57,  2.95it/s] 66%|██████▌   | 331/500 [03:51<03:20,  1.18s/it] 67%|██████▋   | 333/500 [03:52<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:52<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:52<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:52<00:54,  2.97it/s] 68%|██████▊   | 341/500 [03:58<03:07,  1.18s/it] 69%|██████▊   | 343/500 [03:58<02:12,  1.18it/s]Valid Loss:  0.001469508744776249
Epoch:  277  	Training Loss: 0.0016657012747600675
Test Loss:  0.0012789524625986814
Valid Loss:  0.001469501294195652
Epoch:  278  	Training Loss: 0.0016656972002238035
Test Loss:  0.0012789461761713028
Valid Loss:  0.001469496637582779
Epoch:  279  	Training Loss: 0.0016656930092722178
Test Loss:  0.0012789397733286023
Valid Loss:  0.001469491282477975
Epoch:  280  	Training Loss: 0.0016656862571835518
Test Loss:  0.0012789331376552582
Valid Loss:  0.0014694859273731709
Epoch:  281  	Training Loss: 0.0016656792722642422
Test Loss:  0.0012789254542440176
Valid Loss:  0.0014694792916998267
Epoch:  282  	Training Loss: 0.0016656731022521853
Test Loss:  0.0012789203319698572
Valid Loss:  0.0014694732381030917
Epoch:  283  	Training Loss: 0.0016656690277159214
Test Loss:  0.0012789152096956968
Valid Loss:  0.0014694677665829659
Epoch:  284  	Training Loss: 0.0016656620427966118
Test Loss:  0.0012789085740223527
Valid Loss:  0.0014694584533572197
Epoch:  285  	Training Loss: 0.0016656562220305204
Test Loss:  0.0012789024040102959
Valid Loss:  0.0014694532146677375
Epoch:  286  	Training Loss: 0.0016656493535265326
Test Loss:  0.0012788926251232624
Valid Loss:  0.001469447510316968
Epoch:  287  	Training Loss: 0.0016656420193612576
Test Loss:  0.0012788858730345964
Valid Loss:  0.0014694433193653822
Epoch:  288  	Training Loss: 0.0016656359657645226
Test Loss:  0.0012788826134055853
Valid Loss:  0.0014694362180307508
Epoch:  289  	Training Loss: 0.0016656320076435804
Test Loss:  0.0012788793537765741
Valid Loss:  0.0014694288838654757
Epoch:  290  	Training Loss: 0.0016656246734783053
Test Loss:  0.0012788709718734026
Valid Loss:  0.001469425274990499
Epoch:  291  	Training Loss: 0.0016656189691275358
Test Loss:  0.001278863986954093
Valid Loss:  0.0014694173587486148
Epoch:  292  	Training Loss: 0.0016656133811920881
Test Loss:  0.0012788573512807488
Valid Loss:  0.0014694128185510635
Epoch:  293  	Training Loss: 0.0016656070947647095
Test Loss:  0.0012788505991920829
Valid Loss:  0.0014694060664623976
Epoch:  294  	Training Loss: 0.0016656012739986181
Test Loss:  0.0012788448948413134
Valid Loss:  0.0014693995472043753
Epoch:  295  	Training Loss: 0.0016655949875712395
Test Loss:  0.0012788380263373256
Valid Loss:  0.0014693954726681113
Epoch:  296  	Training Loss: 0.0016655923100188375
Test Loss:  0.0012788298772647977
Valid Loss:  0.001469387672841549
Epoch:  297  	Training Loss: 0.0016655847430229187
Test Loss:  0.0012788263848051429
Valid Loss:  0.001469380222260952
Epoch:  298  	Training Loss: 0.0016655800864100456
Test Loss:  0.0012788219610229135
Valid Loss:  0.0014693744014948606
Epoch:  299  	Training Loss: 0.0016655742656439543
Test Loss:  0.0012788143940269947
Valid Loss:  0.0014693685807287693
Epoch:  300  	Training Loss: 0.001665568328462541
Test Loss:  0.00127881090156734
Valid Loss:  0.0014693643897771835
Epoch:  301  	Training Loss: 0.0016655628569424152
Test Loss:  0.0012788067106157541
Valid Loss:  0.001469357986934483
Epoch:  302  	Training Loss: 0.0016655571525916457
Test Loss:  0.0012787998421117663
Valid Loss:  0.0014693554257974029
Epoch:  303  	Training Loss: 0.0016655509825795889
Test Loss:  0.001278791343793273
Valid Loss:  0.0014693539123982191
Epoch:  304  	Training Loss: 0.0016655470244586468
Test Loss:  0.0012787878513336182
Valid Loss:  0.0014693415723741055
Epoch:  305  	Training Loss: 0.0016655409708619118
Test Loss:  0.0012787800515070558
Valid Loss:  0.001469336450099945
Epoch:  306  	Training Loss: 0.0016655359650030732
Test Loss:  0.0012787735322490335
Valid Loss:  0.0014693334233015776
Epoch:  307  	Training Loss: 0.0016655295621603727
Test Loss:  0.0012787689920514822
Valid Loss:  0.0014693280681967735
Epoch:  308  	Training Loss: 0.0016655256040394306
Test Loss:  0.0012787634041160345
Valid Loss:  0.0014693191042169929
Epoch:  309  	Training Loss: 0.0016655210638418794
Test Loss:  0.0012787566520273685
Valid Loss:  0.001469314331188798
Epoch:  310  	Training Loss: 0.0016655160579830408
Test Loss:  0.001278746291063726
Valid Loss:  0.0014693092089146376
Epoch:  311  	Training Loss: 0.0016655100043863058
Test Loss:  0.0012787443120032549
Valid Loss:  0.0014693038538098335
Epoch:  312  	Training Loss: 0.0016655029030516744
Test Loss:  0.0012787391897290945
Valid Loss:  0.0014692984987050295
Epoch:  313  	Training Loss: 0.0016654996434226632
Test Loss:  0.0012787377927452326
Valid Loss:  0.0014692918630316854
Epoch:  314  	Training Loss: 0.0016654955688863993
Test Loss:  0.0012787331361323595
Valid Loss:  0.0014692858094349504
Epoch:  315  	Training Loss: 0.0016654916107654572
Test Loss:  0.0012787239393219352
Valid Loss:  0.0014692838303744793
Epoch:  316  	Training Loss: 0.0016654867213219404
Test Loss:  0.001278718002140522
Valid Loss:  0.0014692762633785605
Epoch:  317  	Training Loss: 0.0016654828796163201
Test Loss:  0.0012787115992978215
Valid Loss:  0.0014692749828100204
Epoch:  318  	Training Loss: 0.001665477640926838
Test Loss:  0.0012787057785317302
Valid Loss:  0.001469263806939125
Epoch:  319  	Training Loss: 0.0016654725186526775
Test Loss:  0.0012786989100277424
Valid Loss:  0.0014692607801407576
Epoch:  320  	Training Loss: 0.0016654686769470572
Test Loss:  0.0012786958832293749
Valid Loss:  0.0014692575205117464
Epoch:  321  	Training Loss: 0.0016654623905196786
Test Loss:  0.00127869111020118
Valid Loss:  0.0014692549593746662
Epoch:  322  	Training Loss: 0.001665456802584231
Test Loss:  0.0012786834267899394
Valid Loss:  0.0014692492550238967
Epoch:  323  	Training Loss: 0.0016654543578624725
Test Loss:  0.0012786793522536755
Valid Loss:  0.0014692444819957018
Epoch:  324  	Training Loss: 0.0016654476057738066
Test Loss:  0.001278674229979515
Valid Loss:  0.0014692405238747597
Epoch:  325  	Training Loss: 0.0016654434148222208
Test Loss:  0.0012786691077053547
Valid Loss:  0.0014692355180159211
Epoch:  326  	Training Loss: 0.0016654371283948421
Test Loss:  0.001278658863157034
Valid Loss:  0.0014692277181893587
Epoch:  327  	Training Loss: 0.001665433868765831
Test Loss:  0.0012786537408828735
Valid Loss:  0.0014692249242216349
Epoch:  328  	Training Loss: 0.0016654287464916706
Test Loss:  0.0012786497827619314
Valid Loss:  0.0014692172408103943
Epoch:  329  	Training Loss: 0.0016654250212013721
Test Loss:  0.0012786448933184147
Valid Loss:  0.0014692128170281649
Epoch:  330  	Training Loss: 0.0016654201317578554
Test Loss:  0.0012786411680281162
Valid Loss:  0.0014692125841975212
Epoch:  331  	Training Loss: 0.0016654152423143387
Test Loss:  0.0012786344159394503
Valid Loss:  0.0014692062977701426
Epoch:  332  	Training Loss: 0.0016654098872095346
Test Loss:  0.0012786309234797955
Valid Loss:  0.001469203969463706
Epoch:  333  	Training Loss: 0.0016654066275805235
Test Loss:  0.001278625801205635
Valid Loss:  0.0014691980322822928
Epoch:  334  	Training Loss: 0.0016654008068144321
Test Loss:  0.0012786197476089
Valid Loss:  0.001469191862270236
Epoch:  335  	Training Loss: 0.0016653963830322027
Test Loss:  0.0012786171864718199
Valid Loss:  0.0014691867399960756
Epoch:  336  	Training Loss: 0.0016653905622661114
Test Loss:  0.0012786114821210504
Valid Loss:  0.001469186507165432
Epoch:  337  	Training Loss: 0.0016653871862217784
Test Loss:  0.001278605661354959
Valid Loss:  0.0014691794058308005
Epoch:  338  	Training Loss: 0.0016653835773468018
Test Loss:  0.0012786025181412697
Valid Loss:  0.001469175796955824
Epoch:  339  	Training Loss: 0.001665380084887147
Test Loss:  0.0012785971630364656
Valid Loss:  0.0014691688120365143
Epoch:  340  	Training Loss: 0.001665375311858952
Test Loss:  0.0012785906437784433
Valid Loss:  0.001469162991270423
Epoch:  341  	Training Loss: 0.0016653722850605845
Test Loss:  0.001278584823012352
Valid Loss:  0.001469157519750297
Epoch:  342  	Training Loss: 0.0016653677448630333
Test Loss:  0.0012785778380930424
Valid Loss:  0.0014691564720124006
Epoch:  343  	Training Loss: 0.001665362622588873
Test Loss:  0.0012785778380930424
Valid Loss:  0.0014691523974761367
Epoch:  344  	Training Loss: 0.0016653594793751836
Test Loss:  0.0012785717844963074
Valid Loss:  0.0014691440155729651
 69%|██████▉   | 345/500 [03:59<01:34,  1.63it/s] 69%|██████▉   | 347/500 [03:59<01:08,  2.22it/s] 70%|██████▉   | 349/500 [03:59<00:50,  2.99it/s] 70%|███████   | 351/500 [04:05<02:56,  1.19s/it] 71%|███████   | 353/500 [04:05<02:05,  1.17it/s] 71%|███████   | 355/500 [04:05<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:06<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:06<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:12<02:43,  1.17s/it] 73%|███████▎  | 363/500 [04:12<01:55,  1.18it/s] 73%|███████▎  | 365/500 [04:12<01:22,  1.64it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.24it/s] 74%|███████▍  | 369/500 [04:12<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:19<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:19<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:19<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:19<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:26<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:26<01:38,  1.19it/s] 77%|███████▋  | 385/500 [04:26<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:26<00:50,  2.25it/s] 78%|███████▊  | 389/500 [04:26<00:36,  3.02it/s] 78%|███████▊  | 391/500 [04:32<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:33<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:33<01:03,  1.64it/s] 79%|███████▉  | 397/500 [04:33<00:45,  2.24it/s] 80%|███████▉  | 399/500 [04:33<00:33,  3.02it/s] 80%|████████  | 401/500 [04:39<01:55,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.19it/s] 81%|████████  | 405/500 [04:39<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:40<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:40<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:46<01:44,  1.17s/it]Epoch:  345  	Training Loss: 0.0016653555212542415
Test Loss:  0.001278568059206009
Valid Loss:  0.0014691391261294484
Epoch:  346  	Training Loss: 0.0016653516795486212
Test Loss:  0.001278561307117343
Valid Loss:  0.0014691323740407825
Epoch:  347  	Training Loss: 0.0016653488855808973
Test Loss:  0.001278555253520608
Valid Loss:  0.001469131326302886
Epoch:  348  	Training Loss: 0.001665344461798668
Test Loss:  0.0012785530416294932
Valid Loss:  0.001469125971198082
Epoch:  349  	Training Loss: 0.0016653398051857948
Test Loss:  0.0012785483850166202
Valid Loss:  0.0014691231772303581
Epoch:  350  	Training Loss: 0.0016653359634801745
Test Loss:  0.001278208801522851
Valid Loss:  0.0014692549593746662
Epoch:  351  	Training Loss: 0.0016653345664963126
Test Loss:  0.0012785623548552394
Valid Loss:  0.0014691411051899195
Epoch:  352  	Training Loss: 0.0016653264174237847
Test Loss:  0.0012785601429641247
Valid Loss:  0.0014691341202706099
Epoch:  353  	Training Loss: 0.0016653237398713827
Test Loss:  0.001278552459552884
Valid Loss:  0.0014691231772303581
Epoch:  354  	Training Loss: 0.0016653207130730152
Test Loss:  0.0012785509461537004
Valid Loss:  0.0014691173564642668
Epoch:  355  	Training Loss: 0.0016653171041980386
Test Loss:  0.0012785440776497126
Valid Loss:  0.0014691173564642668
Epoch:  356  	Training Loss: 0.001665310701355338
Test Loss:  0.0012785365106537938
Valid Loss:  0.0014691094402223825
Epoch:  357  	Training Loss: 0.0016653093043714762
Test Loss:  0.001278530340641737
Valid Loss:  0.0014691073447465897
Epoch:  358  	Training Loss: 0.0016653054626658559
Test Loss:  0.0012785254511982203
Valid Loss:  0.0014691002434119582
Epoch:  359  	Training Loss: 0.001665302086621523
Test Loss:  0.0012785225408151746
Valid Loss:  0.0014690929092466831
Epoch:  360  	Training Loss: 0.0016652990598231554
Test Loss:  0.0012785163708031178
Valid Loss:  0.0014690877869725227
Epoch:  361  	Training Loss: 0.001665295916609466
Test Loss:  0.0012785117141902447
Valid Loss:  0.0014690817333757877
Epoch:  362  	Training Loss: 0.001665293239057064
Test Loss:  0.0012785078724846244
Valid Loss:  0.0014690770767629147
Epoch:  363  	Training Loss: 0.0016652895137667656
Test Loss:  0.001278506824746728
Valid Loss:  0.0014690718380734324
Epoch:  364  	Training Loss: 0.0016652857884764671
Test Loss:  0.001278500771149993
Valid Loss:  0.0014690662501379848
Epoch:  365  	Training Loss: 0.0016652815975248814
Test Loss:  0.0012784977443516254
Valid Loss:  0.0014690628740936518
Epoch:  366  	Training Loss: 0.0016652808990329504
Test Loss:  0.0012784923892468214
Valid Loss:  0.0014690631069242954
Epoch:  367  	Training Loss: 0.001665276475250721
Test Loss:  0.0012784902937710285
Valid Loss:  0.0014690547250211239
Epoch:  368  	Training Loss: 0.0016652746126055717
Test Loss:  0.0012784816790372133
Valid Loss:  0.0014690527459606528
Epoch:  369  	Training Loss: 0.001665270421653986
Test Loss:  0.0012784816790372133
Valid Loss:  0.0014690477401018143
Epoch:  370  	Training Loss: 0.001665265648625791
Test Loss:  0.0012784763239324093
Valid Loss:  0.0014690423849970102
Epoch:  371  	Training Loss: 0.0016652626218274236
Test Loss:  0.0012784716673195362
Valid Loss:  0.0014690409880131483
Epoch:  372  	Training Loss: 0.0016652594786137342
Test Loss:  0.0012784663122147322
Valid Loss:  0.0014690329553559422
Epoch:  373  	Training Loss: 0.0016652577323839068
Test Loss:  0.0012784624705091119
Valid Loss:  0.001469029113650322
Epoch:  374  	Training Loss: 0.001665254938416183
Test Loss:  0.001278458395972848
Valid Loss:  0.0014690266689285636
Epoch:  375  	Training Loss: 0.0016652510967105627
Test Loss:  0.0012784572318196297
Valid Loss:  0.0014690218959003687
Epoch:  376  	Training Loss: 0.0016652470221742988
Test Loss:  0.001278449664823711
Valid Loss:  0.0014690166572108865
Epoch:  377  	Training Loss: 0.0016652431804686785
Test Loss:  0.0012784476857632399
Valid Loss:  0.0014690086245536804
Epoch:  378  	Training Loss: 0.0016652413178235292
Test Loss:  0.0012784452410414815
Valid Loss:  0.00146900350227952
Epoch:  379  	Training Loss: 0.001665238058194518
Test Loss:  0.0012784410500898957
Valid Loss:  0.0014690046664327383
Epoch:  380  	Training Loss: 0.0016652361955493689
Test Loss:  0.001278434880077839
Valid Loss:  0.0014689990784972906
Epoch:  381  	Training Loss: 0.0016652308404445648
Test Loss:  0.0012784323189407587
Valid Loss:  0.0014689925592392683
Epoch:  382  	Training Loss: 0.0016652275808155537
Test Loss:  0.0012784269638359547
Valid Loss:  0.0014689902309328318
Epoch:  383  	Training Loss: 0.0016652261838316917
Test Loss:  0.0012784276623278856
Valid Loss:  0.0014689852250739932
Epoch:  384  	Training Loss: 0.0016652236226946115
Test Loss:  0.001278420677408576
Valid Loss:  0.001468981383368373
Epoch:  385  	Training Loss: 0.001665221294388175
Test Loss:  0.001278419978916645
Valid Loss:  0.0014689811505377293
Epoch:  386  	Training Loss: 0.0016652195481583476
Test Loss:  0.0012784169521182775
Valid Loss:  0.0014689774252474308
Epoch:  387  	Training Loss: 0.0016652146587148309
Test Loss:  0.0012784090358763933
Valid Loss:  0.0014689750969409943
Epoch:  388  	Training Loss: 0.0016652113990858197
Test Loss:  0.0012784084537997842
Valid Loss:  0.0014689683448523283
Epoch:  389  	Training Loss: 0.0016652103513479233
Test Loss:  0.0012784067075699568
Valid Loss:  0.0014689674135297537
Epoch:  390  	Training Loss: 0.001665206509642303
Test Loss:  0.001278399839065969
Valid Loss:  0.0014689628733322024
Epoch:  391  	Training Loss: 0.0016652027843520045
Test Loss:  0.0012783986749127507
Valid Loss:  0.0014689606614410877
Epoch:  392  	Training Loss: 0.0016652001067996025
Test Loss:  0.0012783941347151995
Valid Loss:  0.0014689590316265821
Epoch:  393  	Training Loss: 0.001665199175477028
Test Loss:  0.0012783928541466594
Valid Loss:  0.0014689520467072725
Epoch:  394  	Training Loss: 0.0016651955666020513
Test Loss:  0.0012783900601789355
Valid Loss:  0.0014689469244331121
Epoch:  395  	Training Loss: 0.0016651912592351437
Test Loss:  0.0012783852871507406
Valid Loss:  0.001468947622925043
Epoch:  396  	Training Loss: 0.0016651912592351437
Test Loss:  0.0012783822603523731
Valid Loss:  0.001468940288759768
Epoch:  397  	Training Loss: 0.0016651873011142015
Test Loss:  0.0012783778365701437
Valid Loss:  0.0014689366798847914
Epoch:  398  	Training Loss: 0.001665186369791627
Test Loss:  0.001278377021662891
Valid Loss:  0.0014689336530864239
Epoch:  399  	Training Loss: 0.0016651821788400412
Test Loss:  0.001278373529203236
Valid Loss:  0.0014689308591187
Epoch:  400  	Training Loss: 0.0016651805490255356
Test Loss:  0.0012783693382516503
Valid Loss:  0.0014689264353364706
Epoch:  401  	Training Loss: 0.00166517763864249
Test Loss:  0.0012783682905137539
Valid Loss:  0.0014689243398606777
Epoch:  402  	Training Loss: 0.0016651751939207315
Test Loss:  0.001278362120501697
Valid Loss:  0.0014689222443848848
Epoch:  403  	Training Loss: 0.001665173564106226
Test Loss:  0.0012783589772880077
Valid Loss:  0.0014689206145703793
Epoch:  404  	Training Loss: 0.001665168209001422
Test Loss:  0.0012783557176589966
Valid Loss:  0.0014689150266349316
Epoch:  405  	Training Loss: 0.0016651665791869164
Test Loss:  0.0012783561833202839
Valid Loss:  0.0014689143281430006
Epoch:  406  	Training Loss: 0.0016651628538966179
Test Loss:  0.0012783482670783997
Valid Loss:  0.0014689115341752768
Epoch:  407  	Training Loss: 0.0016651609912514687
Test Loss:  0.0012783474521711469
Valid Loss:  0.0014689057134091854
Epoch:  408  	Training Loss: 0.0016651581972837448
Test Loss:  0.001278345356695354
Valid Loss:  0.0014689036179333925
Epoch:  409  	Training Loss: 0.0016651557525619864
Test Loss:  0.0012783382553607225
Valid Loss:  0.0014689017552882433
Epoch:  410  	Training Loss: 0.0016651523765176535
Test Loss:  0.001278335228562355
Valid Loss:  0.0014688954688608646
Epoch:  411  	Training Loss: 0.0016651477199047804
Test Loss:  0.0012783349957317114
Valid Loss:  0.001468893140554428
Epoch:  412  	Training Loss: 0.0016651453915983438
Test Loss:  0.0012783277779817581
Valid Loss:  0.0014688887167721987
Epoch:  413  	Training Loss: 0.0016651437617838383
Test Loss:   83%|████████▎ | 413/500 [04:46<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:46<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:46<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:47<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:53<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.64it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:00<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:00<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:00<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:00<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:07<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:07<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:07<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:07<00:17,  3.00it/s] 90%|█████████ | 451/500 [05:13<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:14<00:13,  3.01it/s] 92%|█████████▏| 461/500 [05:20<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:21<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:27<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:27<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:27<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.17s/it]0.0012783301062881947
Valid Loss:  0.0014688875526189804
Epoch:  414  	Training Loss: 0.0016651405021548271
Test Loss:  0.0012783244019374251
Valid Loss:  0.0014688819646835327
Epoch:  415  	Training Loss: 0.0016651377081871033
Test Loss:  0.0012783247511833906
Valid Loss:  0.0014688801020383835
Epoch:  416  	Training Loss: 0.001665135845541954
Test Loss:  0.0012783192796632648
Valid Loss:  0.001468883128836751
Epoch:  417  	Training Loss: 0.0016651327023282647
Test Loss:  0.0012783152051270008
Valid Loss:  0.0014688775409013033
Epoch:  418  	Training Loss: 0.0016651314217597246
Test Loss:  0.0012783120619133115
Valid Loss:  0.0014688738156110048
Epoch:  419  	Training Loss: 0.0016651280457153916
Test Loss:  0.0012783089186996222
Valid Loss:  0.0014688705559819937
Epoch:  420  	Training Loss: 0.0016651240875944495
Test Loss:  0.001278304262086749
Valid Loss:  0.0014688709052279592
Epoch:  421  	Training Loss: 0.0016651216428726912
Test Loss:  0.0012782986741513014
Valid Loss:  0.001468866365030408
Epoch:  422  	Training Loss: 0.0016651202458888292
Test Loss:  0.0012782975099980831
Valid Loss:  0.001468864269554615
Epoch:  423  	Training Loss: 0.0016651158221065998
Test Loss:  0.0012782913399860263
Valid Loss:  0.0014688600786030293
Epoch:  424  	Training Loss: 0.0016651151236146688
Test Loss:  0.0012782947160303593
Valid Loss:  0.0014688604278489947
Epoch:  425  	Training Loss: 0.0016651113983243704
Test Loss:  0.0012782912235707045
Valid Loss:  0.0014688598457723856
Epoch:  426  	Training Loss: 0.0016651061596348882
Test Loss:  0.0012782898265868425
Valid Loss:  0.0014688509982079268
Epoch:  427  	Training Loss: 0.0016651056939736009
Test Loss:  0.0012782847043126822
Valid Loss:  0.001468852162361145
Epoch:  428  	Training Loss: 0.0016651041805744171
Test Loss:  0.0012782810954377055
Valid Loss:  0.0014688473893329501
Epoch:  429  	Training Loss: 0.0016651020850986242
Test Loss:  0.0012782757403329015
Valid Loss:  0.0014688419178128242
Epoch:  430  	Training Loss: 0.0016650987090542912
Test Loss:  0.0012782743433490396
Valid Loss:  0.0014688394730910659
Epoch:  431  	Training Loss: 0.0016650953330099583
Test Loss:  0.0012782737612724304
Valid Loss:  0.0014688330702483654
Epoch:  432  	Training Loss: 0.0016650930047035217
Test Loss:  0.0012782694539055228
Valid Loss:  0.0014688309747725725
Epoch:  433  	Training Loss: 0.001665087416768074
Test Loss:  0.0012782670091837645
Valid Loss:  0.0014688305091112852
Epoch:  434  	Training Loss: 0.0016650864854454994
Test Loss:  0.0012782624689862132
Valid Loss:  0.0014688288792967796
Epoch:  435  	Training Loss: 0.0016650829929858446
Test Loss:  0.0012782589765265584
Valid Loss:  0.0014688223600387573
Epoch:  436  	Training Loss: 0.001665081363171339
Test Loss:  0.0012782562989741564
Valid Loss:  0.001468822592869401
Epoch:  437  	Training Loss: 0.0016650788020342588
Test Loss:  0.0012782568810507655
Valid Loss:  0.001468820497393608
Epoch:  438  	Training Loss: 0.001665077405050397
Test Loss:  0.0012782500125467777
Valid Loss:  0.001468819915316999
Epoch:  439  	Training Loss: 0.0016650727484375238
Test Loss:  0.001278252457268536
Valid Loss:  0.001468813163228333
Epoch:  440  	Training Loss: 0.0016650701873004436
Test Loss:  0.0012782441917806864
Valid Loss:  0.0014688114169985056
Epoch:  441  	Training Loss: 0.0016650668112561107
Test Loss:  0.0012782440753653646
Valid Loss:  0.0014688067603856325
Epoch:  442  	Training Loss: 0.0016650636680424213
Test Loss:  0.0012782381381839514
Valid Loss:  0.0014688055962324142
Epoch:  443  	Training Loss: 0.0016650615725666285
Test Loss:  0.0012782393023371696
Valid Loss:  0.0014688039664179087
Epoch:  444  	Training Loss: 0.0016650590114295483
Test Loss:  0.001278238371014595
Valid Loss:  0.0014688008232042193
Epoch:  445  	Training Loss: 0.0016650567995384336
Test Loss:  0.0012782312696799636
Valid Loss:  0.0014687948860228062
Epoch:  446  	Training Loss: 0.0016650543548166752
Test Loss:  0.0012782290577888489
Valid Loss:  0.0014687897637486458
Epoch:  447  	Training Loss: 0.0016650499310344458
Test Loss:  0.001278223586268723
Valid Loss:  0.001468787668272853
Epoch:  448  	Training Loss: 0.0016650480683892965
Test Loss:  0.0012782220728695393
Valid Loss:  0.001468787668272853
Epoch:  449  	Training Loss: 0.001665043644607067
Test Loss:  0.0012782190460711718
Valid Loss:  0.00146878429222852
Epoch:  450  	Training Loss: 0.0016650413163006306
Test Loss:  0.0012782185804098845
Valid Loss:  0.001468779519200325
Epoch:  451  	Training Loss: 0.0016650405013933778
Test Loss:  0.001278214855119586
Valid Loss:  0.0014687792863696814
Epoch:  452  	Training Loss: 0.0016650372417643666
Test Loss:  0.0012782122939825058
Valid Loss:  0.0014687767252326012
Epoch:  453  	Training Loss: 0.0016650347970426083
Test Loss:  0.0012782090343534946
Valid Loss:  0.0014687739312648773
Epoch:  454  	Training Loss: 0.0016650321194902062
Test Loss:  0.0012782050762325525
Valid Loss:  0.001468767412006855
Epoch:  455  	Training Loss: 0.0016650296747684479
Test Loss:  0.0012781999539583921
Valid Loss:  0.0014687671791762114
Epoch:  456  	Training Loss: 0.0016650258330628276
Test Loss:  0.0012781964614987373
Valid Loss:  0.0014687622897326946
Epoch:  457  	Training Loss: 0.0016650233883410692
Test Loss:  0.0012781932018697262
Valid Loss:  0.0014687619404867291
Epoch:  458  	Training Loss: 0.001665022224187851
Test Loss:  0.0012781918048858643
Valid Loss:  0.0014687614748254418
Epoch:  459  	Training Loss: 0.0016650191973894835
Test Loss:  0.0012781878467649221
Valid Loss:  0.0014687555376440287
Epoch:  460  	Training Loss: 0.0016650150064378977
Test Loss:  0.001278187963180244
Valid Loss:  0.0014687529765069485
Epoch:  461  	Training Loss: 0.0016650125617161393
Test Loss:  0.0012781841214746237
Valid Loss:  0.0014687490183860064
Epoch:  462  	Training Loss: 0.0016650096513330936
Test Loss:  0.0012781857512891293
Valid Loss:  0.001468744594603777
Epoch:  463  	Training Loss: 0.001665008021518588
Test Loss:  0.001278182491660118
Valid Loss:  0.0014687408693134785
Epoch:  464  	Training Loss: 0.0016650051111355424
Test Loss:  0.0012781784171238542
Valid Loss:  0.0014687394723296165
Epoch:  465  	Training Loss: 0.0016650025499984622
Test Loss:  0.0012781766708940268
Valid Loss:  0.0014687355142086744
Epoch:  466  	Training Loss: 0.0016650022007524967
Test Loss:  0.001278175157494843
Valid Loss:  0.0014687355142086744
Epoch:  467  	Training Loss: 0.0016649974277243018
Test Loss:  0.001278173178434372
Valid Loss:  0.0014687312068417668
Epoch:  468  	Training Loss: 0.0016649950994178653
Test Loss:  0.0012781692203134298
Valid Loss:  0.0014687252696603537
Epoch:  469  	Training Loss: 0.0016649930039420724
Test Loss:  0.0012781694531440735
Valid Loss:  0.0014687244547531009
Epoch:  470  	Training Loss: 0.001664991956204176
Test Loss:  0.001278165029361844
Valid Loss:  0.0014687238726764917
Epoch:  471  	Training Loss: 0.0016649877652525902
Test Loss:  0.0012781620025634766
Valid Loss:  0.0014687197981402278
Epoch:  472  	Training Loss: 0.0016649842727929354
Test Loss:  0.0012781618861481547
Valid Loss:  0.0014687165385112166
Epoch:  473  	Training Loss: 0.0016649822937324643
Test Loss:  0.0012781592085957527
Valid Loss:  0.0014687137445434928
Epoch:  474  	Training Loss: 0.0016649810131639242
Test Loss:  0.0012781568802893162
Valid Loss:  0.001468712231144309
Epoch:  475  	Training Loss: 0.0016649772878736258
Test Loss:  0.0012781568802893162
Valid Loss:  0.0014687096700072289
Epoch:  476  	Training Loss: 0.001664974493905902
Test Loss:  0.0012781510595232248
Valid Loss:  0.001468704896979034
Epoch:  477  	Training Loss: 0.0016649727476760745
Test Loss:  0.0012781484983861446
Valid Loss:  0.0014687011716887355
Epoch:  478  	Training Loss: 0.0016649701865389943
Test Loss:  0.0012781494297087193
Valid Loss:  0.0014686963986605406
Epoch:  479  	Training Loss: 0.0016649658791720867
Test Loss:  0.0012781466357409954
Valid Loss:  0.0014686946524307132
Epoch:  480  	Training Loss: 0.0016649658791720867
Test Loss:  0.0012781440746039152
Valid Loss:  0.0014686943031847477
Epoch:  481  	Training Loss: 0.0016649639001116157
Test Loss:  0.001278141513466835
Valid Loss:  0.0014686884824186563
 97%|█████████▋| 483/500 [05:34<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:34<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.19s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.17it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.62it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.21it/s]100%|█████████▉| 499/500 [05:41<00:00,  2.97it/s]100%|██████████| 500/500 [05:41<00:00,  1.46it/s]
Epoch:  482  	Training Loss: 0.0016649594763293862
Test Loss:  0.0012781377881765366
Valid Loss:  0.0014686876675114036
Epoch:  483  	Training Loss: 0.0016649573808535933
Test Loss:  0.0012781354598701
Valid Loss:  0.0014686838258057833
Epoch:  484  	Training Loss: 0.0016649564495310187
Test Loss:  0.0012781326659023762
Valid Loss:  0.0014686823124065995
Epoch:  485  	Training Loss: 0.0016649540048092604
Test Loss:  0.001278134062886238
Valid Loss:  0.0014686817303299904
Epoch:  486  	Training Loss: 0.0016649519093334675
Test Loss:  0.0012781346449628472
Valid Loss:  0.0014686789363622665
Epoch:  487  	Training Loss: 0.0016649479512125254
Test Loss:  0.0012781291734427214
Valid Loss:  0.0014686745125800371
Epoch:  488  	Training Loss: 0.0016649465542286634
Test Loss:  0.0012781268451362848
Valid Loss:  0.0014686726499348879
Epoch:  489  	Training Loss: 0.0016649439930915833
Test Loss:  0.0012781249824911356
Valid Loss:  0.0014686735812574625
Epoch:  490  	Training Loss: 0.0016649418976157904
Test Loss:  0.0012781224213540554
Valid Loss:  0.0014686710201203823
Epoch:  491  	Training Loss: 0.0016649409662932158
Test Loss:  0.0012781241675838828
Valid Loss:  0.0014686668291687965
Epoch:  492  	Training Loss: 0.0016649379394948483
Test Loss:  0.0012781155528500676
Valid Loss:  0.0014686635695397854
Epoch:  493  	Training Loss: 0.0016649357276037335
Test Loss:  0.001278117299079895
Valid Loss:  0.0014686607755720615
Epoch:  494  	Training Loss: 0.0016649337485432625
Test Loss:  0.0012781138066202402
Valid Loss:  0.0014686589129269123
Epoch:  495  	Training Loss: 0.0016649332828819752
Test Loss:  0.0012781094992533326
Valid Loss:  0.0014686556532979012
Epoch:  496  	Training Loss: 0.0016649304889142513
Test Loss:  0.0012781070545315742
Valid Loss:  0.0014686558861285448
Epoch:  497  	Training Loss: 0.0016649272292852402
Test Loss:  0.0012781061232089996
Valid Loss:  0.0014686547219753265
Epoch:  498  	Training Loss: 0.001664925366640091
Test Loss:  0.0012781060067936778
Valid Loss:  0.0014686512295156717
Epoch:  499  	Training Loss: 0.00166492466814816
Test Loss:  0.0012781026307493448
Valid Loss:  0.001468647737056017
Epoch:  500  	Training Loss: 0.0016649228055030107
Test Loss:  0.0012780979741364717
Valid Loss:  0.0014686484355479479
seed is  14
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:01,  6.26s/it]  1%|          | 3/500 [00:06<13:52,  1.67s/it]  1%|          | 5/500 [00:06<06:59,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:49,  2.89it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:40,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:31,  1.19s/it]  5%|▍         | 23/500 [00:20<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.24it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:10,  1.17s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:26<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.25it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:59,  1.18s/it]  9%|▊         | 43/500 [00:33<06:25,  1.18it/s]  9%|▉         | 45/500 [00:33<04:38,  1.64it/s]  9%|▉         | 47/500 [00:33<03:22,  2.23it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:46,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:26,  3.01it/s] 12%|█▏        | 61/500 [00:47<08:29,  1.16s/it] 13%|█▎        | 63/500 [00:47<06:04,  1.20it/s] 13%|█▎        | 65/500 [00:47<04:22,  1.66it/s] 13%|█▎        | 67/500 [00:47<03:11,  2.26it/s] 14%|█▍        | 69/500 [00:47<02:21,  3.04it/s]Epoch:  1  	Training Loss: 0.2827312648296356
Test Loss:  0.1170479953289032
Valid Loss:  0.11895665526390076
Epoch:  2  	Training Loss: 0.12102760374546051
Test Loss:  0.07610416412353516
Valid Loss:  0.07912138849496841
Epoch:  3  	Training Loss: 0.08020006120204926
Test Loss:  0.05240624397993088
Valid Loss:  0.05621236935257912
Epoch:  4  	Training Loss: 0.05652841925621033
Test Loss:  0.03892972320318222
Valid Loss:  0.0431588813662529
Epoch:  5  	Training Loss: 0.04292689263820648
Test Loss:  0.031089331954717636
Valid Loss:  0.03550082445144653
Epoch:  6  	Training Loss: 0.0348895862698555
Test Loss:  0.02638261392712593
Valid Loss:  0.030863646417856216
Epoch:  7  	Training Loss: 0.029981359839439392
Test Loss:  0.02339407056570053
Valid Loss:  0.027878841385245323
Epoch:  8  	Training Loss: 0.02680829167366028
Test Loss:  0.021408595144748688
Valid Loss:  0.025813322514295578
Epoch:  9  	Training Loss: 0.024636346846818924
Test Loss:  0.020025625824928284
Valid Loss:  0.02432066574692726
Epoch:  10  	Training Loss: 0.02307683601975441
Test Loss:  0.01898660883307457
Valid Loss:  0.02315857633948326
Epoch:  11  	Training Loss: 0.021894268691539764
Test Loss:  0.0181675273925066
Valid Loss:  0.022231081500649452
Epoch:  12  	Training Loss: 0.02095315046608448
Test Loss:  0.017077608034014702
Valid Loss:  0.02097015455365181
Epoch:  13  	Training Loss: 0.019680431112647057
Test Loss:  0.016215654090046883
Valid Loss:  0.019949153065681458
Epoch:  14  	Training Loss: 0.01865924894809723
Test Loss:  0.015480226837098598
Valid Loss:  0.019052989780902863
Epoch:  15  	Training Loss: 0.017769858241081238
Test Loss:  0.014688713476061821
Valid Loss:  0.018062055110931396
Epoch:  16  	Training Loss: 0.016823243349790573
Test Loss:  0.013799812644720078
Valid Loss:  0.017015516757965088
Epoch:  17  	Training Loss: 0.015817677602171898
Test Loss:  0.012973583303391933
Valid Loss:  0.01601487770676613
Epoch:  18  	Training Loss: 0.014872160740196705
Test Loss:  0.012308257631957531
Valid Loss:  0.01517832837998867
Epoch:  19  	Training Loss: 0.014097150415182114
Test Loss:  0.011754565872251987
Valid Loss:  0.014482644386589527
Epoch:  20  	Training Loss: 0.0134538933634758
Test Loss:  0.011264126747846603
Valid Loss:  0.013866323977708817
Epoch:  21  	Training Loss: 0.012879674322903156
Test Loss:  0.010803241282701492
Valid Loss:  0.013286628760397434
Epoch:  22  	Training Loss: 0.012341574765741825
Test Loss:  0.010062333196401596
Valid Loss:  0.012399358674883842
Epoch:  23  	Training Loss: 0.011479329317808151
Test Loss:  0.009488383308053017
Valid Loss:  0.01170850545167923
Epoch:  24  	Training Loss: 0.01081660483032465
Test Loss:  0.008987002074718475
Valid Loss:  0.011086665093898773
Epoch:  25  	Training Loss: 0.010234067216515541
Test Loss:  0.008547171950340271
Valid Loss:  0.010538501664996147
Epoch:  26  	Training Loss: 0.009725693613290787
Test Loss:  0.008156107738614082
Valid Loss:  0.01004820317029953
Epoch:  27  	Training Loss: 0.009272225201129913
Test Loss:  0.007794418837875128
Valid Loss:  0.009598497301340103
Epoch:  28  	Training Loss: 0.00885231327265501
Test Loss:  0.00745704211294651
Valid Loss:  0.009179165586829185
Epoch:  29  	Training Loss: 0.008460082113742828
Test Loss:  0.0071408809162676334
Valid Loss:  0.008786438032984734
Epoch:  30  	Training Loss: 0.008094280026853085
Test Loss:  0.006841929629445076
Valid Loss:  0.008415421470999718
Epoch:  31  	Training Loss: 0.00775050837546587
Test Loss:  0.00655877823010087
Valid Loss:  0.008063913322985172
Epoch:  32  	Training Loss: 0.007426047697663307
Test Loss:  0.006035856902599335
Valid Loss:  0.0073555572889745235
Epoch:  33  	Training Loss: 0.006827962584793568
Test Loss:  0.0056227524764835835
Valid Loss:  0.006810210645198822
Epoch:  34  	Training Loss: 0.006354409269988537
Test Loss:  0.005279115401208401
Valid Loss:  0.006383298430591822
Epoch:  35  	Training Loss: 0.005962939001619816
Test Loss:  0.005010683089494705
Valid Loss:  0.006037258543074131
Epoch:  36  	Training Loss: 0.0056454334408044815
Test Loss:  0.004793099593371153
Valid Loss:  0.005759963765740395
Epoch:  37  	Training Loss: 0.0053935241885483265
Test Loss:  0.004605771973729134
Valid Loss:  0.005526130087673664
Epoch:  38  	Training Loss: 0.005179206840693951
Test Loss:  0.004435245878994465
Valid Loss:  0.00531516969203949
Epoch:  39  	Training Loss: 0.004984848201274872
Test Loss:  0.004275184124708176
Valid Loss:  0.005117916967719793
Epoch:  40  	Training Loss: 0.0048027653247118
Test Loss:  0.00412438390776515
Valid Loss:  0.004933953285217285
Epoch:  41  	Training Loss: 0.004631789866834879
Test Loss:  0.003982297144830227
Valid Loss:  0.0047593736089766026
Epoch:  42  	Training Loss: 0.004470860585570335
Test Loss:  0.003834415227174759
Valid Loss:  0.004595834296196699
Epoch:  43  	Training Loss: 0.004313766956329346
Test Loss:  0.0037046237848699093
Valid Loss:  0.004447070881724358
Epoch:  44  	Training Loss: 0.004173649474978447
Test Loss:  0.003588245250284672
Valid Loss:  0.00431059580296278
Epoch:  45  	Training Loss: 0.004047184716910124
Test Loss:  0.003482327563688159
Valid Loss:  0.0041843559592962265
Epoch:  46  	Training Loss: 0.003930661827325821
Test Loss:  0.0033829559106379747
Valid Loss:  0.004066896624863148
Epoch:  47  	Training Loss: 0.0038203191943466663
Test Loss:  0.0032893018797039986
Valid Loss:  0.003954942803829908
Epoch:  48  	Training Loss: 0.00371533608995378
Test Loss:  0.003200285602360964
Valid Loss:  0.0038478649221360683
Epoch:  49  	Training Loss: 0.0036154536064714193
Test Loss:  0.003115901257842779
Valid Loss:  0.0037457917351275682
Epoch:  50  	Training Loss: 0.003520687809213996
Test Loss:  0.00303565408103168
Valid Loss:  0.0036482419818639755
Epoch:  51  	Training Loss: 0.003430483862757683
Test Loss:  0.002959073521196842
Valid Loss:  0.0035548005253076553
Epoch:  52  	Training Loss: 0.003344255033880472
Test Loss:  0.0027924543246626854
Valid Loss:  0.0033713604789227247
Epoch:  53  	Training Loss: 0.0031661861576139927
Test Loss:  0.0026492103934288025
Valid Loss:  0.0032079294323921204
Epoch:  54  	Training Loss: 0.0030112641397863626
Test Loss:  0.0025267177261412144
Valid Loss:  0.0030620102770626545
Epoch:  55  	Training Loss: 0.002876626094803214
Test Loss:  0.002420146018266678
Valid Loss:  0.0029329354874789715
Epoch:  56  	Training Loss: 0.002759327879175544
Test Loss:  0.002324868692085147
Valid Loss:  0.0028174365870654583
Epoch:  57  	Training Loss: 0.0026543280109763145
Test Loss:  0.0022378142457455397
Valid Loss:  0.0027122749015688896
Epoch:  58  	Training Loss: 0.002558964304625988
Test Loss:  0.002157325856387615
Valid Loss:  0.0026143635623157024
Epoch:  59  	Training Loss: 0.0024710558354854584
Test Loss:  0.0020826878026127815
Valid Loss:  0.002523472998291254
Epoch:  60  	Training Loss: 0.002389593981206417
Test Loss:  0.002013181336224079
Valid Loss:  0.0024381112307310104
Epoch:  61  	Training Loss: 0.0023137954995036125
Test Loss:  0.001948306686244905
Valid Loss:  0.0023584808222949505
Epoch:  62  	Training Loss: 0.0022432743571698666
Test Loss:  0.0018657931359484792
Valid Loss:  0.0022263149730861187
Epoch:  63  	Training Loss: 0.002136407420039177
Test Loss:  0.001801839331164956
Valid Loss:  0.0021405189763754606
Epoch:  64  	Training Loss: 0.002062224317342043
Test Loss:  0.0017408492276445031
Valid Loss:  0.002061803825199604
Epoch:  65  	Training Loss: 0.0019931441638618708
Test Loss:  0.0016826506471261382
Valid Loss:  0.001988575793802738
Epoch:  66  	Training Loss: 0.001928397105075419
Test Loss:  0.0016275618690997362
Valid Loss:  0.0019203119445592165
Epoch:  67  	Training Loss: 0.0018675402970984578
Test Loss:  0.0015748089645057917
Valid Loss:  0.001856160699389875
Epoch:  68  	Training Loss: 0.0018097794381901622
Test Loss:  0.0015246886759996414
Valid Loss:  0.0017956956289708614
Epoch:  69  	Training Loss: 0.001755076926201582
Test Loss:  0.001477533020079136
Valid Loss:  0.0017388309352099895
Epoch:  70  	Training Loss: 0.0017032206524163485
Test Loss:  0.0014327947283163667
Valid Loss:  0.0016853988636285067
Epoch:  71  	Training Loss: 0.001654024817980826
Test Loss:   14%|█▍        | 71/500 [00:53<08:18,  1.16s/it] 15%|█▍        | 73/500 [00:53<05:56,  1.20it/s] 15%|█▌        | 75/500 [00:54<04:16,  1.66it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.26it/s] 16%|█▌        | 79/500 [00:54<02:18,  3.03it/s] 16%|█▌        | 81/500 [01:00<08:11,  1.17s/it] 17%|█▋        | 83/500 [01:00<05:51,  1.19it/s] 17%|█▋        | 85/500 [01:00<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.01it/s] 18%|█▊        | 91/500 [01:07<08:06,  1.19s/it] 19%|█▊        | 93/500 [01:07<05:47,  1.17it/s] 19%|█▉        | 95/500 [01:07<04:10,  1.62it/s] 19%|█▉        | 97/500 [01:07<03:02,  2.21it/s] 20%|█▉        | 99/500 [01:08<02:15,  2.97it/s] 20%|██        | 101/500 [01:14<07:54,  1.19s/it] 21%|██        | 103/500 [01:14<05:39,  1.17it/s] 21%|██        | 105/500 [01:14<04:04,  1.62it/s] 21%|██▏       | 107/500 [01:14<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:14<02:11,  2.97it/s] 22%|██▏       | 111/500 [01:21<07:30,  1.16s/it] 23%|██▎       | 113/500 [01:21<05:23,  1.20it/s] 23%|██▎       | 115/500 [01:21<03:52,  1.65it/s] 23%|██▎       | 117/500 [01:21<02:49,  2.26it/s] 24%|██▍       | 119/500 [01:21<02:05,  3.04it/s] 24%|██▍       | 121/500 [01:27<07:25,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:18,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:49,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:28<02:03,  2.99it/s] 26%|██▌       | 131/500 [01:34<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:34<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:41,  2.24it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.01it/s]0.0013903636718168855
Valid Loss:  0.0016349374782294035
Epoch:  72  	Training Loss: 0.0016073412261903286
Test Loss:  0.0013368772342801094
Valid Loss:  0.0015643053920939565
Epoch:  73  	Training Loss: 0.0015459191054105759
Test Loss:  0.0012964328052476048
Valid Loss:  0.0015157763846218586
Epoch:  74  	Training Loss: 0.0015029635978862643
Test Loss:  0.0012614903971552849
Valid Loss:  0.0014744242653250694
Epoch:  75  	Training Loss: 0.0014659337466582656
Test Loss:  0.001229188870638609
Valid Loss:  0.0014369485434144735
Epoch:  76  	Training Loss: 0.0014320961199700832
Test Loss:  0.0011991544160991907
Valid Loss:  0.0014027892611920834
Epoch:  77  	Training Loss: 0.0014006579294800758
Test Loss:  0.0011715430300682783
Valid Loss:  0.0013709088088944554
Epoch:  78  	Training Loss: 0.0013715310487896204
Test Loss:  0.0011458947556093335
Valid Loss:  0.0013414431596174836
Epoch:  79  	Training Loss: 0.0013445563381537795
Test Loss:  0.0011216611601412296
Valid Loss:  0.0013138898648321629
Epoch:  80  	Training Loss: 0.001319283852353692
Test Loss:  0.0010989569127559662
Valid Loss:  0.0012877779081463814
Epoch:  81  	Training Loss: 0.0012954489793628454
Test Loss:  0.001077599241398275
Valid Loss:  0.0012632126454263926
Epoch:  82  	Training Loss: 0.0012729852460324764
Test Loss:  0.0010471363784745336
Valid Loss:  0.0012340934481471777
Epoch:  83  	Training Loss: 0.0012431202922016382
Test Loss:  0.0010198811069130898
Valid Loss:  0.0012060763547196984
Epoch:  84  	Training Loss: 0.0012151931878179312
Test Loss:  0.0009949158411473036
Valid Loss:  0.0011792308650910854
Epoch:  85  	Training Loss: 0.001188824069686234
Test Loss:  0.0009718418004922569
Valid Loss:  0.0011536034289747477
Epoch:  86  	Training Loss: 0.001163923880085349
Test Loss:  0.0009501117747277021
Valid Loss:  0.0011289335088804364
Epoch:  87  	Training Loss: 0.0011401614174246788
Test Loss:  0.000929677567910403
Valid Loss:  0.0011053041089326143
Epoch:  88  	Training Loss: 0.0011175412219017744
Test Loss:  0.0009103122865781188
Valid Loss:  0.0010826949728652835
Epoch:  89  	Training Loss: 0.0010960579384118319
Test Loss:  0.0008919445099309087
Valid Loss:  0.0010610530152916908
Epoch:  90  	Training Loss: 0.0010756654664874077
Test Loss:  0.0008736955933272839
Valid Loss:  0.0010396247962489724
Epoch:  91  	Training Loss: 0.0010554819600656629
Test Loss:  0.0008552540093660355
Valid Loss:  0.0010184149723500013
Epoch:  92  	Training Loss: 0.0010349175427109003
Test Loss:  0.0008450915338471532
Valid Loss:  0.001005837693810463
Epoch:  93  	Training Loss: 0.001022501615807414
Test Loss:  0.0008356712060049176
Valid Loss:  0.0009940678719431162
Epoch:  94  	Training Loss: 0.0010111219016835093
Test Loss:  0.0008268452947959304
Valid Loss:  0.0009830961935222149
Epoch:  95  	Training Loss: 0.001000446965917945
Test Loss:  0.0008183098398149014
Valid Loss:  0.000973057234659791
Epoch:  96  	Training Loss: 0.0009904996259137988
Test Loss:  0.0008100796258077025
Valid Loss:  0.0009635982569307089
Epoch:  97  	Training Loss: 0.0009810769697651267
Test Loss:  0.00080217479262501
Valid Loss:  0.0009543312480673194
Epoch:  98  	Training Loss: 0.0009720133966766298
Test Loss:  0.0007946882396936417
Valid Loss:  0.0009456737316213548
Epoch:  99  	Training Loss: 0.0009635627502575517
Test Loss:  0.0007874320144765079
Valid Loss:  0.0009373765205964446
Epoch:  100  	Training Loss: 0.0009554132120683789
Test Loss:  0.0007805291679687798
Valid Loss:  0.0009294613264501095
Epoch:  101  	Training Loss: 0.0009474637336097658
Test Loss:  0.0007737017003819346
Valid Loss:  0.0009217563783749938
Epoch:  102  	Training Loss: 0.0009396419627591968
Test Loss:  0.0007559153600595891
Valid Loss:  0.0009062705794349313
Epoch:  103  	Training Loss: 0.0009229228598996997
Test Loss:  0.0007407217053696513
Valid Loss:  0.0008920329855754972
Epoch:  104  	Training Loss: 0.0009081707103177905
Test Loss:  0.0007279179990291595
Valid Loss:  0.0008790689753368497
Epoch:  105  	Training Loss: 0.0008951348718255758
Test Loss:  0.000716811278834939
Valid Loss:  0.0008672142866998911
Epoch:  106  	Training Loss: 0.0008834675536490977
Test Loss:  0.0007069777348078787
Valid Loss:  0.000856339989695698
Epoch:  107  	Training Loss: 0.0008730092085897923
Test Loss:  0.0006978450110182166
Valid Loss:  0.0008461200632154942
Epoch:  108  	Training Loss: 0.0008632753160782158
Test Loss:  0.0006892611854709685
Valid Loss:  0.0008364107925444841
Epoch:  109  	Training Loss: 0.0008540871203877032
Test Loss:  0.0006812557112425566
Valid Loss:  0.0008271100232377648
Epoch:  110  	Training Loss: 0.0008453335030935705
Test Loss:  0.000673667702358216
Valid Loss:  0.0008183310274034739
Epoch:  111  	Training Loss: 0.0008370899595320225
Test Loss:  0.0006663745152764022
Valid Loss:  0.0008099921979010105
Epoch:  112  	Training Loss: 0.0008292670827358961
Test Loss:  0.0006550406105816364
Valid Loss:  0.0007885138620622456
Epoch:  113  	Training Loss: 0.0008116881363093853
Test Loss:  0.0006487017963081598
Valid Loss:  0.000778556801378727
Epoch:  114  	Training Loss: 0.0008034870261326432
Test Loss:  0.0006423924351111054
Valid Loss:  0.000770126935094595
Epoch:  115  	Training Loss: 0.0007962110685184598
Test Loss:  0.0006362035637721419
Valid Loss:  0.0007625187281519175
Epoch:  116  	Training Loss: 0.0007895610760897398
Test Loss:  0.0006302078836597502
Valid Loss:  0.0007555272895842791
Epoch:  117  	Training Loss: 0.0007833534036763012
Test Loss:  0.0006245148833841085
Valid Loss:  0.0007489905692636967
Epoch:  118  	Training Loss: 0.0007774647092446685
Test Loss:  0.0006191064603626728
Valid Loss:  0.000742885866202414
Epoch:  119  	Training Loss: 0.0007718876004219055
Test Loss:  0.0006141562480479479
Valid Loss:  0.0007370910607278347
Epoch:  120  	Training Loss: 0.0007666313322260976
Test Loss:  0.000609338516369462
Valid Loss:  0.0007316216360777617
Epoch:  121  	Training Loss: 0.0007616009097546339
Test Loss:  0.0006047243368811905
Valid Loss:  0.0007264185696840286
Epoch:  122  	Training Loss: 0.0007567369611933827
Test Loss:  0.0005989593919366598
Valid Loss:  0.0007183319539763033
Epoch:  123  	Training Loss: 0.0007490245625376701
Test Loss:  0.0005931923515163362
Valid Loss:  0.0007110286969691515
Epoch:  124  	Training Loss: 0.0007419248577207327
Test Loss:  0.0005873761256225407
Valid Loss:  0.0007041037897579372
Epoch:  125  	Training Loss: 0.0007351877866312861
Test Loss:  0.0005817067576572299
Valid Loss:  0.0006975488504394889
Epoch:  126  	Training Loss: 0.0007287943735718727
Test Loss:  0.0005763017106801271
Valid Loss:  0.000691241875756532
Epoch:  127  	Training Loss: 0.0007226556772366166
Test Loss:  0.0005711746634915471
Valid Loss:  0.0006852550432085991
Epoch:  128  	Training Loss: 0.0007168898591771722
Test Loss:  0.0005661913892254233
Valid Loss:  0.0006795597728341818
Epoch:  129  	Training Loss: 0.0007114562322385609
Test Loss:  0.00056144327390939
Valid Loss:  0.0006741088582202792
Epoch:  130  	Training Loss: 0.0007063116645440459
Test Loss:  0.0005570098292082548
Valid Loss:  0.0006689471192657948
Epoch:  131  	Training Loss: 0.0007015555165708065
Test Loss:  0.0005525865126401186
Valid Loss:  0.0006642069201916456
Epoch:  132  	Training Loss: 0.0006971186958253384
Test Loss:  0.0005470110336318612
Valid Loss:  0.0006590657867491245
Epoch:  133  	Training Loss: 0.0006917707505635917
Test Loss:  0.0005419758381322026
Valid Loss:  0.0006540382746607065
Epoch:  134  	Training Loss: 0.0006866216426715255
Test Loss:  0.0005373921594582498
Valid Loss:  0.000649143592454493
Epoch:  135  	Training Loss: 0.0006817178800702095
Test Loss:  0.0005331890424713492
Valid Loss:  0.0006445011822506785
Epoch:  136  	Training Loss: 0.0006770820473320782
Test Loss:  0.0005291836569085717
Valid Loss:  0.0006400434649549425
Epoch:  137  	Training Loss: 0.0006726158317178488
Test Loss:  0.0005252768751233816
Valid Loss:  0.0006358656100928783
Epoch:  138  	Training Loss: 0.0006683665560558438
Test Loss:  0.0005215090932324529
Valid Loss:  0.0006317433435469866
Epoch:  139  	Training Loss: 0.0006642498192377388
Test Loss:  0.0005177980638109148
Valid Loss:  0.0006278343498706818
 28%|██▊       | 141/500 [01:41<06:57,  1.16s/it] 29%|██▊       | 143/500 [01:41<04:58,  1.20it/s] 29%|██▉       | 145/500 [01:41<03:34,  1.65it/s] 29%|██▉       | 147/500 [01:41<02:36,  2.26it/s] 30%|██▉       | 149/500 [01:42<01:55,  3.04it/s] 30%|███       | 151/500 [01:48<06:45,  1.16s/it] 31%|███       | 153/500 [01:48<04:49,  1.20it/s] 31%|███       | 155/500 [01:48<03:28,  1.66it/s] 31%|███▏      | 157/500 [01:48<02:31,  2.26it/s] 32%|███▏      | 159/500 [01:48<01:52,  3.04it/s] 32%|███▏      | 161/500 [01:55<06:40,  1.18s/it] 33%|███▎      | 163/500 [01:55<04:45,  1.18it/s] 33%|███▎      | 165/500 [01:55<03:25,  1.63it/s] 33%|███▎      | 167/500 [01:55<02:29,  2.23it/s] 34%|███▍      | 169/500 [01:55<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:01<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:47,  3.00it/s] 36%|███▌      | 181/500 [02:08<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:08<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:15<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:15<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:15<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:16<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:16<01:41,  2.98it/s] 40%|████      | 201/500 [02:22<05:49,  1.17s/it] 41%|████      | 203/500 [02:22<04:09,  1.19it/s] 41%|████      | 205/500 [02:22<02:59,  1.65it/s] 41%|████▏     | 207/500 [02:22<02:10,  2.25it/s]Epoch:  140  	Training Loss: 0.0006602939683943987
Test Loss:  0.0005142597947269678
Valid Loss:  0.0006239997455850244
Epoch:  141  	Training Loss: 0.0006564171053469181
Test Loss:  0.0005109378835186362
Valid Loss:  0.0006201443029567599
Epoch:  142  	Training Loss: 0.0006526017095893621
Test Loss:  0.0005072918720543385
Valid Loss:  0.0006165357772260904
Epoch:  143  	Training Loss: 0.000648881308734417
Test Loss:  0.0005038372473791242
Valid Loss:  0.0006130050169304013
Epoch:  144  	Training Loss: 0.0006452570087276399
Test Loss:  0.0005005430430173874
Valid Loss:  0.000609538983553648
Epoch:  145  	Training Loss: 0.0006416891701519489
Test Loss:  0.0004974041366949677
Valid Loss:  0.0006061475723981857
Epoch:  146  	Training Loss: 0.0006381861167028546
Test Loss:  0.0004943626699969172
Valid Loss:  0.0006028118077665567
Epoch:  147  	Training Loss: 0.0006347773014567792
Test Loss:  0.0004913934390060604
Valid Loss:  0.0005996036343276501
Epoch:  148  	Training Loss: 0.0006314788479357958
Test Loss:  0.0004885030211880803
Valid Loss:  0.0005964726442471147
Epoch:  149  	Training Loss: 0.0006282691610977054
Test Loss:  0.0004856562300119549
Valid Loss:  0.0005933876382187009
Epoch:  150  	Training Loss: 0.0006251052254810929
Test Loss:  0.00048297300236299634
Valid Loss:  0.000590328243561089
Epoch:  151  	Training Loss: 0.0006220185896381736
Test Loss:  0.00048031166079454124
Valid Loss:  0.0005873717018403113
Epoch:  152  	Training Loss: 0.0006190101848915219
Test Loss:  0.0004785063210874796
Valid Loss:  0.000584071152843535
Epoch:  153  	Training Loss: 0.0006159084150567651
Test Loss:  0.0004766535712406039
Valid Loss:  0.0005810706061311066
Epoch:  154  	Training Loss: 0.0006131381960585713
Test Loss:  0.0004748120263684541
Valid Loss:  0.0005783120868727565
Epoch:  155  	Training Loss: 0.0006106135551817715
Test Loss:  0.0004728487110696733
Valid Loss:  0.0005757407052442431
Epoch:  156  	Training Loss: 0.0006082289619371295
Test Loss:  0.0004709413042291999
Valid Loss:  0.000573282886762172
Epoch:  157  	Training Loss: 0.0006059508305042982
Test Loss:  0.0004690188798122108
Valid Loss:  0.0005709357792511582
Epoch:  158  	Training Loss: 0.0006037927232682705
Test Loss:  0.0004670559137593955
Valid Loss:  0.000568652874790132
Epoch:  159  	Training Loss: 0.000601690961048007
Test Loss:  0.00046512577682733536
Valid Loss:  0.0005664157797582448
Epoch:  160  	Training Loss: 0.0005996442632749677
Test Loss:  0.0004632452910300344
Valid Loss:  0.0005642405012622476
Epoch:  161  	Training Loss: 0.0005976309184916317
Test Loss:  0.0004615019715856761
Valid Loss:  0.0005620458396151662
Epoch:  162  	Training Loss: 0.0005956671666353941
Test Loss:  0.0004584754351526499
Valid Loss:  0.0005572106456384063
Epoch:  163  	Training Loss: 0.0005912636406719685
Test Loss:  0.00045572419185191393
Valid Loss:  0.000553057121578604
Epoch:  164  	Training Loss: 0.0005874049384146929
Test Loss:  0.0004530409350991249
Valid Loss:  0.0005493790376931429
Epoch:  165  	Training Loss: 0.0005838877405039966
Test Loss:  0.0004503183881752193
Valid Loss:  0.0005459163803607225
Epoch:  166  	Training Loss: 0.0005805416731163859
Test Loss:  0.00044753504334948957
Valid Loss:  0.0005426533170975745
Epoch:  167  	Training Loss: 0.0005773825105279684
Test Loss:  0.00044489841093309224
Valid Loss:  0.0005394979962147772
Epoch:  168  	Training Loss: 0.0005742940120398998
Test Loss:  0.00044220645213499665
Valid Loss:  0.0005364719545468688
Epoch:  169  	Training Loss: 0.0005712657002732158
Test Loss:  0.00043956254376098514
Valid Loss:  0.0005335056339390576
Epoch:  170  	Training Loss: 0.0005683475756086409
Test Loss:  0.0004370069655124098
Valid Loss:  0.0005307294777594507
Epoch:  171  	Training Loss: 0.0005655913846567273
Test Loss:  0.000434531073551625
Valid Loss:  0.0005279884790070355
Epoch:  172  	Training Loss: 0.0005628707585856318
Test Loss:  0.00042862509144470096
Valid Loss:  0.0005235759308561683
Epoch:  173  	Training Loss: 0.0005577064584940672
Test Loss:  0.0004236817476339638
Valid Loss:  0.0005194962723180652
Epoch:  174  	Training Loss: 0.0005531555507332087
Test Loss:  0.0004194174543954432
Valid Loss:  0.0005156262777745724
Epoch:  175  	Training Loss: 0.0005489559262059629
Test Loss:  0.000415563874412328
Valid Loss:  0.0005119142588227987
Epoch:  176  	Training Loss: 0.000545005314052105
Test Loss:  0.00041209402843378484
Valid Loss:  0.0005083185387775302
Epoch:  177  	Training Loss: 0.0005412357859313488
Test Loss:  0.00040892307879403234
Valid Loss:  0.000504810712300241
Epoch:  178  	Training Loss: 0.0005376117769628763
Test Loss:  0.00040597509359940886
Valid Loss:  0.0005014620255678892
Epoch:  179  	Training Loss: 0.0005341837531886995
Test Loss:  0.0004030835989397019
Valid Loss:  0.0004982962273061275
Epoch:  180  	Training Loss: 0.0005308693507686257
Test Loss:  0.0004003860813099891
Valid Loss:  0.0004951723967678845
Epoch:  181  	Training Loss: 0.0005276866722851992
Test Loss:  0.0003977143787778914
Valid Loss:  0.0004921633517369628
Epoch:  182  	Training Loss: 0.0005246043438091874
Test Loss:  0.0003975696745328605
Valid Loss:  0.0004900223575532436
Epoch:  183  	Training Loss: 0.0005228974041529
Test Loss:  0.00039711687713861465
Valid Loss:  0.0004884072113782167
Epoch:  184  	Training Loss: 0.0005215281853452325
Test Loss:  0.00039652964915148914
Valid Loss:  0.000487040524603799
Epoch:  185  	Training Loss: 0.000520338537171483
Test Loss:  0.0003958138404414058
Valid Loss:  0.0004858283791691065
Epoch:  186  	Training Loss: 0.0005192137323319912
Test Loss:  0.00039497489342465997
Valid Loss:  0.0004847449599765241
Epoch:  187  	Training Loss: 0.0005181776359677315
Test Loss:  0.00039407654548995197
Valid Loss:  0.0004837417509406805
Epoch:  188  	Training Loss: 0.0005171955563127995
Test Loss:  0.0003931273822672665
Valid Loss:  0.0004828236997127533
Epoch:  189  	Training Loss: 0.0005162669694982469
Test Loss:  0.00039225409273058176
Valid Loss:  0.00048190972302109003
Epoch:  190  	Training Loss: 0.0005153481615707278
Test Loss:  0.00039140257285907865
Valid Loss:  0.0004810092505067587
Epoch:  191  	Training Loss: 0.0005144502501934767
Test Loss:  0.00039056502282619476
Valid Loss:  0.00048015089123509824
Epoch:  192  	Training Loss: 0.000513601116836071
Test Loss:  0.00038764410419389606
Valid Loss:  0.0004777825088240206
Epoch:  193  	Training Loss: 0.0005110471975058317
Test Loss:  0.0003850538341794163
Valid Loss:  0.000475457520224154
Epoch:  194  	Training Loss: 0.0005085996817797422
Test Loss:  0.0003827407490462065
Valid Loss:  0.00047319033183157444
Epoch:  195  	Training Loss: 0.0005062762647867203
Test Loss:  0.00038052399759180844
Valid Loss:  0.00047099473886191845
Epoch:  196  	Training Loss: 0.0005040319520048797
Test Loss:  0.0003784239524975419
Valid Loss:  0.00046886331983841956
Epoch:  197  	Training Loss: 0.0005018474766984582
Test Loss:  0.00037637638160958886
Valid Loss:  0.00046676589408889413
Epoch:  198  	Training Loss: 0.0004997045616619289
Test Loss:  0.0003744367277249694
Valid Loss:  0.0004647187306545675
Epoch:  199  	Training Loss: 0.0004976484924554825
Test Loss:  0.0003725574060808867
Valid Loss:  0.0004627755843102932
Epoch:  200  	Training Loss: 0.000495698768645525
Test Loss:  0.0003706883289851248
Valid Loss:  0.00046091381227597594
Epoch:  201  	Training Loss: 0.0004938305355608463
Test Loss:  0.00036882489803247154
Valid Loss:  0.00045911490451544523
Epoch:  202  	Training Loss: 0.0004920352366752923
Test Loss:  0.00036771074519492686
Valid Loss:  0.00045626520295627415
Epoch:  203  	Training Loss: 0.000489664264023304
Test Loss:  0.0003662652743514627
Valid Loss:  0.00045400013914331794
Epoch:  204  	Training Loss: 0.00048771267756819725
Test Loss:  0.00036455492954701185
Valid Loss:  0.00045207689981907606
Epoch:  205  	Training Loss: 0.0004860307089984417
Test Loss:  0.00036294307210482657
Valid Loss:  0.00045033663627691567
Epoch:  206  	Training Loss: 0.0004844404465984553
Test Loss:  0.0003613346198108047
Valid Loss:  0.00044870658894069493
Epoch:  207  	Training Loss: 0.0004829133686143905
Test Loss:  0.00035988062154501677
Valid Loss:  0.0004471602151170373
 42%|████▏     | 209/500 [02:22<01:36,  3.02it/s] 42%|████▏     | 211/500 [02:29<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:29<02:53,  1.65it/s] 43%|████▎     | 217/500 [02:29<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:29<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:35<05:25,  1.16s/it] 45%|████▍     | 223/500 [02:36<03:51,  1.19it/s] 45%|████▌     | 225/500 [02:36<02:46,  1.65it/s] 45%|████▌     | 227/500 [02:36<02:01,  2.25it/s] 46%|████▌     | 229/500 [02:36<01:29,  3.02it/s] 46%|████▌     | 231/500 [02:42<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:42<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:43<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:49<05:07,  1.19s/it] 49%|████▊     | 243/500 [02:49<03:38,  1.17it/s] 49%|████▉     | 245/500 [02:49<02:37,  1.62it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.22it/s] 50%|████▉     | 249/500 [02:50<01:24,  2.98it/s] 50%|█████     | 251/500 [02:56<04:54,  1.18s/it] 51%|█████     | 253/500 [02:56<03:30,  1.17it/s] 51%|█████     | 255/500 [02:56<02:30,  1.62it/s] 51%|█████▏    | 257/500 [02:56<01:49,  2.22it/s] 52%|█████▏    | 259/500 [02:57<01:20,  2.98it/s] 52%|█████▏    | 261/500 [03:03<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:03<03:24,  1.16it/s] 53%|█████▎    | 265/500 [03:03<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:03<01:46,  2.20it/s] 54%|█████▍    | 269/500 [03:04<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:10<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:10<03:11,  1.18it/s]Epoch:  208  	Training Loss: 0.0004814661806449294
Test Loss:  0.00035848066909238696
Valid Loss:  0.00044574638013727963
Epoch:  209  	Training Loss: 0.0004801092727575451
Test Loss:  0.0003571231500245631
Valid Loss:  0.00044446130050346255
Epoch:  210  	Training Loss: 0.00047886461834423244
Test Loss:  0.0003558736352715641
Valid Loss:  0.00044326181523501873
Epoch:  211  	Training Loss: 0.00047770063974894583
Test Loss:  0.00035465796827338636
Valid Loss:  0.00044217356480658054
Epoch:  212  	Training Loss: 0.00047661722055636346
Test Loss:  0.00035238306736573577
Valid Loss:  0.00044111721217632294
Epoch:  213  	Training Loss: 0.0004753934626933187
Test Loss:  0.0003505998756736517
Valid Loss:  0.00044009395060129464
Epoch:  214  	Training Loss: 0.0004742556484416127
Test Loss:  0.00034914218122139573
Valid Loss:  0.00043907869257964194
Epoch:  215  	Training Loss: 0.0004731742665171623
Test Loss:  0.00034789377241395414
Valid Loss:  0.00043806087342090905
Epoch:  216  	Training Loss: 0.00047214716323651373
Test Loss:  0.00034681224497035146
Valid Loss:  0.00043705193093046546
Epoch:  217  	Training Loss: 0.0004711556248366833
Test Loss:  0.00034584588138386607
Valid Loss:  0.00043605692917481065
Epoch:  218  	Training Loss: 0.0004701863508671522
Test Loss:  0.0003449391224421561
Valid Loss:  0.000435090740211308
Epoch:  219  	Training Loss: 0.00046924204798415303
Test Loss:  0.0003440885047893971
Valid Loss:  0.0004341322055552155
Epoch:  220  	Training Loss: 0.00046832324005663395
Test Loss:  0.000343279039952904
Valid Loss:  0.0004331886302679777
Epoch:  221  	Training Loss: 0.0004674399096984416
Test Loss:  0.00034252062323503196
Valid Loss:  0.000432258821092546
Epoch:  222  	Training Loss: 0.0004665883316192776
Test Loss:  0.0003412032383494079
Valid Loss:  0.00043048046063631773
Epoch:  223  	Training Loss: 0.00046479201409965754
Test Loss:  0.0003398222615942359
Valid Loss:  0.00042881726403720677
Epoch:  224  	Training Loss: 0.0004631010815501213
Test Loss:  0.00033835734939202666
Valid Loss:  0.00042725371895357966
Epoch:  225  	Training Loss: 0.000461468065623194
Test Loss:  0.0003368826291989535
Valid Loss:  0.00042568828212097287
Epoch:  226  	Training Loss: 0.00045987515477463603
Test Loss:  0.0003354176878929138
Valid Loss:  0.000424006866523996
Epoch:  227  	Training Loss: 0.00045827392023056746
Test Loss:  0.00033398086088709533
Valid Loss:  0.00042234465945512056
Epoch:  228  	Training Loss: 0.0004567063879221678
Test Loss:  0.00033253474975936115
Valid Loss:  0.00042069918708875775
Epoch:  229  	Training Loss: 0.0004551666206680238
Test Loss:  0.00033093863748945296
Valid Loss:  0.0004190490290056914
Epoch:  230  	Training Loss: 0.000453563203336671
Test Loss:  0.0003292714827693999
Valid Loss:  0.0004173609195277095
Epoch:  231  	Training Loss: 0.0004518913628999144
Test Loss:  0.00032750057289376855
Valid Loss:  0.0004155918431933969
Epoch:  232  	Training Loss: 0.0004500517970882356
Test Loss:  0.00032495052437298
Valid Loss:  0.000413746340200305
Epoch:  233  	Training Loss: 0.0004478685441426933
Test Loss:  0.0003225147374905646
Valid Loss:  0.0004117513308301568
Epoch:  234  	Training Loss: 0.00044547702418640256
Test Loss:  0.0003201225772500038
Valid Loss:  0.0004095537296961993
Epoch:  235  	Training Loss: 0.00044293058454059064
Test Loss:  0.00031775934621691704
Valid Loss:  0.00040711628389544785
Epoch:  236  	Training Loss: 0.0004401942132972181
Test Loss:  0.0003153551951982081
Valid Loss:  0.0004045761306770146
Epoch:  237  	Training Loss: 0.00043737515807151794
Test Loss:  0.00031301905983127654
Valid Loss:  0.0004019798943772912
Epoch:  238  	Training Loss: 0.0004345803754404187
Test Loss:  0.00031073109130375087
Valid Loss:  0.0003994516737293452
Epoch:  239  	Training Loss: 0.0004318337596487254
Test Loss:  0.0003085733042098582
Valid Loss:  0.0003970319521613419
Epoch:  240  	Training Loss: 0.00042920056148432195
Test Loss:  0.00030651577981188893
Valid Loss:  0.00039472145726904273
Epoch:  241  	Training Loss: 0.0004266929754521698
Test Loss:  0.00030460726702585816
Valid Loss:  0.0003924794145859778
Epoch:  242  	Training Loss: 0.00042431033216416836
Test Loss:  0.0003035749541595578
Valid Loss:  0.00039057162939570844
Epoch:  243  	Training Loss: 0.0004225298180244863
Test Loss:  0.0003023715689778328
Valid Loss:  0.00038877068436704576
Epoch:  244  	Training Loss: 0.0004208303871564567
Test Loss:  0.0003010535438079387
Valid Loss:  0.0003870504442602396
Epoch:  245  	Training Loss: 0.00041919300565496087
Test Loss:  0.0002996856055688113
Valid Loss:  0.0003853990638162941
Epoch:  246  	Training Loss: 0.00041759570012800395
Test Loss:  0.0002982903679367155
Valid Loss:  0.00038379550096578896
Epoch:  247  	Training Loss: 0.0004160359385423362
Test Loss:  0.00029691270901821554
Valid Loss:  0.0003822071594186127
Epoch:  248  	Training Loss: 0.0004145100247114897
Test Loss:  0.0002955207019113004
Valid Loss:  0.00038065982516855
Epoch:  249  	Training Loss: 0.0004130143206566572
Test Loss:  0.00029414231539703906
Valid Loss:  0.00037914328277111053
Epoch:  250  	Training Loss: 0.00041154416976496577
Test Loss:  0.00029276032000780106
Valid Loss:  0.0003776690864469856
Epoch:  251  	Training Loss: 0.0004100975056644529
Test Loss:  0.0002913723583333194
Valid Loss:  0.0003762525739148259
Epoch:  252  	Training Loss: 0.0004086801200173795
Test Loss:  0.00028790603391826153
Valid Loss:  0.00037313380744308233
Epoch:  253  	Training Loss: 0.0004052736039739102
Test Loss:  0.0002850249584298581
Valid Loss:  0.0003699803492054343
Epoch:  254  	Training Loss: 0.0004019371990580112
Test Loss:  0.0002824898692779243
Valid Loss:  0.0003670536680147052
Epoch:  255  	Training Loss: 0.0003988105454482138
Test Loss:  0.00028023519553244114
Valid Loss:  0.00036438414826989174
Epoch:  256  	Training Loss: 0.00039594111149199307
Test Loss:  0.00027830631006509066
Valid Loss:  0.0003619978961069137
Epoch:  257  	Training Loss: 0.00039339554496109486
Test Loss:  0.0002767934638541192
Valid Loss:  0.00035999197280034423
Epoch:  258  	Training Loss: 0.000391280569601804
Test Loss:  0.0002754703164100647
Valid Loss:  0.0003583242651075125
Epoch:  259  	Training Loss: 0.00038949676672928035
Test Loss:  0.0002742285723797977
Valid Loss:  0.00035686269984580576
Epoch:  260  	Training Loss: 0.00038792809937149286
Test Loss:  0.00027314736507833004
Valid Loss:  0.0003555978764779866
Epoch:  261  	Training Loss: 0.00038659432902932167
Test Loss:  0.00027213155408389866
Valid Loss:  0.00035443721571937203
Epoch:  262  	Training Loss: 0.000385353690944612
Test Loss:  0.0002707790699787438
Valid Loss:  0.0003532159316819161
Epoch:  263  	Training Loss: 0.00038405891973525286
Test Loss:  0.0002696511219255626
Valid Loss:  0.00035201164428144693
Epoch:  264  	Training Loss: 0.0003828144399449229
Test Loss:  0.00026856723707169294
Valid Loss:  0.0003508194931782782
Epoch:  265  	Training Loss: 0.0003815880627371371
Test Loss:  0.0002675184514373541
Valid Loss:  0.0003496478602755815
Epoch:  266  	Training Loss: 0.00038038965431042016
Test Loss:  0.0002665549982339144
Valid Loss:  0.00034849951043725014
Epoch:  267  	Training Loss: 0.00037921773036941886
Test Loss:  0.00026561811682768166
Valid Loss:  0.0003473737742751837
Epoch:  268  	Training Loss: 0.0003780619881581515
Test Loss:  0.0002646895300131291
Valid Loss:  0.00034626800334081054
Epoch:  269  	Training Loss: 0.0003769227769225836
Test Loss:  0.00026377610629424453
Valid Loss:  0.00034519971814006567
Epoch:  270  	Training Loss: 0.00037581316428259015
Test Loss:  0.0002628584625199437
Valid Loss:  0.00034414921537972987
Epoch:  271  	Training Loss: 0.0003747269220184535
Test Loss:  0.00026194305974058807
Valid Loss:  0.0003431158256717026
Epoch:  272  	Training Loss: 0.00037365240859799087
Test Loss:  0.0002613557153381407
Valid Loss:  0.0003421406727284193
Epoch:  273  	Training Loss: 0.00037274579517543316
Test Loss:  0.00026070247986353934
Valid Loss:  0.0003412787918932736
Epoch:  274  	Training Loss: 0.0003719005617313087
Test Loss:  0.00026004406390711665
Valid Loss:  0.0003404516028240323
Epoch:  275  	Training Loss: 0.00037110934499651194
Test Loss:   55%|█████▌    | 275/500 [03:10<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:10<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:10<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:17<04:15,  1.16s/it] 57%|█████▋    | 283/500 [03:17<03:01,  1.20it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:35,  2.24it/s] 58%|█████▊    | 289/500 [03:17<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:23<04:05,  1.17s/it] 59%|█████▊    | 293/500 [03:24<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:24<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:24<01:31,  2.23it/s] 60%|█████▉    | 299/500 [03:24<01:07,  2.99it/s] 60%|██████    | 301/500 [03:30<03:55,  1.18s/it] 61%|██████    | 303/500 [03:30<02:47,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:31<01:03,  2.99it/s] 62%|██████▏   | 311/500 [03:37<03:42,  1.18s/it] 63%|██████▎   | 313/500 [03:37<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:37<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:38<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:38<01:00,  2.99it/s] 64%|██████▍   | 321/500 [03:44<03:33,  1.19s/it] 65%|██████▍   | 323/500 [03:44<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:44<01:48,  1.62it/s] 65%|██████▌   | 327/500 [03:44<01:18,  2.21it/s] 66%|██████▌   | 329/500 [03:45<00:57,  2.97it/s] 66%|██████▌   | 331/500 [03:51<03:21,  1.19s/it] 67%|██████▋   | 333/500 [03:51<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:51<01:42,  1.61it/s] 67%|██████▋   | 337/500 [03:51<01:14,  2.20it/s] 68%|██████▊   | 339/500 [03:52<00:54,  2.97it/s] 68%|██████▊   | 341/500 [03:58<03:06,  1.17s/it]0.0002593887038528919
Valid Loss:  0.00033967639319598675
Epoch:  276  	Training Loss: 0.0003703693801071495
Test Loss:  0.00025870901299640536
Valid Loss:  0.0003389323828741908
Epoch:  277  	Training Loss: 0.0003696586936712265
Test Loss:  0.000258101150393486
Valid Loss:  0.00033822539262473583
Epoch:  278  	Training Loss: 0.000368978304322809
Test Loss:  0.00025749311316758394
Valid Loss:  0.0003375608357600868
Epoch:  279  	Training Loss: 0.00036831246688961983
Test Loss:  0.00025688466848805547
Valid Loss:  0.00033690701820887625
Epoch:  280  	Training Loss: 0.00036766199627891183
Test Loss:  0.00025624106638133526
Valid Loss:  0.00033628076198510826
Epoch:  281  	Training Loss: 0.0003670304431580007
Test Loss:  0.00025570683646947145
Valid Loss:  0.0003356562810949981
Epoch:  282  	Training Loss: 0.0003664099203888327
Test Loss:  0.00025192624889314175
Valid Loss:  0.0003335079818498343
Epoch:  283  	Training Loss: 0.00036370859015733004
Test Loss:  0.0002497295499779284
Valid Loss:  0.0003315898065920919
Epoch:  284  	Training Loss: 0.00036147559876553714
Test Loss:  0.0002481177216395736
Valid Loss:  0.000329814909491688
Epoch:  285  	Training Loss: 0.00035950058372691274
Test Loss:  0.0002467534504830837
Valid Loss:  0.0003281733952462673
Epoch:  286  	Training Loss: 0.00035774678690358996
Test Loss:  0.00024556246353313327
Valid Loss:  0.0003266606363467872
Epoch:  287  	Training Loss: 0.0003561500634532422
Test Loss:  0.0002443453122396022
Valid Loss:  0.0003252177848480642
Epoch:  288  	Training Loss: 0.0003546420484781265
Test Loss:  0.00024315566406585276
Valid Loss:  0.00032383223879151046
Epoch:  289  	Training Loss: 0.00035322224721312523
Test Loss:  0.00024197578022722155
Valid Loss:  0.0003225087421014905
Epoch:  290  	Training Loss: 0.00035185652086511254
Test Loss:  0.00024084909819066525
Valid Loss:  0.00032121679396368563
Epoch:  291  	Training Loss: 0.0003505262138787657
Test Loss:  0.0002397614880464971
Valid Loss:  0.0003199551720172167
Epoch:  292  	Training Loss: 0.0003492393298074603
Test Loss:  0.0002388183493167162
Valid Loss:  0.00031904943170957267
Epoch:  293  	Training Loss: 0.00034824793692678213
Test Loss:  0.00023796074674464762
Valid Loss:  0.0003181781794410199
Epoch:  294  	Training Loss: 0.00034730916377156973
Test Loss:  0.00023716958821751177
Valid Loss:  0.00031733623472973704
Epoch:  295  	Training Loss: 0.0003463991160970181
Test Loss:  0.00023645050532650203
Valid Loss:  0.00031650307937525213
Epoch:  296  	Training Loss: 0.0003455232654232532
Test Loss:  0.00023575399245601147
Valid Loss:  0.00031569390557706356
Epoch:  297  	Training Loss: 0.0003446829505264759
Test Loss:  0.00023507616424467415
Valid Loss:  0.00031491974368691444
Epoch:  298  	Training Loss: 0.0003438802086748183
Test Loss:  0.00023443016107194126
Valid Loss:  0.0003141640918329358
Epoch:  299  	Training Loss: 0.00034310828777961433
Test Loss:  0.0002338371123187244
Valid Loss:  0.00031342991860583425
Epoch:  300  	Training Loss: 0.00034237990621477365
Test Loss:  0.00023325170332100242
Valid Loss:  0.00031272880733013153
Epoch:  301  	Training Loss: 0.00034168135607615113
Test Loss:  0.00023269228404387832
Valid Loss:  0.00031205511186271906
Epoch:  302  	Training Loss: 0.0003410049539525062
Test Loss:  0.00023184288875199854
Valid Loss:  0.00031103548826649785
Epoch:  303  	Training Loss: 0.00033998931758105755
Test Loss:  0.0002310324925929308
Valid Loss:  0.0003100418543908745
Epoch:  304  	Training Loss: 0.0003390113415662199
Test Loss:  0.00023021778906695545
Valid Loss:  0.00030906478059478104
Epoch:  305  	Training Loss: 0.00033805856946855783
Test Loss:  0.00022940830967854708
Valid Loss:  0.00030810775933787227
Epoch:  306  	Training Loss: 0.00033712730510160327
Test Loss:  0.00022861022443976253
Valid Loss:  0.00030718487687408924
Epoch:  307  	Training Loss: 0.00033622264163568616
Test Loss:  0.00022780962171964347
Valid Loss:  0.00030628900276497006
Epoch:  308  	Training Loss: 0.00033532618544995785
Test Loss:  0.0002270215773023665
Valid Loss:  0.00030540110310539603
Epoch:  309  	Training Loss: 0.00033444439759477973
Test Loss:  0.00022625579731538892
Valid Loss:  0.00030453375075012445
Epoch:  310  	Training Loss: 0.0003335853689350188
Test Loss:  0.00022549915593117476
Valid Loss:  0.00030367454746738076
Epoch:  311  	Training Loss: 0.00033273641020059586
Test Loss:  0.00022477019228972495
Valid Loss:  0.00030281831277534366
Epoch:  312  	Training Loss: 0.00033189781242981553
Test Loss:  0.00022390462982002646
Valid Loss:  0.00030167531804181635
Epoch:  313  	Training Loss: 0.0003308253944851458
Test Loss:  0.0002230108220828697
Valid Loss:  0.00030059454729780555
Epoch:  314  	Training Loss: 0.00032979383831843734
Test Loss:  0.00022213460761122406
Valid Loss:  0.00029956467915326357
Epoch:  315  	Training Loss: 0.0003288021543994546
Test Loss:  0.0002212527033407241
Valid Loss:  0.0002985751780215651
Epoch:  316  	Training Loss: 0.0003278343065176159
Test Loss:  0.00022041384363546968
Valid Loss:  0.0002976120449602604
Epoch:  317  	Training Loss: 0.00032690161606296897
Test Loss:  0.0002195990673499182
Valid Loss:  0.00029666960472241044
Epoch:  318  	Training Loss: 0.00032598580582998693
Test Loss:  0.0002188090147683397
Valid Loss:  0.00029574884683825076
Epoch:  319  	Training Loss: 0.0003250975860282779
Test Loss:  0.0002180517476517707
Valid Loss:  0.0002948444162029773
Epoch:  320  	Training Loss: 0.00032422953518107533
Test Loss:  0.00021729762374889106
Valid Loss:  0.00029395223828032613
Epoch:  321  	Training Loss: 0.0003233762690797448
Test Loss:  0.00021657004253938794
Valid Loss:  0.00029308159719221294
Epoch:  322  	Training Loss: 0.0003225461987312883
Test Loss:  0.0002157766866730526
Valid Loss:  0.00029225595062598586
Epoch:  323  	Training Loss: 0.00032169686164706945
Test Loss:  0.00021501602896023542
Valid Loss:  0.0002914409851655364
Epoch:  324  	Training Loss: 0.0003208662383258343
Test Loss:  0.00021428888430818915
Valid Loss:  0.00029064089176245034
Epoch:  325  	Training Loss: 0.0003200559876859188
Test Loss:  0.00021360645769163966
Valid Loss:  0.00028987001860514283
Epoch:  326  	Training Loss: 0.00031927466625347733
Test Loss:  0.00021293244208209217
Valid Loss:  0.00028912193374708295
Epoch:  327  	Training Loss: 0.0003185122332070023
Test Loss:  0.00021229294361546636
Valid Loss:  0.0002883924753405154
Epoch:  328  	Training Loss: 0.0003177617909386754
Test Loss:  0.00021167559316381812
Valid Loss:  0.0002876883954741061
Epoch:  329  	Training Loss: 0.0003170297422911972
Test Loss:  0.00021107893553562462
Valid Loss:  0.0002869986346922815
Epoch:  330  	Training Loss: 0.00031632030731998384
Test Loss:  0.00021047527843620628
Valid Loss:  0.00028631568420678377
Epoch:  331  	Training Loss: 0.0003156235907226801
Test Loss:  0.000209884368814528
Valid Loss:  0.00028564335661940277
Epoch:  332  	Training Loss: 0.00031493601272813976
Test Loss:  0.0002097601827699691
Valid Loss:  0.0002853598853107542
Epoch:  333  	Training Loss: 0.00031461892649531364
Test Loss:  0.000209606543648988
Valid Loss:  0.0002850766759365797
Epoch:  334  	Training Loss: 0.00031431062961928546
Test Loss:  0.00020947010489180684
Valid Loss:  0.00028480193577706814
Epoch:  335  	Training Loss: 0.0003140130138490349
Test Loss:  0.0002093132643494755
Valid Loss:  0.0002845220733433962
Epoch:  336  	Training Loss: 0.00031371923978440464
Test Loss:  0.00020912916806992143
Valid Loss:  0.0002842447138391435
Epoch:  337  	Training Loss: 0.0003134306753054261
Test Loss:  0.0002089517074637115
Valid Loss:  0.0002839676453731954
Epoch:  338  	Training Loss: 0.0003131511912215501
Test Loss:  0.00020877071074210107
Valid Loss:  0.0002836999483406544
Epoch:  339  	Training Loss: 0.00031288230093196034
Test Loss:  0.00020857268827967346
Valid Loss:  0.00028343277517706156
Epoch:  340  	Training Loss: 0.00031261821277439594
Test Loss:  0.00020839268108829856
Valid Loss:  0.0002831677265930921
Epoch:  341  	Training Loss: 0.0003123554342892021
Test Loss:  0.00020821769430767745
Valid Loss:  0.0002829187724273652
Epoch:  342  	Training Loss: 0.000312100222799927
Test Loss:  0.00020731519907712936
Valid Loss:   69%|██████▊   | 343/500 [03:58<02:12,  1.19it/s] 69%|██████▉   | 345/500 [03:58<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:58<01:09,  2.21it/s] 70%|██████▉   | 349/500 [03:58<00:51,  2.91it/s] 70%|███████   | 351/500 [04:05<02:56,  1.19s/it] 71%|███████   | 353/500 [04:05<02:05,  1.18it/s] 71%|███████   | 355/500 [04:05<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:05<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:05<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:11<02:42,  1.17s/it] 73%|███████▎  | 363/500 [04:12<01:54,  1.19it/s] 73%|███████▎  | 365/500 [04:12<01:21,  1.65it/s] 73%|███████▎  | 367/500 [04:12<00:59,  2.25it/s] 74%|███████▍  | 369/500 [04:12<00:43,  3.01it/s] 74%|███████▍  | 371/500 [04:18<02:30,  1.17s/it] 75%|███████▍  | 373/500 [04:18<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:19<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:19<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:19<00:40,  3.02it/s] 76%|███████▌  | 381/500 [04:25<02:18,  1.16s/it] 77%|███████▋  | 383/500 [04:25<01:37,  1.20it/s] 77%|███████▋  | 385/500 [04:25<01:09,  1.65it/s] 77%|███████▋  | 387/500 [04:25<00:50,  2.26it/s] 78%|███████▊  | 389/500 [04:26<00:36,  3.03it/s] 78%|███████▊  | 391/500 [04:32<02:06,  1.16s/it] 79%|███████▊  | 393/500 [04:32<01:29,  1.20it/s] 79%|███████▉  | 395/500 [04:32<01:03,  1.66it/s] 79%|███████▉  | 397/500 [04:32<00:45,  2.26it/s] 80%|███████▉  | 399/500 [04:32<00:33,  3.04it/s] 80%|████████  | 401/500 [04:39<01:56,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.18it/s] 81%|████████  | 405/500 [04:39<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.00it/s]0.00028199522057548165
Epoch:  343  	Training Loss: 0.00031118944752961397
Test Loss:  0.0002064617001451552
Valid Loss:  0.00028107507387176156
Epoch:  344  	Training Loss: 0.00031028914963826537
Test Loss:  0.0002056472294498235
Valid Loss:  0.0002801676164381206
Epoch:  345  	Training Loss: 0.0003094071871601045
Test Loss:  0.00020482472609728575
Valid Loss:  0.00027927395422011614
Epoch:  346  	Training Loss: 0.00030853424686938524
Test Loss:  0.00020406192925292999
Valid Loss:  0.00027837581001222134
Epoch:  347  	Training Loss: 0.00030767155112698674
Test Loss:  0.00020330146071501076
Valid Loss:  0.0002774938475340605
Epoch:  348  	Training Loss: 0.0003068240766879171
Test Loss:  0.00020258667063899338
Valid Loss:  0.0002766182296909392
Epoch:  349  	Training Loss: 0.00030598274315707386
Test Loss:  0.00020183922606520355
Valid Loss:  0.0002757591428235173
Epoch:  350  	Training Loss: 0.0003051546518690884
Test Loss:  0.00020114170911256224
Valid Loss:  0.00027490276261232793
Epoch:  351  	Training Loss: 0.0003043356700800359
Test Loss:  0.00020045660494361073
Valid Loss:  0.0002740548807196319
Epoch:  352  	Training Loss: 0.0003035292902495712
Test Loss:  0.00019981505465693772
Valid Loss:  0.0002735253074206412
Epoch:  353  	Training Loss: 0.00030297564808279276
Test Loss:  0.0001992475299630314
Valid Loss:  0.0002730045234784484
Epoch:  354  	Training Loss: 0.00030243227956816554
Test Loss:  0.0001987465948332101
Valid Loss:  0.0002724809164647013
Epoch:  355  	Training Loss: 0.00030189921380952
Test Loss:  0.00019826862262561917
Valid Loss:  0.00027196676819585264
Epoch:  356  	Training Loss: 0.0003013769455719739
Test Loss:  0.00019781096489168704
Valid Loss:  0.0002714559668675065
Epoch:  357  	Training Loss: 0.00030086314654909074
Test Loss:  0.0001974073820747435
Valid Loss:  0.0002709555847104639
Epoch:  358  	Training Loss: 0.00030035944655537605
Test Loss:  0.00019701258861459792
Valid Loss:  0.0002704602375160903
Epoch:  359  	Training Loss: 0.0002998665440827608
Test Loss:  0.00019660493126139045
Valid Loss:  0.0002699723991099745
Epoch:  360  	Training Loss: 0.0002993796078953892
Test Loss:  0.000196206514374353
Valid Loss:  0.0002694894792512059
Epoch:  361  	Training Loss: 0.0002989069325849414
Test Loss:  0.00019581840024329722
Valid Loss:  0.00026901831733994186
Epoch:  362  	Training Loss: 0.00029844569507986307
Test Loss:  0.00019563038949854672
Valid Loss:  0.00026846060063689947
Epoch:  363  	Training Loss: 0.00029797578463330865
Test Loss:  0.00019541222718544304
Valid Loss:  0.0002679445897229016
Epoch:  364  	Training Loss: 0.0002975419629365206
Test Loss:  0.00019516880274750292
Valid Loss:  0.00026746606454253197
Epoch:  365  	Training Loss: 0.000297140097245574
Test Loss:  0.00019491146667860448
Valid Loss:  0.00026702549075707793
Epoch:  366  	Training Loss: 0.00029677117709070444
Test Loss:  0.00019464406068436801
Valid Loss:  0.00026661198353394866
Epoch:  367  	Training Loss: 0.0002964141604024917
Test Loss:  0.00019437045557424426
Valid Loss:  0.00026621349388733506
Epoch:  368  	Training Loss: 0.0002960682613775134
Test Loss:  0.00019409498781897128
Valid Loss:  0.0002658311277627945
Epoch:  369  	Training Loss: 0.0002957307733595371
Test Loss:  0.00019385258201509714
Valid Loss:  0.00026546503067947924
Epoch:  370  	Training Loss: 0.00029540807008743286
Test Loss:  0.00019359891302883625
Valid Loss:  0.00026511127362027764
Epoch:  371  	Training Loss: 0.0002950945636257529
Test Loss:  0.00019334779062774032
Valid Loss:  0.00026477285427972674
Epoch:  372  	Training Loss: 0.0002947909233625978
Test Loss:  0.0001924150565173477
Valid Loss:  0.00026398763293400407
Epoch:  373  	Training Loss: 0.00029401996289379895
Test Loss:  0.00019161391537636518
Valid Loss:  0.0002632303803693503
Epoch:  374  	Training Loss: 0.00029327243100851774
Test Loss:  0.00019089411944150925
Valid Loss:  0.0002624922781251371
Epoch:  375  	Training Loss: 0.0002925395965576172
Test Loss:  0.00019022499327547848
Valid Loss:  0.00026176770916208625
Epoch:  376  	Training Loss: 0.00029181939316913486
Test Loss:  0.00018958805594593287
Valid Loss:  0.00026105379220098257
Epoch:  377  	Training Loss: 0.0002911107148975134
Test Loss:  0.00018897291738539934
Valid Loss:  0.000260347209405154
Epoch:  378  	Training Loss: 0.0002904127468355
Test Loss:  0.00018842561985366046
Valid Loss:  0.00025964737869799137
Epoch:  379  	Training Loss: 0.0002897342783398926
Test Loss:  0.00018787698354572058
Valid Loss:  0.0002589547075331211
Epoch:  380  	Training Loss: 0.0002890628529712558
Test Loss:  0.0001873303554020822
Valid Loss:  0.00025827466743066907
Epoch:  381  	Training Loss: 0.00028840574668720365
Test Loss:  0.0001867900718934834
Valid Loss:  0.00025761278811842203
Epoch:  382  	Training Loss: 0.0002877591468859464
Test Loss:  0.0001865559897851199
Valid Loss:  0.0002571505610831082
Epoch:  383  	Training Loss: 0.0002873151970561594
Test Loss:  0.00018627929966896772
Valid Loss:  0.000256700353929773
Epoch:  384  	Training Loss: 0.0002868828596547246
Test Loss:  0.00018597589223645627
Valid Loss:  0.0002562723238952458
Epoch:  385  	Training Loss: 0.00028646900318562984
Test Loss:  0.000185660261195153
Valid Loss:  0.00025586102856323123
Epoch:  386  	Training Loss: 0.0002860620152205229
Test Loss:  0.00018533843103796244
Valid Loss:  0.00025545203243382275
Epoch:  387  	Training Loss: 0.00028566093533299863
Test Loss:  0.0001850231783464551
Valid Loss:  0.00025505098165012896
Epoch:  388  	Training Loss: 0.0002852667239494622
Test Loss:  0.00018471418297849596
Valid Loss:  0.00025465188082307577
Epoch:  389  	Training Loss: 0.0002848772273864597
Test Loss:  0.00018441135762259364
Valid Loss:  0.0002542574657127261
Epoch:  390  	Training Loss: 0.00028449122328311205
Test Loss:  0.0001840977929532528
Valid Loss:  0.0002538682892918587
Epoch:  391  	Training Loss: 0.0002841097884811461
Test Loss:  0.00018379258108325303
Valid Loss:  0.00025348542840220034
Epoch:  392  	Training Loss: 0.00028372969245538116
Test Loss:  0.00018357332737650722
Valid Loss:  0.0002532745129428804
Epoch:  393  	Training Loss: 0.0002835265768226236
Test Loss:  0.00018340729002375156
Valid Loss:  0.0002530632191337645
Epoch:  394  	Training Loss: 0.0002833274775184691
Test Loss:  0.00018324459961149842
Valid Loss:  0.0002528574550524354
Epoch:  395  	Training Loss: 0.0002831286401487887
Test Loss:  0.00018308567814528942
Valid Loss:  0.0002526569296605885
Epoch:  396  	Training Loss: 0.00028293297509662807
Test Loss:  0.0001829284301493317
Valid Loss:  0.0002524625160731375
Epoch:  397  	Training Loss: 0.000282743654679507
Test Loss:  0.00018277860363014042
Valid Loss:  0.0002522716822568327
Epoch:  398  	Training Loss: 0.0002825572737492621
Test Loss:  0.0001826327497838065
Valid Loss:  0.00025208748411387205
Epoch:  399  	Training Loss: 0.0002823736285790801
Test Loss:  0.00018249030108563602
Valid Loss:  0.00025190893211402
Epoch:  400  	Training Loss: 0.0002821950474753976
Test Loss:  0.00018234820163343102
Valid Loss:  0.00025173521135002375
Epoch:  401  	Training Loss: 0.0002820155641529709
Test Loss:  0.00018220764468424022
Valid Loss:  0.0002515609667170793
Epoch:  402  	Training Loss: 0.00028183701215311885
Test Loss:  0.00018190736591350287
Valid Loss:  0.0002512108476366848
Epoch:  403  	Training Loss: 0.00028148898854851723
Test Loss:  0.00018162459309678525
Valid Loss:  0.0002508650650270283
Epoch:  404  	Training Loss: 0.0002811456215567887
Test Loss:  0.00018134276615455747
Valid Loss:  0.0002505218726582825
Epoch:  405  	Training Loss: 0.0002808048448059708
Test Loss:  0.000181094859726727
Valid Loss:  0.000250177807174623
Epoch:  406  	Training Loss: 0.00028046881197951734
Test Loss:  0.00018084471230395138
Valid Loss:  0.00024984084302559495
Epoch:  407  	Training Loss: 0.00028013851260766387
Test Loss:  0.000180595408892259
Valid Loss:  0.00024950571241788566
Epoch:  408  	Training Loss: 0.00027981310267932713
Test Loss:  0.0001803436316549778
Valid Loss:  0.00024917518021538854
Epoch:  409  	Training Loss: 0.0002794894389808178
Test Loss:  0.0001800966274458915
Valid Loss:  0.0002488473546691239
 82%|████████▏ | 411/500 [04:45<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:46<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:46<00:26,  3.02it/s] 84%|████████▍ | 421/500 [04:52<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:52<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:52<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.25it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.03it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.16s/it] 87%|████████▋ | 433/500 [04:59<00:55,  1.20it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.66it/s] 87%|████████▋ | 437/500 [04:59<00:27,  2.26it/s] 88%|████████▊ | 439/500 [04:59<00:20,  3.04it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:06<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:06<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:12<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.26it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:19<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:19<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:19<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.02it/s] 94%|█████████▍| 471/500 [05:26<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:26<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:26<00:15,  1.62it/s]Epoch:  410  	Training Loss: 0.0002791683073155582
Test Loss:  0.00017984909936785698
Valid Loss:  0.0002485237782821059
Epoch:  411  	Training Loss: 0.00027885095914825797
Test Loss:  0.00017960480181500316
Valid Loss:  0.0002482007839716971
Epoch:  412  	Training Loss: 0.00027853483334183693
Test Loss:  0.0001793887495296076
Valid Loss:  0.0002478517999406904
Epoch:  413  	Training Loss: 0.0002782201045192778
Test Loss:  0.00017915408534463495
Valid Loss:  0.0002475178334861994
Epoch:  414  	Training Loss: 0.0002779111673589796
Test Loss:  0.00017890539311338216
Valid Loss:  0.00024719623615965247
Epoch:  415  	Training Loss: 0.0002776097389869392
Test Loss:  0.0001786557986633852
Valid Loss:  0.00024688226403668523
Epoch:  416  	Training Loss: 0.00027731480076909065
Test Loss:  0.00017840153304859996
Valid Loss:  0.00024657449102960527
Epoch:  417  	Training Loss: 0.0002770240243989974
Test Loss:  0.00017815240425989032
Valid Loss:  0.00024627582752145827
Epoch:  418  	Training Loss: 0.0002767388941720128
Test Loss:  0.00017790372658055276
Valid Loss:  0.0002459821989759803
Epoch:  419  	Training Loss: 0.0002764577802736312
Test Loss:  0.0001776818244252354
Valid Loss:  0.0002456938964314759
Epoch:  420  	Training Loss: 0.0002761812647804618
Test Loss:  0.00017745514924172312
Valid Loss:  0.0002454135101288557
Epoch:  421  	Training Loss: 0.0002759121998678893
Test Loss:  0.00017725760699249804
Valid Loss:  0.00024513399694114923
Epoch:  422  	Training Loss: 0.0002756497706286609
Test Loss:  0.0001770820381352678
Valid Loss:  0.00024481717264279723
Epoch:  423  	Training Loss: 0.00027536251582205296
Test Loss:  0.00017686805222183466
Valid Loss:  0.00024451815988868475
Epoch:  424  	Training Loss: 0.0002750884450506419
Test Loss:  0.00017662796017248183
Valid Loss:  0.00024423812283203006
Epoch:  425  	Training Loss: 0.0002748241531662643
Test Loss:  0.00017638593271840364
Valid Loss:  0.0002439667150611058
Epoch:  426  	Training Loss: 0.0002745652454905212
Test Loss:  0.00017615235992707312
Valid Loss:  0.00024370281607843935
Epoch:  427  	Training Loss: 0.0002743138466030359
Test Loss:  0.00017592430231161416
Valid Loss:  0.00024344417033717036
Epoch:  428  	Training Loss: 0.000274064892437309
Test Loss:  0.00017570694035384804
Valid Loss:  0.00024320276861544698
Epoch:  429  	Training Loss: 0.00027382472762838006
Test Loss:  0.00017549966287333518
Valid Loss:  0.0002429709566058591
Epoch:  430  	Training Loss: 0.00027359079103916883
Test Loss:  0.000175294786458835
Valid Loss:  0.00024274771567434072
Epoch:  431  	Training Loss: 0.00027336139464750886
Test Loss:  0.0001750940573401749
Valid Loss:  0.0002425313286948949
Epoch:  432  	Training Loss: 0.00027313665486872196
Test Loss:  0.0001750642986735329
Valid Loss:  0.00024237181060016155
Epoch:  433  	Training Loss: 0.00027294125175103545
Test Loss:  0.0001750136143527925
Valid Loss:  0.0002422140969429165
Epoch:  434  	Training Loss: 0.00027275041793473065
Test Loss:  0.00017494263011030853
Valid Loss:  0.00024205734371207654
Epoch:  435  	Training Loss: 0.0002725603699218482
Test Loss:  0.00017485811258666217
Valid Loss:  0.00024190539261326194
Epoch:  436  	Training Loss: 0.00027237331960350275
Test Loss:  0.00017475798085797578
Valid Loss:  0.0002417579380562529
Epoch:  437  	Training Loss: 0.0002721893251873553
Test Loss:  0.0001746521156746894
Valid Loss:  0.0002416119968984276
Epoch:  438  	Training Loss: 0.0002720071643125266
Test Loss:  0.0001745433546602726
Valid Loss:  0.00024146566283889115
Epoch:  439  	Training Loss: 0.00027182523626834154
Test Loss:  0.00017443056276533753
Valid Loss:  0.0002413191250525415
Epoch:  440  	Training Loss: 0.0002716431044973433
Test Loss:  0.0001743151224218309
Valid Loss:  0.0002411741006653756
Epoch:  441  	Training Loss: 0.00027146158390678465
Test Loss:  0.00017419990035705268
Valid Loss:  0.00024102668976411223
Epoch:  442  	Training Loss: 0.000271280063316226
Test Loss:  0.0001736758858896792
Valid Loss:  0.0002407477149972692
Epoch:  443  	Training Loss: 0.00027093832613900304
Test Loss:  0.00017325763474218547
Valid Loss:  0.0002404810074949637
Epoch:  444  	Training Loss: 0.0002706160885281861
Test Loss:  0.00017291355470661074
Valid Loss:  0.00024022140132728964
Epoch:  445  	Training Loss: 0.00027030607452616096
Test Loss:  0.00017261751054320484
Valid Loss:  0.0002399680088274181
Epoch:  446  	Training Loss: 0.0002700063632801175
Test Loss:  0.0001723520690575242
Valid Loss:  0.0002397147472947836
Epoch:  447  	Training Loss: 0.0002697081654332578
Test Loss:  0.00017211138037964702
Valid Loss:  0.00023946427972987294
Epoch:  448  	Training Loss: 0.0002694164286367595
Test Loss:  0.00017188326455652714
Valid Loss:  0.00023922105901874602
Epoch:  449  	Training Loss: 0.0002691280678845942
Test Loss:  0.00017167141777463257
Valid Loss:  0.0002389789733570069
Epoch:  450  	Training Loss: 0.00026884282124228776
Test Loss:  0.00017147195467259735
Valid Loss:  0.00023874024918768555
Epoch:  451  	Training Loss: 0.000268563482677564
Test Loss:  0.00017128116451203823
Valid Loss:  0.00023850587604101747
Epoch:  452  	Training Loss: 0.0002682911290321499
Test Loss:  0.00017139167175628245
Valid Loss:  0.00023819180205464363
Epoch:  453  	Training Loss: 0.00026795349549502134
Test Loss:  0.0001713948731776327
Valid Loss:  0.0002378930221311748
Epoch:  454  	Training Loss: 0.00026763006462715566
Test Loss:  0.00017132688662968576
Valid Loss:  0.00023760007752571255
Epoch:  455  	Training Loss: 0.00026731169782578945
Test Loss:  0.0001712065131869167
Valid Loss:  0.00023731106193736196
Epoch:  456  	Training Loss: 0.00026699743466451764
Test Loss:  0.00017105299048125744
Valid Loss:  0.00023702188627794385
Epoch:  457  	Training Loss: 0.0002666840155143291
Test Loss:  0.00017087528249248862
Valid Loss:  0.00023673591203987598
Epoch:  458  	Training Loss: 0.00026637385599315166
Test Loss:  0.00017068529268726707
Valid Loss:  0.0002364512620260939
Epoch:  459  	Training Loss: 0.00026606349274516106
Test Loss:  0.00017048809968400747
Valid Loss:  0.00023616489488631487
Epoch:  460  	Training Loss: 0.00026575615629553795
Test Loss:  0.0001702840527286753
Valid Loss:  0.00023588299518451095
Epoch:  461  	Training Loss: 0.00026545001310296357
Test Loss:  0.0001700760331004858
Valid Loss:  0.0002356025215703994
Epoch:  462  	Training Loss: 0.000265142327407375
Test Loss:  0.00016991850861813873
Valid Loss:  0.00023539170797448605
Epoch:  463  	Training Loss: 0.00026490562595427036
Test Loss:  0.00016975973267108202
Valid Loss:  0.00023519252135884017
Epoch:  464  	Training Loss: 0.00026467518182471395
Test Loss:  0.00016960667562671006
Valid Loss:  0.0002349943679291755
Epoch:  465  	Training Loss: 0.00026444587274454534
Test Loss:  0.00016944461094681174
Valid Loss:  0.00023480042000301182
Epoch:  466  	Training Loss: 0.00026422133669257164
Test Loss:  0.0001692950027063489
Valid Loss:  0.00023461709497496486
Epoch:  467  	Training Loss: 0.0002639981103129685
Test Loss:  0.00016914824664127082
Valid Loss:  0.00023443467216566205
Epoch:  468  	Training Loss: 0.00026377980248071253
Test Loss:  0.00016899860929697752
Valid Loss:  0.0002342590014450252
Epoch:  469  	Training Loss: 0.0002635622804518789
Test Loss:  0.00016885172226466238
Valid Loss:  0.00023408896231558174
Epoch:  470  	Training Loss: 0.00026334752328693867
Test Loss:  0.00016870757099241018
Valid Loss:  0.00023392490402329713
Epoch:  471  	Training Loss: 0.0002631350071169436
Test Loss:  0.0001685651805019006
Valid Loss:  0.00023375905584543943
Epoch:  472  	Training Loss: 0.0002629233058542013
Test Loss:  0.0001680554705671966
Valid Loss:  0.0002333251031814143
Epoch:  473  	Training Loss: 0.0002624231274239719
Test Loss:  0.00016759504796937108
Valid Loss:  0.00023289694217965007
Epoch:  474  	Training Loss: 0.00026193418307229877
Test Loss:  0.00016718366532586515
Valid Loss:  0.00023248090292327106
Epoch:  475  	Training Loss: 0.00026145894662477076
Test Loss:  0.00016680220142006874
Valid Loss:  0.000232072125072591
Epoch:  476  	Training Loss: 0.00026098673697561026
Test Loss:  0.0001664402661845088
Valid Loss:  0.00023166426399257034
 95%|█████████▌| 477/500 [05:27<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:27<00:07,  2.97it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:33<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:33<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:40<00:00,  2.99it/s]100%|██████████| 500/500 [05:40<00:00,  1.47it/s]
Epoch:  477  	Training Loss: 0.0002605229674372822
Test Loss:  0.0001660974812693894
Valid Loss:  0.00023125935695134103
Epoch:  478  	Training Loss: 0.00026006530970335007
Test Loss:  0.00016576959751546383
Valid Loss:  0.00023085391148924828
Epoch:  479  	Training Loss: 0.0002596102131064981
Test Loss:  0.0001654463994782418
Valid Loss:  0.00023045501438900828
Epoch:  480  	Training Loss: 0.00025916364393197
Test Loss:  0.0001651319325901568
Valid Loss:  0.00023005726689007133
Epoch:  481  	Training Loss: 0.000258721353020519
Test Loss:  0.00016481966304127127
Valid Loss:  0.00022966094547882676
Epoch:  482  	Training Loss: 0.00025828357320278883
Test Loss:  0.00016473123105242848
Valid Loss:  0.00022928413818590343
Epoch:  483  	Training Loss: 0.0002577681443654001
Test Loss:  0.00016458568279631436
Valid Loss:  0.000228922872338444
Epoch:  484  	Training Loss: 0.0002572934899944812
Test Loss:  0.0001643992291064933
Valid Loss:  0.00022857511066831648
Epoch:  485  	Training Loss: 0.0002568493946455419
Test Loss:  0.00016420141037087888
Valid Loss:  0.00022823158360552043
Epoch:  486  	Training Loss: 0.0002564308524597436
Test Loss:  0.00016397912986576557
Valid Loss:  0.0002278946922160685
Epoch:  487  	Training Loss: 0.00025602386449463665
Test Loss:  0.0001637565583223477
Valid Loss:  0.0002275568840559572
Epoch:  488  	Training Loss: 0.0002556222607381642
Test Loss:  0.00016353800310753286
Valid Loss:  0.00022722265566699207
Epoch:  489  	Training Loss: 0.0002552304067648947
Test Loss:  0.00016331156075466424
Valid Loss:  0.0002268899406772107
Epoch:  490  	Training Loss: 0.0002548482734709978
Test Loss:  0.00016308044723700732
Valid Loss:  0.00022655885550193489
Epoch:  491  	Training Loss: 0.00025447155348956585
Test Loss:  0.0001628451282158494
Valid Loss:  0.0002262339403387159
Epoch:  492  	Training Loss: 0.0002541026333346963
Test Loss:  0.0001621955307200551
Valid Loss:  0.0002258561144117266
Epoch:  493  	Training Loss: 0.00025373109383508563
Test Loss:  0.00016171467723324895
Valid Loss:  0.0002255088766105473
Epoch:  494  	Training Loss: 0.00025338662089779973
Test Loss:  0.0001613337080925703
Valid Loss:  0.00022518908372148871
Epoch:  495  	Training Loss: 0.0002530572528485209
Test Loss:  0.00016102317022159696
Valid Loss:  0.00022488206741400063
Epoch:  496  	Training Loss: 0.00025274045765399933
Test Loss:  0.00016074941959232092
Valid Loss:  0.00022458418970927596
Epoch:  497  	Training Loss: 0.0002524256706237793
Test Loss:  0.00016049909754656255
Valid Loss:  0.0002242993505205959
Epoch:  498  	Training Loss: 0.0002521153655834496
Test Loss:  0.00016026859520934522
Valid Loss:  0.00022402858303394169
Epoch:  499  	Training Loss: 0.00025181606179103255
Test Loss:  0.0001600605610292405
Valid Loss:  0.0002237592125311494
Epoch:  500  	Training Loss: 0.0002515253145247698
Test Loss:  0.000159868344780989
Valid Loss:  0.00022350209474097937
seed is  15
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.38it/s]  1%|          | 4/500 [00:00<00:30, 16.29it/s]  1%|          | 6/500 [00:00<00:30, 16.24it/s]  2%|▏         | 8/500 [00:00<00:30, 16.37it/s]  2%|▏         | 10/500 [00:00<00:29, 16.43it/s]  2%|▏         | 12/500 [00:00<00:30, 16.21it/s]  3%|▎         | 14/500 [00:00<00:30, 16.12it/s]  3%|▎         | 16/500 [00:00<00:30, 16.04it/s]  4%|▎         | 18/500 [00:01<00:29, 16.14it/s]  4%|▍         | 20/500 [00:01<00:29, 16.18it/s]  4%|▍         | 22/500 [00:01<00:29, 16.23it/s]  5%|▍         | 24/500 [00:01<00:29, 16.32it/s]  5%|▌         | 26/500 [00:01<00:28, 16.39it/s]  6%|▌         | 28/500 [00:01<00:28, 16.42it/s]  6%|▌         | 30/500 [00:01<00:28, 16.38it/s]  6%|▋         | 32/500 [00:01<00:28, 16.22it/s]  7%|▋         | 34/500 [00:02<00:28, 16.10it/s]  7%|▋         | 36/500 [00:02<00:28, 16.17it/s]  8%|▊         | 38/500 [00:02<00:28, 16.29it/s]  8%|▊         | 40/500 [00:02<00:28, 16.33it/s]  8%|▊         | 42/500 [00:02<00:28, 16.22it/s]  9%|▉         | 44/500 [00:02<00:28, 16.24it/s]  9%|▉         | 46/500 [00:02<00:27, 16.35it/s] 10%|▉         | 48/500 [00:02<00:27, 16.33it/s] 10%|█         | 50/500 [00:03<00:27, 16.34it/s] 10%|█         | 52/500 [00:03<00:27, 16.39it/s] 11%|█         | 54/500 [00:03<00:27, 16.45it/s] 11%|█         | 56/500 [00:03<00:26, 16.46it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.48it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.09it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.09it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.19it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.27it/s] 14%|█▎        | 68/500 [00:04<00:28, 15.17it/s] 14%|█▍        | 70/500 [00:04<00:30, 14.21it/s] 14%|█▍        | 72/500 [00:04<00:29, 14.42it/s] 15%|█▍        | 74/500 [00:04<00:29, 14.37it/s] 15%|█▌        | 76/500 [00:04<00:29, 14.35it/s] 16%|█▌        | 78/500 [00:04<00:28, 14.94it/s] 16%|█▌        | 80/500 [00:05<00:27, 15.41it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.72it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.97it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.18it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.32it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.33it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.33it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.34it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.37it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.39it/s] 20%|██        | 100/500 [00:06<00:24, 16.43it/s] 20%|██        | 102/500 [00:06<00:24, 16.49it/s] 21%|██        | 104/500 [00:06<00:23, 16.55it/s] 21%|██        | 106/500 [00:06<00:23, 16.53it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.44it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.49it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.49it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.53it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.57it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.60it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.63it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.53it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.39it/s]Epoch:  1  	Training Loss: 0.11484208703041077
Test Loss:  2080.34228515625
Valid Loss:  2083.58056640625
Epoch:  2  	Training Loss: 2083.48095703125
Test Loss:  82950766985216.0
Valid Loss:  82230571433984.0
Epoch:  3  	Training Loss: 82400306528256.0
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:23, 16.10it/s] 26%|██▌       | 128/500 [00:07<00:23, 16.03it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.12it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.28it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.36it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.44it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.44it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.30it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.20it/s] 29%|██▉       | 144/500 [00:08<00:22, 16.06it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.10it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.93it/s] 30%|███       | 150/500 [00:09<00:21, 16.16it/s] 30%|███       | 152/500 [00:09<00:22, 15.45it/s] 31%|███       | 154/500 [00:09<00:22, 15.71it/s] 31%|███       | 156/500 [00:09<00:21, 15.95it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.20it/s] 32%|███▏      | 160/500 [00:09<00:21, 16.16it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.23it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.31it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.42it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.48it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.38it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.31it/s] 35%|███▍      | 174/500 [00:10<00:21, 15.45it/s] 35%|███▌      | 176/500 [00:10<00:21, 15.08it/s] 36%|███▌      | 178/500 [00:11<00:22, 14.11it/s] 36%|███▌      | 180/500 [00:11<00:23, 13.59it/s] 36%|███▋      | 182/500 [00:11<00:23, 13.26it/s] 37%|███▋      | 184/500 [00:11<00:22, 13.90it/s] 37%|███▋      | 186/500 [00:11<00:23, 13.29it/s] 38%|███▊      | 188/500 [00:11<00:24, 12.87it/s] 38%|███▊      | 190/500 [00:12<00:22, 13.79it/s] 38%|███▊      | 192/500 [00:12<00:21, 14.40it/s] 39%|███▉      | 194/500 [00:12<00:20, 14.94it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.39it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.58it/s] 40%|████      | 200/500 [00:12<00:19, 15.76it/s] 40%|████      | 202/500 [00:12<00:18, 15.94it/s] 41%|████      | 204/500 [00:12<00:18, 15.97it/s] 41%|████      | 206/500 [00:12<00:18, 16.07it/s] 42%|████▏     | 208/500 [00:13<00:18, 16.17it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.17it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.25it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.30it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.37it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.43it/s] 44%|████▍     | 220/500 [00:13<00:16, 16.48it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.50it/s] 45%|████▍     | 224/500 [00:14<00:16, 16.52it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.56it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.38it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.21it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.15it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.08it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.13it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.21it/s] 48%|████▊     | 240/500 [00:15<00:15, 16.32it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.39it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.46it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.41it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.27it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.23it/s] 50%|█████     | 252/500 [00:15<00:15, 16.07it/s] 51%|█████     | 254/500 [00:15<00:15, 16.14it/s] 51%|█████     | 256/500 [00:16<00:14, 16.30it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.99it/s] 52%|█████▏    | 260/500 [00:16<00:15, 15.87it/s] 52%|█████▏    | 262/500 [00:16<00:15, 15.81it/s] 53%|█████▎    | 264/500 [00:16<00:15, 15.71it/s] 53%|█████▎    | 266/500 [00:16<00:16, 14.53it/s] 54%|█████▎    | 268/500 [00:16<00:16, 13.84it/s] 54%|█████▍    | 270/500 [00:17<00:16, 13.92it/s] 54%|█████▍    | 272/500 [00:17<00:15, 14.63it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.15it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.50it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.41it/s] 56%|█████▌    | 280/500 [00:17<00:14, 15.65it/s] 56%|█████▋    | 282/500 [00:17<00:13, 15.76it/s] 57%|█████▋    | 284/500 [00:17<00:13, 15.89it/s] 57%|█████▋    | 286/500 [00:18<00:14, 14.99it/s] 58%|█████▊    | 288/500 [00:18<00:14, 14.22it/s] 58%|█████▊    | 290/500 [00:18<00:14, 14.77it/s] 58%|█████▊    | 292/500 [00:18<00:13, 15.23it/s] 59%|█████▉    | 294/500 [00:18<00:13, 15.45it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.77it/s] 60%|█████▉    | 298/500 [00:18<00:12, 15.85it/s] 60%|██████    | 300/500 [00:18<00:12, 15.89it/s] 60%|██████    | 302/500 [00:19<00:12, 16.02it/s] 61%|██████    | 304/500 [00:19<00:12, 16.14it/s] 61%|██████    | 306/500 [00:19<00:11, 16.23it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.16it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.29it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.32it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.40it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.41it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.41it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.36it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.38it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.43it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.50it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.51it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.50it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.52it/s] 67%|██████▋   | 334/500 [00:21<00:10, 16.52it/s] 67%|██████▋   | 336/500 [00:21<00:10, 16.31it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.29it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.29it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.19it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.33it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.44it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.48it/s] 70%|███████   | 350/500 [00:22<00:09, 16.46it/s] 70%|███████   | 352/500 [00:22<00:08, 16.46it/s] 71%|███████   | 354/500 [00:22<00:08, 16.49it/s] 71%|███████   | 356/500 [00:22<00:08, 16.47it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.18it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.10it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.17it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.21it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.18it/s] 74%|███████▎  | 368/500 [00:23<00:08, 16.07it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.85it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.03it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.03it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.08it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.15it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.26it/s] 76%|███████▋  | 382/500 [00:23<00:07, 15.75it/s] 77%|███████▋  | 384/500 [00:24<00:07, 14.57it/s] 77%|███████▋  | 386/500 [00:24<00:07, 14.36it/s] 78%|███████▊  | 388/500 [00:24<00:07, 14.89it/s] 78%|███████▊  | 390/500 [00:24<00:07, 15.22it/s] 78%|███████▊  | 392/500 [00:24<00:06, 15.61it/s] 79%|███████▉  | 394/500 [00:24<00:06, 15.89it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.07it/s] 80%|███████▉  | 398/500 [00:25<00:06, 16.19it/s] 80%|████████  | 400/500 [00:25<00:06, 16.29it/s] 80%|████████  | 402/500 [00:25<00:05, 16.34it/s] 81%|████████  | 404/500 [00:25<00:05, 16.27it/s] 81%|████████  | 406/500 [00:25<00:05, 16.35it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.36it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.37it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.36it/s] 83%|████████▎ | 414/500 [00:26<00:05, 16.40it/s] 83%|████████▎ | 416/500 [00:26<00:05, 16.33it/s] 84%|████████▎ | 418/500 [00:26<00:05, 16.31it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.31it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.35it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.38it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.42it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.49it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.49it/s] 86%|████████▋ | 432/500 [00:27<00:04, 16.53it/s] 87%|████████▋ | 434/500 [00:27<00:03, 16.54it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.59it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.54it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.54it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.53it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.54it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.37it/s] 90%|████████▉ | 448/500 [00:28<00:03, 16.04it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.05it/s] 90%|█████████ | 452/500 [00:28<00:03, 15.97it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.09it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.21it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.30it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.29it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.35it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.23it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.21it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.19it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.17it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.23it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.29it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.21it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.03it/s] 96%|█████████▌| 480/500 [00:30<00:01, 14.83it/s] 96%|█████████▋| 482/500 [00:30<00:01, 15.19it/s] 97%|█████████▋| 484/500 [00:30<00:01, 15.54it/s] 97%|█████████▋| 486/500 [00:30<00:00, 15.71it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.86it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.02it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.14it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.16it/s] 99%|█████████▉| 496/500 [00:31<00:00, 16.08it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 15.64it/s]100%|██████████| 500/500 [00:31<00:00, 15.78it/s]100%|██████████| 500/500 [00:31<00:00, 15.95it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  15
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:52,  6.24s/it]  1%|          | 3/500 [00:06<13:49,  1.67s/it]  1%|          | 5/500 [00:06<06:58,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:44,  1.32s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  2.99it/s]  4%|▍         | 21/500 [00:19<09:24,  1.18s/it]  5%|▍         | 23/500 [00:19<06:40,  1.19it/s]  5%|▌         | 25/500 [00:20<04:47,  1.65it/s]  5%|▌         | 27/500 [00:20<03:29,  2.26it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:08,  1.17s/it]  7%|▋         | 33/500 [00:26<06:32,  1.19it/s]  7%|▋         | 35/500 [00:26<04:42,  1.64it/s]  7%|▋         | 37/500 [00:26<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<08:54,  1.16s/it]  9%|▊         | 43/500 [00:33<06:22,  1.19it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:28,  3.03it/s] 10%|█         | 51/500 [00:40<08:47,  1.17s/it] 11%|█         | 53/500 [00:40<06:17,  1.18it/s] 11%|█         | 55/500 [00:40<04:32,  1.63it/s] 11%|█▏        | 57/500 [00:40<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:40<02:30,  2.92it/s] 12%|█▏        | 61/500 [00:46<08:36,  1.18s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:14,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:23,  3.00it/s] 14%|█▍        | 71/500 [00:53<08:21,  1.17s/it]Epoch:  1  	Training Loss: 0.11484208703041077
Test Loss:  410.5480651855469
Valid Loss:  405.1714172363281
Epoch:  2  	Training Loss: 407.3975524902344
Test Loss:  3.2279906272888184
Valid Loss:  3.192017078399658
Epoch:  3  	Training Loss: 3.2270727157592773
Test Loss:  2.768052577972412
Valid Loss:  2.737017869949341
Epoch:  4  	Training Loss: 2.767845630645752
Test Loss:  2.373767614364624
Valid Loss:  2.3469903469085693
Epoch:  5  	Training Loss: 2.374124050140381
Test Loss:  2.035775661468506
Valid Loss:  2.01267147064209
Epoch:  6  	Training Loss: 2.036573648452759
Test Loss:  1.7460496425628662
Valid Loss:  1.7261159420013428
Epoch:  7  	Training Loss: 1.7471880912780762
Test Loss:  1.4977045059204102
Valid Loss:  1.4805090427398682
Epoch:  8  	Training Loss: 1.4991010427474976
Test Loss:  1.284862995147705
Valid Loss:  1.2700557708740234
Epoch:  9  	Training Loss: 1.2864776849746704
Test Loss:  1.1031444072723389
Valid Loss:  1.0906132459640503
Epoch:  10  	Training Loss: 1.1051526069641113
Test Loss:  0.948138952255249
Valid Loss:  0.9375899434089661
Epoch:  11  	Training Loss: 0.9503644704818726
Test Loss:  0.8153988122940063
Valid Loss:  0.8065153360366821
Epoch:  12  	Training Loss: 0.8177949786186218
Test Loss:  0.7242693901062012
Valid Loss:  0.7165284156799316
Epoch:  13  	Training Loss: 0.7267608642578125
Test Loss:  0.6438085436820984
Valid Loss:  0.6370868682861328
Epoch:  14  	Training Loss: 0.6463922262191772
Test Loss:  0.572974681854248
Valid Loss:  0.5670962333679199
Epoch:  15  	Training Loss: 0.5755733847618103
Test Loss:  0.5101313591003418
Valid Loss:  0.5049973726272583
Epoch:  16  	Training Loss: 0.5127170085906982
Test Loss:  0.4543322026729584
Valid Loss:  0.44985032081604004
Epoch:  17  	Training Loss: 0.4568812847137451
Test Loss:  0.40476709604263306
Valid Loss:  0.40086954832077026
Epoch:  18  	Training Loss: 0.40727174282073975
Test Loss:  0.3607358932495117
Valid Loss:  0.3573572337627411
Epoch:  19  	Training Loss: 0.36318856477737427
Test Loss:  0.3216160237789154
Valid Loss:  0.3187018632888794
Epoch:  20  	Training Loss: 0.3240111172199249
Test Loss:  0.28685152530670166
Valid Loss:  0.284354031085968
Epoch:  21  	Training Loss: 0.2891872525215149
Test Loss:  0.2559548616409302
Valid Loss:  0.25383132696151733
Epoch:  22  	Training Loss: 0.25822991132736206
Test Loss:  0.2270427942276001
Valid Loss:  0.22529399394989014
Epoch:  23  	Training Loss: 0.2292732149362564
Test Loss:  0.20153550803661346
Valid Loss:  0.20012035965919495
Epoch:  24  	Training Loss: 0.20371773838996887
Test Loss:  0.17902696132659912
Valid Loss:  0.17790906131267548
Epoch:  25  	Training Loss: 0.18115848302841187
Test Loss:  0.15916050970554352
Valid Loss:  0.15830717980861664
Epoch:  26  	Training Loss: 0.161239355802536
Test Loss:  0.14162185788154602
Valid Loss:  0.14100462198257446
Epoch:  27  	Training Loss: 0.14364701509475708
Test Loss:  0.12613484263420105
Valid Loss:  0.12572842836380005
Epoch:  28  	Training Loss: 0.12810608744621277
Test Loss:  0.11245661973953247
Valid Loss:  0.11223850399255753
Epoch:  29  	Training Loss: 0.11437413841485977
Test Loss:  0.1003732979297638
Valid Loss:  0.10032351315021515
Epoch:  30  	Training Loss: 0.10223765671253204
Test Loss:  0.08969678729772568
Valid Loss:  0.08979738503694534
Epoch:  31  	Training Loss: 0.09150883555412292
Test Loss:  0.08026105165481567
Valid Loss:  0.08049620687961578
Epoch:  32  	Training Loss: 0.08202190697193146
Test Loss:  0.07170431315898895
Valid Loss:  0.07205890119075775
Epoch:  33  	Training Loss: 0.07341039180755615
Test Loss:  0.0641578957438469
Valid Loss:  0.06461937725543976
Epoch:  34  	Training Loss: 0.06581136584281921
Test Loss:  0.05750167369842529
Valid Loss:  0.05805874615907669
Epoch:  35  	Training Loss: 0.05910462886095047
Test Loss:  0.051629673689603806
Valid Loss:  0.05227226763963699
Epoch:  36  	Training Loss: 0.05318432301282883
Test Loss:  0.046448588371276855
Valid Loss:  0.047167688608169556
Epoch:  37  	Training Loss: 0.047957099974155426
Test Loss:  0.04187614470720291
Valid Loss:  0.042663708329200745
Epoch:  38  	Training Loss: 0.043340642005205154
Test Loss:  0.037839941680431366
Valid Loss:  0.03868873417377472
Epoch:  39  	Training Loss: 0.03926251828670502
Test Loss:  0.034276172518730164
Valid Loss:  0.03517966344952583
Epoch:  40  	Training Loss: 0.03565884754061699
Test Loss:  0.03112858161330223
Valid Loss:  0.032080937176942825
Epoch:  41  	Training Loss: 0.03247332200407982
Test Loss:  0.028347671031951904
Valid Loss:  0.02934364601969719
Epoch:  42  	Training Loss: 0.02965640276670456
Test Loss:  0.025913875550031662
Valid Loss:  0.02694788947701454
Epoch:  43  	Training Loss: 0.027188412845134735
Test Loss:  0.023758139461278915
Valid Loss:  0.024826057255268097
Epoch:  44  	Training Loss: 0.02500024065375328
Test Loss:  0.021847907453775406
Valid Loss:  0.022945981472730637
Epoch:  45  	Training Loss: 0.023059241473674774
Test Loss:  0.020169399678707123
Valid Loss:  0.021316008642315865
Epoch:  46  	Training Loss: 0.021368877962231636
Test Loss:  0.018786495551466942
Valid Loss:  0.01997404731810093
Epoch:  47  	Training Loss: 0.0200362429022789
Test Loss:  0.017702069133520126
Valid Loss:  0.018942704424262047
Epoch:  48  	Training Loss: 0.019027119502425194
Test Loss:  0.01687045954167843
Valid Loss:  0.018188059329986572
Epoch:  49  	Training Loss: 0.01822800561785698
Test Loss:  0.016169145703315735
Valid Loss:  0.01760062947869301
Epoch:  50  	Training Loss: 0.01754361018538475
Test Loss:  0.015587596222758293
Valid Loss:  0.017121927812695503
Epoch:  51  	Training Loss: 0.016976602375507355
Test Loss:  0.015099255368113518
Valid Loss:  0.016704242676496506
Epoch:  52  	Training Loss: 0.016493771225214005
Test Loss:  0.01473120879381895
Valid Loss:  0.01637553609907627
Epoch:  53  	Training Loss: 0.016127625480294228
Test Loss:  0.014412198215723038
Valid Loss:  0.016089096665382385
Epoch:  54  	Training Loss: 0.015806427225470543
Test Loss:  0.014120719395577908
Valid Loss:  0.015824954956769943
Epoch:  55  	Training Loss: 0.015513402409851551
Test Loss:  0.013855664990842342
Valid Loss:  0.015580800361931324
Epoch:  56  	Training Loss: 0.0152436513453722
Test Loss:  0.013611292466521263
Valid Loss:  0.015355043113231659
Epoch:  57  	Training Loss: 0.014996559359133244
Test Loss:  0.013381840661168098
Valid Loss:  0.015139427036046982
Epoch:  58  	Training Loss: 0.014763394370675087
Test Loss:  0.013167688623070717
Valid Loss:  0.014935574494302273
Epoch:  59  	Training Loss: 0.014545506797730923
Test Loss:  0.012964078225195408
Valid Loss:  0.014740560203790665
Epoch:  60  	Training Loss: 0.014337747357785702
Test Loss:  0.012769331224262714
Valid Loss:  0.014553804881870747
Epoch:  61  	Training Loss: 0.014138370752334595
Test Loss:  0.012582212686538696
Valid Loss:  0.01437324471771717
Epoch:  62  	Training Loss: 0.013946077786386013
Test Loss:  0.012401042506098747
Valid Loss:  0.014197438955307007
Epoch:  63  	Training Loss: 0.013759221881628036
Test Loss:  0.012226967141032219
Valid Loss:  0.014027336612343788
Epoch:  64  	Training Loss: 0.013579374179244041
Test Loss:  0.012059454806149006
Valid Loss:  0.013862606137990952
Epoch:  65  	Training Loss: 0.01340584084391594
Test Loss:  0.011898103170096874
Valid Loss:  0.013702831231057644
Epoch:  66  	Training Loss: 0.013238159008324146
Test Loss:  0.01174214482307434
Valid Loss:  0.013547787442803383
Epoch:  67  	Training Loss: 0.013075629249215126
Test Loss:  0.01159127987921238
Valid Loss:  0.013397179543972015
Epoch:  68  	Training Loss: 0.012918036431074142
Test Loss:  0.011445613577961922
Valid Loss:  0.013250772841274738
Epoch:  69  	Training Loss: 0.012765317223966122
Test Loss:  0.011304495856165886
Valid Loss:  0.013108333572745323
Epoch:  70  	Training Loss: 0.012616991065442562
Test Loss:  0.011168019846081734
Valid Loss:  0.012969630770385265
Epoch:  71  	Training Loss: 0.012472953647375107
Test Loss:  0.011035589501261711
Valid Loss:  0.012834500521421432
Epoch:  72  	Training Loss: 0.01233280636370182
Test Loss:  0.01090496126562357
Valid Loss:  0.012700533494353294
Epoch:  73  	Training Loss: 0.012194222770631313
Test Loss:  15%|█▍        | 73/500 [00:53<05:58,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:15,  1.18s/it] 17%|█▋        | 83/500 [01:00<05:53,  1.18it/s] 17%|█▋        | 85/500 [01:00<04:14,  1.63it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:17,  3.00it/s] 18%|█▊        | 91/500 [01:07<07:55,  1.16s/it] 19%|█▊        | 93/500 [01:07<05:40,  1.20it/s] 19%|█▉        | 95/500 [01:07<04:07,  1.63it/s] 19%|█▉        | 97/500 [01:07<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:07<02:13,  3.00it/s] 20%|██        | 101/500 [01:14<07:47,  1.17s/it] 21%|██        | 103/500 [01:14<05:34,  1.19it/s] 21%|██        | 105/500 [01:14<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:14<02:12,  2.95it/s] 22%|██▏       | 111/500 [01:21<07:37,  1.18s/it] 23%|██▎       | 113/500 [01:21<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:21<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:27<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:21,  1.17it/s] 25%|██▌       | 125/500 [01:28<03:51,  1.62it/s] 25%|██▌       | 127/500 [01:28<02:49,  2.19it/s] 26%|██▌       | 129/500 [01:28<02:07,  2.91it/s] 26%|██▌       | 131/500 [01:34<07:12,  1.17s/it] 27%|██▋       | 133/500 [01:34<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:42,  1.64it/s] 27%|██▋       | 137/500 [01:35<02:42,  2.24it/s] 28%|██▊       | 139/500 [01:35<02:01,  2.98it/s] 28%|██▊       | 141/500 [01:41<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:41<05:00,  1.19it/s] 0.010778090916574001
Valid Loss:  0.012569872662425041
Epoch:  74  	Training Loss: 0.012059224769473076
Test Loss:  0.010654766112565994
Valid Loss:  0.012442342936992645
Epoch:  75  	Training Loss: 0.01192764937877655
Test Loss:  0.010534841567277908
Valid Loss:  0.012317835353314877
Epoch:  76  	Training Loss: 0.011799344792962074
Test Loss:  0.010418147780001163
Valid Loss:  0.012196185998618603
Epoch:  77  	Training Loss: 0.01167417410761118
Test Loss:  0.010304553434252739
Valid Loss:  0.012077268213033676
Epoch:  78  	Training Loss: 0.011551978066563606
Test Loss:  0.010193887166678905
Valid Loss:  0.011960973963141441
Epoch:  79  	Training Loss: 0.011432640254497528
Test Loss:  0.01008603721857071
Valid Loss:  0.011847185902297497
Epoch:  80  	Training Loss: 0.011316030286252499
Test Loss:  0.009980859234929085
Valid Loss:  0.011735789477825165
Epoch:  81  	Training Loss: 0.011202020570635796
Test Loss:  0.009878233075141907
Valid Loss:  0.011626699939370155
Epoch:  82  	Training Loss: 0.011090530082583427
Test Loss:  0.009778889827430248
Valid Loss:  0.011520528234541416
Epoch:  83  	Training Loss: 0.010982278734445572
Test Loss:  0.00968187116086483
Valid Loss:  0.011416414752602577
Epoch:  84  	Training Loss: 0.010876292362809181
Test Loss:  0.009587009437382221
Valid Loss:  0.011314251460134983
Epoch:  85  	Training Loss: 0.010772470384836197
Test Loss:  0.009494238533079624
Valid Loss:  0.011213969439268112
Epoch:  86  	Training Loss: 0.010670694522559643
Test Loss:  0.009403516538441181
Valid Loss:  0.011115510016679764
Epoch:  87  	Training Loss: 0.01057091448456049
Test Loss:  0.009314721450209618
Valid Loss:  0.011018783785402775
Epoch:  88  	Training Loss: 0.010473089292645454
Test Loss:  0.009227696806192398
Valid Loss:  0.01092394720762968
Epoch:  89  	Training Loss: 0.010377204045653343
Test Loss:  0.009142468683421612
Valid Loss:  0.01083071157336235
Epoch:  90  	Training Loss: 0.010283091105520725
Test Loss:  0.009058978408575058
Valid Loss:  0.01073905173689127
Epoch:  91  	Training Loss: 0.010190701112151146
Test Loss:  0.008977079764008522
Valid Loss:  0.010649096220731735
Epoch:  92  	Training Loss: 0.010100107640028
Test Loss:  0.008897896856069565
Valid Loss:  0.010562017560005188
Epoch:  93  	Training Loss: 0.01001245342195034
Test Loss:  0.00882028043270111
Valid Loss:  0.010476330295205116
Epoch:  94  	Training Loss: 0.009926353581249714
Test Loss:  0.008744137361645699
Valid Loss:  0.01039199624210596
Epoch:  95  	Training Loss: 0.00984171498566866
Test Loss:  0.008669329807162285
Valid Loss:  0.010309165343642235
Epoch:  96  	Training Loss: 0.009758654050529003
Test Loss:  0.008595934137701988
Valid Loss:  0.010227585211396217
Epoch:  97  	Training Loss: 0.00967700406908989
Test Loss:  0.008523862808942795
Valid Loss:  0.010147235356271267
Epoch:  98  	Training Loss: 0.009596709161996841
Test Loss:  0.008453045040369034
Valid Loss:  0.010068049654364586
Epoch:  99  	Training Loss: 0.00951770693063736
Test Loss:  0.008383436128497124
Valid Loss:  0.00999000109732151
Epoch:  100  	Training Loss: 0.009439950808882713
Test Loss:  0.008314988575875759
Valid Loss:  0.009913014248013496
Epoch:  101  	Training Loss: 0.009363390505313873
Test Loss:  0.008247677236795425
Valid Loss:  0.009837083518505096
Epoch:  102  	Training Loss: 0.009288005530834198
Test Loss:  0.008180676028132439
Valid Loss:  0.009761027991771698
Epoch:  103  	Training Loss: 0.009212825447320938
Test Loss:  0.008114732801914215
Valid Loss:  0.009686179459095001
Epoch:  104  	Training Loss: 0.009138827212154865
Test Loss:  0.008049804717302322
Valid Loss:  0.009612301364541054
Epoch:  105  	Training Loss: 0.009065913036465645
Test Loss:  0.007985871285200119
Valid Loss:  0.009539596736431122
Epoch:  106  	Training Loss: 0.008994204923510551
Test Loss:  0.007922904565930367
Valid Loss:  0.00946778804063797
Epoch:  107  	Training Loss: 0.00892355665564537
Test Loss:  0.007860856130719185
Valid Loss:  0.009397093206644058
Epoch:  108  	Training Loss: 0.008854012005031109
Test Loss:  0.0077997129410505295
Valid Loss:  0.00932726077735424
Epoch:  109  	Training Loss: 0.008785424754023552
Test Loss:  0.007739461492747068
Valid Loss:  0.009258273988962173
Epoch:  110  	Training Loss: 0.008717771619558334
Test Loss:  0.007680063135921955
Valid Loss:  0.009190086275339127
Epoch:  111  	Training Loss: 0.008651001378893852
Test Loss:  0.0076214917935431
Valid Loss:  0.009122690185904503
Epoch:  112  	Training Loss: 0.008585109375417233
Test Loss:  0.007563096936792135
Valid Loss:  0.00905492715537548
Epoch:  113  	Training Loss: 0.008519214577972889
Test Loss:  0.007505455520004034
Valid Loss:  0.008987922221422195
Epoch:  114  	Training Loss: 0.00845413189381361
Test Loss:  0.007448568940162659
Valid Loss:  0.008921641856431961
Epoch:  115  	Training Loss: 0.008389843627810478
Test Loss:  0.00739239901304245
Valid Loss:  0.008856081403791904
Epoch:  116  	Training Loss: 0.008326328359544277
Test Loss:  0.007336927577853203
Valid Loss:  0.008791651576757431
Epoch:  117  	Training Loss: 0.008263648487627506
Test Loss:  0.007282163016498089
Valid Loss:  0.008728119544684887
Epoch:  118  	Training Loss: 0.008201837539672852
Test Loss:  0.007228068076074123
Valid Loss:  0.008665244095027447
Epoch:  119  	Training Loss: 0.008140729740262032
Test Loss:  0.00717462133616209
Valid Loss:  0.008603028021752834
Epoch:  120  	Training Loss: 0.008080331608653069
Test Loss:  0.00712182279676199
Valid Loss:  0.008541470393538475
Epoch:  121  	Training Loss: 0.008020756766200066
Test Loss:  0.007069703191518784
Valid Loss:  0.008481090888381004
Epoch:  122  	Training Loss: 0.007962120696902275
Test Loss:  0.00701823690906167
Valid Loss:  0.008421089500188828
Epoch:  123  	Training Loss: 0.007903985679149628
Test Loss:  0.006967322900891304
Valid Loss:  0.00836165715008974
Epoch:  124  	Training Loss: 0.007846513763070107
Test Loss:  0.006917010527104139
Valid Loss:  0.008303005248308182
Epoch:  125  	Training Loss: 0.007789953146129847
Test Loss:  0.006867345422506332
Valid Loss:  0.008245319128036499
Epoch:  126  	Training Loss: 0.007734236773103476
Test Loss:  0.0068182372488081455
Valid Loss:  0.008188176900148392
Epoch:  127  	Training Loss: 0.007679174654185772
Test Loss:  0.006770004518330097
Valid Loss:  0.008131776936352253
Epoch:  128  	Training Loss: 0.007624868303537369
Test Loss:  0.006722369231283665
Valid Loss:  0.008076109923422337
Epoch:  129  	Training Loss: 0.007571218069642782
Test Loss:  0.006675253622233868
Valid Loss:  0.008020962588489056
Epoch:  130  	Training Loss: 0.00751812569797039
Test Loss:  0.006628652103245258
Valid Loss:  0.007966296747326851
Epoch:  131  	Training Loss: 0.00746558140963316
Test Loss:  0.006582540925592184
Valid Loss:  0.007912145927548409
Epoch:  132  	Training Loss: 0.007413632236421108
Test Loss:  0.006536583416163921
Valid Loss:  0.007857825607061386
Epoch:  133  	Training Loss: 0.007361791096627712
Test Loss:  0.006491080857813358
Valid Loss:  0.007803980261087418
Epoch:  134  	Training Loss: 0.007310465909540653
Test Loss:  0.006446049548685551
Valid Loss:  0.007750612683594227
Epoch:  135  	Training Loss: 0.007259625941514969
Test Loss:  0.006401446182280779
Valid Loss:  0.007697679568082094
Epoch:  136  	Training Loss: 0.007209279108792543
Test Loss:  0.006357284728437662
Valid Loss:  0.007645209785550833
Epoch:  137  	Training Loss: 0.007159401196986437
Test Loss:  0.006313536316156387
Valid Loss:  0.007593199610710144
Epoch:  138  	Training Loss: 0.007110006641596556
Test Loss:  0.006270220503211021
Valid Loss:  0.007541936822235584
Epoch:  139  	Training Loss: 0.007061107084155083
Test Loss:  0.006227415986359119
Valid Loss:  0.007491570431739092
Epoch:  140  	Training Loss: 0.007013025227934122
Test Loss:  0.0061851139180362225
Valid Loss:  0.007442014757543802
Epoch:  141  	Training Loss: 0.006965629756450653
Test Loss:  0.006143282167613506
Valid Loss:  0.007393070496618748
Epoch:  142  	Training Loss: 0.006918787956237793
Test Loss:  0.006101252976804972
Valid Loss:  0.00734355952590704
Epoch:  143  	Training Loss: 0.006871732883155346
Test Loss:  0.00605968339368701
Valid Loss:  0.007294650189578533
 29%|██▉       | 145/500 [01:41<03:36,  1.64it/s] 29%|██▉       | 147/500 [01:41<02:37,  2.24it/s] 30%|██▉       | 149/500 [01:42<01:56,  3.02it/s] 30%|███       | 151/500 [01:48<06:49,  1.17s/it] 31%|███       | 153/500 [01:48<04:52,  1.19it/s] 31%|███       | 155/500 [01:48<03:31,  1.63it/s] 31%|███▏      | 157/500 [01:48<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:48<01:54,  2.99it/s] 32%|███▏      | 161/500 [01:55<06:33,  1.16s/it] 33%|███▎      | 163/500 [01:55<04:41,  1.20it/s] 33%|███▎      | 165/500 [01:55<03:22,  1.65it/s] 33%|███▎      | 167/500 [01:55<02:27,  2.25it/s] 34%|███▍      | 169/500 [01:55<01:50,  3.01it/s] 34%|███▍      | 171/500 [02:01<06:25,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:35,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:08<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:08<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.23it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:15<06:04,  1.18s/it] 39%|███▊      | 193/500 [02:15<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:15<03:06,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.00it/s] 40%|████      | 201/500 [02:22<05:56,  1.19s/it] 41%|████      | 203/500 [02:22<04:13,  1.17it/s] 41%|████      | 205/500 [02:22<03:02,  1.62it/s] 41%|████▏     | 207/500 [02:22<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:23<01:37,  2.97it/s] 42%|████▏     | 211/500 [02:29<05:43,  1.19s/it] 43%|████▎     | 213/500 [02:29<04:05,  1.17it/s]Epoch:  144  	Training Loss: 0.0068252207711339
Test Loss:  0.006018504034727812
Valid Loss:  0.0072461399249732494
Epoch:  145  	Training Loss: 0.006779131479561329
Test Loss:  0.005977698601782322
Valid Loss:  0.007198116276413202
Epoch:  146  	Training Loss: 0.006733460817486048
Test Loss:  0.005937348119914532
Valid Loss:  0.007150639779865742
Epoch:  147  	Training Loss: 0.006688197609037161
Test Loss:  0.0058975438587367535
Valid Loss:  0.007103542797267437
Epoch:  148  	Training Loss: 0.006643341854214668
Test Loss:  0.005858117714524269
Valid Loss:  0.007056818343698978
Epoch:  149  	Training Loss: 0.006598878186196089
Test Loss:  0.005819024983793497
Valid Loss:  0.007010468281805515
Epoch:  150  	Training Loss: 0.0065548052079975605
Test Loss:  0.0057802931405603886
Valid Loss:  0.006964477244764566
Epoch:  151  	Training Loss: 0.006511151324957609
Test Loss:  0.005741945467889309
Valid Loss:  0.006919045001268387
Epoch:  152  	Training Loss: 0.006467970088124275
Test Loss:  0.005703704431653023
Valid Loss:  0.006873343139886856
Epoch:  153  	Training Loss: 0.006424837280064821
Test Loss:  0.005665795877575874
Valid Loss:  0.006828004028648138
Epoch:  154  	Training Loss: 0.006382076535373926
Test Loss:  0.00562821002677083
Valid Loss:  0.006783020682632923
Epoch:  155  	Training Loss: 0.006339672952890396
Test Loss:  0.005591101013123989
Valid Loss:  0.00673837773501873
Epoch:  156  	Training Loss: 0.006297670770436525
Test Loss:  0.005554450675845146
Valid Loss:  0.006694283802062273
Epoch:  157  	Training Loss: 0.0062561300583183765
Test Loss:  0.005518133752048016
Valid Loss:  0.006650717929005623
Epoch:  158  	Training Loss: 0.00621503172442317
Test Loss:  0.005482122302055359
Valid Loss:  0.006607496179640293
Epoch:  159  	Training Loss: 0.00617428682744503
Test Loss:  0.005446424707770348
Valid Loss:  0.006564607843756676
Epoch:  160  	Training Loss: 0.0061338795349001884
Test Loss:  0.00541103258728981
Valid Loss:  0.0065220315009355545
Epoch:  161  	Training Loss: 0.006093804724514484
Test Loss:  0.005375928245484829
Valid Loss:  0.00647978950291872
Epoch:  162  	Training Loss: 0.006054060533642769
Test Loss:  0.005340727046132088
Valid Loss:  0.006437008269131184
Epoch:  163  	Training Loss: 0.006014111451804638
Test Loss:  0.0053058043122291565
Valid Loss:  0.006394557189196348
Epoch:  164  	Training Loss: 0.005974479019641876
Test Loss:  0.005271183326840401
Valid Loss:  0.006352422758936882
Epoch:  165  	Training Loss: 0.0059351734817028046
Test Loss:  0.005236825440078974
Valid Loss:  0.0063106101006269455
Epoch:  166  	Training Loss: 0.005896176677197218
Test Loss:  0.005202749744057655
Valid Loss:  0.006269135046750307
Epoch:  167  	Training Loss: 0.00585749838501215
Test Loss:  0.005168951116502285
Valid Loss:  0.006227967329323292
Epoch:  168  	Training Loss: 0.005819127894937992
Test Loss:  0.005135419778525829
Valid Loss:  0.006187123246490955
Epoch:  169  	Training Loss: 0.005781067535281181
Test Loss:  0.005102166905999184
Valid Loss:  0.0061465902253985405
Epoch:  170  	Training Loss: 0.005743380635976791
Test Loss:  0.005069226957857609
Valid Loss:  0.006106776185333729
Epoch:  171  	Training Loss: 0.005706176161766052
Test Loss:  0.005036594346165657
Valid Loss:  0.00606745108962059
Epoch:  172  	Training Loss: 0.005669343285262585
Test Loss:  0.005003029480576515
Valid Loss:  0.006026990711688995
Epoch:  173  	Training Loss: 0.005631531588733196
Test Loss:  0.00496975751593709
Valid Loss:  0.005986829288303852
Epoch:  174  	Training Loss: 0.0055940281599760056
Test Loss:  0.004936763551086187
Valid Loss:  0.0059469775296747684
Epoch:  175  	Training Loss: 0.005556829273700714
Test Loss:  0.00490402989089489
Valid Loss:  0.00590742751955986
Epoch:  176  	Training Loss: 0.00551993353292346
Test Loss:  0.004871578887104988
Valid Loss:  0.005868181120604277
Epoch:  177  	Training Loss: 0.005483388900756836
Test Loss:  0.004839398432523012
Valid Loss:  0.005829590372741222
Epoch:  178  	Training Loss: 0.005447182804346085
Test Loss:  0.004807499703019857
Valid Loss:  0.005791478790342808
Epoch:  179  	Training Loss: 0.005411273799836636
Test Loss:  0.004775865934789181
Valid Loss:  0.005753666162490845
Epoch:  180  	Training Loss: 0.005375652574002743
Test Loss:  0.004744477570056915
Valid Loss:  0.00571613572537899
Epoch:  181  	Training Loss: 0.005340319126844406
Test Loss:  0.0047133383341133595
Valid Loss:  0.005678890272974968
Epoch:  182  	Training Loss: 0.0053052655421197414
Test Loss:  0.004682768136262894
Valid Loss:  0.005641903728246689
Epoch:  183  	Training Loss: 0.005270721856504679
Test Loss:  0.004652428440749645
Valid Loss:  0.005605200305581093
Epoch:  184  	Training Loss: 0.005236444063484669
Test Loss:  0.0046223234385252
Valid Loss:  0.005568784195929766
Epoch:  185  	Training Loss: 0.005202428437769413
Test Loss:  0.00459244754165411
Valid Loss:  0.005532638635486364
Epoch:  186  	Training Loss: 0.005168679170310497
Test Loss:  0.004562807269394398
Valid Loss:  0.005496765486896038
Epoch:  187  	Training Loss: 0.005135197192430496
Test Loss:  0.004533400759100914
Valid Loss:  0.005461174063384533
Epoch:  188  	Training Loss: 0.005102009512484074
Test Loss:  0.004504237789660692
Valid Loss:  0.005425988230854273
Epoch:  189  	Training Loss: 0.005069120787084103
Test Loss:  0.004475315101444721
Valid Loss:  0.005391077138483524
Epoch:  190  	Training Loss: 0.00503647793084383
Test Loss:  0.004446603357791901
Valid Loss:  0.005356409586966038
Epoch:  191  	Training Loss: 0.005004093050956726
Test Loss:  0.0044181132689118385
Valid Loss:  0.005322020035237074
Epoch:  192  	Training Loss: 0.004971958696842194
Test Loss:  0.004389439709484577
Valid Loss:  0.005287399049848318
Epoch:  193  	Training Loss: 0.004939615726470947
Test Loss:  0.004360983148217201
Valid Loss:  0.005253023002296686
Epoch:  194  	Training Loss: 0.004907526075839996
Test Loss:  0.00433275057002902
Valid Loss:  0.005218924023211002
Epoch:  195  	Training Loss: 0.004875689744949341
Test Loss:  0.004304737783968449
Valid Loss:  0.0051850806921720505
Epoch:  196  	Training Loss: 0.004844099283218384
Test Loss:  0.004276939667761326
Valid Loss:  0.005151485092937946
Epoch:  197  	Training Loss: 0.004812763072550297
Test Loss:  0.0042493888176977634
Valid Loss:  0.005118293687701225
Epoch:  198  	Training Loss: 0.00478172255679965
Test Loss:  0.00422204053029418
Valid Loss:  0.005085342563688755
Epoch:  199  	Training Loss: 0.0047509437426924706
Test Loss:  0.004194950684905052
Valid Loss:  0.00505277793854475
Epoch:  200  	Training Loss: 0.0047204275615513325
Test Loss:  0.004168152809143066
Valid Loss:  0.005020449869334698
Epoch:  201  	Training Loss: 0.004690153058618307
Test Loss:  0.004141553305089474
Valid Loss:  0.004988355562090874
Epoch:  202  	Training Loss: 0.004660104867070913
Test Loss:  0.004115196876227856
Valid Loss:  0.0049564591608941555
Epoch:  203  	Training Loss: 0.00463029695674777
Test Loss:  0.004089040216058493
Valid Loss:  0.004924800246953964
Epoch:  204  	Training Loss: 0.004600721411406994
Test Loss:  0.004063139203935862
Valid Loss:  0.004893370904028416
Epoch:  205  	Training Loss: 0.004571370780467987
Test Loss:  0.00403747009113431
Valid Loss:  0.004862220026552677
Epoch:  206  	Training Loss: 0.004542245529592037
Test Loss:  0.004011978395283222
Valid Loss:  0.00483146496117115
Epoch:  207  	Training Loss: 0.004513381980359554
Test Loss:  0.003986678086221218
Valid Loss:  0.004800925496965647
Epoch:  208  	Training Loss: 0.0044847335666418076
Test Loss:  0.003961580339819193
Valid Loss:  0.0047706132754683495
Epoch:  209  	Training Loss: 0.004456305410712957
Test Loss:  0.003936664201319218
Valid Loss:  0.004740521777421236
Epoch:  210  	Training Loss: 0.0044280970469117165
Test Loss:  0.003911944106221199
Valid Loss:  0.004710645414888859
Epoch:  211  	Training Loss: 0.004400099162012339
Test Loss:  0.0038874540477991104
Valid Loss:  0.004680988844484091
Epoch:  212  	Training Loss: 0.0043723080307245255
Test Loss:  0.0038632862269878387
Valid Loss:  0.004651605151593685
Epoch:  213  	Training Loss: 0.00434483215212822
Test Loss:  0.0038392976857721806
Valid Loss:  0.004622434265911579
 43%|████▎     | 215/500 [02:29<02:56,  1.62it/s] 43%|████▎     | 217/500 [02:29<02:07,  2.21it/s] 44%|████▍     | 219/500 [02:29<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:36<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:36<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:36<01:30,  3.00it/s] 46%|████▌     | 231/500 [02:43<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.23it/s] 48%|████▊     | 239/500 [02:43<01:27,  3.00it/s] 48%|████▊     | 241/500 [02:49<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:50<01:23,  2.99it/s] 50%|█████     | 251/500 [02:56<04:52,  1.17s/it] 51%|█████     | 253/500 [02:56<03:28,  1.19it/s] 51%|█████     | 255/500 [02:57<02:29,  1.64it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.24it/s] 52%|█████▏    | 259/500 [02:57<01:20,  3.01it/s] 52%|█████▏    | 261/500 [03:03<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:03<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:04<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:04<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:04<01:17,  2.96it/s] 54%|█████▍    | 271/500 [03:10<04:30,  1.18s/it] 55%|█████▍    | 273/500 [03:10<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:10<02:18,  1.63it/s] 55%|█████▌    | 277/500 [03:10<01:40,  2.23it/s] 56%|█████▌    | 279/500 [03:11<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:17<04:15,  1.17s/it]Epoch:  214  	Training Loss: 0.0043175676837563515
Test Loss:  0.003815452801063657
Valid Loss:  0.00459358561784029
Epoch:  215  	Training Loss: 0.0042905318550765514
Test Loss:  0.0037917839363217354
Valid Loss:  0.004564940929412842
Epoch:  216  	Training Loss: 0.004263692535459995
Test Loss:  0.0037682820111513138
Valid Loss:  0.004536500200629234
Epoch:  217  	Training Loss: 0.004237048793584108
Test Loss:  0.00374495517462492
Valid Loss:  0.004508261568844318
Epoch:  218  	Training Loss: 0.004210599698126316
Test Loss:  0.0037218069192022085
Valid Loss:  0.004480235278606415
Epoch:  219  	Training Loss: 0.004184355493634939
Test Loss:  0.003698822809383273
Valid Loss:  0.004452396184206009
Epoch:  220  	Training Loss: 0.004158297553658485
Test Loss:  0.0036760137882083654
Valid Loss:  0.00442475825548172
Epoch:  221  	Training Loss: 0.004132434725761414
Test Loss:  0.003653374034911394
Valid Loss:  0.004397318698465824
Epoch:  222  	Training Loss: 0.0041067637503147125
Test Loss:  0.0036304593086242676
Valid Loss:  0.004369717091321945
Epoch:  223  	Training Loss: 0.004080858081579208
Test Loss:  0.0036077171098440886
Valid Loss:  0.0043423352763056755
Epoch:  224  	Training Loss: 0.004055151250213385
Test Loss:  0.0035851546563208103
Valid Loss:  0.004315141122788191
Epoch:  225  	Training Loss: 0.004029631614685059
Test Loss:  0.0035627621691673994
Valid Loss:  0.004288137890398502
Epoch:  226  	Training Loss: 0.004004312679171562
Test Loss:  0.0035405373200774193
Valid Loss:  0.004261323716491461
Epoch:  227  	Training Loss: 0.003979180008172989
Test Loss:  0.003518487326800823
Valid Loss:  0.004234707914292812
Epoch:  228  	Training Loss: 0.003954234533011913
Test Loss:  0.0034965681843459606
Valid Loss:  0.00420837476849556
Epoch:  229  	Training Loss: 0.003929493948817253
Test Loss:  0.0034747994504868984
Valid Loss:  0.004182236269116402
Epoch:  230  	Training Loss: 0.0039049354381859303
Test Loss:  0.003453207202255726
Valid Loss:  0.004156281240284443
Epoch:  231  	Training Loss: 0.0038805571384727955
Test Loss:  0.0034317746758461
Valid Loss:  0.004130495712161064
Epoch:  232  	Training Loss: 0.003856363706290722
Test Loss:  0.003410465084016323
Valid Loss:  0.004104877822101116
Epoch:  233  	Training Loss: 0.003832322545349598
Test Loss:  0.0033893247600644827
Valid Loss:  0.004079447593539953
Epoch:  234  	Training Loss: 0.0038084588013589382
Test Loss:  0.0033683455549180508
Valid Loss:  0.0040541947819292545
Epoch:  235  	Training Loss: 0.003784777596592903
Test Loss:  0.0033475214149802923
Valid Loss:  0.004029122181236744
Epoch:  236  	Training Loss: 0.0037612724117934704
Test Loss:  0.0033268555998802185
Valid Loss:  0.004004219546914101
Epoch:  237  	Training Loss: 0.0037379430141299963
Test Loss:  0.0033063434530049562
Valid Loss:  0.003979496192187071
Epoch:  238  	Training Loss: 0.003714784048497677
Test Loss:  0.0032859807834029198
Valid Loss:  0.003954960033297539
Epoch:  239  	Training Loss: 0.003691797610372305
Test Loss:  0.0032657741103321314
Valid Loss:  0.003930577542632818
Epoch:  240  	Training Loss: 0.0036689795088022947
Test Loss:  0.00324572017416358
Valid Loss:  0.00390638317912817
Epoch:  241  	Training Loss: 0.0036463364958763123
Test Loss:  0.003225782886147499
Valid Loss:  0.003882443532347679
Epoch:  242  	Training Loss: 0.0036238636821508408
Test Loss:  0.0032060928642749786
Valid Loss:  0.003858750220388174
Epoch:  243  	Training Loss: 0.003601651405915618
Test Loss:  0.003186544869095087
Valid Loss:  0.003835218260064721
Epoch:  244  	Training Loss: 0.003579605370759964
Test Loss:  0.0031671549659222364
Valid Loss:  0.0038118474185466766
Epoch:  245  	Training Loss: 0.0035577204544097185
Test Loss:  0.0031478970777243376
Valid Loss:  0.0037886477075517178
Epoch:  246  	Training Loss: 0.003535992931574583
Test Loss:  0.003128788201138377
Valid Loss:  0.0037656060885638
Epoch:  247  	Training Loss: 0.003514424432069063
Test Loss:  0.0031098159961402416
Valid Loss:  0.003742724657058716
Epoch:  248  	Training Loss: 0.00349301565438509
Test Loss:  0.0030909786000847816
Valid Loss:  0.003720012493431568
Epoch:  249  	Training Loss: 0.0034717670641839504
Test Loss:  0.0030722857918590307
Valid Loss:  0.0036974516697227955
Epoch:  250  	Training Loss: 0.0034506660886108875
Test Loss:  0.003053725929930806
Valid Loss:  0.0036750598810613155
Epoch:  251  	Training Loss: 0.003429724834859371
Test Loss:  0.0030353034380823374
Valid Loss:  0.0036528147757053375
Epoch:  252  	Training Loss: 0.0034089325927197933
Test Loss:  0.0030172390397638083
Valid Loss:  0.0036309051793068647
Epoch:  253  	Training Loss: 0.0033885021694004536
Test Loss:  0.002999290358275175
Valid Loss:  0.0036091564688831568
Epoch:  254  	Training Loss: 0.003368212841451168
Test Loss:  0.0029814760200679302
Valid Loss:  0.0035875539761036634
Epoch:  255  	Training Loss: 0.0033480741549283266
Test Loss:  0.0029637895058840513
Valid Loss:  0.0035661119036376476
Epoch:  256  	Training Loss: 0.003328080754727125
Test Loss:  0.00294622709043324
Valid Loss:  0.0035448113922029734
Epoch:  257  	Training Loss: 0.0033082272857427597
Test Loss:  0.0029287938959896564
Valid Loss:  0.0035236647818237543
Epoch:  258  	Training Loss: 0.003288521431386471
Test Loss:  0.0029114701319485903
Valid Loss:  0.003502677660435438
Epoch:  259  	Training Loss: 0.0032689496874809265
Test Loss:  0.0028942800126969814
Valid Loss:  0.003481827676296234
Epoch:  260  	Training Loss: 0.003249522065743804
Test Loss:  0.002877210732549429
Valid Loss:  0.0034611341543495655
Epoch:  261  	Training Loss: 0.0032302294857800007
Test Loss:  0.00286026019603014
Valid Loss:  0.0034405793994665146
Epoch:  262  	Training Loss: 0.0032110775355249643
Test Loss:  0.0028431755490601063
Valid Loss:  0.0034199885558336973
Epoch:  263  	Training Loss: 0.003191834781318903
Test Loss:  0.00282621500082314
Valid Loss:  0.003399547189474106
Epoch:  264  	Training Loss: 0.003172723576426506
Test Loss:  0.0028093878645449877
Valid Loss:  0.0033792508766055107
Epoch:  265  	Training Loss: 0.003153757657855749
Test Loss:  0.002792670391499996
Valid Loss:  0.0033590886741876602
Epoch:  266  	Training Loss: 0.0031349211931228638
Test Loss:  0.0027760695666074753
Valid Loss:  0.003339075017720461
Epoch:  267  	Training Loss: 0.0031162265222519636
Test Loss:  0.002759596798568964
Valid Loss:  0.0033191940747201443
Epoch:  268  	Training Loss: 0.003097668057307601
Test Loss:  0.002743241610005498
Valid Loss:  0.0032994579523801804
Epoch:  269  	Training Loss: 0.0030792420729994774
Test Loss:  0.002727010753005743
Valid Loss:  0.003279855940490961
Epoch:  270  	Training Loss: 0.0030609495006501675
Test Loss:  0.002710889559239149
Valid Loss:  0.003260397119447589
Epoch:  271  	Training Loss: 0.0030427854508161545
Test Loss:  0.0026948852464556694
Valid Loss:  0.003241070546209812
Epoch:  272  	Training Loss: 0.003024754114449024
Test Loss:  0.002679107477888465
Valid Loss:  0.0032219658605754375
Epoch:  273  	Training Loss: 0.003006956772878766
Test Loss:  0.0026634731329977512
Valid Loss:  0.0032029305584728718
Epoch:  274  	Training Loss: 0.0029892860911786556
Test Loss:  0.0026479142252355814
Valid Loss:  0.0031841020099818707
Epoch:  275  	Training Loss: 0.002971737878397107
Test Loss:  0.0026324624195694923
Valid Loss:  0.003165393602102995
Epoch:  276  	Training Loss: 0.0029543170239776373
Test Loss:  0.002617154736071825
Valid Loss:  0.0031467564404010773
Epoch:  277  	Training Loss: 0.002937022829428315
Test Loss:  0.002601921558380127
Valid Loss:  0.0031283299904316664
Epoch:  278  	Training Loss: 0.0029198480769991875
Test Loss:  0.002586830174550414
Valid Loss:  0.003109952202066779
Epoch:  279  	Training Loss: 0.002902799751609564
Test Loss:  0.002571810269728303
Valid Loss:  0.003091778140515089
Epoch:  280  	Training Loss: 0.0028858711011707783
Test Loss:  0.0025569316931068897
Valid Loss:  0.003073666011914611
Epoch:  281  	Training Loss: 0.002869061194360256
Test Loss:  0.002542150905355811
Valid Loss:  0.0030556865967810154
Epoch:  282  	Training Loss: 0.0028523728251457214
Test Loss:  0.0025274520739912987
Valid Loss:  0.0030379071831703186
 57%|█████▋    | 283/500 [03:17<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:17<01:34,  2.24it/s] 58%|█████▊    | 289/500 [03:17<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:24<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:24<02:54,  1.19it/s] 59%|█████▉    | 295/500 [03:24<02:04,  1.64it/s] 59%|█████▉    | 297/500 [03:24<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.02it/s] 60%|██████    | 301/500 [03:30<03:52,  1.17s/it] 61%|██████    | 303/500 [03:31<02:45,  1.19it/s] 61%|██████    | 305/500 [03:31<01:58,  1.64it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.23it/s] 62%|██████▏   | 309/500 [03:31<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:37<03:41,  1.17s/it] 63%|██████▎   | 313/500 [03:37<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:38<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:38<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:44<03:29,  1.17s/it] 65%|██████▍   | 323/500 [03:44<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:44<01:46,  1.64it/s] 65%|██████▌   | 327/500 [03:44<01:17,  2.25it/s] 66%|██████▌   | 329/500 [03:45<00:56,  3.02it/s] 66%|██████▌   | 331/500 [03:51<03:20,  1.19s/it] 67%|██████▋   | 333/500 [03:51<02:22,  1.17it/s] 67%|██████▋   | 335/500 [03:51<01:41,  1.62it/s] 67%|██████▋   | 337/500 [03:51<01:13,  2.21it/s] 68%|██████▊   | 339/500 [03:51<00:54,  2.98it/s] 68%|██████▊   | 341/500 [03:58<03:06,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:12,  1.18it/s] 69%|██████▉   | 345/500 [03:58<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:58<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:58<00:50,  3.01it/s] 70%|███████   | 351/500 [04:05<02:56,  1.18s/it]Epoch:  283  	Training Loss: 0.0028358101844787598
Test Loss:  0.002512877807021141
Valid Loss:  0.0030201859772205353
Epoch:  284  	Training Loss: 0.0028193627949804068
Test Loss:  0.002498406218364835
Valid Loss:  0.0030025914311408997
Epoch:  285  	Training Loss: 0.002803030190989375
Test Loss:  0.0024840403348207474
Valid Loss:  0.0029851319268345833
Epoch:  286  	Training Loss: 0.002786817029118538
Test Loss:  0.002469779923558235
Valid Loss:  0.0029677837155759335
Epoch:  287  	Training Loss: 0.0027707209810614586
Test Loss:  0.002455604262650013
Valid Loss:  0.0029505728743970394
Epoch:  288  	Training Loss: 0.002754738088697195
Test Loss:  0.002441538032144308
Valid Loss:  0.002933479379862547
Epoch:  289  	Training Loss: 0.002738867187872529
Test Loss:  0.0024275698233395815
Valid Loss:  0.002916507888585329
Epoch:  290  	Training Loss: 0.002723108511418104
Test Loss:  0.002413691021502018
Valid Loss:  0.002899652114138007
Epoch:  291  	Training Loss: 0.002707460895180702
Test Loss:  0.002399912104010582
Valid Loss:  0.002882914151996374
Epoch:  292  	Training Loss: 0.0026919252704828978
Test Loss:  0.0023863171227276325
Valid Loss:  0.0028663459233939648
Epoch:  293  	Training Loss: 0.002676567528396845
Test Loss:  0.0023728066589683294
Valid Loss:  0.0028498955070972443
Epoch:  294  	Training Loss: 0.002661313395947218
Test Loss:  0.00235939584672451
Valid Loss:  0.0028335601091384888
Epoch:  295  	Training Loss: 0.0026461707893759012
Test Loss:  0.0023460793308913708
Valid Loss:  0.0028173429891467094
Epoch:  296  	Training Loss: 0.0026311324909329414
Test Loss:  0.002332845935598016
Valid Loss:  0.0028012448456138372
Epoch:  297  	Training Loss: 0.0026162005960941315
Test Loss:  0.002319709863513708
Valid Loss:  0.0027852486819028854
Epoch:  298  	Training Loss: 0.0026013727765530348
Test Loss:  0.0023066529538482428
Valid Loss:  0.002769378712400794
Epoch:  299  	Training Loss: 0.0025866497308015823
Test Loss:  0.0022937003523111343
Valid Loss:  0.002753619337454438
Epoch:  300  	Training Loss: 0.0025720293633639812
Test Loss:  0.0022808227222412825
Valid Loss:  0.0027379707898944616
Epoch:  301  	Training Loss: 0.0025575095787644386
Test Loss:  0.002268036361783743
Valid Loss:  0.002722424454987049
Epoch:  302  	Training Loss: 0.002543090144172311
Test Loss:  0.0022551794536411762
Valid Loss:  0.0027069312054663897
Epoch:  303  	Training Loss: 0.0025286623276770115
Test Loss:  0.0022424240596592426
Valid Loss:  0.0026915417984128
Epoch:  304  	Training Loss: 0.0025143332313746214
Test Loss:  0.0022297531832009554
Valid Loss:  0.0026762618217617273
Epoch:  305  	Training Loss: 0.0025001070462167263
Test Loss:  0.002217175206169486
Valid Loss:  0.002661088015884161
Epoch:  306  	Training Loss: 0.0024859795812517405
Test Loss:  0.0022046882659196854
Valid Loss:  0.0026460131630301476
Epoch:  307  	Training Loss: 0.0024719536304473877
Test Loss:  0.0021922786254435778
Valid Loss:  0.0026310505345463753
Epoch:  308  	Training Loss: 0.0024580289609730244
Test Loss:  0.0021799656096845865
Valid Loss:  0.002616194076836109
Epoch:  309  	Training Loss: 0.002444196492433548
Test Loss:  0.002167731523513794
Valid Loss:  0.0026014295872300863
Epoch:  310  	Training Loss: 0.0024304655380547047
Test Loss:  0.002155586611479521
Valid Loss:  0.0025867740623652935
Epoch:  311  	Training Loss: 0.0024168312083929777
Test Loss:  0.0021435541566461325
Valid Loss:  0.002572178142145276
Epoch:  312  	Training Loss: 0.0024032974615693092
Test Loss:  0.002131612505763769
Valid Loss:  0.0025576769839972258
Epoch:  313  	Training Loss: 0.0023898547515273094
Test Loss:  0.002119756303727627
Valid Loss:  0.0025432752445340157
Epoch:  314  	Training Loss: 0.0023765098303556442
Test Loss:  0.002107972279191017
Valid Loss:  0.0025289752520620823
Epoch:  315  	Training Loss: 0.002363258507102728
Test Loss:  0.0020962748676538467
Valid Loss:  0.0025147779379040003
Epoch:  316  	Training Loss: 0.0023501026444137096
Test Loss:  0.0020846580155193806
Valid Loss:  0.0025006828363984823
Epoch:  317  	Training Loss: 0.002337033860385418
Test Loss:  0.00207311799749732
Valid Loss:  0.002486688317731023
Epoch:  318  	Training Loss: 0.002324062865227461
Test Loss:  0.002061661100015044
Valid Loss:  0.002472788095474243
Epoch:  319  	Training Loss: 0.0023111789487302303
Test Loss:  0.002050281036645174
Valid Loss:  0.0024589861277490854
Epoch:  320  	Training Loss: 0.002298389095813036
Test Loss:  0.002038976177573204
Valid Loss:  0.0024452856741845608
Epoch:  321  	Training Loss: 0.0022856849245727062
Test Loss:  0.0020277504809200764
Valid Loss:  0.0024316785857081413
Epoch:  322  	Training Loss: 0.0022730715572834015
Test Loss:  0.0020166467875242233
Valid Loss:  0.002418213291093707
Epoch:  323  	Training Loss: 0.0022605923004448414
Test Loss:  0.002005624584853649
Valid Loss:  0.0024048369377851486
Epoch:  324  	Training Loss: 0.00224819453433156
Test Loss:  0.0019946699030697346
Valid Loss:  0.002391554182395339
Epoch:  325  	Training Loss: 0.0022358857095241547
Test Loss:  0.001983790658414364
Valid Loss:  0.002378360368311405
Epoch:  326  	Training Loss: 0.002223664429038763
Test Loss:  0.0019729873165488243
Valid Loss:  0.0023652645759284496
Epoch:  327  	Training Loss: 0.002211525570601225
Test Loss:  0.0019622575491666794
Valid Loss:  0.0023522619158029556
Epoch:  328  	Training Loss: 0.002199473325163126
Test Loss:  0.001951606129296124
Valid Loss:  0.00233934517018497
Epoch:  329  	Training Loss: 0.002187504433095455
Test Loss:  0.001941014314070344
Valid Loss:  0.0023265210911631584
Epoch:  330  	Training Loss: 0.0021756223868578672
Test Loss:  0.0019305036403238773
Valid Loss:  0.0023137929383665323
Epoch:  331  	Training Loss: 0.0021638183388859034
Test Loss:  0.0019200606038793921
Valid Loss:  0.0023011518642306328
Epoch:  332  	Training Loss: 0.002152096014469862
Test Loss:  0.0019095824100077152
Valid Loss:  0.0022885329090058804
Epoch:  333  	Training Loss: 0.0021403729915618896
Test Loss:  0.001899168360978365
Valid Loss:  0.0022760103456676006
Epoch:  334  	Training Loss: 0.002128731459379196
Test Loss:  0.001888832775875926
Valid Loss:  0.0022635702043771744
Epoch:  335  	Training Loss: 0.002117172582075
Test Loss:  0.0018785751890391111
Valid Loss:  0.0022512157447636127
Epoch:  336  	Training Loss: 0.002105691935867071
Test Loss:  0.0018683748785406351
Valid Loss:  0.0022389478981494904
Epoch:  337  	Training Loss: 0.0020942911505699158
Test Loss:  0.0018582544289529324
Valid Loss:  0.00222676619887352
Epoch:  338  	Training Loss: 0.0020829711575061083
Test Loss:  0.0018481980077922344
Valid Loss:  0.0022146604023873806
Epoch:  339  	Training Loss: 0.0020717307925224304
Test Loss:  0.0018382191192358732
Valid Loss:  0.0022026458755135536
Epoch:  340  	Training Loss: 0.0020605698227882385
Test Loss:  0.001828304142691195
Valid Loss:  0.002190712606534362
Epoch:  341  	Training Loss: 0.0020494828931987286
Test Loss:  0.001818459713831544
Valid Loss:  0.0021788582671433687
Epoch:  342  	Training Loss: 0.002038477687165141
Test Loss:  0.0018087229691445827
Valid Loss:  0.002167112659662962
Epoch:  343  	Training Loss: 0.0020275793503969908
Test Loss:  0.0017990517662838101
Valid Loss:  0.0021554450504481792
Epoch:  344  	Training Loss: 0.0020167562179267406
Test Loss:  0.0017894473858177662
Valid Loss:  0.002143857767805457
Epoch:  345  	Training Loss: 0.002006009453907609
Test Loss:  0.0017799382330849767
Valid Loss:  0.0021323165856301785
Epoch:  346  	Training Loss: 0.001995342317968607
Test Loss:  0.0017704948550090194
Valid Loss:  0.0021208564285188913
Epoch:  347  	Training Loss: 0.0019847480580210686
Test Loss:  0.0017611067742109299
Valid Loss:  0.0021094821859151125
Epoch:  348  	Training Loss: 0.001974229235202074
Test Loss:  0.0017517863307148218
Valid Loss:  0.002098181052133441
Epoch:  349  	Training Loss: 0.0019637818913906813
Test Loss:  0.0017425313126295805
Valid Loss:  0.0020869639702141285
Epoch:  350  	Training Loss: 0.001953407423570752
Test Loss:  0.0017333353171125054
Valid Loss:  0.0020758220925927162
Epoch:  351  	Training Loss: 0.0019431078108027577
Test Loss:  0.0017241968307644129
Valid Loss:  0.002064760774374008
 71%|███████   | 353/500 [04:05<02:05,  1.17it/s] 71%|███████   | 355/500 [04:05<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:05<01:04,  2.21it/s] 72%|███████▏  | 359/500 [04:05<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:12<02:44,  1.19s/it] 73%|███████▎  | 363/500 [04:12<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:12<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:12<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:12<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:18<02:33,  1.19s/it] 75%|███████▍  | 373/500 [04:19<01:48,  1.17it/s] 75%|███████▌  | 375/500 [04:19<01:17,  1.62it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.21it/s] 76%|███████▌  | 379/500 [04:19<00:40,  2.97it/s] 76%|███████▌  | 381/500 [04:25<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:25<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:26<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:26<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:26<00:36,  3.01it/s] 78%|███████▊  | 391/500 [04:32<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:32<01:31,  1.18it/s] 79%|███████▉  | 395/500 [04:32<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:33<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:33<00:33,  2.99it/s] 80%|████████  | 401/500 [04:39<01:57,  1.18s/it] 81%|████████  | 403/500 [04:39<01:22,  1.18it/s] 81%|████████  | 405/500 [04:39<00:58,  1.63it/s] 81%|████████▏ | 407/500 [04:39<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:40<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:46<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:46<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:46<00:27,  3.00it/s]Epoch:  352  	Training Loss: 0.0019328760681673884
Test Loss:  0.001715238904580474
Valid Loss:  0.002053862437605858
Epoch:  353  	Training Loss: 0.0019228126620873809
Test Loss:  0.0017063544364646077
Valid Loss:  0.002043037209659815
Epoch:  354  	Training Loss: 0.001912824111059308
Test Loss:  0.001697526779025793
Valid Loss:  0.0020322916097939014
Epoch:  355  	Training Loss: 0.0019029012182727456
Test Loss:  0.0016887615201994777
Valid Loss:  0.0020216177217662334
Epoch:  356  	Training Loss: 0.0018930479418486357
Test Loss:  0.0016800453886389732
Valid Loss:  0.0020110239274799824
Epoch:  357  	Training Loss: 0.0018832616042345762
Test Loss:  0.001671391073614359
Valid Loss:  0.0020005011465400457
Epoch:  358  	Training Loss: 0.0018735409248620272
Test Loss:  0.0016627951990813017
Valid Loss:  0.0019900521729141474
Epoch:  359  	Training Loss: 0.0018638860201463103
Test Loss:  0.0016542563680559397
Valid Loss:  0.0019796774722635746
Epoch:  360  	Training Loss: 0.0018542972393333912
Test Loss:  0.0016457715537399054
Valid Loss:  0.001969371223822236
Epoch:  361  	Training Loss: 0.0018447746988385916
Test Loss:  0.0016373420367017388
Valid Loss:  0.001959137851372361
Epoch:  362  	Training Loss: 0.0018353152554482222
Test Loss:  0.00162891810759902
Valid Loss:  0.001948963268660009
Epoch:  363  	Training Loss: 0.0018258902709931135
Test Loss:  0.0016205552965402603
Valid Loss:  0.0019388552755117416
Epoch:  364  	Training Loss: 0.0018165314104408026
Test Loss:  0.0016122410306707025
Valid Loss:  0.0019288215553388
Epoch:  365  	Training Loss: 0.0018072327366098762
Test Loss:  0.001603984972462058
Valid Loss:  0.0019188565202057362
Epoch:  366  	Training Loss: 0.0017979993717744946
Test Loss:  0.0015957908472046256
Valid Loss:  0.0019089588895440102
Epoch:  367  	Training Loss: 0.0017888296861201525
Test Loss:  0.001587643171660602
Valid Loss:  0.0018991224933415651
Epoch:  368  	Training Loss: 0.001779722049832344
Test Loss:  0.0015795533545315266
Valid Loss:  0.001889361534267664
Epoch:  369  	Training Loss: 0.0017706756480038166
Test Loss:  0.0015715401386842132
Valid Loss:  0.0018796415533870459
Epoch:  370  	Training Loss: 0.001761698629707098
Test Loss:  0.0015635795425623655
Valid Loss:  0.0018699977081269026
Epoch:  371  	Training Loss: 0.001752783078700304
Test Loss:  0.0015556716825813055
Valid Loss:  0.0018604227807372808
Epoch:  372  	Training Loss: 0.0017439303919672966
Test Loss:  0.0015477935085073113
Valid Loss:  0.0018509021028876305
Epoch:  373  	Training Loss: 0.001735121477395296
Test Loss:  0.0015399741241708398
Valid Loss:  0.0018414496444165707
Epoch:  374  	Training Loss: 0.0017263743793591857
Test Loss:  0.0015322144608944654
Valid Loss:  0.001832066336646676
Epoch:  375  	Training Loss: 0.0017176863038912416
Test Loss:  0.0015245075337588787
Valid Loss:  0.0018227503169327974
Epoch:  376  	Training Loss: 0.0017090564360842109
Test Loss:  0.0015168576501309872
Valid Loss:  0.0018134948331862688
Epoch:  377  	Training Loss: 0.0017004855908453465
Test Loss:  0.0015092542162165046
Valid Loss:  0.0018043011659756303
Epoch:  378  	Training Loss: 0.0016919723711907864
Test Loss:  0.001501698512583971
Valid Loss:  0.0017951743211597204
Epoch:  379  	Training Loss: 0.0016835179412737489
Test Loss:  0.00149420159868896
Valid Loss:  0.0017861060332506895
Epoch:  380  	Training Loss: 0.0016751183429732919
Test Loss:  0.0014867428690195084
Valid Loss:  0.0017771024722605944
Epoch:  381  	Training Loss: 0.0016667770687490702
Test Loss:  0.0014793411828577518
Valid Loss:  0.0017681537428870797
Epoch:  382  	Training Loss: 0.0016584929544478655
Test Loss:  0.0014720874605700374
Valid Loss:  0.0017593394732102752
Epoch:  383  	Training Loss: 0.0016503417864441872
Test Loss:  0.0014648761134594679
Valid Loss:  0.0017505744472146034
Epoch:  384  	Training Loss: 0.0016422455664724112
Test Loss:  0.0014577170368283987
Valid Loss:  0.0017418728675693274
Epoch:  385  	Training Loss: 0.0016342040617018938
Test Loss:  0.00145060196518898
Valid Loss:  0.0017332329880446196
Epoch:  386  	Training Loss: 0.0016262162243947387
Test Loss:  0.001443531014956534
Valid Loss:  0.0017246545758098364
Epoch:  387  	Training Loss: 0.0016182791441679
Test Loss:  0.001436511636711657
Valid Loss:  0.0017161313444375992
Epoch:  388  	Training Loss: 0.0016103987582027912
Test Loss:  0.0014295283472165465
Valid Loss:  0.0017076680669561028
Epoch:  389  	Training Loss: 0.0016025658696889877
Test Loss:  0.0014225938357412815
Valid Loss:  0.0016992662567645311
Epoch:  390  	Training Loss: 0.0015947874635457993
Test Loss:  0.0014157256809994578
Valid Loss:  0.0016909119440242648
Epoch:  391  	Training Loss: 0.0015870619099587202
Test Loss:  0.0014089032774791121
Valid Loss:  0.0016826235223561525
Epoch:  392  	Training Loss: 0.0015793850179761648
Test Loss:  0.001402178779244423
Valid Loss:  0.001674433471634984
Epoch:  393  	Training Loss: 0.0015718134818598628
Test Loss:  0.0013955035246908665
Valid Loss:  0.0016662984853610396
Epoch:  394  	Training Loss: 0.0015642897924408317
Test Loss:  0.0013888692483305931
Valid Loss:  0.0016582207754254341
Epoch:  395  	Training Loss: 0.0015568166272714734
Test Loss:  0.0013822789769619703
Valid Loss:  0.0016501965001225471
Epoch:  396  	Training Loss: 0.001549396081827581
Test Loss:  0.0013757391134276986
Valid Loss:  0.0016421987675130367
Epoch:  397  	Training Loss: 0.0015420278068631887
Test Loss:  0.0013692453503608704
Valid Loss:  0.0016342592425644398
Epoch:  398  	Training Loss: 0.0015347114531323314
Test Loss:  0.001362791284918785
Valid Loss:  0.0016263751313090324
Epoch:  399  	Training Loss: 0.001527438871562481
Test Loss:  0.0013563765678554773
Valid Loss:  0.0016185418935492635
Epoch:  400  	Training Loss: 0.0015202166978269815
Test Loss:  0.0013500023633241653
Valid Loss:  0.0016107629053294659
Epoch:  401  	Training Loss: 0.0015130424872040749
Test Loss:  0.001343673444353044
Valid Loss:  0.0016030415426939726
Epoch:  402  	Training Loss: 0.001505914144217968
Test Loss:  0.0013372639659792185
Valid Loss:  0.0015952785033732653
Epoch:  403  	Training Loss: 0.0014987476170063019
Test Loss:  0.0013309016358107328
Valid Loss:  0.0015875704120844603
Epoch:  404  	Training Loss: 0.0014916281215846539
Test Loss:  0.0013245792360976338
Valid Loss:  0.001579910283908248
Epoch:  405  	Training Loss: 0.001484555541537702
Test Loss:  0.0013182954862713814
Valid Loss:  0.0015723120886832476
Epoch:  406  	Training Loss: 0.0014775341842323542
Test Loss:  0.001312060048803687
Valid Loss:  0.0015647578984498978
Epoch:  407  	Training Loss: 0.0014705543871968985
Test Loss:  0.0013058553449809551
Valid Loss:  0.001557250740006566
Epoch:  408  	Training Loss: 0.0014636217383667827
Test Loss:  0.00129969313275069
Valid Loss:  0.001549801672808826
Epoch:  409  	Training Loss: 0.0014567351900041103
Test Loss:  0.0012935735285282135
Valid Loss:  0.001542397541925311
Epoch:  410  	Training Loss: 0.001449894392862916
Test Loss:  0.0012874930398538709
Valid Loss:  0.001535046729259193
Epoch:  411  	Training Loss: 0.0014430988812819123
Test Loss:  0.0012814460787922144
Valid Loss:  0.0015277431812137365
Epoch:  412  	Training Loss: 0.0014363490045070648
Test Loss:  0.0012753938790410757
Valid Loss:  0.0015204624505713582
Epoch:  413  	Training Loss: 0.0014296050649136305
Test Loss:  0.0012693817261606455
Valid Loss:  0.0015132338739931583
Epoch:  414  	Training Loss: 0.0014229079242795706
Test Loss:  0.0012634028680622578
Valid Loss:  0.0015060517471283674
Epoch:  415  	Training Loss: 0.0014162539737299085
Test Loss:  0.0012574680149555206
Valid Loss:  0.0014989158371463418
Epoch:  416  	Training Loss: 0.001409643329679966
Test Loss:  0.0012515622656792402
Valid Loss:  0.0014918269589543343
Epoch:  417  	Training Loss: 0.0014030783204361796
Test Loss:  0.0012457047123461962
Valid Loss:  0.0014847854617983103
Epoch:  418  	Training Loss: 0.0013965568505227566
Test Loss:  0.0012398832477629185
Valid Loss:  0.0014777900651097298
Epoch:  419  	Training Loss: 0.0013900758931413293
Test Loss:  0.001234098570421338
Valid Loss:  0.0014708435628563166
Epoch:  420  	Training Loss: 0.0013836388243362308
Test Loss:   84%|████████▍ | 421/500 [04:53<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:53<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.25it/s] 86%|████████▌ | 429/500 [04:53<00:23,  3.02it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.17s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.20it/s] 87%|████████▋ | 435/500 [05:00<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:00<00:27,  2.26it/s] 88%|████████▊ | 439/500 [05:00<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:06<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:07<00:49,  1.16it/s] 89%|████████▉ | 445/500 [05:07<00:34,  1.60it/s] 89%|████████▉ | 447/500 [05:07<00:24,  2.19it/s] 90%|████████▉ | 449/500 [05:07<00:17,  2.94it/s] 90%|█████████ | 451/500 [05:13<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:13<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:14<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:14<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:14<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:20<00:46,  1.19s/it] 93%|█████████▎| 463/500 [05:20<00:31,  1.17it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.62it/s] 93%|█████████▎| 467/500 [05:21<00:14,  2.22it/s] 94%|█████████▍| 469/500 [05:21<00:10,  2.98it/s] 94%|█████████▍| 471/500 [05:27<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:27<00:23,  1.17it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.62it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.22it/s] 96%|█████████▌| 479/500 [05:28<00:07,  2.98it/s] 96%|█████████▌| 481/500 [05:34<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:34<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:34<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.25it/s]0.0012283516116440296
Valid Loss:  0.0014639397850260139
Epoch:  421  	Training Loss: 0.001377244247123599
Test Loss:  0.0012226422550156713
Valid Loss:  0.001457080477848649
Epoch:  422  	Training Loss: 0.001370893558487296
Test Loss:  0.0012170355767011642
Valid Loss:  0.0014503069687634706
Epoch:  423  	Training Loss: 0.0013646293664351106
Test Loss:  0.001211460679769516
Valid Loss:  0.0014435790944844484
Epoch:  424  	Training Loss: 0.0013584070838987827
Test Loss:  0.0012059195432811975
Valid Loss:  0.001436893129721284
Epoch:  425  	Training Loss: 0.0013522244989871979
Test Loss:  0.0012004212476313114
Valid Loss:  0.0014302608324214816
Epoch:  426  	Training Loss: 0.0013460847549140453
Test Loss:  0.0011949548497796059
Valid Loss:  0.001423658337444067
Epoch:  427  	Training Loss: 0.0013399830786511302
Test Loss:  0.0011895167408511043
Valid Loss:  0.001417103223502636
Epoch:  428  	Training Loss: 0.001333920517936349
Test Loss:  0.0011841171653941274
Valid Loss:  0.001410588389262557
Epoch:  429  	Training Loss: 0.0013278969563543797
Test Loss:  0.0011787558905780315
Valid Loss:  0.0014041217509657145
Epoch:  430  	Training Loss: 0.001321913325227797
Test Loss:  0.0011734231375157833
Valid Loss:  0.001397696090862155
Epoch:  431  	Training Loss: 0.0013159674126654863
Test Loss:  0.0011681262403726578
Valid Loss:  0.0013913130387663841
Epoch:  432  	Training Loss: 0.0013100617798045278
Test Loss:  0.0011628515785560012
Valid Loss:  0.0013849774841219187
Epoch:  433  	Training Loss: 0.001304188510403037
Test Loss:  0.0011576088145375252
Valid Loss:  0.0013786774361506104
Epoch:  434  	Training Loss: 0.0012983559863641858
Test Loss:  0.0011524023720994592
Valid Loss:  0.0013724206946790218
Epoch:  435  	Training Loss: 0.0012925600167363882
Test Loss:  0.001147229690104723
Valid Loss:  0.001366199692711234
Epoch:  436  	Training Loss: 0.001286802114918828
Test Loss:  0.001142091117799282
Valid Loss:  0.0013600254897028208
Epoch:  437  	Training Loss: 0.001281079719774425
Test Loss:  0.0011369835119694471
Valid Loss:  0.0013538891216740012
Epoch:  438  	Training Loss: 0.0012753939954563975
Test Loss:  0.001131905592046678
Valid Loss:  0.0013477946631610394
Epoch:  439  	Training Loss: 0.0012697461061179638
Test Loss:  0.0011268602684140205
Valid Loss:  0.001341738854534924
Epoch:  440  	Training Loss: 0.001264132559299469
Test Loss:  0.0011218470754101872
Valid Loss:  0.0013357193674892187
Epoch:  441  	Training Loss: 0.001258556148968637
Test Loss:  0.0011168679920956492
Valid Loss:  0.0013297318946570158
Epoch:  442  	Training Loss: 0.0012530148960649967
Test Loss:  0.001111994031816721
Valid Loss:  0.0013238295214250684
Epoch:  443  	Training Loss: 0.001247564097866416
Test Loss:  0.0011071510380133986
Valid Loss:  0.0013179683592170477
Epoch:  444  	Training Loss: 0.001242146361619234
Test Loss:  0.0011023373808711767
Valid Loss:  0.0013121364172548056
Epoch:  445  	Training Loss: 0.0012367602903395891
Test Loss:  0.0010975550394505262
Valid Loss:  0.0013063474325463176
Epoch:  446  	Training Loss: 0.0012314138002693653
Test Loss:  0.0010928127449005842
Valid Loss:  0.0013005847577005625
Epoch:  447  	Training Loss: 0.0012261074734851718
Test Loss:  0.0010881050257012248
Valid Loss:  0.001294852583669126
Epoch:  448  	Training Loss: 0.0012208339758217335
Test Loss:  0.0010834257118403912
Valid Loss:  0.0012891590595245361
Epoch:  449  	Training Loss: 0.0012155926087871194
Test Loss:  0.0010787693317979574
Valid Loss:  0.0012835065135732293
Epoch:  450  	Training Loss: 0.001210385700687766
Test Loss:  0.0010741404257714748
Valid Loss:  0.0012778867967426777
Epoch:  451  	Training Loss: 0.0012052115052938461
Test Loss:  0.0010695382952690125
Valid Loss:  0.0012723063118755817
Epoch:  452  	Training Loss: 0.0012000687420368195
Test Loss:  0.0010650001931935549
Valid Loss:  0.0012667805422097445
Epoch:  453  	Training Loss: 0.0011949806939810514
Test Loss:  0.0010604843264445662
Valid Loss:  0.0012612879509106278
Epoch:  454  	Training Loss: 0.0011899250093847513
Test Loss:  0.0010559950023889542
Valid Loss:  0.0012558333110064268
Epoch:  455  	Training Loss: 0.0011848993599414825
Test Loss:  0.0010515343165025115
Valid Loss:  0.0012504167389124632
Epoch:  456  	Training Loss: 0.0011799042113125324
Test Loss:  0.0010470973793417215
Valid Loss:  0.0012450298527255654
Epoch:  457  	Training Loss: 0.0011749414261430502
Test Loss:  0.0010426839580759406
Valid Loss:  0.0012396803358569741
Epoch:  458  	Training Loss: 0.001170008210465312
Test Loss:  0.0010383035987615585
Valid Loss:  0.0012343586422502995
Epoch:  459  	Training Loss: 0.0011651061940938234
Test Loss:  0.001033938955515623
Valid Loss:  0.001229079207405448
Epoch:  460  	Training Loss: 0.0011602332815527916
Test Loss:  0.0010296039981767535
Valid Loss:  0.001223830389790237
Epoch:  461  	Training Loss: 0.0011553892400115728
Test Loss:  0.001025296631269157
Valid Loss:  0.001218617195263505
Epoch:  462  	Training Loss: 0.0011505767470225692
Test Loss:  0.0010209716856479645
Valid Loss:  0.0012134355492889881
Epoch:  463  	Training Loss: 0.0011457772925496101
Test Loss:  0.0010166733991354704
Valid Loss:  0.0012082800967618823
Epoch:  464  	Training Loss: 0.0011410091537982225
Test Loss:  0.0010124039836227894
Valid Loss:  0.001203168649226427
Epoch:  465  	Training Loss: 0.001136268489062786
Test Loss:  0.0010081564541906118
Valid Loss:  0.0011980790877714753
Epoch:  466  	Training Loss: 0.0011315570445731282
Test Loss:  0.0010039359331130981
Valid Loss:  0.0011930225882679224
Epoch:  467  	Training Loss: 0.001126876100897789
Test Loss:  0.0009997407905757427
Valid Loss:  0.0011880039237439632
Epoch:  468  	Training Loss: 0.0011222227476537228
Test Loss:  0.0009955712594091892
Valid Loss:  0.0011830104049295187
Epoch:  469  	Training Loss: 0.001117597334086895
Test Loss:  0.0009914248948916793
Valid Loss:  0.0011780448257923126
Epoch:  470  	Training Loss: 0.0011130007915198803
Test Loss:  0.000987307052128017
Valid Loss:  0.0011731155682355165
Epoch:  471  	Training Loss: 0.001108432305045426
Test Loss:  0.0009832122595980763
Valid Loss:  0.0011682137846946716
Epoch:  472  	Training Loss: 0.0011038916418328881
Test Loss:  0.0009791404008865356
Valid Loss:  0.0011633668327704072
Epoch:  473  	Training Loss: 0.001099392306059599
Test Loss:  0.0009750963072292507
Valid Loss:  0.0011585482861846685
Epoch:  474  	Training Loss: 0.0010949181159958243
Test Loss:  0.0009710766607895494
Valid Loss:  0.0011537557002156973
Epoch:  475  	Training Loss: 0.0010904755908995867
Test Loss:  0.0009670786093920469
Valid Loss:  0.0011489966418594122
Epoch:  476  	Training Loss: 0.00108605925925076
Test Loss:  0.0009631133871152997
Valid Loss:  0.0011442630784586072
Epoch:  477  	Training Loss: 0.0010816700523719192
Test Loss:  0.0009591603884473443
Valid Loss:  0.0011395608307793736
Epoch:  478  	Training Loss: 0.0010773069225251675
Test Loss:  0.0009552373667247593
Valid Loss:  0.0011348883854225278
Epoch:  479  	Training Loss: 0.001072968589141965
Test Loss:  0.0009513397235423326
Valid Loss:  0.0011302398052066565
Epoch:  480  	Training Loss: 0.0010686581954360008
Test Loss:  0.0009474599501118064
Valid Loss:  0.0011256180005148053
Epoch:  481  	Training Loss: 0.0010643729474395514
Test Loss:  0.0009436147520318627
Valid Loss:  0.0011210291413590312
Epoch:  482  	Training Loss: 0.0010601140093058348
Test Loss:  0.0009398193215020001
Valid Loss:  0.0011164875468239188
Epoch:  483  	Training Loss: 0.0010559081565588713
Test Loss:  0.000936050433665514
Valid Loss:  0.0011119695845991373
Epoch:  484  	Training Loss: 0.001051724306307733
Test Loss:  0.0009323040721938014
Valid Loss:  0.0011074853828176856
Epoch:  485  	Training Loss: 0.0010475676972419024
Test Loss:  0.0009285766282118857
Valid Loss:  0.0011030212044715881
Epoch:  486  	Training Loss: 0.0010434361174702644
Test Loss:  0.0009248724090866745
Valid Loss:  0.0010986028937622905
Epoch:  487  	Training Loss: 0.0010393259581178427
Test Loss:  0.0009211900760419667
Valid Loss:  0.0010942171793431044
Epoch:  488  	Training Loss: 0.0010352435056120157
Test Loss:  0.0009175257873721421
Valid Loss:  0.0010898556793108582
 98%|█████████▊| 489/500 [05:34<00:03,  3.02it/s] 98%|█████████▊| 491/500 [05:41<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:41<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:41<00:03,  1.64it/s] 99%|█████████▉| 497/500 [05:41<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:41<00:00,  3.00it/s]100%|██████████| 500/500 [05:41<00:00,  1.46it/s]
Epoch:  489  	Training Loss: 0.0010311829391866922
Test Loss:  0.0009138848399743438
Valid Loss:  0.0010855273576453328
Epoch:  490  	Training Loss: 0.0010271456558257341
Test Loss:  0.0009102667099796236
Valid Loss:  0.001081243623048067
Epoch:  491  	Training Loss: 0.0010231338674202561
Test Loss:  0.0009066678467206657
Valid Loss:  0.0010769790969789028
Epoch:  492  	Training Loss: 0.0010191451292484999
Test Loss:  0.0009030624059960246
Valid Loss:  0.0010727511253207922
Epoch:  493  	Training Loss: 0.0010151728056371212
Test Loss:  0.0008994820527732372
Valid Loss:  0.001068542362190783
Epoch:  494  	Training Loss: 0.0010112232994288206
Test Loss:  0.0008959194528870285
Valid Loss:  0.0010643640998750925
Epoch:  495  	Training Loss: 0.0010073024313896894
Test Loss:  0.0008923941059038043
Valid Loss:  0.0010601909598335624
Epoch:  496  	Training Loss: 0.001003412646241486
Test Loss:  0.0008888929150998592
Valid Loss:  0.001056043547578156
Epoch:  497  	Training Loss: 0.000999543583020568
Test Loss:  0.0008854053448885679
Valid Loss:  0.0010519257048144937
Epoch:  498  	Training Loss: 0.0009956974536180496
Test Loss:  0.0008819405920803547
Valid Loss:  0.0010478273034095764
Epoch:  499  	Training Loss: 0.0009918739087879658
Test Loss:  0.0008784928359091282
Valid Loss:  0.0010437588207423687
Epoch:  500  	Training Loss: 0.0009880720172077417
Test Loss:  0.0008750689448788762
Valid Loss:  0.0010397135047242045
seed is  15
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:46,  6.35s/it]  1%|          | 3/500 [00:06<14:03,  1.70s/it]  1%|          | 5/500 [00:06<07:05,  1.16it/s]  1%|▏         | 7/500 [00:06<04:17,  1.91it/s]  2%|▏         | 9/500 [00:06<02:52,  2.85it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:09,  1.57it/s]  3%|▎         | 17/500 [00:13<03:41,  2.19it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:20<09:39,  1.21s/it]  5%|▍         | 23/500 [00:20<06:51,  1.16it/s]  5%|▌         | 25/500 [00:20<04:55,  1.61it/s]  5%|▌         | 27/500 [00:20<03:34,  2.20it/s]  6%|▌         | 29/500 [00:20<02:38,  2.97it/s]  6%|▌         | 31/500 [00:26<09:18,  1.19s/it]  7%|▋         | 33/500 [00:27<06:39,  1.17it/s]  7%|▋         | 35/500 [00:33<12:00,  1.55s/it]  7%|▋         | 37/500 [00:33<08:31,  1.11s/it]  8%|▊         | 39/500 [00:33<06:05,  1.26it/s]  8%|▊         | 41/500 [00:40<11:27,  1.50s/it]  9%|▊         | 43/500 [00:40<08:09,  1.07s/it]  9%|▉         | 45/500 [00:40<05:49,  1.30it/s]  9%|▉         | 47/500 [00:40<04:14,  1.78it/s] 10%|▉         | 49/500 [00:40<03:08,  2.39it/s] 10%|█         | 51/500 [00:47<09:24,  1.26s/it] 11%|█         | 53/500 [00:47<06:42,  1.11it/s] 11%|█         | 55/500 [00:47<04:49,  1.54it/s] 11%|█▏        | 57/500 [00:47<03:30,  2.11it/s] 12%|█▏        | 59/500 [00:47<02:35,  2.84it/s] 12%|█▏        | 61/500 [00:53<08:42,  1.19s/it] 13%|█▎        | 63/500 [00:54<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:54<04:28,  1.62it/s] 13%|█▎        | 67/500 [00:54<03:15,  2.21it/s] 14%|█▍        | 69/500 [00:54<02:25,  2.97it/s]Epoch:  1  	Training Loss: 0.11484208703041077
Test Loss:  27.685344696044922
Valid Loss:  27.37813949584961
Epoch:  2  	Training Loss: 27.49394416809082
Test Loss:  1141.79931640625
Valid Loss:  1126.4453125
Epoch:  3  	Training Loss: 1134.3570556640625
Test Loss:  9.62403392791748
Valid Loss:  9.613468170166016
Epoch:  4  	Training Loss: 9.58865737915039
Test Loss:  8.227561950683594
Valid Loss:  8.202291488647461
Epoch:  5  	Training Loss: 8.154354095458984
Test Loss:  7.101113319396973
Valid Loss:  7.073177337646484
Epoch:  6  	Training Loss: 7.006150245666504
Test Loss:  6.190947532653809
Valid Loss:  6.169071197509766
Epoch:  7  	Training Loss: 6.086148262023926
Test Loss:  5.454461574554443
Valid Loss:  5.444808483123779
Epoch:  8  	Training Loss: 5.348618030548096
Test Loss:  4.857601165771484
Valid Loss:  4.8642683029174805
Epoch:  9  	Training Loss: 4.756996154785156
Test Loss:  4.3731184005737305
Valid Loss:  4.398688793182373
Epoch:  10  	Training Loss: 4.28216028213501
Test Loss:  3.9792184829711914
Valid Loss:  4.025158882141113
Epoch:  11  	Training Loss: 3.900904655456543
Test Loss:  3.658379554748535
Valid Loss:  3.7253217697143555
Epoch:  12  	Training Loss: 3.594593048095703
Test Loss:  479.8235168457031
Valid Loss:  474.2341613769531
Epoch:  13  	Training Loss: 477.97564697265625
Test Loss:  8.0083589553833
Valid Loss:  8.586844444274902
Epoch:  14  	Training Loss: 8.676061630249023
Test Loss:  3.793900966644287
Valid Loss:  4.050240993499756
Epoch:  15  	Training Loss: 4.087020397186279
Test Loss:  1.8621290922164917
Valid Loss:  1.9802403450012207
Epoch:  16  	Training Loss: 1.9924347400665283
Test Loss:  0.9542363286018372
Valid Loss:  1.0136405229568481
Epoch:  17  	Training Loss: 1.0139158964157104
Test Loss:  0.5197677612304688
Valid Loss:  0.55528724193573
Epoch:  18  	Training Loss: 0.5496131181716919
Test Loss:  0.308901846408844
Valid Loss:  0.3356814980506897
Epoch:  19  	Training Loss: 0.3269559144973755
Test Loss:  0.20530366897583008
Valid Loss:  0.2297295778989792
Epoch:  20  	Training Loss: 0.21939398348331451
Test Loss:  0.153798446059227
Valid Loss:  0.1783723682165146
Epoch:  21  	Training Loss: 0.16716238856315613
Test Loss:  0.12785762548446655
Valid Loss:  0.15339615941047668
Epoch:  22  	Training Loss: 0.1416950225830078
Test Loss:  2.034756660461426
Valid Loss:  2.0173263549804688
Epoch:  23  	Training Loss: 2.050462007522583
Test Loss:  1.6308465003967285
Valid Loss:  1.639641284942627
Epoch:  24  	Training Loss: 1.608025312423706
Test Loss:  0.052585843950510025
Valid Loss:  0.06392029672861099
Epoch:  25  	Training Loss: 0.06283245980739594
Test Loss:  0.036340683698654175
Valid Loss:  0.04456353932619095
Epoch:  26  	Training Loss: 0.04283788800239563
Test Loss:  0.02967114746570587
Valid Loss:  0.03588469326496124
Epoch:  27  	Training Loss: 0.03442914038896561
Test Loss:  0.024474304169416428
Valid Loss:  0.029418017715215683
Epoch:  28  	Training Loss: 0.027983922511339188
Test Loss:  0.020377114415168762
Valid Loss:  0.024513917043805122
Epoch:  29  	Training Loss: 0.023112349212169647
Test Loss:  0.017040366306900978
Valid Loss:  0.02051549032330513
Epoch:  30  	Training Loss: 0.019196901470422745
Test Loss:  0.01432860642671585
Valid Loss:  0.01729588583111763
Epoch:  31  	Training Loss: 0.016101624816656113
Test Loss:  0.012124240398406982
Valid Loss:  0.01466076634824276
Epoch:  32  	Training Loss: 0.013599423691630363
Test Loss:  0.023353813216090202
Valid Loss:  0.026654791086912155
Epoch:  33  	Training Loss: 0.024534322321414948
Test Loss:  0.04714232683181763
Valid Loss:  0.0459572970867157
Epoch:  34  	Training Loss: 0.047219060361385345
Test Loss:  0.022881045937538147
Valid Loss:  0.026153098791837692
Epoch:  35  	Training Loss: 0.02408762276172638
Test Loss:  0.01560470275580883
Valid Loss:  0.016920801252126694
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.01685362681746483
Test Loss:  0.014527934603393078
Valid Loss:  0.015862632542848587
Epoch:  37  	Training Loss: 0.01575969159603119
Test Loss:  0.014206990599632263
Valid Loss:  0.015528278425335884
Epoch:  38  	Training Loss: 0.01543063297867775
Test Loss:  0.013905689120292664
Valid Loss:  0.015215848572552204
Epoch:  39  	Training Loss: 0.015100391581654549
Test Loss:  0.013564111664891243
Valid Loss:  0.014890976250171661
Epoch:  40  	Training Loss: 0.01476047933101654
Test Loss:  0.01318977028131485
Valid Loss:  0.01452845148742199
Epoch:  41  	Training Loss: 0.014402339234948158
Test Loss:  0.012795984745025635
Valid Loss:  0.014133408665657043
Epoch:  42  	Training Loss: 0.013963030651211739
Test Loss:  0.005834199953824282
Valid Loss:  0.00663037970662117
Epoch:  43  	Training Loss: 0.006262481212615967
Test Loss:  0.004231512546539307
Valid Loss:  0.004473043605685234
Epoch:  44  	Training Loss: 0.004295832943171263
Test Loss:  0.0030330284498631954
Valid Loss:  0.002882673405110836
Epoch:  45  	Training Loss: 0.0028901221230626106
Test Loss:  0.0020966564770787954
Valid Loss:  0.001892267493531108
Epoch:  46  	Training Loss: 0.0019535026513040066
Test Loss:  0.0015036514960229397
Valid Loss:  0.0013289686758071184
Epoch:  47  	Training Loss: 0.0013822242617607117
Test Loss:  0.001094106468372047
Valid Loss:  0.0009997671004384756
Epoch:  48  	Training Loss: 0.0010105385445058346
Test Loss:  0.0008283432107418776
Valid Loss:  0.000798429420683533
Epoch:  49  	Training Loss: 0.0008006567368283868
Test Loss:  0.0006525643984787166
Valid Loss:  0.0006696395576000214
Epoch:  50  	Training Loss: 0.0006685747066512704
Test Loss:  0.0005432451725937426
Valid Loss:  0.0005899978568777442
Epoch:  51  	Training Loss: 0.0005903368000872433
Test Loss:  0.0004701603320427239
Valid Loss:  0.0005389268044382334
Epoch:  52  	Training Loss: 0.0005393100436776876
Test Loss:  0.00046618818305432796
Valid Loss:  0.000537065789103508
Epoch:  53  	Training Loss: 0.0005375135224312544
Test Loss:  0.0004631057381629944
Valid Loss:  0.0005340647185221314
Epoch:  54  	Training Loss: 0.0005360775394365191
Test Loss:  0.00045998042332939804
Valid Loss:  0.0005324527737684548
Epoch:  55  	Training Loss: 0.00053473433945328
Test Loss:  0.0004573141341097653
Valid Loss:  0.0005303627112880349
Epoch:  56  	Training Loss: 0.0005335691384971142
Test Loss:  0.0004545882693491876
Valid Loss:  0.0005289752734825015
Epoch:  57  	Training Loss: 0.0005324817611835897
Test Loss:  0.00045218292507342994
Valid Loss:  0.0005271228728815913
Epoch:  58  	Training Loss: 0.000531454395968467
Test Loss:  0.00044969108421355486
Valid Loss:  0.0005257984157651663
Epoch:  59  	Training Loss: 0.000530482386238873
Test Loss:  0.0004474697634577751
Valid Loss:  0.0005241596954874694
Epoch:  60  	Training Loss: 0.0005295439623296261
Test Loss:  0.0004451012355275452
Valid Loss:  0.0005228990921750665
Epoch:  61  	Training Loss: 0.00052856863476336
Test Loss:  0.000442947173723951
Valid Loss:  0.0005214688135311007
Epoch:  62  	Training Loss: 0.0005276564625091851
Test Loss:  0.0004392826813273132
Valid Loss:  0.0005200117011554539
Epoch:  63  	Training Loss: 0.0005263789789751172
Test Loss:  0.00043662736425176263
Valid Loss:  0.0005185863119550049
Epoch:  64  	Training Loss: 0.0005254041752777994
Test Loss:  0.000434376357588917
Valid Loss:  0.0005171867087483406
Epoch:  65  	Training Loss: 0.0005245208740234375
Test Loss:  0.00043231667950749397
Valid Loss:  0.0005158327403478324
Epoch:  66  	Training Loss: 0.0005236944416537881
Test Loss:  0.0004303844762034714
Valid Loss:  0.0005145372124388814
Epoch:  67  	Training Loss: 0.0005229124217294157
Test Loss:  0.000428562518209219
Valid Loss:  0.0005132999503985047
Epoch:  68  	Training Loss: 0.0005221691681072116
Test Loss:  0.0004268205084372312
Valid Loss:  0.0005121161229908466
Epoch:  69  	Training Loss: 0.0005214631673879921
Test Loss:  0.00042516065877862275
Valid Loss:  0.0005109870107844472
Epoch:  70  	Training Loss: 0.0005207915091887116
Test Loss:  0.00042358122300356627
Valid Loss:  0.0005099031841382384
Epoch:  71  	Training Loss: 0.0005201465683057904
Test Loss:  0.0004220616538077593
Valid Loss:   14%|█▍        | 71/500 [01:00<08:26,  1.18s/it] 15%|█▍        | 73/500 [01:00<06:02,  1.18it/s] 15%|█▌        | 75/500 [01:00<04:20,  1.63it/s] 15%|█▌        | 77/500 [01:01<03:09,  2.23it/s] 16%|█▌        | 79/500 [01:01<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:07<08:10,  1.17s/it] 17%|█▋        | 83/500 [01:07<05:50,  1.19it/s] 17%|█▋        | 85/500 [01:07<04:12,  1.64it/s] 17%|█▋        | 87/500 [01:07<03:04,  2.24it/s] 18%|█▊        | 89/500 [01:08<02:16,  3.02it/s] 18%|█▊        | 91/500 [01:14<07:59,  1.17s/it] 19%|█▊        | 93/500 [01:14<05:42,  1.19it/s] 19%|█▉        | 95/500 [01:14<04:06,  1.64it/s] 19%|█▉        | 97/500 [01:14<02:59,  2.24it/s] 20%|█▉        | 99/500 [01:14<02:13,  3.01it/s] 20%|██        | 101/500 [01:21<07:48,  1.17s/it] 21%|██        | 103/500 [01:21<05:34,  1.19it/s] 21%|██        | 105/500 [01:21<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:21<02:56,  2.23it/s] 22%|██▏       | 109/500 [01:21<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:27<07:34,  1.17s/it] 23%|██▎       | 113/500 [01:28<05:24,  1.19it/s] 23%|██▎       | 115/500 [01:28<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:28<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:28<02:06,  3.00it/s] 24%|██▍       | 121/500 [01:34<07:19,  1.16s/it] 25%|██▍       | 123/500 [01:34<05:15,  1.20it/s] 25%|██▌       | 125/500 [01:34<03:47,  1.65it/s] 25%|██▌       | 127/500 [01:35<02:45,  2.25it/s] 26%|██▌       | 129/500 [01:35<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:41<07:07,  1.16s/it] 27%|██▋       | 133/500 [01:41<05:05,  1.20it/s] 27%|██▋       | 135/500 [01:41<03:40,  1.66it/s] 27%|██▋       | 137/500 [01:41<02:40,  2.26it/s]0.0005088594043627381
Epoch:  72  	Training Loss: 0.000519532011821866
Test Loss:  0.0004209954640828073
Valid Loss:  0.0005080237751826644
Epoch:  73  	Training Loss: 0.0005189705407246947
Test Loss:  0.000419911986682564
Valid Loss:  0.000507283431943506
Epoch:  74  	Training Loss: 0.0005184444598853588
Test Loss:  0.0004188319726381451
Valid Loss:  0.0005065888399258256
Epoch:  75  	Training Loss: 0.0005179375875741243
Test Loss:  0.00041777134174481034
Valid Loss:  0.0005059284740127623
Epoch:  76  	Training Loss: 0.0005174442194402218
Test Loss:  0.00041668579797260463
Valid Loss:  0.0005050848121754825
Epoch:  77  	Training Loss: 0.0005168629577383399
Test Loss:  0.0004155812202952802
Valid Loss:  0.0005043240962550044
Epoch:  78  	Training Loss: 0.0005163586465641856
Test Loss:  0.00041462646913714707
Valid Loss:  0.0005036023212596774
Epoch:  79  	Training Loss: 0.0005159709835425019
Test Loss:  0.00041367532685399055
Valid Loss:  0.0005029104650020599
Epoch:  80  	Training Loss: 0.0005155958351679146
Test Loss:  0.0004127459251321852
Valid Loss:  0.0005022396799176931
Epoch:  81  	Training Loss: 0.0005152372759766877
Test Loss:  0.00041183881694450974
Valid Loss:  0.0005015850765630603
Epoch:  82  	Training Loss: 0.0005148882046341896
Test Loss:  0.0004115142801310867
Valid Loss:  0.0005007924628444016
Epoch:  83  	Training Loss: 0.0005146892508491874
Test Loss:  0.00041060656076297164
Valid Loss:  0.0005003797123208642
Epoch:  84  	Training Loss: 0.0005142420413903892
Test Loss:  0.0004099886573385447
Valid Loss:  0.0004993530455976725
Epoch:  85  	Training Loss: 0.0005136843537911773
Test Loss:  0.00040909909876063466
Valid Loss:  0.0004982930840924382
Epoch:  86  	Training Loss: 0.0005130642675794661
Test Loss:  0.00040819833520799875
Valid Loss:  0.0004969008732587099
Epoch:  87  	Training Loss: 0.0005124479066580534
Test Loss:  0.0004072062438353896
Valid Loss:  0.0004955552285537124
Epoch:  88  	Training Loss: 0.0005117395194247365
Test Loss:  0.00040627492126077414
Valid Loss:  0.0004939782666042447
Epoch:  89  	Training Loss: 0.0005108520854264498
Test Loss:  0.0004050960415042937
Valid Loss:  0.0004923158558085561
Epoch:  90  	Training Loss: 0.0005098349647596478
Test Loss:  0.0004038711776956916
Valid Loss:  0.0004905768437311053
Epoch:  91  	Training Loss: 0.0005087950266897678
Test Loss:  0.0004026516398880631
Valid Loss:  0.0004888626281172037
Epoch:  92  	Training Loss: 0.0005077780224382877
Test Loss:  0.00040125727537088096
Valid Loss:  0.0004888479597866535
Epoch:  93  	Training Loss: 0.000507598277181387
Test Loss:  0.00040061824256554246
Valid Loss:  0.0004884236259385943
Epoch:  94  	Training Loss: 0.0005074625369161367
Test Loss:  0.0003998595639131963
Valid Loss:  0.0004881421336904168
Epoch:  95  	Training Loss: 0.000507341290358454
Test Loss:  0.00039919267874211073
Valid Loss:  0.000487859157146886
Epoch:  96  	Training Loss: 0.0005072301719337702
Test Loss:  0.0003985585644841194
Valid Loss:  0.0004876009770669043
Epoch:  97  	Training Loss: 0.0005071356426924467
Test Loss:  0.00039794985787011683
Valid Loss:  0.00048740848433226347
Epoch:  98  	Training Loss: 0.0005070589832030237
Test Loss:  0.0003974360297434032
Valid Loss:  0.00048718799371272326
Epoch:  99  	Training Loss: 0.0005069858161732554
Test Loss:  0.00039694173028692603
Valid Loss:  0.00048699078615754843
Epoch:  100  	Training Loss: 0.0005069225444458425
Test Loss:  0.00039648497477173805
Valid Loss:  0.0004868089163210243
Epoch:  101  	Training Loss: 0.000506863696500659
Test Loss:  0.0003960491740144789
Valid Loss:  0.0004866356321144849
Epoch:  102  	Training Loss: 0.0005068069440312684
Test Loss:  0.00039586235652677715
Valid Loss:  0.00048662401968613267
Epoch:  103  	Training Loss: 0.0005067863967269659
Test Loss:  0.0003957042354159057
Valid Loss:  0.0004866174713242799
Epoch:  104  	Training Loss: 0.0005067703314125538
Test Loss:  0.000395577575545758
Valid Loss:  0.00048660830361768603
Epoch:  105  	Training Loss: 0.000506754033267498
Test Loss:  0.000395469949580729
Valid Loss:  0.0004866052477154881
Epoch:  106  	Training Loss: 0.0005067408201284707
Test Loss:  0.00039538409328088164
Valid Loss:  0.0004865982919000089
Epoch:  107  	Training Loss: 0.0005067285965196788
Test Loss:  0.00039531412767246366
Valid Loss:  0.0004865966038778424
Epoch:  108  	Training Loss: 0.0005067191086709499
Test Loss:  0.000395256036426872
Valid Loss:  0.00048659334424883127
Epoch:  109  	Training Loss: 0.0005067075835540891
Test Loss:  0.00039521121652796865
Valid Loss:  0.00048659564345143735
Epoch:  110  	Training Loss: 0.000506698852404952
Test Loss:  0.00039517536060884595
Valid Loss:  0.00048658886225894094
Epoch:  111  	Training Loss: 0.0005066907615400851
Test Loss:  0.0003951452090404928
Valid Loss:  0.00048658420564606786
Epoch:  112  	Training Loss: 0.000506680749822408
Test Loss:  0.00037012025131843984
Valid Loss:  0.0004703281738329679
Epoch:  113  	Training Loss: 0.0004894894082099199
Test Loss:  0.00035214098170399666
Valid Loss:  0.0004588000010699034
Epoch:  114  	Training Loss: 0.0004771985695697367
Test Loss:  0.00033744325628504157
Valid Loss:  0.00044921168591827154
Epoch:  115  	Training Loss: 0.0004670225316658616
Test Loss:  0.00032506859861314297
Valid Loss:  0.00043877045391127467
Epoch:  116  	Training Loss: 0.0004584469716064632
Test Loss:  0.00031486403895542026
Valid Loss:  0.0004299979191273451
Epoch:  117  	Training Loss: 0.00045111094368621707
Test Loss:  0.0003058982838410884
Valid Loss:  0.0004225621814839542
Epoch:  118  	Training Loss: 0.00044448242988437414
Test Loss:  0.00029835887835361063
Valid Loss:  0.00041594519279897213
Epoch:  119  	Training Loss: 0.00043874658877030015
Test Loss:  0.0002918191603384912
Valid Loss:  0.00040993819129653275
Epoch:  120  	Training Loss: 0.00043354491936042905
Test Loss:  0.0002855397469829768
Valid Loss:  0.0004036223981529474
Epoch:  121  	Training Loss: 0.00042871542973443866
Test Loss:  0.00027972678071819246
Valid Loss:  0.00039705756353214383
Epoch:  122  	Training Loss: 0.00042412785114720464
Test Loss:  0.000276785169262439
Valid Loss:  0.00039045687299221754
Epoch:  123  	Training Loss: 0.0004193673375993967
Test Loss:  0.0002742512442637235
Valid Loss:  0.000384819257305935
Epoch:  124  	Training Loss: 0.00041552112088538706
Test Loss:  0.00027182543999515474
Valid Loss:  0.000379675067961216
Epoch:  125  	Training Loss: 0.00041202298598363996
Test Loss:  0.00026958654052577913
Valid Loss:  0.00037487491499632597
Epoch:  126  	Training Loss: 0.00040875276317819953
Test Loss:  0.000267417955910787
Valid Loss:  0.0003704486880451441
Epoch:  127  	Training Loss: 0.0004059018101543188
Test Loss:  0.00026524640270508826
Valid Loss:  0.0003663082025013864
Epoch:  128  	Training Loss: 0.00040329614421352744
Test Loss:  0.00026321111363358796
Valid Loss:  0.0003625328536145389
Epoch:  129  	Training Loss: 0.0004010260454379022
Test Loss:  0.00026131822960451245
Valid Loss:  0.0003590738051570952
Epoch:  130  	Training Loss: 0.0003989438118878752
Test Loss:  0.00025958503829315305
Valid Loss:  0.0003557558520697057
Epoch:  131  	Training Loss: 0.0003969943500123918
Test Loss:  0.000257992185652256
Valid Loss:  0.00035272169043309987
Epoch:  132  	Training Loss: 0.00039522076258435845
Test Loss:  0.0002531322534196079
Valid Loss:  0.000349179666955024
Epoch:  133  	Training Loss: 0.00039212367846630514
Test Loss:  0.0002498513204045594
Valid Loss:  0.00034619716461747885
Epoch:  134  	Training Loss: 0.00038975916686467826
Test Loss:  0.0002469120954629034
Valid Loss:  0.00034313451033085585
Epoch:  135  	Training Loss: 0.00038731377571821213
Test Loss:  0.00024433358339592814
Valid Loss:  0.0003401091671548784
Epoch:  136  	Training Loss: 0.0003848983906209469
Test Loss:  0.00024199136532843113
Valid Loss:  0.00033717526821419597
Epoch:  137  	Training Loss: 0.0003825274179689586
Test Loss:  0.00023993555805645883
Valid Loss:  0.0003344999277032912
Epoch:  138  	Training Loss: 0.00038032321026548743
Test Loss:  0.00023812348081264645
Valid Loss:  0.00033201248152181506
Epoch:  139  	Training Loss: 0.0003782456333283335
Test Loss:  0.0002365109685342759
Valid Loss:   28%|██▊       | 139/500 [01:41<01:58,  3.04it/s] 28%|██▊       | 141/500 [01:48<06:59,  1.17s/it] 29%|██▊       | 143/500 [01:48<04:59,  1.19it/s] 29%|██▉       | 145/500 [01:48<03:35,  1.65it/s] 29%|██▉       | 147/500 [01:48<02:36,  2.25it/s] 30%|██▉       | 149/500 [01:48<01:56,  3.02it/s] 30%|███       | 151/500 [01:54<06:48,  1.17s/it] 31%|███       | 153/500 [01:55<04:51,  1.19it/s] 31%|███       | 155/500 [01:55<03:29,  1.64it/s] 31%|███▏      | 157/500 [01:55<02:32,  2.24it/s] 32%|███▏      | 159/500 [01:55<01:53,  3.02it/s] 32%|███▏      | 161/500 [02:01<06:36,  1.17s/it] 33%|███▎      | 163/500 [02:01<04:43,  1.19it/s] 33%|███▎      | 165/500 [02:02<03:24,  1.64it/s] 33%|███▎      | 167/500 [02:02<02:30,  2.22it/s] 34%|███▍      | 169/500 [02:02<01:50,  2.98it/s] 34%|███▍      | 171/500 [02:08<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:08<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:08<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:09<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:09<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:15<06:09,  1.16s/it] 37%|███▋      | 183/500 [02:15<04:23,  1.20it/s] 37%|███▋      | 185/500 [02:15<03:09,  1.66it/s] 37%|███▋      | 187/500 [02:15<02:18,  2.27it/s] 38%|███▊      | 189/500 [02:15<01:42,  3.04it/s] 38%|███▊      | 191/500 [02:22<05:58,  1.16s/it] 39%|███▊      | 193/500 [02:22<04:15,  1.20it/s] 39%|███▉      | 195/500 [02:22<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:22<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:22<01:42,  2.94it/s] 40%|████      | 201/500 [02:29<05:56,  1.19s/it] 41%|████      | 203/500 [02:29<04:14,  1.17it/s] 41%|████      | 205/500 [02:29<03:02,  1.62it/s]0.00032969252788461745
Epoch:  140  	Training Loss: 0.00037624279502779245
Test Loss:  0.00023496367793995887
Valid Loss:  0.0003273310139775276
Epoch:  141  	Training Loss: 0.0003741846885532141
Test Loss:  0.00023354942095465958
Valid Loss:  0.00032511126482859254
Epoch:  142  	Training Loss: 0.00037220888771116734
Test Loss:  0.00023386243265122175
Valid Loss:  0.000323122541885823
Epoch:  143  	Training Loss: 0.0003694925981108099
Test Loss:  0.00023387603869196028
Valid Loss:  0.000321411615004763
Epoch:  144  	Training Loss: 0.00036721082869917154
Test Loss:  0.000233859071158804
Valid Loss:  0.0003199581115040928
Epoch:  145  	Training Loss: 0.0003652597952168435
Test Loss:  0.00023390425485558808
Valid Loss:  0.0003187363035976887
Epoch:  146  	Training Loss: 0.00036358280340209603
Test Loss:  0.00023401735234074295
Valid Loss:  0.00031772148213349283
Epoch:  147  	Training Loss: 0.0003621470823418349
Test Loss:  0.00023420830257236958
Valid Loss:  0.0003168843686580658
Epoch:  148  	Training Loss: 0.0003609159030020237
Test Loss:  0.00023445684928447008
Valid Loss:  0.00031619518995285034
Epoch:  149  	Training Loss: 0.00035986246075481176
Test Loss:  0.00023475773923564702
Valid Loss:  0.0003156348248012364
Epoch:  150  	Training Loss: 0.0003589545958675444
Test Loss:  0.00023509821039624512
Valid Loss:  0.00031518290052190423
Epoch:  151  	Training Loss: 0.0003581773198675364
Test Loss:  0.00023545451404061168
Valid Loss:  0.00031481526093557477
Epoch:  152  	Training Loss: 0.0003575124137569219
Test Loss:  0.00023475046327803284
Valid Loss:  0.00031204608967527747
Epoch:  153  	Training Loss: 0.00035581167321652174
Test Loss:  0.0002340931969229132
Valid Loss:  0.0003094025596510619
Epoch:  154  	Training Loss: 0.00035423244116827846
Test Loss:  0.00023356344900093973
Valid Loss:  0.0003069882222916931
Epoch:  155  	Training Loss: 0.0003527535009197891
Test Loss:  0.00023301246983464807
Valid Loss:  0.0003047680947929621
Epoch:  156  	Training Loss: 0.00035135942744091153
Test Loss:  0.00023241584131028503
Valid Loss:  0.00030263332882896066
Epoch:  157  	Training Loss: 0.0003500347665976733
Test Loss:  0.00023165068705566227
Valid Loss:  0.00030063005397096276
Epoch:  158  	Training Loss: 0.00034875975688919425
Test Loss:  0.00023083508131094277
Valid Loss:  0.0002987846964970231
Epoch:  159  	Training Loss: 0.000347458990290761
Test Loss:  0.000229972560191527
Valid Loss:  0.0002969285997096449
Epoch:  160  	Training Loss: 0.0003460920415818691
Test Loss:  0.00022906900267116725
Valid Loss:  0.0002950693015009165
Epoch:  161  	Training Loss: 0.0003447424969635904
Test Loss:  0.0002281898632645607
Valid Loss:  0.0002933574724011123
Epoch:  162  	Training Loss: 0.00034353905357420444
Test Loss:  0.0002264773938804865
Valid Loss:  0.0002919282705988735
Epoch:  163  	Training Loss: 0.0003423524904064834
Test Loss:  0.00022504445223603398
Valid Loss:  0.00029057072242721915
Epoch:  164  	Training Loss: 0.0003412709920667112
Test Loss:  0.00022377543791662902
Valid Loss:  0.0002892565098591149
Epoch:  165  	Training Loss: 0.00034024129854515195
Test Loss:  0.00022259044635575265
Valid Loss:  0.00028792436933144927
Epoch:  166  	Training Loss: 0.00033918028930202127
Test Loss:  0.00022147007985040545
Valid Loss:  0.00028662668773904443
Epoch:  167  	Training Loss: 0.0003381549322512001
Test Loss:  0.00022039961186237633
Valid Loss:  0.00028536957688629627
Epoch:  168  	Training Loss: 0.00033713242737576365
Test Loss:  0.00021932725212536752
Valid Loss:  0.00028407794889062643
Epoch:  169  	Training Loss: 0.0003360759874340147
Test Loss:  0.00021828686294611543
Valid Loss:  0.0002828243013937026
Epoch:  170  	Training Loss: 0.0003350455081090331
Test Loss:  0.00021728080173488706
Valid Loss:  0.0002816061023622751
Epoch:  171  	Training Loss: 0.0003340492839924991
Test Loss:  0.00021630115224979818
Valid Loss:  0.00028042259509675205
Epoch:  172  	Training Loss: 0.0003330751205794513
Test Loss:  0.000217891632928513
Valid Loss:  0.00027981202583760023
Epoch:  173  	Training Loss: 0.0003318612580187619
Test Loss:  0.00021791650215163827
Valid Loss:  0.0002789890277199447
Epoch:  174  	Training Loss: 0.0003310156462248415
Test Loss:  0.00021739376825280488
Valid Loss:  0.00027804955607280135
Epoch:  175  	Training Loss: 0.00033022824209183455
Test Loss:  0.00021668263070750982
Valid Loss:  0.0002770448918454349
Epoch:  176  	Training Loss: 0.0003294019843451679
Test Loss:  0.0002157883282052353
Valid Loss:  0.00027605833020061255
Epoch:  177  	Training Loss: 0.0003286090213805437
Test Loss:  0.00021490822837222368
Valid Loss:  0.0002751027641352266
Epoch:  178  	Training Loss: 0.0003278455405961722
Test Loss:  0.00021405295410659164
Valid Loss:  0.00027417950332164764
Epoch:  179  	Training Loss: 0.0003271099994890392
Test Loss:  0.00021322684187907726
Valid Loss:  0.00027328822761774063
Epoch:  180  	Training Loss: 0.0003263921826146543
Test Loss:  0.00021239831403363496
Valid Loss:  0.0002723879588302225
Epoch:  181  	Training Loss: 0.00032563362037763
Test Loss:  0.0002115629322361201
Valid Loss:  0.0002714828588068485
Epoch:  182  	Training Loss: 0.0003248460416216403
Test Loss:  0.0002056924276985228
Valid Loss:  0.00026688395882956684
Epoch:  183  	Training Loss: 0.0003205334360245615
Test Loss:  0.00020169082563370466
Valid Loss:  0.0002635079436004162
Epoch:  184  	Training Loss: 0.0003171161806676537
Test Loss:  0.0001985048729693517
Valid Loss:  0.00026070716558024287
Epoch:  185  	Training Loss: 0.00031407311325892806
Test Loss:  0.00019559286010917276
Valid Loss:  0.0002582013257779181
Epoch:  186  	Training Loss: 0.0003112194826826453
Test Loss:  0.00019311968935653567
Valid Loss:  0.00025591906160116196
Epoch:  187  	Training Loss: 0.00030860750121064484
Test Loss:  0.00019095974857918918
Valid Loss:  0.000253814592724666
Epoch:  188  	Training Loss: 0.00030616295407526195
Test Loss:  0.000188991311006248
Valid Loss:  0.00025181466480717063
Epoch:  189  	Training Loss: 0.00030370295280590653
Test Loss:  0.0001871892309281975
Valid Loss:  0.0002498934045433998
Epoch:  190  	Training Loss: 0.000301308959024027
Test Loss:  0.00018549984088167548
Valid Loss:  0.0002480408875271678
Epoch:  191  	Training Loss: 0.00029892506427131593
Test Loss:  0.00018391093180980533
Valid Loss:  0.0002462342381477356
Epoch:  192  	Training Loss: 0.00029663191526196897
Test Loss:  0.00018443037697579712
Valid Loss:  0.0002458644157741219
Epoch:  193  	Training Loss: 0.0002957743126899004
Test Loss:  0.00018487198394723237
Valid Loss:  0.00024555157870054245
Epoch:  194  	Training Loss: 0.0002950498601421714
Test Loss:  0.0001852383284131065
Valid Loss:  0.0002452601620461792
Epoch:  195  	Training Loss: 0.0002944147272501141
Test Loss:  0.00018553250993136317
Valid Loss:  0.0002449873718433082
Epoch:  196  	Training Loss: 0.00029384432127699256
Test Loss:  0.00018576232832856476
Valid Loss:  0.0002447209844831377
Epoch:  197  	Training Loss: 0.00029332481790333986
Test Loss:  0.00018593859567772597
Valid Loss:  0.0002444532292429358
Epoch:  198  	Training Loss: 0.0002928371832240373
Test Loss:  0.00018606914090923965
Valid Loss:  0.0002441867836751044
Epoch:  199  	Training Loss: 0.00029238028218969703
Test Loss:  0.0001861623313743621
Valid Loss:  0.00024392057093791664
Epoch:  200  	Training Loss: 0.0002919448888860643
Test Loss:  0.00018622484640218318
Valid Loss:  0.0002436524082440883
Epoch:  201  	Training Loss: 0.0002915259392466396
Test Loss:  0.00018626239034347236
Valid Loss:  0.0002433830959489569
Epoch:  202  	Training Loss: 0.0002911255578510463
Test Loss:  0.00018264687969349325
Valid Loss:  0.0002401420788373798
Epoch:  203  	Training Loss: 0.0002886444563046098
Test Loss:  0.0001805239007808268
Valid Loss:  0.00023807268007658422
Epoch:  204  	Training Loss: 0.0002869874588213861
Test Loss:  0.00017903893603943288
Valid Loss:  0.00023648148635402322
Epoch:  205  	Training Loss: 0.0002855964994523674
Test Loss:  0.00017784812371246517
Valid Loss:  0.00023509639140684158
Epoch:  206  	Training Loss: 0.0002843085676431656
Test Loss:  0.00017681388999335468
Valid Loss:  0.00023381806386169046
 41%|████▏     | 207/500 [02:29<02:13,  2.20it/s] 42%|████▏     | 209/500 [02:29<01:38,  2.96it/s] 42%|████▏     | 211/500 [02:35<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:35<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:36<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:36<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:36<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:42<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:42<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:43<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:43<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:43<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:49<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:49<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:49<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:50<01:58,  2.21it/s] 48%|████▊     | 239/500 [02:50<01:27,  2.98it/s] 48%|████▊     | 241/500 [02:56<05:01,  1.17s/it] 49%|████▊     | 243/500 [02:56<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:56<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:56<01:52,  2.24it/s] 50%|████▉     | 249/500 [02:56<01:23,  3.01it/s] 50%|█████     | 251/500 [03:03<04:50,  1.17s/it] 51%|█████     | 253/500 [03:03<03:26,  1.19it/s] 51%|█████     | 255/500 [03:03<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:03<01:47,  2.25it/s] 52%|█████▏    | 259/500 [03:03<01:19,  3.02it/s] 52%|█████▏    | 261/500 [03:10<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:10<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:10<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:10<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:10<01:18,  2.96it/s] 54%|█████▍    | 271/500 [03:16<04:27,  1.17s/it] 55%|█████▍    | 273/500 [03:17<03:10,  1.19it/s]Epoch:  207  	Training Loss: 0.0002830668818205595
Test Loss:  0.00017587470938451588
Valid Loss:  0.00023261144815478474
Epoch:  208  	Training Loss: 0.0002818596549332142
Test Loss:  0.00017498972010798752
Valid Loss:  0.00023144451552070677
Epoch:  209  	Training Loss: 0.00028067611856386065
Test Loss:  0.00017414400645066053
Valid Loss:  0.0002303127257619053
Epoch:  210  	Training Loss: 0.00027951577794738114
Test Loss:  0.00017333119467366487
Valid Loss:  0.00022920944320503622
Epoch:  211  	Training Loss: 0.0002783778472803533
Test Loss:  0.00017254348495043814
Valid Loss:  0.000228129283641465
Epoch:  212  	Training Loss: 0.00027726154075935483
Test Loss:  0.00017267382645513862
Valid Loss:  0.0002280490007251501
Epoch:  213  	Training Loss: 0.00027703522937372327
Test Loss:  0.00017280137399211526
Valid Loss:  0.0002279728214489296
Epoch:  214  	Training Loss: 0.00027682201471179724
Test Loss:  0.00017292385746259242
Valid Loss:  0.00022789988724980503
Epoch:  215  	Training Loss: 0.0002766186953522265
Test Loss:  0.00017304027278441936
Valid Loss:  0.0002278305619256571
Epoch:  216  	Training Loss: 0.0002764236996881664
Test Loss:  0.00017314704018644989
Valid Loss:  0.0002277606981806457
Epoch:  217  	Training Loss: 0.0002762344083748758
Test Loss:  0.0001732526725390926
Valid Loss:  0.0002276893355883658
Epoch:  218  	Training Loss: 0.00027605274226516485
Test Loss:  0.00017335359007120132
Valid Loss:  0.00022762334265280515
Epoch:  219  	Training Loss: 0.0002758774207904935
Test Loss:  0.00017345142259728163
Valid Loss:  0.00022755948884878308
Epoch:  220  	Training Loss: 0.0002757068141363561
Test Loss:  0.00017353985458612442
Valid Loss:  0.0002274921425851062
Epoch:  221  	Training Loss: 0.0002755412133410573
Test Loss:  0.000173627253388986
Valid Loss:  0.00022742408327758312
Epoch:  222  	Training Loss: 0.00027538108406588435
Test Loss:  0.00017425284022465348
Valid Loss:  0.00022743153385818005
Epoch:  223  	Training Loss: 0.00027493800735101104
Test Loss:  0.00017483640112914145
Valid Loss:  0.0002274870639666915
Epoch:  224  	Training Loss: 0.0002746125974226743
Test Loss:  0.00017537099483888596
Valid Loss:  0.00022757949773222208
Epoch:  225  	Training Loss: 0.0002743785735219717
Test Loss:  0.00017585654859431088
Valid Loss:  0.00022768552298657596
Epoch:  226  	Training Loss: 0.00027420546393841505
Test Loss:  0.00017628693603910506
Valid Loss:  0.00022779761638958007
Epoch:  227  	Training Loss: 0.0002740813069976866
Test Loss:  0.0001766685745678842
Valid Loss:  0.0002279068430652842
Epoch:  228  	Training Loss: 0.00027398852398619056
Test Loss:  0.00017700584430713207
Valid Loss:  0.00022801304294262081
Epoch:  229  	Training Loss: 0.00027392141055315733
Test Loss:  0.00017729905084706843
Valid Loss:  0.0002281103515997529
Epoch:  230  	Training Loss: 0.00027387432055547833
Test Loss:  0.0001775567652657628
Valid Loss:  0.0002281974593643099
Epoch:  231  	Training Loss: 0.0002738379407674074
Test Loss:  0.0001777802681317553
Valid Loss:  0.00022828002693131566
Epoch:  232  	Training Loss: 0.0002738111943472177
Test Loss:  0.0001751862291712314
Valid Loss:  0.00022566480038221925
Epoch:  233  	Training Loss: 0.0002714637666940689
Test Loss:  0.0001758888247422874
Valid Loss:  0.00022458478633780032
Epoch:  234  	Training Loss: 0.0002693389542400837
Test Loss:  0.0001746054767863825
Valid Loss:  0.00022274233924690634
Epoch:  235  	Training Loss: 0.0002673559938557446
Test Loss:  0.0001746292255120352
Valid Loss:  0.00022157171042636037
Epoch:  236  	Training Loss: 0.00026552943745628
Test Loss:  0.00017375501920469105
Valid Loss:  0.00022009870735928416
Epoch:  237  	Training Loss: 0.0002638173755258322
Test Loss:  0.0001734872057568282
Valid Loss:  0.0002189349615946412
Epoch:  238  	Training Loss: 0.0002621948078740388
Test Loss:  0.000172836022102274
Valid Loss:  0.00021765629935543984
Epoch:  239  	Training Loss: 0.0002606493071652949
Test Loss:  0.00017246326024178416
Valid Loss:  0.0002165495534427464
Epoch:  240  	Training Loss: 0.0002591805241536349
Test Loss:  0.00017183551972266287
Valid Loss:  0.00021537728025577962
Epoch:  241  	Training Loss: 0.0002577726845629513
Test Loss:  0.00017135500092990696
Valid Loss:  0.0002143043966498226
Epoch:  242  	Training Loss: 0.0002564157475717366
Test Loss:  0.0001721061416901648
Valid Loss:  0.00021398704848252237
Epoch:  243  	Training Loss: 0.00025532604195177555
Test Loss:  0.00017020234372466803
Valid Loss:  0.000212372891837731
Epoch:  244  	Training Loss: 0.00025430144160054624
Test Loss:  0.00016986997798085213
Valid Loss:  0.00021158249001018703
Epoch:  245  	Training Loss: 0.0002532931393943727
Test Loss:  0.00016866278019733727
Valid Loss:  0.00021035301324445754
Epoch:  246  	Training Loss: 0.0002522761933505535
Test Loss:  0.00016797900025267154
Valid Loss:  0.00020940903050359339
Epoch:  247  	Training Loss: 0.00025129830464720726
Test Loss:  0.00016706250607967377
Valid Loss:  0.00020836690964642912
Epoch:  248  	Training Loss: 0.0002503616560716182
Test Loss:  0.00016635027714073658
Valid Loss:  0.00020742023480124772
Epoch:  249  	Training Loss: 0.0002494655200280249
Test Loss:  0.00016555862384848297
Valid Loss:  0.0002064497966784984
Epoch:  250  	Training Loss: 0.00024859007680788636
Test Loss:  0.00016484911611769348
Valid Loss:  0.00020554264483507723
Epoch:  251  	Training Loss: 0.0002477532543707639
Test Loss:  0.00016414184938184917
Valid Loss:  0.0002046453591901809
Epoch:  252  	Training Loss: 0.0002469477476552129
Test Loss:  0.00015904034080449492
Valid Loss:  0.00019959788187406957
Epoch:  253  	Training Loss: 0.00024229363771155477
Test Loss:  0.0001553210022393614
Valid Loss:  0.00019601026724558324
Epoch:  254  	Training Loss: 0.0002385331317782402
Test Loss:  0.00015204286319203675
Valid Loss:  0.00019304885063320398
Epoch:  255  	Training Loss: 0.00023548568424303085
Test Loss:  0.00014934429782442749
Valid Loss:  0.00019062458886764944
Epoch:  256  	Training Loss: 0.0002328365808352828
Test Loss:  0.00014708373055327684
Valid Loss:  0.00018849970365408808
Epoch:  257  	Training Loss: 0.00023036751372274011
Test Loss:  0.00014486147847492248
Valid Loss:  0.00018652222934179008
Epoch:  258  	Training Loss: 0.00022783491294831038
Test Loss:  0.00014272538828663528
Valid Loss:  0.00018466889741830528
Epoch:  259  	Training Loss: 0.00022553402232006192
Test Loss:  0.00014089552860241383
Valid Loss:  0.00018300439114682376
Epoch:  260  	Training Loss: 0.00022339765564538538
Test Loss:  0.00013925074017606676
Valid Loss:  0.00018145711510442197
Epoch:  261  	Training Loss: 0.00022138455824460834
Test Loss:  0.0001378029555780813
Valid Loss:  0.00018000656564254314
Epoch:  262  	Training Loss: 0.00021944017498753965
Test Loss:  0.00013714696979150176
Valid Loss:  0.00017934449715539813
Epoch:  263  	Training Loss: 0.00021776033099740744
Test Loss:  0.00013635032519232482
Valid Loss:  0.0001784363412298262
Epoch:  264  	Training Loss: 0.0002162572054658085
Test Loss:  0.0001355141430394724
Valid Loss:  0.00017745008517522365
Epoch:  265  	Training Loss: 0.00021479569841176271
Test Loss:  0.00013469159603118896
Valid Loss:  0.00017645613115746528
Epoch:  266  	Training Loss: 0.0002133459784090519
Test Loss:  0.0001338739530183375
Valid Loss:  0.00017549176118336618
Epoch:  267  	Training Loss: 0.00021187012316659093
Test Loss:  0.00013305808533914387
Valid Loss:  0.0001745154440868646
Epoch:  268  	Training Loss: 0.00021042939624749124
Test Loss:  0.0001322911266470328
Valid Loss:  0.0001735634868964553
Epoch:  269  	Training Loss: 0.00020903264521621168
Test Loss:  0.00013154710177332163
Valid Loss:  0.00017262890469282866
Epoch:  270  	Training Loss: 0.0002076589735224843
Test Loss:  0.0001308255596086383
Valid Loss:  0.00017170517821796238
Epoch:  271  	Training Loss: 0.00020631004008464515
Test Loss:  0.0001301322045037523
Valid Loss:  0.0001708046765998006
Epoch:  272  	Training Loss: 0.0002049835165962577
Test Loss:  0.00012795609654858708
Valid Loss:  0.0001674283412285149
Epoch:  273  	Training Loss: 0.00020328600658103824
Test Loss:  0.0001314641413046047
Valid Loss:  0.00017006369307637215
 55%|█████▌    | 275/500 [03:17<02:17,  1.64it/s] 55%|█████▌    | 277/500 [03:17<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:17<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:29<07:37,  2.09s/it] 57%|█████▋    | 283/500 [03:29<05:22,  1.49s/it] 57%|█████▋    | 285/500 [03:30<03:47,  1.06s/it] 57%|█████▋    | 287/500 [03:30<02:42,  1.31it/s] 58%|█████▊    | 289/500 [03:30<01:56,  1.81it/s] 58%|█████▊    | 291/500 [03:36<04:38,  1.33s/it] 59%|█████▊    | 293/500 [03:36<03:17,  1.05it/s] 59%|█████▉    | 295/500 [03:36<02:20,  1.45it/s] 59%|█████▉    | 297/500 [03:37<01:41,  2.00it/s] 60%|█████▉    | 299/500 [03:37<01:14,  2.70it/s] 60%|██████    | 301/500 [03:43<03:58,  1.20s/it] 61%|██████    | 303/500 [03:43<02:49,  1.16it/s] 61%|██████    | 305/500 [03:43<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:43<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:43<01:04,  2.95it/s] 62%|██████▏   | 311/500 [03:50<03:40,  1.16s/it] 63%|██████▎   | 313/500 [03:50<02:36,  1.20it/s] 63%|██████▎   | 315/500 [03:50<01:51,  1.65it/s] 63%|██████▎   | 317/500 [03:50<01:21,  2.26it/s] 64%|██████▍   | 319/500 [03:50<00:59,  3.03it/s] 64%|██████▍   | 321/500 [03:57<03:30,  1.18s/it] 65%|██████▍   | 323/500 [03:57<02:29,  1.18it/s] 65%|██████▌   | 325/500 [03:57<01:47,  1.63it/s] 65%|██████▌   | 327/500 [03:57<01:17,  2.23it/s] 66%|██████▌   | 329/500 [03:57<00:57,  3.00it/s] 66%|██████▌   | 331/500 [04:03<03:20,  1.19s/it] 67%|██████▋   | 333/500 [04:04<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:04<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:04<01:13,  2.21it/s] 68%|██████▊   | 339/500 [04:04<00:54,  2.98it/s]Epoch:  274  	Training Loss: 0.0002022269181907177
Test Loss:  0.00012857488763984293
Valid Loss:  0.00016609157319180667
Epoch:  275  	Training Loss: 0.00020198845595587045
Test Loss:  0.00013633329945150763
Valid Loss:  0.0001733666140353307
Epoch:  276  	Training Loss: 0.00020292893168516457
Test Loss:  0.00013313590898178518
Valid Loss:  0.00016878002497833222
Epoch:  277  	Training Loss: 0.00020585245511028916
Test Loss:  0.00015108336810953915
Valid Loss:  0.000186610734090209
Epoch:  278  	Training Loss: 0.00021245144307613373
Test Loss:  0.00015209231059998274
Valid Loss:  0.0001852136483648792
Epoch:  279  	Training Loss: 0.00022550078574568033
Test Loss:  0.00019865731883328408
Valid Loss:  0.00023149537446442991
Epoch:  280  	Training Loss: 0.000251565536018461
Test Loss:  0.0002247794473078102
Valid Loss:  0.00025258405366912484
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.0002998655254486948
Test Loss:  0.00021369545720517635
Valid Loss:  0.0002406285348115489
Epoch:  282  	Training Loss: 0.00028542717336677015
Test Loss:  0.00016983531531877816
Valid Loss:  0.00019429120584391057
Epoch:  283  	Training Loss: 0.0002266569499624893
Test Loss:  0.00015935824194457382
Valid Loss:  0.00018357581575401127
Epoch:  284  	Training Loss: 0.00020960811525583267
Test Loss:  0.00015677724150009453
Valid Loss:  0.00018121565517503768
Epoch:  285  	Training Loss: 0.00020393329032231122
Test Loss:  0.000155750778503716
Valid Loss:  0.00018045745673589408
Epoch:  286  	Training Loss: 0.00020144018344581127
Test Loss:  0.00015483977040275931
Valid Loss:  0.0001797869335860014
Epoch:  287  	Training Loss: 0.00019984980463050306
Test Loss:  0.00015380882541649044
Valid Loss:  0.00017897234647534788
Epoch:  288  	Training Loss: 0.0001985382696148008
Test Loss:  0.00015268934657797217
Valid Loss:  0.00017804393428377807
Epoch:  289  	Training Loss: 0.00019733321096282452
Test Loss:  0.00015151957632042468
Valid Loss:  0.0001770544477039948
Epoch:  290  	Training Loss: 0.00019618755322881043
Test Loss:  0.00015034197713248432
Valid Loss:  0.0001760507293511182
Epoch:  291  	Training Loss: 0.00019508606055751443
Test Loss:  0.0001491829752922058
Valid Loss:  0.0001750507508404553
Epoch:  292  	Training Loss: 0.00019402435282245278
Test Loss:  0.00014763307990506291
Valid Loss:  0.00017488868616055697
Epoch:  293  	Training Loss: 0.00019166202400811017
Test Loss:  0.00014714713324792683
Valid Loss:  0.00017402248340658844
Epoch:  294  	Training Loss: 0.00019127133418805897
Test Loss:  0.00014713176642544568
Valid Loss:  0.00017413278692401946
Epoch:  295  	Training Loss: 0.00019109537242911756
Test Loss:  0.00014704902423545718
Valid Loss:  0.00017405420658178627
Epoch:  296  	Training Loss: 0.00019096850883215666
Test Loss:  0.0001469980488764122
Valid Loss:  0.00017406178812962025
Epoch:  297  	Training Loss: 0.00019086671818513423
Test Loss:  0.00014693943376187235
Valid Loss:  0.00017404143000021577
Epoch:  298  	Training Loss: 0.0001907760015456006
Test Loss:  0.00014688597002532333
Valid Loss:  0.00017403335368726403
Epoch:  299  	Training Loss: 0.00019069462723564357
Test Loss:  0.00014683199697174132
Valid Loss:  0.00017401012883055955
Epoch:  300  	Training Loss: 0.00019061524653807282
Test Loss:  0.00014677896979264915
Valid Loss:  0.00017399233183823526
Epoch:  301  	Training Loss: 0.0001905353128677234
Test Loss:  0.00014673045370727777
Valid Loss:  0.00017396628390997648
Epoch:  302  	Training Loss: 0.00019046379020437598
Test Loss:  0.00014566717436537147
Valid Loss:  0.00017297174781560898
Epoch:  303  	Training Loss: 0.00018965109484270215
Test Loss:  0.0001446575188310817
Valid Loss:  0.00017203681636601686
Epoch:  304  	Training Loss: 0.00018887617625296116
Test Loss:  0.00014369326527230442
Valid Loss:  0.0001711537188384682
Epoch:  305  	Training Loss: 0.00018813140923157334
Test Loss:  0.0001427547977073118
Valid Loss:  0.0001702985173324123
Epoch:  306  	Training Loss: 0.00018737581558525562
Test Loss:  0.0001418468018528074
Valid Loss:  0.000169478909811005
Epoch:  307  	Training Loss: 0.00018664852541405708
Test Loss:  0.00014097429811954498
Valid Loss:  0.00016869392129592597
Epoch:  308  	Training Loss: 0.00018594632274471223
Test Loss:  0.00014013503096066415
Valid Loss:  0.00016794487601146102
Epoch:  309  	Training Loss: 0.0001852667483035475
Test Loss:  0.00013926361862104386
Valid Loss:  0.00016722676809877157
Epoch:  310  	Training Loss: 0.0001846126397140324
Test Loss:  0.00013840501196682453
Valid Loss:  0.000166505720699206
Epoch:  311  	Training Loss: 0.00018397902022115886
Test Loss:  0.00013757914712186903
Valid Loss:  0.00016576508642174304
Epoch:  312  	Training Loss: 0.0001833657588576898
Test Loss:  0.00013728148769587278
Valid Loss:  0.00016548781422898173
Epoch:  313  	Training Loss: 0.00018325314158573747
Test Loss:  0.00013700831914320588
Valid Loss:  0.0001652391511015594
Epoch:  314  	Training Loss: 0.0001831510162446648
Test Loss:  0.0001367575750919059
Valid Loss:  0.00016501653590239584
Epoch:  315  	Training Loss: 0.00018305731646250933
Test Loss:  0.00013652310008183122
Valid Loss:  0.00016481074271723628
Epoch:  316  	Training Loss: 0.0001829679822549224
Test Loss:  0.0001363002957077697
Valid Loss:  0.00016461944323964417
Epoch:  317  	Training Loss: 0.00018288528372067958
Test Loss:  0.00013608943845611066
Valid Loss:  0.00016443875210825354
Epoch:  318  	Training Loss: 0.00018280779477208853
Test Loss:  0.00013588623551186174
Valid Loss:  0.00016427099762950093
Epoch:  319  	Training Loss: 0.00018273148452863097
Test Loss:  0.00013569649308919907
Valid Loss:  0.00016411193064413965
Epoch:  320  	Training Loss: 0.00018266089318785816
Test Loss:  0.00013551089796237648
Valid Loss:  0.00016395674902014434
Epoch:  321  	Training Loss: 0.00018259229545947164
Test Loss:  0.00013532934826798737
Valid Loss:  0.0001638089888729155
Epoch:  322  	Training Loss: 0.00018252585141453892
Test Loss:  0.00013478715845849365
Valid Loss:  0.00016333890380337834
Epoch:  323  	Training Loss: 0.0001820217294152826
Test Loss:  0.00013425882207229733
Valid Loss:  0.00016288203187286854
Epoch:  324  	Training Loss: 0.00018153293058276176
Test Loss:  0.00013374327681958675
Valid Loss:  0.00016243525897152722
Epoch:  325  	Training Loss: 0.00018105762137565762
Test Loss:  0.00013324654719326645
Valid Loss:  0.0001619944378035143
Epoch:  326  	Training Loss: 0.0001805927895475179
Test Loss:  0.0001327475911239162
Valid Loss:  0.00016157103527802974
Epoch:  327  	Training Loss: 0.00018014137458521873
Test Loss:  0.00013220398977864534
Valid Loss:  0.0001611620537005365
Epoch:  328  	Training Loss: 0.00017970317276194692
Test Loss:  0.00013167390716262162
Valid Loss:  0.00016075829626061022
Epoch:  329  	Training Loss: 0.0001792771799955517
Test Loss:  0.0001311618252657354
Valid Loss:  0.00016036976012401283
Epoch:  330  	Training Loss: 0.0001788613444659859
Test Loss:  0.0001306624326389283
Valid Loss:  0.0001599887473275885
Epoch:  331  	Training Loss: 0.00017845790716819465
Test Loss:  0.0001301706361118704
Valid Loss:  0.0001596159127075225
Epoch:  332  	Training Loss: 0.00017806555842980742
Test Loss:  0.0001295218535233289
Valid Loss:  0.00015909154899418354
Epoch:  333  	Training Loss: 0.00017764332005754113
Test Loss:  0.0001289007777813822
Valid Loss:  0.0001585953577887267
Epoch:  334  	Training Loss: 0.00017723366909194738
Test Loss:  0.00012830302875954658
Valid Loss:  0.00015812049969099462
Epoch:  335  	Training Loss: 0.00017683638725429773
Test Loss:  0.00012771805631928146
Valid Loss:  0.00015765776333864778
Epoch:  336  	Training Loss: 0.00017645169282332063
Test Loss:  0.00012715513003058732
Valid Loss:  0.00015721068484708667
Epoch:  337  	Training Loss: 0.00017607497284188867
Test Loss:  0.00012660605716519058
Valid Loss:  0.0001567781437188387
Epoch:  338  	Training Loss: 0.000175710505573079
Test Loss:  0.0001260708086192608
Valid Loss:  0.00015636099851690233
Epoch:  339  	Training Loss: 0.0001753579854266718
Test Loss:  0.00012555409921333194
Valid Loss:  0.0001559485972393304
 68%|██████▊   | 341/500 [04:10<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:10<02:12,  1.18it/s] 69%|██████▉   | 345/500 [04:11<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:11<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:11<00:50,  3.01it/s] 70%|███████   | 351/500 [04:17<02:52,  1.16s/it] 71%|███████   | 353/500 [04:17<02:02,  1.20it/s] 71%|███████   | 355/500 [04:17<01:27,  1.66it/s] 71%|███████▏  | 357/500 [04:17<01:03,  2.26it/s] 72%|███████▏  | 359/500 [04:17<00:46,  3.04it/s] 72%|███████▏  | 361/500 [04:24<02:44,  1.19s/it] 73%|███████▎  | 363/500 [04:24<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:24<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:24<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:24<00:44,  2.97it/s] 74%|███████▍  | 371/500 [04:31<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:31<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:31<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:31<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:31<00:40,  3.00it/s] 76%|███████▌  | 381/500 [04:37<02:19,  1.18s/it] 77%|███████▋  | 383/500 [04:38<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:38<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:38<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:38<00:38,  2.91it/s] 78%|███████▊  | 391/500 [04:44<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:45<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:45<01:05,  1.61it/s] 79%|███████▉  | 397/500 [04:45<00:46,  2.20it/s] 80%|███████▉  | 399/500 [04:45<00:34,  2.96it/s] 80%|████████  | 401/500 [04:51<01:56,  1.17s/it] 81%|████████  | 403/500 [04:51<01:21,  1.19it/s] 81%|████████  | 405/500 [04:52<00:57,  1.64it/s]Epoch:  340  	Training Loss: 0.0001750108494888991
Test Loss:  0.00012505019549280405
Valid Loss:  0.00015555336722172797
Epoch:  341  	Training Loss: 0.00017467726138420403
Test Loss:  0.00012455842806957662
Valid Loss:  0.00015516819257754833
Epoch:  342  	Training Loss: 0.00017435189511161298
Test Loss:  0.00012321170652285218
Valid Loss:  0.0001540525845484808
Epoch:  343  	Training Loss: 0.00017391178698744625
Test Loss:  0.00012255803449079394
Valid Loss:  0.00015352632908616215
Epoch:  344  	Training Loss: 0.00017356044554617256
Test Loss:  0.00012192587018944323
Valid Loss:  0.0001530305453343317
Epoch:  345  	Training Loss: 0.00017323947395198047
Test Loss:  0.00012137451267335564
Valid Loss:  0.00015260571672115475
Epoch:  346  	Training Loss: 0.0001729372306726873
Test Loss:  0.00012086169590475038
Valid Loss:  0.00015221093781292439
Epoch:  347  	Training Loss: 0.0001726511400192976
Test Loss:  0.00012037999840686098
Valid Loss:  0.0001518441131338477
Epoch:  348  	Training Loss: 0.00017237842257600278
Test Loss:  0.00011992920917691663
Valid Loss:  0.00015150832768995315
Epoch:  349  	Training Loss: 0.00017211800150107592
Test Loss:  0.00011952435306739062
Valid Loss:  0.00015120375610422343
Epoch:  350  	Training Loss: 0.0001718660641927272
Test Loss:  0.0001191398041555658
Valid Loss:  0.00015092073590494692
Epoch:  351  	Training Loss: 0.0001716218830551952
Test Loss:  0.0001187781454063952
Valid Loss:  0.00015065193292684853
Epoch:  352  	Training Loss: 0.0001713853853289038
Test Loss:  0.0001187829184345901
Valid Loss:  0.00015066625201143324
Epoch:  353  	Training Loss: 0.00017136175301857293
Test Loss:  0.00011872232425957918
Valid Loss:  0.00015061016893014312
Epoch:  354  	Training Loss: 0.00017134126392193139
Test Loss:  0.00011867730063386261
Valid Loss:  0.00015057052951306105
Epoch:  355  	Training Loss: 0.0001713173696771264
Test Loss:  0.00011863703548442572
Valid Loss:  0.00015053042443469167
Epoch:  356  	Training Loss: 0.0001712980738375336
Test Loss:  0.00011859623191412538
Valid Loss:  0.00015049363719299436
Epoch:  357  	Training Loss: 0.000171277453773655
Test Loss:  0.00011855432239826769
Valid Loss:  0.00015045817417558283
Epoch:  358  	Training Loss: 0.00017125805607065558
Test Loss:  0.00011851942690555006
Valid Loss:  0.0001504246611148119
Epoch:  359  	Training Loss: 0.00017123803263530135
Test Loss:  0.00011848728900076821
Valid Loss:  0.0001503905514255166
Epoch:  360  	Training Loss: 0.00017121848941314965
Test Loss:  0.0001184546563308686
Valid Loss:  0.00015035757678560913
Epoch:  361  	Training Loss: 0.00017120043048635125
Test Loss:  0.0001184254142572172
Valid Loss:  0.00015032896772027016
Epoch:  362  	Training Loss: 0.00017118113464675844
Test Loss:  0.00011605140753090382
Valid Loss:  0.0001483689120505005
Epoch:  363  	Training Loss: 0.00016889763355720788
Test Loss:  0.00011354299203958362
Valid Loss:  0.00014621796435676515
Epoch:  364  	Training Loss: 0.00016697004321031272
Test Loss:  0.00011185956100234762
Valid Loss:  0.00014479164383374155
Epoch:  365  	Training Loss: 0.00016533545567654073
Test Loss:  0.00011027423897758126
Valid Loss:  0.00014340190682560205
Epoch:  366  	Training Loss: 0.00016390561359003186
Test Loss:  0.00010908255353569984
Valid Loss:  0.00014232881949283183
Epoch:  367  	Training Loss: 0.0001626242301426828
Test Loss:  0.00010796064452733845
Valid Loss:  0.00014127910253591835
Epoch:  368  	Training Loss: 0.0001614399952813983
Test Loss:  0.00010695133823901415
Valid Loss:  0.00014039463712833822
Epoch:  369  	Training Loss: 0.0001603288110345602
Test Loss:  0.00010586774442344904
Valid Loss:  0.00013954985479358584
Epoch:  370  	Training Loss: 0.0001592729677213356
Test Loss:  0.00010485686652828008
Valid Loss:  0.00013878689787816256
Epoch:  371  	Training Loss: 0.00015822998830117285
Test Loss:  0.00010387125803390518
Valid Loss:  0.00013804019545204937
Epoch:  372  	Training Loss: 0.0001571929460624233
Test Loss:  0.00010374296107329428
Valid Loss:  0.00013783971371594816
Epoch:  373  	Training Loss: 0.000157061469508335
Test Loss:  0.00010371269308961928
Valid Loss:  0.00013774351100437343
Epoch:  374  	Training Loss: 0.00015696283662691712
Test Loss:  0.00010373374971095473
Valid Loss:  0.00013770564692094922
Epoch:  375  	Training Loss: 0.0001568758161738515
Test Loss:  0.00010377373109804466
Valid Loss:  0.00013768271310254931
Epoch:  376  	Training Loss: 0.00015679489297326654
Test Loss:  0.00010382500477135181
Valid Loss:  0.0001376767613692209
Epoch:  377  	Training Loss: 0.0001567181316204369
Test Loss:  0.00010388194641564041
Valid Loss:  0.0001376820437144488
Epoch:  378  	Training Loss: 0.00015664740931242704
Test Loss:  0.00010394184209872037
Valid Loss:  0.0001376894215354696
Epoch:  379  	Training Loss: 0.00015657841868232936
Test Loss:  0.00010400299652246758
Valid Loss:  0.00013770262012258172
Epoch:  380  	Training Loss: 0.00015651434659957886
Test Loss:  0.00010407100489828736
Valid Loss:  0.00013771469821222126
Epoch:  381  	Training Loss: 0.00015645206440240145
Test Loss:  0.00010413245763629675
Valid Loss:  0.0001377270236844197
Epoch:  382  	Training Loss: 0.0001563954574521631
Test Loss:  0.00010280133574269712
Valid Loss:  0.00013697327813133597
Epoch:  383  	Training Loss: 0.00015529757365584373
Test Loss:  0.00010145598935196176
Valid Loss:  0.00013596141070593148
Epoch:  384  	Training Loss: 0.00015436882677022368
Test Loss:  0.00010029025725089014
Valid Loss:  0.0001350291131529957
Epoch:  385  	Training Loss: 0.0001535394403617829
Test Loss:  9.925826452672482e-05
Valid Loss:  0.00013420236064121127
Epoch:  386  	Training Loss: 0.000152780266944319
Test Loss:  9.828261681832373e-05
Valid Loss:  0.0001334298140136525
Epoch:  387  	Training Loss: 0.00015203101793304086
Test Loss:  9.739790402818471e-05
Valid Loss:  0.0001327141944784671
Epoch:  388  	Training Loss: 0.0001513233146397397
Test Loss:  9.656391921453178e-05
Valid Loss:  0.00013204508286435157
Epoch:  389  	Training Loss: 0.00015062758757267147
Test Loss:  9.579733887221664e-05
Valid Loss:  0.00013141609088052064
Epoch:  390  	Training Loss: 0.00014997977996245027
Test Loss:  9.510353265795857e-05
Valid Loss:  0.00013083856902085245
Epoch:  391  	Training Loss: 0.00014937343075871468
Test Loss:  9.447085903957486e-05
Valid Loss:  0.00013030938862357289
Epoch:  392  	Training Loss: 0.00014880264643579721
Test Loss:  9.433765080757439e-05
Valid Loss:  0.00013014700380153954
Epoch:  393  	Training Loss: 0.00014822304365225136
Test Loss:  9.406325261807069e-05
Valid Loss:  0.00012985264766030014
Epoch:  394  	Training Loss: 0.00014769783592782915
Test Loss:  9.3757567810826e-05
Valid Loss:  0.00012952747056260705
Epoch:  395  	Training Loss: 0.0001471836876589805
Test Loss:  9.346992737846449e-05
Valid Loss:  0.0001292204688070342
Epoch:  396  	Training Loss: 0.00014668423682451248
Test Loss:  9.317568765254691e-05
Valid Loss:  0.00012890688958577812
Epoch:  397  	Training Loss: 0.00014619596186093986
Test Loss:  9.289961599279195e-05
Valid Loss:  0.0001286001643165946
Epoch:  398  	Training Loss: 0.00014571071369573474
Test Loss:  9.260678052669391e-05
Valid Loss:  0.00012829320621676743
Epoch:  399  	Training Loss: 0.00014520548575092107
Test Loss:  9.231813601218164e-05
Valid Loss:  0.00012797927774954587
Epoch:  400  	Training Loss: 0.0001447100075893104
Test Loss:  9.203067020280287e-05
Valid Loss:  0.00012766692088916898
Epoch:  401  	Training Loss: 0.00014422180538531393
Test Loss:  9.17465949896723e-05
Valid Loss:  0.00012735507334582508
Epoch:  402  	Training Loss: 0.00014373863814398646
Test Loss:  9.172452701022848e-05
Valid Loss:  0.0001269279746338725
Epoch:  403  	Training Loss: 0.00014287637895904481
Test Loss:  9.19944723136723e-05
Valid Loss:  0.0001268538908334449
Epoch:  404  	Training Loss: 0.00014222577738109976
Test Loss:  9.221749496646225e-05
Valid Loss:  0.00012679581413976848
Epoch:  405  	Training Loss: 0.00014173539238981903
Test Loss:  9.248697460861877e-05
Valid Loss:  0.00012682628585025668
Epoch:  406  	Training Loss: 0.0001413638237863779
Test Loss:  9.2746973678004e-05
Valid Loss:  0.0001268890337087214
 81%|████████▏ | 407/500 [04:52<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:52<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:58<01:43,  1.17s/it] 83%|████████▎ | 413/500 [04:58<01:12,  1.19it/s] 83%|████████▎ | 415/500 [04:58<00:51,  1.65it/s] 83%|████████▎ | 417/500 [04:58<00:36,  2.25it/s] 84%|████████▍ | 419/500 [04:59<00:26,  3.02it/s] 84%|████████▍ | 421/500 [05:05<01:32,  1.17s/it] 85%|████████▍ | 423/500 [05:05<01:04,  1.19it/s] 85%|████████▌ | 425/500 [05:05<00:46,  1.63it/s] 85%|████████▌ | 427/500 [05:05<00:33,  2.21it/s] 86%|████████▌ | 429/500 [05:05<00:23,  2.97it/s] 86%|████████▌ | 431/500 [05:12<01:22,  1.19s/it] 87%|████████▋ | 433/500 [05:12<00:57,  1.17it/s] 87%|████████▋ | 435/500 [05:12<00:40,  1.61it/s] 87%|████████▋ | 437/500 [05:12<00:28,  2.20it/s] 88%|████████▊ | 439/500 [05:12<00:20,  2.96it/s] 88%|████████▊ | 441/500 [05:19<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:19<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:19<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:19<00:23,  2.22it/s] 90%|████████▉ | 449/500 [05:19<00:17,  2.99it/s] 90%|█████████ | 451/500 [05:25<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:26<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:26<00:27,  1.64it/s] 91%|█████████▏| 457/500 [05:26<00:19,  2.24it/s] 92%|█████████▏| 459/500 [05:26<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:32<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:32<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:33<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:33<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:33<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:39<00:34,  1.17s/it] 95%|█████████▍| 473/500 [05:39<00:22,  1.19it/s]Epoch:  407  	Training Loss: 0.00014108477625995874
Test Loss:  9.300003875978291e-05
Valid Loss:  0.00012698236969299614
Epoch:  408  	Training Loss: 0.0001408702228218317
Test Loss:  9.324444545200095e-05
Valid Loss:  0.00012708656140603125
Epoch:  409  	Training Loss: 0.00014071105397306383
Test Loss:  9.347075683763251e-05
Valid Loss:  0.0001271941582672298
Epoch:  410  	Training Loss: 0.00014058907981961966
Test Loss:  9.367816528538242e-05
Valid Loss:  0.00012730408343486488
Epoch:  411  	Training Loss: 0.00014049650053493679
Test Loss:  9.386835154145956e-05
Valid Loss:  0.00012741168029606342
Epoch:  412  	Training Loss: 0.000140426229336299
Test Loss:  9.2893693363294e-05
Valid Loss:  0.0001266142789972946
Epoch:  413  	Training Loss: 0.00013947015395388007
Test Loss:  9.184330701828003e-05
Valid Loss:  0.00012567886733449996
Epoch:  414  	Training Loss: 0.00013865481014363468
Test Loss:  9.095667337533087e-05
Valid Loss:  0.00012490595690906048
Epoch:  415  	Training Loss: 0.00013793856487609446
Test Loss:  9.00711675058119e-05
Valid Loss:  0.00012422027066349983
Epoch:  416  	Training Loss: 0.00013730087084695697
Test Loss:  8.928349416237324e-05
Valid Loss:  0.00012362003326416016
Epoch:  417  	Training Loss: 0.00013671637861989439
Test Loss:  8.855592750478536e-05
Valid Loss:  0.00012306393182370812
Epoch:  418  	Training Loss: 0.00013614745694212615
Test Loss:  8.788910054136068e-05
Valid Loss:  0.0001225533487740904
Epoch:  419  	Training Loss: 0.00013560883235186338
Test Loss:  8.726576925255358e-05
Valid Loss:  0.0001220383564941585
Epoch:  420  	Training Loss: 0.00013508176198229194
Test Loss:  8.669424278195947e-05
Valid Loss:  0.0001215060765389353
Epoch:  421  	Training Loss: 0.00013459411275107414
Test Loss:  8.617468120064586e-05
Valid Loss:  0.000121024226245936
Epoch:  422  	Training Loss: 0.00013413839042186737
Test Loss:  8.628315845271572e-05
Valid Loss:  0.00012106842041248456
Epoch:  423  	Training Loss: 0.00013393288827501237
Test Loss:  8.634927507955581e-05
Valid Loss:  0.00012108335795346648
Epoch:  424  	Training Loss: 0.0001337448920821771
Test Loss:  8.638355939183384e-05
Valid Loss:  0.00012107909424230456
Epoch:  425  	Training Loss: 0.00013356983254197985
Test Loss:  8.640945452498272e-05
Valid Loss:  0.00012106937356293201
Epoch:  426  	Training Loss: 0.00013340481382329017
Test Loss:  8.642337343189865e-05
Valid Loss:  0.00012105016503483057
Epoch:  427  	Training Loss: 0.0001332468818873167
Test Loss:  8.642741886433214e-05
Valid Loss:  0.0001210268892464228
Epoch:  428  	Training Loss: 0.00013309506175573915
Test Loss:  8.642896864330396e-05
Valid Loss:  0.00012100415187887847
Epoch:  429  	Training Loss: 0.00013294859672896564
Test Loss:  8.643023465992883e-05
Valid Loss:  0.00012098393926862627
Epoch:  430  	Training Loss: 0.00013280962593853474
Test Loss:  8.642920874990523e-05
Valid Loss:  0.00012096352293156087
Epoch:  431  	Training Loss: 0.000132673914777115
Test Loss:  8.64248868310824e-05
Valid Loss:  0.00012094475096091628
Epoch:  432  	Training Loss: 0.00013254451914690435
Test Loss:  8.626213821116835e-05
Valid Loss:  0.00012079080624971539
Epoch:  433  	Training Loss: 0.00013210040924604982
Test Loss:  8.605875336797908e-05
Valid Loss:  0.00012059487926308066
Epoch:  434  	Training Loss: 0.0001317521237069741
Test Loss:  8.581103611504659e-05
Valid Loss:  0.00012035783583996817
Epoch:  435  	Training Loss: 0.00013141732779331505
Test Loss:  8.55512116686441e-05
Valid Loss:  0.00012010054342681542
Epoch:  436  	Training Loss: 0.0001311068917857483
Test Loss:  8.529170008841902e-05
Valid Loss:  0.00011984261800535023
Epoch:  437  	Training Loss: 0.00013080803910270333
Test Loss:  8.504377910867333e-05
Valid Loss:  0.00011958784307353199
Epoch:  438  	Training Loss: 0.0001305196201428771
Test Loss:  8.480383257847279e-05
Valid Loss:  0.00011934057692997158
Epoch:  439  	Training Loss: 0.0001302391610806808
Test Loss:  8.457891090074554e-05
Valid Loss:  0.00011907448060810566
Epoch:  440  	Training Loss: 0.0001299623108934611
Test Loss:  8.435999188804999e-05
Valid Loss:  0.00011879575322382152
Epoch:  441  	Training Loss: 0.0001296706177527085
Test Loss:  8.414630428887904e-05
Valid Loss:  0.00011852218449348584
Epoch:  442  	Training Loss: 0.0001293849345529452
Test Loss:  8.390739822061732e-05
Valid Loss:  0.00011824241664726287
Epoch:  443  	Training Loss: 0.00012917841377202421
Test Loss:  8.375971810892224e-05
Valid Loss:  0.00011804828682215884
Epoch:  444  	Training Loss: 0.00012899667490273714
Test Loss:  8.366650581592694e-05
Valid Loss:  0.00011790668941102922
Epoch:  445  	Training Loss: 0.00012883139424957335
Test Loss:  8.360922220163047e-05
Valid Loss:  0.00011780034401454031
Epoch:  446  	Training Loss: 0.00012867894838564098
Test Loss:  8.357221668120474e-05
Valid Loss:  0.00011771422578021884
Epoch:  447  	Training Loss: 0.00012853226508013904
Test Loss:  8.354792225873098e-05
Valid Loss:  0.00011764446389861405
Epoch:  448  	Training Loss: 0.0001283931778743863
Test Loss:  8.35322862258181e-05
Valid Loss:  0.00011758534674299881
Epoch:  449  	Training Loss: 0.0001282612356590107
Test Loss:  8.3522594650276e-05
Valid Loss:  0.00011753362196031958
Epoch:  450  	Training Loss: 0.00012813367357011884
Test Loss:  8.351744327228516e-05
Valid Loss:  0.00011748572433134541
Epoch:  451  	Training Loss: 0.00012801121920347214
Test Loss:  8.351430005859584e-05
Valid Loss:  0.00011743856885004789
Epoch:  452  	Training Loss: 0.00012789349420927465
Test Loss:  8.368632552446797e-05
Valid Loss:  0.00011759271728806198
Epoch:  453  	Training Loss: 0.0001278216950595379
Test Loss:  8.381523366551846e-05
Valid Loss:  0.00011771248682634905
Epoch:  454  	Training Loss: 0.00012776150833815336
Test Loss:  8.393247844651341e-05
Valid Loss:  0.00011782368528656662
Epoch:  455  	Training Loss: 0.00012771511683240533
Test Loss:  8.402617822866887e-05
Valid Loss:  0.00011791430006269366
Epoch:  456  	Training Loss: 0.00012767058797180653
Test Loss:  8.41005239635706e-05
Valid Loss:  0.00011798874038504437
Epoch:  457  	Training Loss: 0.00012763310223817825
Test Loss:  8.416337368544191e-05
Valid Loss:  0.000118056676001288
Epoch:  458  	Training Loss: 0.00012759529636241496
Test Loss:  8.422473911195993e-05
Valid Loss:  0.00011812144657596946
Epoch:  459  	Training Loss: 0.00012756472278852016
Test Loss:  8.427839929936454e-05
Valid Loss:  0.00011818018538178876
Epoch:  460  	Training Loss: 0.0001275354588869959
Test Loss:  8.432996401097625e-05
Valid Loss:  0.00011823721433756873
Epoch:  461  	Training Loss: 0.00012751069152727723
Test Loss:  8.43742091092281e-05
Valid Loss:  0.00011828590504592285
Epoch:  462  	Training Loss: 0.00012748657900374383
Test Loss:  8.413268369622529e-05
Valid Loss:  0.00011796635226346552
Epoch:  463  	Training Loss: 0.0001270921202376485
Test Loss:  8.381784573430195e-05
Valid Loss:  0.0001175859069917351
Epoch:  464  	Training Loss: 0.00012669526040554047
Test Loss:  8.348228584509343e-05
Valid Loss:  0.0001171821349998936
Epoch:  465  	Training Loss: 0.00012628681724891067
Test Loss:  8.315680315718055e-05
Valid Loss:  0.00011679502495098859
Epoch:  466  	Training Loss: 0.0001259111159015447
Test Loss:  8.28671472845599e-05
Valid Loss:  0.00011643276957329363
Epoch:  467  	Training Loss: 0.00012555558350868523
Test Loss:  8.260102185886353e-05
Valid Loss:  0.00011610005458351225
Epoch:  468  	Training Loss: 0.00012521600001491606
Test Loss:  8.236274879891425e-05
Valid Loss:  0.00011579156125662848
Epoch:  469  	Training Loss: 0.00012488877109717578
Test Loss:  8.214678382501006e-05
Valid Loss:  0.0001155007048510015
Epoch:  470  	Training Loss: 0.00012457050615921617
Test Loss:  8.190171502064914e-05
Valid Loss:  0.00011522663407959044
Epoch:  471  	Training Loss: 0.0001242545258719474
Test Loss:  8.166560292011127e-05
Valid Loss:  0.0001149588351836428
Epoch:  472  	Training Loss: 0.0001239266130141914
Test Loss:  8.164990140357986e-05
Valid Loss:  0.00011493123020045459
Epoch:  473  	Training Loss: 0.00012389279436320066
Test Loss:  8.16329411463812e-05
Valid Loss:  0.00011490879842313007
Epoch:  474  	Training Loss: 0.00012386056187096983
Test Loss:   95%|█████████▌| 475/500 [05:39<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:39<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:40<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:46<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:46<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:46<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:46<00:05,  2.24it/s] 98%|█████████▊| 489/500 [05:46<00:03,  3.01it/s] 98%|█████████▊| 491/500 [05:53<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:53<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:53<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:53<00:01,  2.26it/s]100%|█████████▉| 499/500 [05:53<00:00,  3.03it/s]100%|██████████| 500/500 [05:53<00:00,  1.41it/s]
8.161801815731451e-05
Valid Loss:  0.00011488591553643346
Epoch:  475  	Training Loss: 0.00012382990098558366
Test Loss:  8.160418656188995e-05
Valid Loss:  0.00011486612493172288
Epoch:  476  	Training Loss: 0.0001237997494172305
Test Loss:  8.159410208463669e-05
Valid Loss:  0.00011484425340313464
Epoch:  477  	Training Loss: 0.00012376860831864178
Test Loss:  8.158535638358444e-05
Valid Loss:  0.00011482913396321237
Epoch:  478  	Training Loss: 0.00012373826757539064
Test Loss:  8.157592674251646e-05
Valid Loss:  0.0001148087321780622
Epoch:  479  	Training Loss: 0.00012370831973385066
Test Loss:  8.156623516697437e-05
Valid Loss:  0.00011479374370537698
Epoch:  480  	Training Loss: 0.0001236805401276797
Test Loss:  8.155847899615765e-05
Valid Loss:  0.00011477724183350801
Epoch:  481  	Training Loss: 0.00012365130532998592
Test Loss:  8.155590330716223e-05
Valid Loss:  0.00011476365034468472
Epoch:  482  	Training Loss: 0.00012362294364720583
Test Loss:  8.064266148721799e-05
Valid Loss:  0.00011376658221706748
Epoch:  483  	Training Loss: 0.0001231677015312016
Test Loss:  8.080045517999679e-05
Valid Loss:  0.00011382144293747842
Epoch:  484  	Training Loss: 0.0001229302870342508
Test Loss:  8.095008524833247e-05
Valid Loss:  0.00011388208804419264
Epoch:  485  	Training Loss: 0.0001227350439876318
Test Loss:  8.109764894470572e-05
Valid Loss:  0.00011395246838219464
Epoch:  486  	Training Loss: 0.00012257618072908372
Test Loss:  8.124328451231122e-05
Valid Loss:  0.00011402927339076996
Epoch:  487  	Training Loss: 0.00012244518438819796
Test Loss:  8.138689008774236e-05
Valid Loss:  0.0001141152752097696
Epoch:  488  	Training Loss: 0.00012233719462528825
Test Loss:  8.152135706041008e-05
Valid Loss:  0.00011419900692999363
Epoch:  489  	Training Loss: 0.00012224949023220688
Test Loss:  8.165206236299127e-05
Valid Loss:  0.00011428538709878922
Epoch:  490  	Training Loss: 0.0001221776328748092
Test Loss:  8.177402196452022e-05
Valid Loss:  0.00011436721251811832
Epoch:  491  	Training Loss: 0.00012211751891300082
Test Loss:  8.188923675334081e-05
Valid Loss:  0.0001144487177953124
Epoch:  492  	Training Loss: 0.00012206855171825737
Test Loss:  8.211913518607616e-05
Valid Loss:  0.00011464999988675117
Epoch:  493  	Training Loss: 0.0001220194244524464
Test Loss:  8.223338227253407e-05
Valid Loss:  0.00011474511120468378
Epoch:  494  	Training Loss: 0.00012197995238238946
Test Loss:  8.231574611272663e-05
Valid Loss:  0.00011480866669444367
Epoch:  495  	Training Loss: 0.00012194451846880838
Test Loss:  8.237578731495887e-05
Valid Loss:  0.00011485302820801735
Epoch:  496  	Training Loss: 0.00012191106361569837
Test Loss:  8.243056072387844e-05
Valid Loss:  0.00011489625467220321
Epoch:  497  	Training Loss: 0.0001218787074321881
Test Loss:  8.248123776866123e-05
Valid Loss:  0.00011493192141642794
Epoch:  498  	Training Loss: 0.00012184809747850522
Test Loss:  8.253144915215671e-05
Valid Loss:  0.00011496640217956156
Epoch:  499  	Training Loss: 0.00012181849160697311
Test Loss:  8.257781155407429e-05
Valid Loss:  0.00011499895481392741
Epoch:  500  	Training Loss: 0.00012178910401416942
Test Loss:  8.26231116661802e-05
Valid Loss:  0.0001150289608631283
seed is  16
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:31, 15.96it/s]  1%|          | 4/500 [00:00<00:30, 16.06it/s]  1%|          | 6/500 [00:00<00:30, 16.30it/s]  2%|▏         | 8/500 [00:00<00:30, 16.34it/s]  2%|▏         | 10/500 [00:00<00:32, 15.13it/s]  2%|▏         | 12/500 [00:00<00:33, 14.46it/s]  3%|▎         | 14/500 [00:00<00:35, 13.72it/s]  3%|▎         | 16/500 [00:01<00:36, 13.31it/s]  4%|▎         | 18/500 [00:01<00:35, 13.43it/s]  4%|▍         | 20/500 [00:01<00:33, 14.14it/s]  4%|▍         | 22/500 [00:01<00:32, 14.78it/s]  5%|▍         | 24/500 [00:01<00:31, 15.27it/s]  5%|▌         | 26/500 [00:01<00:30, 15.32it/s]  6%|▌         | 28/500 [00:01<00:31, 15.23it/s]  6%|▌         | 30/500 [00:02<00:30, 15.56it/s]  6%|▋         | 32/500 [00:02<00:29, 15.60it/s]  7%|▋         | 34/500 [00:02<00:29, 15.64it/s]  7%|▋         | 36/500 [00:02<00:29, 15.71it/s]  8%|▊         | 38/500 [00:02<00:28, 15.98it/s]  8%|▊         | 40/500 [00:02<00:28, 16.10it/s]  8%|▊         | 42/500 [00:02<00:28, 16.04it/s]  9%|▉         | 44/500 [00:02<00:28, 16.17it/s]  9%|▉         | 46/500 [00:03<00:27, 16.22it/s] 10%|▉         | 48/500 [00:03<00:27, 16.29it/s] 10%|█         | 50/500 [00:03<00:27, 16.27it/s] 10%|█         | 52/500 [00:03<00:27, 16.33it/s] 11%|█         | 54/500 [00:03<00:27, 16.43it/s] 11%|█         | 56/500 [00:03<00:26, 16.47it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.48it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.33it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.31it/s] 13%|█▎        | 64/500 [00:04<00:26, 16.32it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.30it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.38it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.40it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.32it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.05it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.23it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.31it/s] 16%|█▌        | 80/500 [00:05<00:25, 16.31it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.25it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.30it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.36it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.34it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.34it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.36it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.46it/s] 19%|█▉        | 96/500 [00:06<00:24, 16.49it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.53it/s] 20%|██        | 100/500 [00:06<00:24, 16.55it/s] 20%|██        | 102/500 [00:06<00:24, 16.53it/s] 21%|██        | 104/500 [00:06<00:26, 15.13it/s] 21%|██        | 106/500 [00:06<00:26, 15.04it/s] 22%|██▏       | 108/500 [00:06<00:25, 15.36it/s] 22%|██▏       | 110/500 [00:06<00:26, 14.83it/s] 22%|██▏       | 112/500 [00:07<00:25, 15.13it/s] 23%|██▎       | 114/500 [00:07<00:25, 14.85it/s] 23%|██▎       | 116/500 [00:07<00:27, 13.90it/s] 24%|██▎       | 118/500 [00:07<00:26, 14.43it/s] 24%|██▍       | 120/500 [00:07<00:25, 14.88it/s] 24%|██▍       | 122/500 [00:07<00:24, 15.30it/s] 25%|██▍       | 124/500 [00:07<00:24, 15.61it/s]Epoch:  1  	Training Loss: 0.5628746747970581
Test Loss:  5712.0537109375
Valid Loss:  5721.1845703125
Epoch:  2  	Training Loss: 5721.6064453125
Test Loss:  1.0378555236879958e+19
Valid Loss:  1.0288804301727859e+19
Epoch:  3  	Training Loss: 1.03108033303764e+19
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:23, 15.74it/s] 26%|██▌       | 128/500 [00:08<00:23, 15.79it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.81it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.03it/s] 27%|██▋       | 134/500 [00:08<00:23, 15.86it/s] 27%|██▋       | 136/500 [00:08<00:22, 15.91it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.03it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.10it/s] 28%|██▊       | 142/500 [00:09<00:22, 16.18it/s] 29%|██▉       | 144/500 [00:09<00:22, 16.10it/s] 29%|██▉       | 146/500 [00:09<00:21, 16.15it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.21it/s] 30%|███       | 150/500 [00:09<00:21, 16.33it/s] 30%|███       | 152/500 [00:09<00:21, 16.33it/s] 31%|███       | 154/500 [00:09<00:21, 16.27it/s] 31%|███       | 156/500 [00:09<00:21, 16.29it/s] 32%|███▏      | 158/500 [00:10<00:21, 16.26it/s] 32%|███▏      | 160/500 [00:10<00:20, 16.24it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.29it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.27it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.35it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.21it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.25it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.29it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.30it/s] 35%|███▌      | 176/500 [00:11<00:19, 16.41it/s] 36%|███▌      | 178/500 [00:11<00:19, 16.40it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.39it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.23it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.18it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.24it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.21it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.25it/s] 38%|███▊      | 192/500 [00:12<00:18, 16.36it/s] 39%|███▉      | 194/500 [00:12<00:18, 16.39it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.41it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.45it/s] 40%|████      | 200/500 [00:12<00:18, 16.32it/s] 40%|████      | 202/500 [00:12<00:18, 16.28it/s] 41%|████      | 204/500 [00:12<00:18, 16.24it/s] 41%|████      | 206/500 [00:12<00:18, 16.30it/s] 42%|████▏     | 208/500 [00:13<00:17, 16.35it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.41it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.36it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.40it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.43it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.13it/s] 44%|████▍     | 220/500 [00:13<00:18, 15.48it/s] 44%|████▍     | 222/500 [00:13<00:17, 15.71it/s] 45%|████▍     | 224/500 [00:14<00:17, 16.00it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.17it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.25it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.23it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.28it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.30it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.38it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.29it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.12it/s] 48%|████▊     | 242/500 [00:15<00:16, 15.66it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.92it/s] 49%|████▉     | 246/500 [00:15<00:15, 15.97it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.08it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.25it/s] 50%|█████     | 252/500 [00:15<00:15, 16.34it/s] 51%|█████     | 254/500 [00:15<00:15, 16.37it/s] 51%|█████     | 256/500 [00:16<00:14, 16.33it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.39it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.44it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.37it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.38it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.07it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.10it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.11it/s] 54%|█████▍    | 272/500 [00:17<00:14, 16.18it/s] 55%|█████▍    | 274/500 [00:17<00:13, 16.25it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.27it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.30it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.19it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.20it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.25it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.32it/s] 58%|█████▊    | 288/500 [00:18<00:12, 16.33it/s] 58%|█████▊    | 290/500 [00:18<00:12, 16.34it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.32it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.17it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.25it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.34it/s] 60%|██████    | 300/500 [00:18<00:12, 16.38it/s] 60%|██████    | 302/500 [00:18<00:12, 16.39it/s] 61%|██████    | 304/500 [00:18<00:11, 16.45it/s] 61%|██████    | 306/500 [00:19<00:11, 16.44it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.43it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.34it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.29it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.28it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.37it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.41it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.28it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.25it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.28it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.33it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.35it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.12it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.22it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.29it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.35it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.27it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.24it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.27it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.30it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.30it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.33it/s] 70%|███████   | 350/500 [00:21<00:09, 16.30it/s] 70%|███████   | 352/500 [00:21<00:09, 16.25it/s] 71%|███████   | 354/500 [00:22<00:09, 16.20it/s] 71%|███████   | 356/500 [00:22<00:08, 16.30it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.31it/s] 72%|███████▏  | 360/500 [00:22<00:08, 15.75it/s] 72%|███████▏  | 362/500 [00:22<00:09, 14.81it/s] 73%|███████▎  | 364/500 [00:22<00:08, 15.31it/s] 73%|███████▎  | 366/500 [00:22<00:08, 15.64it/s] 74%|███████▎  | 368/500 [00:22<00:08, 15.84it/s] 74%|███████▍  | 370/500 [00:23<00:08, 15.39it/s] 74%|███████▍  | 372/500 [00:23<00:08, 15.06it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:08, 14.80it/s] 75%|███████▌  | 376/500 [00:23<00:08, 15.11it/s] 76%|███████▌  | 378/500 [00:23<00:07, 15.45it/s] 76%|███████▌  | 380/500 [00:23<00:07, 15.77it/s] 76%|███████▋  | 382/500 [00:23<00:07, 15.86it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.94it/s] 77%|███████▋  | 386/500 [00:24<00:07, 16.06it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.16it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.19it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.27it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.40it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.25it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.29it/s] 80%|████████  | 400/500 [00:24<00:06, 16.36it/s] 80%|████████  | 402/500 [00:25<00:05, 16.41it/s] 81%|████████  | 404/500 [00:25<00:05, 16.28it/s] 81%|████████  | 406/500 [00:25<00:05, 16.08it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.19it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.25it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.30it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.33it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.35it/s] 84%|████████▎ | 418/500 [00:26<00:04, 16.43it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.46it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.31it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.23it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.29it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.40it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.44it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.52it/s] 87%|████████▋ | 434/500 [00:27<00:03, 16.58it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.56it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.58it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.49it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.32it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.25it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.32it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.38it/s] 90%|█████████ | 450/500 [00:28<00:03, 16.39it/s] 90%|█████████ | 452/500 [00:28<00:02, 16.33it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.29it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.26it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.29it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.22it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.14it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.19it/s] 93%|█████████▎| 466/500 [00:29<00:02, 16.32it/s] 94%|█████████▎| 468/500 [00:29<00:01, 16.37it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.26it/s] 94%|█████████▍| 472/500 [00:29<00:01, 15.97it/s] 95%|█████████▍| 474/500 [00:29<00:01, 15.99it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.09it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.14it/s] 96%|█████████▌| 480/500 [00:29<00:01, 15.90it/s] 96%|█████████▋| 482/500 [00:30<00:01, 16.04it/s] 97%|█████████▋| 484/500 [00:30<00:00, 16.16it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.13it/s] 98%|█████████▊| 488/500 [00:30<00:00, 15.93it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.03it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.16it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.10it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.07it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:31<00:00, 16.14it/s]100%|██████████| 500/500 [00:31<00:00, 16.23it/s]100%|██████████| 500/500 [00:31<00:00, 16.06it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  16
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:42,  6.22s/it]  1%|          | 3/500 [00:06<13:46,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:13,  1.95it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:12<10:40,  1.31s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.17it/s]  4%|▍         | 19/500 [00:13<02:42,  2.95it/s]  4%|▍         | 21/500 [00:20<09:46,  1.23s/it]  5%|▍         | 23/500 [00:20<06:57,  1.14it/s]  5%|▌         | 25/500 [00:20<04:59,  1.59it/s]  5%|▌         | 27/500 [00:20<03:37,  2.17it/s]  6%|▌         | 29/500 [00:20<02:41,  2.92it/s]  6%|▌         | 31/500 [00:26<09:11,  1.18s/it]  7%|▋         | 33/500 [00:26<06:33,  1.19it/s]  7%|▋         | 35/500 [00:27<04:43,  1.64it/s]  7%|▋         | 37/500 [00:27<03:26,  2.24it/s]  8%|▊         | 39/500 [00:27<02:32,  3.02it/s]  8%|▊         | 41/500 [00:33<08:57,  1.17s/it]  9%|▊         | 43/500 [00:33<06:24,  1.19it/s]  9%|▉         | 45/500 [00:33<04:36,  1.64it/s]  9%|▉         | 47/500 [00:34<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:50,  1.18s/it] 11%|█         | 53/500 [00:40<06:19,  1.18it/s] 11%|█         | 55/500 [00:40<04:33,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:20,  2.21it/s] 12%|█▏        | 59/500 [00:41<02:28,  2.97it/s] 12%|█▏        | 61/500 [00:47<08:43,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:15,  1.16it/s] 13%|█▎        | 65/500 [00:47<04:30,  1.61it/s] 13%|█▎        | 67/500 [00:47<03:17,  2.19it/s] 14%|█▍        | 69/500 [00:48<02:25,  2.95it/s] 14%|█▍        | 71/500 [00:54<08:21,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:58,  1.19it/s]Epoch:  1  	Training Loss: 0.5628746747970581
Test Loss:  173.8211669921875
Valid Loss:  171.153564453125
Epoch:  2  	Training Loss: 171.97348022460938
Test Loss:  0.3614790439605713
Valid Loss:  0.3586198687553406
Epoch:  3  	Training Loss: 0.36453866958618164
Test Loss:  0.36146771907806396
Valid Loss:  0.3586086332798004
Epoch:  4  	Training Loss: 0.36452800035476685
Test Loss:  0.3614560663700104
Valid Loss:  0.35859739780426025
Epoch:  5  	Training Loss: 0.36451709270477295
Test Loss:  0.36144328117370605
Valid Loss:  0.3585856854915619
Epoch:  6  	Training Loss: 0.36450523138046265
Test Loss:  0.3614298105239868
Valid Loss:  0.35857370495796204
Epoch:  7  	Training Loss: 0.36449307203292847
Test Loss:  0.3614163398742676
Valid Loss:  0.3585616946220398
Epoch:  8  	Training Loss: 0.3644807040691376
Test Loss:  0.36140263080596924
Valid Loss:  0.35854947566986084
Epoch:  9  	Training Loss: 0.3644677996635437
Test Loss:  0.361388623714447
Valid Loss:  0.3585370182991028
Epoch:  10  	Training Loss: 0.36445459723472595
Test Loss:  0.36137428879737854
Valid Loss:  0.35852426290512085
Epoch:  11  	Training Loss: 0.36444082856178284
Test Loss:  0.3613596558570862
Valid Loss:  0.358511358499527
Epoch:  12  	Training Loss: 0.3644269108772278
Test Loss:  0.36131104826927185
Valid Loss:  0.35846757888793945
Epoch:  13  	Training Loss: 0.3643836975097656
Test Loss:  0.3612619638442993
Valid Loss:  0.3584238290786743
Epoch:  14  	Training Loss: 0.3643399477005005
Test Loss:  0.3612075746059418
Valid Loss:  0.35837844014167786
Epoch:  15  	Training Loss: 0.3642948865890503
Test Loss:  0.3611510396003723
Valid Loss:  0.3583301305770874
Epoch:  16  	Training Loss: 0.3642469644546509
Test Loss:  0.36109042167663574
Valid Loss:  0.3582790493965149
Epoch:  17  	Training Loss: 0.36419612169265747
Test Loss:  0.3610250949859619
Valid Loss:  0.35822156071662903
Epoch:  18  	Training Loss: 0.36413946747779846
Test Loss:  0.3609492778778076
Valid Loss:  0.35815995931625366
Epoch:  19  	Training Loss: 0.36407768726348877
Test Loss:  0.3608715236186981
Valid Loss:  0.35809314250946045
Epoch:  20  	Training Loss: 0.36401480436325073
Test Loss:  0.3607865273952484
Valid Loss:  0.35802221298217773
Epoch:  21  	Training Loss: 0.3639450669288635
Test Loss:  0.36068686842918396
Valid Loss:  0.3579438626766205
Epoch:  22  	Training Loss: 0.36386439204216003
Test Loss:  0.3606000244617462
Valid Loss:  0.3578721284866333
Epoch:  23  	Training Loss: 0.36379069089889526
Test Loss:  0.36051037907600403
Valid Loss:  0.35779887437820435
Epoch:  24  	Training Loss: 0.3637133836746216
Test Loss:  0.36041122674942017
Valid Loss:  0.35772252082824707
Epoch:  25  	Training Loss: 0.36363038420677185
Test Loss:  0.36030706763267517
Valid Loss:  0.35764235258102417
Epoch:  26  	Training Loss: 0.3635452091693878
Test Loss:  0.36019963026046753
Valid Loss:  0.3575591444969177
Epoch:  27  	Training Loss: 0.3634548783302307
Test Loss:  0.3600899577140808
Valid Loss:  0.35747429728507996
Epoch:  28  	Training Loss: 0.36336010694503784
Test Loss:  0.3599781095981598
Valid Loss:  0.3573843538761139
Epoch:  29  	Training Loss: 0.3632619380950928
Test Loss:  0.3598606288433075
Valid Loss:  0.35728710889816284
Epoch:  30  	Training Loss: 0.3631550073623657
Test Loss:  0.35973379015922546
Valid Loss:  0.3571808338165283
Epoch:  31  	Training Loss: 0.3630361258983612
Test Loss:  0.3595926761627197
Valid Loss:  0.3570626378059387
Epoch:  32  	Training Loss: 0.36290448904037476
Test Loss:  0.3594447374343872
Valid Loss:  0.3569358289241791
Epoch:  33  	Training Loss: 0.3627645969390869
Test Loss:  0.35928577184677124
Valid Loss:  0.3567972779273987
Epoch:  34  	Training Loss: 0.36261487007141113
Test Loss:  0.3591039776802063
Valid Loss:  0.35664695501327515
Epoch:  35  	Training Loss: 0.3624485731124878
Test Loss:  0.3589176535606384
Valid Loss:  0.35648882389068604
Epoch:  36  	Training Loss: 0.36226940155029297
Test Loss:  0.35871031880378723
Valid Loss:  0.35632020235061646
Epoch:  37  	Training Loss: 0.36207544803619385
Test Loss:  0.3584947884082794
Valid Loss:  0.35614532232284546
Epoch:  38  	Training Loss: 0.36187469959259033
Test Loss:  0.35826826095581055
Valid Loss:  0.35596010088920593
Epoch:  39  	Training Loss: 0.36166107654571533
Test Loss:  0.3580264449119568
Valid Loss:  0.3557511568069458
Epoch:  40  	Training Loss: 0.361433744430542
Test Loss:  0.35777974128723145
Valid Loss:  0.35553431510925293
Epoch:  41  	Training Loss: 0.36120277643203735
Test Loss:  0.357524037361145
Valid Loss:  0.35529351234436035
Epoch:  42  	Training Loss: 0.3609655499458313
Test Loss:  0.35723981261253357
Valid Loss:  0.35502517223358154
Epoch:  43  	Training Loss: 0.36070841550827026
Test Loss:  0.3569450378417969
Valid Loss:  0.3547385334968567
Epoch:  44  	Training Loss: 0.36044153571128845
Test Loss:  0.35661500692367554
Valid Loss:  0.35442131757736206
Epoch:  45  	Training Loss: 0.3601408004760742
Test Loss:  0.356274276971817
Valid Loss:  0.3540894389152527
Epoch:  46  	Training Loss: 0.35982465744018555
Test Loss:  0.35592398047447205
Valid Loss:  0.35374587774276733
Epoch:  47  	Training Loss: 0.35948848724365234
Test Loss:  0.3555621802806854
Valid Loss:  0.3533855080604553
Epoch:  48  	Training Loss: 0.3591299057006836
Test Loss:  0.35517698526382446
Valid Loss:  0.3530137538909912
Epoch:  49  	Training Loss: 0.35874974727630615
Test Loss:  0.3547784984111786
Valid Loss:  0.3526231646537781
Epoch:  50  	Training Loss: 0.3583506941795349
Test Loss:  0.35437247157096863
Valid Loss:  0.3522185683250427
Epoch:  51  	Training Loss: 0.3579406142234802
Test Loss:  0.35396692156791687
Valid Loss:  0.3518143594264984
Epoch:  52  	Training Loss: 0.35753095149993896
Test Loss:  0.3535112142562866
Valid Loss:  0.3513543903827667
Epoch:  53  	Training Loss: 0.3570646643638611
Test Loss:  0.3530561029911041
Valid Loss:  0.3508949875831604
Epoch:  54  	Training Loss: 0.35659897327423096
Test Loss:  0.352601557970047
Valid Loss:  0.3504362106323242
Epoch:  55  	Training Loss: 0.3561338782310486
Test Loss:  0.35214763879776
Valid Loss:  0.3499780595302582
Epoch:  56  	Training Loss: 0.35566937923431396
Test Loss:  0.3516942858695984
Valid Loss:  0.3495204746723175
Epoch:  57  	Training Loss: 0.3552054762840271
Test Loss:  0.35124146938323975
Valid Loss:  0.3490634560585022
Epoch:  58  	Training Loss: 0.354742169380188
Test Loss:  0.35078930854797363
Valid Loss:  0.34860706329345703
Epoch:  59  	Training Loss: 0.3542795181274414
Test Loss:  0.3503376841545105
Valid Loss:  0.3481512665748596
Epoch:  60  	Training Loss: 0.3538174033164978
Test Loss:  0.3498866856098175
Valid Loss:  0.3476960361003876
Epoch:  61  	Training Loss: 0.35335594415664673
Test Loss:  0.3494362533092499
Valid Loss:  0.34724146127700806
Epoch:  62  	Training Loss: 0.3528950810432434
Test Loss:  0.3490214943885803
Valid Loss:  0.3468247056007385
Epoch:  63  	Training Loss: 0.35247260332107544
Test Loss:  0.34860724210739136
Valid Loss:  0.3464084565639496
Epoch:  64  	Training Loss: 0.35205066204071045
Test Loss:  0.348193496465683
Valid Loss:  0.34599268436431885
Epoch:  65  	Training Loss: 0.35162919759750366
Test Loss:  0.3477802276611328
Valid Loss:  0.3455774188041687
Epoch:  66  	Training Loss: 0.35120826959609985
Test Loss:  0.34736746549606323
Valid Loss:  0.34516268968582153
Epoch:  67  	Training Loss: 0.35078784823417664
Test Loss:  0.34695518016815186
Valid Loss:  0.34474843740463257
Epoch:  68  	Training Loss: 0.3503679037094116
Test Loss:  0.3465433716773987
Valid Loss:  0.3443346619606018
Epoch:  69  	Training Loss: 0.3499484658241272
Test Loss:  0.3461320400238037
Valid Loss:  0.34392139315605164
Epoch:  70  	Training Loss: 0.349529504776001
Test Loss:  0.34572121500968933
Valid Loss:  0.34350860118865967
Epoch:  71  	Training Loss: 0.3491111099720001
Test Loss:  0.34531089663505554
Valid Loss:  0.3430963456630707
Epoch:  72  	Training Loss: 0.3486931622028351
Test Loss:  0.34492138028144836
Valid Loss:  0.34270620346069336
Epoch:  73  	Training Loss: 0.34829771518707275
Test Loss:  0.344532310962677
Valid Loss:  0.34231647849082947
Epoch:  74  	Training Loss: 0.34790265560150146
Test Loss:  0.34414368867874146
 15%|█▌        | 75/500 [00:54<04:18,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:08,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.01it/s] 16%|█▌        | 81/500 [01:01<08:12,  1.18s/it] 17%|█▋        | 83/500 [01:01<05:52,  1.18it/s] 17%|█▋        | 85/500 [01:01<04:13,  1.64it/s] 17%|█▋        | 87/500 [01:01<03:05,  2.23it/s] 18%|█▊        | 89/500 [01:01<02:16,  3.00it/s] 18%|█▊        | 91/500 [01:07<08:00,  1.18s/it] 19%|█▊        | 93/500 [01:08<05:43,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:07,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:14,  2.98it/s] 20%|██        | 101/500 [01:14<07:48,  1.17s/it] 21%|██        | 103/500 [01:14<05:34,  1.19it/s] 21%|██        | 105/500 [01:14<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:15<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:15<02:10,  3.01it/s] 22%|██▏       | 111/500 [01:21<07:34,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:24,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:21<02:51,  2.24it/s] 24%|██▍       | 119/500 [01:22<02:06,  3.01it/s] 24%|██▍       | 121/500 [01:28<07:21,  1.16s/it] 25%|██▍       | 123/500 [01:28<05:15,  1.20it/s] 25%|██▌       | 125/500 [01:28<03:46,  1.65it/s] 25%|██▌       | 127/500 [01:28<02:45,  2.26it/s] 26%|██▌       | 129/500 [01:28<02:02,  3.03it/s] 26%|██▌       | 131/500 [01:35<07:11,  1.17s/it] 27%|██▋       | 133/500 [01:35<05:08,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:35<02:41,  2.24it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.02it/s] 28%|██▊       | 141/500 [01:41<07:06,  1.19s/it] 29%|██▊       | 143/500 [01:42<05:04,  1.17it/s] 29%|██▉       | 145/500 [01:42<03:39,  1.62it/s]Valid Loss:  0.3419272303581238
Epoch:  75  	Training Loss: 0.3475080728530884
Test Loss:  0.3437555134296417
Valid Loss:  0.3415384292602539
Epoch:  76  	Training Loss: 0.3471139669418335
Test Loss:  0.3433678150177002
Valid Loss:  0.34115004539489746
Epoch:  77  	Training Loss: 0.34672030806541443
Test Loss:  0.3429805040359497
Valid Loss:  0.3407621383666992
Epoch:  78  	Training Loss: 0.3463270664215088
Test Loss:  0.3425936698913574
Valid Loss:  0.3403746485710144
Epoch:  79  	Training Loss: 0.34593433141708374
Test Loss:  0.34220728278160095
Valid Loss:  0.3399876356124878
Epoch:  80  	Training Loss: 0.3455420136451721
Test Loss:  0.3418213427066803
Valid Loss:  0.339601069688797
Epoch:  81  	Training Loss: 0.3451501727104187
Test Loss:  0.3414357900619507
Valid Loss:  0.33921492099761963
Epoch:  82  	Training Loss: 0.3447587490081787
Test Loss:  0.3410639464855194
Valid Loss:  0.33884328603744507
Epoch:  83  	Training Loss: 0.34438204765319824
Test Loss:  0.34069252014160156
Valid Loss:  0.33847200870513916
Epoch:  84  	Training Loss: 0.3440057635307312
Test Loss:  0.34032148122787476
Valid Loss:  0.33810120820999146
Epoch:  85  	Training Loss: 0.3436298966407776
Test Loss:  0.3399508595466614
Valid Loss:  0.3377307653427124
Epoch:  86  	Training Loss: 0.3432543873786926
Test Loss:  0.33958062529563904
Valid Loss:  0.33736076951026917
Epoch:  87  	Training Loss: 0.34287935495376587
Test Loss:  0.3392108082771301
Valid Loss:  0.33699119091033936
Epoch:  88  	Training Loss: 0.34250473976135254
Test Loss:  0.33884143829345703
Valid Loss:  0.3366219997406006
Epoch:  89  	Training Loss: 0.34213051199913025
Test Loss:  0.338472455739975
Valid Loss:  0.33625322580337524
Epoch:  90  	Training Loss: 0.3417567014694214
Test Loss:  0.33810386061668396
Valid Loss:  0.33588486909866333
Epoch:  91  	Training Loss: 0.34138330817222595
Test Loss:  0.33773568272590637
Valid Loss:  0.33551692962646484
Epoch:  92  	Training Loss: 0.34101036190986633
Test Loss:  0.337377667427063
Valid Loss:  0.33515962958335876
Epoch:  93  	Training Loss: 0.34064823389053345
Test Loss:  0.33702006936073303
Valid Loss:  0.3348027467727661
Epoch:  94  	Training Loss: 0.3402864933013916
Test Loss:  0.3366628587245941
Valid Loss:  0.3344462513923645
Epoch:  95  	Training Loss: 0.3399251699447632
Test Loss:  0.33630603551864624
Valid Loss:  0.3340901732444763
Epoch:  96  	Training Loss: 0.3395642042160034
Test Loss:  0.335949569940567
Valid Loss:  0.3337344527244568
Epoch:  97  	Training Loss: 0.3392036557197571
Test Loss:  0.33559346199035645
Valid Loss:  0.3333791494369507
Epoch:  98  	Training Loss: 0.33884352445602417
Test Loss:  0.3352378010749817
Valid Loss:  0.33302420377731323
Epoch:  99  	Training Loss: 0.3384837210178375
Test Loss:  0.334882527589798
Valid Loss:  0.3326696455478668
Epoch:  100  	Training Loss: 0.3381243348121643
Test Loss:  0.3345276117324829
Valid Loss:  0.33231547474861145
Epoch:  101  	Training Loss: 0.33776533603668213
Test Loss:  0.3341730833053589
Valid Loss:  0.33196166157722473
Epoch:  102  	Training Loss: 0.337406724691391
Test Loss:  0.3338264226913452
Valid Loss:  0.3316161334514618
Epoch:  103  	Training Loss: 0.3370564877986908
Test Loss:  0.33348017930984497
Valid Loss:  0.3312709331512451
Epoch:  104  	Training Loss: 0.33670660853385925
Test Loss:  0.3331342339515686
Valid Loss:  0.3309261202812195
Epoch:  105  	Training Loss: 0.33635708689689636
Test Loss:  0.33278870582580566
Valid Loss:  0.3305816650390625
Epoch:  106  	Training Loss: 0.3360079526901245
Test Loss:  0.3324435353279114
Valid Loss:  0.33023759722709656
Epoch:  107  	Training Loss: 0.3356591761112213
Test Loss:  0.33209872245788574
Valid Loss:  0.3298938572406769
Epoch:  108  	Training Loss: 0.33531075716018677
Test Loss:  0.33175429701805115
Valid Loss:  0.32955050468444824
Epoch:  109  	Training Loss: 0.33496275544166565
Test Loss:  0.3314101994037628
Valid Loss:  0.32920747995376587
Epoch:  110  	Training Loss: 0.3346150815486908
Test Loss:  0.3310664892196655
Valid Loss:  0.3288648724555969
Epoch:  111  	Training Loss: 0.334267795085907
Test Loss:  0.3307231068611145
Valid Loss:  0.32852256298065186
Epoch:  112  	Training Loss: 0.33392083644866943
Test Loss:  0.3303864002227783
Valid Loss:  0.3281871974468231
Epoch:  113  	Training Loss: 0.3335808515548706
Test Loss:  0.3300500512123108
Valid Loss:  0.32785212993621826
Epoch:  114  	Training Loss: 0.3332412540912628
Test Loss:  0.32971400022506714
Valid Loss:  0.32751739025115967
Epoch:  115  	Training Loss: 0.3329019546508789
Test Loss:  0.3293783366680145
Valid Loss:  0.3271830081939697
Epoch:  116  	Training Loss: 0.33256304264068604
Test Loss:  0.3290430009365082
Valid Loss:  0.32684898376464844
Epoch:  117  	Training Loss: 0.33222445845603943
Test Loss:  0.3287079930305481
Valid Loss:  0.3265152871608734
Epoch:  118  	Training Loss: 0.3318862020969391
Test Loss:  0.32837337255477905
Valid Loss:  0.32618197798728943
Epoch:  119  	Training Loss: 0.3315483331680298
Test Loss:  0.3280390501022339
Valid Loss:  0.3258489668369293
Epoch:  120  	Training Loss: 0.33121079206466675
Test Loss:  0.3277050852775574
Valid Loss:  0.3255162835121155
Epoch:  121  	Training Loss: 0.33087360858917236
Test Loss:  0.3273714780807495
Valid Loss:  0.32518401741981506
Epoch:  122  	Training Loss: 0.33053675293922424
Test Loss:  0.32704317569732666
Valid Loss:  0.32485711574554443
Epoch:  123  	Training Loss: 0.33020544052124023
Test Loss:  0.3267152011394501
Valid Loss:  0.32453060150146484
Epoch:  124  	Training Loss: 0.3298744559288025
Test Loss:  0.32638752460479736
Valid Loss:  0.3242044150829315
Epoch:  125  	Training Loss: 0.3295438289642334
Test Loss:  0.3260602355003357
Valid Loss:  0.32387852668762207
Epoch:  126  	Training Loss: 0.3292135000228882
Test Loss:  0.3257332444190979
Valid Loss:  0.32355302572250366
Epoch:  127  	Training Loss: 0.328883558511734
Test Loss:  0.32540661096572876
Valid Loss:  0.32322782278060913
Epoch:  128  	Training Loss: 0.3285539448261261
Test Loss:  0.32508033514022827
Valid Loss:  0.32290297746658325
Epoch:  129  	Training Loss: 0.32822465896606445
Test Loss:  0.32475438714027405
Valid Loss:  0.32257845997810364
Epoch:  130  	Training Loss: 0.3278957009315491
Test Loss:  0.3244287371635437
Valid Loss:  0.3222543001174927
Epoch:  131  	Training Loss: 0.32756710052490234
Test Loss:  0.324103444814682
Valid Loss:  0.3219304382801056
Epoch:  132  	Training Loss: 0.32723885774612427
Test Loss:  0.323783278465271
Valid Loss:  0.32161182165145874
Epoch:  133  	Training Loss: 0.3269158899784088
Test Loss:  0.32346343994140625
Valid Loss:  0.3212934732437134
Epoch:  134  	Training Loss: 0.32659322023391724
Test Loss:  0.3231438994407654
Valid Loss:  0.32097551226615906
Epoch:  135  	Training Loss: 0.3262708783149719
Test Loss:  0.32282471656799316
Valid Loss:  0.3206578493118286
Epoch:  136  	Training Loss: 0.32594889402389526
Test Loss:  0.3225058317184448
Valid Loss:  0.32034051418304443
Epoch:  137  	Training Loss: 0.32562723755836487
Test Loss:  0.32218724489212036
Valid Loss:  0.32002347707748413
Epoch:  138  	Training Loss: 0.32530587911605835
Test Loss:  0.32186901569366455
Valid Loss:  0.3197067677974701
Epoch:  139  	Training Loss: 0.3249848484992981
Test Loss:  0.3215510845184326
Valid Loss:  0.3193903863430023
Epoch:  140  	Training Loss: 0.3246641159057617
Test Loss:  0.32123348116874695
Valid Loss:  0.3190743327140808
Epoch:  141  	Training Loss: 0.324343740940094
Test Loss:  0.32091620564460754
Valid Loss:  0.3187585473060608
Epoch:  142  	Training Loss: 0.32402366399765015
Test Loss:  0.3206026256084442
Valid Loss:  0.3184465765953064
Epoch:  143  	Training Loss: 0.3237074315547943
Test Loss:  0.32028940320014954
Valid Loss:  0.31813496351242065
Epoch:  144  	Training Loss: 0.32339155673980713
Test Loss:  0.3199765086174011
Valid Loss:  0.3178236484527588
Epoch:  145  	Training Loss: 0.3230760097503662
Test Loss:  0.3196639120578766
Valid Loss:  0.3175126314163208
Epoch:  146  	Training Loss: 0.3227607011795044
Test Loss:  0.3193516135215759
Valid Loss:  0.3172019422054291
Epoch:  147  	Training Loss: 0.322445809841156
Test Loss:  0.3190396726131439
Valid Loss:  0.31689155101776123 29%|██▉       | 147/500 [01:42<02:39,  2.21it/s] 30%|██▉       | 149/500 [01:42<01:58,  2.96it/s] 30%|███       | 151/500 [01:48<06:55,  1.19s/it] 31%|███       | 153/500 [01:49<04:57,  1.17it/s] 31%|███       | 155/500 [01:49<03:33,  1.61it/s] 31%|███▏      | 157/500 [01:49<02:35,  2.21it/s] 32%|███▏      | 159/500 [01:49<01:54,  2.97it/s] 32%|███▏      | 161/500 [01:55<06:42,  1.19s/it] 33%|███▎      | 163/500 [01:55<04:47,  1.17it/s] 33%|███▎      | 165/500 [01:56<03:26,  1.62it/s] 33%|███▎      | 167/500 [01:56<02:30,  2.21it/s] 34%|███▍      | 169/500 [01:56<01:51,  2.98it/s] 34%|███▍      | 171/500 [02:02<06:28,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:37,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.00it/s] 36%|███▌      | 181/500 [02:09<06:14,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:28,  1.18it/s] 37%|███▋      | 185/500 [02:09<03:13,  1.63it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.22it/s] 38%|███▊      | 189/500 [02:09<01:43,  2.99it/s] 38%|███▊      | 191/500 [02:16<06:04,  1.18s/it] 39%|███▊      | 193/500 [02:16<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:16,  2.22it/s] 40%|███▉      | 199/500 [02:16<01:40,  2.99it/s] 40%|████      | 201/500 [02:23<05:48,  1.17s/it] 41%|████      | 203/500 [02:23<04:08,  1.19it/s] 41%|████      | 205/500 [02:23<02:58,  1.65it/s] 41%|████▏     | 207/500 [02:23<02:10,  2.25it/s] 42%|████▏     | 209/500 [02:23<01:36,  3.03it/s] 42%|████▏     | 211/500 [02:29<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:00,  1.19it/s] 43%|████▎     | 215/500 [02:30<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.01it/s]
Epoch:  148  	Training Loss: 0.3221311867237091
Test Loss:  0.3187279999256134
Valid Loss:  0.31658151745796204
Epoch:  149  	Training Loss: 0.32181692123413086
Test Loss:  0.31841665506362915
Valid Loss:  0.3162717819213867
Epoch:  150  	Training Loss: 0.3215029239654541
Test Loss:  0.31810563802719116
Valid Loss:  0.3159623444080353
Epoch:  151  	Training Loss: 0.321189284324646
Test Loss:  0.31779494881629944
Valid Loss:  0.3156532645225525
Epoch:  152  	Training Loss: 0.32087594270706177
Test Loss:  0.3174876570701599
Valid Loss:  0.3153475522994995
Epoch:  153  	Training Loss: 0.3205661177635193
Test Loss:  0.31718069314956665
Valid Loss:  0.31504225730895996
Epoch:  154  	Training Loss: 0.3202565908432007
Test Loss:  0.3168739974498749
Valid Loss:  0.3147372007369995
Epoch:  155  	Training Loss: 0.31994736194610596
Test Loss:  0.31656765937805176
Valid Loss:  0.31443241238594055
Epoch:  156  	Training Loss: 0.3196384310722351
Test Loss:  0.31626152992248535
Valid Loss:  0.31412798166275024
Epoch:  157  	Training Loss: 0.3193298280239105
Test Loss:  0.3159557580947876
Valid Loss:  0.3138238489627838
Epoch:  158  	Training Loss: 0.3190215229988098
Test Loss:  0.3156502842903137
Valid Loss:  0.31351998448371887
Epoch:  159  	Training Loss: 0.3187134861946106
Test Loss:  0.3153451085090637
Valid Loss:  0.3132164180278778
Epoch:  160  	Training Loss: 0.31840577721595764
Test Loss:  0.3150402307510376
Valid Loss:  0.312913179397583
Epoch:  161  	Training Loss: 0.31809836626052856
Test Loss:  0.31473565101623535
Valid Loss:  0.3126102089881897
Epoch:  162  	Training Loss: 0.31779128313064575
Test Loss:  0.3144341707229614
Valid Loss:  0.3123103976249695
Epoch:  163  	Training Loss: 0.31748732924461365
Test Loss:  0.3141329884529114
Valid Loss:  0.31201082468032837
Epoch:  164  	Training Loss: 0.3171836733818054
Test Loss:  0.3138320744037628
Valid Loss:  0.3117116093635559
Epoch:  165  	Training Loss: 0.31688034534454346
Test Loss:  0.31353145837783813
Valid Loss:  0.31141263246536255
Epoch:  166  	Training Loss: 0.3165772557258606
Test Loss:  0.31323111057281494
Valid Loss:  0.31111395359039307
Epoch:  167  	Training Loss: 0.316274493932724
Test Loss:  0.3129311203956604
Valid Loss:  0.31081557273864746
Epoch:  168  	Training Loss: 0.3159720301628113
Test Loss:  0.3126313388347626
Valid Loss:  0.31051748991012573
Epoch:  169  	Training Loss: 0.31566986441612244
Test Loss:  0.3123319149017334
Valid Loss:  0.3102196753025055
Epoch:  170  	Training Loss: 0.31536799669265747
Test Loss:  0.3120327591896057
Valid Loss:  0.30992215871810913
Epoch:  171  	Training Loss: 0.315066397190094
Test Loss:  0.3117338716983795
Valid Loss:  0.30962494015693665
Epoch:  172  	Training Loss: 0.3147650957107544
Test Loss:  0.3114373981952667
Valid Loss:  0.30933013558387756
Epoch:  173  	Training Loss: 0.3144662380218506
Test Loss:  0.3111412227153778
Valid Loss:  0.30903559923171997
Epoch:  174  	Training Loss: 0.31416767835617065
Test Loss:  0.3108453154563904
Valid Loss:  0.30874139070510864
Epoch:  175  	Training Loss: 0.3138694167137146
Test Loss:  0.3105497360229492
Valid Loss:  0.3084474802017212
Epoch:  176  	Training Loss: 0.3135714828968048
Test Loss:  0.31025445461273193
Valid Loss:  0.3081538677215576
Epoch:  177  	Training Loss: 0.3132737874984741
Test Loss:  0.30995941162109375
Valid Loss:  0.30786049365997314
Epoch:  178  	Training Loss: 0.3129764199256897
Test Loss:  0.30966469645500183
Valid Loss:  0.30756744742393494
Epoch:  179  	Training Loss: 0.31267932057380676
Test Loss:  0.3093702793121338
Valid Loss:  0.3072746694087982
Epoch:  180  	Training Loss: 0.3123825192451477
Test Loss:  0.30907613039016724
Valid Loss:  0.3069821894168854
Epoch:  181  	Training Loss: 0.3120860457420349
Test Loss:  0.30878227949142456
Valid Loss:  0.3066900074481964
Epoch:  182  	Training Loss: 0.3117898404598236
Test Loss:  0.3084907531738281
Valid Loss:  0.3064001500606537
Epoch:  183  	Training Loss: 0.31149598956108093
Test Loss:  0.3081994652748108
Valid Loss:  0.30611056089401245
Epoch:  184  	Training Loss: 0.31120240688323975
Test Loss:  0.30790847539901733
Valid Loss:  0.30582118034362793
Epoch:  185  	Training Loss: 0.31090912222862244
Test Loss:  0.30761778354644775
Valid Loss:  0.30553215742111206
Epoch:  186  	Training Loss: 0.31061607599258423
Test Loss:  0.3073273301124573
Valid Loss:  0.3052433729171753
Epoch:  187  	Training Loss: 0.3103233575820923
Test Loss:  0.3070371448993683
Valid Loss:  0.3049548864364624
Epoch:  188  	Training Loss: 0.31003087759017944
Test Loss:  0.3067472577095032
Valid Loss:  0.3046666383743286
Epoch:  189  	Training Loss: 0.3097386360168457
Test Loss:  0.30645760893821716
Valid Loss:  0.3043786883354187
Epoch:  190  	Training Loss: 0.3094467520713806
Test Loss:  0.30616825819015503
Valid Loss:  0.3040909767150879
Epoch:  191  	Training Loss: 0.30915504693984985
Test Loss:  0.3058791756629944
Valid Loss:  0.30380356311798096
Epoch:  192  	Training Loss: 0.30886369943618774
Test Loss:  0.30559179186820984
Valid Loss:  0.3035178780555725
Epoch:  193  	Training Loss: 0.3085740804672241
Test Loss:  0.3053046762943268
Valid Loss:  0.30323243141174316
Epoch:  194  	Training Loss: 0.308284729719162
Test Loss:  0.3050178289413452
Valid Loss:  0.3029472529888153
Epoch:  195  	Training Loss: 0.30799561738967896
Test Loss:  0.3047313094139099
Valid Loss:  0.30266237258911133
Epoch:  196  	Training Loss: 0.3077068328857422
Test Loss:  0.3044450283050537
Valid Loss:  0.30237776041030884
Epoch:  197  	Training Loss: 0.3074182868003845
Test Loss:  0.3041589856147766
Valid Loss:  0.30209341645240784
Epoch:  198  	Training Loss: 0.30713003873825073
Test Loss:  0.3038732409477234
Valid Loss:  0.3018093705177307
Epoch:  199  	Training Loss: 0.30684205889701843
Test Loss:  0.30358776450157166
Valid Loss:  0.3015255331993103
Epoch:  200  	Training Loss: 0.30655431747436523
Test Loss:  0.3033025562763214
Valid Loss:  0.30124199390411377
Epoch:  201  	Training Loss: 0.3062668740749359
Test Loss:  0.30301761627197266
Valid Loss:  0.3009587526321411
Epoch:  202  	Training Loss: 0.3059796988964081
Test Loss:  0.3027341365814209
Valid Loss:  0.3006768822669983
Epoch:  203  	Training Loss: 0.30569398403167725
Test Loss:  0.30245089530944824
Valid Loss:  0.3003953695297241
Epoch:  204  	Training Loss: 0.3054085671901703
Test Loss:  0.3021678924560547
Valid Loss:  0.3001140356063843
Epoch:  205  	Training Loss: 0.30512338876724243
Test Loss:  0.301885187625885
Valid Loss:  0.2998329997062683
Epoch:  206  	Training Loss: 0.30483847856521606
Test Loss:  0.3016027510166168
Valid Loss:  0.29955223202705383
Epoch:  207  	Training Loss: 0.3045538365840912
Test Loss:  0.30132055282592773
Valid Loss:  0.29927173256874084
Epoch:  208  	Training Loss: 0.3042694330215454
Test Loss:  0.30103862285614014
Valid Loss:  0.29899147152900696
Epoch:  209  	Training Loss: 0.3039853274822235
Test Loss:  0.30075693130493164
Valid Loss:  0.29871147871017456
Epoch:  210  	Training Loss: 0.3037014901638031
Test Loss:  0.300475537776947
Valid Loss:  0.29843175411224365
Epoch:  211  	Training Loss: 0.3034178614616394
Test Loss:  0.3001944124698639
Valid Loss:  0.29815226793289185
Epoch:  212  	Training Loss: 0.303134560585022
Test Loss:  0.2999145984649658
Valid Loss:  0.2978741526603699
Epoch:  213  	Training Loss: 0.302852600812912
Test Loss:  0.2996350824832916
Valid Loss:  0.2975963056087494
Epoch:  214  	Training Loss: 0.3025709092617035
Test Loss:  0.29935580492019653
Valid Loss:  0.2973187267780304
Epoch:  215  	Training Loss: 0.3022894859313965
Test Loss:  0.29907679557800293
Valid Loss:  0.2970414161682129
Epoch:  216  	Training Loss: 0.30200836062431335
Test Loss:  0.298798143863678
Valid Loss:  0.2967643737792969
Epoch:  217  	Training Loss: 0.3017275035381317
Test Loss:  0.29851967096328735
Valid Loss:  0.29648762941360474
Epoch:  218  	Training Loss: 0.3014468848705292
Test Loss:  0.2982414960861206
Valid Loss:  0.2962111234664917
Epoch:  219  	Training Loss: 0.3011665940284729
Test Loss:  0.29796355962753296
Valid Loss:  0.29593485593795776
Epoch:  220  	Training Loss: 0.3008865416049957
Test Loss:  0.2976859211921692
Valid Loss:  0.2956589162349701
 44%|████▍     | 221/500 [02:36<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:37<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:37<01:30,  2.98it/s] 46%|████▌     | 231/500 [02:43<05:18,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:47,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:43,  1.62it/s] 47%|████▋     | 237/500 [02:43<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:44<01:27,  2.97it/s] 48%|████▊     | 241/500 [02:50<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:50<03:38,  1.18it/s] 49%|████▉     | 245/500 [02:50<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.22it/s] 50%|████▉     | 249/500 [02:50<01:24,  2.99it/s] 50%|█████     | 251/500 [02:57<04:53,  1.18s/it] 51%|█████     | 253/500 [02:57<03:28,  1.18it/s] 51%|█████     | 255/500 [02:57<02:29,  1.63it/s] 51%|█████▏    | 257/500 [02:57<01:48,  2.23it/s] 52%|█████▏    | 259/500 [02:57<01:20,  3.01it/s] 52%|█████▏    | 261/500 [03:04<04:40,  1.17s/it] 53%|█████▎    | 263/500 [03:04<03:19,  1.19it/s] 53%|█████▎    | 265/500 [03:04<02:23,  1.64it/s] 53%|█████▎    | 267/500 [03:04<01:43,  2.24it/s] 54%|█████▍    | 269/500 [03:04<01:16,  3.01it/s] 54%|█████▍    | 271/500 [03:10<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:11<03:11,  1.18it/s] 55%|█████▌    | 275/500 [03:11<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:11<01:39,  2.23it/s] 56%|█████▌    | 279/500 [03:11<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:17<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:17<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:17<02:10,  1.64it/s] 57%|█████▋    | 287/500 [03:18<01:34,  2.24it/s] 58%|█████▊    | 289/500 [03:18<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:24<04:02,  1.16s/it] 59%|█████▊    | 293/500 [03:24<02:52,  1.20it/s]Epoch:  221  	Training Loss: 0.30060672760009766
Test Loss:  0.2974085211753845
Valid Loss:  0.2953832149505615
Epoch:  222  	Training Loss: 0.30032724142074585
Test Loss:  0.2971319854259491
Valid Loss:  0.2951083481311798
Epoch:  223  	Training Loss: 0.3000485301017761
Test Loss:  0.2968556880950928
Valid Loss:  0.2948336899280548
Epoch:  224  	Training Loss: 0.2997701168060303
Test Loss:  0.29657965898513794
Valid Loss:  0.2945593595504761
Epoch:  225  	Training Loss: 0.2994919717311859
Test Loss:  0.2963038682937622
Valid Loss:  0.29428523778915405
Epoch:  226  	Training Loss: 0.29921406507492065
Test Loss:  0.2960283160209656
Valid Loss:  0.2940113842487335
Epoch:  227  	Training Loss: 0.2989364564418793
Test Loss:  0.2957530617713928
Valid Loss:  0.29373782873153687
Epoch:  228  	Training Loss: 0.298659086227417
Test Loss:  0.29547804594039917
Valid Loss:  0.2934644818305969
Epoch:  229  	Training Loss: 0.2983819544315338
Test Loss:  0.2952033281326294
Valid Loss:  0.29319143295288086
Epoch:  230  	Training Loss: 0.2981051206588745
Test Loss:  0.29492881894111633
Valid Loss:  0.2929185926914215
Epoch:  231  	Training Loss: 0.2978285253047943
Test Loss:  0.2946545481681824
Valid Loss:  0.29264605045318604
Epoch:  232  	Training Loss: 0.2975521683692932
Test Loss:  0.29438114166259766
Valid Loss:  0.29237425327301025
Epoch:  233  	Training Loss: 0.29727667570114136
Test Loss:  0.29410791397094727
Valid Loss:  0.29210275411605835
Epoch:  234  	Training Loss: 0.2970013916492462
Test Loss:  0.29383498430252075
Valid Loss:  0.29183149337768555
Epoch:  235  	Training Loss: 0.29672640562057495
Test Loss:  0.2935623228549957
Valid Loss:  0.2915605306625366
Epoch:  236  	Training Loss: 0.2964516282081604
Test Loss:  0.2932898700237274
Valid Loss:  0.291289746761322
Epoch:  237  	Training Loss: 0.29617708921432495
Test Loss:  0.29301774501800537
Valid Loss:  0.2910192608833313
Epoch:  238  	Training Loss: 0.29590287804603577
Test Loss:  0.29274582862854004
Valid Loss:  0.2907490134239197
Epoch:  239  	Training Loss: 0.2956289052963257
Test Loss:  0.2924741506576538
Valid Loss:  0.29047906398773193
Epoch:  240  	Training Loss: 0.2953551709651947
Test Loss:  0.2922027111053467
Valid Loss:  0.2902092933654785
Epoch:  241  	Training Loss: 0.2950817048549652
Test Loss:  0.2919315695762634
Valid Loss:  0.289939820766449
Epoch:  242  	Training Loss: 0.29480844736099243
Test Loss:  0.29166117310523987
Valid Loss:  0.2896710932254791
Epoch:  243  	Training Loss: 0.2945360541343689
Test Loss:  0.2913910448551178
Valid Loss:  0.28940266370773315
Epoch:  244  	Training Loss: 0.2942638695240021
Test Loss:  0.2911211848258972
Valid Loss:  0.28913450241088867
Epoch:  245  	Training Loss: 0.29399195313453674
Test Loss:  0.29085153341293335
Valid Loss:  0.2888665199279785
Epoch:  246  	Training Loss: 0.2937203049659729
Test Loss:  0.29058215022087097
Valid Loss:  0.28859883546829224
Epoch:  247  	Training Loss: 0.29344889521598816
Test Loss:  0.29031306505203247
Valid Loss:  0.28833141922950745
Epoch:  248  	Training Loss: 0.2931777536869049
Test Loss:  0.29004421830177307
Valid Loss:  0.28806424140930176
Epoch:  249  	Training Loss: 0.29290688037872314
Test Loss:  0.2897756099700928
Valid Loss:  0.28779730200767517
Epoch:  250  	Training Loss: 0.2926362454891205
Test Loss:  0.2895072400569916
Valid Loss:  0.2875306308269501
Epoch:  251  	Training Loss: 0.2923658490180969
Test Loss:  0.28923916816711426
Valid Loss:  0.2872641980648041
Epoch:  252  	Training Loss: 0.29209572076797485
Test Loss:  0.288971483707428
Valid Loss:  0.2869982123374939
Epoch:  253  	Training Loss: 0.2918260395526886
Test Loss:  0.2887040376663208
Valid Loss:  0.2867324650287628
Epoch:  254  	Training Loss: 0.29155659675598145
Test Loss:  0.2884368896484375
Valid Loss:  0.2864669859409332
Epoch:  255  	Training Loss: 0.2912874221801758
Test Loss:  0.2881699502468109
Valid Loss:  0.28620174527168274
Epoch:  256  	Training Loss: 0.291018545627594
Test Loss:  0.2879033088684082
Valid Loss:  0.28593677282333374
Epoch:  257  	Training Loss: 0.29074984788894653
Test Loss:  0.2876368761062622
Valid Loss:  0.28567203879356384
Epoch:  258  	Training Loss: 0.29048144817352295
Test Loss:  0.2873706817626953
Valid Loss:  0.28540754318237305
Epoch:  259  	Training Loss: 0.2902132570743561
Test Loss:  0.2871047854423523
Valid Loss:  0.28514331579208374
Epoch:  260  	Training Loss: 0.2899453341960907
Test Loss:  0.2868391275405884
Valid Loss:  0.28487932682037354
Epoch:  261  	Training Loss: 0.2896776795387268
Test Loss:  0.28657370805740356
Valid Loss:  0.28461557626724243
Epoch:  262  	Training Loss: 0.2894102931022644
Test Loss:  0.286308616399765
Valid Loss:  0.28435218334198
Epoch:  263  	Training Loss: 0.28914323449134827
Test Loss:  0.28604382276535034
Valid Loss:  0.284089058637619
Epoch:  264  	Training Loss: 0.28887641429901123
Test Loss:  0.28577920794487
Valid Loss:  0.28382614254951477
Epoch:  265  	Training Loss: 0.2886098623275757
Test Loss:  0.28551486134529114
Valid Loss:  0.283563494682312
Epoch:  266  	Training Loss: 0.28834354877471924
Test Loss:  0.28525078296661377
Valid Loss:  0.28330111503601074
Epoch:  267  	Training Loss: 0.2880774736404419
Test Loss:  0.2849869430065155
Valid Loss:  0.2830389142036438
Epoch:  268  	Training Loss: 0.2878116965293884
Test Loss:  0.2847233712673187
Valid Loss:  0.28277701139450073
Epoch:  269  	Training Loss: 0.2875461280345917
Test Loss:  0.28446000814437866
Valid Loss:  0.28251534700393677
Epoch:  270  	Training Loss: 0.2872808277606964
Test Loss:  0.2841969132423401
Valid Loss:  0.2822539508342743
Epoch:  271  	Training Loss: 0.28701573610305786
Test Loss:  0.2839340567588806
Valid Loss:  0.2819927930831909
Epoch:  272  	Training Loss: 0.2867509424686432
Test Loss:  0.28367137908935547
Valid Loss:  0.2817317843437195
Epoch:  273  	Training Loss: 0.28648629784584045
Test Loss:  0.2834089398384094
Valid Loss:  0.28147101402282715
Epoch:  274  	Training Loss: 0.2862219214439392
Test Loss:  0.2831467390060425
Valid Loss:  0.2812104821205139
Epoch:  275  	Training Loss: 0.2859577536582947
Test Loss:  0.28288477659225464
Valid Loss:  0.28095024824142456
Epoch:  276  	Training Loss: 0.285693883895874
Test Loss:  0.2826230823993683
Valid Loss:  0.28069019317626953
Epoch:  277  	Training Loss: 0.2854301929473877
Test Loss:  0.28236162662506104
Valid Loss:  0.2804304361343384
Epoch:  278  	Training Loss: 0.28516680002212524
Test Loss:  0.2821003794670105
Valid Loss:  0.28017088770866394
Epoch:  279  	Training Loss: 0.2849036455154419
Test Loss:  0.28183940052986145
Valid Loss:  0.2799115777015686
Epoch:  280  	Training Loss: 0.28464072942733765
Test Loss:  0.2815787196159363
Valid Loss:  0.27965253591537476
Epoch:  281  	Training Loss: 0.2843780517578125
Test Loss:  0.28131818771362305
Valid Loss:  0.27939373254776
Epoch:  282  	Training Loss: 0.28411567211151123
Test Loss:  0.28105780482292175
Valid Loss:  0.27913498878479004
Epoch:  283  	Training Loss: 0.28385329246520996
Test Loss:  0.2807976007461548
Valid Loss:  0.27887651324272156
Epoch:  284  	Training Loss: 0.28359121084213257
Test Loss:  0.2805376648902893
Valid Loss:  0.2786182761192322
Epoch:  285  	Training Loss: 0.2833293676376343
Test Loss:  0.2802779972553253
Valid Loss:  0.2783603072166443
Epoch:  286  	Training Loss: 0.2830677628517151
Test Loss:  0.28001856803894043
Valid Loss:  0.2781025171279907
Epoch:  287  	Training Loss: 0.282806396484375
Test Loss:  0.27975937724113464
Valid Loss:  0.27784502506256104
Epoch:  288  	Training Loss: 0.2825452983379364
Test Loss:  0.27950042486190796
Valid Loss:  0.27758777141571045
Epoch:  289  	Training Loss: 0.2822844386100769
Test Loss:  0.27924174070358276
Valid Loss:  0.2773307263851166
Epoch:  290  	Training Loss: 0.2820237874984741
Test Loss:  0.2789832353591919
Valid Loss:  0.2770739793777466
Epoch:  291  	Training Loss: 0.2817634344100952
Test Loss:  0.2787250280380249
Valid Loss:  0.2768174111843109
Epoch:  292  	Training Loss: 0.2815033197402954
Test Loss:  0.2784668803215027
Valid Loss:  0.2765609622001648
Epoch:  293  	Training Loss: 0.2812432646751404
Test Loss:  0.27820900082588196
Valid Loss:  0.2763047516345978
 59%|█████▉    | 295/500 [03:24<02:03,  1.66it/s] 59%|█████▉    | 297/500 [03:24<01:29,  2.26it/s] 60%|█████▉    | 299/500 [03:24<01:06,  3.04it/s] 60%|██████    | 301/500 [03:31<03:55,  1.18s/it] 61%|██████    | 303/500 [03:31<02:47,  1.18it/s] 61%|██████    | 305/500 [03:31<01:59,  1.63it/s] 61%|██████▏   | 307/500 [03:31<01:26,  2.22it/s] 62%|██████▏   | 309/500 [03:31<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:38<03:42,  1.18s/it] 63%|██████▎   | 313/500 [03:38<02:37,  1.19it/s] 63%|██████▎   | 315/500 [03:38<01:52,  1.64it/s] 63%|██████▎   | 317/500 [03:38<01:21,  2.24it/s] 64%|██████▍   | 319/500 [03:38<01:00,  3.01it/s] 64%|██████▍   | 321/500 [03:44<03:27,  1.16s/it] 65%|██████▍   | 323/500 [03:44<02:27,  1.20it/s] 65%|██████▌   | 325/500 [03:45<01:45,  1.66it/s] 65%|██████▌   | 327/500 [03:45<01:16,  2.26it/s] 66%|██████▌   | 329/500 [03:45<00:56,  3.04it/s] 66%|██████▌   | 331/500 [03:51<03:16,  1.16s/it] 67%|██████▋   | 333/500 [03:51<02:19,  1.20it/s] 67%|██████▋   | 335/500 [03:51<01:39,  1.66it/s] 67%|██████▋   | 337/500 [03:51<01:12,  2.26it/s] 68%|██████▊   | 339/500 [03:52<00:52,  3.04it/s] 68%|██████▊   | 341/500 [03:58<03:05,  1.17s/it] 69%|██████▊   | 343/500 [03:58<02:11,  1.19it/s] 69%|██████▉   | 345/500 [03:58<01:34,  1.64it/s] 69%|██████▉   | 347/500 [03:58<01:08,  2.24it/s] 70%|██████▉   | 349/500 [03:58<00:50,  3.01it/s] 70%|███████   | 351/500 [04:05<02:54,  1.17s/it] 71%|███████   | 353/500 [04:05<02:03,  1.19it/s] 71%|███████   | 355/500 [04:05<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:05<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:05<00:46,  3.01it/s] 72%|███████▏  | 361/500 [04:11<02:40,  1.16s/it] 73%|███████▎  | 363/500 [04:11<01:53,  1.20it/s] 73%|███████▎  | 365/500 [04:12<01:21,  1.66it/s]Epoch:  294  	Training Loss: 0.28098347783088684
Test Loss:  0.27795132994651794
Valid Loss:  0.27604877948760986
Epoch:  295  	Training Loss: 0.2807239294052124
Test Loss:  0.2776939272880554
Valid Loss:  0.27579304575920105
Epoch:  296  	Training Loss: 0.28046464920043945
Test Loss:  0.277436763048172
Valid Loss:  0.2755375802516937
Epoch:  297  	Training Loss: 0.2802055776119232
Test Loss:  0.2771798074245453
Valid Loss:  0.2752823233604431
Epoch:  298  	Training Loss: 0.2799467444419861
Test Loss:  0.27692317962646484
Valid Loss:  0.275027334690094
Epoch:  299  	Training Loss: 0.27968817949295044
Test Loss:  0.27666670083999634
Valid Loss:  0.274772584438324
Epoch:  300  	Training Loss: 0.2794298827648163
Test Loss:  0.2764105200767517
Valid Loss:  0.27451810240745544
Epoch:  301  	Training Loss: 0.27917182445526123
Test Loss:  0.2761545777320862
Valid Loss:  0.27426379919052124
Epoch:  302  	Training Loss: 0.2789139747619629
Test Loss:  0.2758985757827759
Valid Loss:  0.27400946617126465
Epoch:  303  	Training Loss: 0.2786560654640198
Test Loss:  0.2756427824497223
Valid Loss:  0.27375540137290955
Epoch:  304  	Training Loss: 0.27839842438697815
Test Loss:  0.2753872573375702
Valid Loss:  0.27350157499313354
Epoch:  305  	Training Loss: 0.2781410217285156
Test Loss:  0.2751319408416748
Valid Loss:  0.27324795722961426
Epoch:  306  	Training Loss: 0.2778838574886322
Test Loss:  0.2748768925666809
Valid Loss:  0.2729945778846741
Epoch:  307  	Training Loss: 0.2776269316673279
Test Loss:  0.2746220827102661
Valid Loss:  0.272741436958313
Epoch:  308  	Training Loss: 0.27737027406692505
Test Loss:  0.2743675112724304
Valid Loss:  0.2724885642528534
Epoch:  309  	Training Loss: 0.27711382508277893
Test Loss:  0.2741132080554962
Valid Loss:  0.2722359299659729
Epoch:  310  	Training Loss: 0.2768576741218567
Test Loss:  0.2738591432571411
Valid Loss:  0.2719835340976715
Epoch:  311  	Training Loss: 0.2766016721725464
Test Loss:  0.2736052870750427
Valid Loss:  0.2717313766479492
Epoch:  312  	Training Loss: 0.27634602785110474
Test Loss:  0.2733513116836548
Valid Loss:  0.2714790999889374
Epoch:  313  	Training Loss: 0.27609017491340637
Test Loss:  0.27309757471084595
Valid Loss:  0.27122706174850464
Epoch:  314  	Training Loss: 0.2758346199989319
Test Loss:  0.2728440761566162
Valid Loss:  0.270975261926651
Epoch:  315  	Training Loss: 0.2755792737007141
Test Loss:  0.27259084582328796
Valid Loss:  0.27072370052337646
Epoch:  316  	Training Loss: 0.27532416582107544
Test Loss:  0.2723378539085388
Valid Loss:  0.2704724073410034
Epoch:  317  	Training Loss: 0.27506932616233826
Test Loss:  0.2720850706100464
Valid Loss:  0.2702212929725647
Epoch:  318  	Training Loss: 0.2748147249221802
Test Loss:  0.27183252573013306
Valid Loss:  0.26997044682502747
Epoch:  319  	Training Loss: 0.2745603919029236
Test Loss:  0.2715802788734436
Valid Loss:  0.26971983909606934
Epoch:  320  	Training Loss: 0.2743062376976013
Test Loss:  0.2713282108306885
Valid Loss:  0.2694694995880127
Epoch:  321  	Training Loss: 0.27405235171318054
Test Loss:  0.2710764408111572
Valid Loss:  0.26921939849853516
Epoch:  322  	Training Loss: 0.27379870414733887
Test Loss:  0.2708245515823364
Valid Loss:  0.26896923780441284
Epoch:  323  	Training Loss: 0.2735450267791748
Test Loss:  0.2705729603767395
Valid Loss:  0.26871931552886963
Epoch:  324  	Training Loss: 0.27329158782958984
Test Loss:  0.2703216075897217
Valid Loss:  0.26846960186958313
Epoch:  325  	Training Loss: 0.273038387298584
Test Loss:  0.27007046341896057
Valid Loss:  0.2682201564311981
Epoch:  326  	Training Loss: 0.2727854549884796
Test Loss:  0.26981955766677856
Valid Loss:  0.2679709494113922
Epoch:  327  	Training Loss: 0.27253273129463196
Test Loss:  0.26956886053085327
Valid Loss:  0.267721951007843
Epoch:  328  	Training Loss: 0.272280216217041
Test Loss:  0.26931846141815186
Valid Loss:  0.2674732208251953
Epoch:  329  	Training Loss: 0.27202796936035156
Test Loss:  0.26906824111938477
Valid Loss:  0.2672246992588043
Epoch:  330  	Training Loss: 0.2717759609222412
Test Loss:  0.2688182592391968
Valid Loss:  0.26697641611099243
Epoch:  331  	Training Loss: 0.27152419090270996
Test Loss:  0.26856857538223267
Valid Loss:  0.26672834157943726
Epoch:  332  	Training Loss: 0.2712726593017578
Test Loss:  0.2683185040950775
Valid Loss:  0.2664799988269806
Epoch:  333  	Training Loss: 0.271020770072937
Test Loss:  0.26806867122650146
Valid Loss:  0.26623183488845825
Epoch:  334  	Training Loss: 0.2707691788673401
Test Loss:  0.2678190767765045
Valid Loss:  0.2659839391708374
Epoch:  335  	Training Loss: 0.2705177664756775
Test Loss:  0.26756972074508667
Valid Loss:  0.26573628187179565
Epoch:  336  	Training Loss: 0.2702666223049164
Test Loss:  0.2673206329345703
Valid Loss:  0.265488862991333
Epoch:  337  	Training Loss: 0.270015686750412
Test Loss:  0.2670717239379883
Valid Loss:  0.2652416527271271
Epoch:  338  	Training Loss: 0.2697650194168091
Test Loss:  0.26682308316230774
Valid Loss:  0.26499468088150024
Epoch:  339  	Training Loss: 0.2695145606994629
Test Loss:  0.2665746510028839
Valid Loss:  0.2647479772567749
Epoch:  340  	Training Loss: 0.2692643702030182
Test Loss:  0.2663264870643616
Valid Loss:  0.2645014524459839
Epoch:  341  	Training Loss: 0.2690143883228302
Test Loss:  0.26607853174209595
Valid Loss:  0.26425519585609436
Epoch:  342  	Training Loss: 0.2687646448612213
Test Loss:  0.2658303380012512
Valid Loss:  0.26400870084762573
Epoch:  343  	Training Loss: 0.2685146629810333
Test Loss:  0.2655823826789856
Valid Loss:  0.2637624442577362
Epoch:  344  	Training Loss: 0.26826491951942444
Test Loss:  0.2653346657752991
Valid Loss:  0.2635164260864258
Epoch:  345  	Training Loss: 0.26801541447639465
Test Loss:  0.26508718729019165
Valid Loss:  0.26327061653137207
Epoch:  346  	Training Loss: 0.26776614785194397
Test Loss:  0.26483994722366333
Valid Loss:  0.26302504539489746
Epoch:  347  	Training Loss: 0.2675171196460724
Test Loss:  0.2645929455757141
Valid Loss:  0.26277974247932434
Epoch:  348  	Training Loss: 0.2672683298587799
Test Loss:  0.264346182346344
Valid Loss:  0.26253464818000793
Epoch:  349  	Training Loss: 0.2670198082923889
Test Loss:  0.264099657535553
Valid Loss:  0.262289822101593
Epoch:  350  	Training Loss: 0.26677146553993225
Test Loss:  0.2638533413410187
Valid Loss:  0.2620451748371124
Epoch:  351  	Training Loss: 0.26652342081069946
Test Loss:  0.2636072635650635
Valid Loss:  0.2618007957935333
Epoch:  352  	Training Loss: 0.2662755250930786
Test Loss:  0.26336097717285156
Valid Loss:  0.26155614852905273
Epoch:  353  	Training Loss: 0.2660274803638458
Test Loss:  0.263114869594574
Valid Loss:  0.26131176948547363
Epoch:  354  	Training Loss: 0.26577961444854736
Test Loss:  0.2628690004348755
Valid Loss:  0.26106759905815125
Epoch:  355  	Training Loss: 0.265531986951828
Test Loss:  0.2626233696937561
Valid Loss:  0.26082366704940796
Epoch:  356  	Training Loss: 0.26528459787368774
Test Loss:  0.2623780071735382
Valid Loss:  0.2605799734592438
Epoch:  357  	Training Loss: 0.265037477016449
Test Loss:  0.2621328830718994
Valid Loss:  0.2603365182876587
Epoch:  358  	Training Loss: 0.26479053497314453
Test Loss:  0.26188796758651733
Valid Loss:  0.2600932717323303
Epoch:  359  	Training Loss: 0.26454389095306396
Test Loss:  0.26164332032203674
Valid Loss:  0.25985029339790344
Epoch:  360  	Training Loss: 0.2642974555492401
Test Loss:  0.2613988518714905
Valid Loss:  0.2596075236797333
Epoch:  361  	Training Loss: 0.26405125856399536
Test Loss:  0.2611546516418457
Valid Loss:  0.2593649923801422
Epoch:  362  	Training Loss: 0.2638052701950073
Test Loss:  0.2609100937843323
Valid Loss:  0.2591221034526825
Epoch:  363  	Training Loss: 0.2635589838027954
Test Loss:  0.26066580414772034
Valid Loss:  0.25887948274612427
Epoch:  364  	Training Loss: 0.2633129358291626
Test Loss:  0.2604216933250427
Valid Loss:  0.25863713026046753
Epoch:  365  	Training Loss: 0.2630670964717865
Test Loss:  0.2601779103279114
Valid Loss:  0.2583949565887451
Epoch:  366  	Training Loss: 0.2628215253353119
Test Loss:  0.25993430614471436
Valid Loss:  0.2581530511379242
 73%|███████▎  | 367/500 [04:12<00:58,  2.27it/s] 74%|███████▍  | 369/500 [04:12<00:42,  3.05it/s] 74%|███████▍  | 371/500 [04:18<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:18<01:48,  1.18it/s] 75%|███████▌  | 375/500 [04:19<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:19<00:55,  2.22it/s] 76%|███████▌  | 379/500 [04:19<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:25<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:25<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:25<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:25<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:26<00:37,  3.00it/s] 78%|███████▊  | 391/500 [04:32<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:32<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:32<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:32<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:32<00:33,  2.99it/s] 80%|████████  | 401/500 [04:39<01:56,  1.17s/it] 81%|████████  | 403/500 [04:39<01:21,  1.19it/s] 81%|████████  | 405/500 [04:39<00:57,  1.64it/s] 81%|████████▏ | 407/500 [04:39<00:41,  2.24it/s] 82%|████████▏ | 409/500 [04:39<00:30,  3.01it/s] 82%|████████▏ | 411/500 [04:46<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:46<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:46<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:46<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:46<00:27,  3.00it/s] 84%|████████▍ | 421/500 [04:52<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:53<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:53<00:45,  1.63it/s] 85%|████████▌ | 427/500 [04:53<00:32,  2.23it/s] 86%|████████▌ | 429/500 [04:53<00:23,  2.99it/s] 86%|████████▌ | 431/500 [04:59<01:20,  1.16s/it] 87%|████████▋ | 433/500 [04:59<00:56,  1.19it/s] 87%|████████▋ | 435/500 [04:59<00:39,  1.65it/s] 87%|████████▋ | 437/500 [05:00<00:28,  2.25it/s]Epoch:  367  	Training Loss: 0.2625761926174164
Test Loss:  0.25969094038009644
Valid Loss:  0.2579113841056824
Epoch:  368  	Training Loss: 0.2623310685157776
Test Loss:  0.25944784283638
Valid Loss:  0.25766995549201965
Epoch:  369  	Training Loss: 0.2620862126350403
Test Loss:  0.2592049539089203
Valid Loss:  0.25742876529693604
Epoch:  370  	Training Loss: 0.2618415951728821
Test Loss:  0.25896233320236206
Valid Loss:  0.25718778371810913
Epoch:  371  	Training Loss: 0.261597216129303
Test Loss:  0.25871992111206055
Valid Loss:  0.2569470703601837
Epoch:  372  	Training Loss: 0.261353075504303
Test Loss:  0.2584770917892456
Valid Loss:  0.2567059099674225
Epoch:  373  	Training Loss: 0.26110851764678955
Test Loss:  0.25823450088500977
Valid Loss:  0.25646501779556274
Epoch:  374  	Training Loss: 0.2608641982078552
Test Loss:  0.257992148399353
Valid Loss:  0.2562243342399597
Epoch:  375  	Training Loss: 0.2606201171875
Test Loss:  0.2577500343322754
Valid Loss:  0.2559838891029358
Epoch:  376  	Training Loss: 0.2603762447834015
Test Loss:  0.25750812888145447
Valid Loss:  0.25574371218681335
Epoch:  377  	Training Loss: 0.2601326107978821
Test Loss:  0.25726646184921265
Valid Loss:  0.25550371408462524
Epoch:  378  	Training Loss: 0.25988924503326416
Test Loss:  0.2570250630378723
Valid Loss:  0.2552639842033386
Epoch:  379  	Training Loss: 0.25964611768722534
Test Loss:  0.2567838728427887
Valid Loss:  0.2550244927406311
Epoch:  380  	Training Loss: 0.25940319895744324
Test Loss:  0.2565429210662842
Valid Loss:  0.2547852098941803
Epoch:  381  	Training Loss: 0.25916051864624023
Test Loss:  0.25630220770835876
Valid Loss:  0.2545461356639862
Epoch:  382  	Training Loss: 0.25891804695129395
Test Loss:  0.2560611963272095
Valid Loss:  0.2543068528175354
Epoch:  383  	Training Loss: 0.25867533683776855
Test Loss:  0.25582045316696167
Valid Loss:  0.2540677487850189
Epoch:  384  	Training Loss: 0.25843286514282227
Test Loss:  0.2555798888206482
Valid Loss:  0.25382888317108154
Epoch:  385  	Training Loss: 0.2581906020641327
Test Loss:  0.2553395926952362
Valid Loss:  0.25359025597572327
Epoch:  386  	Training Loss: 0.2579485774040222
Test Loss:  0.2550995349884033
Valid Loss:  0.2533518970012665
Epoch:  387  	Training Loss: 0.25770679116249084
Test Loss:  0.25485968589782715
Valid Loss:  0.25311368703842163
Epoch:  388  	Training Loss: 0.2574652433395386
Test Loss:  0.2546200752258301
Valid Loss:  0.25287577509880066
Epoch:  389  	Training Loss: 0.257223904132843
Test Loss:  0.2543807029724121
Valid Loss:  0.252638041973114
Epoch:  390  	Training Loss: 0.25698283314704895
Test Loss:  0.25414156913757324
Valid Loss:  0.25240060687065125
Epoch:  391  	Training Loss: 0.256742000579834
Test Loss:  0.2539026439189911
Valid Loss:  0.2521633505821228
Epoch:  392  	Training Loss: 0.25650137662887573
Test Loss:  0.2536632716655731
Valid Loss:  0.25192564725875854
Epoch:  393  	Training Loss: 0.2562602758407593
Test Loss:  0.25342413783073425
Valid Loss:  0.2516882121562958
Epoch:  394  	Training Loss: 0.2560194432735443
Test Loss:  0.2531852126121521
Valid Loss:  0.25145095586776733
Epoch:  395  	Training Loss: 0.25577884912490845
Test Loss:  0.25294655561447144
Valid Loss:  0.2512139678001404
Epoch:  396  	Training Loss: 0.2555384635925293
Test Loss:  0.2527080774307251
Valid Loss:  0.25097718834877014
Epoch:  397  	Training Loss: 0.25529831647872925
Test Loss:  0.25246989727020264
Valid Loss:  0.250740647315979
Epoch:  398  	Training Loss: 0.2550583779811859
Test Loss:  0.2522318959236145
Valid Loss:  0.25050434470176697
Epoch:  399  	Training Loss: 0.25481870770454407
Test Loss:  0.25199413299560547
Valid Loss:  0.25026825070381165
Epoch:  400  	Training Loss: 0.25457924604415894
Test Loss:  0.25175657868385315
Valid Loss:  0.2500323951244354
Epoch:  401  	Training Loss: 0.2543400228023529
Test Loss:  0.25151926279067993
Valid Loss:  0.24979674816131592
Epoch:  402  	Training Loss: 0.2541010081768036
Test Loss:  0.2512815594673157
Valid Loss:  0.24956069886684418
Epoch:  403  	Training Loss: 0.25386157631874084
Test Loss:  0.25104403495788574
Valid Loss:  0.24932484328746796
Epoch:  404  	Training Loss: 0.2536223828792572
Test Loss:  0.2508067488670349
Valid Loss:  0.24908922612667084
Epoch:  405  	Training Loss: 0.2533833980560303
Test Loss:  0.2505697011947632
Valid Loss:  0.248853862285614
Epoch:  406  	Training Loss: 0.25314468145370483
Test Loss:  0.25033286213874817
Valid Loss:  0.2486186921596527
Epoch:  407  	Training Loss: 0.2529061436653137
Test Loss:  0.25009626150131226
Valid Loss:  0.2483837604522705
Epoch:  408  	Training Loss: 0.2526678442955017
Test Loss:  0.24985986948013306
Valid Loss:  0.2481490671634674
Epoch:  409  	Training Loss: 0.2524297833442688
Test Loss:  0.24962373077869415
Valid Loss:  0.24791456758975983
Epoch:  410  	Training Loss: 0.252191960811615
Test Loss:  0.24938780069351196
Valid Loss:  0.24768030643463135
Epoch:  411  	Training Loss: 0.2519543766975403
Test Loss:  0.24915209412574768
Valid Loss:  0.24744629859924316
Epoch:  412  	Training Loss: 0.2517169713973999
Test Loss:  0.24891595542430878
Valid Loss:  0.24721179902553558
Epoch:  413  	Training Loss: 0.2514791488647461
Test Loss:  0.2486800253391266
Valid Loss:  0.2469775378704071
Epoch:  414  	Training Loss: 0.2512415647506714
Test Loss:  0.2484443038702011
Valid Loss:  0.24674350023269653
Epoch:  415  	Training Loss: 0.251004159450531
Test Loss:  0.24820882081985474
Valid Loss:  0.24650968611240387
Epoch:  416  	Training Loss: 0.2507669925689697
Test Loss:  0.24797356128692627
Valid Loss:  0.2462761104106903
Epoch:  417  	Training Loss: 0.25053009390830994
Test Loss:  0.2477385401725769
Valid Loss:  0.24604275822639465
Epoch:  418  	Training Loss: 0.25029340386390686
Test Loss:  0.24750374257564545
Valid Loss:  0.2458096593618393
Epoch:  419  	Training Loss: 0.2500569224357605
Test Loss:  0.2472691684961319
Valid Loss:  0.24557673931121826
Epoch:  420  	Training Loss: 0.24982067942619324
Test Loss:  0.24703484773635864
Valid Loss:  0.24534405767917633
Epoch:  421  	Training Loss: 0.24958467483520508
Test Loss:  0.2468007206916809
Valid Loss:  0.2451116144657135
Epoch:  422  	Training Loss: 0.24934890866279602
Test Loss:  0.24656639993190765
Valid Loss:  0.24487894773483276
Epoch:  423  	Training Loss: 0.24911290407180786
Test Loss:  0.2463323026895523
Valid Loss:  0.24464651942253113
Epoch:  424  	Training Loss: 0.24887715280056
Test Loss:  0.24609841406345367
Valid Loss:  0.2444143146276474
Epoch:  425  	Training Loss: 0.24864161014556885
Test Loss:  0.24586477875709534
Valid Loss:  0.24418233335018158
Epoch:  426  	Training Loss: 0.248406320810318
Test Loss:  0.24563133716583252
Valid Loss:  0.24395056068897247
Epoch:  427  	Training Loss: 0.24817124009132385
Test Loss:  0.2453981637954712
Valid Loss:  0.24371904134750366
Epoch:  428  	Training Loss: 0.24793636798858643
Test Loss:  0.24516519904136658
Valid Loss:  0.24348774552345276
Epoch:  429  	Training Loss: 0.2477017641067505
Test Loss:  0.24493245780467987
Valid Loss:  0.24325667321681976
Epoch:  430  	Training Loss: 0.24746736884117126
Test Loss:  0.24469992518424988
Valid Loss:  0.24302580952644348
Epoch:  431  	Training Loss: 0.24723321199417114
Test Loss:  0.24446764588356018
Valid Loss:  0.2427951544523239
Epoch:  432  	Training Loss: 0.24699926376342773
Test Loss:  0.2442348599433899
Valid Loss:  0.24256405234336853
Epoch:  433  	Training Loss: 0.24676483869552612
Test Loss:  0.2440023273229599
Valid Loss:  0.24233318865299225
Epoch:  434  	Training Loss: 0.2465306520462036
Test Loss:  0.24377000331878662
Valid Loss:  0.24210253357887268
Epoch:  435  	Training Loss: 0.246296688914299
Test Loss:  0.24353791773319244
Valid Loss:  0.24187210202217102
Epoch:  436  	Training Loss: 0.2460629642009735
Test Loss:  0.24330604076385498
Valid Loss:  0.24164187908172607
Epoch:  437  	Training Loss: 0.24582943320274353
Test Loss:  0.2430744171142578
Valid Loss:  0.24141190946102142
Epoch:  438  	Training Loss: 0.24559614062309265
Test Loss:  0.24284297227859497
Valid Loss:  0.2411821335554123
Epoch:  439  	Training Loss: 0.24536308646202087
Test Loss:  0.24261178076267242
Valid Loss:   88%|████████▊ | 439/500 [05:00<00:20,  3.02it/s] 88%|████████▊ | 441/500 [05:06<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:06<00:48,  1.19it/s] 89%|████████▉ | 445/500 [05:06<00:33,  1.64it/s] 89%|████████▉ | 447/500 [05:06<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:07<00:17,  2.98it/s] 90%|█████████ | 451/500 [05:13<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:13<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:13<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:13<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:13<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:20<00:45,  1.16s/it] 93%|█████████▎| 463/500 [05:20<00:30,  1.20it/s] 93%|█████████▎| 465/500 [05:20<00:21,  1.65it/s] 93%|█████████▎| 467/500 [05:20<00:14,  2.25it/s] 94%|█████████▍| 469/500 [05:20<00:10,  3.03it/s] 94%|█████████▍| 471/500 [05:26<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:26<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:27<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:27<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:27<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:33<00:22,  1.18s/it] 97%|█████████▋| 483/500 [05:33<00:14,  1.18it/s] 97%|█████████▋| 485/500 [05:33<00:09,  1.63it/s] 97%|█████████▋| 487/500 [05:34<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:34<00:03,  3.00it/s] 98%|█████████▊| 491/500 [05:40<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:40<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:40<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:40<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:41<00:00,  2.98it/s]100%|██████████| 500/500 [05:41<00:00,  1.47it/s]
0.24095261096954346
Epoch:  440  	Training Loss: 0.2451302707195282
Test Loss:  0.2423807978630066
Valid Loss:  0.24072329699993134
Epoch:  441  	Training Loss: 0.24489763379096985
Test Loss:  0.24215006828308105
Valid Loss:  0.24049420654773712
Epoch:  442  	Training Loss: 0.244665265083313
Test Loss:  0.2419188767671585
Valid Loss:  0.2402646839618683
Epoch:  443  	Training Loss: 0.2444324493408203
Test Loss:  0.24168792366981506
Valid Loss:  0.24003539979457855
Epoch:  444  	Training Loss: 0.24419985711574554
Test Loss:  0.24145722389221191
Valid Loss:  0.23980632424354553
Epoch:  445  	Training Loss: 0.24396750330924988
Test Loss:  0.2412267029285431
Valid Loss:  0.2395774871110916
Epoch:  446  	Training Loss: 0.24373534321784973
Test Loss:  0.24099642038345337
Valid Loss:  0.2393488585948944
Epoch:  447  	Training Loss: 0.24350345134735107
Test Loss:  0.24076637625694275
Valid Loss:  0.2391204684972763
Epoch:  448  	Training Loss: 0.24327178299427032
Test Loss:  0.24053654074668884
Valid Loss:  0.2388923019170761
Epoch:  449  	Training Loss: 0.24304033815860748
Test Loss:  0.24030692875385284
Valid Loss:  0.23866435885429382
Epoch:  450  	Training Loss: 0.24280908703804016
Test Loss:  0.24007755517959595
Valid Loss:  0.23843660950660706
Epoch:  451  	Training Loss: 0.24257808923721313
Test Loss:  0.23984839022159576
Valid Loss:  0.2382090985774994
Epoch:  452  	Training Loss: 0.24234730005264282
Test Loss:  0.2396189421415329
Valid Loss:  0.23798131942749023
Epoch:  453  	Training Loss: 0.24211621284484863
Test Loss:  0.23938970267772675
Valid Loss:  0.2377537488937378
Epoch:  454  	Training Loss: 0.24188536405563354
Test Loss:  0.2391607016324997
Valid Loss:  0.23752640187740326
Epoch:  455  	Training Loss: 0.24165472388267517
Test Loss:  0.23893192410469055
Valid Loss:  0.23729926347732544
Epoch:  456  	Training Loss: 0.2414243221282959
Test Loss:  0.23870335519313812
Valid Loss:  0.23707234859466553
Epoch:  457  	Training Loss: 0.24119415879249573
Test Loss:  0.238475039601326
Valid Loss:  0.23684567213058472
Epoch:  458  	Training Loss: 0.24096421897411346
Test Loss:  0.23824691772460938
Valid Loss:  0.23661920428276062
Epoch:  459  	Training Loss: 0.24073448777198792
Test Loss:  0.23801904916763306
Valid Loss:  0.23639297485351562
Epoch:  460  	Training Loss: 0.24050498008728027
Test Loss:  0.23779138922691345
Valid Loss:  0.23616696894168854
Epoch:  461  	Training Loss: 0.24027571082115173
Test Loss:  0.23756395280361176
Valid Loss:  0.23594118654727936
Epoch:  462  	Training Loss: 0.2400466650724411
Test Loss:  0.23733584582805634
Valid Loss:  0.23571473360061646
Epoch:  463  	Training Loss: 0.23981694877147675
Test Loss:  0.23710797727108002
Valid Loss:  0.23548851907253265
Epoch:  464  	Training Loss: 0.2395874559879303
Test Loss:  0.2368803322315216
Valid Loss:  0.23526254296302795
Epoch:  465  	Training Loss: 0.23935820162296295
Test Loss:  0.2366528958082199
Valid Loss:  0.23503674566745758
Epoch:  466  	Training Loss: 0.2391291707754135
Test Loss:  0.23642569780349731
Valid Loss:  0.2348112016916275
Epoch:  467  	Training Loss: 0.23890036344528198
Test Loss:  0.23619872331619263
Valid Loss:  0.23458588123321533
Epoch:  468  	Training Loss: 0.23867179453372955
Test Loss:  0.23597195744514465
Valid Loss:  0.23436075448989868
Epoch:  469  	Training Loss: 0.23844343423843384
Test Loss:  0.23574542999267578
Valid Loss:  0.23413588106632233
Epoch:  470  	Training Loss: 0.23821528255939484
Test Loss:  0.235519140958786
Valid Loss:  0.23391121625900269
Epoch:  471  	Training Loss: 0.23798738420009613
Test Loss:  0.23529306054115295
Valid Loss:  0.23368677496910095
Epoch:  472  	Training Loss: 0.23775967955589294
Test Loss:  0.23506653308868408
Valid Loss:  0.2334619164466858
Epoch:  473  	Training Loss: 0.2375316023826599
Test Loss:  0.2348402738571167
Valid Loss:  0.23323729634284973
Epoch:  474  	Training Loss: 0.2373037189245224
Test Loss:  0.23461423814296722
Valid Loss:  0.23301288485527039
Epoch:  475  	Training Loss: 0.237076073884964
Test Loss:  0.23438841104507446
Valid Loss:  0.23278871178627014
Epoch:  476  	Training Loss: 0.2368486523628235
Test Loss:  0.2341628074645996
Valid Loss:  0.2325647473335266
Epoch:  477  	Training Loss: 0.2366214394569397
Test Loss:  0.23393741250038147
Valid Loss:  0.23234102129936218
Epoch:  478  	Training Loss: 0.23639445006847382
Test Loss:  0.23371225595474243
Valid Loss:  0.23211747407913208
Epoch:  479  	Training Loss: 0.23616769909858704
Test Loss:  0.2334873080253601
Valid Loss:  0.23189419507980347
Epoch:  480  	Training Loss: 0.23594115674495697
Test Loss:  0.23326259851455688
Valid Loss:  0.23167109489440918
Epoch:  481  	Training Loss: 0.235714852809906
Test Loss:  0.23303809762001038
Valid Loss:  0.231448233127594
Epoch:  482  	Training Loss: 0.23548875749111176
Test Loss:  0.2328132539987564
Valid Loss:  0.23122505843639374
Epoch:  483  	Training Loss: 0.23526233434677124
Test Loss:  0.23258864879608154
Valid Loss:  0.2310020625591278
Epoch:  484  	Training Loss: 0.23503613471984863
Test Loss:  0.2323642373085022
Valid Loss:  0.23077932000160217
Epoch:  485  	Training Loss: 0.23481014370918274
Test Loss:  0.23214007914066315
Valid Loss:  0.23055678606033325
Epoch:  486  	Training Loss: 0.23458437621593475
Test Loss:  0.2319161295890808
Valid Loss:  0.23033449053764343
Epoch:  487  	Training Loss: 0.23435884714126587
Test Loss:  0.23169240355491638
Valid Loss:  0.23011237382888794
Epoch:  488  	Training Loss: 0.2341335415840149
Test Loss:  0.23146888613700867
Valid Loss:  0.22989049553871155
Epoch:  489  	Training Loss: 0.23390842974185944
Test Loss:  0.23124560713768005
Valid Loss:  0.22966885566711426
Epoch:  490  	Training Loss: 0.23368358612060547
Test Loss:  0.23102253675460815
Valid Loss:  0.22944742441177368
Epoch:  491  	Training Loss: 0.23345892131328583
Test Loss:  0.23079970479011536
Valid Loss:  0.22922620177268982
Epoch:  492  	Training Loss: 0.2332344949245453
Test Loss:  0.23057645559310913
Valid Loss:  0.22900459170341492
Epoch:  493  	Training Loss: 0.23300966620445251
Test Loss:  0.2303534299135208
Valid Loss:  0.22878320515155792
Epoch:  494  	Training Loss: 0.23278506100177765
Test Loss:  0.23013059794902802
Valid Loss:  0.22856204211711884
Epoch:  495  	Training Loss: 0.2325606793165207
Test Loss:  0.2299080342054367
Valid Loss:  0.22834108769893646
Epoch:  496  	Training Loss: 0.23233652114868164
Test Loss:  0.22968566417694092
Valid Loss:  0.2281203418970108
Epoch:  497  	Training Loss: 0.2321125864982605
Test Loss:  0.22946351766586304
Valid Loss:  0.22789983451366425
Epoch:  498  	Training Loss: 0.23188886046409607
Test Loss:  0.22924159467220306
Valid Loss:  0.2276795506477356
Epoch:  499  	Training Loss: 0.23166537284851074
Test Loss:  0.229019895195961
Valid Loss:  0.22745946049690247
Epoch:  500  	Training Loss: 0.23144209384918213
Test Loss:  0.22879841923713684
Valid Loss:  0.22723960876464844
seed is  16
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:40,  6.33s/it]  1%|          | 3/500 [00:06<14:02,  1.69s/it]  1%|          | 5/500 [00:06<07:07,  1.16it/s]  1%|▏         | 7/500 [00:06<04:19,  1.90it/s]  2%|▏         | 9/500 [00:06<02:52,  2.84it/s]  2%|▏         | 11/500 [00:13<10:49,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:42,  2.18it/s]  4%|▍         | 19/500 [00:13<02:42,  2.96it/s]  4%|▍         | 21/500 [00:19<09:32,  1.20s/it]  5%|▍         | 23/500 [00:20<06:46,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:12,  1.18s/it]  7%|▋         | 33/500 [00:26<06:34,  1.18it/s]  7%|▋         | 35/500 [00:27<04:44,  1.63it/s]  7%|▋         | 37/500 [00:27<03:27,  2.23it/s]  8%|▊         | 39/500 [00:27<02:33,  3.00it/s]  8%|▊         | 41/500 [00:33<08:53,  1.16s/it]  9%|▊         | 43/500 [00:33<06:21,  1.20it/s]  9%|▉         | 45/500 [00:33<04:34,  1.66it/s]  9%|▉         | 47/500 [00:33<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:30,  3.00it/s] 10%|█         | 51/500 [00:40<08:44,  1.17s/it] 11%|█         | 53/500 [00:40<06:15,  1.19it/s] 11%|█         | 55/500 [00:40<04:31,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.24it/s] 12%|█▏        | 59/500 [00:40<02:29,  2.96it/s] 12%|█▏        | 61/500 [00:47<08:42,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:13,  1.17it/s] 13%|█▎        | 65/500 [00:53<11:10,  1.54s/it] 13%|█▎        | 67/500 [00:53<07:56,  1.10s/it] 14%|█▍        | 69/500 [00:54<05:40,  1.27it/s]Epoch:  1  	Training Loss: 0.5628746747970581
Test Loss:  9.833333969116211
Valid Loss:  9.813705444335938
Epoch:  2  	Training Loss: 9.882356643676758
Test Loss:  66.08252716064453
Valid Loss:  63.255043029785156
Epoch:  3  	Training Loss: 63.33098602294922
Test Loss:  4.249645233154297
Valid Loss:  4.3726582527160645
Epoch:  4  	Training Loss: 4.339073181152344
Test Loss:  4.2087721824646
Valid Loss:  4.342665195465088
Epoch:  5  	Training Loss: 4.303880214691162
Test Loss:  4.179369926452637
Valid Loss:  4.319643974304199
Epoch:  6  	Training Loss: 4.279790878295898
Test Loss:  4.153782367706299
Valid Loss:  4.299492359161377
Epoch:  7  	Training Loss: 4.259294033050537
Test Loss:  4.1327691078186035
Valid Loss:  4.281465530395508
Epoch:  8  	Training Loss: 4.241888999938965
Test Loss:  4.116246223449707
Valid Loss:  4.265014171600342
Epoch:  9  	Training Loss: 4.226782321929932
Test Loss:  4.103103160858154
Valid Loss:  4.251212120056152
Epoch:  10  	Training Loss: 4.2145280838012695
Test Loss:  4.09210205078125
Valid Loss:  4.2379984855651855
Epoch:  11  	Training Loss: 4.202901840209961
Test Loss:  4.082394599914551
Valid Loss:  4.225198745727539
Epoch:  12  	Training Loss: 4.191878318786621
Test Loss:  0.051869966089725494
Valid Loss:  0.052238672971725464
Epoch:  13  	Training Loss: 0.05361850559711456
Test Loss:  0.035896122455596924
Valid Loss:  0.03501428663730621
Epoch:  14  	Training Loss: 0.03713821619749069
Test Loss:  0.027918264269828796
Valid Loss:  0.02699356898665428
Epoch:  15  	Training Loss: 0.028939608484506607
Test Loss:  0.02353488653898239
Valid Loss:  0.02357400208711624
Epoch:  16  	Training Loss: 0.024799752980470657
Test Loss:  0.02131737768650055
Valid Loss:  0.021144527941942215
Epoch:  17  	Training Loss: 0.022339507937431335
Test Loss:  0.019377227872610092
Valid Loss:  0.019531581550836563
Epoch:  18  	Training Loss: 0.02049507200717926
Test Loss:  0.017980635166168213
Valid Loss:  0.017909273505210876
Epoch:  19  	Training Loss: 0.0189166571944952
Test Loss:  0.016452990472316742
Valid Loss:  0.016738377511501312
Epoch:  20  	Training Loss: 0.017581172287464142
Test Loss:  0.015231129713356495
Valid Loss:  0.015499578788876534
Epoch:  21  	Training Loss: 0.01639837957918644
Test Loss:  0.014048042707145214
Valid Loss:  0.014473870396614075
Epoch:  22  	Training Loss: 0.015303943306207657
Test Loss:  0.01108558289706707
Valid Loss:  0.013625097461044788
Epoch:  23  	Training Loss: 0.013686250895261765
Test Loss:  0.011246120557188988
Valid Loss:  0.011958645656704903
Epoch:  24  	Training Loss: 0.012693246826529503
Test Loss:  0.009805809706449509
Valid Loss:  0.011851426213979721
Epoch:  25  	Training Loss: 0.01214250735938549
Test Loss:  0.010165786370635033
Valid Loss:  0.011303569190204144
Epoch:  26  	Training Loss: 0.011883103288710117
Test Loss:  0.009576245211064816
Valid Loss:  0.011431543156504631
Epoch:  27  	Training Loss: 0.011749980971217155
Test Loss:  0.009790567681193352
Valid Loss:  0.011188872158527374
Epoch:  28  	Training Loss: 0.011650502681732178
Test Loss:  0.009473875164985657
Valid Loss:  0.011261540465056896
Epoch:  29  	Training Loss: 0.011566962115466595
Test Loss:  0.009578687138855457
Valid Loss:  0.011095350608229637
Epoch:  30  	Training Loss: 0.011461440473794937
Test Loss:  0.00937214121222496
Valid Loss:  0.011086659505963326
Epoch:  31  	Training Loss: 0.011355210095643997
Test Loss:  0.009416833519935608
Valid Loss:  0.01093723438680172
Epoch:  32  	Training Loss: 0.011255612596869469
Test Loss:  0.009050702676177025
Valid Loss:  0.009090235456824303
Epoch:  33  	Training Loss: 0.010246476158499718
Test Loss:  0.008316205814480782
Valid Loss:  0.008973187766969204
Epoch:  34  	Training Loss: 0.009816327132284641
Test Loss:  0.008068371564149857
Valid Loss:  0.008273943327367306
Epoch:  35  	Training Loss: 0.009349403902888298
Test Loss:  0.007401429582387209
Valid Loss:  0.007686257362365723
Epoch:  36  	Training Loss: 0.008682429790496826
Test Loss:  0.0068984380923211575
Valid Loss:  0.006966298446059227
Epoch:  37  	Training Loss: 0.00809531006962061
Test Loss:  0.006327584385871887
Valid Loss:  0.006503256969153881
Epoch:  38  	Training Loss: 0.0075698187574744225
Test Loss:  0.005883337929844856
Valid Loss:  0.006045811343938112
Epoch:  39  	Training Loss: 0.007116462104022503
Test Loss:  0.005486484616994858
Valid Loss:  0.005753412842750549
Epoch:  40  	Training Loss: 0.00675604771822691
Test Loss:  0.005204858258366585
Valid Loss:  0.00552285835146904
Epoch:  41  	Training Loss: 0.006505298428237438
Test Loss:  0.0050074439495801926
Valid Loss:  0.005355985835194588
Epoch:  42  	Training Loss: 0.006330491043627262
Test Loss:  0.004780957475304604
Valid Loss:  0.005215298384428024
Epoch:  43  	Training Loss: 0.006155545823276043
Test Loss:  0.004730917513370514
Valid Loss:  0.005050300620496273
Epoch:  44  	Training Loss: 0.006046556401997805
Test Loss:  0.004606058355420828
Valid Loss:  0.004947180859744549
Epoch:  45  	Training Loss: 0.0059420643374323845
Test Loss:  0.004516473971307278
Valid Loss:  0.004792028572410345
Epoch:  46  	Training Loss: 0.0058396426029503345
Test Loss:  0.004391634836792946
Valid Loss:  0.004680500365793705
Epoch:  47  	Training Loss: 0.0057252272963523865
Test Loss:  0.004281877540051937
Valid Loss:  0.0045091090723872185
Epoch:  48  	Training Loss: 0.005563667044043541
Test Loss:  0.00410337932407856
Valid Loss:  0.004289405886083841
Epoch:  49  	Training Loss: 0.005342503543943167
Test Loss:  0.003919898997992277
Valid Loss:  0.0040183300152421
Epoch:  50  	Training Loss: 0.005125340074300766
Test Loss:  0.003749909345060587
Valid Loss:  0.0037971558049321175
Epoch:  51  	Training Loss: 0.004935882519930601
Test Loss:  0.003568971296772361
Valid Loss:  0.0036114640533924103
Epoch:  52  	Training Loss: 0.004763488657772541
Test Loss:  0.0034724611323326826
Valid Loss:  0.003454651916399598
Epoch:  53  	Training Loss: 0.0045461105182766914
Test Loss:  0.0033576013520359993
Valid Loss:  0.003364213276654482
Epoch:  54  	Training Loss: 0.004419838078320026
Test Loss:  0.003100755624473095
Valid Loss:  0.0030892977956682444
Epoch:  55  	Training Loss: 0.004163007251918316
Test Loss:  0.0032351554837077856
Valid Loss:  0.0034268712624907494
Epoch:  56  	Training Loss: 0.004395513795316219
Test Loss:  0.0031523811630904675
Valid Loss:  0.003052111715078354
Epoch:  57  	Training Loss: 0.004129267297685146
Test Loss:  0.0032156012021005154
Valid Loss:  0.0034820628352463245
Epoch:  58  	Training Loss: 0.00441695423796773
Test Loss:  0.0033508315682411194
Valid Loss:  0.003239214885979891
Epoch:  59  	Training Loss: 0.004290041513741016
Test Loss:  0.0029958239756524563
Valid Loss:  0.003146054223179817
Epoch:  60  	Training Loss: 0.004141782410442829
Test Loss:  0.0032468303106725216
Valid Loss:  0.0031762514263391495
Epoch:  61  	Training Loss: 0.004305130336433649
Test Loss:  0.0031981864012777805
Valid Loss:  0.003583527635782957
Epoch:  62  	Training Loss: 0.0044862087815999985
Test Loss:  0.004418455995619297
Valid Loss:  0.0038998459931463003
Epoch:  63  	Training Loss: 0.005156511440873146
Test Loss:  0.005647700279951096
Valid Loss:  0.0069048479199409485
Epoch:  64  	Training Loss: 0.00760243134573102
Test Loss:  0.011483638547360897
Valid Loss:  0.00973262544721365
Epoch:  65  	Training Loss: 0.011555308476090431
Test Loss:  0.01009341236203909
Valid Loss:  0.011222632601857185
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.011600352823734283
Test Loss:  0.0032101888209581375
Valid Loss:  0.003262082114815712
Epoch:  67  	Training Loss: 0.004401314537972212
Test Loss:  0.002787252888083458
Valid Loss:  0.00310708349570632
Epoch:  68  	Training Loss: 0.004108616150915623
Test Loss:  0.0027397102676331997
Valid Loss:  0.0030138057190924883
Epoch:  69  	Training Loss: 0.00402121851220727
Test Loss:  0.0026695840060710907
Valid Loss:  0.002959085628390312
Epoch:  70  	Training Loss: 0.003943980671465397
Test Loss:  0.0026040838565677404
Valid Loss:  0.0028992420993745327
Epoch:  71  	Training Loss: 0.0038698636926710606
 14%|█▍        | 71/500 [01:00<10:46,  1.51s/it] 15%|█▍        | 73/500 [01:00<07:39,  1.08s/it] 15%|█▌        | 75/500 [01:00<05:28,  1.29it/s] 15%|█▌        | 77/500 [01:00<03:57,  1.78it/s] 16%|█▌        | 79/500 [01:00<02:53,  2.43it/s] 16%|█▌        | 81/500 [01:07<08:33,  1.23s/it] 17%|█▋        | 83/500 [01:07<06:07,  1.13it/s] 17%|█▋        | 85/500 [01:07<04:26,  1.56it/s] 17%|█▋        | 87/500 [01:07<03:13,  2.14it/s] 18%|█▊        | 89/500 [01:07<02:22,  2.88it/s] 18%|█▊        | 91/500 [01:14<08:09,  1.20s/it] 19%|█▊        | 93/500 [01:14<05:50,  1.16it/s] 19%|█▉        | 95/500 [01:14<04:13,  1.60it/s] 19%|█▉        | 97/500 [01:14<03:04,  2.18it/s] 20%|█▉        | 99/500 [01:14<02:16,  2.93it/s] 20%|██        | 101/500 [01:20<07:53,  1.19s/it] 21%|██        | 103/500 [01:21<05:38,  1.17it/s] 21%|██        | 105/500 [01:21<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:21<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:27<07:42,  1.19s/it] 23%|██▎       | 113/500 [01:28<05:31,  1.17it/s] 23%|██▎       | 115/500 [01:28<03:58,  1.62it/s] 23%|██▎       | 117/500 [01:28<02:53,  2.21it/s] 24%|██▍       | 119/500 [01:28<02:08,  2.96it/s] 24%|██▍       | 121/500 [01:34<07:32,  1.19s/it] 25%|██▍       | 123/500 [01:35<05:25,  1.16it/s] 25%|██▌       | 125/500 [01:35<03:55,  1.59it/s] 25%|██▌       | 127/500 [01:35<02:51,  2.17it/s] 26%|██▌       | 129/500 [01:35<02:06,  2.93it/s] 26%|██▌       | 131/500 [01:42<07:33,  1.23s/it] 27%|██▋       | 133/500 [01:42<05:23,  1.13it/s] 27%|██▋       | 135/500 [01:42<03:52,  1.57it/s] 27%|██▋       | 137/500 [01:42<02:48,  2.15it/s] 28%|██▊       | 139/500 [01:42<02:04,  2.90it/s]Test Loss:  0.0025441849138587713
Valid Loss:  0.0028453459963202477
Epoch:  72  	Training Loss: 0.003802361898124218
Test Loss:  0.0025528473779559135
Valid Loss:  0.002775519620627165
Epoch:  73  	Training Loss: 0.0037450804375112057
Test Loss:  0.002548868302255869
Valid Loss:  0.0027454583905637264
Epoch:  74  	Training Loss: 0.003716536331921816
Test Loss:  0.0025383736938238144
Valid Loss:  0.0027263788506388664
Epoch:  75  	Training Loss: 0.003694580402225256
Test Loss:  0.0025260443799197674
Valid Loss:  0.0027109154034405947
Epoch:  76  	Training Loss: 0.003674538107588887
Test Loss:  0.002513982355594635
Valid Loss:  0.0026980414986610413
Epoch:  77  	Training Loss: 0.0036561060696840286
Test Loss:  0.002502845600247383
Valid Loss:  0.002686216961592436
Epoch:  78  	Training Loss: 0.0036387417931109667
Test Loss:  0.00249272957444191
Valid Loss:  0.002674827119335532
Epoch:  79  	Training Loss: 0.0036223530769348145
Test Loss:  0.0024830144830048084
Valid Loss:  0.0026640030555427074
Epoch:  80  	Training Loss: 0.0036067883484065533
Test Loss:  0.00247332826256752
Valid Loss:  0.0026535133365541697
Epoch:  81  	Training Loss: 0.0035918361973017454
Test Loss:  0.002463985700160265
Valid Loss:  0.0026434557512402534
Epoch:  82  	Training Loss: 0.0035775573924183846
Test Loss:  0.0024196673184633255
Valid Loss:  0.0026115896180272102
Epoch:  83  	Training Loss: 0.003535320283845067
Test Loss:  0.002382221631705761
Valid Loss:  0.0025811148807406425
Epoch:  84  	Training Loss: 0.003495960496366024
Test Loss:  0.002345877233892679
Valid Loss:  0.0025522401556372643
Epoch:  85  	Training Loss: 0.003458687337115407
Test Loss:  0.002309690695255995
Valid Loss:  0.0025240806862711906
Epoch:  86  	Training Loss: 0.0034224099945276976
Test Loss:  0.00227683549746871
Valid Loss:  0.0024984534829854965
Epoch:  87  	Training Loss: 0.0033875051885843277
Test Loss:  0.002247435040771961
Valid Loss:  0.0024756500497460365
Epoch:  88  	Training Loss: 0.003356163389980793
Test Loss:  0.0022198690567165613
Valid Loss:  0.002454957226291299
Epoch:  89  	Training Loss: 0.003326648147776723
Test Loss:  0.0021916620898991823
Valid Loss:  0.00243460014462471
Epoch:  90  	Training Loss: 0.0032969913445413113
Test Loss:  0.002165215089917183
Valid Loss:  0.0024148873053491116
Epoch:  91  	Training Loss: 0.003268914995715022
Test Loss:  0.0021400635596364737
Valid Loss:  0.002395796589553356
Epoch:  92  	Training Loss: 0.003241709666326642
Test Loss:  0.002133201342076063
Valid Loss:  0.002389179076999426
Epoch:  93  	Training Loss: 0.0032335056457668543
Test Loss:  0.002126456471160054
Valid Loss:  0.0023836581967771053
Epoch:  94  	Training Loss: 0.0032259421423077583
Test Loss:  0.002120037330314517
Valid Loss:  0.002378463977947831
Epoch:  95  	Training Loss: 0.0032185567542910576
Test Loss:  0.0021139495074748993
Valid Loss:  0.0023734827991575003
Epoch:  96  	Training Loss: 0.0032113445922732353
Test Loss:  0.00210815598256886
Valid Loss:  0.0023687747307121754
Epoch:  97  	Training Loss: 0.0032044530380517244
Test Loss:  0.0021027359180152416
Valid Loss:  0.0023646103218197823
Epoch:  98  	Training Loss: 0.0031978092156350613
Test Loss:  0.002097702119499445
Valid Loss:  0.002360550919547677
Epoch:  99  	Training Loss: 0.0031912410631775856
Test Loss:  0.0020929945167154074
Valid Loss:  0.0023565792944282293
Epoch:  100  	Training Loss: 0.003184718079864979
Test Loss:  0.0020885157864540815
Valid Loss:  0.002352755516767502
Epoch:  101  	Training Loss: 0.0031783543527126312
Test Loss:  0.0020842496305704117
Valid Loss:  0.002348832320421934
Epoch:  102  	Training Loss: 0.0031720148399472237
Test Loss:  0.0020606238394975662
Valid Loss:  0.0023297586012631655
Epoch:  103  	Training Loss: 0.0031446386128664017
Test Loss:  0.002038870006799698
Valid Loss:  0.002312429714947939
Epoch:  104  	Training Loss: 0.003120051696896553
Test Loss:  0.0020182740408927202
Valid Loss:  0.0022965148091316223
Epoch:  105  	Training Loss: 0.0030973826069384813
Test Loss:  0.0019986331462860107
Valid Loss:  0.0022816085256636143
Epoch:  106  	Training Loss: 0.0030761342495679855
Test Loss:  0.001979713561013341
Valid Loss:  0.0022675171494483948
Epoch:  107  	Training Loss: 0.003056071698665619
Test Loss:  0.0019616475328803062
Valid Loss:  0.002254161983728409
Epoch:  108  	Training Loss: 0.003037157002836466
Test Loss:  0.0019444702193140984
Valid Loss:  0.0022415095008909702
Epoch:  109  	Training Loss: 0.0030190604738891125
Test Loss:  0.001926574856042862
Valid Loss:  0.0022289969492703676
Epoch:  110  	Training Loss: 0.002999763935804367
Test Loss:  0.0019097959157079458
Valid Loss:  0.0022173842880874872
Epoch:  111  	Training Loss: 0.0029817884787917137
Test Loss:  0.0018941130256280303
Valid Loss:  0.0022065918892621994
Epoch:  112  	Training Loss: 0.0029648144263774157
Test Loss:  0.0018346698489040136
Valid Loss:  0.0021893586963415146
Epoch:  113  	Training Loss: 0.002920405473560095
Test Loss:  0.0018226061947643757
Valid Loss:  0.002171269850805402
Epoch:  114  	Training Loss: 0.0029037599451839924
Test Loss:  0.0018138457089662552
Valid Loss:  0.002166124526411295
Epoch:  115  	Training Loss: 0.002892048330977559
Test Loss:  0.0018079697620123625
Valid Loss:  0.002158836927264929
Epoch:  116  	Training Loss: 0.0028817174024879932
Test Loss:  0.0018024493474513292
Valid Loss:  0.002153170295059681
Epoch:  117  	Training Loss: 0.002872108481824398
Test Loss:  0.001797917764633894
Valid Loss:  0.0021471071522682905
Epoch:  118  	Training Loss: 0.0028631584718823433
Test Loss:  0.0017934992210939527
Valid Loss:  0.0021410337649285793
Epoch:  119  	Training Loss: 0.002854336518794298
Test Loss:  0.0017891817260533571
Valid Loss:  0.0021350146271288395
Epoch:  120  	Training Loss: 0.0028456361033022404
Test Loss:  0.001784906955435872
Valid Loss:  0.0021290509030222893
Epoch:  121  	Training Loss: 0.0028370567597448826
Test Loss:  0.0017806575633585453
Valid Loss:  0.0021232333965599537
Epoch:  122  	Training Loss: 0.0028285994194447994
Test Loss:  0.0018072155071422458
Valid Loss:  0.002085598185658455
Epoch:  123  	Training Loss: 0.0027952021919190884
Test Loss:  0.001782949548214674
Valid Loss:  0.002076266799122095
Epoch:  124  	Training Loss: 0.002774080727249384
Test Loss:  0.0017726323567330837
Valid Loss:  0.002064979635179043
Epoch:  125  	Training Loss: 0.0027550850063562393
Test Loss:  0.0017597684636712074
Valid Loss:  0.0020550722256302834
Epoch:  126  	Training Loss: 0.002736019901931286
Test Loss:  0.0017471355386078358
Valid Loss:  0.0020448402501642704
Epoch:  127  	Training Loss: 0.002716687973588705
Test Loss:  0.0017348676919937134
Valid Loss:  0.0020350608974695206
Epoch:  128  	Training Loss: 0.0026982221752405167
Test Loss:  0.0017230140510946512
Valid Loss:  0.0020253672264516354
Epoch:  129  	Training Loss: 0.0026805666275322437
Test Loss:  0.0017112114001065493
Valid Loss:  0.0020164609886705875
Epoch:  130  	Training Loss: 0.0026638307608664036
Test Loss:  0.0017004397232085466
Valid Loss:  0.0020081782713532448
Epoch:  131  	Training Loss: 0.002647880930453539
Test Loss:  0.0016895865555852652
Valid Loss:  0.0019999081268906593
Epoch:  132  	Training Loss: 0.0026324638165533543
Test Loss:  0.0016770790098235011
Valid Loss:  0.0019978962372988462
Epoch:  133  	Training Loss: 0.0026216721162199974
Test Loss:  0.0016721445135772228
Valid Loss:  0.001993380021303892
Epoch:  134  	Training Loss: 0.0026142047718167305
Test Loss:  0.0016685370355844498
Valid Loss:  0.0019883576314896345
Epoch:  135  	Training Loss: 0.002607339061796665
Test Loss:  0.0016652493504807353
Valid Loss:  0.0019830791279673576
Epoch:  136  	Training Loss: 0.0026006288826465607
Test Loss:  0.0016624592244625092
Valid Loss:  0.0019782723393291235
Epoch:  137  	Training Loss: 0.0025944262742996216
Test Loss:  0.0016601221868768334
Valid Loss:  0.001973390346392989
Epoch:  138  	Training Loss: 0.00258832098916173
Test Loss:  0.001658732770010829
Valid Loss:  0.001968561904504895
Epoch:  139  	Training Loss: 0.002582315355539322
Test Loss:  0.0016579534858465195
Valid Loss:  0.0019637905061244965
Epoch:  140  	Training Loss: 0.002576397033408284
Test Loss:   28%|██▊       | 141/500 [01:48<07:08,  1.19s/it] 29%|██▊       | 143/500 [01:49<05:06,  1.17it/s] 29%|██▉       | 145/500 [01:49<03:39,  1.61it/s] 29%|██▉       | 147/500 [01:49<02:40,  2.20it/s] 30%|██▉       | 149/500 [01:49<01:58,  2.96it/s] 30%|███       | 151/500 [01:55<06:52,  1.18s/it] 31%|███       | 153/500 [01:55<04:55,  1.18it/s] 31%|███       | 155/500 [01:56<03:32,  1.63it/s] 31%|███▏      | 157/500 [01:56<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:56<01:54,  2.98it/s] 32%|███▏      | 161/500 [02:02<06:40,  1.18s/it] 33%|███▎      | 163/500 [02:02<04:45,  1.18it/s] 33%|███▎      | 165/500 [02:02<03:25,  1.63it/s] 33%|███▎      | 167/500 [02:03<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:03<01:50,  3.00it/s] 34%|███▍      | 171/500 [02:09<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:09<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:09<03:18,  1.63it/s] 35%|███▌      | 177/500 [02:09<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:09<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:16<06:12,  1.17s/it] 37%|███▋      | 183/500 [02:16<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:16<03:11,  1.64it/s] 37%|███▋      | 187/500 [02:16<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:16<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:22<05:59,  1.16s/it] 39%|███▊      | 193/500 [02:23<04:16,  1.20it/s] 39%|███▉      | 195/500 [02:23<03:04,  1.65it/s] 39%|███▉      | 197/500 [02:23<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:23<01:39,  3.01it/s] 40%|████      | 201/500 [02:29<05:56,  1.19s/it] 41%|████      | 203/500 [02:30<04:14,  1.17it/s] 41%|████      | 205/500 [02:30<03:02,  1.61it/s] 41%|████▏     | 207/500 [02:30<02:13,  2.20it/s]0.0016572107560932636
Valid Loss:  0.00195907149463892
Epoch:  141  	Training Loss: 0.0025705599691718817
Test Loss:  0.0016564957331866026
Valid Loss:  0.0019544181413948536
Epoch:  142  	Training Loss: 0.002564910566434264
Test Loss:  0.0016623864648863673
Valid Loss:  0.0019469434628263116
Epoch:  143  	Training Loss: 0.0025497928727418184
Test Loss:  0.0016621846007183194
Valid Loss:  0.0019437478622421622
Epoch:  144  	Training Loss: 0.002537407213822007
Test Loss:  0.0016658755484968424
Valid Loss:  0.0019367323257029057
Epoch:  145  	Training Loss: 0.0025264222640544176
Test Loss:  0.0016614829655736685
Valid Loss:  0.0019341285806149244
Epoch:  146  	Training Loss: 0.002516173291951418
Test Loss:  0.0016637558583170176
Valid Loss:  0.0019262448186054826
Epoch:  147  	Training Loss: 0.0025070244446396828
Test Loss:  0.0016573991160839796
Valid Loss:  0.0019251690246164799
Epoch:  148  	Training Loss: 0.002498800167813897
Test Loss:  0.001661432906985283
Valid Loss:  0.00191646465100348
Epoch:  149  	Training Loss: 0.0024912357330322266
Test Loss:  0.0016526241088286042
Valid Loss:  0.0019165920093655586
Epoch:  150  	Training Loss: 0.0024839944671839476
Test Loss:  0.0016582384705543518
Valid Loss:  0.0019063481595367193
Epoch:  151  	Training Loss: 0.0024772207252681255
Test Loss:  0.001647972734645009
Valid Loss:  0.001908402075059712
Epoch:  152  	Training Loss: 0.0024705957621335983
Test Loss:  0.001596030662767589
Valid Loss:  0.0018584702629595995
Epoch:  153  	Training Loss: 0.002422352321445942
Test Loss:  0.0015521785244345665
Valid Loss:  0.0018329552840441465
Epoch:  154  	Training Loss: 0.002392296213656664
Test Loss:  0.0015173103893175721
Valid Loss:  0.0018129763193428516
Epoch:  155  	Training Loss: 0.0023669274523854256
Test Loss:  0.0014888301957398653
Valid Loss:  0.0017960992408916354
Epoch:  156  	Training Loss: 0.002343728905543685
Test Loss:  0.0014640253502875566
Valid Loss:  0.0017785493982955813
Epoch:  157  	Training Loss: 0.0023214188404381275
Test Loss:  0.001440937165170908
Valid Loss:  0.0017619198188185692
Epoch:  158  	Training Loss: 0.0022995206527411938
Test Loss:  0.0014200885780155659
Valid Loss:  0.0017464745324105024
Epoch:  159  	Training Loss: 0.002278077881783247
Test Loss:  0.0014014455955475569
Valid Loss:  0.0017321635968983173
Epoch:  160  	Training Loss: 0.0022574691101908684
Test Loss:  0.0013840335886925459
Valid Loss:  0.0017177232075482607
Epoch:  161  	Training Loss: 0.0022370615042746067
Test Loss:  0.0013669771142303944
Valid Loss:  0.0017025365959852934
Epoch:  162  	Training Loss: 0.0022168566938489676
Test Loss:  0.0013604757841676474
Valid Loss:  0.001708311028778553
Epoch:  163  	Training Loss: 0.0022023788187652826
Test Loss:  0.0013680023839697242
Valid Loss:  0.0016991891898214817
Epoch:  164  	Training Loss: 0.002192397601902485
Test Loss:  0.0013694439548999071
Valid Loss:  0.0016966419061645865
Epoch:  165  	Training Loss: 0.0021840068511664867
Test Loss:  0.0013714059023186564
Valid Loss:  0.0016915731830522418
Epoch:  166  	Training Loss: 0.0021763716358691454
Test Loss:  0.0013719700509682298
Valid Loss:  0.0016876793233677745
Epoch:  167  	Training Loss: 0.002169473096728325
Test Loss:  0.0013722365256398916
Valid Loss:  0.0016834805719554424
Epoch:  168  	Training Loss: 0.002162851858884096
Test Loss:  0.001371825230307877
Valid Loss:  0.0016793275717645884
Epoch:  169  	Training Loss: 0.002156413160264492
Test Loss:  0.0013711003120988607
Valid Loss:  0.001675000530667603
Epoch:  170  	Training Loss: 0.002150119049474597
Test Loss:  0.001370193320326507
Valid Loss:  0.0016706519527360797
Epoch:  171  	Training Loss: 0.002143941819667816
Test Loss:  0.0013691801577806473
Valid Loss:  0.0016662830021232367
Epoch:  172  	Training Loss: 0.002137872390449047
Test Loss:  0.001360110123641789
Valid Loss:  0.0016649400349706411
Epoch:  173  	Training Loss: 0.002127814805135131
Test Loss:  0.001355582382529974
Valid Loss:  0.001660227426327765
Epoch:  174  	Training Loss: 0.0021186498925089836
Test Loss:  0.0013516058679670095
Valid Loss:  0.0016550789587199688
Epoch:  175  	Training Loss: 0.0021096605341881514
Test Loss:  0.0013476621825248003
Valid Loss:  0.001650057965889573
Epoch:  176  	Training Loss: 0.0021009412594139576
Test Loss:  0.0013438593596220016
Valid Loss:  0.0016459859907627106
Epoch:  177  	Training Loss: 0.0020926608704030514
Test Loss:  0.0013401979813352227
Valid Loss:  0.0016418638406321406
Epoch:  178  	Training Loss: 0.0020845525432378054
Test Loss:  0.0013365729246288538
Valid Loss:  0.0016377185238525271
Epoch:  179  	Training Loss: 0.0020765899680554867
Test Loss:  0.0013331029331311584
Valid Loss:  0.0016339647118002176
Epoch:  180  	Training Loss: 0.0020691347308456898
Test Loss:  0.0013297289842739701
Valid Loss:  0.0016301185823976994
Epoch:  181  	Training Loss: 0.0020619819406419992
Test Loss:  0.001326588448137045
Valid Loss:  0.0016266235616058111
Epoch:  182  	Training Loss: 0.0020551863126456738
Test Loss:  0.0012908193748444319
Valid Loss:  0.0015983430203050375
Epoch:  183  	Training Loss: 0.0020291288383305073
Test Loss:  0.0012598790926858783
Valid Loss:  0.0015797712840139866
Epoch:  184  	Training Loss: 0.002007327741011977
Test Loss:  0.001232673181220889
Valid Loss:  0.0015625311061739922
Epoch:  185  	Training Loss: 0.0019878563471138477
Test Loss:  0.0012076422572135925
Valid Loss:  0.0015482724411413074
Epoch:  186  	Training Loss: 0.0019712240900844336
Test Loss:  0.001186290057376027
Valid Loss:  0.0015370012260973454
Epoch:  187  	Training Loss: 0.001957604195922613
Test Loss:  0.0011681721080094576
Valid Loss:  0.0015272145392373204
Epoch:  188  	Training Loss: 0.0019461140036582947
Test Loss:  0.0011523187858983874
Valid Loss:  0.0015183008508756757
Epoch:  189  	Training Loss: 0.0019359600264579058
Test Loss:  0.0011383212404325604
Valid Loss:  0.00150990579277277
Epoch:  190  	Training Loss: 0.0019270553020760417
Test Loss:  0.0011258828453719616
Valid Loss:  0.0015011318027973175
Epoch:  191  	Training Loss: 0.001919097499921918
Test Loss:  0.0011151694925501943
Valid Loss:  0.0014937566593289375
Epoch:  192  	Training Loss: 0.001912155537866056
Test Loss:  0.001115480437874794
Valid Loss:  0.0014809949789196253
Epoch:  193  	Training Loss: 0.0019000319298356771
Test Loss:  0.0011143686715513468
Valid Loss:  0.001475547906011343
Epoch:  194  	Training Loss: 0.0018896772526204586
Test Loss:  0.0011132705258205533
Valid Loss:  0.0014698929153382778
Epoch:  195  	Training Loss: 0.0018802061676979065
Test Loss:  0.0011118013644590974
Valid Loss:  0.0014645563205704093
Epoch:  196  	Training Loss: 0.0018713388126343489
Test Loss:  0.001109971315599978
Valid Loss:  0.0014596988912671804
Epoch:  197  	Training Loss: 0.0018629870610311627
Test Loss:  0.0011079180985689163
Valid Loss:  0.001454837853088975
Epoch:  198  	Training Loss: 0.0018550765234977007
Test Loss:  0.001105719362385571
Valid Loss:  0.0014502413105219603
Epoch:  199  	Training Loss: 0.0018476586556062102
Test Loss:  0.0011034398339688778
Valid Loss:  0.0014457819052040577
Epoch:  200  	Training Loss: 0.0018406312447041273
Test Loss:  0.001101112924516201
Valid Loss:  0.001441406668163836
Epoch:  201  	Training Loss: 0.001833997666835785
Test Loss:  0.0010987258283421397
Valid Loss:  0.0014365180395543575
Epoch:  202  	Training Loss: 0.001827580388635397
Test Loss:  0.0010946625843644142
Valid Loss:  0.0014356421306729317
Epoch:  203  	Training Loss: 0.0018157189479097724
Test Loss:  0.0011006827699020505
Valid Loss:  0.001430479809641838
Epoch:  204  	Training Loss: 0.0018067294731736183
Test Loss:  0.0011026666034013033
Valid Loss:  0.0014297878369688988
Epoch:  205  	Training Loss: 0.0017997629474848509
Test Loss:  0.0011068760650232434
Valid Loss:  0.0014284573262557387
Epoch:  206  	Training Loss: 0.001794313662685454
Test Loss:  0.0011100016999989748
Valid Loss:  0.001428477931767702
Epoch:  207  	Training Loss: 0.001790001057088375
Test Loss:  0.0011134527157992125
Valid Loss:  0.00142848608084023
Epoch:  208  	Training Loss: 0.0017865457339212298
Test Loss:  0.0011164413299411535
Valid Loss:  0.0014289033133536577
 42%|████▏     | 209/500 [02:30<01:38,  2.94it/s] 42%|████▏     | 211/500 [02:36<05:42,  1.18s/it] 43%|████▎     | 213/500 [02:36<04:04,  1.18it/s] 43%|████▎     | 215/500 [02:37<02:55,  1.63it/s] 43%|████▎     | 217/500 [02:37<02:07,  2.22it/s] 44%|████▍     | 219/500 [02:37<01:34,  2.98it/s] 44%|████▍     | 221/500 [02:43<05:28,  1.18s/it] 45%|████▍     | 223/500 [02:43<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:43<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:44<02:02,  2.23it/s] 46%|████▌     | 229/500 [02:44<01:30,  2.99it/s] 46%|████▌     | 231/500 [02:50<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:50<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:50<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:50<01:57,  2.24it/s] 48%|████▊     | 239/500 [02:50<01:26,  3.01it/s] 48%|████▊     | 241/500 [02:57<05:01,  1.16s/it] 49%|████▊     | 243/500 [02:57<03:35,  1.19it/s] 49%|████▉     | 245/500 [02:57<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:57<01:54,  2.20it/s] 50%|████▉     | 249/500 [02:57<01:25,  2.93it/s] 50%|█████     | 251/500 [03:04<04:53,  1.18s/it] 51%|█████     | 253/500 [03:04<03:29,  1.18it/s] 51%|█████     | 255/500 [03:04<02:30,  1.63it/s] 51%|█████▏    | 257/500 [03:04<01:49,  2.22it/s] 52%|█████▏    | 259/500 [03:04<01:21,  2.95it/s] 52%|█████▏    | 261/500 [03:11<04:44,  1.19s/it] 53%|█████▎    | 263/500 [03:11<03:22,  1.17it/s] 53%|█████▎    | 265/500 [03:11<02:25,  1.62it/s] 53%|█████▎    | 267/500 [03:11<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:11<01:17,  2.96it/s] 54%|█████▍    | 271/500 [03:17<04:31,  1.18s/it] 55%|█████▍    | 273/500 [03:18<03:13,  1.18it/s] 55%|█████▌    | 275/500 [03:18<02:18,  1.62it/s]Epoch:  209  	Training Loss: 0.0017837530467659235
Test Loss:  0.0011193028185516596
Valid Loss:  0.0014293751446530223
Epoch:  210  	Training Loss: 0.0017814929597079754
Test Loss:  0.0011218693107366562
Valid Loss:  0.001430015778169036
Epoch:  211  	Training Loss: 0.0017796445172280073
Test Loss:  0.0011242160107940435
Valid Loss:  0.001430660835467279
Epoch:  212  	Training Loss: 0.0017781245987862349
Test Loss:  0.0011185903567820787
Valid Loss:  0.0014160422142595053
Epoch:  213  	Training Loss: 0.0017681560711935163
Test Loss:  0.0011133389780297875
Valid Loss:  0.001409763004630804
Epoch:  214  	Training Loss: 0.0017622907180339098
Test Loss:  0.0011089063482359052
Valid Loss:  0.0014050175668671727
Epoch:  215  	Training Loss: 0.0017574293306097388
Test Loss:  0.001105268020182848
Valid Loss:  0.0014009291771799326
Epoch:  216  	Training Loss: 0.0017530217301100492
Test Loss:  0.0011021709069609642
Valid Loss:  0.0013969669817015529
Epoch:  217  	Training Loss: 0.0017489111050963402
Test Loss:  0.001099516754038632
Valid Loss:  0.0013935142196714878
Epoch:  218  	Training Loss: 0.0017450950108468533
Test Loss:  0.0010971499141305685
Valid Loss:  0.0013900892809033394
Epoch:  219  	Training Loss: 0.0017413459718227386
Test Loss:  0.0010949750430881977
Valid Loss:  0.0013867567759007215
Epoch:  220  	Training Loss: 0.001737644663080573
Test Loss:  0.0010929238051176071
Valid Loss:  0.0013834740966558456
Epoch:  221  	Training Loss: 0.0017339885234832764
Test Loss:  0.0010909673292189837
Valid Loss:  0.0013802924659103155
Epoch:  222  	Training Loss: 0.001730570336803794
Test Loss:  0.0010875411098822951
Valid Loss:  0.0013685126323252916
Epoch:  223  	Training Loss: 0.0017263238551095128
Test Loss:  0.001084718736819923
Valid Loss:  0.001364783151075244
Epoch:  224  	Training Loss: 0.0017237511929124594
Test Loss:  0.0010819945018738508
Valid Loss:  0.0013621062971651554
Epoch:  225  	Training Loss: 0.0017212973907589912
Test Loss:  0.0010794986737892032
Valid Loss:  0.00136005028616637
Epoch:  226  	Training Loss: 0.0017189981881529093
Test Loss:  0.001077241264283657
Valid Loss:  0.0013578265206888318
Epoch:  227  	Training Loss: 0.0017167567275464535
Test Loss:  0.0010751395020633936
Valid Loss:  0.001355663058348
Epoch:  228  	Training Loss: 0.0017145616002380848
Test Loss:  0.0010731164366006851
Valid Loss:  0.0013538133352994919
Epoch:  229  	Training Loss: 0.0017124181613326073
Test Loss:  0.001071245176717639
Valid Loss:  0.001351805403828621
Epoch:  230  	Training Loss: 0.0017102975398302078
Test Loss:  0.001069470657967031
Valid Loss:  0.001349822268821299
Epoch:  231  	Training Loss: 0.0017081941477954388
Test Loss:  0.0010677885729819536
Valid Loss:  0.0013478758046403527
Epoch:  232  	Training Loss: 0.001706116134300828
Test Loss:  0.001052224077284336
Valid Loss:  0.001328127458691597
Epoch:  233  	Training Loss: 0.0016886399826034904
Test Loss:  0.001037645386531949
Valid Loss:  0.0013162303948774934
Epoch:  234  	Training Loss: 0.0016742086736485362
Test Loss:  0.001024664961732924
Valid Loss:  0.00130295695271343
Epoch:  235  	Training Loss: 0.0016609346494078636
Test Loss:  0.0010128180729225278
Valid Loss:  0.0012903311289846897
Epoch:  236  	Training Loss: 0.0016478218603879213
Test Loss:  0.0010031100828200579
Valid Loss:  0.0012777396477758884
Epoch:  237  	Training Loss: 0.0016361007001250982
Test Loss:  0.0009944585617631674
Valid Loss:  0.001265968894585967
Epoch:  238  	Training Loss: 0.0016251918859779835
Test Loss:  0.000986939063295722
Valid Loss:  0.0012554243439808488
Epoch:  239  	Training Loss: 0.0016151490854099393
Test Loss:  0.0009798549581319094
Valid Loss:  0.0012451126240193844
Epoch:  240  	Training Loss: 0.0016051786951720715
Test Loss:  0.0009731207392178476
Valid Loss:  0.0012352126650512218
Epoch:  241  	Training Loss: 0.0015955899143591523
Test Loss:  0.0009672542801126838
Valid Loss:  0.0012263604439795017
Epoch:  242  	Training Loss: 0.001586774829775095
Test Loss:  0.0009688925929367542
Valid Loss:  0.0012263926910236478
Epoch:  243  	Training Loss: 0.0015863815788179636
Test Loss:  0.0009701764211058617
Valid Loss:  0.0012265141122043133
Epoch:  244  	Training Loss: 0.0015860837884247303
Test Loss:  0.0009711795137263834
Valid Loss:  0.001226678374223411
Epoch:  245  	Training Loss: 0.0015858426922932267
Test Loss:  0.0009719697991386056
Valid Loss:  0.001226857304573059
Epoch:  246  	Training Loss: 0.001585635356605053
Test Loss:  0.000972596462816
Valid Loss:  0.0012270327424630523
Epoch:  247  	Training Loss: 0.0015854521188884974
Test Loss:  0.0009730930905789137
Valid Loss:  0.0012271986342966557
Epoch:  248  	Training Loss: 0.0015852843644097447
Test Loss:  0.0009734906489029527
Valid Loss:  0.0012273472966626287
Epoch:  249  	Training Loss: 0.0015851280186325312
Test Loss:  0.0009738064254634082
Valid Loss:  0.0012274805922061205
Epoch:  250  	Training Loss: 0.001584980171173811
Test Loss:  0.0009740589302964509
Valid Loss:  0.0012275947956368327
Epoch:  251  	Training Loss: 0.0015848397742956877
Test Loss:  0.000974257942289114
Valid Loss:  0.0012276929337531328
Epoch:  252  	Training Loss: 0.001584705663844943
Test Loss:  0.0009692558669485152
Valid Loss:  0.0012248121201992035
Epoch:  253  	Training Loss: 0.00158030167222023
Test Loss:  0.0009660362266004086
Valid Loss:  0.001222377410158515
Epoch:  254  	Training Loss: 0.0015764699783176184
Test Loss:  0.0009636771865189075
Valid Loss:  0.0012199750635772943
Epoch:  255  	Training Loss: 0.0015728895086795092
Test Loss:  0.0009619243210181594
Valid Loss:  0.0012177091557532549
Epoch:  256  	Training Loss: 0.0015696038026362658
Test Loss:  0.0009605607483536005
Valid Loss:  0.0012155090225860476
Epoch:  257  	Training Loss: 0.001566410530358553
Test Loss:  0.0009592930437065661
Valid Loss:  0.0012134165735915303
Epoch:  258  	Training Loss: 0.0015633160946890712
Test Loss:  0.0009580842452123761
Valid Loss:  0.001211443799547851
Epoch:  259  	Training Loss: 0.001560386037454009
Test Loss:  0.0009569619433023036
Valid Loss:  0.0012095158454030752
Epoch:  260  	Training Loss: 0.0015575444558635354
Test Loss:  0.0009558772435411811
Valid Loss:  0.001207641209475696
Epoch:  261  	Training Loss: 0.0015547939110547304
Test Loss:  0.0009548708330839872
Valid Loss:  0.00120592734310776
Epoch:  262  	Training Loss: 0.0015521383611485362
Test Loss:  0.0009408615296706557
Valid Loss:  0.0012098121223971248
Epoch:  263  	Training Loss: 0.0015445617027580738
Test Loss:  0.0009465395123697817
Valid Loss:  0.0011964067816734314
Epoch:  264  	Training Loss: 0.001537864562124014
Test Loss:  0.0009369713952764869
Valid Loss:  0.0011987434700131416
Epoch:  265  	Training Loss: 0.0015318295918405056
Test Loss:  0.0009407715406268835
Valid Loss:  0.0011890059104189277
Epoch:  266  	Training Loss: 0.0015265351394191384
Test Loss:  0.000934251700527966
Valid Loss:  0.0011899565579369664
Epoch:  267  	Training Loss: 0.001521501922979951
Test Loss:  0.0009363066637888551
Valid Loss:  0.0011823228560388088
Epoch:  268  	Training Loss: 0.001516693620942533
Test Loss:  0.0009313362534157932
Valid Loss:  0.0011819908395409584
Epoch:  269  	Training Loss: 0.0015120527241379023
Test Loss:  0.0009321393445134163
Valid Loss:  0.0011757779866456985
Epoch:  270  	Training Loss: 0.0015075602568686008
Test Loss:  0.0009281747043132782
Valid Loss:  0.0011745437514036894
Epoch:  271  	Training Loss: 0.0015031849034130573
Test Loss:  0.0009281057864427567
Valid Loss:  0.0011692943517118692
Epoch:  272  	Training Loss: 0.001498916419222951
Test Loss:  0.0009244951652362943
Valid Loss:  0.0011663609184324741
Epoch:  273  	Training Loss: 0.0014961083652451634
Test Loss:  0.0009211968863382936
Valid Loss:  0.0011633578687906265
Epoch:  274  	Training Loss: 0.0014936064835637808
Test Loss:  0.0009182201465591788
Valid Loss:  0.0011607708875089884
Epoch:  275  	Training Loss: 0.0014914465136826038
Test Loss:  0.0009154527797363698
Valid Loss:  0.0011582672595977783
Epoch:  276  	Training Loss: 0.0014895086642354727
Test Loss:  0.0009129417594522238
Valid Loss:  0.0011561417486518621
Epoch:  277  	Training Loss: 0.0014878632500767708
Test Loss:  0.0009107046062126756
 55%|█████▌    | 277/500 [03:18<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:18<01:14,  2.96it/s] 56%|█████▌    | 281/500 [03:24<04:19,  1.18s/it] 57%|█████▋    | 283/500 [03:24<03:04,  1.17it/s] 57%|█████▋    | 285/500 [03:25<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:25<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:25<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:31<04:04,  1.17s/it] 59%|█████▊    | 293/500 [03:31<02:53,  1.19it/s] 59%|█████▉    | 295/500 [03:31<02:04,  1.65it/s] 59%|█████▉    | 297/500 [03:31<01:30,  2.25it/s] 60%|█████▉    | 299/500 [03:32<01:06,  3.01it/s] 60%|██████    | 301/500 [03:38<03:51,  1.16s/it] 61%|██████    | 303/500 [03:38<02:44,  1.20it/s] 61%|██████    | 305/500 [03:38<01:58,  1.65it/s] 61%|██████▏   | 307/500 [03:38<01:25,  2.25it/s] 62%|██████▏   | 309/500 [03:38<01:03,  3.02it/s] 62%|██████▏   | 311/500 [03:45<03:40,  1.17s/it] 63%|██████▎   | 313/500 [03:45<02:36,  1.19it/s] 63%|██████▎   | 315/500 [03:45<01:52,  1.65it/s] 63%|██████▎   | 317/500 [03:45<01:21,  2.26it/s] 64%|██████▍   | 319/500 [03:45<00:59,  3.02it/s] 64%|██████▍   | 321/500 [03:51<03:28,  1.17s/it] 65%|██████▍   | 323/500 [03:51<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:52<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:52<01:16,  2.25it/s] 66%|██████▌   | 329/500 [03:52<00:56,  3.03it/s] 66%|██████▌   | 331/500 [03:58<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:58<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:58<01:40,  1.65it/s] 67%|██████▋   | 337/500 [03:59<01:12,  2.25it/s] 68%|██████▊   | 339/500 [03:59<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:05<03:07,  1.18s/it] 69%|██████▊   | 343/500 [04:05<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:05<01:34,  1.63it/s]Valid Loss:  0.0011543510481715202
Epoch:  278  	Training Loss: 0.0014864718541502953
Test Loss:  0.000908603542484343
Valid Loss:  0.0011525220470502973
Epoch:  279  	Training Loss: 0.001485146814957261
Test Loss:  0.0009066027123481035
Valid Loss:  0.0011507619637995958
Epoch:  280  	Training Loss: 0.0014838812639936805
Test Loss:  0.0009046607883647084
Valid Loss:  0.0011490689357742667
Epoch:  281  	Training Loss: 0.001482672058045864
Test Loss:  0.0009028009953908622
Valid Loss:  0.0011474482016637921
Epoch:  282  	Training Loss: 0.0014815146569162607
Test Loss:  0.0009082667529582977
Valid Loss:  0.001137268845923245
Epoch:  283  	Training Loss: 0.001474752789363265
Test Loss:  0.0009069793159142137
Valid Loss:  0.0011365734972059727
Epoch:  284  	Training Loss: 0.0014707541558891535
Test Loss:  0.0009065641206689179
Valid Loss:  0.001134293619543314
Epoch:  285  	Training Loss: 0.0014670203672721982
Test Loss:  0.0009053150424733758
Valid Loss:  0.0011321280617266893
Epoch:  286  	Training Loss: 0.0014633634127676487
Test Loss:  0.0009037842974066734
Valid Loss:  0.0011301302583888173
Epoch:  287  	Training Loss: 0.0014598979614675045
Test Loss:  0.0008966524037532508
Valid Loss:  0.0011278530582785606
Epoch:  288  	Training Loss: 0.0014572687214240432
Test Loss:  0.0008979398990049958
Valid Loss:  0.0011266241781413555
Epoch:  289  	Training Loss: 0.001454740297049284
Test Loss:  0.0008867577416822314
Valid Loss:  0.001124049536883831
Epoch:  290  	Training Loss: 0.0014528922038152814
Test Loss:  0.0008910829201340675
Valid Loss:  0.0011208774521946907
Epoch:  291  	Training Loss: 0.0014493392081931233
Test Loss:  0.0008809465798549354
Valid Loss:  0.0011194513645023108
Epoch:  292  	Training Loss: 0.0014476969372481108
Test Loss:  0.0008778463816270232
Valid Loss:  0.001120618893764913
Epoch:  293  	Training Loss: 0.001442549517378211
Test Loss:  0.0008820060174912214
Valid Loss:  0.0011155700776726007
Epoch:  294  	Training Loss: 0.0014382167719304562
Test Loss:  0.0008798950584605336
Valid Loss:  0.001117224688641727
Epoch:  295  	Training Loss: 0.001434581819921732
Test Loss:  0.0008836764609441161
Valid Loss:  0.001113859354518354
Epoch:  296  	Training Loss: 0.001431622658856213
Test Loss:  0.0008829526486806571
Valid Loss:  0.0011158653069287539
Epoch:  297  	Training Loss: 0.001429036376066506
Test Loss:  0.0008867280557751656
Valid Loss:  0.0011132885701954365
Epoch:  298  	Training Loss: 0.001426774775609374
Test Loss:  0.0008863596012815833
Valid Loss:  0.0011150725185871124
Epoch:  299  	Training Loss: 0.0014247954823076725
Test Loss:  0.00088943523587659
Valid Loss:  0.0011131756473332644
Epoch:  300  	Training Loss: 0.0014230560045689344
Test Loss:  0.000889352522790432
Valid Loss:  0.0011147998739033937
Epoch:  301  	Training Loss: 0.0014215229311957955
Test Loss:  0.0008918896783143282
Valid Loss:  0.001113192061893642
Epoch:  302  	Training Loss: 0.0014201386366039515
Test Loss:  0.0008861540118232369
Valid Loss:  0.001103755785152316
Epoch:  303  	Training Loss: 0.0014137888792902231
Test Loss:  0.0008795277681201696
Valid Loss:  0.0010991593590006232
Epoch:  304  	Training Loss: 0.001408398849889636
Test Loss:  0.0008740572957322001
Valid Loss:  0.001094368170015514
Epoch:  305  	Training Loss: 0.0014032494509592652
Test Loss:  0.0008690534741617739
Valid Loss:  0.0010899973567575216
Epoch:  306  	Training Loss: 0.001398254418745637
Test Loss:  0.0008644910994917154
Valid Loss:  0.0010858423775061965
Epoch:  307  	Training Loss: 0.001393371494486928
Test Loss:  0.000860269065015018
Valid Loss:  0.0010818734299391508
Epoch:  308  	Training Loss: 0.0013885661028325558
Test Loss:  0.0008563224691897631
Valid Loss:  0.0010780435986816883
Epoch:  309  	Training Loss: 0.001383820315822959
Test Loss:  0.0008525925222784281
Valid Loss:  0.001074322615750134
Epoch:  310  	Training Loss: 0.0013791238889098167
Test Loss:  0.0008490458712913096
Valid Loss:  0.0010707378387451172
Epoch:  311  	Training Loss: 0.0013744907919317484
Test Loss:  0.0008456555660814047
Valid Loss:  0.0010672032367438078
Epoch:  312  	Training Loss: 0.001369887264445424
Test Loss:  0.0008420140366069973
Valid Loss:  0.0010670609772205353
Epoch:  313  	Training Loss: 0.0013654115609824657
Test Loss:  0.0008426695130765438
Valid Loss:  0.001063650124706328
Epoch:  314  	Training Loss: 0.0013617039658129215
Test Loss:  0.0008415555348619819
Valid Loss:  0.0010620882967486978
Epoch:  315  	Training Loss: 0.0013583686668425798
Test Loss:  0.0008410608861595392
Valid Loss:  0.0010598866501823068
Epoch:  316  	Training Loss: 0.0013551785377785563
Test Loss:  0.0008401506929658353
Valid Loss:  0.0010580484522506595
Epoch:  317  	Training Loss: 0.001352099934592843
Test Loss:  0.0008392957970499992
Valid Loss:  0.0010561051312834024
Epoch:  318  	Training Loss: 0.0013490936253219843
Test Loss:  0.0008383390959352255
Valid Loss:  0.0010542809031903744
Epoch:  319  	Training Loss: 0.0013461434282362461
Test Loss:  0.0008373395539820194
Valid Loss:  0.0010524203535169363
Epoch:  320  	Training Loss: 0.001343230833299458
Test Loss:  0.0008363085798919201
Valid Loss:  0.0010505500249564648
Epoch:  321  	Training Loss: 0.001340351765975356
Test Loss:  0.0008352278964594007
Valid Loss:  0.0010490373242646456
Epoch:  322  	Training Loss: 0.0013375630369409919
Test Loss:  0.0008153369999490678
Valid Loss:  0.001022798242047429
Epoch:  323  	Training Loss: 0.0013197396183386445
Test Loss:  0.0007992689497768879
Valid Loss:  0.0010067688999697566
Epoch:  324  	Training Loss: 0.0013066488318145275
Test Loss:  0.0007849594112485647
Valid Loss:  0.0009935353882610798
Epoch:  325  	Training Loss: 0.0012947388458997011
Test Loss:  0.0007723338785581291
Valid Loss:  0.0009823997970670462
Epoch:  326  	Training Loss: 0.0012843413278460503
Test Loss:  0.0007604285492561758
Valid Loss:  0.0009726521093398333
Epoch:  327  	Training Loss: 0.001275068847462535
Test Loss:  0.0007497232290916145
Valid Loss:  0.0009640431962907314
Epoch:  328  	Training Loss: 0.0012666034745052457
Test Loss:  0.0007405078504234552
Valid Loss:  0.000956874224357307
Epoch:  329  	Training Loss: 0.0012592675630003214
Test Loss:  0.0007323911995626986
Valid Loss:  0.0009506028727628291
Epoch:  330  	Training Loss: 0.0012528521474450827
Test Loss:  0.0007253859657794237
Valid Loss:  0.0009453085949644446
Epoch:  331  	Training Loss: 0.0012472844682633877
Test Loss:  0.0007190378964878619
Valid Loss:  0.000940502155572176
Epoch:  332  	Training Loss: 0.0012420802377164364
Test Loss:  0.000717372284270823
Valid Loss:  0.0009400765411555767
Epoch:  333  	Training Loss: 0.0012409297050908208
Test Loss:  0.0007161232060752809
Valid Loss:  0.0009397831745445728
Epoch:  334  	Training Loss: 0.0012400539126247168
Test Loss:  0.0007151425234042108
Valid Loss:  0.000939540914259851
Epoch:  335  	Training Loss: 0.0012393381912261248
Test Loss:  0.0007143313996493816
Valid Loss:  0.000939312158152461
Epoch:  336  	Training Loss: 0.0012387190945446491
Test Loss:  0.0007136395433917642
Valid Loss:  0.0009390832856297493
Epoch:  337  	Training Loss: 0.001238160883076489
Test Loss:  0.0007130313897505403
Valid Loss:  0.0009388508042320609
Epoch:  338  	Training Loss: 0.0012376450467854738
Test Loss:  0.0007124822004698217
Valid Loss:  0.0009386138408444822
Epoch:  339  	Training Loss: 0.0012371590128168464
Test Loss:  0.0007119770161807537
Valid Loss:  0.0009383740834891796
Epoch:  340  	Training Loss: 0.0012366952141746879
Test Loss:  0.0007115085609257221
Valid Loss:  0.0009381350828334689
Epoch:  341  	Training Loss: 0.001236251788213849
Test Loss:  0.0007110704900696874
Valid Loss:  0.0009378566755913198
Epoch:  342  	Training Loss: 0.0012358265230432153
Test Loss:  0.0007086330442689359
Valid Loss:  0.0009258781792595983
Epoch:  343  	Training Loss: 0.0012230563443154097
Test Loss:  0.0007058725459501147
Valid Loss:  0.0009189854608848691
Epoch:  344  	Training Loss: 0.0012139184400439262
Test Loss:  0.0007023942889645696
Valid Loss:  0.0009128922829404473
Epoch:  345  	Training Loss: 0.0012052885722368956
Test Loss:  0.000698709161952138
Valid Loss:  0.0009070573723874986
 69%|██████▉   | 347/500 [04:05<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:06<00:50,  2.98it/s] 70%|███████   | 351/500 [04:12<02:55,  1.18s/it] 71%|███████   | 353/500 [04:12<02:04,  1.18it/s] 71%|███████   | 355/500 [04:12<01:28,  1.64it/s] 71%|███████▏  | 357/500 [04:12<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:12<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:19<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:19<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:19<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:19<01:00,  2.21it/s] 74%|███████▍  | 369/500 [04:19<00:44,  2.98it/s] 74%|███████▍  | 371/500 [04:26<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:26<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:26<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:26<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:26<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:32<02:20,  1.18s/it] 77%|███████▋  | 383/500 [04:33<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:33<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:33<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:33<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:39<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:39<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:40<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:40<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:40<00:33,  3.00it/s] 80%|████████  | 401/500 [04:46<01:54,  1.15s/it] 81%|████████  | 403/500 [04:46<01:20,  1.21it/s] 81%|████████  | 405/500 [04:46<00:57,  1.67it/s] 81%|████████▏ | 407/500 [04:46<00:40,  2.27it/s] 82%|████████▏ | 409/500 [04:46<00:29,  3.04it/s] 82%|████████▏ | 411/500 [04:53<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:53<01:13,  1.18it/s]Epoch:  346  	Training Loss: 0.001196888741105795
Test Loss:  0.0006948927184566855
Valid Loss:  0.0009012397495098412
Epoch:  347  	Training Loss: 0.0011885318672284484
Test Loss:  0.0006910812226124108
Valid Loss:  0.0008956000674515963
Epoch:  348  	Training Loss: 0.0011803829111158848
Test Loss:  0.0006873324746266007
Valid Loss:  0.0008900872198864818
Epoch:  349  	Training Loss: 0.001172428485006094
Test Loss:  0.0006836591637693346
Valid Loss:  0.0008846928831189871
Epoch:  350  	Training Loss: 0.0011646695202216506
Test Loss:  0.0006800653645768762
Valid Loss:  0.0008794075693003833
Epoch:  351  	Training Loss: 0.0011569969356060028
Test Loss:  0.000676457944791764
Valid Loss:  0.0008740993216633797
Epoch:  352  	Training Loss: 0.001149371499195695
Test Loss:  0.0006778848473913968
Valid Loss:  0.0008739307522773743
Epoch:  353  	Training Loss: 0.0011477333027869463
Test Loss:  0.0006792738568037748
Valid Loss:  0.0008738855831325054
Epoch:  354  	Training Loss: 0.0011463670525699854
Test Loss:  0.0006806050660088658
Valid Loss:  0.0008739375043660402
Epoch:  355  	Training Loss: 0.001145207672379911
Test Loss:  0.0006818696274422109
Valid Loss:  0.0008740603225305676
Epoch:  356  	Training Loss: 0.0011442219838500023
Test Loss:  0.0006830652710050344
Valid Loss:  0.0008742280770093203
Epoch:  357  	Training Loss: 0.0011433844920247793
Test Loss:  0.0006841856520622969
Valid Loss:  0.0008744277292862535
Epoch:  358  	Training Loss: 0.0011426631826907396
Test Loss:  0.0006852297810837626
Valid Loss:  0.0008746499661356211
Epoch:  359  	Training Loss: 0.001142051536589861
Test Loss:  0.0006861615693196654
Valid Loss:  0.0008747568354010582
Epoch:  360  	Training Loss: 0.0011415687622502446
Test Loss:  0.0006870142533443868
Valid Loss:  0.0008749001426622272
Epoch:  361  	Training Loss: 0.0011411472223699093
Test Loss:  0.0006877916166558862
Valid Loss:  0.0008750628912821412
Epoch:  362  	Training Loss: 0.0011407730635255575
Test Loss:  0.0006846670876257122
Valid Loss:  0.0008723605424165726
Epoch:  363  	Training Loss: 0.0011355828028172255
Test Loss:  0.0006829705089330673
Valid Loss:  0.0008699321188032627
Epoch:  364  	Training Loss: 0.0011311329435557127
Test Loss:  0.0006815647357143462
Valid Loss:  0.0008675363496877253
Epoch:  365  	Training Loss: 0.0011270097456872463
Test Loss:  0.0006801826530136168
Valid Loss:  0.0008651036769151688
Epoch:  366  	Training Loss: 0.0011230956297367811
Test Loss:  0.000678773270919919
Valid Loss:  0.000862587068695575
Epoch:  367  	Training Loss: 0.001119313295930624
Test Loss:  0.0006772651104256511
Valid Loss:  0.0008599646971561015
Epoch:  368  	Training Loss: 0.001115551684051752
Test Loss:  0.0006756776128895581
Valid Loss:  0.0008573284139856696
Epoch:  369  	Training Loss: 0.0011118609691038728
Test Loss:  0.0006740184617228806
Valid Loss:  0.0008546714670956135
Epoch:  370  	Training Loss: 0.0011082333512604237
Test Loss:  0.0006721786339767277
Valid Loss:  0.0008520152186974883
Epoch:  371  	Training Loss: 0.0011046668514609337
Test Loss:  0.0006703049875795841
Valid Loss:  0.0008494651410728693
Epoch:  372  	Training Loss: 0.0011011776514351368
Test Loss:  0.0006666496046818793
Valid Loss:  0.0008474672213196754
Epoch:  373  	Training Loss: 0.0010983396787196398
Test Loss:  0.0006640012143179774
Valid Loss:  0.00084550870815292
Epoch:  374  	Training Loss: 0.0010962544474750757
Test Loss:  0.0006618574261665344
Valid Loss:  0.0008437064825557172
Epoch:  375  	Training Loss: 0.001094452920369804
Test Loss:  0.0006598894251510501
Valid Loss:  0.0008418483193963766
Epoch:  376  	Training Loss: 0.0010927233379334211
Test Loss:  0.0006580289336852729
Valid Loss:  0.000839990854728967
Epoch:  377  	Training Loss: 0.001091038342565298
Test Loss:  0.0006562526104971766
Valid Loss:  0.0008381651132367551
Epoch:  378  	Training Loss: 0.001089388271793723
Test Loss:  0.0006545459036715329
Valid Loss:  0.0008363818051293492
Epoch:  379  	Training Loss: 0.0010877700988203287
Test Loss:  0.0006529054371640086
Valid Loss:  0.0008346455870196223
Epoch:  380  	Training Loss: 0.00108618033118546
Test Loss:  0.0006513193948194385
Valid Loss:  0.0008329499396495521
Epoch:  381  	Training Loss: 0.001084617106243968
Test Loss:  0.0006497901631519198
Valid Loss:  0.0008312997524626553
Epoch:  382  	Training Loss: 0.001083077397197485
Test Loss:  0.0006537279114127159
Valid Loss:  0.0008281563059426844
Epoch:  383  	Training Loss: 0.001076309010386467
Test Loss:  0.0006518895388580859
Valid Loss:  0.0008261672919616103
Epoch:  384  	Training Loss: 0.0010708239860832691
Test Loss:  0.0006529635284096003
Valid Loss:  0.00082404725253582
Epoch:  385  	Training Loss: 0.0010661814594641328
Test Loss:  0.0006520099705085158
Valid Loss:  0.0008222158066928387
Epoch:  386  	Training Loss: 0.0010620546527206898
Test Loss:  0.0006520271999761462
Valid Loss:  0.0008202343015000224
Epoch:  387  	Training Loss: 0.001058247871696949
Test Loss:  0.0006507865618914366
Valid Loss:  0.0008181551238521934
Epoch:  388  	Training Loss: 0.0010546280536800623
Test Loss:  0.0006499761366285384
Valid Loss:  0.0008165408507920802
Epoch:  389  	Training Loss: 0.0010512506123632193
Test Loss:  0.0006487287464551628
Valid Loss:  0.0008151649963110685
Epoch:  390  	Training Loss: 0.001048180041834712
Test Loss:  0.0006447537452913821
Valid Loss:  0.0008133528754115105
Epoch:  391  	Training Loss: 0.0010459674522280693
Test Loss:  0.0006463383324444294
Valid Loss:  0.0008126083994284272
Epoch:  392  	Training Loss: 0.0010434924624860287
Test Loss:  0.0006405501044355333
Valid Loss:  0.0008071282645687461
Epoch:  393  	Training Loss: 0.0010398246813565493
Test Loss:  0.0006361006526276469
Valid Loss:  0.0008039053063839674
Epoch:  394  	Training Loss: 0.0010370237287133932
Test Loss:  0.0006322985864244401
Valid Loss:  0.0008012684993445873
Epoch:  395  	Training Loss: 0.0010344746988266706
Test Loss:  0.0006287454161792994
Valid Loss:  0.0007987366989254951
Epoch:  396  	Training Loss: 0.0010321179870516062
Test Loss:  0.0006254975451156497
Valid Loss:  0.0007964307442307472
Epoch:  397  	Training Loss: 0.0010299241403117776
Test Loss:  0.000622514053247869
Valid Loss:  0.0007943029631860554
Epoch:  398  	Training Loss: 0.0010278685949742794
Test Loss:  0.0006197034381330013
Valid Loss:  0.0007922841468825936
Epoch:  399  	Training Loss: 0.0010259301634505391
Test Loss:  0.0006171729764901102
Valid Loss:  0.0007904716767370701
Epoch:  400  	Training Loss: 0.0010239874245598912
Test Loss:  0.0006143617210909724
Valid Loss:  0.0007878170581534505
Epoch:  401  	Training Loss: 0.0010218012612313032
Test Loss:  0.0006118256715126336
Valid Loss:  0.0007850825204513967
Epoch:  402  	Training Loss: 0.0010198624804615974
Test Loss:  0.0006042823079042137
Valid Loss:  0.0007829798851162195
Epoch:  403  	Training Loss: 0.001014400040730834
Test Loss:  0.0006019192514941096
Valid Loss:  0.0007719311397522688
Epoch:  404  	Training Loss: 0.001009423634968698
Test Loss:  0.0005958478432148695
Valid Loss:  0.0007722453447058797
Epoch:  405  	Training Loss: 0.0010049691190943122
Test Loss:  0.0005936361849308014
Valid Loss:  0.0007650321931578219
Epoch:  406  	Training Loss: 0.001000887481495738
Test Loss:  0.0005892319022677839
Valid Loss:  0.0007639973191544414
Epoch:  407  	Training Loss: 0.0009970266837626696
Test Loss:  0.000586913141887635
Valid Loss:  0.0007588383159600198
Epoch:  408  	Training Loss: 0.0009933304972946644
Test Loss:  0.0005834151525050402
Valid Loss:  0.0007570735178887844
Epoch:  409  	Training Loss: 0.0009897419949993491
Test Loss:  0.0005811783485114574
Valid Loss:  0.0007530605653300881
Epoch:  410  	Training Loss: 0.000986249651759863
Test Loss:  0.0005783201195299625
Valid Loss:  0.0007509072311222553
Epoch:  411  	Training Loss: 0.0009828850161284208
Test Loss:  0.0005761598004028201
Valid Loss:  0.0007475794991478324
Epoch:  412  	Training Loss: 0.0009795741643756628
Test Loss:  0.000575610960368067
Valid Loss:  0.0007451330311596394
Epoch:  413  	Training Loss: 0.0009760527755133808
Test Loss:  0.0005747336545027792
Valid Loss:  0.0007430187542922795
Epoch:  414  	Training Loss: 0.0009726788848638535
Test Loss:   83%|████████▎ | 415/500 [04:53<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:53<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:53<00:27,  2.99it/s] 84%|████████▍ | 421/500 [05:00<01:33,  1.19s/it] 85%|████████▍ | 423/500 [05:00<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:00<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:00<00:32,  2.22it/s] 86%|████████▌ | 429/500 [05:00<00:23,  2.99it/s] 86%|████████▌ | 431/500 [05:06<01:21,  1.17s/it] 87%|████████▋ | 433/500 [05:07<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:07<00:39,  1.64it/s] 87%|████████▋ | 437/500 [05:07<00:28,  2.24it/s] 88%|████████▊ | 439/500 [05:07<00:20,  3.01it/s] 88%|████████▊ | 441/500 [05:13<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:13<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:14<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:14<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:14<00:16,  3.00it/s] 90%|█████████ | 451/500 [05:20<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:20<00:39,  1.18it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.63it/s] 91%|█████████▏| 457/500 [05:21<00:19,  2.23it/s] 92%|█████████▏| 459/500 [05:21<00:13,  3.00it/s] 92%|█████████▏| 461/500 [05:27<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:27<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:27<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:28<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:34<00:34,  1.18s/it] 95%|█████████▍| 473/500 [05:34<00:22,  1.18it/s] 95%|█████████▌| 475/500 [05:34<00:15,  1.63it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.23it/s] 96%|█████████▌| 479/500 [05:34<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:41<00:22,  1.19s/it]0.0005737102474085987
Valid Loss:  0.0007409700192511082
Epoch:  415  	Training Loss: 0.0009693952742964029
Test Loss:  0.0005725888768211007
Valid Loss:  0.0007389308302663267
Epoch:  416  	Training Loss: 0.0009661839576438069
Test Loss:  0.0005713870050385594
Valid Loss:  0.0007368922815658152
Epoch:  417  	Training Loss: 0.0009630192071199417
Test Loss:  0.0005700915353372693
Valid Loss:  0.0007348247454501688
Epoch:  418  	Training Loss: 0.0009598521864973009
Test Loss:  0.0005687070661224425
Valid Loss:  0.0007327334606088698
Epoch:  419  	Training Loss: 0.00095669727306813
Test Loss:  0.0005672674160450697
Valid Loss:  0.0007308042841032147
Epoch:  420  	Training Loss: 0.000953600974753499
Test Loss:  0.0005657774163410068
Valid Loss:  0.0007288269698619843
Epoch:  421  	Training Loss: 0.000950553163420409
Test Loss:  0.0005642459145747125
Valid Loss:  0.0007268408080562949
Epoch:  422  	Training Loss: 0.0009475387632846832
Test Loss:  0.0005630224477499723
Valid Loss:  0.0007275916868820786
Epoch:  423  	Training Loss: 0.0009453899692744017
Test Loss:  0.000564298068638891
Valid Loss:  0.0007270713103935122
Epoch:  424  	Training Loss: 0.0009437983972020447
Test Loss:  0.0005651693209074438
Valid Loss:  0.0007270935457199812
Epoch:  425  	Training Loss: 0.000942476443015039
Test Loss:  0.0005661074537783861
Valid Loss:  0.0007272592047229409
Epoch:  426  	Training Loss: 0.0009413014631718397
Test Loss:  0.0005670269019901752
Valid Loss:  0.0007274863310158253
Epoch:  427  	Training Loss: 0.0009402555879205465
Test Loss:  0.0005679357564076781
Valid Loss:  0.0007277512340806425
Epoch:  428  	Training Loss: 0.0009393244981765747
Test Loss:  0.0005688295932486653
Valid Loss:  0.0007280516438186169
Epoch:  429  	Training Loss: 0.000938493525609374
Test Loss:  0.0005697031156159937
Valid Loss:  0.00072837108746171
Epoch:  430  	Training Loss: 0.0009377594105899334
Test Loss:  0.0005705596995539963
Valid Loss:  0.0007286975742317736
Epoch:  431  	Training Loss: 0.0009371272753924131
Test Loss:  0.000571376527659595
Valid Loss:  0.0007290435023605824
Epoch:  432  	Training Loss: 0.0009365610894747078
Test Loss:  0.0005519906408153474
Valid Loss:  0.0007055237656459212
Epoch:  433  	Training Loss: 0.0009194884332828224
Test Loss:  0.0005341277574189007
Valid Loss:  0.0006974227144382894
Epoch:  434  	Training Loss: 0.0009064511395990849
Test Loss:  0.000523386406712234
Valid Loss:  0.0006821420975029469
Epoch:  435  	Training Loss: 0.0008964859298430383
Test Loss:  0.0005118483677506447
Valid Loss:  0.0006797246169298887
Epoch:  436  	Training Loss: 0.0008887274307198822
Test Loss:  0.0005058017559349537
Valid Loss:  0.0006687102140858769
Epoch:  437  	Training Loss: 0.0008824598044157028
Test Loss:  0.0004979756777174771
Valid Loss:  0.0006694943876937032
Epoch:  438  	Training Loss: 0.00087750144302845
Test Loss:  0.0004947185516357422
Valid Loss:  0.0006608397234231234
Epoch:  439  	Training Loss: 0.0008734231814742088
Test Loss:  0.0004889108240604401
Valid Loss:  0.0006631099968217313
Epoch:  440  	Training Loss: 0.0008700046455487609
Test Loss:  0.0004867131356149912
Valid Loss:  0.0006554157007485628
Epoch:  441  	Training Loss: 0.0008671764517202973
Test Loss:  0.0004821947368327528
Valid Loss:  0.0006587589741684496
Epoch:  442  	Training Loss: 0.0008647972717881203
Test Loss:  0.00047994026681408286
Valid Loss:  0.0006419190904125571
Epoch:  443  	Training Loss: 0.0008449635934084654
Test Loss:  0.0004813577688764781
Valid Loss:  0.0006376879755407572
Epoch:  444  	Training Loss: 0.0008381293737329543
Test Loss:  0.0004812392871826887
Valid Loss:  0.0006351277697831392
Epoch:  445  	Training Loss: 0.0008332355646416545
Test Loss:  0.00048023712588474154
Valid Loss:  0.0006329070893116295
Epoch:  446  	Training Loss: 0.0008288320968858898
Test Loss:  0.00047878845361992717
Valid Loss:  0.0006307002040557563
Epoch:  447  	Training Loss: 0.0008245828212238848
Test Loss:  0.0004771580279339105
Valid Loss:  0.000628531095571816
Epoch:  448  	Training Loss: 0.000820486806333065
Test Loss:  0.00047547894064337015
Valid Loss:  0.0006265824194997549
Epoch:  449  	Training Loss: 0.0008166634361259639
Test Loss:  0.00047120198723860085
Valid Loss:  0.000624234729912132
Epoch:  450  	Training Loss: 0.0008137086988426745
Test Loss:  0.0004709267523139715
Valid Loss:  0.0006248365971259773
Epoch:  451  	Training Loss: 0.0008112340001389384
Test Loss:  0.0004653724026866257
Valid Loss:  0.0006206480320543051
Epoch:  452  	Training Loss: 0.0008085625013336539
Test Loss:  0.0004633889184333384
Valid Loss:  0.0006185953970998526
Epoch:  453  	Training Loss: 0.0008023370173759758
Test Loss:  0.0004636413068510592
Valid Loss:  0.0006169129628688097
Epoch:  454  	Training Loss: 0.0007975580519996583
Test Loss:  0.0004638317332137376
Valid Loss:  0.0006155881565064192
Epoch:  455  	Training Loss: 0.0007935685571283102
Test Loss:  0.0004639519611373544
Valid Loss:  0.0006144509534351528
Epoch:  456  	Training Loss: 0.0007901403587311506
Test Loss:  0.0004639537073671818
Valid Loss:  0.0006133858114480972
Epoch:  457  	Training Loss: 0.0007871104753576219
Test Loss:  0.00046381406718865037
Valid Loss:  0.0006123353959992528
Epoch:  458  	Training Loss: 0.0007843668572604656
Test Loss:  0.0004635356890503317
Valid Loss:  0.0006112616392783821
Epoch:  459  	Training Loss: 0.0007818317972123623
Test Loss:  0.00046312325866892934
Valid Loss:  0.0006101485341787338
Epoch:  460  	Training Loss: 0.0007794491830281913
Test Loss:  0.0004625897854566574
Valid Loss:  0.000608988746535033
Epoch:  461  	Training Loss: 0.0007771817035973072
Test Loss:  0.00046195057802833617
Valid Loss:  0.0006077811121940613
Epoch:  462  	Training Loss: 0.0007750019431114197
Test Loss:  0.0004613869823515415
Valid Loss:  0.0006084020133130252
Epoch:  463  	Training Loss: 0.0007739798165857792
Test Loss:  0.0004616662045009434
Valid Loss:  0.0006088028894737363
Epoch:  464  	Training Loss: 0.0007735224789939821
Test Loss:  0.00046208954881876707
Valid Loss:  0.0006090169190429151
Epoch:  465  	Training Loss: 0.0007731427904218435
Test Loss:  0.0004625403380487114
Valid Loss:  0.0006091642426326871
Epoch:  466  	Training Loss: 0.0007727963966317475
Test Loss:  0.00046297276276163757
Valid Loss:  0.0006092874682508409
Epoch:  467  	Training Loss: 0.0007724915631115437
Test Loss:  0.0004633910139091313
Valid Loss:  0.0006094006821513176
Epoch:  468  	Training Loss: 0.0007722115842625499
Test Loss:  0.0004638002428691834
Valid Loss:  0.0006095138378441334
Epoch:  469  	Training Loss: 0.0007719519780948758
Test Loss:  0.0004642092972062528
Valid Loss:  0.0006096659926697612
Epoch:  470  	Training Loss: 0.0007717155385762453
Test Loss:  0.0004646021989174187
Valid Loss:  0.000609815469942987
Epoch:  471  	Training Loss: 0.0007714960956946015
Test Loss:  0.00046497926814481616
Valid Loss:  0.0006099581951275468
Epoch:  472  	Training Loss: 0.0007712933584116399
Test Loss:  0.0004568657896015793
Valid Loss:  0.0005993558443151414
Epoch:  473  	Training Loss: 0.00076581712346524
Test Loss:  0.00044990109745413065
Valid Loss:  0.0005963703151792288
Epoch:  474  	Training Loss: 0.0007616827497258782
Test Loss:  0.00044489256106317043
Valid Loss:  0.0005884610582143068
Epoch:  475  	Training Loss: 0.0007585623534396291
Test Loss:  0.0004400626930873841
Valid Loss:  0.0005881264223717153
Epoch:  476  	Training Loss: 0.0007562806131318212
Test Loss:  0.0004371769609861076
Valid Loss:  0.0005817308556288481
Epoch:  477  	Training Loss: 0.0007545296102762222
Test Loss:  0.0004335395060479641
Valid Loss:  0.0005828774883411825
Epoch:  478  	Training Loss: 0.0007531492155976593
Test Loss:  0.0004318993887864053
Valid Loss:  0.0005772319855168462
Epoch:  479  	Training Loss: 0.0007521172519773245
Test Loss:  0.0004290628421586007
Valid Loss:  0.0005795243778266013
Epoch:  480  	Training Loss: 0.000751349376514554
Test Loss:  0.0004283255257178098
Valid Loss:  0.0005742533830925822
Epoch:  481  	Training Loss: 0.0007507600821554661
Test Loss:  0.0004258644476067275
Valid Loss:  0.000577273138333112
Epoch:  482  	Training Loss: 0.0007502922671847045
Test Loss:  0.00042872774065472186
Valid Loss:   97%|█████████▋| 483/500 [05:41<00:14,  1.17it/s] 97%|█████████▋| 485/500 [05:41<00:09,  1.62it/s] 97%|█████████▋| 487/500 [05:41<00:05,  2.21it/s] 98%|█████████▊| 489/500 [05:41<00:03,  2.97it/s] 98%|█████████▊| 491/500 [05:54<00:18,  2.08s/it] 99%|█████████▊| 493/500 [05:54<00:10,  1.48s/it] 99%|█████████▉| 495/500 [05:54<00:05,  1.05s/it] 99%|█████████▉| 497/500 [05:54<00:02,  1.32it/s]100%|█████████▉| 499/500 [05:54<00:00,  1.82it/s]100%|██████████| 500/500 [05:54<00:00,  1.41it/s]
0.0005721679190173745
Epoch:  483  	Training Loss: 0.0007425750372931361
Test Loss:  0.000431967549957335
Valid Loss:  0.000573398545384407
Epoch:  484  	Training Loss: 0.0007412902778014541
Test Loss:  0.00042992978706024587
Valid Loss:  0.0005715922452509403
Epoch:  485  	Training Loss: 0.0007411169353872538
Test Loss:  0.0004328642971813679
Valid Loss:  0.0005750602576881647
Epoch:  486  	Training Loss: 0.0007414440624415874
Test Loss:  0.00043037085561081767
Valid Loss:  0.0005716546438634396
Epoch:  487  	Training Loss: 0.0007405428914353251
Test Loss:  0.00043099207687191665
Valid Loss:  0.0005721724592149258
Epoch:  488  	Training Loss: 0.0007404100033454597
Test Loss:  0.00042956072138622403
Valid Loss:  0.000571694690734148
Epoch:  489  	Training Loss: 0.0007408322999253869
Test Loss:  0.0004326167982071638
Valid Loss:  0.0005750114214606583
Epoch:  490  	Training Loss: 0.0007409509271383286
Test Loss:  0.000430337997386232
Valid Loss:  0.0005717554013244808
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.0007401590701192617
Test Loss:  0.0004290555079933256
Valid Loss:  0.0005686706281267107
Epoch:  492  	Training Loss: 0.0007375749410130084
Test Loss:  0.0004292096709832549
Valid Loss:  0.0005685249925591052
Epoch:  493  	Training Loss: 0.000736589077860117
Test Loss:  0.00042936281533911824
Valid Loss:  0.0005683799972757697
Epoch:  494  	Training Loss: 0.0007356508867815137
Test Loss:  0.0004295220714993775
Valid Loss:  0.0005682334303855896
Epoch:  495  	Training Loss: 0.0007347575156018138
Test Loss:  0.0004296735569369048
Valid Loss:  0.0005680847680196166
Epoch:  496  	Training Loss: 0.0007339015719480813
Test Loss:  0.0004298215208109468
Valid Loss:  0.0005679319729097188
Epoch:  497  	Training Loss: 0.0007330803782679141
Test Loss:  0.00042995414696633816
Valid Loss:  0.0005677719018422067
Epoch:  498  	Training Loss: 0.0007322879391722381
Test Loss:  0.0004300701548345387
Valid Loss:  0.0005676058353856206
Epoch:  499  	Training Loss: 0.0007315210532397032
Test Loss:  0.0004301679437048733
Valid Loss:  0.0005674294661730528
Epoch:  500  	Training Loss: 0.0007307767518796027
Test Loss:  0.00043024925980716944
Valid Loss:  0.0005672468105331063
seed is  17
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.36it/s]  1%|          | 4/500 [00:00<00:30, 16.50it/s]  1%|          | 6/500 [00:00<00:30, 16.43it/s]  2%|▏         | 8/500 [00:00<00:30, 16.36it/s]  2%|▏         | 10/500 [00:00<00:30, 16.32it/s]  2%|▏         | 12/500 [00:00<00:29, 16.45it/s]  3%|▎         | 14/500 [00:00<00:29, 16.45it/s]  3%|▎         | 16/500 [00:00<00:29, 16.27it/s]  4%|▎         | 18/500 [00:01<00:29, 16.25it/s]  4%|▍         | 20/500 [00:01<00:29, 16.25it/s]  4%|▍         | 22/500 [00:01<00:29, 16.02it/s]  5%|▍         | 24/500 [00:01<00:29, 16.08it/s]  5%|▌         | 26/500 [00:01<00:29, 16.14it/s]  6%|▌         | 28/500 [00:01<00:29, 16.25it/s]  6%|▌         | 30/500 [00:01<00:28, 16.33it/s]  6%|▋         | 32/500 [00:01<00:28, 16.38it/s]  7%|▋         | 34/500 [00:02<00:28, 16.40it/s]  7%|▋         | 36/500 [00:02<00:28, 16.32it/s]  8%|▊         | 38/500 [00:02<00:28, 16.34it/s]  8%|▊         | 40/500 [00:02<00:27, 16.45it/s]  8%|▊         | 42/500 [00:02<00:27, 16.40it/s]  9%|▉         | 44/500 [00:02<00:28, 16.27it/s]  9%|▉         | 46/500 [00:02<00:27, 16.34it/s] 10%|▉         | 48/500 [00:02<00:27, 16.35it/s] 10%|█         | 50/500 [00:03<00:27, 16.39it/s] 10%|█         | 52/500 [00:03<00:27, 16.43it/s] 11%|█         | 54/500 [00:03<00:27, 16.47it/s] 11%|█         | 56/500 [00:03<00:27, 16.42it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.16it/s] 12%|█▏        | 60/500 [00:03<00:27, 16.13it/s] 12%|█▏        | 62/500 [00:03<00:27, 16.13it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.18it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.28it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.33it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.07it/s] 14%|█▍        | 72/500 [00:04<00:26, 16.19it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.30it/s] 15%|█▌        | 76/500 [00:04<00:25, 16.33it/s] 16%|█▌        | 78/500 [00:04<00:25, 16.39it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.41it/s] 16%|█▋        | 82/500 [00:05<00:25, 16.47it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.47it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.46it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.41it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.33it/s] 18%|█▊        | 92/500 [00:05<00:26, 15.63it/s] 19%|█▉        | 94/500 [00:05<00:25, 15.90it/s] 19%|█▉        | 96/500 [00:05<00:25, 16.04it/s] 20%|█▉        | 98/500 [00:06<00:25, 16.05it/s] 20%|██        | 100/500 [00:06<00:24, 16.22it/s] 20%|██        | 102/500 [00:06<00:24, 16.32it/s] 21%|██        | 104/500 [00:06<00:24, 16.43it/s] 21%|██        | 106/500 [00:06<00:23, 16.48it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.39it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.25it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.39it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.41it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.51it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.53it/s] 24%|██▍       | 120/500 [00:07<00:22, 16.54it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.59it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.62it/s]Epoch:  1  	Training Loss: 0.130367249250412
Test Loss:  2333.28271484375
Valid Loss:  2340.305419921875
Epoch:  2  	Training Loss: 2343.00537109375
Test Loss:  171665178755072.0
Valid Loss:  170167476682752.0
Epoch:  3  	Training Loss: 170533740085248.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.60it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.56it/s] 26%|██▌       | 130/500 [00:07<00:22, 16.35it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.39it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.45it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.50it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.53it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.58it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.58it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.59it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.29it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.25it/s] 30%|███       | 150/500 [00:09<00:21, 16.36it/s] 30%|███       | 152/500 [00:09<00:21, 16.39it/s] 31%|███       | 154/500 [00:09<00:21, 16.31it/s] 31%|███       | 156/500 [00:09<00:21, 16.34it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.39it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.36it/s] 32%|███▏      | 162/500 [00:09<00:20, 16.41it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.32it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.06it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.01it/s] 34%|███▍      | 170/500 [00:10<00:20, 15.95it/s] 34%|███▍      | 172/500 [00:10<00:21, 14.92it/s] 35%|███▍      | 174/500 [00:10<00:22, 14.17it/s] 35%|███▌      | 176/500 [00:10<00:23, 13.52it/s] 36%|███▌      | 178/500 [00:11<00:24, 13.02it/s] 36%|███▌      | 180/500 [00:11<00:24, 13.30it/s] 36%|███▋      | 182/500 [00:11<00:22, 14.08it/s] 37%|███▋      | 184/500 [00:11<00:21, 14.71it/s] 37%|███▋      | 186/500 [00:11<00:20, 15.19it/s] 38%|███▊      | 188/500 [00:11<00:20, 15.31it/s] 38%|███▊      | 190/500 [00:11<00:21, 14.34it/s] 38%|███▊      | 192/500 [00:12<00:21, 14.26it/s] 39%|███▉      | 194/500 [00:12<00:20, 14.80it/s] 39%|███▉      | 196/500 [00:12<00:19, 15.31it/s] 40%|███▉      | 198/500 [00:12<00:19, 15.69it/s] 40%|████      | 200/500 [00:12<00:18, 15.95it/s] 40%|████      | 202/500 [00:12<00:18, 16.18it/s] 41%|████      | 204/500 [00:12<00:18, 16.26it/s] 41%|████      | 206/500 [00:12<00:17, 16.35it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.40it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.36it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.27it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.33it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.44it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.44it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.46it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.51it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.41it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.46it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.40it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.28it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.29it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.37it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.44it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.02it/s] 48%|████▊     | 240/500 [00:14<00:17, 14.75it/s] 48%|████▊     | 242/500 [00:15<00:17, 15.15it/s] 49%|████▉     | 244/500 [00:15<00:16, 15.53it/s] 49%|████▉     | 246/500 [00:15<00:16, 15.61it/s] 50%|████▉     | 248/500 [00:15<00:15, 15.88it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.10it/s] 50%|█████     | 252/500 [00:15<00:15, 16.10it/s] 51%|█████     | 254/500 [00:15<00:15, 16.11it/s] 51%|█████     | 256/500 [00:15<00:15, 16.07it/s] 52%|█████▏    | 258/500 [00:16<00:15, 16.07it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.17it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.33it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.42it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.11it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.19it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.24it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.17it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.76it/s] 55%|█████▌    | 276/500 [00:17<00:14, 15.40it/s] 56%|█████▌    | 278/500 [00:17<00:14, 15.54it/s] 56%|█████▌    | 280/500 [00:17<00:14, 15.19it/s] 56%|█████▋    | 282/500 [00:17<00:14, 15.54it/s] 57%|█████▋    | 284/500 [00:17<00:13, 15.81it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.00it/s] 58%|█████▊    | 288/500 [00:17<00:13, 16.06it/s] 58%|█████▊    | 290/500 [00:18<00:13, 16.07it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.18it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.31it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.29it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.39it/s] 60%|██████    | 300/500 [00:18<00:12, 16.43it/s] 60%|██████    | 302/500 [00:18<00:12, 16.40it/s] 61%|██████    | 304/500 [00:18<00:11, 16.42it/s] 61%|██████    | 306/500 [00:19<00:11, 16.30it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.40it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.43it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.46it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.53it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.35it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.31it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.35it/s] 64%|██████▍   | 322/500 [00:20<00:10, 16.39it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.47it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.49it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.53it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.56it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.60it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.45it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.24it/s] 68%|██████▊   | 338/500 [00:21<00:09, 16.32it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.38it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.43it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.55it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.56it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.24it/s] 70%|███████   | 350/500 [00:21<00:09, 16.12it/s] 70%|███████   | 352/500 [00:21<00:09, 16.09it/s] 71%|███████   | 354/500 [00:22<00:09, 16.12it/s] 71%|███████   | 356/500 [00:22<00:08, 16.18it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.21it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.35it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.32it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.22it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.30it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.43it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.45it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.41it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.48it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.50it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.57it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.50it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.40it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.43it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.45it/s] 78%|███████▊  | 388/500 [00:24<00:06, 16.26it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.40it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.37it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.44it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.46it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.43it/s] 80%|████████  | 400/500 [00:24<00:06, 16.40it/s] 80%|████████  | 402/500 [00:24<00:06, 16.25it/s] 81%|████████  | 404/500 [00:25<00:05, 16.30it/s] 81%|████████  | 406/500 [00:25<00:05, 16.38it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.43it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.46it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.50it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.43it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.48it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.29it/s] 84%|████████▍ | 420/500 [00:26<00:04, 16.28it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.32it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.36it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.42it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.44it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.39it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.20it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.30it/s] 87%|████████▋ | 436/500 [00:27<00:03, 16.34it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.29it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.36it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.42it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.46it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.46it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.33it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.43it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.44it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.37it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.43it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.50it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.53it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.45it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.34it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.29it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.39it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.41it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.37it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.23it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.22it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.30it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.43it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.34it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.26it/s] 97%|█████████▋| 486/500 [00:30<00:00, 16.39it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.45it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.48it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.36it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.46it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.46it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.34it/s]100%|██████████| 500/500 [00:30<00:00, 14.64it/s]100%|██████████| 500/500 [00:30<00:00, 16.15it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  17
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<50:47,  6.11s/it]  1%|          | 3/500 [00:06<13:33,  1.64s/it]  1%|          | 5/500 [00:06<06:50,  1.20it/s]  1%|▏         | 7/500 [00:06<04:09,  1.97it/s]  2%|▏         | 9/500 [00:06<02:46,  2.94it/s]  2%|▏         | 11/500 [00:12<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:19,  1.11it/s]  3%|▎         | 15/500 [00:19<13:15,  1.64s/it]  3%|▎         | 17/500 [00:19<09:12,  1.14s/it]  4%|▍         | 19/500 [00:19<06:29,  1.24it/s]  4%|▍         | 21/500 [00:26<12:11,  1.53s/it]  5%|▍         | 23/500 [00:26<08:36,  1.08s/it]  5%|▌         | 25/500 [00:32<13:30,  1.71s/it]  5%|▌         | 27/500 [00:32<09:33,  1.21s/it]  6%|▌         | 29/500 [00:32<06:48,  1.15it/s]  6%|▌         | 31/500 [00:45<19:22,  2.48s/it]  7%|▋         | 33/500 [00:45<13:39,  1.75s/it]  7%|▋         | 35/500 [00:51<16:44,  2.16s/it]  7%|▋         | 37/500 [00:51<11:49,  1.53s/it]  8%|▊         | 39/500 [00:51<08:23,  1.09s/it]  8%|▊         | 39/500 [01:02<08:23,  1.09s/it]  8%|▊         | 41/500 [01:04<20:11,  2.64s/it]  9%|▊         | 43/500 [01:04<14:13,  1.87s/it]  9%|▉         | 45/500 [01:10<16:57,  2.24s/it]  9%|▉         | 47/500 [01:10<11:58,  1.59s/it] 10%|▉         | 49/500 [01:10<08:29,  1.13s/it] 10%|▉         | 49/500 [01:22<08:29,  1.13s/it] 10%|█         | 51/500 [01:23<19:50,  2.65s/it] 11%|█         | 53/500 [01:23<13:59,  1.88s/it] 11%|█         | 55/500 [01:29<16:42,  2.25s/it] 11%|█▏        | 57/500 [01:29<11:48,  1.60s/it] 12%|█▏        | 59/500 [01:29<08:22,  1.14s/it] 12%|█▏        | 61/500 [01:42<19:27,  2.66s/it] 13%|█▎        | 63/500 [01:42<13:42,  1.88s/it]Epoch:  1  	Training Loss: 0.130367249250412
Test Loss:  0.8218948841094971
Valid Loss:  0.8190760612487793
Epoch:  2  	Training Loss: 0.8126922845840454
Test Loss:  0.11753147840499878
Valid Loss:  0.11850716173648834
Epoch:  3  	Training Loss: 0.12077280879020691
Test Loss:  0.11638692021369934
Valid Loss:  0.11747513711452484
Epoch:  4  	Training Loss: 0.11970596015453339
Test Loss:  0.11638691276311874
Valid Loss:  0.11747510731220245
Epoch:  5  	Training Loss: 0.119705930352211
Test Loss:  0.11638689041137695
Valid Loss:  0.11747507750988007
Epoch:  6  	Training Loss: 0.11970590800046921
Test Loss:  0.11638688296079636
Valid Loss:  0.11747505515813828
Epoch:  7  	Training Loss: 0.11970588564872742
Test Loss:  0.11638686805963516
Valid Loss:  0.11747503280639648
Epoch:  8  	Training Loss: 0.11970586329698563
Test Loss:  0.11638686060905457
Valid Loss:  0.11747501790523529
Epoch:  9  	Training Loss: 0.11970584839582443
Test Loss:  0.11638685315847397
Valid Loss:  0.1174750030040741
Epoch:  10  	Training Loss: 0.11970582604408264
Test Loss:  0.11638684570789337
Valid Loss:  0.1174749806523323
Epoch:  11  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747497320175171
Epoch:  12  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747497320175171
Epoch:  13  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747496575117111
Epoch:  14  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747496575117111
Epoch:  15  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  17  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  18  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  19  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  20  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  21  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495830059052
Epoch:  22  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  23  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  24  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  25  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  27  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  28  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  29  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  30  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  32  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  33  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  34  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  35  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  37  	Training Loss: 0.11970580369234085
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495830059052
Epoch:  38  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  39  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  40  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  42  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  43  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  44  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  45  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  47  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  48  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  49  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  50  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  52  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  53  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  54  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  55  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  57  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  58  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  59  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  60  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  62  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  63  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
 13%|█▎        | 65/500 [01:48<16:19,  2.25s/it] 13%|█▎        | 67/500 [01:48<11:32,  1.60s/it] 14%|█▍        | 69/500 [01:49<08:11,  1.14s/it] 14%|█▍        | 71/500 [02:01<18:55,  2.65s/it] 15%|█▍        | 73/500 [02:01<13:20,  1.87s/it] 15%|█▌        | 75/500 [02:07<15:52,  2.24s/it] 15%|█▌        | 77/500 [02:07<11:12,  1.59s/it] 16%|█▌        | 79/500 [02:07<07:56,  1.13s/it] 16%|█▌        | 81/500 [02:20<18:35,  2.66s/it] 17%|█▋        | 83/500 [02:20<13:06,  1.89s/it] 17%|█▋        | 85/500 [02:27<15:49,  2.29s/it] 17%|█▋        | 87/500 [02:27<11:10,  1.62s/it] 18%|█▊        | 89/500 [02:27<07:55,  1.16s/it] 18%|█▊        | 91/500 [02:39<18:10,  2.67s/it] 19%|█▊        | 93/500 [02:39<12:48,  1.89s/it] 19%|█▉        | 95/500 [02:46<15:17,  2.27s/it] 19%|█▉        | 97/500 [02:46<10:48,  1.61s/it] 20%|█▉        | 99/500 [02:46<07:39,  1.15s/it] 20%|██        | 101/500 [02:58<17:53,  2.69s/it] 21%|██        | 103/500 [02:59<12:35,  1.90s/it] 21%|██        | 105/500 [03:05<14:55,  2.27s/it] 21%|██▏       | 107/500 [03:05<10:32,  1.61s/it] 22%|██▏       | 109/500 [03:05<07:28,  1.15s/it] 22%|██▏       | 111/500 [03:18<17:18,  2.67s/it] 23%|██▎       | 113/500 [03:18<12:11,  1.89s/it] 23%|██▎       | 115/500 [03:24<14:35,  2.27s/it] 23%|██▎       | 117/500 [03:24<10:18,  1.61s/it] 24%|██▍       | 119/500 [03:24<07:18,  1.15s/it] 24%|██▍       | 121/500 [03:37<16:47,  2.66s/it]Epoch:  64  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  65  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  67  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  68  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  69  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495830059052
Epoch:  70  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  72  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  73  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  74  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  75  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  77  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  78  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  79  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  80  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  82  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  83  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  84  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495085000992
Epoch:  85  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  87  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  88  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  89  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  90  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.11970581114292145
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  92  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  93  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  94  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  95  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  97  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  98  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  99  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  100  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  102  	Training Loss: 0.11970580369234085
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495830059052
Epoch:  103  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  104  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  105  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  107  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  108  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  109  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  110  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  112  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  113  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  114  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  115  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  117  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  118  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  119  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  120  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  122  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  123  	Training Loss: 0.11970580369234085
Test Loss:   25%|██▍       | 123/500 [03:37<11:49,  1.88s/it] 25%|██▌       | 125/500 [03:43<14:05,  2.26s/it] 25%|██▌       | 127/500 [03:43<09:57,  1.60s/it] 26%|██▌       | 129/500 [03:43<07:04,  1.14s/it] 26%|██▌       | 131/500 [03:56<16:18,  2.65s/it] 27%|██▋       | 133/500 [03:56<11:29,  1.88s/it] 27%|██▋       | 135/500 [04:02<13:45,  2.26s/it] 27%|██▋       | 137/500 [04:02<09:42,  1.60s/it] 28%|██▊       | 139/500 [04:02<06:52,  1.14s/it] 28%|██▊       | 141/500 [04:15<16:02,  2.68s/it] 29%|██▊       | 143/500 [04:15<11:17,  1.90s/it] 29%|██▉       | 145/500 [04:21<13:24,  2.27s/it] 29%|██▉       | 147/500 [04:22<09:27,  1.61s/it] 30%|██▉       | 149/500 [04:22<06:41,  1.14s/it] 30%|██▉       | 149/500 [04:32<06:41,  1.14s/it] 30%|███       | 151/500 [04:34<15:43,  2.70s/it] 31%|███       | 153/500 [04:35<11:04,  1.91s/it] 31%|███       | 155/500 [04:41<13:09,  2.29s/it] 31%|███▏      | 157/500 [04:41<09:16,  1.62s/it] 32%|███▏      | 159/500 [04:41<06:34,  1.16s/it] 32%|███▏      | 159/500 [04:52<06:34,  1.16s/it] 32%|███▏      | 161/500 [04:54<15:12,  2.69s/it] 33%|███▎      | 163/500 [04:54<10:42,  1.91s/it] 33%|███▎      | 165/500 [05:00<12:41,  2.27s/it] 33%|███▎      | 167/500 [05:00<08:56,  1.61s/it] 34%|███▍      | 169/500 [05:00<06:20,  1.15s/it] 34%|███▍      | 169/500 [05:12<06:20,  1.15s/it] 34%|███▍      | 171/500 [05:13<14:38,  2.67s/it] 35%|███▍      | 173/500 [05:13<10:18,  1.89s/it] 35%|███▌      | 175/500 [05:19<12:19,  2.28s/it] 35%|███▌      | 177/500 [05:19<08:41,  1.62s/it] 36%|███▌      | 179/500 [05:20<06:11,  1.16s/it] 36%|███▌      | 181/500 [05:32<14:13,  2.68s/it]0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  124  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  125  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  127  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  128  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  129  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  130  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  132  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  133  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  134  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  135  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  137  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  138  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  139  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  140  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  142  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  143  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  144  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  145  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  147  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  148  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  149  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  150  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  152  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495085000992
Epoch:  153  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  154  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  155  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  157  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  158  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  159  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  160  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  162  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  163  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  164  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  165  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  167  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  168  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495085000992
Epoch:  169  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  170  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  172  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  173  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  174  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  175  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  177  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  178  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  179  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  180  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  182  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
 37%|███▋      | 183/500 [05:32<10:00,  1.89s/it] 37%|███▋      | 185/500 [05:38<11:56,  2.27s/it] 37%|███▋      | 187/500 [05:39<08:24,  1.61s/it] 38%|███▊      | 189/500 [05:39<05:57,  1.15s/it] 38%|███▊      | 191/500 [05:51<13:44,  2.67s/it] 39%|███▊      | 193/500 [05:51<09:40,  1.89s/it] 39%|███▉      | 195/500 [05:58<11:29,  2.26s/it] 39%|███▉      | 197/500 [05:58<08:06,  1.60s/it] 40%|███▉      | 199/500 [05:58<05:43,  1.14s/it] 40%|████      | 201/500 [06:10<13:14,  2.66s/it] 41%|████      | 203/500 [06:10<09:18,  1.88s/it] 41%|████      | 205/500 [06:17<11:02,  2.25s/it] 41%|████▏     | 207/500 [06:17<07:47,  1.59s/it] 42%|████▏     | 209/500 [06:17<05:30,  1.14s/it] 42%|████▏     | 211/500 [06:29<12:47,  2.66s/it] 43%|████▎     | 213/500 [06:29<08:59,  1.88s/it] 43%|████▎     | 215/500 [06:36<10:42,  2.25s/it] 43%|████▎     | 217/500 [06:36<07:32,  1.60s/it] 44%|████▍     | 219/500 [06:36<05:20,  1.14s/it] 44%|████▍     | 221/500 [06:48<12:22,  2.66s/it] 45%|████▍     | 223/500 [06:49<08:42,  1.88s/it] 45%|████▌     | 225/500 [06:55<10:21,  2.26s/it] 45%|████▌     | 227/500 [06:55<07:17,  1.60s/it] 46%|████▌     | 229/500 [06:55<05:09,  1.14s/it] 46%|████▌     | 231/500 [07:07<11:52,  2.65s/it] 47%|████▋     | 233/500 [07:08<08:21,  1.88s/it] 47%|████▋     | 235/500 [07:14<09:56,  2.25s/it] 47%|████▋     | 237/500 [07:14<07:00,  1.60s/it] 48%|████▊     | 239/500 [07:14<04:57,  1.14s/it] 48%|████▊     | 241/500 [07:20<07:34,  1.75s/it]Valid Loss:  0.11747495085000992
Epoch:  183  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  184  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  185  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  187  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  188  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  189  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  190  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  192  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  193  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  194  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  195  	Training Loss: 0.11970580369234085
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  197  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  198  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495830059052
Epoch:  199  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495830059052
Epoch:  200  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  202  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  203  	Training Loss: 0.11970581114292145
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495085000992
Epoch:  204  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  205  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  207  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  208  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  209  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  210  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  212  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  213  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  214  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  215  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  217  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  218  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  219  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  220  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  222  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  223  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  224  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  225  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  227  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  228  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  229  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  230  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  232  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  233  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  234  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  235  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  237  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  238  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  239  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  240  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  241  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  242  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052 49%|████▊     | 243/500 [07:21<05:21,  1.25s/it] 49%|████▉     | 245/500 [07:27<07:43,  1.82s/it] 49%|████▉     | 247/500 [07:27<05:27,  1.29s/it] 50%|████▉     | 249/500 [07:27<03:52,  1.08it/s] 50%|█████     | 251/500 [07:40<10:27,  2.52s/it] 51%|█████     | 253/500 [07:40<07:20,  1.78s/it] 51%|█████     | 255/500 [07:46<08:57,  2.20s/it] 51%|█████▏    | 257/500 [07:46<06:18,  1.56s/it] 52%|█████▏    | 259/500 [07:46<04:27,  1.11s/it] 52%|█████▏    | 261/500 [07:59<10:34,  2.66s/it] 53%|█████▎    | 263/500 [07:59<07:25,  1.88s/it] 53%|█████▎    | 265/500 [08:05<08:50,  2.26s/it] 53%|█████▎    | 267/500 [08:05<06:12,  1.60s/it] 54%|█████▍    | 269/500 [08:06<04:23,  1.14s/it] 54%|█████▍    | 271/500 [08:18<10:13,  2.68s/it] 55%|█████▍    | 273/500 [08:18<07:10,  1.90s/it] 55%|█████▌    | 275/500 [08:25<08:31,  2.27s/it] 55%|█████▌    | 277/500 [08:25<05:59,  1.61s/it] 56%|█████▌    | 279/500 [08:25<04:13,  1.15s/it] 56%|█████▌    | 281/500 [08:37<09:48,  2.69s/it] 57%|█████▋    | 283/500 [08:38<06:52,  1.90s/it] 57%|█████▋    | 285/500 [08:44<08:07,  2.27s/it] 57%|█████▋    | 287/500 [08:44<05:43,  1.61s/it] 58%|█████▊    | 289/500 [08:44<04:02,  1.15s/it] 58%|█████▊    | 291/500 [08:57<09:19,  2.68s/it] 59%|█████▊    | 293/500 [08:57<06:32,  1.90s/it] 59%|█████▉    | 295/500 [09:03<07:46,  2.28s/it] 59%|█████▉    | 297/500 [09:03<05:27,  1.61s/it] 60%|█████▉    | 299/500 [09:03<03:51,  1.15s/it] 60%|██████    | 301/500 [09:16<08:50,  2.67s/it]
Epoch:  243  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  244  	Training Loss: 0.11970581114292145
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495085000992
Epoch:  245  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  247  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  248  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  249  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  250  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  252  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  253  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  254  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  255  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  257  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  258  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  259  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  260  	Training Loss: 0.11970581114292145
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  262  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495085000992
Epoch:  263  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  264  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  265  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  267  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  268  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  269  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  270  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  272  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  273  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  274  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  275  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  277  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  278  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  279  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  280  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  282  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  283  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  284  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  285  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  287  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  288  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495085000992
Epoch:  289  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  290  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  292  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  293  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  294  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  295  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  297  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  298  	Training Loss: 0.11970581114292145
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  299  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  300  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
 61%|██████    | 303/500 [09:16<06:11,  1.89s/it] 61%|██████    | 305/500 [09:16<04:21,  1.34s/it] 61%|██████▏   | 307/500 [09:16<03:04,  1.04it/s] 62%|██████▏   | 309/500 [09:16<02:11,  1.45it/s] 62%|██████▏   | 311/500 [09:29<07:21,  2.34s/it] 63%|██████▎   | 313/500 [09:29<05:09,  1.66s/it] 63%|██████▎   | 315/500 [09:35<06:31,  2.12s/it] 63%|██████▎   | 317/500 [09:35<04:35,  1.50s/it] 64%|██████▍   | 319/500 [09:35<03:14,  1.07s/it] 64%|██████▍   | 321/500 [09:48<07:49,  2.62s/it] 65%|██████▍   | 323/500 [09:48<05:29,  1.86s/it] 65%|██████▌   | 325/500 [09:54<06:31,  2.24s/it] 65%|██████▌   | 327/500 [09:54<04:34,  1.59s/it] 66%|██████▌   | 329/500 [09:55<03:13,  1.13s/it] 66%|██████▌   | 331/500 [10:07<07:28,  2.65s/it] 67%|██████▋   | 333/500 [10:07<05:13,  1.88s/it] 67%|██████▋   | 335/500 [10:13<06:11,  2.25s/it] 67%|██████▋   | 337/500 [10:14<04:20,  1.60s/it] 68%|██████▊   | 339/500 [10:14<03:03,  1.14s/it] 68%|██████▊   | 341/500 [10:26<07:02,  2.66s/it] 69%|██████▊   | 343/500 [10:26<04:55,  1.88s/it] 69%|██████▉   | 345/500 [10:32<05:47,  2.24s/it] 69%|██████▉   | 347/500 [10:33<04:03,  1.59s/it] 70%|██████▉   | 349/500 [10:33<02:51,  1.13s/it] 70%|███████   | 351/500 [10:45<06:35,  2.65s/it] 71%|███████   | 353/500 [10:45<04:36,  1.88s/it] 71%|███████   | 355/500 [10:51<05:26,  2.25s/it] 71%|███████▏  | 357/500 [10:52<03:48,  1.60s/it] 72%|███████▏  | 359/500 [10:52<02:40,  1.14s/it] 72%|███████▏  | 359/500 [11:02<02:40,  1.14s/it] 72%|███████▏  | 361/500 [11:04<06:09,  2.66s/it]Epoch:  302  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  303  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  304  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  305  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  306  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  307  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  308  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495085000992
Epoch:  309  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  310  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  312  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  313  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  314  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  315  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  317  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  318  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  319  	Training Loss: 0.11970581114292145
Test Loss:  0.11638683825731277
Valid Loss:  0.11747495085000992
Epoch:  320  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  322  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  323  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  324  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  325  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  327  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  328  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  329  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  330  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  332  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  333  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  334  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  335  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  337  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  338  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  339  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  340  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  342  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  343  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  344  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  345  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  347  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  348  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  349  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  350  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  352  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  353  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  354  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  355  	Training Loss: 0.11970581114292145
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  357  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  358  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  359  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  360  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
 73%|███████▎  | 363/500 [11:04<04:17,  1.88s/it] 73%|███████▎  | 365/500 [11:11<05:06,  2.27s/it] 73%|███████▎  | 367/500 [11:11<03:34,  1.61s/it] 74%|███████▍  | 369/500 [11:11<02:30,  1.15s/it] 74%|███████▍  | 369/500 [11:22<02:30,  1.15s/it] 74%|███████▍  | 371/500 [11:23<05:43,  2.66s/it] 75%|███████▍  | 373/500 [11:23<03:59,  1.88s/it] 75%|███████▌  | 375/500 [11:30<04:42,  2.26s/it] 75%|███████▌  | 377/500 [11:30<03:17,  1.60s/it] 76%|███████▌  | 379/500 [11:30<02:18,  1.14s/it] 76%|███████▌  | 381/500 [11:42<05:15,  2.65s/it] 77%|███████▋  | 383/500 [11:42<03:39,  1.88s/it] 77%|███████▋  | 385/500 [11:49<04:20,  2.26s/it] 77%|███████▋  | 387/500 [11:49<03:01,  1.60s/it] 78%|███████▊  | 389/500 [11:49<02:06,  1.14s/it] 78%|███████▊  | 391/500 [12:02<04:51,  2.67s/it] 79%|███████▊  | 393/500 [12:02<03:22,  1.89s/it] 79%|███████▉  | 395/500 [12:08<03:57,  2.26s/it] 79%|███████▉  | 397/500 [12:08<02:45,  1.61s/it] 80%|███████▉  | 399/500 [12:08<01:55,  1.14s/it] 80%|████████  | 401/500 [12:21<04:23,  2.66s/it] 81%|████████  | 403/500 [12:21<03:02,  1.88s/it] 81%|████████  | 405/500 [12:27<03:35,  2.26s/it] 81%|████████▏ | 407/500 [12:27<02:29,  1.61s/it] 82%|████████▏ | 409/500 [12:27<01:44,  1.14s/it] 82%|████████▏ | 411/500 [12:40<03:57,  2.67s/it] 83%|████████▎ | 413/500 [12:40<02:44,  1.89s/it] 83%|████████▎ | 415/500 [12:46<03:13,  2.27s/it] 83%|████████▎ | 417/500 [12:46<02:13,  1.61s/it] 84%|████████▍ | 419/500 [12:47<01:32,  1.15s/it]Epoch:  362  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  363  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  364  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  365  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  367  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  368  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  369  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  370  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  372  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  373  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  374  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  375  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  377  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  378  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  379  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  380  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  382  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  383  	Training Loss: 0.11970581114292145
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495085000992
Epoch:  384  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  385  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495085000992
Epoch:  387  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  388  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  389  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  390  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  392  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  393  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  394  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  395  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  397  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  398  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  399  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  400  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  402  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  403  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  404  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  405  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  407  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  408  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  409  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  410  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  412  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  413  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  414  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  415  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  417  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  418  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  419  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  420  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
 84%|████████▍ | 421/500 [12:59<03:31,  2.68s/it] 85%|████████▍ | 423/500 [12:59<02:26,  1.90s/it] 85%|████████▌ | 425/500 [13:05<02:49,  2.26s/it] 85%|████████▌ | 427/500 [13:06<01:57,  1.60s/it] 86%|████████▌ | 429/500 [13:06<01:21,  1.14s/it] 86%|████████▌ | 431/500 [13:18<03:03,  2.66s/it] 87%|████████▋ | 433/500 [13:18<02:06,  1.88s/it] 87%|████████▋ | 435/500 [13:24<02:26,  2.25s/it] 87%|████████▋ | 437/500 [13:25<01:40,  1.60s/it] 88%|████████▊ | 439/500 [13:25<01:09,  1.14s/it] 88%|████████▊ | 441/500 [13:37<02:36,  2.65s/it] 89%|████████▊ | 443/500 [13:37<01:47,  1.88s/it] 89%|████████▉ | 445/500 [13:44<02:04,  2.26s/it] 89%|████████▉ | 447/500 [13:44<01:25,  1.61s/it] 90%|████████▉ | 449/500 [13:44<00:58,  1.14s/it] 90%|█████████ | 451/500 [13:56<02:10,  2.67s/it] 91%|█████████ | 453/500 [13:56<01:28,  1.89s/it] 91%|█████████ | 455/500 [14:03<01:42,  2.27s/it] 91%|█████████▏| 457/500 [14:03<01:09,  1.61s/it] 92%|█████████▏| 459/500 [14:03<00:47,  1.15s/it] 92%|█████████▏| 461/500 [14:15<01:43,  2.65s/it] 93%|█████████▎| 463/500 [14:16<01:09,  1.88s/it] 93%|█████████▎| 465/500 [14:22<01:18,  2.25s/it] 93%|█████████▎| 467/500 [14:22<00:52,  1.60s/it] 94%|█████████▍| 469/500 [14:22<00:35,  1.14s/it] 94%|█████████▍| 469/500 [14:32<00:35,  1.14s/it] 94%|█████████▍| 471/500 [14:35<01:17,  2.69s/it] 95%|█████████▍| 473/500 [14:35<00:51,  1.90s/it] 95%|█████████▌| 475/500 [14:41<00:57,  2.28s/it] 95%|█████████▌| 477/500 [14:41<00:37,  1.62s/it] 96%|█████████▌| 479/500 [14:41<00:24,  1.15s/it]Epoch:  421  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  422  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  423  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  424  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  425  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  427  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  428  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  429  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  430  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  432  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  433  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  434  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  435  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  437  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  438  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  439  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  440  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.11970581114292145
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  442  	Training Loss: 0.11970580369234085
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
Epoch:  443  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  444  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  445  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  447  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  448  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  449  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  450  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  452  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  453  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  454  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  455  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  457  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  458  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  459  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  460  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  462  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  463  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  464  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  465  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  467  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  468  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  469  	Training Loss: 0.11970579624176025
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  470  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  472  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  473  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  474  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  475  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  477  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  478  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  479  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  480  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
 96%|█████████▌| 479/500 [14:52<00:24,  1.15s/it] 96%|█████████▌| 481/500 [14:54<00:51,  2.71s/it] 97%|█████████▋| 483/500 [14:54<00:32,  1.92s/it] 97%|█████████▋| 485/500 [15:01<00:34,  2.29s/it] 97%|█████████▋| 487/500 [15:01<00:21,  1.63s/it] 98%|█████████▊| 489/500 [15:01<00:12,  1.16s/it] 98%|█████████▊| 489/500 [15:12<00:12,  1.16s/it] 98%|█████████▊| 491/500 [15:13<00:24,  2.68s/it] 99%|█████████▊| 493/500 [15:13<00:13,  1.90s/it] 99%|█████████▉| 495/500 [15:20<00:11,  2.29s/it] 99%|█████████▉| 497/500 [15:20<00:04,  1.62s/it]100%|█████████▉| 499/500 [15:20<00:01,  1.15s/it]100%|██████████| 500/500 [15:26<00:00,  1.85s/it]
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  482  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  483  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  484  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
Epoch:  485  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  487  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  488  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  489  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  490  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  492  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  493  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  494  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  495  	Training Loss: 0.11970581114292145
Test Loss:  0.11638685315847397
Valid Loss:  0.11747495830059052
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747494339942932
Epoch:  497  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  498  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  499  	Training Loss: 0.11970581114292145
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495830059052
Epoch:  500  	Training Loss: 0.11970580369234085
Test Loss:  0.11638684570789337
Valid Loss:  0.11747495085000992
**************************************************learning rate decay**************************************************
seed is  17
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:33,  6.20s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:55,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:12<10:38,  1.31s/it]  3%|▎         | 13/500 [00:13<07:15,  1.12it/s]  3%|▎         | 15/500 [00:13<05:04,  1.59it/s]  3%|▎         | 17/500 [00:13<03:37,  2.22it/s]  4%|▍         | 19/500 [00:13<02:40,  3.01it/s]  4%|▍         | 21/500 [00:19<09:34,  1.20s/it]  5%|▍         | 23/500 [00:19<06:48,  1.17it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.22it/s]  6%|▌         | 29/500 [00:20<02:37,  2.99it/s]  6%|▌         | 31/500 [00:26<09:16,  1.19s/it]  7%|▋         | 33/500 [00:26<06:37,  1.17it/s]  7%|▋         | 35/500 [00:26<04:46,  1.62it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:33<09:04,  1.19s/it]  9%|▊         | 43/500 [00:33<06:29,  1.17it/s]  9%|▉         | 45/500 [00:33<04:40,  1.62it/s]  9%|▉         | 47/500 [00:33<03:24,  2.22it/s] 10%|▉         | 49/500 [00:34<02:31,  2.98it/s] 10%|█         | 51/500 [00:40<08:53,  1.19s/it] 11%|█         | 53/500 [00:40<06:20,  1.17it/s] 11%|█         | 55/500 [00:40<04:34,  1.62it/s] 11%|█▏        | 57/500 [00:40<03:21,  2.20it/s] 12%|█▏        | 59/500 [00:41<02:29,  2.94it/s] 12%|█▏        | 61/500 [00:47<08:35,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:09,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:26,  1.64it/s] 13%|█▎        | 67/500 [00:47<03:13,  2.23it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.97it/s]Epoch:  1  	Training Loss: 0.130367249250412
Test Loss:  0.017738137394189835
Valid Loss:  0.021756794303655624
Epoch:  2  	Training Loss: 0.020201604813337326
Test Loss:  0.013218970969319344
Valid Loss:  0.01596783846616745
Epoch:  3  	Training Loss: 0.014706360176205635
Test Loss:  0.009134361520409584
Valid Loss:  0.011225301772356033
Epoch:  4  	Training Loss: 0.010334434919059277
Test Loss:  0.006157842930406332
Valid Loss:  0.007658788003027439
Epoch:  5  	Training Loss: 0.006965236272662878
Test Loss:  0.0046854219399392605
Valid Loss:  0.005618527065962553
Epoch:  6  	Training Loss: 0.005284374579787254
Test Loss:  0.003812530543655157
Valid Loss:  0.0047963703982532024
Epoch:  7  	Training Loss: 0.0044019874185323715
Test Loss:  0.0035681664012372494
Valid Loss:  0.00399056077003479
Epoch:  8  	Training Loss: 0.003944164142012596
Test Loss:  0.003007172839716077
Valid Loss:  0.0038395863957703114
Epoch:  9  	Training Loss: 0.0035747764632105827
Test Loss:  0.003133137011900544
Valid Loss:  0.0033290726132690907
Epoch:  10  	Training Loss: 0.0034019555896520615
Test Loss:  0.0025768016930669546
Valid Loss:  0.003341780975461006
Epoch:  11  	Training Loss: 0.0031537581235170364
Test Loss:  0.0028258557431399822
Valid Loss:  0.0029184683226048946
Epoch:  12  	Training Loss: 0.0030488441698253155
Test Loss:  0.0021049422211945057
Valid Loss:  0.0027204249054193497
Epoch:  13  	Training Loss: 0.002626485889777541
Test Loss:  0.002045378554612398
Valid Loss:  0.002263264963403344
Epoch:  14  	Training Loss: 0.002344978041946888
Test Loss:  0.001709267497062683
Valid Loss:  0.002123265527188778
Epoch:  15  	Training Loss: 0.002114950679242611
Test Loss:  0.0016358576249331236
Valid Loss:  0.0019162087701261044
Epoch:  16  	Training Loss: 0.0019570523872971535
Test Loss:  0.0015080507146194577
Valid Loss:  0.0018227538093924522
Epoch:  17  	Training Loss: 0.0018494109390303493
Test Loss:  0.0014436476631090045
Valid Loss:  0.0017193546518683434
Epoch:  18  	Training Loss: 0.0017572575015947223
Test Loss:  0.0013666105223819613
Valid Loss:  0.0016387766227126122
Epoch:  19  	Training Loss: 0.00167555152438581
Test Loss:  0.0013055268209427595
Valid Loss:  0.0015623820945620537
Epoch:  20  	Training Loss: 0.0016025950899347663
Test Loss:  0.001249584718607366
Valid Loss:  0.0014952279161661863
Epoch:  21  	Training Loss: 0.0015384071739390492
Test Loss:  0.0012007278855890036
Valid Loss:  0.0014350168639793992
Epoch:  22  	Training Loss: 0.001481260871514678
Test Loss:  0.0011089572217315435
Valid Loss:  0.0013481697533279657
Epoch:  23  	Training Loss: 0.0013946662656962872
Test Loss:  0.0010342792375013232
Valid Loss:  0.0012579333269968629
Epoch:  24  	Training Loss: 0.001311696134507656
Test Loss:  0.0009773601777851582
Valid Loss:  0.0011649971129372716
Epoch:  25  	Training Loss: 0.0012328927405178547
Test Loss:  0.0009072881657630205
Valid Loss:  0.0010854024440050125
Epoch:  26  	Training Loss: 0.0011589702917262912
Test Loss:  0.0008570380159653723
Valid Loss:  0.0010172887705266476
Epoch:  27  	Training Loss: 0.001097112544812262
Test Loss:  0.0008127053733915091
Valid Loss:  0.000968825479503721
Epoch:  28  	Training Loss: 0.0010507048573344946
Test Loss:  0.0007857984164729714
Valid Loss:  0.0009346427395939827
Epoch:  29  	Training Loss: 0.0010163248516619205
Test Loss:  0.0007611714536324143
Valid Loss:  0.0009103072807192802
Epoch:  30  	Training Loss: 0.0009933734545484185
Test Loss:  0.0007425853982567787
Valid Loss:  0.0008920185500755906
Epoch:  31  	Training Loss: 0.0009762863628566265
Test Loss:  0.000729671330191195
Valid Loss:  0.0008783524390310049
Epoch:  32  	Training Loss: 0.0009624760132282972
Test Loss:  0.0007298027048818767
Valid Loss:  0.0008678218582645059
Epoch:  33  	Training Loss: 0.0009530989918857813
Test Loss:  0.0007166191353462636
Valid Loss:  0.0008456712821498513
Epoch:  34  	Training Loss: 0.0009317852091044188
Test Loss:  0.0006953300326131284
Valid Loss:  0.0008189409272745252
Epoch:  35  	Training Loss: 0.0009047454805113375
Test Loss:  0.0006928108632564545
Valid Loss:  0.0008118230616673827
Epoch:  36  	Training Loss: 0.0008978871628642082
Test Loss:  0.0006889307987876236
Valid Loss:  0.0008111967472359538
Epoch:  37  	Training Loss: 0.0008957133977673948
Test Loss:  0.0006885866168886423
Valid Loss:  0.0008107557659968734
Epoch:  38  	Training Loss: 0.0008944808505475521
Test Loss:  0.0006888544885441661
Valid Loss:  0.0008101571584120393
Epoch:  39  	Training Loss: 0.0008933328208513558
Test Loss:  0.0006889897049404681
Valid Loss:  0.0008097820682451129
Epoch:  40  	Training Loss: 0.0008923857240006328
Test Loss:  0.0006913768593221903
Valid Loss:  0.000808723212685436
Epoch:  41  	Training Loss: 0.0008915680227801204
Test Loss:  0.0006895925616845489
Valid Loss:  0.0008087243186309934
Epoch:  42  	Training Loss: 0.0008908428135327995
Test Loss:  0.0006582853966392577
Valid Loss:  0.0007895226590335369
Epoch:  43  	Training Loss: 0.0008661504834890366
Test Loss:  0.0006347361486405134
Valid Loss:  0.0007523501990363002
Epoch:  44  	Training Loss: 0.0008306414820253849
Test Loss:  0.000613851472735405
Valid Loss:  0.0007432513521052897
Epoch:  45  	Training Loss: 0.0008153558010235429
Test Loss:  0.0006046993657946587
Valid Loss:  0.0007290011271834373
Epoch:  46  	Training Loss: 0.0007996883941814303
Test Loss:  0.000591952120885253
Valid Loss:  0.0007136834319680929
Epoch:  47  	Training Loss: 0.0007837058510631323
Test Loss:  0.0005810812581330538
Valid Loss:  0.0006980913458392024
Epoch:  48  	Training Loss: 0.0007680375128984451
Test Loss:  0.0005687684752047062
Valid Loss:  0.0006833004881627858
Epoch:  49  	Training Loss: 0.0007530278526246548
Test Loss:  0.0005577634437941015
Valid Loss:  0.000669140717945993
Epoch:  50  	Training Loss: 0.0007392294937744737
Test Loss:  0.0005464107962325215
Valid Loss:  0.0006570686236955225
Epoch:  51  	Training Loss: 0.0007266107713803649
Test Loss:  0.0005378090427257121
Valid Loss:  0.0006467061466537416
Epoch:  52  	Training Loss: 0.0007157786167226732
Test Loss:  0.000503380608279258
Valid Loss:  0.0006101499311625957
Epoch:  53  	Training Loss: 0.0006787112215533853
Test Loss:  0.00047744368202984333
Valid Loss:  0.0005796445184387267
Epoch:  54  	Training Loss: 0.0006485111080110073
Test Loss:  0.0004550186567939818
Valid Loss:  0.0005539691774174571
Epoch:  55  	Training Loss: 0.0006226683617569506
Test Loss:  0.00043517560698091984
Valid Loss:  0.0005339282797649503
Epoch:  56  	Training Loss: 0.0006012764060869813
Test Loss:  0.00041975599015131593
Valid Loss:  0.000519132474437356
Epoch:  57  	Training Loss: 0.0005844136467203498
Test Loss:  0.0004066133697051555
Valid Loss:  0.000506732554640621
Epoch:  58  	Training Loss: 0.0005708266980946064
Test Loss:  0.00039531977381557226
Valid Loss:  0.0004959928337484598
Epoch:  59  	Training Loss: 0.0005595467519015074
Test Loss:  0.00038556469371542335
Valid Loss:  0.0004864088259637356
Epoch:  60  	Training Loss: 0.0005494941142387688
Test Loss:  0.00037685691495426
Valid Loss:  0.00047788527444936335
Epoch:  61  	Training Loss: 0.0005404244875535369
Test Loss:  0.0003694033657666296
Valid Loss:  0.0004698192933574319
Epoch:  62  	Training Loss: 0.0005318754119798541
Test Loss:  0.0003611152060329914
Valid Loss:  0.00046686234418302774
Epoch:  63  	Training Loss: 0.0005274824216030538
Test Loss:  0.0003645189863163978
Valid Loss:  0.00046289488091133535
Epoch:  64  	Training Loss: 0.0005245697102509439
Test Loss:  0.00035810796543955803
Valid Loss:  0.00046308519085869193
Epoch:  65  	Training Loss: 0.000522494490724057
Test Loss:  0.0003645132528617978
Valid Loss:  0.0004603776033036411
Epoch:  66  	Training Loss: 0.0005213449476286769
Test Loss:  0.0003562059428077191
Valid Loss:  0.0004620924883056432
Epoch:  67  	Training Loss: 0.0005204392946325243
Test Loss:  0.0003645110409706831
Valid Loss:  0.00045924968435429037
Epoch:  68  	Training Loss: 0.0005196407437324524
Test Loss:  0.00035433797165751457
Valid Loss:  0.00046151186688803136
Epoch:  69  	Training Loss: 0.0005190121592022479
Test Loss:  0.0003650007420219481
Valid Loss:  0.00045831286115571856
 14%|█▍        | 71/500 [00:54<08:23,  1.17s/it] 15%|█▍        | 73/500 [00:54<06:00,  1.19it/s] 15%|█▌        | 75/500 [00:54<04:19,  1.64it/s] 15%|█▌        | 77/500 [00:54<03:09,  2.24it/s] 16%|█▌        | 79/500 [00:54<02:20,  3.00it/s] 16%|█▌        | 81/500 [01:00<08:07,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:48,  1.20it/s] 17%|█▋        | 85/500 [01:01<04:11,  1.65it/s] 17%|█▋        | 87/500 [01:01<03:02,  2.26it/s] 18%|█▊        | 89/500 [01:01<02:15,  3.04it/s] 18%|█▊        | 91/500 [01:07<07:58,  1.17s/it] 19%|█▊        | 93/500 [01:07<05:41,  1.19it/s] 19%|█▉        | 95/500 [01:07<04:05,  1.65it/s] 19%|█▉        | 97/500 [01:08<02:59,  2.25it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:47,  1.17s/it] 21%|██        | 103/500 [01:14<05:34,  1.19it/s] 21%|██        | 105/500 [01:14<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:14<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:14<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:21<07:42,  1.19s/it] 23%|██▎       | 113/500 [01:21<05:30,  1.17it/s] 23%|██▎       | 115/500 [01:21<03:57,  1.62it/s] 23%|██▎       | 117/500 [01:21<02:52,  2.21it/s] 24%|██▍       | 119/500 [01:21<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:28<07:27,  1.18s/it] 25%|██▍       | 123/500 [01:28<05:19,  1.18it/s] 25%|██▌       | 125/500 [01:28<03:50,  1.63it/s] 25%|██▌       | 127/500 [01:28<02:47,  2.23it/s] 26%|██▌       | 129/500 [01:28<02:04,  2.99it/s] 26%|██▌       | 131/500 [01:35<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:10,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:43,  1.63it/s]Epoch:  70  	Training Loss: 0.0005183614557608962
Test Loss:  0.0003538086311891675
Valid Loss:  0.00046085420763120055
Epoch:  71  	Training Loss: 0.0005177863058634102
Test Loss:  0.0003646191325969994
Valid Loss:  0.0004575903294607997
Epoch:  72  	Training Loss: 0.0005172733217477798
Test Loss:  0.00035537840449251235
Valid Loss:  0.00045409303857013583
Epoch:  73  	Training Loss: 0.000513568171299994
Test Loss:  0.00035271618980914354
Valid Loss:  0.00045080084237270057
Epoch:  74  	Training Loss: 0.0005106533062644303
Test Loss:  0.0003501240280456841
Valid Loss:  0.00044828036334365606
Epoch:  75  	Training Loss: 0.0005083243013359606
Test Loss:  0.00034843996400013566
Valid Loss:  0.000446149060735479
Epoch:  76  	Training Loss: 0.0005063706776127219
Test Loss:  0.00034660036908462644
Valid Loss:  0.00044451194116845727
Epoch:  77  	Training Loss: 0.0005047807935625315
Test Loss:  0.00034522503847256303
Valid Loss:  0.00044306000927463174
Epoch:  78  	Training Loss: 0.0005033825291320682
Test Loss:  0.0003439270658418536
Valid Loss:  0.00044176517985761166
Epoch:  79  	Training Loss: 0.0005021088290959597
Test Loss:  0.000342823623213917
Valid Loss:  0.00044064444955438375
Epoch:  80  	Training Loss: 0.00050095294136554
Test Loss:  0.0003420087741687894
Valid Loss:  0.00043973163701593876
Epoch:  81  	Training Loss: 0.0004998603835701942
Test Loss:  0.0003413302474655211
Valid Loss:  0.00043884656042791903
Epoch:  82  	Training Loss: 0.0004988021682947874
Test Loss:  0.0003272448666393757
Valid Loss:  0.00043411730439402163
Epoch:  83  	Training Loss: 0.0004924607928842306
Test Loss:  0.0003400843415874988
Valid Loss:  0.0004284416208975017
Epoch:  84  	Training Loss: 0.0004868700634688139
Test Loss:  0.00032416850444860756
Valid Loss:  0.0004247328033670783
Epoch:  85  	Training Loss: 0.00048176164273172617
Test Loss:  0.0003291627508588135
Valid Loss:  0.0004212399653624743
Epoch:  86  	Training Loss: 0.0004773630644194782
Test Loss:  0.0003201751969754696
Valid Loss:  0.00041826223605312407
Epoch:  87  	Training Loss: 0.0004733894602395594
Test Loss:  0.000321076950058341
Valid Loss:  0.0004153352347202599
Epoch:  88  	Training Loss: 0.0004698334669228643
Test Loss:  0.0003163971705362201
Valid Loss:  0.0004127211286686361
Epoch:  89  	Training Loss: 0.0004665298038162291
Test Loss:  0.0003154675359837711
Valid Loss:  0.00041012937435880303
Epoch:  90  	Training Loss: 0.00046339689288288355
Test Loss:  0.00031239690724760294
Valid Loss:  0.0004076950717717409
Epoch:  91  	Training Loss: 0.00046037998981773853
Test Loss:  0.00031071461853571236
Valid Loss:  0.00040521976188756526
Epoch:  92  	Training Loss: 0.00045740901259705424
Test Loss:  0.000299909122986719
Valid Loss:  0.0004001556371804327
Epoch:  93  	Training Loss: 0.0004505454853642732
Test Loss:  0.0002983568119816482
Valid Loss:  0.0003947665973100811
Epoch:  94  	Training Loss: 0.0004447176761459559
Test Loss:  0.00029373675351962447
Valid Loss:  0.0003903824253939092
Epoch:  95  	Training Loss: 0.000439726107288152
Test Loss:  0.000290514319203794
Valid Loss:  0.0003861121949739754
Epoch:  96  	Training Loss: 0.0004351100360509008
Test Loss:  0.00028770900098606944
Valid Loss:  0.00038203276926651597
Epoch:  97  	Training Loss: 0.0004308318020775914
Test Loss:  0.00028434820706024766
Valid Loss:  0.00037826187326572835
Epoch:  98  	Training Loss: 0.00042686768574640155
Test Loss:  0.00028224787092767656
Valid Loss:  0.0003746350994333625
Epoch:  99  	Training Loss: 0.00042323709931224585
Test Loss:  0.0002784889074973762
Valid Loss:  0.00037139299092814326
Epoch:  100  	Training Loss: 0.00041986029827967286
Test Loss:  0.00027692041476257145
Valid Loss:  0.0003681987873278558
Epoch:  101  	Training Loss: 0.00041668349876999855
Test Loss:  0.0002740685595199466
Valid Loss:  0.00036520540015771985
Epoch:  102  	Training Loss: 0.0004137182841077447
Test Loss:  0.00027289011632092297
Valid Loss:  0.00036246690433472395
Epoch:  103  	Training Loss: 0.00041139108361676335
Test Loss:  0.00027060540742240846
Valid Loss:  0.0003602392098400742
Epoch:  104  	Training Loss: 0.00040936697041615844
Test Loss:  0.00026890801382251084
Valid Loss:  0.00035833491710945964
Epoch:  105  	Training Loss: 0.0004075600882060826
Test Loss:  0.00026751108816824853
Valid Loss:  0.0003565387160051614
Epoch:  106  	Training Loss: 0.0004058906633872539
Test Loss:  0.00026612146757543087
Valid Loss:  0.0003549683024175465
Epoch:  107  	Training Loss: 0.00040437348070554435
Test Loss:  0.0002648418885655701
Valid Loss:  0.00035356241278350353
Epoch:  108  	Training Loss: 0.0004029706178698689
Test Loss:  0.00026363341021351516
Valid Loss:  0.00035225291503593326
Epoch:  109  	Training Loss: 0.00040162552613765
Test Loss:  0.0002625346533022821
Valid Loss:  0.00035105127608403563
Epoch:  110  	Training Loss: 0.0004003560170531273
Test Loss:  0.0002615197445265949
Valid Loss:  0.00034994707675650716
Epoch:  111  	Training Loss: 0.0003991496632806957
Test Loss:  0.00026055629132315516
Valid Loss:  0.0003488916845526546
Epoch:  112  	Training Loss: 0.00039798987563699484
Test Loss:  0.00025232540792785585
Valid Loss:  0.0003420270513743162
Epoch:  113  	Training Loss: 0.0003905564663000405
Test Loss:  0.0002452282060403377
Valid Loss:  0.00033504958264529705
Epoch:  114  	Training Loss: 0.00038338324520736933
Test Loss:  0.00024256500182673335
Valid Loss:  0.0003313517663627863
Epoch:  115  	Training Loss: 0.00037940312176942825
Test Loss:  0.00024054027744568884
Valid Loss:  0.00032847822876647115
Epoch:  116  	Training Loss: 0.00037624454125761986
Test Loss:  0.00023767133825458586
Valid Loss:  0.0003258440119680017
Epoch:  117  	Training Loss: 0.00037331966450437903
Test Loss:  0.00023583532311022282
Valid Loss:  0.00032341087353415787
Epoch:  118  	Training Loss: 0.00037060939939692616
Test Loss:  0.00023364493972621858
Valid Loss:  0.0003211506991647184
Epoch:  119  	Training Loss: 0.00036811750032939017
Test Loss:  0.0002320473431609571
Valid Loss:  0.00031900766771286726
Epoch:  120  	Training Loss: 0.00036577030550688505
Test Loss:  0.00023033286561258137
Valid Loss:  0.00031694714562036097
Epoch:  121  	Training Loss: 0.0003635269240476191
Test Loss:  0.00022884210920892656
Valid Loss:  0.00031499131000600755
Epoch:  122  	Training Loss: 0.00036138639552518725
Test Loss:  0.00023024409892968833
Valid Loss:  0.000314570585032925
Epoch:  123  	Training Loss: 0.0003603890654630959
Test Loss:  0.0002290143456775695
Valid Loss:  0.0003141070483252406
Epoch:  124  	Training Loss: 0.00035944528644904494
Test Loss:  0.00022901917691342533
Valid Loss:  0.0003136764862574637
Epoch:  125  	Training Loss: 0.0003585391095839441
Test Loss:  0.00022854501730762422
Valid Loss:  0.00031325293821282685
Epoch:  126  	Training Loss: 0.00035766977816820145
Test Loss:  0.0002283174981130287
Valid Loss:  0.0003128668759018183
Epoch:  127  	Training Loss: 0.00035683513851836324
Test Loss:  0.00022797432029619813
Valid Loss:  0.00031249760650098324
Epoch:  128  	Training Loss: 0.00035603903234004974
Test Loss:  0.00022770860232412815
Valid Loss:  0.0003121321205981076
Epoch:  129  	Training Loss: 0.00035527150612324476
Test Loss:  0.00022745026217307895
Valid Loss:  0.0003117650921922177
Epoch:  130  	Training Loss: 0.0003545329673215747
Test Loss:  0.00022712061763741076
Valid Loss:  0.00031145557295531034
Epoch:  131  	Training Loss: 0.0003538398595992476
Test Loss:  0.00022693183564115316
Valid Loss:  0.0003111567348241806
Epoch:  132  	Training Loss: 0.0003531737602315843
Test Loss:  0.0002244289789814502
Valid Loss:  0.00030885072192177176
Epoch:  133  	Training Loss: 0.0003505586937535554
Test Loss:  0.0002227450313512236
Valid Loss:  0.0003067472134716809
Epoch:  134  	Training Loss: 0.0003481625462882221
Test Loss:  0.00022114627063274384
Valid Loss:  0.00030470825731754303
Epoch:  135  	Training Loss: 0.00034589917049743235
Test Loss:  0.0002196076966356486
Valid Loss:  0.00030272064032033086
Epoch:  136  	Training Loss: 0.0003437509876675904
Test Loss:  0.00021809476311318576
Valid Loss:  0.0003007942286785692
Epoch:  137  	Training Loss: 0.00034170097205787897
Test Loss:  0.00021662793005816638
 27%|██▋       | 137/500 [01:35<02:43,  2.22it/s] 28%|██▊       | 139/500 [01:35<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:41<07:03,  1.18s/it] 29%|██▊       | 143/500 [01:42<05:02,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:42<01:57,  2.99it/s] 30%|███       | 151/500 [01:48<06:47,  1.17s/it] 31%|███       | 153/500 [01:48<04:51,  1.19it/s] 31%|███       | 155/500 [01:48<03:29,  1.65it/s] 31%|███▏      | 157/500 [01:49<02:32,  2.25it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.02it/s] 32%|███▏      | 161/500 [01:55<06:35,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:43,  1.19it/s] 33%|███▎      | 165/500 [01:55<03:23,  1.64it/s] 33%|███▎      | 167/500 [01:55<02:28,  2.25it/s] 34%|███▍      | 169/500 [01:55<01:49,  3.02it/s] 34%|███▍      | 171/500 [02:02<06:23,  1.17s/it] 35%|███▍      | 173/500 [02:02<04:34,  1.19it/s] 35%|███▌      | 175/500 [02:02<03:17,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:23,  2.24it/s] 36%|███▌      | 179/500 [02:02<01:46,  3.01it/s] 36%|███▌      | 181/500 [02:09<06:19,  1.19s/it] 37%|███▋      | 183/500 [02:09<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:09<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:09<02:21,  2.21it/s] 38%|███▊      | 189/500 [02:09<01:44,  2.96it/s] 38%|███▊      | 191/500 [02:15<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:16<04:18,  1.19it/s] 39%|███▉      | 195/500 [02:16<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  2.98it/s] 40%|████      | 201/500 [02:22<05:49,  1.17s/it] 41%|████      | 203/500 [02:22<04:10,  1.19it/s]Valid Loss:  0.0002989077183883637
Epoch:  138  	Training Loss: 0.00033972732489928603
Test Loss:  0.0002151688386220485
Valid Loss:  0.00029706850182265043
Epoch:  139  	Training Loss: 0.0003378294932190329
Test Loss:  0.00021379668032750487
Valid Loss:  0.00029529526364058256
Epoch:  140  	Training Loss: 0.000335999415256083
Test Loss:  0.0002124490711139515
Valid Loss:  0.0002935625670943409
Epoch:  141  	Training Loss: 0.00033422926208004355
Test Loss:  0.00021114395349286497
Valid Loss:  0.00029185478342697024
Epoch:  142  	Training Loss: 0.00033250468550249934
Test Loss:  0.00021072641538921744
Valid Loss:  0.00029012636514380574
Epoch:  143  	Training Loss: 0.0003308185550849885
Test Loss:  0.00020865793339908123
Valid Loss:  0.0002884492860175669
Epoch:  144  	Training Loss: 0.0003291866451036185
Test Loss:  0.00020809631678275764
Valid Loss:  0.0002869896707125008
Epoch:  145  	Training Loss: 0.00032758997986093163
Test Loss:  0.00020649963698815554
Valid Loss:  0.00028552653384394944
Epoch:  146  	Training Loss: 0.00032601371640339494
Test Loss:  0.00020580212003551424
Valid Loss:  0.0002841847308445722
Epoch:  147  	Training Loss: 0.00032445398392155766
Test Loss:  0.00020446450798772275
Valid Loss:  0.0002828288124874234
Epoch:  148  	Training Loss: 0.0003229073772672564
Test Loss:  0.00020367107936181128
Valid Loss:  0.0002815457119140774
Epoch:  149  	Training Loss: 0.0003213759628124535
Test Loss:  0.00020248979853931814
Valid Loss:  0.0002802531234920025
Epoch:  150  	Training Loss: 0.0003198572085238993
Test Loss:  0.00020164682064205408
Valid Loss:  0.00027900285203941166
Epoch:  151  	Training Loss: 0.0003183490480296314
Test Loss:  0.0002005646238103509
Valid Loss:  0.00027774638147093356
Epoch:  152  	Training Loss: 0.00031685232534073293
Test Loss:  0.00019945972599089146
Valid Loss:  0.000276768347248435
Epoch:  153  	Training Loss: 0.00031584000680595636
Test Loss:  0.00019888655515387654
Valid Loss:  0.0002758648479357362
Epoch:  154  	Training Loss: 0.0003148716641589999
Test Loss:  0.00019812819664366543
Valid Loss:  0.0002750687999650836
Epoch:  155  	Training Loss: 0.00031395870610140264
Test Loss:  0.00019754648383241147
Valid Loss:  0.00027433811919763684
Epoch:  156  	Training Loss: 0.00031308422330766916
Test Loss:  0.0001969461009139195
Valid Loss:  0.00027366523863747716
Epoch:  157  	Training Loss: 0.00031223861151374876
Test Loss:  0.00019640696700662374
Valid Loss:  0.00027301732916384935
Epoch:  158  	Training Loss: 0.00031140705686993897
Test Loss:  0.00019587072893045843
Valid Loss:  0.0002723942743614316
Epoch:  159  	Training Loss: 0.0003105978830717504
Test Loss:  0.00019535233150236309
Valid Loss:  0.00027180268079973757
Epoch:  160  	Training Loss: 0.000309807772282511
Test Loss:  0.00019487796816974878
Valid Loss:  0.00027124187909066677
Epoch:  161  	Training Loss: 0.00030904391314834356
Test Loss:  0.0001944006944540888
Valid Loss:  0.0002707095118239522
Epoch:  162  	Training Loss: 0.0003083030751440674
Test Loss:  0.00019531813450157642
Valid Loss:  0.0002699953911360353
Epoch:  163  	Training Loss: 0.0003069072845391929
Test Loss:  0.00019340449944138527
Valid Loss:  0.00026908653671853244
Epoch:  164  	Training Loss: 0.00030558949219994247
Test Loss:  0.00019373177201487124
Valid Loss:  0.00026838656049221754
Epoch:  165  	Training Loss: 0.0003043365431949496
Test Loss:  0.0001923502131830901
Valid Loss:  0.00026755730505101383
Epoch:  166  	Training Loss: 0.0003031181695405394
Test Loss:  0.00019233007333241403
Valid Loss:  0.00026686617638915777
Epoch:  167  	Training Loss: 0.0003019321884494275
Test Loss:  0.0001913114101625979
Valid Loss:  0.0002660935861058533
Epoch:  168  	Training Loss: 0.00030077097471803427
Test Loss:  0.00019109582353848964
Valid Loss:  0.00026541666011326015
Epoch:  169  	Training Loss: 0.0002996409893967211
Test Loss:  0.00019027781672775745
Valid Loss:  0.00026471493765711784
Epoch:  170  	Training Loss: 0.00029853853629902005
Test Loss:  0.00018998380983248353
Valid Loss:  0.00026407313998788595
Epoch:  171  	Training Loss: 0.00029746495420113206
Test Loss:  0.00018927059136331081
Valid Loss:  0.0002634118136484176
Epoch:  172  	Training Loss: 0.00029641768196597695
Test Loss:  0.0001885648089228198
Valid Loss:  0.0002625425695441663
Epoch:  173  	Training Loss: 0.00029553440981544554
Test Loss:  0.00018792599439620972
Valid Loss:  0.0002617160207591951
Epoch:  174  	Training Loss: 0.00029467581771314144
Test Loss:  0.00018736414494924247
Valid Loss:  0.0002609038492664695
Epoch:  175  	Training Loss: 0.0002938262769021094
Test Loss:  0.00018681134679354727
Valid Loss:  0.00026010896544903517
Epoch:  176  	Training Loss: 0.0002929852344095707
Test Loss:  0.00018628689576871693
Valid Loss:  0.00025934065342880785
Epoch:  177  	Training Loss: 0.0002921619452536106
Test Loss:  0.000185778655577451
Valid Loss:  0.0002585807233117521
Epoch:  178  	Training Loss: 0.0002913482894655317
Test Loss:  0.00018523994367569685
Valid Loss:  0.0002578483836259693
Epoch:  179  	Training Loss: 0.0002905518049374223
Test Loss:  0.00018474095850251615
Valid Loss:  0.00025712396018207073
Epoch:  180  	Training Loss: 0.00028976076282560825
Test Loss:  0.00018423171422909945
Valid Loss:  0.00025640608510002494
Epoch:  181  	Training Loss: 0.00028897495940327644
Test Loss:  0.0001837128947954625
Valid Loss:  0.0002557052066549659
Epoch:  182  	Training Loss: 0.0002882006810978055
Test Loss:  0.0001817816955735907
Valid Loss:  0.00025390106020495296
Epoch:  183  	Training Loss: 0.00028622400714084506
Test Loss:  0.00018062388699036092
Valid Loss:  0.0002522716240491718
Epoch:  184  	Training Loss: 0.000284351670416072
Test Loss:  0.00017922148981597275
Valid Loss:  0.00025071518030017614
Epoch:  185  	Training Loss: 0.0002825705159921199
Test Loss:  0.00017807568656280637
Valid Loss:  0.00024924386525526643
Epoch:  186  	Training Loss: 0.00028085961821489036
Test Loss:  0.00017693222616799176
Valid Loss:  0.00024783090339042246
Epoch:  187  	Training Loss: 0.00027923224843107164
Test Loss:  0.00017589543131180108
Valid Loss:  0.0002464688732288778
Epoch:  188  	Training Loss: 0.0002776632900349796
Test Loss:  0.00017491607286501676
Valid Loss:  0.000245155009906739
Epoch:  189  	Training Loss: 0.00027615553699433804
Test Loss:  0.00017392389418091625
Valid Loss:  0.00024385460710618645
Epoch:  190  	Training Loss: 0.0002746953396126628
Test Loss:  0.00017304328503087163
Valid Loss:  0.00024260436475742608
Epoch:  191  	Training Loss: 0.00027326864073984325
Test Loss:  0.00017206590564455837
Valid Loss:  0.0002413401671219617
Epoch:  192  	Training Loss: 0.0002718712785281241
Test Loss:  0.0001704250753391534
Valid Loss:  0.00023802253417670727
Epoch:  193  	Training Loss: 0.00026857247576117516
Test Loss:  0.00016807159408926964
Valid Loss:  0.00023580290144309402
Epoch:  194  	Training Loss: 0.00026620164862833917
Test Loss:  0.00016632814367767423
Valid Loss:  0.00023396342294290662
Epoch:  195  	Training Loss: 0.0002642985782586038
Test Loss:  0.00016505373059771955
Valid Loss:  0.00023225549375638366
Epoch:  196  	Training Loss: 0.00026248677750118077
Test Loss:  0.00016382112517021596
Valid Loss:  0.000230599325732328
Epoch:  197  	Training Loss: 0.00026072608307003975
Test Loss:  0.00016263560974039137
Valid Loss:  0.00022899324540048838
Epoch:  198  	Training Loss: 0.000259013962931931
Test Loss:  0.00016149906150531024
Valid Loss:  0.00022744045418221503
Epoch:  199  	Training Loss: 0.0002573406381998211
Test Loss:  0.0001604197605047375
Valid Loss:  0.00022591679589822888
Epoch:  200  	Training Loss: 0.0002557002007961273
Test Loss:  0.00015935077681206167
Valid Loss:  0.0002244242641609162
Epoch:  201  	Training Loss: 0.000254096114076674
Test Loss:  0.00015830366464797407
Valid Loss:  0.00022296576935332268
Epoch:  202  	Training Loss: 0.0002525228192098439
Test Loss:  0.00015702623932156712
Valid Loss:  0.00022178083600010723
Epoch:  203  	Training Loss: 0.0002510885242372751
Test Loss:  0.00015671606524847448
Valid Loss:  0.00022069607803132385
Epoch:  204  	Training Loss: 0.00024968833895400167
Test Loss:  0.00015546660870313644
Valid Loss:  0.00021951664530206472
 41%|████      | 205/500 [02:23<03:00,  1.64it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:23<01:37,  3.00it/s] 42%|████▏     | 211/500 [02:29<05:38,  1.17s/it] 43%|████▎     | 213/500 [02:29<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:29<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:29<02:06,  2.23it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.00it/s] 44%|████▍     | 221/500 [02:36<05:22,  1.16s/it] 45%|████▍     | 223/500 [02:36<03:50,  1.20it/s] 45%|████▌     | 225/500 [02:36<02:45,  1.66it/s] 45%|████▌     | 227/500 [02:36<02:00,  2.26it/s] 46%|████▌     | 229/500 [02:36<01:29,  3.04it/s] 46%|████▌     | 231/500 [02:43<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:43<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:43<02:41,  1.64it/s] 47%|████▋     | 237/500 [02:43<01:57,  2.25it/s] 48%|████▊     | 239/500 [02:43<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:49<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:50<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:50<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.24it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.01it/s] 50%|█████     | 251/500 [02:56<04:57,  1.19s/it] 51%|█████     | 253/500 [02:56<03:31,  1.17it/s] 51%|█████     | 255/500 [02:57<02:32,  1.61it/s] 51%|█████▏    | 257/500 [02:57<02:01,  2.01it/s] 52%|█████▏    | 259/500 [02:57<01:28,  2.71it/s] 52%|█████▏    | 261/500 [03:03<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:04<03:24,  1.16it/s] 53%|█████▎    | 265/500 [03:04<02:26,  1.61it/s] 53%|█████▎    | 267/500 [03:04<01:46,  2.19it/s] 54%|█████▍    | 269/500 [03:04<01:18,  2.95it/s] 54%|█████▍    | 271/500 [03:10<04:29,  1.18s/it]Epoch:  205  	Training Loss: 0.00024831522023305297
Test Loss:  0.0001551218010718003
Valid Loss:  0.0002184387412853539
Epoch:  206  	Training Loss: 0.0002469626779202372
Test Loss:  0.00015391167835332453
Valid Loss:  0.00021726670092903078
Epoch:  207  	Training Loss: 0.0002456263464409858
Test Loss:  0.0001535321498522535
Valid Loss:  0.00021619178005494177
Epoch:  208  	Training Loss: 0.0002443049452267587
Test Loss:  0.0001523556129541248
Valid Loss:  0.00021503210882656276
Epoch:  209  	Training Loss: 0.0002429976302664727
Test Loss:  0.00015194728621281683
Valid Loss:  0.00021396897500380874
Epoch:  210  	Training Loss: 0.00024170444521587342
Test Loss:  0.0001507862762082368
Valid Loss:  0.0002128219057340175
Epoch:  211  	Training Loss: 0.00024042531731538475
Test Loss:  0.0001503542298451066
Valid Loss:  0.000211772698094137
Epoch:  212  	Training Loss: 0.00023915778729133308
Test Loss:  0.0001505151012679562
Valid Loss:  0.00021130999084562063
Epoch:  213  	Training Loss: 0.00023869387223385274
Test Loss:  0.0001498385681770742
Valid Loss:  0.0002108943008352071
Epoch:  214  	Training Loss: 0.00023829574638511986
Test Loss:  0.0001495856704423204
Valid Loss:  0.000210593017982319
Epoch:  215  	Training Loss: 0.00023793676518835127
Test Loss:  0.00014928342716302723
Valid Loss:  0.00021034340898040682
Epoch:  216  	Training Loss: 0.00023760116891935468
Test Loss:  0.00014908338198438287
Valid Loss:  0.00021014321828261018
Epoch:  217  	Training Loss: 0.00023728168162051588
Test Loss:  0.00014888911391608417
Valid Loss:  0.00020997843239456415
Epoch:  218  	Training Loss: 0.0002369760477449745
Test Loss:  0.00014874238695483655
Valid Loss:  0.00020983940339647233
Epoch:  219  	Training Loss: 0.00023668014910072088
Test Loss:  0.0001486029796069488
Valid Loss:  0.00020972199854440987
Epoch:  220  	Training Loss: 0.00023639357823412865
Test Loss:  0.0001485030079493299
Valid Loss:  0.00020961801055818796
Epoch:  221  	Training Loss: 0.00023611242068000138
Test Loss:  0.00014840392395853996
Valid Loss:  0.00020952196791768074
Epoch:  222  	Training Loss: 0.0002358373603783548
Test Loss:  0.00014863652177155018
Valid Loss:  0.00020941846014466137
Epoch:  223  	Training Loss: 0.00023527521989308298
Test Loss:  0.00014863806427456439
Valid Loss:  0.00020925451826769859
Epoch:  224  	Training Loss: 0.00023476920614484698
Test Loss:  0.0001485209504608065
Valid Loss:  0.00020905783458147198
Epoch:  225  	Training Loss: 0.0002342978259548545
Test Loss:  0.00014835389447398484
Valid Loss:  0.00020884460536763072
Epoch:  226  	Training Loss: 0.00023385393433272839
Test Loss:  0.00014816549082752317
Valid Loss:  0.00020863306417595595
Epoch:  227  	Training Loss: 0.0002334339078515768
Test Loss:  0.00014796992763876915
Valid Loss:  0.00020842156664002687
Epoch:  228  	Training Loss: 0.0002330355637241155
Test Loss:  0.00014777561591472477
Valid Loss:  0.0002082113642245531
Epoch:  229  	Training Loss: 0.00023265695199370384
Test Loss:  0.00014758147881366313
Valid Loss:  0.00020800376660190523
Epoch:  230  	Training Loss: 0.00023229516227729619
Test Loss:  0.00014739477774128318
Valid Loss:  0.00020779977785423398
Epoch:  231  	Training Loss: 0.0002319516206625849
Test Loss:  0.00014721337356604636
Valid Loss:  0.00020759631297551095
Epoch:  232  	Training Loss: 0.0002316218160558492
Test Loss:  0.00014654186088591814
Valid Loss:  0.0002065030566882342
Epoch:  233  	Training Loss: 0.00023066968424245715
Test Loss:  0.0001457662438042462
Valid Loss:  0.0002055601216852665
Epoch:  234  	Training Loss: 0.00022981822257861495
Test Loss:  0.00014521054981742054
Valid Loss:  0.00020477306679822505
Epoch:  235  	Training Loss: 0.00022903477656655014
Test Loss:  0.00014472272596322
Valid Loss:  0.0002040806575678289
Epoch:  236  	Training Loss: 0.00022829390945844352
Test Loss:  0.00014431113959290087
Valid Loss:  0.0002034586068475619
Epoch:  237  	Training Loss: 0.0002275805309182033
Test Loss:  0.0001439424231648445
Valid Loss:  0.00020288450468797237
Epoch:  238  	Training Loss: 0.00022688957687932998
Test Loss:  0.00014360251952894032
Valid Loss:  0.00020235074043739587
Epoch:  239  	Training Loss: 0.0002262170019093901
Test Loss:  0.00014329398982226849
Valid Loss:  0.00020184538152534515
Epoch:  240  	Training Loss: 0.0002255594590678811
Test Loss:  0.00014300186012405902
Valid Loss:  0.00020136364037171006
Epoch:  241  	Training Loss: 0.00022491489653475583
Test Loss:  0.00014272474800236523
Valid Loss:  0.0002008987939916551
Epoch:  242  	Training Loss: 0.00022427752264775336
Test Loss:  0.00014278896560426801
Valid Loss:  0.000199523608898744
Epoch:  243  	Training Loss: 0.0002229064702987671
Test Loss:  0.00014053047925699502
Valid Loss:  0.00019856615108437836
Epoch:  244  	Training Loss: 0.00022198862279765308
Test Loss:  0.0001415740989614278
Valid Loss:  0.00019796707783825696
Epoch:  245  	Training Loss: 0.0002210911043221131
Test Loss:  0.0001394489372614771
Valid Loss:  0.0001970984594663605
Epoch:  246  	Training Loss: 0.00022021066979505122
Test Loss:  0.00014050556637812406
Valid Loss:  0.00019654887728393078
Epoch:  247  	Training Loss: 0.0002193435502704233
Test Loss:  0.00013845867943018675
Valid Loss:  0.0001956885971594602
Epoch:  248  	Training Loss: 0.00021847733296453953
Test Loss:  0.00013942999066784978
Valid Loss:  0.000195116619579494
Epoch:  249  	Training Loss: 0.00021761706739198416
Test Loss:  0.00013737179688178003
Valid Loss:  0.0001942025264725089
Epoch:  250  	Training Loss: 0.00021675077732652426
Test Loss:  0.00013841508189216256
Valid Loss:  0.0001936251064762473
Epoch:  251  	Training Loss: 0.00021590571850538254
Test Loss:  0.0001363461051369086
Valid Loss:  0.00019276776583865285
Epoch:  252  	Training Loss: 0.00021506076154764742
Test Loss:  0.00013640687393490225
Valid Loss:  0.00019220224930904806
Epoch:  253  	Training Loss: 0.00021425055456347764
Test Loss:  0.0001358140871161595
Valid Loss:  0.00019154726760461926
Epoch:  254  	Training Loss: 0.00021345829009078443
Test Loss:  0.00013554269389715046
Valid Loss:  0.00019094019080512226
Epoch:  255  	Training Loss: 0.00021268046111799777
Test Loss:  0.00013511395081877708
Valid Loss:  0.00019031271222047508
Epoch:  256  	Training Loss: 0.00021191631094552577
Test Loss:  0.0001347602519672364
Valid Loss:  0.00018969917437061667
Epoch:  257  	Training Loss: 0.0002111654612235725
Test Loss:  0.00013437672168947756
Valid Loss:  0.00018908787751570344
Epoch:  258  	Training Loss: 0.00021042473963461816
Test Loss:  0.0001340079470537603
Valid Loss:  0.0001884741213871166
Epoch:  259  	Training Loss: 0.00020969181787222624
Test Loss:  0.00013364118058234453
Valid Loss:  0.00018786046712193638
Epoch:  260  	Training Loss: 0.00020896582282148302
Test Loss:  0.00013327720807865262
Valid Loss:  0.0001872465800261125
Epoch:  261  	Training Loss: 0.000208243727684021
Test Loss:  0.0001329146616626531
Valid Loss:  0.00018663128139451146
Epoch:  262  	Training Loss: 0.00020752994169015437
Test Loss:  0.00013238542305771261
Valid Loss:  0.00018617979367263615
Epoch:  263  	Training Loss: 0.00020685949129983783
Test Loss:  0.00013207996380515397
Valid Loss:  0.00018565580830909312
Epoch:  264  	Training Loss: 0.00020604221208486706
Test Loss:  0.00013147084973752499
Valid Loss:  0.00018488813657313585
Epoch:  265  	Training Loss: 0.0002049647446256131
Test Loss:  0.00013082016084808856
Valid Loss:  0.00018394665676169097
Epoch:  266  	Training Loss: 0.0002036921796388924
Test Loss:  0.0001300375151913613
Valid Loss:  0.00018292712047696114
Epoch:  267  	Training Loss: 0.00020234176190569997
Test Loss:  0.0001293655950576067
Valid Loss:  0.00018205263768322766
Epoch:  268  	Training Loss: 0.0002010668395087123
Test Loss:  0.00012878753477707505
Valid Loss:  0.00018133065896108747
Epoch:  269  	Training Loss: 0.0001999724336201325
Test Loss:  0.00012830455671064556
Valid Loss:  0.00018066566553898156
Epoch:  270  	Training Loss: 0.00019902884378097951
Test Loss:  0.00012802760466001928
Valid Loss:  0.0001801519829314202
Epoch:  271  	Training Loss: 0.00019829436496365815
Test Loss:  0.00012772445916198194
Valid Loss:  0.00017970633052755147
 55%|█████▍    | 273/500 [03:10<03:12,  1.18it/s] 55%|█████▌    | 275/500 [03:11<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:11<01:40,  2.22it/s] 56%|█████▌    | 279/500 [03:11<01:13,  2.99it/s] 56%|█████▌    | 281/500 [03:17<04:20,  1.19s/it] 57%|█████▋    | 283/500 [03:17<03:05,  1.17it/s] 57%|█████▋    | 285/500 [03:17<02:12,  1.62it/s] 57%|█████▋    | 287/500 [03:18<01:36,  2.21it/s] 58%|█████▊    | 289/500 [03:18<01:10,  2.98it/s] 58%|█████▊    | 289/500 [03:30<01:10,  2.98it/s] 58%|█████▊    | 291/500 [03:30<07:18,  2.10s/it] 59%|█████▊    | 293/500 [03:30<05:08,  1.49s/it] 59%|█████▉    | 295/500 [03:30<03:38,  1.06s/it] 59%|█████▉    | 297/500 [03:31<02:35,  1.31it/s] 60%|█████▉    | 299/500 [03:31<01:51,  1.80it/s] 60%|██████    | 301/500 [03:37<04:22,  1.32s/it] 61%|██████    | 303/500 [03:37<03:06,  1.06it/s] 61%|██████    | 305/500 [03:37<02:13,  1.47it/s] 61%|██████▏   | 307/500 [03:37<01:35,  2.01it/s] 62%|██████▏   | 309/500 [03:37<01:10,  2.72it/s] 62%|██████▏   | 311/500 [03:44<03:47,  1.20s/it] 63%|██████▎   | 313/500 [03:44<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:44<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:44<01:23,  2.19it/s] 64%|██████▍   | 319/500 [03:44<01:01,  2.94it/s] 64%|██████▍   | 321/500 [03:51<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:51<02:30,  1.17it/s] 65%|██████▌   | 325/500 [03:51<01:47,  1.62it/s] 65%|██████▌   | 327/500 [03:51<01:18,  2.22it/s] 66%|██████▌   | 329/500 [03:51<00:57,  2.98it/s] 66%|██████▌   | 331/500 [03:57<03:17,  1.17s/it] 67%|██████▋   | 333/500 [03:58<02:20,  1.19it/s] 67%|██████▋   | 335/500 [03:58<01:40,  1.65it/s] 67%|██████▋   | 337/500 [03:58<01:12,  2.25it/s]Epoch:  272  	Training Loss: 0.00019768011406995356
Test Loss:  0.00012799716205336154
Valid Loss:  0.00017907467554323375
Epoch:  273  	Training Loss: 0.00019704230362549424
Test Loss:  0.00012795407383237034
Valid Loss:  0.00017851131269708276
Epoch:  274  	Training Loss: 0.00019654101924970746
Test Loss:  0.00012773583875969052
Valid Loss:  0.00017795746680349112
Epoch:  275  	Training Loss: 0.00019607393187470734
Test Loss:  0.00012742821127176285
Valid Loss:  0.00017741203191690147
Epoch:  276  	Training Loss: 0.0001956156629603356
Test Loss:  0.00012707718997262418
Valid Loss:  0.00017686886712908745
Epoch:  277  	Training Loss: 0.0001951500598806888
Test Loss:  0.0001267208717763424
Valid Loss:  0.00017633070820011199
Epoch:  278  	Training Loss: 0.00019468332175165415
Test Loss:  0.0001263533195015043
Valid Loss:  0.00017580333224032074
Epoch:  279  	Training Loss: 0.00019421728211455047
Test Loss:  0.00012598861940205097
Valid Loss:  0.00017529141041450202
Epoch:  280  	Training Loss: 0.00019375409465283155
Test Loss:  0.00012562875053845346
Valid Loss:  0.0001747907663229853
Epoch:  281  	Training Loss: 0.00019329202768858522
Test Loss:  0.0001252751098945737
Valid Loss:  0.00017429848958272487
Epoch:  282  	Training Loss: 0.0001928325364133343
Test Loss:  0.00012170256377430633
Valid Loss:  0.00017311392002739012
Epoch:  283  	Training Loss: 0.00019221118418499827
Test Loss:  0.00012700731167569757
Valid Loss:  0.00017407987616024911
Epoch:  284  	Training Loss: 0.0001918409252539277
Test Loss:  0.00011924031423404813
Valid Loss:  0.00017266337818000466
Epoch:  285  	Training Loss: 0.00019210641039535403
Test Loss:  0.00013515262980945408
Valid Loss:  0.00017782271606847644
Epoch:  286  	Training Loss: 0.0001940060465130955
Test Loss:  0.00012027872435282916
Valid Loss:  0.0001793138508219272
Epoch:  287  	Training Loss: 0.00020012911409139633
Test Loss:  0.00017307483358308673
Valid Loss:  0.0002046122681349516
Epoch:  288  	Training Loss: 0.00021709143766202033
Test Loss:  0.00016494348528794944
Valid Loss:  0.00023781933123245835
Epoch:  289  	Training Loss: 0.00026227495982311666
Test Loss:  0.00037604462704621255
Valid Loss:  0.00037642649840563536
Epoch:  290  	Training Loss: 0.00037888577207922935
Test Loss:  0.0005560152931138873
Valid Loss:  0.0006559600587934256
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.0006878782296553254
Test Loss:  0.00012801623961422592
Valid Loss:  0.00019237502419855446
Epoch:  292  	Training Loss: 0.00021225986711215228
Test Loss:  0.00011851322778966278
Valid Loss:  0.00017515139188617468
Epoch:  293  	Training Loss: 0.00019202637486159801
Test Loss:  0.00011866024578921497
Valid Loss:  0.00017138296971097589
Epoch:  294  	Training Loss: 0.0001867187093012035
Test Loss:  0.00011984322918578982
Valid Loss:  0.00017054456111509353
Epoch:  295  	Training Loss: 0.00018509998335503042
Test Loss:  0.00012064419570378959
Valid Loss:  0.00017027018475346267
Epoch:  296  	Training Loss: 0.0001844358630478382
Test Loss:  0.00012101476750103757
Valid Loss:  0.00017003220273181796
Epoch:  297  	Training Loss: 0.00018400434055365622
Test Loss:  0.00012113383854739368
Valid Loss:  0.00016977181076072156
Epoch:  298  	Training Loss: 0.00018364531570114195
Test Loss:  0.00012111985415685922
Valid Loss:  0.0001694872189546004
Epoch:  299  	Training Loss: 0.00018330462626181543
Test Loss:  0.00012104534107493237
Valid Loss:  0.00016919508925639093
Epoch:  300  	Training Loss: 0.0001829779939725995
Test Loss:  0.0001209409674629569
Valid Loss:  0.00016890028200577945
Epoch:  301  	Training Loss: 0.00018265812832396477
Test Loss:  0.0001208193862112239
Valid Loss:  0.00016860618779901415
Epoch:  302  	Training Loss: 0.00018234201706945896
Test Loss:  0.00012054610124323517
Valid Loss:  0.00016821609460748732
Epoch:  303  	Training Loss: 0.0001819574536057189
Test Loss:  0.00012030103243887424
Valid Loss:  0.00016785239859018475
Epoch:  304  	Training Loss: 0.0001815942523535341
Test Loss:  0.00012008521298412234
Valid Loss:  0.00016752051305957139
Epoch:  305  	Training Loss: 0.00018126887152902782
Test Loss:  0.0001198787649627775
Valid Loss:  0.00016720891289878637
Epoch:  306  	Training Loss: 0.00018096546409651637
Test Loss:  0.00011970779451075941
Valid Loss:  0.00016692503413651139
Epoch:  307  	Training Loss: 0.00018069168436340988
Test Loss:  0.0001195561999338679
Valid Loss:  0.00016667795716784894
Epoch:  308  	Training Loss: 0.0001804355124477297
Test Loss:  0.0001194051728816703
Valid Loss:  0.00016645027790218592
Epoch:  309  	Training Loss: 0.00018019058916252106
Test Loss:  0.00011926815204788
Valid Loss:  0.0001662420982029289
Epoch:  310  	Training Loss: 0.00017995518282987177
Test Loss:  0.00011914526112377644
Valid Loss:  0.00016604483244009316
Epoch:  311  	Training Loss: 0.0001797224540496245
Test Loss:  0.00011904370330739766
Valid Loss:  0.00016585637058597058
Epoch:  312  	Training Loss: 0.00017949435277841985
Test Loss:  0.00011867583089042455
Valid Loss:  0.00016522666555829346
Epoch:  313  	Training Loss: 0.00017878846847452223
Test Loss:  0.00011831067968159914
Valid Loss:  0.00016463521751575172
Epoch:  314  	Training Loss: 0.00017812132136896253
Test Loss:  0.00011796465696534142
Valid Loss:  0.00016407070506829768
Epoch:  315  	Training Loss: 0.00017747840320225805
Test Loss:  0.00011763354996219277
Valid Loss:  0.00016351498197764158
Epoch:  316  	Training Loss: 0.0001768643269315362
Test Loss:  0.000117310177301988
Valid Loss:  0.00016299501294270158
Epoch:  317  	Training Loss: 0.00017630684305913746
Test Loss:  0.0001169829920399934
Valid Loss:  0.00016249156033154577
Epoch:  318  	Training Loss: 0.00017578336701262742
Test Loss:  0.00011669263039948419
Valid Loss:  0.00016200743266381323
Epoch:  319  	Training Loss: 0.00017528110765852034
Test Loss:  0.00011644724145298824
Valid Loss:  0.00016155815683305264
Epoch:  320  	Training Loss: 0.00017481716349720955
Test Loss:  0.00011618781718425453
Valid Loss:  0.00016111793229356408
Epoch:  321  	Training Loss: 0.0001743748434819281
Test Loss:  0.00011594463285291567
Valid Loss:  0.00016071376740001142
Epoch:  322  	Training Loss: 0.00017394068709108979
Test Loss:  0.00011554485536180437
Valid Loss:  0.00016024135402403772
Epoch:  323  	Training Loss: 0.0001734444813337177
Test Loss:  0.00011527188325999305
Valid Loss:  0.00015978731971699744
Epoch:  324  	Training Loss: 0.0001729772484395653
Test Loss:  0.0001150149037130177
Valid Loss:  0.0001593380147824064
Epoch:  325  	Training Loss: 0.00017251697136089206
Test Loss:  0.00011476781946839765
Valid Loss:  0.0001588878221809864
Epoch:  326  	Training Loss: 0.00017206036136485636
Test Loss:  0.00011451615137048066
Valid Loss:  0.0001584421406732872
Epoch:  327  	Training Loss: 0.00017161009600386024
Test Loss:  0.00011427231947891414
Valid Loss:  0.0001579987001605332
Epoch:  328  	Training Loss: 0.00017116620438173413
Test Loss:  0.00011402445670682937
Valid Loss:  0.00015755827189423144
Epoch:  329  	Training Loss: 0.00017072746413759887
Test Loss:  0.00011377847113180906
Valid Loss:  0.00015712145250290632
Epoch:  330  	Training Loss: 0.00017029314767569304
Test Loss:  0.00011353527224855497
Valid Loss:  0.0001566894497955218
Epoch:  331  	Training Loss: 0.0001698636478977278
Test Loss:  0.00011329517292324454
Valid Loss:  0.0001562616671435535
Epoch:  332  	Training Loss: 0.0001694390521151945
Test Loss:  0.00011271253606537357
Valid Loss:  0.0001558281946927309
Epoch:  333  	Training Loss: 0.00016910230624489486
Test Loss:  0.00011239847663091496
Valid Loss:  0.0001555129128973931
Epoch:  334  	Training Loss: 0.00016877359303180128
Test Loss:  0.000112095833173953
Valid Loss:  0.0001551880268380046
Epoch:  335  	Training Loss: 0.0001684121962171048
Test Loss:  0.00011157400149386376
Valid Loss:  0.000154672481585294
Epoch:  336  	Training Loss: 0.00016788620268926024
Test Loss:  0.00011108839680673555
Valid Loss:  0.00015394657384604216
Epoch:  337  	Training Loss: 0.0001672999351285398
Test Loss:  0.00011063729471061379
Valid Loss:  0.00015320639067795128
 68%|██████▊   | 339/500 [03:58<00:53,  3.02it/s] 68%|██████▊   | 341/500 [04:04<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:04<02:11,  1.19it/s] 69%|██████▉   | 345/500 [04:04<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:05<01:08,  2.24it/s] 70%|██████▉   | 349/500 [04:05<00:50,  3.02it/s] 70%|███████   | 351/500 [04:11<02:54,  1.17s/it] 71%|███████   | 353/500 [04:11<02:03,  1.19it/s] 71%|███████   | 355/500 [04:11<01:27,  1.65it/s] 71%|███████▏  | 357/500 [04:11<01:03,  2.24it/s] 72%|███████▏  | 359/500 [04:12<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:18<02:44,  1.19s/it] 73%|███████▎  | 363/500 [04:18<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:18<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:18<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:18<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:25<02:32,  1.18s/it] 75%|███████▍  | 373/500 [04:25<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:25<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:25<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:25<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:32<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:32<01:39,  1.17it/s] 77%|███████▋  | 385/500 [04:32<01:10,  1.62it/s] 77%|███████▋  | 387/500 [04:32<00:50,  2.22it/s] 78%|███████▊  | 389/500 [04:32<00:37,  2.98it/s] 78%|███████▊  | 391/500 [04:38<02:07,  1.17s/it] 79%|███████▊  | 393/500 [04:39<01:30,  1.19it/s] 79%|███████▉  | 395/500 [04:39<01:04,  1.64it/s] 79%|███████▉  | 397/500 [04:39<00:46,  2.24it/s] 80%|███████▉  | 399/500 [04:39<00:33,  3.01it/s] 80%|████████  | 401/500 [04:45<01:57,  1.19s/it] 81%|████████  | 403/500 [04:45<01:22,  1.17it/s]Epoch:  338  	Training Loss: 0.0001666188327362761
Test Loss:  0.00010972733434755355
Valid Loss:  0.00015216894098557532
Epoch:  339  	Training Loss: 0.00016568932915106416
Test Loss:  0.00010868707613553852
Valid Loss:  0.0001509400608483702
Epoch:  340  	Training Loss: 0.00016453678836114705
Test Loss:  0.00010748631757451221
Valid Loss:  0.0001494190946687013
Epoch:  341  	Training Loss: 0.00016306445468217134
Test Loss:  0.00010602102702250704
Valid Loss:  0.00014754105359315872
Epoch:  342  	Training Loss: 0.0001613148779142648
Test Loss:  0.00010446958185639232
Valid Loss:  0.00014545767044182867
Epoch:  343  	Training Loss: 0.0001594770874362439
Test Loss:  0.00010325944458600134
Valid Loss:  0.000143626777571626
Epoch:  344  	Training Loss: 0.00015786141739226878
Test Loss:  0.0001023905715555884
Valid Loss:  0.00014201461453922093
Epoch:  345  	Training Loss: 0.00015646262909285724
Test Loss:  0.00010176243813475594
Valid Loss:  0.00014061930414754897
Epoch:  346  	Training Loss: 0.00015532691031694412
Test Loss:  0.00010141963139176369
Valid Loss:  0.00013952481094747782
Epoch:  347  	Training Loss: 0.000154426452354528
Test Loss:  0.00010122614912688732
Valid Loss:  0.000138662668177858
Epoch:  348  	Training Loss: 0.00015364775026682764
Test Loss:  0.00010117742931470275
Valid Loss:  0.00013807523646391928
Epoch:  349  	Training Loss: 0.00015303320833481848
Test Loss:  0.00010115901386598125
Valid Loss:  0.00013763220340479165
Epoch:  350  	Training Loss: 0.0001525121770100668
Test Loss:  0.00010115794430021197
Valid Loss:  0.00013729841157328337
Epoch:  351  	Training Loss: 0.00015206784883048385
Test Loss:  0.00010117127385456115
Valid Loss:  0.0001370249956380576
Epoch:  352  	Training Loss: 0.0001516632328275591
Test Loss:  0.00010140189988305792
Valid Loss:  0.00013706492609344423
Epoch:  353  	Training Loss: 0.00015135033754631877
Test Loss:  0.00010156366624869406
Valid Loss:  0.0001370816316921264
Epoch:  354  	Training Loss: 0.00015107032959349453
Test Loss:  0.00010167704022023827
Valid Loss:  0.00013707659672945738
Epoch:  355  	Training Loss: 0.00015081380843184888
Test Loss:  0.00010175604256801307
Valid Loss:  0.0001370571699226275
Epoch:  356  	Training Loss: 0.00015057709242682904
Test Loss:  0.00010181082325289026
Valid Loss:  0.0001370244426652789
Epoch:  357  	Training Loss: 0.0001503551029600203
Test Loss:  0.00010184640996158123
Valid Loss:  0.00013698019029106945
Epoch:  358  	Training Loss: 0.00015014471136964858
Test Loss:  0.00010186704457737505
Valid Loss:  0.00013692628999706358
Epoch:  359  	Training Loss: 0.0001499419449828565
Test Loss:  0.00010187925363425165
Valid Loss:  0.00013686277088709176
Epoch:  360  	Training Loss: 0.00014974424266256392
Test Loss:  0.00010188017768086866
Valid Loss:  0.00013679043331649154
Epoch:  361  	Training Loss: 0.0001495522155892104
Test Loss:  0.00010187295265495777
Valid Loss:  0.0001367124350508675
Epoch:  362  	Training Loss: 0.00014936624211259186
Test Loss:  0.00010162015678361058
Valid Loss:  0.00013655312068294734
Epoch:  363  	Training Loss: 0.00014919966633897275
Test Loss:  0.00010150235902983695
Valid Loss:  0.00013645726721733809
Epoch:  364  	Training Loss: 0.00014904726413078606
Test Loss:  0.00010144255065824836
Valid Loss:  0.00013638744712807238
Epoch:  365  	Training Loss: 0.00014889930025674403
Test Loss:  0.00010140638914890587
Valid Loss:  0.00013632766786031425
Epoch:  366  	Training Loss: 0.00014875351916998625
Test Loss:  0.00010137840581592172
Valid Loss:  0.00013627001317217946
Epoch:  367  	Training Loss: 0.00014860945520922542
Test Loss:  0.00010135385673493147
Valid Loss:  0.00013621299876831472
Epoch:  368  	Training Loss: 0.00014846633712295443
Test Loss:  0.00010133055911865085
Valid Loss:  0.000136151269543916
Epoch:  369  	Training Loss: 0.00014832518354523927
Test Loss:  0.00010130618466064334
Valid Loss:  0.00013608476729132235
Epoch:  370  	Training Loss: 0.00014818424824625254
Test Loss:  0.00010128102439921349
Valid Loss:  0.0001360168680548668
Epoch:  371  	Training Loss: 0.00014804457896389067
Test Loss:  0.00010125416156370193
Valid Loss:  0.00013594538904726505
Epoch:  372  	Training Loss: 0.00014790595741942525
Test Loss:  0.00010142847168026492
Valid Loss:  0.00013593293260782957
Epoch:  373  	Training Loss: 0.00014756365271750838
Test Loss:  0.00010135721822734922
Valid Loss:  0.00013580296945292503
Epoch:  374  	Training Loss: 0.0001472593139624223
Test Loss:  0.00010119781654793769
Valid Loss:  0.00013562219101004303
Epoch:  375  	Training Loss: 0.00014696257130708545
Test Loss:  0.00010101305815624073
Valid Loss:  0.00013542687520384789
Epoch:  376  	Training Loss: 0.00014667843061033636
Test Loss:  0.00010081323853228241
Valid Loss:  0.00013523032248485833
Epoch:  377  	Training Loss: 0.00014640577137470245
Test Loss:  0.000100619115983136
Valid Loss:  0.00013504571688827127
Epoch:  378  	Training Loss: 0.000146141042932868
Test Loss:  0.00010042590292869136
Valid Loss:  0.00013485978706739843
Epoch:  379  	Training Loss: 0.00014588335761800408
Test Loss:  0.00010023446520790458
Valid Loss:  0.00013467650569509715
Epoch:  380  	Training Loss: 0.0001456386235076934
Test Loss:  0.00010004734212998301
Valid Loss:  0.00013450015103444457
Epoch:  381  	Training Loss: 0.00014540052507072687
Test Loss:  9.985968063119799e-05
Valid Loss:  0.00013432829291559756
Epoch:  382  	Training Loss: 0.00014516455121338367
Test Loss:  9.943434270098805e-05
Valid Loss:  0.00013411723193712533
Epoch:  383  	Training Loss: 0.0001450246199965477
Test Loss:  9.927948849508539e-05
Valid Loss:  0.00013404536002781242
Epoch:  384  	Training Loss: 0.00014491600450128317
Test Loss:  9.92264031083323e-05
Valid Loss:  0.0001340195449301973
Epoch:  385  	Training Loss: 0.0001448152761440724
Test Loss:  9.921115997713059e-05
Valid Loss:  0.00013400931493379176
Epoch:  386  	Training Loss: 0.00014471808390226215
Test Loss:  9.921045420924202e-05
Valid Loss:  0.00013400240277405828
Epoch:  387  	Training Loss: 0.00014462368562817574
Test Loss:  9.921478340402246e-05
Valid Loss:  0.00013399487943388522
Epoch:  388  	Training Loss: 0.00014453151379711926
Test Loss:  9.922072058543563e-05
Valid Loss:  0.00013398357259575278
Epoch:  389  	Training Loss: 0.00014443942927755415
Test Loss:  9.922544995788485e-05
Valid Loss:  0.00013396888971328735
Epoch:  390  	Training Loss: 0.0001443493238184601
Test Loss:  9.922805475071073e-05
Valid Loss:  0.00013395040878094733
Epoch:  391  	Training Loss: 0.0001442585198674351
Test Loss:  9.922995377564803e-05
Valid Loss:  0.00013392789696808904
Epoch:  392  	Training Loss: 0.00014416802150662988
Test Loss:  9.930834494298324e-05
Valid Loss:  0.00013379853044170886
Epoch:  393  	Training Loss: 0.00014386512339115143
Test Loss:  9.924022015184164e-05
Valid Loss:  0.000133596797240898
Epoch:  394  	Training Loss: 0.00014357530744746327
Test Loss:  9.912622044794261e-05
Valid Loss:  0.0001333719992544502
Epoch:  395  	Training Loss: 0.00014329145778901875
Test Loss:  9.899364522425458e-05
Valid Loss:  0.0001331372477579862
Epoch:  396  	Training Loss: 0.00014301060582511127
Test Loss:  9.885855251923203e-05
Valid Loss:  0.0001329034275840968
Epoch:  397  	Training Loss: 0.00014273116539698094
Test Loss:  9.872293594526127e-05
Valid Loss:  0.000132670029415749
Epoch:  398  	Training Loss: 0.00014245437341742218
Test Loss:  9.858253906713799e-05
Valid Loss:  0.00013243273133412004
Epoch:  399  	Training Loss: 0.00014218084106687456
Test Loss:  9.844513260759413e-05
Valid Loss:  0.00013219774700701237
Epoch:  400  	Training Loss: 0.00014190890942700207
Test Loss:  9.830830822465941e-05
Valid Loss:  0.0001319661969318986
Epoch:  401  	Training Loss: 0.00014163969899527729
Test Loss:  9.817393583944067e-05
Valid Loss:  0.00013173744082450867
Epoch:  402  	Training Loss: 0.0001413722347933799
Test Loss:  9.812499047257006e-05
Valid Loss:  0.0001315330882789567
Epoch:  403  	Training Loss: 0.00014113515499047935
Test Loss:  9.795062942430377e-05
Valid Loss:  0.00013129426224622875
Epoch:  404  	Training Loss: 0.00014091149205341935
Test Loss:  9.778366074897349e-05
Valid Loss:  0.00013107337872497737
 81%|████████  | 405/500 [04:46<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:46<00:41,  2.22it/s] 82%|████████▏ | 409/500 [04:46<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:52<01:44,  1.18s/it] 83%|████████▎ | 413/500 [04:52<01:13,  1.18it/s] 83%|████████▎ | 415/500 [04:52<00:52,  1.63it/s] 83%|████████▎ | 417/500 [04:53<00:37,  2.23it/s] 84%|████████▍ | 419/500 [04:53<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:59<01:33,  1.18s/it] 85%|████████▍ | 423/500 [04:59<01:05,  1.18it/s] 85%|████████▌ | 425/500 [04:59<00:46,  1.63it/s] 85%|████████▌ | 427/500 [04:59<00:33,  2.20it/s] 86%|████████▌ | 429/500 [05:00<00:24,  2.96it/s] 86%|████████▌ | 431/500 [05:06<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:06<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:06<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:06<00:28,  2.23it/s] 88%|████████▊ | 439/500 [05:06<00:20,  3.00it/s] 88%|████████▊ | 441/500 [05:13<01:09,  1.17s/it] 89%|████████▊ | 443/500 [05:13<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:13<00:33,  1.65it/s] 89%|████████▉ | 447/500 [05:13<00:23,  2.25it/s] 90%|████████▉ | 449/500 [05:13<00:16,  3.02it/s] 90%|█████████ | 451/500 [05:20<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:20<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:20<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:20<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:20<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:26<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:26<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:27<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:27<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:27<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:33<00:33,  1.17s/it]Epoch:  405  	Training Loss: 0.00014069527969695628
Test Loss:  9.762094123288989e-05
Valid Loss:  0.00013087087427265942
Epoch:  406  	Training Loss: 0.00014048407319933176
Test Loss:  9.746922296471894e-05
Valid Loss:  0.00013068663247395307
Epoch:  407  	Training Loss: 0.0001402765337843448
Test Loss:  9.732760372571647e-05
Valid Loss:  0.00013051647692918777
Epoch:  408  	Training Loss: 0.00014007152640260756
Test Loss:  9.719267109176144e-05
Valid Loss:  0.00013035206939093769
Epoch:  409  	Training Loss: 0.00013986852718517184
Test Loss:  9.706944547360763e-05
Valid Loss:  0.0001301931479247287
Epoch:  410  	Training Loss: 0.0001396658772137016
Test Loss:  9.694445907371119e-05
Valid Loss:  0.00013003805361222476
Epoch:  411  	Training Loss: 0.0001394673017784953
Test Loss:  9.682022937340662e-05
Valid Loss:  0.0001298889983445406
Epoch:  412  	Training Loss: 0.0001392718404531479
Test Loss:  9.589793626219034e-05
Valid Loss:  0.00012863791198469698
Epoch:  413  	Training Loss: 0.0001385844952892512
Test Loss:  9.562616469338536e-05
Valid Loss:  0.00012798747047781944
Epoch:  414  	Training Loss: 0.00013809703523293138
Test Loss:  9.551113907946274e-05
Valid Loss:  0.0001275518152397126
Epoch:  415  	Training Loss: 0.00013770352234132588
Test Loss:  9.545147622702643e-05
Valid Loss:  0.00012721674283966422
Epoch:  416  	Training Loss: 0.00013736067921854556
Test Loss:  9.537670848658308e-05
Valid Loss:  0.00012691633310168982
Epoch:  417  	Training Loss: 0.00013704216689802706
Test Loss:  9.531082469038665e-05
Valid Loss:  0.0001267033803742379
Epoch:  418  	Training Loss: 0.0001367514196317643
Test Loss:  9.524840425001457e-05
Valid Loss:  0.00012652206351049244
Epoch:  419  	Training Loss: 0.00013648041931446642
Test Loss:  9.517848957329988e-05
Valid Loss:  0.0001263566518900916
Epoch:  420  	Training Loss: 0.00013621649122796953
Test Loss:  9.511621465208009e-05
Valid Loss:  0.00012622718350030482
Epoch:  421  	Training Loss: 0.00013596084318123758
Test Loss:  9.507000504527241e-05
Valid Loss:  0.00012613610306289047
Epoch:  422  	Training Loss: 0.0001357206201646477
Test Loss:  9.491023956798017e-05
Valid Loss:  0.00012595110456459224
Epoch:  423  	Training Loss: 0.00013545213732868433
Test Loss:  9.477579442318529e-05
Valid Loss:  0.00012577156303450465
Epoch:  424  	Training Loss: 0.00013519050844479352
Test Loss:  9.464317554375157e-05
Valid Loss:  0.0001255880342796445
Epoch:  425  	Training Loss: 0.00013493181904777884
Test Loss:  9.451354708289728e-05
Valid Loss:  0.00012540281750261784
Epoch:  426  	Training Loss: 0.00013467553071677685
Test Loss:  9.438379493076354e-05
Valid Loss:  0.0001252146903425455
Epoch:  427  	Training Loss: 0.00013442043564282358
Test Loss:  9.425927419215441e-05
Valid Loss:  0.00012502871686592698
Epoch:  428  	Training Loss: 0.0001341651368420571
Test Loss:  9.413432417204604e-05
Valid Loss:  0.00012483382306527346
Epoch:  429  	Training Loss: 0.00013390855747275054
Test Loss:  9.39973906497471e-05
Valid Loss:  0.00012463275925256312
Epoch:  430  	Training Loss: 0.000133654146338813
Test Loss:  9.385689918417484e-05
Valid Loss:  0.0001244295563083142
Epoch:  431  	Training Loss: 0.00013340232544578612
Test Loss:  9.371267515234649e-05
Valid Loss:  0.00012422438885550946
Epoch:  432  	Training Loss: 0.0001331516687059775
Test Loss:  9.339644748251885e-05
Valid Loss:  0.00012389430776238441
Epoch:  433  	Training Loss: 0.00013295409735292196
Test Loss:  9.31736285565421e-05
Valid Loss:  0.000123614925541915
Epoch:  434  	Training Loss: 0.00013276710524223745
Test Loss:  9.29752059164457e-05
Valid Loss:  0.00012335450446698815
Epoch:  435  	Training Loss: 0.00013258468243293464
Test Loss:  9.278907964471728e-05
Valid Loss:  0.00012310360034462065
Epoch:  436  	Training Loss: 0.00013240597036201507
Test Loss:  9.26099019125104e-05
Valid Loss:  0.0001228622713824734
Epoch:  437  	Training Loss: 0.0001322306925430894
Test Loss:  9.243629756383598e-05
Valid Loss:  0.00012262805830687284
Epoch:  438  	Training Loss: 0.0001320582814514637
Test Loss:  9.226904512615874e-05
Valid Loss:  0.0001224002189701423
Epoch:  439  	Training Loss: 0.00013189006131142378
Test Loss:  9.210599819198251e-05
Valid Loss:  0.00012217833136674017
Epoch:  440  	Training Loss: 0.0001317236601607874
Test Loss:  9.195078746415675e-05
Valid Loss:  0.00012195524323033169
Epoch:  441  	Training Loss: 0.00013155258784536272
Test Loss:  9.179103653877974e-05
Valid Loss:  0.00012173563300166279
Epoch:  442  	Training Loss: 0.00013138377107679844
Test Loss:  9.199509804602712e-05
Valid Loss:  0.00012192055146442726
Epoch:  443  	Training Loss: 0.000131248016259633
Test Loss:  9.212279110215604e-05
Valid Loss:  0.00012206766405142844
Epoch:  444  	Training Loss: 0.0001311370579060167
Test Loss:  9.221509390044957e-05
Valid Loss:  0.0001221884012920782
Epoch:  445  	Training Loss: 0.00013104474055580795
Test Loss:  9.229607530869544e-05
Valid Loss:  0.00012229461572133005
Epoch:  446  	Training Loss: 0.00013096295879222453
Test Loss:  9.236734331352636e-05
Valid Loss:  0.00012239116767887026
Epoch:  447  	Training Loss: 0.00013089156709611416
Test Loss:  9.243367821909487e-05
Valid Loss:  0.00012247853737790138
Epoch:  448  	Training Loss: 0.00013082605437375605
Test Loss:  9.249635331798345e-05
Valid Loss:  0.0001225578016601503
Epoch:  449  	Training Loss: 0.00013076519826427102
Test Loss:  9.255554323317483e-05
Valid Loss:  0.00012262750533409417
Epoch:  450  	Training Loss: 0.00013070825661998242
Test Loss:  9.260782098863274e-05
Valid Loss:  0.00012269028229638934
Epoch:  451  	Training Loss: 0.0001306542253587395
Test Loss:  9.265634434996173e-05
Valid Loss:  0.00012274603068362921
Epoch:  452  	Training Loss: 0.00013060156197752804
Test Loss:  9.270376176573336e-05
Valid Loss:  0.00012280144437681884
Epoch:  453  	Training Loss: 0.00013042698265053332
Test Loss:  9.270443115383387e-05
Valid Loss:  0.0001228208711836487
Epoch:  454  	Training Loss: 0.00013026679516769946
Test Loss:  9.269115253118798e-05
Valid Loss:  0.00012282299576327205
Epoch:  455  	Training Loss: 0.0001301187730859965
Test Loss:  9.267538553103805e-05
Valid Loss:  0.0001228189648827538
Epoch:  456  	Training Loss: 0.00012997978774365038
Test Loss:  9.265575499739498e-05
Valid Loss:  0.00012280920054763556
Epoch:  457  	Training Loss: 0.00012984918430447578
Test Loss:  9.263896208722144e-05
Valid Loss:  0.000122795783681795
Epoch:  458  	Training Loss: 0.0001297232083743438
Test Loss:  9.26189823076129e-05
Valid Loss:  0.0001227743341587484
Epoch:  459  	Training Loss: 0.00012959842570126057
Test Loss:  9.259673242922872e-05
Valid Loss:  0.00012274608889129013
Epoch:  460  	Training Loss: 0.00012947669893037528
Test Loss:  9.257196506951004e-05
Valid Loss:  0.0001227085303980857
Epoch:  461  	Training Loss: 0.00012935565609950572
Test Loss:  9.25434724194929e-05
Valid Loss:  0.00012265797704458237
Epoch:  462  	Training Loss: 0.0001292346278205514
Test Loss:  9.250544098904356e-05
Valid Loss:  0.00012237107148393989
Epoch:  463  	Training Loss: 0.00012902992602903396
Test Loss:  9.240996587323025e-05
Valid Loss:  0.00012209720443934202
Epoch:  464  	Training Loss: 0.0001288641942664981
Test Loss:  9.227829286828637e-05
Valid Loss:  0.00012183883518446237
Epoch:  465  	Training Loss: 0.00012872499064542353
Test Loss:  9.212818258674815e-05
Valid Loss:  0.0001215949741890654
Epoch:  466  	Training Loss: 0.00012860342394560575
Test Loss:  9.197325562126935e-05
Valid Loss:  0.00012136906298110262
Epoch:  467  	Training Loss: 0.00012849533231928945
Test Loss:  9.182279609376565e-05
Valid Loss:  0.0001211610360769555
Epoch:  468  	Training Loss: 0.00012839528790209442
Test Loss:  9.168048563878983e-05
Valid Loss:  0.00012096976570319384
Epoch:  469  	Training Loss: 0.0001283015590161085
Test Loss:  9.154833969660103e-05
Valid Loss:  0.00012079375301254913
Epoch:  470  	Training Loss: 0.00012821124983020127
Test Loss:  9.142873022938147e-05
Valid Loss:  0.00012062740279361606
Epoch:  471  	Training Loss: 0.00012812099885195494
Test Loss:  9.131417027674615e-05
Valid Loss:  0.00012047262134728953
Epoch:  472  	Training Loss: 0.00012803553545381874
Test Loss:   95%|█████████▍| 473/500 [05:33<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:33<00:15,  1.65it/s] 95%|█████████▌| 477/500 [05:34<00:10,  2.25it/s] 96%|█████████▌| 479/500 [05:34<00:06,  3.02it/s] 96%|█████████▌| 481/500 [05:40<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:40<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:40<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:40<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:40<00:03,  3.03it/s] 98%|█████████▊| 491/500 [05:47<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:47<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:47<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:47<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:47<00:00,  3.01it/s]100%|██████████| 500/500 [05:47<00:00,  1.44it/s]
9.077235154109076e-05
Valid Loss:  0.00012010819045826793
Epoch:  473  	Training Loss: 0.00012787138985004276
Test Loss:  9.058311115950346e-05
Valid Loss:  0.00011993585212621838
Epoch:  474  	Training Loss: 0.00012773663911502808
Test Loss:  9.04725311556831e-05
Valid Loss:  0.00011980674753431231
Epoch:  475  	Training Loss: 0.00012760446406900883
Test Loss:  9.038057760335505e-05
Valid Loss:  0.000119687472761143
Epoch:  476  	Training Loss: 0.00012747164873871952
Test Loss:  9.029328066390008e-05
Valid Loss:  0.00011957228707615286
Epoch:  477  	Training Loss: 0.00012733644689433277
Test Loss:  9.02080355444923e-05
Valid Loss:  0.00011945876758545637
Epoch:  478  	Training Loss: 0.00012720125960186124
Test Loss:  9.012527880258858e-05
Valid Loss:  0.00011934769281651825
Epoch:  479  	Training Loss: 0.00012706717825494707
Test Loss:  9.004438470583409e-05
Valid Loss:  0.00011923967394977808
Epoch:  480  	Training Loss: 0.00012693146709352732
Test Loss:  8.996771066449583e-05
Valid Loss:  0.0001191264163935557
Epoch:  481  	Training Loss: 0.00012679051724262536
Test Loss:  8.988376794150099e-05
Valid Loss:  0.00011901122343260795
Epoch:  482  	Training Loss: 0.0001266509061679244
Test Loss:  8.986455213744193e-05
Valid Loss:  0.0001188787937280722
Epoch:  483  	Training Loss: 0.0001263119775103405
Test Loss:  8.976170647656545e-05
Valid Loss:  0.00011869670561281964
Epoch:  484  	Training Loss: 0.0001259903801837936
Test Loss:  8.96047058631666e-05
Valid Loss:  0.00011849756265291944
Epoch:  485  	Training Loss: 0.00012567700468935072
Test Loss:  8.939762483350933e-05
Valid Loss:  0.00011827149137388915
Epoch:  486  	Training Loss: 0.00012536387657746673
Test Loss:  8.91715899342671e-05
Valid Loss:  0.0001180323088192381
Epoch:  487  	Training Loss: 0.00012505616177804768
Test Loss:  8.8930843048729e-05
Valid Loss:  0.00011778285261243582
Epoch:  488  	Training Loss: 0.00012475522817112505
Test Loss:  8.868533041095361e-05
Valid Loss:  0.00011753290891647339
Epoch:  489  	Training Loss: 0.00012445737957023084
Test Loss:  8.843402611091733e-05
Valid Loss:  0.0001172766787931323
Epoch:  490  	Training Loss: 0.00012416430399753153
Test Loss:  8.818200149107724e-05
Valid Loss:  0.00011701896437443793
Epoch:  491  	Training Loss: 0.00012387314927764237
Test Loss:  8.793142478680238e-05
Valid Loss:  0.00011676071881083772
Epoch:  492  	Training Loss: 0.00012358222738839686
Test Loss:  8.788655395619571e-05
Valid Loss:  0.00011672313121380284
Epoch:  493  	Training Loss: 0.00012352981138974428
Test Loss:  8.787277329247445e-05
Valid Loss:  0.00011670097592286766
Epoch:  494  	Training Loss: 0.00012347722076810896
Test Loss:  8.786907710600644e-05
Valid Loss:  0.00011667911167023703
Epoch:  495  	Training Loss: 0.00012342305853962898
Test Loss:  8.787012484390289e-05
Valid Loss:  0.00011665926285786554
Epoch:  496  	Training Loss: 0.00012336911458987743
Test Loss:  8.787431579548866e-05
Valid Loss:  0.00011663886834867299
Epoch:  497  	Training Loss: 0.00012331671314314008
Test Loss:  8.787834667600691e-05
Valid Loss:  0.0001166198417195119
Epoch:  498  	Training Loss: 0.00012326525757089257
Test Loss:  8.788779086899012e-05
Valid Loss:  0.00011659836309263483
Epoch:  499  	Training Loss: 0.00012321214308030903
Test Loss:  8.789384446572512e-05
Valid Loss:  0.00011657389404717833
Epoch:  500  	Training Loss: 0.00012315961066633463
Test Loss:  8.79022481967695e-05
Valid Loss:  0.00011654198169708252
seed is  18
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.43it/s]  1%|          | 4/500 [00:00<00:30, 16.43it/s]  1%|          | 6/500 [00:00<00:30, 16.01it/s]  2%|▏         | 8/500 [00:00<00:32, 15.29it/s]  2%|▏         | 10/500 [00:00<00:31, 15.65it/s]  2%|▏         | 12/500 [00:00<00:32, 15.25it/s]  3%|▎         | 14/500 [00:00<00:31, 15.53it/s]  3%|▎         | 16/500 [00:01<00:30, 15.65it/s]  4%|▎         | 18/500 [00:01<00:30, 15.85it/s]  4%|▍         | 20/500 [00:01<00:30, 15.94it/s]  4%|▍         | 22/500 [00:01<00:29, 16.08it/s]  5%|▍         | 24/500 [00:01<00:29, 16.20it/s]  5%|▌         | 26/500 [00:01<00:29, 16.30it/s]  6%|▌         | 28/500 [00:01<00:28, 16.39it/s]  6%|▌         | 30/500 [00:01<00:28, 16.45it/s]  6%|▋         | 32/500 [00:01<00:28, 16.36it/s]  7%|▋         | 34/500 [00:02<00:28, 16.32it/s]  7%|▋         | 36/500 [00:02<00:28, 16.38it/s]  8%|▊         | 38/500 [00:02<00:28, 16.44it/s]  8%|▊         | 40/500 [00:02<00:27, 16.46it/s]  8%|▊         | 42/500 [00:02<00:28, 16.21it/s]  9%|▉         | 44/500 [00:02<00:28, 16.28it/s]  9%|▉         | 46/500 [00:02<00:27, 16.31it/s] 10%|▉         | 48/500 [00:02<00:27, 16.24it/s] 10%|█         | 50/500 [00:03<00:27, 16.22it/s] 10%|█         | 52/500 [00:03<00:27, 16.17it/s] 11%|█         | 54/500 [00:03<00:27, 16.31it/s] 11%|█         | 56/500 [00:03<00:27, 16.39it/s] 12%|█▏        | 58/500 [00:03<00:26, 16.42it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.42it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.37it/s] 13%|█▎        | 64/500 [00:03<00:27, 16.14it/s] 13%|█▎        | 66/500 [00:04<00:27, 16.07it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.06it/s] 14%|█▍        | 70/500 [00:04<00:26, 16.07it/s] 14%|█▍        | 72/500 [00:04<00:26, 15.97it/s] 15%|█▍        | 74/500 [00:04<00:26, 16.15it/s] 15%|█▌        | 76/500 [00:04<00:26, 16.18it/s] 16%|█▌        | 78/500 [00:04<00:26, 16.23it/s] 16%|█▌        | 80/500 [00:04<00:25, 16.28it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.97it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.95it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.13it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.25it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.32it/s] 18%|█▊        | 92/500 [00:05<00:24, 16.41it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.38it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.27it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.22it/s] 20%|██        | 100/500 [00:06<00:24, 16.33it/s] 20%|██        | 102/500 [00:06<00:24, 16.37it/s] 21%|██        | 104/500 [00:06<00:24, 16.35it/s] 21%|██        | 106/500 [00:06<00:24, 16.30it/s] 22%|██▏       | 108/500 [00:06<00:23, 16.36it/s] 22%|██▏       | 110/500 [00:06<00:23, 16.44it/s] 22%|██▏       | 112/500 [00:06<00:23, 16.39it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.28it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.30it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.35it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.43it/s] 24%|██▍       | 122/500 [00:07<00:22, 16.48it/s] 25%|██▍       | 124/500 [00:07<00:22, 16.51it/s]Epoch:  1  	Training Loss: 0.5382072925567627
Test Loss:  11666.2275390625
Valid Loss:  11696.9140625
Epoch:  2  	Training Loss: 11691.669921875
Test Loss:  4.076763232124598e+20
Valid Loss:  4.041367753803233e+20
Epoch:  3  	Training Loss: 4.0499632959045344e+20
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.52it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.47it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.54it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.50it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.47it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.47it/s] 28%|██▊       | 138/500 [00:08<00:21, 16.51it/s] 28%|██▊       | 140/500 [00:08<00:21, 16.49it/s] 28%|██▊       | 142/500 [00:08<00:21, 16.54it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.45it/s] 29%|██▉       | 146/500 [00:08<00:21, 16.38it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.32it/s] 30%|███       | 150/500 [00:09<00:21, 16.40it/s] 30%|███       | 152/500 [00:09<00:21, 16.35it/s] 31%|███       | 154/500 [00:09<00:21, 16.36it/s] 31%|███       | 156/500 [00:09<00:21, 16.37it/s] 32%|███▏      | 158/500 [00:09<00:21, 16.27it/s] 32%|███▏      | 160/500 [00:09<00:21, 16.14it/s] 32%|███▏      | 162/500 [00:09<00:21, 15.95it/s] 33%|███▎      | 164/500 [00:10<00:21, 15.96it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.05it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.18it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.24it/s] 34%|███▍      | 172/500 [00:10<00:20, 16.24it/s] 35%|███▍      | 174/500 [00:10<00:19, 16.32it/s] 35%|███▌      | 176/500 [00:10<00:19, 16.39it/s] 36%|███▌      | 178/500 [00:10<00:19, 16.42it/s] 36%|███▌      | 180/500 [00:11<00:19, 16.48it/s] 36%|███▋      | 182/500 [00:11<00:19, 16.31it/s] 37%|███▋      | 184/500 [00:11<00:19, 16.18it/s] 37%|███▋      | 186/500 [00:11<00:19, 16.14it/s] 38%|███▊      | 188/500 [00:11<00:19, 16.22it/s] 38%|███▊      | 190/500 [00:11<00:19, 16.28it/s] 38%|███▊      | 192/500 [00:11<00:18, 16.36it/s] 39%|███▉      | 194/500 [00:11<00:18, 16.34it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.30it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.28it/s] 40%|████      | 200/500 [00:12<00:18, 16.34it/s] 40%|████      | 202/500 [00:12<00:18, 16.07it/s] 41%|████      | 204/500 [00:12<00:18, 16.10it/s] 41%|████      | 206/500 [00:12<00:18, 16.20it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.28it/s] 42%|████▏     | 210/500 [00:12<00:17, 16.13it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.11it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.21it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.27it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.15it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.18it/s] 44%|████▍     | 222/500 [00:13<00:17, 16.25it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.33it/s] 45%|████▌     | 226/500 [00:13<00:16, 16.40it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.36it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.33it/s] 46%|████▋     | 232/500 [00:14<00:16, 16.23it/s] 47%|████▋     | 234/500 [00:14<00:16, 16.30it/s] 47%|████▋     | 236/500 [00:14<00:16, 16.33it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.35it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.36it/s] 48%|████▊     | 242/500 [00:14<00:15, 16.37it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.38it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.39it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.41it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.42it/s] 50%|█████     | 252/500 [00:15<00:15, 16.41it/s] 51%|█████     | 254/500 [00:15<00:14, 16.40it/s] 51%|█████     | 256/500 [00:15<00:14, 16.47it/s] 52%|█████▏    | 258/500 [00:15<00:14, 16.35it/s] 52%|█████▏    | 260/500 [00:15<00:14, 16.32it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.36it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.29it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.32it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.39it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.42it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.26it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.28it/s] 55%|█████▌    | 276/500 [00:16<00:13, 16.25it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.18it/s] 56%|█████▌    | 280/500 [00:17<00:13, 16.27it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.32it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.36it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.39it/s] 58%|█████▊    | 288/500 [00:17<00:12, 16.42it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.45it/s] 58%|█████▊    | 292/500 [00:17<00:12, 16.32it/s] 59%|█████▉    | 294/500 [00:18<00:12, 15.97it/s] 59%|█████▉    | 296/500 [00:18<00:12, 15.94it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.09it/s] 60%|██████    | 300/500 [00:18<00:12, 16.28it/s] 60%|██████    | 302/500 [00:18<00:12, 16.30it/s] 61%|██████    | 304/500 [00:18<00:11, 16.38it/s] 61%|██████    | 306/500 [00:18<00:11, 16.35it/s] 62%|██████▏   | 308/500 [00:18<00:12, 15.53it/s] 62%|██████▏   | 310/500 [00:19<00:12, 15.66it/s] 62%|██████▏   | 312/500 [00:19<00:12, 15.62it/s] 63%|██████▎   | 314/500 [00:19<00:11, 15.84it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.09it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.18it/s] 64%|██████▍   | 320/500 [00:19<00:11, 16.30it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.35it/s] 65%|██████▍   | 324/500 [00:19<00:10, 16.30it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.33it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.32it/s] 66%|██████▌   | 330/500 [00:20<00:10, 16.23it/s] 66%|██████▋   | 332/500 [00:20<00:10, 16.34it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.25it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.34it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.38it/s] 68%|██████▊   | 340/500 [00:20<00:09, 16.41it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.47it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.47it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.48it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.34it/s] 70%|███████   | 350/500 [00:21<00:09, 16.35it/s] 70%|███████   | 352/500 [00:21<00:09, 16.39it/s] 71%|███████   | 354/500 [00:21<00:08, 16.38it/s] 71%|███████   | 356/500 [00:21<00:08, 16.40it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.42it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.45it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.42it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.45it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.43it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.41it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.36it/s] 74%|███████▍  | 372/500 [00:22<00:07, 16.27it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:22<00:07, 16.29it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.23it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.34it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.35it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.44it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.36it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.44it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.35it/s] 78%|███████▊  | 390/500 [00:23<00:06, 16.23it/s] 78%|███████▊  | 392/500 [00:24<00:06, 15.48it/s] 79%|███████▉  | 394/500 [00:24<00:06, 15.74it/s] 79%|███████▉  | 396/500 [00:24<00:06, 15.58it/s] 80%|███████▉  | 398/500 [00:24<00:06, 15.22it/s] 80%|████████  | 400/500 [00:24<00:06, 15.43it/s] 80%|████████  | 402/500 [00:24<00:06, 14.25it/s] 81%|████████  | 404/500 [00:24<00:06, 14.76it/s] 81%|████████  | 406/500 [00:25<00:06, 15.03it/s] 82%|████████▏ | 408/500 [00:25<00:05, 15.35it/s] 82%|████████▏ | 410/500 [00:25<00:05, 15.64it/s] 82%|████████▏ | 412/500 [00:25<00:05, 15.75it/s] 83%|████████▎ | 414/500 [00:25<00:05, 15.88it/s] 83%|████████▎ | 416/500 [00:25<00:05, 15.95it/s] 84%|████████▎ | 418/500 [00:25<00:05, 16.08it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.08it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.23it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.35it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.40it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.46it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.47it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.36it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.25it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.27it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.28it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.20it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.11it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.21it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.27it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.31it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.35it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.34it/s] 91%|█████████ | 454/500 [00:27<00:02, 16.42it/s] 91%|█████████ | 456/500 [00:28<00:02, 16.44it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.49it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.50it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.43it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.48it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.34it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.36it/s] 94%|█████████▍| 470/500 [00:28<00:01, 16.23it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.31it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.32it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.32it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.29it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.36it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.36it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.39it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.35it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.39it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.32it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.37it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.42it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.43it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.48it/s]100%|██████████| 500/500 [00:30<00:00, 16.25it/s]100%|██████████| 500/500 [00:30<00:00, 16.23it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  18
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:34,  6.20s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:57,  1.18it/s]  1%|▏         | 7/500 [00:06<04:14,  1.94it/s]  2%|▏         | 9/500 [00:06<02:50,  2.88it/s]  2%|▏         | 11/500 [00:13<10:51,  1.33s/it]  3%|▎         | 13/500 [00:13<07:25,  1.09it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.97it/s]  4%|▍         | 21/500 [00:19<09:33,  1.20s/it]  5%|▍         | 23/500 [00:20<06:47,  1.17it/s]  5%|▌         | 25/500 [00:20<04:52,  1.63it/s]  5%|▌         | 27/500 [00:20<03:32,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.00it/s]  6%|▌         | 31/500 [00:26<09:15,  1.18s/it]  7%|▋         | 33/500 [00:26<06:36,  1.18it/s]  7%|▋         | 35/500 [00:27<04:45,  1.63it/s]  7%|▋         | 37/500 [00:27<03:28,  2.22it/s]  8%|▊         | 39/500 [00:27<02:34,  2.99it/s]  8%|▊         | 41/500 [00:33<08:59,  1.17s/it]  9%|▊         | 43/500 [00:33<06:26,  1.18it/s]  9%|▉         | 45/500 [00:33<04:37,  1.64it/s]  9%|▉         | 47/500 [00:33<03:22,  2.24it/s] 10%|▉         | 49/500 [00:34<02:29,  3.01it/s] 10%|█         | 51/500 [00:40<08:43,  1.17s/it] 11%|█         | 53/500 [00:40<06:16,  1.19it/s] 11%|█         | 55/500 [00:40<04:30,  1.64it/s] 11%|█▏        | 57/500 [00:40<03:17,  2.25it/s] 12%|█▏        | 59/500 [00:40<02:25,  3.02it/s] 12%|█▏        | 61/500 [00:47<08:30,  1.16s/it] 13%|█▎        | 63/500 [00:47<06:05,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:24,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:47<02:22,  3.02it/s] 14%|█▍        | 71/500 [00:53<08:21,  1.17s/it] 15%|█▍        | 73/500 [00:54<05:58,  1.19it/s]Epoch:  1  	Training Loss: 0.5382072925567627
Test Loss:  72.7817611694336
Valid Loss:  71.63346862792969
Epoch:  2  	Training Loss: 71.92866516113281
Test Loss:  0.5889146327972412
Valid Loss:  0.5831665396690369
Epoch:  3  	Training Loss: 0.5912472605705261
Test Loss:  0.5882828831672668
Valid Loss:  0.5825442671775818
Epoch:  4  	Training Loss: 0.590618371963501
Test Loss:  0.5876511335372925
Valid Loss:  0.5819219350814819
Epoch:  5  	Training Loss: 0.5899893641471863
Test Loss:  0.5870192646980286
Valid Loss:  0.5812994837760925
Epoch:  6  	Training Loss: 0.5893602967262268
Test Loss:  0.5863981246948242
Valid Loss:  0.5806925296783447
Epoch:  7  	Training Loss: 0.5887460708618164
Test Loss:  0.5862954258918762
Valid Loss:  0.5805939435958862
Epoch:  8  	Training Loss: 0.5886486768722534
Test Loss:  0.5862927436828613
Valid Loss:  0.5805912017822266
Epoch:  9  	Training Loss: 0.588645875453949
Test Loss:  0.5862900018692017
Valid Loss:  0.5805884003639221
Epoch:  10  	Training Loss: 0.5886430740356445
Test Loss:  0.5862873196601868
Valid Loss:  0.5805855989456177
Epoch:  11  	Training Loss: 0.5886402130126953
Test Loss:  0.5862846374511719
Valid Loss:  0.5805827975273132
Epoch:  12  	Training Loss: 0.5886374711990356
Test Loss:  0.586283266544342
Valid Loss:  0.5805814862251282
Epoch:  13  	Training Loss: 0.588636040687561
Test Loss:  0.5862818956375122
Valid Loss:  0.5805801153182983
Epoch:  14  	Training Loss: 0.5886346697807312
Test Loss:  0.5862805843353271
Valid Loss:  0.5805788040161133
Epoch:  15  	Training Loss: 0.5886332988739014
Test Loss:  0.5862792730331421
Valid Loss:  0.5805773735046387
Epoch:  16  	Training Loss: 0.5886318683624268
Test Loss:  0.586277961730957
Valid Loss:  0.5805760622024536
Epoch:  17  	Training Loss: 0.5886305570602417
Test Loss:  0.586276650428772
Valid Loss:  0.5805747509002686
Epoch:  18  	Training Loss: 0.5886292457580566
Test Loss:  0.5862752795219421
Valid Loss:  0.580573320388794
Epoch:  19  	Training Loss: 0.588627815246582
Test Loss:  0.5862739682197571
Valid Loss:  0.5805719494819641
Epoch:  20  	Training Loss: 0.5886263847351074
Test Loss:  0.5862725973129272
Valid Loss:  0.5805705785751343
Epoch:  21  	Training Loss: 0.5886250734329224
Test Loss:  0.5862712860107422
Valid Loss:  0.5805692076683044
Epoch:  22  	Training Loss: 0.5886237025260925
Test Loss:  0.5862699151039124
Valid Loss:  0.5805678367614746
Epoch:  23  	Training Loss: 0.5886222720146179
Test Loss:  0.5862685441970825
Valid Loss:  0.5805664658546448
Epoch:  24  	Training Loss: 0.5886208415031433
Test Loss:  0.5862671136856079
Valid Loss:  0.5805649757385254
Epoch:  25  	Training Loss: 0.5886193513870239
Test Loss:  0.5862658023834229
Valid Loss:  0.5805636644363403
Epoch:  26  	Training Loss: 0.5886179208755493
Test Loss:  0.586264431476593
Valid Loss:  0.580562174320221
Epoch:  27  	Training Loss: 0.5886165499687195
Test Loss:  0.5862630605697632
Valid Loss:  0.5805609226226807
Epoch:  28  	Training Loss: 0.5886151194572449
Test Loss:  0.5862616300582886
Valid Loss:  0.5805594325065613
Epoch:  29  	Training Loss: 0.588613748550415
Test Loss:  0.5862603187561035
Valid Loss:  0.5805580019950867
Epoch:  30  	Training Loss: 0.5886123180389404
Test Loss:  0.5862589478492737
Valid Loss:  0.5805566310882568
Epoch:  31  	Training Loss: 0.5886108875274658
Test Loss:  0.5862575769424438
Valid Loss:  0.5805552005767822
Epoch:  32  	Training Loss: 0.5886094570159912
Test Loss:  0.5862562656402588
Valid Loss:  0.5805538892745972
Epoch:  33  	Training Loss: 0.5886081457138062
Test Loss:  0.5862549543380737
Valid Loss:  0.5805525779724121
Epoch:  34  	Training Loss: 0.5886068344116211
Test Loss:  0.5862536430358887
Valid Loss:  0.5805513262748718
Epoch:  35  	Training Loss: 0.5886054635047913
Test Loss:  0.5862523317337036
Valid Loss:  0.580549955368042
Epoch:  36  	Training Loss: 0.5886040925979614
Test Loss:  0.5862510204315186
Valid Loss:  0.5805486440658569
Epoch:  37  	Training Loss: 0.5886027812957764
Test Loss:  0.5862497687339783
Valid Loss:  0.5805473327636719
Epoch:  38  	Training Loss: 0.5886014103889465
Test Loss:  0.586248517036438
Valid Loss:  0.5805460214614868
Epoch:  39  	Training Loss: 0.5886000394821167
Test Loss:  0.5862472057342529
Valid Loss:  0.580544650554657
Epoch:  40  	Training Loss: 0.5885987281799316
Test Loss:  0.5862458348274231
Valid Loss:  0.5805433988571167
Epoch:  41  	Training Loss: 0.5885974168777466
Test Loss:  0.5862445831298828
Valid Loss:  0.5805420279502869
Epoch:  42  	Training Loss: 0.5885960459709167
Test Loss:  0.5862432718276978
Valid Loss:  0.580540657043457
Epoch:  43  	Training Loss: 0.5885946750640869
Test Loss:  0.5862419605255127
Valid Loss:  0.580539345741272
Epoch:  44  	Training Loss: 0.5885933637619019
Test Loss:  0.5862406492233276
Valid Loss:  0.5805380344390869
Epoch:  45  	Training Loss: 0.588591992855072
Test Loss:  0.5862393379211426
Valid Loss:  0.5805367231369019
Epoch:  46  	Training Loss: 0.588590681552887
Test Loss:  0.5862380266189575
Valid Loss:  0.5805354118347168
Epoch:  47  	Training Loss: 0.5885893106460571
Test Loss:  0.5862367153167725
Valid Loss:  0.5805341005325317
Epoch:  48  	Training Loss: 0.5885879993438721
Test Loss:  0.5862354040145874
Valid Loss:  0.5805326700210571
Epoch:  49  	Training Loss: 0.5885866284370422
Test Loss:  0.5862341523170471
Valid Loss:  0.5805314183235168
Epoch:  50  	Training Loss: 0.5885852575302124
Test Loss:  0.5862329006195068
Valid Loss:  0.580530047416687
Epoch:  51  	Training Loss: 0.5885839462280273
Test Loss:  0.586231529712677
Valid Loss:  0.580528736114502
Epoch:  52  	Training Loss: 0.5885826349258423
Test Loss:  0.5862302780151367
Valid Loss:  0.5805274248123169
Epoch:  53  	Training Loss: 0.5885812640190125
Test Loss:  0.5862289667129517
Valid Loss:  0.5805261135101318
Epoch:  54  	Training Loss: 0.5885798931121826
Test Loss:  0.5862276554107666
Valid Loss:  0.580524742603302
Epoch:  55  	Training Loss: 0.5885785818099976
Test Loss:  0.5862263441085815
Valid Loss:  0.5805233716964722
Epoch:  56  	Training Loss: 0.5885772109031677
Test Loss:  0.5862250328063965
Valid Loss:  0.5805220603942871
Epoch:  57  	Training Loss: 0.5885758399963379
Test Loss:  0.5862237215042114
Valid Loss:  0.5805208086967468
Epoch:  58  	Training Loss: 0.5885745286941528
Test Loss:  0.5862224102020264
Valid Loss:  0.580519437789917
Epoch:  59  	Training Loss: 0.588573157787323
Test Loss:  0.5862210988998413
Valid Loss:  0.5805181264877319
Epoch:  60  	Training Loss: 0.5885718464851379
Test Loss:  0.5862197875976562
Valid Loss:  0.5805168151855469
Epoch:  61  	Training Loss: 0.5885704755783081
Test Loss:  0.5862184762954712
Valid Loss:  0.5805153846740723
Epoch:  62  	Training Loss: 0.5885691046714783
Test Loss:  0.5862172245979309
Valid Loss:  0.580514132976532
Epoch:  63  	Training Loss: 0.588567852973938
Test Loss:  0.5862159132957458
Valid Loss:  0.5805128812789917
Epoch:  64  	Training Loss: 0.5885665416717529
Test Loss:  0.5862146615982056
Valid Loss:  0.5805115699768066
Epoch:  65  	Training Loss: 0.5885651707649231
Test Loss:  0.5862134695053101
Valid Loss:  0.5805102586746216
Epoch:  66  	Training Loss: 0.5885639190673828
Test Loss:  0.586212158203125
Valid Loss:  0.5805090069770813
Epoch:  67  	Training Loss: 0.5885626077651978
Test Loss:  0.5862108469009399
Valid Loss:  0.580507755279541
Epoch:  68  	Training Loss: 0.5885612964630127
Test Loss:  0.5862095952033997
Valid Loss:  0.580506443977356
Epoch:  69  	Training Loss: 0.5885599851608276
Test Loss:  0.5862083435058594
Valid Loss:  0.5805051326751709
Epoch:  70  	Training Loss: 0.5885586738586426
Test Loss:  0.5862071514129639
Valid Loss:  0.5805038213729858
Epoch:  71  	Training Loss: 0.5885573625564575
Test Loss:  0.5862058401107788
Valid Loss:  0.5805025100708008
Epoch:  72  	Training Loss: 0.5885560512542725
Test Loss:  0.5862045288085938
Valid Loss:  0.5805012583732605
Epoch:  73  	Training Loss: 0.5885547399520874
Test Loss:  0.5862032175064087
Valid Loss:  0.5804999470710754
Epoch:  74  	Training Loss: 0.5885533690452576
Test Loss:  0.5862019062042236
Valid Loss:  0.5804985761642456
Epoch:  75  	Training Loss: 0.5885519981384277
Test Loss:  0.5862005949020386
Valid Loss:   15%|█▌        | 75/500 [00:54<04:17,  1.65it/s] 15%|█▌        | 77/500 [00:54<03:07,  2.25it/s] 16%|█▌        | 79/500 [00:54<02:19,  3.02it/s] 16%|█▌        | 81/500 [01:00<08:06,  1.16s/it] 17%|█▋        | 83/500 [01:00<05:48,  1.20it/s] 17%|█▋        | 85/500 [01:01<04:37,  1.50it/s] 17%|█▋        | 86/500 [01:01<03:59,  1.73it/s] 18%|█▊        | 88/500 [01:01<02:48,  2.44it/s] 18%|█▊        | 90/500 [01:01<02:02,  3.35it/s] 18%|█▊        | 92/500 [01:08<08:11,  1.20s/it] 19%|█▉        | 94/500 [01:08<05:44,  1.18it/s] 19%|█▉        | 96/500 [01:08<04:05,  1.64it/s] 20%|█▉        | 98/500 [01:08<02:57,  2.26it/s] 20%|██        | 100/500 [01:08<02:10,  3.05it/s] 20%|██        | 102/500 [01:14<07:53,  1.19s/it] 21%|██        | 104/500 [01:15<05:36,  1.18it/s] 21%|██        | 106/500 [01:15<04:01,  1.63it/s] 22%|██▏       | 108/500 [01:15<02:55,  2.23it/s] 22%|██▏       | 110/500 [01:15<02:09,  3.00it/s] 22%|██▏       | 112/500 [01:21<07:32,  1.17s/it] 23%|██▎       | 114/500 [01:21<05:22,  1.20it/s] 23%|██▎       | 116/500 [01:21<03:52,  1.65it/s] 24%|██▎       | 118/500 [01:22<02:49,  2.26it/s] 24%|██▍       | 120/500 [01:22<02:05,  3.04it/s] 24%|██▍       | 122/500 [01:28<07:17,  1.16s/it] 25%|██▍       | 124/500 [01:28<05:12,  1.20it/s] 25%|██▌       | 126/500 [01:28<03:44,  1.66it/s] 26%|██▌       | 128/500 [01:28<02:43,  2.27it/s] 26%|██▌       | 130/500 [01:28<02:01,  3.05it/s] 26%|██▋       | 132/500 [01:35<07:08,  1.16s/it] 27%|██▋       | 134/500 [01:35<05:05,  1.20it/s] 27%|██▋       | 136/500 [01:35<03:39,  1.66it/s] 28%|██▊       | 138/500 [01:35<02:40,  2.26it/s] 28%|██▊       | 140/500 [01:35<01:58,  3.04it/s] 28%|██▊       | 142/500 [01:42<07:02,  1.18s/it] 29%|██▉       | 144/500 [01:42<05:01,  1.18it/s] 29%|██▉       | 146/500 [01:42<03:37,  1.63it/s] 30%|██▉       | 148/500 [01:42<02:37,  2.23it/s]0.5804972648620605
Epoch:  76  	Training Loss: 0.5885506868362427
Test Loss:  0.5861992835998535
Valid Loss:  0.5804959535598755
Epoch:  77  	Training Loss: 0.5885493755340576
Test Loss:  0.5861979722976685
Valid Loss:  0.5804946422576904
Epoch:  78  	Training Loss: 0.5885480642318726
Test Loss:  0.5861967206001282
Valid Loss:  0.5804933309555054
Epoch:  79  	Training Loss: 0.5885466933250427
Test Loss:  0.5861954689025879
Valid Loss:  0.5804920196533203
Epoch:  80  	Training Loss: 0.5885454416275024
Test Loss:  0.5861940979957581
Valid Loss:  0.5804906487464905
Epoch:  81  	Training Loss: 0.5885440707206726
Test Loss:  0.5861928462982178
Valid Loss:  0.5804893970489502
Epoch:  82  	Training Loss: 0.5885426998138428
Test Loss:  0.5861914157867432
Valid Loss:  0.5804879665374756
Epoch:  83  	Training Loss: 0.5885412693023682
Test Loss:  0.5861901044845581
Valid Loss:  0.580486536026001
Epoch:  84  	Training Loss: 0.5885398387908936
Test Loss:  0.5861886739730835
Valid Loss:  0.5804852247238159
Epoch:  85  	Training Loss: 0.5885384678840637
Test Loss:  0.5861873626708984
Valid Loss:  0.5804837942123413
Epoch:  86  	Training Loss: 0.5885370969772339
Test Loss:  0.5861859321594238
Valid Loss:  0.5804823637008667
Epoch:  87  	Training Loss: 0.5885356664657593
Test Loss:  0.5861846208572388
Valid Loss:  0.5804809927940369
Epoch:  88  	Training Loss: 0.5885342359542847
Test Loss:  0.5861831903457642
Valid Loss:  0.580479621887207
Epoch:  89  	Training Loss: 0.5885328054428101
Test Loss:  0.5861818194389343
Valid Loss:  0.5804781913757324
Epoch:  90  	Training Loss: 0.5885313749313354
Test Loss:  0.5861804485321045
Valid Loss:  0.5804767608642578
Epoch:  91  	Training Loss: 0.5885299444198608
Test Loss:  0.5861790180206299
Valid Loss:  0.5804754495620728
Epoch:  92  	Training Loss: 0.588528573513031
Test Loss:  0.5861777067184448
Valid Loss:  0.5804740190505981
Epoch:  93  	Training Loss: 0.5885271430015564
Test Loss:  0.5861762762069702
Valid Loss:  0.5804726481437683
Epoch:  94  	Training Loss: 0.5885257720947266
Test Loss:  0.5861749053001404
Valid Loss:  0.5804712772369385
Epoch:  95  	Training Loss: 0.588524341583252
Test Loss:  0.5861735343933105
Valid Loss:  0.5804698467254639
Epoch:  96  	Training Loss: 0.5885229110717773
Test Loss:  0.5861722230911255
Valid Loss:  0.5804684162139893
Epoch:  97  	Training Loss: 0.5885215401649475
Test Loss:  0.5861707925796509
Valid Loss:  0.5804671049118042
Epoch:  98  	Training Loss: 0.5885201692581177
Test Loss:  0.5861694812774658
Valid Loss:  0.5804656744003296
Epoch:  99  	Training Loss: 0.5885187387466431
Test Loss:  0.5861680507659912
Valid Loss:  0.5804643034934998
Epoch:  100  	Training Loss: 0.5885173082351685
Test Loss:  0.5861666202545166
Valid Loss:  0.5804629325866699
Epoch:  101  	Training Loss: 0.5885158777236938
Test Loss:  0.5861653089523315
Valid Loss:  0.5804615020751953
Epoch:  102  	Training Loss: 0.588514506816864
Test Loss:  0.5861639976501465
Valid Loss:  0.580460250377655
Epoch:  103  	Training Loss: 0.588513195514679
Test Loss:  0.5861627459526062
Valid Loss:  0.5804588794708252
Epoch:  104  	Training Loss: 0.5885118246078491
Test Loss:  0.5861614942550659
Valid Loss:  0.5804575681686401
Epoch:  105  	Training Loss: 0.5885105133056641
Test Loss:  0.5861601829528809
Valid Loss:  0.5804563760757446
Epoch:  106  	Training Loss: 0.588509202003479
Test Loss:  0.5861588716506958
Valid Loss:  0.5804550647735596
Epoch:  107  	Training Loss: 0.588507890701294
Test Loss:  0.5861576795578003
Valid Loss:  0.5804537534713745
Epoch:  108  	Training Loss: 0.5885065793991089
Test Loss:  0.5861563682556152
Valid Loss:  0.5804524421691895
Epoch:  109  	Training Loss: 0.5885052680969238
Test Loss:  0.5861550569534302
Valid Loss:  0.5804511308670044
Epoch:  110  	Training Loss: 0.5885040163993835
Test Loss:  0.5861537456512451
Valid Loss:  0.5804498195648193
Epoch:  111  	Training Loss: 0.5885026454925537
Test Loss:  0.5861524939537048
Valid Loss:  0.5804485082626343
Epoch:  112  	Training Loss: 0.5885013341903687
Test Loss:  0.5861511826515198
Valid Loss:  0.5804471969604492
Epoch:  113  	Training Loss: 0.5884999632835388
Test Loss:  0.5861498713493347
Valid Loss:  0.5804458856582642
Epoch:  114  	Training Loss: 0.588498592376709
Test Loss:  0.5861485004425049
Valid Loss:  0.5804445743560791
Epoch:  115  	Training Loss: 0.5884972810745239
Test Loss:  0.5861471891403198
Valid Loss:  0.5804431438446045
Epoch:  116  	Training Loss: 0.5884958505630493
Test Loss:  0.58614581823349
Valid Loss:  0.5804418325424194
Epoch:  117  	Training Loss: 0.5884945392608643
Test Loss:  0.5861445665359497
Valid Loss:  0.5804404616355896
Epoch:  118  	Training Loss: 0.5884931087493896
Test Loss:  0.5861431360244751
Valid Loss:  0.5804390907287598
Epoch:  119  	Training Loss: 0.5884917974472046
Test Loss:  0.58614182472229
Valid Loss:  0.5804377794265747
Epoch:  120  	Training Loss: 0.5884904265403748
Test Loss:  0.586140513420105
Valid Loss:  0.5804364681243896
Epoch:  121  	Training Loss: 0.5884890556335449
Test Loss:  0.5861392021179199
Valid Loss:  0.5804350972175598
Epoch:  122  	Training Loss: 0.5884877443313599
Test Loss:  0.5861378908157349
Valid Loss:  0.5804338455200195
Epoch:  123  	Training Loss: 0.5884864330291748
Test Loss:  0.5861366987228394
Valid Loss:  0.5804325342178345
Epoch:  124  	Training Loss: 0.5884851217269897
Test Loss:  0.5861353874206543
Valid Loss:  0.5804312825202942
Epoch:  125  	Training Loss: 0.5884838104248047
Test Loss:  0.5861341953277588
Valid Loss:  0.5804299712181091
Epoch:  126  	Training Loss: 0.5884824991226196
Test Loss:  0.5861328840255737
Valid Loss:  0.5804286599159241
Epoch:  127  	Training Loss: 0.5884812474250793
Test Loss:  0.5861315727233887
Valid Loss:  0.5804274082183838
Epoch:  128  	Training Loss: 0.5884799361228943
Test Loss:  0.5861303806304932
Valid Loss:  0.5804260969161987
Epoch:  129  	Training Loss: 0.5884786248207092
Test Loss:  0.5861290693283081
Valid Loss:  0.5804248452186584
Epoch:  130  	Training Loss: 0.588477373123169
Test Loss:  0.5861278176307678
Valid Loss:  0.5804235935211182
Epoch:  131  	Training Loss: 0.5884760618209839
Test Loss:  0.5861265659332275
Valid Loss:  0.5804222822189331
Epoch:  132  	Training Loss: 0.5884747505187988
Test Loss:  0.5861252546310425
Valid Loss:  0.580420970916748
Epoch:  133  	Training Loss: 0.588473379611969
Test Loss:  0.5861238837242126
Valid Loss:  0.5804196000099182
Epoch:  134  	Training Loss: 0.5884720087051392
Test Loss:  0.5861225724220276
Valid Loss:  0.5804182291030884
Epoch:  135  	Training Loss: 0.5884706974029541
Test Loss:  0.5861212015151978
Valid Loss:  0.5804169178009033
Epoch:  136  	Training Loss: 0.5884692668914795
Test Loss:  0.5861198902130127
Valid Loss:  0.5804156064987183
Epoch:  137  	Training Loss: 0.5884679555892944
Test Loss:  0.5861185789108276
Valid Loss:  0.5804142355918884
Epoch:  138  	Training Loss: 0.5884666442871094
Test Loss:  0.5861172676086426
Valid Loss:  0.5804128646850586
Epoch:  139  	Training Loss: 0.5884652137756348
Test Loss:  0.5861159563064575
Valid Loss:  0.5804115533828735
Epoch:  140  	Training Loss: 0.5884639024734497
Test Loss:  0.5861145853996277
Valid Loss:  0.5804102420806885
Epoch:  141  	Training Loss: 0.5884625315666199
Test Loss:  0.5861132740974426
Valid Loss:  0.5804088711738586
Epoch:  142  	Training Loss: 0.58846116065979
Test Loss:  0.5861119031906128
Valid Loss:  0.5804075598716736
Epoch:  143  	Training Loss: 0.588459849357605
Test Loss:  0.5861106514930725
Valid Loss:  0.5804061889648438
Epoch:  144  	Training Loss: 0.5884584784507751
Test Loss:  0.5861092805862427
Valid Loss:  0.5804048776626587
Epoch:  145  	Training Loss: 0.5884571075439453
Test Loss:  0.5861080288887024
Valid Loss:  0.5804035663604736
Epoch:  146  	Training Loss: 0.5884557366371155
Test Loss:  0.5861066579818726
Valid Loss:  0.5804022550582886
Epoch:  147  	Training Loss: 0.5884544253349304
Test Loss:  0.5861054062843323
Valid Loss:  0.5804009437561035
Epoch:  148  	Training Loss: 0.5884530544281006
Test Loss:  0.5861040353775024
Valid Loss:  0.5803995728492737
Epoch:  149  	Training Loss: 0.5884517431259155
Test Loss:  0.5861027240753174
Valid Loss:  0.5803982615470886
 30%|███       | 150/500 [01:42<01:56,  3.00it/s] 30%|███       | 152/500 [01:48<06:46,  1.17s/it] 31%|███       | 154/500 [01:48<04:49,  1.19it/s] 31%|███       | 156/500 [01:49<03:28,  1.65it/s] 32%|███▏      | 158/500 [01:49<02:32,  2.25it/s] 32%|███▏      | 160/500 [01:49<01:52,  3.02it/s] 32%|███▏      | 162/500 [01:55<06:32,  1.16s/it] 33%|███▎      | 164/500 [01:55<04:40,  1.20it/s] 33%|███▎      | 166/500 [01:55<03:21,  1.66it/s] 34%|███▎      | 168/500 [01:55<02:27,  2.25it/s] 34%|███▍      | 170/500 [01:56<02:02,  2.69it/s] 34%|███▍      | 172/500 [02:02<06:52,  1.26s/it] 35%|███▍      | 173/500 [02:03<05:52,  1.08s/it] 35%|███▍      | 174/500 [02:03<04:49,  1.13it/s] 35%|███▌      | 175/500 [02:03<03:52,  1.40it/s] 35%|███▌      | 177/500 [02:03<02:29,  2.16it/s] 36%|███▌      | 179/500 [02:03<01:43,  3.10it/s] 36%|███▌      | 181/500 [02:09<06:43,  1.27s/it] 37%|███▋      | 183/500 [02:10<04:37,  1.14it/s] 37%|███▋      | 185/500 [02:10<03:14,  1.62it/s] 37%|███▋      | 187/500 [02:10<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:10<01:42,  3.04it/s] 38%|███▊      | 191/500 [02:16<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:16<04:20,  1.18it/s] 39%|███▉      | 195/500 [02:17<03:06,  1.64it/s] 39%|███▉      | 197/500 [02:17<02:15,  2.24it/s] 40%|███▉      | 199/500 [02:17<01:39,  3.01it/s] 40%|████      | 201/500 [02:23<05:50,  1.17s/it] 41%|████      | 203/500 [02:23<04:09,  1.19it/s] 41%|████      | 205/500 [02:23<02:59,  1.64it/s] 41%|████▏     | 207/500 [02:23<02:10,  2.24it/s] 42%|████▏     | 209/500 [02:24<01:36,  3.01it/s] 42%|████▏     | 211/500 [02:30<05:35,  1.16s/it] 43%|████▎     | 213/500 [02:30<03:59,  1.20it/s] 43%|████▎     | 215/500 [02:30<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:30<02:06,  2.24it/s] 44%|████▍     | 219/500 [02:30<01:33,  3.02it/s] 44%|████▍     | 221/500 [02:37<05:33,  1.19s/it] 45%|████▍     | 223/500 [02:37<03:57,  1.17it/s]Epoch:  150  	Training Loss: 0.5884503722190857
Test Loss:  0.5861014127731323
Valid Loss:  0.5803968906402588
Epoch:  151  	Training Loss: 0.5884490609169006
Test Loss:  0.5861001014709473
Valid Loss:  0.5803955793380737
Epoch:  152  	Training Loss: 0.5884476900100708
Test Loss:  0.586098849773407
Valid Loss:  0.5803943276405334
Epoch:  153  	Training Loss: 0.5884464383125305
Test Loss:  0.5860977172851562
Valid Loss:  0.5803930759429932
Epoch:  154  	Training Loss: 0.5884451866149902
Test Loss:  0.5860964059829712
Valid Loss:  0.5803918838500977
Epoch:  155  	Training Loss: 0.58844393491745
Test Loss:  0.5860952138900757
Valid Loss:  0.5803906321525574
Epoch:  156  	Training Loss: 0.5884426832199097
Test Loss:  0.5860939621925354
Valid Loss:  0.5803893804550171
Epoch:  157  	Training Loss: 0.5884414315223694
Test Loss:  0.5860928297042847
Valid Loss:  0.5803881883621216
Epoch:  158  	Training Loss: 0.5884401798248291
Test Loss:  0.5860915184020996
Valid Loss:  0.5803868770599365
Epoch:  159  	Training Loss: 0.5884389281272888
Test Loss:  0.5860903263092041
Valid Loss:  0.580385684967041
Epoch:  160  	Training Loss: 0.5884376764297485
Test Loss:  0.5860891342163086
Valid Loss:  0.5803844332695007
Epoch:  161  	Training Loss: 0.5884363651275635
Test Loss:  0.5860878825187683
Valid Loss:  0.5803832411766052
Epoch:  162  	Training Loss: 0.588435173034668
Test Loss:  0.586086630821228
Valid Loss:  0.5803819894790649
Epoch:  163  	Training Loss: 0.5884338617324829
Test Loss:  0.5860853791236877
Valid Loss:  0.5803806781768799
Epoch:  164  	Training Loss: 0.5884326100349426
Test Loss:  0.5860841274261475
Valid Loss:  0.5803794860839844
Epoch:  165  	Training Loss: 0.5884313583374023
Test Loss:  0.5860828757286072
Valid Loss:  0.5803781747817993
Epoch:  166  	Training Loss: 0.5884301066398621
Test Loss:  0.5860816240310669
Valid Loss:  0.580376923084259
Epoch:  167  	Training Loss: 0.588428795337677
Test Loss:  0.5860803723335266
Valid Loss:  0.5803756713867188
Epoch:  168  	Training Loss: 0.5884274840354919
Test Loss:  0.5860791206359863
Valid Loss:  0.5803743600845337
Epoch:  169  	Training Loss: 0.5884262323379517
Test Loss:  0.5860779285430908
Valid Loss:  0.5803731679916382
Epoch:  170  	Training Loss: 0.5884249210357666
Test Loss:  0.5860766172409058
Valid Loss:  0.5803718566894531
Epoch:  171  	Training Loss: 0.5884236097335815
Test Loss:  0.5860753655433655
Valid Loss:  0.5803706049919128
Epoch:  172  	Training Loss: 0.5884222984313965
Test Loss:  0.58607417345047
Valid Loss:  0.5803693532943726
Epoch:  173  	Training Loss: 0.588421106338501
Test Loss:  0.5860729217529297
Valid Loss:  0.5803681015968323
Epoch:  174  	Training Loss: 0.5884198546409607
Test Loss:  0.5860717296600342
Valid Loss:  0.5803669095039368
Epoch:  175  	Training Loss: 0.5884186029434204
Test Loss:  0.5860704779624939
Valid Loss:  0.5803656578063965
Epoch:  176  	Training Loss: 0.5884173512458801
Test Loss:  0.5860692262649536
Valid Loss:  0.5803643465042114
Epoch:  177  	Training Loss: 0.5884160995483398
Test Loss:  0.5860680341720581
Valid Loss:  0.5803631544113159
Epoch:  178  	Training Loss: 0.5884148478507996
Test Loss:  0.5860668420791626
Valid Loss:  0.5803619623184204
Epoch:  179  	Training Loss: 0.5884135961532593
Test Loss:  0.5860655903816223
Valid Loss:  0.5803606510162354
Epoch:  180  	Training Loss: 0.588412344455719
Test Loss:  0.586064338684082
Valid Loss:  0.5803594589233398
Epoch:  181  	Training Loss: 0.5884110927581787
Test Loss:  0.5860631465911865
Valid Loss:  0.5803582668304443
Epoch:  182  	Training Loss: 0.5884099006652832
Test Loss:  0.586061954498291
Valid Loss:  0.5803570747375488
Epoch:  183  	Training Loss: 0.5884086489677429
Test Loss:  0.5860607028007507
Valid Loss:  0.5803558230400085
Epoch:  184  	Training Loss: 0.5884073972702026
Test Loss:  0.5860594511032104
Valid Loss:  0.5803545713424683
Epoch:  185  	Training Loss: 0.5884060859680176
Test Loss:  0.5860582590103149
Valid Loss:  0.5803532600402832
Epoch:  186  	Training Loss: 0.5884048342704773
Test Loss:  0.5860570669174194
Valid Loss:  0.5803520679473877
Epoch:  187  	Training Loss: 0.588403582572937
Test Loss:  0.5860558152198792
Valid Loss:  0.5803508162498474
Epoch:  188  	Training Loss: 0.5884023904800415
Test Loss:  0.5860545635223389
Valid Loss:  0.5803495645523071
Epoch:  189  	Training Loss: 0.5884010791778564
Test Loss:  0.5860533714294434
Valid Loss:  0.5803483724594116
Epoch:  190  	Training Loss: 0.5883998274803162
Test Loss:  0.5860521793365479
Valid Loss:  0.5803471207618713
Epoch:  191  	Training Loss: 0.5883985757827759
Test Loss:  0.5860508680343628
Valid Loss:  0.580345869064331
Epoch:  192  	Training Loss: 0.5883973836898804
Test Loss:  0.5860496759414673
Valid Loss:  0.5803446769714355
Epoch:  193  	Training Loss: 0.5883961319923401
Test Loss:  0.5860484838485718
Valid Loss:  0.5803433656692505
Epoch:  194  	Training Loss: 0.588394820690155
Test Loss:  0.5860472917556763
Valid Loss:  0.580342173576355
Epoch:  195  	Training Loss: 0.5883936285972595
Test Loss:  0.586046040058136
Valid Loss:  0.5803409814834595
Epoch:  196  	Training Loss: 0.5883923768997192
Test Loss:  0.5860447883605957
Valid Loss:  0.5803396701812744
Epoch:  197  	Training Loss: 0.588391125202179
Test Loss:  0.5860435962677002
Valid Loss:  0.5803384780883789
Epoch:  198  	Training Loss: 0.5883898138999939
Test Loss:  0.5860424041748047
Valid Loss:  0.5803372859954834
Epoch:  199  	Training Loss: 0.5883885622024536
Test Loss:  0.5860411524772644
Valid Loss:  0.5803360342979431
Epoch:  200  	Training Loss: 0.5883873701095581
Test Loss:  0.5860399007797241
Valid Loss:  0.5803347826004028
Epoch:  201  	Training Loss: 0.588386058807373
Test Loss:  0.5860387086868286
Valid Loss:  0.5803335905075073
Epoch:  202  	Training Loss: 0.5883848071098328
Test Loss:  0.5860374569892883
Valid Loss:  0.5803322792053223
Epoch:  203  	Training Loss: 0.5883836150169373
Test Loss:  0.5860362648963928
Valid Loss:  0.5803310871124268
Epoch:  204  	Training Loss: 0.588382363319397
Test Loss:  0.5860350131988525
Valid Loss:  0.5803298354148865
Epoch:  205  	Training Loss: 0.5883810520172119
Test Loss:  0.586033821105957
Valid Loss:  0.5803285837173462
Epoch:  206  	Training Loss: 0.5883798599243164
Test Loss:  0.5860326290130615
Valid Loss:  0.5803273916244507
Epoch:  207  	Training Loss: 0.5883786678314209
Test Loss:  0.586031436920166
Valid Loss:  0.5803261995315552
Epoch:  208  	Training Loss: 0.5883773565292358
Test Loss:  0.5860301852226257
Valid Loss:  0.5803249478340149
Epoch:  209  	Training Loss: 0.5883761644363403
Test Loss:  0.5860289931297302
Valid Loss:  0.5803236961364746
Epoch:  210  	Training Loss: 0.5883748531341553
Test Loss:  0.5860277414321899
Valid Loss:  0.5803224444389343
Epoch:  211  	Training Loss: 0.588373601436615
Test Loss:  0.5860265493392944
Valid Loss:  0.5803213119506836
Epoch:  212  	Training Loss: 0.5883724093437195
Test Loss:  0.5860252380371094
Valid Loss:  0.5803200006484985
Epoch:  213  	Training Loss: 0.5883710980415344
Test Loss:  0.5860239863395691
Valid Loss:  0.5803186893463135
Epoch:  214  	Training Loss: 0.5883698463439941
Test Loss:  0.5860227346420288
Valid Loss:  0.5803173780441284
Epoch:  215  	Training Loss: 0.5883685350418091
Test Loss:  0.5860214829444885
Valid Loss:  0.5803161859512329
Epoch:  216  	Training Loss: 0.588367223739624
Test Loss:  0.5860202312469482
Valid Loss:  0.5803148746490479
Epoch:  217  	Training Loss: 0.588365912437439
Test Loss:  0.5860189199447632
Valid Loss:  0.5803135633468628
Epoch:  218  	Training Loss: 0.5883646011352539
Test Loss:  0.5860176682472229
Valid Loss:  0.5803122520446777
Epoch:  219  	Training Loss: 0.5883632898330688
Test Loss:  0.5860163569450378
Valid Loss:  0.5803109407424927
Epoch:  220  	Training Loss: 0.5883619785308838
Test Loss:  0.5860151052474976
Valid Loss:  0.5803096890449524
Epoch:  221  	Training Loss: 0.5883607268333435
Test Loss:  0.5860137939453125
Valid Loss:  0.5803084373474121
Epoch:  222  	Training Loss: 0.5883594155311584
Test Loss:  0.586012601852417
Valid Loss:  0.580307126045227
Epoch:  223  	Training Loss: 0.5883581042289734
Test Loss:  0.5860112905502319
Valid Loss:  0.5803059339523315
 45%|████▌     | 225/500 [02:37<02:50,  1.61it/s] 45%|████▌     | 227/500 [02:37<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:37<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:44<05:14,  1.17s/it] 47%|████▋     | 233/500 [02:44<03:44,  1.19it/s] 47%|████▋     | 235/500 [02:44<02:40,  1.65it/s] 47%|████▋     | 237/500 [02:44<01:56,  2.25it/s] 48%|████▊     | 239/500 [02:44<01:26,  3.02it/s] 48%|████▊     | 241/500 [02:50<05:05,  1.18s/it] 49%|████▊     | 243/500 [02:51<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:51<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:51<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:51<01:23,  3.00it/s] 50%|█████     | 251/500 [02:57<04:55,  1.18s/it] 51%|█████     | 253/500 [02:57<03:30,  1.18it/s] 51%|█████     | 255/500 [02:58<02:30,  1.63it/s] 51%|█████▏    | 257/500 [02:58<01:49,  2.22it/s] 52%|█████▏    | 259/500 [02:58<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:04<04:45,  1.19s/it] 53%|█████▎    | 263/500 [03:04<03:23,  1.17it/s] 53%|█████▎    | 265/500 [03:04<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:05<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:05<01:17,  2.96it/s] 54%|█████▍    | 271/500 [03:11<04:31,  1.18s/it] 55%|█████▍    | 273/500 [03:11<03:13,  1.18it/s] 55%|█████▌    | 275/500 [03:11<02:18,  1.62it/s] 55%|█████▌    | 277/500 [03:12<01:41,  2.20it/s] 56%|█████▌    | 279/500 [03:12<01:16,  2.90it/s] 56%|█████▌    | 281/500 [03:18<04:27,  1.22s/it] 57%|█████▋    | 283/500 [03:18<03:10,  1.14it/s] 57%|█████▋    | 285/500 [03:18<02:16,  1.58it/s] 57%|█████▋    | 287/500 [03:19<01:39,  2.15it/s] 58%|█████▊    | 289/500 [03:19<01:13,  2.89it/s] 58%|█████▊    | 291/500 [03:25<04:16,  1.23s/it] 59%|█████▊    | 293/500 [03:25<03:02,  1.14it/s] 59%|█████▉    | 295/500 [03:26<02:10,  1.57it/s] 59%|█████▉    | 297/500 [03:26<01:34,  2.15it/s]Epoch:  224  	Training Loss: 0.5883567929267883
Test Loss:  0.5860100388526917
Valid Loss:  0.5803046226501465
Epoch:  225  	Training Loss: 0.5883554816246033
Test Loss:  0.5860087871551514
Valid Loss:  0.5803033113479614
Epoch:  226  	Training Loss: 0.588354229927063
Test Loss:  0.5860075354576111
Valid Loss:  0.5803020000457764
Epoch:  227  	Training Loss: 0.5883529186248779
Test Loss:  0.5860062837600708
Valid Loss:  0.5803008079528809
Epoch:  228  	Training Loss: 0.5883516073226929
Test Loss:  0.5860049724578857
Valid Loss:  0.5802994966506958
Epoch:  229  	Training Loss: 0.5883504152297974
Test Loss:  0.5860037803649902
Valid Loss:  0.5802981853485107
Epoch:  230  	Training Loss: 0.5883490443229675
Test Loss:  0.5860024690628052
Valid Loss:  0.5802969336509705
Epoch:  231  	Training Loss: 0.5883477926254272
Test Loss:  0.5860012173652649
Valid Loss:  0.5802956819534302
Epoch:  232  	Training Loss: 0.5883464813232422
Test Loss:  0.5859999656677246
Valid Loss:  0.5802944302558899
Epoch:  233  	Training Loss: 0.5883451700210571
Test Loss:  0.5859986543655396
Valid Loss:  0.5802931785583496
Epoch:  234  	Training Loss: 0.5883438587188721
Test Loss:  0.585997462272644
Valid Loss:  0.5802918672561646
Epoch:  235  	Training Loss: 0.5883426666259766
Test Loss:  0.585996150970459
Valid Loss:  0.5802905559539795
Epoch:  236  	Training Loss: 0.5883412957191467
Test Loss:  0.5859949588775635
Valid Loss:  0.5802892446517944
Epoch:  237  	Training Loss: 0.5883400440216064
Test Loss:  0.5859936475753784
Valid Loss:  0.5802880525588989
Epoch:  238  	Training Loss: 0.5883387327194214
Test Loss:  0.5859923362731934
Valid Loss:  0.5802867412567139
Epoch:  239  	Training Loss: 0.5883374214172363
Test Loss:  0.5859911441802979
Valid Loss:  0.5802855491638184
Epoch:  240  	Training Loss: 0.5883361101150513
Test Loss:  0.5859898328781128
Valid Loss:  0.5802842378616333
Epoch:  241  	Training Loss: 0.588334858417511
Test Loss:  0.5859885811805725
Valid Loss:  0.5802829265594482
Epoch:  242  	Training Loss: 0.5883336067199707
Test Loss:  0.5859873294830322
Valid Loss:  0.5802816152572632
Epoch:  243  	Training Loss: 0.5883322358131409
Test Loss:  0.5859860181808472
Valid Loss:  0.5802803039550781
Epoch:  244  	Training Loss: 0.5883309245109558
Test Loss:  0.5859847068786621
Valid Loss:  0.5802789926528931
Epoch:  245  	Training Loss: 0.588329553604126
Test Loss:  0.585983395576477
Valid Loss:  0.580277681350708
Epoch:  246  	Training Loss: 0.5883282423019409
Test Loss:  0.585982084274292
Valid Loss:  0.580276370048523
Epoch:  247  	Training Loss: 0.5883269309997559
Test Loss:  0.5859807729721069
Valid Loss:  0.5802750587463379
Epoch:  248  	Training Loss: 0.5883256196975708
Test Loss:  0.5859794616699219
Valid Loss:  0.5802737474441528
Epoch:  249  	Training Loss: 0.588324248790741
Test Loss:  0.5859781503677368
Valid Loss:  0.580272376537323
Epoch:  250  	Training Loss: 0.5883228778839111
Test Loss:  0.5859768390655518
Valid Loss:  0.5802710652351379
Epoch:  251  	Training Loss: 0.5883215665817261
Test Loss:  0.5859755277633667
Valid Loss:  0.5802697539329529
Epoch:  252  	Training Loss: 0.588320255279541
Test Loss:  0.5859743356704712
Valid Loss:  0.5802684426307678
Epoch:  253  	Training Loss: 0.588318943977356
Test Loss:  0.5859730243682861
Valid Loss:  0.5802671909332275
Epoch:  254  	Training Loss: 0.5883176326751709
Test Loss:  0.5859717130661011
Valid Loss:  0.5802658796310425
Epoch:  255  	Training Loss: 0.5883163213729858
Test Loss:  0.585970401763916
Valid Loss:  0.5802645683288574
Epoch:  256  	Training Loss: 0.5883150100708008
Test Loss:  0.5859691500663757
Valid Loss:  0.5802632570266724
Epoch:  257  	Training Loss: 0.588313639163971
Test Loss:  0.5859678983688354
Valid Loss:  0.5802619457244873
Epoch:  258  	Training Loss: 0.5883123278617859
Test Loss:  0.5859665274620056
Valid Loss:  0.5802606344223022
Epoch:  259  	Training Loss: 0.5883110165596008
Test Loss:  0.5859652757644653
Valid Loss:  0.5802593231201172
Epoch:  260  	Training Loss: 0.5883097052574158
Test Loss:  0.5859639644622803
Valid Loss:  0.5802580714225769
Epoch:  261  	Training Loss: 0.5883083939552307
Test Loss:  0.58596271276474
Valid Loss:  0.5802567601203918
Epoch:  262  	Training Loss: 0.5883070230484009
Test Loss:  0.5859614610671997
Valid Loss:  0.5802554488182068
Epoch:  263  	Training Loss: 0.5883057713508606
Test Loss:  0.5859602093696594
Valid Loss:  0.5802541971206665
Epoch:  264  	Training Loss: 0.5883045196533203
Test Loss:  0.5859589576721191
Valid Loss:  0.5802529454231262
Epoch:  265  	Training Loss: 0.5883032083511353
Test Loss:  0.5859577059745789
Valid Loss:  0.5802516937255859
Epoch:  266  	Training Loss: 0.5883018970489502
Test Loss:  0.5859564542770386
Valid Loss:  0.5802503824234009
Epoch:  267  	Training Loss: 0.5883006453514099
Test Loss:  0.5859552025794983
Valid Loss:  0.5802491307258606
Epoch:  268  	Training Loss: 0.5882993936538696
Test Loss:  0.585953950881958
Valid Loss:  0.5802479386329651
Epoch:  269  	Training Loss: 0.5882980823516846
Test Loss:  0.5859526991844177
Valid Loss:  0.58024662733078
Epoch:  270  	Training Loss: 0.5882967710494995
Test Loss:  0.5859514474868774
Valid Loss:  0.5802453756332397
Epoch:  271  	Training Loss: 0.5882955193519592
Test Loss:  0.5859501361846924
Valid Loss:  0.5802440643310547
Epoch:  272  	Training Loss: 0.5882942080497742
Test Loss:  0.5859489440917969
Valid Loss:  0.5802428126335144
Epoch:  273  	Training Loss: 0.5882929563522339
Test Loss:  0.5859477519989014
Valid Loss:  0.5802416205406189
Epoch:  274  	Training Loss: 0.5882916450500488
Test Loss:  0.5859465599060059
Valid Loss:  0.5802403688430786
Epoch:  275  	Training Loss: 0.5882904529571533
Test Loss:  0.5859453082084656
Valid Loss:  0.5802391767501831
Epoch:  276  	Training Loss: 0.588289201259613
Test Loss:  0.5859440565109253
Valid Loss:  0.5802379250526428
Epoch:  277  	Training Loss: 0.5882879495620728
Test Loss:  0.5859428644180298
Valid Loss:  0.5802366137504578
Epoch:  278  	Training Loss: 0.5882866382598877
Test Loss:  0.5859416127204895
Valid Loss:  0.5802353620529175
Epoch:  279  	Training Loss: 0.5882853865623474
Test Loss:  0.585940420627594
Valid Loss:  0.580234169960022
Epoch:  280  	Training Loss: 0.5882841348648071
Test Loss:  0.5859391689300537
Valid Loss:  0.5802329182624817
Epoch:  281  	Training Loss: 0.5882828831672668
Test Loss:  0.5859379768371582
Valid Loss:  0.5802316665649414
Epoch:  282  	Training Loss: 0.5882816314697266
Test Loss:  0.5859366059303284
Valid Loss:  0.5802303552627563
Epoch:  283  	Training Loss: 0.5882803201675415
Test Loss:  0.5859352946281433
Valid Loss:  0.5802290439605713
Epoch:  284  	Training Loss: 0.5882789492607117
Test Loss:  0.585934042930603
Valid Loss:  0.5802276730537415
Epoch:  285  	Training Loss: 0.5882775783538818
Test Loss:  0.585932731628418
Valid Loss:  0.5802264213562012
Epoch:  286  	Training Loss: 0.5882762670516968
Test Loss:  0.5859314203262329
Valid Loss:  0.5802249908447266
Epoch:  287  	Training Loss: 0.5882749557495117
Test Loss:  0.5859301090240479
Valid Loss:  0.5802237391471863
Epoch:  288  	Training Loss: 0.5882736444473267
Test Loss:  0.5859287977218628
Valid Loss:  0.5802224278450012
Epoch:  289  	Training Loss: 0.588272213935852
Test Loss:  0.5859274864196777
Valid Loss:  0.5802211165428162
Epoch:  290  	Training Loss: 0.588270902633667
Test Loss:  0.5859261751174927
Valid Loss:  0.5802197456359863
Epoch:  291  	Training Loss: 0.5882695913314819
Test Loss:  0.5859248638153076
Valid Loss:  0.5802184343338013
Epoch:  292  	Training Loss: 0.5882682800292969
Test Loss:  0.5859236121177673
Valid Loss:  0.5802172422409058
Epoch:  293  	Training Loss: 0.5882669687271118
Test Loss:  0.5859224200248718
Valid Loss:  0.5802159309387207
Epoch:  294  	Training Loss: 0.5882657170295715
Test Loss:  0.5859211683273315
Valid Loss:  0.5802146792411804
Epoch:  295  	Training Loss: 0.5882644653320312
Test Loss:  0.585919976234436
Valid Loss:  0.5802134275436401
Epoch:  296  	Training Loss: 0.5882631540298462
Test Loss:  0.585918664932251
Valid Loss:  0.5802121758460999
Epoch:  297  	Training Loss: 0.5882618427276611
Test Loss:  0.5859174728393555
Valid Loss:  0.5802109241485596
 60%|█████▉    | 299/500 [03:26<01:09,  2.90it/s] 60%|██████    | 301/500 [03:32<03:56,  1.19s/it] 61%|██████    | 303/500 [03:32<02:47,  1.17it/s] 61%|██████    | 305/500 [03:32<02:00,  1.62it/s] 61%|██████▏   | 307/500 [03:33<01:27,  2.22it/s] 62%|██████▏   | 309/500 [03:33<01:04,  2.98it/s] 62%|██████▏   | 311/500 [03:39<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:39<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:39<01:54,  1.62it/s] 63%|██████▎   | 317/500 [03:40<01:23,  2.20it/s] 64%|██████▍   | 319/500 [03:40<01:01,  2.97it/s] 64%|██████▍   | 321/500 [03:46<03:28,  1.17s/it] 65%|██████▍   | 323/500 [03:46<02:28,  1.19it/s] 65%|██████▌   | 325/500 [03:46<01:46,  1.65it/s] 65%|██████▌   | 327/500 [03:46<01:17,  2.24it/s] 66%|██████▌   | 329/500 [03:46<00:57,  3.00it/s] 66%|██████▌   | 331/500 [03:53<03:19,  1.18s/it] 67%|██████▋   | 333/500 [03:53<02:21,  1.18it/s] 67%|██████▋   | 335/500 [03:53<01:41,  1.63it/s] 67%|██████▋   | 337/500 [03:53<01:13,  2.23it/s] 68%|██████▊   | 339/500 [03:53<00:53,  3.00it/s] 68%|██████▊   | 341/500 [04:00<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:00<02:12,  1.19it/s] 69%|██████▉   | 345/500 [04:00<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:00<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:00<00:50,  3.00it/s] 70%|███████   | 351/500 [04:06<02:53,  1.17s/it] 71%|███████   | 353/500 [04:06<02:03,  1.19it/s] 71%|███████   | 355/500 [04:07<01:28,  1.65it/s] 71%|███████▏  | 357/500 [04:07<01:03,  2.25it/s] 72%|███████▏  | 359/500 [04:07<00:46,  3.02it/s] 72%|███████▏  | 361/500 [04:13<02:44,  1.19s/it] 73%|███████▎  | 363/500 [04:13<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:13<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:14<01:00,  2.22it/s] 74%|███████▍  | 369/500 [04:14<00:43,  2.98it/s] 74%|███████▍  | 371/500 [04:20<02:30,  1.17s/it]Epoch:  298  	Training Loss: 0.5882605910301208
Test Loss:  0.5859161615371704
Valid Loss:  0.5802096128463745
Epoch:  299  	Training Loss: 0.5882593393325806
Test Loss:  0.5859149694442749
Valid Loss:  0.580208420753479
Epoch:  300  	Training Loss: 0.5882580280303955
Test Loss:  0.5859137773513794
Valid Loss:  0.580207109451294
Epoch:  301  	Training Loss: 0.5882567167282104
Test Loss:  0.5859124660491943
Valid Loss:  0.5802057981491089
Epoch:  302  	Training Loss: 0.5882555246353149
Test Loss:  0.585911214351654
Valid Loss:  0.5802045464515686
Epoch:  303  	Training Loss: 0.5882542133331299
Test Loss:  0.5859099626541138
Valid Loss:  0.5802032947540283
Epoch:  304  	Training Loss: 0.5882529020309448
Test Loss:  0.5859086513519287
Valid Loss:  0.5802019834518433
Epoch:  305  	Training Loss: 0.588251531124115
Test Loss:  0.5859073400497437
Valid Loss:  0.5802006721496582
Epoch:  306  	Training Loss: 0.5882502794265747
Test Loss:  0.5859061479568481
Valid Loss:  0.5801994204521179
Epoch:  307  	Training Loss: 0.5882489085197449
Test Loss:  0.5859048366546631
Valid Loss:  0.5801980495452881
Epoch:  308  	Training Loss: 0.5882476568222046
Test Loss:  0.5859035849571228
Valid Loss:  0.5801968574523926
Epoch:  309  	Training Loss: 0.5882463455200195
Test Loss:  0.5859023332595825
Valid Loss:  0.5801955461502075
Epoch:  310  	Training Loss: 0.5882450342178345
Test Loss:  0.5859010219573975
Valid Loss:  0.5801942348480225
Epoch:  311  	Training Loss: 0.5882437229156494
Test Loss:  0.5858997702598572
Valid Loss:  0.5801929235458374
Epoch:  312  	Training Loss: 0.5882424116134644
Test Loss:  0.5858984589576721
Valid Loss:  0.5801916122436523
Epoch:  313  	Training Loss: 0.5882411003112793
Test Loss:  0.5858971476554871
Valid Loss:  0.5801903009414673
Epoch:  314  	Training Loss: 0.5882397890090942
Test Loss:  0.5858958959579468
Valid Loss:  0.5801889896392822
Epoch:  315  	Training Loss: 0.5882383584976196
Test Loss:  0.5858945250511169
Valid Loss:  0.5801876187324524
Epoch:  316  	Training Loss: 0.5882370471954346
Test Loss:  0.5858932137489319
Valid Loss:  0.5801863074302673
Epoch:  317  	Training Loss: 0.5882356762886047
Test Loss:  0.5858919620513916
Valid Loss:  0.5801849961280823
Epoch:  318  	Training Loss: 0.5882343649864197
Test Loss:  0.5858906507492065
Valid Loss:  0.5801836848258972
Epoch:  319  	Training Loss: 0.5882329940795898
Test Loss:  0.5858893394470215
Valid Loss:  0.5801823139190674
Epoch:  320  	Training Loss: 0.5882316827774048
Test Loss:  0.5858880281448364
Valid Loss:  0.5801810622215271
Epoch:  321  	Training Loss: 0.588230311870575
Test Loss:  0.5858867168426514
Valid Loss:  0.580179750919342
Epoch:  322  	Training Loss: 0.5882290005683899
Test Loss:  0.5858854055404663
Valid Loss:  0.5801783800125122
Epoch:  323  	Training Loss: 0.5882276296615601
Test Loss:  0.5858840942382812
Valid Loss:  0.5801770687103271
Epoch:  324  	Training Loss: 0.5882262587547302
Test Loss:  0.5858827829360962
Valid Loss:  0.5801756978034973
Epoch:  325  	Training Loss: 0.5882248878479004
Test Loss:  0.5858814716339111
Valid Loss:  0.5801743268966675
Epoch:  326  	Training Loss: 0.5882235765457153
Test Loss:  0.5858801603317261
Valid Loss:  0.5801730155944824
Epoch:  327  	Training Loss: 0.5882222056388855
Test Loss:  0.585878849029541
Valid Loss:  0.5801717042922974
Epoch:  328  	Training Loss: 0.5882208347320557
Test Loss:  0.585877537727356
Valid Loss:  0.5801703333854675
Epoch:  329  	Training Loss: 0.588219404220581
Test Loss:  0.5858761668205261
Valid Loss:  0.5801689624786377
Epoch:  330  	Training Loss: 0.588218092918396
Test Loss:  0.5858748555183411
Valid Loss:  0.5801676511764526
Epoch:  331  	Training Loss: 0.5882167816162109
Test Loss:  0.5858734846115112
Valid Loss:  0.5801663398742676
Epoch:  332  	Training Loss: 0.5882153511047363
Test Loss:  0.585872232913971
Valid Loss:  0.5801649689674377
Epoch:  333  	Training Loss: 0.5882140398025513
Test Loss:  0.5858709216117859
Valid Loss:  0.5801635980606079
Epoch:  334  	Training Loss: 0.5882127285003662
Test Loss:  0.5858696103096008
Valid Loss:  0.5801622867584229
Epoch:  335  	Training Loss: 0.5882112979888916
Test Loss:  0.5858682990074158
Valid Loss:  0.580160915851593
Epoch:  336  	Training Loss: 0.5882099866867065
Test Loss:  0.5858669281005859
Valid Loss:  0.580159604549408
Epoch:  337  	Training Loss: 0.5882086157798767
Test Loss:  0.5858656764030457
Valid Loss:  0.5801582336425781
Epoch:  338  	Training Loss: 0.5882072448730469
Test Loss:  0.5858643651008606
Valid Loss:  0.5801569223403931
Epoch:  339  	Training Loss: 0.5882059335708618
Test Loss:  0.5858630537986755
Valid Loss:  0.580155611038208
Epoch:  340  	Training Loss: 0.5882045030593872
Test Loss:  0.5858616828918457
Valid Loss:  0.5801542401313782
Epoch:  341  	Training Loss: 0.5882031917572021
Test Loss:  0.5858603715896606
Valid Loss:  0.5801528692245483
Epoch:  342  	Training Loss: 0.5882018208503723
Test Loss:  0.5858590602874756
Valid Loss:  0.5801514983177185
Epoch:  343  	Training Loss: 0.5882004499435425
Test Loss:  0.5858576893806458
Valid Loss:  0.5801501274108887
Epoch:  344  	Training Loss: 0.5881990194320679
Test Loss:  0.5858563184738159
Valid Loss:  0.5801488161087036
Epoch:  345  	Training Loss: 0.5881975889205933
Test Loss:  0.5858549475669861
Valid Loss:  0.580147385597229
Epoch:  346  	Training Loss: 0.5881961584091187
Test Loss:  0.5858535766601562
Valid Loss:  0.5801459550857544
Epoch:  347  	Training Loss: 0.5881948471069336
Test Loss:  0.5858522653579712
Valid Loss:  0.5801445841789246
Epoch:  348  	Training Loss: 0.588193416595459
Test Loss:  0.5858508348464966
Valid Loss:  0.5801432132720947
Epoch:  349  	Training Loss: 0.5881919860839844
Test Loss:  0.5858495235443115
Valid Loss:  0.5801418423652649
Epoch:  350  	Training Loss: 0.5881905555725098
Test Loss:  0.5858481526374817
Valid Loss:  0.5801404714584351
Epoch:  351  	Training Loss: 0.5881891846656799
Test Loss:  0.5858467817306519
Valid Loss:  0.5801390409469604
Epoch:  352  	Training Loss: 0.5881878137588501
Test Loss:  0.5858453512191772
Valid Loss:  0.5801376104354858
Epoch:  353  	Training Loss: 0.5881862640380859
Test Loss:  0.5858439207077026
Valid Loss:  0.5801361799240112
Epoch:  354  	Training Loss: 0.5881848335266113
Test Loss:  0.585842490196228
Valid Loss:  0.5801346302032471
Epoch:  355  	Training Loss: 0.5881834030151367
Test Loss:  0.5858410596847534
Valid Loss:  0.5801332592964172
Epoch:  356  	Training Loss: 0.5881819128990173
Test Loss:  0.5858396887779236
Valid Loss:  0.5801318287849426
Epoch:  357  	Training Loss: 0.588180422782898
Test Loss:  0.585838258266449
Valid Loss:  0.5801303386688232
Epoch:  358  	Training Loss: 0.5881789922714233
Test Loss:  0.5858368277549744
Valid Loss:  0.5801289081573486
Epoch:  359  	Training Loss: 0.588177502155304
Test Loss:  0.5858353972434998
Valid Loss:  0.580127477645874
Epoch:  360  	Training Loss: 0.5881760120391846
Test Loss:  0.5858340263366699
Valid Loss:  0.5801260471343994
Epoch:  361  	Training Loss: 0.58817458152771
Test Loss:  0.5858325958251953
Valid Loss:  0.5801246166229248
Epoch:  362  	Training Loss: 0.5881730914115906
Test Loss:  0.5858312249183655
Valid Loss:  0.5801233053207397
Epoch:  363  	Training Loss: 0.5881717801094055
Test Loss:  0.5858299732208252
Valid Loss:  0.5801219344139099
Epoch:  364  	Training Loss: 0.5881704688072205
Test Loss:  0.5858286619186401
Valid Loss:  0.5801206231117249
Epoch:  365  	Training Loss: 0.5881690979003906
Test Loss:  0.5858274102210999
Valid Loss:  0.5801193714141846
Epoch:  366  	Training Loss: 0.5881677865982056
Test Loss:  0.5858260989189148
Valid Loss:  0.5801180005073547
Epoch:  367  	Training Loss: 0.5881664156913757
Test Loss:  0.5858247876167297
Valid Loss:  0.5801166296005249
Epoch:  368  	Training Loss: 0.5881650447845459
Test Loss:  0.5858235359191895
Valid Loss:  0.5801153182983398
Epoch:  369  	Training Loss: 0.5881637334823608
Test Loss:  0.5858222246170044
Valid Loss:  0.5801140069961548
Epoch:  370  	Training Loss: 0.588162362575531
Test Loss:  0.5858209133148193
Valid Loss:  0.5801126956939697
Epoch:  371  	Training Loss: 0.588161051273346
Test Loss:  0.5858196020126343
Valid Loss:  0.5801113843917847
 75%|███████▍  | 373/500 [04:20<01:46,  1.19it/s] 75%|███████▌  | 375/500 [04:20<01:15,  1.65it/s] 75%|███████▌  | 377/500 [04:20<00:54,  2.25it/s] 76%|███████▌  | 379/500 [04:20<00:39,  3.03it/s] 76%|███████▌  | 381/500 [04:27<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:27<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:27<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:27<00:51,  2.20it/s] 78%|███████▊  | 389/500 [04:27<00:37,  2.96it/s] 78%|███████▊  | 391/500 [04:34<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:34<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:34<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:34<00:46,  2.23it/s] 80%|███████▉  | 399/500 [04:34<00:33,  3.00it/s] 80%|████████  | 401/500 [04:41<01:55,  1.17s/it] 81%|████████  | 403/500 [04:41<01:21,  1.19it/s] 81%|████████  | 405/500 [04:41<00:57,  1.65it/s] 81%|████████▏ | 407/500 [04:41<00:41,  2.25it/s] 82%|████████▏ | 409/500 [04:41<00:30,  3.02it/s] 82%|████████▏ | 411/500 [04:47<01:44,  1.17s/it] 83%|████████▎ | 413/500 [04:47<01:13,  1.19it/s] 83%|████████▎ | 415/500 [04:48<00:51,  1.64it/s] 83%|████████▎ | 417/500 [04:48<00:37,  2.24it/s] 84%|████████▍ | 419/500 [04:48<00:26,  3.01it/s] 84%|████████▍ | 421/500 [04:54<01:32,  1.17s/it] 85%|████████▍ | 423/500 [04:54<01:04,  1.19it/s] 85%|████████▌ | 425/500 [04:54<00:45,  1.65it/s] 85%|████████▌ | 427/500 [04:55<00:32,  2.24it/s] 86%|████████▌ | 429/500 [04:55<00:23,  3.01it/s] 86%|████████▌ | 431/500 [05:01<01:20,  1.17s/it] 87%|████████▋ | 433/500 [05:01<00:56,  1.19it/s] 87%|████████▋ | 435/500 [05:01<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:01<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:01<00:20,  2.98it/s] 88%|████████▊ | 441/500 [05:08<01:08,  1.17s/it] 89%|████████▊ | 443/500 [05:08<00:47,  1.19it/s] 89%|████████▉ | 445/500 [05:08<00:33,  1.64it/s]Epoch:  372  	Training Loss: 0.5881597399711609
Test Loss:  0.5858181715011597
Valid Loss:  0.5801098942756653
Epoch:  373  	Training Loss: 0.5881582498550415
Test Loss:  0.5858167409896851
Valid Loss:  0.5801084041595459
Epoch:  374  	Training Loss: 0.5881568193435669
Test Loss:  0.5858153700828552
Valid Loss:  0.5801070332527161
Epoch:  375  	Training Loss: 0.5881553292274475
Test Loss:  0.5858139395713806
Valid Loss:  0.5801055431365967
Epoch:  376  	Training Loss: 0.5881538391113281
Test Loss:  0.5858125686645508
Valid Loss:  0.5801041126251221
Epoch:  377  	Training Loss: 0.5881524085998535
Test Loss:  0.5858111381530762
Valid Loss:  0.5801026821136475
Epoch:  378  	Training Loss: 0.5881509184837341
Test Loss:  0.5858097076416016
Valid Loss:  0.5801012516021729
Epoch:  379  	Training Loss: 0.5881494283676147
Test Loss:  0.5858083367347717
Valid Loss:  0.5800998210906982
Epoch:  380  	Training Loss: 0.5881479978561401
Test Loss:  0.5858068466186523
Valid Loss:  0.5800983309745789
Epoch:  381  	Training Loss: 0.5881465673446655
Test Loss:  0.5858054161071777
Valid Loss:  0.580096960067749
Epoch:  382  	Training Loss: 0.5881451368331909
Test Loss:  0.5858040452003479
Valid Loss:  0.5800955295562744
Epoch:  383  	Training Loss: 0.5881436467170715
Test Loss:  0.5858026742935181
Valid Loss:  0.5800940990447998
Epoch:  384  	Training Loss: 0.5881421566009521
Test Loss:  0.5858011841773987
Valid Loss:  0.5800926089286804
Epoch:  385  	Training Loss: 0.5881406664848328
Test Loss:  0.5857997536659241
Valid Loss:  0.580091118812561
Epoch:  386  	Training Loss: 0.5881391763687134
Test Loss:  0.5857983231544495
Valid Loss:  0.5800896883010864
Epoch:  387  	Training Loss: 0.5881377458572388
Test Loss:  0.5857968926429749
Valid Loss:  0.580088198184967
Epoch:  388  	Training Loss: 0.5881363153457642
Test Loss:  0.5857954621315002
Valid Loss:  0.5800867080688477
Epoch:  389  	Training Loss: 0.588134765625
Test Loss:  0.5857940912246704
Valid Loss:  0.5800853371620178
Epoch:  390  	Training Loss: 0.5881333351135254
Test Loss:  0.5857926607131958
Valid Loss:  0.5800838470458984
Epoch:  391  	Training Loss: 0.5881317853927612
Test Loss:  0.5857912302017212
Valid Loss:  0.5800824165344238
Epoch:  392  	Training Loss: 0.5881303548812866
Test Loss:  0.5857897996902466
Valid Loss:  0.5800809860229492
Epoch:  393  	Training Loss: 0.588128924369812
Test Loss:  0.5857884287834167
Valid Loss:  0.5800795555114746
Epoch:  394  	Training Loss: 0.5881274938583374
Test Loss:  0.5857870578765869
Valid Loss:  0.5800781846046448
Epoch:  395  	Training Loss: 0.5881260633468628
Test Loss:  0.5857856869697571
Valid Loss:  0.5800768136978149
Epoch:  396  	Training Loss: 0.5881246328353882
Test Loss:  0.5857843160629272
Valid Loss:  0.5800753831863403
Epoch:  397  	Training Loss: 0.5881232619285583
Test Loss:  0.5857830047607422
Valid Loss:  0.5800739526748657
Epoch:  398  	Training Loss: 0.588121771812439
Test Loss:  0.5857815742492676
Valid Loss:  0.5800726413726807
Epoch:  399  	Training Loss: 0.5881204605102539
Test Loss:  0.5857802629470825
Valid Loss:  0.580071210861206
Epoch:  400  	Training Loss: 0.5881190299987793
Test Loss:  0.5857788920402527
Valid Loss:  0.5800697803497314
Epoch:  401  	Training Loss: 0.5881175994873047
Test Loss:  0.5857775211334229
Valid Loss:  0.5800684690475464
Epoch:  402  	Training Loss: 0.5881162285804749
Test Loss:  0.5857762098312378
Valid Loss:  0.5800670385360718
Epoch:  403  	Training Loss: 0.5881147384643555
Test Loss:  0.5857747793197632
Valid Loss:  0.5800656080245972
Epoch:  404  	Training Loss: 0.5881133079528809
Test Loss:  0.5857733488082886
Valid Loss:  0.5800641775131226
Epoch:  405  	Training Loss: 0.5881118774414062
Test Loss:  0.5857719779014587
Valid Loss:  0.580062747001648
Epoch:  406  	Training Loss: 0.5881104469299316
Test Loss:  0.5857706069946289
Valid Loss:  0.5800613164901733
Epoch:  407  	Training Loss: 0.588109016418457
Test Loss:  0.5857692360877991
Valid Loss:  0.5800598859786987
Epoch:  408  	Training Loss: 0.5881075859069824
Test Loss:  0.5857678651809692
Valid Loss:  0.5800585150718689
Epoch:  409  	Training Loss: 0.5881061553955078
Test Loss:  0.5857664346694946
Valid Loss:  0.5800571441650391
Epoch:  410  	Training Loss: 0.5881047248840332
Test Loss:  0.5857650637626648
Valid Loss:  0.5800557136535645
Epoch:  411  	Training Loss: 0.5881032943725586
Test Loss:  0.585763692855835
Valid Loss:  0.5800542831420898
Epoch:  412  	Training Loss: 0.588101863861084
Test Loss:  0.5857623219490051
Valid Loss:  0.5800528526306152
Epoch:  413  	Training Loss: 0.5881004333496094
Test Loss:  0.5857608318328857
Valid Loss:  0.5800514221191406
Epoch:  414  	Training Loss: 0.5880990028381348
Test Loss:  0.5857595205307007
Valid Loss:  0.580049991607666
Epoch:  415  	Training Loss: 0.5880975127220154
Test Loss:  0.5857581496238708
Valid Loss:  0.5800485610961914
Epoch:  416  	Training Loss: 0.588096022605896
Test Loss:  0.5857567191123962
Valid Loss:  0.5800471901893616
Epoch:  417  	Training Loss: 0.5880945920944214
Test Loss:  0.5857553482055664
Valid Loss:  0.5800457000732422
Epoch:  418  	Training Loss: 0.5880932211875916
Test Loss:  0.5857539772987366
Valid Loss:  0.5800442695617676
Epoch:  419  	Training Loss: 0.5880917310714722
Test Loss:  0.5857524871826172
Valid Loss:  0.580042839050293
Epoch:  420  	Training Loss: 0.5880902409553528
Test Loss:  0.5857511162757874
Valid Loss:  0.5800414085388184
Epoch:  421  	Training Loss: 0.5880888104438782
Test Loss:  0.5857497453689575
Valid Loss:  0.5800399780273438
Epoch:  422  	Training Loss: 0.5880874395370483
Test Loss:  0.5857483148574829
Valid Loss:  0.5800385475158691
Epoch:  423  	Training Loss: 0.5880858898162842
Test Loss:  0.5857468843460083
Valid Loss:  0.5800370573997498
Epoch:  424  	Training Loss: 0.5880844593048096
Test Loss:  0.5857454538345337
Valid Loss:  0.5800356268882751
Epoch:  425  	Training Loss: 0.5880829095840454
Test Loss:  0.5857440233230591
Valid Loss:  0.5800341963768005
Epoch:  426  	Training Loss: 0.5880814790725708
Test Loss:  0.5857425928115845
Valid Loss:  0.5800327062606812
Epoch:  427  	Training Loss: 0.5880799889564514
Test Loss:  0.5857411623001099
Valid Loss:  0.5800312757492065
Epoch:  428  	Training Loss: 0.588078498840332
Test Loss:  0.5857397317886353
Valid Loss:  0.5800298452377319
Epoch:  429  	Training Loss: 0.5880770683288574
Test Loss:  0.5857383608818054
Valid Loss:  0.5800283551216125
Epoch:  430  	Training Loss: 0.5880755186080933
Test Loss:  0.585736870765686
Valid Loss:  0.5800269246101379
Epoch:  431  	Training Loss: 0.5880740880966187
Test Loss:  0.5857354998588562
Valid Loss:  0.5800254344940186
Epoch:  432  	Training Loss: 0.588072657585144
Test Loss:  0.5857341289520264
Valid Loss:  0.5800240635871887
Epoch:  433  	Training Loss: 0.5880711674690247
Test Loss:  0.5857326984405518
Valid Loss:  0.5800225734710693
Epoch:  434  	Training Loss: 0.58806973695755
Test Loss:  0.5857313871383667
Valid Loss:  0.5800211429595947
Epoch:  435  	Training Loss: 0.5880683064460754
Test Loss:  0.5857299566268921
Valid Loss:  0.5800197720527649
Epoch:  436  	Training Loss: 0.5880668759346008
Test Loss:  0.5857285261154175
Valid Loss:  0.5800182819366455
Epoch:  437  	Training Loss: 0.5880653858184814
Test Loss:  0.5857272148132324
Valid Loss:  0.5800169110298157
Epoch:  438  	Training Loss: 0.5880639553070068
Test Loss:  0.5857257843017578
Valid Loss:  0.5800155401229858
Epoch:  439  	Training Loss: 0.5880625247955322
Test Loss:  0.585724413394928
Valid Loss:  0.5800141096115112
Epoch:  440  	Training Loss: 0.5880610942840576
Test Loss:  0.5857229828834534
Valid Loss:  0.5800126791000366
Epoch:  441  	Training Loss: 0.588059663772583
Test Loss:  0.5857216119766235
Valid Loss:  0.580011248588562
Epoch:  442  	Training Loss: 0.5880582332611084
Test Loss:  0.5857201814651489
Valid Loss:  0.5800097584724426
Epoch:  443  	Training Loss: 0.5880566835403442
Test Loss:  0.5857187509536743
Valid Loss:  0.5800082683563232
Epoch:  444  	Training Loss: 0.5880551338195801
Test Loss:  0.5857172012329102
Valid Loss:  0.5800067782402039
Epoch:  445  	Training Loss: 0.5880536437034607
Test Loss:  0.5857157707214355
Valid Loss:  0.5800052285194397
 89%|████████▉ | 447/500 [05:08<00:23,  2.24it/s] 90%|████████▉ | 449/500 [05:08<00:16,  3.01it/s] 90%|█████████ | 451/500 [05:15<00:58,  1.19s/it] 91%|█████████ | 453/500 [05:15<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:15<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:15<00:19,  2.22it/s] 92%|█████████▏| 459/500 [05:15<00:13,  2.98it/s] 92%|█████████▏| 461/500 [05:21<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:22<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:22<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:22<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:22<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:28<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:28<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:28<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:29<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:29<00:06,  3.01it/s] 96%|█████████▌| 481/500 [05:35<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:35<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:35<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:35<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:36<00:03,  2.96it/s] 98%|█████████▊| 491/500 [05:42<00:10,  1.17s/it] 99%|█████████▊| 493/500 [05:42<00:05,  1.19it/s] 99%|█████████▉| 495/500 [05:42<00:03,  1.65it/s] 99%|█████████▉| 497/500 [05:42<00:01,  2.24it/s]100%|█████████▉| 499/500 [05:42<00:00,  3.01it/s]100%|██████████| 500/500 [05:42<00:00,  1.46it/s]
Epoch:  446  	Training Loss: 0.5880521535873413
Test Loss:  0.5857142806053162
Valid Loss:  0.5800037384033203
Epoch:  447  	Training Loss: 0.5880506038665771
Test Loss:  0.5857127904891968
Valid Loss:  0.5800023078918457
Epoch:  448  	Training Loss: 0.588049054145813
Test Loss:  0.5857113599777222
Valid Loss:  0.5800007581710815
Epoch:  449  	Training Loss: 0.5880476236343384
Test Loss:  0.5857099294662476
Valid Loss:  0.5799992680549622
Epoch:  450  	Training Loss: 0.5880460739135742
Test Loss:  0.5857084393501282
Valid Loss:  0.5799977779388428
Epoch:  451  	Training Loss: 0.5880445241928101
Test Loss:  0.5857069492340088
Valid Loss:  0.5799962282180786
Epoch:  452  	Training Loss: 0.5880430340766907
Test Loss:  0.585705578327179
Valid Loss:  0.579994797706604
Epoch:  453  	Training Loss: 0.5880415439605713
Test Loss:  0.5857042074203491
Valid Loss:  0.5799933671951294
Epoch:  454  	Training Loss: 0.5880401730537415
Test Loss:  0.5857028365135193
Valid Loss:  0.5799919962882996
Epoch:  455  	Training Loss: 0.5880386829376221
Test Loss:  0.5857014060020447
Valid Loss:  0.5799906253814697
Epoch:  456  	Training Loss: 0.5880372524261475
Test Loss:  0.5857000350952148
Valid Loss:  0.5799891948699951
Epoch:  457  	Training Loss: 0.5880358219146729
Test Loss:  0.585698664188385
Valid Loss:  0.5799877047538757
Epoch:  458  	Training Loss: 0.5880343914031982
Test Loss:  0.5856972932815552
Valid Loss:  0.5799863338470459
Epoch:  459  	Training Loss: 0.5880329608917236
Test Loss:  0.5856958627700806
Valid Loss:  0.5799849033355713
Epoch:  460  	Training Loss: 0.588031530380249
Test Loss:  0.5856944918632507
Valid Loss:  0.5799834728240967
Epoch:  461  	Training Loss: 0.5880300998687744
Test Loss:  0.5856931209564209
Valid Loss:  0.5799820423126221
Epoch:  462  	Training Loss: 0.5880286693572998
Test Loss:  0.5856916904449463
Valid Loss:  0.5799806118011475
Epoch:  463  	Training Loss: 0.5880271196365356
Test Loss:  0.5856903195381165
Valid Loss:  0.5799791812896729
Epoch:  464  	Training Loss: 0.588025689125061
Test Loss:  0.5856888890266418
Valid Loss:  0.5799777507781982
Epoch:  465  	Training Loss: 0.5880242586135864
Test Loss:  0.585687518119812
Valid Loss:  0.5799763202667236
Epoch:  466  	Training Loss: 0.588022768497467
Test Loss:  0.5856860876083374
Valid Loss:  0.5799748301506042
Epoch:  467  	Training Loss: 0.5880212783813477
Test Loss:  0.5856846570968628
Valid Loss:  0.5799733996391296
Epoch:  468  	Training Loss: 0.588019847869873
Test Loss:  0.5856832265853882
Valid Loss:  0.579971969127655
Epoch:  469  	Training Loss: 0.5880184173583984
Test Loss:  0.5856818556785583
Valid Loss:  0.5799705386161804
Epoch:  470  	Training Loss: 0.588016927242279
Test Loss:  0.5856804847717285
Valid Loss:  0.579969048500061
Epoch:  471  	Training Loss: 0.5880154967308044
Test Loss:  0.5856790542602539
Valid Loss:  0.5799676775932312
Epoch:  472  	Training Loss: 0.5880140066146851
Test Loss:  0.5856776237487793
Valid Loss:  0.5799661874771118
Epoch:  473  	Training Loss: 0.5880125164985657
Test Loss:  0.5856761932373047
Valid Loss:  0.5799646973609924
Epoch:  474  	Training Loss: 0.5880110263824463
Test Loss:  0.5856747627258301
Valid Loss:  0.5799632668495178
Epoch:  475  	Training Loss: 0.5880095958709717
Test Loss:  0.5856733322143555
Valid Loss:  0.5799617767333984
Epoch:  476  	Training Loss: 0.5880080461502075
Test Loss:  0.5856719017028809
Valid Loss:  0.5799603462219238
Epoch:  477  	Training Loss: 0.5880065560340881
Test Loss:  0.5856704711914062
Valid Loss:  0.5799589157104492
Epoch:  478  	Training Loss: 0.5880051255226135
Test Loss:  0.5856690406799316
Valid Loss:  0.5799573659896851
Epoch:  479  	Training Loss: 0.5880036354064941
Test Loss:  0.585667610168457
Valid Loss:  0.5799559354782104
Epoch:  480  	Training Loss: 0.5880021452903748
Test Loss:  0.5856661796569824
Valid Loss:  0.5799545049667358
Epoch:  481  	Training Loss: 0.5880006551742554
Test Loss:  0.5856648087501526
Valid Loss:  0.5799530148506165
Epoch:  482  	Training Loss: 0.5879992246627808
Test Loss:  0.5856633186340332
Valid Loss:  0.5799515247344971
Epoch:  483  	Training Loss: 0.5879976749420166
Test Loss:  0.5856618285179138
Valid Loss:  0.5799500346183777
Epoch:  484  	Training Loss: 0.5879961252212524
Test Loss:  0.5856603384017944
Valid Loss:  0.5799484848976135
Epoch:  485  	Training Loss: 0.5879945755004883
Test Loss:  0.5856589078903198
Valid Loss:  0.5799469947814941
Epoch:  486  	Training Loss: 0.5879930257797241
Test Loss:  0.5856573581695557
Valid Loss:  0.5799455046653748
Epoch:  487  	Training Loss: 0.5879915952682495
Test Loss:  0.585655927658081
Valid Loss:  0.5799440145492554
Epoch:  488  	Training Loss: 0.5879900455474854
Test Loss:  0.5856544971466064
Valid Loss:  0.579942524433136
Epoch:  489  	Training Loss: 0.5879884958267212
Test Loss:  0.5856530666351318
Valid Loss:  0.5799409747123718
Epoch:  490  	Training Loss: 0.587986946105957
Test Loss:  0.5856515765190125
Valid Loss:  0.5799394845962524
Epoch:  491  	Training Loss: 0.5879853963851929
Test Loss:  0.5856500864028931
Valid Loss:  0.5799379944801331
Epoch:  492  	Training Loss: 0.5879839658737183
Test Loss:  0.5856486558914185
Valid Loss:  0.5799365639686584
Epoch:  493  	Training Loss: 0.5879824757575989
Test Loss:  0.5856472849845886
Valid Loss:  0.5799351334571838
Epoch:  494  	Training Loss: 0.5879809856414795
Test Loss:  0.5856459140777588
Valid Loss:  0.5799337029457092
Epoch:  495  	Training Loss: 0.5879796147346497
Test Loss:  0.5856444835662842
Valid Loss:  0.5799322724342346
Epoch:  496  	Training Loss: 0.5879781246185303
Test Loss:  0.5856431722640991
Valid Loss:  0.5799307823181152
Epoch:  497  	Training Loss: 0.5879766941070557
Test Loss:  0.5856417417526245
Valid Loss:  0.5799293518066406
Epoch:  498  	Training Loss: 0.5879752039909363
Test Loss:  0.5856403112411499
Valid Loss:  0.5799279808998108
Epoch:  499  	Training Loss: 0.5879737734794617
Test Loss:  0.5856388807296753
Valid Loss:  0.5799265503883362
Epoch:  500  	Training Loss: 0.5879723429679871
Test Loss:  0.5856375694274902
Valid Loss:  0.5799251794815063
seed is  18
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:03,  6.14s/it]  1%|          | 3/500 [00:06<13:36,  1.64s/it]  1%|          | 5/500 [00:06<06:51,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.94it/s]  2%|▏         | 11/500 [00:13<10:50,  1.33s/it]  3%|▎         | 13/500 [00:13<07:23,  1.10it/s]  3%|▎         | 15/500 [00:13<05:10,  1.56it/s]  3%|▎         | 17/500 [00:13<03:41,  2.18it/s]  4%|▍         | 19/500 [00:13<02:41,  2.98it/s]  4%|▍         | 21/500 [00:19<09:29,  1.19s/it]  5%|▍         | 23/500 [00:19<06:45,  1.18it/s]  5%|▌         | 25/500 [00:20<04:51,  1.63it/s]  5%|▌         | 27/500 [00:20<03:31,  2.23it/s]  6%|▌         | 29/500 [00:20<02:36,  3.01it/s]  6%|▌         | 31/500 [00:26<09:05,  1.16s/it]  7%|▋         | 33/500 [00:26<06:29,  1.20it/s]  7%|▋         | 35/500 [00:26<04:40,  1.66it/s]  7%|▋         | 37/500 [00:26<03:24,  2.26it/s]  8%|▊         | 39/500 [00:27<02:31,  3.04it/s]  8%|▊         | 41/500 [00:33<08:54,  1.16s/it]  9%|▊         | 43/500 [00:33<06:22,  1.20it/s]  9%|▉         | 45/500 [00:33<04:35,  1.65it/s]  9%|▉         | 47/500 [00:33<03:21,  2.25it/s] 10%|▉         | 49/500 [00:33<02:29,  3.02it/s] 10%|█         | 51/500 [00:40<09:07,  1.22s/it] 11%|█         | 53/500 [00:40<06:31,  1.14it/s] 11%|█         | 55/500 [00:40<04:41,  1.58it/s] 11%|█▏        | 57/500 [00:40<03:25,  2.15it/s] 12%|█▏        | 59/500 [00:40<02:31,  2.90it/s] 12%|█▏        | 61/500 [00:47<08:40,  1.19s/it] 13%|█▎        | 63/500 [00:47<06:11,  1.18it/s] 13%|█▎        | 65/500 [00:47<04:27,  1.63it/s] 13%|█▎        | 67/500 [00:47<03:15,  2.22it/s] 14%|█▍        | 69/500 [00:47<02:24,  2.98it/s]Epoch:  1  	Training Loss: 0.5382072925567627
Test Loss:  4.027912139892578
Valid Loss:  4.012406349182129
Epoch:  2  	Training Loss: 4.033105850219727
Test Loss:  4.549676895141602
Valid Loss:  4.4392876625061035
Epoch:  3  	Training Loss: 4.501565933227539
Test Loss:  0.12658941745758057
Valid Loss:  0.1419256031513214
Epoch:  4  	Training Loss: 0.1406419277191162
Test Loss:  0.11603531986474991
Valid Loss:  0.13336879014968872
Epoch:  5  	Training Loss: 0.13006365299224854
Test Loss:  0.10437726229429245
Valid Loss:  0.12356461584568024
Epoch:  6  	Training Loss: 0.1183936595916748
Test Loss:  0.08917807042598724
Valid Loss:  0.10694120824337006
Epoch:  7  	Training Loss: 0.1042906641960144
Test Loss:  0.07001867145299911
Valid Loss:  0.08525046706199646
Epoch:  8  	Training Loss: 0.08281873911619186
Test Loss:  0.05238722637295723
Valid Loss:  0.06456019729375839
Epoch:  9  	Training Loss: 0.062045805156230927
Test Loss:  0.0415642075240612
Valid Loss:  0.051591526716947556
Epoch:  10  	Training Loss: 0.04904789477586746
Test Loss:  0.03495151549577713
Valid Loss:  0.043451420962810516
Epoch:  11  	Training Loss: 0.04090774059295654
Test Loss:  0.030937518924474716
Valid Loss:  0.03833397850394249
Epoch:  12  	Training Loss: 0.03580503910779953
Test Loss:  0.02767184190452099
Valid Loss:  0.03426574170589447
Epoch:  13  	Training Loss: 0.03227273374795914
Test Loss:  0.02590324729681015
Valid Loss:  0.03194630891084671
Epoch:  14  	Training Loss: 0.029622185975313187
Test Loss:  0.023064803332090378
Valid Loss:  0.028251228854060173
Epoch:  15  	Training Loss: 0.026796940714120865
Test Loss:  0.02137133851647377
Valid Loss:  0.026259826496243477
Epoch:  16  	Training Loss: 0.024275731295347214
Test Loss:  0.019083036109805107
Valid Loss:  0.023162774741649628
Epoch:  17  	Training Loss: 0.022023841738700867
Test Loss:  0.01775146834552288
Valid Loss:  0.021724175661802292
Epoch:  18  	Training Loss: 0.020019616931676865
Test Loss:  0.01594071462750435
Valid Loss:  0.019128695130348206
Epoch:  19  	Training Loss: 0.018250342458486557
Test Loss:  0.015043526887893677
Valid Loss:  0.018307067453861237
Epoch:  20  	Training Loss: 0.01680801995098591
Test Loss:  0.013614434748888016
Valid Loss:  0.016047697514295578
Epoch:  21  	Training Loss: 0.015412608161568642
Test Loss:  0.012799586169421673
Valid Loss:  0.015496229752898216
Epoch:  22  	Training Loss: 0.014185612089931965
Test Loss:  0.009727940894663334
Valid Loss:  0.01185112539678812
Epoch:  23  	Training Loss: 0.011005058884620667
Test Loss:  0.007827123627066612
Valid Loss:  0.009535348042845726
Epoch:  24  	Training Loss: 0.008765287697315216
Test Loss:  0.006405998952686787
Valid Loss:  0.007747728377580643
Epoch:  25  	Training Loss: 0.0071977274492383
Test Loss:  0.005487118382006884
Valid Loss:  0.006646667141467333
Epoch:  26  	Training Loss: 0.006201519165188074
Test Loss:  0.004873271565884352
Valid Loss:  0.005871616769582033
Epoch:  27  	Training Loss: 0.005502845160663128
Test Loss:  0.004376864060759544
Valid Loss:  0.005258430261164904
Epoch:  28  	Training Loss: 0.004943075589835644
Test Loss:  0.003951105754822493
Valid Loss:  0.00474239606410265
Epoch:  29  	Training Loss: 0.004460545256733894
Test Loss:  0.003574660047888756
Valid Loss:  0.004286220297217369
Epoch:  30  	Training Loss: 0.004033214878290892
Test Loss:  0.0032369899563491344
Valid Loss:  0.003883830737322569
Epoch:  31  	Training Loss: 0.0036511581856757402
Test Loss:  0.0029364791698753834
Valid Loss:  0.003526785410940647
Epoch:  32  	Training Loss: 0.0033103874884545803
Test Loss:  0.0026183309964835644
Valid Loss:  0.003171158954501152
Epoch:  33  	Training Loss: 0.0029515272472053766
Test Loss:  0.0024112476967275143
Valid Loss:  0.002901306841522455
Epoch:  34  	Training Loss: 0.002710919361561537
Test Loss:  0.0022246376611292362
Valid Loss:  0.0026702461764216423
Epoch:  35  	Training Loss: 0.0024966634809970856
Test Loss:  0.002056397497653961
Valid Loss:  0.0024611153639853
Epoch:  36  	Training Loss: 0.0023037809878587723
Test Loss:  0.001904268516227603
Valid Loss:  0.00227256678044796
Epoch:  37  	Training Loss: 0.002130047185346484
Test Loss:  0.0017668382497504354
Valid Loss:  0.0021022651344537735
Epoch:  38  	Training Loss: 0.0019743600860238075
Test Loss:  0.0016442518681287766
Valid Loss:  0.0019505377858877182
Epoch:  39  	Training Loss: 0.0018349888268858194
Test Loss:  0.001533808303065598
Valid Loss:  0.001813356066122651
Epoch:  40  	Training Loss: 0.0017098723910748959
Test Loss:  0.0014337757602334023
Valid Loss:  0.001690135570243001
Epoch:  41  	Training Loss: 0.0015973950503394008
Test Loss:  0.0013431648258119822
Valid Loss:  0.001579804578796029
Epoch:  42  	Training Loss: 0.0014962172135710716
Test Loss:  0.0010748757049441338
Valid Loss:  0.00124216394033283
Epoch:  43  	Training Loss: 0.001196879195049405
Test Loss:  0.0009245981927961111
Valid Loss:  0.0010750896763056517
Epoch:  44  	Training Loss: 0.0010428959503769875
Test Loss:  0.0008344782399944961
Valid Loss:  0.0009663741220720112
Epoch:  45  	Training Loss: 0.0009489654330536723
Test Loss:  0.0007718249107711017
Valid Loss:  0.0008898208616301417
Epoch:  46  	Training Loss: 0.0008838786161504686
Test Loss:  0.0007257074466906488
Valid Loss:  0.0008331838762387633
Epoch:  47  	Training Loss: 0.0008364617242477834
Test Loss:  0.0006906500784680247
Valid Loss:  0.0007907854160293937
Epoch:  48  	Training Loss: 0.0008010228630155325
Test Loss:  0.0006633450975641608
Valid Loss:  0.0007580344099551439
Epoch:  49  	Training Loss: 0.0007738115964457393
Test Loss:  0.0006416704272851348
Valid Loss:  0.0007322389865294099
Epoch:  50  	Training Loss: 0.0007524962420575321
Test Loss:  0.0006241427036002278
Valid Loss:  0.0007115696789696813
Epoch:  51  	Training Loss: 0.0007354509434662759
Test Loss:  0.0006097039440646768
Valid Loss:  0.0006946911453269422
Epoch:  52  	Training Loss: 0.0007215122459456325
Test Loss:  0.0005426271818578243
Valid Loss:  0.0006268300930969417
Epoch:  53  	Training Loss: 0.0006501408643089235
Test Loss:  0.0004915434401482344
Valid Loss:  0.000563316629268229
Epoch:  54  	Training Loss: 0.0005879729287698865
Test Loss:  0.0004398584133014083
Valid Loss:  0.0005032381159253418
Epoch:  55  	Training Loss: 0.0005269503453746438
Test Loss:  0.0003917149151675403
Valid Loss:  0.0004477185138966888
Epoch:  56  	Training Loss: 0.0004714248061645776
Test Loss:  0.00035885089891962707
Valid Loss:  0.00041232153307646513
Epoch:  57  	Training Loss: 0.0004349818336777389
Test Loss:  0.00033033915678970516
Valid Loss:  0.00038035697070881724
Epoch:  58  	Training Loss: 0.000403261452447623
Test Loss:  0.00030451721977442503
Valid Loss:  0.00035209947964176536
Epoch:  59  	Training Loss: 0.0003746229049284011
Test Loss:  0.0002817023196257651
Valid Loss:  0.000327368441503495
Epoch:  60  	Training Loss: 0.00034901691833510995
Test Loss:  0.00026116915978491306
Valid Loss:  0.0003053375403396785
Epoch:  61  	Training Loss: 0.0003255956689827144
Test Loss:  0.00024238170590251684
Valid Loss:  0.0002855709462892264
Epoch:  62  	Training Loss: 0.00030398034141398966
Test Loss:  0.00024041389406193048
Valid Loss:  0.0002694504801183939
Epoch:  63  	Training Loss: 0.0002899474638979882
Test Loss:  0.00022180801897775382
Valid Loss:  0.0002571034128777683
Epoch:  64  	Training Loss: 0.0002761141222435981
Test Loss:  0.00021467983606271446
Valid Loss:  0.00024247226247098297
Epoch:  65  	Training Loss: 0.00026267024804838
Test Loss:  0.00020079349633306265
Valid Loss:  0.00023099624377209693
Epoch:  66  	Training Loss: 0.00025063316570594907
Test Loss:  0.00019336785771884024
Valid Loss:  0.00021931447554379702
Epoch:  67  	Training Loss: 0.000239429937209934
Test Loss:  0.00018172302225138992
Valid Loss:  0.00020809339184779674
Epoch:  68  	Training Loss: 0.00022880002507008612
Test Loss:  0.00017314008437097073
Valid Loss:  0.00019595760386437178
Epoch:  69  	Training Loss: 0.00021863749134354293
Test Loss:  0.0001642505230847746
Valid Loss:  0.00018552943947724998
Epoch:  70  	Training Loss: 0.0002095401578117162
Test Loss:  0.00015741270908620209
Valid Loss:  0.00017598312115296721
 14%|█▍        | 71/500 [00:54<08:26,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:02,  1.18it/s] 15%|█▌        | 75/500 [00:54<04:20,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:00<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:01<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:07<08:01,  1.18s/it] 19%|█▊        | 93/500 [01:07<05:44,  1.18it/s] 19%|█▉        | 95/500 [01:08<04:07,  1.63it/s] 19%|█▉        | 97/500 [01:08<03:00,  2.23it/s] 20%|█▉        | 99/500 [01:08<02:13,  3.01it/s] 20%|██        | 101/500 [01:14<07:49,  1.18s/it] 21%|██        | 103/500 [01:14<05:35,  1.18it/s] 21%|██        | 105/500 [01:14<04:01,  1.64it/s] 21%|██▏       | 107/500 [01:15<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:15<02:10,  3.00it/s] 22%|██▏       | 111/500 [01:21<07:34,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:21<03:53,  1.65it/s] 23%|██▎       | 117/500 [01:21<02:50,  2.25it/s] 24%|██▍       | 119/500 [01:21<02:05,  3.03it/s] 24%|██▍       | 121/500 [01:28<07:23,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:16,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:28<02:03,  3.01it/s] 26%|██▌       | 131/500 [01:35<07:15,  1.18s/it] 27%|██▋       | 133/500 [01:35<05:11,  1.18it/s] 27%|██▋       | 135/500 [01:35<03:44,  1.63it/s] 27%|██▋       | 137/500 [01:35<02:43,  2.22it/s]Epoch:  71  	Training Loss: 0.0002013238554354757
Test Loss:  0.00015059183351695538
Valid Loss:  0.00016744140884838998
Epoch:  72  	Training Loss: 0.0001937543274834752
Test Loss:  0.0001478232443332672
Valid Loss:  0.00016575580229982734
Epoch:  73  	Training Loss: 0.00019164709374308586
Test Loss:  0.00014676054706797004
Valid Loss:  0.00016406444774474949
Epoch:  74  	Training Loss: 0.00018975338025484234
Test Loss:  0.00014495827781502157
Valid Loss:  0.00016260327538475394
Epoch:  75  	Training Loss: 0.00018811049812939018
Test Loss:  0.00014373115845955908
Valid Loss:  0.00016127976414281875
Epoch:  76  	Training Loss: 0.0001866807579062879
Test Loss:  0.0001421612687408924
Valid Loss:  0.0001600156247150153
Epoch:  77  	Training Loss: 0.00018530426314100623
Test Loss:  0.00014086680312175304
Valid Loss:  0.0001587729639140889
Epoch:  78  	Training Loss: 0.00018398543761577457
Test Loss:  0.0001396511506754905
Valid Loss:  0.00015758443623781204
Epoch:  79  	Training Loss: 0.0001827868982218206
Test Loss:  0.00013846174988429993
Valid Loss:  0.00015645143867004663
Epoch:  80  	Training Loss: 0.00018167962844017893
Test Loss:  0.000137323047965765
Valid Loss:  0.00015534863632638007
Epoch:  81  	Training Loss: 0.00018060857837554067
Test Loss:  0.0001363549381494522
Valid Loss:  0.0001542932295706123
Epoch:  82  	Training Loss: 0.00017959173419512808
Test Loss:  0.00013641652185469866
Valid Loss:  0.000154018824105151
Epoch:  83  	Training Loss: 0.00017936350195668638
Test Loss:  0.0001360388268949464
Valid Loss:  0.00015377948875539005
Epoch:  84  	Training Loss: 0.00017916859360411763
Test Loss:  0.0001358327135676518
Valid Loss:  0.0001535645715193823
Epoch:  85  	Training Loss: 0.00017896627832669765
Test Loss:  0.0001356084831058979
Valid Loss:  0.0001533653849037364
Epoch:  86  	Training Loss: 0.0001787641813280061
Test Loss:  0.00013544218381866813
Valid Loss:  0.0001531732705188915
Epoch:  87  	Training Loss: 0.0001785544736776501
Test Loss:  0.0001352696563117206
Valid Loss:  0.0001529859728179872
Epoch:  88  	Training Loss: 0.00017834152095019817
Test Loss:  0.00013510356075130403
Valid Loss:  0.00015280408842954785
Epoch:  89  	Training Loss: 0.0001781251485226676
Test Loss:  0.00013494127779267728
Valid Loss:  0.00015262517263181508
Epoch:  90  	Training Loss: 0.00017790962010622025
Test Loss:  0.00013475264131557196
Valid Loss:  0.00015246232214849442
Epoch:  91  	Training Loss: 0.0001777003926690668
Test Loss:  0.00013459577166941017
Valid Loss:  0.00015232348232530057
Epoch:  92  	Training Loss: 0.0001775003329385072
Test Loss:  0.0001285276230191812
Valid Loss:  0.0001477124314988032
Epoch:  93  	Training Loss: 0.00017195989494211972
Test Loss:  0.0001254401431651786
Valid Loss:  0.0001441545318812132
Epoch:  94  	Training Loss: 0.00016737582336645573
Test Loss:  0.000122060562716797
Valid Loss:  0.0001408387761330232
Epoch:  95  	Training Loss: 0.00016325764590874314
Test Loss:  0.00011918301606783643
Valid Loss:  0.00013784164912067354
Epoch:  96  	Training Loss: 0.00015959370648488402
Test Loss:  0.00011658051516860723
Valid Loss:  0.0001351154496660456
Epoch:  97  	Training Loss: 0.00015639913908671588
Test Loss:  0.00011420287773944438
Valid Loss:  0.0001327789796050638
Epoch:  98  	Training Loss: 0.00015360544784925878
Test Loss:  0.00011199434811715037
Valid Loss:  0.00013067385589238256
Epoch:  99  	Training Loss: 0.0001511147856945172
Test Loss:  0.0001098774082493037
Valid Loss:  0.00012873555533587933
Epoch:  100  	Training Loss: 0.00014879892114549875
Test Loss:  0.00010791300883283839
Valid Loss:  0.00012701826926786453
Epoch:  101  	Training Loss: 0.00014666651259176433
Test Loss:  0.0001060418871929869
Valid Loss:  0.00012539055023808032
Epoch:  102  	Training Loss: 0.00014466397988144308
Test Loss:  0.00010406299406895414
Valid Loss:  0.00012113408592995256
Epoch:  103  	Training Loss: 0.00014068064047023654
Test Loss:  0.00010076926264446229
Valid Loss:  0.00011709194222930819
Epoch:  104  	Training Loss: 0.00013703774311579764
Test Loss:  9.714573388919234e-05
Valid Loss:  0.00011223898036405444
Epoch:  105  	Training Loss: 0.00013336580013856292
Test Loss:  9.39508099691011e-05
Valid Loss:  0.00010761841986095533
Epoch:  106  	Training Loss: 0.00012988159141968936
Test Loss:  9.051801316672936e-05
Valid Loss:  0.00010337676212657243
Epoch:  107  	Training Loss: 0.00012620702909771353
Test Loss:  8.661660103825852e-05
Valid Loss:  9.946280624717474e-05
Epoch:  108  	Training Loss: 0.0001225891028298065
Test Loss:  8.261864422820508e-05
Valid Loss:  9.596952440915629e-05
Epoch:  109  	Training Loss: 0.00011913993512280285
Test Loss:  7.911601278465241e-05
Valid Loss:  9.288705041399226e-05
Epoch:  110  	Training Loss: 0.00011596574040595442
Test Loss:  7.589872984681278e-05
Valid Loss:  9.010918438434601e-05
Epoch:  111  	Training Loss: 0.0001129248266806826
Test Loss:  7.294107490452006e-05
Valid Loss:  8.75847035786137e-05
Epoch:  112  	Training Loss: 0.0001100720401154831
Test Loss:  7.043326331768185e-05
Valid Loss:  8.6099753389135e-05
Epoch:  113  	Training Loss: 0.00010836174624273553
Test Loss:  7.188991730799899e-05
Valid Loss:  8.59412393765524e-05
Epoch:  114  	Training Loss: 0.00010691635543480515
Test Loss:  7.017332973191515e-05
Valid Loss:  8.491869084537029e-05
Epoch:  115  	Training Loss: 0.00010569230653345585
Test Loss:  7.121537055354565e-05
Valid Loss:  8.489079482387751e-05
Epoch:  116  	Training Loss: 0.00010466166713740677
Test Loss:  7.001803169259802e-05
Valid Loss:  8.417175558861345e-05
Epoch:  117  	Training Loss: 0.00010377906437497586
Test Loss:  7.074381574057043e-05
Valid Loss:  8.419221558142453e-05
Epoch:  118  	Training Loss: 0.00010302421287633479
Test Loss:  6.987476081121713e-05
Valid Loss:  8.366166730411351e-05
Epoch:  119  	Training Loss: 0.00010235547961201519
Test Loss:  7.034721784293652e-05
Valid Loss:  8.367667760467157e-05
Epoch:  120  	Training Loss: 0.0001017566246446222
Test Loss:  6.969600508455187e-05
Valid Loss:  8.326827082782984e-05
Epoch:  121  	Training Loss: 0.00010121675586560741
Test Loss:  6.998407479841262e-05
Valid Loss:  8.326313400175422e-05
Epoch:  122  	Training Loss: 0.00010073366138385609
Test Loss:  6.977524753892794e-05
Valid Loss:  8.310961129609495e-05
Epoch:  123  	Training Loss: 0.00010067669063573703
Test Loss:  6.968178786337376e-05
Valid Loss:  8.300082117784768e-05
Epoch:  124  	Training Loss: 0.00010062735236715525
Test Loss:  6.955389108043164e-05
Valid Loss:  8.288919343613088e-05
Epoch:  125  	Training Loss: 0.00010058365296572447
Test Loss:  6.946444045752287e-05
Valid Loss:  8.280136535177007e-05
Epoch:  126  	Training Loss: 0.00010054705489892513
Test Loss:  6.938885780982673e-05
Valid Loss:  8.272261766251177e-05
Epoch:  127  	Training Loss: 0.00010051276331068948
Test Loss:  6.932033284101635e-05
Valid Loss:  8.265001088147983e-05
Epoch:  128  	Training Loss: 0.00010048029798781499
Test Loss:  6.92609028192237e-05
Valid Loss:  8.258482557721436e-05
Epoch:  129  	Training Loss: 0.00010044957889476791
Test Loss:  6.920626037754118e-05
Valid Loss:  8.252372936112806e-05
Epoch:  130  	Training Loss: 0.00010041993664344773
Test Loss:  6.915998528711498e-05
Valid Loss:  8.24675225885585e-05
Epoch:  131  	Training Loss: 0.00010039202607003972
Test Loss:  6.911791570018977e-05
Valid Loss:  8.241557952715084e-05
Epoch:  132  	Training Loss: 0.00010036463208962232
Test Loss:  6.897604907862842e-05
Valid Loss:  8.145321771735325e-05
Epoch:  133  	Training Loss: 9.938316361512989e-05
Test Loss:  6.800327537348494e-05
Valid Loss:  8.020555833354592e-05
Epoch:  134  	Training Loss: 9.833710646489635e-05
Test Loss:  6.787771417293698e-05
Valid Loss:  7.940880459500477e-05
Epoch:  135  	Training Loss: 9.730876627145335e-05
Test Loss:  6.649104761891067e-05
Valid Loss:  7.80707923695445e-05
Epoch:  136  	Training Loss: 9.630959539208561e-05
Test Loss:  6.687396671622992e-05
Valid Loss:  7.7678298112005e-05
Epoch:  137  	Training Loss: 9.539357415633276e-05
Test Loss:  6.505268538603559e-05
Valid Loss:  7.616481161676347e-05
Epoch:  138  	Training Loss: 9.45813735597767e-05
Test Loss:  6.648585258517414e-05
Valid Loss:   28%|██▊       | 139/500 [01:35<02:00,  2.99it/s] 28%|██▊       | 141/500 [01:41<07:01,  1.17s/it] 29%|██▊       | 143/500 [01:42<05:02,  1.18it/s] 29%|██▉       | 145/500 [01:42<03:37,  1.63it/s] 29%|██▉       | 147/500 [01:42<02:38,  2.23it/s] 30%|██▉       | 149/500 [01:42<01:57,  3.00it/s] 30%|███       | 151/500 [01:48<06:53,  1.19s/it] 31%|███       | 153/500 [01:48<04:55,  1.17it/s] 31%|███       | 155/500 [01:49<03:32,  1.62it/s] 31%|███▏      | 157/500 [01:49<02:34,  2.22it/s] 32%|███▏      | 159/500 [01:49<01:54,  2.98it/s] 32%|███▏      | 161/500 [01:55<06:40,  1.18s/it] 33%|███▎      | 163/500 [01:55<04:46,  1.18it/s] 33%|███▎      | 165/500 [01:55<03:26,  1.63it/s] 33%|███▎      | 167/500 [01:56<02:29,  2.22it/s] 34%|███▍      | 169/500 [01:56<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:02<06:29,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:38,  1.17it/s] 35%|███▌      | 175/500 [02:02<03:19,  1.63it/s] 35%|███▌      | 177/500 [02:02<02:25,  2.22it/s] 36%|███▌      | 179/500 [02:03<01:47,  2.98it/s] 36%|███▌      | 181/500 [02:09<06:13,  1.17s/it] 37%|███▋      | 183/500 [02:09<04:26,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:20,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.00it/s] 38%|███▊      | 191/500 [02:16<06:03,  1.18s/it] 39%|███▊      | 193/500 [02:16<04:19,  1.18it/s] 39%|███▉      | 195/500 [02:16<03:07,  1.63it/s] 39%|███▉      | 197/500 [02:16<02:15,  2.23it/s] 40%|███▉      | 199/500 [02:16<01:40,  3.00it/s] 40%|████      | 201/500 [02:22<05:51,  1.17s/it] 41%|████      | 203/500 [02:23<04:10,  1.19it/s] 41%|████      | 205/500 [02:23<03:00,  1.63it/s]7.65729128033854e-05
Epoch:  139  	Training Loss: 9.390773630002514e-05
Test Loss:  6.371690687956288e-05
Valid Loss:  7.466016541002318e-05
Epoch:  140  	Training Loss: 9.34603885980323e-05
Test Loss:  6.754873902536929e-05
Valid Loss:  7.68457175581716e-05
Epoch:  141  	Training Loss: 9.341474651591852e-05
Test Loss:  6.355233199428767e-05
Valid Loss:  7.448412361554801e-05
Epoch:  142  	Training Loss: 9.412405779585242e-05
Test Loss:  6.586180097656325e-05
Valid Loss:  7.484128582291305e-05
Epoch:  143  	Training Loss: 9.145625517703593e-05
Test Loss:  6.412324000848457e-05
Valid Loss:  7.35862777219154e-05
Epoch:  144  	Training Loss: 9.104727359954268e-05
Test Loss:  6.482332537416369e-05
Valid Loss:  7.393863779725507e-05
Epoch:  145  	Training Loss: 9.09253503778018e-05
Test Loss:  6.478031718870625e-05
Valid Loss:  7.385593198705465e-05
Epoch:  146  	Training Loss: 9.0847272076644e-05
Test Loss:  6.498505536001176e-05
Valid Loss:  7.393663690891117e-05
Epoch:  147  	Training Loss: 9.078279254026711e-05
Test Loss:  6.508929800475016e-05
Valid Loss:  7.395699503831565e-05
Epoch:  148  	Training Loss: 9.072550165001303e-05
Test Loss:  6.52088929200545e-05
Valid Loss:  7.399333117064089e-05
Epoch:  149  	Training Loss: 9.067374048754573e-05
Test Loss:  6.530350947286934e-05
Valid Loss:  7.401834591291845e-05
Epoch:  150  	Training Loss: 9.06271961866878e-05
Test Loss:  6.53891111142002e-05
Valid Loss:  7.40419200155884e-05
Epoch:  151  	Training Loss: 9.058380237547681e-05
Test Loss:  6.546198710566387e-05
Valid Loss:  7.40610048524104e-05
Epoch:  152  	Training Loss: 9.054406837094575e-05
Test Loss:  6.525573553517461e-05
Valid Loss:  7.391102553810924e-05
Epoch:  153  	Training Loss: 9.025459439726546e-05
Test Loss:  6.512755498988554e-05
Valid Loss:  7.381165778497234e-05
Epoch:  154  	Training Loss: 8.99849328561686e-05
Test Loss:  6.499894516309723e-05
Valid Loss:  7.371691754087806e-05
Epoch:  155  	Training Loss: 8.973760850494727e-05
Test Loss:  6.487515202024952e-05
Valid Loss:  7.362918404396623e-05
Epoch:  156  	Training Loss: 8.951057679951191e-05
Test Loss:  6.47487977403216e-05
Valid Loss:  7.354430999839678e-05
Epoch:  157  	Training Loss: 8.929692558012903e-05
Test Loss:  6.462637975346297e-05
Valid Loss:  7.34620334696956e-05
Epoch:  158  	Training Loss: 8.909727330319583e-05
Test Loss:  6.451305671362206e-05
Valid Loss:  7.338719296967611e-05
Epoch:  159  	Training Loss: 8.891746256267652e-05
Test Loss:  6.439727440010756e-05
Valid Loss:  7.331195229198784e-05
Epoch:  160  	Training Loss: 8.874756167642772e-05
Test Loss:  6.428263441193849e-05
Valid Loss:  7.323808677028865e-05
Epoch:  161  	Training Loss: 8.858846558723599e-05
Test Loss:  6.41738370177336e-05
Valid Loss:  7.317183190025389e-05
Epoch:  162  	Training Loss: 8.844344120007008e-05
Test Loss:  6.303418922470883e-05
Valid Loss:  7.24075798643753e-05
Epoch:  163  	Training Loss: 8.762205834500492e-05
Test Loss:  6.196635513333604e-05
Valid Loss:  7.159693632274866e-05
Epoch:  164  	Training Loss: 8.713587885722518e-05
Test Loss:  6.120446778368205e-05
Valid Loss:  7.103902316885069e-05
Epoch:  165  	Training Loss: 8.674162381794304e-05
Test Loss:  6.057495920686051e-05
Valid Loss:  7.057050970615819e-05
Epoch:  166  	Training Loss: 8.640135638415813e-05
Test Loss:  6.0071783082094043e-05
Valid Loss:  7.018086034804583e-05
Epoch:  167  	Training Loss: 8.60963627928868e-05
Test Loss:  5.965996388113126e-05
Valid Loss:  6.98471994837746e-05
Epoch:  168  	Training Loss: 8.581409201724455e-05
Test Loss:  5.931296618655324e-05
Valid Loss:  6.955434218980372e-05
Epoch:  169  	Training Loss: 8.5547158960253e-05
Test Loss:  5.9017573221353814e-05
Valid Loss:  6.92924513714388e-05
Epoch:  170  	Training Loss: 8.52911762194708e-05
Test Loss:  5.876495924894698e-05
Valid Loss:  6.906983617227525e-05
Epoch:  171  	Training Loss: 8.504203287884593e-05
Test Loss:  5.853959737578407e-05
Valid Loss:  6.886206392664462e-05
Epoch:  172  	Training Loss: 8.479774260194972e-05
Test Loss:  5.8952620747732e-05
Valid Loss:  6.901455344632268e-05
Epoch:  173  	Training Loss: 8.460661047138274e-05
Test Loss:  5.909683386562392e-05
Valid Loss:  6.902255699969828e-05
Epoch:  174  	Training Loss: 8.444573904853314e-05
Test Loss:  5.9204307035543025e-05
Valid Loss:  6.902054155943915e-05
Epoch:  175  	Training Loss: 8.430070010945201e-05
Test Loss:  5.9298185078660026e-05
Valid Loss:  6.902296445332468e-05
Epoch:  176  	Training Loss: 8.416953642154112e-05
Test Loss:  5.938195681665093e-05
Valid Loss:  6.902855966472998e-05
Epoch:  177  	Training Loss: 8.404965774388984e-05
Test Loss:  5.945196244283579e-05
Valid Loss:  6.903414760017768e-05
Epoch:  178  	Training Loss: 8.393882308155298e-05
Test Loss:  5.950969352852553e-05
Valid Loss:  6.903886242071167e-05
Epoch:  179  	Training Loss: 8.383343811146915e-05
Test Loss:  5.955636515864171e-05
Valid Loss:  6.904404290253296e-05
Epoch:  180  	Training Loss: 8.373454329557717e-05
Test Loss:  5.9593650803435594e-05
Valid Loss:  6.904756446601823e-05
Epoch:  181  	Training Loss: 8.364049426745623e-05
Test Loss:  5.9617843362502754e-05
Valid Loss:  6.904943438712507e-05
Epoch:  182  	Training Loss: 8.355070895049721e-05
Test Loss:  5.931025225436315e-05
Valid Loss:  6.882612069603056e-05
Epoch:  183  	Training Loss: 8.346386312041432e-05
Test Loss:  5.930567203904502e-05
Valid Loss:  6.884203321533278e-05
Epoch:  184  	Training Loss: 8.339200576301664e-05
Test Loss:  5.921840784139931e-05
Valid Loss:  6.879091961309314e-05
Epoch:  185  	Training Loss: 8.33214508020319e-05
Test Loss:  5.915543079026975e-05
Valid Loss:  6.875826511532068e-05
Epoch:  186  	Training Loss: 8.325175440404564e-05
Test Loss:  5.908658204134554e-05
Valid Loss:  6.871939694974571e-05
Epoch:  187  	Training Loss: 8.318223990499973e-05
Test Loss:  5.901950498810038e-05
Valid Loss:  6.86833809595555e-05
Epoch:  188  	Training Loss: 8.31128127174452e-05
Test Loss:  5.894969217479229e-05
Valid Loss:  6.864727765787393e-05
Epoch:  189  	Training Loss: 8.304420043714345e-05
Test Loss:  5.8877569244941697e-05
Valid Loss:  6.861086149001494e-05
Epoch:  190  	Training Loss: 8.297516615130007e-05
Test Loss:  5.8804216678254306e-05
Valid Loss:  6.857343396404758e-05
Epoch:  191  	Training Loss: 8.290444384329021e-05
Test Loss:  5.873138798051514e-05
Valid Loss:  6.85353297740221e-05
Epoch:  192  	Training Loss: 8.283434726763517e-05
Test Loss:  5.8681493101175874e-05
Valid Loss:  6.85062914271839e-05
Epoch:  193  	Training Loss: 8.274064748547971e-05
Test Loss:  5.8621048083296046e-05
Valid Loss:  6.847041368018836e-05
Epoch:  194  	Training Loss: 8.264812640845776e-05
Test Loss:  5.8554040151648223e-05
Valid Loss:  6.843022856628522e-05
Epoch:  195  	Training Loss: 8.255557622760534e-05
Test Loss:  5.8483838074607775e-05
Valid Loss:  6.838889385107905e-05
Epoch:  196  	Training Loss: 8.246430661529303e-05
Test Loss:  5.841166421305388e-05
Valid Loss:  6.834643863840029e-05
Epoch:  197  	Training Loss: 8.237469592131674e-05
Test Loss:  5.833886098116636e-05
Valid Loss:  6.830734491813928e-05
Epoch:  198  	Training Loss: 8.228499791584909e-05
Test Loss:  5.8263216487830505e-05
Valid Loss:  6.826422031736001e-05
Epoch:  199  	Training Loss: 8.219580195145682e-05
Test Loss:  5.8186975365970284e-05
Valid Loss:  6.822093564551324e-05
Epoch:  200  	Training Loss: 8.21073044789955e-05
Test Loss:  5.8111432736041024e-05
Valid Loss:  6.817456596763805e-05
Epoch:  201  	Training Loss: 8.201894524972886e-05
Test Loss:  5.8030287618748844e-05
Valid Loss:  6.812864012317732e-05
Epoch:  202  	Training Loss: 8.193045505322516e-05
Test Loss:  5.694099309039302e-05
Valid Loss:  6.734712223988026e-05
Epoch:  203  	Training Loss: 8.130179776344448e-05
Test Loss:  5.650928505929187e-05
Valid Loss:  6.69528599246405e-05
Epoch:  204  	Training Loss: 8.086685556918383e-05
Test Loss:  5.630861414829269e-05
Valid Loss:  6.673258758382872e-05
Epoch:  205  	Training Loss: 8.055882062762976e-05
Test Loss:  5.6197917729150504e-05
Valid Loss:  6.658762868028134e-05
Epoch:  206  	Training Loss: 8.031913603190333e-05
Test Loss:  5.617732313112356e-05
Valid Loss:  6.649597344221547e-05
 41%|████▏     | 207/500 [02:23<02:12,  2.21it/s] 42%|████▏     | 209/500 [02:23<01:37,  2.97it/s] 42%|████▏     | 211/500 [02:29<05:41,  1.18s/it] 43%|████▎     | 213/500 [02:29<04:03,  1.18it/s] 43%|████▎     | 215/500 [02:30<02:55,  1.63it/s] 43%|████▎     | 217/500 [02:30<02:08,  2.21it/s] 44%|████▍     | 219/500 [02:30<01:34,  2.97it/s] 44%|████▍     | 221/500 [02:36<05:29,  1.18s/it] 45%|████▍     | 223/500 [02:36<03:54,  1.18it/s] 45%|████▌     | 225/500 [02:36<02:48,  1.63it/s] 45%|████▌     | 227/500 [02:37<02:02,  2.22it/s] 46%|████▌     | 229/500 [02:37<01:31,  2.96it/s] 46%|████▌     | 231/500 [02:43<05:17,  1.18s/it] 47%|████▋     | 233/500 [02:43<03:46,  1.18it/s] 47%|████▋     | 235/500 [02:43<02:42,  1.63it/s] 47%|████▋     | 237/500 [02:43<01:58,  2.22it/s] 48%|████▊     | 239/500 [02:44<01:27,  2.99it/s] 48%|████▊     | 241/500 [02:50<05:03,  1.17s/it] 49%|████▊     | 243/500 [02:50<03:36,  1.19it/s] 49%|████▉     | 245/500 [02:50<02:35,  1.64it/s] 49%|████▉     | 247/500 [02:50<01:53,  2.24it/s] 50%|████▉     | 249/500 [02:50<01:23,  3.01it/s] 50%|█████     | 251/500 [03:03<08:40,  2.09s/it] 51%|█████     | 253/500 [03:03<06:06,  1.49s/it] 51%|█████     | 255/500 [03:03<04:19,  1.06s/it] 51%|█████▏    | 257/500 [03:03<03:04,  1.31it/s] 52%|█████▏    | 259/500 [03:03<02:13,  1.81it/s] 52%|█████▏    | 261/500 [03:10<05:16,  1.32s/it] 53%|█████▎    | 263/500 [03:10<03:44,  1.05it/s] 53%|█████▎    | 265/500 [03:10<02:40,  1.46it/s] 53%|█████▎    | 267/500 [03:10<01:56,  2.01it/s] 54%|█████▍    | 269/500 [03:10<01:25,  2.71it/s] 54%|█████▍    | 271/500 [03:16<04:35,  1.20s/it]Epoch:  207  	Training Loss: 8.015351340873167e-05
Test Loss:  5.615396730718203e-05
Valid Loss:  6.641763320658356e-05
Epoch:  208  	Training Loss: 8.002342656254768e-05
Test Loss:  5.6156324717449024e-05
Valid Loss:  6.635693716816604e-05
Epoch:  209  	Training Loss: 7.992333848960698e-05
Test Loss:  5.6168631999753416e-05
Valid Loss:  6.629773270105943e-05
Epoch:  210  	Training Loss: 7.983443356351927e-05
Test Loss:  5.6171760661527514e-05
Valid Loss:  6.624040543101728e-05
Epoch:  211  	Training Loss: 7.975440530572087e-05
Test Loss:  5.61859123990871e-05
Valid Loss:  6.619295163545758e-05
Epoch:  212  	Training Loss: 7.96859385445714e-05
Test Loss:  5.50581025891006e-05
Valid Loss:  6.523040065076202e-05
Epoch:  213  	Training Loss: 7.870016997912899e-05
Test Loss:  5.384680480347015e-05
Valid Loss:  6.424501771107316e-05
Epoch:  214  	Training Loss: 7.784798799548298e-05
Test Loss:  5.285993393044919e-05
Valid Loss:  6.342735287034884e-05
Epoch:  215  	Training Loss: 7.709575584158301e-05
Test Loss:  5.195337871555239e-05
Valid Loss:  6.271741585806012e-05
Epoch:  216  	Training Loss: 7.641615229658782e-05
Test Loss:  5.1106399041600525e-05
Valid Loss:  6.209901766851544e-05
Epoch:  217  	Training Loss: 7.579359225928783e-05
Test Loss:  5.0366717914585024e-05
Valid Loss:  6.15451717749238e-05
Epoch:  218  	Training Loss: 7.520990038756281e-05
Test Loss:  4.9689042498357594e-05
Valid Loss:  6.102845509303734e-05
Epoch:  219  	Training Loss: 7.461909262929112e-05
Test Loss:  4.905229798168875e-05
Valid Loss:  6.053433389752172e-05
Epoch:  220  	Training Loss: 7.403762720059603e-05
Test Loss:  4.847229865845293e-05
Valid Loss:  6.0073132772231475e-05
Epoch:  221  	Training Loss: 7.348131475737318e-05
Test Loss:  4.7943995014065877e-05
Valid Loss:  5.964341835351661e-05
Epoch:  222  	Training Loss: 7.294616079889238e-05
Test Loss:  4.651757626561448e-05
Valid Loss:  5.860891178599559e-05
Epoch:  223  	Training Loss: 7.126876153051853e-05
Test Loss:  4.4885957322549075e-05
Valid Loss:  5.738280015066266e-05
Epoch:  224  	Training Loss: 6.97735813446343e-05
Test Loss:  4.3743835703935474e-05
Valid Loss:  5.648909791489132e-05
Epoch:  225  	Training Loss: 6.841503636678681e-05
Test Loss:  4.2663770727813244e-05
Valid Loss:  5.56164923182223e-05
Epoch:  226  	Training Loss: 6.716896314173937e-05
Test Loss:  4.1788800444919616e-05
Valid Loss:  5.48919961147476e-05
Epoch:  227  	Training Loss: 6.601955828955397e-05
Test Loss:  4.099331272300333e-05
Valid Loss:  5.422598769655451e-05
Epoch:  228  	Training Loss: 6.495371781056747e-05
Test Loss:  4.0302656998392195e-05
Valid Loss:  5.363085801945999e-05
Epoch:  229  	Training Loss: 6.395815580617636e-05
Test Loss:  3.968505188822746e-05
Valid Loss:  5.310048800311051e-05
Epoch:  230  	Training Loss: 6.30224822089076e-05
Test Loss:  3.9120492147048935e-05
Valid Loss:  5.261725891614333e-05
Epoch:  231  	Training Loss: 6.214033783180639e-05
Test Loss:  3.8609163311775774e-05
Valid Loss:  5.216048884904012e-05
Epoch:  232  	Training Loss: 6.132476846687496e-05
Test Loss:  3.8160414987942204e-05
Valid Loss:  5.147411866346374e-05
Epoch:  233  	Training Loss: 6.100186874391511e-05
Test Loss:  3.879356518154964e-05
Valid Loss:  5.194071854930371e-05
Epoch:  234  	Training Loss: 6.073625263525173e-05
Test Loss:  3.863786332658492e-05
Valid Loss:  5.159936335985549e-05
Epoch:  235  	Training Loss: 6.051485252100974e-05
Test Loss:  3.905292760464363e-05
Valid Loss:  5.1887051085941494e-05
Epoch:  236  	Training Loss: 6.032823876012117e-05
Test Loss:  3.9035745430737734e-05
Valid Loss:  5.172742385184392e-05
Epoch:  237  	Training Loss: 6.0169375501573086e-05
Test Loss:  3.9319260395132005e-05
Valid Loss:  5.191228410694748e-05
Epoch:  238  	Training Loss: 6.003220551065169e-05
Test Loss:  3.9363367250189185e-05
Valid Loss:  5.1848335715476424e-05
Epoch:  239  	Training Loss: 5.9913178120041266e-05
Test Loss:  3.956333239329979e-05
Valid Loss:  5.1971146604046226e-05
Epoch:  240  	Training Loss: 5.980848800390959e-05
Test Loss:  3.962809205404483e-05
Valid Loss:  5.195558333070949e-05
Epoch:  241  	Training Loss: 5.971535938442685e-05
Test Loss:  3.9772650779923424e-05
Valid Loss:  5.2041359595023096e-05
Epoch:  242  	Training Loss: 5.9632289776345715e-05
Test Loss:  3.950497921323404e-05
Valid Loss:  5.1907602028222755e-05
Epoch:  243  	Training Loss: 5.920013063587248e-05
Test Loss:  3.844376988126896e-05
Valid Loss:  5.073396459920332e-05
Epoch:  244  	Training Loss: 5.886704093427397e-05
Test Loss:  3.938024747185409e-05
Valid Loss:  5.1800423534587026e-05
Epoch:  245  	Training Loss: 5.868614971404895e-05
Test Loss:  3.779366670642048e-05
Valid Loss:  4.988129876437597e-05
Epoch:  246  	Training Loss: 5.885280552320182e-05
Test Loss:  4.2198746086796746e-05
Valid Loss:  5.451204197015613e-05
Epoch:  247  	Training Loss: 5.994738603476435e-05
Test Loss:  4.096176053280942e-05
Valid Loss:  5.2451279771048576e-05
Epoch:  248  	Training Loss: 6.359115650411695e-05
Test Loss:  6.127844972070307e-05
Valid Loss:  7.281747821252793e-05
Epoch:  249  	Training Loss: 7.426115917041898e-05
Test Loss:  7.885073137003928e-05
Valid Loss:  8.772024011705071e-05
Epoch:  250  	Training Loss: 0.00010475139424670488
Test Loss:  0.00019397545838728547
Valid Loss:  0.00019907092791981995
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.0001895496970973909
Test Loss:  5.370815779315308e-05
Valid Loss:  6.591874989680946e-05
Epoch:  252  	Training Loss: 6.850024510640651e-05
Test Loss:  4.135570634389296e-05
Valid Loss:  5.365555261960253e-05
Epoch:  253  	Training Loss: 6.009660137351602e-05
Test Loss:  4.0000501030590385e-05
Valid Loss:  5.2328381570987403e-05
Epoch:  254  	Training Loss: 5.9529840655159205e-05
Test Loss:  3.952404949814081e-05
Valid Loss:  5.188993236515671e-05
Epoch:  255  	Training Loss: 5.927748861722648e-05
Test Loss:  3.921873576473445e-05
Valid Loss:  5.161810258869082e-05
Epoch:  256  	Training Loss: 5.904897989239544e-05
Test Loss:  3.896697671734728e-05
Valid Loss:  5.1392657042015344e-05
Epoch:  257  	Training Loss: 5.882130790269002e-05
Test Loss:  3.8742982724215835e-05
Valid Loss:  5.11875914526172e-05
Epoch:  258  	Training Loss: 5.8600147895049304e-05
Test Loss:  3.8542162656085566e-05
Valid Loss:  5.099713962408714e-05
Epoch:  259  	Training Loss: 5.838463403051719e-05
Test Loss:  3.8356793083949015e-05
Valid Loss:  5.0816714065149426e-05
Epoch:  260  	Training Loss: 5.817314377054572e-05
Test Loss:  3.818714321823791e-05
Valid Loss:  5.064759898232296e-05
Epoch:  261  	Training Loss: 5.79652696615085e-05
Test Loss:  3.802797436947003e-05
Valid Loss:  5.0484064558986574e-05
Epoch:  262  	Training Loss: 5.7760978961596265e-05
Test Loss:  3.755156649276614e-05
Valid Loss:  5.012107430957258e-05
Epoch:  263  	Training Loss: 5.745635644416325e-05
Test Loss:  3.718545849551447e-05
Valid Loss:  4.9854585085995495e-05
Epoch:  264  	Training Loss: 5.7184101024176925e-05
Test Loss:  3.6876990634482354e-05
Valid Loss:  4.96321554237511e-05
Epoch:  265  	Training Loss: 5.6930395658127964e-05
Test Loss:  3.66137464880012e-05
Valid Loss:  4.943410021951422e-05
Epoch:  266  	Training Loss: 5.6691773352213204e-05
Test Loss:  3.638047928689048e-05
Valid Loss:  4.9253252655034885e-05
Epoch:  267  	Training Loss: 5.646801582770422e-05
Test Loss:  3.616490721469745e-05
Valid Loss:  4.908467235509306e-05
Epoch:  268  	Training Loss: 5.6252003560075536e-05
Test Loss:  3.5967546864412725e-05
Valid Loss:  4.89247431687545e-05
Epoch:  269  	Training Loss: 5.604383477475494e-05
Test Loss:  3.578665928216651e-05
Valid Loss:  4.8774269089335576e-05
Epoch:  270  	Training Loss: 5.584552127402276e-05
Test Loss:  3.562050551408902e-05
Valid Loss:  4.863170033786446e-05
Epoch:  271  	Training Loss: 5.565420724451542e-05
Test Loss:  3.54642907041125e-05
Valid Loss:  4.8495530791115016e-05
Epoch:  272  	Training Loss: 5.546645843423903e-05
Test Loss:  3.54146322933957e-05
Valid Loss:  4.843063288717531e-05
Epoch:  273  	Training Loss: 5.5363550927722827e-05
Test Loss:  3.535924042807892e-05
Valid Loss:   55%|█████▍    | 273/500 [03:17<03:16,  1.16it/s] 55%|█████▌    | 275/500 [03:17<02:20,  1.60it/s] 55%|█████▌    | 277/500 [03:17<01:41,  2.19it/s] 56%|█████▌    | 279/500 [03:17<01:15,  2.94it/s] 56%|█████▌    | 281/500 [03:23<04:18,  1.18s/it] 56%|█████▋    | 282/500 [03:24<03:45,  1.03s/it] 57%|█████▋    | 283/500 [03:24<03:09,  1.14it/s] 57%|█████▋    | 284/500 [03:24<02:32,  1.41it/s] 57%|█████▋    | 286/500 [03:24<01:38,  2.17it/s] 58%|█████▊    | 288/500 [03:24<01:07,  3.12it/s] 58%|█████▊    | 290/500 [03:24<00:49,  4.27it/s] 58%|█████▊    | 292/500 [03:31<04:08,  1.19s/it] 59%|█████▉    | 294/500 [03:31<02:52,  1.20it/s] 59%|█████▉    | 296/500 [03:31<02:01,  1.68it/s] 60%|█████▉    | 298/500 [03:31<01:28,  2.29it/s] 60%|██████    | 300/500 [03:31<01:04,  3.10it/s] 60%|██████    | 302/500 [03:38<03:52,  1.17s/it] 61%|██████    | 304/500 [03:38<02:44,  1.19it/s] 61%|██████    | 306/500 [03:38<01:57,  1.65it/s] 62%|██████▏   | 308/500 [03:38<01:24,  2.26it/s] 62%|██████▏   | 310/500 [03:38<01:02,  3.05it/s] 62%|██████▏   | 312/500 [03:44<03:42,  1.18s/it] 63%|██████▎   | 314/500 [03:45<02:37,  1.18it/s] 63%|██████▎   | 316/500 [03:45<01:52,  1.63it/s] 64%|██████▎   | 318/500 [03:45<01:21,  2.23it/s] 64%|██████▍   | 320/500 [03:45<00:59,  3.00it/s] 64%|██████▍   | 322/500 [03:51<03:35,  1.21s/it] 65%|██████▍   | 324/500 [03:52<02:32,  1.15it/s] 65%|██████▌   | 326/500 [03:52<01:48,  1.60it/s] 66%|██████▌   | 328/500 [03:52<01:18,  2.18it/s] 66%|██████▌   | 330/500 [03:52<00:57,  2.93it/s] 66%|██████▋   | 332/500 [03:58<03:19,  1.19s/it] 67%|██████▋   | 334/500 [03:58<02:21,  1.17it/s] 67%|██████▋   | 336/500 [03:59<01:41,  1.62it/s] 68%|██████▊   | 338/500 [03:59<01:13,  2.21it/s] 68%|██████▊   | 340/500 [03:59<00:53,  2.97it/s]4.835391155211255e-05
Epoch:  274  	Training Loss: 5.5261967645492405e-05
Test Loss:  3.530222238623537e-05
Valid Loss:  4.8274436267092824e-05
Epoch:  275  	Training Loss: 5.516110104508698e-05
Test Loss:  3.524591738823801e-05
Valid Loss:  4.8193865950452164e-05
Epoch:  276  	Training Loss: 5.506117668119259e-05
Test Loss:  3.5191100323572755e-05
Valid Loss:  4.811446706298739e-05
Epoch:  277  	Training Loss: 5.496193625731394e-05
Test Loss:  3.513778938213363e-05
Valid Loss:  4.8036650696303695e-05
Epoch:  278  	Training Loss: 5.486315058078617e-05
Test Loss:  3.508567897370085e-05
Valid Loss:  4.795952918357216e-05
Epoch:  279  	Training Loss: 5.476537626236677e-05
Test Loss:  3.503497282508761e-05
Valid Loss:  4.788377555087209e-05
Epoch:  280  	Training Loss: 5.46685369045008e-05
Test Loss:  3.498496880638413e-05
Valid Loss:  4.7807960072532296e-05
Epoch:  281  	Training Loss: 5.457178485812619e-05
Test Loss:  3.4935765143018216e-05
Valid Loss:  4.7734320105519146e-05
Epoch:  282  	Training Loss: 5.447631701827049e-05
Test Loss:  3.4857323043979704e-05
Valid Loss:  4.7624780563637614e-05
Epoch:  283  	Training Loss: 5.420098386821337e-05
Test Loss:  3.4709592000581324e-05
Valid Loss:  4.7450455895159394e-05
Epoch:  284  	Training Loss: 5.39373213541694e-05
Test Loss:  3.457907951087691e-05
Valid Loss:  4.729929059976712e-05
Epoch:  285  	Training Loss: 5.368257552618161e-05
Test Loss:  3.4442473406670615e-05
Valid Loss:  4.714483657153323e-05
Epoch:  286  	Training Loss: 5.343249358702451e-05
Test Loss:  3.430300057516433e-05
Valid Loss:  4.699025157606229e-05
Epoch:  287  	Training Loss: 5.318749026628211e-05
Test Loss:  3.4201751986984164e-05
Valid Loss:  4.688317858381197e-05
Epoch:  288  	Training Loss: 5.295234586810693e-05
Test Loss:  3.40059632435441e-05
Valid Loss:  4.666382301365957e-05
Epoch:  289  	Training Loss: 5.2718809456564486e-05
Test Loss:  3.392169310245663e-05
Valid Loss:  4.658068064600229e-05
Epoch:  290  	Training Loss: 5.2486742788460106e-05
Test Loss:  3.376766471774317e-05
Valid Loss:  4.6405541070271283e-05
Epoch:  291  	Training Loss: 5.226281064096838e-05
Test Loss:  3.3637868909863755e-05
Valid Loss:  4.6262022806331515e-05
Epoch:  292  	Training Loss: 5.2042472816538066e-05
Test Loss:  3.345683217048645e-05
Valid Loss:  4.6039836888667196e-05
Epoch:  293  	Training Loss: 5.196264828555286e-05
Test Loss:  3.333787026349455e-05
Valid Loss:  4.591618198901415e-05
Epoch:  294  	Training Loss: 5.1893166528316215e-05
Test Loss:  3.32360141328536e-05
Valid Loss:  4.581701068673283e-05
Epoch:  295  	Training Loss: 5.182625318411738e-05
Test Loss:  3.3141812309622765e-05
Valid Loss:  4.572659599944018e-05
Epoch:  296  	Training Loss: 5.1761082431767136e-05
Test Loss:  3.305428253952414e-05
Valid Loss:  4.5641238102689385e-05
Epoch:  297  	Training Loss: 5.16976579092443e-05
Test Loss:  3.297159855719656e-05
Valid Loss:  4.555963823804632e-05
Epoch:  298  	Training Loss: 5.163581226952374e-05
Test Loss:  3.2892858143895864e-05
Valid Loss:  4.548145807348192e-05
Epoch:  299  	Training Loss: 5.157546911505051e-05
Test Loss:  3.2819079933688045e-05
Valid Loss:  4.540658846963197e-05
Epoch:  300  	Training Loss: 5.151610093889758e-05
Test Loss:  3.2749005185905844e-05
Valid Loss:  4.533440005616285e-05
Epoch:  301  	Training Loss: 5.14581442985218e-05
Test Loss:  3.268240106990561e-05
Valid Loss:  4.5265431253938004e-05
Epoch:  302  	Training Loss: 5.140138455317356e-05
Test Loss:  3.29267350025475e-05
Valid Loss:  4.542858005152084e-05
Epoch:  303  	Training Loss: 5.120541391079314e-05
Test Loss:  3.3014533983077854e-05
Valid Loss:  4.544133844319731e-05
Epoch:  304  	Training Loss: 5.104076990392059e-05
Test Loss:  3.3047705073840916e-05
Valid Loss:  4.540495137916878e-05
Epoch:  305  	Training Loss: 5.088560646981932e-05
Test Loss:  3.306090002297424e-05
Valid Loss:  4.535424159257673e-05
Epoch:  306  	Training Loss: 5.073732609162107e-05
Test Loss:  3.306548387627117e-05
Valid Loss:  4.53104694315698e-05
Epoch:  307  	Training Loss: 5.059978138888255e-05
Test Loss:  3.30075818055775e-05
Valid Loss:  4.519859794527292e-05
Epoch:  308  	Training Loss: 5.045936268288642e-05
Test Loss:  3.302739423816092e-05
Valid Loss:  4.517567140283063e-05
Epoch:  309  	Training Loss: 5.0323185860179365e-05
Test Loss:  3.298871888546273e-05
Valid Loss:  4.50903462478891e-05
Epoch:  310  	Training Loss: 5.019033051212318e-05
Test Loss:  3.299834133940749e-05
Valid Loss:  4.506629556999542e-05
Epoch:  311  	Training Loss: 5.006474384572357e-05
Test Loss:  3.293794725323096e-05
Valid Loss:  4.496296605793759e-05
Epoch:  312  	Training Loss: 4.993874244973995e-05
Test Loss:  3.261100209783763e-05
Valid Loss:  4.462732977117412e-05
Epoch:  313  	Training Loss: 4.977349453838542e-05
Test Loss:  3.238338103983551e-05
Valid Loss:  4.443900616024621e-05
Epoch:  314  	Training Loss: 4.9619880883255973e-05
Test Loss:  3.217136691091582e-05
Valid Loss:  4.426043597050011e-05
Epoch:  315  	Training Loss: 4.9475798732601106e-05
Test Loss:  3.1975221645552665e-05
Valid Loss:  4.409499160829e-05
Epoch:  316  	Training Loss: 4.933976742904633e-05
Test Loss:  3.179313716827892e-05
Valid Loss:  4.394090501591563e-05
Epoch:  317  	Training Loss: 4.920870560454205e-05
Test Loss:  3.1620140362065285e-05
Valid Loss:  4.379369784146547e-05
Epoch:  318  	Training Loss: 4.90797683596611e-05
Test Loss:  3.14580429403577e-05
Valid Loss:  4.365423956187442e-05
Epoch:  319  	Training Loss: 4.8956600949168205e-05
Test Loss:  3.1308114557759836e-05
Valid Loss:  4.3523461499717087e-05
Epoch:  320  	Training Loss: 4.883811197942123e-05
Test Loss:  3.116756124654785e-05
Valid Loss:  4.3400388676673174e-05
Epoch:  321  	Training Loss: 4.872391582466662e-05
Test Loss:  3.1036095606395975e-05
Valid Loss:  4.328262002673e-05
Epoch:  322  	Training Loss: 4.8613379476591945e-05
Test Loss:  3.099953755736351e-05
Valid Loss:  4.328254362917505e-05
Epoch:  323  	Training Loss: 4.850011464441195e-05
Test Loss:  3.094492421951145e-05
Valid Loss:  4.3245927372481674e-05
Epoch:  324  	Training Loss: 4.839590474148281e-05
Test Loss:  3.087987715844065e-05
Valid Loss:  4.318989522289485e-05
Epoch:  325  	Training Loss: 4.829462704947218e-05
Test Loss:  3.081235627178103e-05
Valid Loss:  4.312519376981072e-05
Epoch:  326  	Training Loss: 4.81949609820731e-05
Test Loss:  3.0742932722205296e-05
Valid Loss:  4.305649781599641e-05
Epoch:  327  	Training Loss: 4.809566598851234e-05
Test Loss:  3.06752699543722e-05
Valid Loss:  4.298684871173464e-05
Epoch:  328  	Training Loss: 4.7998022637329996e-05
Test Loss:  3.060973176616244e-05
Valid Loss:  4.291863297112286e-05
Epoch:  329  	Training Loss: 4.790146340383217e-05
Test Loss:  3.054549597436562e-05
Valid Loss:  4.285117393010296e-05
Epoch:  330  	Training Loss: 4.780593735631555e-05
Test Loss:  3.04843870253535e-05
Valid Loss:  4.2784955439856276e-05
Epoch:  331  	Training Loss: 4.771120075020008e-05
Test Loss:  3.0424846045207232e-05
Valid Loss:  4.271973739378154e-05
Epoch:  332  	Training Loss: 4.761727177537978e-05
Test Loss:  3.0486180548905395e-05
Valid Loss:  4.267877375241369e-05
Epoch:  333  	Training Loss: 4.743514728033915e-05
Test Loss:  3.052120882784948e-05
Valid Loss:  4.26232727477327e-05
Epoch:  334  	Training Loss: 4.726279075839557e-05
Test Loss:  3.053652835660614e-05
Valid Loss:  4.255998646840453e-05
Epoch:  335  	Training Loss: 4.709780478151515e-05
Test Loss:  3.053502587135881e-05
Valid Loss:  4.2487416067160666e-05
Epoch:  336  	Training Loss: 4.693845403380692e-05
Test Loss:  3.05209141515661e-05
Valid Loss:  4.240930138621479e-05
Epoch:  337  	Training Loss: 4.6783599827904254e-05
Test Loss:  3.0496110412059352e-05
Valid Loss:  4.2325526010245085e-05
Epoch:  338  	Training Loss: 4.6632125304313377e-05
Test Loss:  3.0462306312983856e-05
Valid Loss:  4.2238487367285416e-05
Epoch:  339  	Training Loss: 4.6484419726766646e-05
Test Loss:  3.0421393603319302e-05
Valid Loss:  4.214738146401942e-05
Epoch:  340  	Training Loss: 4.633890057448298e-05
Test Loss:  3.037473652511835e-05
Valid Loss:  4.205401273793541e-05
Epoch:  341  	Training Loss: 4.6195800678106025e-05
Test Loss:  3.0323866667458788e-05
 68%|██████▊   | 342/500 [04:05<03:06,  1.18s/it] 69%|██████▉   | 344/500 [04:05<02:11,  1.18it/s] 69%|██████▉   | 346/500 [04:05<01:35,  1.61it/s] 70%|██████▉   | 348/500 [04:06<01:08,  2.20it/s] 70%|███████   | 350/500 [04:06<00:50,  2.96it/s] 70%|███████   | 352/500 [04:12<02:57,  1.20s/it] 71%|███████   | 354/500 [04:12<02:05,  1.16it/s] 71%|███████   | 356/500 [04:12<01:29,  1.61it/s] 72%|███████▏  | 358/500 [04:13<01:04,  2.20it/s] 72%|███████▏  | 360/500 [04:13<00:47,  2.95it/s] 72%|███████▏  | 362/500 [04:19<02:46,  1.20s/it] 73%|███████▎  | 364/500 [04:19<01:57,  1.16it/s] 73%|███████▎  | 366/500 [04:19<01:23,  1.60it/s] 74%|███████▎  | 368/500 [04:20<01:00,  2.18it/s] 74%|███████▍  | 370/500 [04:20<00:44,  2.94it/s] 74%|███████▍  | 372/500 [04:26<02:30,  1.18s/it] 75%|███████▍  | 374/500 [04:26<01:46,  1.18it/s] 75%|███████▌  | 376/500 [04:26<01:15,  1.63it/s] 76%|███████▌  | 378/500 [04:26<00:54,  2.23it/s] 76%|███████▌  | 380/500 [04:26<00:40,  3.00it/s] 76%|███████▋  | 382/500 [04:33<02:18,  1.18s/it] 77%|███████▋  | 384/500 [04:33<01:37,  1.19it/s] 77%|███████▋  | 386/500 [04:33<01:09,  1.64it/s] 78%|███████▊  | 388/500 [04:33<00:49,  2.24it/s] 78%|███████▊  | 390/500 [04:33<00:36,  3.01it/s] 78%|███████▊  | 392/500 [04:40<02:06,  1.17s/it] 79%|███████▉  | 394/500 [04:40<01:29,  1.19it/s] 79%|███████▉  | 396/500 [04:40<01:03,  1.64it/s] 80%|███████▉  | 398/500 [04:40<00:45,  2.25it/s] 80%|████████  | 400/500 [04:40<00:33,  3.02it/s] 80%|████████  | 402/500 [04:46<01:55,  1.18s/it] 81%|████████  | 404/500 [04:47<01:21,  1.19it/s] 81%|████████  | 406/500 [04:47<00:57,  1.63it/s] 82%|████████▏ | 408/500 [04:47<00:41,  2.23it/s]Valid Loss:  4.1959436202887446e-05
Epoch:  342  	Training Loss: 4.605500726029277e-05
Test Loss:  3.042247953999322e-05
Valid Loss:  4.199439354124479e-05
Epoch:  343  	Training Loss: 4.595745849655941e-05
Test Loss:  3.0476319807348773e-05
Valid Loss:  4.1987332224380225e-05
Epoch:  344  	Training Loss: 4.5865825086366385e-05
Test Loss:  3.0513954698108137e-05
Valid Loss:  4.1970670281443745e-05
Epoch:  345  	Training Loss: 4.5777738705510274e-05
Test Loss:  3.054197441088036e-05
Valid Loss:  4.19493080698885e-05
Epoch:  346  	Training Loss: 4.569316661218181e-05
Test Loss:  3.0561539460904896e-05
Valid Loss:  4.192374035483226e-05
Epoch:  347  	Training Loss: 4.56107227364555e-05
Test Loss:  3.0574588890885934e-05
Valid Loss:  4.189432365819812e-05
Epoch:  348  	Training Loss: 4.553057442535646e-05
Test Loss:  3.058163929381408e-05
Valid Loss:  4.186385194770992e-05
Epoch:  349  	Training Loss: 4.545203410089016e-05
Test Loss:  3.05837020277977e-05
Valid Loss:  4.182980046607554e-05
Epoch:  350  	Training Loss: 4.5374996261671185e-05
Test Loss:  3.0580718885175884e-05
Valid Loss:  4.1793904529185966e-05
Epoch:  351  	Training Loss: 4.5299406338017434e-05
Test Loss:  3.057425783481449e-05
Valid Loss:  4.175634967396036e-05
Epoch:  352  	Training Loss: 4.522511881077662e-05
Test Loss:  3.054793342016637e-05
Valid Loss:  4.164145502727479e-05
Epoch:  353  	Training Loss: 4.517408160609193e-05
Test Loss:  3.067924262722954e-05
Valid Loss:  4.1713359678396955e-05
Epoch:  354  	Training Loss: 4.5137199776945636e-05
Test Loss:  3.078698864555918e-05
Valid Loss:  4.176640504738316e-05
Epoch:  355  	Training Loss: 4.5107379264663905e-05
Test Loss:  3.088797893724404e-05
Valid Loss:  4.1818559111561626e-05
Epoch:  356  	Training Loss: 4.508237907430157e-05
Test Loss:  3.098097658948973e-05
Valid Loss:  4.1867231630021706e-05
Epoch:  357  	Training Loss: 4.506228651735e-05
Test Loss:  3.106710209976882e-05
Valid Loss:  4.191407060716301e-05
Epoch:  358  	Training Loss: 4.504564276430756e-05
Test Loss:  3.114592982456088e-05
Valid Loss:  4.1957722714869305e-05
Epoch:  359  	Training Loss: 4.503189484239556e-05
Test Loss:  3.1218340154737234e-05
Valid Loss:  4.1998540837084875e-05
Epoch:  360  	Training Loss: 4.502066076383926e-05
Test Loss:  3.12852680508513e-05
Valid Loss:  4.2037019738927484e-05
Epoch:  361  	Training Loss: 4.5011460315436125e-05
Test Loss:  3.134618600597605e-05
Valid Loss:  4.2071642383234575e-05
Epoch:  362  	Training Loss: 4.500381328398362e-05
Test Loss:  3.1275769288185984e-05
Valid Loss:  4.204879223834723e-05
Epoch:  363  	Training Loss: 4.491310392040759e-05
Test Loss:  3.1172457966022193e-05
Valid Loss:  4.1977975342888385e-05
Epoch:  364  	Training Loss: 4.4838874600827694e-05
Test Loss:  3.105980431428179e-05
Valid Loss:  4.1889012209139764e-05
Epoch:  365  	Training Loss: 4.477098991628736e-05
Test Loss:  3.094866769970395e-05
Valid Loss:  4.179656389169395e-05
Epoch:  366  	Training Loss: 4.470638668863103e-05
Test Loss:  3.084322815993801e-05
Valid Loss:  4.1706043703015894e-05
Epoch:  367  	Training Loss: 4.464494850253686e-05
Test Loss:  3.0746436095796525e-05
Valid Loss:  4.162037294008769e-05
Epoch:  368  	Training Loss: 4.458606417756528e-05
Test Loss:  3.065785494982265e-05
Valid Loss:  4.153892950853333e-05
Epoch:  369  	Training Loss: 4.4528787839226425e-05
Test Loss:  3.057732465094887e-05
Valid Loss:  4.1462641092948616e-05
Epoch:  370  	Training Loss: 4.447329047252424e-05
Test Loss:  3.0503457310260274e-05
Valid Loss:  4.1391391278011724e-05
Epoch:  371  	Training Loss: 4.441858982318081e-05
Test Loss:  3.043516699108295e-05
Valid Loss:  4.1324343328597024e-05
Epoch:  372  	Training Loss: 4.4365093344822526e-05
Test Loss:  3.0203347705537453e-05
Valid Loss:  4.1038423660211265e-05
Epoch:  373  	Training Loss: 4.428686952451244e-05
Test Loss:  3.017209019162692e-05
Valid Loss:  4.100390651728958e-05
Epoch:  374  	Training Loss: 4.421948688104749e-05
Test Loss:  3.0110739317024127e-05
Valid Loss:  4.092859671800397e-05
Epoch:  375  	Training Loss: 4.4153868657303974e-05
Test Loss:  3.005939652211964e-05
Valid Loss:  4.086377884959802e-05
Epoch:  376  	Training Loss: 4.408942913869396e-05
Test Loss:  3.0010556656634435e-05
Valid Loss:  4.080076178070158e-05
Epoch:  377  	Training Loss: 4.4026011892128736e-05
Test Loss:  2.9964710847707465e-05
Valid Loss:  4.074002936249599e-05
Epoch:  378  	Training Loss: 4.39636642113328e-05
Test Loss:  2.9920091037638485e-05
Valid Loss:  4.0680253732716665e-05
Epoch:  379  	Training Loss: 4.3900457967538387e-05
Test Loss:  2.9876184271415696e-05
Valid Loss:  4.062070365762338e-05
Epoch:  380  	Training Loss: 4.383851774036884e-05
Test Loss:  2.9835484383511357e-05
Valid Loss:  4.056297620991245e-05
Epoch:  381  	Training Loss: 4.3777232349384576e-05
Test Loss:  2.979642158607021e-05
Valid Loss:  4.050743154948577e-05
Epoch:  382  	Training Loss: 4.371720933704637e-05
Test Loss:  2.946420863736421e-05
Valid Loss:  4.0375372918788344e-05
Epoch:  383  	Training Loss: 4.3420463043730706e-05
Test Loss:  2.906982263084501e-05
Valid Loss:  4.007285679108463e-05
Epoch:  384  	Training Loss: 4.320007064961828e-05
Test Loss:  2.873933408409357e-05
Valid Loss:  3.981253757956438e-05
Epoch:  385  	Training Loss: 4.299225111026317e-05
Test Loss:  2.8459653549361974e-05
Valid Loss:  3.958841261919588e-05
Epoch:  386  	Training Loss: 4.279675704310648e-05
Test Loss:  2.8219918021932244e-05
Valid Loss:  3.9391899917973205e-05
Epoch:  387  	Training Loss: 4.2608680814737454e-05
Test Loss:  2.800689617288299e-05
Valid Loss:  3.921480310964398e-05
Epoch:  388  	Training Loss: 4.2423456761753187e-05
Test Loss:  2.7819585739052854e-05
Valid Loss:  3.9053506043273956e-05
Epoch:  389  	Training Loss: 4.224477015668526e-05
Test Loss:  2.7652504286379553e-05
Valid Loss:  3.8906538975425065e-05
Epoch:  390  	Training Loss: 4.2068317270604894e-05
Test Loss:  2.7496484108269215e-05
Valid Loss:  3.876865957863629e-05
Epoch:  391  	Training Loss: 4.1891726141329855e-05
Test Loss:  2.7354279154678807e-05
Valid Loss:  3.863765959977172e-05
Epoch:  392  	Training Loss: 4.171954788034782e-05
Test Loss:  2.7143589250044897e-05
Valid Loss:  3.835022289422341e-05
Epoch:  393  	Training Loss: 4.150917811784893e-05
Test Loss:  2.7141551981912926e-05
Valid Loss:  3.83082042390015e-05
Epoch:  394  	Training Loss: 4.131091191084124e-05
Test Loss:  2.7083384338766336e-05
Valid Loss:  3.820980782620609e-05
Epoch:  395  	Training Loss: 4.111645102966577e-05
Test Loss:  2.7022351787309162e-05
Valid Loss:  3.811720307567157e-05
Epoch:  396  	Training Loss: 4.092494782526046e-05
Test Loss:  2.695314287848305e-05
Valid Loss:  3.801955608651042e-05
Epoch:  397  	Training Loss: 4.073657692060806e-05
Test Loss:  2.6877201889874414e-05
Valid Loss:  3.7921290640952066e-05
Epoch:  398  	Training Loss: 4.0552178688813e-05
Test Loss:  2.6749283279059455e-05
Valid Loss:  3.776681478484534e-05
Epoch:  399  	Training Loss: 4.0369555790675804e-05
Test Loss:  2.6710818929132074e-05
Valid Loss:  3.7709702155552804e-05
Epoch:  400  	Training Loss: 4.018586332676932e-05
Test Loss:  2.661394319147803e-05
Valid Loss:  3.759410901693627e-05
Epoch:  401  	Training Loss: 4.0005041228141636e-05
Test Loss:  2.6478670406504534e-05
Valid Loss:  3.743792331079021e-05
Epoch:  402  	Training Loss: 3.9826376450946555e-05
Test Loss:  2.6428464479977265e-05
Valid Loss:  3.73910297639668e-05
Epoch:  403  	Training Loss: 3.9719685446470976e-05
Test Loss:  2.6382465875940397e-05
Valid Loss:  3.73487091565039e-05
Epoch:  404  	Training Loss: 3.961535912822001e-05
Test Loss:  2.6339188480051234e-05
Valid Loss:  3.730857133632526e-05
Epoch:  405  	Training Loss: 3.951308463001624e-05
Test Loss:  2.6297671865904704e-05
Valid Loss:  3.727120201801881e-05
Epoch:  406  	Training Loss: 3.941317118005827e-05
Test Loss:  2.625818524393253e-05
Valid Loss:  3.723460395121947e-05
Epoch:  407  	Training Loss: 3.931536411982961e-05
Test Loss:  2.6220130166620947e-05
Valid Loss:  3.719942469615489e-05
Epoch:  408  	Training Loss: 3.9219587051775306e-05
Test Loss:  2.6184185117017478e-05
Valid Loss:  3.716657010954805e-05
 82%|████████▏ | 410/500 [04:47<00:30,  3.00it/s] 82%|████████▏ | 412/500 [04:53<01:42,  1.16s/it] 83%|████████▎ | 414/500 [04:53<01:11,  1.20it/s] 83%|████████▎ | 416/500 [04:53<00:50,  1.66it/s] 84%|████████▎ | 418/500 [04:53<00:36,  2.27it/s] 84%|████████▍ | 420/500 [04:54<00:26,  3.04it/s] 84%|████████▍ | 422/500 [05:00<01:32,  1.19s/it] 85%|████████▍ | 424/500 [05:00<01:04,  1.17it/s] 85%|████████▌ | 426/500 [05:00<00:45,  1.62it/s] 86%|████████▌ | 428/500 [05:00<00:32,  2.22it/s] 86%|████████▌ | 430/500 [05:01<00:23,  2.98it/s] 86%|████████▋ | 432/500 [05:07<01:19,  1.17s/it] 87%|████████▋ | 434/500 [05:07<00:55,  1.19it/s] 87%|████████▋ | 436/500 [05:07<00:38,  1.65it/s] 88%|████████▊ | 438/500 [05:07<00:27,  2.25it/s] 88%|████████▊ | 440/500 [05:07<00:19,  3.02it/s] 88%|████████▊ | 442/500 [05:14<01:07,  1.17s/it] 89%|████████▉ | 444/500 [05:14<00:46,  1.19it/s] 89%|████████▉ | 446/500 [05:14<00:32,  1.65it/s] 90%|████████▉ | 448/500 [05:14<00:23,  2.26it/s] 90%|█████████ | 450/500 [05:14<00:16,  3.03it/s] 90%|█████████ | 452/500 [05:20<00:56,  1.17s/it] 91%|█████████ | 454/500 [05:20<00:38,  1.19it/s] 91%|█████████ | 456/500 [05:21<00:26,  1.65it/s] 92%|█████████▏| 458/500 [05:21<00:18,  2.25it/s] 92%|█████████▏| 460/500 [05:21<00:13,  3.03it/s] 92%|█████████▏| 462/500 [05:27<00:44,  1.16s/it] 93%|█████████▎| 464/500 [05:27<00:30,  1.20it/s] 93%|█████████▎| 466/500 [05:27<00:20,  1.65it/s] 94%|█████████▎| 468/500 [05:27<00:14,  2.26it/s] 94%|█████████▍| 470/500 [05:28<00:09,  3.04it/s] 94%|█████████▍| 472/500 [05:34<00:32,  1.18s/it] 95%|█████████▍| 474/500 [05:34<00:21,  1.19it/s]Epoch:  409  	Training Loss: 3.912566171493381e-05
Test Loss:  2.614855839055963e-05
Valid Loss:  3.71345849998761e-05
Epoch:  410  	Training Loss: 3.903386095771566e-05
Test Loss:  2.6115549189853482e-05
Valid Loss:  3.710353121277876e-05
Epoch:  411  	Training Loss: 3.894373367074877e-05
Test Loss:  2.6083518605446443e-05
Valid Loss:  3.7074543797643855e-05
Epoch:  412  	Training Loss: 3.885554178850725e-05
Test Loss:  2.6130588594242e-05
Valid Loss:  3.712099714903161e-05
Epoch:  413  	Training Loss: 3.8770314858993515e-05
Test Loss:  2.612364914966747e-05
Valid Loss:  3.7109643017174676e-05
Epoch:  414  	Training Loss: 3.869495412800461e-05
Test Loss:  2.6093754058820195e-05
Valid Loss:  3.707212090375833e-05
Epoch:  415  	Training Loss: 3.862201265292242e-05
Test Loss:  2.605497866170481e-05
Valid Loss:  3.7024819903308526e-05
Epoch:  416  	Training Loss: 3.855082468362525e-05
Test Loss:  2.601515006972477e-05
Valid Loss:  3.6975485272705555e-05
Epoch:  417  	Training Loss: 3.848195046884939e-05
Test Loss:  2.5975488824769855e-05
Valid Loss:  3.692587051773444e-05
Epoch:  418  	Training Loss: 3.84140366804786e-05
Test Loss:  2.593625322333537e-05
Valid Loss:  3.687640855787322e-05
Epoch:  419  	Training Loss: 3.8347036024788395e-05
Test Loss:  2.5898170861182734e-05
Valid Loss:  3.6827870644629e-05
Epoch:  420  	Training Loss: 3.8281061279121786e-05
Test Loss:  2.586044320196379e-05
Valid Loss:  3.67795983038377e-05
Epoch:  421  	Training Loss: 3.821683276328258e-05
Test Loss:  2.5827459467109293e-05
Valid Loss:  3.673428000183776e-05
Epoch:  422  	Training Loss: 3.8154110370669514e-05
Test Loss:  2.563011003076099e-05
Valid Loss:  3.650037251645699e-05
Epoch:  423  	Training Loss: 3.804267180385068e-05
Test Loss:  2.5623039618949406e-05
Valid Loss:  3.648706478998065e-05
Epoch:  424  	Training Loss: 3.7947760574752465e-05
Test Loss:  2.5608751457184553e-05
Valid Loss:  3.646645200205967e-05
Epoch:  425  	Training Loss: 3.785434819292277e-05
Test Loss:  2.559086715336889e-05
Valid Loss:  3.6445140722207725e-05
Epoch:  426  	Training Loss: 3.775815275730565e-05
Test Loss:  2.5571278456482105e-05
Valid Loss:  3.6422225093701854e-05
Epoch:  427  	Training Loss: 3.766377267311327e-05
Test Loss:  2.5552155420882627e-05
Valid Loss:  3.640079012257047e-05
Epoch:  428  	Training Loss: 3.757168451556936e-05
Test Loss:  2.5533609004924074e-05
Valid Loss:  3.6379380617290735e-05
Epoch:  429  	Training Loss: 3.748122981050983e-05
Test Loss:  2.5514615117572248e-05
Valid Loss:  3.635917164501734e-05
Epoch:  430  	Training Loss: 3.7392812373582274e-05
Test Loss:  2.5493740395177156e-05
Valid Loss:  3.633926826296374e-05
Epoch:  431  	Training Loss: 3.730586468009278e-05
Test Loss:  2.5466499209869653e-05
Valid Loss:  3.632032166933641e-05
Epoch:  432  	Training Loss: 3.7220837839413434e-05
Test Loss:  2.5430554160266183e-05
Valid Loss:  3.626263787737116e-05
Epoch:  433  	Training Loss: 3.71509522665292e-05
Test Loss:  2.540362038416788e-05
Valid Loss:  3.621519135776907e-05
Epoch:  434  	Training Loss: 3.7081823393236846e-05
Test Loss:  2.5379271392012015e-05
Valid Loss:  3.617141192080453e-05
Epoch:  435  	Training Loss: 3.7013072869740427e-05
Test Loss:  2.53546404564986e-05
Valid Loss:  3.612909495132044e-05
Epoch:  436  	Training Loss: 3.6945464671589434e-05
Test Loss:  2.533074439270422e-05
Valid Loss:  3.608801489463076e-05
Epoch:  437  	Training Loss: 3.687922435346991e-05
Test Loss:  2.530963502067607e-05
Valid Loss:  3.605141682783142e-05
Epoch:  438  	Training Loss: 3.681562520796433e-05
Test Loss:  2.5292392820119858e-05
Valid Loss:  3.60184239980299e-05
Epoch:  439  	Training Loss: 3.675556217785925e-05
Test Loss:  2.5284234652644955e-05
Valid Loss:  3.599194678827189e-05
Epoch:  440  	Training Loss: 3.669920261017978e-05
Test Loss:  2.5272056518588215e-05
Valid Loss:  3.5961580579169095e-05
Epoch:  441  	Training Loss: 3.664413088699803e-05
Test Loss:  2.5261484552174807e-05
Valid Loss:  3.5933273466071114e-05
Epoch:  442  	Training Loss: 3.659075446194038e-05
Test Loss:  2.5142326194327325e-05
Valid Loss:  3.582808858482167e-05
Epoch:  443  	Training Loss: 3.650887811090797e-05
Test Loss:  2.503157520550303e-05
Valid Loss:  3.572644345695153e-05
Epoch:  444  	Training Loss: 3.6443929275264964e-05
Test Loss:  2.4929731807787903e-05
Valid Loss:  3.563017526175827e-05
Epoch:  445  	Training Loss: 3.638543785200454e-05
Test Loss:  2.4832675990182906e-05
Valid Loss:  3.553590067895129e-05
Epoch:  446  	Training Loss: 3.63299623131752e-05
Test Loss:  2.4744600523263216e-05
Valid Loss:  3.5448872949928045e-05
Epoch:  447  	Training Loss: 3.6277844628784806e-05
Test Loss:  2.4665409000590444e-05
Valid Loss:  3.536578151397407e-05
Epoch:  448  	Training Loss: 3.622897929744795e-05
Test Loss:  2.459917959640734e-05
Valid Loss:  3.5293774999445304e-05
Epoch:  449  	Training Loss: 3.6183751944918185e-05
Test Loss:  2.453630804666318e-05
Valid Loss:  3.522457700455561e-05
Epoch:  450  	Training Loss: 3.6139506846666336e-05
Test Loss:  2.4477281840518117e-05
Valid Loss:  3.5158576793037355e-05
Epoch:  451  	Training Loss: 3.609608393162489e-05
Test Loss:  2.442180266370997e-05
Valid Loss:  3.5096032661385834e-05
Epoch:  452  	Training Loss: 3.6053534131497145e-05
Test Loss:  2.4287521227961406e-05
Valid Loss:  3.498660589684732e-05
Epoch:  453  	Training Loss: 3.59600962838158e-05
Test Loss:  2.4167742594727315e-05
Valid Loss:  3.489121445454657e-05
Epoch:  454  	Training Loss: 3.586964885471389e-05
Test Loss:  2.4057721020653844e-05
Valid Loss:  3.480318991933018e-05
Epoch:  455  	Training Loss: 3.57822427758947e-05
Test Loss:  2.3955897631822154e-05
Valid Loss:  3.472138996585272e-05
Epoch:  456  	Training Loss: 3.569736873032525e-05
Test Loss:  2.3860327928559855e-05
Valid Loss:  3.464518522378057e-05
Epoch:  457  	Training Loss: 3.5614517400972545e-05
Test Loss:  2.377111741225235e-05
Valid Loss:  3.457292768871412e-05
Epoch:  458  	Training Loss: 3.5533834306988865e-05
Test Loss:  2.3687880457146093e-05
Valid Loss:  3.4504955692682415e-05
Epoch:  459  	Training Loss: 3.5454941098578274e-05
Test Loss:  2.3609445634065196e-05
Valid Loss:  3.444056346779689e-05
Epoch:  460  	Training Loss: 3.5377244785195217e-05
Test Loss:  2.3535114451078698e-05
Valid Loss:  3.437995110289194e-05
Epoch:  461  	Training Loss: 3.530133835738525e-05
Test Loss:  2.346517976548057e-05
Valid Loss:  3.4321612474741414e-05
Epoch:  462  	Training Loss: 3.5225712053943425e-05
Test Loss:  2.339307866350282e-05
Valid Loss:  3.423589441808872e-05
Epoch:  463  	Training Loss: 3.51611633959692e-05
Test Loss:  2.3352837160928175e-05
Valid Loss:  3.418333290028386e-05
Epoch:  464  	Training Loss: 3.510002716211602e-05
Test Loss:  2.332030089746695e-05
Valid Loss:  3.413556987652555e-05
Epoch:  465  	Training Loss: 3.503960033413023e-05
Test Loss:  2.3288186639547348e-05
Valid Loss:  3.4087956009898335e-05
Epoch:  466  	Training Loss: 3.498010482871905e-05
Test Loss:  2.3257025532075204e-05
Valid Loss:  3.4041710023302585e-05
Epoch:  467  	Training Loss: 3.492108953651041e-05
Test Loss:  2.3226304620038718e-05
Valid Loss:  3.39958060067147e-05
Epoch:  468  	Training Loss: 3.486290734144859e-05
Test Loss:  2.320024032087531e-05
Valid Loss:  3.395556632312946e-05
Epoch:  469  	Training Loss: 3.480592567939311e-05
Test Loss:  2.3173768568085507e-05
Valid Loss:  3.3916607208084315e-05
Epoch:  470  	Training Loss: 3.474932600511238e-05
Test Loss:  2.3147620595409535e-05
Valid Loss:  3.3877327950904146e-05
Epoch:  471  	Training Loss: 3.4693428460741416e-05
Test Loss:  2.312256401637569e-05
Valid Loss:  3.383910734555684e-05
Epoch:  472  	Training Loss: 3.463848406681791e-05
Test Loss:  2.3277067157323472e-05
Valid Loss:  3.3956137485802174e-05
Epoch:  473  	Training Loss: 3.4584838431328535e-05
Test Loss:  2.337943806196563e-05
Valid Loss:  3.4025048080366105e-05
Epoch:  474  	Training Loss: 3.4541106288088486e-05
Test Loss:  2.345983375562355e-05
Valid Loss:  3.407495023566298e-05
Epoch:  475  	Training Loss: 3.4503180359024554e-05
Test Loss:  2.352994488319382e-05
Valid Loss:  3.41176419169642e-05
Epoch:  476  	Training Loss: 3.446984555921517e-05
Test Loss:   95%|█████████▌| 476/500 [05:34<00:14,  1.64it/s] 96%|█████████▌| 478/500 [05:34<00:09,  2.24it/s] 96%|█████████▌| 480/500 [05:34<00:06,  3.01it/s] 96%|█████████▋| 482/500 [05:41<00:20,  1.17s/it] 97%|█████████▋| 484/500 [05:41<00:13,  1.20it/s] 97%|█████████▋| 486/500 [05:41<00:08,  1.65it/s] 98%|█████████▊| 488/500 [05:41<00:05,  2.26it/s] 98%|█████████▊| 490/500 [05:41<00:03,  3.03it/s] 98%|█████████▊| 492/500 [05:48<00:09,  1.18s/it] 99%|█████████▉| 494/500 [05:48<00:05,  1.18it/s] 99%|█████████▉| 496/500 [05:48<00:02,  1.63it/s]100%|█████████▉| 498/500 [05:48<00:00,  2.22it/s]100%|██████████| 500/500 [05:48<00:00,  2.98it/s]100%|██████████| 500/500 [05:48<00:00,  1.43it/s]
2.3594970116391778e-05
Valid Loss:  3.41570375894662e-05
Epoch:  477  	Training Loss: 3.444038156885654e-05
Test Loss:  2.3656019038753584e-05
Valid Loss:  3.419471249799244e-05
Epoch:  478  	Training Loss: 3.441438457230106e-05
Test Loss:  2.3713744667475112e-05
Valid Loss:  3.4230808523716405e-05
Epoch:  479  	Training Loss: 3.439137799432501e-05
Test Loss:  2.3768709070282057e-05
Valid Loss:  3.426585317356512e-05
Epoch:  480  	Training Loss: 3.437120176386088e-05
Test Loss:  2.3821125068934634e-05
Valid Loss:  3.429961725487374e-05
Epoch:  481  	Training Loss: 3.435316466493532e-05
Test Loss:  2.387045242357999e-05
Valid Loss:  3.433217716519721e-05
Epoch:  482  	Training Loss: 3.433728852542117e-05
Test Loss:  2.377612327109091e-05
Valid Loss:  3.426072362344712e-05
Epoch:  483  	Training Loss: 3.423062298679724e-05
Test Loss:  2.3654389224248007e-05
Valid Loss:  3.4156844776589423e-05
Epoch:  484  	Training Loss: 3.412891237530857e-05
Test Loss:  2.354193384235259e-05
Valid Loss:  3.405874304007739e-05
Epoch:  485  	Training Loss: 3.402846778044477e-05
Test Loss:  2.343547203054186e-05
Valid Loss:  3.3966418413911015e-05
Epoch:  486  	Training Loss: 3.392701910343021e-05
Test Loss:  2.333715747226961e-05
Valid Loss:  3.3879816328408197e-05
Epoch:  487  	Training Loss: 3.3828193409135565e-05
Test Loss:  2.3247155695571564e-05
Valid Loss:  3.37996389134787e-05
Epoch:  488  	Training Loss: 3.3730622817529365e-05
Test Loss:  2.3163556761574e-05
Valid Loss:  3.3724405511748046e-05
Epoch:  489  	Training Loss: 3.3633979910518974e-05
Test Loss:  2.3084321583155543e-05
Valid Loss:  3.365195152582601e-05
Epoch:  490  	Training Loss: 3.353939246153459e-05
Test Loss:  2.3005803086562082e-05
Valid Loss:  3.358339017722756e-05
Epoch:  491  	Training Loss: 3.344603828736581e-05
Test Loss:  2.2929390979697928e-05
Valid Loss:  3.351534542161971e-05
Epoch:  492  	Training Loss: 3.335407382110134e-05
Test Loss:  2.286206290591508e-05
Valid Loss:  3.3451011404395103e-05
Epoch:  493  	Training Loss: 3.3247139072045684e-05
Test Loss:  2.2785516193835065e-05
Valid Loss:  3.337663656566292e-05
Epoch:  494  	Training Loss: 3.3142398024210706e-05
Test Loss:  2.2715099476044998e-05
Valid Loss:  3.3306256227660924e-05
Epoch:  495  	Training Loss: 3.303935955045745e-05
Test Loss:  2.264843715238385e-05
Valid Loss:  3.323962300783023e-05
Epoch:  496  	Training Loss: 3.293807458248921e-05
Test Loss:  2.2585487386095338e-05
Valid Loss:  3.3171658287756145e-05
Epoch:  497  	Training Loss: 3.2838357583386824e-05
Test Loss:  2.2525491658598185e-05
Valid Loss:  3.310371903353371e-05
Epoch:  498  	Training Loss: 3.2740397728048265e-05
Test Loss:  2.246909571113065e-05
Valid Loss:  3.303736593807116e-05
Epoch:  499  	Training Loss: 3.264373663114384e-05
Test Loss:  2.2416610590880737e-05
Valid Loss:  3.297268631285988e-05
Epoch:  500  	Training Loss: 3.254852708778344e-05
Test Loss:  2.2367814381141216e-05
Valid Loss:  3.2910120353335515e-05
seed is  19
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:30, 16.30it/s]  1%|          | 4/500 [00:00<00:30, 16.49it/s]  1%|          | 6/500 [00:00<00:30, 16.35it/s]  2%|▏         | 8/500 [00:00<00:30, 16.23it/s]  2%|▏         | 10/500 [00:00<00:30, 16.32it/s]  2%|▏         | 12/500 [00:00<00:29, 16.43it/s]  3%|▎         | 14/500 [00:00<00:29, 16.34it/s]  3%|▎         | 16/500 [00:00<00:29, 16.38it/s]  4%|▎         | 18/500 [00:01<00:29, 16.34it/s]  4%|▍         | 20/500 [00:01<00:29, 16.43it/s]  4%|▍         | 22/500 [00:01<00:29, 16.46it/s]  5%|▍         | 24/500 [00:01<00:28, 16.52it/s]  5%|▌         | 26/500 [00:01<00:28, 16.45it/s]  6%|▌         | 28/500 [00:01<00:28, 16.37it/s]  6%|▌         | 30/500 [00:01<00:28, 16.25it/s]  6%|▋         | 32/500 [00:01<00:28, 16.16it/s]  7%|▋         | 34/500 [00:02<00:28, 16.32it/s]  7%|▋         | 36/500 [00:02<00:28, 16.44it/s]  8%|▊         | 38/500 [00:02<00:28, 16.50it/s]  8%|▊         | 40/500 [00:02<00:27, 16.51it/s]  8%|▊         | 42/500 [00:02<00:27, 16.52it/s]  9%|▉         | 44/500 [00:02<00:27, 16.50it/s]  9%|▉         | 46/500 [00:02<00:27, 16.27it/s] 10%|▉         | 48/500 [00:02<00:27, 16.23it/s] 10%|█         | 50/500 [00:03<00:27, 16.21it/s] 10%|█         | 52/500 [00:03<00:27, 16.10it/s] 11%|█         | 54/500 [00:03<00:27, 16.01it/s] 11%|█         | 56/500 [00:03<00:27, 16.18it/s] 12%|█▏        | 58/500 [00:03<00:27, 16.30it/s] 12%|█▏        | 60/500 [00:03<00:26, 16.38it/s] 12%|█▏        | 62/500 [00:03<00:26, 16.47it/s] 13%|█▎        | 64/500 [00:03<00:26, 16.27it/s] 13%|█▎        | 66/500 [00:04<00:26, 16.28it/s] 14%|█▎        | 68/500 [00:04<00:26, 16.19it/s] 14%|█▍        | 70/500 [00:04<00:29, 14.81it/s] 14%|█▍        | 72/500 [00:04<00:29, 14.75it/s] 15%|█▍        | 74/500 [00:04<00:27, 15.27it/s] 15%|█▌        | 76/500 [00:04<00:27, 15.65it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.88it/s] 16%|█▌        | 80/500 [00:04<00:26, 15.96it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.91it/s] 17%|█▋        | 84/500 [00:05<00:25, 16.05it/s] 17%|█▋        | 86/500 [00:05<00:25, 16.06it/s] 18%|█▊        | 88/500 [00:05<00:25, 16.04it/s] 18%|█▊        | 90/500 [00:05<00:25, 16.12it/s] 18%|█▊        | 92/500 [00:05<00:25, 16.19it/s] 19%|█▉        | 94/500 [00:05<00:24, 16.28it/s] 19%|█▉        | 96/500 [00:05<00:24, 16.32it/s] 20%|█▉        | 98/500 [00:06<00:24, 16.42it/s] 20%|██        | 100/500 [00:06<00:24, 16.51it/s] 20%|██        | 102/500 [00:06<00:25, 15.70it/s] 21%|██        | 104/500 [00:06<00:25, 15.35it/s] 21%|██        | 106/500 [00:06<00:25, 15.51it/s] 22%|██▏       | 108/500 [00:06<00:24, 15.80it/s] 22%|██▏       | 110/500 [00:06<00:24, 15.98it/s] 22%|██▏       | 112/500 [00:06<00:24, 16.11it/s] 23%|██▎       | 114/500 [00:07<00:23, 16.10it/s] 23%|██▎       | 116/500 [00:07<00:23, 16.20it/s] 24%|██▎       | 118/500 [00:07<00:23, 16.33it/s] 24%|██▍       | 120/500 [00:07<00:23, 16.21it/s] 24%|██▍       | 122/500 [00:07<00:23, 16.25it/s] 25%|██▍       | 124/500 [00:07<00:23, 16.30it/s]Epoch:  1  	Training Loss: 0.048232775181531906
Test Loss:  1333.1827392578125
Valid Loss:  1333.3017578125
Epoch:  2  	Training Loss: 1335.393310546875
Test Loss:  481662429298688.0
Valid Loss:  477456213475328.0
Epoch:  3  	Training Loss: 478433452752896.0
Test Loss:  inf
Valid Loss:  inf
Epoch:  4  	Training Loss: inf
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:07<00:22, 16.34it/s] 26%|██▌       | 128/500 [00:07<00:22, 16.37it/s] 26%|██▌       | 130/500 [00:08<00:22, 16.34it/s] 26%|██▋       | 132/500 [00:08<00:22, 16.15it/s] 27%|██▋       | 134/500 [00:08<00:22, 16.24it/s] 27%|██▋       | 136/500 [00:08<00:22, 16.07it/s] 28%|██▊       | 138/500 [00:08<00:22, 16.23it/s] 28%|██▊       | 140/500 [00:08<00:22, 16.27it/s] 28%|██▊       | 142/500 [00:08<00:22, 16.18it/s] 29%|██▉       | 144/500 [00:08<00:21, 16.20it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.96it/s] 30%|██▉       | 148/500 [00:09<00:21, 16.04it/s] 30%|███       | 150/500 [00:09<00:21, 16.09it/s] 30%|███       | 152/500 [00:09<00:21, 16.23it/s] 31%|███       | 154/500 [00:09<00:21, 16.39it/s] 31%|███       | 156/500 [00:09<00:20, 16.45it/s] 32%|███▏      | 158/500 [00:09<00:20, 16.41it/s] 32%|███▏      | 160/500 [00:09<00:20, 16.32it/s] 32%|███▏      | 162/500 [00:10<00:20, 16.34it/s] 33%|███▎      | 164/500 [00:10<00:20, 16.40it/s] 33%|███▎      | 166/500 [00:10<00:20, 16.44it/s] 34%|███▎      | 168/500 [00:10<00:20, 16.44it/s] 34%|███▍      | 170/500 [00:10<00:20, 16.46it/s] 34%|███▍      | 172/500 [00:10<00:20, 15.73it/s] 35%|███▍      | 174/500 [00:10<00:20, 15.87it/s] 35%|███▌      | 176/500 [00:10<00:22, 14.64it/s] 36%|███▌      | 178/500 [00:11<00:22, 14.05it/s] 36%|███▌      | 180/500 [00:11<00:21, 14.63it/s] 36%|███▋      | 182/500 [00:11<00:21, 15.08it/s] 37%|███▋      | 184/500 [00:11<00:20, 15.46it/s] 37%|███▋      | 186/500 [00:11<00:21, 14.78it/s] 38%|███▊      | 188/500 [00:11<00:20, 15.27it/s] 38%|███▊      | 190/500 [00:11<00:20, 15.49it/s] 38%|███▊      | 192/500 [00:11<00:19, 15.75it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.94it/s] 39%|███▉      | 196/500 [00:12<00:18, 16.11it/s] 40%|███▉      | 198/500 [00:12<00:18, 16.02it/s] 40%|████      | 200/500 [00:12<00:18, 16.07it/s] 40%|████      | 202/500 [00:12<00:18, 16.17it/s] 41%|████      | 204/500 [00:12<00:18, 16.24it/s] 41%|████      | 206/500 [00:12<00:18, 16.27it/s] 42%|████▏     | 208/500 [00:12<00:17, 16.37it/s] 42%|████▏     | 210/500 [00:13<00:17, 16.42it/s] 42%|████▏     | 212/500 [00:13<00:17, 16.45it/s] 43%|████▎     | 214/500 [00:13<00:17, 16.47it/s] 43%|████▎     | 216/500 [00:13<00:17, 16.52it/s] 44%|████▎     | 218/500 [00:13<00:17, 16.39it/s] 44%|████▍     | 220/500 [00:13<00:17, 16.40it/s] 44%|████▍     | 222/500 [00:13<00:16, 16.49it/s] 45%|████▍     | 224/500 [00:13<00:16, 16.48it/s] 45%|████▌     | 226/500 [00:14<00:16, 16.52it/s] 46%|████▌     | 228/500 [00:14<00:16, 16.55it/s] 46%|████▌     | 230/500 [00:14<00:16, 16.58it/s] 46%|████▋     | 232/500 [00:14<00:17, 15.75it/s] 47%|████▋     | 234/500 [00:14<00:16, 15.93it/s] 47%|████▋     | 236/500 [00:14<00:16, 15.95it/s] 48%|████▊     | 238/500 [00:14<00:16, 16.12it/s] 48%|████▊     | 240/500 [00:14<00:15, 16.28it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.37it/s] 49%|████▉     | 244/500 [00:15<00:15, 16.40it/s] 49%|████▉     | 246/500 [00:15<00:15, 16.45it/s] 50%|████▉     | 248/500 [00:15<00:15, 16.48it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:15<00:15, 16.42it/s] 50%|█████     | 252/500 [00:15<00:15, 16.32it/s] 51%|█████     | 254/500 [00:15<00:15, 16.31it/s] 51%|█████     | 256/500 [00:15<00:15, 16.16it/s] 52%|█████▏    | 258/500 [00:16<00:14, 16.32it/s] 52%|█████▏    | 260/500 [00:16<00:14, 16.16it/s] 52%|█████▏    | 262/500 [00:16<00:14, 16.20it/s] 53%|█████▎    | 264/500 [00:16<00:14, 16.08it/s] 53%|█████▎    | 266/500 [00:16<00:14, 16.24it/s] 54%|█████▎    | 268/500 [00:16<00:14, 16.28it/s] 54%|█████▍    | 270/500 [00:16<00:14, 16.17it/s] 54%|█████▍    | 272/500 [00:16<00:14, 16.19it/s] 55%|█████▍    | 274/500 [00:16<00:13, 16.38it/s] 55%|█████▌    | 276/500 [00:17<00:13, 16.37it/s] 56%|█████▌    | 278/500 [00:17<00:13, 16.44it/s] 56%|█████▌    | 280/500 [00:17<00:13, 15.87it/s] 56%|█████▋    | 282/500 [00:17<00:13, 16.04it/s] 57%|█████▋    | 284/500 [00:17<00:13, 16.16it/s] 57%|█████▋    | 286/500 [00:17<00:13, 16.18it/s] 58%|█████▊    | 288/500 [00:17<00:13, 16.24it/s] 58%|█████▊    | 290/500 [00:17<00:12, 16.30it/s] 58%|█████▊    | 292/500 [00:18<00:12, 16.31it/s] 59%|█████▉    | 294/500 [00:18<00:12, 16.04it/s] 59%|█████▉    | 296/500 [00:18<00:12, 16.17it/s] 60%|█████▉    | 298/500 [00:18<00:12, 16.31it/s] 60%|██████    | 300/500 [00:18<00:12, 16.45it/s] 60%|██████    | 302/500 [00:18<00:12, 16.36it/s] 61%|██████    | 304/500 [00:18<00:11, 16.43it/s] 61%|██████    | 306/500 [00:18<00:11, 16.48it/s] 62%|██████▏   | 308/500 [00:19<00:11, 16.54it/s] 62%|██████▏   | 310/500 [00:19<00:11, 16.62it/s] 62%|██████▏   | 312/500 [00:19<00:11, 16.53it/s] 63%|██████▎   | 314/500 [00:19<00:11, 16.51it/s] 63%|██████▎   | 316/500 [00:19<00:11, 16.43it/s] 64%|██████▎   | 318/500 [00:19<00:11, 16.50it/s] 64%|██████▍   | 320/500 [00:19<00:10, 16.52it/s] 64%|██████▍   | 322/500 [00:19<00:10, 16.48it/s] 65%|██████▍   | 324/500 [00:20<00:10, 16.48it/s] 65%|██████▌   | 326/500 [00:20<00:10, 16.25it/s] 66%|██████▌   | 328/500 [00:20<00:10, 16.26it/s] 66%|██████▌   | 330/500 [00:20<00:10, 15.66it/s] 66%|██████▋   | 332/500 [00:20<00:10, 15.84it/s] 67%|██████▋   | 334/500 [00:20<00:10, 16.00it/s] 67%|██████▋   | 336/500 [00:20<00:10, 16.17it/s] 68%|██████▊   | 338/500 [00:20<00:09, 16.28it/s] 68%|██████▊   | 340/500 [00:21<00:09, 16.36it/s] 68%|██████▊   | 342/500 [00:21<00:09, 16.40it/s] 69%|██████▉   | 344/500 [00:21<00:09, 16.37it/s] 69%|██████▉   | 346/500 [00:21<00:09, 16.33it/s] 70%|██████▉   | 348/500 [00:21<00:09, 16.36it/s] 70%|███████   | 350/500 [00:21<00:09, 16.19it/s] 70%|███████   | 352/500 [00:21<00:09, 16.24it/s] 71%|███████   | 354/500 [00:21<00:08, 16.24it/s] 71%|███████   | 356/500 [00:22<00:08, 16.31it/s] 72%|███████▏  | 358/500 [00:22<00:08, 16.44it/s] 72%|███████▏  | 360/500 [00:22<00:08, 16.39it/s] 72%|███████▏  | 362/500 [00:22<00:08, 16.47it/s] 73%|███████▎  | 364/500 [00:22<00:08, 16.34it/s] 73%|███████▎  | 366/500 [00:22<00:08, 16.31it/s] 74%|███████▎  | 368/500 [00:22<00:08, 16.36it/s] 74%|███████▍  | 370/500 [00:22<00:07, 16.39it/s] 74%|███████▍  | 372/500 [00:23<00:07, 16.43it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:23<00:07, 16.42it/s] 75%|███████▌  | 376/500 [00:23<00:07, 16.45it/s] 76%|███████▌  | 378/500 [00:23<00:07, 16.48it/s] 76%|███████▌  | 380/500 [00:23<00:07, 16.48it/s] 76%|███████▋  | 382/500 [00:23<00:07, 16.35it/s] 77%|███████▋  | 384/500 [00:23<00:07, 16.28it/s] 77%|███████▋  | 386/500 [00:23<00:06, 16.38it/s] 78%|███████▊  | 388/500 [00:23<00:06, 16.41it/s] 78%|███████▊  | 390/500 [00:24<00:06, 16.42it/s] 78%|███████▊  | 392/500 [00:24<00:06, 16.46it/s] 79%|███████▉  | 394/500 [00:24<00:06, 16.48it/s] 79%|███████▉  | 396/500 [00:24<00:06, 16.43it/s] 80%|███████▉  | 398/500 [00:24<00:06, 16.47it/s] 80%|████████  | 400/500 [00:24<00:06, 16.38it/s] 80%|████████  | 402/500 [00:24<00:05, 16.37it/s] 81%|████████  | 404/500 [00:24<00:05, 16.40it/s] 81%|████████  | 406/500 [00:25<00:05, 16.41it/s] 82%|████████▏ | 408/500 [00:25<00:05, 16.46it/s] 82%|████████▏ | 410/500 [00:25<00:05, 16.48it/s] 82%|████████▏ | 412/500 [00:25<00:05, 16.47it/s] 83%|████████▎ | 414/500 [00:25<00:05, 16.42it/s] 83%|████████▎ | 416/500 [00:25<00:05, 16.38it/s] 84%|████████▎ | 418/500 [00:25<00:04, 16.41it/s] 84%|████████▍ | 420/500 [00:25<00:04, 16.38it/s] 84%|████████▍ | 422/500 [00:26<00:04, 16.43it/s] 85%|████████▍ | 424/500 [00:26<00:04, 16.44it/s] 85%|████████▌ | 426/500 [00:26<00:04, 16.46it/s] 86%|████████▌ | 428/500 [00:26<00:04, 16.13it/s] 86%|████████▌ | 430/500 [00:26<00:04, 16.14it/s] 86%|████████▋ | 432/500 [00:26<00:04, 16.23it/s] 87%|████████▋ | 434/500 [00:26<00:04, 16.32it/s] 87%|████████▋ | 436/500 [00:26<00:03, 16.26it/s] 88%|████████▊ | 438/500 [00:27<00:03, 16.41it/s] 88%|████████▊ | 440/500 [00:27<00:03, 16.50it/s] 88%|████████▊ | 442/500 [00:27<00:03, 16.54it/s] 89%|████████▉ | 444/500 [00:27<00:03, 16.54it/s] 89%|████████▉ | 446/500 [00:27<00:03, 16.39it/s] 90%|████████▉ | 448/500 [00:27<00:03, 16.41it/s] 90%|█████████ | 450/500 [00:27<00:03, 16.48it/s] 90%|█████████ | 452/500 [00:27<00:02, 16.21it/s] 91%|█████████ | 454/500 [00:28<00:02, 16.29it/s] 91%|█████████ | 456/500 [00:28<00:02, 15.99it/s] 92%|█████████▏| 458/500 [00:28<00:02, 16.09it/s] 92%|█████████▏| 460/500 [00:28<00:02, 16.15it/s] 92%|█████████▏| 462/500 [00:28<00:02, 16.27it/s] 93%|█████████▎| 464/500 [00:28<00:02, 16.32it/s] 93%|█████████▎| 466/500 [00:28<00:02, 16.12it/s] 94%|█████████▎| 468/500 [00:28<00:01, 16.18it/s] 94%|█████████▍| 470/500 [00:29<00:01, 16.25it/s] 94%|█████████▍| 472/500 [00:29<00:01, 16.30it/s] 95%|█████████▍| 474/500 [00:29<00:01, 16.28it/s] 95%|█████████▌| 476/500 [00:29<00:01, 16.20it/s] 96%|█████████▌| 478/500 [00:29<00:01, 16.24it/s] 96%|█████████▌| 480/500 [00:29<00:01, 16.31it/s] 96%|█████████▋| 482/500 [00:29<00:01, 16.37it/s] 97%|█████████▋| 484/500 [00:29<00:00, 16.37it/s] 97%|█████████▋| 486/500 [00:29<00:00, 16.38it/s] 98%|█████████▊| 488/500 [00:30<00:00, 16.40it/s] 98%|█████████▊| 490/500 [00:30<00:00, 16.44it/s] 98%|█████████▊| 492/500 [00:30<00:00, 16.40it/s] 99%|█████████▉| 494/500 [00:30<00:00, 16.31it/s] 99%|█████████▉| 496/500 [00:30<00:00, 16.31it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:30<00:00, 16.39it/s]100%|██████████| 500/500 [00:30<00:00, 16.40it/s]100%|██████████| 500/500 [00:30<00:00, 16.22it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  19
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:36,  6.21s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:48,  2.91it/s]  2%|▏         | 11/500 [00:13<10:45,  1.32s/it]  3%|▎         | 13/500 [00:13<07:20,  1.11it/s]  3%|▎         | 15/500 [00:19<12:59,  1.61s/it]  3%|▎         | 17/500 [00:19<09:02,  1.12s/it]  4%|▍         | 19/500 [00:19<06:21,  1.26it/s]  4%|▍         | 19/500 [00:31<06:21,  1.26it/s]  4%|▍         | 21/500 [00:31<19:33,  2.45s/it]  5%|▍         | 23/500 [00:32<13:42,  1.72s/it]  5%|▌         | 25/500 [00:38<16:58,  2.14s/it]  5%|▌         | 27/500 [00:38<11:57,  1.52s/it]  6%|▌         | 29/500 [00:38<08:28,  1.08s/it]  6%|▌         | 31/500 [00:51<20:35,  2.63s/it]  7%|▋         | 33/500 [00:51<14:30,  1.86s/it]  7%|▋         | 35/500 [00:57<17:27,  2.25s/it]  7%|▋         | 37/500 [00:57<12:19,  1.60s/it]  8%|▊         | 39/500 [00:57<08:44,  1.14s/it]  8%|▊         | 41/500 [01:10<20:51,  2.73s/it]  9%|▊         | 43/500 [01:10<14:41,  1.93s/it]  9%|▉         | 45/500 [01:17<17:19,  2.28s/it]  9%|▉         | 47/500 [01:17<12:14,  1.62s/it] 10%|▉         | 49/500 [01:17<08:40,  1.15s/it] 10%|█         | 51/500 [01:29<19:50,  2.65s/it] 11%|█         | 53/500 [01:29<13:58,  1.88s/it] 11%|█         | 55/500 [01:35<16:40,  2.25s/it] 11%|█▏        | 57/500 [01:36<11:47,  1.60s/it] 12%|█▏        | 59/500 [01:36<08:21,  1.14s/it] 12%|█▏        | 61/500 [01:48<19:35,  2.68s/it] 13%|█▎        | 63/500 [01:48<13:48,  1.90s/it]Epoch:  1  	Training Loss: 0.048232778906822205
Test Loss:  85.08393859863281
Valid Loss:  84.23150634765625
Epoch:  2  	Training Loss: 84.71293640136719
Test Loss:  2194.53271484375
Valid Loss:  2154.72412109375
Epoch:  3  	Training Loss: 2164.791015625
Test Loss:  8.355098724365234
Valid Loss:  8.195793151855469
Epoch:  4  	Training Loss: 8.260896682739258
Test Loss:  3.740955352783203
Valid Loss:  3.6637203693389893
Epoch:  5  	Training Loss: 3.697343587875366
Test Loss:  1.7624367475509644
Valid Loss:  1.7222723960876465
Epoch:  6  	Training Loss: 1.7408736944198608
Test Loss:  0.9895734786987305
Valid Loss:  0.9669368863105774
Epoch:  7  	Training Loss: 0.979346513748169
Test Loss:  0.6414151191711426
Valid Loss:  0.626247763633728
Epoch:  8  	Training Loss: 0.6352951526641846
Test Loss:  0.42059582471847534
Valid Loss:  0.41038379073143005
Epoch:  9  	Training Loss: 0.4170360565185547
Test Loss:  0.2787700295448303
Valid Loss:  0.27191126346588135
Epoch:  10  	Training Loss: 0.276823490858078
Test Loss:  0.21762458980083466
Valid Loss:  0.21347619593143463
Epoch:  11  	Training Loss: 0.2175806611776352
Test Loss:  0.21762460470199585
Valid Loss:  0.21347621083259583
Epoch:  12  	Training Loss: 0.2175806760787964
Test Loss:  0.21762460470199585
Valid Loss:  0.21347618103027344
Epoch:  13  	Training Loss: 0.2175806760787964
Test Loss:  0.21762457489967346
Valid Loss:  0.21347619593143463
Epoch:  14  	Training Loss: 0.2175806611776352
Test Loss:  0.21762458980083466
Valid Loss:  0.21347621083259583
Epoch:  15  	Training Loss: 0.2175806611776352
Test Loss:  0.21762458980083466
Valid Loss:  0.21347619593143463
**************************************************learning rate decay**************************************************
Epoch:  16  	Training Loss: 0.2175806611776352
Test Loss:  0.21762458980083466
Valid Loss:  0.21347619593143463
Epoch:  17  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  18  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  19  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347619593143463
Epoch:  20  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  21  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  22  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  23  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  24  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347619593143463
Epoch:  25  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  27  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347619593143463
Epoch:  28  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  29  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  30  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  31  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  32  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  33  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  34  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  35  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  37  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  38  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  39  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  40  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  41  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  42  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  43  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  44  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  45  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  46  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  47  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  48  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  49  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  50  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  51  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  52  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  53  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  54  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  55  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  56  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  57  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  58  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  59  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  60  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  61  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  62  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  63  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
 13%|█▎        | 65/500 [01:55<16:25,  2.27s/it] 13%|█▎        | 67/500 [01:55<11:35,  1.61s/it] 14%|█▍        | 69/500 [01:55<08:13,  1.15s/it] 14%|█▍        | 71/500 [02:07<19:09,  2.68s/it] 15%|█▍        | 73/500 [02:08<13:30,  1.90s/it] 15%|█▌        | 75/500 [02:14<16:19,  2.30s/it] 15%|█▌        | 77/500 [02:14<11:31,  1.63s/it] 16%|█▌        | 79/500 [02:14<08:10,  1.16s/it] 16%|█▌        | 81/500 [02:27<18:53,  2.71s/it] 17%|█▋        | 83/500 [02:27<13:18,  1.91s/it] 17%|█▋        | 85/500 [02:33<15:43,  2.27s/it] 17%|█▋        | 87/500 [02:34<11:06,  1.61s/it] 18%|█▊        | 89/500 [02:34<07:52,  1.15s/it] 18%|█▊        | 91/500 [02:46<18:02,  2.65s/it] 19%|█▊        | 93/500 [02:46<12:42,  1.87s/it] 19%|█▉        | 95/500 [02:52<15:12,  2.25s/it] 19%|█▉        | 97/500 [02:53<10:44,  1.60s/it] 20%|█▉        | 99/500 [02:53<07:37,  1.14s/it] 20%|██        | 101/500 [03:05<17:48,  2.68s/it] 21%|██        | 103/500 [03:05<12:33,  1.90s/it] 21%|██        | 105/500 [03:12<15:03,  2.29s/it] 21%|██▏       | 107/500 [03:12<10:37,  1.62s/it] 22%|██▏       | 109/500 [03:12<07:31,  1.15s/it] 22%|██▏       | 111/500 [03:25<17:36,  2.72s/it] 23%|██▎       | 113/500 [03:25<12:23,  1.92s/it] 23%|██▎       | 115/500 [03:31<14:42,  2.29s/it] 23%|██▎       | 117/500 [03:31<10:22,  1.63s/it] 24%|██▍       | 119/500 [03:31<07:21,  1.16s/it] 24%|██▍       | 121/500 [03:44<16:57,  2.68s/it] 25%|██▍       | 123/500 [03:44<11:56,  1.90s/it]Epoch:  64  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  65  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  67  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  68  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  69  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  70  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  71  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  72  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  73  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  74  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  75  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  76  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  77  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  78  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  79  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  80  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  81  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  82  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  83  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  84  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  85  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  86  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  87  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  88  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  89  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  90  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347619593143463
**************************************************learning rate decay**************************************************
Epoch:  91  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  92  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  93  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  94  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  95  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  96  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  97  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  98  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  99  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  100  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  101  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  102  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  103  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  104  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  105  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  106  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  107  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347616612911224
Epoch:  108  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  109  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  110  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  111  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  112  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  113  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  114  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  115  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  117  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  118  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  119  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  120  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  121  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  122  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  123  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  124  	Training Loss: 0.217580646276474
Test Loss:   25%|██▌       | 125/500 [03:50<14:13,  2.28s/it] 25%|██▌       | 127/500 [03:51<10:02,  1.62s/it] 26%|██▌       | 129/500 [03:51<07:07,  1.15s/it] 26%|██▌       | 131/500 [04:03<16:29,  2.68s/it] 27%|██▋       | 133/500 [04:03<11:36,  1.90s/it] 27%|██▋       | 135/500 [04:10<13:53,  2.28s/it] 27%|██▋       | 137/500 [04:10<09:47,  1.62s/it] 28%|██▊       | 139/500 [04:10<06:56,  1.15s/it] 28%|██▊       | 139/500 [04:21<06:56,  1.15s/it] 28%|██▊       | 141/500 [04:22<15:58,  2.67s/it] 29%|██▊       | 143/500 [04:23<11:15,  1.89s/it] 29%|██▉       | 145/500 [04:29<13:29,  2.28s/it] 29%|██▉       | 147/500 [04:29<09:31,  1.62s/it] 30%|██▉       | 149/500 [04:29<06:44,  1.15s/it] 30%|██▉       | 149/500 [04:41<06:44,  1.15s/it] 30%|███       | 151/500 [04:42<15:39,  2.69s/it] 31%|███       | 153/500 [04:42<11:01,  1.91s/it] 31%|███       | 155/500 [04:48<13:03,  2.27s/it] 31%|███▏      | 157/500 [04:48<09:12,  1.61s/it] 32%|███▏      | 159/500 [04:48<06:31,  1.15s/it] 32%|███▏      | 159/500 [05:01<06:31,  1.15s/it] 32%|███▏      | 161/500 [05:01<15:06,  2.67s/it] 33%|███▎      | 163/500 [05:01<10:38,  1.89s/it] 33%|███▎      | 165/500 [05:07<12:38,  2.26s/it] 33%|███▎      | 167/500 [05:07<08:54,  1.61s/it] 34%|███▍      | 169/500 [05:08<06:18,  1.14s/it] 34%|███▍      | 171/500 [05:20<14:33,  2.66s/it] 35%|███▍      | 173/500 [05:20<10:15,  1.88s/it] 35%|███▌      | 175/500 [05:26<12:11,  2.25s/it] 35%|███▌      | 177/500 [05:26<08:36,  1.60s/it] 36%|███▌      | 179/500 [05:27<06:05,  1.14s/it] 36%|███▌      | 181/500 [05:39<14:12,  2.67s/it] 37%|███▋      | 183/500 [05:39<10:00,  1.89s/it]0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  125  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  126  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  127  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  128  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  129  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  130  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  131  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  132  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  133  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  134  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  135  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  136  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  137  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  138  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  139  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  140  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  142  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  143  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  144  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  145  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  146  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  147  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  148  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  149  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  150  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  151  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  152  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  153  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  154  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  155  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  156  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  157  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  158  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  159  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  160  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  161  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  162  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  163  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  164  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  165  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  166  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  167  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  168  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  169  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  170  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  171  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  172  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  173  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  174  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  175  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  176  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  177  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  178  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  179  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  180  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347619593143463
**************************************************learning rate decay**************************************************
Epoch:  181  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  182  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  183  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  184  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
 37%|███▋      | 185/500 [05:46<11:54,  2.27s/it] 37%|███▋      | 187/500 [05:46<08:23,  1.61s/it] 38%|███▊      | 189/500 [05:46<05:56,  1.15s/it] 38%|███▊      | 191/500 [05:58<13:40,  2.66s/it] 39%|███▊      | 193/500 [05:58<09:37,  1.88s/it] 39%|███▉      | 195/500 [06:05<11:26,  2.25s/it] 39%|███▉      | 197/500 [06:05<08:03,  1.60s/it] 40%|███▉      | 199/500 [06:05<05:42,  1.14s/it] 40%|████      | 201/500 [06:17<13:18,  2.67s/it] 41%|████      | 203/500 [06:17<09:21,  1.89s/it] 41%|████      | 205/500 [06:24<11:16,  2.29s/it] 41%|████▏     | 207/500 [06:24<07:56,  1.63s/it] 42%|████▏     | 209/500 [06:24<05:37,  1.16s/it] 42%|████▏     | 211/500 [06:37<12:54,  2.68s/it] 42%|████▏     | 212/500 [06:37<10:46,  2.25s/it] 43%|████▎     | 213/500 [06:37<08:42,  1.82s/it] 43%|████▎     | 215/500 [06:43<11:07,  2.34s/it] 43%|████▎     | 217/500 [06:44<07:22,  1.56s/it] 44%|████▍     | 219/500 [06:44<05:01,  1.07s/it] 44%|████▍     | 221/500 [06:56<12:48,  2.75s/it] 45%|████▍     | 223/500 [06:57<08:49,  1.91s/it] 45%|████▌     | 225/500 [07:03<10:32,  2.30s/it] 45%|████▌     | 227/500 [07:03<07:21,  1.62s/it] 46%|████▌     | 229/500 [07:03<05:10,  1.14s/it] 46%|████▌     | 231/500 [07:16<12:08,  2.71s/it] 47%|████▋     | 233/500 [07:16<08:29,  1.91s/it] 47%|████▋     | 235/500 [07:22<10:07,  2.29s/it] 47%|████▋     | 237/500 [07:22<07:06,  1.62s/it] 48%|████▊     | 239/500 [07:23<05:01,  1.15s/it] 48%|████▊     | 241/500 [07:35<11:43,  2.72s/it] 49%|████▊     | 243/500 [07:35<08:13,  1.92s/it]Valid Loss:  0.21347618103027344
Epoch:  185  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  186  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  187  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  188  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  189  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  190  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  191  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  192  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  193  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  194  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  195  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  196  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  197  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  198  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  199  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  200  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  201  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  202  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  203  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  204  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  205  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  206  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  207  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  208  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  209  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  210  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  211  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  212  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  213  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  214  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  215  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  216  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  217  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  218  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  219  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  220  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  221  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  222  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  223  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  224  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  225  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  226  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  227  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  228  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  229  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  230  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  231  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  232  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  233  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  234  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  235  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  236  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  237  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  238  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  239  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  240  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  241  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  242  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  243  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  244  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:   49%|████▉     | 245/500 [07:42<09:40,  2.27s/it] 49%|████▉     | 247/500 [07:42<06:49,  1.62s/it] 50%|████▉     | 249/500 [07:42<04:49,  1.15s/it] 50%|█████     | 251/500 [07:54<11:11,  2.70s/it] 51%|█████     | 253/500 [07:55<07:52,  1.91s/it] 51%|█████     | 255/500 [08:01<09:21,  2.29s/it] 51%|█████▏    | 257/500 [08:01<06:35,  1.63s/it] 52%|█████▏    | 259/500 [08:01<04:39,  1.16s/it] 52%|█████▏    | 261/500 [08:14<10:53,  2.73s/it] 53%|█████▎    | 263/500 [08:14<07:38,  1.94s/it] 53%|█████▎    | 265/500 [08:21<09:03,  2.31s/it] 53%|█████▎    | 267/500 [08:21<06:22,  1.64s/it] 54%|█████▍    | 269/500 [08:21<04:29,  1.17s/it] 54%|█████▍    | 271/500 [08:34<10:21,  2.71s/it] 55%|█████▍    | 273/500 [08:34<07:15,  1.92s/it] 55%|█████▌    | 275/500 [08:40<08:38,  2.30s/it] 55%|█████▌    | 277/500 [08:40<06:04,  1.63s/it] 56%|█████▌    | 279/500 [08:40<04:17,  1.16s/it] 56%|█████▌    | 279/500 [08:51<04:17,  1.16s/it] 56%|█████▌    | 281/500 [08:53<09:47,  2.68s/it] 57%|█████▋    | 283/500 [08:53<06:51,  1.90s/it] 57%|█████▋    | 285/500 [08:59<08:08,  2.27s/it] 57%|█████▋    | 287/500 [08:59<05:43,  1.61s/it] 58%|█████▊    | 289/500 [08:59<04:02,  1.15s/it] 58%|█████▊    | 289/500 [09:11<04:02,  1.15s/it] 58%|█████▊    | 291/500 [09:12<09:17,  2.67s/it] 59%|█████▊    | 293/500 [09:12<06:30,  1.89s/it] 59%|█████▉    | 295/500 [09:18<07:44,  2.26s/it] 59%|█████▉    | 297/500 [09:18<05:26,  1.61s/it] 60%|█████▉    | 299/500 [09:19<03:49,  1.14s/it] 60%|█████▉    | 299/500 [09:31<03:49,  1.14s/it] 60%|██████    | 301/500 [09:31<08:53,  2.68s/it] 61%|██████    | 303/500 [09:31<06:13,  1.90s/it]0.21347618103027344
Epoch:  245  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  246  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  247  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  248  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  249  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  250  	Training Loss: 0.2175806611776352
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  251  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  252  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  253  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  254  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  255  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  256  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  257  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  258  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  259  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  260  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  261  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  262  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  263  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  264  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  265  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  266  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  267  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  268  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  269  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  270  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  271  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  272  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  273  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  274  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  275  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  276  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  277  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  278  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  279  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  280  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  281  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  282  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  283  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  284  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  285  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  286  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  287  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  288  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  289  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  290  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  291  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  292  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  293  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347619593143463
Epoch:  294  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  295  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  296  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  297  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  298  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  299  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  300  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  301  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  302  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  303  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  304  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
 61%|██████    | 305/500 [09:38<07:22,  2.27s/it] 61%|██████▏   | 307/500 [09:38<05:11,  1.61s/it] 62%|██████▏   | 309/500 [09:38<03:39,  1.15s/it] 62%|██████▏   | 311/500 [09:50<08:27,  2.68s/it] 63%|██████▎   | 313/500 [09:51<05:55,  1.90s/it] 63%|██████▎   | 315/500 [09:57<07:01,  2.28s/it] 63%|██████▎   | 317/500 [09:57<04:55,  1.62s/it] 64%|██████▍   | 319/500 [09:57<03:28,  1.15s/it] 64%|██████▍   | 321/500 [10:10<08:00,  2.68s/it] 65%|██████▍   | 323/500 [10:10<05:36,  1.90s/it] 65%|██████▌   | 325/500 [10:16<06:38,  2.28s/it] 65%|██████▌   | 327/500 [10:16<04:39,  1.62s/it] 66%|██████▌   | 329/500 [10:16<03:16,  1.15s/it] 66%|██████▌   | 331/500 [10:29<07:32,  2.68s/it] 67%|██████▋   | 333/500 [10:29<05:16,  1.90s/it] 67%|██████▋   | 335/500 [10:35<06:15,  2.28s/it] 67%|██████▋   | 337/500 [10:35<04:23,  1.62s/it] 68%|██████▊   | 339/500 [10:36<03:05,  1.15s/it] 68%|██████▊   | 341/500 [10:48<07:08,  2.69s/it] 69%|██████▊   | 343/500 [10:48<04:59,  1.91s/it] 69%|██████▉   | 345/500 [10:55<05:54,  2.28s/it] 69%|██████▉   | 347/500 [10:55<04:07,  1.62s/it] 70%|██████▉   | 349/500 [10:55<02:54,  1.15s/it] 70%|███████   | 351/500 [11:08<06:41,  2.69s/it] 71%|███████   | 353/500 [11:08<04:40,  1.91s/it] 71%|███████   | 355/500 [11:14<05:32,  2.29s/it] 71%|███████▏  | 357/500 [11:14<03:52,  1.63s/it] 72%|███████▏  | 359/500 [11:14<02:43,  1.16s/it] 72%|███████▏  | 361/500 [11:27<06:12,  2.68s/it] 73%|███████▎  | 363/500 [11:27<04:19,  1.90s/it]Epoch:  305  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  306  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  307  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  308  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  309  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  310  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  311  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  312  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  313  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  314  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  315  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  316  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  317  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  318  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  319  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  320  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  321  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  322  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  323  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  324  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  325  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  326  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  327  	Training Loss: 0.217580646276474
Test Loss:  0.21762455999851227
Valid Loss:  0.21347618103027344
Epoch:  328  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  329  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  330  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  331  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  332  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  333  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  334  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  335  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  336  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  337  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  338  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  339  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  340  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  341  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  342  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  343  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  344  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  345  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  346  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  347  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  348  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  349  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  350  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  351  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  352  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  353  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  354  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  355  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  356  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  357  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  358  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  359  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  360  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  361  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  362  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  363  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  364  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
 73%|███████▎  | 365/500 [11:33<05:05,  2.26s/it] 73%|███████▎  | 367/500 [11:33<03:33,  1.61s/it] 74%|███████▍  | 369/500 [11:33<02:29,  1.14s/it] 74%|███████▍  | 371/500 [11:46<05:44,  2.67s/it] 75%|███████▍  | 373/500 [11:46<04:00,  1.89s/it] 75%|███████▌  | 375/500 [11:52<04:42,  2.26s/it] 75%|███████▌  | 377/500 [11:52<03:16,  1.60s/it] 76%|███████▌  | 379/500 [11:53<02:17,  1.14s/it] 76%|███████▌  | 381/500 [12:05<05:13,  2.64s/it] 77%|███████▋  | 383/500 [12:05<03:38,  1.87s/it] 77%|███████▋  | 385/500 [12:11<04:18,  2.25s/it] 77%|███████▋  | 387/500 [12:11<03:00,  1.59s/it] 78%|███████▊  | 389/500 [12:11<02:05,  1.13s/it] 78%|███████▊  | 391/500 [12:24<04:47,  2.64s/it] 79%|███████▊  | 393/500 [12:24<03:19,  1.87s/it] 79%|███████▉  | 395/500 [12:30<04:00,  2.29s/it] 79%|███████▉  | 397/500 [12:31<02:47,  1.62s/it] 80%|███████▉  | 399/500 [12:31<01:56,  1.16s/it] 80%|███████▉  | 399/500 [12:41<01:56,  1.16s/it] 80%|████████  | 401/500 [12:44<04:31,  2.74s/it] 81%|████████  | 403/500 [12:44<03:08,  1.94s/it] 81%|████████  | 405/500 [12:50<03:38,  2.30s/it] 81%|████████▏ | 407/500 [12:50<02:31,  1.63s/it] 82%|████████▏ | 409/500 [12:50<01:45,  1.16s/it] 82%|████████▏ | 409/500 [13:01<01:45,  1.16s/it] 82%|████████▏ | 411/500 [13:03<04:02,  2.72s/it] 83%|████████▎ | 413/500 [13:03<02:47,  1.93s/it] 83%|████████▎ | 415/500 [13:09<03:15,  2.30s/it] 83%|████████▎ | 417/500 [13:10<02:15,  1.63s/it] 84%|████████▍ | 419/500 [13:10<01:34,  1.16s/it] 84%|████████▍ | 419/500 [13:21<01:34,  1.16s/it] 84%|████████▍ | 421/500 [13:22<03:32,  2.69s/it] 85%|████████▍ | 423/500 [13:22<02:26,  1.91s/it]Epoch:  365  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  366  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  367  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  368  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  369  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  370  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  371  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  372  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  373  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  374  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  375  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  376  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  377  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  378  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  379  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  380  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  381  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  382  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  383  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  384  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  385  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  386  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  387  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  388  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  389  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  390  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  391  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  392  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  393  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  394  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  395  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  396  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  397  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  398  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  399  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  400  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  401  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  402  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  403  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  404  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  405  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  406  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  407  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  408  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  409  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  410  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  411  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  412  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  413  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  414  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  415  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  417  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  418  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  419  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  420  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  421  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  422  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  423  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  424  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
 85%|████████▌ | 425/500 [13:29<02:51,  2.28s/it] 85%|████████▌ | 427/500 [13:29<01:58,  1.62s/it] 86%|████████▌ | 429/500 [13:29<01:21,  1.15s/it] 86%|████████▌ | 429/500 [13:41<01:21,  1.15s/it] 86%|████████▌ | 431/500 [13:41<03:04,  2.67s/it] 87%|████████▋ | 433/500 [13:42<02:06,  1.89s/it] 87%|████████▋ | 435/500 [13:48<02:26,  2.26s/it] 87%|████████▋ | 437/500 [13:48<01:41,  1.60s/it] 88%|████████▊ | 439/500 [13:48<01:09,  1.14s/it] 88%|████████▊ | 441/500 [14:01<02:37,  2.67s/it] 89%|████████▊ | 443/500 [14:01<01:47,  1.89s/it] 89%|████████▉ | 445/500 [14:07<02:04,  2.27s/it] 89%|████████▉ | 447/500 [14:07<01:25,  1.61s/it] 90%|████████▉ | 449/500 [14:07<00:58,  1.15s/it] 90%|█████████ | 451/500 [14:20<02:11,  2.68s/it] 91%|█████████ | 453/500 [14:20<01:29,  1.90s/it] 91%|█████████ | 455/500 [14:26<01:42,  2.27s/it] 91%|█████████▏| 457/500 [14:26<01:09,  1.62s/it] 92%|█████████▏| 459/500 [14:27<00:47,  1.15s/it] 92%|█████████▏| 461/500 [14:39<01:45,  2.69s/it] 93%|█████████▎| 463/500 [14:39<01:10,  1.91s/it] 93%|█████████▎| 465/500 [14:46<01:19,  2.27s/it] 93%|█████████▎| 467/500 [14:46<00:53,  1.61s/it] 94%|█████████▍| 469/500 [14:46<00:35,  1.15s/it] 94%|█████████▍| 471/500 [14:58<01:16,  2.65s/it] 95%|█████████▍| 473/500 [14:58<00:50,  1.88s/it] 95%|█████████▌| 475/500 [15:04<00:56,  2.24s/it] 95%|█████████▌| 477/500 [15:05<00:36,  1.59s/it] 96%|█████████▌| 479/500 [15:05<00:23,  1.13s/it] 96%|█████████▌| 481/500 [15:17<00:50,  2.63s/it] 97%|█████████▋| 483/500 [15:17<00:31,  1.87s/it]Epoch:  425  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  426  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  427  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  428  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  429  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  430  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  431  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  432  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  433  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  434  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  435  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  436  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  437  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  438  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  439  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  440  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  441  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  442  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  443  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  444  	Training Loss: 0.2175806611776352
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  445  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  446  	Training Loss: 0.217580646276474
Test Loss:  0.21762458980083466
Valid Loss:  0.21347618103027344
Epoch:  447  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  448  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  449  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  450  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  451  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  452  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  453  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  454  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  455  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  456  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347619593143463
Epoch:  457  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  458  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  459  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  460  	Training Loss: 0.217580646276474
Test Loss:  0.21762455999851227
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  461  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  462  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  463  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  464  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  465  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  466  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  467  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  468  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  469  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  470  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  471  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  472  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  473  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  474  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  475  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  476  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  477  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  478  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  479  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  480  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  481  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  482  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  483  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  484  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
 97%|█████████▋| 485/500 [15:23<00:33,  2.23s/it] 97%|█████████▋| 487/500 [15:23<00:20,  1.59s/it] 98%|█████████▊| 489/500 [15:24<00:12,  1.13s/it] 98%|█████████▊| 491/500 [15:36<00:24,  2.67s/it] 99%|█████████▊| 493/500 [15:36<00:13,  1.89s/it] 99%|█████████▉| 495/500 [15:43<00:11,  2.29s/it] 99%|█████████▉| 497/500 [15:43<00:04,  1.62s/it]100%|█████████▉| 499/500 [15:43<00:01,  1.16s/it]100%|██████████| 500/500 [15:49<00:00,  1.90s/it]
Epoch:  485  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  486  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  487  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  488  	Training Loss: 0.2175806611776352
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  489  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  490  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  491  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347619593143463
Epoch:  492  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  493  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  494  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  495  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
Epoch:  496  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  497  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  498  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  499  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
Epoch:  500  	Training Loss: 0.217580646276474
Test Loss:  0.21762457489967346
Valid Loss:  0.21347618103027344
**************************************************learning rate decay**************************************************
seed is  19
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:10,  6.15s/it]  1%|          | 3/500 [00:06<13:37,  1.64s/it]  1%|          | 5/500 [00:06<06:52,  1.20it/s]  1%|▏         | 7/500 [00:06<04:10,  1.97it/s]  2%|▏         | 9/500 [00:06<02:47,  2.93it/s]  2%|▏         | 11/500 [00:12<10:41,  1.31s/it]  3%|▎         | 13/500 [00:13<07:17,  1.11it/s]  3%|▎         | 15/500 [00:13<05:05,  1.59it/s]  3%|▎         | 17/500 [00:13<03:38,  2.21it/s]  4%|▍         | 19/500 [00:13<02:39,  3.01it/s]  4%|▍         | 21/500 [00:19<09:29,  1.19s/it]  5%|▍         | 23/500 [00:19<06:44,  1.18it/s]  5%|▌         | 25/500 [00:19<04:49,  1.64it/s]  5%|▌         | 27/500 [00:20<03:30,  2.25it/s]  6%|▌         | 29/500 [00:20<02:35,  3.03it/s]  6%|▌         | 31/500 [00:26<09:11,  1.18s/it]  7%|▋         | 33/500 [00:26<06:34,  1.18it/s]  7%|▋         | 35/500 [00:32<11:52,  1.53s/it]  7%|▋         | 37/500 [00:33<08:26,  1.09s/it]  8%|▊         | 39/500 [00:33<06:01,  1.27it/s]  8%|▊         | 41/500 [00:39<11:24,  1.49s/it]  9%|▊         | 43/500 [00:39<08:08,  1.07s/it]  9%|▉         | 45/500 [00:39<05:50,  1.30it/s]  9%|▉         | 47/500 [00:39<04:14,  1.78it/s] 10%|▉         | 49/500 [00:40<03:07,  2.41it/s] 10%|█         | 51/500 [00:46<09:17,  1.24s/it] 11%|█         | 53/500 [00:46<06:38,  1.12it/s] 11%|█         | 55/500 [00:46<04:46,  1.55it/s] 11%|█▏        | 57/500 [00:46<03:28,  2.13it/s] 12%|█▏        | 59/500 [00:46<02:33,  2.87it/s] 12%|█▏        | 61/500 [00:53<08:34,  1.17s/it] 13%|█▎        | 63/500 [00:53<06:08,  1.19it/s] 13%|█▎        | 65/500 [00:53<04:25,  1.64it/s] 13%|█▎        | 67/500 [00:53<03:13,  2.24it/s] 14%|█▍        | 69/500 [00:53<02:23,  3.01it/s]Epoch:  1  	Training Loss: 0.048232778906822205
Test Loss:  9.136682510375977
Valid Loss:  8.977808952331543
Epoch:  2  	Training Loss: 8.971023559570312
Test Loss:  41.953887939453125
Valid Loss:  42.220890045166016
Epoch:  3  	Training Loss: 42.74300765991211
Test Loss:  0.8527315258979797
Valid Loss:  0.8785849213600159
Epoch:  4  	Training Loss: 0.8492469191551208
Test Loss:  0.852400541305542
Valid Loss:  0.8782469034194946
Epoch:  5  	Training Loss: 0.8489176034927368
Test Loss:  0.8520708084106445
Valid Loss:  0.8779103755950928
Epoch:  6  	Training Loss: 0.848590075969696
Test Loss:  0.8517419099807739
Valid Loss:  0.8775744438171387
Epoch:  7  	Training Loss: 0.8482632637023926
Test Loss:  0.8514134883880615
Valid Loss:  0.877238929271698
Epoch:  8  	Training Loss: 0.8479386568069458
Test Loss:  0.8510987758636475
Valid Loss:  0.8769174814224243
Epoch:  9  	Training Loss: 0.8476426601409912
Test Loss:  0.8507850170135498
Valid Loss:  0.8765969276428223
Epoch:  10  	Training Loss: 0.8473477363586426
Test Loss:  0.8504723310470581
Valid Loss:  0.8762772083282471
Epoch:  11  	Training Loss: 0.847053587436676
Test Loss:  0.8501598238945007
Valid Loss:  0.875957727432251
Epoch:  12  	Training Loss: 0.8467597961425781
Test Loss:  39.08611297607422
Valid Loss:  38.301944732666016
Epoch:  13  	Training Loss: 38.58647537231445
Test Loss:  0.7916717529296875
Valid Loss:  0.7982112169265747
Epoch:  14  	Training Loss: 0.7779437303543091
Test Loss:  0.6344125270843506
Valid Loss:  0.6527173519134521
Epoch:  15  	Training Loss: 0.6304835081100464
Test Loss:  0.6266403794288635
Valid Loss:  0.646708607673645
Epoch:  16  	Training Loss: 0.6244267225265503
Test Loss:  0.6222714185714722
Valid Loss:  0.6440612077713013
Epoch:  17  	Training Loss: 0.6210014820098877
Test Loss:  0.619117259979248
Valid Loss:  0.6419532299041748
Epoch:  18  	Training Loss: 0.6183537244796753
Test Loss:  0.6168583035469055
Valid Loss:  0.6402505040168762
Epoch:  19  	Training Loss: 0.6165566444396973
Test Loss:  0.6147626042366028
Valid Loss:  0.6386653780937195
Epoch:  20  	Training Loss: 0.6149560809135437
Test Loss:  0.6131779551506042
Valid Loss:  0.6371870040893555
Epoch:  21  	Training Loss: 0.613550066947937
Test Loss:  0.6119343042373657
Valid Loss:  0.6358535289764404
Epoch:  22  	Training Loss: 0.6123894453048706
Test Loss:  0.2470010370016098
Valid Loss:  0.27232062816619873
Epoch:  23  	Training Loss: 0.25492119789123535
Test Loss:  0.04701966047286987
Valid Loss:  0.06377647817134857
Epoch:  24  	Training Loss: 0.0565483421087265
Test Loss:  0.038138579577207565
Valid Loss:  0.05190262198448181
Epoch:  25  	Training Loss: 0.04677335172891617
Test Loss:  0.03718164935708046
Valid Loss:  0.05006779730319977
Epoch:  26  	Training Loss: 0.045444831252098083
Test Loss:  0.03647179156541824
Valid Loss:  0.04898366332054138
Epoch:  27  	Training Loss: 0.04452931135892868
Test Loss:  0.03576014190912247
Valid Loss:  0.04801318049430847
Epoch:  28  	Training Loss: 0.04365384578704834
Test Loss:  0.035058461129665375
Valid Loss:  0.04708191379904747
Epoch:  29  	Training Loss: 0.04280061274766922
Test Loss:  0.03437213599681854
Valid Loss:  0.04617629945278168
Epoch:  30  	Training Loss: 0.04196828603744507
Test Loss:  0.03370220214128494
Valid Loss:  0.04529318958520889
Epoch:  31  	Training Loss: 0.0411568321287632
Test Loss:  0.03304923325777054
Valid Loss:  0.044432174414396286
Epoch:  32  	Training Loss: 0.04036576300859451
Test Loss:  0.01894058845937252
Valid Loss:  0.02702941931784153
Epoch:  33  	Training Loss: 0.023742765188217163
Test Loss:  0.029781809076666832
Valid Loss:  0.02889968827366829
Epoch:  34  	Training Loss: 0.02976948395371437
Test Loss:  0.08593107014894485
Valid Loss:  0.09599193930625916
Epoch:  35  	Training Loss: 0.09287673234939575
Test Loss:  0.2652167081832886
Valid Loss:  0.250128835439682
**************************************************learning rate decay**************************************************
Epoch:  36  	Training Loss: 0.25667324662208557
Test Loss:  0.010563196614384651
Valid Loss:  0.01415244396775961
Epoch:  37  	Training Loss: 0.012825805693864822
Test Loss:  0.007902578450739384
Valid Loss:  0.010091687552630901
Epoch:  38  	Training Loss: 0.00928500946611166
Test Loss:  0.00618776585906744
Valid Loss:  0.007852958515286446
Epoch:  39  	Training Loss: 0.007238410413265228
Test Loss:  0.005037917755544186
Valid Loss:  0.0062727611511945724
Epoch:  40  	Training Loss: 0.005847621243447065
Test Loss:  0.004219355992972851
Valid Loss:  0.005192845594137907
Epoch:  41  	Training Loss: 0.004858833737671375
Test Loss:  0.00364210968837142
Valid Loss:  0.004443023819476366
Epoch:  42  	Training Loss: 0.004171396605670452
Test Loss:  0.003491914365440607
Valid Loss:  0.004342755302786827
Epoch:  43  	Training Loss: 0.0040635354816913605
Test Loss:  0.0033937173429876566
Valid Loss:  0.004284469410777092
Epoch:  44  	Training Loss: 0.00399942509829998
Test Loss:  0.0033278027549386024
Valid Loss:  0.0042502982541918755
Epoch:  45  	Training Loss: 0.003960415255278349
Test Loss:  0.0032814969308674335
Valid Loss:  0.004229437559843063
Epoch:  46  	Training Loss: 0.003934998996555805
Test Loss:  0.0032480612862855196
Valid Loss:  0.004215608816593885
Epoch:  47  	Training Loss: 0.003917381167411804
Test Loss:  0.00322271347977221
Valid Loss:  0.004205293953418732
Epoch:  48  	Training Loss: 0.0039040246047079563
Test Loss:  0.0032031559385359287
Valid Loss:  0.004197337664663792
Epoch:  49  	Training Loss: 0.003893334185704589
Test Loss:  0.0031861369498074055
Valid Loss:  0.004188240505754948
Epoch:  50  	Training Loss: 0.0038830735720694065
Test Loss:  0.0031712641939520836
Valid Loss:  0.004178043454885483
Epoch:  51  	Training Loss: 0.0038728215731680393
Test Loss:  0.003155686892569065
Valid Loss:  0.004167402163147926
Epoch:  52  	Training Loss: 0.0038613667711615562
Test Loss:  0.00319043081253767
Valid Loss:  0.0037435945123434067
Epoch:  53  	Training Loss: 0.0036207379307597876
Test Loss:  0.002987970132380724
Valid Loss:  0.0037145232781767845
Epoch:  54  	Training Loss: 0.00353023549541831
Test Loss:  0.0029694291297346354
Valid Loss:  0.003606590209528804
Epoch:  55  	Training Loss: 0.003463044296950102
Test Loss:  0.0028854813426733017
Valid Loss:  0.0035604294389486313
Epoch:  56  	Training Loss: 0.003410330507904291
Test Loss:  0.0028511667624115944
Valid Loss:  0.003496569814160466
Epoch:  57  	Training Loss: 0.003364706877619028
Test Loss:  0.002799332607537508
Valid Loss:  0.0034534165170043707
Epoch:  58  	Training Loss: 0.003324978519231081
Test Loss:  0.002763834549114108
Valid Loss:  0.0034090615808963776
Epoch:  59  	Training Loss: 0.003290199674665928
Test Loss:  0.0027265038806945086
Valid Loss:  0.003371879458427429
Epoch:  60  	Training Loss: 0.0032596425153315067
Test Loss:  0.00269209872931242
Valid Loss:  0.0033382640685886145
Epoch:  61  	Training Loss: 0.003232803428545594
Test Loss:  0.0026651890948414803
Valid Loss:  0.0033057485707104206
Epoch:  62  	Training Loss: 0.003209238639101386
Test Loss:  0.0025166466366499662
Valid Loss:  0.0032736770808696747
Epoch:  63  	Training Loss: 0.003163933288305998
Test Loss:  0.002506652381271124
Valid Loss:  0.003248048946261406
Epoch:  64  	Training Loss: 0.003144308924674988
Test Loss:  0.0024962518364191055
Valid Loss:  0.0032300774473696947
Epoch:  65  	Training Loss: 0.0031309197656810284
Test Loss:  0.0024855230003595352
Valid Loss:  0.0032140789553523064
Epoch:  66  	Training Loss: 0.00311896950006485
Test Loss:  0.0024759836960583925
Valid Loss:  0.003199596656486392
Epoch:  67  	Training Loss: 0.003108309581875801
Test Loss:  0.0024673896841704845
Valid Loss:  0.0031864363700151443
Epoch:  68  	Training Loss: 0.003098741639405489
Test Loss:  0.0024596224538981915
Valid Loss:  0.0031744875013828278
Epoch:  69  	Training Loss: 0.0030901487916707993
Test Loss:  0.002452580723911524
Valid Loss:  0.0031635684426873922
Epoch:  70  	Training Loss: 0.0030824104323983192
Test Loss:  0.002446199767291546
Valid Loss:  0.0031535832677036524
Epoch:  71  	Training Loss: 0.0030754292383790016
Test Loss:  0.0024402476847171783
Valid Loss:   14%|█▍        | 71/500 [00:59<08:23,  1.17s/it] 15%|█▍        | 73/500 [01:00<06:00,  1.19it/s] 15%|█▌        | 75/500 [01:00<04:19,  1.64it/s] 15%|█▌        | 77/500 [01:00<03:09,  2.23it/s] 16%|█▌        | 79/500 [01:00<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:07<08:34,  1.23s/it] 17%|█▋        | 83/500 [01:07<06:07,  1.14it/s] 17%|█▋        | 85/500 [01:07<04:23,  1.57it/s] 17%|█▋        | 87/500 [01:07<03:12,  2.15it/s] 18%|█▊        | 89/500 [01:07<02:22,  2.89it/s] 18%|█▊        | 91/500 [01:14<08:14,  1.21s/it] 19%|█▊        | 93/500 [01:14<05:53,  1.15it/s] 19%|█▉        | 95/500 [01:14<04:14,  1.59it/s] 19%|█▉        | 97/500 [01:14<03:05,  2.18it/s] 20%|█▉        | 99/500 [01:14<02:17,  2.92it/s] 20%|██        | 101/500 [01:20<07:53,  1.19s/it] 21%|██        | 103/500 [01:21<05:38,  1.17it/s] 21%|██        | 105/500 [01:21<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:21<02:57,  2.21it/s] 22%|██▏       | 109/500 [01:21<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:27<07:36,  1.17s/it] 23%|██▎       | 113/500 [01:27<05:26,  1.19it/s] 23%|██▎       | 115/500 [01:34<10:04,  1.57s/it] 23%|██▎       | 117/500 [01:34<07:09,  1.12s/it] 24%|██▍       | 119/500 [01:34<05:06,  1.24it/s] 24%|██▍       | 121/500 [01:41<09:31,  1.51s/it] 25%|██▍       | 123/500 [01:41<06:45,  1.07s/it] 25%|██▌       | 125/500 [01:41<04:49,  1.30it/s] 25%|██▌       | 127/500 [01:41<03:28,  1.79it/s] 26%|██▌       | 129/500 [01:41<02:32,  2.43it/s] 26%|██▌       | 131/500 [01:47<07:28,  1.22s/it] 27%|██▋       | 133/500 [01:47<05:20,  1.15it/s] 27%|██▋       | 135/500 [01:48<03:50,  1.59it/s] 27%|██▋       | 137/500 [01:48<02:47,  2.17it/s] 28%|██▊       | 139/500 [01:48<02:04,  2.91it/s]0.003144440706819296
Epoch:  72  	Training Loss: 0.003069124184548855
Test Loss:  0.0023183668963611126
Valid Loss:  0.002964275423437357
Epoch:  73  	Training Loss: 0.00291314534842968
Test Loss:  0.002223316580057144
Valid Loss:  0.0028360115829855204
Epoch:  74  	Training Loss: 0.0028002329636365175
Test Loss:  0.0021458829287439585
Valid Loss:  0.0027309972792863846
Epoch:  75  	Training Loss: 0.0027132206596434116
Test Loss:  0.0020799003541469574
Valid Loss:  0.002640531398355961
Epoch:  76  	Training Loss: 0.0026440999936312437
Test Loss:  0.0020250119268894196
Valid Loss:  0.002564599271863699
Epoch:  77  	Training Loss: 0.0025891526602208614
Test Loss:  0.00197790190577507
Valid Loss:  0.002497071633115411
Epoch:  78  	Training Loss: 0.00254345266148448
Test Loss:  0.001942673814482987
Valid Loss:  0.0024433780927211046
Epoch:  79  	Training Loss: 0.0025049971882253885
Test Loss:  0.001911700121127069
Valid Loss:  0.0024005009327083826
Epoch:  80  	Training Loss: 0.002471785293892026
Test Loss:  0.0018897061236202717
Valid Loss:  0.00236494280397892
Epoch:  81  	Training Loss: 0.0024442183785140514
Test Loss:  0.0018741362728178501
Valid Loss:  0.0023315143771469593
Epoch:  82  	Training Loss: 0.002418415155261755
Test Loss:  0.0018662334186956286
Valid Loss:  0.0023197117261588573
Epoch:  83  	Training Loss: 0.002406457206234336
Test Loss:  0.0018588341772556305
Valid Loss:  0.0023057335056364536
Epoch:  84  	Training Loss: 0.0023951209150254726
Test Loss:  0.0018525200430303812
Valid Loss:  0.0022901766933500767
Epoch:  85  	Training Loss: 0.0023845818359404802
Test Loss:  0.0018473246600478888
Valid Loss:  0.0022763314191251993
Epoch:  86  	Training Loss: 0.0023751112166792154
Test Loss:  0.001842615776695311
Valid Loss:  0.0022636803332716227
Epoch:  87  	Training Loss: 0.002366576110944152
Test Loss:  0.0018382694106549025
Valid Loss:  0.0022514970041811466
Epoch:  88  	Training Loss: 0.002358424011617899
Test Loss:  0.0018342750845476985
Valid Loss:  0.0022397367283701897
Epoch:  89  	Training Loss: 0.002350584603846073
Test Loss:  0.0018304928671568632
Valid Loss:  0.0022283182479441166
Epoch:  90  	Training Loss: 0.0023430343717336655
Test Loss:  0.001826989115215838
Valid Loss:  0.002213146537542343
Epoch:  91  	Training Loss: 0.002335753757506609
Test Loss:  0.001823002123273909
Valid Loss:  0.002198249101638794
Epoch:  92  	Training Loss: 0.0023287334479391575
Test Loss:  0.0018099936423823237
Valid Loss:  0.0022056414745748043
Epoch:  93  	Training Loss: 0.0023280074819922447
Test Loss:  0.0018182650674134493
Valid Loss:  0.002202351577579975
Epoch:  94  	Training Loss: 0.0023274999111890793
Test Loss:  0.0018147286027669907
Valid Loss:  0.0022049909457564354
Epoch:  95  	Training Loss: 0.002327101770788431
Test Loss:  0.0018168139504268765
Valid Loss:  0.002204794902354479
Epoch:  96  	Training Loss: 0.0023267590440809727
Test Loss:  0.0018163833301514387
Valid Loss:  0.002205910626798868
Epoch:  97  	Training Loss: 0.0023264503106474876
Test Loss:  0.0018171612173318863
Valid Loss:  0.002206390257924795
Epoch:  98  	Training Loss: 0.0023261739406734705
Test Loss:  0.0018173318821936846
Valid Loss:  0.002207051031291485
Epoch:  99  	Training Loss: 0.002325922716408968
Test Loss:  0.001817889977246523
Valid Loss:  0.002207579556852579
Epoch:  100  	Training Loss: 0.002325694542378187
Test Loss:  0.0018180932383984327
Valid Loss:  0.0022082594223320484
Epoch:  101  	Training Loss: 0.002325486857444048
Test Loss:  0.0018183989450335503
Valid Loss:  0.002208751393482089
Epoch:  102  	Training Loss: 0.002325296401977539
Test Loss:  0.0018267682753503323
Valid Loss:  0.002207670360803604
Epoch:  103  	Training Loss: 0.0023249993100762367
Test Loss:  0.0018248812993988395
Valid Loss:  0.0022083839867264032
Epoch:  104  	Training Loss: 0.002324858447536826
Test Loss:  0.001825007377192378
Valid Loss:  0.002208756050094962
Epoch:  105  	Training Loss: 0.0023247282952070236
Test Loss:  0.001824751729145646
Valid Loss:  0.0022091686259955168
Epoch:  106  	Training Loss: 0.0023246046621352434
Test Loss:  0.0018245709361508489
Valid Loss:  0.002209545113146305
Epoch:  107  	Training Loss: 0.0023244840558618307
Test Loss:  0.0018243821104988456
Valid Loss:  0.002209901809692383
Epoch:  108  	Training Loss: 0.002324356697499752
Test Loss:  0.0018241681391373277
Valid Loss:  0.0022101430222392082
Epoch:  109  	Training Loss: 0.002324196044355631
Test Loss:  0.001823963364586234
Valid Loss:  0.0022103458177298307
Epoch:  110  	Training Loss: 0.002324038418009877
Test Loss:  0.001823752885684371
Valid Loss:  0.002210527891293168
Epoch:  111  	Training Loss: 0.0023238840512931347
Test Loss:  0.0018235488096252084
Valid Loss:  0.0022106971591711044
Epoch:  112  	Training Loss: 0.00232371361926198
Test Loss:  0.0018165416549891233
Valid Loss:  0.0022149248979985714
Epoch:  113  	Training Loss: 0.002323716413229704
Test Loss:  0.0018266564002260566
Valid Loss:  0.002209374448284507
Epoch:  114  	Training Loss: 0.002323758788406849
Test Loss:  0.0018125658389180899
Valid Loss:  0.002217838540673256
Epoch:  115  	Training Loss: 0.0023238761350512505
Test Loss:  0.0018331165192648768
Valid Loss:  0.0022066349629312754
**************************************************learning rate decay**************************************************
Epoch:  116  	Training Loss: 0.0023241452872753143
Test Loss:  0.0018224813975393772
Valid Loss:  0.002202235860750079
Epoch:  117  	Training Loss: 0.0023202139418572187
Test Loss:  0.0018156880978494883
Valid Loss:  0.0021962597966194153
Epoch:  118  	Training Loss: 0.002316728001460433
Test Loss:  0.0018108431249856949
Valid Loss:  0.002189408056437969
Epoch:  119  	Training Loss: 0.0023133973591029644
Test Loss:  0.0018066760385408998
Valid Loss:  0.0021823327988386154
Epoch:  120  	Training Loss: 0.0023101395927369595
Test Loss:  0.0018028577324002981
Valid Loss:  0.0021752226166427135
Epoch:  121  	Training Loss: 0.002306950744241476
Test Loss:  0.0017992351204156876
Valid Loss:  0.0021681629586964846
Epoch:  122  	Training Loss: 0.0023038238286972046
Test Loss:  0.0018030510982498527
Valid Loss:  0.0021630004048347473
Epoch:  123  	Training Loss: 0.0023017930798232555
Test Loss:  0.0017955813091248274
Valid Loss:  0.002166168764233589
Epoch:  124  	Training Loss: 0.002300797961652279
Test Loss:  0.0017996345413848758
Valid Loss:  0.0021646267268806696
Epoch:  125  	Training Loss: 0.00230071390978992
Test Loss:  0.0017965345177799463
Valid Loss:  0.002166522666811943
Epoch:  126  	Training Loss: 0.0023004820104688406
Test Loss:  0.0017995660891756415
Valid Loss:  0.002165547339245677
Epoch:  127  	Training Loss: 0.002300480380654335
Test Loss:  0.0017969803884625435
Valid Loss:  0.0021673329174518585
Epoch:  128  	Training Loss: 0.002300419844686985
Test Loss:  0.0017998793628066778
Valid Loss:  0.002166266553103924
Epoch:  129  	Training Loss: 0.0023003784008324146
Test Loss:  0.0017973219510167837
Valid Loss:  0.002167890314012766
Epoch:  130  	Training Loss: 0.002300283871591091
Test Loss:  0.0017998646944761276
Valid Loss:  0.002166982041671872
Epoch:  131  	Training Loss: 0.0023002366069704294
Test Loss:  0.0017976369708776474
Valid Loss:  0.0021684663370251656
Epoch:  132  	Training Loss: 0.0023002170491963625
Test Loss:  0.0018001748248934746
Valid Loss:  0.002167525002732873
Epoch:  133  	Training Loss: 0.002300166292116046
Test Loss:  0.001797125325538218
Valid Loss:  0.0021693408489227295
Epoch:  134  	Training Loss: 0.0023001038935035467
Test Loss:  0.0018004134763032198
Valid Loss:  0.002168075181543827
Epoch:  135  	Training Loss: 0.0023001092486083508
Test Loss:  0.0017971365014091134
Valid Loss:  0.0021699308417737484
Epoch:  136  	Training Loss: 0.0023000347428023815
Test Loss:  0.0018005025340244174
Valid Loss:  0.0021685389801859856
Epoch:  137  	Training Loss: 0.002300023101270199
Test Loss:  0.0017971957568079233
Valid Loss:  0.0021703499369323254
Epoch:  138  	Training Loss: 0.00229995371773839
Test Loss:  0.0018005510792136192
Valid Loss:  0.0021689189597964287
Epoch:  139  	Training Loss: 0.0022999579086899757
Test Loss:  0.001797192613594234
Valid Loss:  0.0021706754341721535
 28%|██▊       | 141/500 [02:00<12:26,  2.08s/it] 29%|██▊       | 143/500 [02:00<08:47,  1.48s/it] 29%|██▉       | 145/500 [02:00<06:14,  1.05s/it] 29%|██▉       | 147/500 [02:00<04:27,  1.32it/s] 30%|██▉       | 149/500 [02:01<03:12,  1.82it/s] 30%|███       | 151/500 [02:07<07:46,  1.34s/it] 31%|███       | 153/500 [02:07<05:32,  1.04it/s] 31%|███       | 155/500 [02:07<03:58,  1.45it/s] 31%|███▏      | 157/500 [02:07<02:52,  1.99it/s] 32%|███▏      | 159/500 [02:07<02:06,  2.69it/s] 32%|███▏      | 161/500 [02:14<06:43,  1.19s/it] 33%|███▎      | 163/500 [02:14<04:47,  1.17it/s] 33%|███▎      | 165/500 [02:14<03:26,  1.62it/s] 33%|███▎      | 167/500 [02:14<02:30,  2.21it/s] 34%|███▍      | 169/500 [02:14<01:51,  2.98it/s] 34%|███▍      | 171/500 [02:21<06:27,  1.18s/it] 35%|███▍      | 173/500 [02:21<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:21<03:18,  1.63it/s] 35%|███▌      | 177/500 [02:21<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:21<01:47,  2.99it/s] 36%|███▌      | 181/500 [02:27<06:12,  1.17s/it] 37%|███▋      | 183/500 [02:27<04:25,  1.19it/s] 37%|███▋      | 185/500 [02:28<03:11,  1.65it/s] 37%|███▋      | 187/500 [02:28<02:19,  2.25it/s] 38%|███▊      | 189/500 [02:28<01:43,  3.02it/s] 38%|███▊      | 191/500 [02:34<06:01,  1.17s/it] 39%|███▊      | 193/500 [02:34<04:17,  1.19it/s] 39%|███▉      | 195/500 [02:34<03:05,  1.64it/s] 39%|███▉      | 197/500 [02:34<02:14,  2.25it/s] 40%|███▉      | 199/500 [02:35<01:39,  3.02it/s] 40%|████      | 201/500 [02:41<05:46,  1.16s/it] 41%|████      | 203/500 [02:41<04:07,  1.20it/s] 41%|████      | 205/500 [02:41<02:58,  1.66it/s]Epoch:  140  	Training Loss: 0.002299865707755089
Test Loss:  0.0018003780860453844
Valid Loss:  0.0021692754235118628
**************************************************learning rate decay**************************************************
Epoch:  141  	Training Loss: 0.0022998442873358727
Test Loss:  0.001799817313440144
Valid Loss:  0.002169561805203557
Epoch:  142  	Training Loss: 0.002299815881997347
Test Loss:  0.0017998004332184792
Valid Loss:  0.002169567160308361
Epoch:  143  	Training Loss: 0.002299802377820015
Test Loss:  0.0017997719114646316
Valid Loss:  0.0021695769391953945
Epoch:  144  	Training Loss: 0.002299790969118476
Test Loss:  0.0017997354734688997
Valid Loss:  0.0021695862524211407
Epoch:  145  	Training Loss: 0.002299778163433075
Test Loss:  0.0017996919341385365
Valid Loss:  0.0021695978939533234
Epoch:  146  	Training Loss: 0.0022997651249170303
Test Loss:  0.0017996418755501509
Valid Loss:  0.002169606741517782
Epoch:  147  	Training Loss: 0.0022997520864009857
Test Loss:  0.0017995946109294891
Valid Loss:  0.002169618383049965
Epoch:  148  	Training Loss: 0.002299739047884941
Test Loss:  0.001799539546482265
Valid Loss:  0.0021696293260902166
Epoch:  149  	Training Loss: 0.0022997288033366203
Test Loss:  0.0017994826193898916
Valid Loss:  0.0021696416661143303
Epoch:  150  	Training Loss: 0.002299715531989932
Test Loss:  0.0017994255758821964
Valid Loss:  0.0021696521434932947
Epoch:  151  	Training Loss: 0.0022997045889496803
Test Loss:  0.0017993676010519266
Valid Loss:  0.002169665414839983
Epoch:  152  	Training Loss: 0.002299692016094923
Test Loss:  0.0017989195184782147
Valid Loss:  0.0021693366579711437
Epoch:  153  	Training Loss: 0.0022993492893874645
Test Loss:  0.0017985454760491848
Valid Loss:  0.0021690763533115387
Epoch:  154  	Training Loss: 0.0022990445140749216
Test Loss:  0.0017982280114665627
Valid Loss:  0.0021688665729016066
Epoch:  155  	Training Loss: 0.0022987877018749714
Test Loss:  0.0017979698022827506
Valid Loss:  0.00216874061152339
Epoch:  156  	Training Loss: 0.0022986121475696564
Test Loss:  0.0017977565294131637
Valid Loss:  0.0021686458494514227
Epoch:  157  	Training Loss: 0.0022984864190220833
Test Loss:  0.0017975838854908943
Valid Loss:  0.0021685739047825336
Epoch:  158  	Training Loss: 0.0022983886301517487
Test Loss:  0.0017974512884393334
Valid Loss:  0.002168535953387618
Epoch:  159  	Training Loss: 0.002298309002071619
Test Loss:  0.0017973626963794231
Valid Loss:  0.0021685082465410233
Epoch:  160  	Training Loss: 0.0022982433438301086
Test Loss:  0.0017972923815250397
Valid Loss:  0.002168494276702404
Epoch:  161  	Training Loss: 0.0022982005029916763
Test Loss:  0.001797234988771379
Valid Loss:  0.002168488223105669
Epoch:  162  	Training Loss: 0.0022981716319918633
Test Loss:  0.001794736715964973
Valid Loss:  0.0021651415154337883
Epoch:  163  	Training Loss: 0.002296437043696642
Test Loss:  0.0017931718612089753
Valid Loss:  0.002161551732569933
Epoch:  164  	Training Loss: 0.0022949075791984797
Test Loss:  0.0017918790690600872
Valid Loss:  0.0021578746382147074
Epoch:  165  	Training Loss: 0.002293392550200224
Test Loss:  0.001790207577869296
Valid Loss:  0.002154408022761345
Epoch:  166  	Training Loss: 0.002291893819347024
Test Loss:  0.0017888916190713644
Valid Loss:  0.0021508149802684784
Epoch:  167  	Training Loss: 0.0022904048673808575
Test Loss:  0.0017872763564810157
Valid Loss:  0.0021473930682986975
Epoch:  168  	Training Loss: 0.0022889345418661833
Test Loss:  0.0017859559739008546
Valid Loss:  0.0021438817493617535
Epoch:  169  	Training Loss: 0.0022874826099723577
Test Loss:  0.0017843358218669891
Valid Loss:  0.002140538999810815
Epoch:  170  	Training Loss: 0.0022860397584736347
Test Loss:  0.0017830152064561844
Valid Loss:  0.0021371012553572655
Epoch:  171  	Training Loss: 0.0022846166975796223
Test Loss:  0.001781402388587594
Valid Loss:  0.0021338302176445723
Epoch:  172  	Training Loss: 0.0022832038812339306
Test Loss:  0.0017814357997849584
Valid Loss:  0.0021338704973459244
Epoch:  173  	Training Loss: 0.002283187583088875
Test Loss:  0.001781451515853405
Valid Loss:  0.0021339119412004948
Epoch:  174  	Training Loss: 0.002283172681927681
Test Loss:  0.0017814594320952892
Valid Loss:  0.002133953385055065
Epoch:  175  	Training Loss: 0.0022831554524600506
Test Loss:  0.0017814578022807837
Valid Loss:  0.002133995294570923
Epoch:  176  	Training Loss: 0.0022831407841295004
Test Loss:  0.0017814484890550375
Valid Loss:  0.0021340404637157917
Epoch:  177  	Training Loss: 0.0022831247188150883
Test Loss:  0.0017814356833696365
Valid Loss:  0.0021340842358767986
Epoch:  178  	Training Loss: 0.0022831098176538944
Test Loss:  0.0017814186867326498
Valid Loss:  0.002134128240868449
Epoch:  179  	Training Loss: 0.002283095382153988
Test Loss:  0.0017813986632972956
Valid Loss:  0.002134172711521387
Epoch:  180  	Training Loss: 0.002283078618347645
Test Loss:  0.0017813758458942175
Valid Loss:  0.0021342148538678885
Epoch:  181  	Training Loss: 0.0022830632515251637
Test Loss:  0.0017813534941524267
Valid Loss:  0.0021342607215046883
Epoch:  182  	Training Loss: 0.0022830392699688673
Test Loss:  0.001795667689293623
Valid Loss:  0.002109177876263857
Epoch:  183  	Training Loss: 0.0022739204578101635
Test Loss:  0.001746956491842866
Valid Loss:  0.002122091595083475
Epoch:  184  	Training Loss: 0.002263996982946992
Test Loss:  0.0017677433788776398
Valid Loss:  0.0021016146056354046
Epoch:  185  	Training Loss: 0.002258721739053726
Test Loss:  0.0017448419239372015
Valid Loss:  0.002107480773702264
Epoch:  186  	Training Loss: 0.0022545126266777515
Test Loss:  0.001760936575010419
Valid Loss:  0.0020935842767357826
Epoch:  187  	Training Loss: 0.0022517116740345955
Test Loss:  0.0017413002206012607
Valid Loss:  0.0020988723263144493
Epoch:  188  	Training Loss: 0.0022484862711280584
Test Loss:  0.001757551566697657
Valid Loss:  0.0020859581418335438
Epoch:  189  	Training Loss: 0.002246381249278784
Test Loss:  0.0017375999595969915
Valid Loss:  0.002091108588501811
Epoch:  190  	Training Loss: 0.0022429306991398335
Test Loss:  0.0017520692199468613
Valid Loss:  0.0020786861423403025
Epoch:  191  	Training Loss: 0.002240376081317663
Test Loss:  0.001734804012812674
Valid Loss:  0.0020833301823586226
Epoch:  192  	Training Loss: 0.002237662672996521
Test Loss:  0.0017440631054341793
Valid Loss:  0.002074663992971182
Epoch:  193  	Training Loss: 0.002236167900264263
Test Loss:  0.0017346604727208614
Valid Loss:  0.00207627285271883
Epoch:  194  	Training Loss: 0.0022346738260239363
Test Loss:  0.0017432759050279856
Valid Loss:  0.0020686567295342684
Epoch:  195  	Training Loss: 0.002233602572232485
Test Loss:  0.0017339137848466635
Valid Loss:  0.002070606919005513
Epoch:  196  	Training Loss: 0.0022324384190142155
Test Loss:  0.0017427974380552769
Valid Loss:  0.002062739571556449
Epoch:  197  	Training Loss: 0.0022313555236905813
Test Loss:  0.0017329397378489375
Valid Loss:  0.002064742613583803
Epoch:  198  	Training Loss: 0.002230084966868162
Test Loss:  0.001741507789120078
Valid Loss:  0.0020570391789078712
Epoch:  199  	Training Loss: 0.002228979952633381
Test Loss:  0.0017318087629973888
Valid Loss:  0.002058688784018159
Epoch:  200  	Training Loss: 0.002227621152997017
Test Loss:  0.001740428269840777
Valid Loss:  0.0020514260977506638
Epoch:  201  	Training Loss: 0.00222682673484087
Test Loss:  0.0017302846536040306
Valid Loss:  0.0020537092350423336
Epoch:  202  	Training Loss: 0.002225737553089857
Test Loss:  0.0017308247042819858
Valid Loss:  0.002053854987025261
Epoch:  203  	Training Loss: 0.0022256593219935894
Test Loss:  0.0017310898983851075
Valid Loss:  0.0020541127305477858
Epoch:  204  	Training Loss: 0.00222558481618762
Test Loss:  0.0017312905983999372
Valid Loss:  0.00205437745898962
Epoch:  205  	Training Loss: 0.0022255154326558113
Test Loss:  0.0017314681317657232
Valid Loss:  0.0020546386949718
Epoch:  206  	Training Loss: 0.0022254507057368755
Test Loss:  0.001731631811708212
Valid Loss:  0.002054889453575015
Epoch:  207  	Training Loss: 0.002225389238446951
Test Loss:  0.0017317847814410925
Valid Loss:   41%|████▏     | 207/500 [02:41<02:09,  2.26it/s] 42%|████▏     | 209/500 [02:41<01:35,  3.03it/s] 42%|████▏     | 211/500 [02:48<05:37,  1.17s/it] 43%|████▎     | 213/500 [02:48<04:01,  1.19it/s] 43%|████▎     | 215/500 [02:48<02:53,  1.64it/s] 43%|████▎     | 217/500 [02:48<02:06,  2.25it/s] 44%|████▍     | 219/500 [02:48<01:33,  3.01it/s] 44%|████▍     | 221/500 [02:55<05:35,  1.20s/it] 45%|████▍     | 223/500 [02:55<03:59,  1.16it/s] 45%|████▌     | 225/500 [02:55<02:51,  1.60it/s] 45%|████▌     | 227/500 [02:55<02:04,  2.18it/s] 46%|████▌     | 229/500 [02:55<01:32,  2.94it/s] 46%|████▌     | 231/500 [03:02<05:23,  1.20s/it] 47%|████▋     | 233/500 [03:02<03:50,  1.16it/s] 47%|████▋     | 235/500 [03:02<02:45,  1.60it/s] 47%|████▋     | 237/500 [03:02<02:00,  2.19it/s] 48%|████▊     | 239/500 [03:02<01:28,  2.95it/s] 48%|████▊     | 241/500 [03:08<05:05,  1.18s/it] 49%|████▊     | 243/500 [03:09<03:37,  1.18it/s] 49%|████▉     | 245/500 [03:09<02:36,  1.63it/s] 49%|████▉     | 247/500 [03:09<01:53,  2.23it/s] 50%|████▉     | 249/500 [03:09<01:23,  3.00it/s] 50%|█████     | 251/500 [03:15<04:50,  1.17s/it] 51%|█████     | 253/500 [03:15<03:26,  1.19it/s] 51%|█████     | 255/500 [03:15<02:28,  1.65it/s] 51%|█████▏    | 257/500 [03:16<01:47,  2.25it/s] 52%|█████▏    | 259/500 [03:16<01:19,  3.03it/s] 52%|█████▏    | 261/500 [03:22<04:37,  1.16s/it] 53%|█████▎    | 263/500 [03:22<03:18,  1.20it/s] 53%|█████▎    | 265/500 [03:22<02:22,  1.65it/s] 53%|█████▎    | 267/500 [03:22<01:43,  2.26it/s] 54%|█████▍    | 269/500 [03:22<01:16,  3.02it/s] 54%|█████▍    | 271/500 [03:29<04:26,  1.16s/it] 55%|█████▍    | 273/500 [03:29<03:09,  1.20it/s] 55%|█████▌    | 275/500 [03:29<02:16,  1.65it/s]0.0020551257766783237
Epoch:  208  	Training Loss: 0.002225331962108612
Test Loss:  0.001731927040964365
Valid Loss:  0.0020553520880639553
Epoch:  209  	Training Loss: 0.002225275617092848
Test Loss:  0.0017320617334917188
Valid Loss:  0.002055567456409335
Epoch:  210  	Training Loss: 0.0022252206690609455
Test Loss:  0.0017321878112852573
Valid Loss:  0.002055773977190256
Epoch:  211  	Training Loss: 0.0022251703776419163
Test Loss:  0.0017323055071756244
Valid Loss:  0.002055969089269638
Epoch:  212  	Training Loss: 0.0022251205518841743
Test Loss:  0.0017309621907770634
Valid Loss:  0.0020550130866467953
Epoch:  213  	Training Loss: 0.0022240737453103065
Test Loss:  0.001730393967591226
Valid Loss:  0.002054546494036913
Epoch:  214  	Training Loss: 0.002223531249910593
Test Loss:  0.0017301775515079498
Valid Loss:  0.0020542340353131294
Epoch:  215  	Training Loss: 0.0022231608163565397
Test Loss:  0.0017300848849117756
Valid Loss:  0.0020539904944598675
Epoch:  216  	Training Loss: 0.002222862094640732
Test Loss:  0.001730081858113408
Valid Loss:  0.0020537786185741425
Epoch:  217  	Training Loss: 0.0022226476576179266
Test Loss:  0.0017301752232015133
Valid Loss:  0.0020536347292363644
Epoch:  218  	Training Loss: 0.002222488634288311
Test Loss:  0.0017302659107372165
Valid Loss:  0.00205351784825325
Epoch:  219  	Training Loss: 0.0022223605774343014
Test Loss:  0.0017303458880633116
Valid Loss:  0.0020534121431410313
Epoch:  220  	Training Loss: 0.0022222469560801983
Test Loss:  0.0017304221400991082
Valid Loss:  0.0020533259958028793
Epoch:  221  	Training Loss: 0.0022221612744033337
Test Loss:  0.0017304928041994572
Valid Loss:  0.0020532547496259212
Epoch:  222  	Training Loss: 0.002222089795395732
Test Loss:  0.0017304725479334593
Valid Loss:  0.002053286647424102
Epoch:  223  	Training Loss: 0.0022220558021217585
Test Loss:  0.0017304499633610249
Valid Loss:  0.002053316216915846
Epoch:  224  	Training Loss: 0.0022220222745090723
Test Loss:  0.0017304329667240381
Valid Loss:  0.0020533506758511066
Epoch:  225  	Training Loss: 0.002221988048404455
Test Loss:  0.0017304089851677418
Valid Loss:  0.002053383272141218
Epoch:  226  	Training Loss: 0.0022219554521143436
Test Loss:  0.001730387913994491
Valid Loss:  0.0020534154027700424
Epoch:  227  	Training Loss: 0.002221922390162945
Test Loss:  0.0017303661443293095
Valid Loss:  0.002053445903584361
Epoch:  228  	Training Loss: 0.0022218869999051094
Test Loss:  0.0017303447239100933
Valid Loss:  0.002053476870059967
Epoch:  229  	Training Loss: 0.0022218534722924232
Test Loss:  0.0017303242348134518
Valid Loss:  0.002053507836535573
Epoch:  230  	Training Loss: 0.002221821341663599
Test Loss:  0.0017303035128861666
Valid Loss:  0.0020535378716886044
Epoch:  231  	Training Loss: 0.0022217868827283382
Test Loss:  0.0017302791820839047
Valid Loss:  0.0020535695366561413
Epoch:  232  	Training Loss: 0.002221754752099514
Test Loss:  0.00173064018599689
Valid Loss:  0.002053567674010992
Epoch:  233  	Training Loss: 0.0022217463701963425
Test Loss:  0.0017308583483099937
Valid Loss:  0.002053607953712344
Epoch:  234  	Training Loss: 0.0022217414807528257
Test Loss:  0.0017310003750026226
Valid Loss:  0.0020536731462925673
Epoch:  235  	Training Loss: 0.002221735194325447
Test Loss:  0.0017310967668890953
Valid Loss:  0.00205374788492918
Epoch:  236  	Training Loss: 0.0022217314690351486
Test Loss:  0.0017311734845861793
Valid Loss:  0.0020538289099931717
Epoch:  237  	Training Loss: 0.0022217268124222755
Test Loss:  0.0017312392592430115
Valid Loss:  0.0020539076067507267
Epoch:  238  	Training Loss: 0.0022217242512851954
Test Loss:  0.001731289317831397
Valid Loss:  0.002053986769169569
Epoch:  239  	Training Loss: 0.0022217195946723223
Test Loss:  0.00173133984208107
Valid Loss:  0.0020540582481771708
Epoch:  240  	Training Loss: 0.0022217142395675182
Test Loss:  0.0017313843127340078
Valid Loss:  0.0020541336853057146
Epoch:  241  	Training Loss: 0.0022217133082449436
Test Loss:  0.001731428550556302
Valid Loss:  0.0020542005077004433
Epoch:  242  	Training Loss: 0.002221709582954645
Test Loss:  0.0017285002395510674
Valid Loss:  0.00204751780256629
Epoch:  243  	Training Loss: 0.002218175446614623
Test Loss:  0.0017254792619496584
Valid Loss:  0.0020409724675118923
Epoch:  244  	Training Loss: 0.0022147870622575283
Test Loss:  0.0017224515322595835
Valid Loss:  0.002034595934674144
Epoch:  245  	Training Loss: 0.0022115297615528107
Test Loss:  0.00171961123123765
Valid Loss:  0.0020287849474698305
Epoch:  246  	Training Loss: 0.0022087018005549908
Test Loss:  0.0017168187769129872
Valid Loss:  0.0020230854861438274
Epoch:  247  	Training Loss: 0.0022059313487261534
Test Loss:  0.001714076497592032
Valid Loss:  0.00201749661937356
Epoch:  248  	Training Loss: 0.0022032209672033787
Test Loss:  0.0017113890498876572
Valid Loss:  0.002012014389038086
Epoch:  249  	Training Loss: 0.0022005662322044373
Test Loss:  0.00170875433832407
Valid Loss:  0.0020066334400326014
Epoch:  250  	Training Loss: 0.002197965979576111
Test Loss:  0.0017061664257198572
Valid Loss:  0.002001355402171612
Epoch:  251  	Training Loss: 0.0021954202093183994
Test Loss:  0.001703632646240294
Valid Loss:  0.001996175618842244
Epoch:  252  	Training Loss: 0.0021929265931248665
Test Loss:  0.0017030237941071391
Valid Loss:  0.0019936400931328535
Epoch:  253  	Training Loss: 0.002191696083173156
Test Loss:  0.0017022306565195322
Valid Loss:  0.0019912011921405792
Epoch:  254  	Training Loss: 0.0021904786117374897
Test Loss:  0.001701335422694683
Valid Loss:  0.001988826785236597
Epoch:  255  	Training Loss: 0.0021892741788178682
Test Loss:  0.0017003887332975864
Valid Loss:  0.0019864991772919893
Epoch:  256  	Training Loss: 0.002188080223277211
Test Loss:  0.0016994159668684006
Valid Loss:  0.0019842050969600677
Epoch:  257  	Training Loss: 0.0021868948824703693
Test Loss:  0.001698434934951365
Valid Loss:  0.001981940120458603
Epoch:  258  	Training Loss: 0.0021857270039618015
Test Loss:  0.001697454834356904
Valid Loss:  0.001979696797206998
Epoch:  259  	Training Loss: 0.0021846024319529533
Test Loss:  0.0016966285184025764
Valid Loss:  0.0019778679125010967
Epoch:  260  	Training Loss: 0.002183781238272786
Test Loss:  0.0016958252526819706
Valid Loss:  0.001976048108190298
Epoch:  261  	Training Loss: 0.0021829730831086636
Test Loss:  0.0016950343269854784
Valid Loss:  0.001974237384274602
Epoch:  262  	Training Loss: 0.0021821726113557816
Test Loss:  0.001693676458671689
Valid Loss:  0.001969732576981187
Epoch:  263  	Training Loss: 0.002180189359933138
Test Loss:  0.0016921162605285645
Valid Loss:  0.0019653779454529285
Epoch:  264  	Training Loss: 0.0021782550029456615
Test Loss:  0.001690469216555357
Valid Loss:  0.001961152534931898
Epoch:  265  	Training Loss: 0.0021763648837804794
Test Loss:  0.0016887970268726349
Valid Loss:  0.001957031898200512
Epoch:  266  	Training Loss: 0.002174519468098879
Test Loss:  0.0016871094703674316
Valid Loss:  0.001953002531081438
Epoch:  267  	Training Loss: 0.0021727047860622406
Test Loss:  0.0016854351852089167
Valid Loss:  0.001949040568433702
Epoch:  268  	Training Loss: 0.002170923165977001
Test Loss:  0.0016837763832882047
Valid Loss:  0.0019451603293418884
Epoch:  269  	Training Loss: 0.0021691741421818733
Test Loss:  0.0016821498284116387
Valid Loss:  0.0019413420232012868
Epoch:  270  	Training Loss: 0.0021674553863704205
Test Loss:  0.0016805368941277266
Valid Loss:  0.0019375968258827925
Epoch:  271  	Training Loss: 0.002165765967220068
Test Loss:  0.0016789536457508802
Valid Loss:  0.001933908904902637
Epoch:  272  	Training Loss: 0.0021641049534082413
Test Loss:  0.0016785751795396209
Valid Loss:  0.001934360945597291
Epoch:  273  	Training Loss: 0.002164058154448867
Test Loss:  0.0016785236075520515
Valid Loss:  0.001934695988893509
Epoch:  274  	Training Loss: 0.002164018340408802
Test Loss:  0.0016785970656201243
Valid Loss:  0.0019349857466295362
Epoch:  275  	Training Loss: 0.0021639871411025524
Test Loss:  0.0016787128988653421
Valid Loss:  0.0019352496601641178
Epoch:  276  	Training Loss: 0.00216395640745759
Test Loss:  0.0016788425855338573
 55%|█████▌    | 277/500 [03:29<01:38,  2.26it/s] 56%|█████▌    | 279/500 [03:29<01:12,  3.03it/s] 56%|█████▌    | 281/500 [03:35<04:15,  1.17s/it] 57%|█████▋    | 283/500 [03:36<03:01,  1.19it/s] 57%|█████▋    | 285/500 [03:36<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:36<01:34,  2.25it/s] 58%|█████▊    | 289/500 [03:36<01:09,  3.03it/s] 58%|█████▊    | 291/500 [03:42<04:06,  1.18s/it] 59%|█████▊    | 293/500 [03:42<02:55,  1.18it/s] 59%|█████▉    | 295/500 [03:43<02:05,  1.63it/s] 59%|█████▉    | 297/500 [03:43<01:30,  2.23it/s] 60%|█████▉    | 299/500 [03:43<01:06,  3.00it/s] 60%|██████    | 301/500 [03:49<03:53,  1.17s/it] 61%|██████    | 303/500 [03:49<02:46,  1.19it/s] 61%|██████    | 305/500 [03:49<01:59,  1.64it/s] 61%|██████▏   | 307/500 [03:50<01:26,  2.24it/s] 62%|██████▏   | 309/500 [03:50<01:03,  3.00it/s] 62%|██████▏   | 311/500 [03:56<03:46,  1.20s/it] 63%|██████▎   | 313/500 [03:56<02:41,  1.16it/s] 63%|██████▎   | 315/500 [03:56<01:55,  1.60it/s] 63%|██████▎   | 317/500 [03:57<01:23,  2.18it/s] 64%|██████▍   | 319/500 [03:57<01:01,  2.94it/s] 64%|██████▍   | 321/500 [04:03<03:30,  1.18s/it] 65%|██████▍   | 323/500 [04:03<02:29,  1.18it/s] 65%|██████▌   | 325/500 [04:03<01:46,  1.64it/s] 65%|██████▌   | 327/500 [04:03<01:17,  2.24it/s] 66%|██████▌   | 329/500 [04:03<00:56,  3.01it/s] 66%|██████▌   | 331/500 [04:10<03:17,  1.17s/it] 67%|██████▋   | 333/500 [04:10<02:19,  1.19it/s] 67%|██████▋   | 335/500 [04:10<01:40,  1.65it/s] 67%|██████▋   | 337/500 [04:10<01:12,  2.25it/s] 68%|██████▊   | 339/500 [04:10<00:53,  3.02it/s] 68%|██████▊   | 341/500 [04:16<03:06,  1.17s/it] 69%|██████▊   | 343/500 [04:17<02:12,  1.19it/s]Valid Loss:  0.0019354871474206448
Epoch:  277  	Training Loss: 0.002163931727409363
Test Loss:  0.0016789716901257634
Valid Loss:  0.001935711596161127
Epoch:  278  	Training Loss: 0.0021639077458530664
Test Loss:  0.001679095788858831
Valid Loss:  0.001935920212417841
Epoch:  279  	Training Loss: 0.0021638870239257812
Test Loss:  0.001679214183241129
Valid Loss:  0.0019361167214810848
Epoch:  280  	Training Loss: 0.002163869794458151
Test Loss:  0.001679329085163772
Valid Loss:  0.0019363017054274678
Epoch:  281  	Training Loss: 0.0021638525649905205
Test Loss:  0.0016794351395219564
Valid Loss:  0.0019364735344424844
Epoch:  282  	Training Loss: 0.0021638385951519012
Test Loss:  0.0016791722737252712
Valid Loss:  0.0019366096239537
Epoch:  283  	Training Loss: 0.0021638344042003155
Test Loss:  0.0016789669170975685
Valid Loss:  0.0019367148634046316
Epoch:  284  	Training Loss: 0.0021638309117406607
Test Loss:  0.0016788034699857235
Valid Loss:  0.0019367951899766922
Epoch:  285  	Training Loss: 0.0021638297475874424
Test Loss:  0.0016786762280389667
Valid Loss:  0.0019368623616173863
Epoch:  286  	Training Loss: 0.002163826022297144
Test Loss:  0.0016785758780315518
Valid Loss:  0.0019369112560525537
Epoch:  287  	Training Loss: 0.0021638248581439257
Test Loss:  0.0016784989275038242
Valid Loss:  0.0019369517685845494
Epoch:  288  	Training Loss: 0.0021638241596519947
Test Loss:  0.0016784362960606813
Valid Loss:  0.0019369819201529026
Epoch:  289  	Training Loss: 0.002163821831345558
Test Loss:  0.001678386121056974
Valid Loss:  0.0019370063673704863
Epoch:  290  	Training Loss: 0.002163819968700409
Test Loss:  0.0016783501487225294
Valid Loss:  0.0019370235968381166
Epoch:  291  	Training Loss: 0.0021638195030391216
Test Loss:  0.001678317436017096
Valid Loss:  0.0019370345398783684
Epoch:  292  	Training Loss: 0.0021638183388859034
Test Loss:  0.0016749599017202854
Valid Loss:  0.0019343586172908545
Epoch:  293  	Training Loss: 0.0021606548689305782
Test Loss:  0.0016740441787987947
Valid Loss:  0.0019327691989019513
Epoch:  294  	Training Loss: 0.0021589945536106825
Test Loss:  0.0016739300917834044
Valid Loss:  0.0019318618578836322
Epoch:  295  	Training Loss: 0.002158138435333967
Test Loss:  0.0016740151913836598
Valid Loss:  0.0019311548676341772
Epoch:  296  	Training Loss: 0.0021576695144176483
Test Loss:  0.0016743034357205033
Valid Loss:  0.0019307263428345323
Epoch:  297  	Training Loss: 0.0021575060673058033
Test Loss:  0.0016746565233916044
Valid Loss:  0.0019305141177028418
Epoch:  298  	Training Loss: 0.0021574459969997406
Test Loss:  0.0016749654896557331
Valid Loss:  0.0019303075969219208
Epoch:  299  	Training Loss: 0.00215739943087101
Test Loss:  0.0016752402298152447
Valid Loss:  0.0019301562570035458
Epoch:  300  	Training Loss: 0.0021573612466454506
Test Loss:  0.001675478066317737
Valid Loss:  0.0019300084095448256
Epoch:  301  	Training Loss: 0.0021573330741375685
Test Loss:  0.001675695413723588
Valid Loss:  0.0019299585837870836
Epoch:  302  	Training Loss: 0.002157315844669938
Test Loss:  0.001676503336057067
Valid Loss:  0.00192961934953928
Epoch:  303  	Training Loss: 0.0021573067642748356
Test Loss:  0.0016769255744293332
Valid Loss:  0.001929441117681563
Epoch:  304  	Training Loss: 0.0021573046687990427
Test Loss:  0.0016771438531577587
Valid Loss:  0.0019293493824079633
Epoch:  305  	Training Loss: 0.0021573039703071117
Test Loss:  0.0016772558446973562
Valid Loss:  0.0019292919896543026
Epoch:  306  	Training Loss: 0.0021573028061538935
Test Loss:  0.0016773082315921783
Valid Loss:  0.0019292610231786966
Epoch:  307  	Training Loss: 0.002157301874831319
Test Loss:  0.0016773347742855549
Valid Loss:  0.0019292441429570317
Epoch:  308  	Training Loss: 0.0021573028061538935
Test Loss:  0.0016773445531725883
Valid Loss:  0.0019292292417958379
Epoch:  309  	Training Loss: 0.00215730257332325
Test Loss:  0.0016773487441241741
Valid Loss:  0.0019292178330942988
Epoch:  310  	Training Loss: 0.002157303038984537
Test Loss:  0.0016773466486483812
Valid Loss:  0.0019292093347758055
Epoch:  311  	Training Loss: 0.00215730257332325
Test Loss:  0.001677344087511301
Valid Loss:  0.0019292046781629324
Epoch:  312  	Training Loss: 0.0021573014091700315
Test Loss:  0.001682586269453168
Valid Loss:  0.0019058238249272108
Epoch:  313  	Training Loss: 0.002144644968211651
Test Loss:  0.0016506812535226345
Valid Loss:  0.0019171873573213816
Epoch:  314  	Training Loss: 0.0021414814982563257
Test Loss:  0.0016623283736407757
Valid Loss:  0.0019108745036646724
Epoch:  315  	Training Loss: 0.00214062025770545
Test Loss:  0.0016522074583917856
Valid Loss:  0.0019152171444147825
Epoch:  316  	Training Loss: 0.002140311524271965
Test Loss:  0.001658999128267169
Valid Loss:  0.0019122968660667539
Epoch:  317  	Training Loss: 0.0021400698460638523
Test Loss:  0.0016538375057280064
Valid Loss:  0.0019146109698340297
Epoch:  318  	Training Loss: 0.002139899879693985
Test Loss:  0.0016582959797233343
Valid Loss:  0.0019129487918689847
Epoch:  319  	Training Loss: 0.0021398812532424927
Test Loss:  0.0016541669610887766
Valid Loss:  0.0019148619612678885
Epoch:  320  	Training Loss: 0.0021397853270173073
Test Loss:  0.001658688299357891
Valid Loss:  0.0019131521694362164
Epoch:  321  	Training Loss: 0.0021397657692432404
Test Loss:  0.0016545378603041172
Valid Loss:  0.0019150667358189821
Epoch:  322  	Training Loss: 0.0021396633237600327
Test Loss:  0.0016445424407720566
Valid Loss:  0.001907880650833249
Epoch:  323  	Training Loss: 0.0021321456879377365
Test Loss:  0.0016416452126577497
Valid Loss:  0.0019051044946536422
Epoch:  324  	Training Loss: 0.0021290327422320843
Test Loss:  0.0016403432236984372
Valid Loss:  0.0019031527917832136
Epoch:  325  	Training Loss: 0.0021270043216645718
Test Loss:  0.0016404027119278908
Valid Loss:  0.0019018533639609814
Epoch:  326  	Training Loss: 0.002125837840139866
Test Loss:  0.0016406186623498797
Valid Loss:  0.0019008114468306303
Epoch:  327  	Training Loss: 0.002124952618032694
Test Loss:  0.0016408641822636127
Valid Loss:  0.0018998458981513977
Epoch:  328  	Training Loss: 0.002124264370650053
Test Loss:  0.001641270355321467
Valid Loss:  0.0018990590469911695
Epoch:  329  	Training Loss: 0.0021238522604107857
Test Loss:  0.0016417971346527338
Valid Loss:  0.001898440532386303
Epoch:  330  	Training Loss: 0.002123616635799408
Test Loss:  0.0016423487104475498
Valid Loss:  0.0018979392480105162
Epoch:  331  	Training Loss: 0.002123491372913122
Test Loss:  0.0016429238021373749
Valid Loss:  0.0018975990824401379
Epoch:  332  	Training Loss: 0.0021234271116554737
Test Loss:  0.0016444404609501362
Valid Loss:  0.0018955074483528733
Epoch:  333  	Training Loss: 0.0021227234974503517
Test Loss:  0.0016452108975499868
Valid Loss:  0.0018935904372483492
Epoch:  334  	Training Loss: 0.0021220752969384193
Test Loss:  0.0016454849392175674
Valid Loss:  0.0018917890265583992
Epoch:  335  	Training Loss: 0.0021214508451521397
Test Loss:  0.0016454349970445037
Valid Loss:  0.0018900592112913728
Epoch:  336  	Training Loss: 0.0021208408288657665
Test Loss:  0.0016453691059723496
Valid Loss:  0.0018883770098909736
Epoch:  337  	Training Loss: 0.0021202396601438522
Test Loss:  0.0016454299911856651
Valid Loss:  0.001886736135929823
Epoch:  338  	Training Loss: 0.0021196454763412476
Test Loss:  0.0016454013530164957
Valid Loss:  0.0018851226195693016
Epoch:  339  	Training Loss: 0.0021190603729337454
Test Loss:  0.0016453174175694585
Valid Loss:  0.0018835295923054218
Epoch:  340  	Training Loss: 0.0021184775978326797
Test Loss:  0.0016451957635581493
Valid Loss:  0.0018819582182914019
Epoch:  341  	Training Loss: 0.0021179013419896364
Test Loss:  0.0016450535040348768
Valid Loss:  0.001880778931081295
Epoch:  342  	Training Loss: 0.002117331139743328
Test Loss:  0.0016439510509371758
Valid Loss:  0.0018813684582710266
Epoch:  343  	Training Loss: 0.002117315772920847
Test Loss:  0.0016439688624814153
Valid Loss:  0.001881374977529049
Epoch:  344  	Training Loss: 0.0021173052955418825
Test Loss:  0.0016439894679933786
Valid Loss:  0.0018813759088516235
Epoch:  345  	Training Loss: 0.0021172957494854927 69%|██████▉   | 345/500 [04:17<01:34,  1.64it/s] 69%|██████▉   | 347/500 [04:17<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:17<00:50,  2.99it/s] 70%|███████   | 351/500 [04:23<02:55,  1.18s/it] 71%|███████   | 353/500 [04:23<02:04,  1.18it/s] 71%|███████   | 355/500 [04:24<01:28,  1.63it/s] 71%|███████▏  | 357/500 [04:24<01:04,  2.23it/s] 72%|███████▏  | 359/500 [04:24<00:47,  3.00it/s] 72%|███████▏  | 361/500 [04:30<02:44,  1.18s/it] 73%|███████▎  | 363/500 [04:30<01:56,  1.18it/s] 73%|███████▎  | 365/500 [04:30<01:22,  1.63it/s] 73%|███████▎  | 367/500 [04:31<00:59,  2.23it/s] 74%|███████▍  | 369/500 [04:31<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:37<02:31,  1.18s/it] 75%|███████▍  | 373/500 [04:37<01:47,  1.18it/s] 75%|███████▌  | 375/500 [04:37<01:16,  1.63it/s] 75%|███████▌  | 377/500 [04:37<00:55,  2.23it/s] 76%|███████▌  | 379/500 [04:38<00:40,  2.99it/s] 76%|███████▌  | 381/500 [04:44<02:19,  1.17s/it] 77%|███████▋  | 383/500 [04:44<01:38,  1.18it/s] 77%|███████▋  | 385/500 [04:44<01:10,  1.64it/s] 77%|███████▋  | 387/500 [04:44<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:44<00:37,  2.99it/s] 78%|███████▊  | 391/500 [04:51<02:08,  1.18s/it] 79%|███████▊  | 393/500 [04:51<01:30,  1.18it/s] 79%|███████▉  | 395/500 [04:51<01:04,  1.63it/s] 79%|███████▉  | 397/500 [04:51<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:51<00:33,  2.99it/s] 80%|████████  | 401/500 [04:58<01:58,  1.19s/it] 81%|████████  | 403/500 [04:58<01:22,  1.17it/s] 81%|████████  | 405/500 [04:58<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:58<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:58<00:30,  2.97it/s] 82%|████████▏ | 411/500 [05:05<01:46,  1.19s/it] 83%|████████▎ | 413/500 [05:05<01:14,  1.17it/s]
Test Loss:  0.0016440150793641806
Valid Loss:  0.0018813792848959565
Epoch:  346  	Training Loss: 0.0021172864362597466
Test Loss:  0.001644041738472879
Valid Loss:  0.0018813831266015768
Epoch:  347  	Training Loss: 0.002117276657372713
Test Loss:  0.001644063275307417
Valid Loss:  0.0018813835922628641
Epoch:  348  	Training Loss: 0.00211726943962276
Test Loss:  0.0016440900508314371
Valid Loss:  0.0018813885981217027
Epoch:  349  	Training Loss: 0.0021172575652599335
Test Loss:  0.001644112286157906
Valid Loss:  0.0018813908100128174
Epoch:  350  	Training Loss: 0.0021172496490180492
Test Loss:  0.0016441363841295242
Valid Loss:  0.0018813933711498976
Epoch:  351  	Training Loss: 0.0021172401029616594
Test Loss:  0.0016441629268229008
Valid Loss:  0.0018813956994563341
Epoch:  352  	Training Loss: 0.0021172293927520514
Test Loss:  0.0016444174107164145
Valid Loss:  0.001881372183561325
Epoch:  353  	Training Loss: 0.002117224968969822
Test Loss:  0.0016445772489532828
Valid Loss:  0.0018813787028193474
Epoch:  354  	Training Loss: 0.0021172212436795235
Test Loss:  0.00164468539878726
Valid Loss:  0.001881396514363587
Epoch:  355  	Training Loss: 0.0021172165870666504
Test Loss:  0.0016447615344077349
Valid Loss:  0.0018814278300851583
Epoch:  356  	Training Loss: 0.00211721146479249
Test Loss:  0.001644821371883154
Valid Loss:  0.0018814580980688334
Epoch:  357  	Training Loss: 0.002117206808179617
Test Loss:  0.0016448704991489649
Valid Loss:  0.0018814931390807033
Epoch:  358  	Training Loss: 0.002117202617228031
Test Loss:  0.0016449156682938337
Valid Loss:  0.0018815244548022747
Epoch:  359  	Training Loss: 0.00211719935759902
Test Loss:  0.001644952455535531
Valid Loss:  0.0018815560033544898
Epoch:  360  	Training Loss: 0.002117194700986147
Test Loss:  0.0016449913382530212
Valid Loss:  0.0018815887160599232
Epoch:  361  	Training Loss: 0.002117190510034561
Test Loss:  0.0016450270777568221
Valid Loss:  0.001881615724414587
Epoch:  362  	Training Loss: 0.0021171860862523317
Test Loss:  0.0016449716640636325
Valid Loss:  0.0018814940704032779
Epoch:  363  	Training Loss: 0.002117145573720336
Test Loss:  0.001644967240281403
Valid Loss:  0.001881396397948265
Epoch:  364  	Training Loss: 0.0021171215921640396
Test Loss:  0.0016449878457933664
Valid Loss:  0.001881288830190897
Epoch:  365  	Training Loss: 0.0021170987747609615
Test Loss:  0.0016450248658657074
Valid Loss:  0.0018811696209013462
Epoch:  366  	Training Loss: 0.002117076888680458
Test Loss:  0.0016450758557766676
Valid Loss:  0.001881047384813428
Epoch:  367  	Training Loss: 0.00211705663241446
Test Loss:  0.001645136740989983
Valid Loss:  0.0018809668254107237
Epoch:  368  	Training Loss: 0.0021170463878661394
Test Loss:  0.0016452008858323097
Valid Loss:  0.0018808846361935139
Epoch:  369  	Training Loss: 0.002117037307471037
Test Loss:  0.0016452621202915907
Valid Loss:  0.0018808473832905293
Epoch:  370  	Training Loss: 0.0021170340478420258
Test Loss:  0.0016453200951218605
Valid Loss:  0.0018808554159477353
Epoch:  371  	Training Loss: 0.002117027062922716
Test Loss:  0.0016453638672828674
Valid Loss:  0.0018808332970365882
Epoch:  372  	Training Loss: 0.0021170207764953375
Test Loss:  0.0016446445370092988
Valid Loss:  0.0018787846202030778
Epoch:  373  	Training Loss: 0.002116110408678651
Test Loss:  0.0016438579186797142
Valid Loss:  0.0018767935689538717
Epoch:  374  	Training Loss: 0.0021152105182409286
Test Loss:  0.0016430346295237541
Valid Loss:  0.0018748440779745579
Epoch:  375  	Training Loss: 0.0021143187768757343
Test Loss:  0.0016421948093920946
Valid Loss:  0.0018729263683781028
Epoch:  376  	Training Loss: 0.0021134382113814354
Test Loss:  0.0016413461416959763
Valid Loss:  0.001871044747531414
Epoch:  377  	Training Loss: 0.00211256742477417
Test Loss:  0.0016404961934313178
Valid Loss:  0.0018691853620111942
Epoch:  378  	Training Loss: 0.0021117047872394323
Test Loss:  0.0016396513674408197
Valid Loss:  0.00186735054012388
Epoch:  379  	Training Loss: 0.002110852161422372
Test Loss:  0.001638811081647873
Valid Loss:  0.001865536905825138
Epoch:  380  	Training Loss: 0.002110007917508483
Test Loss:  0.0016379767330363393
Valid Loss:  0.0018637442262843251
Epoch:  381  	Training Loss: 0.002109173685312271
Test Loss:  0.0016371577512472868
Valid Loss:  0.0018619694747030735
Epoch:  382  	Training Loss: 0.0021083480678498745
Test Loss:  0.001634175656363368
Valid Loss:  0.0018571254331618547
Epoch:  383  	Training Loss: 0.0021045212633907795
Test Loss:  0.0016323563177138567
Valid Loss:  0.0018556073773652315
Epoch:  384  	Training Loss: 0.0021031200885772705
Test Loss:  0.0016314333770424128
Valid Loss:  0.00185479037463665
Epoch:  385  	Training Loss: 0.00210238853469491
Test Loss:  0.0016309402417391539
Valid Loss:  0.001854084199294448
Epoch:  386  	Training Loss: 0.0021018092520534992
Test Loss:  0.0016303055454045534
Valid Loss:  0.0018534696428105235
Epoch:  387  	Training Loss: 0.002101302146911621
Test Loss:  0.0016302212607115507
Valid Loss:  0.001852621091529727
Epoch:  388  	Training Loss: 0.002100798999890685
Test Loss:  0.0016299986746162176
Valid Loss:  0.0018518331926316023
Epoch:  389  	Training Loss: 0.0021002995781600475
Test Loss:  0.001629865262657404
Valid Loss:  0.0018510082736611366
Epoch:  390  	Training Loss: 0.0020998038817197084
Test Loss:  0.0016298750415444374
Valid Loss:  0.0018501318991184235
Epoch:  391  	Training Loss: 0.0020993128418922424
Test Loss:  0.0016296124085783958
Valid Loss:  0.0018493746174499393
Epoch:  392  	Training Loss: 0.0020988252945244312
Test Loss:  0.001629492500796914
Valid Loss:  0.0018484366592019796
Epoch:  393  	Training Loss: 0.0020983524154871702
Test Loss:  0.0016292294021695852
Valid Loss:  0.0018475641263648868
Epoch:  394  	Training Loss: 0.0020978839602321386
Test Loss:  0.001628977945074439
Valid Loss:  0.001846692175604403
Epoch:  395  	Training Loss: 0.0020974185317754745
Test Loss:  0.001628740457817912
Valid Loss:  0.0018458205740898848
Epoch:  396  	Training Loss: 0.002096958691254258
Test Loss:  0.0016286408063024282
Valid Loss:  0.0018449036870151758
Epoch:  397  	Training Loss: 0.0020965025760233402
Test Loss:  0.0016283895820379257
Valid Loss:  0.0018440550193190575
Epoch:  398  	Training Loss: 0.0020960490219295025
Test Loss:  0.0016281516291201115
Valid Loss:  0.0018432040233165026
Epoch:  399  	Training Loss: 0.002095598727464676
Test Loss:  0.0016280522104352713
Valid Loss:  0.0018423101864755154
Epoch:  400  	Training Loss: 0.0020951551850885153
Test Loss:  0.0016277437098324299
Valid Loss:  0.0018415048252791166
Epoch:  401  	Training Loss: 0.002094711409881711
Test Loss:  0.0016276482492685318
Valid Loss:  0.0018407665193080902
Epoch:  402  	Training Loss: 0.0020942750852555037
Test Loss:  0.0016183562111109495
Valid Loss:  0.0018115537241101265
Epoch:  403  	Training Loss: 0.0020730309188365936
Test Loss:  0.001614298322238028
Valid Loss:  0.001812121132388711
Epoch:  404  	Training Loss: 0.0020720399916172028
Test Loss:  0.0016113347373902798
Valid Loss:  0.0018124058842658997
Epoch:  405  	Training Loss: 0.0020712176337838173
Test Loss:  0.0016091354191303253
Valid Loss:  0.0018124885391443968
Epoch:  406  	Training Loss: 0.002070484682917595
Test Loss:  0.0016074833692982793
Valid Loss:  0.001812470844015479
Epoch:  407  	Training Loss: 0.0020698104053735733
Test Loss:  0.0016061693895608187
Valid Loss:  0.001812484348192811
Epoch:  408  	Training Loss: 0.0020692013204097748
Test Loss:  0.0016040238551795483
Valid Loss:  0.0018127148505300283
Epoch:  409  	Training Loss: 0.002068656962364912
Test Loss:  0.0016024451470002532
Valid Loss:  0.0018128131050616503
Epoch:  410  	Training Loss: 0.002068169880658388
Test Loss:  0.0016012738924473524
Valid Loss:  0.0018128036754205823
Epoch:  411  	Training Loss: 0.0020677107386291027
Test Loss:  0.0016003430355340242
Valid Loss:  0.001812727889046073
Epoch:  412  	Training Loss: 0.002067269291728735
Test Loss:  0.0015969452215358615
Valid Loss:  0.0018108792137354612
Epoch:  413  	Training Loss: 0.002065303735435009
Test Loss:  0.0015956391580402851
Valid Loss:  0.0018090377561748028
 83%|████████▎ | 415/500 [05:05<00:52,  1.61it/s] 83%|████████▎ | 417/500 [05:05<00:37,  2.20it/s] 84%|████████▍ | 419/500 [05:05<00:27,  2.95it/s] 84%|████████▍ | 421/500 [05:11<01:34,  1.19s/it] 85%|████████▍ | 423/500 [05:12<01:05,  1.17it/s] 85%|████████▌ | 425/500 [05:12<00:46,  1.62it/s] 85%|████████▌ | 427/500 [05:12<00:33,  2.21it/s] 86%|████████▌ | 429/500 [05:12<00:23,  2.96it/s] 86%|████████▌ | 431/500 [05:19<01:24,  1.23s/it] 87%|████████▋ | 433/500 [05:19<00:59,  1.13it/s] 87%|████████▋ | 435/500 [05:19<00:41,  1.56it/s] 87%|████████▋ | 437/500 [05:19<00:29,  2.12it/s] 88%|████████▊ | 439/500 [05:19<00:21,  2.85it/s] 88%|████████▊ | 441/500 [05:26<01:12,  1.22s/it] 89%|████████▊ | 443/500 [05:26<00:49,  1.14it/s] 89%|████████▉ | 445/500 [05:26<00:34,  1.58it/s] 89%|████████▉ | 447/500 [05:26<00:24,  2.16it/s] 90%|████████▉ | 449/500 [05:26<00:17,  2.90it/s] 90%|█████████ | 451/500 [05:33<00:59,  1.21s/it] 91%|█████████ | 453/500 [05:33<00:40,  1.15it/s] 91%|█████████ | 455/500 [05:33<00:28,  1.59it/s] 91%|█████████▏| 457/500 [05:33<00:19,  2.18it/s] 92%|█████████▏| 459/500 [05:33<00:13,  2.93it/s] 92%|█████████▏| 461/500 [05:39<00:45,  1.17s/it] 93%|█████████▎| 463/500 [05:40<00:31,  1.19it/s] 93%|█████████▎| 465/500 [05:40<00:21,  1.64it/s] 93%|█████████▎| 467/500 [05:40<00:14,  2.24it/s] 94%|█████████▍| 469/500 [05:40<00:10,  3.01it/s] 94%|█████████▍| 471/500 [05:46<00:33,  1.17s/it] 95%|█████████▍| 473/500 [05:46<00:22,  1.19it/s] 95%|█████████▌| 475/500 [05:47<00:15,  1.64it/s] 95%|█████████▌| 477/500 [05:47<00:10,  2.24it/s] 96%|█████████▌| 479/500 [05:47<00:07,  2.99it/s] 96%|█████████▌| 481/500 [05:53<00:22,  1.18s/it]Epoch:  414  	Training Loss: 0.002063758671283722
Test Loss:  0.0015938077121973038
Valid Loss:  0.0018077469430863857
Epoch:  415  	Training Loss: 0.00206254655495286
Test Loss:  0.0015932442620396614
Valid Loss:  0.0018062159651890397
Epoch:  416  	Training Loss: 0.0020614464301615953
Test Loss:  0.001592264510691166
Valid Loss:  0.0018049034988507628
Epoch:  417  	Training Loss: 0.0020604049786925316
Test Loss:  0.0015916345873847604
Valid Loss:  0.0018035590182989836
Epoch:  418  	Training Loss: 0.0020594168454408646
Test Loss:  0.0015911293448880315
Valid Loss:  0.0018021882278844714
Epoch:  419  	Training Loss: 0.002058477373793721
Test Loss:  0.0015907343477010727
Valid Loss:  0.0018008325714617968
Epoch:  420  	Training Loss: 0.002057594247162342
Test Loss:  0.0015904308529570699
Valid Loss:  0.0017995168454945087
Epoch:  421  	Training Loss: 0.0020567667670547962
Test Loss:  0.001590140862390399
Valid Loss:  0.0017982565332204103
Epoch:  422  	Training Loss: 0.0020559646654874086
Test Loss:  0.0015776543878018856
Valid Loss:  0.0017895838245749474
Epoch:  423  	Training Loss: 0.002046900102868676
Test Loss:  0.0015723817050457
Valid Loss:  0.0017856049817055464
Epoch:  424  	Training Loss: 0.0020425685215741396
Test Loss:  0.0015701493248343468
Valid Loss:  0.001782917184755206
Epoch:  425  	Training Loss: 0.0020397440530359745
Test Loss:  0.0015691285952925682
Valid Loss:  0.0017808610573410988
Epoch:  426  	Training Loss: 0.002037487458437681
Test Loss:  0.0015686850529164076
Valid Loss:  0.0017790741985663772
Epoch:  427  	Training Loss: 0.002035892568528652
Test Loss:  0.0015691118314862251
Valid Loss:  0.0017776861786842346
Epoch:  428  	Training Loss: 0.002034767996519804
Test Loss:  0.0015696119517087936
Valid Loss:  0.0017765811644494534
Epoch:  429  	Training Loss: 0.002033833647146821
Test Loss:  0.0015701174270361662
Valid Loss:  0.0017756239976733923
Epoch:  430  	Training Loss: 0.002033097902312875
Test Loss:  0.0015705502592027187
Valid Loss:  0.0017747150268405676
Epoch:  431  	Training Loss: 0.0020324275828897953
Test Loss:  0.0015709905419498682
Valid Loss:  0.0017739434260874987
Epoch:  432  	Training Loss: 0.0020319309551268816
Test Loss:  0.0015716667985543609
Valid Loss:  0.0017735576257109642
Epoch:  433  	Training Loss: 0.002031823620200157
Test Loss:  0.001571982866153121
Valid Loss:  0.0017733549466356635
Epoch:  434  	Training Loss: 0.0020317276939749718
Test Loss:  0.001572157721966505
Valid Loss:  0.0017732364358380437
Epoch:  435  	Training Loss: 0.002031638752669096
Test Loss:  0.0015722684329375625
Valid Loss:  0.001773149473592639
Epoch:  436  	Training Loss: 0.0020315530709922314
Test Loss:  0.001572359586134553
Valid Loss:  0.0017730850959196687
Epoch:  437  	Training Loss: 0.002031484618782997
Test Loss:  0.0015724350232630968
Valid Loss:  0.0017730308463796973
Epoch:  438  	Training Loss: 0.0020314177963882685
Test Loss:  0.0015725051052868366
Valid Loss:  0.0017729823011904955
Epoch:  439  	Training Loss: 0.0020313591230660677
Test Loss:  0.0015725712291896343
Valid Loss:  0.0017729380633682013
Epoch:  440  	Training Loss: 0.002031307201832533
Test Loss:  0.001572651439346373
Valid Loss:  0.0017729061655700207
Epoch:  441  	Training Loss: 0.002031264826655388
Test Loss:  0.0015727304853498936
Valid Loss:  0.0017728793900460005
Epoch:  442  	Training Loss: 0.0020312261767685413
Test Loss:  0.0015740286326035857
Valid Loss:  0.0017727073282003403
Epoch:  443  	Training Loss: 0.002031160518527031
Test Loss:  0.0015749491285532713
Valid Loss:  0.0017726473743095994
Epoch:  444  	Training Loss: 0.00203111139126122
Test Loss:  0.0015756093198433518
Valid Loss:  0.0017726595979183912
Epoch:  445  	Training Loss: 0.0020310732070356607
Test Loss:  0.001576087437570095
Valid Loss:  0.001772719551809132
Epoch:  446  	Training Loss: 0.0020310399122536182
Test Loss:  0.001576441922225058
Valid Loss:  0.001772809773683548
Epoch:  447  	Training Loss: 0.002031009178608656
Test Loss:  0.0015767086297273636
Valid Loss:  0.0017729164101183414
Epoch:  448  	Training Loss: 0.0020309824030846357
Test Loss:  0.001576914917677641
Valid Loss:  0.0017730373656377196
Epoch:  449  	Training Loss: 0.0020309570245444775
Test Loss:  0.0015770794125273824
Valid Loss:  0.0017731611151248217
Epoch:  450  	Training Loss: 0.0020309328101575375
Test Loss:  0.0015772158512845635
Valid Loss:  0.0017732881242409348
Epoch:  451  	Training Loss: 0.0020309113897383213
Test Loss:  0.001577330520376563
Valid Loss:  0.0017734201392158866
Epoch:  452  	Training Loss: 0.0020308904349803925
Test Loss:  0.0015655354363843799
Valid Loss:  0.001748558133840561
Epoch:  453  	Training Loss: 0.0020133452489972115
Test Loss:  0.0015648780390620232
Valid Loss:  0.001742699765600264
Epoch:  454  	Training Loss: 0.002009752206504345
Test Loss:  0.0015600495971739292
Valid Loss:  0.0017425963887944818
Epoch:  455  	Training Loss: 0.002008630894124508
Test Loss:  0.0015569780953228474
Valid Loss:  0.0017419393407180905
Epoch:  456  	Training Loss: 0.0020076704677194357
Test Loss:  0.0015542798209935427
Valid Loss:  0.0017413769382983446
Epoch:  457  	Training Loss: 0.0020068190060555935
Test Loss:  0.0015522631583735347
Valid Loss:  0.0017406339757144451
Epoch:  458  	Training Loss: 0.002006025519222021
Test Loss:  0.0015507253119722009
Valid Loss:  0.001739770406857133
Epoch:  459  	Training Loss: 0.002005194779485464
Test Loss:  0.001549477456137538
Valid Loss:  0.0017385398969054222
Epoch:  460  	Training Loss: 0.002004203386604786
Test Loss:  0.001548430067487061
Valid Loss:  0.0017374164890497923
Epoch:  461  	Training Loss: 0.0020032315514981747
Test Loss:  0.0015475163236260414
Valid Loss:  0.0017363853985443711
Epoch:  462  	Training Loss: 0.002002321183681488
Test Loss:  0.0015463815070688725
Valid Loss:  0.0017341198399662971
Epoch:  463  	Training Loss: 0.0020004764664918184
Test Loss:  0.0015462585724890232
Valid Loss:  0.0017327492823824286
Epoch:  464  	Training Loss: 0.001999587519094348
Test Loss:  0.0015465987380594015
Valid Loss:  0.0017319866456091404
Epoch:  465  	Training Loss: 0.0019991258159279823
Test Loss:  0.001547105610370636
Valid Loss:  0.0017314663855358958
Epoch:  466  	Training Loss: 0.0019988366402685642
Test Loss:  0.0015475201653316617
Valid Loss:  0.0017312531126663089
Epoch:  467  	Training Loss: 0.001998720457777381
Test Loss:  0.0015477552078664303
Valid Loss:  0.0017312078271061182
Epoch:  468  	Training Loss: 0.0019986764527857304
Test Loss:  0.0015479882713407278
Valid Loss:  0.0017311634728685021
Epoch:  469  	Training Loss: 0.001998631749302149
Test Loss:  0.0015481750015169382
Valid Loss:  0.001731143449433148
Epoch:  470  	Training Loss: 0.001998589839786291
Test Loss:  0.0015483981696888804
Valid Loss:  0.0017311011906713247
Epoch:  471  	Training Loss: 0.0019985514227300882
Test Loss:  0.0015485715121030807
Valid Loss:  0.0017310855910182
Epoch:  472  	Training Loss: 0.001998510677367449
Test Loss:  0.0015240010106936097
Valid Loss:  0.0017252761172130704
Epoch:  473  	Training Loss: 0.0019878591410815716
Test Loss:  0.0015153399435803294
Valid Loss:  0.0017197252018377185
Epoch:  474  	Training Loss: 0.001982097513973713
Test Loss:  0.0015111108077690005
Valid Loss:  0.0017147422768175602
Epoch:  475  	Training Loss: 0.001977980602532625
Test Loss:  0.0015083950711414218
Valid Loss:  0.0017101307166740298
Epoch:  476  	Training Loss: 0.001974420389160514
Test Loss:  0.00150661775842309
Valid Loss:  0.001706134295091033
Epoch:  477  	Training Loss: 0.001971160527318716
Test Loss:  0.0015049262437969446
Valid Loss:  0.0017021405510604382
Epoch:  478  	Training Loss: 0.001968182623386383
Test Loss:  0.001503781764768064
Valid Loss:  0.0016984594985842705
Epoch:  479  	Training Loss: 0.0019656983204185963
Test Loss:  0.0015031853690743446
Valid Loss:  0.0016952899750322104
Epoch:  480  	Training Loss: 0.001963587012141943
Test Loss:  0.0015025438042357564
Valid Loss:  0.0016924424562603235
Epoch:  481  	Training Loss: 0.0019616633653640747
Test Loss:  0.0015018775593489408
Valid Loss:  0.001689742668531835
Epoch:  482  	Training Loss: 0.0019598817452788353
Test Loss:  0.0015026733744889498
Valid Loss:   97%|█████████▋| 483/500 [05:53<00:14,  1.19it/s] 97%|█████████▋| 485/500 [05:53<00:09,  1.64it/s] 97%|█████████▋| 487/500 [05:54<00:05,  2.23it/s] 98%|█████████▊| 489/500 [05:54<00:03,  3.00it/s] 98%|█████████▊| 491/500 [06:00<00:10,  1.19s/it] 99%|█████████▊| 493/500 [06:00<00:05,  1.18it/s] 99%|█████████▉| 495/500 [06:00<00:03,  1.63it/s] 99%|█████████▉| 497/500 [06:00<00:01,  2.22it/s]100%|█████████▉| 499/500 [06:01<00:00,  2.99it/s]100%|██████████| 500/500 [06:01<00:00,  1.38it/s]
0.0016892430139705539
Epoch:  483  	Training Loss: 0.00195956788957119
Test Loss:  0.0015033690724521875
Valid Loss:  0.0016887937672436237
Epoch:  484  	Training Loss: 0.001959266373887658
Test Loss:  0.001503973500803113
Valid Loss:  0.0016883858479559422
Epoch:  485  	Training Loss: 0.00195897463709116
Test Loss:  0.0015045036561787128
Valid Loss:  0.0016880185576155782
Epoch:  486  	Training Loss: 0.0019587124697864056
Test Loss:  0.0015049731591716409
Valid Loss:  0.0016877372981980443
Epoch:  487  	Training Loss: 0.0019585047848522663
Test Loss:  0.0015053905081003904
Valid Loss:  0.0016874844441190362
Epoch:  488  	Training Loss: 0.0019582994282245636
Test Loss:  0.001505753374658525
Valid Loss:  0.0016872503329068422
Epoch:  489  	Training Loss: 0.001958100125193596
Test Loss:  0.001506080268882215
Valid Loss:  0.0016870331019163132
Epoch:  490  	Training Loss: 0.001957901520654559
Test Loss:  0.0015063656028360128
Valid Loss:  0.0016868326347321272
Epoch:  491  	Training Loss: 0.0019577094353735447
Test Loss:  0.0015066214837133884
Valid Loss:  0.0016866475343704224
Epoch:  492  	Training Loss: 0.0019575185142457485
Test Loss:  0.0015065347542986274
Valid Loss:  0.0016870030667632818
Epoch:  493  	Training Loss: 0.0019573576282709837
Test Loss:  0.0015066321939229965
Valid Loss:  0.0016872792039066553
Epoch:  494  	Training Loss: 0.001957206754013896
Test Loss:  0.0015068268403410912
Valid Loss:  0.0016875158762559295
Epoch:  495  	Training Loss: 0.001957065425813198
Test Loss:  0.001507061067968607
Valid Loss:  0.0016877299640327692
Epoch:  496  	Training Loss: 0.0019569331780076027
Test Loss:  0.001507319277152419
Valid Loss:  0.0016879338072612882
Epoch:  497  	Training Loss: 0.0019568062853068113
Test Loss:  0.0015075871488079429
Valid Loss:  0.0016881241463124752
Epoch:  498  	Training Loss: 0.0019566891714930534
Test Loss:  0.00150785269215703
Valid Loss:  0.001688313903287053
Epoch:  499  	Training Loss: 0.0019565774127840996
Test Loss:  0.0015081216115504503
Valid Loss:  0.0016885004006326199
Epoch:  500  	Training Loss: 0.0019564710091799498
Test Loss:  0.0015083815669640899
Valid Loss:  0.001688681193627417
seed is  20
---------------------------------------- SGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:00<00:37, 13.43it/s]  1%|          | 4/500 [00:00<00:33, 14.92it/s]  1%|          | 6/500 [00:00<00:32, 15.37it/s]  2%|▏         | 8/500 [00:00<00:31, 15.57it/s]  2%|▏         | 10/500 [00:00<00:32, 15.30it/s]  2%|▏         | 12/500 [00:00<00:31, 15.58it/s]  3%|▎         | 14/500 [00:00<00:30, 15.73it/s]  3%|▎         | 16/500 [00:01<00:30, 15.85it/s]  4%|▎         | 18/500 [00:01<00:30, 15.91it/s]  4%|▍         | 20/500 [00:01<00:30, 15.93it/s]  4%|▍         | 22/500 [00:01<00:29, 15.97it/s]  5%|▍         | 24/500 [00:01<00:30, 15.83it/s]  5%|▌         | 26/500 [00:01<00:30, 15.77it/s]  6%|▌         | 28/500 [00:01<00:29, 15.80it/s]  6%|▌         | 30/500 [00:01<00:29, 15.93it/s]  6%|▋         | 32/500 [00:02<00:29, 15.96it/s]  7%|▋         | 34/500 [00:02<00:29, 16.02it/s]  7%|▋         | 36/500 [00:02<00:28, 16.10it/s]  8%|▊         | 38/500 [00:02<00:28, 16.12it/s]  8%|▊         | 40/500 [00:02<00:28, 16.28it/s]  8%|▊         | 42/500 [00:02<00:28, 16.33it/s]  9%|▉         | 44/500 [00:02<00:28, 16.25it/s]  9%|▉         | 46/500 [00:02<00:28, 16.15it/s] 10%|▉         | 48/500 [00:03<00:28, 16.11it/s] 10%|█         | 50/500 [00:03<00:27, 16.18it/s] 10%|█         | 52/500 [00:03<00:27, 16.05it/s] 11%|█         | 54/500 [00:03<00:27, 16.00it/s] 11%|█         | 56/500 [00:03<00:27, 15.95it/s] 12%|█▏        | 58/500 [00:03<00:27, 15.95it/s] 12%|█▏        | 60/500 [00:03<00:27, 15.81it/s] 12%|█▏        | 62/500 [00:03<00:27, 15.85it/s] 13%|█▎        | 64/500 [00:04<00:27, 15.99it/s] 13%|█▎        | 66/500 [00:04<00:27, 15.85it/s] 14%|█▎        | 68/500 [00:04<00:27, 15.93it/s] 14%|█▍        | 70/500 [00:04<00:27, 15.79it/s] 14%|█▍        | 72/500 [00:04<00:27, 15.75it/s] 15%|█▍        | 74/500 [00:04<00:26, 15.84it/s] 15%|█▌        | 76/500 [00:04<00:26, 15.98it/s] 16%|█▌        | 78/500 [00:04<00:26, 15.90it/s] 16%|█▌        | 80/500 [00:05<00:26, 15.89it/s] 16%|█▋        | 82/500 [00:05<00:26, 15.70it/s] 17%|█▋        | 84/500 [00:05<00:26, 15.84it/s] 17%|█▋        | 86/500 [00:05<00:25, 15.94it/s] 18%|█▊        | 88/500 [00:05<00:25, 15.92it/s] 18%|█▊        | 90/500 [00:05<00:26, 15.45it/s] 18%|█▊        | 92/500 [00:05<00:26, 15.52it/s] 19%|█▉        | 94/500 [00:05<00:26, 15.57it/s] 19%|█▉        | 96/500 [00:06<00:25, 15.66it/s] 20%|█▉        | 98/500 [00:06<00:25, 15.55it/s] 20%|██        | 100/500 [00:06<00:25, 15.41it/s] 20%|██        | 102/500 [00:06<00:42,  9.38it/s] 21%|██        | 104/500 [00:07<00:53,  7.36it/s] 21%|██        | 106/500 [00:07<00:46,  8.45it/s] 22%|██▏       | 108/500 [00:07<00:40,  9.79it/s] 22%|██▏       | 110/500 [00:07<00:35, 11.05it/s] 22%|██▏       | 112/500 [00:07<00:31, 12.15it/s] 23%|██▎       | 114/500 [00:07<00:29, 13.01it/s] 23%|██▎       | 116/500 [00:07<00:28, 13.70it/s] 24%|██▎       | 118/500 [00:08<00:26, 14.17it/s] 24%|██▍       | 120/500 [00:08<00:26, 14.43it/s] 24%|██▍       | 122/500 [00:08<00:25, 14.81it/s] 25%|██▍       | 124/500 [00:08<00:24, 15.08it/s]Epoch:  1  	Training Loss: 0.2410266399383545
Test Loss:  4024.01806640625
Valid Loss:  4022.1865234375
Epoch:  2  	Training Loss: 4021.14208984375
Test Loss:  458812364423168.0
Valid Loss:  454858981244928.0
Epoch:  3  	Training Loss: 455832764416000.0
Test Loss:  nan
Valid Loss:  nan
Epoch:  4  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  5  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  6  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  7  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  8  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  9  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  10  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  11  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  12  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  13  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  14  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  15  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  16  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  17  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  18  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  19  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  20  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  21  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  22  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  23  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  24  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  25  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  26  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  27  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  28  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  29  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  30  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  31  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  32  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  33  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  34  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  35  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  36  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  37  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  38  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  39  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  40  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  41  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  42  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  43  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  44  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  45  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  46  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  47  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  48  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  49  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  50  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  51  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  52  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  53  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  54  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  55  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  56  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  57  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  58  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  59  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  60  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  61  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  62  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  63  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  64  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  65  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  66  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  67  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  68  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  69  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  70  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  71  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  72  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  73  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  74  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  75  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  76  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  77  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  78  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  79  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  80  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  81  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  82  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  83  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  84  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  85  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  86  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  87  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  88  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  89  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  90  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  91  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  92  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  93  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  94  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  95  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  96  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  97  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  98  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  99  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  100  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  101  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  102  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  103  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  104  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  105  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  106  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  107  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  108  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  109  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  110  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  111  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  112  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  113  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  114  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  115  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  116  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  117  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  118  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  119  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  120  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  121  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  122  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  123  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  124  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 25%|██▌       | 126/500 [00:08<00:24, 15.31it/s] 26%|██▌       | 128/500 [00:08<00:24, 15.37it/s] 26%|██▌       | 130/500 [00:08<00:23, 15.52it/s] 26%|██▋       | 132/500 [00:08<00:23, 15.58it/s] 27%|██▋       | 134/500 [00:09<00:23, 15.33it/s] 27%|██▋       | 136/500 [00:09<00:23, 15.52it/s] 28%|██▊       | 138/500 [00:09<00:23, 15.59it/s] 28%|██▊       | 140/500 [00:09<00:22, 15.73it/s] 28%|██▊       | 142/500 [00:09<00:22, 15.78it/s] 29%|██▉       | 144/500 [00:09<00:22, 15.76it/s] 29%|██▉       | 146/500 [00:09<00:22, 15.79it/s] 30%|██▉       | 148/500 [00:09<00:22, 15.86it/s] 30%|███       | 150/500 [00:10<00:22, 15.83it/s] 30%|███       | 152/500 [00:10<00:21, 15.95it/s] 31%|███       | 154/500 [00:10<00:21, 15.86it/s] 31%|███       | 156/500 [00:10<00:22, 15.36it/s] 32%|███▏      | 158/500 [00:10<00:22, 15.48it/s] 32%|███▏      | 160/500 [00:10<00:21, 15.68it/s] 32%|███▏      | 162/500 [00:10<00:21, 15.70it/s] 33%|███▎      | 164/500 [00:11<00:21, 15.37it/s] 33%|███▎      | 166/500 [00:11<00:21, 15.57it/s] 34%|███▎      | 168/500 [00:11<00:20, 15.85it/s] 34%|███▍      | 170/500 [00:11<00:20, 15.91it/s] 34%|███▍      | 172/500 [00:11<00:20, 15.89it/s] 35%|███▍      | 174/500 [00:11<00:20, 15.88it/s] 35%|███▌      | 176/500 [00:11<00:20, 15.76it/s] 36%|███▌      | 178/500 [00:11<00:20, 15.89it/s] 36%|███▌      | 180/500 [00:12<00:20, 15.91it/s] 36%|███▋      | 182/500 [00:12<00:20, 15.72it/s] 37%|███▋      | 184/500 [00:12<00:20, 15.59it/s] 37%|███▋      | 186/500 [00:12<00:20, 14.98it/s] 38%|███▊      | 188/500 [00:12<00:20, 15.15it/s] 38%|███▊      | 190/500 [00:12<00:20, 15.44it/s] 38%|███▊      | 192/500 [00:12<00:19, 15.50it/s] 39%|███▉      | 194/500 [00:12<00:19, 15.57it/s] 39%|███▉      | 196/500 [00:13<00:19, 15.68it/s] 40%|███▉      | 198/500 [00:13<00:19, 15.74it/s] 40%|████      | 200/500 [00:13<00:19, 15.39it/s] 40%|████      | 202/500 [00:13<00:19, 15.64it/s] 41%|████      | 204/500 [00:13<00:18, 15.75it/s] 41%|████      | 206/500 [00:13<00:18, 15.88it/s] 42%|████▏     | 208/500 [00:13<00:18, 15.78it/s] 42%|████▏     | 210/500 [00:13<00:19, 15.17it/s] 42%|████▏     | 212/500 [00:14<00:18, 15.51it/s] 43%|████▎     | 214/500 [00:14<00:18, 15.63it/s] 43%|████▎     | 216/500 [00:14<00:17, 15.83it/s] 44%|████▎     | 218/500 [00:14<00:18, 15.16it/s] 44%|████▍     | 220/500 [00:14<00:18, 15.44it/s] 44%|████▍     | 222/500 [00:14<00:17, 15.60it/s] 45%|████▍     | 224/500 [00:14<00:17, 15.85it/s] 45%|████▌     | 226/500 [00:14<00:17, 15.94it/s] 46%|████▌     | 228/500 [00:15<00:17, 15.98it/s] 46%|████▌     | 230/500 [00:15<00:16, 16.01it/s] 46%|████▋     | 232/500 [00:15<00:16, 16.07it/s] 47%|████▋     | 234/500 [00:15<00:16, 16.06it/s] 47%|████▋     | 236/500 [00:15<00:16, 16.04it/s] 48%|████▊     | 238/500 [00:15<00:16, 16.06it/s] 48%|████▊     | 240/500 [00:15<00:16, 16.11it/s] 48%|████▊     | 242/500 [00:15<00:15, 16.15it/s] 49%|████▉     | 244/500 [00:16<00:15, 16.10it/s] 49%|████▉     | 246/500 [00:16<00:15, 16.20it/s] 50%|████▉     | 248/500 [00:16<00:15, 16.20it/s]Epoch:  125  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  126  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  127  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  128  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  129  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  130  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  131  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  132  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  133  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  134  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  135  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  136  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  137  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  138  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  139  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  140  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  141  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  142  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  143  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  144  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  145  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  146  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  147  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  148  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  149  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  150  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  151  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  152  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  153  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  154  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  155  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  156  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  157  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  158  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  159  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  160  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  161  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  162  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  163  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  164  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  165  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  166  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  167  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  168  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  169  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  170  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  171  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  172  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  173  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  174  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  175  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  176  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  177  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  178  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  179  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  180  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  181  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  182  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  183  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  184  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  185  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  186  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  187  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  188  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  189  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  190  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  191  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  192  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  193  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  194  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  195  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  196  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  197  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  198  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  199  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  200  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  201  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  202  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  203  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  204  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  205  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  206  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  207  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  208  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  209  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  210  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  211  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  212  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  213  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  214  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  215  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  216  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  217  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  218  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  219  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  220  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  221  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  222  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  223  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  224  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  225  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  226  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  227  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  228  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  229  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  230  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  231  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  232  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  233  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  234  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  235  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  236  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  237  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  238  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  239  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  240  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  241  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  242  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  243  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  244  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  245  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  246  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  247  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  248  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 50%|█████     | 250/500 [00:16<00:15, 16.15it/s] 50%|█████     | 252/500 [00:16<00:15, 15.99it/s] 51%|█████     | 254/500 [00:16<00:15, 15.84it/s] 51%|█████     | 256/500 [00:16<00:15, 15.96it/s] 52%|█████▏    | 258/500 [00:16<00:15, 15.89it/s] 52%|█████▏    | 260/500 [00:17<00:15, 15.95it/s] 52%|█████▏    | 262/500 [00:17<00:14, 16.03it/s] 53%|█████▎    | 264/500 [00:17<00:14, 16.00it/s] 53%|█████▎    | 266/500 [00:17<00:14, 15.71it/s] 54%|█████▎    | 268/500 [00:17<00:14, 15.49it/s] 54%|█████▍    | 270/500 [00:17<00:14, 15.66it/s] 54%|█████▍    | 272/500 [00:17<00:14, 15.80it/s] 55%|█████▍    | 274/500 [00:17<00:14, 15.88it/s] 55%|█████▌    | 276/500 [00:18<00:14, 15.82it/s] 56%|█████▌    | 278/500 [00:18<00:14, 15.39it/s] 56%|█████▌    | 280/500 [00:18<00:14, 15.64it/s] 56%|█████▋    | 282/500 [00:18<00:13, 15.85it/s] 57%|█████▋    | 284/500 [00:18<00:13, 15.83it/s] 57%|█████▋    | 286/500 [00:18<00:13, 15.77it/s] 58%|█████▊    | 288/500 [00:18<00:13, 15.74it/s] 58%|█████▊    | 290/500 [00:18<00:13, 15.73it/s] 58%|█████▊    | 292/500 [00:19<00:13, 15.52it/s] 59%|█████▉    | 294/500 [00:19<00:13, 15.59it/s] 59%|█████▉    | 296/500 [00:19<00:12, 15.74it/s] 60%|█████▉    | 298/500 [00:19<00:12, 15.93it/s] 60%|██████    | 300/500 [00:19<00:12, 15.92it/s] 60%|██████    | 302/500 [00:19<00:12, 15.87it/s] 61%|██████    | 304/500 [00:19<00:12, 15.72it/s] 61%|██████    | 306/500 [00:20<00:12, 15.87it/s] 62%|██████▏   | 308/500 [00:20<00:12, 15.95it/s] 62%|██████▏   | 310/500 [00:20<00:11, 16.08it/s] 62%|██████▏   | 312/500 [00:20<00:11, 15.95it/s] 63%|██████▎   | 314/500 [00:20<00:11, 15.95it/s] 63%|██████▎   | 316/500 [00:20<00:11, 16.01it/s] 64%|██████▎   | 318/500 [00:20<00:11, 16.00it/s] 64%|██████▍   | 320/500 [00:20<00:11, 16.02it/s] 64%|██████▍   | 322/500 [00:20<00:11, 16.08it/s] 65%|██████▍   | 324/500 [00:21<00:10, 16.19it/s] 65%|██████▌   | 326/500 [00:21<00:10, 16.12it/s] 66%|██████▌   | 328/500 [00:21<00:10, 15.89it/s] 66%|██████▌   | 330/500 [00:21<00:10, 15.92it/s] 66%|██████▋   | 332/500 [00:21<00:10, 15.82it/s] 67%|██████▋   | 334/500 [00:21<00:10, 15.88it/s] 67%|██████▋   | 336/500 [00:21<00:10, 15.88it/s] 68%|██████▊   | 338/500 [00:22<00:10, 15.84it/s] 68%|██████▊   | 340/500 [00:22<00:10, 15.95it/s] 68%|██████▊   | 342/500 [00:22<00:09, 16.00it/s] 69%|██████▉   | 344/500 [00:22<00:09, 15.89it/s] 69%|██████▉   | 346/500 [00:22<00:09, 15.96it/s] 70%|██████▉   | 348/500 [00:22<00:09, 15.96it/s] 70%|███████   | 350/500 [00:22<00:09, 16.02it/s] 70%|███████   | 352/500 [00:22<00:09, 16.07it/s] 71%|███████   | 354/500 [00:23<00:09, 15.52it/s] 71%|███████   | 356/500 [00:23<00:09, 15.80it/s] 72%|███████▏  | 358/500 [00:23<00:08, 15.91it/s] 72%|███████▏  | 360/500 [00:23<00:08, 15.76it/s] 72%|███████▏  | 362/500 [00:23<00:08, 15.57it/s] 73%|███████▎  | 364/500 [00:23<00:08, 15.64it/s] 73%|███████▎  | 366/500 [00:23<00:08, 15.77it/s] 74%|███████▎  | 368/500 [00:23<00:08, 15.94it/s] 74%|███████▍  | 370/500 [00:24<00:08, 15.79it/s] 74%|███████▍  | 372/500 [00:24<00:08, 15.53it/s]Epoch:  249  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  250  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  251  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  252  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  253  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  254  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  255  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  256  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  257  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  258  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  259  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  260  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  261  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  262  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  263  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  264  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  265  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  266  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  267  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  268  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  269  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  270  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  271  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  272  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  273  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  274  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  275  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  276  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  277  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  278  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  279  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  280  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  281  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  282  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  283  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  284  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  285  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  286  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  287  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  288  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  289  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  290  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  291  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  292  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  293  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  294  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  295  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  296  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  297  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  298  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  299  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  300  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  301  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  302  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  303  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  304  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  305  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  306  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  307  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  308  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  309  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  310  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  311  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  312  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  313  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  314  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  315  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  316  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  317  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  318  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  319  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  320  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  321  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  322  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  323  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  324  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  325  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  326  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  327  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  328  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  329  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  330  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  331  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  332  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  333  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  334  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  335  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  336  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  337  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  338  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  339  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  340  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  341  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  342  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  343  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  344  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  345  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  346  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  347  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  348  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  349  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  350  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  351  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  352  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  353  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  354  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  355  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  356  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  357  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  358  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  359  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  360  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  361  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  362  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  363  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  364  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  365  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  366  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  367  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  368  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  369  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  370  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  371  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  372  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
 75%|███████▍  | 374/500 [00:24<00:08, 15.55it/s] 75%|███████▌  | 376/500 [00:24<00:07, 15.73it/s] 76%|███████▌  | 378/500 [00:24<00:07, 15.89it/s] 76%|███████▌  | 380/500 [00:24<00:07, 15.76it/s] 76%|███████▋  | 382/500 [00:24<00:07, 15.78it/s] 77%|███████▋  | 384/500 [00:24<00:07, 15.82it/s] 77%|███████▋  | 386/500 [00:25<00:07, 15.93it/s] 78%|███████▊  | 388/500 [00:25<00:07, 15.57it/s] 78%|███████▊  | 390/500 [00:25<00:07, 15.40it/s] 78%|███████▊  | 392/500 [00:25<00:06, 15.46it/s] 79%|███████▉  | 394/500 [00:25<00:06, 15.42it/s] 79%|███████▉  | 396/500 [00:25<00:06, 15.60it/s] 80%|███████▉  | 398/500 [00:25<00:06, 15.30it/s] 80%|████████  | 400/500 [00:25<00:06, 15.38it/s] 80%|████████  | 402/500 [00:26<00:06, 14.71it/s] 81%|████████  | 404/500 [00:26<00:06, 14.60it/s] 81%|████████  | 406/500 [00:26<00:06, 14.45it/s] 82%|████████▏ | 408/500 [00:26<00:06, 14.79it/s] 82%|████████▏ | 410/500 [00:26<00:05, 15.08it/s] 82%|████████▏ | 412/500 [00:26<00:05, 15.31it/s] 83%|████████▎ | 414/500 [00:26<00:05, 15.52it/s] 83%|████████▎ | 416/500 [00:27<00:05, 15.61it/s] 84%|████████▎ | 418/500 [00:27<00:05, 15.64it/s] 84%|████████▍ | 420/500 [00:27<00:05, 15.76it/s] 84%|████████▍ | 422/500 [00:27<00:04, 15.82it/s] 85%|████████▍ | 424/500 [00:27<00:04, 15.91it/s] 85%|████████▌ | 426/500 [00:27<00:04, 15.86it/s] 86%|████████▌ | 428/500 [00:27<00:04, 15.96it/s] 86%|████████▌ | 430/500 [00:27<00:04, 16.04it/s] 86%|████████▋ | 432/500 [00:28<00:04, 16.08it/s] 87%|████████▋ | 434/500 [00:28<00:04, 16.18it/s] 87%|████████▋ | 436/500 [00:28<00:03, 16.02it/s] 88%|████████▊ | 438/500 [00:28<00:03, 16.04it/s] 88%|████████▊ | 440/500 [00:28<00:03, 15.93it/s] 88%|████████▊ | 442/500 [00:28<00:03, 16.09it/s] 89%|████████▉ | 444/500 [00:28<00:03, 16.07it/s] 89%|████████▉ | 446/500 [00:28<00:03, 16.08it/s] 90%|████████▉ | 448/500 [00:29<00:03, 16.07it/s] 90%|█████████ | 450/500 [00:29<00:03, 16.14it/s] 90%|█████████ | 452/500 [00:29<00:02, 16.21it/s] 91%|█████████ | 454/500 [00:29<00:02, 16.25it/s] 91%|█████████ | 456/500 [00:29<00:02, 16.26it/s] 92%|█████████▏| 458/500 [00:29<00:02, 16.21it/s] 92%|█████████▏| 460/500 [00:29<00:02, 16.17it/s] 92%|█████████▏| 462/500 [00:29<00:02, 16.19it/s] 93%|█████████▎| 464/500 [00:29<00:02, 16.24it/s] 93%|█████████▎| 466/500 [00:30<00:02, 16.06it/s] 94%|█████████▎| 468/500 [00:30<00:02, 15.96it/s] 94%|█████████▍| 470/500 [00:30<00:01, 15.90it/s] 94%|█████████▍| 472/500 [00:30<00:01, 15.87it/s] 95%|█████████▍| 474/500 [00:30<00:01, 15.85it/s] 95%|█████████▌| 476/500 [00:30<00:01, 15.87it/s] 96%|█████████▌| 478/500 [00:30<00:01, 16.00it/s] 96%|█████████▌| 480/500 [00:31<00:01, 16.04it/s] 96%|█████████▋| 482/500 [00:31<00:01, 16.06it/s] 97%|█████████▋| 484/500 [00:31<00:00, 16.06it/s] 97%|█████████▋| 486/500 [00:31<00:00, 15.96it/s] 98%|█████████▊| 488/500 [00:31<00:00, 15.72it/s] 98%|█████████▊| 490/500 [00:31<00:00, 15.76it/s] 98%|█████████▊| 492/500 [00:31<00:00, 15.87it/s] 99%|█████████▉| 494/500 [00:31<00:00, 16.08it/s] 99%|█████████▉| 496/500 [00:32<00:00, 16.19it/s]Epoch:  373  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  374  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  375  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  376  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  377  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  378  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  379  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  380  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  381  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  382  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  383  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  384  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  385  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  386  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  387  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  388  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  389  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  390  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  391  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  392  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  393  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  394  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  395  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  396  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  397  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  398  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  399  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  400  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  401  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  402  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  403  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  404  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  405  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  406  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  407  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  408  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  409  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  410  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  411  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  412  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  413  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  414  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  415  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  416  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  417  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  418  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  419  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  420  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  421  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  422  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  423  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  424  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  425  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  426  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  427  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  428  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  429  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  430  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  431  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  432  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  433  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  434  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  435  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  436  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  437  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  438  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  439  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  440  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  441  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  442  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  443  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  444  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  445  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  446  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  447  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  448  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  449  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  450  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  451  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  452  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  453  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  454  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  455  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  456  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  457  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  458  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  459  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  460  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  461  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  462  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  463  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  464  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  465  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  466  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  467  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  468  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  469  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  470  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  471  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  472  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  473  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  474  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  475  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  476  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  477  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  478  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  479  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  480  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  481  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  482  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  483  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  484  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  485  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  486  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  487  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  488  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  489  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  490  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  491  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  492  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  493  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  494  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  495  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  496  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
100%|█████████▉| 498/500 [00:32<00:00, 16.19it/s]100%|██████████| 500/500 [00:32<00:00, 15.97it/s]100%|██████████| 500/500 [00:32<00:00, 15.50it/s]
Epoch:  497  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  498  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  499  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
Epoch:  500  	Training Loss: nan
Test Loss:  nan
Valid Loss:  nan
seed is  20
---------------------------------------- NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<51:37,  6.21s/it]  1%|          | 3/500 [00:06<13:45,  1.66s/it]  1%|          | 5/500 [00:06<06:56,  1.19it/s]  1%|▏         | 7/500 [00:06<04:12,  1.95it/s]  2%|▏         | 9/500 [00:06<02:49,  2.90it/s]  2%|▏         | 11/500 [00:13<11:03,  1.36s/it]  3%|▎         | 13/500 [00:13<07:31,  1.08it/s]  3%|▎         | 15/500 [00:13<05:15,  1.54it/s]  3%|▎         | 17/500 [00:13<03:45,  2.14it/s]  4%|▍         | 19/500 [00:13<02:44,  2.92it/s]  4%|▍         | 21/500 [00:20<09:37,  1.21s/it]  5%|▍         | 23/500 [00:20<06:49,  1.16it/s]  5%|▌         | 25/500 [00:20<04:53,  1.62it/s]  5%|▌         | 27/500 [00:20<03:33,  2.21it/s]  6%|▌         | 29/500 [00:20<02:37,  2.98it/s]  6%|▌         | 31/500 [00:26<09:17,  1.19s/it]  7%|▋         | 33/500 [00:27<06:38,  1.17it/s]  7%|▋         | 35/500 [00:27<04:49,  1.60it/s]  7%|▋         | 37/500 [00:27<03:33,  2.16it/s]  8%|▊         | 39/500 [00:27<02:38,  2.91it/s]  8%|▊         | 41/500 [00:33<09:02,  1.18s/it]  9%|▊         | 43/500 [00:33<06:27,  1.18it/s]  9%|▉         | 45/500 [00:34<04:40,  1.62it/s]  9%|▉         | 47/500 [00:34<03:25,  2.20it/s] 10%|▉         | 49/500 [00:34<02:33,  2.94it/s] 10%|█         | 51/500 [00:40<08:51,  1.18s/it] 11%|█         | 53/500 [00:40<06:19,  1.18it/s] 11%|█         | 55/500 [00:41<04:33,  1.63it/s] 11%|█▏        | 57/500 [00:41<03:19,  2.22it/s] 12%|█▏        | 59/500 [00:41<02:27,  2.99it/s] 12%|█▏        | 61/500 [00:47<08:31,  1.17s/it] 13%|█▎        | 63/500 [00:47<06:06,  1.19it/s] 13%|█▎        | 65/500 [00:47<04:23,  1.65it/s] 13%|█▎        | 67/500 [00:47<03:12,  2.25it/s] 14%|█▍        | 69/500 [00:48<02:22,  3.02it/s] 14%|█▍        | 71/500 [00:54<08:25,  1.18s/it] 15%|█▍        | 73/500 [00:54<06:02,  1.18it/s]Epoch:  1  	Training Loss: 0.2410266399383545
Test Loss:  429.8265380859375
Valid Loss:  423.3851318359375
Epoch:  2  	Training Loss: 425.50433349609375
Test Loss:  1.9018927812576294
Valid Loss:  1.8788540363311768
Epoch:  3  	Training Loss: 1.898371934890747
Test Loss:  1.7574927806854248
Valid Loss:  1.7357118129730225
Epoch:  4  	Training Loss: 1.7538952827453613
Test Loss:  1.623902440071106
Valid Loss:  1.6033045053482056
Epoch:  5  	Training Loss: 1.6202478408813477
Test Loss:  1.500331163406372
Valid Loss:  1.4808461666107178
Epoch:  6  	Training Loss: 1.4966366291046143
Test Loss:  1.3860442638397217
Valid Loss:  1.367606282234192
Epoch:  7  	Training Loss: 1.3823254108428955
Test Loss:  1.2803590297698975
Valid Loss:  1.2629066705703735
Epoch:  8  	Training Loss: 1.2766298055648804
Test Loss:  1.182640790939331
Valid Loss:  1.166116714477539
Epoch:  9  	Training Loss: 1.1789138317108154
Test Loss:  1.092301368713379
Valid Loss:  1.0766509771347046
Epoch:  10  	Training Loss: 1.0885872840881348
Test Loss:  1.0087933540344238
Valid Loss:  0.9939664006233215
Epoch:  11  	Training Loss: 1.0051023960113525
Test Loss:  0.9321836829185486
Valid Loss:  0.9184895157814026
Epoch:  12  	Training Loss: 0.9293097257614136
Test Loss:  0.8894634246826172
Valid Loss:  0.8792661428451538
Epoch:  13  	Training Loss: 0.8888468742370605
Test Loss:  0.8620038032531738
Valid Loss:  0.8546793460845947
Epoch:  14  	Training Loss: 0.8630388975143433
Test Loss:  0.8419824838638306
Valid Loss:  0.8361103534698486
Epoch:  15  	Training Loss: 0.8444486260414124
Test Loss:  0.8265103101730347
Valid Loss:  0.8211159706115723
Epoch:  16  	Training Loss: 0.8294650912284851
Test Loss:  0.8130301237106323
Valid Loss:  0.8074110746383667
Epoch:  17  	Training Loss: 0.8159619569778442
Test Loss:  0.8007434010505676
Valid Loss:  0.7947402000427246
Epoch:  18  	Training Loss: 0.8038467168807983
Test Loss:  0.7893295884132385
Valid Loss:  0.7834609746932983
Epoch:  19  	Training Loss: 0.7926341891288757
Test Loss:  0.7784795761108398
Valid Loss:  0.7728978395462036
Epoch:  20  	Training Loss: 0.7819970846176147
Test Loss:  0.7682744264602661
Valid Loss:  0.7630273699760437
Epoch:  21  	Training Loss: 0.7719034552574158
Test Loss:  0.7584601044654846
Valid Loss:  0.7534370422363281
Epoch:  22  	Training Loss: 0.7620989680290222
Test Loss:  0.7490723133087158
Valid Loss:  0.7440348863601685
Epoch:  23  	Training Loss: 0.7525976300239563
Test Loss:  0.7399518489837646
Valid Loss:  0.7348448038101196
Epoch:  24  	Training Loss: 0.7433598041534424
Test Loss:  0.7311567664146423
Valid Loss:  0.7258235216140747
Epoch:  25  	Training Loss: 0.7343418598175049
Test Loss:  0.7226549386978149
Valid Loss:  0.7169495224952698
Epoch:  26  	Training Loss: 0.7255077958106995
Test Loss:  0.7143568992614746
Valid Loss:  0.7082818746566772
Epoch:  27  	Training Loss: 0.7169114351272583
Test Loss:  0.7061730623245239
Valid Loss:  0.6997833251953125
Epoch:  28  	Training Loss: 0.7084593176841736
Test Loss:  0.7009251117706299
Valid Loss:  0.6946438550949097
Epoch:  29  	Training Loss: 0.7032842040061951
Test Loss:  0.7003720998764038
Valid Loss:  0.6939966678619385
Epoch:  30  	Training Loss: 0.7026729583740234
Test Loss:  0.700007438659668
Valid Loss:  0.6935461759567261
Epoch:  31  	Training Loss: 0.7022226452827454
Test Loss:  0.6997438669204712
Valid Loss:  0.6932224035263062
Epoch:  32  	Training Loss: 0.7019003629684448
Test Loss:  0.699569582939148
Valid Loss:  0.6930018067359924
Epoch:  33  	Training Loss: 0.7016831040382385
Test Loss:  0.6994197964668274
Valid Loss:  0.6928020715713501
Epoch:  34  	Training Loss: 0.7015045881271362
Test Loss:  0.6992883086204529
Valid Loss:  0.6926344037055969
Epoch:  35  	Training Loss: 0.7013569474220276
Test Loss:  0.6991738080978394
Valid Loss:  0.6924928426742554
Epoch:  36  	Training Loss: 0.7012336254119873
Test Loss:  0.6990674734115601
Valid Loss:  0.6923638582229614
Epoch:  37  	Training Loss: 0.7011250257492065
Test Loss:  0.6989831924438477
Valid Loss:  0.6922595500946045
Epoch:  38  	Training Loss: 0.7010371685028076
Test Loss:  0.6989032626152039
Valid Loss:  0.6921699643135071
Epoch:  39  	Training Loss: 0.7009551525115967
Test Loss:  0.6988338232040405
Valid Loss:  0.6920949220657349
Epoch:  40  	Training Loss: 0.7008839845657349
Test Loss:  0.6987727880477905
Valid Loss:  0.6920232772827148
Epoch:  41  	Training Loss: 0.7008169889450073
Test Loss:  0.698723554611206
Valid Loss:  0.6919543743133545
Epoch:  42  	Training Loss: 0.7007511854171753
Test Loss:  0.6986770629882812
Valid Loss:  0.6918858885765076
Epoch:  43  	Training Loss: 0.7006892561912537
Test Loss:  0.698636531829834
Valid Loss:  0.6918268203735352
Epoch:  44  	Training Loss: 0.700639009475708
Test Loss:  0.6985966563224792
Valid Loss:  0.6917680501937866
Epoch:  45  	Training Loss: 0.7005923986434937
Test Loss:  0.6985602378845215
Valid Loss:  0.691716194152832
Epoch:  46  	Training Loss: 0.7005518674850464
Test Loss:  0.6985240578651428
Valid Loss:  0.6916646361351013
Epoch:  47  	Training Loss: 0.7005127668380737
Test Loss:  0.6984895467758179
Valid Loss:  0.691616415977478
Epoch:  48  	Training Loss: 0.7004766464233398
Test Loss:  0.6984552145004272
Valid Loss:  0.6915683746337891
Epoch:  49  	Training Loss: 0.7004408240318298
Test Loss:  0.6984272003173828
Valid Loss:  0.6915234327316284
Epoch:  50  	Training Loss: 0.7004052400588989
Test Loss:  0.6983999013900757
Valid Loss:  0.6914823055267334
Epoch:  51  	Training Loss: 0.7003695964813232
Test Loss:  0.6983727216720581
Valid Loss:  0.6914424896240234
Epoch:  52  	Training Loss: 0.7003340721130371
Test Loss:  0.6983458995819092
Valid Loss:  0.6914076805114746
Epoch:  53  	Training Loss: 0.7002975940704346
Test Loss:  0.698319137096405
Valid Loss:  0.6913741827011108
Epoch:  54  	Training Loss: 0.7002619504928589
Test Loss:  0.6982929110527039
Valid Loss:  0.6913434267044067
Epoch:  55  	Training Loss: 0.7002300024032593
Test Loss:  0.6982673406600952
Valid Loss:  0.6913185715675354
Epoch:  56  	Training Loss: 0.7001991868019104
Test Loss:  0.6982419490814209
Valid Loss:  0.6912937164306641
Epoch:  57  	Training Loss: 0.7001690864562988
Test Loss:  0.6982172131538391
Valid Loss:  0.6912704706192017
Epoch:  58  	Training Loss: 0.7001425623893738
Test Loss:  0.6981942653656006
Valid Loss:  0.6912505626678467
Epoch:  59  	Training Loss: 0.7001196146011353
Test Loss:  0.6981713771820068
Valid Loss:  0.6912306547164917
Epoch:  60  	Training Loss: 0.7000970244407654
Test Loss:  0.6981489658355713
Valid Loss:  0.6912105083465576
Epoch:  61  	Training Loss: 0.700075089931488
Test Loss:  0.6981265544891357
Valid Loss:  0.6911904811859131
Epoch:  62  	Training Loss: 0.7000532150268555
Test Loss:  0.6981056332588196
Valid Loss:  0.6911722421646118
Epoch:  63  	Training Loss: 0.7000331878662109
Test Loss:  0.6980854868888855
Valid Loss:  0.6911540031433105
Epoch:  64  	Training Loss: 0.7000138759613037
Test Loss:  0.6980653405189514
Valid Loss:  0.6911357641220093
Epoch:  65  	Training Loss: 0.699994683265686
Test Loss:  0.6980451941490173
Valid Loss:  0.691117525100708
Epoch:  66  	Training Loss: 0.6999754905700684
Test Loss:  0.6980249881744385
Valid Loss:  0.6910992860794067
Epoch:  67  	Training Loss: 0.6999562382698059
Test Loss:  0.6980065107345581
Valid Loss:  0.6910809278488159
Epoch:  68  	Training Loss: 0.6999369859695435
Test Loss:  0.697987973690033
Valid Loss:  0.6910626888275146
Epoch:  69  	Training Loss: 0.699917733669281
Test Loss:  0.6979694366455078
Valid Loss:  0.6910444498062134
Epoch:  70  	Training Loss: 0.6998985409736633
Test Loss:  0.6979508996009827
Valid Loss:  0.6910262107849121
Epoch:  71  	Training Loss: 0.6998792886734009
Test Loss:  0.6979323625564575
Valid Loss:  0.6910079717636108
Epoch:  72  	Training Loss: 0.6998600363731384
Test Loss:  0.6979109644889832
Valid Loss:  0.6909868717193604
Epoch:  73  	Training Loss: 0.6998380422592163
Test Loss:  0.6978895664215088
Valid Loss:  0.6909658312797546
Epoch:  74  	Training Loss: 0.6998164057731628
Test Loss:  0.6978687047958374
Valid Loss:  0.6909452676773071
Epoch:  75  	Training Loss: 0.6997953653335571
Test Loss:  0.6978477239608765
 15%|█▌        | 75/500 [00:54<04:21,  1.63it/s] 15%|█▌        | 77/500 [00:54<03:10,  2.22it/s] 16%|█▌        | 79/500 [00:54<02:20,  2.99it/s] 16%|█▌        | 81/500 [01:01<08:17,  1.19s/it] 17%|█▋        | 83/500 [01:01<05:55,  1.17it/s] 17%|█▋        | 85/500 [01:01<04:16,  1.62it/s] 17%|█▋        | 87/500 [01:01<03:06,  2.21it/s] 18%|█▊        | 89/500 [01:01<02:18,  2.97it/s] 18%|█▊        | 91/500 [01:08<08:10,  1.20s/it] 19%|█▊        | 93/500 [01:08<05:49,  1.17it/s] 19%|█▉        | 95/500 [01:08<04:11,  1.61it/s] 19%|█▉        | 97/500 [01:08<03:03,  2.20it/s] 20%|█▉        | 99/500 [01:08<02:15,  2.96it/s] 20%|██        | 101/500 [01:15<07:49,  1.18s/it] 21%|██        | 103/500 [01:15<05:34,  1.19it/s] 21%|██        | 105/500 [01:15<04:00,  1.64it/s] 21%|██▏       | 107/500 [01:15<02:55,  2.24it/s] 22%|██▏       | 109/500 [01:15<02:09,  3.02it/s] 22%|██▏       | 111/500 [01:21<07:34,  1.17s/it] 23%|██▎       | 113/500 [01:21<05:25,  1.19it/s] 23%|██▎       | 115/500 [01:22<03:54,  1.64it/s] 23%|██▎       | 117/500 [01:22<02:52,  2.22it/s] 24%|██▍       | 119/500 [01:22<02:07,  2.98it/s] 24%|██▍       | 121/500 [01:28<07:21,  1.17s/it] 25%|██▍       | 123/500 [01:28<05:17,  1.19it/s] 25%|██▌       | 125/500 [01:28<03:48,  1.64it/s] 25%|██▌       | 127/500 [01:28<02:46,  2.24it/s] 26%|██▌       | 129/500 [01:29<02:03,  3.02it/s] 26%|██▌       | 131/500 [01:35<07:10,  1.17s/it] 27%|██▋       | 133/500 [01:35<05:07,  1.19it/s] 27%|██▋       | 135/500 [01:35<03:41,  1.65it/s] 27%|██▋       | 137/500 [01:35<02:40,  2.25it/s] 28%|██▊       | 139/500 [01:35<01:59,  3.03it/s] 28%|██▊       | 141/500 [01:42<06:57,  1.16s/it] 29%|██▊       | 143/500 [01:42<04:58,  1.20it/s] 29%|██▉       | 145/500 [01:42<03:34,  1.65it/s] 29%|██▉       | 147/500 [01:42<02:37,  2.25it/s]Valid Loss:  0.6909246444702148
Epoch:  76  	Training Loss: 0.6997746229171753
Test Loss:  0.6978272795677185
Valid Loss:  0.6909043788909912
Epoch:  77  	Training Loss: 0.6997541785240173
Test Loss:  0.697806715965271
Valid Loss:  0.6908842325210571
Epoch:  78  	Training Loss: 0.6997337937355042
Test Loss:  0.6977862119674683
Valid Loss:  0.690864086151123
Epoch:  79  	Training Loss: 0.6997134685516357
Test Loss:  0.6977657675743103
Valid Loss:  0.6908438801765442
Epoch:  80  	Training Loss: 0.6996930241584778
Test Loss:  0.6977452039718628
Valid Loss:  0.6908235549926758
Epoch:  81  	Training Loss: 0.6996725797653198
Test Loss:  0.6977246999740601
Valid Loss:  0.6908034086227417
Epoch:  82  	Training Loss: 0.6996521353721619
Test Loss:  0.6977040767669678
Valid Loss:  0.6907831430435181
Epoch:  83  	Training Loss: 0.6996316313743591
Test Loss:  0.6976833343505859
Valid Loss:  0.6907627582550049
Epoch:  84  	Training Loss: 0.6996110677719116
Test Loss:  0.6976625919342041
Valid Loss:  0.6907423138618469
Epoch:  85  	Training Loss: 0.6995904445648193
Test Loss:  0.6976419687271118
Valid Loss:  0.6907219290733337
Epoch:  86  	Training Loss: 0.699569821357727
Test Loss:  0.69762122631073
Valid Loss:  0.6907014846801758
Epoch:  87  	Training Loss: 0.6995491981506348
Test Loss:  0.6976004838943481
Valid Loss:  0.6906810998916626
Epoch:  88  	Training Loss: 0.6995285749435425
Test Loss:  0.6975798010826111
Valid Loss:  0.6906607151031494
Epoch:  89  	Training Loss: 0.6995080709457397
Test Loss:  0.6975590586662292
Valid Loss:  0.6906402707099915
Epoch:  90  	Training Loss: 0.6994874477386475
Test Loss:  0.6975382566452026
Valid Loss:  0.6906198263168335
Epoch:  91  	Training Loss: 0.6994667053222656
Test Loss:  0.6975175142288208
Valid Loss:  0.6905993223190308
Epoch:  92  	Training Loss: 0.6994460821151733
Test Loss:  0.6974959969520569
Valid Loss:  0.6905782222747803
Epoch:  93  	Training Loss: 0.6994247436523438
Test Loss:  0.697474479675293
Valid Loss:  0.690557062625885
Epoch:  94  	Training Loss: 0.6994032859802246
Test Loss:  0.6974530220031738
Valid Loss:  0.6905359029769897
Epoch:  95  	Training Loss: 0.6993820071220398
Test Loss:  0.6974315643310547
Valid Loss:  0.6905146837234497
Epoch:  96  	Training Loss: 0.6993604898452759
Test Loss:  0.697409987449646
Valid Loss:  0.6904935240745544
Epoch:  97  	Training Loss: 0.6993391513824463
Test Loss:  0.6973884701728821
Valid Loss:  0.6904723048210144
Epoch:  98  	Training Loss: 0.6993178129196167
Test Loss:  0.6973669528961182
Valid Loss:  0.6904511451721191
Epoch:  99  	Training Loss: 0.6992963552474976
Test Loss:  0.6973453760147095
Valid Loss:  0.6904298663139343
Epoch:  100  	Training Loss: 0.6992749571800232
Test Loss:  0.6973239183425903
Valid Loss:  0.6904087066650391
Epoch:  101  	Training Loss: 0.6992535591125488
Test Loss:  0.6973024010658264
Valid Loss:  0.6903874278068542
Epoch:  102  	Training Loss: 0.6992321014404297
Test Loss:  0.6972838044166565
Valid Loss:  0.6903692483901978
Epoch:  103  	Training Loss: 0.6992136836051941
Test Loss:  0.6972652673721313
Valid Loss:  0.6903509497642517
Epoch:  104  	Training Loss: 0.6991952657699585
Test Loss:  0.697246789932251
Valid Loss:  0.6903327703475952
Epoch:  105  	Training Loss: 0.6991768479347229
Test Loss:  0.6972282528877258
Valid Loss:  0.690314531326294
Epoch:  106  	Training Loss: 0.6991584300994873
Test Loss:  0.6972097158432007
Valid Loss:  0.6902962923049927
Epoch:  107  	Training Loss: 0.6991400122642517
Test Loss:  0.6971912980079651
Valid Loss:  0.6902780532836914
Epoch:  108  	Training Loss: 0.6991215944290161
Test Loss:  0.6971727609634399
Valid Loss:  0.6902598142623901
Epoch:  109  	Training Loss: 0.6991032361984253
Test Loss:  0.6971542835235596
Valid Loss:  0.6902416348457336
Epoch:  110  	Training Loss: 0.6990848183631897
Test Loss:  0.6971358060836792
Valid Loss:  0.6902234554290771
Epoch:  111  	Training Loss: 0.6990664601325989
Test Loss:  0.6971173286437988
Valid Loss:  0.6902052760124207
Epoch:  112  	Training Loss: 0.6990481615066528
Test Loss:  0.6970982551574707
Valid Loss:  0.6901864409446716
Epoch:  113  	Training Loss: 0.6990290880203247
Test Loss:  0.697079062461853
Valid Loss:  0.6901676058769226
Epoch:  114  	Training Loss: 0.6990100145339966
Test Loss:  0.6970599889755249
Valid Loss:  0.6901488304138184
Epoch:  115  	Training Loss: 0.698991060256958
Test Loss:  0.6970407962799072
Valid Loss:  0.6901299953460693
Epoch:  116  	Training Loss: 0.6989721059799194
Test Loss:  0.6970217227935791
Valid Loss:  0.6901111602783203
Epoch:  117  	Training Loss: 0.6989530920982361
Test Loss:  0.697002649307251
Valid Loss:  0.6900923252105713
Epoch:  118  	Training Loss: 0.6989340782165527
Test Loss:  0.6969835162162781
Valid Loss:  0.690073549747467
Epoch:  119  	Training Loss: 0.6989150643348694
Test Loss:  0.69696444272995
Valid Loss:  0.690054714679718
Epoch:  120  	Training Loss: 0.698896050453186
Test Loss:  0.6969453692436218
Valid Loss:  0.6900359392166138
Epoch:  121  	Training Loss: 0.6988770961761475
Test Loss:  0.6969261765480042
Valid Loss:  0.6900171041488647
Epoch:  122  	Training Loss: 0.6988580226898193
Test Loss:  0.6969078183174133
Valid Loss:  0.689998984336853
Epoch:  123  	Training Loss: 0.6988397240638733
Test Loss:  0.6968892812728882
Valid Loss:  0.6899808049201965
Epoch:  124  	Training Loss: 0.6988214254379272
Test Loss:  0.6968709230422974
Valid Loss:  0.6899627447128296
Epoch:  125  	Training Loss: 0.6988031268119812
Test Loss:  0.6968525648117065
Valid Loss:  0.6899445652961731
Epoch:  126  	Training Loss: 0.6987848281860352
Test Loss:  0.6968340873718262
Valid Loss:  0.6899263858795166
Epoch:  127  	Training Loss: 0.6987664699554443
Test Loss:  0.6968157291412354
Valid Loss:  0.6899083256721497
Epoch:  128  	Training Loss: 0.6987481713294983
Test Loss:  0.6967973113059998
Valid Loss:  0.6898902058601379
Epoch:  129  	Training Loss: 0.6987298727035522
Test Loss:  0.6967789530754089
Valid Loss:  0.6898720860481262
Epoch:  130  	Training Loss: 0.698711633682251
Test Loss:  0.6967605352401733
Valid Loss:  0.6898540258407593
Epoch:  131  	Training Loss: 0.6986932754516602
Test Loss:  0.6967421770095825
Valid Loss:  0.6898359060287476
Epoch:  132  	Training Loss: 0.6986750364303589
Test Loss:  0.6967238783836365
Valid Loss:  0.6898178458213806
Epoch:  133  	Training Loss: 0.6986568570137024
Test Loss:  0.69670569896698
Valid Loss:  0.689799964427948
Epoch:  134  	Training Loss: 0.6986387372016907
Test Loss:  0.6966874003410339
Valid Loss:  0.689781904220581
Epoch:  135  	Training Loss: 0.6986205577850342
Test Loss:  0.6966692209243774
Valid Loss:  0.6897640228271484
Epoch:  136  	Training Loss: 0.6986024379730225
Test Loss:  0.6966509222984314
Valid Loss:  0.689746081829071
Epoch:  137  	Training Loss: 0.6985843181610107
Test Loss:  0.6966326832771301
Valid Loss:  0.6897280812263489
Epoch:  138  	Training Loss: 0.6985660791397095
Test Loss:  0.6966145634651184
Valid Loss:  0.6897101998329163
Epoch:  139  	Training Loss: 0.6985481381416321
Test Loss:  0.6965963840484619
Valid Loss:  0.6896922588348389
Epoch:  140  	Training Loss: 0.6985300183296204
Test Loss:  0.6965781450271606
Valid Loss:  0.6896743774414062
Epoch:  141  	Training Loss: 0.6985119581222534
Test Loss:  0.6965600252151489
Valid Loss:  0.6896564960479736
Epoch:  142  	Training Loss: 0.6984938383102417
Test Loss:  0.696539044380188
Valid Loss:  0.6896358728408813
Epoch:  143  	Training Loss: 0.6984729766845703
Test Loss:  0.696518063545227
Valid Loss:  0.6896151900291443
Epoch:  144  	Training Loss: 0.6984521150588989
Test Loss:  0.6964970827102661
Valid Loss:  0.6895945072174072
Epoch:  145  	Training Loss: 0.6984312534332275
Test Loss:  0.6964760422706604
Valid Loss:  0.6895737648010254
Epoch:  146  	Training Loss: 0.6984103918075562
Test Loss:  0.6964550018310547
Valid Loss:  0.6895530819892883
Epoch:  147  	Training Loss: 0.6983894109725952
Test Loss:  0.6964340209960938
Valid Loss:  0.6895323991775513
Epoch:  148  	Training Loss: 0.6983685493469238
Test Loss:  0.6964128613471985
Valid Loss:  0.6895115375518799
Epoch:  149  	Training Loss: 0.6983475685119629
Test Loss:  0.6963918805122375
Valid Loss:   30%|██▉       | 149/500 [01:42<01:56,  3.02it/s] 30%|███       | 151/500 [01:48<06:49,  1.17s/it] 31%|███       | 153/500 [01:49<04:52,  1.18it/s] 31%|███       | 155/500 [01:49<03:30,  1.64it/s] 31%|███▏      | 157/500 [01:49<02:33,  2.24it/s] 32%|███▏      | 159/500 [01:49<01:53,  3.00it/s] 32%|███▏      | 161/500 [01:55<06:37,  1.17s/it] 33%|███▎      | 163/500 [01:55<04:44,  1.19it/s] 33%|███▎      | 165/500 [01:56<03:24,  1.64it/s] 33%|███▎      | 167/500 [01:56<02:28,  2.24it/s] 34%|███▍      | 169/500 [01:56<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:02<06:26,  1.18s/it] 35%|███▍      | 173/500 [02:02<04:36,  1.18it/s] 35%|███▌      | 175/500 [02:02<03:18,  1.64it/s] 35%|███▌      | 177/500 [02:02<02:24,  2.23it/s] 36%|███▌      | 179/500 [02:03<01:46,  3.00it/s] 36%|███▌      | 181/500 [02:09<06:15,  1.18s/it] 37%|███▋      | 183/500 [02:09<04:27,  1.19it/s] 37%|███▋      | 185/500 [02:09<03:12,  1.64it/s] 37%|███▋      | 187/500 [02:09<02:19,  2.24it/s] 38%|███▊      | 189/500 [02:09<01:43,  3.01it/s] 38%|███▊      | 191/500 [02:16<06:08,  1.19s/it] 39%|███▊      | 193/500 [02:16<04:22,  1.17it/s] 39%|███▉      | 195/500 [02:16<03:08,  1.62it/s] 39%|███▉      | 197/500 [02:16<02:17,  2.21it/s] 40%|███▉      | 199/500 [02:16<01:41,  2.97it/s] 40%|████      | 201/500 [02:23<05:53,  1.18s/it] 41%|████      | 203/500 [02:23<04:12,  1.18it/s] 41%|████      | 205/500 [02:23<03:01,  1.63it/s] 41%|████▏     | 207/500 [02:23<02:11,  2.23it/s] 42%|████▏     | 209/500 [02:23<01:37,  2.99it/s] 42%|████▏     | 211/500 [02:30<05:49,  1.21s/it] 43%|████▎     | 213/500 [02:30<04:09,  1.15it/s] 43%|████▎     | 215/500 [02:30<02:59,  1.59it/s] 43%|████▎     | 217/500 [02:30<02:10,  2.17it/s] 44%|████▍     | 219/500 [02:30<01:36,  2.92it/s] 44%|████▍     | 221/500 [02:37<05:39,  1.22s/it]0.6894909143447876
Epoch:  150  	Training Loss: 0.698326587677002
Test Loss:  0.6963708400726318
Valid Loss:  0.6894701719284058
Epoch:  151  	Training Loss: 0.6983056664466858
Test Loss:  0.6963497400283813
Valid Loss:  0.6894493699073792
Epoch:  152  	Training Loss: 0.6982846856117249
Test Loss:  0.696331262588501
Valid Loss:  0.6894311904907227
Epoch:  153  	Training Loss: 0.6982663869857788
Test Loss:  0.6963129043579102
Valid Loss:  0.6894131302833557
Epoch:  154  	Training Loss: 0.6982480883598328
Test Loss:  0.6962944269180298
Valid Loss:  0.6893949508666992
Epoch:  155  	Training Loss: 0.6982297301292419
Test Loss:  0.6962759494781494
Valid Loss:  0.689376711845398
Epoch:  156  	Training Loss: 0.6982113122940063
Test Loss:  0.696257472038269
Valid Loss:  0.6893585920333862
Epoch:  157  	Training Loss: 0.6981929540634155
Test Loss:  0.6962389349937439
Valid Loss:  0.689340353012085
Epoch:  158  	Training Loss: 0.6981745958328247
Test Loss:  0.6962205171585083
Valid Loss:  0.6893222332000732
Epoch:  159  	Training Loss: 0.6981562376022339
Test Loss:  0.6962020397186279
Valid Loss:  0.689303994178772
Epoch:  160  	Training Loss: 0.6981378793716431
Test Loss:  0.6961835622787476
Valid Loss:  0.6892858743667603
Epoch:  161  	Training Loss: 0.6981195211410522
Test Loss:  0.6961650848388672
Valid Loss:  0.689267635345459
Epoch:  162  	Training Loss: 0.6981011629104614
Test Loss:  0.6961449384689331
Valid Loss:  0.6892478466033936
Epoch:  163  	Training Loss: 0.6980811357498169
Test Loss:  0.696124792098999
Valid Loss:  0.6892279982566833
Epoch:  164  	Training Loss: 0.6980611085891724
Test Loss:  0.6961047053337097
Valid Loss:  0.6892081499099731
Epoch:  165  	Training Loss: 0.6980410814285278
Test Loss:  0.6960844993591309
Valid Loss:  0.6891883611679077
Epoch:  166  	Training Loss: 0.6980210542678833
Test Loss:  0.6960644125938416
Valid Loss:  0.6891684532165527
Epoch:  167  	Training Loss: 0.6980010271072388
Test Loss:  0.6960443258285522
Valid Loss:  0.6891486644744873
Epoch:  168  	Training Loss: 0.6979809999465942
Test Loss:  0.6960240602493286
Valid Loss:  0.6891288161277771
Epoch:  169  	Training Loss: 0.6979609727859497
Test Loss:  0.6960040330886841
Valid Loss:  0.6891089677810669
Epoch:  170  	Training Loss: 0.6979408860206604
Test Loss:  0.6959838271141052
Valid Loss:  0.6890891790390015
Epoch:  171  	Training Loss: 0.6979209184646606
Test Loss:  0.6959636807441711
Valid Loss:  0.6890692710876465
Epoch:  172  	Training Loss: 0.6979008316993713
Test Loss:  0.6959456205368042
Valid Loss:  0.6890515089035034
Epoch:  173  	Training Loss: 0.697882890701294
Test Loss:  0.695927619934082
Valid Loss:  0.6890337467193604
Epoch:  174  	Training Loss: 0.6978649497032166
Test Loss:  0.6959095001220703
Valid Loss:  0.6890159845352173
Epoch:  175  	Training Loss: 0.6978470087051392
Test Loss:  0.6958914995193481
Valid Loss:  0.6889982223510742
Epoch:  176  	Training Loss: 0.697829008102417
Test Loss:  0.695873498916626
Valid Loss:  0.6889804601669312
Epoch:  177  	Training Loss: 0.6978111267089844
Test Loss:  0.6958554983139038
Valid Loss:  0.6889627575874329
Epoch:  178  	Training Loss: 0.697793185710907
Test Loss:  0.6958374977111816
Valid Loss:  0.6889450550079346
Epoch:  179  	Training Loss: 0.6977753639221191
Test Loss:  0.6958194971084595
Valid Loss:  0.6889273524284363
Epoch:  180  	Training Loss: 0.6977574825286865
Test Loss:  0.6958016753196716
Valid Loss:  0.6889097094535828
Epoch:  181  	Training Loss: 0.6977397203445435
Test Loss:  0.6957837343215942
Valid Loss:  0.6888920664787292
Epoch:  182  	Training Loss: 0.6977218389511108
Test Loss:  0.6957640647888184
Valid Loss:  0.6888726949691772
Epoch:  183  	Training Loss: 0.6977022886276245
Test Loss:  0.6957443356513977
Valid Loss:  0.6888532638549805
Epoch:  184  	Training Loss: 0.6976826786994934
Test Loss:  0.695724606513977
Valid Loss:  0.6888338327407837
Epoch:  185  	Training Loss: 0.6976630687713623
Test Loss:  0.6957049369812012
Valid Loss:  0.6888144612312317
Epoch:  186  	Training Loss: 0.6976434588432312
Test Loss:  0.6956852674484253
Valid Loss:  0.6887950897216797
Epoch:  187  	Training Loss: 0.6976239085197449
Test Loss:  0.6956655979156494
Valid Loss:  0.6887756586074829
Epoch:  188  	Training Loss: 0.6976042985916138
Test Loss:  0.6956459283828735
Valid Loss:  0.6887563467025757
Epoch:  189  	Training Loss: 0.6975848078727722
Test Loss:  0.6956263184547424
Valid Loss:  0.6887370347976685
Epoch:  190  	Training Loss: 0.6975653171539307
Test Loss:  0.6956067085266113
Valid Loss:  0.6887176632881165
Epoch:  191  	Training Loss: 0.6975457668304443
Test Loss:  0.6955870389938354
Valid Loss:  0.6886982917785645
Epoch:  192  	Training Loss: 0.697526216506958
Test Loss:  0.6955677270889282
Valid Loss:  0.6886792778968811
Epoch:  193  	Training Loss: 0.6975069642066956
Test Loss:  0.6955483555793762
Valid Loss:  0.6886601448059082
Epoch:  194  	Training Loss: 0.6974877119064331
Test Loss:  0.6955289244651794
Valid Loss:  0.6886411309242249
Epoch:  195  	Training Loss: 0.6974684000015259
Test Loss:  0.6955095529556274
Valid Loss:  0.6886221170425415
Epoch:  196  	Training Loss: 0.6974492073059082
Test Loss:  0.6954902410507202
Valid Loss:  0.6886029839515686
Epoch:  197  	Training Loss: 0.697429895401001
Test Loss:  0.6954708099365234
Valid Loss:  0.6885839104652405
Epoch:  198  	Training Loss: 0.6974107027053833
Test Loss:  0.6954514384269714
Valid Loss:  0.6885648965835571
Epoch:  199  	Training Loss: 0.6973914504051208
Test Loss:  0.695432186126709
Valid Loss:  0.6885458827018738
Epoch:  200  	Training Loss: 0.6973721981048584
Test Loss:  0.6954128742218018
Valid Loss:  0.6885268092155457
Epoch:  201  	Training Loss: 0.6973530054092407
Test Loss:  0.6953935623168945
Valid Loss:  0.6885077953338623
Epoch:  202  	Training Loss: 0.697333812713623
Test Loss:  0.6953752636909485
Valid Loss:  0.6884898543357849
Epoch:  203  	Training Loss: 0.6973156332969666
Test Loss:  0.695357084274292
Valid Loss:  0.6884719133377075
Epoch:  204  	Training Loss: 0.6972975134849548
Test Loss:  0.6953388452529907
Valid Loss:  0.6884539127349854
Epoch:  205  	Training Loss: 0.6972793340682983
Test Loss:  0.6953206658363342
Valid Loss:  0.688435971736908
Epoch:  206  	Training Loss: 0.6972613334655762
Test Loss:  0.6953024864196777
Valid Loss:  0.6884180307388306
Epoch:  207  	Training Loss: 0.6972432136535645
Test Loss:  0.6952842473983765
Valid Loss:  0.688400149345398
Epoch:  208  	Training Loss: 0.6972250938415527
Test Loss:  0.6952661275863647
Valid Loss:  0.6883822679519653
Epoch:  209  	Training Loss: 0.697206974029541
Test Loss:  0.6952478885650635
Valid Loss:  0.6883643865585327
Epoch:  210  	Training Loss: 0.6971889734268188
Test Loss:  0.6952297687530518
Valid Loss:  0.6883465051651001
Epoch:  211  	Training Loss: 0.6971708536148071
Test Loss:  0.69521164894104
Valid Loss:  0.6883286833763123
Epoch:  212  	Training Loss: 0.6971529126167297
Test Loss:  0.6951916217803955
Valid Loss:  0.6883089542388916
Epoch:  213  	Training Loss: 0.69713294506073
Test Loss:  0.695171594619751
Valid Loss:  0.6882891654968262
Epoch:  214  	Training Loss: 0.697113037109375
Test Loss:  0.6951515078544617
Valid Loss:  0.6882693767547607
Epoch:  215  	Training Loss: 0.6970930695533752
Test Loss:  0.6951314210891724
Valid Loss:  0.6882496476173401
Epoch:  216  	Training Loss: 0.6970731019973755
Test Loss:  0.6951113939285278
Valid Loss:  0.6882299184799194
Epoch:  217  	Training Loss: 0.6970531940460205
Test Loss:  0.6950913667678833
Valid Loss:  0.6882102489471436
Epoch:  218  	Training Loss: 0.6970332860946655
Test Loss:  0.6950713396072388
Valid Loss:  0.6881904602050781
Epoch:  219  	Training Loss: 0.6970133185386658
Test Loss:  0.6950513124465942
Valid Loss:  0.6881706714630127
Epoch:  220  	Training Loss: 0.696993350982666
Test Loss:  0.6950312852859497
Valid Loss:  0.6881510019302368
Epoch:  221  	Training Loss: 0.696973443031311
Test Loss:  0.6950112581253052
Valid Loss:  0.6881312131881714
Epoch:  222  	Training Loss: 0.696953535079956
Test Loss:  0.6949918270111084
Valid Loss:  0.6881121397018433
Epoch:  223  	Training Loss: 0.696934163570404
Test Loss:  0.6949723958969116
Valid Loss:   45%|████▍     | 223/500 [02:37<04:02,  1.14it/s] 45%|████▌     | 225/500 [02:37<02:53,  1.58it/s] 45%|████▌     | 227/500 [02:37<02:06,  2.17it/s] 46%|████▌     | 229/500 [02:37<01:32,  2.92it/s] 46%|████▌     | 231/500 [02:44<05:21,  1.20s/it] 47%|████▋     | 233/500 [02:44<03:49,  1.16it/s] 47%|████▋     | 235/500 [02:44<02:44,  1.61it/s] 47%|████▋     | 237/500 [02:44<02:00,  2.19it/s] 48%|████▊     | 239/500 [02:44<01:28,  2.95it/s] 48%|████▊     | 241/500 [02:51<05:06,  1.18s/it] 49%|████▊     | 243/500 [02:51<03:37,  1.18it/s] 49%|████▉     | 245/500 [02:51<02:36,  1.63it/s] 49%|████▉     | 247/500 [02:51<01:53,  2.23it/s] 50%|████▉     | 249/500 [02:51<01:23,  2.99it/s] 50%|█████     | 251/500 [02:57<04:53,  1.18s/it] 51%|█████     | 253/500 [02:58<03:29,  1.18it/s] 51%|█████     | 255/500 [02:58<02:29,  1.63it/s] 51%|█████▏    | 257/500 [02:58<01:48,  2.23it/s] 52%|█████▏    | 259/500 [02:58<01:20,  2.99it/s] 52%|█████▏    | 261/500 [03:04<04:46,  1.20s/it] 53%|█████▎    | 263/500 [03:04<03:23,  1.16it/s] 53%|█████▎    | 265/500 [03:05<02:25,  1.61it/s] 53%|█████▎    | 267/500 [03:05<01:45,  2.20it/s] 54%|█████▍    | 269/500 [03:05<01:17,  2.96it/s] 54%|█████▍    | 271/500 [03:11<04:29,  1.18s/it] 55%|█████▍    | 273/500 [03:11<03:11,  1.18it/s] 55%|█████▌    | 275/500 [03:11<02:17,  1.63it/s] 55%|█████▌    | 277/500 [03:12<01:40,  2.23it/s] 56%|█████▌    | 279/500 [03:12<01:13,  3.00it/s] 56%|█████▌    | 281/500 [03:18<04:16,  1.17s/it] 57%|█████▋    | 283/500 [03:18<03:02,  1.19it/s] 57%|█████▋    | 285/500 [03:18<02:10,  1.65it/s] 57%|█████▋    | 287/500 [03:18<01:34,  2.24it/s] 58%|█████▊    | 289/500 [03:18<01:10,  3.01it/s] 58%|█████▊    | 291/500 [03:25<04:09,  1.19s/it] 59%|█████▊    | 293/500 [03:25<02:58,  1.16it/s] 59%|█████▉    | 295/500 [03:25<02:08,  1.60it/s]0.6880929470062256
Epoch:  224  	Training Loss: 0.6969148516654968
Test Loss:  0.6949529051780701
Valid Loss:  0.6880738735198975
Epoch:  225  	Training Loss: 0.6968954801559448
Test Loss:  0.6949334740638733
Valid Loss:  0.688054621219635
Epoch:  226  	Training Loss: 0.6968761682510376
Test Loss:  0.6949139833450317
Valid Loss:  0.6880354881286621
Epoch:  227  	Training Loss: 0.6968568563461304
Test Loss:  0.6948946714401245
Valid Loss:  0.688016414642334
Epoch:  228  	Training Loss: 0.6968375444412231
Test Loss:  0.694875180721283
Valid Loss:  0.6879972219467163
Epoch:  229  	Training Loss: 0.6968182325363159
Test Loss:  0.694855809211731
Valid Loss:  0.6879781484603882
Epoch:  230  	Training Loss: 0.6967989206314087
Test Loss:  0.6948363780975342
Valid Loss:  0.6879590153694153
Epoch:  231  	Training Loss: 0.6967796087265015
Test Loss:  0.6948169469833374
Valid Loss:  0.6879398822784424
Epoch:  232  	Training Loss: 0.6967602968215942
Test Loss:  0.6948001384735107
Valid Loss:  0.6879233717918396
Epoch:  233  	Training Loss: 0.6967436075210571
Test Loss:  0.6947833895683289
Valid Loss:  0.6879068613052368
Epoch:  234  	Training Loss: 0.69672691822052
Test Loss:  0.6947665810585022
Valid Loss:  0.6878902912139893
Epoch:  235  	Training Loss: 0.6967102289199829
Test Loss:  0.6947498321533203
Valid Loss:  0.6878737807273865
Epoch:  236  	Training Loss: 0.6966935396194458
Test Loss:  0.6947330832481384
Valid Loss:  0.6878573894500732
Epoch:  237  	Training Loss: 0.6966769099235535
Test Loss:  0.6947163939476013
Valid Loss:  0.6878408193588257
Epoch:  238  	Training Loss: 0.6966602802276611
Test Loss:  0.6946997046470642
Valid Loss:  0.6878243684768677
Epoch:  239  	Training Loss: 0.6966437101364136
Test Loss:  0.6946830153465271
Valid Loss:  0.6878079771995544
Epoch:  240  	Training Loss: 0.6966270804405212
Test Loss:  0.6946663856506348
Valid Loss:  0.6877915859222412
Epoch:  241  	Training Loss: 0.6966105699539185
Test Loss:  0.6946496963500977
Valid Loss:  0.6877752542495728
Epoch:  242  	Training Loss: 0.6965939998626709
Test Loss:  0.6946305632591248
Valid Loss:  0.6877562999725342
Epoch:  243  	Training Loss: 0.6965749263763428
Test Loss:  0.6946114301681519
Valid Loss:  0.6877375245094299
Epoch:  244  	Training Loss: 0.6965558528900146
Test Loss:  0.6945922374725342
Valid Loss:  0.6877186298370361
Epoch:  245  	Training Loss: 0.6965368390083313
Test Loss:  0.6945731043815613
Valid Loss:  0.6876997351646423
Epoch:  246  	Training Loss: 0.6965177655220032
Test Loss:  0.6945539712905884
Valid Loss:  0.6876809597015381
Epoch:  247  	Training Loss: 0.6964987516403198
Test Loss:  0.6945347785949707
Valid Loss:  0.6876620650291443
Epoch:  248  	Training Loss: 0.6964796781539917
Test Loss:  0.694515585899353
Valid Loss:  0.6876431703567505
Epoch:  249  	Training Loss: 0.6964606046676636
Test Loss:  0.6944963932037354
Valid Loss:  0.6876242756843567
Epoch:  250  	Training Loss: 0.6964414715766907
Test Loss:  0.6944772005081177
Valid Loss:  0.6876053810119629
Epoch:  251  	Training Loss: 0.6964224576950073
Test Loss:  0.6944580078125
Valid Loss:  0.6875864267349243
Epoch:  252  	Training Loss: 0.6964033842086792
Test Loss:  0.6944400072097778
Valid Loss:  0.6875686645507812
Epoch:  253  	Training Loss: 0.6963854432106018
Test Loss:  0.6944220066070557
Valid Loss:  0.687550961971283
Epoch:  254  	Training Loss: 0.6963675022125244
Test Loss:  0.6944040060043335
Valid Loss:  0.6875332593917847
Epoch:  255  	Training Loss: 0.6963496208190918
Test Loss:  0.6943860054016113
Valid Loss:  0.6875154972076416
Epoch:  256  	Training Loss: 0.6963317394256592
Test Loss:  0.6943680644035339
Valid Loss:  0.6874978542327881
Epoch:  257  	Training Loss: 0.6963138580322266
Test Loss:  0.6943500638008118
Valid Loss:  0.6874801516532898
Epoch:  258  	Training Loss: 0.696295976638794
Test Loss:  0.6943321228027344
Valid Loss:  0.6874624490737915
Epoch:  259  	Training Loss: 0.6962780952453613
Test Loss:  0.6943142414093018
Valid Loss:  0.687444806098938
Epoch:  260  	Training Loss: 0.6962602734565735
Test Loss:  0.6942963600158691
Valid Loss:  0.6874271631240845
Epoch:  261  	Training Loss: 0.6962425112724304
Test Loss:  0.6942784190177917
Valid Loss:  0.687409520149231
Epoch:  262  	Training Loss: 0.6962246894836426
Test Loss:  0.6942516565322876
Valid Loss:  0.6873831748962402
Epoch:  263  	Training Loss: 0.696198046207428
Test Loss:  0.6942249536514282
Valid Loss:  0.6873567700386047
Epoch:  264  	Training Loss: 0.6961714029312134
Test Loss:  0.6941980123519897
Valid Loss:  0.6873303651809692
Epoch:  265  	Training Loss: 0.696144700050354
Test Loss:  0.6941710710525513
Valid Loss:  0.687303900718689
Epoch:  266  	Training Loss: 0.6961179971694946
Test Loss:  0.6941442489624023
Valid Loss:  0.6872774362564087
Epoch:  267  	Training Loss: 0.6960912346839905
Test Loss:  0.6941173672676086
Valid Loss:  0.6872508525848389
Epoch:  268  	Training Loss: 0.6960643529891968
Test Loss:  0.6940903663635254
Valid Loss:  0.687224268913269
Epoch:  269  	Training Loss: 0.6960375905036926
Test Loss:  0.6940633058547974
Valid Loss:  0.6871976852416992
Epoch:  270  	Training Loss: 0.6960107088088989
Test Loss:  0.6940364241600037
Valid Loss:  0.6871711015701294
Epoch:  271  	Training Loss: 0.69598388671875
Test Loss:  0.6940093040466309
Valid Loss:  0.68714439868927
Epoch:  272  	Training Loss: 0.6959570050239563
Test Loss:  0.6939893960952759
Valid Loss:  0.6871247887611389
Epoch:  273  	Training Loss: 0.6959370970726013
Test Loss:  0.6939694881439209
Valid Loss:  0.687105119228363
Epoch:  274  	Training Loss: 0.6959173679351807
Test Loss:  0.6939495801925659
Valid Loss:  0.6870855093002319
Epoch:  275  	Training Loss: 0.6958975195884705
Test Loss:  0.6939296126365662
Valid Loss:  0.6870658993721008
Epoch:  276  	Training Loss: 0.6958776712417603
Test Loss:  0.6939096450805664
Valid Loss:  0.6870461702346802
Epoch:  277  	Training Loss: 0.6958577632904053
Test Loss:  0.6938896179199219
Valid Loss:  0.6870265603065491
Epoch:  278  	Training Loss: 0.6958378553390503
Test Loss:  0.6938697099685669
Valid Loss:  0.6870068907737732
Epoch:  279  	Training Loss: 0.6958180665969849
Test Loss:  0.6938496828079224
Valid Loss:  0.6869872808456421
Epoch:  280  	Training Loss: 0.6957981586456299
Test Loss:  0.6938297748565674
Valid Loss:  0.6869674921035767
Epoch:  281  	Training Loss: 0.6957783699035645
Test Loss:  0.6938097476959229
Valid Loss:  0.6869478225708008
Epoch:  282  	Training Loss: 0.6957584619522095
Test Loss:  0.6937881708145142
Valid Loss:  0.6869266033172607
Epoch:  283  	Training Loss: 0.6957368850708008
Test Loss:  0.6937664747238159
Valid Loss:  0.6869052648544312
Epoch:  284  	Training Loss: 0.6957154273986816
Test Loss:  0.6937448978424072
Valid Loss:  0.6868840456008911
Epoch:  285  	Training Loss: 0.6956939697265625
Test Loss:  0.6937233209609985
Valid Loss:  0.6868627667427063
Epoch:  286  	Training Loss: 0.6956724524497986
Test Loss:  0.6937016844749451
Valid Loss:  0.6868414878845215
Epoch:  287  	Training Loss: 0.6956509351730347
Test Loss:  0.6936800479888916
Valid Loss:  0.6868200898170471
Epoch:  288  	Training Loss: 0.695629358291626
Test Loss:  0.6936583518981934
Valid Loss:  0.6867988109588623
Epoch:  289  	Training Loss: 0.6956078410148621
Test Loss:  0.6936367750167847
Valid Loss:  0.6867774128913879
Epoch:  290  	Training Loss: 0.6955863237380981
Test Loss:  0.693615198135376
Valid Loss:  0.6867561340332031
Epoch:  291  	Training Loss: 0.6955648064613342
Test Loss:  0.6935935020446777
Valid Loss:  0.6867347955703735
Epoch:  292  	Training Loss: 0.6955432891845703
Test Loss:  0.6935737133026123
Valid Loss:  0.6867153644561768
Epoch:  293  	Training Loss: 0.6955236196517944
Test Loss:  0.6935539841651917
Valid Loss:  0.68669593334198
Epoch:  294  	Training Loss: 0.6955040097236633
Test Loss:  0.693534255027771
Valid Loss:  0.6866765022277832
Epoch:  295  	Training Loss: 0.6954843997955322
Test Loss:  0.6935145854949951
Valid Loss:  0.6866570711135864
Epoch:  296  	Training Loss: 0.6954647302627563
Test Loss:  0.6934947967529297
Valid Loss:  0.6866376399993896
Epoch:  297  	Training Loss: 0.6954451203346252
Test Loss:  0.6934750080108643
Valid Loss:   59%|█████▉    | 297/500 [03:25<01:34,  2.16it/s] 60%|█████▉    | 299/500 [03:26<01:09,  2.91it/s] 60%|██████    | 301/500 [03:32<03:57,  1.19s/it] 61%|██████    | 303/500 [03:32<02:48,  1.17it/s] 61%|██████    | 305/500 [03:32<02:01,  1.61it/s] 61%|██████▏   | 307/500 [03:32<01:28,  2.19it/s] 62%|██████▏   | 309/500 [03:32<01:04,  2.94it/s] 62%|██████▏   | 311/500 [03:39<03:45,  1.19s/it] 63%|██████▎   | 313/500 [03:39<02:40,  1.17it/s] 63%|██████▎   | 315/500 [03:39<01:54,  1.61it/s] 63%|██████▎   | 317/500 [03:39<01:23,  2.18it/s] 64%|██████▍   | 319/500 [03:39<01:02,  2.92it/s] 64%|██████▍   | 321/500 [03:46<03:32,  1.19s/it] 65%|██████▍   | 323/500 [03:46<02:31,  1.17it/s] 65%|██████▌   | 325/500 [03:46<01:48,  1.61it/s] 65%|██████▌   | 327/500 [03:46<01:19,  2.17it/s] 66%|██████▌   | 329/500 [03:46<00:58,  2.92it/s] 66%|██████▌   | 331/500 [03:53<03:23,  1.20s/it] 67%|██████▋   | 333/500 [03:53<02:24,  1.16it/s] 67%|██████▋   | 335/500 [03:53<01:43,  1.60it/s] 67%|██████▋   | 337/500 [03:53<01:14,  2.19it/s] 68%|██████▊   | 339/500 [03:53<00:54,  2.95it/s] 68%|██████▊   | 341/500 [04:00<03:08,  1.19s/it] 69%|██████▊   | 343/500 [04:00<02:13,  1.18it/s] 69%|██████▉   | 345/500 [04:00<01:35,  1.63it/s] 69%|██████▉   | 347/500 [04:00<01:08,  2.23it/s] 70%|██████▉   | 349/500 [04:00<00:50,  3.00it/s] 70%|███████   | 351/500 [04:07<02:57,  1.19s/it] 71%|███████   | 353/500 [04:07<02:06,  1.17it/s] 71%|███████   | 355/500 [04:07<01:30,  1.61it/s] 71%|███████▏  | 357/500 [04:07<01:05,  2.20it/s] 72%|███████▏  | 359/500 [04:07<00:47,  2.96it/s] 72%|███████▏  | 361/500 [04:14<02:47,  1.21s/it] 73%|███████▎  | 363/500 [04:14<01:58,  1.15it/s] 73%|███████▎  | 365/500 [04:14<01:24,  1.60it/s] 73%|███████▎  | 367/500 [04:14<01:00,  2.18it/s] 74%|███████▍  | 369/500 [04:14<00:44,  2.93it/s]0.6866181492805481
Epoch:  298  	Training Loss: 0.6954255104064941
Test Loss:  0.6934552788734436
Valid Loss:  0.6865987181663513
Epoch:  299  	Training Loss: 0.6954058408737183
Test Loss:  0.693435549736023
Valid Loss:  0.6865792274475098
Epoch:  300  	Training Loss: 0.6953861713409424
Test Loss:  0.6934158205986023
Valid Loss:  0.686559796333313
Epoch:  301  	Training Loss: 0.6953665614128113
Test Loss:  0.6933960318565369
Valid Loss:  0.6865403652191162
Epoch:  302  	Training Loss: 0.6953469514846802
Test Loss:  0.6933765411376953
Valid Loss:  0.6865211725234985
Epoch:  303  	Training Loss: 0.6953275203704834
Test Loss:  0.6933571100234985
Valid Loss:  0.6865019798278809
Epoch:  304  	Training Loss: 0.6953081488609314
Test Loss:  0.693337619304657
Valid Loss:  0.6864827871322632
Epoch:  305  	Training Loss: 0.6952887773513794
Test Loss:  0.6933181285858154
Valid Loss:  0.6864635944366455
Epoch:  306  	Training Loss: 0.6952694058418274
Test Loss:  0.6932985782623291
Valid Loss:  0.6864444017410278
Epoch:  307  	Training Loss: 0.6952500343322754
Test Loss:  0.6932791471481323
Valid Loss:  0.6864252090454102
Epoch:  308  	Training Loss: 0.6952306628227234
Test Loss:  0.6932597160339355
Valid Loss:  0.6864060759544373
Epoch:  309  	Training Loss: 0.6952112913131714
Test Loss:  0.693240225315094
Valid Loss:  0.6863868832588196
Epoch:  310  	Training Loss: 0.6951919198036194
Test Loss:  0.6932207345962524
Valid Loss:  0.6863677501678467
Epoch:  311  	Training Loss: 0.6951725482940674
Test Loss:  0.6932013630867004
Valid Loss:  0.686348557472229
Epoch:  312  	Training Loss: 0.6951532363891602
Test Loss:  0.6931830048561096
Valid Loss:  0.6863305568695068
Epoch:  313  	Training Loss: 0.6951349973678589
Test Loss:  0.6931647658348083
Valid Loss:  0.6863125562667847
Epoch:  314  	Training Loss: 0.6951168775558472
Test Loss:  0.6931465268135071
Valid Loss:  0.6862945556640625
Epoch:  315  	Training Loss: 0.6950986981391907
Test Loss:  0.693128228187561
Valid Loss:  0.6862766146659851
Epoch:  316  	Training Loss: 0.6950805187225342
Test Loss:  0.6931099891662598
Valid Loss:  0.6862586736679077
Epoch:  317  	Training Loss: 0.6950623989105225
Test Loss:  0.6930917501449585
Valid Loss:  0.6862406730651855
Epoch:  318  	Training Loss: 0.695044219493866
Test Loss:  0.6930735111236572
Valid Loss:  0.6862226724624634
Epoch:  319  	Training Loss: 0.695026159286499
Test Loss:  0.693055272102356
Valid Loss:  0.6862047910690308
Epoch:  320  	Training Loss: 0.6950080394744873
Test Loss:  0.6930371522903442
Valid Loss:  0.6861868500709534
Epoch:  321  	Training Loss: 0.6949899196624756
Test Loss:  0.6930189728736877
Valid Loss:  0.686168909072876
Epoch:  322  	Training Loss: 0.6949717998504639
Test Loss:  0.6930010318756104
Valid Loss:  0.6861512660980225
Epoch:  323  	Training Loss: 0.6949540376663208
Test Loss:  0.6929831504821777
Valid Loss:  0.6861337423324585
Epoch:  324  	Training Loss: 0.6949362754821777
Test Loss:  0.6929652690887451
Valid Loss:  0.6861160397529602
Epoch:  325  	Training Loss: 0.6949183940887451
Test Loss:  0.6929473280906677
Valid Loss:  0.6860984563827515
Epoch:  326  	Training Loss: 0.6949005722999573
Test Loss:  0.6929295063018799
Valid Loss:  0.686080813407898
Epoch:  327  	Training Loss: 0.6948828101158142
Test Loss:  0.6929115653038025
Valid Loss:  0.6860631704330444
Epoch:  328  	Training Loss: 0.6948649883270264
Test Loss:  0.6928936839103699
Valid Loss:  0.6860455274581909
Epoch:  329  	Training Loss: 0.6948471665382385
Test Loss:  0.6928757429122925
Valid Loss:  0.6860278844833374
Epoch:  330  	Training Loss: 0.6948293447494507
Test Loss:  0.6928578019142151
Valid Loss:  0.6860102415084839
Epoch:  331  	Training Loss: 0.6948115229606628
Test Loss:  0.6928399205207825
Valid Loss:  0.6859925985336304
Epoch:  332  	Training Loss: 0.694793701171875
Test Loss:  0.692819356918335
Valid Loss:  0.6859723329544067
Epoch:  333  	Training Loss: 0.6947733163833618
Test Loss:  0.6927988529205322
Valid Loss:  0.6859521865844727
Epoch:  334  	Training Loss: 0.6947528123855591
Test Loss:  0.6927782297134399
Valid Loss:  0.6859318614006042
Epoch:  335  	Training Loss: 0.6947323679924011
Test Loss:  0.6927577257156372
Valid Loss:  0.6859116554260254
Epoch:  336  	Training Loss: 0.6947119832038879
Test Loss:  0.6927371621131897
Valid Loss:  0.6858913898468018
Epoch:  337  	Training Loss: 0.69469153881073
Test Loss:  0.6927165985107422
Valid Loss:  0.6858711242675781
Epoch:  338  	Training Loss: 0.6946710348129272
Test Loss:  0.6926960349082947
Valid Loss:  0.6858508586883545
Epoch:  339  	Training Loss: 0.6946505308151245
Test Loss:  0.6926754117012024
Valid Loss:  0.6858305931091309
Epoch:  340  	Training Loss: 0.6946301460266113
Test Loss:  0.6926548480987549
Valid Loss:  0.6858103275299072
Epoch:  341  	Training Loss: 0.6946096420288086
Test Loss:  0.6926342844963074
Valid Loss:  0.6857901811599731
Epoch:  342  	Training Loss: 0.6945891976356506
Test Loss:  0.692615270614624
Valid Loss:  0.6857713460922241
Epoch:  343  	Training Loss: 0.6945702433586121
Test Loss:  0.6925961375236511
Valid Loss:  0.6857525110244751
Epoch:  344  	Training Loss: 0.6945512294769287
Test Loss:  0.692577064037323
Valid Loss:  0.6857337355613708
Epoch:  345  	Training Loss: 0.6945322751998901
Test Loss:  0.6925579309463501
Valid Loss:  0.685714840888977
Epoch:  346  	Training Loss: 0.694513201713562
Test Loss:  0.692538857460022
Valid Loss:  0.6856961250305176
Epoch:  347  	Training Loss: 0.6944943070411682
Test Loss:  0.6925197839736938
Valid Loss:  0.6856773495674133
Epoch:  348  	Training Loss: 0.6944752335548401
Test Loss:  0.6925007104873657
Valid Loss:  0.6856585741043091
Epoch:  349  	Training Loss: 0.6944563388824463
Test Loss:  0.692481517791748
Valid Loss:  0.6856397390365601
Epoch:  350  	Training Loss: 0.6944373250007629
Test Loss:  0.6924625039100647
Valid Loss:  0.685620903968811
Epoch:  351  	Training Loss: 0.6944183111190796
Test Loss:  0.6924434900283813
Valid Loss:  0.685602068901062
Epoch:  352  	Training Loss: 0.694399356842041
Test Loss:  0.6924213171005249
Valid Loss:  0.6855803728103638
Epoch:  353  	Training Loss: 0.6943774223327637
Test Loss:  0.692399263381958
Valid Loss:  0.685558557510376
Epoch:  354  	Training Loss: 0.6943553686141968
Test Loss:  0.6923770904541016
Valid Loss:  0.6855367422103882
Epoch:  355  	Training Loss: 0.6943333148956299
Test Loss:  0.6923548579216003
Valid Loss:  0.6855149865150452
Epoch:  356  	Training Loss: 0.6943113207817078
Test Loss:  0.6923327445983887
Valid Loss:  0.6854931116104126
Epoch:  357  	Training Loss: 0.6942893266677856
Test Loss:  0.6923105716705322
Valid Loss:  0.6854712963104248
Epoch:  358  	Training Loss: 0.6942671537399292
Test Loss:  0.6922883987426758
Valid Loss:  0.685449481010437
Epoch:  359  	Training Loss: 0.6942451596260071
Test Loss:  0.6922661662101746
Valid Loss:  0.6854275465011597
Epoch:  360  	Training Loss: 0.6942231059074402
Test Loss:  0.6922439336776733
Valid Loss:  0.6854057312011719
Epoch:  361  	Training Loss: 0.6942009925842285
Test Loss:  0.6922217607498169
Valid Loss:  0.6853837966918945
Epoch:  362  	Training Loss: 0.6941788196563721
Test Loss:  0.6922052502632141
Valid Loss:  0.6853675842285156
Epoch:  363  	Training Loss: 0.6941624879837036
Test Loss:  0.6921887397766113
Valid Loss:  0.6853512525558472
Epoch:  364  	Training Loss: 0.6941460371017456
Test Loss:  0.6921722888946533
Valid Loss:  0.6853350400924683
Epoch:  365  	Training Loss: 0.6941296458244324
Test Loss:  0.6921557188034058
Valid Loss:  0.6853188276290894
Epoch:  366  	Training Loss: 0.6941132545471191
Test Loss:  0.6921392679214478
Valid Loss:  0.6853026151657104
Epoch:  367  	Training Loss: 0.6940968632698059
Test Loss:  0.6921229362487793
Valid Loss:  0.6852864027023315
Epoch:  368  	Training Loss: 0.6940805912017822
Test Loss:  0.6921064853668213
Valid Loss:  0.6852703094482422
Epoch:  369  	Training Loss: 0.6940642595291138
Test Loss:  0.6920900344848633
Valid Loss:  0.6852541565895081
Epoch:  370  	Training Loss: 0.6940479278564453
Test Loss:  0.6920737028121948
Valid Loss:  0.6852380037307739
Epoch:  371  	Training Loss: 0.6940315961837769
Test Loss:  0.6920573115348816
Valid Loss:   74%|███████▍  | 371/500 [04:20<02:34,  1.20s/it] 75%|███████▍  | 373/500 [04:21<01:49,  1.16it/s] 75%|███████▌  | 375/500 [04:21<01:17,  1.61it/s] 75%|███████▌  | 377/500 [04:21<00:55,  2.20it/s] 76%|███████▌  | 379/500 [04:21<00:40,  2.96it/s] 76%|███████▌  | 381/500 [04:27<02:22,  1.20s/it] 77%|███████▋  | 383/500 [04:28<01:40,  1.16it/s] 77%|███████▋  | 385/500 [04:28<01:11,  1.61it/s] 77%|███████▋  | 387/500 [04:28<00:51,  2.19it/s] 78%|███████▊  | 389/500 [04:28<00:37,  2.93it/s] 78%|███████▊  | 391/500 [04:34<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:34<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:35<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:35<00:46,  2.21it/s] 80%|███████▉  | 399/500 [04:35<00:33,  2.97it/s] 80%|████████  | 401/500 [04:41<01:57,  1.19s/it] 81%|████████  | 403/500 [04:41<01:22,  1.17it/s] 81%|████████  | 405/500 [04:41<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:42<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:42<00:30,  2.98it/s] 82%|████████▏ | 411/500 [04:48<01:45,  1.18s/it] 83%|████████▎ | 413/500 [04:48<01:14,  1.17it/s] 83%|████████▎ | 415/500 [04:48<00:52,  1.62it/s] 83%|████████▎ | 417/500 [04:48<00:37,  2.21it/s] 84%|████████▍ | 419/500 [04:49<00:27,  2.97it/s] 84%|████████▍ | 421/500 [04:55<01:34,  1.20s/it] 85%|████████▍ | 423/500 [04:55<01:06,  1.16it/s] 85%|████████▌ | 425/500 [04:55<00:46,  1.60it/s] 85%|████████▌ | 427/500 [04:55<00:33,  2.19it/s] 86%|████████▌ | 429/500 [04:56<00:24,  2.95it/s] 86%|████████▌ | 431/500 [05:02<01:21,  1.18s/it] 87%|████████▋ | 433/500 [05:02<00:56,  1.18it/s] 87%|████████▋ | 435/500 [05:02<00:39,  1.63it/s] 87%|████████▋ | 437/500 [05:02<00:28,  2.22it/s] 88%|████████▊ | 439/500 [05:02<00:20,  2.99it/s] 88%|████████▊ | 441/500 [05:09<01:10,  1.20s/it] 89%|████████▊ | 443/500 [05:09<00:48,  1.17it/s]0.6852219104766846
Epoch:  372  	Training Loss: 0.6940153241157532
Test Loss:  0.6920394897460938
Valid Loss:  0.685204267501831
Epoch:  373  	Training Loss: 0.6939975619316101
Test Loss:  0.6920216083526611
Valid Loss:  0.6851867437362671
Epoch:  374  	Training Loss: 0.693979799747467
Test Loss:  0.6920037865638733
Valid Loss:  0.6851691603660583
Epoch:  375  	Training Loss: 0.6939620971679688
Test Loss:  0.6919859647750854
Valid Loss:  0.6851515769958496
Epoch:  376  	Training Loss: 0.6939443349838257
Test Loss:  0.6919680833816528
Valid Loss:  0.6851340532302856
Epoch:  377  	Training Loss: 0.6939266324043274
Test Loss:  0.6919503211975098
Valid Loss:  0.6851165890693665
Epoch:  378  	Training Loss: 0.6939089298248291
Test Loss:  0.6919325590133667
Valid Loss:  0.6850990653038025
Epoch:  379  	Training Loss: 0.6938912272453308
Test Loss:  0.6919147968292236
Valid Loss:  0.6850815415382385
Epoch:  380  	Training Loss: 0.6938736438751221
Test Loss:  0.6918970346450806
Valid Loss:  0.6850640177726746
Epoch:  381  	Training Loss: 0.6938560009002686
Test Loss:  0.6918792724609375
Valid Loss:  0.6850466132164001
Epoch:  382  	Training Loss: 0.6938382983207703
Test Loss:  0.6918589472770691
Valid Loss:  0.6850265264511108
Epoch:  383  	Training Loss: 0.6938180327415466
Test Loss:  0.6918386220932007
Valid Loss:  0.6850064396858215
Epoch:  384  	Training Loss: 0.693797767162323
Test Loss:  0.6918182373046875
Valid Loss:  0.684986412525177
Epoch:  385  	Training Loss: 0.6937775611877441
Test Loss:  0.6917979717254639
Valid Loss:  0.6849663257598877
Epoch:  386  	Training Loss: 0.6937572956085205
Test Loss:  0.6917776465415955
Valid Loss:  0.6849462985992432
Epoch:  387  	Training Loss: 0.6937370896339417
Test Loss:  0.691757321357727
Valid Loss:  0.6849263906478882
Epoch:  388  	Training Loss: 0.6937169432640076
Test Loss:  0.6917369365692139
Valid Loss:  0.6849063038825989
Epoch:  389  	Training Loss: 0.6936966776847839
Test Loss:  0.6917166709899902
Valid Loss:  0.6848862767219543
Epoch:  390  	Training Loss: 0.6936764717102051
Test Loss:  0.6916964054107666
Valid Loss:  0.6848663091659546
Epoch:  391  	Training Loss: 0.6936562657356262
Test Loss:  0.6916761994361877
Valid Loss:  0.6848463416099548
Epoch:  392  	Training Loss: 0.6936361193656921
Test Loss:  0.6916518211364746
Valid Loss:  0.6848224401473999
Epoch:  393  	Training Loss: 0.6936119198799133
Test Loss:  0.6916275024414062
Valid Loss:  0.6847984194755554
Epoch:  394  	Training Loss: 0.6935876607894897
Test Loss:  0.6916030645370483
Valid Loss:  0.6847743988037109
Epoch:  395  	Training Loss: 0.6935634613037109
Test Loss:  0.6915786266326904
Valid Loss:  0.6847503185272217
Epoch:  396  	Training Loss: 0.6935391426086426
Test Loss:  0.6915541887283325
Valid Loss:  0.6847262382507324
Epoch:  397  	Training Loss: 0.6935149431228638
Test Loss:  0.6915298104286194
Valid Loss:  0.6847022771835327
Epoch:  398  	Training Loss: 0.6934905648231506
Test Loss:  0.6915053129196167
Valid Loss:  0.6846781373023987
Epoch:  399  	Training Loss: 0.693466305732727
Test Loss:  0.6914808750152588
Valid Loss:  0.6846541166305542
Epoch:  400  	Training Loss: 0.6934419870376587
Test Loss:  0.6914564371109009
Valid Loss:  0.6846300363540649
Epoch:  401  	Training Loss: 0.6934176683425903
Test Loss:  0.6914319396018982
Valid Loss:  0.6846059560775757
Epoch:  402  	Training Loss: 0.693393349647522
Test Loss:  0.6914072036743164
Valid Loss:  0.6845815181732178
Epoch:  403  	Training Loss: 0.693368673324585
Test Loss:  0.6913824677467346
Valid Loss:  0.6845571994781494
Epoch:  404  	Training Loss: 0.6933441162109375
Test Loss:  0.6913576126098633
Valid Loss:  0.6845327019691467
Epoch:  405  	Training Loss: 0.6933194398880005
Test Loss:  0.6913328170776367
Valid Loss:  0.6845082640647888
Epoch:  406  	Training Loss: 0.6932947039604187
Test Loss:  0.6913079023361206
Valid Loss:  0.6844838261604309
Epoch:  407  	Training Loss: 0.6932699680328369
Test Loss:  0.6912830471992493
Valid Loss:  0.6844592690467834
Epoch:  408  	Training Loss: 0.6932452321052551
Test Loss:  0.6912580728530884
Valid Loss:  0.6844346523284912
Epoch:  409  	Training Loss: 0.6932203769683838
Test Loss:  0.6912330389022827
Valid Loss:  0.6844100952148438
Epoch:  410  	Training Loss: 0.6931955814361572
Test Loss:  0.6912080645561218
Valid Loss:  0.6843854784965515
Epoch:  411  	Training Loss: 0.6931707262992859
Test Loss:  0.6911829710006714
Valid Loss:  0.6843608617782593
Epoch:  412  	Training Loss: 0.6931458115577698
Test Loss:  0.6911624073982239
Valid Loss:  0.6843405961990356
Epoch:  413  	Training Loss: 0.693125307559967
Test Loss:  0.6911417841911316
Valid Loss:  0.6843201518058777
Epoch:  414  	Training Loss: 0.6931047439575195
Test Loss:  0.6911212205886841
Valid Loss:  0.684299886226654
Epoch:  415  	Training Loss: 0.6930842399597168
Test Loss:  0.691100537776947
Valid Loss:  0.6842795610427856
Epoch:  416  	Training Loss: 0.6930637359619141
Test Loss:  0.6910797953605652
Valid Loss:  0.6842591762542725
Epoch:  417  	Training Loss: 0.6930431127548218
Test Loss:  0.6910591125488281
Valid Loss:  0.6842387914657593
Epoch:  418  	Training Loss: 0.6930225491523743
Test Loss:  0.6910384893417358
Valid Loss:  0.6842184662818909
Epoch:  419  	Training Loss: 0.6930020451545715
Test Loss:  0.691017746925354
Valid Loss:  0.6841980814933777
Epoch:  420  	Training Loss: 0.692981481552124
Test Loss:  0.6909971237182617
Valid Loss:  0.6841776967048645
Epoch:  421  	Training Loss: 0.6929609179496765
Test Loss:  0.6909763813018799
Valid Loss:  0.6841573715209961
Epoch:  422  	Training Loss: 0.6929402947425842
Test Loss:  0.6909387111663818
Valid Loss:  0.684120237827301
Epoch:  423  	Training Loss: 0.6929028630256653
Test Loss:  0.6909010410308838
Valid Loss:  0.684083104133606
Epoch:  424  	Training Loss: 0.6928653717041016
Test Loss:  0.6908632516860962
Valid Loss:  0.6840459108352661
Epoch:  425  	Training Loss: 0.6928277611732483
Test Loss:  0.6908252239227295
Valid Loss:  0.6840085387229919
Epoch:  426  	Training Loss: 0.6927899718284607
Test Loss:  0.6907870769500732
Valid Loss:  0.6839709281921387
Epoch:  427  	Training Loss: 0.6927520632743835
Test Loss:  0.690748929977417
Valid Loss:  0.6839333176612854
Epoch:  428  	Training Loss: 0.6927140951156616
Test Loss:  0.6907106041908264
Valid Loss:  0.6838955283164978
Epoch:  429  	Training Loss: 0.6926759481430054
Test Loss:  0.6906720399856567
Valid Loss:  0.6838576197624207
Epoch:  430  	Training Loss: 0.6926376223564148
Test Loss:  0.6906335353851318
Valid Loss:  0.683819591999054
Epoch:  431  	Training Loss: 0.6925992965698242
Test Loss:  0.6905947327613831
Valid Loss:  0.6837815046310425
Epoch:  432  	Training Loss: 0.6925607919692993
Test Loss:  0.6905733942985535
Valid Loss:  0.683760404586792
Epoch:  433  	Training Loss: 0.6925394535064697
Test Loss:  0.6905519366264343
Valid Loss:  0.6837393045425415
Epoch:  434  	Training Loss: 0.6925181150436401
Test Loss:  0.69053053855896
Valid Loss:  0.683718204498291
Epoch:  435  	Training Loss: 0.6924968361854553
Test Loss:  0.6905090808868408
Valid Loss:  0.6836970448493958
Epoch:  436  	Training Loss: 0.6924754977226257
Test Loss:  0.6904876232147217
Valid Loss:  0.68367600440979
Epoch:  437  	Training Loss: 0.6924542188644409
Test Loss:  0.6904661655426025
Valid Loss:  0.6836548447608948
Epoch:  438  	Training Loss: 0.6924328207969666
Test Loss:  0.6904447078704834
Valid Loss:  0.6836336851119995
Epoch:  439  	Training Loss: 0.692411482334137
Test Loss:  0.6904232501983643
Valid Loss:  0.683612585067749
Epoch:  440  	Training Loss: 0.6923901438713074
Test Loss:  0.6904017925262451
Valid Loss:  0.6835914254188538
Epoch:  441  	Training Loss: 0.6923688054084778
Test Loss:  0.690380334854126
Valid Loss:  0.6835702657699585
Epoch:  442  	Training Loss: 0.6923474073410034
Test Loss:  0.6903520822525024
Valid Loss:  0.6835424304008484
Epoch:  443  	Training Loss: 0.6923193335533142
Test Loss:  0.6903238296508789
Valid Loss:  0.6835145950317383
Epoch:  444  	Training Loss: 0.692291259765625
Test Loss:  0.6902954578399658
Valid Loss:  0.6834867000579834
Epoch:  445  	Training Loss: 0.6922630071640015
Test Loss:  0.6902670860290527
Valid Loss:   89%|████████▉ | 445/500 [05:09<00:34,  1.61it/s] 89%|████████▉ | 447/500 [05:09<00:24,  2.20it/s] 90%|████████▉ | 449/500 [05:09<00:17,  2.96it/s] 90%|█████████ | 451/500 [05:16<00:57,  1.18s/it] 91%|█████████ | 453/500 [05:16<00:40,  1.17it/s] 91%|█████████ | 455/500 [05:16<00:27,  1.62it/s] 91%|█████████▏| 457/500 [05:16<00:19,  2.21it/s] 92%|█████████▏| 459/500 [05:16<00:13,  2.97it/s] 92%|█████████▏| 461/500 [05:23<00:45,  1.18s/it] 93%|█████████▎| 463/500 [05:23<00:31,  1.18it/s] 93%|█████████▎| 465/500 [05:23<00:21,  1.63it/s] 93%|█████████▎| 467/500 [05:23<00:14,  2.23it/s] 94%|█████████▍| 469/500 [05:23<00:10,  3.00it/s] 94%|█████████▍| 471/500 [05:30<00:34,  1.20s/it] 95%|█████████▍| 473/500 [05:30<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:30<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:30<00:10,  2.19it/s] 96%|█████████▌| 479/500 [05:30<00:07,  2.92it/s] 96%|█████████▌| 481/500 [05:36<00:22,  1.20s/it] 97%|█████████▋| 483/500 [05:37<00:14,  1.16it/s] 97%|█████████▋| 485/500 [05:37<00:09,  1.60it/s] 97%|█████████▋| 487/500 [05:37<00:05,  2.19it/s] 98%|█████████▊| 489/500 [05:37<00:03,  2.93it/s] 98%|█████████▊| 491/500 [05:43<00:10,  1.18s/it] 99%|█████████▊| 493/500 [05:43<00:05,  1.18it/s] 99%|█████████▉| 495/500 [05:44<00:03,  1.63it/s] 99%|█████████▉| 497/500 [05:44<00:01,  2.22it/s]100%|█████████▉| 499/500 [05:44<00:00,  2.97it/s]100%|██████████| 500/500 [05:44<00:00,  1.45it/s]
0.6834587454795837
Epoch:  446  	Training Loss: 0.6922348737716675
Test Loss:  0.6902387142181396
Valid Loss:  0.6834307909011841
Epoch:  447  	Training Loss: 0.6922065615653992
Test Loss:  0.690210223197937
Valid Loss:  0.6834027171134949
Epoch:  448  	Training Loss: 0.6921782493591309
Test Loss:  0.6901817321777344
Valid Loss:  0.6833747029304504
Epoch:  449  	Training Loss: 0.6921498775482178
Test Loss:  0.6901531219482422
Valid Loss:  0.6833465099334717
Epoch:  450  	Training Loss: 0.6921214461326599
Test Loss:  0.6901245713233948
Valid Loss:  0.6833182573318481
Epoch:  451  	Training Loss: 0.692093014717102
Test Loss:  0.6900959610939026
Valid Loss:  0.6832901239395142
Epoch:  452  	Training Loss: 0.6920645236968994
Test Loss:  0.6900765895843506
Valid Loss:  0.683271050453186
Epoch:  453  	Training Loss: 0.692045271396637
Test Loss:  0.6900571584701538
Valid Loss:  0.6832519173622131
Epoch:  454  	Training Loss: 0.6920260190963745
Test Loss:  0.6900377869606018
Valid Loss:  0.683232843875885
Epoch:  455  	Training Loss: 0.6920067071914673
Test Loss:  0.6900184154510498
Valid Loss:  0.6832138299942017
Epoch:  456  	Training Loss: 0.6919874548912048
Test Loss:  0.6899990439414978
Valid Loss:  0.6831947565078735
Epoch:  457  	Training Loss: 0.6919682025909424
Test Loss:  0.6899796724319458
Valid Loss:  0.6831756830215454
Epoch:  458  	Training Loss: 0.6919488906860352
Test Loss:  0.6899603009223938
Valid Loss:  0.6831566095352173
Epoch:  459  	Training Loss: 0.6919296979904175
Test Loss:  0.6899409294128418
Valid Loss:  0.6831375360488892
Epoch:  460  	Training Loss: 0.691910445690155
Test Loss:  0.6899216175079346
Valid Loss:  0.683118462562561
Epoch:  461  	Training Loss: 0.6918911933898926
Test Loss:  0.6899022459983826
Valid Loss:  0.6830993890762329
Epoch:  462  	Training Loss: 0.6918718814849854
Test Loss:  0.6898811459541321
Valid Loss:  0.6830786466598511
Epoch:  463  	Training Loss: 0.6918509602546692
Test Loss:  0.6898600459098816
Valid Loss:  0.6830578446388245
Epoch:  464  	Training Loss: 0.6918299198150635
Test Loss:  0.6898389458656311
Valid Loss:  0.6830370426177979
Epoch:  465  	Training Loss: 0.6918089389801025
Test Loss:  0.6898177862167358
Valid Loss:  0.683016300201416
Epoch:  466  	Training Loss: 0.6917879581451416
Test Loss:  0.6897966265678406
Valid Loss:  0.6829954981803894
Epoch:  467  	Training Loss: 0.6917669177055359
Test Loss:  0.6897755861282349
Valid Loss:  0.6829746961593628
Epoch:  468  	Training Loss: 0.6917458772659302
Test Loss:  0.6897543668746948
Valid Loss:  0.6829538345336914
Epoch:  469  	Training Loss: 0.6917248964309692
Test Loss:  0.6897332072257996
Valid Loss:  0.68293297290802
Epoch:  470  	Training Loss: 0.6917037963867188
Test Loss:  0.6897119283676147
Valid Loss:  0.6829121112823486
Epoch:  471  	Training Loss: 0.691682755947113
Test Loss:  0.6896908283233643
Valid Loss:  0.682891309261322
Epoch:  472  	Training Loss: 0.6916617155075073
Test Loss:  0.6896581053733826
Valid Loss:  0.6828590631484985
Epoch:  473  	Training Loss: 0.69162917137146
Test Loss:  0.6896253824234009
Valid Loss:  0.682826817035675
Epoch:  474  	Training Loss: 0.691596508026123
Test Loss:  0.6895924806594849
Valid Loss:  0.682794451713562
Epoch:  475  	Training Loss: 0.6915638446807861
Test Loss:  0.6895595788955688
Valid Loss:  0.6827620267868042
Epoch:  476  	Training Loss: 0.6915311813354492
Test Loss:  0.6895266771316528
Valid Loss:  0.6827295422554016
Epoch:  477  	Training Loss: 0.6914983987808228
Test Loss:  0.6894935369491577
Valid Loss:  0.682697057723999
Epoch:  478  	Training Loss: 0.6914655566215515
Test Loss:  0.6894605159759521
Valid Loss:  0.6826643943786621
Epoch:  479  	Training Loss: 0.6914325952529907
Test Loss:  0.689427375793457
Valid Loss:  0.6826317310333252
Epoch:  480  	Training Loss: 0.6913995742797852
Test Loss:  0.6893941164016724
Valid Loss:  0.6825990676879883
Epoch:  481  	Training Loss: 0.6913665533065796
Test Loss:  0.6893607378005981
Valid Loss:  0.6825662851333618
Epoch:  482  	Training Loss: 0.6913334131240845
Test Loss:  0.6893383264541626
Valid Loss:  0.6825441122055054
Epoch:  483  	Training Loss: 0.6913111209869385
Test Loss:  0.689315915107727
Valid Loss:  0.6825220584869385
Epoch:  484  	Training Loss: 0.6912887692451477
Test Loss:  0.6892934441566467
Valid Loss:  0.6824999451637268
Epoch:  485  	Training Loss: 0.6912664175033569
Test Loss:  0.6892709732055664
Valid Loss:  0.6824777722358704
Epoch:  486  	Training Loss: 0.6912441253662109
Test Loss:  0.6892485618591309
Valid Loss:  0.6824556589126587
Epoch:  487  	Training Loss: 0.6912218332290649
Test Loss:  0.6892260313034058
Valid Loss:  0.682433545589447
Epoch:  488  	Training Loss: 0.6911994218826294
Test Loss:  0.6892036199569702
Valid Loss:  0.6824114322662354
Epoch:  489  	Training Loss: 0.6911770701408386
Test Loss:  0.6891811490058899
Valid Loss:  0.6823892593383789
Epoch:  490  	Training Loss: 0.6911547183990479
Test Loss:  0.6891586780548096
Valid Loss:  0.6823670864105225
Epoch:  491  	Training Loss: 0.6911323070526123
Test Loss:  0.6891362071037292
Valid Loss:  0.682344913482666
Epoch:  492  	Training Loss: 0.6911099553108215
Test Loss:  0.6891136765480042
Valid Loss:  0.6823227405548096
Epoch:  493  	Training Loss: 0.6910876035690308
Test Loss:  0.689091145992279
Valid Loss:  0.6823006272315979
Epoch:  494  	Training Loss: 0.6910651922225952
Test Loss:  0.6890685558319092
Valid Loss:  0.6822783946990967
Epoch:  495  	Training Loss: 0.6910427808761597
Test Loss:  0.6890460848808289
Valid Loss:  0.6822562217712402
Epoch:  496  	Training Loss: 0.6910203695297241
Test Loss:  0.6890235543251038
Valid Loss:  0.6822341084480286
Epoch:  497  	Training Loss: 0.6909980177879333
Test Loss:  0.6890010833740234
Valid Loss:  0.6822118759155273
Epoch:  498  	Training Loss: 0.690975546836853
Test Loss:  0.6889784932136536
Valid Loss:  0.6821897029876709
Epoch:  499  	Training Loss: 0.6909531354904175
Test Loss:  0.6889559030532837
Valid Loss:  0.6821675300598145
Epoch:  500  	Training Loss: 0.6909307241439819
Test Loss:  0.6889333128929138
Valid Loss:  0.6821452379226685
seed is  20
---------------------------------------- Modified_NGD ----------------------------------------
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:06<52:24,  6.30s/it]  1%|          | 3/500 [00:06<13:58,  1.69s/it]  1%|          | 5/500 [00:06<07:02,  1.17it/s]  1%|▏         | 7/500 [00:06<04:16,  1.92it/s]  2%|▏         | 9/500 [00:06<02:51,  2.86it/s]  2%|▏         | 11/500 [00:13<10:47,  1.32s/it]  3%|▎         | 13/500 [00:13<07:21,  1.10it/s]  3%|▎         | 15/500 [00:13<05:07,  1.58it/s]  3%|▎         | 17/500 [00:13<03:39,  2.20it/s]  4%|▍         | 19/500 [00:13<02:40,  3.00it/s]  4%|▍         | 21/500 [00:19<09:35,  1.20s/it]  5%|▍         | 23/500 [00:20<06:48,  1.17it/s]  5%|▌         | 25/500 [00:26<12:25,  1.57s/it]  5%|▌         | 27/500 [00:26<08:48,  1.12s/it]  6%|▌         | 29/500 [00:26<06:16,  1.25it/s]  6%|▌         | 31/500 [00:33<11:58,  1.53s/it]  7%|▋         | 33/500 [00:33<08:30,  1.09s/it]  7%|▋         | 35/500 [00:33<06:04,  1.27it/s]  7%|▋         | 37/500 [00:33<04:23,  1.75it/s]  8%|▊         | 39/500 [00:33<03:12,  2.39it/s]  8%|▊         | 41/500 [00:40<09:35,  1.25s/it]  9%|▊         | 43/500 [00:40<06:50,  1.11it/s]  9%|▉         | 45/500 [00:40<04:55,  1.54it/s]  9%|▉         | 47/500 [00:40<03:34,  2.11it/s] 10%|▉         | 49/500 [00:40<02:38,  2.85it/s] 10%|█         | 51/500 [00:47<09:04,  1.21s/it] 11%|█         | 53/500 [00:47<06:29,  1.15it/s] 11%|█         | 55/500 [00:47<04:39,  1.59it/s] 11%|█▏        | 57/500 [00:47<03:23,  2.17it/s] 12%|█▏        | 59/500 [00:47<02:30,  2.93it/s] 12%|█▏        | 61/500 [00:54<08:48,  1.20s/it] 13%|█▎        | 63/500 [00:54<06:17,  1.16it/s] 13%|█▎        | 65/500 [01:00<11:18,  1.56s/it] 13%|█▎        | 67/500 [01:00<08:02,  1.11s/it] 14%|█▍        | 69/500 [01:00<05:44,  1.25it/s] 14%|█▍        | 71/500 [01:07<10:43,  1.50s/it]Epoch:  1  	Training Loss: 0.2410266399383545
Test Loss:  32.53209686279297
Valid Loss:  32.452606201171875
Epoch:  2  	Training Loss: 32.69630432128906
Test Loss:  104.44546508789062
Valid Loss:  104.67608642578125
Epoch:  3  	Training Loss: 105.73684692382812
Test Loss:  25.191898345947266
Valid Loss:  25.038854598999023
Epoch:  4  	Training Loss: 25.198711395263672
Test Loss:  25.179834365844727
Valid Loss:  25.02707290649414
Epoch:  5  	Training Loss: 25.186904907226562
Test Loss:  25.167625427246094
Valid Loss:  25.015153884887695
Epoch:  6  	Training Loss: 25.174957275390625
Test Loss:  25.155275344848633
Valid Loss:  25.003089904785156
Epoch:  7  	Training Loss: 25.162870407104492
Test Loss:  25.142772674560547
Valid Loss:  24.990882873535156
Epoch:  8  	Training Loss: 25.150634765625
Test Loss:  25.13011932373047
Valid Loss:  24.978527069091797
Epoch:  9  	Training Loss: 25.13825035095215
Test Loss:  25.117313385009766
Valid Loss:  24.966022491455078
Epoch:  10  	Training Loss: 25.125717163085938
Test Loss:  25.104358673095703
Valid Loss:  24.953371047973633
Epoch:  11  	Training Loss: 25.113037109375
Test Loss:  25.091243743896484
Valid Loss:  24.940567016601562
Epoch:  12  	Training Loss: 25.100204467773438
Test Loss:  192.47650146484375
Valid Loss:  191.15756225585938
Epoch:  13  	Training Loss: 192.7431640625
Test Loss:  14.152681350708008
Valid Loss:  13.894119262695312
Epoch:  14  	Training Loss: 13.911951065063477
Test Loss:  14.152595520019531
Valid Loss:  13.894004821777344
Epoch:  15  	Training Loss: 13.911849021911621
Test Loss:  14.152507781982422
Valid Loss:  13.893888473510742
Epoch:  16  	Training Loss: 13.911741256713867
Test Loss:  14.15241813659668
Valid Loss:  13.893768310546875
Epoch:  17  	Training Loss: 13.91162109375
Test Loss:  14.152322769165039
Valid Loss:  13.89364242553711
Epoch:  18  	Training Loss: 13.911483764648438
Test Loss:  14.152227401733398
Valid Loss:  13.893497467041016
Epoch:  19  	Training Loss: 13.911333084106445
Test Loss:  14.152127265930176
Valid Loss:  13.893346786499023
Epoch:  20  	Training Loss: 13.911153793334961
Test Loss:  14.152017593383789
Valid Loss:  13.893181800842285
Epoch:  21  	Training Loss: 13.910921096801758
Test Loss:  14.151887893676758
Valid Loss:  13.892972946166992
Epoch:  22  	Training Loss: 13.910632133483887
Test Loss:  413.7123718261719
Valid Loss:  400.7752990722656
Epoch:  23  	Training Loss: 398.9513854980469
Test Loss:  6.633853912353516
Valid Loss:  6.557099342346191
Epoch:  24  	Training Loss: 6.580228328704834
Test Loss:  6.633882522583008
Valid Loss:  6.5571136474609375
Epoch:  25  	Training Loss: 6.580251693725586
Test Loss:  6.633910655975342
Valid Loss:  6.557127952575684
**************************************************learning rate decay**************************************************
Epoch:  26  	Training Loss: 6.58027458190918
Test Loss:  1.0246849060058594
Valid Loss:  1.2912360429763794
Epoch:  27  	Training Loss: 1.2041023969650269
Test Loss:  0.6081416010856628
Valid Loss:  0.7071628570556641
Epoch:  28  	Training Loss: 0.666264533996582
Test Loss:  0.6073075532913208
Valid Loss:  0.6874929666519165
Epoch:  29  	Training Loss: 0.6481209993362427
Test Loss:  0.5861493349075317
Valid Loss:  0.6730371713638306
Epoch:  30  	Training Loss: 0.6323325634002686
Test Loss:  0.5740408301353455
Valid Loss:  0.6574512720108032
Epoch:  31  	Training Loss: 0.6157107353210449
Test Loss:  0.5558905601501465
Valid Loss:  0.636088490486145
Epoch:  32  	Training Loss: 0.593616247177124
Test Loss:  0.4987175464630127
Valid Loss:  0.5808755159378052
Epoch:  33  	Training Loss: 0.5414301156997681
Test Loss:  0.4560449421405792
Valid Loss:  0.5392832159996033
Epoch:  34  	Training Loss: 0.5024592876434326
Test Loss:  0.42351293563842773
Valid Loss:  0.5071609616279602
Epoch:  35  	Training Loss: 0.4725927710533142
Test Loss:  0.3981022834777832
Valid Loss:  0.481649249792099
Epoch:  36  	Training Loss: 0.44903191924095154
Test Loss:  0.3777255415916443
Valid Loss:  0.46078139543533325
Epoch:  37  	Training Loss: 0.4298614263534546
Test Loss:  0.36093461513519287
Valid Loss:  0.44320249557495117
Epoch:  38  	Training Loss: 0.41376858949661255
Test Loss:  0.3467223346233368
Valid Loss:  0.4279771149158478
Epoch:  39  	Training Loss: 0.39985334873199463
Test Loss:  0.3343861699104309
Valid Loss:  0.4144584536552429
Epoch:  40  	Training Loss: 0.38749784231185913
Test Loss:  0.3234335780143738
Valid Loss:  0.40219736099243164
Epoch:  41  	Training Loss: 0.3762773871421814
Test Loss:  0.31579384207725525
Valid Loss:  0.39389413595199585
Epoch:  42  	Training Loss: 0.36887794733047485
Test Loss:  0.28913968801498413
Valid Loss:  0.3623550534248352
Epoch:  43  	Training Loss: 0.3490638732910156
Test Loss:  0.2553410232067108
Valid Loss:  0.31578293442726135
Epoch:  44  	Training Loss: 0.2944953441619873
Test Loss:  0.2085440754890442
Valid Loss:  0.2609637975692749
Epoch:  45  	Training Loss: 0.24950356781482697
Test Loss:  0.17812514305114746
Valid Loss:  0.2205187976360321
Epoch:  46  	Training Loss: 0.2062971591949463
Test Loss:  0.1462821215391159
Valid Loss:  0.18228423595428467
Epoch:  47  	Training Loss: 0.1709265410900116
Test Loss:  0.12112151086330414
Valid Loss:  0.15139421820640564
Epoch:  48  	Training Loss: 0.14045584201812744
Test Loss:  0.10189886391162872
Valid Loss:  0.12612995505332947
Epoch:  49  	Training Loss: 0.11506491899490356
Test Loss:  0.08337096869945526
Valid Loss:  0.10394920408725739
Epoch:  50  	Training Loss: 0.09366380423307419
Test Loss:  0.06988462060689926
Valid Loss:  0.08629228174686432
Epoch:  51  	Training Loss: 0.07621265202760696
Test Loss:  0.05765007063746452
Valid Loss:  0.07131575047969818
Epoch:  52  	Training Loss: 0.062126997858285904
Test Loss:  0.04669112339615822
Valid Loss:  0.057206012308597565
Epoch:  53  	Training Loss: 0.049285102635622025
Test Loss:  0.042842525988817215
Valid Loss:  0.05283283069729805
Epoch:  54  	Training Loss: 0.04540941119194031
Test Loss:  0.04333024471998215
Valid Loss:  0.05077719688415527
Epoch:  55  	Training Loss: 0.044471126049757004
Test Loss:  0.036552757024765015
Valid Loss:  0.04495922476053238
Epoch:  56  	Training Loss: 0.03836651146411896
Test Loss:  0.03354443982243538
Valid Loss:  0.039487000554800034
Epoch:  57  	Training Loss: 0.03428656607866287
Test Loss:  0.03300105407834053
Valid Loss:  0.04060777276754379
Epoch:  58  	Training Loss: 0.034513428807258606
Test Loss:  0.028198249638080597
Valid Loss:  0.033671677112579346
Epoch:  59  	Training Loss: 0.02907131053507328
Test Loss:  0.026424385607242584
Valid Loss:  0.03378140926361084
Epoch:  60  	Training Loss: 0.028256993740797043
Test Loss:  0.025165218859910965
Valid Loss:  0.03147917985916138
Epoch:  61  	Training Loss: 0.02688153088092804
Test Loss:  0.024327322840690613
Valid Loss:  0.0315406396985054
Epoch:  62  	Training Loss: 0.026461858302354813
Test Loss:  0.0423298217356205
Valid Loss:  0.039656445384025574
Epoch:  63  	Training Loss: 0.03971944376826286
Test Loss:  0.20137792825698853
Valid Loss:  0.20869392156600952
Epoch:  64  	Training Loss: 0.20342636108398438
Test Loss:  0.5266305208206177
Valid Loss:  0.46829020977020264
Epoch:  65  	Training Loss: 0.47677773237228394
Test Loss:  0.036071062088012695
Valid Loss:  0.05337736755609512
**************************************************learning rate decay**************************************************
Epoch:  66  	Training Loss: 0.05632665008306503
Test Loss:  0.03720945119857788
Valid Loss:  0.03645338863134384
Epoch:  67  	Training Loss: 0.04353922978043556
Test Loss:  0.024256372824311256
Valid Loss:  0.03226965665817261
Epoch:  68  	Training Loss: 0.03690159320831299
Test Loss:  0.025280125439167023
Valid Loss:  0.028716400265693665
Epoch:  69  	Training Loss: 0.034240055829286575
Test Loss:  0.022184330970048904
Valid Loss:  0.02774425968527794
Epoch:  70  	Training Loss: 0.03240088373422623
Test Loss:  0.022606560960412025
Valid Loss:  0.02602272666990757
Epoch:  71  	Training Loss: 0.031089771538972855
Test Loss:  0.021289948374032974
Valid Loss:  0.025605319067835808
Epoch:  72  	Training Loss: 0.030135221779346466
Test Loss:   15%|█▍        | 73/500 [01:07<07:37,  1.07s/it] 15%|█▌        | 75/500 [01:07<05:27,  1.30it/s] 15%|█▌        | 77/500 [01:07<03:56,  1.79it/s] 16%|█▌        | 79/500 [01:07<02:52,  2.44it/s] 16%|█▌        | 81/500 [01:14<08:44,  1.25s/it] 17%|█▋        | 83/500 [01:14<06:14,  1.11it/s] 17%|█▋        | 85/500 [01:14<04:29,  1.54it/s] 17%|█▋        | 87/500 [01:14<03:16,  2.11it/s] 18%|█▊        | 89/500 [01:14<02:24,  2.84it/s] 18%|█▊        | 91/500 [01:21<08:22,  1.23s/it] 19%|█▊        | 93/500 [01:21<05:58,  1.13it/s] 19%|█▉        | 95/500 [01:21<04:17,  1.57it/s] 19%|█▉        | 97/500 [01:21<03:07,  2.15it/s] 20%|█▉        | 99/500 [01:21<02:18,  2.89it/s] 20%|██        | 101/500 [01:28<07:55,  1.19s/it] 21%|██        | 103/500 [01:28<05:38,  1.17it/s] 21%|██        | 105/500 [01:28<04:03,  1.62it/s] 21%|██▏       | 107/500 [01:28<02:57,  2.22it/s] 22%|██▏       | 109/500 [01:28<02:11,  2.98it/s] 22%|██▏       | 111/500 [01:35<07:45,  1.20s/it] 23%|██▎       | 113/500 [01:35<05:33,  1.16it/s] 23%|██▎       | 115/500 [01:35<03:59,  1.61it/s] 23%|██▎       | 117/500 [01:35<02:54,  2.19it/s] 24%|██▍       | 119/500 [01:35<02:09,  2.94it/s] 24%|██▍       | 121/500 [01:42<07:37,  1.21s/it] 25%|██▍       | 123/500 [01:42<05:26,  1.15it/s] 25%|██▌       | 125/500 [01:42<03:54,  1.60it/s] 25%|██▌       | 127/500 [01:42<02:50,  2.18it/s] 26%|██▌       | 129/500 [01:42<02:06,  2.94it/s] 26%|██▌       | 131/500 [01:48<07:18,  1.19s/it] 27%|██▋       | 133/500 [01:49<05:12,  1.17it/s] 27%|██▋       | 135/500 [01:49<03:44,  1.62it/s] 27%|██▋       | 137/500 [01:49<02:43,  2.21it/s] 28%|██▊       | 139/500 [01:49<02:03,  2.93it/s] 28%|██▊       | 141/500 [01:56<07:14,  1.21s/it]0.019837182015180588
Valid Loss:  0.024472825229167938
Epoch:  73  	Training Loss: 0.02879421040415764
Test Loss:  0.018564287573099136
Valid Loss:  0.02339768595993519
Epoch:  74  	Training Loss: 0.02751385234296322
Test Loss:  0.017386365681886673
Valid Loss:  0.022388186305761337
Epoch:  75  	Training Loss: 0.02628587745130062
Test Loss:  0.016307702288031578
Valid Loss:  0.02135477215051651
Epoch:  76  	Training Loss: 0.025065232068300247
Test Loss:  0.015307238325476646
Valid Loss:  0.020391754806041718
Epoch:  77  	Training Loss: 0.02394074946641922
Test Loss:  0.014441062696278095
Valid Loss:  0.019512848928570747
Epoch:  78  	Training Loss: 0.02290874347090721
Test Loss:  0.013668464496731758
Valid Loss:  0.01860574260354042
Epoch:  79  	Training Loss: 0.02192864753305912
Test Loss:  0.012934179045259953
Valid Loss:  0.017756374552845955
Epoch:  80  	Training Loss: 0.021013960242271423
Test Loss:  0.01217446755617857
Valid Loss:  0.01692422293126583
Epoch:  81  	Training Loss: 0.02010386250913143
Test Loss:  0.011510852724313736
Valid Loss:  0.016150467097759247
Epoch:  82  	Training Loss: 0.019261855632066727
Test Loss:  0.011037414893507957
Valid Loss:  0.01577427238225937
Epoch:  83  	Training Loss: 0.01878419704735279
Test Loss:  0.01068057306110859
Valid Loss:  0.015490416437387466
Epoch:  84  	Training Loss: 0.018415268510580063
Test Loss:  0.010412300005555153
Valid Loss:  0.015280530788004398
Epoch:  85  	Training Loss: 0.01814645528793335
Test Loss:  0.010218212381005287
Valid Loss:  0.015118835493922234
Epoch:  86  	Training Loss: 0.017944490537047386
Test Loss:  0.01007079891860485
Valid Loss:  0.014983647502958775
Epoch:  87  	Training Loss: 0.017784234136343002
Test Loss:  0.009952638298273087
Valid Loss:  0.014867952093482018
Epoch:  88  	Training Loss: 0.017652032896876335
Test Loss:  0.009855503216385841
Valid Loss:  0.014764891937375069
Epoch:  89  	Training Loss: 0.017538201063871384
Test Loss:  0.009771940298378468
Valid Loss:  0.014669517055153847
Epoch:  90  	Training Loss: 0.01743614301085472
Test Loss:  0.009697631001472473
Valid Loss:  0.01457910519093275
Epoch:  91  	Training Loss: 0.017342109233140945
Test Loss:  0.00962945818901062
Valid Loss:  0.014491848647594452
Epoch:  92  	Training Loss: 0.017253369092941284
Test Loss:  0.008666610345244408
Valid Loss:  0.011001825332641602
Epoch:  93  	Training Loss: 0.01327177882194519
Test Loss:  0.008482690900564194
Valid Loss:  0.010593419894576073
Epoch:  94  	Training Loss: 0.012780727818608284
Test Loss:  0.00815169233828783
Valid Loss:  0.010200045071542263
Epoch:  95  	Training Loss: 0.012322431430220604
Test Loss:  0.0078433221206069
Valid Loss:  0.009835361503064632
Epoch:  96  	Training Loss: 0.011892275884747505
Test Loss:  0.007583748549222946
Valid Loss:  0.009505854919552803
Epoch:  97  	Training Loss: 0.01150045357644558
Test Loss:  0.007382897660136223
Valid Loss:  0.009210621938109398
Epoch:  98  	Training Loss: 0.011155100539326668
Test Loss:  0.007233771029859781
Valid Loss:  0.008960127830505371
Epoch:  99  	Training Loss: 0.01086035743355751
Test Loss:  0.00714033842086792
Valid Loss:  0.008792497217655182
Epoch:  100  	Training Loss: 0.010621210560202599
Test Loss:  0.0070840222761034966
Valid Loss:  0.008666862733662128
Epoch:  101  	Training Loss: 0.010430151596665382
Test Loss:  0.007060865871608257
Valid Loss:  0.008599357679486275
Epoch:  102  	Training Loss: 0.010291727259755135
Test Loss:  0.007316182367503643
Valid Loss:  0.008542226627469063
Epoch:  103  	Training Loss: 0.010261593386530876
Test Loss:  0.007192895282059908
Valid Loss:  0.008563445881009102
Epoch:  104  	Training Loss: 0.010253628715872765
Test Loss:  0.007259716745465994
Valid Loss:  0.008561444468796253
Epoch:  105  	Training Loss: 0.010250854305922985
Test Loss:  0.007239639759063721
Valid Loss:  0.008572322316467762
Epoch:  106  	Training Loss: 0.01024941261857748
Test Loss:  0.0072595104575157166
Valid Loss:  0.008576720952987671
Epoch:  107  	Training Loss: 0.010248443111777306
Test Loss:  0.007259665057063103
Valid Loss:  0.008583246730268002
Epoch:  108  	Training Loss: 0.010247698053717613
Test Loss:  0.0072679705917835236
Valid Loss:  0.008587844669818878
Epoch:  109  	Training Loss: 0.010247113183140755
Test Loss:  0.007271504960954189
Valid Loss:  0.008592480793595314
Epoch:  110  	Training Loss: 0.010246635414659977
Test Loss:  0.007276396732777357
Valid Loss:  0.008596323430538177
Epoch:  111  	Training Loss: 0.010246247053146362
Test Loss:  0.007279879413545132
Valid Loss:  0.008599831722676754
Epoch:  112  	Training Loss: 0.0102459155023098
Test Loss:  0.006888015195727348
Valid Loss:  0.00868165772408247
Epoch:  113  	Training Loss: 0.009931888431310654
Test Loss:  0.006866778247058392
Valid Loss:  0.008736666291952133
Epoch:  114  	Training Loss: 0.009920664131641388
Test Loss:  0.006862835958600044
Valid Loss:  0.00875622034072876
Epoch:  115  	Training Loss: 0.009917624294757843
Test Loss:  0.00686273816972971
Valid Loss:  0.008758516050875187
Epoch:  116  	Training Loss: 0.009915515780448914
Test Loss:  0.006863284390419722
Valid Loss:  0.008758779615163803
Epoch:  117  	Training Loss: 0.009913535788655281
Test Loss:  0.006863874848932028
Valid Loss:  0.008758941665291786
Epoch:  118  	Training Loss: 0.009911594912409782
Test Loss:  0.006864506285637617
Valid Loss:  0.00875915214419365
Epoch:  119  	Training Loss: 0.009909690357744694
Test Loss:  0.006865138188004494
Valid Loss:  0.008759395219385624
Epoch:  120  	Training Loss: 0.009907806292176247
Test Loss:  0.006865793839097023
Valid Loss:  0.008759679272770882
Epoch:  121  	Training Loss: 0.009905952028930187
Test Loss:  0.006866454612463713
Valid Loss:  0.0087599977850914
Epoch:  122  	Training Loss: 0.009904099628329277
Test Loss:  0.006911363452672958
Valid Loss:  0.008751066401600838
Epoch:  123  	Training Loss: 0.00986667349934578
Test Loss:  0.006943888030946255
Valid Loss:  0.008775458671152592
Epoch:  124  	Training Loss: 0.009839246049523354
Test Loss:  0.006973134353756905
Valid Loss:  0.008808081038296223
Epoch:  125  	Training Loss: 0.009816547855734825
Test Loss:  0.007002794183790684
Valid Loss:  0.008835366927087307
Epoch:  126  	Training Loss: 0.009798715822398663
Test Loss:  0.0070305452682077885
Valid Loss:  0.008861497044563293
Epoch:  127  	Training Loss: 0.009784864261746407
Test Loss:  0.007055690512061119
Valid Loss:  0.00888512097299099
Epoch:  128  	Training Loss: 0.009774263948202133
Test Loss:  0.007078325375914574
Valid Loss:  0.00890676025301218
Epoch:  129  	Training Loss: 0.009766162373125553
Test Loss:  0.007097965572029352
Valid Loss:  0.008932849392294884
Epoch:  130  	Training Loss: 0.009759181179106236
Test Loss:  0.0071178013458848
Valid Loss:  0.008951239287853241
Epoch:  131  	Training Loss: 0.009753735736012459
Test Loss:  0.007135852240025997
Valid Loss:  0.008967990055680275
Epoch:  132  	Training Loss: 0.009749511256814003
Test Loss:  0.007228898350149393
Valid Loss:  0.008994871750473976
Epoch:  133  	Training Loss: 0.009730743244290352
Test Loss:  0.007266888860613108
Valid Loss:  0.009008996188640594
Epoch:  134  	Training Loss: 0.009727926924824715
Test Loss:  0.007281224709004164
Valid Loss:  0.00901476014405489
Epoch:  135  	Training Loss: 0.00972728431224823
Test Loss:  0.007286388427019119
Valid Loss:  0.009016932919621468
Epoch:  136  	Training Loss: 0.00972694531083107
Test Loss:  0.007288115564733744
Valid Loss:  0.00901772454380989
Epoch:  137  	Training Loss: 0.009726641699671745
Test Loss:  0.007288574706763029
Valid Loss:  0.009017996490001678
Epoch:  138  	Training Loss: 0.009726348333060741
Test Loss:  0.007288557477295399
Valid Loss:  0.00901807751506567
Epoch:  139  	Training Loss: 0.009726062417030334
Test Loss:  0.00728838425129652
Valid Loss:  0.00901807751506567
Epoch:  140  	Training Loss: 0.009725779294967651
Test Loss:  0.00728813698515296
Valid Loss:  0.00901806354522705
Epoch:  141  	Training Loss: 0.009725495241582394
Test Loss:  0.007287887390702963
Valid Loss:  0.009018036536872387
Epoch:  142  	Training Loss: 0.009725219570100307
Test Loss:  0.007224910892546177
Valid Loss:  0.00894973985850811
 29%|██▊       | 143/500 [01:56<05:10,  1.15it/s] 29%|██▉       | 145/500 [01:56<03:43,  1.59it/s] 29%|██▉       | 147/500 [01:56<02:42,  2.18it/s] 30%|██▉       | 149/500 [01:56<01:59,  2.93it/s] 30%|███       | 151/500 [02:03<07:01,  1.21s/it] 31%|███       | 153/500 [02:03<05:00,  1.16it/s] 31%|███       | 155/500 [02:03<03:35,  1.60it/s] 31%|███▏      | 157/500 [02:03<02:36,  2.19it/s] 32%|███▏      | 159/500 [02:03<01:56,  2.94it/s] 32%|███▏      | 161/500 [02:09<06:39,  1.18s/it] 33%|███▎      | 163/500 [02:09<04:44,  1.18it/s] 33%|███▎      | 165/500 [02:10<03:24,  1.64it/s] 33%|███▎      | 167/500 [02:10<02:29,  2.23it/s] 34%|███▍      | 169/500 [02:10<01:50,  2.99it/s] 34%|███▍      | 171/500 [02:16<06:22,  1.16s/it] 35%|███▍      | 173/500 [02:16<04:33,  1.20it/s] 35%|███▌      | 175/500 [02:16<03:16,  1.65it/s] 35%|███▌      | 177/500 [02:16<02:22,  2.26it/s] 36%|███▌      | 179/500 [02:17<01:45,  3.03it/s] 36%|███▌      | 181/500 [02:23<06:20,  1.19s/it] 37%|███▋      | 183/500 [02:23<04:30,  1.17it/s] 37%|███▋      | 185/500 [02:23<03:16,  1.61it/s] 37%|███▋      | 187/500 [02:23<02:24,  2.17it/s] 38%|███▊      | 189/500 [02:24<01:46,  2.91it/s] 38%|███▊      | 191/500 [02:30<06:10,  1.20s/it] 39%|███▊      | 193/500 [02:30<04:24,  1.16it/s] 39%|███▉      | 195/500 [02:30<03:09,  1.61it/s] 39%|███▉      | 197/500 [02:30<02:17,  2.20it/s] 40%|███▉      | 199/500 [02:31<01:41,  2.96it/s] 40%|████      | 201/500 [02:37<05:58,  1.20s/it] 41%|████      | 203/500 [02:37<04:16,  1.16it/s] 41%|████      | 205/500 [02:37<03:03,  1.60it/s] 41%|████▏     | 207/500 [02:37<02:13,  2.19it/s] 42%|████▏     | 209/500 [02:37<01:39,  2.94it/s] 42%|████▏     | 211/500 [02:44<05:44,  1.19s/it]Epoch:  143  	Training Loss: 0.009650759398937225
Test Loss:  0.00721680698916316
Valid Loss:  0.008882004767656326
Epoch:  144  	Training Loss: 0.009571194648742676
Test Loss:  0.007163030095398426
Valid Loss:  0.008790960535407066
Epoch:  145  	Training Loss: 0.009505320340394974
Test Loss:  0.007134214974939823
Valid Loss:  0.008690028451383114
Epoch:  146  	Training Loss: 0.009441567584872246
Test Loss:  0.007086997851729393
Valid Loss:  0.008611222729086876
Epoch:  147  	Training Loss: 0.009395601227879524
Test Loss:  0.007057009730488062
Valid Loss:  0.008555823937058449
Epoch:  148  	Training Loss: 0.009361173026263714
Test Loss:  0.007033098489046097
Valid Loss:  0.008518705144524574
Epoch:  149  	Training Loss: 0.009335514158010483
Test Loss:  0.00702258525416255
Valid Loss:  0.008486100472509861
Epoch:  150  	Training Loss: 0.009313467890024185
Test Loss:  0.007009419612586498
Valid Loss:  0.008456287905573845
Epoch:  151  	Training Loss: 0.009296953678131104
Test Loss:  0.007021425291895866
Valid Loss:  0.008433183655142784
Epoch:  152  	Training Loss: 0.00928745698183775
Test Loss:  0.00604273984208703
Valid Loss:  0.007647248916327953
Epoch:  153  	Training Loss: 0.008309686556458473
Test Loss:  0.005429833196103573
Valid Loss:  0.007119536399841309
Epoch:  154  	Training Loss: 0.007672575302422047
Test Loss:  0.005025737453252077
Valid Loss:  0.0067592766135931015
Epoch:  155  	Training Loss: 0.007234886288642883
Test Loss:  0.004732790403068066
Valid Loss:  0.0064674862660467625
Epoch:  156  	Training Loss: 0.0069127799943089485
Test Loss:  0.004507715813815594
Valid Loss:  0.006229221820831299
Epoch:  157  	Training Loss: 0.006651385687291622
Test Loss:  0.0043223146349191666
Valid Loss:  0.00601097010076046
Epoch:  158  	Training Loss: 0.006425820291042328
Test Loss:  0.004157986491918564
Valid Loss:  0.005808678921312094
Epoch:  159  	Training Loss: 0.006223637145012617
Test Loss:  0.004007169045507908
Valid Loss:  0.0056244125589728355
Epoch:  160  	Training Loss: 0.006038154009729624
Test Loss:  0.0038686126936227083
Valid Loss:  0.005452478304505348
Epoch:  161  	Training Loss: 0.005864116828888655
Test Loss:  0.0037398547865450382
Valid Loss:  0.005290668923407793
Epoch:  162  	Training Loss: 0.0057000028900802135
Test Loss:  0.003681441303342581
Valid Loss:  0.005213549826294184
Epoch:  163  	Training Loss: 0.005633236840367317
Test Loss:  0.0036367240827530622
Valid Loss:  0.005153654143214226
Epoch:  164  	Training Loss: 0.005582243204116821
Test Loss:  0.003603304736316204
Valid Loss:  0.005107893142849207
Epoch:  165  	Training Loss: 0.005543437786400318
Test Loss:  0.0035782004706561565
Valid Loss:  0.00507062254473567
Epoch:  166  	Training Loss: 0.005512723699212074
Test Loss:  0.0035575018264353275
Valid Loss:  0.0050386423245072365
Epoch:  167  	Training Loss: 0.005486925132572651
Test Loss:  0.003540735226124525
Valid Loss:  0.005011392757296562
Epoch:  168  	Training Loss: 0.005464691203087568
Test Loss:  0.0035260093864053488
Valid Loss:  0.004987035878002644
Epoch:  169  	Training Loss: 0.005444683134555817
Test Loss:  0.0035117692314088345
Valid Loss:  0.004963291343301535
Epoch:  170  	Training Loss: 0.005424999166280031
Test Loss:  0.0034970655106008053
Valid Loss:  0.004938336554914713
Epoch:  171  	Training Loss: 0.005404573865234852
Test Loss:  0.003482506610453129
Valid Loss:  0.004912102594971657
Epoch:  172  	Training Loss: 0.005381436087191105
Test Loss:  0.003458444494754076
Valid Loss:  0.004850912373512983
Epoch:  173  	Training Loss: 0.005305951926857233
Test Loss:  0.0034350426867604256
Valid Loss:  0.004798797890543938
Epoch:  174  	Training Loss: 0.005236359313130379
Test Loss:  0.003416941501200199
Valid Loss:  0.004746569320559502
Epoch:  175  	Training Loss: 0.005170971155166626
Test Loss:  0.003404152812436223
Valid Loss:  0.004700380843132734
Epoch:  176  	Training Loss: 0.005113831255584955
Test Loss:  0.003397134132683277
Valid Loss:  0.004664082080125809
Epoch:  177  	Training Loss: 0.005067954771220684
Test Loss:  0.0033946395851671696
Valid Loss:  0.004635637626051903
Epoch:  178  	Training Loss: 0.005030901171267033
Test Loss:  0.003395350417122245
Valid Loss:  0.004613029304891825
Epoch:  179  	Training Loss: 0.005000911187380552
Test Loss:  0.0033982573077082634
Valid Loss:  0.004595102742314339
Epoch:  180  	Training Loss: 0.0049767573364079
Test Loss:  0.003402368165552616
Valid Loss:  0.004580914042890072
Epoch:  181  	Training Loss: 0.004957227036356926
Test Loss:  0.003407450392842293
Valid Loss:  0.004569694399833679
Epoch:  182  	Training Loss: 0.0049414304085075855
Test Loss:  0.0034473976120352745
Valid Loss:  0.004531955346465111
Epoch:  183  	Training Loss: 0.0048929257318377495
Test Loss:  0.0034716976806521416
Valid Loss:  0.004517103545367718
Epoch:  184  	Training Loss: 0.004877369850873947
Test Loss:  0.0034794167149811983
Valid Loss:  0.004505765158683062
Epoch:  185  	Training Loss: 0.004870029166340828
Test Loss:  0.0034772735089063644
Valid Loss:  0.00449320999905467
Epoch:  186  	Training Loss: 0.004864271264523268
Test Loss:  0.003469292540103197
Valid Loss:  0.004479743540287018
Epoch:  187  	Training Loss: 0.0048582833260297775
Test Loss:  0.003459310857579112
Valid Loss:  0.004465880803763866
Epoch:  188  	Training Loss: 0.004851639736443758
Test Loss:  0.0034477710723876953
Valid Loss:  0.004450473003089428
Epoch:  189  	Training Loss: 0.004843203816562891
Test Loss:  0.003433023579418659
Valid Loss:  0.004428835120052099
Epoch:  190  	Training Loss: 0.004830156918615103
Test Loss:  0.003415862563997507
Valid Loss:  0.004403784871101379
Epoch:  191  	Training Loss: 0.004814730957150459
Test Loss:  0.003395514329895377
Valid Loss:  0.004371901974081993
Epoch:  192  	Training Loss: 0.004796035122126341
Test Loss:  0.0029371795244514942
Valid Loss:  0.003954474814236164
Epoch:  193  	Training Loss: 0.004364525433629751
Test Loss:  0.002675438765436411
Valid Loss:  0.0037243757396936417
Epoch:  194  	Training Loss: 0.004116656258702278
Test Loss:  0.002531297504901886
Valid Loss:  0.00360374734736979
Epoch:  195  	Training Loss: 0.003975227940827608
Test Loss:  0.0024539874866604805
Valid Loss:  0.0035448491107672453
Epoch:  196  	Training Loss: 0.003895965637639165
Test Loss:  0.002413342706859112
Valid Loss:  0.003517838893458247
Epoch:  197  	Training Loss: 0.0038519399240612984
Test Loss:  0.002392273396253586
Valid Loss:  0.0035059337969869375
Epoch:  198  	Training Loss: 0.0038274931721389294
Test Loss:  0.0023821385111659765
Valid Loss:  0.0035003931261599064
Epoch:  199  	Training Loss: 0.0038128397427499294
Test Loss:  0.002376202028244734
Valid Loss:  0.003497048746794462
Epoch:  200  	Training Loss: 0.003802740480750799
Test Loss:  0.0023721070028841496
Valid Loss:  0.0034943115897476673
Epoch:  201  	Training Loss: 0.003794564865529537
Test Loss:  0.0023688883520662785
Valid Loss:  0.0034915737342089415
Epoch:  202  	Training Loss: 0.0037873624823987484
Test Loss:  0.002284263027831912
Valid Loss:  0.003101373789831996
Epoch:  203  	Training Loss: 0.003288187086582184
Test Loss:  0.002319979714229703
Valid Loss:  0.003108392935246229
Epoch:  204  	Training Loss: 0.0032805996015667915
Test Loss:  0.0023273369297385216
Valid Loss:  0.0031110281124711037
Epoch:  205  	Training Loss: 0.0032777292653918266
Test Loss:  0.002329274546355009
Valid Loss:  0.0031123775988817215
Epoch:  206  	Training Loss: 0.003275335766375065
Test Loss:  0.0023302994668483734
Valid Loss:  0.0031135454773902893
Epoch:  207  	Training Loss: 0.0032732519321143627
Test Loss:  0.002331193070858717
Valid Loss:  0.0031147077679634094
Epoch:  208  	Training Loss: 0.003271769266575575
Test Loss:  0.0023388091940432787
Valid Loss:  0.003117429558187723
Epoch:  209  	Training Loss: 0.003270973451435566
Test Loss:  0.002340482547879219
Valid Loss:  0.0031184563413262367
Epoch:  210  	Training Loss: 0.0032703904435038567
Test Loss:  0.0023411172442138195
Valid Loss:  0.0031191669404506683
Epoch:  211  	Training Loss: 0.0032698758877813816
Test Loss:  0.002341556828469038
Valid Loss:  0.003119794186204672
Epoch:  212  	Training Loss: 0.003269416280090809
Test Loss:   43%|████▎     | 213/500 [02:44<04:06,  1.17it/s] 43%|████▎     | 215/500 [02:44<02:56,  1.61it/s] 43%|████▎     | 217/500 [02:44<02:08,  2.20it/s] 44%|████▍     | 219/500 [02:44<01:35,  2.95it/s] 44%|████▍     | 221/500 [02:51<05:30,  1.18s/it] 45%|████▍     | 223/500 [02:51<03:55,  1.18it/s] 45%|████▌     | 225/500 [02:51<02:49,  1.62it/s] 45%|████▌     | 227/500 [02:51<02:03,  2.21it/s] 46%|████▌     | 229/500 [02:51<01:31,  2.97it/s] 46%|████▌     | 231/500 [02:58<05:25,  1.21s/it] 47%|████▋     | 233/500 [02:58<03:51,  1.15it/s] 47%|████▋     | 235/500 [02:58<02:46,  1.59it/s] 47%|████▋     | 237/500 [02:58<02:00,  2.18it/s] 48%|████▊     | 239/500 [02:58<01:29,  2.93it/s] 48%|████▊     | 241/500 [03:05<05:12,  1.21s/it] 49%|████▊     | 243/500 [03:05<03:42,  1.15it/s] 49%|████▉     | 245/500 [03:05<02:40,  1.59it/s] 49%|████▉     | 247/500 [03:05<01:56,  2.18it/s] 50%|████▉     | 249/500 [03:05<01:25,  2.93it/s] 50%|█████     | 251/500 [03:12<05:06,  1.23s/it] 51%|█████     | 253/500 [03:12<03:38,  1.13it/s] 51%|█████     | 255/500 [03:12<02:36,  1.57it/s] 51%|█████▏    | 257/500 [03:12<01:53,  2.14it/s] 52%|█████▏    | 259/500 [03:12<01:23,  2.87it/s] 52%|█████▏    | 261/500 [03:19<04:59,  1.25s/it] 53%|█████▎    | 263/500 [03:19<03:32,  1.11it/s] 53%|█████▎    | 265/500 [03:19<02:32,  1.54it/s] 53%|█████▎    | 267/500 [03:20<01:50,  2.11it/s] 54%|█████▍    | 269/500 [03:20<01:20,  2.85it/s] 54%|█████▍    | 271/500 [03:26<04:40,  1.23s/it] 55%|█████▍    | 273/500 [03:26<03:19,  1.14it/s] 55%|█████▌    | 275/500 [03:27<02:23,  1.57it/s] 55%|█████▌    | 277/500 [03:27<01:43,  2.15it/s] 56%|█████▌    | 279/500 [03:27<01:16,  2.89it/s]0.0021129720844328403
Valid Loss:  0.002864321693778038
Epoch:  213  	Training Loss: 0.0030091425869613886
Test Loss:  0.001965024508535862
Valid Loss:  0.0026473677717149258
Epoch:  214  	Training Loss: 0.0027942247688770294
Test Loss:  0.0018185274675488472
Valid Loss:  0.002484515542164445
Epoch:  215  	Training Loss: 0.002619248814880848
Test Loss:  0.0017234808765351772
Valid Loss:  0.002345264656469226
Epoch:  216  	Training Loss: 0.0024769119918346405
Test Loss:  0.0016213038470596075
Valid Loss:  0.0022354652173817158
Epoch:  217  	Training Loss: 0.0023552789352834225
Test Loss:  0.00156010955106467
Valid Loss:  0.0021305640693753958
Epoch:  218  	Training Loss: 0.0022495442535728216
Test Loss:  0.0014764927327632904
Valid Loss:  0.0020647512283176184
Epoch:  219  	Training Loss: 0.0021663294173777103
Test Loss:  0.001448916969820857
Valid Loss:  0.002012810204178095
Epoch:  220  	Training Loss: 0.0021005102898925543
Test Loss:  0.0014021496754139662
Valid Loss:  0.001980390166863799
Epoch:  221  	Training Loss: 0.002053116913884878
Test Loss:  0.0013836913276463747
Valid Loss:  0.0019532463047653437
Epoch:  222  	Training Loss: 0.0020160283893346786
Test Loss:  0.001394577557221055
Valid Loss:  0.0019481938797980547
Epoch:  223  	Training Loss: 0.002012399258092046
Test Loss:  0.001392441801726818
Valid Loss:  0.0019463419448584318
Epoch:  224  	Training Loss: 0.0020097477827221155
Test Loss:  0.0013915083836764097
Valid Loss:  0.0019443462369963527
Epoch:  225  	Training Loss: 0.0020071608014404774
Test Loss:  0.0013904989464208484
Valid Loss:  0.001942401984706521
Epoch:  226  	Training Loss: 0.002004656009376049
Test Loss:  0.0013895761221647263
Valid Loss:  0.0019406293286010623
Epoch:  227  	Training Loss: 0.002002283465117216
Test Loss:  0.0013887251261621714
Valid Loss:  0.0019389268709346652
Epoch:  228  	Training Loss: 0.0020000003278255463
Test Loss:  0.001387893222272396
Valid Loss:  0.0019372544484212995
Epoch:  229  	Training Loss: 0.001997753046452999
Test Loss:  0.0013870841357856989
Valid Loss:  0.0019356142729520798
Epoch:  230  	Training Loss: 0.0019956156611442566
Test Loss:  0.0013904471416026354
Valid Loss:  0.0019335424294695258
Epoch:  231  	Training Loss: 0.0019936803728342056
Test Loss:  0.001385354669764638
Valid Loss:  0.0019325315952301025
Epoch:  232  	Training Loss: 0.0019917325116693974
Test Loss:  0.0013941095676273108
Valid Loss:  0.0019144383259117603
Epoch:  233  	Training Loss: 0.0019762306474149227
Test Loss:  0.001376930857077241
Valid Loss:  0.0019028021488338709
Epoch:  234  	Training Loss: 0.001962111098691821
Test Loss:  0.0013797112042084336
Valid Loss:  0.0018886460456997156
Epoch:  235  	Training Loss: 0.0019487859681248665
Test Loss:  0.0013667804887518287
Valid Loss:  0.001877819187939167
Epoch:  236  	Training Loss: 0.0019360283622518182
Test Loss:  0.0013632175978273153
Valid Loss:  0.0018657332984730601
Epoch:  237  	Training Loss: 0.0019237789092585444
Test Loss:  0.0013543933164328337
Valid Loss:  0.001855004345998168
Epoch:  238  	Training Loss: 0.0019120101351290941
Test Loss:  0.0013488992117345333
Valid Loss:  0.0018440907588228583
Epoch:  239  	Training Loss: 0.0019008847884833813
Test Loss:  0.0013466686941683292
Valid Loss:  0.001834035268984735
Epoch:  240  	Training Loss: 0.0018905181204900146
Test Loss:  0.0013383305631577969
Valid Loss:  0.0018253090092912316
Epoch:  241  	Training Loss: 0.0018804960418492556
Test Loss:  0.0013340364675968885
Valid Loss:  0.0018166075460612774
Epoch:  242  	Training Loss: 0.0018708216957747936
Test Loss:  0.001269858912564814
Valid Loss:  0.001775831333361566
Epoch:  243  	Training Loss: 0.0018165848450735211
Test Loss:  0.0012372054625302553
Valid Loss:  0.0017508489545434713
Epoch:  244  	Training Loss: 0.0017787885153666139
Test Loss:  0.0012139074970036745
Valid Loss:  0.001727561466395855
Epoch:  245  	Training Loss: 0.0017453617183491588
Test Loss:  0.0011966786114498973
Valid Loss:  0.0017052049515768886
Epoch:  246  	Training Loss: 0.0017155853565782309
Test Loss:  0.0011805153917521238
Valid Loss:  0.001684179063886404
Epoch:  247  	Training Loss: 0.0016878917813301086
Test Loss:  0.001167659880593419
Valid Loss:  0.0016640404937788844
Epoch:  248  	Training Loss: 0.0016632959013804793
Test Loss:  0.0011569095076993108
Valid Loss:  0.001645025797188282
Epoch:  249  	Training Loss: 0.0016409190138801932
Test Loss:  0.001145435031503439
Valid Loss:  0.0016270148335024714
Epoch:  250  	Training Loss: 0.0016193072078749537
Test Loss:  0.0011338895419612527
Valid Loss:  0.001609693979844451
Epoch:  251  	Training Loss: 0.0015983921475708485
Test Loss:  0.0011225787457078695
Valid Loss:  0.0015928216744214296
Epoch:  252  	Training Loss: 0.0015786399599164724
Test Loss:  0.0011082334676757455
Valid Loss:  0.0015904069878160954
Epoch:  253  	Training Loss: 0.0015566854272037745
Test Loss:  0.0011066966690123081
Valid Loss:  0.0015807671006768942
Epoch:  254  	Training Loss: 0.001539180288091302
Test Loss:  0.0011066050501540303
Valid Loss:  0.0015731422463431954
Epoch:  255  	Training Loss: 0.0015248898416757584
Test Loss:  0.0011059927055612206
Valid Loss:  0.0015685169491916895
Epoch:  256  	Training Loss: 0.0015128054656088352
Test Loss:  0.001106299925595522
Valid Loss:  0.0015649492852389812
Epoch:  257  	Training Loss: 0.0015025762841105461
Test Loss:  0.0011070923646911979
Valid Loss:  0.0015624616062268615
Epoch:  258  	Training Loss: 0.0014939871616661549
Test Loss:  0.0011083431309089065
Valid Loss:  0.001560703618451953
Epoch:  259  	Training Loss: 0.0014866947894915938
Test Loss:  0.0011098803952336311
Valid Loss:  0.0015595841687172651
Epoch:  260  	Training Loss: 0.0014804904349148273
Test Loss:  0.0011116205714643002
Valid Loss:  0.0015589615795761347
Epoch:  261  	Training Loss: 0.0014752084389328957
Test Loss:  0.0011134862434118986
Valid Loss:  0.0015587263042107224
Epoch:  262  	Training Loss: 0.0014707003720104694
Test Loss:  0.0011061751283705235
Valid Loss:  0.0015544770285487175
Epoch:  263  	Training Loss: 0.0014647557400166988
Test Loss:  0.0011029113084077835
Valid Loss:  0.0015487249474972486
Epoch:  264  	Training Loss: 0.0014596320688724518
Test Loss:  0.0011004088446497917
Valid Loss:  0.0015462380833923817
Epoch:  265  	Training Loss: 0.001456051249988377
Test Loss:  0.0010988302528858185
Valid Loss:  0.001543581485748291
Epoch:  266  	Training Loss: 0.0014528315514326096
Test Loss:  0.0010969345457851887
Valid Loss:  0.0015418593538925052
Epoch:  267  	Training Loss: 0.0014499283861368895
Test Loss:  0.0010957976337522268
Valid Loss:  0.0015394254587590694
Epoch:  268  	Training Loss: 0.001447079237550497
Test Loss:  0.0010941880755126476
Valid Loss:  0.0015375270741060376
Epoch:  269  	Training Loss: 0.001444392604753375
Test Loss:  0.001092951511964202
Valid Loss:  0.0015356279909610748
Epoch:  270  	Training Loss: 0.0014418363571166992
Test Loss:  0.0010917764157056808
Valid Loss:  0.0015337623190134764
Epoch:  271  	Training Loss: 0.001439363812096417
Test Loss:  0.0010906483512371778
Valid Loss:  0.0015319623053073883
Epoch:  272  	Training Loss: 0.0014369611162692308
Test Loss:  0.0010942092631012201
Valid Loss:  0.0015128374798223376
Epoch:  273  	Training Loss: 0.0014214118709787726
Test Loss:  0.0010839963797479868
Valid Loss:  0.0015067264903336763
Epoch:  274  	Training Loss: 0.001407783362083137
Test Loss:  0.0010788466315716505
Valid Loss:  0.0014976540114730597
Epoch:  275  	Training Loss: 0.001395493047311902
Test Loss:  0.0010734230745583773
Valid Loss:  0.0014897300861775875
Epoch:  276  	Training Loss: 0.0013844403438270092
Test Loss:  0.0010668733157217503
Valid Loss:  0.001483737025409937
Epoch:  277  	Training Loss: 0.0013740317663177848
Test Loss:  0.0010612289188429713
Valid Loss:  0.001478054327890277
Epoch:  278  	Training Loss: 0.0013648851308971643
Test Loss:  0.0010562620591372252
Valid Loss:  0.001473044278100133
Epoch:  279  	Training Loss: 0.0013569608563557267
Test Loss:  0.0010516808833926916
Valid Loss:  0.001468348316848278
Epoch:  280  	Training Loss: 0.0013498584739863873
Test Loss:  0.0010471655987203121
Valid Loss:  0.0014637906569987535
 56%|█████▌    | 281/500 [03:33<04:24,  1.21s/it] 57%|█████▋    | 283/500 [03:33<03:07,  1.16it/s] 57%|█████▋    | 285/500 [03:34<02:14,  1.60it/s] 57%|█████▋    | 287/500 [03:34<01:37,  2.19it/s] 58%|█████▊    | 289/500 [03:34<01:11,  2.94it/s] 58%|█████▊    | 291/500 [03:40<04:12,  1.21s/it] 59%|█████▊    | 293/500 [03:40<02:59,  1.15it/s] 59%|█████▉    | 295/500 [03:41<02:08,  1.59it/s] 59%|█████▉    | 297/500 [03:41<01:33,  2.18it/s] 60%|█████▉    | 299/500 [03:41<01:08,  2.93it/s] 60%|██████    | 301/500 [03:47<03:58,  1.20s/it] 61%|██████    | 303/500 [03:47<02:49,  1.16it/s] 61%|██████    | 305/500 [03:47<02:00,  1.61it/s] 61%|██████▏   | 307/500 [03:48<01:27,  2.20it/s] 62%|██████▏   | 309/500 [03:48<01:04,  2.97it/s] 62%|██████▏   | 311/500 [03:54<03:43,  1.18s/it] 63%|██████▎   | 313/500 [03:54<02:38,  1.18it/s] 63%|██████▎   | 315/500 [03:54<01:53,  1.63it/s] 63%|██████▎   | 317/500 [03:54<01:22,  2.23it/s] 64%|██████▍   | 319/500 [03:55<01:00,  2.99it/s] 64%|██████▍   | 321/500 [04:01<03:31,  1.18s/it] 65%|██████▍   | 323/500 [04:01<02:29,  1.18it/s] 65%|██████▌   | 325/500 [04:01<01:47,  1.63it/s] 65%|██████▌   | 327/500 [04:01<01:17,  2.23it/s] 66%|██████▌   | 329/500 [04:01<00:57,  3.00it/s] 66%|██████▌   | 331/500 [04:08<03:20,  1.19s/it] 67%|██████▋   | 333/500 [04:08<02:22,  1.17it/s] 67%|██████▋   | 335/500 [04:08<01:41,  1.62it/s] 67%|██████▋   | 337/500 [04:08<01:13,  2.22it/s] 68%|██████▊   | 339/500 [04:08<00:54,  2.98it/s] 68%|██████▊   | 341/500 [04:15<03:11,  1.20s/it] 69%|██████▊   | 343/500 [04:15<02:15,  1.16it/s] 69%|██████▉   | 345/500 [04:15<01:36,  1.60it/s] 69%|██████▉   | 347/500 [04:15<01:09,  2.19it/s]Epoch:  281  	Training Loss: 0.0013432338600978255
Test Loss:  0.0010431359987705946
Valid Loss:  0.0014597137924283743
Epoch:  282  	Training Loss: 0.001337084686383605
Test Loss:  0.0010359121952205896
Valid Loss:  0.0014560851268470287
Epoch:  283  	Training Loss: 0.0013345081824809313
Test Loss:  0.001032613217830658
Valid Loss:  0.0014519415562972426
Epoch:  284  	Training Loss: 0.0013327209744602442
Test Loss:  0.0010311033111065626
Valid Loss:  0.001447852235287428
Epoch:  285  	Training Loss: 0.0013311144430190325
Test Loss:  0.0010287363547831774
Valid Loss:  0.0014440977247431874
Epoch:  286  	Training Loss: 0.0013295691460371017
Test Loss:  0.0010263411095365882
Valid Loss:  0.001440513995476067
Epoch:  287  	Training Loss: 0.0013280571438372135
Test Loss:  0.0010241672862321138
Valid Loss:  0.0014370162971317768
Epoch:  288  	Training Loss: 0.0013265721499919891
Test Loss:  0.0010219723917543888
Valid Loss:  0.0014335985761135817
Epoch:  289  	Training Loss: 0.0013251170748844743
Test Loss:  0.001019794843159616
Valid Loss:  0.0014307692181318998
Epoch:  290  	Training Loss: 0.0013236852828413248
Test Loss:  0.0010176380164921284
Valid Loss:  0.0014280884061008692
Epoch:  291  	Training Loss: 0.0013222802663221955
Test Loss:  0.0010155071504414082
Valid Loss:  0.0014254453126341105
Epoch:  292  	Training Loss: 0.001320898998528719
Test Loss:  0.001008969615213573
Valid Loss:  0.0014191908994689584
Epoch:  293  	Training Loss: 0.0013164279516786337
Test Loss:  0.0010046313982456923
Valid Loss:  0.001413325546309352
Epoch:  294  	Training Loss: 0.001312795327976346
Test Loss:  0.0010000438196584582
Valid Loss:  0.0014086292358115315
Epoch:  295  	Training Loss: 0.0013095769099891186
Test Loss:  0.000995793379843235
Valid Loss:  0.0014045368880033493
Epoch:  296  	Training Loss: 0.001306628342717886
Test Loss:  0.0009933494729921222
Valid Loss:  0.0014001738745719194
Epoch:  297  	Training Loss: 0.0013040348421782255
Test Loss:  0.0009906721534207463
Valid Loss:  0.0013966195983812213
Epoch:  298  	Training Loss: 0.001301715848967433
Test Loss:  0.0009877983247861266
Valid Loss:  0.0013936480972915888
Epoch:  299  	Training Loss: 0.0012997024459764361
Test Loss:  0.0009854056406766176
Valid Loss:  0.0013909467961639166
Epoch:  300  	Training Loss: 0.0012978862505406141
Test Loss:  0.0009831679053604603
Valid Loss:  0.001388744916766882
Epoch:  301  	Training Loss: 0.0012963225599378347
Test Loss:  0.0009810762712731957
Valid Loss:  0.0013869267422705889
Epoch:  302  	Training Loss: 0.0012950615491718054
Test Loss:  0.0009768137242645025
Valid Loss:  0.001383035210892558
Epoch:  303  	Training Loss: 0.0012909523211419582
Test Loss:  0.0009732132893987
Valid Loss:  0.0013793702237308025
Epoch:  304  	Training Loss: 0.0012874616077169776
Test Loss:  0.0009698659414425492
Valid Loss:  0.0013760026777163148
Epoch:  305  	Training Loss: 0.0012844076845794916
Test Loss:  0.0009672048036009073
Valid Loss:  0.0013731303624808788
Epoch:  306  	Training Loss: 0.001281914534047246
Test Loss:  0.0009651458240114152
Valid Loss:  0.0013704125303775072
Epoch:  307  	Training Loss: 0.001279848045669496
Test Loss:  0.0009636527975089848
Valid Loss:  0.001368020661175251
Epoch:  308  	Training Loss: 0.001278242445550859
Test Loss:  0.0009622845682315528
Valid Loss:  0.001366014126688242
Epoch:  309  	Training Loss: 0.001276851980946958
Test Loss:  0.0009610771667212248
Valid Loss:  0.001364229479804635
Epoch:  310  	Training Loss: 0.0012755249626934528
Test Loss:  0.0009599454351700842
Valid Loss:  0.0013624915154650807
Epoch:  311  	Training Loss: 0.0012742180842906237
Test Loss:  0.0009590586414560676
Valid Loss:  0.0013607980217784643
Epoch:  312  	Training Loss: 0.001272920984774828
Test Loss:  0.0009631022694520652
Valid Loss:  0.0013610628666356206
Epoch:  313  	Training Loss: 0.0012721717357635498
Test Loss:  0.0009651454165577888
Valid Loss:  0.0013617963995784521
Epoch:  314  	Training Loss: 0.0012717389035969973
Test Loss:  0.0009660740615800023
Valid Loss:  0.0013626990839838982
Epoch:  315  	Training Loss: 0.0012714086333289742
Test Loss:  0.0009663973469287157
Valid Loss:  0.001363655785098672
Epoch:  316  	Training Loss: 0.0012711163144558668
Test Loss:  0.0009664097451604903
Valid Loss:  0.0013646286679431796
Epoch:  317  	Training Loss: 0.0012708513531833887
Test Loss:  0.0009662548545747995
Valid Loss:  0.0013655953807756305
Epoch:  318  	Training Loss: 0.0012706008274108171
Test Loss:  0.0009660219657234848
Valid Loss:  0.0013665531296283007
Epoch:  319  	Training Loss: 0.0012703677639365196
Test Loss:  0.0009657509508542717
Valid Loss:  0.0013674949295818806
Epoch:  320  	Training Loss: 0.001270145527087152
Test Loss:  0.0009654699824750423
Valid Loss:  0.0013684160076081753
Epoch:  321  	Training Loss: 0.0012699374929070473
Test Loss:  0.0009651815053075552
Valid Loss:  0.001369320321828127
Epoch:  322  	Training Loss: 0.0012697416823357344
Test Loss:  0.0009647520491853356
Valid Loss:  0.00136745092459023
Epoch:  323  	Training Loss: 0.0012688958086073399
Test Loss:  0.0009642040822654963
Valid Loss:  0.0013657368253916502
Epoch:  324  	Training Loss: 0.0012681118678301573
Test Loss:  0.0009636231116019189
Valid Loss:  0.001364183030091226
Epoch:  325  	Training Loss: 0.0012673756573349237
Test Loss:  0.0009630366694182158
Valid Loss:  0.0013627959415316582
Epoch:  326  	Training Loss: 0.0012666836846619844
Test Loss:  0.0009624174563214183
Valid Loss:  0.0013616019859910011
Epoch:  327  	Training Loss: 0.0012660245411098003
Test Loss:  0.0009617669275030494
Valid Loss:  0.0013606626307591796
Epoch:  328  	Training Loss: 0.0012654433958232403
Test Loss:  0.0009611232671886683
Valid Loss:  0.0013598487712442875
Epoch:  329  	Training Loss: 0.0012649220880120993
Test Loss:  0.0009604765800759196
Valid Loss:  0.001359127345494926
Epoch:  330  	Training Loss: 0.00126444804482162
Test Loss:  0.0009598644683137536
Valid Loss:  0.0013584962580353022
Epoch:  331  	Training Loss: 0.0012640287168323994
Test Loss:  0.0009593695867806673
Valid Loss:  0.001357954228296876
Epoch:  332  	Training Loss: 0.0012636627070605755
Test Loss:  0.0009589123073965311
Valid Loss:  0.001357578206807375
Epoch:  333  	Training Loss: 0.0012634017039090395
Test Loss:  0.000958490651100874
Valid Loss:  0.0013573134783655405
Epoch:  334  	Training Loss: 0.0012631891295313835
Test Loss:  0.0009581407648511231
Valid Loss:  0.0013570496812462807
Epoch:  335  	Training Loss: 0.0012629859847947955
Test Loss:  0.0009578113676980138
Valid Loss:  0.0013568481663241982
Epoch:  336  	Training Loss: 0.0012628012336790562
Test Loss:  0.0009574876166880131
Valid Loss:  0.0013567042769864202
Epoch:  337  	Training Loss: 0.0012626333627849817
Test Loss:  0.0009572051931172609
Valid Loss:  0.0013565551489591599
Epoch:  338  	Training Loss: 0.001262470381334424
Test Loss:  0.000956947507802397
Valid Loss:  0.0013564139371737838
Epoch:  339  	Training Loss: 0.0012623087968677282
Test Loss:  0.0009567160159349442
Valid Loss:  0.0013562687672674656
Epoch:  340  	Training Loss: 0.0012621503556147218
Test Loss:  0.0009564989595673978
Valid Loss:  0.0013561276718974113
Epoch:  341  	Training Loss: 0.0012619976187124848
Test Loss:  0.0009562947088852525
Valid Loss:  0.0013559877406805754
Epoch:  342  	Training Loss: 0.0012618451146408916
Test Loss:  0.000956463220063597
Valid Loss:  0.0013558696955442429
Epoch:  343  	Training Loss: 0.0012616838794201612
Test Loss:  0.0009564406354911625
Valid Loss:  0.0013557912316173315
Epoch:  344  	Training Loss: 0.0012615271843969822
Test Loss:  0.000956336734816432
Valid Loss:  0.0013557322090491652
Epoch:  345  	Training Loss: 0.001261371304281056
Test Loss:  0.0009562041377648711
Valid Loss:  0.001355684595182538
Epoch:  346  	Training Loss: 0.0012612201971933246
Test Loss:  0.0009560601320117712
Valid Loss:  0.0013556338381022215
Epoch:  347  	Training Loss: 0.0012610716512426734
Test Loss:  0.0009559126337990165
Valid Loss:  0.001355583779513836
Epoch:  348  	Training Loss: 0.0012609250843524933
Test Loss:  0.0009557627490721643
Valid Loss:  0.001355538610368967
Epoch:  349  	Training Loss: 0.0012607816606760025
Test Loss:   70%|██████▉   | 349/500 [04:15<00:51,  2.95it/s] 70%|███████   | 351/500 [04:22<02:56,  1.18s/it] 71%|███████   | 353/500 [04:22<02:04,  1.18it/s] 71%|███████   | 355/500 [04:22<01:29,  1.62it/s] 71%|███████▏  | 357/500 [04:22<01:04,  2.22it/s] 72%|███████▏  | 359/500 [04:22<00:47,  2.97it/s] 72%|███████▏  | 361/500 [04:28<02:45,  1.19s/it] 73%|███████▎  | 363/500 [04:29<01:56,  1.17it/s] 73%|███████▎  | 365/500 [04:29<01:23,  1.62it/s] 73%|███████▎  | 367/500 [04:29<00:59,  2.22it/s] 74%|███████▍  | 369/500 [04:29<00:43,  2.99it/s] 74%|███████▍  | 371/500 [04:35<02:31,  1.17s/it] 75%|███████▍  | 373/500 [04:35<01:47,  1.19it/s] 75%|███████▌  | 375/500 [04:36<01:16,  1.64it/s] 75%|███████▌  | 377/500 [04:36<00:54,  2.24it/s] 76%|███████▌  | 379/500 [04:36<00:40,  3.01it/s] 76%|███████▌  | 381/500 [04:42<02:21,  1.19s/it] 77%|███████▋  | 383/500 [04:42<01:39,  1.18it/s] 77%|███████▋  | 385/500 [04:42<01:10,  1.63it/s] 77%|███████▋  | 387/500 [04:43<00:50,  2.23it/s] 78%|███████▊  | 389/500 [04:43<00:36,  3.00it/s] 78%|███████▊  | 391/500 [04:49<02:09,  1.19s/it] 79%|███████▊  | 393/500 [04:49<01:31,  1.17it/s] 79%|███████▉  | 395/500 [04:49<01:04,  1.62it/s] 79%|███████▉  | 397/500 [04:49<00:46,  2.22it/s] 80%|███████▉  | 399/500 [04:50<00:33,  2.98it/s] 80%|████████  | 401/500 [04:56<01:57,  1.19s/it] 81%|████████  | 403/500 [04:56<01:22,  1.17it/s] 81%|████████  | 405/500 [04:56<00:58,  1.62it/s] 81%|████████▏ | 407/500 [04:56<00:42,  2.21it/s] 82%|████████▏ | 409/500 [04:56<00:30,  2.98it/s] 82%|████████▏ | 411/500 [05:03<01:44,  1.18s/it] 83%|████████▎ | 413/500 [05:03<01:13,  1.18it/s] 83%|████████▎ | 415/500 [05:09<02:10,  1.54s/it]0.0009556161239743233
Valid Loss:  0.0013554890174418688
Epoch:  350  	Training Loss: 0.00126063940115273
Test Loss:  0.0009554706048220396
Valid Loss:  0.0013554453616961837
Epoch:  351  	Training Loss: 0.001260500866919756
Test Loss:  0.000955328403506428
Valid Loss:  0.0013553998433053493
Epoch:  352  	Training Loss: 0.0012603653594851494
Test Loss:  0.000955360708758235
Valid Loss:  0.0013554117176681757
Epoch:  353  	Training Loss: 0.001260357559658587
Test Loss:  0.0009553796844556928
Valid Loss:  0.0013554188190028071
Epoch:  354  	Training Loss: 0.001260346733033657
Test Loss:  0.0009553948766551912
Valid Loss:  0.00135543302167207
Epoch:  355  	Training Loss: 0.0012603392824530602
Test Loss:  0.0009554077405482531
Valid Loss:  0.001355446525849402
Epoch:  356  	Training Loss: 0.001260329969227314
Test Loss:  0.0009554200805723667
Valid Loss:  0.0013554573524743319
Epoch:  357  	Training Loss: 0.0012603224022313952
Test Loss:  0.000955429975874722
Valid Loss:  0.0013554682955145836
Epoch:  358  	Training Loss: 0.00126031250692904
Test Loss:  0.000955438707023859
Valid Loss:  0.0013554779579862952
Epoch:  359  	Training Loss: 0.0012603034265339375
Test Loss:  0.0009554489515721798
Valid Loss:  0.0013554872712120414
Epoch:  360  	Training Loss: 0.0012602964416146278
Test Loss:  0.0009554598364047706
Valid Loss:  0.0013554978650063276
Epoch:  361  	Training Loss: 0.0012602871283888817
Test Loss:  0.0009554692078381777
Valid Loss:  0.0013555099721997976
Epoch:  362  	Training Loss: 0.0012602787464857101
Test Loss:  0.0009462764719501138
Valid Loss:  0.0013562109088525176
Epoch:  363  	Training Loss: 0.0012564559001475573
Test Loss:  0.0009504889021627605
Valid Loss:  0.0013551481533795595
Epoch:  364  	Training Loss: 0.0012532483087852597
Test Loss:  0.0009405793389305472
Valid Loss:  0.0013567740097641945
Epoch:  365  	Training Loss: 0.00125035154633224
Test Loss:  0.0009485151967965066
Valid Loss:  0.0013549062423408031
Epoch:  366  	Training Loss: 0.0012476688716560602
Test Loss:  0.000941238715313375
Valid Loss:  0.0013559694634750485
Epoch:  367  	Training Loss: 0.0012459533754736185
Test Loss:  0.0009496614220552146
Valid Loss:  0.001353852916508913
Epoch:  368  	Training Loss: 0.0012448029592633247
Test Loss:  0.0009400880080647767
Valid Loss:  0.0013545709662139416
Epoch:  369  	Training Loss: 0.0012437243713065982
Test Loss:  0.0009474370745010674
Valid Loss:  0.0013526726979762316
Epoch:  370  	Training Loss: 0.0012427086476236582
Test Loss:  0.0009358866373077035
Valid Loss:  0.0013542661909013987
Epoch:  371  	Training Loss: 0.0012422213330864906
Test Loss:  0.0009495346457697451
Valid Loss:  0.001351362094283104
Epoch:  372  	Training Loss: 0.0012415848905220628
Test Loss:  0.0009471618686802685
Valid Loss:  0.0013516669860109687
Epoch:  373  	Training Loss: 0.0012413670774549246
Test Loss:  0.0009455367689952254
Valid Loss:  0.0013518568594008684
Epoch:  374  	Training Loss: 0.0012412283103913069
Test Loss:  0.0009444036986678839
Valid Loss:  0.001351954648271203
Epoch:  375  	Training Loss: 0.0012411221396178007
Test Loss:  0.0009435955435037613
Valid Loss:  0.001351980958133936
Epoch:  376  	Training Loss: 0.0012410343624651432
Test Loss:  0.0009429945494048297
Valid Loss:  0.0013519596541300416
Epoch:  377  	Training Loss: 0.0012409542687237263
Test Loss:  0.0009425363969057798
Valid Loss:  0.0013519066851586103
Epoch:  378  	Training Loss: 0.0012408776674419641
Test Loss:  0.00094217638252303
Valid Loss:  0.0013518338091671467
Epoch:  379  	Training Loss: 0.0012408033944666386
Test Loss:  0.0009418753907084465
Valid Loss:  0.0013517411425709724
Epoch:  380  	Training Loss: 0.0012407316826283932
Test Loss:  0.0009416209068149328
Valid Loss:  0.0013516438193619251
Epoch:  381  	Training Loss: 0.001240661833435297
Test Loss:  0.0009413963998667896
Valid Loss:  0.0013515392784029245
Epoch:  382  	Training Loss: 0.0012405930319800973
Test Loss:  0.0009341687546111643
Valid Loss:  0.0013522584922611713
Epoch:  383  	Training Loss: 0.0012402040883898735
Test Loss:  0.0009416509419679642
Valid Loss:  0.0013490177225321531
Epoch:  384  	Training Loss: 0.0012396533275023103
Test Loss:  0.0009324485436081886
Valid Loss:  0.0013503613881766796
Epoch:  385  	Training Loss: 0.0012393034994602203
Test Loss:  0.0009403901640325785
Valid Loss:  0.0013470196863636374
Epoch:  386  	Training Loss: 0.0012385864974930882
Test Loss:  0.0009340642718598247
Valid Loss:  0.001347622717730701
Epoch:  387  	Training Loss: 0.001237999415025115
Test Loss:  0.0009382865973748267
Valid Loss:  0.0013456512242555618
Epoch:  388  	Training Loss: 0.001237531891092658
Test Loss:  0.0009331735200248659
Valid Loss:  0.0013459923211485147
Epoch:  389  	Training Loss: 0.0012370452750474215
Test Loss:  0.0009371094056405127
Valid Loss:  0.001344124204479158
Epoch:  390  	Training Loss: 0.0012365574948489666
Test Loss:  0.000932095805183053
Valid Loss:  0.0013444555224850774
Epoch:  391  	Training Loss: 0.0012361170956864953
Test Loss:  0.0009360566036775708
Valid Loss:  0.0013426044024527073
Epoch:  392  	Training Loss: 0.0012355950893834233
Test Loss:  0.0009130015969276428
Valid Loss:  0.001350809121504426
Epoch:  393  	Training Loss: 0.0012278871145099401
Test Loss:  0.0009261730592697859
Valid Loss:  0.0013352376408874989
Epoch:  394  	Training Loss: 0.0012215067399665713
Test Loss:  0.0009115418652072549
Valid Loss:  0.00134041637647897
Epoch:  395  	Training Loss: 0.0012161185732111335
Test Loss:  0.0009197637555189431
Valid Loss:  0.0013309482019394636
Epoch:  396  	Training Loss: 0.0012118020094931126
Test Loss:  0.0009112899424508214
Valid Loss:  0.00133353634737432
Epoch:  397  	Training Loss: 0.0012079195585101843
Test Loss:  0.0009158884640783072
Valid Loss:  0.0013273139484226704
Epoch:  398  	Training Loss: 0.0012045183684676886
Test Loss:  0.0009104290511459112
Valid Loss:  0.0013282744912430644
Epoch:  399  	Training Loss: 0.001201330334879458
Test Loss:  0.0009130141115747392
Valid Loss:  0.0013230947079136968
Epoch:  400  	Training Loss: 0.0011981925927102566
Test Loss:  0.0009086460340768099
Valid Loss:  0.0013231259072199464
Epoch:  401  	Training Loss: 0.0011953078210353851
Test Loss:  0.000910073344130069
Valid Loss:  0.001318873604759574
Epoch:  402  	Training Loss: 0.0011925441212952137
Test Loss:  0.0008817997295409441
Valid Loss:  0.0012990818358957767
Epoch:  403  	Training Loss: 0.0011743626091629267
Test Loss:  0.0008749951375648379
Valid Loss:  0.0012794312788173556
Epoch:  404  	Training Loss: 0.0011598074343055487
Test Loss:  0.0008617683779448271
Valid Loss:  0.0012659687781706452
Epoch:  405  	Training Loss: 0.001148841343820095
Test Loss:  0.000868458766490221
Valid Loss:  0.0012514885747805238
Epoch:  406  	Training Loss: 0.0011410415172576904
Test Loss:  0.0008491450571455061
Valid Loss:  0.0012466339394450188
Epoch:  407  	Training Loss: 0.001134261954575777
Test Loss:  0.0008779429481364787
Valid Loss:  0.0012297736248001456
Epoch:  408  	Training Loss: 0.001129950862377882
Test Loss:  0.0008374279132112861
Valid Loss:  0.0012380746193230152
Epoch:  409  	Training Loss: 0.0011290229158475995
Test Loss:  0.0009187832474708557
Valid Loss:  0.0012226279359310865
Epoch:  410  	Training Loss: 0.001137001789174974
Test Loss:  0.0008371687727048993
Valid Loss:  0.0012602342758327723
Epoch:  411  	Training Loss: 0.0011526766465976834
Test Loss:  0.0010253842920064926
Valid Loss:  0.0012552046682685614
Epoch:  412  	Training Loss: 0.0011898886878043413
Test Loss:  0.0009823535801842809
Valid Loss:  0.0012389100156724453
Epoch:  413  	Training Loss: 0.0011682158801704645
Test Loss:  0.0009534056298434734
Valid Loss:  0.0012303846888244152
Epoch:  414  	Training Loss: 0.0011555913370102644
Test Loss:  0.0009335631038993597
Valid Loss:  0.0012261755764484406
Epoch:  415  	Training Loss: 0.001148222596384585
Test Loss:  0.0009197057806886733
Valid Loss:  0.0012243036180734634
**************************************************learning rate decay**************************************************
Epoch:  416  	Training Loss: 0.0011439069639891386
Test Loss:  0.0008733093272894621
Valid Loss:  0.0012168341781944036
 83%|████████▎ | 417/500 [05:09<01:31,  1.10s/it] 84%|████████▍ | 419/500 [05:10<01:03,  1.27it/s] 84%|████████▍ | 421/500 [05:16<01:58,  1.50s/it] 85%|████████▍ | 423/500 [05:16<01:22,  1.07s/it] 85%|████████▌ | 425/500 [05:16<00:57,  1.30it/s] 85%|████████▌ | 427/500 [05:16<00:40,  1.79it/s] 86%|████████▌ | 429/500 [05:16<00:29,  2.44it/s] 86%|████████▌ | 431/500 [05:23<01:23,  1.22s/it] 87%|████████▋ | 433/500 [05:23<00:58,  1.15it/s] 87%|████████▋ | 435/500 [05:23<00:41,  1.58it/s] 87%|████████▋ | 437/500 [05:23<00:29,  2.16it/s] 88%|████████▊ | 439/500 [05:23<00:20,  2.91it/s] 88%|████████▊ | 441/500 [05:29<01:09,  1.18s/it] 89%|████████▊ | 443/500 [05:29<00:48,  1.18it/s] 89%|████████▉ | 445/500 [05:30<00:33,  1.63it/s] 89%|████████▉ | 447/500 [05:30<00:23,  2.23it/s] 90%|████████▉ | 449/500 [05:30<00:17,  3.00it/s] 90%|█████████ | 451/500 [05:36<00:57,  1.17s/it] 91%|█████████ | 453/500 [05:36<00:39,  1.19it/s] 91%|█████████ | 455/500 [05:36<00:27,  1.65it/s] 91%|█████████▏| 457/500 [05:37<00:19,  2.25it/s] 92%|█████████▏| 459/500 [05:37<00:13,  3.03it/s] 92%|█████████▏| 461/500 [05:43<00:47,  1.21s/it] 93%|█████████▎| 463/500 [05:43<00:32,  1.15it/s] 93%|█████████▎| 465/500 [05:43<00:21,  1.60it/s] 93%|█████████▎| 467/500 [05:44<00:15,  2.19it/s] 94%|█████████▍| 469/500 [05:44<00:10,  2.94it/s] 94%|█████████▍| 471/500 [05:50<00:34,  1.19s/it] 95%|█████████▍| 473/500 [05:50<00:23,  1.16it/s] 95%|█████████▌| 475/500 [05:50<00:15,  1.61it/s] 95%|█████████▌| 477/500 [05:50<00:10,  2.20it/s] 96%|█████████▌| 479/500 [05:51<00:07,  2.96it/s] 96%|█████████▌| 481/500 [05:57<00:22,  1.17s/it] 97%|█████████▋| 483/500 [05:57<00:14,  1.19it/s]Epoch:  417  	Training Loss: 0.0011248212540522218
Test Loss:  0.0008595014223828912
Valid Loss:  0.001217990997247398
Epoch:  418  	Training Loss: 0.001120616914704442
Test Loss:  0.0008543823496438563
Valid Loss:  0.001219455269165337
Epoch:  419  	Training Loss: 0.00111959979403764
Test Loss:  0.0008522628922946751
Valid Loss:  0.0012202656362205744
Epoch:  420  	Training Loss: 0.0011193504324182868
Test Loss:  0.0008525465964339674
Valid Loss:  0.001220005564391613
Epoch:  421  	Training Loss: 0.0011192318052053452
Test Loss:  0.0008526953170076013
Valid Loss:  0.0012198119657114148
Epoch:  422  	Training Loss: 0.00111911550629884
Test Loss:  0.0008567441254854202
Valid Loss:  0.0012155352160334587
Epoch:  423  	Training Loss: 0.0011163410963490605
Test Loss:  0.0008584995521232486
Valid Loss:  0.0012116641737520695
Epoch:  424  	Training Loss: 0.0011139406124129891
Test Loss:  0.0008591710939072073
Valid Loss:  0.0012079071020707488
Epoch:  425  	Training Loss: 0.0011116343084722757
Test Loss:  0.0008593460079282522
Valid Loss:  0.0012042161542922258
Epoch:  426  	Training Loss: 0.0011093660723417997
Test Loss:  0.0008593077072873712
Valid Loss:  0.0012005658354610205
Epoch:  427  	Training Loss: 0.0011071281041949987
Test Loss:  0.0008591703954152763
Valid Loss:  0.0011969561455771327
Epoch:  428  	Training Loss: 0.0011049158638343215
Test Loss:  0.0008589959470555186
Valid Loss:  0.0011933979112654924
Epoch:  429  	Training Loss: 0.0011027302825823426
Test Loss:  0.0008588011260144413
Valid Loss:  0.0011898786760866642
Epoch:  430  	Training Loss: 0.0011005813721567392
Test Loss:  0.0008585395407862961
Valid Loss:  0.0011864156695082784
Epoch:  431  	Training Loss: 0.0010984744876623154
Test Loss:  0.0008583132876083255
Valid Loss:  0.0011829989962279797
Epoch:  432  	Training Loss: 0.0010963953100144863
Test Loss:  0.0008590754587203264
Valid Loss:  0.0011821147054433823
Epoch:  433  	Training Loss: 0.0010961785446852446
Test Loss:  0.0008597894920967519
Valid Loss:  0.0011813272722065449
Epoch:  434  	Training Loss: 0.0010960010113194585
Test Loss:  0.0008604504400864244
Valid Loss:  0.0011806354159489274
Epoch:  435  	Training Loss: 0.0010958549100905657
Test Loss:  0.0008610595832578838
Valid Loss:  0.0011800214415416121
Epoch:  436  	Training Loss: 0.0010957345366477966
Test Loss:  0.0008616268751211464
Valid Loss:  0.0011794744059443474
Epoch:  437  	Training Loss: 0.001095636747777462
Test Loss:  0.0008621489396318793
Valid Loss:  0.0011789902346208692
Epoch:  438  	Training Loss: 0.0010955538600683212
Test Loss:  0.0008626308990642428
Valid Loss:  0.0011785586830228567
Epoch:  439  	Training Loss: 0.0010954885510727763
Test Loss:  0.0008630715310573578
Valid Loss:  0.0011781733483076096
Epoch:  440  	Training Loss: 0.0010954325553029776
Test Loss:  0.0008634794503450394
Valid Loss:  0.0011778298066928983
Epoch:  441  	Training Loss: 0.0010953897144645452
Test Loss:  0.0008638506988063455
Valid Loss:  0.0011775234015658498
Epoch:  442  	Training Loss: 0.001095350831747055
Test Loss:  0.0008578969864174724
Valid Loss:  0.0011802325025200844
Epoch:  443  	Training Loss: 0.0010941755026578903
Test Loss:  0.0008560804417356849
Valid Loss:  0.0011809882707893848
Epoch:  444  	Training Loss: 0.0010939069325104356
Test Loss:  0.0008553059305995703
Valid Loss:  0.0011809831485152245
Epoch:  445  	Training Loss: 0.0010937228798866272
Test Loss:  0.0008548303158022463
Valid Loss:  0.0011807342525571585
Epoch:  446  	Training Loss: 0.0010935505852103233
Test Loss:  0.0008544485317543149
Valid Loss:  0.0011804113164544106
Epoch:  447  	Training Loss: 0.0010933836456388235
Test Loss:  0.0008540968410670757
Valid Loss:  0.0011800797656178474
Epoch:  448  	Training Loss: 0.0010932213626801968
Test Loss:  0.0008537558605894446
Valid Loss:  0.0011797485640272498
Epoch:  449  	Training Loss: 0.0010930646676570177
Test Loss:  0.0008534232620149851
Valid Loss:  0.001179419574327767
Epoch:  450  	Training Loss: 0.00109295011498034
Test Loss:  0.0008536354871466756
Valid Loss:  0.001178872655145824
Epoch:  451  	Training Loss: 0.0010928880656138062
Test Loss:  0.0008535660454072058
Valid Loss:  0.0011785845272243023
Epoch:  452  	Training Loss: 0.0010928348638117313
Test Loss:  0.0008537194808013737
Valid Loss:  0.0011779014021158218
Epoch:  453  	Training Loss: 0.0010925752576440573
Test Loss:  0.0008538661058992147
Valid Loss:  0.0011772445868700743
Epoch:  454  	Training Loss: 0.0010923249647021294
Test Loss:  0.0008540038834325969
Valid Loss:  0.0011766136158257723
Epoch:  455  	Training Loss: 0.0010920854983851314
Test Loss:  0.000854130950756371
Valid Loss:  0.001176012447103858
Epoch:  456  	Training Loss: 0.0010918548796325922
Test Loss:  0.0008542518480680883
Valid Loss:  0.001175431883893907
Epoch:  457  	Training Loss: 0.0010916315950453281
Test Loss:  0.0008543634321540594
Valid Loss:  0.0011748734395951033
Epoch:  458  	Training Loss: 0.0010914178565144539
Test Loss:  0.0008544703596271574
Valid Loss:  0.0011743358336389065
Epoch:  459  	Training Loss: 0.0010912076104432344
Test Loss:  0.0008545642485842109
Valid Loss:  0.0011738187167793512
Epoch:  460  	Training Loss: 0.0010910059791058302
Test Loss:  0.0008546522003598511
Valid Loss:  0.00117331906221807
Epoch:  461  	Training Loss: 0.0010908122640103102
Test Loss:  0.000854743761010468
Valid Loss:  0.0011728409444913268
Epoch:  462  	Training Loss: 0.0010906305396929383
Test Loss:  0.0008503762073814869
Valid Loss:  0.0011693304404616356
Epoch:  463  	Training Loss: 0.0010886609088629484
Test Loss:  0.0008469064487144351
Valid Loss:  0.0011664058547466993
Epoch:  464  	Training Loss: 0.0010871220147237182
Test Loss:  0.0008441025274805725
Valid Loss:  0.0011638763826340437
Epoch:  465  	Training Loss: 0.0010858626337721944
Test Loss:  0.0008418151410296559
Valid Loss:  0.0011616736883297563
Epoch:  466  	Training Loss: 0.0010848268866539001
Test Loss:  0.0008399420185014606
Valid Loss:  0.0011596812400966883
Epoch:  467  	Training Loss: 0.0010839183814823627
Test Loss:  0.0008384280372411013
Valid Loss:  0.0011578523553907871
Epoch:  468  	Training Loss: 0.0010831253603100777
Test Loss:  0.0008371591684408486
Valid Loss:  0.0011563021689653397
Epoch:  469  	Training Loss: 0.0010824534110724926
Test Loss:  0.0008360811043530703
Valid Loss:  0.001154857687652111
Epoch:  470  	Training Loss: 0.0010818366426974535
Test Loss:  0.0008351639262400568
Valid Loss:  0.0011535430094227195
Epoch:  471  	Training Loss: 0.0010812886757776141
Test Loss:  0.0008343700901605189
Valid Loss:  0.0011523815337568521
Epoch:  472  	Training Loss: 0.0010808021761476994
Test Loss:  0.0008321363711729646
Valid Loss:  0.001149998977780342
Epoch:  473  	Training Loss: 0.001078604836948216
Test Loss:  0.0008302928181365132
Valid Loss:  0.0011475294595584273
Epoch:  474  	Training Loss: 0.001076552434824407
Test Loss:  0.0008286911179311574
Valid Loss:  0.001144983689300716
Epoch:  475  	Training Loss: 0.0010746691841632128
Test Loss:  0.0008269828977063298
Valid Loss:  0.0011425022967159748
Epoch:  476  	Training Loss: 0.0010727953631430864
Test Loss:  0.0008252524421550333
Valid Loss:  0.0011400519870221615
Epoch:  477  	Training Loss: 0.0010709904599934816
Test Loss:  0.0008236744324676692
Valid Loss:  0.00113762472756207
Epoch:  478  	Training Loss: 0.0010692765936255455
Test Loss:  0.0008221803000196815
Valid Loss:  0.0011352229630574584
Epoch:  479  	Training Loss: 0.0010676700621843338
Test Loss:  0.0008206758066080511
Valid Loss:  0.0011328505352139473
Epoch:  480  	Training Loss: 0.0010660904226824641
Test Loss:  0.000819155597127974
Valid Loss:  0.0011305355001240969
Epoch:  481  	Training Loss: 0.0010645224247127771
Test Loss:  0.0008176731644198298
Valid Loss:  0.0011282525956630707
Epoch:  482  	Training Loss: 0.0010629715397953987
Test Loss:  0.0008199134026654065
Valid Loss:  0.0011264291824772954
Epoch:  483  	Training Loss: 0.0010617708321660757
Test Loss:  0.0008209608495235443
Valid Loss:  0.0011253897100687027
Epoch:  484  	Training Loss: 0.0010607377626001835
Test Loss:  0.0008215392590500414
Valid Loss:  0.0011246356880292296
Epoch:  485  	Training Loss: 0.0010597645305097103
 97%|█████████▋| 485/500 [05:57<00:09,  1.65it/s] 97%|█████████▋| 487/500 [05:57<00:05,  2.25it/s] 98%|█████████▊| 489/500 [05:57<00:03,  3.02it/s] 98%|█████████▊| 491/500 [06:04<00:10,  1.19s/it] 99%|█████████▊| 493/500 [06:04<00:05,  1.17it/s] 99%|█████████▉| 495/500 [06:04<00:03,  1.62it/s] 99%|█████████▉| 497/500 [06:04<00:01,  2.22it/s]100%|█████████▉| 499/500 [06:04<00:00,  2.99it/s]100%|██████████| 500/500 [06:04<00:00,  1.37it/s]
Test Loss:  0.000821945199277252
Valid Loss:  0.001124001806601882
Epoch:  486  	Training Loss: 0.0010589216835796833
Test Loss:  0.0008234505075961351
Valid Loss:  0.0011229553492739797
Epoch:  487  	Training Loss: 0.001058184658177197
Test Loss:  0.0008241875329986215
Valid Loss:  0.0011222949251532555
Epoch:  488  	Training Loss: 0.0010575205087661743
Test Loss:  0.0008246361976489425
Valid Loss:  0.0011217829305678606
Epoch:  489  	Training Loss: 0.0010569423902779818
Test Loss:  0.0008262100163847208
Valid Loss:  0.0011209144722670317
Epoch:  490  	Training Loss: 0.0010564507683739066
Test Loss:  0.0008269509999081492
Valid Loss:  0.0011203985195606947
Epoch:  491  	Training Loss: 0.0010560210794210434
Test Loss:  0.0008273727144114673
Valid Loss:  0.0011200106237083673
Epoch:  492  	Training Loss: 0.0010556147899478674
Test Loss:  0.0008282744092866778
Valid Loss:  0.0011186576448380947
Epoch:  493  	Training Loss: 0.0010553086176514626
Test Loss:  0.000829074066132307
Valid Loss:  0.0011175530962646008
Epoch:  494  	Training Loss: 0.0010550818406045437
Test Loss:  0.0008297798340208828
Valid Loss:  0.0011166419135406613
Epoch:  495  	Training Loss: 0.0010549138532951474
Test Loss:  0.0008303964859806001
Valid Loss:  0.0011158942943438888
Epoch:  496  	Training Loss: 0.001054786262102425
Test Loss:  0.0008309312397614121
Valid Loss:  0.001115275314077735
Epoch:  497  	Training Loss: 0.0010546876583248377
Test Loss:  0.0008313936414197087
Valid Loss:  0.001114766113460064
Epoch:  498  	Training Loss: 0.0010546098928898573
Test Loss:  0.000831796380225569
Valid Loss:  0.0011143408482894301
Epoch:  499  	Training Loss: 0.0010545485420152545
Test Loss:  0.0008321392233483493
Valid Loss:  0.0011139853158965707
Epoch:  500  	Training Loss: 0.001054499065503478
Test Loss:  0.000832432764582336
Valid Loss:  0.0011136936955153942
