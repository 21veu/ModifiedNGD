/home/yuyi/Documents/ModifiedNGD/utils/readData.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)
/home/yuyi/anaconda3/envs/ng/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/torch/csrc/autograd/engine.cpp:1151.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yuyi/Documents/ModifiedNGD/utils/modified_fisher_inverse.py:78: UserWarning: torch.linalg.svd: During SVD computation with the selected cusolver driver, batches 0 failed to converge. A more accurate method will be used to compute the SVD as a fallback. Check doc at https://pytorch.org/docs/stable/generated/torch.linalg.svd.html (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/cuda/linalg/BatchLinearAlgebraLib.cpp:900.)
  U ,Lambda, Vh = torch.linalg.svd(J)
If Nan?  0
tensor(86.2218, device='cuda:0', dtype=torch.float64)
tensor(42.8074, device='cuda:0', dtype=torch.float64)
tensor(1.6817, device='cuda:0', dtype=torch.float64)
tensor(8.0022, device='cuda:0', dtype=torch.float64)
tensor(28.9292, device='cuda:0', dtype=torch.float64)
tensor(39.9964, device='cuda:0', dtype=torch.float64)
tensor(5.7048, device='cuda:0', dtype=torch.float64)
tensor(62.1127, device='cuda:0', dtype=torch.float64)
perturbed 
 tensor(94.8896, device='cuda:0', dtype=torch.float64)
perturbed 
 tensor(47.0275, device='cuda:0', dtype=torch.float64)
perturbed 
 tensor(nan, device='cuda:0', dtype=torch.float64)
perturbed 
 tensor(nan, device='cuda:0', dtype=torch.float64)
perturbed 
 tensor(31.7339, device='cuda:0', dtype=torch.float64)
perturbed 
 tensor(43.9805, device='cuda:0', dtype=torch.float64)
perturbed 
 tensor(nan, device='cuda:0', dtype=torch.float64)
perturbed 
 tensor(nan, device='cuda:0', dtype=torch.float64)
Train info: 
 train data shape: torch.Size([1024, 8]), 
 train lable shape: torch.Size([1024, 1]), 
 positive / negative: 0.5 / 0.5
Test info: 
 test data shape: torch.Size([512, 8]), 
 test lable shape: torch.Size([512, 1]), , 
 positive / negative: 0.1015625 / 0.8984375
Valid info: 
 valid data shape: torch.Size([512, 8]), valid lable shape: torch.Size([512, 1]), 
 positive / negative: 0.078125 / 0.921875
seed is  1
---------------------------------------- NGD ----------------------------------------
Traceback (most recent call last):
  File "/home/yuyi/Documents/ModifiedNGD/train_H.py", line 289, in <module>
    train(model,mode, lr_decay=True)
  File "/home/yuyi/Documents/ModifiedNGD/train_H.py", line 67, in train
    F_inverse_modified, preserved_eigens = modified_Fisher_inverse(model=model,
  File "/home/yuyi/Documents/ModifiedNGD/utils/modified_fisher_inverse.py", line 78, in modified_Fisher_inverse
    U ,Lambda, Vh = torch.linalg.svd(J)
torch._C._LinAlgError: linalg.svd: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: 1023).
